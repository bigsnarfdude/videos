Okay, the next topic is from Rong Zianna and he is going to talk about the computational mean field game and their immersion. Okay, should I start? Yes. All right, okay, okay. Thank you so much for the invitation. I was originally planned to attend a meeting in person. I was so excited. I was so excited. I can sort of meet old friends and make new friends. But somehow, just two days, right two days before the flight, I got COVID. So I'm sorry that I couldn't be there in person. I almost recovered, but I might still cough a bit, if not too much, during the talk. So I apologize at first. So today I'm going to share some of our recent work. Sorry, some of our recent work. Some of our recent work. Join work with my two excellent students, Jia Jia Yu and Bill Huang. And the majority part of the result I share is actually from them. And also Chen Xiao and Ten Cheng, my colleague at the ECSC RPI. And Jai Chen, a colleague at the IBM, and Wu Chen from University of Southern California and Stan Oshu from UCLA. Okay, the problem we are interested in is essentially this is called optimal control of population dynamics. So, like the picture I show you here, there's a couple of examples. When I learned this from Stan Osha, I think this is a very, very interesting questions. So, therefore, we're trying to do something about that. So, the first picture movie, you see that is imagine you have two point clouds or two groups. Point clouds or two groups of joints fly in space. So, people would like to control the dynamic of those two groups of joints. They have interaction, they want to avoid the collision. The other example as I show is this so-called like crowd motion, for instance. You have a group of population, they want to move out of some space, they have some obstacles. They are trying to move in the shortest way, but at the same time, avoid. Same time, avoid obstacle. And the third, very interesting example is about the recent advance of the deep learning, a so-called deep generative model, which essentially a model of the density moving in the space, in my opinion. So those very interesting different kinds of applications essentially related to this kind of optimal control of the population dynamics. So in one simple sentence, it's essentially doing the following thing. So the population Following thing. So, the propagation dynamic basically, each agent moving the space, basically trying to minimize some kind of cost. This cost can be written as some kinetic energy and some interaction energy and some kind of a termination cost and with some constraint of the population dynamics. So, more precisely, has the following mathematical formula. So, each single player basically would like to minimize. Basically, we like to minimize this objective function. So, L, this you can view this as a kinetic energy, and F is interaction cost, and G is the matching cost about the terminal. And this each single player, they are looking for optimize this energy function. At the same time, the whole population dynamic should, I mean, the whole agent should satisfy the population dynamics. So, people actually show in the literature. Actually, show in the literature so the whole system, if you achieve this so-called large equilibrium, is going to satisfy this two very, very interesting equations. One is called the Hamilton-Jacobi-Baumann equation, and the other one is continuity. If you have some noise here for simplicity, I sort of shut down the noise at this moment, but all our methodology actually can be straightforward to apply to some individual noise case. So, you will see the continuity equation of Foucault-Planck equation. Continuity equation or Foucault-Planck equation. The very interesting point here is for this continuity equation, basically you have the initial density and the continuity equation tell you the mass preservation and the initial density is going to evolve to the essentially final density. Then you have the other backward system. You have this final matching term, basically some kind of guidance of the terminal density and the move backward to. Move backward to the initial. So, those two equations actually talk to each other. It's quite similar as the procedure of the deep learning. You have the forward procedure, you have the backward propagation. So, this is a very, very interesting phenomenon. I think it has a lot of application in terms of that. So, what we're trying to do is basically solve this called a variational mean field gain problem. So, over there, previously, I showed this agent. That should single dynamic in a space, and as a mean field, is actually for the special case of the interaction and the final cost have this so-called potential, and it will satisfy the following variational PDE problem. So, L here is some kind of a given kinetic energy, F is interaction cost, and this is the concern, which is continuity question of the population dynamics. So, this actually is a generalization. So, this actually is a generalization of a very popular problem called optimal transport. If you write down L as exactly kinetic energy, basically it's rho v squared, and you ignore the intact, you basically say induction free and the terminal causes you're asking your terminal is exactly the same as some given density. This is precisely by a more Branier model of the dynamic formula of the operating. The dynamic formula of the optimal transport, which is very, very popular recent years about the data science. So, we're trying to solve the small general formula, meanwhile, our methodology can actually be naturally solved the optimal transport problem. So, there is something between called the mean field planning problem. Over there, you're still asking the row zero is some given density and row one is another given density, but then you can introduce the interaction cost. Okay, so what we're trying to do. what we're trying to do is we're trying to develop a computational scalable algorithms using some conventional methodology in a low node dimension case and also for the high dimension case we're going to leverage some methodology in a deep learning based approach we would like to have our efficient algorithm with a reasonable theoretical guarantee and we hope we can uh connect this to the deep generative model uh sort of uh solve this using the deep generative model and meanwhile Deep generative model, and meanwhile, we can use this as a guidance to improve or enhance the robustness of deep generating model. Of course, we're looking for real-life applications, which I will show you briefly in a picture later. So here's a talk online. So I may give lots of details. I will basically focus on the first two parts. I will talk about conventional vibrational PTE and optimization-based methods for lower-dimensional Euclidean space setup. And after that, I'm going to talk about the sort of inverse problem using a bi-level optimization-based approach. Now, I will briefly mention our generalizational extension to the lower-dimension manifold case. Now, I'll talk about the deep learning-based approach in a high-dimensional setup. So, that's the plan. So, let me say a few words about the literature of the conventional numerical-based approach. Approach. Basically, I'll focus on a dynamic formula. So there's a very rich literature about numerical optimal transport. So, and also mean field, there's a PE-based, purely PDE-based approach, as I mentioned to you before. You have this Hamden-Jacobi-Bauman equation and the continuity equation, and there's a PDE-based approach about that. So, here I want to mention this a very original PDE-based approach using A based approach using the optimization methods. So, in the literature, at least there are two types of optimization-based method. One is called the augmented Lagrangian. So basically, using the augmented Lagrangian method to handle the continuity equation constraint. And the other one is called the primer dual method. Also, use the primer dual basis methods to handle the continuity equation constraints. So if you take a look at this. If you take a look at this two types of methodology, so if you take a look at the sub-optimization problem in terms of row, you take a derivative, you essentially will see some point-wise cubic equation you have to solve. And then once you solve the cubic equation, it's not easy to do the perturbation analysis, which means it's not easy to do our convergence analysis eventually. So the other thing, there The other thing, it might be a bit tricky, is those two types of solvers, it's very, very good, very nice for this special type of energy optimal transport. And over there, you can actually solve it with a closed form. But if you're trying to work in a general kinetic energy L and also a general interaction cost, so you may have to solve some sub- To solve some sub-optimization problem, so uh, so here we would like to do something, we want to design a new uh uh solvers, which is very solvers, very simple, but very effective. And we hope the solver can, the sub-optimal sub-problem can have a fast solver. And we have the naturally a mass conservation property. And we hope our solver can show some convergence to the continuous problem. The continuous problem. And in addition, we also hope our solver should be very efficient and convenient for the inverse problem setup. So here is basically the most important slides, I would say, the idea. So once you have that, the rest of things are very, very natural. So this is based on our observation is if you think about the continuity equation, this is a continuity equation. So the projection to the continuity So the projection to the continuity equation actually have some very, very nice formula. So if you write on the projection step, you write on the saddle point problem, it immediately is going to realize the projection part can be actually solved by some kind of a Poisson equation. And in the Euclidean domain, the Poisson equation actually can be solved very, very efficiently using faster forward transformation. Well, here, depending on the boundary conditions, if you have a Neumann boundary condition, If you have an Neumann boundary condition, you need to use a cosine. If you have a direction, you have to use a sign. So, but nevertheless, this can be solved in a very, very efficient way. And meanwhile, this projection stuff is actually invariant. If you have a different kind of objective function, I just essentially compute the gradient. There, once I compute the gradient, I just project. So, this stuff is actually there. It's always there, no matter what kind of objective function you're choosing, just compute a gradient. Choosing just compute a gradient and project. So, this becomes a very, very efficient algorithm. In fact, that's sort of our initial effort to propose a faster algorithm. Now, you can discretize it using standard numerical PDE techniques, which I will skip this part. Then we can come up with a discretized solver. So, in fact, this is not a new algorithm at all. It's very well-known algorithm called the Very well-known algorithm called the FISTA, a faster E2D softer special algorithm. Actually, people show that for a given discretization level, if you have the problem is convex, then this FISTA algorithm is going to converge to the optimized in the discretized level. So this is actually just the application of the FISA in some sense. So as I mentioned, this projected gradient descendant method is actually flexible. So the gradient descendant. So the gradient descent step is actually very, it can be very easily implemented and it also is element-wise. And also the projection step can be very, very efficiently computed using fast cosine transformation. So meanwhile, we can also accelerate this projective gradient descent method combined with, for instance, multi-grade strategy. And later on, I'm going to show you how this actually can be accelerated. This actually can be accelerated a lot. So, the other nice part of this projective gradient descent method is it's easy to do perturbation analysis because the gradient descent step, you can do the perturbation using Intel expansions. And the pausal equation part, you can also do the perturbation. This is very different from the previous algorithm based on augmented Lagrangian or Prime Minister. Over there, there's a cubic equation you have to solve. Those cubic equations, the root of the cubic equation is not easy to do perturbation analysis. Is not easy to do perturbation analysis. As far as I know, I don't know how to do it. But for this algorithm, we can easily do the perturbation analysis, which gave us an opportunity to show the convergence of the discretized solution to the continuous optimizer. Actually, this is for the first time we establish the convergence result in using the optimization algorithm to approach the continuous. So, let me show you some. So, let me show you some quickly show you some results. This is a comparison for optimal transport setup. So, you can see this FISTA algorithm is actually FISTAR is actually based on our algorithm and multi-level FISTA and the multi-grid FISTA. And there is some other method is augmented Lagrangia, as I mentioned to you, and the GProxy is essentially paramount durable based methods. As you can see, that our method is actually the feasibility versus always. The visibility residue is always very small, and the mass residue is actually very, very small compared with other two methods. All the two methods. And also, in terms of time, if we use the multi-level or multi-grid strategy, you can see here, this is about like 20 times speed up. So now I can show you some interesting pictures. So this is show if we have some interaction. This is called a cloud motion. So if you have an interaction. The cloud motion. So if you have interaction and the mass moving the space can successfully avoid the interaction. And this is a different regularization. Oh, sorry, different interaction term to give you different movement, sorry, give you different movement. What's going on? Give you different density evolution in the space. You can see the optimal transport case, this is this guy. And this is the, if you choose the Fe is the row. If you choose the Fe is the rho square divided by two, and this is a if you choose this is one over row, you will see different effect of the density evolution in the space. So here is a mean field setup and some comparison with the mean field planning. So now, once we have this forward solver, we actually ask a question about this inverse mean field gain problem. Over there, when you handle the population dynamic, When you handle the population dynamics, so imagine a possible setup is you have a group of drones flying in space. So somehow you don't know the environment of the space. But after you send a couple of group of joints flying in space, then you say, can I, based on the density or trajectory of this group of joint, can I detect the environment of the space? Then later on, I send a new group of joint and I can have a smart way to avoid the obstacle. So in the setup, Obstacle. So in the setup is basically the obstacle B is unknown. And in some cases, maybe you have a different choice of magic. G is also not unknown. So our inverse problem setup is say, based on the given training data, can we actually reconstruct the obstacle or maybe also the reconstruct the magic? So that's the setup of the inverse problem. So there's some literatures in the inverse problem. Problem of this amine field problem. As far as we know, so there's the actually Ha Ming is sitting there in the audience. So they actually propose one of the first sort of inverse setup is so-called inverse optimal transport. Over there, they don't really handle the dynamic formula, but the Nino programming formula use of the entropy regulation. They have a very, very beautiful theory to say they can actually. To say they can actually change the ballot problem to be a single-level optimization and solve it in a very elegant way. The other paper is actually from Stan Osho's group. They propose this inverse mean field gain problem. But their methodologies are not exactly using a bi-level based methods. They basically write down the lower level constraint as the key constraint, homogeneous bow mass continuity equation as the kickety point of the mean field gain. Of the initial game, then they solve this non-convex optimization problem using a single level. So, what we're trying to do is we want to directly use the bad level method. We want to analyze the discretize the bad level system. We want to show whether this bad level formula can really give us the reconstruction guarantee of the desired obstacle on the metric. And also, we want to design an algorithm, and hopefully, we can have some theoretical convergence guarantee of the algorithm. Of the algorithm. And meanwhile, we're working on some higher dimension using a deep learning-based approach to do the inverse problem. So, now let me show you. Maybe I only have a couple of minutes. Let me show you all this. So, here's the bi-level formula we are considering. So, basically, you have a group of training data. So, based on some on OMB, suppose you have the group of training data of the density and the flux movement. Flux movement in the space, I'm saying I want to look for obstacles such that the obstacle created the density should match my given training data. And a similar idea, suppose I don't know the metric, the G part. So I'm saying for a given set of the training data, rho m and g m evolving space for unknowing g, I'm saying I'm looking for a G such that A G such that I can solve this mainfield gain problem. I got the row and M, and I should match my training there. You here, you can view this as the difference, the L2 norm difference, or whatever norm difference. And you may probably, you may add in some kind of regularization there as well. So this is basically the bad level setup. So actually, we are able to show this very preliminary. Able to show this very preliminary version of the theorem based on the discretizer setup. So the theorem basically tells us: if you assume, given a B, and there always exists a unique pair of the rho and M, then with a suitable initialization, the suitable choice of the distance to the aground source, actually, the problem we're solving, suppose we can solve this optimization problem, then the solution. Problem, then the solution will give us exactly what we're looking for for the obstacle curves case. So we're still working on the theorem for the metric case, but this is what we have so far. So then we also design a numerical algorithm. So this is a, I write on simplified version. This is a so-called generalized alternative gradient descent methods. This is actually a general methodology can be applied to some other English problem as well. But here I just to English problem as well. But here, I just to present you this one. I mean, the simplified version is very, very naive, straightforward. Actually, what you do is you remember our mainfield gain problem is actually a constraint optimization problem. What you do is you do that projection gradient descent approach, that forward solver, run a couple of iterations, then you do the projection of the upper level problem. So the tricky part is you run. So, the tricky part is you run a couple of intuition here. You have to, when you compute the derivative, you have to backtracking all the layers you actually have. This is essentially the same idea as the back propagation in the deep learning community. So, we actually leverage that and then we have this very effective algorithm. And we can also show some convergence result with a reasonable assumption, basically, the objective function. Assumption, basically the objective function is the upper level use upper level. Upper level is the Lipschitz continuous, and the lower level also continues. And then we can show the iteration of this proposed algorithm actually in the average sense is going to converge. So that's what we have. Now, let me show you some very, very preliminary numerical results. We're actually working on the preprint of this paper. It's not ready yet. So as you can see, Is not ready yet. So, as you can see here, the first row of the picture of the movie. Sorry, the first row of the movie basically have the different kinds of obstacles. The movie actually shows a number of iterations. When the iteration goes on, goes on, starting from the randomly issue guess, and eventually we can get back to the obstacles, which means we can detect the environment. And meanwhile, another advantage is Meanwhile, another advantage is once you solve this B problem, actually you also automatically solve the lower level problem. Then you can actually have the trajectory as well. And the second, the bottom one is about the knowing the metric. So here is very a toy example. We consider this 2D problem. We put this metric, satisfy this condition, our ground truth. Then the movie shows you after the Then the movie show you after the optimization iterations, you will see this metric actually gradually approach to what we're looking for. So I have, I think I have a five minutes. Let me say something about the high dimension case. So I'm going to skip this part. So actually using the similar methodology based on this projected gradient descent method, we can actually generalize this mean field gain problem on the manifold effect. Game problem on the manifold. In fact, the reason is in many real-life problems, especially in data, the core problem is not exactly sitting in the Euclidean space, but a high-dimensional manifold. So that's our major motivation to do this on a general setup. So I skip this part. Let me show some pictures and we can do computation on the manifold and the different kinds of manifold. It could be with a very complicated topology. It could be with a very complicated topology. I think one of the previous speakers mentioned their beautiful methodology solving the optimal transport on this on the unisphere. So here we automatically have a solver for the optimal transport on the manifold. So this could be very complicated shapes, like different animals, or we don't really care about the co-dimension of the manifold. As long as the dimension of the manifold is low, like 2D, 3D, if you have a triangle mesh, tetahron, or you have a point card, the representation. Titron, or you have a point card representation, we can solve them. Now, I'm gonna, since I have a couple minutes, I'm gonna say something about solving this in a high dimension using some deep neuronal baseline methods. So one of the sorry, one of the motivation to do this in a high dimension is many practical problems actually can be modeled as a high-dimension referging problem. Here in the movie, I show you, you have a group of actually eight groups. A group of actually eight groups of point clouds, or you can view this as eight groups of joints. They find a space, they're trying to avoid the collision and each opposite direction wants to switch. So if you think about the conventional numerical P methods, so each of the group actually is a 2D problem. You have eight groups, they actually have an interaction. So if you want to avoid the condition, so this is overall 16 dimensional. condition so this is an overall 16 dimension problem it's not easy to solve or it's just impossible to solve using conventional method and the other movie the other picture i show is the robot arm control problem so the configuration space the configuration space of the robot arm is actually not three-dimensional but the high dimension depends on the freedom of the joint of the robot so you want to control the the the movement of the uh path planning of the robot moving in the configuration space to avoid Moving in the configuration space to avoid a possible obstacle and at the same time minimize some kind of a cost you are looking for. So, this is also a high-dimension control problem. It's not easy to do using the conventional-based methods. So, in the literature, actually, Lars and Stan, they have a pioneer work using a deep neural network. Their methodology is solving the use of neural network to represent the density and also the control. Then, then they can write on the Then they can write on the constraint for the constraint humanitarian could be Baumann equation and continuity equation to be some constraint and they use some apparent-based method to solve this constraint optimization problem. What they have is basically density and v. So we're trying to design a very different idea and solve this directly using the trajectory-based methodology. So, and this is actually immediately connected to some deep genetic model, which I will. Some deep genetic model, which I'm going to skip. Now, here's what we're trying to do. I put a QR code if you're interested in, you can actually see the paper. So, what we're trying to do is we're using, we want to connect this mean field gain problem with the so-called normalizing flow. Actually, one of the previous speakers also mentioned this, because normalizing flow basically is the idea to transport the density in the space. And meanwhile, this is like a bi-direction. Meanwhile, and this. Meanwhile, and this mean field gain problem will give some guidance to enhance the performance of the normal inert flow. So, as I mentioned, normal inflow is basically the way, the composition of the mapping to move the density from a simple density, let's say Gaussian, to some very complicated density. So, here is our idea. Basically, we say instead of using the value function and the value function and the the the the control so we're trying to uh discretize or write down the mean field game problem using the trajectory based formula so write down the trajectory based formula if you write down the trajectory based formula you think about the od the ode in terms of the trajectory based formula you can write down the the trajectory as a bunch of the composition of the mappings which is exactly the idea of the normalizing flow so so therefore we can actually using this to combine with the conventional To combine with the conventional normalized flow techniques to solve this high-dimensional mean field gain problem. And meanwhile, the other thing is, if you think about that, conventional normal and flow user design actually minimize the KL divergence directly without doing this control. So they don't have the kinetic energy, don't have the interaction. So for the kinetic energy and interaction, in terms of the meaningful game, you can feel this as a regularization of the normal and flow. Of the normal end flow. And a simple argument can show that if you do this, for instance, the kinetic energy regulator, this can actually reduce the Lipschitz constant of your normal and flow, therefore can enhance the generalization gap of your normal flow. So let me show you, let me have one minute. Let me show you some results. We have some approximation theorem about how the neuron article can approximate the solution in a reasonable way. And I'm going to skip this part. and I'm going to skip this part. So here is some some ways we're solving this optical transport in high dimension. So as you as you can see the dimension can be two dimension, 10 dimension, 50 dimension, 100 dimension. But compare our method with the mainfield game network, as I mentioned, Larson the standard work. You can see because we actually do not force using the parity based method to force the continuity equation and the homoting of the Bellman equation. homoting or bellman equation we directly do that using the uh particle-based approach so therefore our uh we don't have that uh uh constraint problem so therefore our actually our matching term is actually uh is is more improved and also our time is actually uh much more uh efficient or more linear uh scanning in terms of dimension and there's another one is like uh doing the crop motion Is like doing the crawl motion in a high dimension. So you will see here is a two-dimensional case, 10-dimensional case, 50-dimensional case, 100-dimensional case. So here's some two slides we actually just have quite recently, which I would love to share with you. So this is the cloud moving in the space, and you have some interaction, you have some interaction, and you and I actually successfully solve that. Actually, successfully solve them and can actually successfully avoid a collision, and they can also switch the direction. And this picture shows you two clouds. If without the interaction and also the obstacles, they actually move directly from bottom to top, and there's no change of the trajectory. But now, if you put the if you put the constraint, if you put the obstacle and also put the induction, you can see the point cloud can be actually Cloud can be actually naturally moved, and because of the interaction, and this purple dots actually will be affected by the blue dots. Also, the trajectory also can be affected. This is a, I actually got this result this morning. It may not be the best so far, but it actually can solve this robot pass planning problem. So, this is a really high dimension, essentially a 10-dimension problem. Now, we solve that, and you can see this. That you can see this robot arm actually can start from a given point can avoid the obstacle and heading to the target. Okay, that's down then we can also, as I mentioned, we can go back and show the enhancement of the normal energy flow. This is a picture show you, if you control the if you have a control of the kinetic energy and the intensity, you have the enhanced generations. So I skipped this part maybe. So I skipped those parts maybe. So summarize, we propose a projected gradient descendant-based method. So solving mean field gain problem. We have a balloon to solve inverse. And also we combine with the normal underflow to solve high dimension. Okay, I should stop. Sorry. That's it.