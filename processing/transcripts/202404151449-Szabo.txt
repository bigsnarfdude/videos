Organizers, for giving me the opportunity to speak here. So, this is joint work with Jan Schweig, who's in Prague, and Christina Tonin Alli, who's in Paris. And first, I will talk about stability of molecular cellular automata, and then I will talk about how to generalize these things for random molecular cellular automata. So, first, let's see the general setting. So, I will consider a cellular alternative for the D-dimensional integer lattice. All my pictures and examples. All my pictures and examples will be in two dimensions, but everything I say works for any dimensions. So I will consider cellular optometer, which is a discrete time marker chain on Zd, where every vertex can be either in state 0, which is the empty circle, or state 1, which is the full circle. And at every discrete time step, every site updates the state based on some local monotone map. Local map meaning that it depends. Local map meaning that it depends on finitely the coordinates, and monotone means that it's monotone in the coordinate-wise order of the configurations. That is, if for some configuration we get the bad gives one, then if I add more ones to this configuration, it should also give one. Right, so let's see two examples for these local rules that I will use throughout the talk. So, both are majority voting rules. The first one is Tunes rules. The first one is tools rules. So, in this case, if we want to update the state of this middle vertex, then it will check its own state and the state of its north and east neighbors, and it will tweak to the majority. So if at least two of these three vertices are in state one, then this vertex will clip to state one. If at least two of them in state zero, then this will be zero in the next step. And the other one is the nearest neighbor voting, which is very similar to this Tunes rule. Similar to this tomb's rule, but now when we want to update the state of this middle vertex, then it not only checks its own state at the north and east neighbor, but also the south and west neighbors. So it will flip to the majority of these five vertexes. So when we start the monotone cellular automata from some initial configuration, then at every time step each vertex updates themselves based on this local rule, or this shifted version of this local rule. Version of this current rule. And up to this point, the evolution is completely deterministic. So, what we do is we subject this evolution to some random noise in the form of defective sets. At each time step, every site will be defective with some small probability p independently of every other vertex. And when a site is defective, then it will flip to zero in the next lifestyle. So, in this case, we have this 3D. So in this case, we have these three defective sites, they will all be zero in the next step, and every other vertex will update its state based on these two sports north-center vortex. And in this case, so when we have this random evolution, so if we started from the O1 configuration, since our map is monotone, in the absence of defective size, we would forever be in the O1 configuration. But we can ask how the introduction is. But we can ask how the introduction of this noise will affect the behaviour, the evolution of our process. The defect and the uh update are alternating or at the same time? So before you die because of a defect, can you still infect your neighbor? So everything is at the same time. So now, let's say we have these defects, this will update based on the state of these tree. So this will be one. Of these three, so this will be one in the same step, this will be zero. So the defect is at like zero prime or it's continuously predicted? Are the defects at fixed sites or do they move around fixed site? They move around. So every time step, every site is defective with some probability B. And then the defect can be ch is changing the defect as far as Yes. So at each time step So at each time step we have different effective size. Everything independent, right? At every step, we have independent effective parameters. Yes. So maybe this simulation will help. So now we have with some small probability. We start with the initial configuration OL1 that we have defective sites with some probability P, and then we can see how this works. So we can see that these defective sites pop up. These defective sites pop up. And in case of the Northeast Center voting, what we see is that even if we have some small cluster of defective sites that appear together, they will soon disappear. So we will only have basically the defective sites that immediately disappear. But in case of the nearest neighbor voting, we do have some sets of defective sites that if they appear together, then they will forever be present. And then with the appearance of other defective And then with the appearance of other defective sites, this set of zeros will keep growing and they will eventually take over the whole space. Does defective mean it always goes to zero? Does it just mean defective? It always goes to zero. Defective is always zero. And it turns out that these are the two kind of behaviors that we can observe. So if p is very small, then we will either be very close to the all-long code ratio, or zeros will take over the possibilities. And before I move on, formalizing things a bit more, let me just tell you how it relates to bootstrap percolation, because this whole workshop is about bootstrap percolation. So when we talk about bootstrap percolation, then we have at time zero some set of initially infected sites. So we could think about in this framework as having at time zero defective sites, and the defective sites are the infected sites. sites are the infected sites. So infected vertices would be the state zero vertices. And then it was repercolition, we wouldn't have defective sites at any later time. So we only have the defectives at time zero. And the local monotone map that we apply, we would need to choose this map in a way that ensures that once the vertex is in state zero, then it will forever remain in state zero. So it sort of fits into this framework and so like this is what we And so, like, this is what we would have in bootstrap percolation. This is the directly triangular bootstrap percolation. This is the two-level bootstrap. And we could similarly define stability for bootstrap as well. So we would say that the system is unstable if zeros will take over, no matter how small the initial probability of p vector stats are, unstable if for small p, zeros will not take over the possibilities. So we can define this same. So we can define these same sort of things for bootstrap as well, but here we will need to allow defective sites only at time signal. But yeah, so for our setting we can have defective sites at time set. So to be a bit more precise, so we look at a cellular autonomy on Z D that at each space-time point applies either the map phi, which is a local map, probability 1 minus P, or Phi Z. 1 minus p, or phi 0, the defective map, which gives the outcome 0 with probability p. And then how can we define stability? So we start from the all-1 configuration, and then we look at the state of the origin at time t, and we look at the probability that the origin is in state zero. We let t go to infinity, because we are interested in the long-time behavior, and we let p, the defective side probability, go to zero. And if this limit is the same, And if this limit is zero, then we say that the central automaton is stable. We can define the critical parameter as the supremum of the parameter values of P, for which the time limit of this probability is treated as one. And then in this case, stability would mean that Pc is treated larger than zero. So if we are thinking about boost percolation mindset, then stability is the stability is Vc greater than zero and unstable would be Pc equals zero. And in 1980 Tum introduced the paper in which he completely characterized all these local volatile maps in terms of stability and he proved that a monotonous standard or automata is stable against random perturbations if and only if its monotony map is an erotor. Now what is an erotor? Now, what is an eroder? We say that a map is an eroder if, in the absence of defective sites, any finite set of zeros would disappear in a finite number of steps. So, let's check if this works for our two examples. So, here for north-east-central vaulting, assume we have this finite set of zeros, and now we will only apply the north-east-centric vaulting and not the effective setting. Now, if we have a finite set of zeros, then we can draw a random. Of zeros, then we can draw a right triangle around them. Any vertex outside of this triangle is in state zero, and they will forever stay in state zero because they are in state zero, and at least one of their least or worst neighbors are also in state zero. So the zeros must stay inside this triangle. And if we look at this triangle, if we check the vertices below the diagonal, then they have their north and east reversed outside of the triangle. Reversed outside of the triangle. So, in the next step, the triangle must become smaller. And so, within the finitely many steps, this triangle will disappear. So, indeed, these finite set of zeros will disappear. So, this map is indeed an eroder, so we have stability. What can we say about the nearest neighbor voting pool? So, here, if we have any finite configuration of zeros, which one period is, Configuration of zeros, which one per rectangle, then they will forever remain in state zero because every vertex in the rectangle has themselves in state zero and at least two of their neighbors. So which means that at least three out of the five relevant vertices are in state zero, so they will forever remain in state zero. So for these two rules, this is quite easy to check this eroder condition, but of course we could have more difficult rules, and as I said, everything works in any. And as I said, everything works in any dimensions. So, in higher dimensions, it might be quite hard to check by hand whether this works or not. But later on, not in Tung's original paper, but in some later work, an equivalent condition for being an eroder was introduced. And this condition used minimal one set. So, for any math 5, we can define its minimal one set. Its minimal one sets as minimal subsets of our vertex set, such that if we have a configuration which is one on A and zero everywhere else, then our local map gives the outcome to one. These are minimal sets of ones that ensures that the outcome will be one. And we have the following collision phrase on the rotor if and only if the intersection of the comax hell of these minimal one sets is. This minimum one sets is empty. And again, we could check our two rules. So we had the Norse east center voting, where we needed two out of these three vertices to be in state one in order for the map to fit the output. So what are the convex hulls? So we have any subset of two is a minimal one set. So we have this one as a convex hull. We have this line as a convex half half. We have this line as a convex black, we have this one, and indeed their intersection is zero. So again, we can see that this is an erotor. And if we look at the nearest neighbor voting, then we have these five vertices and we need at least three out of these five vertices to give the outcome one. How can we choose three vertices? Well, they could be along the same line. Could be along the same line, that this is a convex alpha, and we have another one, a vertical one, or they could form a triangle. We could have smaller triangles like this. We have four of these, and they could also form a larger triangle. We also have four of these. And I'm not drawing all of these things, but we can see that all of these convex houses will contain the origin. These convex house will contain the origin. So, therefore, this map is indeed an emotion. And again, this is something that if we are used to bootstrap percolation, this is a different way of thinking because for bootstrap, as I said, infected sites are zeros, so updated families are determined by minimal zero sets instead of minimal one sets. Right. But so, what is the interest? But so what is the intuition behind these eroders? So how can we really see what's happening? So it turns out that just like for Booster percolation, the way that the behavior of the cellular automaton is determined is determining how these rules act on calculates. So for any direction u, we can define this closed calculate hu which Halfway, HU, whose boundary is perpendicular to U, and then we let every vertex on HU be in state one, but every other vertex being state zero. And then we want to see what happens if we let the standard automata started from this initial configuration evolve for one step. And we can determine the edge speed for this direction u as the speed of once, like how much. Of ones, like how much this boundary will move in one step of the evolution of the stellar oxygen. If this boundary doesn't move, then the speed is zero. If the boundary, if ones will be spreading, then we see how many steps these ones will be spreading, and then we will have a positive speed. And if ones will be shrinking and the zeros are spreading, then we would have a negative speed. And this is the formula that actually gives us the edge speed. And if we have a closer look at this formula, then it's quite easy to understand how it works. So assume that this is the set of ones and this is the zeros that we have. Say that here, this is the origin. So assume that we have some minimum ones that are like this is the Minimum one set, or like this is the convex hell of the minimum one set here. Now, this minimum one set is completely in state one, so it ensures that the origin stays in state one. But then we can look at the distance of the minimum one set from the origin, which is L. If I would shift this minimal one set to the left by L, it would still be completely a state one. Which means that if I take the vertex here, which is a distance L from the origin, L from the origin, this will link to 1. So the boundary will have to move at least L. And this L, this list, is just the infinite of the scalar product of U and all of the vertices in minimum one set. So this is the distance of a minimum one set from the boundary of the half plate. And why do we have the supremum? Because this is one of the minimum one sets, but Is one of the minimal onesets, but we might have multiple ones, right? So if we had a minimal one set here, let's say V, which is a larger distance, then ones would move even more. This is L2, then we know that vertices of distance L2 from the boundary would also be one. So that's why we have this supremum of the infinite of the scalar product. The scalar product. So we have these ash speeds, and we can determine this for every direction. And my statement is that phi is a derodor, which means that finite set of zeros with secure. If and only if we can determine directions such that their convex envelope contains the origin and that the sum of the h speed is true. Why is this true? So if we have directions that such that they're convex envelope contains the origin, this means that I can draw a polygon, let's say a triangle, whose sides are perpendicular to these directions. Let's say this is u1, u2, and u3. And so if I have a finite set of zeros, then I can draw a large enough polygon determined by these directions. Determined by these directions around this finite set of zeros. Now, first assume that the speed of all of these directions is non-negative, so positive or zero. So let's say in these two directions it's positive and here this is one. This means that these two sides of the triangle will not move, as we have seen for the northeast central volting. And this side will have a positive direction, so it will keep shrinking, and then this polygon will be like. And then this polygon will eventually shrink, and zeros will be simple. But here we have a slightly stronger, weaker condition. We just need that the sum of the speeds is strictly positive, because we could have, say, for example, a rectangle where the speeds here is 0, 0, we have speed 2 here, and speed minus 1 here. And assume that everything is in state 0 inside the rectangle. Inside the rectangle, we know that this boundary moves at speed 2, so at each time step, two of these columns will flip to 2. But the other boundary moves at speed minus 1, so it will grow only one step in that direction. So it will still be shrinking. So it's possible that we have a set of zeros that keep shrinking, but moves around a little bit in space. So this is the intuition of Of why being an eroder means that zeros will disappear, and how is determined by how the rule acts on headlines. Right, so let me say something a little bit about the proof of Tung's theorem. So it says that a monotonous stellar automaton is stable if and only if the map is a reloton. Now, one direction is quite easy if a map is not a. If a map is not an eroder, then the cellular automaton is not going to be stable. Why is it true? If a map is not an eroder, then there are finite set of zeros that will never disappear, once it appears. So eventually, almost surely, everything will be zero. The other direction is a bit more tricky, which says that if pi is an erotor, then we have stability. And since we have defined these We have defined these polygons that we have here. One could suspect that we'll have to track the growth of these polynomials, just like we do in bootstrap calculation, these growths of proplace to prove stability or being strictly positive. But this is actually not what's happening here. We have a fires argument. And I will just tell you the main idea behind this. So how does this fires argument go? Assume that we find a zero. Assume that we find a zero at some large time, then we want to know why it flipped to zero. We started from the OL1 configuration, so there must be some defective size that causes vertex to stay zero. So we keep looking back in time and explore its history, and we stop when we have found all the defective sites that contributed to this bad text being state zero. And then we can build this oriented. Then we can build this oriented graph, which we call an explanation graph. And then the probability that the origin is in state zero can be bounded from above by the expected number of these explanation graphs. Then we know that each defective site is present with probability p. So if N D denotes the number of explanation graph with D defective sites, then this expected value is just a sum over P of N D times definitive D, and we would want this to go to zero. And we would want this to go to zero. However, unfortunately, we can't count this N D efficient. So what we would need is an exponential bound in D on N D, and we can do that. I'm not saying that N D is larger than exponential. We also can't prove that it's larger than exponential indeed, but we can find an efficient way to do this. And so what Toon did is he introduced some weird constructions. Some weird construction, some weird subgraph of this exponential graph, which is called the two contours. And when we construct these two contours, the way it's constructed is determined by how we choose these polygons that we keep shrinking. And this construction is quite involved, and I'm not going to talk about it, but it has some nice properties, the tool contour that we have, which allows us to count now as. Allows us to count now and the number of tune contours with the defective sites and get an exponential count. So, this was tomb result, and what we have done is we sort of redefine these two contours in a way that we could give an intuitive meaning to it, and also generalize these two contours to random monotonous cellular automata. So, what is a random monotone cellular automata? So, so far we have considered cellular automata, which applies. Cellular automata, which applies one local map, and now we subject this to some others. What we can do is consider a cellular automata that applies multiple local maps, phi1 to phi n, and at each time step each vertex chooses one of these local maps based on some probability distribution. So it will choose a map phi i with some probability phi i. So already without So, already, without subjecting it to random noise, we do have some randomness. And it turns out that when we do this, things are getting much harder very quickly. So, as I said, we have generalized two cottons for this kind of random molecular cellular automata, and one could immediately find a trivial condition for this random molecular cellular automata. This random model cellular automaton to be stable. Namely, if we can choose these maps phi one to phi m in a way that they are all erodors and we can choose a single polypo that corresponds to all of these maps and would shrink under all of these maps. Then it's quite simple to generalize the result and show stability because regardless of what we do if we have some finite set of zeros, We have some finite set of zeros, we could just put a polygon around it, and no matter which rule we will decide to choose, this polygon will keep shrinking. So that's a trivial generalization, but if we want to do anything harder than with anything different, then we have to work much harder. One thing that we would be particularly interested in is a cellular automaton that applies some of That applies some locomotives to file and one additional map, the identity map. Now, what does the identity map do? It does nothing. If the vertex was in state one, then it remains in state one. If it was in state zero, it remains in state zero. So this is really the simplest possible thing that we can imagine. And then we subject it to some random noise, try zero, with some point. And we want to see. And we want to see how this cellular torpedo behaves. Why are we particularly interested in this? Well, if we choose the parameter in a way that P equals epsilon and 1 minus Q times 1 minus P is lambda times epsilon and also rescale time by epsilon, then as a continuous time limit, we get monotonous interactive particle systems. Now, if you're not familiar with interactive particle systems, so this will be continuous. Systems. So these will be continuous time systems or Zd. And in this case, each side would have two exponential clocks, one at rate 1 and one at rate lambda. If the rate 1 clock rings, then it updates a state based on the defective map. If the rate lambda clock rings, then it updates a state based on the other log ring map. But in this case, of course, we lose this simultaneous updates of the site. Updates of the site. And we could ask what happens now. And one natural intuition would be that since we are applying the identity map, which just leaves the vertices in the state that they've been in, that it's just going to slow down the whole evolution, and nothing particular will happen. But this is actually not the case. And it turns out that just by introducing this identifier, it can actually It can actually change the behavior from stable to unstable and also from unstable to stable. Because there are situations, for example, if we look at this report, this speed that we get to here and the speed minus one, so these speeds are attained at different set of minimum ones. And it is possible that when we apply the identity map, Identity map, it will slow down this speed much more than it slows this up. So that it's possible that actually this right-hand side of the referral will not catch up with the left-hand side, and instead it will keep increasing. So already, when we introduce this identity map, things are going to be a bit more difficult, and there is no complete characterization of the No complete characterization of the rules in this case, but there are some partial results. So in 1999, Gray looked at these interactive particle systems and he gave sufficient conditions for stability and for unstability, but he couldn't characterize it completely. And his conditions are actually quite technical and hard to check, but we managed to give an alternative geometric condition that only depends. Geometric condition that only depends on the minimal one sets for stability and possibility. And let me just quickly explain what this condition is. So for erotors, we had the condition that the intersection of the convex half must be empty to get stability. Now, what we have here is not the intersection of the convex half, but this is a bit of a stronger criteria. So if we have So, if we have this conex house, then what is this set? This is basically the smallest cones from the origin that contain the convex cuts. And if these cones are still, their intersection is still empty, then we will have stability, which is of course a stronger criteria than just the cones. Criteria than just the convex halves having empty intersection. And to have unstable, so in the original case, whenever the intersection of the convex half was not empty, we had that the cellular automaton was unstable. Now what we have that if the intersection of the convex half contains the origin, then the cellular automaton, then the interactive particle system will be that stable. And what are these And what are these rules that this corresponds to? So it turns out that again we can look at these polygons and we know that for eroders these are shrinking. We have some which are just shrinking and then we have some which move around and shrink. That these are exactly the set of eroders which don't move around, they are just shrinking and this would be the set of non-eroders where zeros would expand but not let. Would expand, but not like moving the realm of expand. Right, so let me wrap up with some open questions and future directions. So, first of all, as I said, here are some necessary and sufficient conditions for the stability for interacting particle systems, but it's by far not complete. So, even just to expand a little bit on the set of rules from which we can say something would be Something would be quite nice. If we are not talking about interactive particle systems, but back in this time, we could look at the stability of random cellular automatons that apply multiple eroders. I talked about the cellular automata that applies one eroder and the identity map, and the identity map is not an eroder. But since if we apply multiple eroders, If we apply multiple erotors, then we could ask that since they are all stable, will the combination of them still be stable? And actually, we managed to prove the following. So if as three eroders that combine the following, so this is minus one, minus one. So we combine three majority bulk maps. One is the majority bulk more dispute vertices. One of these three vertices, the other these three, and the third one is this, and each vertex chooses one of these with equal probability, then actually we will have stability, and this wasn't true before. But we don't believe that it's true in general, that if we combine eroders, then we would have stability. For example, For example, it is believed that if we combine these four majority goods, which are all eroders, then this should be unstable. But this is not proof, and I don't know of any examples where we apply multiple eroders and we can prove that they're going to be unstable. So that will be an interesting thing. Also, we could look at other really Also, we could look at other related models. I have mentioned how Booster percolation sort of fits into this framework, and actually, with Ibilo, we managed to use two contours in the context of Booster Percolation. As Rob mentioned in the morning, it was recently proved that the Booster percolation PC is strictly positive in any dimension, and we could give an alternative proof using two. Alternative proof using two papers for this result. And this is actually a 12-page proof, so it's very nice and short, and it also gives some improved explicit bounds of the critical parameter of some model script. And of course, the most ambitious thing is to ask what happens if we have two-sided errors, because so far we have only considered defective sites that will flip to zero. But of course, they could flip to zero. But of course they could flip to zero or certain probabilities, and there's uh well based I can't even say any partial results in the direction. All right, thank you for the information. Is there any questions? Online questions? Ah, I have more of a comment, but there is this mapping between this cellular automata, or even more generally, this random cellular automata and in dimension D and bootstrap percolation in dimension D plus one. In dimension equals one, one cell is automaton, and if you comply multiple, like these random ones, then it maps to bootstrap procreation. So it can be, for example, booted bootstrap procreation, but it's more general than that. So p but what she's saying is really a bootstrap propagation result in a sense and uh can so can go in both ways. So yeah. Going both ways. Other comments or questions? Like everything in front of the power. So maybe you can say more about what sort of bounds are you looking for here when you say good, explicit bounds? So this pair's argument will give a bound to any rules. So basically we could, for any subprime goose of calculation, we could give a We give a lower bound of PC. When I say improved explicit bounds, I think it's for the direct train or concern, whatever. So before that, there was a bound like 10 to the minus 100, and our bound is like 10 to the minus 6. So that's true. The bound should be still like 0.1 something. So it's still a bit far away, but it's worth. It's it's it's worth mentioning. So the the tools method, the way I always understood it, gives extremely poor bounds in general. Yes, it does, but if you want to look in general, yeah, but if you want to look at like a specific rule, then you can always look into how these contours are defined and make some improvements that are very specific to that rule and get somewhat better bounds. But also, there are some interesting. Also, there are some interesting part of the systems for which we could prove better pounds that already exist in the literature, which were still not very good pounds, but give some improvement. Just one comment on your 10 to the minus 6 and 10 to the minus 100, especially because it is exactly 10 to the minus 100 when Vladis proved that for P value. Proved that for P very large the zero temperature route dynamics are stabilizes in plus. A physicist asked what's the bound you have on P. And it said 10 to the minus 100. And the physicist said, OK, so if you have no minus in the universe, you only have pluses. That's your statement. That would be a very nice tent to the. You're very right because about 10 to the minus 100 is from a multi-scalary normalization, so kind of thing, and this is a fair learning test of that. Last counterexample, is there a heuristic explanation why this take a random combination of these four rulers would be unstable? Well, we believe this to be unstable, it's sort of like this. Stable is sort of like this. So if we look at just this map, the northeast center, what it would do if we have a set of zeros, it will keep shrinking in this way. And the triangle might fill up. So there might be some zeros that would be over here, but it will keep shrinking this way. If we take like this math, it pushes zeros in the other direction. So they are sort of working against each other. So when this would be destroying thing in that direction, be destroying things in that direction and building a little bit here, but not much. The other one destroys things in the other direction, and so somehow they would stop each other from destroying zeros. That would be, but this is what we believe and simulation suggests that this is unstable in the parapsystem. This is a bit of a tangent, and I suppose. This is a bit of a tangent, and I sort of hesitate to bring it up a little bit, but either for you or anyone who's feeling ambitious, I wonder if you've thought at all about the gap positive rates problem. Is this because the problem is in a little bit of a difficult situation if I understand correctly? But the problem is basically the following: to take any one-dimensional set. One-dimensional cellular automaton at all, and then you add noise to it, which is a small probability of noise, but you have to allow any state to be produced by the noise, but a small density. And then the question is: can you ever sort of have more than one stationary measure? Can you have a phase transition for any such thing? Any such thing. And my understanding of the problem is that for decades everyone thought that the answer must be no, one image means it cannot be a phase transition. But there is this paper, or several papers by Peter Gatch, which kind of proves that you can, you can have multiple living examples where you can. But the problem is that the argument is so complicated that I think it's fair to say that nobody. Complicated, and I think it's fair to say that nobody other than the sanity, and it's been different for decades.