So, yeah, I'm going to be talking about some work that I did when I was at Manchester and I have since run away to Cambridge. So, I've been working on this with Anastasia and Raphael. And it's quite similar to the phononic crystal type of problem that Raphael mentioned earlier, except this time. Raphael mentioned earlier, except this time we're pulling in a case with limited periodicity. We'll be talking about two different methods that both use the Wien-Hoff technique, but in different ways. So first, let's set up the problem. We have a full quadrant of scatterers making what we've dubbed the quarter lasses. What we've dubbed the quarter lattice. So, this lattice is square, it's doubly periodic, and it's infinite in the positive x and y directions. There's going to be a sound wave impacting on this. We're going to be trying to find the acoustic pressure field, and each of the scatterers are going to be infinitely tall cylinders with Soundsoft. With Soundsoft boundary conditions or Dirichlet boundary conditions. Each of these cylinders are identical in every way. They're going to have the same radius given by A and they're going to be equally spaced in both the X and Y directions with the spacing given by S. We're going to denote the positions of each of the centers of Each of the centers of the scatterers by this vector Rn, which I've given here is in Cartesian coordinates. So this is to indicate the cylinder in the nth column in the nth row. We put this condition to make sure that none of the scatters intersect or overlapping anyway. We're looking for time harmonic solution. We're looking for time harmonic solutions to the linear wave equation. So, by assuming and suppressing this time factor, then we can reduce our governing equation down to basically the standard Helmholtz. And the incident wave that we're considering is just a simple non-skew plane wave that's incoming on the lattice from the outside. So, I've written it here in terms of Uh, so I've written it here in terms of polar coordinates r and theta, as well as two parameters: um, the wave number k and an incident angle theta i. So, to start, uh, we're going to be following the same procedures, uh these two papers here, and we're going to assume that the scatterers are small in comparison to the wavelength. So, if you couple that with the simplicity of the scatterers and the sound-soft boundary conditions. Soundsoft boundary conditions, then we can liken each of these scatterers to isotropic point scatterers. So we're going to be using and abusing Faulty's approximation in this work. So what this means is that each of the local scattered fields of each of the cylinders has no dependency on a local observation angle. So if you take them individually, Take them individually, they're simply a product of an unknown scatching coefficient and a local Green's function, which in this case is a Hackel's function of first kind at zeroth order. So then our total field is going to be the summation of our incident wave plus what's called a monopole expansion, which is the summation of all these local scatter fields of every single cylinder in its lattice. Once we apply the boundary conditions and approximate for small scatterers, then we obtain this system of equations which we need to solve for our unknown scattering coefficients. So it was at this point that we wanted to try to make our lives a little bit easier by taking this summation and splitting it into two parts. Two parts. So one part of it is going to stay on the left-hand side of the quality and become part of the Wienhop sourcing, part of the Wienhop kernel. And the second part is going to move over to the right-hand side and become part of the Wienhop sourcing. And how the two methods I'm going to mention today differ is how we make that split. So for the first one, we are going to simply We are going to simply decompose the lattice into a series of rows. So, what this means is that if you were to say focus on this blue scatter here, then all of the terms in that summation that are associated with these red scatters will stay on the left-hand side and everything else will move to the right. So, this is the exact same system of equations that we got before. Of equations that we got before, but after I've done this split. And for those who have seen semi-infinite grating problems, which were the main focus on those few papers that I mentioned earlier, you may recognize the left-hand side here. The right-hand side is a little bit different from those problems because you've got this massive term here. And of course, this method works just the same way if we decide to split into columns instead, but without lots of generality, I'm just going to stick with rows for now. So how we solve this system is by using the discrete Bien-Hoff technique in pretty much the same way as you do for Much the same way as you do for semi-infinite grating problems. And when we do that, we get an answer that looks like this. So it's written as an infinite matrix equation. So each of these bold letters represent vectors of scattering coefficients, specifically for the nth row. And then the solution itself is. And then the solution itself is split into two parts. The first one is what you would get if you were to solve the associated semi-infinite array problem. So if you were to take just that row isolated and on its own, that'll be the solution that you get. So this part contains the influence of the incident wave. Wave. The other part adds the influence from all the other rows in this lattice. Now, in reality, we are supposed to have an infinite number of these rows and an infinite number of these equations with each of these vectors being infinitely big. Infinitely big, the matrices are supposed to be infinite, and the upper limit of this sum is supposed to be infinite as well. But in reality, we've got to introduce some sort of truncation so we can at least try to compute this numerically. So we have to introduce a truncation on all of the above. So when we do that, we can We can rearrange and piece together all these equations to create one giant matrix equation. And then it's just a matter of inverting this matrix and we have our scattering coefficients. So yeah, so that's the gist of the first method. We published a paper about this last year and And a lot, I gotta give credit to David Hiliwit and Stuart Hawkins for helping me out a great deal in finding effective means of comparison for this method with like more numerical based methods. So, what we ended up coming up with two different methods: one is like a least square. Is a like a least squares collocation method based off David's work up here. And the second one is using Stuart's TMAT solver package, which I think he's been working on for quite a while now. The two of them give quite similar results. Uh, give quite similar results. So, I'm only going to show I'm only going to show you comparisons with the least squares collocation method. Um, but yeah, the other thing that we wanted to do for this one is we wanted to take great care in choosing our frequencies. So, if we take like so, what I've got here is sort of a rough estimation for the dispersion diagram. Dispersion diagram. If you were to look at a fully infinite doubly periodic lattice and for a specific case of cylinder radius and spacing. And what we wanted to do was choose frequencies carefully such that we would be able to have one that was within a pass band and you. And yet, not push the frequency too high because if we did, then we'd be pushing the limits of foldies approximation. So, in the end, we chose these three frequencies here, the first two being quite comfortably in the stop band, whereas the last one should be within the pass band. And here's the results. So, what I've done here is I've Here is plotted the real part of the total field. The top row is using this Wiener Hoff method and the bottom row is using the numerical least squares collocation method. So you can see that these two completely independent methods are given are given very agreeable results. Agreeable results for all three frequencies. So now on to the second method. So this one is going to, like I mentioned before, this one's going to differ in how we split that two-dimensional sum. So this time, if we again focused on that same blue scatter as before, and we want to keep As before, and we want to keep these red nearest neighbours or the terms associated with them staying on the left-hand side this time. So, after that split, this is our new system of equations. And what happens here, if we transform this with the one-sided two-dimensional Z transform, we get an entirely new. One, we get an entirely new Wiener-Hoff equation. So, a quick rundown of the terms in here. So, this A here is the transform of all the scattering coefficients. And this is the function that we need to find. This B1 plus is the transform of the boundary data on the horizontal face. B2 is the same thing but for the vertical face. And then we have this term here, which is there to cancel out duplications in the scattering coefficients. And lastly, you've got this forcing term, so the set transform of the forcing terms. And it's important to note that this is including both incident wave influence and any incomparable. Any incoming waves that are coming from scatterers that are not the nearest neighbors. The last two terms are two kernel functions, which are given here. And they are pretty similar. You can consider them sort of as truncated versions of the original discrete mean hop. Discrete mean hop kernels in two dimensions for the top one and they share much of the same feature much of the same features including reciprocal symmetry. So replacing Z by one over Z, for instance, you get the same thing. So how we intend to so how we intend to find a solution. So, how we intend to find a solution? Well, we used a method that Anastasia has recently published, which was on a more general Riener Hoff equation, where we have two variables, two complex variables, and three unknown functions. And how this method works is we want to try to define a manifold that is the set. Uh, that is the set of z and zeta points such that this kernel function is zero. So, to get that, to get a function that describes that manifold, what we need to do is solve that equation, which is which ends up meaning we have to solve a quadratic. Solving a quadratic means we got two solutions, the manifold function and it's reciprocal. And then, if we substitute either of these. If we substitute either of these values for z into that wee and a half equation, then the term with A plus plus is eliminated straight away. And we get two equations which we can add and subtract to remove more of the unknowns until we reach this reduced mean half equation. This is looking This is looking a lot better for us because instead of three unknown functions, we've got one, and instead of two complex variables, we've got one. So this can actually be solved using more standard methods. In fact, you only really need some splitting of the right-hand side, and there isn't a kernel to factorize. So I would argue we. So, I would argue it's easier than most Reiner Hoff problems. But once you do that and find this B2 function, you can use that to find a solution for B1 and then use both of them to find a solution for A. And then it's just a matter of using the inverse Z transform and we have our scattering coefficients. We have our scattering coefficients. Or do we? Because actually, remember, there was the forcing had both incident wave influence and non-nearest neighbor influence. So the reality is we've actually got an implicit solution. And originally, this was actually one term and Determined the scattering coefficients weren't separated. So, what we originally planned to do was to try to create an iterative scheme from this. But unfortunately, it kept diverging on us, so we had to backtrack a little bit. But we did find out, we did figure out how to separate them. So, we get a rather similar matrix equation to before, except this time all of the Except this time all of the dimensions are doubled. So, trying to formulate and solve this matrix equation is quite tricky to do, at least for me. So, what I opted to do was kind of cheat a little and tried reshaping the data. Tried reshaping the data. So, what I mean by that is if you take this four-dimensional tensor, which I've sort of drawn like so, and reorganize the data, the data entries in this tensor, so it becomes a two-dimensional block matrix. And what that does with this matrix of scattering coefficients, it turns it into a column vector of column vectors. Vector of column vectors. And once you do that, you can just form a standard matrix equation and then invert this thing. We have our coefficients. And so, like before, theoretically, we're supposed to have infinity everywhere. So these blocks are supposed to be infinitely square and they're supposed to be infinite. Square, and there's supposed to be an infinite number of them. But in reality, we have to introduce some sort of truncation. And so, for each of these indices, we truncate at the exact same place. So, what we end up working out is the same number of coefficients in the x direction as the y direction, if that makes sense. So, what that ends up doing is that creates a square block matrix where each of the blocks are square. So, doing the same thing as we did before. And the good thing about looking at those previous two methods is that it gives us a goal to strive towards for this new method. And so in this top one now, we've got we're now using the new method and again the results and yeah and we're also looking at the exact same cases that I showed you before and we get very agreeable results again. And in the paper that we just submitted on this Just submitted on this method. We also looked into the error between the methods as well as how well they satisfy the system of equations. Unfortunately, I don't really have time to show you all of that, but let me know if you want to have a look. But the other the next main thing that's main thing that I looked at was this is my attempt of using the trying to use the scattering coefficients to see if I can glean any information about the effective wave numbers of this quarter lattice. So if we look at this where what I've done is I've plotted the absolute value of the coefficients. Of the coefficients along various rows and columns. And what you see here is imagine yourself planted at the start of any row or column. And as you move further along that row or column, you're moving deeper into the lattice. So I forgot to mention this is during the stop bank case. So during the stop bank case, you're So during the stock bank case you're going to be exponentially decaying as you move deeper into the lattice. That is right up until you hit the main diagonal of the lattice, in which case your new nearest edge is not where you come from, but the other one. So from that point, you're not progressing deeper into the lattice anymore, you're running alongside one of the edges. So that's why at a certain point in each of these rows of behavior. In each of these rows, the behavior turns from exponential decay to constant, well, constant absolute value, that is. So this actually, this behavior matches between the second method and the least squares collocation method, but the older method of split into arrays. Split into arrays doesn't seem to capture this very well, which is a little disappointing. But to be fair, it wasn't really built that way. So to look at it a different way, if we were to try to plot the coefficients along various diagonals of the lattice, then in that particular case, as you progress along that diagonal, you'll always be moving. Diagonal, you'll always be moving deeper into the lattice. So you'll always have exponential decay. And again, only splitting into semi-infinite arrays doesn't seem to capture this. So here I've done various diagonals, including the main one with a gradient of 1,1, as well as two others where you've got a gradient of 1,2 and 2, 1. Two, one. I think I need to hurry up a bit. So, the last thing I wanted to show you was sort of, I guess, proof that as the truncation is going to infinity, these methods are converging to something, which is what these diagrams are, which is what Diagrams, which is what these plots are meant to show. So, again, I'm plotting the coefficients along the main diagonal using all three methods and all three test cases. And even though the convergence is a bit slower for the pass-band case, it is rather blatant for the stock band case. For the stockbank cases. The only thing of note is that for each of these lines, we've taken a small truncation starting at 20 and plotting 20 coefficients and increasing it by increments of 10 all the way to 100. So one thing that So, one thing of note is that when you get to a certain point, the behaviour stops being captured and it starts to turn round. But this error completely reverses once you increase the truncation. So, in reality, this pink line with n is 100, it's still doing this turning around behavior, it's just a lot later. Behavior, it's just a lot later than all the others. Yeah, okay. Um, this last graph that I wanted to show you is a bit just more of a bit of fun, really. It was just to show that as you increase the wave number, the exponential decay is gonna be slower. And that's what these graphs are showing for the new method and for. The new method and for least squares collocation, and yeah, I'm running out of time, so I'll just hurry through the summary. So there's a few further topics that we want to do. We want to continue with this investigation into the effect of wave numbers because I think it'll be important with linking this work with the method of Hobana Homogena. Work with the method of homogenization so that we can link the quarter lattice with the quarter wedge. Out of the three methods, the latter method is the slowest of a lot, but I do think that it's because the code's not optimized yet. And I think asymptotic expansions can help. And there's also a rather interesting expansion. Interesting expansion where we can retry this method but include more nearest neighbors, more layers of nearest neighbors. And I'll just stop there. Thank you.