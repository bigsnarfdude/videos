And after Marcel's warming up talk, he'll continue on the Schrodinger problem, short-term limits and stability. So please start. Thanks a lot, Martin, for the introduction. And also, I would like to take the opportunity to thank all the organizers for giving me the opportunity to talk in this very nice, at least very nice workshop. So, today I would like to. workshop so today i would like to discuss some ongoing almost finished hopefully soon hopefully hopefully soon finished work with alberto chierini giaco mudrejo and luca tamanini that's about the schroding problem so i will take a slightly different uh angle with sorry small problem of mine Yes, I will take a slightly different angle from the one that Marcel used. So I will introduce the problem as an entropy minimization problem as follows. So I take a stochastic process, which in this case is the simplest possible one, is a drifted Brownian motion where the drift is of gradient type. I denote by M its invariant major. Its invariant measure. And I call R the reference measure, which is the joint law at times zero and capital T of my diffusion process. Then the corresponding Schrodinger problem is that of minimizing relative entropy against R among all couplings of the marginals new and new. And I call the optimal value. The optimum value CT, and I will often refer to it as to the entropic transportation cost. Okay, so the problem formulated this way, it's rooted in some large events considerations. So it amounts to the problem of finding the most likely evolution of a cloud of independent Brownian particles conditionally on the observation of the. Conditionally on the observation of the configuration at time zero and at time capital T. So this problem is very similar. It's actually essentially the same than EOT, so the entropic optimal transfer problem that Marcel has discussed. There are some differences though. There are some technical differences in the sense that in Marcel's problem, the R is not defined exactly in the way Is not defined exactly in the way that I define it. And also, there are some slightly, some more, like I would say, philosophical differences in the sense that assumptions that are natural for one problem are not natural in this problem and vice versa. For example, the cost C here in the Schrodinger problem is something you cannot really put your hands on because it's related to the heat kernel of the diffusion process, which is very rarely known in. Known in an explicit form. Okay, but other than that, the problems are the same, and you should think that my capital T plays the same role of epsilon in Marcel's talk. All right, so then let's come to optimality conditions. This is also something we have seen in Marcel's talk. Essentially, under rather mild assumptions, we have existence of two measurable functions. Of two measurable functions, phi t and psi t, of course, sorry, the real value, such that the density of the optimal coupling that I denote phi t u nu against the reference measure, sorry, oh, here's a type of the log density rather, rewrites as the sum of phi t and sum. So I will call So I will call phi t the Schrödinger potential in analogy with the Cantor-Rovich potential. And from now on, I will make a simplifying assumption that the magic quote where my diffusion leaves is just Rd, the potential is zero, so I'm just dealing with primary motion, and the measure M is then just the Lebesgue. So this is, of course, the framework that corresponds. Course, the framework that corresponds to the quadratic regular regularization of quadratic optimal transport. And in this sense, it's meaningful for both entropic optimal transport and the Schrodinger-Bridge problem. And in this setting, this is the setting where most results that are available for one problem can also be applied to the other one. So I think it's a good one to compare existing results. Okay. Okay, so the first set of results I would like to talk about is about convergence to optimal transport, so about the T to zero limit. And I would like just to make a brief recap of some of the already existing literature, which is growing quite fast. So, the first, I guess, okay, of course. First, I guess, okay. Let me say that here I will put some names. This is not at all an exhaustive list, so there are many more relevant contributions that I'm omitting just for lack of space, but keep in mind that this list is really not complete. So, I guess the first and probably the simplest type of result is the one that tells you that if you scale by time the entropic cost and then you let time to zero, what you recover is one half the square of assistant distance. The square varsity distance. Then, of course, you may wonder about first-order expansion around t to zero, and the first-order term turns out to be the sum of the marginal entropies. And then you may even wonder about second-order expansion. And it turns out that under hypothesis, the second-order expansion, the second-order term in the expansion is given by the average feature information along the geode. Information along the geodesic connecting the two margins. Okay, so this is about the optimal value, about the cost. And of course, I guess the next thing you want to know is what happens to the plans. And the very first result I can find is that of Nikami, who essentially tells us that the sequence of optimal plans is a function of Of optimal plans as a function of times is weakly tight, and any accumulation point is cyclic and monotonous. So, in particular, if you have uniqueness for the optimal transfer problem, you have weak convergence to the unique optimal transfer plan. And then there is this very nice recent result by Berton, Gazal, and Knuds that provides with a weak Laura deviation principles, Laura deviation principle for the sequence of. Deviation principle for the sequence of optimal plants as t goes to zero, and the rate function is given by one-half x minus y squared, so the cost, minus the sum of the optimal potential for the optimal transfer problem, so for the t equal to zero problem. There are many other results available for discrete versions of the Frodo problem or semi-disc. Versions of the Frodo problem or semi-discrete versions. I'm not really mentioning those here because they somehow are a bit less related to what I would like to talk about today. But let's say here you have with convergence and here you have like asymptotic Gaussian bounds for the rate of convergence and essentially this function is just measuring how far the point xy is from being the sum of the Being the sum of the open potential for the noiseless problem. Okay, so what I would like to, so one contribution that I would like to discuss today is about the convergence to the Renier map. Of course, okay, I don't really need to be very specific about this slide. Here, I'm just recalling what quadratic optimal transport is, and this is just the And this is just the well-known theorem by Panier that tells you that as soon as one of the marginals has density against the bag, then the unique optimal plan is induced by a map F, and F can be recovered as the gradient of some convex function theta zero. So theta zero, one could call it Kamporovich potential, and the gradient of theta zero is The gradient of theta zero is what we refer to usually as the Brunier map. And I will define the gradient of phi zero as being the difference between the gradient of theta zero and so the Brunier map and the identity. So the gradient of phi zero is tells you exactly, sorry, is exactly the displacement that each particle makes in the optimal transport plan between you. Transport plan between you and me. Okay, so on the dual side, so about convergence of the potentials, well, we have once again a contribution by Marcel, a very recent one that he has already discussed briefly in. No, I don't know. No, he didn't. Okay, I will discuss it a bit anyways here. So the contribution is in this setting. Contribution is in this setting about regularized quadratic optimal transport is as soon as the marginals have finite entropy. And once again, in Marcel's result, you wouldn't find this assumption, but I needed to translate his result in terms of the problem that I'm looking at now. Then you have L1 convergence of the risk optimal dual potential towards the counteromic potential. This is pretty neat and pretty general. So, of course, it goes far beyond the setting of quadratic transport. And in Marcel and Johanna's paper, they also have some results that hint or there are some suggestions of how to adapt these results in a setting where the cost is not explicitly known that would correspond more. That would correspond more directly to the Schrödinger problem we are discussing here. And I will elaborate a bit more on your suggestions later. So the question we had was kind of what comes next, the convergence of the potential. So what we were wondering is, can you provide a convergence result for the gradient of the Schrodinger potential? Can you say that it Showing your potential, can you say that it converges to the Brinier map? And what assumptions do you need in order to establish such a result? Of course, this is desirable even from an applied standpoint because you would like to use the plan where you push forward mu through the proxy of the Brainier map as an approximation of the optimal transfer plan. So we want to investigate this convergence. To investigate this convergence and see when it happens, if it happens, and what assumptions do we need. So, here is a result. So, in order to state it, I need to introduce Fischer information. So, of course, Fitzer information is very much related to relative entropy. So, the Fisher information of the measure mu against the Beg measure L can be defined. Define as the L2 norm of the gradient of the log of the density of against n when this object exists and it's plus infinity otherwise. And the result that we have is that if you assume that the entropy of nu is finite and the Fischer information of nu is finite, which also implies that the entropy of nu is finite, and if you furthermore reinforce this by assuming Reinforce this by assuming that the density of μ against Lebesgue is bounded above and below on compact sets contained in the support of μ. Well, then we have an L2 convergence of the Brani map, sorry, of the Riscale gradient of the Schrödinger potential towards the Brani map. Of course, if μ satisfies some kind of quantity inequality, then this result also implies an L2 convergence for the potentials, so you can improve from L1 to L2. So let me just comment a little bit about the hypothesis. H1, this is sharp, because in fact, if the visual information of μ is not finite, you can easily construct examples where this object is not in L2. Object is not in L2. So you cannot really do much without this. The local boundedness of the densities on compacts of the support is not sharp. So we know that at least in some situations it could be removed, but it's not really clear how to find a more general assumption where you can still that is easily checkable, where you can prove this. Easily checkable where you can prove this convergence result. And here I worked with quadratic transport, but the result is a natural extension if you assume that the diffusion with which we are working satisfies the Bachelium Li conditions for some k that could be negative. So we don't need positive curvature, we just need some curvature. All right. So All right. So I would just like to tell you what the proof relies on because it's something that may have an independent interest. So the proof relies on what we call the character estimate. And I will give you some hint on why we use this name. So this is a basic estimate that tells you that the L2 norm of the gradient of the Schrödinger potential is bounded by Schrodinger potential is bounded by the sum of two terms. So you have t times the square root of the Fisher information plus somehow the rescaled cost minus the marginal entropy. Once again, you take the square root. So this is really the heart of the proof. And how can you get this estimate? You can either obtain this working via stochastic. Working via stochastic control. Actually, that's why we call it the corrector estimate, because in a stochastic control interpretation, this thing here is just the norm of the optimal control that corresponds to the Schrodinger bridge. But you could also prove this via gamma calculus, Background calculus, or autocalculus. Essentially, it amounts to the usual interpolation argument a la bakrienne relédou, but instead Background Riley double, but instead of working with one function, you have to work with two functions. One satisfies the backward heat equation and one satisfies the forward heat equation. So this estimate actually has other useful applications. It can be used to establish a family of novel functional inequalities. It can be used to establish displacement convexity of the entropy along Schrodinger bridges. And it can also be used to study the large T behavior. Study the large T behavior of Schrodinger bridges, which is not, of course, what we're discussing here today. But it's something that, from a stochastic control perspective, is very interesting and connected to the so-called turnpike phenomenon in stochastic control. Okay, so then just how the proof goes, very quickly, there are three steps. So you see that our corrector estimate immediately gives. Corrector estimate immediately gives us some weak compactness in L2, because essentially, if this is finite, then this is bounded in T. And you know that this guy will converges to will converge to one square, sorry, to one half the square versus ten distance. So this is also bounded. So then the next thing you have to do, you have to identify the limit. And in order to do this, we In order to do this, we kind of exploit the ideas of Marcel and Johannes that we have to adapt to our setting. And in order to do this, this very nice paper by Norris on heat kernel asymptotics turns out to be very useful. It kind of does almost all the job. And then we just have to conclude because once the limit is identified and we identify limit is identified and we identify to be the the Brenier map we just have a weak convergence in L2 and L2 is very kind so weak convergence plus convergence of the norms will imply strong convergence but you see that the squared L2 norm of the Brinier map is nothing but sorry of the gradient of the of the Brinier map is nothing but the square buses in distance and you just see that the characteristic See that the corrector estimate that we have here implies, at least with this inequality, already implies that the L2 norm of the Riscale gradient of the Schrodinger potential converges to one half Wasserstein distance. Sorry, converges exactly to the Wasserstein distance because this guy will go to zero and this guy will go to W2 mu. To W to new, okay. This is more or less how the proof goes, and you can see that everything will work provided you have this curvature. All right, then I would just like to conclude by discussing a bit stability. So, okay, once again, I can profit from what Matt Self said. So, the problem is obviously the one where Is obviously the one where you try to understand: okay, if I change a bit one of the marginals, can I say something about how much the plans change? And as Marcel said, there are recent results for Lichette's cost and compact spaces. And then there is one of the papers that Marcel has discussed. And here I would like to finish by presenting a result that is a result that is somewhat a bit A bit an alternative to those that Marcel has discussed. And in order to express this result, I have to introduce a couple more objects. So the first one is the negative Sobolette norm, which is just the negative Sobolev norm of nu minus nu bar with respect to nu is just the dual of the usual L2 norm of the gradient. Of the gradient. I guess you have seen this norm already because it often pops up in optimal transfer. And well, one nice feature of this norm is that essentially if nu bar is obtained multiplying nu by a density of the form one plus epsilon, some function, then you have essentially a synthetic equivalence between this h minus one more and the vascular. Is H minus one more and the Basis and distance when epsilon is very small. Of course, you need hypothesis for this. It's not true in general, but in a way, when the perturbation is small, this norm, as I said, pretty much looks like the Walsh time distance. Of course, the drawback of this norm is that in general, it's not super easy to come up with an upper bound for this in concrete situations. And the second thing I would like to introduce is a symmetrized version of the relative entropy. So, here the symmetric relative entropy between the optimal plants is just sum of the entropy of the plan with marginal new against the plan with marginal new bar and the entropy of the plan with marginal new bar against the plan with marginal. So, it's just the easiest way to simplify relative action. And the stability is. And the stability result that we have is that if, oh, sorry, here there is a bar, if I forgot, and if my marginals are integrable enough, and I will discuss a bit what do I mean by integrable enough in a second, then you can bound the symmetrized entropy between the optimal plans. With a contribution of three terms, so you have the same object but computed on the marginals, and then you have the sum of the h minus one norm between new and new bar taken once in new and once in new bar. And all of this is multiplied by the square root of t times the entropic cost. The entropic cost. So, once again, you have a generalization of this if you assume the backgrounding condition. So, what about integrability? So, actually, you see that you don't see anything here in the right-hand side that relates to the integrability of the marginals. And actually, we just need integrability to be able to perform some intermediate calculations in the. Intermediate calculations in the proof. So since we don't need to write the final bound, we strongly think that it's not actually really needed for the bound to hold. But for the moment, we cannot really state the result that we would like to state without integrability assumption. Okay, so something that is not really desirable is that in order for the right-hand side to be finite, you need And side to be finite, you need the new and new bar to be equivalent measures because the schematic entropy has to be finite. But you can trade this with if you assume that the feature information of nu against m is finite. So, if you want to drop the symmetric entropy and work with the usual entropy, you can do it, but then you have to reinforce a little bit the assumptions on the Marsons and ask for. On the marginals, and ask for finite feature information. And well, a desirable aspect of this estimate is that it doesn't explode when the regularization parameter goes to zero. So you see here that the right-hand side doesn't explode because those terms will just vanish. And this guy is just going to the password time distance. And the question is: is this object getting becoming something trivial? trivial in the t to zero limit and so the answer is is no it's it will be a kind of a measure of the distance between the optimal transport geodesic between new new and new new bar but okay i didn't want to to write it explicitly here okay i guess this is all what i wanted to say and okay thank you very much for for paying attention Very much for paying attention. Thanks a lot, Johnny, for this very nice talk. Are there any comments, questions? So, I have a very short question. So, in your proof, when you use a correct estimate, this This heat kernel estimates they enter to get rid of the T in front of the gradient. Is this correct? Or is this a misinterpretation? So you mean this estimate? Yeah, in the last step, you need this to control the T gratify T or? So this one is entirely implied by the character estimate, for which you don't need this paper here. In this paper here. Okay, can you show this again? So, why does T to zero not cancel this? Well, so if I let T to zero here, unless I'm mistaken, so this guy will go to zero, right? Yes, yes, yes, okay. And this guy goes to W2 squared. Yeah, okay. So at least on this, the upper bound is the one you want. This is the upper bound, is the one you want. The lower bound is easier, actually. So, the reason why we need this is because we need to identify the limit. And this is not as easy as we hoped. So essentially, this paper is giving a non-quantitative version of this Lar deviation result about the logarithm of the heat kernel when time. Of the heat kernel when time is short. So it's telling, so this paper is telling you that I think this is one of them, but maybe I'm all. So there is this. So this is to distance squared, yeah. And so this is a point-wise convergence for fixed X and Y. And this paper here. And this paper here is telling that under very mild conditions, this convergence is actually uniform on compact sets. And this is something that is needed in order to be able to loot what Marcel had done with your hands. So, yeah. Dan, please. Hi, thanks, Giovanni, for a very nice talk. I'm curious, maybe I missed this, but if you can comment on where you need the fact that the densities are bounded away from zero on compacts. Yeah, once again, I need it here in the identification of the limit. I think this is the part where probably what we're doing is not super sharp, because essentially, is not super sharp because essentially what what we um so the way we identified the limit um so so you if you take a compact set we have we have a bound on the l2 norm of the gradient and if you have this these bounds on the density then you know that the mu restricted to the compact set satisfies a Poincaré inequality and then you can transfer the bounds And then you can transfer the bounds from the gradient to the function on compacters. And so then you have weak converters in L2, but then there you can use what Marside has done, because he knows that the L1 limit is the object that we need. Or rather, I should say, then we can use the adaptation of what NASA is done for this thing. I'll scroll this way. And I don't think, I mean, I think there are probably better ways of doing this. I guess then it also really depends on what is the goal. So we. Okay, there's one thing that I should say probably. There is no hope to prove the result that we have for discretely supported measures, simply because the Schrödinger problem is just not well defined in depth. That's not well defined in that case. I guess compact support continuous measures could be reasonable here. Yeah. Yeah. So, okay, but okay, the thing which is nice is that the measure mu can have arbitrary support, so this would cover Gaussians and even measure with fat tates, provided I find a feature. Okay, so there do not seem to be any further questions. So let's thank Giovanni again for this very nice talk. And we'll switch to the next talk by Benjamin Jardin.