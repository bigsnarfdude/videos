Estimators for the AFC schemes. So, my talk will be divided into four parts. First, I will introduce what these AFC schemes are. Then, we will look at the post-era analysis for the schemes, in which I will be introducing two different approaches. One would be a residual-based post-era estimator, and the second one will be using the SOPG solution to bound the error. Then I will show the numerical studies, which will validate the Which will validate the results that we have found. The second part of the talk is the work that I'm currently working on, and that is the interplay of hanging nodes and AFC schemes. And finally, I will give a conclusion and some outlook. Okay, so the introduction is quite simple. We are interested in the steady-state convection-diffusion equations, and the equations are given by this. I have my diffusion parameter epsilon. I have some convective field phi. Xilin, I have some convective field phi B and a reaction term C, along with some deliverylate and Meyman boundary conditions. Now we know that under such an assumption, we have an existence of a weak solution, but we are more interested in the case of convection domination, that is, whenever my convection is more than my diffusion, as then we have presence of layers in the interior and the boundary, and hence we need a discretization which approximates this layer properly. So what do we mean by an ideal discretization? So, what do we mean by an ideal discretization? We want a discretization that computes this layers accurately and sharply. Now, many schemes such as the SUPG do it really well, and AFC schemes also do it properly. Next, we want physically consistent results. That is, we want our numerical solutions to possess the same property that the annual resolutions do. In our case, that is the maximum principle, and hence we want our numerical solutions to satisfy the discrete counterpart of it. To satisfy the discrete counterpart of it, namely the discrete Maximum principle. Schemes such as SUPG or the SOL schemes introduced by Folker fail to do so, and hence we have the presence of spurious oscillations in the vicinity of players. AFC schemes belong to a very small class of schemes which satisfy this property really well. Lastly, we want the efficient computation of the solution. Now, after discretizing our equations, we want the solution to be computed efficiently. Computed efficiently. Now, for linear discretizations, such as SCPG, it's quite easy, but for non-linear discretization, it's quite tough. And in the paper by myself and Folker Jun, we discussed different ideas to solve these non-linear equations. But we believe that because of the second property, that is the physically consistent results, the ESC schemes are very well suited for applications. Now, in this talk, I will combine the idea of a posteriorist. Combine the idea of posterior estimators and the AFC schemes. So let's start with the variational problem of the AFC schemes. We want a solution UH in my finite dimensional space VH such that this is my variational formulation. My first part is the bilinear form that we get from my convection diffusion equation. The next is my stabilization term, and then I have my right-hand side. My stabilization term is given by the following formulation, where dij is my Where dij is my artificial diffusion matrix that is depending on the Gullagan stiffness matrix A. And my alpha ij's are the solution-dependent limiters. Now, the idea is whenever my alpha ijs are equal to one, then I move back to my original Leroy formulation. And if my alpha ijs are equal to zero, then I have an overly diffusive system. So in the smoother regions, I want my alpha ijs close to be one so that I recover the original color informulation. I recover the original color in formulation and in the presence of layers, I want them to be close to zero so that the layers are smooth out. Now, for my post-array analysis, there's a different presentation that I would be using for the stabilization term given in the paper by Gabriel Verncher, Folker Ewan, Peter Klobla, and Richard Rankin, in which we have an edge-based formulation. In this, E is my set of edges and my alpha E and D E corresponding to alpha ij dij. corresponding to alpha ij dij, where E is the edge having the end points xi n xj, and T E is my tangential derivative across the E. The starting point of my precedent-based approach is the natural norm of the system, namely the AFC norm, in which we already have with priority analysis. My AFC norm comprises of two parts. First is my energy norm and second is my stabilization norm. My energy norm has my H1 semi-norm. Energy norm has my H1 semi-norm and my L2 norm. So let's start. Let IH be denote this quadrang interpolation operator. Then using the standard Gulfin orthogonality arguments, I can rewrite my AFC norm into the following parts. My first three parts are the standard residual estimator that we get whenever we use post-error estimation for convection diffusion equations. And hence, Diffusion equations, and hence we can bound them in a similar way. One example of this bound can be found in the paper by Folker June and Julia Novo, in which we bound the first three terms using residues. The first residue is the residue on the mesh cell K, and the second residue is the residue on the mesh cell F. Here, FH denotes my all the set of all faces on my triangulation, and K denotes my set of all triangulations. Here, Arg Uh. Here, RkUH is my residue on the mesh K given by this, and Rf is the residue given on the faces. Here, this denotes the jump across the faces if I have a phase in the interior of my domain, and then this denotes the residue whenever I have a Neumann phase. Otherwise, the residue on the phase is zero if I have a delift boundary. And F is the unit normal across the phase F. Now, by Now, by standard interpolation estimates, Cauchy-Schwarz, and Young's inequality, I can further reduce my equations into the following ones. Here I have presence of certain constants. First is my C of I. C of i denotes the interpolation constant that we get. C of f are the phase and trace inequality constants that we get. And lastly, the c of y. So the c of y comes from the generalized Young's inequality for who we will find an For who we will find an optimal value data. What we have done here is we have divided our AFC norm into the following two parts. First is the energy norm, and second is the stabilization term. Why is it so? So we note that in my right-hand side, I already have the stabilization term. Now, the stabilization term is linear in the second and the third argument. So using the linearity, we add and subtract this u of h in both the parts. Now my first term here. Now, my first term here cancels out with the first term here because they have the same scaling arguments. And hence, what I've reduced is that I have an estimator in my energy norm of the system. Now, finally, we need to approximate the second term. Now, using the eth stabilization formulation, again, my interpolation estimates, Cauchy-Schwarz, trace, inverse, and Young's inequality, I further reduce this and bound this term using the following formulation. Here, again, I have Here, again, I have three new constants, namely kappa1, kappa two, and c inverse. Kappa1 is given by the following formulation, where c of i is my interpolation constant, and the c edge max is a constant depending on the shape of my triangulation. This is a computable constant that we found, and the details can be found in the paper. And the C of inverse is the inverse constant that we get from the inverse inequality. So, finally, what we So, finally, what we do is we collect all these terms and then using standard calculus argument, we find an optimal value of Cy, which was equal to 4. And then, finally, this is our global posterior estimate. Our global posterior estimate is found in the energy norm of the system, where it is divided into three parts. First is the estimator over the mesh cell K. Second is the estimator over the phase F. And lastly, we have an estimator over the edges E. Over the edges E. Here we have the presence of certain constants, namely Ci, Cf, and C inverse, which comes in kappa 1. In the numerical simulations, we set all these constants to unity. Another thing to note is that if I am in two-dimensional case, then my set of faces and set of edges coincide, and hence my eta2 and eta3 are getting summed over the same. That is my set of all edges. All edges. Now let's look at the lower bound. I define this lower bound as a formal local lower bound, which I will explain later why it's so. So I have a mesh cell eta k, and then I have three terms, my estimator on the mesh cell k, on the face, and then on the edges. So my where these individual constants are given by this. Now I have to first I use the local lower bound, the standard. The local lower bound, the standard strategy that we use to find the local lower bound for my eta interior k and eta phases. Using standard bubble function arguments, we can bound my eta interior k by the following formulation, where what we notice that my fh, b h, and ch are finite element approximation of f, b, and c respectively, and these are nothing but the oscillation terms. And using the phase bubble arguments, we bound the the phase bubble arguments we bound the eta phase f where i get this omega f is my set of patch cells which share a phase f this delta f f h n is the chronic delta function which is one whenever i have a neumann phase and zero otherwise and then the last terms are nothing but the oscillations again these are standard for the convection diffusion equation and the same analysis carries forward to the afc schemes post-train analysis as well Post-it analysis as well. Lastly, we want to see what happens to the third term, that is the stabilization term we get. Now, in my third term, I have something of the artificial diffusion matrix modulus of DEE. Now, in the paper by Gabriel Bancher, Polker Jung, Peter Knobler, and Richard Rankin, this artificial diffusion matrix is bounded by the following term. And hence, we use this approximation to finally bound my eta dhe in this following function. Eta dhe in this foreign formulation. One thing to note is that this is not a proper local lower bound because I don't have an error term but a decaying term here. Now what happens is this is not a proper local lower bound and hence the reason of calling the local lower bound a formal local lower bound. But we want to investigate how this local lower bound behaves or how it decays in the convection dominated case. In the convection-dominated case, and which we will see in the numerical studies. Finally, combining all these estimates, I get a formal local law bound in the following formulation, in which I collect all the terms and I get it here. One thing to note is that I have a dependency of epsilon in the denominator, in all other terms. This leads that my estimator is not robust with respect to epsilon. Now, this is a standard issue with a residual-based estimators. A residual-based estimators for convection diffusion equation, in which, whenever we approximate in the energy norm, they lose the robustness with respect to epsilon. One more estimator has been proposed for the AFC schemes, which is a fully computable estimator, but that also uses the robustness with respect to epsilon. Okay, now let's look at the second approach, which I refer to as the AFCS-UPG approach. Now, in this first paper, that by myself and following. First, paper that by myself and Falker Jun. What we did is that, as I mentioned, that the AHC is a non-linear scheme. I start my non-linear loop with my SUPG solution. And then we use this fact and we exploit it to bound my error term. So let U of AFC be my AFC solution and U of SUPG be my CPG solution. Then I can bound my error in the energy norm by triangular inequality by adding this SUPG. Inequality by adding this SUPG and subtracting it. Now, what I do is I bound my norm of U minus U of SUPG in the energy norm by the SUPG norm. Now, why is it so? The reason is in the paper by Faulk-Yun and Julianovo, robust estimators with respect to epsilon has been proposed for the SUPG solution and robustness with respect to epsilon in the SUPG norm. Let us call those estimators as eta-SUPG. SUPG and this second terminology u of SUPG minus U of AFC is nothing but computable because as I know my initial solution and I know my AFC solution and hence what we do is we can bound this whole term in a global upper bound by 2 eta square SUPG plus eta square SUPG. We would like to see how this estimator behaves with our residual based estimator, but more importantly, we want to see how the individual term behaves. Individual term behaves. Okay, now let's move on to the numerical studies in two-dimensional. We follow the standard strategy for solving the equation, that is, we solve, we estimate, we mark, and then we define. We want to check how good an estimator is, and we follow the standard procedure. Namely, what we do is we check the effectivity index for this estimator. We define the effectivity index by our global bound divided by the known solution. The known solution. And now, if this is close to one, then we say that our estimator is quite well and predicts the solution really well. For the numerical simulations, we will be looking at two different kinds of limiter. The first one is the monolithic upbend limiter proposed in this paper by Kuzmi, in which we have an upbend kind of limiter. And the second is the linearity preservation limiter proposed in the paper by Benjier, Yuan, and Klomblaw. Now, the linearity preservation. Now, the linearity preservation limiter makes this even linearity preserving by introducing a constant gamma i, which depends on the property of the triangulation. We will look at this constant a little bit later in the hanging notes part. And then in the final paper, the third reference, the authors compared these two schemes and compared them on their they provided a unified analysis and they compared these respectively. Okay, so how will we compare the results? The comparing of the results. Compare the results. The comparing of the results would be done in the following five parameters. First is the effectivity index. Second, we want to look at the adaptive grid refinement, how well our grid is refined. Third is the behavior of eta dh. As mentioned earlier, eta dh does not provide a formal local lower bound, but we have to see that how it behaves as the mesh becomes fine. Next, we want to look at the behavior of eta-sUPG and ETA-ASC-SUPG. Lastly, we want to see how well it approximates the internal layer. Well, it approximates the internal layer in one example, in which we want to check the thickness of the interior layer depending on the estimator that we use. Okay, now how to solve the iterative solvers that we get for the AFC schemes. I will provide a very brief overview or a review of the schemes that we and the whole work can be found in the following two references. So, let's first look at the matrix formulation of my EFC schemes. My EFC schemes can be written down by the My AAC schemes can be written down like this, where A is my standard color formulation, and D is my artificial diffusion matrix, and alpha is my limiter matrix. What we do is that we take the limiter matrix to my right-hand side, and then we keep the matrix as constant. This method we refer to as fixed point right-hand side in this paper by myself and Folk-June. And then we use a dynamic damping parameter to find the next solution. In this paper, solution. In these papers, we investigated two, three different methods. One of them was the speak spot right-hand side. The second one was an implicit approach in which we keep the limiters to the left-hand side. And then lastly, we checked the Newton's method. Out of all of them, the fixed one attended side was the most efficient in terms of computing time. The reason being this matrix remains constant and hence we need to factor it once. We can store that factorization and then we can use this. Factorization, and then we can use this factorization again and again in the nitrate loop. And this is what we use to solve a non-linear problem that arises in the posterior estimation. Okay, now let's look at some numerical examples. The first example we will look has a known solution, this, defined on the unit boundary 0, 1 with a diffusivity constant of 10 inverse 3, some convection and some reaction. This example was proposed in the paper by This example was proposed in the paper by Alejandro Allende and co-authors. We use P even finite elements for our simulation, and we stop the non-linear iteration in the same way that is proposed in our paper. That is, if either my number of iterations beat to 25,000 or the residue is less than 10 inverse 10 into the square root of number of degrees of freedom. The second stop algorithm is called the adaptable algorithm, in which we choose either whenever we reach one of them. choose either whenever we reach one of them. That is, either my global upper bound is less than 10 inverse 3, or my degrees of freedom is approximately equal to 10 raised to 6. Okay, let's first present results with respect to the effectivity index. Before presenting these results, I want to see how we started the adaptive loop. We started the adaptive loop with uniform refinement for the first two steps, and then we switched on to the adaptive loops. Here, what we see is that the same thing. Here, what we see is that the same thing. When I have uniform refinement, my estimator is like this, my effectivity index is the same. And as soon as I switch to that loop, it jumps up and then it decays as my degrees of freedom increases. For the LP limiter, what we see is that my effectivity index is better as compared on uniform mesh refinement. But for my monolithic urban limiter, my effectivity index is worse as compared to the uniform refinement. In fact, we see this kind of. In fact, we see this kind of some kind of irregularity here. Why is it so? We will see in the next slide. Next, let's look at the AFC-SUPG estimator. Contrary to the residual estimator, here the effectivity index is quite similar for both the limiters. That is, it is independent on the choice of limiters. The estimators for the adaptive grids is always better than the uniform grids. And both of them are way better than the residual. Way better than the residual-based estimator. So let's first investigate what happens with the AFCFCPG estimator. Here we plot the different values of eta-CPG and eta HCSUPG. On the left, I have the monolithic urban and on the right, I have the hiniatic visa benefiter. We see that in both the cases, what happens is my leading term for my eta is eta of SUPG in both the cases, and hence is the driving force in the mesh refinement. Force in the mesh refinement. And as my eta ESHCPG is the less dominating term, the mesh is refined. The dominating term refines the mesh more. And hence, my estimator is kind of independent on the choice of the eliminators. Now let's look at the errors of these terms. What we first note is the errors for the denote the eliminator. Here we see that on my adapt, so both the grids have been defined adaptively, and we see that as Adaptively, and we see that as my number of degrees of freedom increases, my error with the linearity preserving limiter decays optimally. My eta DES for the linear also decays with the proper rate. And even in the AFCS-UPG estimator case, my error is decaying properly well. Now let's look at the monolithic urban limiter. Here, what we see is that initially my error is reducing fine. Sorry, here my error is reducing fine. And then slowly my error. And then slowly, my error loses its optimal order convergence. If we note this eta, which is coinciding with the line of eta dh here, it also has the same behavior as the mesh becomes fine. This can be observed here in the AFC-SCPG estimator case also. As my mesh becomes fine, my error is losing optimal property. Now, the question is, why is it so? Now, in this paper by Berninger-Eune-Knoblo, in which the first convergence analysis was given for the monologue. Analysis was given for the polymologic upper limiter. It was noted that as my mesh becomes non-deleunee or it has some obtuse angles, the error loses its optimal order convergence. Now for the refinement of the grid, we used red-green refinements. That is, we refined the red and then we closed the grids using green refinements, which led to the presence of non-dilivatoring elations. As the match became fine, this non-diluvenitarian elation. This non-delivenate triangulation increased, and hence we see a loss of optimal order of convergence. Now, let's look at the adaptive grids. On the left, I have the grids with monolithic urban limiter, and on the right, I have the grids with linear presence limiter. If we look closely, we see that here we have presence of non-delay unit regulations in certain parts of the grids. And this is not the most fine estimate. And hence, we can expect to lose the pro or. Expect to lose the order of convergence, and this is the same thing that we observe in our estimator as well. Hence, we can say that our estimator predicts this behavior of AFSCMs pretty well. Next, we want to look at how well their layers are properly refined. For this, we will consider an example with an interior and boundary layer proposed in the paper by Hughes, Mallard, and Izukami. Now, in this example, a true solution to the problem is not known, but it is known that the solution is between the boundary layer. Is known that the solution is between the bounds of one and zero. So, now let's first look at the adapter grids. The adapter grids, as I mentioned, that the limiter as the estimator is independent of the limiter. Hence, I will be presenting only the results with the monolithic upper limiter in this for the adaptive units. On the left, I have my residual estimator, and on the right, I have my AFC-CPG estimator. We see that the residual estimator and the AFC-CPG estimator refines the boundary layers properly. Refines the boundary layers properly, but in the interior, the residual estimator refines it better as compared to the AFCS-CPG estimator. In fact, the layer is much more finer. Now, let's check the thickness of the layer. We'll do the thickness of the interior layer. On the left, I have the MU and on the right, I have the TLP limiter. So, what we see is this. On the MU limiter, my residual estimator, the measure. The mesh, the thickness is far less as compared to my AFC SUPG estimator. And same goes for LPT meter, where my thickness is less as compared to my AFC-SUPG estimator. Now, why is it so? The reason is the, as in my AFC-SUPG estimator, the driving force is the, what you say, the SUPG estimator from the paper of Folker Yoon and Julia Novo. One of the things with that estimator is that it only resolves the That it only resolves the dominating layer the most and does not resolve all the layers properly. Whereas the residual-based estimator that we proposed resolves each layer and hence we can see that the thickness of the interior layer is less as compared to the AFCF-EBG estimator. Okay, now the next question that I want to cover is a work in progress that I'm currently working on, and that is the interplay of hanging notes with these non-linear stabilizations. Now, the first question that should Now, the first question that should come is: why should we study handing maps? Now, as I mentioned, that is, we are using these red-green refinements. The issue arises whenever we go for these green completions. Because of these green completions, the grid loses its property. And hence, we need red refinement because it preserves the angle after red refinement. And hanging notes helps to do so. The more important property comes when we work with 3D measure refinement. With 3D measure refinement. In 3D measure refinement, we want to avoid prisms and pyramids whenever we are refining a hexahedra or a tetrahedra, because it becomes difficult for the finite element code to handle this. And hence, one should know how the hanging nodes works with these schemes. Lastly, someone might want to study the HP adaptive refinement of the ASC schemes. And in that case, again, these hanging must play an important role. Lastly, Lastly, we have certain stabilized schemes like this we just saw for the AFC schemes, which are relying on the property of the triangulation. There are more stabilized schemes such as the one given by Zuwan Sikhadano in which the properties of the stabilized schemes is depending on the triangulation. And hence it makes sense to study the hanging notes in context of AFC schemes. Okay, so the general applicability of hanging notes is known by Nodes is known by mostly everyone in the final element community, but let's give it a proper definition and see. So, let's write first a lemma that mentions how to find the value at this hanging node. Now, this lemma has been written in the PhD thesis of casting phrasal from, and then I extended it for higher order elements in my PhD thesis. So, let T be a non-conforming triangulation of omega, that is T as hanging nodes. We denote this hanging nodes. hanging nodes. We denote these hanging nodes by capital H of t and let I and my n of f I denote all the nodes or the nodal functionals. Now as we are concentrating on Lagrangian elements my nodal functionals can be associated with a nodal. And hence let P be our node which is not a hanging node. Then I can write my values at this hanging node as a linear combination of my non-hanging nodes using these coefficients A of Q P. Okay, this then we have a next theorem in which, if suppose I have a grid hierarchy at omega, that means I have refined grids, and then if my initial grid is a conforming grid, and then I have a subsequent grids, then and let t be my final grid refinement, then a basis for my VH on this grid is given by the following formulation. Here, phi of p is my basis function, phi p and c belongs to the basis function. P and C belongs to the basis function on my non-conforming plane, and my phi UNC is the same thing. And why this theorem is important is because it shows that my support of my phi of P is the support of the non-conforming basis plus the support of my hanging dots. Why is the temporium? I will tell you later. Okay, now let's see the first. First is the difficulties that arise with this monolithic upper limiter. Now, in the paper, Now, in the paper by again by Gabriel Bancher, Folker, even in Patek Novelo, the DMP satisfaction of this monorithic oval limiter based on a certain assumption of this, Aij plus Aji is less than equal to zero, where Aij is this definite matrix. They had two conditions. One condition was this. Now on conforming grids, this condition is equivalent that the gradient is less than equal to zero. But on non-conforming grids, this condition is not equivalent to this. Hence, To this. Hence, one needs to check this condition for each point and see what happens. Now, the issue is on conforming grids, this condition fails to satisfy, and hence, one can expect the vibration of DMP for monorithic urban limit. Let's look at an example of a batch. Suppose I have a convection diffusion equation, that is, I don't have a reaction, and I have a sample grid. I have a unit domain, and my I naught is my hanging node. And then I want to check the values of AI1 and AI3. The values of AI1 and AI3. Now, this is my hanging note, which is depending on I1 and I3. So, when I compute my A13 plus A31, I get it like this. Now, here, what happens is if, say, B1 is 0 and my B2 is greater than 3 epsilon, then this is large. And hence, one can expect the violation of DMT in this case, which we will see in the numerical studies as well. The next is the LP limiter. Now, the LP limiter. Now, the LP limiter definition depends on a certain constant and on the grid as well. The DMP satisfaction is dependent on the positivity of the dosome. And as hanging notes, when they are used, the assumption for DMP is always satisfied. But we require a certain modification, namely in the linearity preserving constant gamma i. This linearity preserving constant gamma i is divided by this ratio, in which I have a In which I have a maximum and the term I have a distance. Here, delta i is the support of f of i, and delta i convex is the convex hell of that support. Now, for hanging notes, what we do is the computation of the numerator is quite simple, but the computation of denominator becomes quite involved. For conforming, this is not an issue, and the ideas have been given in this paper by Peter. But for the computation of denominator, what we do is computation of denominator what we do is we replace this delta i convex by another subset called delta i t convex such that the distance is less than distance of delta i convex because of this substitution my gamma i increases if i substitute this here but it from the theory of uh e of schemes for conforming grids an increase in gamma i should still preserve the dynamic preserving property so now let's look at what these So, now let's look at what these actually are. So, here I have some sample grids with some sample hanging nodes, and let's see what they are. So, first, let's look on the top here. I have a node xi, and now I have two hanging nodes, this and this. As I mentioned in the theorem, so first the comes that what is my delta i that is support. Now, as I mentioned, that my support of xi is equal to support of xi, the non-conforming part, plus the support. Non-conforming part plus the support of the handy node. Now, if I look at this node, then the support of this function is given by this triangulation. And if I look at this handy node, then the support of this function is given by this triangulation. And hence, my support of xi, which is delta i, is given by this whole formulation. Now, the convex hell of this set is given here in the gray region. So, for this, it's not an issue. But suppose I have a hanging node here and a hanging node here, then what happens? I hang a node here, then what happens? Now, for again for xi, for this part, my support is given here, and then for this part, my support is given here for this node. So, my delta i becomes this. And if I take the convoluted combination, then the convex combination is this gray region. Now, suppose you have one more extreme situation in which I have a hanging node here and a hanging node here. Then, again, my delta i becomes in this structure and my convex. In this structure, and my convex combination becomes this. Now, as I mentioned, the computation of the numerator is easy, but the computation of denominator is tough, as computing this distance, it's not easy. So, what we do is, instead of computing on this gray region, we compute on this purple region. What we do is we compute the denominator on this delta i convex, which is this blue or purple color, in which we compute the distance between these terms, similar to this and this. Similar to this and this. Now, this region is a subset of this region, and hence my delta, this property holds, and hence my gamma i increases. So, this is the modification for the L P limit. The third limiter that I want to introduce is the modified monologue of the limiter. This name I have given it. This limiter has been proposed recently in the paper by Peter Knoblaw in the Proceedings of Enumath. There, it is mentioned as algebraically stable. Here it is mentioned as algebraically stabilized methods. And what it does is that it drops the symmetry condition of alpha ij and introduces a matrix B, which is depending on these limiters. Now, one small modification that I did from this is that I have kept this matrix D here. The reason is it makes the presentation uniform and more precisely, again, I have this M matrix here. Now, these limiters alpha i bar j are computed similar to the mono. J are computed similar to the monolithic upwend emitter. The only difference being the upfending condition is not getting used. And my constant, there are such constants pi plus and pi minus, which I have not introduced here properly in the upbendometer, but I hope some of you know, in which my upbuilding condition is replaced by this. Now the question remains: does this framework still work in our residual based estimator? And the answer is surprisingly yes. My residual based estimator still holds. The residual based estimator still holds as because I replace here my modulus of dE square and 1 minus alpha E square by this terminology modulus of B E minus D E whole square. And hence I can use my residuous estimator that I defined previously here as well. Okay, now let's look at the numerical studies. We will compare the results on three properties. First is the discrete maximum principle. We want to see that if my discrete maximum principle is getting satisfied. Discrete maximum principle is getting satisfied or not. So, for that, I define a function called variation of uh, which is nothing but the difference of uh max minus uh min. Next, again, I want to see the smearing of my internal layer, how my internal layer is behaving on grids with conforming closure and on grids with hanging nodes. And lastly, I want to see how does the error order behave on grids with hanging nodes. Okay, so I move back to my example with interior boundary layer in the Hughes Maritime Tsukami, and I present this variation. On the left, This variation. On the left, I have my results with Lp limiter. Now, the solution of this Hughes-Musican example is between one and zero, hence, variation should be equal to one. And this is what we observe. On all adaptively refined grids, either if I have a conforming or a hanging, my DMP is getting satisfied. On the right, I have the results with this modified monolithic upbind, and the same property holds as the LP. That means my variation is again equally authentic. On the center, I have the monolithic upbind limiter. Monolithic upbind limiter. And here, where the property is not satisfied, we see as soon as my mesh becomes adaptably refined for the hanging nodes, I have a validation of DMP. But there is one more interesting thing. If we look closely to the grid, what we see is that even for conformally closed grids on high refinement level, the DMP is not getting satisfied. The reason is simple. The DMP property is relying on the delivenate property of the grid. Unit property of the grid, and hence we have a violation of DMP here on conformity closed grid as well for the monolithic orbital limiter. Whereas we don't observe them either for the LP or the MMU limiter. Now let's look at the thickness of the interlades. On the left, I have conforming closed grids. On the right, I have hanging notes. For the BJK, for the LP limiter, what we see is that on refined grids, we have the thickness more or less the same, and hence, for the LP limiter, For the L filimeter, the smearing is the same irrespective of the grid refinement. Whereas for the MMU limiter or the MU limiter, the smearing on the conformally closed grid is better as compared to the smearing on the hanging node grids. In this respect, my LP limiter is performing a little bit better than the other two limiters. Now let's look at the error orders. In this, I want to look at some different examples with known solution, and I look at an example with corner boundary. Look at an example with corner boundary layer. I call this a corner boundary layer because I have a boundary layer on the corner of the domain. This example was proposed in the paper of Volke June, Peter Knobla, and Simona Servescu, in which I have a known solution defined on a unit domain 0 mu square with some diffusion 10 inverse 2, constant reaction, and zero boundary conditions. Now, here I have my errors on the adaptive grids. On the left, I have conformally closed grids, and then on the right, I have the hanging down grids. Okay, now let's. Okay, now let's see what happens. First, I want to look at the results of the linearity preserving limiters. On the linearity preserving limiters, what we see is that my error reduces optimally on both my hanging grids as well as my conformally closed grids. My eta is digging properly here. My sorry, my eta 3 is dicking properly, as well as my eta, which is given by this capital blue line, is also dicking properly here. Now, if we look at this monolithic. Now, if we look at this monolithic urban limiter, here we have the similar observations that we obtained previously in the previous example. That means as my mesh becomes fine, my limiter loses its optimal convergence property. But not surprisingly enough, for the modified monolithic limiter, the same thing happens here. If you look at this pink line, then we see that again, it is losing some of its property. Here, we can look at this eta, this light blue, which is getting Light blue, which is getting overshadowed by both of them. So here is my eta, and it follows the same property. And we see that the limiter is losing its property. But and if we look on the hankin or grids, we still lose the optimal property, but here it's not that irregular. It's kind of a uniform regular, but not that irregular in such sense. But it is still losing the optimal property. That is my monolithic upbend limiter and my modified monolith. Monolithic up-bund limiter and my modified monolithic up-build limiter both have the same convergence property, even though they don't have the same DMP properties. Now, let's look at some conclusions. First conclusions is that the effectivity index is not robust to the residual-based approach. Now, this is a standard issue that one faces whenever we use a residual-based estimators for convection diffusion equations in energy norm, and we have the same issues. Next, for the AFCS CPG estimator, the effectivity index was better as Effectivity index was better as compared to the risk-based approach. The second observation is that the limiter did not play a role in the SCPG estimator, as my SAPG estimator is the dominating term in that. The next conclusion is that for the monolithic upper endometer, we have a reduced order of convergence because on conformally closed grids, because of a presence of non-delay unit triangulations in all the limiters, my eta d and sorry, my mu. eta dh and sorry my mu limiter my eta dh is the dominating problem and if the problem becomes locally diffusion dominated for lp limiter dominating term is in the convection dominant situation with adapt regulated refinement my problem could become locally diffusion dominated in that case i have to use the alpilimeter to obtain my proper order of convergence the next issue is that if i have a small diffusion coefficient then the emulator becomes non-linear then we Becomes non-linear, then we have to use MU limiter because the problems with LP limiter become difficult to solve. And this was observed in this paper by myself and Folker Hun, in which we observed that the non-linear problem arising with the LP limiter was more difficult to solve as compared to non-linear problem with the MU limiter. Next, the residual estimator approximates the internal layer better. As I mentioned, that my AFC-SUPG estimator has the dominated Has the dominant term of the SUPG estimator and it does not resource all the ray properly, and hence, the residual estimator approximates all layers properly. The conclusions for hanging nodes are following, or the preliminary conclusions. The DMP is getting violated for MU limiter on grids irrespective of grid refinement. Either we have conforming closed grids or grids with hanging nodes. My DMP is satisfied for my LP and the MMU limiter, irrespective of the grid refinement, which is quite well. Of the retrofine, which is quite well, but the same convergence holds for Mu and my NMU limiter, and hence, in this case, the convergence property is not that nice. And lastly, my LP limiter gave us the most satisfying results on graceful hanging notes with respect to DMP preservation as well as order of convergence. All the results regarding the estimate have been compiled in this paper that is recently published, and you can find it. Now, what are the outlook? Now, what are the outlooks? The first outlook and the most important according to me is the development of robust estimators. Now, as I mentioned, that the energy normally robustness gets lost, and hence one should develop robust estimators for this for the EFE solutions. Next, we want to study the numerical in 3D. In 3D, whenever we go, the problem becomes more interesting and more challenging in both respect. And we want to see how does these estimators behave in 3D. The next is the extending the analysis of the local efficiency. Local efficiency. As I mentioned, the local efficiency that we have is not a proper local bound or a formal local bound we have, and hence, we want to properly analyze this eta3 term, as well as we want to show the local efficiency of this AFC-SCPD approach, as I believe that's quite a nice estimator. And lastly, the work that I'm currently working on is this comparison of the results with this monolithic conduct limiter that was proposed recently by Dimitri Kuzmin in this paper. Yesterday, Hennes gave a quite a nice introduction on this limit. Gave a quite a nice introduction on this limiter, and in the preliminary studies that I did with monorithic convex limiter on conformally closed grids, we see that it is a DMP-satisfying grid which has the same effectivity index, a little bit higher than the LP limiter. But the most advantage of this one of the CONIX limiter is that it requires very few iterations as compared to the PGK limiter. And hence, it is quite a nice prospect of using non-conformally closed grids. Non-conformally closed grids, but one needs to analyze this more. And with this, I would like to thank all of you. If you have any questions. Thank you very much. Are there any questions from the audience? Just shoot. I have a quick question. On slide 19, you were showing. You were showing slide 19? Yes. Well, this is slide 8 in my 19. Yes. So what are you, what is this example that you're solving here? Is it a smooth solution? Yeah, so this is the example that I was solving. Okay. So what? Okay, so why is first order the optimal? Because if because I'm in the energy norm of the system and I'm using given elements, but but provable isn't it h one half uh no but by by the analysis um from uh gabriel and folk and uh so they proved order of half convergence in the acenome and order of one convergence in the energy norm Of one benefit in the energy now, I see. Okay, it's the energy now. Okay, thank you. Yep, so