Second day of the workshop. I think almost everyone is here, so we should probably get started. So it's my pleasure to introduce the first speakers of the day. The plan for this session, it's about one and a half hours, and then I think we'll have some coffee afterwards. So, yeah, I guess the talks are kind of imaging-based again. So, I'll introduce our first speaker here. So, this is Alonzo Ramirez Manzanares, and he's Manzanares, and he's going to be talking about supervised learning for estimating multi-compartment T2 distributions from MR data on brain tissue. So I'll let you explain what that is. And then hopefully you can have a bit of discussion and stuff afterwards. Thank you very much. Good morning, everyone. I'm very happy to be here. I would like to thank the organizer for this invitation. Yes, so I'm going to talk about supervised learning in applications from MRI. Learning in applications from MRI data for estimating multi-compartment to distributions. So, this work is the result of a collaboration between people in Mexico and people in Switzerland. Okay, maybe. I need to confirm here. I need to configure. And yes. Okay. So, my talk is about, I'm going to talk about the problem statement and challenges. I think it's maybe the most important part for this workshop. I will talk about the state of the art and Talk about the state of the art and supervised learning and classic optimization methods to solve this problem. Of course, our proposal. And finally, I will show results for two applications. Use of the proposal model to detect degradation in myelin content in the brain. R, the application two, it's about to accurately quantify the demunination process in the brain. Okay. Well, so the idea is to detect damages in great and white. Detect damages in great and white matter in the brain. So, I'm going to show you results in rat brains, but also we are now working. This is an ongoing project, and we are working to export that results to human data sets. Okay, so the idea is to estimate per voxel T2 magnetic relaxation times. And this is important because the T2 property on the tells magnetic interactions in the microstructure of the tissue. So, the idea is when you So, the idea is when you see a regular T2 weighted image, it's just a point in the estimation of the T2 property. Let's say that in the experiment, you select an echo time in which you want to measure the MRI signal and the contrast is coming from this, but actually you are not measuring the property T2, sorry, but also just the magnitude of the signal. That's the idea. So, if you actually want to estimate the T2 value, then you need to acquire a Two value, then you need to acquire a multi-echo sequence, which is you need to select another echo time, and then you can characterize this exponential decay, this negative exponential decay that is going to provide you information about the tissue. So we call this a multi-echo sequence that you need to acquire. Okay, so the idea is to estimate the actual T2 value in the brain and use that to detect tissue damages, for instance, the immelination in multiple. The immelination in multiple sclerosis, for instance, is a classical disease that we want to tackle. Okay, so the problem is that inside of a box cell, there are several tissues, kind of the type of tissues, not only one. So you have the axons and you have the myelin, and sometimes you have pools of water inside of a single boxel. So instead of computing a single k2 value, we want to compute. T2 value, we want to compute distributions of T2 values. So the T2 values are given in milliseconds. So for instance, from in this range, we can detect the presence of myelin. And in this range, we can detect the presence of axons and the extracellular part of the axons, the intracellular part of the axons connecting the neurons, right? And for instance, we can find a voxel like this one, like this one. We have mild content, axon content, and a pool of water. Content and a pool of water that we also need to characterize in order to compute the presence or not of one of these tissues, right? So that means that if we have the MRI signal that we are acquiring at different echo times, so it's a convex combination of the signals belonging to each one of these compartments, and they are weighted by the probability of this compartment with a particular T2 value is present inside of the voxel. So this distribution. Inside of the boxel. So, this distribution that it's the unknown we want to estimate, we want to estimate these distributions are weighting the presence. So, in fact, the integral of this, this could be coming very slow. So, the integral part of this distribution, let's say, about the myelin is going to indicate the percentage of myelin inside of the box. So, we want to detect changes in these distributions. Okay, so for instance, if we have in a voxel, We have in a voxel three compartments, myelin, naxon, sanguader. So there are three signal decays, three exponential decays, and the signal, the black signal that we are acquiring for that box cell only, it's a convex combination of the three decays. And we want to separate. It's an unmixing problem if you want to see it in that way. So for this problem, we acquired the MRI data. It looks great. And when I say the acquired data, we acquire data with different echo times in order to be able to estimate these distributions. To estimate these distributions, right? But actually, there are big challenges in dealing with the data. So we have noise and artifacts. Let me talk about the noise. First, the noise, we have Reissian noise, and this is not additive noise, it's multiplicative noise. That means that the noise depends on the magnitude of the signal, and that's a problem that we need to model. So the Reissian distribution of the noise becomes because you are computing the magnitude of a complex number, and then you have a Gaussian noise in the real and in the imaginary part. Real and in the imaginary part of the signal, and then when you compute the magnitude, then you get a different distribution on the mass-recent distribution, right? But there is a big problem because the noise is multiplicative. The magnitude of the noise depends on the magnitude of the signal. It's not just an addition. And then, if you see the MRI signal, the noisy signal compared with the free noise signal, you will see something that we call the Reese and bias. That means that if you want to fit a model with at least squares, for instance, Model with at least squares, for instance, classical model, your model is going to try to be centered in the observations. And your model is going to be here and not here in the actual case because of the recent bias. So that's a problem. And depending on the magnitude of the signal, if I have a red signal around here, the bias is going to be smaller. And if the signal is very close to zero, the bias is going to be bigger. So that's challenging to model that kind of stuff. Still, we have some analytical solutions, but they don't work very, very well. I mean, Very well. I mean, the mixture between all the artifacts plus the recent bias is becoming very challenging. Another thing is the bias field. So you have your coil, your reception coil, when you are acquiring the MRI signal, and then you point the coil close to the region you are interested in to detect the damage. But if you are moving far away from the coil, then the signal is dropping. And then you need to compensate for that. We have methods to do that. But of course, the solution are not perfect. They are good, but not perfect. Good, but not perfect, right? So, we need to compensate that. Of course, you know about the movement. This is an in vivo experiment, so the rat is moving, so we need to compensate for that again. The solution is not perfect. And we have something that is called signal drift. So, you are making repetitions of your experiment in order to average data and increase the signal-to-noise ratio, increase the power of the signal. Then, surprisingly, you will see that the signal is dropping along the time that you are acquiring signals. Okay, what is the yeah, so it's dropping, and you need to fit a linear model to this and then compensate that decrease in the signal in order to avoid problems in the T2 estimation because you are having an scaling effect. So you need to do all this in order to get a nice T2 estimation. So it's a challenge. Okay, the last one, refocusing pulses. So when you are computing a multi-equatic, in order to estimate the decision. In order to stimulate the signal decay, it's supposed to be exponential decay, but it's not because you have remnant energy of the magnetic fields. So you need to use that extended phase graph model that makes a prediction of the fluctuation of the signals instead of being a very smooth exponential. Then you have an analytical expression that you can generate signals that simulate these problems. And the parameter that is involved in this problem is the alpha value. So instead of the MRI signal, Value. So instead of the MRI signal, it's just a linear combination of MRI signals, exponential decay. Now you have to use the APG model to generate signals that fluctuate depending on the remnant magnetic field that you're observing. So you see, you need to put a lot of things together in order to get a good result. Okay, so in all my research, I'm using, like you guys, this kind of numerical optimization to solve this kind of problems. That means that we want to estimate the difference between the MRI signal. Estimate the difference between the MRI signal and the model that we are trying to estimate. So the distribution P can be discretized and put in a vector. So it's just a vector with the integral sequential to one. So this is the probability of distribution of the T2 values. Maybe for the myelin, for the accent, that's the unknown I want to estimate. We want this is the data term of the likelihood term, and we can, of course, add regularization capsules to force the solution to be in the region we want to. We know with prior. Region we want to. We know with prior information that we want to solve. So, in my research, I use these kinds of approaches all the time in my group. And the problem here is that, for instance, if you want to solve this problem fast enough, then maybe you want to make the assumption about the noise likelihood. And by using the L Pephronome, you're assuming that it's Gaussian, but it's not Gaussian, Reissian. That's a problem there. And the Reissian bias is not in the model. Maybe you can add something in this dictionary of signal. In this dictionary of signals, so one way to solve this is to create a matrix that is a dictionary of MRI signals and then leave the method to select with the probability term saying it's 30% of one column of this matrix and 50% of another column of this matrix. This matrix is a dictionary. This is a very successful method. So people try different approaches and realize that talking about numerical optimization, this method performs very well. Okay. But still, if you have this fluctuation for the remnant part of Factu for the remnant part of the magnetic alpha value, then you need to compute a huge dictionary, really huge dictionary, because you have to take into account different kind of fluctations. So it's quite complicated and the solution is going to be very slow because you have a very big and you have to solve this voxel by voxel. And you want to solve millions of boxes. So it's becoming problematic, right? Okay. So yeah. So the dictionary depends on all the information you want to. Dictionary depends on all the information you want to model, and it's going to become problematic. Okay, so one of my students comes to me and says, Let's use supervised learning. And I say, Okay, it's okay to use supervised learning because I prefer to use classical methods. But what about this problem? So, in this problem, we want to tackle several artifacts like recent bias, non-ideal refocusing pulses, the fluctuation, these fluctuations, and the long processing times to compute millions of millions of boxes. So, let's give a try and see what's going on. So, I'm bringing this problem to this. On so I'm bringing this problem to this workshop because if I presented this problem in a computer science event, everyone is going to say, Of course, supervised learning is the us. It's very powerful. But here we can discuss about the pertinence or not to use supervised learning as opposed to use classical. I think we can do that. So yeah, so let's try to tackle this. So there is a work in the state of the art that they use multi-layer perceptron, classical artificial neural networks. And I say that this is like a proof of concept because they use a lot of measurements. Because they use a lot of measurements, 60 measurements is a lot for echo times that is hard to translate to the clinical setting. And they tested on a very low noise. The SNR, the signal-to-noise ratio was like 200. This is not realistic. Okay, so yeah, so we want to improve this and to adapt this for data, which is with a realistic signal-to-noise rate. Okay, so can we use providers? Can we use provided leading? I say to my students, yes, we have a direct model for the APG. This, we know the expression, so we have the direct model. So we can generate a lot of signals, and we have also the direct model for the resident noise. So it's difficult to invert, but we know the direct model is very easy. So we can generate a huge database with a lot of signals and train a supervised learning method with thousands of thousands of samples. So it sounds good in that sense. Okay. Good in that sense. Okay? Good. So we use transformers, not multilayer perceptions. It's the last generation of artificial neural networks. And the idea to use the very, very last thing, it's about the positional encoding or self-attention mechanisms. I think it's important in this problem because these neural networks provide the structure in which you have a special part of the network focused in to detect relationships between the Detect relationships between the inputs that you are feeding to the training of the neural network. That means that the remnant, the patterns of the remnant magnetic fields are related between one echo and the other. So one is with more power and more power, less power, less power, etc. So there are relationships between these fluctuations. But you have to separate fluctuations due to noise and fluctuations due to the remnant magnetic field. And we hope that the automatic learning system is going to the... Automatic learning system is going to detect those fluctuations such that if there is another fluctuation associated to noise, because they have the other tool, it's going to say no, the noise is that, so actually the actual value is this. So sounds in theory, it sounds very good to use the very last generation of neural networks. Okay. So yeah, talking about the classical supervised learning. So these networks avoid the grading vanishing problem that is very common in the last years. Better for high-dimensional input. Last year's better for high-dimensional input data. We have 32 echoes in our data, so it's high-dimensional, some sense, and better in parallel training. So that means that you can train the network with a lot of samples in a competitive time. Okay, so this is the structure of a transformer. So you have your input signal, your output distribution, you feel this and want the machine to estimate the distributions of the T2 values. And you have the encoding stage in which the relationship between the input. The relationship between the inputs are learned from the data. It's not fixed, it's learned from the data. And then you have the estimation layer, which is actually in charge of taking the transformation of the inputs and then compute the distribution in the classical. Okay, so case one. So let's apply this to a case. So in this case, we have data from RV and it's only five echo times, only five echo times, very low requirements. The SNR is very. The SNR is very low, 14. So that means that the power of the signal is not that big than the noise, the power of the noise. So it's just 14 times, not 100 or something. And we want to detect the damage in the TAEP rats. So TAIEP means that those rats have tremor, ataxia, tonic immobility episodes, epilepsy, and paralysis. They have everything. They are really damaged. So there are mutant rats. And the hypothesis about this big damage is diamondization of... Big damage is diamyelinization of the white matter. So the myelin, the percentage of myelin, is very low on the ratis. But let's see if the method can detect that. Okay, so we create a huge database of training with a lot of signals created with the APG model. And yeah, this is the kind of distributions we use for training. This is the kind of signals we use for training. And yeah, of course, we need to mimic the acquisition protocol. Exactly, signals have to be generated with the same acquisition protocol. The same acquisition protocol, and then we run the estimation. So, for the loss function of the artificial network, we use a Thomas combination of the difference between the predicted distribution and the actual distribution per voxel. So we use the L2 difference of the representation of the distribution that it's in a vector, but also the Varsstein distance in the distribution that actually it computes the Earth's mover distance, because we know that the estimation of the distribution is very successful to do that. Successful to do that, okay? So, this is the kind of solutions that the transformer is providing. So, let me show you a zoom of this solution, and then we can look to the other. So, the black one is the ground truth. So, in training mode, we have the ground truth. And we see that the solution of the transformer is the red one. It follows pretty close to the actual case, but it's not perfect because of the high level of noise. And you can see that the multi-layer perceptor that was used in the other work is performing. Other work it's performing not that bad, but not like in the transformer case, so it's making some mistakes. So, in this case, the transformer is performing much better in the case of very low signal-to-noise range when there is a lot of noise. Okay, so now we take our rats. We have seven rats, and we put all the box cells of the white matter of the rats and use the machine to infer the solution and the detection of the distributions. And you see that for the control rats in green, you will see that most of the rats. In green, you will see that most of the rats present a percentage of myelin content. And for the Taiev rats, you see that the most of the rats present the absence of myelin. Of course, there are some voxels in the Taiev rats that they are not damaged. Some voxels are damaged in the white matter, but not all the white matter is damaged. But a big portion of the white matter is damaged. And interestingly, you see a shift in the P2 value of the axonal part. Value of the axonal part. So there are reports that that shift in the value of the T2 from here to here is associated with inflammation process. So TAER seems to be not only about the lack of myelin, but also an inflammation process of the tissue. And the method is reporting, but nobody knows. We need to trust in the scientific experiments to see that we are estimating well. In the APAL case, it seems to be inflammation. We need histology, microscope. Need histology, microscope analysis to do that, so yeah. But you look for inflammation and histology, it's complicated because when you the hydrate, the tissue is a shrink and this is challenging, but seems to be that the method is working very well. Phase two, so in this case, instead of using 60 echo times, we take 32, which is a lot. But the idea is to have a very high-quality data set and then from that learn how we can reduce the required. Learn how we can reduce the requirements for the method in order to transport that to a clinical setting. So that's the idea. And then, yeah, we do that to create a golden standard. We cannot have a ground root in the frame, but we want to create a golden standard. So for the taste, this golden standard, we are going to compute a quantitative measure that is the myling water fraction. And it's very easily the area that is associated to the myling content, of course, divided by the total area. Of course, divided by the total area, which integrates one. So it's the percentage of the myling distribution. That's the definition of my lingual refraction. And then we have our very nice data. We have 16 repetitions. And then we average all this data in order to have very high quality data. So we see that we see the loss function across the training process of the multi-director spectrum and the transformer. They look more or less the same. That means that for high quality data, For high quality data, the multi-layer percentron and the transformer are performing quite similar. So, maybe there is no advantage to use a transformer with respect to a classical neural network because the data is high quality. When low quality data, the transformer is performing much better than the other. So, this the multilayer perceptron is lighter, it's faster to train. So, you have to collect one of your simple. Okay, so this is the kind of scientific results that we are getting. We see that the transformer actually. We see that the transformer, I'm showing it for the transformer, so it's following the distributions very well. In the previous slide, the transformer is performing better, but just slightly better. So, let's see the results of the transformer. But, of course, life is hard. And sometimes the transformer, of course, is making mistakes in the estimation, this kind of mistakes in the Mylin country. Okay, we know. Okay, so we put back the myling water fraction in the maps of the rat. So, you can see a rat here, you can see the corpus callosum, and also the Brynstein. And also the brainstem, some white matter structures of the brain stain. And we see that you cannot see, but this is around 20%. Sorry, this is around 20%. So you see that along the corpus guyosum, we can detect migrant wave function around 20%. Okay, so we can discuss about these results more later. So now we can say that what happened in instead of using 16 repetitions and average data, we are also using only 10, for instance. So by using only 10, For instance, so by using only 10 repetitions, we are in a threshold of 10% of the error with respect to the result when we use the whole data set, 16 repetitions. So maybe 10 repetitions, it's enough. We can improve the result by making more repetitions, maybe it's 50 repetitions or whatever, and see if we can reduce the requirements of the images. Of course, we are assuming that the solution with 16 repetition. The solution with 16 repetition is good enough, so that's tricky. Maybe the solution with 16 repetition is not good. So we are taking that as a gold standard. But I'm doing my sabbatical leave in the Institute of Neurobiology. So we have access to the scanner, to the rats, and when we can do more repetition. Before that, I would like to hear your opinion about this work. That's why I'm here for feedback. Okay, so conclusions. So in this workshop, I will say that this presentation belongs to the machine learning algorithms and a Below the machine learning algorithms and approaches to complement the statistical techniques. So, this is kind of the dark side of the things. But in my research, I'm trying to balance when you have a very good analytical model to generate the direct model. I'm working in diffusion MRI. This is my main field. This is not my main field. But I think this problem was nice to tackle with supervised learning. So, in my main research, I say automatic learning, ah, be careful. Ah, be careful. I don't want to use it because I don't trust in the results. But if we have a very nice analytical direct model and we can generate the samples to train the network, that's it. Seems to work well. But be careful about that. Okay, so in this case, we have the ingredients because we have the direct model for the MRI signals and we have the direct model for the noise. Seems good. The results seem to be okay. So I'm happy with that. The maps of the rats seem okay. Disease, okay, and I let me say this. So, the classical black box interpretation problem: when you just classify the rats, this is healthy, this is damaged, and say, what is the thing that the automatic learning process is learning? I don't know. I cannot trust because I don't know what is learning. So, in this problem, in particular, the solution is giving you the information because it's damaged because the myelin is low, or it's damaged because the d2 of the axon. The V2 of the axonal part of the box is shift to the right. So that black box interpretation that we don't know what is going on in this case is less. So, of course, it's a black box still, because we don't know how the network is getting rid of the recent bias. For instance, what is the network is doing to eliminate, we don't know. But in terms of medical interpretation, we have the information to say something that is happening in the tissue. So that's why I think for this. So that's why I think for this problem, I like the solution. But yes, so I would like to hear your opinion because this is an ongoing project research. And I just want to say thank you very much for your attention. This is my student that is in charge of this project in CMAT. And of course, there is contact information and I will be happy to hear your questions. Thank you. Thanks, Alonso. Yes, just some questions. Yeah, just some questions. Why are you getting this risky and bias? Well, it's because your data is in K-space, right? You're transforming it over to image space. Exactly. And you're taking the magnitude, right? Exactly. And so it's bounded at zero, right? And so basically you have a normal and become. You have a normal normal and becomes a Raleigh distribution in the limit when exactly. So, how do you solve that? How do you quantify the bias? Well, in that case, what you do is you use the phase. Yes. Because the bias is because you're just using half the data. In that case, I suspect if you, but before you transform the magnitude imaging, both the real and the complex parts should be normally distributed. Exactly. And you should be able to. Exactly, and you should be able to use that information to quantify the risk. Yes, so that's tricky. You are completely right. There are methods now that are doing that. So, when you have the raw data, you can do that. And the other noisy method. You're on a sabbatical next year and you have access to the scanner. Exactly. And you know, yes, and you know, I have access to a preclinical scanner, a Brooker one. But if you are working with a Philly Phillips or Simmons or whatever, you have to pay a lot. Really, insane quantity. Lot really very good friends with the physicists exactly to get the raw data. Yeah, yeah, you have to be friends with the physicists exactly. But if you are in the lab, you should try to get access to the phase data and try to solve that. No, no, it's a good idea. And we are, I mean, another colleague from the Junior University is working in that and the results are very impressive. But many times, for instance, if you want to process the human connection project, then you all the data already have the opportunity. Yeah, and then get rid of the region bias and you. Yeah, and then get rid of the recent bias, and you still have another seven problems to do that. Yeah, you have another seven problems, but that one seems to be addressable. Sure, just I want to mention that when it's very interesting because I really like this kind of approaches. I've been working with dictionaries many, many years. So, actually, you can put some bases in the columns of the dictionary with the recent bias and then try to detect the recent bias, separate that. You can do that. You're doing it sort of data-driven way to do it, but there's sort of also a scientific way of doing it. Scientific way of doing it, there's a physics, right? Exactly, and you could just use the physics, yeah, it's like a very good solution, but still, but it's not working very well. Yeah, actually, I think using phase one. Yes, okay. Thanks. On that matter, have you tried to just, I mean, if you don't have the raw data, just use some kind of a log transform? Because then it's making you additive noise and finance that's working. That's working. So, yeah, when the level of noise is because you have several combinations of artifacts, and you know, you have artifacts because of the movement and whatever, that's tricky. But actually, there are specialized methods to remove the recent bias. And then you add or subtract something depending on the signal to noise. And yes, one approach is based on the logarithm of the signal. And it works at a certain level of noise. And another level of noise, when the combination of several things. When the combination of several things, yeah, because you know, the problem is that I have to say it because the problem is that in medical imaging, we are facing problems like detect very subtle changes. And sometimes the patient is coming and say, What is going on? And say, ah, you have a problem with the mylin. Yes, I know, because I cannot move my arm. I already knew. Oh, because, but the machine, the image. Because but the machine the image is telling you that you have this problem. Yes, yes, I know. We need to detect when the problem is really in the very first stages. And these subtle changes, because we want to detect the changes very subtle, any problem that is precluding the MRI signal is problematic. If we were only interested in compute the T2 value in the boxel, that's robust. But if we want to compute this area with a very high accuracy, This area with a very high accuracy, the small problems, a remnant of the solution, of the problems that you are solving, it's affecting the solution. That's the thing. That's why we are trying to get the best data as possible to have a baseline to know what are we doing. It's challenging, yes. Okay, maybe one, yeah, maybe we can pick the questions upon this in the coffee break if you've got any further questions. I think just in the interest of timing. I think just in the interest of timing. Okay. So let's just thank Alonzo again for that. So next up, we have Shushin. Yeah, we need to try and get your slides. I don't know. Let me ask.