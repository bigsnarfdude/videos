Great. Thanks. Well, thanks first to the organizers for putting together this great workshop in Oaxaca. Very much enjoying the relaxed atmosphere and getting a chance to talk to people in this beautiful environment. So I'll be talking about a paper that got put on the archive last week with Hofi Hanna-Stoder, Luke Lipstru, and Maria Palachkova. And let me start by saying. And let me start by saying that actually the perspective that we took in this paper and that I'll be presenting in this talk is a bit different from most of the previous speakers thus far, because I'm not going to be addressing the question of what types of special functions appear in perturbative computations. I'm going to be asking a different type of question, which is about the analytic structure that we encounter in the integrals that we encounter in such computations and the methods I'll be. And the methods I'll be using apply equally well to all such special functions. So, you know, whether elliptic curves arise or hierarchy curves or flabio manifolds, what have you, really all the things I'll be able to say today can be applied to all such cases. So I'm kind of cutting across the different types of special functions that we're interested in here with a different language that allows us to ask a different type of question. So the type of question I'm in particular. Of question, I'm in particular interested in is where discontinuities arise in Feynman integrals. So let's say I have a Feynman integral that I happen to know is singular on a pair of surfaces lambda and lambda prime. So these are kinematic surfaces, they can be thresholds or what have you. The type of question I want to ask is, in such a situation, is it always going to be the case that I can compute a discontinuity with respect to these singular surfaces or even an iterated discontinuity and get a non-zero answer. A non-zero answer. In other words, when are these iterated discontinuities with respect to some singularities that appear in my Feynman integral, when do such discontinuities vanish? And it turns out there are many cases where such discontinuities can actually be shown to vanish from first principles. So that's what I'll be talking about today. So let me start by just giving some basic ideas behind what's often called Lando analysis because the tools to Because the tools to ask this type of question were first kind of introduced by Lando in 1959. But before I really specialize to the case of Feynman integrals, we can just consider function of some variable, which we can think of as our kinematic variable, which is given by a one-fold integral over, let's call it x, with some contour gamma and a denominator, which depends on this external parameter. Which depends on this external parameter and my integration variable, where this is just going to be some polynomial in my integration variable. So I can write it as some product of roots. And so, what we want to ask is where this function f can become singular, and the idea is that. And the idea is that if this contour gamma is fixed, like it will be for Feynman integrals, right, in Louvimentum space, for instance, we're just integrating along the real line. In Feynman parameter space, we're integrating from zero to infinity on the real line. Then the idea is that this function, which is itself an integral, can only become singular when it inherits the singularities of the integrand, which of course occur where these roots of this polynomial in the denominator vanish. But more specifically, we have the following type of picture. We have the following type of picture. So, this is in the integration variable plane. Let me start to use some colors. So, I have some integration contour gamma, which I'll just draw a cartoon for. Can people see that purple? Ish, yeah? Okay. Sorry? Not really. All right, well, as long as you can at least see it. Colors are a bonus. So the idea is that we have this integral over gamma, and we have some set of roots in the space of the variable x, which is where our integrand becomes singular. So I can label this like R1, R2, R3, and R4. And the position of these roots will depend on our external. Of these roots will depend on our external variable s. So, as I move this variable s around, which we can think of as some kind of external momenta in our process when I actually go to Feynman integrals, these singular points or surfaces will start to move around. So, one of three things can happen as we do this. One thing that can happen is one of these roots can pass through our contour, but in such a way that I can just deform my. I can just deform my contour out of the way via some analytic continuation, and nothing really happens to my integral. Another thing that can happen, though, is that two of my roots might approach the contour, two or more might approach the contour from opposite sides in such a way that the contour gets pinched and it cannot be analytically continued away or deformed away. So, this will give rise to what we often call a pinch singularity. Because we cannot avoid the singularity that appears in the integrand as we integrate along this contour gamma, so f itself would become singular. And then the other thing that can happen is a single one of these roots might approach one of the endpoints of the integration. And I can't deform away from the end point of this integration just because it's part of the definition of my integral. So in such a situation, we get what's called an endpoint singularity. So these are the types of mechanisms that allow. Mechanisms that allow this function f to develop singularities or inherit singularities from the antigrand. So, what Landau did was he wrote down a set of necessary conditions for such a thing to happen. I will write down the version that applies to this toy model integral, but the ideas are the same as what he did for Feynman integrals. And the idea is that a necessary set of conditions for such a singularity in F of S to arise. Regularity of S to arise is number one, we must be at a point in the space of S and X where G is zero, of course, because that's where my integrand is becoming singular. And then we have two possibilities. We want a condition that tells us either that a pinch is happening or that an endpoint singularity is arising. So the pinch singularity. pinch singularity we can think of in the by putting the following condition on our which order s on our position in s next space namely i take the g polynomial and i differentiate once with respect to the integration variable if i look back up at this polynomial what'll happen right is by the chain rule i'll get a sum By the chain rule, I'll get a sum of all different sets of these roots minus one. But if I'm at a point where two of these roots are sitting on top of each other, clearly every term in that sum is going to vanish. So this is a necessary condition for a pinch singularity to happen. And then the other option is that I can have endpoint singularities. So I'll just write that somewhat schematically by saying x is equal to gamma of zero. Gamma of zero or one, by which I mean the beginning or the end point of my integration contour gamma. Okay, so this is the idea behind, you know, if we want to just look at a Feynman integral and ask where it becomes singular, well, we can look at where the zeros and the denominator appear and we can apply some set of equations that look like this. So, unless there are any questions I can show. So unless there are any questions, I can show how this works in the case of a bubble integral. So let's consider the following Feynman integral, which I've given two different masses, and I have some momentum P coming in, which I don't require to be light-like. So in momentum space, just in case P. In momentum space, just in case people are more comfortable with that, let me write out what this looks like. So I can consider this just in two dimensions as a finite integral. Hopefully, people are comfortable with this representation. Now, I'm actually going to make use of the Feynman parameter representation more. So, that corresponds to introducing Feynman parameters using textbook quantum field theory methods and then integrating out the loop momentum. And doing so, I can rewrite this as an integral, a one-fold integral over some Feynman parameter alpha. And I can do it as a one-fold integral because even though I introduce two Feynman parameters, there's a projective redundancy. Parameters, there's a projective redundancy, so I'm going to use that to get rid of one. And the denominator ends up looking like this, where S is p squared. So, this is an integral that now looks exactly. An integral that now looks exactly like what we talked about here. We just have some polynomial in the denominator, which depends on this integration parameter alpha. And then we have some external kinematic variables s and m1 and m2 that we can move around. And so let's look at where this singularity, or sorry, this integral has a pinch singularity. So I want to focus on a situation where the denominator is zero and the derivative of this denominator with respect to alpha is zero. Denominator with respect to alpha is zero. So, just to be concrete, the first condition, which is just setting this polynomial to zero, is given by a pair of solutions, which look like the following. And I'll actually use this graphically, which is why I'm writing it out. And then we've got a denominator that looks like 2s. Sorry, that's kind of overlapping. Is that a little too small in the back? The details aren't so important. The details aren't so important. What really matters is I have a square root here. That's really what I'm going to use. So that's just the roots of the denominator here. If I want to then satisfy this pinch condition, one of the solutions I find, it corresponds to the threshold of this integral, meaning that p squared has just the right amount of energy to create a particle of mass m1 and m2. So we have that s is equal to m1. M1 plus M2 squared. And then if we plug this back into the alpha plus minus, we see that alpha plus minus are both equal to m2 over m2 plus m1 plus some i epsilon. Where if you're worried about the Where, if you're worried about the fact that I've broken some symmetry in M1 and M2, so how is M2 in the numerator? Well, it's just because how I broke the projective redundancy in the final parameters. Okay, so I can now ask the question, what happens if I compute a discontinuity with respect to this singularity, right? We're in the situation where we have two roots of my denominator that are pinching the integration contour. So what I can do, so some So, what I can do, so some branch point is going to occur there in the space of external kinematics, so I can analytically continue around that branch point. So, in other words, in the space of S variables, or of the S variable, the external momentum squared, what we have is something that looks like this, where we have a branch cut that starts at the threshold where s is equal to m1 plus m2 squared. To squared. And so we can ask, let me draw this in a different color. If I consider my integral starting at a point here, and I analytically continue it around to the other side of the branch cut, what's going to happen inside my integral or in the space of integration variables? So we can track that by just plugging in the relevant values to alpha plus minus. Just plugging in the relevant values to alpha plus minus here. And what we find is the following. So this is an alpha space. So we have some point where the pinch happens. That's M2 over M1 plus M2, which is of course below 1. My integration contours from 0 to 1. My integration contours from zero to one, and so this is indeed going to pinch the pinch that occurs along this contour here. And if I plot the alpha plus alpha minus solutions as I analytically continue s around this circle, what we'll find is that alpha plus, which started here, is going to do a half circle down to here, whereas alpha minus alpha. Alpha minus, which started here, is going to switch places with it. Okay, and the half circle occurs just because we have this square root. Okay, so even though S is going around a full 2 pi, each of these only go around an angle pi. And so the idea is that what we can do is think about how this changes our integration contour before and after the Contour before and after the, or you know, after the analytic continuation, then compute the discontinuity by taking the difference of the new integral minus the original integral. Okay? Does that general strategy make sense? So in other words, I started with some integral. Let me call this denominator f for notational ease. So then, my discontinuity with respect to the threshold of my integral is given by first an integral Over this polynomial f with the new contour, which I'll draw in a second, minus the original contour, the difference of these two integrals, where the new integration contour, if I follow what had to happen here as I did this analytic continuation, well, my contour got dragged out of place by these two. out of place by these two roots that because of the I epsilon prescription end up just below and just above the original integration contour. And so this new contour looks like this as opposed to the original contour look like just a straight line. That means that I can write this difference of integrals which have the same integrand as the same As the same integrand, but now integrated just over a couple of small little cycles around the roots that appear here and here, because I'm subtracting off the scrape portion. So my new cycle here is just going to be given by small circle first around this guy, which This guy, which now it becomes a question of how you want to think about it. This was alpha minus before I analytically continued, now alpha plus after this analytic continuation. This is alpha minus after the analytic continuation, but they've swapped places. Okay? So this discontinuity is given by the same integral, but over this new integration contour, which it just circled those two poles, which is just a residue or a pair of residues. Or a pair of residues. All right? Are people happy with that? Great. So, all of that was just to illustrate a key point, which I'll now just state in more generality, which is that when we compute discontinuities of Feynman integrals, what happens in general is we have some singular surfaces that pinch the integration contour. And what can be shown using Picard-Lefschetz theory. Using Picard-Lefschetz theory, or in particular, more recently by Eric Panzer and Marco Berghoff, using a relative version of Picard-Lefschet's theory that applies nicely to Feynman parameter space. What can be shown is that the discontinuity can then be written as an integral where the integration cycle is localized to that pinched surface. Okay? So in this simple example, the key takeaway is that this new integration contour no longer knows about the integration boundaries from our original integral, which were at zero. Boundaries from our original integral, which were at zero and one. And this generalizes: if I compute a discontinuity of a Feynman integral that involves pinching some number of Feynman parameter contours analogous to this, well, the new integration contour that computes that discontinuity for me will no longer know about the integration boundaries in those Feynman parameters. So, more specifically, I have in mind, I'm going to start from The general form of five-month parameter integrals. So often this is written using the semantic polynomials. So we have something that looks like this. So I consider some finite integral that has E internal edges. I have some GL1 or projective redundancy. And then I'm going to have to remind myself. And then I'm going to have to remind myself of the powers here. I have a u polynomial, which is a polynomial in my Feynman parameters, and the F polynomial. And sorry, I don't have time to introduce these today, but you can find them in textbooks if you're interested. They're just polynomials in the timing parameters. And L is the loop order of my. L is the loop order of my Feynman diagram. E is a number of internal edges. D is the space-time dimension. So the general strategy I want to make use of today then is I want to start with an integral that looks like this. And then I want to consider how I can prove restrictions on the analytic structure of this integral, on the double discontinuities of this integral, by keeping track of how the integration boundaries at Boundaries at where these individual Feynman parameters are zero get dropped or forgotten by my integral as I compute discontinuities. And then once I've done that, I can ask which singularities can still appear in the result. So to go back to this bubble example, there were some endpoint singularities, which I didn't highlight. Namely, there are two endpoint singularities. Which occur when m1 squared equals zero or m2 squared equals zero. So using this type of reasoning, the fact that I no longer, this discontinuity integral no longer knows about these integration endpoints, what I can conclude in this simple example, which I want to be able to prove in more general examples, is that if I first take a discontinuity, Is that if I first take a discontinuity with respect to this threshold, oops, and then compute a discontinuity with respect to, for instance, m1 squared equals zero. Well, I haven't written that with enough space, but I know this has to be zero just by keeping track of the integration contours. So this is going to be the basic move that I want to make use of more generally. Any questions on that? Any questions on that? Okay. So that all sounds nice and good until you actually try and do this in practice. Those of you who will have tried to understand the singularity structure or analytic structure of finite integrals will know that we're actually very bad in general at finding all the places in the space of integration variables that singularities can arise. So in particular, it's often the case. Particular, it's often the case that a given kinematic singularity arises due to multiple pinches along the contour. So I can draw another cartoon that illustrates this. So in some integration plane corresponding to alpha i, I have some cartoon contour gamma. And as some kinematic parameter goes to zero, that corresponds to some singular surface. To zero, that corresponds to some singular surface. What can happen is that I have multiple places where this integration contour gets pinched by potentially as many singular roots or roots in the denominator that. That exist. And in fact, I can have other places outside of what we think of the original integration contours where these roots come together. And in general, once I start computing discontinuities and analytically continuing my integral, I don't really necessarily know where the contour is unless I keep very close track. So anytime a pair of these roots come together on some Riemann sheet, that could correspond to a singularity or a discontinuity of my Feynman integral. Integral. So the difficulty is that if all I tell you is I want to compute some discontinuity with respect to lambda, which is some kinematic surface, I haven't told you anything about where that singularity arises in the space of integration variables. And in general, it's very hard to keep track of where, once you've done some set of analytic continuations, where those singularities that are actually contributing at that point in time. At that point in time, actually exists. And in particular, we don't even have a general method for finding all such singularities. In general, this requires blowing up one's Feynman integral to resolve singularities that arise when you have very non-trivial intersections between the singular surfaces in your Feynman integral, and it can be a lot of work. So, what I want to describe is some methods now for avoiding these types of questions where we don't need to worry. Where we don't need to worry about whether we found all solutions to the Landau equations or stated differently, whether we know all the places in the space of integration variables where singularities are arising. I just want to have some algorithm that allows me to address after I've computed a given discontinuity, which Feynman parameter boundaries have been forgotten about. And also, once those Feynman parameter boundaries have been forgotten, which singularities I can still access. Okay, that's kind of the two. That's kind of the two problems that remain to be solved to use this observation in practice. Any questions on that? The two, yeah, let me write them down actually. So, the first point is when we compute some discontinuity, which can appear after some other set of discontinuities, I'm not telling you exactly which discontinuity I computed already. How do we determine? Which Feynman parameter contours are compined because this is equivalent to asking which of these Feynman parameter. Of these Feynman parameter boundaries, we'll forget about in the discontinuity. And then the second discontinuity, or sorry, the second difficulty is once we know or have some mechanism for deciding which integration endpoints are. Our integral no longer knows about how can we reliably determine Determine which singularities can still be accessed. Right, the idea is that if I don't know where all the singularities arise in my Feynman integral, there may be some, you know, if I'm interested in. Some, you know, if I'm interested in some singularity that exists at lambda prime equals zero, there may be some solution to the Landau equations where every single Feynman parameter contour is pinched that gives rise to that singularity. So no matter which integration endpoints I drop or that I forget about, I will always be able to access that singularity. And in general, I don't know when such singularities arise. So this is a real question. When can I reliably check this? Can I reliably check this? So, I'm going to now present what we do to circumvent both of these questions. So, the first question, we essentially sidestep the problem. So, it's in general going to be very hard to determine when you compute a given discontinuity after computing some other discontinuities, which singularity. Singularities in your space of integration variables have actually you've analytically continued around, and which have been involved somehow in giving rise to the singularity. So, what we do is we instead just ask the simpler question, given what this singularity looks like in terms of the Mandelstam invariance or masses, you know, if I just write a polynomial equals zero, which identifies that surface, what's the minimal set of Feynman parameter contours that have to have been? Parameter contours that have to have been pinched in order to resolve that singularity. So we formalize this with what we call minimal cuts. And the idea behind minimal cuts, I can write down a kind of formal definition if you want, but let me first just try and describe it and see if that's sufficient. The idea is that, number one, these minimal cuts have to partition all the external momenta in my process. External momenta in my process into subsets that correspond to the Mandelstam invariants that appear in the description of my singular surface. And two, if there's some internal mass that my singularity depends on, I also better cut one of the propagators that depend on that internal mass. And then the minimal part is I want the minimal sets of propagators that I can cut that have this property so that if I put any of them back off shell, one of the first two conditions doesn't. Cross-shell, one of the first two conditions isn't satisfied. Let me just draw some examples and then hopefully it'll become clear. Let's consider, for instance, this box triangle. Let me just get my conventions straight with my notes so I don't make any mistakes. So we have P1 through P5. So one of the singularities that arises in this Arises in this diagram can be described by the surface where S12, which is just the sum of P1 plus 2 squared, is equal to 0. So the minimal cut that I want to just draw for this singular surface is just the one that makes sure to partition the combination of momenta P1 plus P2, right? Because the kind of cut diagram that I associate with this cut, which corresponds With this cut, which corresponds to pinching, all of the non-cut propagators will then look like this, where I have P1 and P2 coming into this vertex, and then P3, P4, P5 coming into this vertex. And if I hadn't cut any of these three lines, which turned into these three lines, well, the way I construct this cut graph is, like I said, I contract all the Graph is like I said, I contract all the edges that have not been cut. So let's say I didn't cut this propagator on the right. I would have contracted these two edges. I would have had one vertex with all five momenta coming in. And there's kind of an intuitive sense, right, in which this graph could not resolve the sum of momenta P1 plus P2 because we have all five momenta flowing into a single vertex, right? So that's the intuitive notion. So we can do a more non-trivial example. Example. Let's say I have a singular surface described by lambda prime equals, I better do one that actually exists. S12 minus S45 equals zero. So now the idea is I better be able to resolve not only P1 plus P2, but also P4 plus P5. And so because there's a unique Because there's a unique, or sorry, because there's momentum flowing into every vertex, there's again a unique cut that I associate with S45. So now I can just combine those two cuts. And the cut diagram I will get when I contract the uncut propagators, which is this guy and this guy, is I'll get something that looks like this. The ice cream cone diagram, for those of you who have seen it. Seen it where I have in this example, everything is massive, yes, where I see this cut diagram can resolve the sums of momentum P1 plus P2 and P4 plus P5. Okay? So this is the basic intuition. If I had some internal mass associated with one. Internal mass associated with one of these propagators and lambda, my surface dependent on that internal mass, I would also want to make sure that I cut the propagator that depended on that internal mass. All right. Yeah. Oh, because I want these cuts to be minimal. To be minimal. So you're suggesting that, for instance, this would have been a sufficient cut to isolate S12. That's right. For the top one, yeah? Yeah, yeah, that one corresponded to just the bottom cut. One corresponded to just the bottom cut, that's right, and it's only the second example that corresponds to this cut. Sorry, okay. So yeah, that one looked like this. Why it's the bubble? So, why didn't I cut some of the propagators on top, for instance? So, yeah, I could have ended up with something that looked more like. Have ended up with something that looked more like, let's see, let's say I didn't cut this guy, then I'd have something that looked like this. You're asking why I couldn't have considered that guy? Yeah, that's contained in this minimal idea that if I take this propagator off shell, all my conditions are still satisfied. So, the reason I want a minimal cut is because I'm looking for. Is because I'm looking for the smallest set of propagators that have to be involved in a given pinch in order to resolve the singular surface. I can always cut more. And in general, I do expect solutions to the Landau equations in which more propagators are involved in the pinch and correspondingly more Feynman parameters are involved in the pinch. But I want the minimal set of cuts because I want to be able to make a statement of the form as soon as you tell me this is a singular. As soon as you tell me this is the singular surface you're looking at, these ones have to be cut. I don't care about subtleties associated with blow-ups. Just in order to resolve this surface, these are the propagators that have to be cut. Therefore, I know they're going to be involved in the pinch. Maybe more things are involved in the pinch. Maybe this is actually the diagram that corresponds to the pinch when I compute a discontinuity. But confirming that in any given example is extremely difficult. So I'm going to try and sidestep the problem by saying, I don't care where this singularity. I don't care where this singularity arose in Feynman parameter space, it's going to definitely involve these three propagators that I cut in the first example. So, is the logic there a bit clear? This is an intuitive argument. I haven't proven this, but I have over a thousand examples to back it up. So we can take that up later. Okay, so that's the idea behind minimal cuts. And I better keep moving given the time. The time. So the idea now is that I've given you some prescription for once you compute a given discontinuity. And all I've told you is, or all you've told me is where that discontinuity is in the space of kinematic variables, external kinematic variables. We have some understanding of which Weiman parameters must have been involved in the pinch. The implicit argument here is that as soon as one of the As one of the propagators in the diagram is cut in momentum space, that implies that the Feynman parameter that corresponds to it will participate in the pinch in the Feynman parameter space. So now, though, we want to come up with a way to reliably check which singularities can still arise after we've dropped these Feynman parameter propagators, or sorry, Feynman parameter integration endpoint. And the key to doing that is to recognize. is to recognize that something interesting is happening topologically every time a singularity arises in a five-minute interval. So let's go back to this. Oh, I should have not erased that. This picture we had before, where we have two types of things that can happen when we have a singularity in our finite integral. Singularity in our Feynman integral. We can either have two of the singular surfaces in the integrand approaching each other and pinching the contour, or one of these singular surfaces approaching an integration endpoint. But if I think about the following space, which I'll call y, so it's a space of e minus one independent Feynman parameters, and I'm going to subtract off the vanishing locus of my U and F point. My U and F polynomials, as well as all of the integration endpoints. So, this is in some sense the space in which my integration contour can live, right? My integration contour can't pass through one of these singular surfaces in my integrand. Integrand and okay, it certainly can intersect one of my integration endpoints. But from the point of view of whether or not one of these singular surfaces is intersecting this one of these endpoints, this is the interesting space to look at because my claim is that something topological happens to this space in either of these two situations, right? In this pinch situation, we have some of In this pinch situation, we have some of the roots of the URF polynomials sitting on top of each other, intersecting each other. In this situation, we have one of the singular roots of one of these polynomials sitting on top of one of the integration endpoints. And this only happens in some limit as some kinematic variable goes to zero. So the idea is going to be the following. And this was an idea that was introduced by Bevila, Mazera, and Tellen in In some papers, they referred to or described this principal Landau determinant, and they released some code for doing the check I'm about to describe. They suggested computing the signed Euler characteristic of this space, both before and after taking this limit. And the idea is if you're in either of these situations, this space is going to degenerate somehow, and the Euler characteristics. Degenerate somehow, and the Euler characteristic is going to drop, or the absolute value of the Euler characteristic is going to drop. So the question is: is this Euler characteristic number greater than Euler characteristic after I send some kinematic parameter to zero? And the idea is that if these two numbers are the same, we cannot possibly be in one of these. Same, we cannot possibly be in one of these situations on this lambda that goes to zero surface because nothing topologically interesting is happening, okay. And this is insensitive to algebraic blow ops and whatnot. This is just a topological question. So, this is the version of the what I'll call Euler characteristic test that was proposed by Fevila, Mazzera, and Tellen. And what I've been telling you, though, is that there's a clear modified version of this test that we can also ask, which is We can also ask, which is if I know after computing some number of discontinuities, my integral no longer knows about all of the integration endpoints in the finite parameters, clearly I should only be subtracting off the endpoints that I believe my integral still knows about, right? So what we do is we define a modified space with some number of indices i through j, which is just the same space. Space, we still need to subtract off u equals zero, f equals zero, but now I only sorry, take look at the integration boundaries that I believe my integral still knows about. So I don't subtract off. So, I don't subtract off the ones corresponding to index i through j, because these are the ones that I believe my integral doesn't know about after I've computed some discontinuity. And then I can ask the same question, just replacing this modified space in here, right? I can ask, does the Euler characteristic of this space drop in some limit lambda goes to zero, which can be a threshold limit or one of the masses vanishes or something? And if this number is the same before and after time, Number is the same before and after taking this limit. Well, nothing topologically interesting can be happening, and we know that no singularity can arise. Okay, so this is a reliable test. Any questions on that? So they proposed everything down to here. We're only slightly modifying it by not subtracting off all the integration boundaries. So their method was to look at. Boundaries. So their method was to look at where get a reliable test for where singularities can arise in finite integrals. Now we're just slightly modifying to look at where singularities can arise in the discontinuities of finite integrals. And I should really mention that this works upon ideas from FAM that go all the way back to the 60s. But the specific implementation of this type of question, yes, is due to Sebastian and friends from just the last couple of years. All right, any questions on that? Okay. That. Okay, now I can put all this together, especially because I'm at zero minutes. Let me just describe in words how we put this together. So if I have a given five-minute integral and I say I want to compute a discontinuity with respect to some singular surface lambda, I go and construct the minimal cut or minimal cut, so it can be multiple that correspond to this lambda equals zero surface. That tells me which Feynman parameter. Tells me which Feynman parameter boundaries I believe have been dropped from my integral. So I no longer have an integration endpoint where the corresponding Feynman parameters are equal to zero. I then go and use this modified Euler characteristic test to ask about this surface lambda prime equals zero, namely after dropping or not dropping, but specifically not subtracting off the boundaries that my integration, my discontinuity integral no longer knows about. Continuity integral no longer knows about. I take the limit the lambda prime goes to zero and ask if the Euler characteristic drops in that limit. If it doesn't, I can reliably say that this double discontinuity must be zero because after taking this discontinuity, I can no longer access the singularity, therefore I cannot have a discontinuity here. And in fact, this argument doesn't rely on taking these discontinuities in a mediate sequence, so I can actually have any number of discontinuities before these two. Continuities before these two. So, in that sense, it puts constraints on these Feynman integrals that are quite a bit different from the extended semi-relations if you've seen those, but I don't have time to talk about them at this point. Okay, so are there any questions about that? This definitely depends on the order, yes. It very much matters that lambda became before not lambda prime, but I'm allowed to have any. To prime, but I'm allowed to have any set of discontinuities here and here. It very much depends on the order, yes. Yeah. Okay, so let me just take two. Oh, yes, question? Yeah. So it's not a question I've thought about. not a question I've thought about. Here's how maybe one could do it is you could ask. No, I don't think it would be very useful actually because first, well, the boundary conditions in differential equations generally are sensitive to the first discontinuity that can be accessed, right? And this question, I didn't highlight it, but I should highlight it now. This is a question about all possible integration contours simultaneously. Contour simultaneously. It didn't care, right? It's also sensitive to if I have two roots that intersect over here, even if the integration contour is there. And so I don't think it'll be useful for boundary conditions because the boundary conditions are asking about the original integration contour. And this is addressing a question about any arbitrary analytic continuation, which presumably, you know, after you've gone to whatever order in epsilon, you will see. To whatever order an epsilon, you will see all these singularities. Yeah, good question. So, if it's okay, I'll take two minutes just to highlight a couple of examples to show how powerful this is. So let me just draw some diagrams and write down some numbers. So, we looked at a few two-loop examples that look like the following. So, back to the So, back to this triangle box, we also looked at examples that look like this. So, all of these are massless. That's why I've drawn two external propagators there. And then we also looked at a non-planar example, which I want to get right, which I can draw as this. And just to quote some numbers, using this method, we find 156 constraints of the form shown here for this integral. Now, note that I haven't talked about polylogarithms, but this is really a statement about the number of letters in one's symbol that can't. Letters in one symbol that can't appear after another. And we only missed 31 constraints. What I mean by that is the following. We can look at the answer for this integral, and we can just empirically ask which symbol letters don't appear after other ones. That kind of gives us an upper bound on what types or what set of constraints we might have had a hope of deriving. But because we're using these minimal But because we're using these minimal cuts, which is a conservative estimate of which Feynman parameter integration boundaries have been dropped, we're not guaranteed to get all such hierarchical constraints of this form. But this is a statement that actually we get the vast majority by doing about a tenth of the work as you'd have to do if you wanted everything. So similarly, we get 620 constraints here, 540 here. So these are extremely So these are extremely all over the place, very powerful. We missed 25 here. We miss nine here. So actually, we're not missing much information. And in fact, from the point of view of the space of functions that arise once one requires these constraints, my belief is that you don't miss anything for reasons that I don't have time to go into, but essentially, integrability. Essentially, integrability of one's function seems to imply the rest of these constraints. But that's a teaser for future work. Let me just draw one final diagram that we looked at, just to get those of you who like standard model processes interested. So we can consider something like this. Gluon fusion to Higgs plus jet, I think is what we did. So we have here a top cork going around, and then we have sorry, I'm not drawing these very well, but some kind of Z boson, for instance, here going to a Higgs. And so this is an extremely non-trivial three-loop process, which is drawn better in the paper. Three loop process, which is drawn better in the paper, and we can still derive constraints on these types of integrals because this is a fairly efficient method. So I won't write down the explicit constraint since I'm out of time, but this looks like a promising method for understanding even types of standard model processes that are hard to compute because these constraints don't care about masslessness. They don't care about whether we're in dim reg or an integer dimension. Where in dimreg or in integer dimensions, et cetera, they all just seem to apply. So let me just end there. Ah, yeah. So they're a completely separate class of constraints, and that's Separate class of constraints. And that's because, and the easy way to see that is because as soon as I've taken a discontinuity with respect to this surface lambda, I can never access a singularity in Lambda prime, this other singular surface. That's different from the extended Steinman relations because we know in practice that even though partially overlapping momentum channels are not allowed to appear next to each other in the symbol due to extended Steinman, we do encounter situations that look Encounter situations that look like this, where we have some symbol letters in between, and then we have S234, for instance. So, extended assignment would say those two are not allowed to appear next to each other, but they do appear after each other in the symbol. So, conceptually, these are totally distinct from that point of view. Have you checked with Nance and his machine learning collaborators? In which way you wanted to publicly get it? So, I don't think. So, I don't think that this method for deriving constraints is going to be overly fruitful in planar end equal spore. And that's just because, well, empirically, having looked at many examples up to high loop orders there, we just don't see many examples where symbol letters don't ever appear after another symbol letter. And my belief is that there, dual conformal symmetry kind of swamps all this information out. One could expand out one's dual conformal invariant letters in terms of Mandelstamps and play this game. Terms of Mandel stamps and played this game, but I think once you require that things recombine into conformal invariant letters, it kind of implies all this stuff. That's kind of my expectation. I haven't really explored that. But from that point of view, this is actually a very nice method for looking at messery integrals where there's a lot of kinematic dependence. Oh, yeah. So this isn't missing 31 possible letters. This is, so all three of these integrals have been computed by different groups, and the appropriate citations are in our paper. I won't remember the authors off the top of my head. So, what we're doing is we're comparing. So, what we're doing is we're comparing the constraints we see to the answer they find in Dimreg, the higher order on Epsilon. And then we're asking: okay, we see that all these constraints are satisfied. How many more could there have been just by looking empirically at which letters never appear after others? And so here we find 31 such patterns, which we didn't explain, or 25 or 9. So that's what I have in mind when I say that. Does that clarify that? No, actually you don't. So I can say the following. So I looked at this example. So for those of you who aren't so familiar with bootstrap methods, the idea is you try and build a space of polylogarithms. This integral happens to evaluate the polylogarithms. You build a space of polylogarithms that you expect to be able to. Algorithms that you expect to be able to arise in this integral given where it has branch cuts. Okay, so this is again a question we can answer using these types of methods. And you get some set of symbol letters, which are the logarithmic branch points more or less that appear in this finite integral. And then you can just start building the space of polylogarithms that have those singularities. Then the hope is that once you've built that space of functions to the right transcendental weight, you can use knowledge of what behavior of this integral ought to have. Knowledge of what behavior this integral ought to have, for instance, in special kinematic limits, to try and find a unique function that exhibits all the right properties. So you would essentially bypass having to integrate it directly. You just find the answer by finding the only function that has all the right properties. So the point is that these hierarchical or genealogical constraints are great input for this approach because once we build the space of polylogarithms, we can direct. Build the space of polylogarithms, we can directly impose that these constraints on the sequences of discontinuities are satisfied. In practice, what I found in looking at this example is not only are these constraints much more powerful than the extended assignment relations, but it was sufficient to only look at the constraints where this first discontinuity, lambda, corresponded to some Mandelstam equals. Mandel stem equals to zero. So, like the threshold type singularities. Integrability seemed to then imply all the other constraints we derived, including the ones we missed, or also the ones we missed. So, from that point of view, it looks like this is a heavily over-constrained system. So, in practice, what might be the case is that you only need to consider the constraints that apply to surfaces that look like this, and then one gets everything. But that's something I can't prove theoretically. This is an observation at this point. Theoretically, this is an observation at this point. So yeah, there's a couple of ways you can compute this. Actually, the PLD collaboration, so Febla, Azera, and Telen, they provide code for computing this using semi-numerical methods. And so if you know a little bit of Julia, You know a little bit of Julia, you can modify it to do this for you, or you can email me or Sebastian. It's not a big change. So, this is what we're using in practice is their code. Another way you could go about this is just asking this type of question in Macaulay 2 or one of these other packages. And I can tell you why it's slightly different, but maybe not everyone needs to hear that discussion. Any other questions? Laura, let's thank Andrea. And lunch is now in.