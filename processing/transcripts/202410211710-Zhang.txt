Part of the talk has been given, delivered several years ago. I'm going to focus on some recent advancement. Well, my talk concerns incompressible fluids with moving boundaries. As we can see here, this type of applications have some hard difficulties. Has some core difficulties. They have multiple phases, multiple band scales, time scales. They have large geometric deformations, which might led to potential topological changes. There are jumps in physical variables at the interface. So despite all these difficulties, we want to have a theoretical framework for modeling and analysis, on top of which we want to get Of which we want to get false and high-order algorithm for simulation. False-order accuracy is a necessity, in my opinion, for many applications. That's one of the reasons why we are progressing so slowly. So, currently, we have lots of interface tracking methods, and some of them are not just the interface tracking. Not just the interface tracking methods, but they have the same philosophy to say, okay, large geometric deformation and topological changes are hard. We are going to avoid that. We are going to avoid the geometric modeling and topological computing by converting the problem into numerical PDE in this form. In level set meta, f is the sign distance function. In VOF metas, f is the volume fraction. The volume fraction. These methods have been tremendously successful. However, they do have their limitations. The first motivation for a new approach is to preserve geometrical features such as sharp corners. So what I'm showing here is if I have the disk here rotate to full revolutions. Full level for level set of methods, you get the corners run it up. This is a known, well-known phenomenon caused by numerical diffusion. I believe this morning Professor Zeleski talked about these T junctions of three phases. And this kind of junctions are unavoidable for three and multiple phases. Multiple theses. The motivation number two is the limit of the underlying theoretical underpinning or context. So at least in VOF method, we have the theoretical mindset of ordinary differential equation with the uniqueness of a solution for which these two flow map like this. The flow map is The flow map is often a homeomorphism. Well, it tends to a point the set in a very natural way because phi here is a diffeomorphism. It's therefore a homeomorphism. Therefore, it should preserve all topological structures of this point set M. Therefore, theoretically, this viewpoint does not allow Viewpoint does not allow any topological change. In other words, any topological change is a failure in preserving topological structures. The other thing I want to emphasize is that the set M here has no precise meaning. It can be open, closed, both open, closed, neither open nor closed. This kind of ambiguity. This kind of ambiguity or wiggle room is not amenable to rigorous analysis. People often talk about VOF methods and level set methods as being automatic treatment of topological changes. However, I think this is also a disadvantage because many a time you don't have control over how the topological changes are. Changes occur and proceed. So, for topological changes, let me do a little bit advertise that my student Ji Chi will talk tomorrow, the last talk about our high-order handling of topological changes. So, the third motivation naturally comes to the failure of preserving topological structures of Reserving topological structures of BOF level set. As I just discussed, if you have a disk under diffeomorphism, it should remain to be a disk all the time. However, there are some breaking ups through some levels. Motivation number four is that we do not more often than not. More often than not, we design our algorithms for domains with very simple topology and geometry. However, in realistic applications, we often encounter domains with a complicated topology and geometry. This is 3D Stanford Buddha, which is ubiquitous in computer graphics. Well, there's another physical concern is that, for example, in bubble influence. Is that, for example, in bubbly flow, sometimes we want to know per volume cube, how many bubbles are there? This number of bubbles or density of bubbles will be connected to the physics of the fluids. However, this information is global, but such as the betting numbers, these global information is really difficult to get by using the whole set or Using the whole set or EuroF method. So the last motivation is that it's the order of accuracy. So in one of my papers, we proved that current explicit interface tracking methods are at best second order accurate. On top of that, if you do curvature estimation from these These perturbed interface, you really get a low accuracy. This table shows that if you get four digits of accuracy interface tracking, the smallest error in your curvature estimation for unit circle will be 14%. That might be a very big error depending on the Depending on the application. So, what do we do? The idea is so simple. The current methods avoid the geometry and topology. I'm going to not avoid it. I'm going to tackle geometry and topology problems by differential geometry and algebraic topology. Of course, I only use a little bit, algebraic topology and differential geometry. And I'm hoping to convince you that even with To convince you that even with a teeny tiny bit of algebraic topology, the improvement in efficiency and accuracy in your computing can be huge. So what is MARS? MARS stands for mapping and adjusting regular semi-analytic sets. That is the shortest summary of our theoretical context. So Context. So it consists of eight steps. The first step is to model the idea of continuum with a topological space. Essentially, this is a continuum assumption hypothesis. Then I'm going to give a complete classification based on homomorphism on all equivalence classes. Then I'm going to put a geometry there. To put a geometry there, high-order geometry. The fourth step is to equip this topological space with algebraic structure, this Boolean algebra. This is really the workhorse inside many of our algorithms. Then, in order to do analysis, I'm going to define a metric so that the space is strengthened to a metric space. To a metric space, which will provide a unified analysis to current explicit interface tracking method and give our ideas for high-order interface tracking and curvature estimation. So topological changes will be very naturally incorporated in our framework, both theoretically and algorithm. And the eighth step. And the eighth step is to show that, on top of this framework, we can tackle geometric PDEs. So I'm going to give the definition of the INSAT. The Inset is a regular open semi-analytic set whose boundary is bonded. That's quite a mouthful. Why do we need a regular? That's essentially the continuum hypothesis because fluid. Because fluids and solids, when we are viewing from a mathematical point of view, they don't have lower dimensional quantities such as isolated points, crevices, that kind of thing. Why do we use open set? Because if you use open set, your representation of the continuum is unique by its boundary. However, if you use closed set, you don't have that. What does it mean? What does this mean, semi-analytic? That means piecewise smooth. That's an intuitive way to think about semi-analytic. Why do we need whose boundary is bounded? Because if we have this condition, the space have a Boolean algebra structure. Otherwise, you cannot have the Boolean algebra structure. Well, here are some two examples. Here are some two examples. You might have noticed that the Q1, Q2, Q are singular points. They are not manifold points. In other words, these points makes the boundary of inset not manifold. So, therefore, insets are more general than manifold-based theory of methods because Because these singular points must happen in topological changes. If you don't have these kinds of points, you don't have topological changes. Sometimes they must happen during the topological change. So inside is slightly more general than manifolds viewpoint in this context. Then we prove the theorem. Then we prove the theorem, which is essentially the topological classification of all non-trivial insets. This int here is the interior. So if you have a Jordan curve and it's oriented this way, and imagine you traverse this Jordan curve and look at your left, this is the interior of gamma. Of course, if you Of course, if you orient it that way, the unbounded complement will be the interior. This says that any non-trivial 2D inset can be represented this way, which gives you an efficient representation of 2D insets. This is a more fun example showing that this appenda being represented to this accuracy. represented to this accuracy only needs 80 points you only need 80 points and cubic curves to cubic spines to have this kind of accuracy and then the right hand side is this so-called Haas diagram or if you're topologists this is actually the topological stratification of the space of the Of the space that represents the panda. And what do we get from there? What we get from there is order one algorithm for getting the global betting numbers of the topological space by simply counting the number of the yellow nodes to get the betting number. That's the number of holes. So that was, I talked about that. As I talk about that, then we were stuck in 3D for a long time. Our starting point is the early success of algebraic topology on the classification of compact two manifolds. We have talked about the manifold not being general enough, but in 3D, it's a good starting point. Point. What we wanted to achieve is to use three bedding numbers to completely classify 3D insets. The details will be given by Chi Chi tomorrow, but let me just give you a scoop of the flavor. The key concept we cooked up is the so-called G-surface. What is a G-surface? Imagine you have a compact two-manifold. Compact two manifold and you quotient this topological space on some one-dimensional CW complex. It's just the union of some curve or point. For example, this life buoy is originally two-manifold. And imagine you have, you collapse the cross-section of the circle to a line segment. To a line segment, that's a that's the quotient uh action, and you get this type of thing. This time, this thing is clearly not a two-manifold because of the line here. These are more complicated, but they are still just one G surface. Why is this G surface so important? Because we can classify We can classify all 3D insights by G surfaces. They're all homeomorphic to the gluing of a set of G surfaces that are pairwise almost destroyed. It's quite a mouthful. I will skip the details and just show you some example here. But what should be striking is exactly the same unique representation of 3D inset to its 2D content. To its 2D counterpart. The only difference is that you have to replace this dotting curve with the G-surface Sij. The proof is pretty long. I'm not going to go over it here. So now we have a topological representation. We have a unique representation. Have a unique representation. One key part is the Boolean algebra on 2D and 3D insets. So when we are trying to discrete spatial operators, we need this bringing algebra to cut cells. That's need number one. The second is high-order curvature estimation. The third is how we treat topological changes. Topological changes to third-order accuracy, and GC will talk about that tomorrow. Of course, we need to prove with respect to regularized set theoretical operations, we indeed have a Boolean algebra theoretically. The difficulty is really to say how do we implement it computationally. Again, I'm skipping all the details because Skipping all the details because this is the overview just to show you one idea. This is the regularized union, this is the intersection. Our algorithms are more complete than those in computer science and computer graphics in terms of completeness. In other words, we handle all generic cases and all possible And all possible arbitrally complicated topology. And our algorithm is close to optimum. It is sort of like n log n. But if you really want other n algorithm, we can do it, just at the expense of much more complicated data structures. This is a 3D case with complicated topology. You have a dire. Have a tire solid torus. You dig a hole here, you dig a torus hole here, and you connect them with a tube. So this test case is pretty tough for current 3D algorithm, but for ours, there was no problem. On the top, we have this intersection. This is the union. Yeah, this is the union, or this is the intersection. This is union. We also can also handle complicated geometry. That's no problem. Okay, now let me talk about the metric space for analyzing interface tracking problems. We have been talking about the limit of traditional interface tracking framework. So here we redefine the interface tracking. Redefine the interface tracking problem. See, the train of thoughts is like this. If you have this ODE and U is C1, there is no topological change. If we want to have topological change, we have to relax U to piecewise lip sheets or component-wise lip sheets so that two different parts of the material can Part of the material can collapse into. Know that we cannot handle one piece split into two. In that case, the flow map is not continuous. We will get to that later, or if you're interested, come talk to me. Similarly, if you have a geometric PDE and your PDE is well posed, it will give you a unique solution. That uniqueness. That uniqueness gives you a flow map. So, why do we bind ourselves to some specific PDEs? Why not generalize the theoretical context just to a continuous flow map? This flow map says you give me an inset and a time increment, I will give you another inset. So, this way we incorporate the ODE, PDE. Incorporate the ODE, PDE, or ODE, and PDE systems. So I believe this is the right analytical framework to attack the interface tracking problem with topological changes. So the second part is how I visualize we can handle topological changes theoretically in a very satisfactory. In a very satisfactory way. Suppose there are some fluids drawn into each other. Oh, I can get into that later. I'll skip this. So the metric of the metric space is the exclusive disjunction take a norm means the volume or their area, two insets. And then any numerical methods is composition. methods is a composition of three unitary operation operations upon this insect. So to sum up, the correct underpinning of theoretical context of interface tracking should be upon the insets with actions of flow map on it. So we have some analysis. So, we have some analysis about the errors. Essentially, you can break up the entire interface tracking error into four parts. The first one is simply the representation error of the initial condition accumulated through all your time stepping. And these three are corresponding to the three constituting operations of Marx method. I'm going to skip this. I'm going to skip this. So, this is the example I talk about. So, using only the very standard techniques from algebraic topology, you can describe this topological change as one equivalence class suddenly changing another, changing into another one. Okay, so topological. So, topological change is special in the sense that it's a sudden switching from one equivalence class to another. This is discrete, there's no continuity in the sense of calculus. So, if you're familiar with algebraic topology, these are standard techniques. You have a simplification map, you augment it to T map, and then you have a homology map. The homology map tells you how the homology of the How the homology of the inside changes. Okay, now I'm going to talk a little bit about numerical simulation of multi-phase flows. This is often neglected in VOF and level set method. I'm going to define H bar as the smallest relevant length scale of the mean flow. I'm going to define HL bar as the I'm going to define HL bar as the smallest relevant time scale of the interface. In many multi-phase flow applications, you have H L much, much less than H bar. Because, for example, if you have a no-slip condition moving in the fluids, you have boundary layers near the interface. In the EO numerical computation, we should. We should, we computational scientists, should design a numerical tool that respects these physical facts. The problem with level set and VOF methods is that they construct this length scale, H L bar, from this much bigger length scale, H bar. Therefore, their accuracy is really limited. Accuracy is really limited. They don't have sub-scale resolution, except arguably AMR. So the problem, there is a discrepancy between the real physics and the characteristics of the algorithm at the very starting point. If you add a curvature estimation, The curvature estimation into the picture, the length scale you used for estimating the curvature should be in between. Okay, I was going to skip this, but Buyang just talked about the regularization of points. So my method is so simple. I'm going to use the discrete flow map just to act on the points. If they are stretched too far, I'm going to act. Stretched too far, I'm going to add pre-images. If they are stretched, if they are compressed for two points being too close, I'm going to remove them. It's extremely simple and can be analyzed to false and six other accurate under the Mars framework. Okay, please click panda. Open. So, if you put a panda in the vortex share, it preserves the topology very nicely. This is the real grid computation. Let's close it. And as you can see here, our methods can easily get to machine precision while all the precision while all the other VOF double set they they only have four five digits of accuracy for another additional fruit you get is that our methods the accuracy of our method does not degrade if you have five or Or arbitrary number of phases. Okay, this is a 3D test case. If you go back, this is the famous vortex shear of solid ball. So this gets very thin. So in real F level set, it's common to see there are. It's common to see there are holes here, but in our methods, we can preserve very thin structures. So for the Stanford Buddha, we have we can preserve the number of the number of holes here. It's five. Here, it's five very nicely, and peacefully. Okay, so that's the interface tracking part. Based on the Boolean algebra, I also proposed the high-order, this is actually eighth-order method for estimating curvature. The key idea is this: when we have a really A really accurate representation of the material region, we first will rotate it so that the tangent here is almost zero. And by a very elementary analysis, that reduces the accurate leading truncation error by a factor of about a thousand. However, if you use VOF and LOSAT methods, if you use VWF and level set method and you rotate it it's very complicated and inaccurate operation so our so the height function method by Sussman is probably the the most accurate method on estimating curvature but our methods are more accurate by eight orders magnitude um did the This is published in a while ago. So we also did a mean curvation flow. So we have false six. We also have ace order. I didn't show here it here. And the point I want to make here is that the Mars remark Framework, you can do accuracy analysis very naturally in a very straightforward way. But stability analysis is hard. In fact, stability analysis does not belong to the Mars framework. It belongs to your partial differential equation. And so the point here is that the Mars analysis framework gives you Gives you consistency, high-order consistency. If you have the analysis for the discrete scheme, that's a wonderful combination. Okay, so that's the first part of my interview tracking and the curvature estimation. So, then what we did these in the past several years are these seven steps. The first one Steps. The first one is that we developed the AI-aided algorithm for polynomial reconstruction with Poise letter generation. This is what I always believe that AI should be a very good complement to traditional scientific computing. Maybe let me talk about this and go back. The big picture is this. We have bulk flow, and I'm going to insist that we use rectangular structured grids to compute variables on the bulk flow. Because we have Boolean algebra, here it comes again, because we have Boolean algebra, we can use this grid to cut the bulk flow into many pieces. If and classify the cell into pure cells, empty cells, or interface cells. So when we are discretizing our spatial operator, we have to say how do we deal with this interface cells. That's when this AIA data algorithm comes to help. It comes to help. It gives you an algorithm to selecting nearby points so that you can fit a high-order multivariate polynomial to discretize the operator. Then based on this PLG, we will talk about this in the last talk on Thursday, how we did the cut-sell method for elliptic equation. For elliptical equations, both in 2D and 3D. What is so special about this consequence method? I've seen in the literature how people want the discretized matrices to be symmetric or positive definite. In our method, one disadvantage of doing this type of thing, this type of thing, is that the discrete Of thing is that the discretized Laplacian is not symmetric, it's not even definite. So, here it brings up the question of how do we solve the resulting linear system. The specialty of our cut-cell method is that we can prove that the linear system is very effective solved. Is very effectively solved by a combination of multi-grid method and LU preconditioner. The cost of solving the elliptic equation is order N. Then based on these, we also did some elliptic interface problem. I don't have time to cover it, but I will probably report to Professor Jin Li someday later. Someday later. We have four six other for the elliptic interface problems. Then we have a semi-Lagrangian finite volume method for infection equations. Then we get to Navier-Stokes for regular domains and we augment this using PLG to irregular domains and extended it to moving boundaries. And we augmented it to with support adaptive measure. We support adaptive measure finding a parallel computer. So I'm going to skip this. And since Professor Jiang Guo Liu is here, I'm going to talk about our Navier-Stokes solver. So Professor Shen also talked about this morning. So I think maybe So I think maybe this is more interested than the other stuff. So we have some previous methods like settle point approach, Torn's projection method, all the second order projection methods, and the pressure Poisson equation approach. They all have their strengths and disadvantages, but they have some common limits, like no higher than second order accuracy. No higher than second-order accuracy and the temporal integration coupled with spatial discretization. This is bad for software implementation and maintenance. And the instability is the most worse killer. What we want to achieve for our Navier-Stokes solver, we want, well, this I already talked about. So is this, we want to handle moving boundaries under the same framework. Under the same framework, we want to preserve energy dissipation by the SAV approach proposed by Professor Shen and colleagues. We want to enforce flow incompressibility. In other words, we want the divergence of our velocity to decay automatically. We want to enforce all the accuracy both in time and in space. We want optimal complexity. On top of this, we want to have AMR and parallel computing so that. EMR and parallel computing so that given a certain hardware facility, our algorithm is kind of close to optimal. These are kindergarten knowledge to the audience. We have the Hamhold decomposition with define a projection. Then we this lemma This lemma, I don't know whether people are familiar with it. So, if you have no penetration conditions, the condition of divergence free is equivalent to the adjoint, self-adjointness of this projection operator. We make a lot of use of this fact. Okay, so Professor Liu and colleagues wrote a paper in CPAM. The paper in CPAM talking about this commentator. This is truly the core of the difficulty of Nagar-Stokes near no-sided bonding conditions because on periodic obound conditions, all the major operators, they commute. We we are everybody is happy. But the fact that Laplacian and projection does not commute cause most of the difficulty. Most of them are difficult. So, I'm going to say a little bit about the UPV formulation proposed by Professor William. This is the strong form. I don't think this is in this paper, but rather in a later TCP paper talking about the strong form of the OPP. So, I was in Lawrence, Berkeley, and my job. Berkeley, and my job was to get out a fourth-order projection method. I was so hopeless until I saw the paper by Professor Liu. One of the brilliant, brilliant idea is to control the divergence velocity with the heat equation. After you rewrite, reformulate divergence. We formulate Navier-Stokes into a perturbed system of heat equation. So you have this mechanism to say, okay, the divergence of velocity cannot jump up and bite me because the maximum principle says you have to die. So we tried, I tried to borrow the idea or adapted the idea into financial. Or adapted the idea into finite volume formulation, but every time I failed, then I started thinking it's because of all these questions. The first is a gap between the PDE and computation because if I discretize this set of PDEs, there is no projection operators. Why, if you add a projection operator into your own PDEDEDEDEDEEEEEEEEEEE Add a projection operator into your algorithm, that's a discrepancy between your PDE and your algorithm. Then you might say, Oh, we can just put some projection operator into before some of the use. Then the real question is, where do we want to put all the projection operators? The second problem is that for high-order discrete projections, no matter stagger. Projections, no matter stagger grid or co-located grid, you really cannot get all these nice properties of the projection operator. None of them can be satisfied. But then there is this central question, how does the error affect the microstability? And it's very difficult to answer this question under this framework because this derivation assumes that. This derivation assumes that U is divergence free. So, numerical experiment, many, many numerical experiments confirmed the instability if I just use this strong form to do narrow stocks. So then after a while, we published the paper in JSC. The theoretical ground of that paper was still not solid enough. So then, Enough. So then we did some more work, worked harder, and cooked up some GPU formulation. This formulation borrows some ideas, but have our own originality. You might be surprised that there is no penetration condition. In other words, W dot n does not appear in the equation. appear in the equation. So let me go back a little bit and I forgot to introduce this W. So the idea behind this formulation is this. It's so difficult to fulfill this incompressibility condition on velocity. So we might as well just assume that the velocity is not divergence free. Speaking from a geometric Speaking from a geometric viewpoint, you want the manifold of U and you want the U and the pressure to evolve on the sub-manifold with the constraint of divergence of U equal to zero. It's so difficult. Projection method says that, okay, if you are deviating from this sub-manifold, I'm going to project you back. You back, but here the idea is different. The idea says I'm going to embed this sub-manifold into a higher-dimensional manifold. Why dimension, higher dimension? Because I have W, U, and Q. This is a three variable system. It forms a higher dimension. Now, I'm going to use Professor Liu's idea to say, I'm going to set up a mechanism to drive. Mechanism to drive any deviating solution from the sub manifold back to the submanifold. This is the heat equation here. Then we are very happy about this idea. We try to prove unconditional stability. We cannot. We try to essentially all combinations of different boundary conditions. Uh, boundary conditions, um, except one, except removing the uh which the no penetration condition. But finally, after meeting with Weang Li, my gratitude to Professor Li for the idea. Um, for the for the criticize, we will fix the problem after. The problem after Buiang Li risked the problem. So the point line is this. In order for this to treat the equation to really take effect, you need at least this derivative, homogeneous derivatives of boundary condition, or partial divergence of w partial n equal to zero. If you don't have this boundary condition, If you don't have this boundary condition, the divergence of W might still blow up. And this is a necessary condition. You see, if your W blows up, the divergence of W must blow up first. So anyway, we remove the W dot N equal to zero, but we add some penalty idea. Penalty idea to the boundary here so that the W of n also dies out by the solution of ordinary differential equation here. We must have lambda as positive. Then we can show the first thing we want to show is that this new formulation of Navier-Stokes is equivalent to the original Navier-Stokes. Know Navier Stokes. This is one way, this is the other way. Theoretically, we have no numerics yet. And we can also prove that the kinetic energy is decreasing. Then we can also show that the divergence of W has exponential decay. Then, based on this formulation, we are going to cut. We are going to couple, we are going to put Professor Shen's beautiful work into the formulation. I learned it from Jiang Yang. And then for this formulation, we can prove theoretically energy decay. Then we drag some Roanjacuda methods. Ronge-Kuda methods into the picture, the only requirement is that the Range-Kuda method must be algebraically stable. Let's skip this. Then the mean conclusion is that if the RK method is algebraically stable, we can prove that the modified energy is indeed decaying. And so is the divergence W. So is the divergence W. This is the mechanism I was talking about. W deviating from the sub-manifold, and this mechanism will drive it back to the sub-anifold. Okay, then we have this, we simulated this high Reynolds number flow for 20,000, and we get a false order accuracy for both. Accuracy for both velocity and pressure. Professor Shen talked about Stokes pressure. Here, we don't claim we have false order for pressure because this is a high Reynolds number. The viscosity here is small. So, viscosity scales Stokes pressure. And if we refine the And if we refine the order of accuracy, it will drop. Let me show. This is a 10 to the fifth Reynolds number. We get all these vortices, boundary structures. We could use this one. We augmented with AMR and parallel computing and evolution. AMR and parallel computing. I'm going to show you some. This is the level one, the white box, the level two, and the blue box, level three. Some knowledge those. Then we augment the solver to moving boundaries. I will leave the details to you for the last talk on Thursday, how we get it worked for. Them work for moving boundaries. This is a test, the last test. We have a cylinder oscillating inside an incompressible flow. All the boundary conditions are no slip. These are the vorticities and the stream functions. Could you please click on velocity? So we get a fourth order accuracy on velocity, but we only get a third-order accuracy on pressure in the sense of two norms because this the Reynolds number here is low. So the scaling of the Stokes pressure by new, you can avoid the error job of a finite volume method. Of finite volume methods in solving the Poisson equation because your boundary condition is a second-order derivative of velocity. Okay, with that, I'm going to summarize. I have Mars for influence tracking. Most of the work is already done. We are writing the paper. We have GPA-BS. My gratitude to Professor Liu and Professor Shen. Professor Liu and Professor Shen. We will assemble all these modules to augment the software to three different service flows and fluid structure interaction, contact line problems. And I'll just stop there. And thank you very much.