By Professor Teal on Frontiers of Arithmetic in Enumerative Geometry. Just so that you know what I'm talking about, so in 1879, Hermann Saeser Hannibal Schubert, the guy with the ambitious parents and not the composer, he wrote a book, and he essentially says that innumerative geometry Is the art of counting the number D of figures, geometric figures, that meet well, meet, have some position with other With other fixed figures. He wrote a whole book on the calculus of numerical geometry. And the classic example is in 1849, there's the Cayley-Solman theorem, where they independently, but at the same time, showed that on a smooth cubic surface, there are always 27 lines. And at that time, they were probably thinking over C, but it works over any algebraic with closed field. Closed field. And as you saw last time, here's a smooth cubic surface. And it turns out on this one, all the lines are real. This is the this is, and but it's not very general because it has echo ones, those who know about it. But what's nice about this one is it glows in the dark. Anyways, yes. Is the hein's glow in the dark or the dark? That one glows in the dark. That one glows in the dark. Okay, so, okay, but more is known. So, in 1858, Schlafely, he showed that these 27 lines have a remarkable incidence configuration. They lie on a surface, and you can see on there, you should pass around again, that some of the lines, you can see the lines on there if you can say it right. Some of the lines have, I mean, it's on a surface, so lines will tend to meet, but some of them don't meet. Don't meet. And together, this forms an instance configuration, which is the same for all general cubic surfaces. Not for that one. It's a degenerate configuration. And the symmetry group of the configuration is what we now call E6. Yeah, it's the Coxeter group E6. Or it's isomorphic to it. I mean, it turns out there's a direct relation. It turns out there's a direct relation. I mean, the cubic surface is such an incredibly interesting object. There is a relation to the Liberal Sixth with it. But that's what I'm doing here today. And that's a subgroup of S27. It's not the whole group. Well, this was in 1870. And actually, the first book on Galabois theory, Camille Jardin, in addition to talking about Galabois theory, he talked about these 20. About Gallois theory, he talked about these 27 lines with respect to Gallo theory. And I mean, you can look in his book, and he takes a cubic, so this is a cubic, and maybe I'll just, it's over Q. And then the lines are defined over some field extension over Q. I mean, what I mean is. I mean, what I mean is, you know, each line has a, it's, it's a zero set of a two-dimensional space of forms, and that two-dimensional space is defined over a field. So you look at the common field extension of all the lines, and then it turns out this is a normal closure. And so he observed that because this Galois group has to preserve the lines on the surface, it may bereave them. Be lines on the surface, it may be them. This is a subgroup of E6. Now, of course, since then, it's been shown that it's equal to E6 in general. I mean, in general, in the user arithmetic sense. And of course, all this is valid over any field. Nothing special about the rational numbers. And in this setup that you saw, And in this setup that you saw in Thomas's talk, where you would consider, say, a parameter space of all cubic surfaces, which are cubic polynomials, taking up 20 variables. Over the open subset of smooth cubic surfaces, you have an instance variety. This is a 271 branch to cover. And then you can ask what's the Galois group of this object. So you have this, you take the function field of the instant variety, it's an extension of this. It's an extension of this function field, which is just a large rational function field. Take the normal closure, and that's for his Galois group. And it's known to be E6. It's also the monodromic group. And this makes sense over any field by the construction that Thomas showed at the end, who takes this instance, where you take the top-dimensional top fiber product. So when you say everything, do you mean tightening C0 or it doesn't matter? It doesn't matter. I mean, yeah, the basic reason is. Yeah, basic the basic reason is that these objects are defined over z, and so you can reduce any prime you want, including the zero or, yeah. I mean, this is a fairly universal setup. Okay, but there's more to the cubic surface than just the Galois theory, is that also, Schlaifly, in the same time, he also showed that if you're looking at a real cubic surface, like the one you can actually put. Cubic surface, like the one you can actually put your fingers on, like this one, then you can look at the number of lines, the number of lines that are real. And the numbers that are real are either 3 or 7 or 15 or 27. And later, in 1942, Segre observed that there are two types of lines and And I got a far less residual. Actually, it's my end. I'm not going to farm it. So, if you take a line and you take a plane through the line, it's going to meet the cubic in a residual quadratic. That quadratic meets the line in two points. And as you look at the pencil of planes that contain the line, you get a bunch of pairs of points. And so, this line has an involution on it where you're. This line has an involution on it where you interchange these points. And the question is whether the involution has a fixed point or not. Maybe it's over R, it's a fixed point or not over R. These are the two types, and I actually get it wrong, so I'm not going to say which one is which. And they're called hyperbolic or elliptic. It has to do with the discriminant of this residual quadrant generically. I mean, you can think of it as a function of the generic point of a line. And then Up and up in Teleman, and independently, Finashin, sorry about my handwriting, and Harlohoff, they showed in, oh gosh, I didn't put the date, they showed that H minus E is 3. So there's an invariant here. And this can be understood essentially as the degree of a map or degree of a zero section or another bunch. So there's some really interesting. So, in addition to the Galois group, and I'm not completely unrelated, but it's not so clear why it's related. I'll get to your question in a minute. There's a very interesting reality here. There's a lower bound to the number of real solutions. You can achieve the upper bound, and there are gaps, and there's this interesting invariant. Yes, please. So A to B are the number of solutions. Yeah, yeah, yeah, yeah, yeah. This is the number of hyperbolic and the number of elliptic. Okay. Yeah. In the number of elliptic. Yeah, I'm sorry. No. So that's so, so the point is, is that what you see here is some rather interesting arithmetic themes. So interesting as in small Galois groups having to do with some internal structure that you're not aware of initially. And also interesting reality. And so, I mean, what I'm going to say is that I'm going to So, I mean, what I'm going to talk about the rest of my time here, I'm going to talk about somewhat of a large-scale project I've been doing. I've been doing since I got my PhD. And to sort of understand some aspects of arithmetic. Originally was reality, but I left the reality behind some time ago. I got crazy before I got completely old. And it's some computation. And some computation that's helped understand this. So, I'm not going to talk about so much individual results or theorems. I don't know, there's, if I were to count, it is somewhere between a dozen and three dozen papers that I've written on this, and probably as many with other people who related work or inspired by some of this. Now, what I want to talk about is a A source for examples. I mean, as you saw in Thomas's talk, it helps to have a lot. If there's something you want to study, you have no idea anything about it, you want to have some examples to look at. And eventually you find where the good examples are, and then you study those. For instance, I'm certain when people started thinking about algebraic curves back with Newton, he didn't understand how important genus, you know, cubic curves were. Cubic curves were. Although he did classify them. Likewise, his surfaces, we saw the interesting arithmetic of Q3 surfaces. This is something that people eventually discovered, and then they started studying it further. But a source for examples of unusual arithmetic questions in neurogeometry for me has been the Schubert calculus. The same Schubert. Different, a little bit different than what he talked about in his book. It's what he did after the book, of enumerative geometry. Of enumerative geometry. And so this is a particular class of geometric problems that are fairly fundamental. They're in a number of ways. I mean, almost any set of equations you have in algebraic geometry can be understood as a degeneracy locus, and these are understood, the numbers can be understood using tuberculosis, specialization or something in there. Or something for there. But here, but I'm going to talk about the base case. Here, the figures you're looking at are linear spaces of a vector space, sometimes a vector space with structure with a symmetric alternating form, or maybe an exotic structure, like a non-classical Lie group. And the fixed figures. Figures, those which are imposing conditions. I mean, I should have pointed. So, the cubic surface, the fixed figure is the cubic surface, and you want to count the lines on it. And the condition is line on it. But there are many other types of geometric conditions you know. But the fixed figures here are what are called flags of linear spaces. And I'm going to give a couple of examples to illustrate this without trying to go through. Without trying to go through to detail. And the conditions, the conditions are just simple incidence conditions. Like such that you meet a linear space in a particular dimension. And I'll illustrate that. And well, before I forget it, I want to point out that what makes this useful. makes this useful for this is that we understand this the Schubert calculus in this setting extremely well. We can list, you know, there's a way to list all possible geometric problems of this sort. There'll be a way to compute all their solutions using simple algorithms that the combinatorialists provided for us. There are hundreds of millions of these which are easily computable, like on your even on your toy laptop. And so it provides somewhat of an interesting laboratory for studying phenomena. I mean, for instance, if you want to, you know, people, you know, you might want to understand, say, variation in insects, and you study one of the one million species of beetles. You study all of them, you get some large data set and get information about this. And the fact that we understand what these all are and can generate them means you can automate this process. them means you can automate this process if you if you so wish. So let me just give it a give a simple example. I'm going to ask, this is like the oldest we have, I'm going to look at the number of lines in, well, in projected 3 space that meet four lines. And this is quite old. So I take four lines in space. Four lines in space. And it's known that if you take three lines that do not meet in space, they're going to lie on a unique hyperboloid of one sheet. And in fact, since they don't meet, the hyperboloid is doubly rolled. If you want to check, you can look at this. Some people made ball as a kid, and some people didn't. So it's doubly ruled. And the lines that meet by three lines are. rule and the lines that meet our three lines are the lines are the lines of the other ruling. And so if you put your fourth line in here, this is a quadratic. So it's going to be the fourth line will meet this in two points. And through each point on the quadratic, there's a line in the other ruling. That's the two solutions. So there's a really beautiful classical geometry behind this problem of four lines. Let me describe a problem that's a little more complicated. I'll just go here. And the reason it's more complicated is The reason it's more complicated is because it's one of these that has, oh, cool. It's one of these that has interesting geometry. So I'm going to look at, this is the most in the weeds I'm going to get in my pot. Sorry about this. So the number of four planes, I'll call them H. And I'm going to say complex eight-dimensional space, but that's really just a red memory. It's really any field. And you'll understand. And you'll understand when I describe it's really, I mean, again, just with the lines on the cubic surface, these are all defined over Z, and so you can think of your data for it. And I'm using LGRAC to Collegefield just to think about things more easily, that meet four planes, K1, K4, each in a two-plane. Two plane. So these are linear spaces that are assumed general, and the condition is that this meets each of these in a two-plane. Yes? So K1 through K4 are two planes? These are four planes. That's four or four planes. Four or four planes. These four planes. I mean, the problem is, I have four planes meaning four planes and four, four planes. It's like it's a tongue twister. Or it's basically, when I was in graduate school, we would call this the Rother. Here's what we would call this the Rothenberg notation. One of my professors, Mel Rothenberg, used the same notation for everything. So there's a point X and a manifold X and a tangent vector X and a vector space X. And you had to understand the context. So, you know, we didn't mean, but I often thought about Mel Rothenberg later and how actually people made fun of it. And I don't know that that was a good thing. I think it's a good example. I mean, today, I think today what people did to poor man. Well, anyways, we were graduating students trying to learn differential geometry from someone who, and we couldn't know what objects he was talking about. Okay, we were frustrated. And it was funny. I mean, it's not very fair. I mean, for instance, people make fun of my. People make fun of my stuttering, people make fun of my handwriting, and I have no control over those. So if you do that, we can meet up back and have to play. I understand, yeah, yeah, yeah, I understand. But the Rosenberg notation is just too big to look for. Okay, let's get back to this. Okay, so first of all, these are general. So any two of these don't meet because they're new linear algebra. So any, so C8, so any two of these are in direct sum. So for instance, I can. Since I can just consider the direct sum of k1 and k2, and that's equal to c8. And now, if I take k3, it's a direct sum with each of these, so that means that, okay, there are natural projections from this direct sum on each of the factors, and those projections, this is an isomorphism onto those because the kernel of the projection of K1 is K2, K3 does not meet K2. So you have isomorphism. K2. So you have isomorphisms here. And you also have an isomorphism here. Isomorphisms here. This actually, for the problem of four lines, it has the same structure, but just no interest in Yalo theory. No, that one does not go on the joint. But it's, yeah, so you have these isomorphisms. And, Frank, before you point that out, so the fact that E8, sorry, E6 basically both occurs as a symmetry and as the gutter. The symmetry, and there's the Galois group of a field on which it's defined. Is this a coincidence? Yes, okay, I didn't make the point. Because you have to preserve this incident structure, the Galois group, well, okay, the Galois group has an action on the lines, and that image is inside of E6, but in fact it's in bed. Oh, okay. Yeah, sorry. Sorry. Thanks. I mean, you should have asked me that earlier. Yeah, sorry about that. I mean, the problem is I talk about this a lot, so I forget to say the important bits. A lot, so I forget to say the important bits. So these guys are in direct sum, and they and so what I can do is I can, there's a map from k1 that goes to k3, that goes to k2, that goes to k4. These are all isomorphisms back to k1. And I'm going to call this map phi, and for, I'll call this map C, the map, the map that. The map that goes through K3 to K2. So you have these isomorphisms. This is an almond of GLK1. And so here's a fact. And is that the solutions to this problem, they correspond to two planes H in K1 such that phi of H equals H. There are two dimensions. They're two-dimensional stable subspaces. And one way you can see that if I have a two-dimensional stable subspace, I can map it to here and map it to here, and it's a direct sum of these two. Well, in fact, what is it? It's H direct sum C of H. But then the image of H and K3 and K4 are where this linear subspace meets K3 and K4. So that'll be a solution. I'm sorry, I said this is really in the weeds and quick, just accept it. Quick, just accept it. And so, what happens is, is I wanted to, so what turns out, okay, so this is a really interesting structure. But you can, from here, you can analyze everything about this geometric problem, all the arithmetic questions. So, for instance, okay, so assuming these are in general positions, phi is semi-simple, so it has four eigenvectors. Or eigenvectors. Right? Okay? And if you imagine moving in the space of all semi-simple linear transformations, you can permute the eigenvectors freely. I mean, you can just do it in your head, actually, over any field, write it down. And so it turns out that the, okay, so first of all, the Galois group of the eigenvalue, eigenvector problem. Of the eigenvalue eigenvector problem is S4 obviously acting on four elements. But here, because these stable spaces are sums of two eigenvectors, what I'm going to get is the Galois group here, or the only symptom group, is S4 acting on pairs of eigenvectors. And so this is, okay, first of all, the number here is six. So you see that this has six solutions given by any pair of notions of the whole space. A two-dozi stable space. But the Galois group is not S6, it's this group. It turns out this is a primitive, although it's somewhat beside the point. And so this is a geometric problem that has a very small Galois group. It's actually, this is also alternating. In fact, this is actually this group of type D, if you want to think about it. Right, which is also S4. D3 is A3. D3 is A3. Once I put that notation, oh, no, this is the Dickian diagram for D3. Refraction group. Yeah, yeah. But I'm sorry. It is true, yes. But that's somewhat beside the point. It's really this group. It's really this interesting permutation group. And now also, let's look at reality, okay? Because we should be concerned about reality. We live there. And so what happens is, you can look at these eigenvectors. is you can look at these eigenvectors and there's there's three possibilities. You have four of them are real, you have two are real and two are complex, or there are four of them are complex. But if four of them are complex, they actually come up in two pairs of conjugates. Okay? And then you can ask which subsets of these, right? Because these are two elements subsets of these, are stable under complex conjugation. Well here, all six are stable. Well, here, all six are stable under complex conjugation. Here, if I pick the two real ones, they're stable. I can also pick the two complex conjugate ones, and I get a real subspace, so there's two. And here, it's the same argument, but a little bit different, because any, you need to take two conjugate pairs, and so there's also two. And so, this is an example where the reality, you can get all of them to be real. That's actually a theorem of Bakquiel. You can get all Schubert problems real. Problems real. But there's a lower bound on the number of real solutions, and there's an interesting gap here. This gap is because there's a hidden in here, well, okay, you've seen the gap here. That's the reason it is what we'll see, it's because this special structure. So, this is an example of a Schubert problem that has some unusual arithmetic and geometry. This was realized, I mean, that, okay, people know this problem forever, but that it has these interesting structures was realized by Rob V. These introducing structures was realized by Robbie Vaquiel because it came out of a computer calculation he did. It was like somebody he wanted to study. And it's easy to generalize this. So as I said, yeah, so there's, you know, you see gaps and lower bounds, upper bounds, how would you select things to be real? You know, this turns out to be all the real. And so I want to talk about, okay, so now I'm going to split my talk. Now, I'm going to split my talk. I'm going to talk a little about reality because that's some of the things I've worked on or thought about, and it's kind of a little bit fascinating. I'm going to try not to get into the weeds. And then I'm going to talk about Galois groups at the end if I have time. So around 1993, Boris Shapiro mentioned to me a way that he claimed will always. That he claimed will always give you real solutions to Schubert problems. And I'll tell you what it was. It turns out it was false, but it was correct for the Grassmannian. And there are generalizations. So he suggested a way to ensure that all solutions are real and Schubert Copulus. And I've been talking about the Grossmanian so far. There are many other flag varieties, and it's really enormously. And it's really enormously difficult to wrapper rhyme around all of them at once. So I'm not going to do that to you all, other than saying there are other ones. But it's actually kind of easy. It's also beautiful classical geometry. So I'm going to talk about everybody's favorite algebraic variety. So this is a Framcreas variety. I'm sorry. I'll draw my T's the same. So this is the. So this is the moment curve if you're not in algebraic geometry. In algebraic geometry, it's called the rational normal curve. And it also comes up at Lie theoretically. It has a very standard Lie theoretical interpretation. You exponentiate a principal nilpotent in GLN, and you look at the orbit of a generic vector under it. I mentioned that because these, you know, there's some lead. Because these, you know, there's some sort of lethargic stuff interacting here. So this is the rational normal curve. And then if I take some i, I'm going to talk about fi of t, this is the, so actually, I like column vectors. This is the span of gamma of t, gamma prime of t, gamma to the t i minus first power of t. If you want to make this a little more intrinsic, this is really. A little more intrinsic. This is really, this is a map of P1, and you can take all the eye jets or I minus one jets because I want something I-dimensional. This is I-dimensional because this curve is convex everywhere. And this is the I-plane osculating. So at least one person in the room knows what that means. Gamma of T. Who's that? Who's that? No, it's an Italian word. Oh, isn't it? It comes from Latin. It's kissing. I know what it is. There are two people who know it. Osculating gamma T. Well, oscillating gamma at gamma of t. It's the, it's, it's, it's, so in the case when i is two and you projectivize, this is the tangent to the curve and so on. It's the highest, it's the plane that is i sort of contact. Plain density sort of contact. And it's also, it also comes by exponentiating by this principle of local one I talked about before. And what Shapiro said, and he attributed this to him and his brother, he said that if the fixed spaces, if the fixed flags, I mentioned that Schubert calculus involves flags, although I only gave you an example of one element of the flag, but in general you'll have several nested subspaces. If the fixed flags If the fixed flags oscillate gamma at real points, then the claim is that all solutions to these geometric problems are real. And that's kind of preposterous because you could formulate this as, okay, if you don't, the geometric problem is a system of equations, and I have a system of equations with real parameters, and all the solutions are real, always. All the solutions are real, always. And that's just, that's just, you know, it's just bizarre. It's wrong. It can't be true. So for instance, if I took these, if I took these to be oscillating the rational normal curve, so for instance, I can have it oscillated at 0, that's k1, k2 at infinity. These are blocks of size 4. I'm just writing down a standard basis vector. And then K3 and K4, you just take, well, you just figure it out. Then these will all be real. That's actually not hard to track. I mean... Now, he told this to me before I ever touched a computer, and I actually never ever investigated this until I learned to formulate math on a computer sometime in the middle of my postdoc. My postdoc, and it shockingly appeared to be real. But let me say a couple of equivalent statements. So here's an equivalent statement: a rational function with real critical points. So this is a rational function on P1 with real critical points is real. Meaning that it's, you know, that you may have to multiply by a complex. You may have to multiply by a complex number to turn it to be real, but it's real. The polynomials can both be real simultaneously. Another one is that if I have F1 of T up to F, K of T, these are polynomials in T. Then they're Wronskian. And such that they're Wronskian. And the Wronskian is the determinant of Of f i minus 1 j of t. It's the determinant of the square matrix. So k by k square matrix has only real roots. Then the span of these guys, F1 up to Fk, is real. These are equivalent statements. I mean, there's classical mathematics behind this, and this is a special case of that, because the critical This is a special case of that because the critical points of a rational function is just fg prime minus gf prime. You can take the curve of this in the microphone or talk calculus, which is a run. And here's another one. If I have a rational plane curve, so this is a parametrized map. So P from P1 to P1. P1 to P2, and the flexes are in R P1. So a flex of a rational curve is a place where the derivative and the second derivative are, you know, the tangent and the second derivative are dependent. Frank. Yes? What was the stotation bracket F12FK? Oh, I mean the span. Span. Sorry. The span. Meaning these could be common. Meaning, these can be complex, but their span as a vector subspace is normal. I mean, that's the problem: you give me a basis, and it may not be real, but the span is stable under complex pipe coefficient. Of course, if you choose the right basis, like a triangular basis, then it'll have to be real, so real coefficients. So these are all equivalent statements. Oh, flexed Rn is real. And these are maximally inflected curves. Are maximally inflected cards. There are a bunch of other equivalents, too. And I want to point out that this conjecture they made, what happened is I turned my computer on this, and it appeared to be true. And so, the story was I actually built a computer when I was a postdoc because I had no money for buying a machine. It's cheaper. And then I tested this for like about a year or so and wrote a paper about it. And it sort of, you know. It sort of passed into the world as this interesting conjecture. And now there's, I think, five or six proofs of it. There's actually a very recent proof. Yeah, six proofs. Because more recent proof, I've reproves this, but also does something more general. And they've so far appeared in really top journals. I mean, journals that I can't, that I haven't published in months, like JAMS, Advanced Humanities, Animals. And the first proof used some really, really interesting stuff. Really interesting stuff in theory of integral systems and mathematical physics. Now, there's an elementary topological proof, there's algebraic proofs. Anyways, now, okay, so something that I and my team did over the years is we, so this is so I'll say we instead of I. I'm not listing my collaborators because there's a lot and I didn't want to get miss anybody. And I didn't want to get miss anybody. But we popularized this. Well, I popularized it originally with this, and some variants, and there are extensions of this conjecture, which I'm not going to state because it involves a lot of notation. I'll state one. So I have this rational normal curve. I could replace a tangent. I could replace a tangent flag by a flag that's spanned by its intersection with the curve. I'll call that a secant flag. And if you choose flags that are secant, where the intervals of secancy are disjoint, somewhat ordered on the curve, then apparently they're all real. And there's a special form of that has just been proven in the sixth paper here. Because it has to do with total positivity in the gross mining. Is this getting close to now if and only if conditions? No. Only if conditions? No, God, it's not if an only one. Not only. Alright, the example I gave you there, you can choose four planes that do not come from oscillating for which all the I values are. What about interval, the generalization? No, it's not. It really is not. And I, I mean, so in okay, in a shitload of computations, that's a technical term. I'm sorry. I'm sorry, laps in my high school vernacular. Yeah, it's not a characterization. So I probably, and some variants and extensions in, let's see, in, yeah, and yeah, okay, in originally in sort of medium scale, like, like I said, like on my, you know, on a computer that I had built. On a computer that I built, or on a couple of machines, and later, I should say that we discovered possible extensions of this by simple experimentation. Like I ran something on my computer and I eventually looked at it, and it's clear something was going on. But as I mentioned before, if there's a phenomenon you do not understand, I don't think you should publish a conjecture based upon one. Based upon one week's computation. But later, in systematic, and I'll talk about experiments, we, or my research group, found and studied, I mean, because in some of these experiments, we discovered other phenomena. These experiments, we discovered other phenomena which we then later explored at other times: extensions, sorry about my writing, and generalizations and also non-generalizations. That there's some things you might want to think were true, like Boris's original conjecture is just simply false. That was one thing we discovered. It's false as stated, but We discovered. It's false as stated, but there are ways to get something, to alter it to get something that might be true. Did he tell you how he came up with it? Yeah. He had no fucking reason for it. I have to say, okay, so he mentions this to me, and like, I'm trained. You don't make conjectures unless you have a good reason for it. He said, would it be nice if it were true? Yeah, yeah, yeah. Yeah. And I think I made him famous. By my calculations. Anyways, nevertheless, now I want to say that some of the conjectures and observations we've made have improved. I talked about all these papers that appeared. Some of them are approved by members of my group, and some of them are approved by other people. But most of them remain open. And I'm going to take just a couple minutes to talk about how we organize this. Well, you know, how we organize this. So, we, I mean, as I said, and I'm not going to write on the board because of my writing. So, the Schubert calculus, we understand what all the geometric problems are. We understand how to formulate them as assistance of polynomial equations. We understand how many solutions there are. And so, eventually, by the second large-scale experiment, we have access to, at that time, my department. At that time, my department had five rooms with a. I checked last and I looked up what I wrote about it with about 200 computers in it. Each had four cores at the time. Eventually I've created six. And when they were not being used for calculus instruction, they were set up as a simple Beowulf cluster where you have one computer that sends jobs to all of them. And there was a computational resource for my department. And so we. And so we also had a database server in my department that was just some old machine they didn't trash. And so we set up something where we created a database which had things we wanted to study, things that had been studied, and then things we wanted to compute, how much computation had been going on. Because by things we want to compute, I mean a list of Schubert problems. I think initially it was like 500 or Like 500 or something, we ended up having. And then, for each of those, we computed many millions or hundreds of millions of Grugner bases and calculated how many were real and how many were complex, and also other data about the way we chose the flags. And that was stored in this table. And what happened is when a computer would wake up, we'd set a job to it, and each of these problems. Each of these problems were batched by pre-computation to things that would take under two hours, eight hours, because that's the bottom wall time, or needed a huge amount of extra time. Because some of them, the computation was very difficult. And then it would wake up, and depending on the time when that process had started, it would look for a short, a medium, or if there was like a weekend or school break, a long problem. It would do this. If it failed, we would know that there was. Failed, we would know that there was a problem that was started or not finished, and we'd fix it up. This ran autonomously for many, many years on about four different large experiments. And some of the later ones, some of the later computations were inspired by things we observed in the earlier ones. We started thinking, well, maybe this might be true, or look at this. And this used to be available online. You could just go. Online. You could just go to a web page and you could explore and browse the data. And there were some people who wrote papers based upon some of the data we had observed. So we had observed some unusual lower bounds. And one of Thomas' undergraduate advisors, Eugene Mookaine, proved some of these conjectures by just perusing our data. We also did a lot of this. We discovered a phenomenon of gaps in the Schubert calculus by looking at our data at one time. And it turns out I made because I was going from memory and not from so, first of all, this all disappeared. So I no longer have, I have some of the data, but I don't have the infrastructure and I have a database server anymore, so you can't look at it. Because in the pandemic, we lost some of our computer help, and then the ones who were left were very stressed. And somehow somebody deleted this, and I was asked by my department head to not complain. Department had to not complain because we might lose all of our computer power. But in fact, you know, you know, they they deleted like a dec a decade's worth of computation and some interesting data. The department is my wife, and I'm not going to go against her. But she told me to complain. She told me to complain, of course, you listen to your department. Only head of department could do that. I would do that to any other head of the department. But yo, but yo, but I mean, no, so at one time when we lost our computer. No, so at one time when we lost our computer help, there was a discussion to assign me to be systems administrator. And I know just enough to cause trouble, but more than every other faculty in my member in my department. So it was really, it was a bad time. So there was an error in backup strategy? No, no. They turned it off without backing it up. Why was this not backed up? Because the people who had set it up had already left. And they never backed up the thing. No, it. Backed up, I think. No, it the backups, yeah, no, no, there are serious problems. No, the new people coming in didn't know their head from a hole in the ground. Okay. But I think the problem was before, if there was not a backup, before they came in. I think the problem was, is all the expertise of loss of clear the backups were. No, we had a serious calamity in my department because of loss of expertise. Now, that's, I mean, I have some backups of the data. Of the data. I mean, it's also my fault. I could have just downloaded the. I mean, I could have, you know, someday said, let's download everything from this. Put it in a hard drive. Yes. I mean, I have some backups, but I realize they're not the most recent, which is. Yeah, well, this is before getting. Okay, anyways, but I want to say that I looked in my old papers, and this used around five. And this used around five terahertz years of computation, not 15 like a abstract. I'm sorry about that. And we solved at least 14 billion Bergman bases in doing this. I mean, a lot of them, a lot of time was spent on extremely hard to compute examples, because I think those are, it's most interesting to compute examples at the very edge of your understanding. Anyway, so that's a story about reality. That's a story about reality and computations. And what was because I mean, it turns out that only about a tenth of these were studying the given conjecture, because we also wanted to study around the conjecture, like you asked about the non-groups. So we didn't just do those that were just the sequencer, just showing me what we looked at at the overlap because we wanted to see how it might depend. And there's a lot of fascinating. And there's really a lot of fascinating stuff in those days that we don't understand. And this required really a very large, I mean, to do it the level I wanted to do it, I mean, also my belief is this is based upon this notion that if you don't understand why something's true, you should have very strong evidence for it. So I wanted to use all possible computational tools to get data for certain conjectures. And that was why we did this overkill computing. Also, the computing was free at that time. Computing was free at that time. It was paid for out of people's school fees. But those days are gone. We don't have those. I mean, I should say, at that time, I also had some dedicated... I mean, at one time I had a little bit of one of our university clusters, and we could use some of that, although it was really hard to use, getting into install the software we needed. Do you think it's possible that with current technology and uh cl the cloud and whatever that this could be rebuilt in a few months? Within a few months? Of course, yeah, I think it can. I mean, in fact, you can do the exact same experiment we did, at least, well, yeah, I mean, well, yeah, of course. So I just say, I wrote a paper early on describing just our experimental setup. And at this time, I point out how just like in physics, I mean, maybe I should share the paper because the first two pages of it are some of the manifesto for doing large-scale. For doing large-scale computations and just seeing where the chips fall, because we discovered many things in this. So, I'm going to talk about something that's a little more special and smaller-scale now in my last few minutes. Galois brews. Okay. So, first thing is, is the literally in the first experiments before I was using this cluster, when I was just using, there was a time when I had. I was just using, there was a time when I had a way to log into everybody in my department's machine, run something that would run for a week, and when it was done, it would email me the results. And, you know, so I had to periodically log into people's machines, ask them permission. If somebody had too many, I don't know, too many browsers open, they complained that the computer's running slow, they'd have to leave the problem. No, no, the funniest thing was, I got in a shitload of trouble when I was in Wisconsin. Was I got in a shitload of trouble when I was in Wisconsin. The department, the associate at the time, was a numerical analyst who complained to me for slowing her machine down when, in fact, she had 20 different processes of interactive MATLAB running. And that was the problem. I just typed top. And she didn't know to type. I'm sorry. This numerical analyst didn't know to type top. Okay. You know, but what do I do? I'm a post-hoc, I apologize, and I got. Post talk, I apologize, and I got in trouble. It's just an episode of post talk. But in the first experiments, we discovered, of the reality conjectures, we discovered small Galois groups. By a small Galois group, what I mean is it's not the full symmetric group. And because, and I'm going to call these enriched. And the reason is, is in this setting, as you saw in Thomas's talk with the cubic surface, when you Or the cubic surface, when you have a small Galois group, there's a belief that this is due to some extra structure. So your geometric problem is enriched with extra structure. This is like in the Russian Revolution, there was the Mensheviks, and they were the main party, but then this minor splinter group called the Bolsheviks, the big party, took over because of their naming. In fact, it's a Russian who told me to use this term. And Moscow probably does it. But anyway, let me get back to it. So these are, we found. We found some of the small Gallo groups, which are interesting. And now, so I knew from the beginning that there was a lot more, there was interesting Galileo groups out there. But also, Ravi Vakiel had come up with a way to study Schubert calculus on the Grassmanni and combinatorial. He has a very interesting, two papers in the animals. And in there, he actually studied Galvo Grouch, and he found that. He actually studied Galileo and he found that problem that I talked about earlier. And so the goal was, and this is along G-O-A-L, is to identify the interesting problems, meaning these guys, study them, and, well, maybe classify. Maybe classify, but you have to find the interesting problems. But also prove theorems about other ones. So, one example, and everything here was originally discovered somewhat experimentally. So, the cross-mounting of two planes in n-space, it's a generalization of lines in CP3. So, these are fairly simple objects. And it's known now that all Schrubert problems. And it's known now that all Schubert problems are, at least alternating. This is something that Robbie uses. Meaning that their Galois group, they have D solutions, that their Galois group contains AD. Because the methods don't allow us to show that it's the full symmetric group, because we're using some group of the REC methods. And originally, from calculation, but eventually a proof is that these. But eventually a proof is that these all are too transitive. I mean, this actually comes about from some combinatorics, and there's a weaker version of the lemma that proves this that uses an input two-transitivity. That's one reason to say two transitivity. Also, there aren't a lot of two-transitive permutation groups. And typically, the groups, not all of them, but they're often either imprimitive or full symmetric in this world. We're not going to find the mathematics. We're not going to find the bathing points. And then, but then, you know, so G49, exactly 14 out of, what's the number? 3, 5, 0, 1 are enriched. This was actually, Robbie, this was actually understood that these are likely enriched by Robin Van McKeel, and we later studied them, explaining their structure completely. And then, as I said, And then, as I said, that's G48. And then for G49, exactly 148 out of what's the number of 31,806. What is this number? So I can list all the Schubert problems possible. There's some data. And then I find all those that have at least two solutions. And I cannot reduce to some smaller flag manifold. And that's the number. Okay, so these are. Okay, so these are enriched. And what's interesting, so I mean, for this, there's a common control method that takes about a week, and we've coded it three different ways, and it takes a week whether you use maple or use something more sophisticated. And it gives you like 150 that it does not understand if they're alternating or not, and then you study them. And here, we understand these completely. We actually have a, they fall in three distinct geometric families. One of them is the one I showed earlier. And one of the other families, we understand it fairly generally, how to construct these generally. And I don't know much more about that. And it hits in a classification. So I'm going to talk just briefly about what these calculate, you know, how do you. About what these calculate, you know, how do we actually sift through the wheat for the chaff? I should say, before I go on, I'm studying much more than these now. This is old work. And it turns out that this is something which I was talking about early work on Galois groups, and I happen to have a number of theorists in the audience, which is very helpful because he reminded me of something I should have remembered from graduate school, namely, you can. From graduate school, namely, you can compute for venius elements. I mean, I knew this in graduate school, and then so, so, but what's interesting, okay, so, but we can take advantage of an interesting quirk in symbolic computation. Actually, in all these calculations, it starts by formulating a Schubert problem in some system of local coordinates with some, you know, with some probably rational coefficient flags. Rational coefficient flags. And then what you would typically do is you would eliminate, you find, you know, this is something zero-dimensional reduced scheme. You find a univariate polynomial whose roots, if you know the roots, you can reconstruct the solutions. It's essentially the ring or the field of that polynomial is the coordinate ring of your solutions. You eliminate, and then you study it. But if this is very expensive in characteristic serve, you can get polynomials that have that take gigabytes. And fortunately, STRM sequences work in exact arithmetic. You could be reality there. But you could also reduce mod P, and it depends on what day of the week your favorite prime is. Right now I like 8111. Right now, I like 8111 because I did an experiment, and this seems to be the fastest prime for doing all Schubert problems on Lagrangian cross-monty of five planes in 10 space. Meaning smaller primes, it takes longer, and larger primes a little bit longer, or sporadic. But in fact, it's really sporadic, actually, as to which prime works. I mean, don't ask me why. That's my favorite word today. And then you can eliminate. And of course, you can also. And of course, you could also reduce mod P, and you finally factor to get a Frovenius element. I mean, there's this thing you learn in graduate school, then you relearn when you're a little older, that you have a this is some scheme, it's a reduced scheme mod B. It has a coordinate ring, and the coordinate ring is a sum of fields, and by computing and limit and factoring, you find which field extensions. Factoring, you find which field extensions you have. And that actually, and so Frovenius on there acts by this factorization. But you know that way back when you're working over your function field, there's an element of the Galois group of your function field that when you specialize in this prime acts as for beads. And moreover, there's a version of, I would say of Chevitar density theorem is more of Hilbert's irreducible theorem that works over families that tells you you can pick a prime and you're selecting uniformly at random from the Galileo group. To uniformly at random from the Gallo order. But it turns out that while this diagram commutes mathematically, it does not commute in time. Is that this is super fast and this takes forever. And so this has been useful. And I should say that this method, it works well up to around 300 solutions, so a degree 300 extensions, and I guess 20 variables. I haven't pushed it much past 20 variables. I haven't pushed it much past 20 variables. So you can study innovative problems, their Gallo groups, at least get lower bonds on them, up to fairly large size fields. And that was a revelation because when I was doing reality, there's an upper limit of about 100 solutions and about 12 variables. And because we're just searching for interesting stuff, we throw away some. For interesting stuff, we throw away something that's a symmetric group and forget about it. And then, those that are interesting, we compute a couple million Rouvenius elements or more to get an idea of the distribution before we actually apply mathematics. This requires fewer computational resources. So, initially, I was doing this on some server I own. And now I have 128 core. I'll just call it a node, but it's probably more than one node in a computational cluster in my department. I'm hoping. I'm hoping that they will keep it running more than three years because with centralized computing, they throw things away after three years and they're perfectly good, whereas our old computer people can repair them. And I also have 56 cores on people's desks at home. And this costs 10K, this cost maybe 3K to buy these. So you can get, if you're So you can get, if you're studying something that's not as massive as, say, reality, something as simple as Galileo groups, you can do quite a bit with fewer resources. Toys. Well, a lot of toys put together. This is a lot of toys put together. The original cluster was 200 toys put together. How do you get access to people's toys at home? No, no, no. I own two machines. No, I own two machines. Okay, my children went to university, one in Canada and one on a full scholarship. So I suddenly, so money is a little on my office, so I can just buy a computer anytime I want. I can't buy it on my grant because I can't be, because then somebody who doesn't know computing would be the systems administrator, and they wouldn't allow me to install software without begging them. And they turn it off for maintenance once a month when it doesn't need to be turned off. And I'd use a bad file server. To summarize, if you buy a computer. If you buy a computer through your grant, then it doesn't come back to your office. It goes to those guys, and then this one goes to these guys. This is just a rack and a server that my department runs for a numerical analyst. And the person who manages that works for us half-time. The machines on my desk are run by people who are Windows specialists. Okay? You call. No, no, I mean, yo. I mean, yo, centralization is coming to you guys too. No, no, it has come. And it's a curse, it's a nightmare. It's unbelievable. I don't know. Anyways, yeah, let me get back to my talk. So I beefed a little bit about issues of computing. I thought it'd be interesting for people to hear that. And I just wanted to talk about something that I was doing mostly about 12 to 15 years ago, like from 2006 to 2014. 2014, which is a really large-scale computation of the sort that needs HPC resources. And there are some issues in doing this. You don't have complete control over things. And I have to say, these machines are the best because these are pretty good, but these machines are the best because I can run them forever. I mean, right now I'm computing something that takes 18 hours to compute one Frobenius element, and I'm going to have to compute between 300 and 600 of them. And I can just, you know, it's just sitting at home. And I can just, you know, it's just sitting at home, no, no. And, you know, if the machine has to be turned off, I start it again. And I don't have to worry about any wall time or kids using it or stuff. But I just want to give an idea of this is a different thing that other people do, but it certainly is a large-scale set of computations. Thanks. 