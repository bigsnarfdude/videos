So, my talk today is on the rank inference based on top choice of multiple comparisons. So, that necessary means that we are talking about inference for discrete numbers and the rank involve all items. So, then necessary means it involves high-dimensional inference too. So, this based on the joint work with Zipen Lo, who was my postdoctoral, and which Farrell and Wee Chen Wong and Maxine Yi. They were my former students. So let me begin with introduction and then talk about model and uncertainty quantification. And then we talk about the how do we do rank inference, numerical studies, and the conclusion. So let me begin with an introduction. So I mean ranks play an important role in many applications from web search, I mean to voting, movie. To voting, movie music, booking ratings, recommending systems, product design, sports competition. And as Jia Hua said, if we have time, we could chat about refereeing system. It could be used to do referee, I mean, particularly for the conference like NERPS, which received over 10,000 of papers. Refereeing burden is really a big thing. And well, I mean, typical approach is that people. Typical approach is that people while trying to estimate the preference scores of each products or in the sport competition is intrinsic ability or in the paper situation is intrinsic quality of the paper. And we know that there's a lot of uncertainty to it. So here is just an example that on the US best college rankings through 1996 to 2020. So here, I mean, there's So, here, I mean, there's a display here is 25 years average. It's believed 25 years average to be, I mean, less uncertain right than five years average, which you can still see a lot of uncertainty there. Now, the open question naturally asks, I mean, use the social inference. How do we give uncertainty quantification for displayed ranks? So, in particular, is a school A is indeed better than school B? A is indeed better than school B. In other words, the intrinsic score or the preference score of A is really big than B. This is relatively simple. The harder one is school C indeed among top 20 rankings. That's a little bit hard because there's need to compare with all other members in the team. And how many schools should I apply to ensure the top fives are selected? Should I apply five? Should I apply 10? Should I apply 10 in order to have 95% confidence or top one is within my set? So, this is really a new challenging problem because it involves all unknown scores in order to get a rank. So, therefore, we contribute to high-dimensional inference. And another challenge is limited sample size. As I said, I was hoping at the end of the day, if we have time, we chat how to reduce possible number of references for those conferences. Refereeings for those conferences. So that we will have a limited number of comparisons. And our work, of course, relates to a vast literature. The first one is related to ranking estimation based on pairwise comparisons. And this area is probably most frequently studied. And our own group contribute to this part of, I mean, of this part of work too. And then there are relatively few people. Leave a few papers on studying multiple ways, so in multiple ways comparisons. And so, in other words, if I give you four items, you give me the full rank of those four items. So, for the refereeing papers, if one referee referee, let's say five papers, then you already give full rank of all those five items. And so this is relative few. Uh, so this is relative few, and then in terms of stereotypical inference for ranks, so it's very recent things, right? So, we all study based on pairwise comparisons, and there's only study based on pairwise comparisons, and most of the existing methods is unfortunately sub-optimal, and this is really the motivation of our studies. Okay, so let me begin with the model and uncertainty. So, let me assume that you have M items. M items will pick from M items will pick from M item for comparisons. So, in the next Netflix movie competition, you could ranking competition, you could imagine that the company mail you four movies at random and ask you to rate. And here, I assume you only observe the top choice. So, in other words, whenever I give you three products, you observe the one that's been bought, right? The top one. If I give you three, the top one. If I give you three web pages, you observe the top choice. And so this is the, so I pick M items at random and for M items from those N items at random and you get, I mean, you get multiple people to rate it. So you get the outcomes. And I assume that each product has intrinsic score called theta one up to theta n. One up to theta n. So, this is the intrinsic score that we want to learn among 10,000 of papers, each of those theta i's representing the quality of the papers. So, now suppose M item being given to you or M web page being given to you. So, you and you observe what is the probability that you observe the top rank, right? Let's say, suppose it was compared. Top rank, right? Let's say suppose it was compared L times. So you're able to compute the frequency of each comparisons. So what is the model? So the model that govern the top choice is according to the axiom of choice of loose, which basically says that the probability of ice item win is proportional to the intrinsic. To the intrinsic score, and then divide by the total number of items under comparison. So, this is the model that we have. So, in other words, so my imagination is like you have a lot of products. Let's say if I pick three, I read I render, you observe the top one. If I pick three, I think I render another one, you observe the top one. If I pick another three, you observe the top one. So, just like web page, you only know which one being clicked, and you do not know really what are the second one. So, based on this, our question. So based on this, our question is: I mean, how do I estimate these intrinsic scores? And of course, so in other words, in our case, we only apply, I only assume that you observe only the top choice. So if in the case of the loose model, like here, where you have a complete rank, if you observe complete rank, if I give you three items, so you will see the top item among. So you will see the top item among the three items, right? So you will see also observe the top item among two items. That will give you the equivalent information. So in other words, my model today is like this. I have M items. I pick M item at random and I ask L person for the preference and everybody give me a multinomial outcome. And based on those multinomial outcomes, And based on those multinomial outcomes, I would like to infer about all those preference scores. So our learning objective is to provide estimation as well as uncertain quantification of all those preference scores so that we can easily rank the movies just according to the preference scores. And based on that uncertainty, we'll also be able to get the ranking inferences. Inferences. And in particular, if every time I give you two and you pick the winner, so this is the traditional Bradley-Terry-Luce models, just like a tennis competition. Every time when you have a competition, you know which one is the winning. So this is our learning objective. Now, since our data is following multinomial distribution, so it's not that hard to write down the likelihood, right? So the likelihood would be like this, right? This one. So among all those items that are under comparison. So in the graph, I mean, in the graph terminology, so whenever a few items under comparison, we say there's an edge, I mean link between all the nodes. Okay, so this is among those under comparisons. Since you compare L times, so you were able to summarize the frequency of winning. So this is the frequency of IQ. So, this is the frequency of IKs winning, and then finds the probability. So, this is really just a negative log likelihood of this Bernoulli trial. And let me denote P, the probability of link, meaning that probability that a particular group being picked up, particular three items being picked up. I denote this as a P. So this is really a generalization of Erdős random graph. It's a random. Erdish random graph is a random graph, a hypergraph. And our, so of course, there's identifiability issues. Everybody adding five points, it will be the same. So it wouldn't change the probability of comparison. So therefore, we do the maximum likelihood subject to the identifiability constraints. So this is the MLE, which is a natural estimator to this high-dimensional setting, in which I assume. Setting in which I assume n go to infinity. Now, the first thing that we go straight to the results. If the probability, the probability of edge connection, if the probability of a particular group being picked up is at least this size, then we basically say that I have mean square error in L2 sense is controlled by this, and in L infinity sense. This and in L infinity sets controlled by this. So this formula looks a little bit cold. So let me explain what it is. So we first of all, we basically saying the L2 error and L infinite error is more or less the same order other than this log n. So this basically saying the error is in the estimation of scores is spread across all the entries. It's not concentrated in any particular entries. Now, if you ask me what is a particular Me, what is a particular score can be estimated. If you want to estimate my score, I have at least had to be involved in comparison. So, how many times I got involved in comparison? So, then there's M minus one person, right? So, if you choose M minus one to form a group of M. So, this is the choice. And then, what is the probability that particular group being picked is P, and then once that group has been picked, there's L times. Picked there's L times of comparisons. So, this is the sample size. So, for this mean square error is proportional to the square root of the sample size, which as you expect would be the optimal. And in particular, if m equal to 2, which is the BTL model, so in that particular case, our results actually reduce to recent studies based on pairwise comparisons. So, now what is the new about our rate? The new about our race result. First, we give the nearly optimal sampling complexity in a similar study by Jiang and his collaborators. So they require P much bigger, meaning that the sampling frequencies had to be much higher. So it's a square root P order than ours. Ours is only polynomial of this, which is basically the minimum possible because in all Even possible because, in order to be able to get a consistent estimate of each individual scores, right? So, all those hypergraphs have to be connected. If you have isolated like this, there's no way you can tell whether this group is better or this group is better. So, in order to have a consistent estimator, you need hypergraph to be connected. Just like Erdős Reni's case, hypergraph need to be connected, require and has at least to be this big. This big. So, this is the first intensive sampling complexity. And this really has an implication if, as I said, if you really apply these two refereeing systems, basically what means you require very few referees, maybe each paper, only one referee probably is enough. So, the second one, what we are talking here is top K, right? So, since we are getting uniform convergence, so this Docker error is uniformly. This docker error is uniformly controlled by this order. So long as the kth item and k plus one item signal is bigger than this error, then you could consistently recover the top k items. And this is this them say exactly this. If the gap between kth item and k plus one item is sufficiently large, delta k, then you can recover each entry. So this is first on the race result. On the rates result. So then the second result is on the uncertainty quantification, the asymptotic normality result based on this observation over the hyper-random graph. So in order to understand and to introduce the notation, so let me say that if I want to estimate a particular item, let's say the m item, so I use theta minus m is the parameter excluding the mth. Excluding the mth item. And this would be the likelihood that involves the likelihood involves the nth item. And let me denote the gradient of this, which is the derivative of the log likelihood. So this would be really the derivative of log likelihood of multinomials, as you can see, very familiar. Before I was writing here, saying all those are connected. Now I'm writing in summation, adding a random variable here. Summation adding a random variable here, or I want to say this random variable is really an independent Bernoulli trial. So this making all of those number random, all of these random variables being some of independent random variables, which is relatively easy to analyze. So this will be the first derivative. And let me denote this GM here to be the second derivative of this likelihood. And then, of course, just follow through. And then, of course, just follow traditional maximum likelihood like Taylor expansion. You can easily assume that this one, the difference between your estimated one and the true one, would be equal to this, the first derivative divided by second derivative. I think the most difficult part is to show that this one can be replaced in high dimensional by the true parameter theta m here. And this really is And this really is one of the key challenges in the proof. But if you were able to establish that, then the numerator is just some of independent random variables. Denominator will be similarly a sum of independent random variables. So you could easily establish the asympot normality. And this is what we really putting in a more formal result. Basically, saying the difference between these two, the expansion what we have there is uniformly controlled. So all those controlled. So all those the error between the left and right is uniformly over m and this is the order of magnitude that can be controlled. And once uniform controlled, then you can easily establish the asynchronous normality and this is the end with asynchronous variance being given by here. So again the technical proof is mainly establishing the first line and the second is relatively easy. Rely only one out argument and On leave on our argument, and the here is that we just show you above. So, what is our result comparing with the prior odds? The prior odds is always study on m equal to 2 pairwise comparisons. So, in the Liu and his collaborator published in Operation Research, require L to be big than N squares, huge requirements. In other studies, require L equal to M equal to 2. M equals 2, L is finite, the number of comparison is finite, and we actually extend this study to all of those cases. Now, in terms of probability, P, that is the sampling complexity, the sparseness of hypergraph P, so Hang and is collaborated require one to n tenth and And tenths, and whereas we are requiring basically the minimum sampling complexity. So, this is on the asymptotic normality side. Now, this is the new part, right? So, how do we do the inference? So, again, this, let me motivate the question again, right? So, you're asking, are those top two random movie are really statistically significant? So, that's probably relatively easy to answer. That's probably relatively easy to answer if you fix two particular items. If you fix the top two, probably need a uniform convergence. And then the other one is you may asking what is the 95% confidence interval for the rank of, let's say, breakfast activity. So what is this one, the confidence interval from number three to number 10? Or what is the confidence interval? So this is really on inference on discrete values. Discrete values and any of those really involve all, I mean, at least all pairwise comparisons. So, in more general, we're asking the following question. How to build simultaneous confidence intervals for a few items? So, if I give you three movies, can you give me not only the confidence interval for one movie's rank in, but also I would like to give you all three movies simultaneous contents rank. movies simultaneous contents rank. And then, of course, you're asking yourself: is an item among the top K ranking with high confidence? Is one particular item among the top K with high confidence? And this is the second question you may ask. The third, you may ask how to select a set of top K items with confidence. So these are really involve all. Really involve all unknown scores, and we really need some kind of new framework in order to address this kind of issues. Okay, so here's the idea. Let's fix one, let's say Breakfast at Tiffany, one particular movie. And I would like to know what is the intervals for the rank. So in order to know what is the interval for the rank, at least I need to compare this item, this particular This item, this particular movie, with the rest of the movies. So, this is the other movies compared with the current movie. So, all the other papers compared with the current paper. So, this is the difference. So, let's say suppose for a moment that you and I were able to construct a simultaneous confidence interval for the difference of preference score between the case item and M item. M is the one of your interest for all case. Your interest for all case. So, if you're able to construct simultaneous competence intervals, so let me display all those simultaneous components intervals here. So, there are only three possible scenarios. One possible scenario is that all these is above zero. So, which really means case item, these item is better than the item, M item that you are interested in. So, in other words, I'm the worst, right? So, my rank is at best one, two, three. My rank is at best one, two, three. My rank is at best four. So this is counting how many of them have lower confidence limits big than zero. That would be my lower limits of the best rank I could have. So this will be the lower confidence limit. And similarly, if I'm looking at this side, so this side means that the theta k minus theta m is below. That k might say that m is below zero, that means I'm better. So I'm better, so that means I can counting from here on, and this is counting backwards. What is the rank? And this give an interval of this rank. And then, of course, there's indifference. There are many indifference in between. So this is basically the idea of converting the, I mean, the simultaneous competence interval into a rank so that you can get the With one minus alpha confidence interval for this rank. So, this is based on the idea. So, in order to achieve this idea, of course, you need to construct the statistics. So, the statistics or the random variable. So, this is your estimated value, the preference score difference, and this is true preference score difference. And now I have compared our time. I have compared our time, so I divide by square root L and divide by standard error that I have here. So this would be the distributions of your interest. Once you're getting this distribution, then you can construct simultaneous confidence interval for pairwise comparisons. Now I'm doing more than just one item. I'm doing more ambitious, right? A bunch of items. So therefore, I max over those items of interest. And now if you And now, if we go back to our asymptotic expansion among linearization among all those M items, so this is the likelihood that we have here. If you write it down, it's really a summation of L different kind of comparisons. And that's how what we do here. So, by our linearization, the statistic what we have here can be written something like of this form. And then And then this form can be approximated by the multiplier bootstrap, the Gaussian multiplier bootstrap here. So this is your estimate score, and then you just add in normal random variable here, and this is the G you have. Now, the issue is whether this G distribution approximate this T eta distribution. If approximate is correct, then we can construct simultaneous competence interval for. Just a simultaneous confidence interval for this, and therefore we can achieve the result we would like to have. And the next thing I'm basically saying is that the bootstrap that we constructed, so the quantile that we get here from the bootstrap and the one that you want actually is asymptotically consistent. And this holds for, I mean, all different sets. I mean, all different sets kind of M. So, therefore, different M give you a different adaptive weight because this G alpha would depend on M. So, based on simultaneous competence interval of pairwise comparisons, so using the translation that we translate here, right, so from pairwise competence intervals into the rank intervals, so I could get a simultaneous competence intervals for all. For all items of your interest, right? So, you can calculate the lower bound and upper bound just simultaneously for all the items that we just said a moment ago. So, that will give you the simultaneous contents interval. Now, how do our contribution compare with the existing literature? So, for the pairwise comparison, that is BTL model, Chao Gao and his collaborators basically propose one mass alpha. Propose a one-minute hour for confidence interval based on sort of like Bon-Fernoulli adjustment. So when we have pairwise comparison here, like this, pairwise comparison here, like this. So the uncertainty here basically being replaced by, let's say, one over n hybrid upper quantiles. So it might replace a very, one of the very conservative. Like a very conservative estimate when we construct. There's a two source of uncertainties, but one source of uncertainty is being replaced by extreme high quantile so that you have only one source of uncertainty. Because of that, I mean, because of this kind of like conservativenism, so their multiplier, that is the confidence intervals with be an order of magnitude wider than our methods. Methods. And in addition, if you do this way, the method cannot do simultaneous confidence intervals. If I give you three papers, you cannot rank three papers simultaneously. And our method, of course, apply to also one-sided confidence interval as well. So as an example, if I test in the hypothesis, say, well, is a particular item, let's say Breakfast Actony, or a particular paper, is it ranked on Is it rank on top K or not on top K? So, in this case, you could just construct a lower countance limit like this, right? And then just be your critical region. So, if you are far in this critical region, you reject the null hypothesis. And of course, this is really a simple translation. You could easily say that this test will have approximately, will have a power, I mean, size control at alpha and power. Alpha and power go to one so long as the signal strength is sufficiently large. And this is more or less the minimum information theoretical minimum that you can get. So now the next thing we asking ourselves is, can I find a set of items? Let's say 10 items, a set of items. A set of items so that the top K item, top five items being included in my 10 items with probability, high probability. And under our framework, all these kind of inference issues become relatively easy. So in this case, I just do one-sided confidence interval for all the item m. So in other words, what I would like to do is like I would like to give each To give each product a one-sided competence interval, and this is each product's one-sided competence interval following our methods. And now, if you just drawing one-side competence interval like this, right? So, this is item one, this is one-side competence interval for item two, this is for item three, and so on. So, if you do for each of these kind of items, so now what is the icon? Now, what is the icon below K? It would be this item, this item, and this item. So, therefore, you pick in these three items in this particular case to be the top K items. So, in other words, under our framework, you can also do asking the question, what is how many product I need to choose? So the guaranteed top K items are all there. And this is really, you just construct many one-sided confidence intervals, and you do that. levels and you do that. So now let me illustrate and help you understand a little bit by doing numerical studies. So in this particular case, so let me remind the setting again. Let's assume that I have 6D movies or 6D products. And every time I pick three products for you, and then I ask in 20 person, 20 customers to rank which are the top choice. And you do not know the second choice. Not know the second choice. So, you know, 20 customers buy the product and you did not see the second choice, or 20 webs, 20 person click the website and you see which one being selected. And this is the true preference score of theta star uniformly between two and four. And in this particular case, any particular group being picked for comparison, any three item being picked for comparison is P. And this P is, I let is changing here. Uh, I let it change in here so that uh, so that this value will be dependent on p because n is fixed, m is fixed, uh, l is fixed, only is a function of p. So as p changes, I change this too. So and according to our results, the theoretical rates of convergence is of this rate. So here I'm plotting here. It's basically more or less linear, demonstrating that our rate of convergence is correct. And similarly, you can do for the L2. And similarly, you can do for the L2 error. L2 error is just multiply the n here, and you plot here. So, this is more or less showing that the result is correct based on 200 simulations. And we basically also seen that the asymptote normality hold for each individual theta i star. And here we just verify one of those theta i's, let's say the first item. The first item, not necessarily in our Not necessary in the first item that I'm just choosing here. And this is done for different L's. So once three parts have been chosen, you could ask five person to rank, 10% to rank, 20% to rank. So this is corresponding to 5, 10, and 20. And then you have different P's. The bigger the P, the more dense the graph, the more, I mean, sample size you have. So this is the one of the least most powerful. The least and most fast one, right? So, this is the most dense one. So, asymptotic normality basically holds quite well, and also standard error that's sigma one here being also estimated well. That's why you do not see all dispersion phenomenon there. So, this is on the asymptote normalities. Now, as an illustration of construct condensed intervals, so again, it's under the same model. Now, we just increase the sample size a little bit. Increase the sample size a little bit. L instead of 20, now become 80. I do 500 simulations. And this is for different kinds of sampling complexities. So P equal to 0.5 means any three items being selected with probably 0.5. And this is the confidence interval based on our methods of theta i. So this is courage basically correct, right? So it is for different scenarios, it's always have 95% courage. Now, if you are talking about And courage. Now, if you are talking about the one item, let's say the 10th item, is the courage of the rank correct? We also basically say the imperial courage is 100%, which is correct because we are when we infer from simultaneous confidence interval into the rank inference is a conservative inference. So therefore, it's not exactly identified, it's 100%. And this is the associated width, a sample. The associated width as sample size increases, the sampling complexity, I mean, sampling probability increases. So the length getting smaller and smaller at the right order of magnitude that we would like to see. Now, in contrast, if we use in Bonfernori type of methods based on Gao and his collaborators, then the lens basically double our lens because they are using. Length because they're using, I mean, there are two sources of error. They're fixing one source of error using extreme quantile methods. And here is just one particular like a data application. In this particular case, there's 100 jokes and it be read by a lot of users. And for illustration purposes, in this case, n is equal to 100 plus exact 100 jokes. So I just take it. So I just take in three, I mean, three jokes at random, and each three jokes been picked with probability like 5%. And once being picked, I asked 80% to rate. And then I only assume that I observed the top choice. And based on this data, so I was able to get in all the estimated scores, like Joker number 89 would be the highest, and so on, right? And let's say Joker. And so on, right? And let's say joke number 10. So this will be the confidence interval based on our methods. So the rank, the observed rank or estimate rank is 10. Our interval is 8 to 12 based on slightly different of our two methods. And if you're using Gao and his collaborators, so it would be 4 to 16 because they are more conservative. They're getting much wider. And also we can do one-sided and uniformly one-sided competence band. The competence band, interval, and so on. So, let me skip this. So, let me do a conclusion remark and also a quick comparison. So, what we did in this paper, we studied multi-way comparisons with only observed the top choice. And this extends the traditional BTL model, which is based on pairwise comparisons, and modified by PL model, which is based on. PL model, which is based on full ranking. So, if you I give you 10 items, you have all ranked among those 10 items in a useful and practical way. In many practical cases, you only observe the top choice. And naturally, we propose MLE for estimating scores, and we establish the optimal LO2 and L infinity rate of convergence under basically minimum sampling schemes and optimal rates. rates. And we derive also linear expansions and establish a syntax merits for each preference scores. And then we introduce a new inference framework for rank of items based on pairwise comparisons. And we verify all those asymptotic results and numerical experiments through numerical experiments. So let me quickly just do a few quick discussion. So the natural people may Discussion. So the natural people may ask: can we like, can L be as small as one? I mean, our interval based on L big than one, how do we extend to the situation when size are difference? So if you referee three papers, you have top one amount three, you have second one among two. So if you referee four papers, you have top one among four, and then the remaining also top one amount three, top one. Remaining also top one man three, top one two. So, how can we conduct inference where you have comparisons are heterogeneous, not necessarily all based on three items? What is the difference if comparison graphs are fixed? And what are the spectral methods? And what is relationship with them, maximum likelihood methods, and how to construct inferences under those general comparison graphs. So, we have some premier results. Some premier results, and I was hoping some of those results one day I can apply to, let's say, refereeing system in the conference. So, for give you an example, in 2022, so neuronips received over 10,000 submissions. In 2023, ICML received nearly 7,000, 6,500 papers. And this is really a huge burden on the system, and people complain about quarterly review. And people complain about quarter reviewers, and also there's a number of individual noises, and so on and so forth. And I mean, in this such kind of conference situations, there are many referees simultaneously review multiple papers. So therefore, you have complete ranking among all those items. And this would be fitting exactly the framework that I'm saying in this discussion. So therefore, we could. So therefore, we could estimate the quality of each individual paper based on pairwise or multiple items of comparisons. And hopefully, at the end, really just rely on each individual paper being reviewed by one referee will be adequate, just qualified referee, adequate to draw a conclusion on the quality. And this is pretty much I want to say, thank you very much for the Thank you very much for the attention.