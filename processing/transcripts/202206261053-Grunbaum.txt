Video, which I should be able to do here. Okay, so let me get rid of this here. Okay, so about the title of the talk, I could have written a much longer title and it would be... Can you hear me okay? Yes. Yeah, okay. So this would be a much longer version of the talk that I'm going to give. And if you remember, David Thompson at the very end, yesterday. Thompson at the very end yesterday mentioned something of this field being a very good one because it puts you in contact with lots of interesting problems. I think he mentioned science and statistics. He may have mentioned mathematics too. I forget now. I wanted to try to convince you that if you go back at least 60 years in time, it's now more than 60 years of a real. Than 60 years of a remarkable series of papers by Slepian, Landam, and Pollack. We'll go into some detail in a moment. Given the nature of this conference, the fact that we're not got together, we're not all together, I'm going to give you a very short version of a very, very long ongoing story. The main point of my talk is that whatever they did is only the beginning of something that can The beginning of something that can be exploited further and further. The main topic of the problem, of course, is time and band limiting. And in order to them, I'm going to be very limited in time. My dream will be to finish in 20 minutes so we can get further on schedule. Or if we want, people may want to ask questions. The main surprises come at the very end. Crisis comes at the very end. I mean, for some of you, everything will be new, for some of you, everything will be old. It all depends. Okay? So, let me briefly say that I was not really interested in band and time limiting. I was interested many years ago in a version of X-ray tomography, which I called limited-angle tomography. For the gantry, if you go to a hospital, instead of the X-ray tube. Instead of the X-ray tube going all the way around the patient, it only goes for a limited sector in angles, and that's the analog of time limiting. This only works for patients of compact support, and that's the analog of band limiting. Now, I learned of the work of Slepian Lando and Paul Beck by looking at this great book on Fourier series and integrals written by Harry Dean and Henry McKean. And Henry McKean, and I'm very, very thankful for that. So, this is too small for you to see. I don't want to start changing the amplification here, but this is a very nice survey paper that Davis Lepian wrote if the year is 83, and it's called Some Comments on Fourier Analysis and Certainty and Modeling. What I wanted to mention is that I have stolen. Is that I have stolen from him the word serendipity. After all, the title of my talk is Serendipity Strikes Again. And I want to show you, you can all access this paper. Some of you know it very, very well. So he's talking about the word serendipity is mentioned here. It is repeated over here. And the main point, there are two main points I want to read to you from here, that there was a lack. That there was a lucky accident that we found a second-order differential operator that commuted with an integral operator that was at the heart of the problem. This has appeared some few times in different talks yesterday. Then he goes on to say that, let me just read the very last sentence here. Most of us feel that there is something deeper here that we currently understand, that there is a way. Understand that there is a way of viewing these problems more abstractly that will explain the relegant solution in a more natural and profound way. And he goes on like that. Okay, so that explains, I mean, I stole from David the word serendipity that he uses here twice. And all that I want to say is that, damn it, he was so right. Okay, so here is a brief summary. Summary of the work that Slepi and Lando and Pollek, they are, the three of them are in blue color here. So they look at the problem coming from the Fourier situation where the eigenfunctions are e to the ikx, and they land into the famous sing kernel. And considering this as the kernel for an integral operator, they find, as Slepian was saying, As Slepian was saying just a moment ago, a commuting second-order differential operator. I don't have time to write it down. You either know this better than me or you don't really care. So in any case, this is just what I want to mention here. Then Slepian himself looked at two other cases. He looked at Rn and looked at the radial functions in Rn. So functions that are functions of only one variable, real. Functions of only one variable, really, he found the Bessel functions here, a corresponding kernel, and a commuting differential operator. Then he did the same thing a few years later. If I remember, this is paper maybe number four in the series. He dealt with the integers, okay? And that's what they did. So by that time, I was interested in using an analog of what they had been done in this problem. Had been done in this problem in tomography, and I started looking and I asked myself: how come they haven't done the case of the DFT, not the Fourier series, not the Fourier integral, but the finite case when you just deal with the end rules of unity. So I managed to get myself invited to Bell Labs. I went to Bell Labs. I actually gave a talk there about this stuff. There about this stuff, and in private, I asked David how you must have written a paper somewhere where you do the end roots of unity. And both David and Henry Landau kept saying, no, we have never done that. I simply said, I'm sure you're confused. You must have written that somewhere. You just don't remember it. Well, came back to Berkeley. This was before the days of email. Before the days of email. So, this is a letter dated April 25th, 1979, where he says, Well, blah, blah, blah, nice meeting you. He says, the kernel that you have suggested would be the one in here. And he says, I haven't worked on this one ever. So I said, Well, maybe they are right. Maybe they have never done it after all. So since I have already done this on my own, I brought. Done this on my own, I wrote a paper, came out maybe a couple of years later, where I do the eigenvectors of a very specific Teplitz matrix, which is the one that you will get if you are doing the DFT. Replace this sink kernel by some other kernel, and these are called a discrete version of the prolit spheroidal wave functions. All right, so that would be the first thing that I did, but it's First thing that I did that is sort of a little extension of the previous one. My real interest was and still is: are there other situations where you can do something analogous to what they are doing? In each case, you will have to look for some appropriate form of harmonic analysis or maybe something even more complicated and see what happens. So, as I told you, I did the case of Z N. The Z n, the n roots of unity, then with the capital students, we did the case of Fourier analysis that is non-abelian. So that was actually concretely the case here would be SO3 over SO2. And in the abstract here, which you cannot read, I say the sphere may be the most natural example for the applications. So in that paper, we actually consider what are nowadays called Consider what are nowadays called the slipping functions on the sphere. Okay, so we are at this level here. And there was a paper later by Frederick Simmons and other people here, where they actually noticed the work that we have done and they call these the slipping functions, which is a very, very nice choice. I then looked at some other cases. This is another paper, but let me. This is another paper. Let me. So, here is a slightly general picture of what I'm trying to do. I want to replace the exponentials. This is the initial case of David Schlepian, Henry Lando, and Henry Pollack, by the eigenfunctions of some Schrodinger-type differential operator, where the potential V I'm going to Potential V, I'm going to pick so that everything works. So, what do I mean by that? Given the potential, there are going to be some eigenfunctions. They're going to take the place of the exponentials, say, or maybe the Bessel functions, or whatever they are. And you should form then a time-band limiting operator, the analog of the sync kernel. And you would like to find a commuting differential operator. That's a problem that I've been pushing for a very, very long time. So I asked for a simpler question to find those situations, that is those v's for which the eigenfunctions keep in mind the function e to the i kx, which of course satisfies a differential equation in k, but it does so in a stupid way because it's the same, this enters in a very symmetric way. In a very symmetric way. So my question was: How can you find all the v's so that the corresponding eigenfunctions will satisfy not only the initial differential equation in x, but also a differential equation in k. And you can prove a little bit of work that if you insist that the order here of the second equation should be m, then there are only two families. Then there are only two families: either the Bessel case, where the potential is C over x squared. If C is equal to zero, you are in the Fourier case, of course, and the AD case. So the AD case had never been thought of before, but more important than this, we found that there are more V's than the one just here. You can deform these V's in ways that maybe was not. Maybe was not expected. There are deformations that involve certain times. These times here, I call them T1, T2, and so on. And it turns out that in these cases, you do have this so-called bispectral property. This equation and that equation are both satisfied, but it turns out that the potentials are solutions of equations that back in the 70s at least were exactly the same. Back in the 70s, at least, were extremely popular. The main example is the Cortevik-Debries equation. Some of you may have heard of them. It's an integrable nonlinear partial differential equation that exhibits solitons. What does any of these have to do with the initial problem of sloppy and landowner pollach? You tell me. Okay, so I wrote a paper, a long paper, with my friend. With my friend Hans Deustermer in the Netherlands called differential equations in the spectral parameter, where we actually do exactly what I just told you. We classify the situations where you have this bispectral property. And as I mentioned at the beginning here, the origin of the problem, this business of limited angle tomography. I think we even have a reference there to Slepian Landau. To Slepian, Lando, and Pole. Okay, so I'm done. I mean, the ideal audience, I don't want to belittle any one of those of you in the audience, but my real audience, to be quite honest, are these three guys. I wish I could be talking to them. Okay? What I've told you up to now, you can all listen to, and you're part of the audience, but those are the guys. But those are the guys that I wish I could wake up. What I told you up to now, I've been torturing them over the years. And in fact, if you go back to the paper of the survey paper of David Sclepian, he refers to the fact that myself and my students were trying to push the staff in different directions. What happens now, I think, should show. I think it should shock everyone. I thought I was sort of an expert on these papers and their uses and so on. But very recently, within what are we now, June, six months, I discovered something that I should have learned much, much earlier. And I hope it will shock you too. So, what am I talking about? There is something called the Riemann Seta function. Okay, I don't have time to. Okay, I don't have time to define anything. It's formally defined if S is a complex number, but take it to be, if you want, a complex number with real part bigger than one, so that these series will converge. This is a well-defined series, and there is a unique extension, analytic extension to this function, to the complex plane, except for some obvious pole somewhere. And the so-called Riemann. And the so-called Riemann hypothesis is essentially, I'm going too fast, that all the zeros of this function lie on some particular line. I wish I could talk to my friends, Slepnando, and Polek, and just watch their reaction when I tell them that, believe it or not, something they did has some connection with this function. First question, of course, will be, what have you been doing? Course will be what you have been drinking last night or even right now, and shouldn't you be taking away and put away? So I'm going to show you now, very briefly, very briefly, a paper that appeared in the last issue of the proceedings of the National Academy of Sciences. And you may not be able to. And you may not be able to read this, so I'm going to read it for you. The ultraviolet prolate spectrum, what does that mean? It means you look at the differential operator we are talking about, okay, and you compute its spectrum. Now, that to be technical here, ultraviolet refers to looking at the operator in a domain different from the usual. A domain different from the usual one. But you can also do this for the other one. It had been done by Alain Kahn, who is one of the authors here. So let me try to finish the sentence. The UV product spectrum matches the series of zeta, zeta being the Riemann zeta function. You have to be a little bit careful with the meaning of matching. It's not a claim that they are exactly the same. Alain Kahn, a very distinguished French method. Distinguished French mathematician, winner of all the prizes you can think of, Fields Medal, professor of the Coll√®ge de France, IHES, etc., etc., and an amazing guy, has been working for 20 years or more. I think the first paper is 1998, and he has been using, if you can read super, well, you have to have amazing eyes, but I should have a better skill to show you. This is exactly the second order. Exactly, the second-order differential operator that Slepian, Lando, and Pollack used. So, in this paper, they show, and you have to go back to all their papers too, an amazing connection, a very tantalizing collection between the work of these three guys that had nothing to do, you would say, with the Riemann Zeta function and the serials of the Riemann Zeta function. What I was very lucky. I was very lucky. Let me see. Oh, yeah. I was invited by the proceedings of the National Academy of Sciences to write a commentary. So this is what I took my title from. I'm stealing the title of my talk from the title of this paper of mine. Well, the whole thing is in two pages. You can read if you have access. If anybody wants to see this, send me an. This send me an email. I will forward to you the PDF. But you are young people, you know how to access the proceedings of the Academy of Sciences. I'm going to read the first sentence. It says the breadth and depth of reference one, that's the reference to Khan and Moscovich, are truly remarkable. And then it talks, I explain, and then I say their paper doesn't need any comment. Paper doesn't need any commentary, and if it needed a commentary, I'm certainly not qualified to do it. On the other hand, I care a lot about the prolates, okay? So assuming that there are some young people in the audience, like you guys look all very young to me, my paper then gives a historical view and it tells you where the prolates really come from. And then it has a section called looking farther. Has a section called Looking Farther Afield, which is my hope of where things may go. So I'm going to read for you the last paragraph. It says, one can only speculate whether any of the deformations of the basic cases mentioned above, those are the ones with these time parameters, will someday feature in some physically meaningful problem or play some role in the study of the zeros of the zeta function. Of the zeros of the SETA function. Reference one, that's the paper of Alain, Khon, and Moscovici, should inspire people to look in new directions. And I thank you, and I have more or less managed to do what I wanted, which was to end 10 minutes earlier of my allotted time. Thank you very much. I can now turn.