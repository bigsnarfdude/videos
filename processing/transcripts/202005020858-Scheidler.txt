Yes, one second. Share and maybe I can do this full screen. Can you guys all see this? Oh, yeah, it looks good. Oh, yeah, it looks good. Okay. Yeah, so Andrew had asked me to say a few words about Richard Guy before my talk, which is why I get like an extra long slot. So I have about 10 minutes to talk about Richard Guy, and it's impossible to say whatever, you know, all the things that need to be said about Richard Guy in 10 minutes, but I'm going to try and at least say something. So as you all know, Richard Guy passed away about a couple of years ago. About a couple, going on a couple of months ago, at the fine old age of 103, we had all sorts of events planned, memorial events and so on, which initially we were feverishly planning them and then we were feverishly canceling them because of COVID. So, unfortunately, there's not really been much opportunity to honor Richard Guy and celebrate his life and even mourn him properly. And there are more events. And there are more events planned in the fall. It's not really clear how they're going to happen or if they're going to happen, but we'll see. But I'll still try in the 10 minutes to say a few words. And there are articles in the works about Richard and his mathematics and his work for the CMS notes and for the AMS notices. So there'll be a lot more about his mathematics to come in these articles. So I think I'd rather just say a few words about the man and sort of a friend and the way that we all interacted with him. The way that we all interacted with him, and as Andrew said, hopefully, we can share more stories later on. So, I have not to do dry facts and figures, I have prepared a little bit about Richard's life because actually the life is full of really amazing things. He's had an amazing life. He's also had the life is sort of full of superlatives. So, Richard and also his wife Louise were pioneers in many, many ways. We'll see this. So, Richard was born in 1916 in the UK. He got his The UK. He got his bachelor's and master's from Cambridge. He also got himself a teaching diploma, but he never got a PhD actually. He got married in 1940 to Louise Guy, whom many of you probably fondly remember. They had three children. And then came the war. So Richard was a young man in the war. And he was hired as a meteorologist, actually, by the Royal Air Force. And his job was to forecast weather for bombing. Weather for bombing runs over mainland Europe. And he was even initially a civilian, but then he actually was in the RAF and he held the rank of flight left. I think you're supposed to say flight lieutenant when it's British. He was first posted in the UK and then in Iceland and then in Bermuda. So already then he got around. After the war was over, they lived near Manchester. He briefly returned to Manchester and taught high school. And then they moved to London. And then they moved to London and he taught at a place called Goldsmith's College, which is a teacher training college, or at least was at the time associated with London University. And then they up and left in 1951 and went to Singapore. Now, I think even by today's standards, that's kind of a pretty bold move to do, but in those days, this must have been something unbelievably exotic, you know, to go to Singapore and just live there. So they lived in Singapore for 10 years. He was a faculty member. For 10 years, he was a faculty member at what was then called the University of Malaya. And then it got even more exotic, and they moved to Delhi. He taught at IIT Delhi for about three years. And one of the people he taught there was Manjul Bhargava's uncle. Now, Manjul credits this uncle for getting him into mathematics. And Manjul tells the story how this uncle told him about this amazing professor at the university that was teaching him math. That was teaching him math classes and so on. And so, even then, you know, Richard had had influence on the lives of like very important mathematicians. And they thought, Manjula and Richard thought very highly of each other. And the way that Richard always worded it was like Manjula and he were in each other's fan club. Those were Richard's words about this. And then in 1965, they up and left again and came to Calgary. And by that time, I mean, they were going on 50, right? Richard was going on 50. So I dealt IG. Richard was going on 50. So at that age, he started a completely new career. He was hired to the University of Calgary as a faculty member. He was there from 1965 till 1982 and became an emeritus afterwards. And of course, he was still a fixture very much of the department long, long after he retired. In 1991, the university awarded him an honorary doctorate degree. I remember that. I was actually at the ceremony where this happened. So this was really nice. And when Richard was asked about it, he just sort of shrugged and said, It his, he just sort of shrugged and said, You know, probably by this time it was a real embarrassment to the university that I didn't have a PhD, so they gave me one. And I mean, Richard was always very low-key about these kind of things, right? So Richard's wife, Louise, passed away in 2010, right on Richard's 90th, actually this is incorrect, this is Richard's 94th birthday. And I remember that day was a very sad day. We were all eating dinner. We were invited for dinner at Matt Greenberg's house, and Louise had been. And Louise had been in the hospital briefly and died right on Richard's birthday. That was very, very sad. She was 92 years old. They were married 71 years. I don't think there's anyone here at this workshop who's even near 71 age-wise. And this is how long Richard and Louise were married. And all 71 years, they were absolutely devoted to each other. And then, as you know, Richard Guy passed away on March 9th of this year at the ripe old age of 103. The ripe old age of 103, in fact, almost 103 and a half years old. So that's a snapshot of his life. So you see already that he's had a very, very interesting life. I don't want to, I mean, I will say a few words. So of course, Richard was a very, very celebrated mathematician. He had two firm feet in two disciplines. One was number theory, but I think he first and foremost considered himself to be a discrete mathematician, to be a combinatorialist. A combinatorialist. And he's made huge contributions to that field. He and Conway and Elvin Berlicum wrote this book together, four-volume book called Winning Ways, which is essentially the definitive work on combinatorial game theory. It's been translated into, I don't know how many languages. And that community has experienced quite some loss because Alvin Burlikam passed away last year, right around the same time Richard passed away. And then Richard, of course, passed away on March 9th. Richard, of course, passed away on March 9th, and a month later, on April 9th, John Conway passed away, actually, of COVID-related health problems. I mean, John had been in ill health for a while, but so all three authors of this monumentous volume passed away quite recently. So it's really a big, big loss. In the number theory community, maybe the thing Richard is best known for is UPoint, which is the unsolved problems in number theory. It's a volume of problems. It's a volume of problems that he put together and edited over the years. I think it's maybe in its third or even fourth edition. I think this originated with the West Coast number theory meeting, where one of the traditions is that people bring problems that are being discussed there. And then there was always a problem. These problems were compiled into a collection. And Richard did this for the longest time. He was for many, many years essentially the record keeper and scribe for these problem collections. And I think out of For these problem collections, and I think out of that grew unsolved problems in number theory. And this has influenced so many mathematicians. I mean, many people have looked at these problems and just solved them. Many students have written theses about them. So he's had a big, big impact there. Richard was also a very, very celebrated educator. He said many times to me and other people that he actually considered his mentorship and education of students, especially young people in particular, much, much more important. In particular, much more important than all his research contributions. He supervised many students, even in his late years, even until a couple of years ago, we would co-supervise undergraduate students. I know he's co-supervised many undergraduate students with Mike Jacobson. And this worked actually really well because we had access to good students and we had access to grant money and Richard, of course, was a source of a never ending source of like really, really good problems that were very suitable for undergraduate students. Very suitable for undergraduate students. And I know he really liked this. Richard, both Richard and Louise were avid pacifists at a time when this was probably quite frowned upon. You know, I mean, this was during the Cold War and so on. Many of you have probably seen the button that was a permanent fixture on Richard's jacket that said peace is a disarming concept. Richard and Louise were environmentalists long before that became a thing, and most people know. And most people know here, probably, that he raised enormous amounts of money for the Alberta Wilderness Association. They had the annual tower climb where they would climb the Calgary Tower to raise funds for this. Later on, it was the Bow Tower. He actually did this for the very last time at age 100. He climbed the entire Bow Tower, carrying a picture of his wife up there, and he raised an unbelievable amount of funds for this. He was, of course, also an avid mountaineer. There is our Avid mountaineer. There is actually a backpacker hut named after Richard and Louise Guy. They were very, very active in the Alpine Club of Canada. And that was one of the things that brought them together initially that they hiked together and mountaineered together. I've put together, I mean, if you go on the internet, there's unbelievable amounts of things written about Richard. There's websites, there's videos. I've put together a few to just give, I mean, you can look this up at your leisure. These are all live web links that give you a little bit of the snapshot of his life. Little bit of the snapshot of his life, and there's also a wonderful book written about Richard by Chick Scott. Chick Scott lives in Banff, he's himself an avid mountaineer and a very celebrated author. Anybody in the mountaineering community knows him because he's written a lot of books about the mountainseer and things. And he's written a book called Young at Heart: The Inspirational Lives of Richard and Louise Guy. It's published by the Alpine Club of Canada in 2012. I have a couple of spare copies. After Richard passed away, I ordered a whole bunch. After Richard passed away, I ordered a whole bunch and they arrived at my house sort of in the nick of just before everything shut down for COVID. So, if anyone is interested, I'm happy to part with some of them. So, that's really kind of in a nutshell what, you know, Richard the man and Richard the friend. I want to conclude with a couple of things. The first is one of the funniest stories that I remember about Richard, and that was shortly after. And that was shortly after his 100th birthday, he came back from a trip. He was still traveling then. He would go to the gathering for Gardner and he would go to Marfest and things. And at that point, he traveled. And then he came back. When he came back, he came down to my office. He walked in and he's grinning from ear to ear. I mean, he's clearly just beaming with something that was very, very funny. And so I asked him, Richard, what's up? What's so funny? Well, it turned out that on that trip, Air Canada had issued him an infant body. Him an infant boarding pass. So I guess Air Canada is like a Y2K, they couldn't really handle three-digit ages. And after that, Richard became a big celebrity with Air Canada. The other thing I want to say is oftentimes Richard was asked what was his secret and how did he make it to such a ripe old age and how did he stay so healthy. And he had 10 health rules that he would follow. And I've written up these 10 health rules and these are exactly in the These 10 health rules, and these are exactly in the same wording and in the same formatting as he emailed them to me. And they're quite fantastic. So I just want to read them because they tell a lot about Richard. So, rule number one, choose your parents carefully. Rule number two, choose your spouse carefully. Richard Switzerland did this. Get to know a good GP and a good dentist and keep well away from both of them. Keep away from hospitals where there's a good deal of disease and death. Use it or lose it. Whatever you feel like in. Whatever you feel like indulging in once a month is alright. For example, take a bath once a month, whether you need it or not. Watch your weight. If you find yourself pairing your toenails before you dare weigh yourself, you're in trouble. Exercise. Remember Mark Twain's advice. Whenever you feel the urge to take exercise, lie down until the urge passes off. And finally, never cross the street at a pedestrian crossing. That's where the motor cars will get you, which is certainly true in Calgary. Which is certainly true in Calgary. So we remember Richard Guy very fondly, and I know there's at least two of us, Mike and I, who will talk about joint work with Richard Guy. But this is really just a brief snapshot. I'm hoping that as the conference and the day progresses, there will be more stories about Richard. This brings me to my talk. So, the work I want to talk about today is joint work with Richard Guy and with Ethan White. So, this came out And with Ethan White. So, this came out of an NSOQSRA project that Ethan did with Richard and me in 2017. So, this was a co-supervision. Ethan is now a PhD student at UBC. And we started this project, but then afterwards, Ethan really sort of took off with it and made it, turned it from a student project into like a full-blown, very serious research project. And that's the topic I want to talk about today. And this is about the kind of And this is about the kind of problems that Richard really liked. They kind of sit at the interface of combinatorics and number theory. I guess they qualify as combinatorial number theory. They're deceptively simple to state, and they are really, really difficult to get any proofs for. We managed to get some proofs, but really nothing like you would want to. And the main protagonist is a difference necklace. So let's start with a very, very simple question here. This is a puzzle. Is it possible to arrange the numbers one, two, three up to 50? The numbers 1, 2, 3, up to 15 in a chain such that the sum of any two adjacent terms is a square. So, very simple question. If you don't want the answer given away, then I don't know, turn your audio off for just a second and your video, because I'm going to give away the answer in just a minute. So, the answer is yes, and here's an example. So, you see here that if you add up any adjacent terms, then you get a square. 9 and 7 is 16, 7 and 2 is 9. 7 and 2 is 9, 2 and 14 is 16, and so on. So, of course, as a mathematician, you immediately take a puzzle like that and you try and generalize it. So, you ask, well, what about, what if you replace 15 by an arbitrary integer? What if you look at sums that are something else other than squares? Squares, maybe some other property. So, there's infinitely many generalizations on a question like this. So, here's some generalizations. Is it possible to arrange the numbers now one through n in a chain? Through n in a chain such that the sum of any two adjacent terms is: well, we started with a square, but you could ask maybe a cube or a triangular or pentagonal number or a Fibonacci or Luca number and so on. And the fact is that these questions, while very, very simple to state, they're actually very, very difficult to prove. And the squares case was actually not settled until a couple of years ago. So it was finally settled in 2018 by a man named Robert Gerbitz. By a man named Robert Gerbitz, who posted to the Mersenne Forum. He has a blog post on the Mersenne Forum, and he answered this question. What happened is over time they came up with a construction of n, like an infinite family of n's for which this was all possible, for which this was possible to find such arrangements. And then that got refined and that got refined. And finally, they got to the point where they got to all n from a particular point on. And then he did a huge computer. And then he did a huge computer search to get up to that n and finally answered the question in full. And the answer is yes, for all n greater or equal 25. And if you want closed chain circular arrangements, then it's possible for all n greater or equal 32. So there are some smaller n's for which you can do this. We just saw n equals 15, but then there's gaps where you can't do it. But starting at these two thresholds, you can do it for all n. Now, when you get to the other questions that I had, cubes, triangular, and pentagonal numbers. Cubes, triangular, and pentagonal numbers, nothing is known. The answer is almost certainly yes, and the answer is almost certainly there's infinitely many arrangements, but proving this seems to be extremely difficult. The Fibonacci and Lucan number case was settled by Elvin Bernicamp and Richard Guy in a beautiful little preprint called Fibonacci Place Billiards. And that's the reason why it's called that is because they came up with this technique where they would arrange these numbers in sort of a grid pattern where Where it looked almost like they were around the rim of a billiard table, and then they would connect them up in sort of the patterns that a billiard ball would take bouncing off the border of a billiard table. That's why they called it Fibonacci-Paved Billiard, and they characterized this case in full. So they specified exactly for which Fibonacci numbers and Luca numbers you can do this. But other than that, very little is known. And so this led us to look into the question of well, what if you look instead of sums, you look at differences of adjacent numbers? Differences of adjacent numbers. Well, really, absolute value differences, okay? And that's where Eason came in. So let's ask a very stupid question: is it possible to arrange the numbers one through n in a chain such that the absolute difference of any two adjacent terms is a square? And the answer is duh, of course you can, because you just write them down like this, right? So this is not a very good question. So what about circular arrangements? Well, Ethan started looking at this and realized that even if you look at close That even if you look at closed chains, circular arrangements, the answer is you can almost always do this. And in fact, you can almost always get by with just the squares one and four. So you don't even need any square. You can just do it with one and four. So this was not really a very good question to ask. So we were thinking about maybe we can find some better questions to ask. And so we decided, well, really, I should say, Ethan sort of started to run with the question where you look at circular arrangements and you look at differences of adjacent. And you look at differences of adjacent terms, and you make it so that the difference takes on one of two numbers. For example, one and four. So the difference is absolute difference always one or four, but it doesn't have to be one or four. It could be any numbers, A and B. And that leads to the main protagonist of this talk, which is an AB difference necklace. So we look at arrangement O, and the other modification we do is we now shift all our numbers down. Rather than looking at numbers one through N, we look at zero through N minus one, because some of this requires more. One, because some of this requires modular arithmetic, and it's just easier to do it this way. And really, the results don't really change. So, what we looked at is so-called AB difference necklaces. So, we're going to fix two values, A and B. Let's say A is less than B, and then N. N is the number of things that we want to arrange, and AB are our fixed difference values. And then an AB difference necklace of length n is a circular arrangement of the integers 0 through n minus 1. integer 0 through n minus 1 such that any two adjacent terms have difference plus minus a or plus minus b that's a difference necklace so here's an example this is a 4 7 necklace of length 11 so this is an arrangement a circular arrangement of the numbers 0 through 10 such that the difference of any two adjacent any two adjacent terms any two beads is plus minus four or plus minus eleven right eight minus four is four four minus zero is four um 4, 0 minus 7 is 7, is minus 7, 7 minus 3 is 4, and so on. So that's a 4-7 necklace. So you can ask questions: can you always, do these always exist? If they exist, how many are there? Are there infinitely many? And so on and so forth. So this is what ESA started looking into. And you immediately come up with some necessary conditions for the existence. So the first condition is that A and B have to be co-prime. The difference values have to be co-prime. Values have to be co-prime because if they have a common factor, then of course that common factor is preserved in the difference, and then there's no way. So in order to get all numbers covered from 0 to n minus 1, that common factor has to be 1. Otherwise, you're only, if the common factor is d, then you're only getting every d's number. So d has to be 1. So that's the first necessary condition. Another necessary condition is that the length has to be at least a plus b. That's easily seen by looking at. plus b, that's easily seen by looking at the neighbors of b minus 1. So one of them has to be a plus b minus 1. So that's your length a plus b. That's the shortest length that you can actually get. And a third one that's not quite as obvious, but if you think about it a little bit, it's also obvious. That is that if A and B are both odd, then you can't have an odd length necklace. You need an even length necklace. And one way to do this is you alternate between odd and even. Okay, so these are necessary conditions. Okay, so these are necessary conditions for the existence. So we're going to assume these from now on, because otherwise none of these things exist. And then we looked at when do they exist, and I'll summarize the results that we found. That was mainly both stuff that was done over the summer of 2017. So I'll summarize them all in a theorem. And the theorem says that these things always exist for all permissible A and B in the case where 2A less or equals B. So in other words, A and B are not all that close together. All that close together. And the way you prove this is you can do an explicit construction for a equals one. And then you can do a very simple construction for n equals a plus b. That's that you can easily write down a necklace like that. And then you do a construction for n equals 3a plus b. That's for a greater or equal 2. And this is where we need this gap between a and b. That construction does not work if a and Work if A and B are too close together. So that's where this is needed. And then you use Frobenius' coin problem to glue these together. So I know a couple of days ago, actually, Andrew Granville gave a talk about the Frobenius coin problem in the Bennett et al. seminar. So the Frobenius coin problem says that you have two co-prime numbers, and then you can basically put them together to get currency kind of thing. And in this case, you put them together to get length necklaces. A plus B and 3A plus B are A plus b and 3a plus b are co-prime, and then you look at linear combinations, you can get arbitrary linear combinations, and for each linear combination, you interpret it as a length, and you get a difference necklace. And so this even gives you an explicit lower bound, so sufficiently large, we have an explicit lower bound, and from the Fubinis coin problem, although it's not a very good bound. Most of the time, the real bond is better. This 2A less or equal B is a very annoying restriction. The theorem almost certainly holds. The theorem almost certainly holds without that restriction, but we, despite considerable brain racking, have not been able to prove that. I posed that as one of the open problems at last year's West Coast number theory meeting, but so far I haven't heard of anyone solving this. So here's something to work on. Okay. Pardon me. So then we started. So how do you analyze these things? Well, associated with these necklaces. With these necklaces, is what I call the AB difference graphs. So you draw a graph which we denote by G sub A B of N, pardon me for a second. The vertices are just the vertices, the number 0 through n minus 1, and then you throw in all permissible differences. So you draw an edge whenever the difference is an allowed value. So whenever the difference of two verticals... So, whenever the difference of two vertices is plus minus A or plus minus B. So, that's all the possible differences. So, that gives you a graph. Here's an example. For example, if the differences are 1 and 5, this is the graph on 18 vertices, 0 through 17. And you see here there's an edge whenever the difference is plus minus 5 or plus minus 1. Okay? And then you see here that your AB difference necklaces sit inside here, and you see actually something more. See, actually, something more. The AB difference necklaces are precisely the Hamiltonian cycles in these graphs. A Hamiltonian cycle is a cycle in the graph that includes all the vertices. Okay, so here would be one you can go here and then up here and back, something like that, right? So we're looking at Hamiltonian cycles in these graphs. Now, we also want to rule out obvious differences. Obviously, if you have like one of these circular arrangements, you can, I don't know, you can rule Circular arrangements, you can, I don't know, you can rotate it or you can flip it and so on, and you don't really get a different arrangement. It's all the same arrangements. So, these arrangements have symmetries, they're essentially the rigid motions of a regular n-gon, and we only want to count them up to these symmetries, and then you see that the A-B necklaces of length n are in one-to-one correspondence with the Hamiltonian cycles in these graphs. So, now we've turned it into a graph theory problem. Now, if we denote by n sub. Now, if we denote by n sub AB of n the number of these necklaces of length n up to symmetries, then determining this count, so this is what we wanted to figure out: the number of necklaces, AB necklaces, difference necklaces of length n, that amounts to counting Hamiltonian cycles in these graphs. And this is something that graph theorists do all the time. So Hamiltonian cycles in all sorts of different graphs, grid graphs and torus graphs and all sorts of other different graphs. This is something that graph theorists do. Different graphs. This is something that graph theorists do all the time, and they have techniques for that. So, that also gives us a way of actually trying to count these necklaces directly. So, we started looking at some very specific parameters, and we started with the easiest, and that is A equals 1 and B equals 2. So, the number of 1, 2 necklaces, it turns out it's just 1. So, this is a circular arrangement where all the differences are plus minus 1 and plus minus 2. And there's just really one way to do this. And there's just really one way to do this. And when you think about it a bit, you come to the conclusion very quickly that the only possible way to do this is you start at zero, you count up with the evens, and then you count back down with the odds. You can also count up with the odds and count back down with the evens, but that's the symmetry. So that doesn't count. So that's not so interesting. When you move up to 1, 3, you get something a little bit more interesting. This is related to the Fibonacci numbers. So remember, when you have 2, when you have two odd... Two three when you have two odd differences, one and three, there's no odd length necklaces, so that's zero here. But for the even length necklaces, you get it's related to the n minus n over two Fibonacci number. So it's Fibonacci number n over two minus one. And I'm going to do, I'm going to start doing something that I'm going to do throughout this talk, and that is proof by picture. So here's proof by picture. So you write down the corresponding graph for one, three, and you look at Three, and you look at the neighbors of zero, they have to be three or one, and then you look at how a Hamiltonian cycle would proceed on this. Well, there's sort of two possibilities: one can have neighbor two or neighbor four. If it has number two, then the cycle contains this path here. If it has neighbor, you know, neighbor three, then the Hamiltonian cycle goes over, sorry, it has two has neighbor five or three. So here it has neighbor five, here it has neighbor three, and then you see very clearly. Has neighbor three, and then you see very quickly if it has neighbor three, you expand the Hamiltonian cycle, and unless you get a really short cycle, something of length six or so, it has to go on like this. And then there's a nice technique that you can employ where you now look at these graphs and these arrangements and you shift everything down. And let's say you shift everything down by two. So you shift down this piece of path here. Now, of course, if you shift this down by two, Now, of course, if you shift this down by two, you're going to get some negative numbers, and now you're just going to ignore the negative numbers. And you just keep everything else and make a path out of that. And you can show that those paths shifted down are in one-to-one correspondence to the paths that look like this. So if you shift this down here by two, you're going to see you get an arbitrary path, but now of length n minus two, and similarly of length n minus four. And then you see here, this is the Fibonacci recurrence. That's where that comes from. Gonauti recurrence. That's where that comes from. And then you just look at the stoic value, and that's how you get this. So, this is the technique that allows us to do this. So, we went on to 2, 3. Here you get a beautiful little recurrence relation like this. This is degree 5 and some starting values. And again, it's the same idea here. You start with this path. You convince yourself that this is what the path has to look like. And then from 4, you grow it in two ways. It can grow from 4 to 6, or you can go from 4 to 7. Or you can go from four to seven. And from four to seven, you convince yourself that all the paths look like this, and you shift this one down by one, this one down by five, and you get this beautiful little recurrence relation. Okay, then it stops being pretty. So now the next thing we did is one, four, and you get this very ugly recurrence of degree 13. And the idea is again the same. I mean, you start with this, you divvy them up into these two things with a superscript two and three, then you divvy the twos up into something with superscript. Divide the twos up into something with superscript four and five, and the threes in superscript six and seven, and then you relate them to shorter circular arrangements, and you get this recurrence relation. But this shows you very quickly two things. One is this technique, I mean, it's a combinatorial explosion. You get so many cases, this is really as far as it goes. Like even if you go to something like one, five, there's just so many cases. Realistically, you can't really do it. So, cherry-picking small cases is all fine and dandy, but in general, this technique. All fine and dandy, but in general, this technique is just not really doable. The other thing is, this raises the question of whether this degree 13 is optimal, and the answer is it isn't. When you look at the characteristic polynomial for this recurrence, you'll see that it factors into a degree 4 and a degree 9 factor, and the optimal recurrence relation is degree 9. So you can actually do this with a degree 9 recurrence relation. Okay, but this of course raises another question, and that is, do these things always satisfy a recurrence relation? Satisfy a recurrence relation. And that's what we then set out to do. And then the summer was over, and Ethan went on to UBC to start his masters. And at some point, there was a summer and there was more time. And he started working on this. And he set out to prove this. And he did prove it. And so, I guess what I'm talking about from now on is really pretty much exclusively Ethan's work. And he proved that for any permissible values A and B, this sequence. A and B, this sequence, the number of AB difference necklaces, satisfies a linear homogeneous recurrence relation with constant integer coefficients. Note that this does not settle the existence question, right? Because of course, the only solution to this recurrence relation could be identically zero. What it does tell us is if these things exist, they grow exponentially. And the techniques that are employed here are actually not restricted to just two difference values. You could actually make it any. Difference values. You could actually make it any number of finite difference values. So you could make it ABCDE, etc., and then you get ABCDE graphs and they are more cluttered, but in principle, this still works. So what I want to do is I want to give you a proof sketch, and then for the rest of the time, I want to show you how we prove this, and it's going to be all by picture. So we've written this all up formally, and as so often in graph theory, it's like very verbose and lots of complicated constructions. But once you stare at the pictures, then it's not so hard. Then it's not so hard to follow what's going on. So, here's a proof sketch. We're using something called the transfer matrix method. This is a standard tool that graph theorists and combinatorics people use, and it goes like this. So, we take our graph here, G A B of N, and remember we want to count Hamiltonian cycles in that graph. And you do a big, huge construction, and you construct a directed graph from this called D sub A B. So, this is now independent of the length, but it's still dependent. The length, but it's still dependent on AB. And the construction of the graph, which I'll show you in a minute, goes as follows. So you have a unique start vertex S, which only has outgoing edges. And then you have a collection of end vertices with only incoming edges. And what you show is that the Hamiltonian cycles in this GAB graph, so these are exactly the difference necklaces that we're looking for, are in one-to-one correspondence with weight n walks in this digraph, starting at S and ending at some end. Starting at s and ending at some n vertex. Weight n here means the sum of all the edge weights. This is the hard part. This is where you have to do very, very hard work. Constructing this graph is very complicated. Once you have the graph, the rest is charge play via this transfer matrix method. And the argument goes like this. You look at the adjacency matrix of, well, you have to be a bit careful here. It's not quite this diagraph. You look at the adjacency matrix of an appropriate subdivision of. Appropriate subdivision of this digraph, which is actually an unweighted graph with lots and lots of more edges. The adjacency matrix, you remember, just puts a one whenever there's an, so it's indexed by pairs of vertices. It puts a one if there's an directed edge and it puts zero otherwise. And then there's a well-known theorem that says that if you take powers of this adjacency matrix, then the VW entry of such a power is just in the subdivision, it's the length n walks from V to W. Walks from V to W. In our graph, if you go back to the DAB, it's the weight n walks from V to W. Okay, now if you make V a start vertex and W any end vertex, and you add them all up, that gives you precisely the count of all walks from S to any end vertex. And that's exactly the count that we want. That's exactly our difference necklaces. Okay, so we just need to, we need this matrix. Now, it's a matrix, and every matrix. Now it's a matrix, and every matrix we learned in linear algebra satisfies a polynomial equation. That's called the minimal polynomial of the matrix. It's the polynomial of minimal degree, such that if you plug in the matrix, you get zero. So you get this matrix equation here. And now, if you again look at the S E's entry for every end vertex E and you add them all up and you plug them all into this recurrence relations, these coefficients are independent of anything, then you get precisely this recurrence relation. Then you get precisely this recurrence relation. So, once you have the graph, the rest is really not so hard. So, I want to give you an idea of how you would construct a graph like this. Okay, so what we want to do is we want to now do this construction. We want to construct this graph. So, here's how you do this. You first start with something called a block. We call them AB blocks. And what you do is you take your Hamiltonian cycles and you slice them up into two column graphs. So, again, so here. graphs. So again, so here are two GAB graphs. This is G23 of 14 and this is G23 of 17. And what we're going to do is we're going to take slices of two columns. So always the first and second column, the second and third column, the third and fourth column, and so on. These graphs look like this, right? This is really the first two columns here. This is the second two columns here. Also, the second two columns here, and also the next two columns. And then this is these guys here, and this guy's here. Guys here, and this guy is here, and this is the last one. And of course, you can look at graphs like this, and you can completely forget about this G23 graph, and you can just define graphs like this, which are basically things on two columns. Every vertex has degree at most two. And you can even divvy them up into start blocks, mid-blocks, and end blocks. So clearly, the start block here is the start, end block is the end, and the mid-blocks are in the middle. But you can define this abstractly, right? For a start block, because it's supposed to start with. For a start block, because it's supposed to start with a cycle, everything in the left column has degree 2. For an end block, because it's supposed to end on a cycle, everything in the right column has degree 2. All the other vertices have degree at most 2. And end blocks are allowed to have shorter last columns. So the columns are always full length, they're always length B, but the last one is shorter. And so it's clear that these Hamiltonian cycles give you blocks, but the reverse is also true. So of course, you can't just put blocks together. So, of course, you can't just put blocks together willy-nilly. They have to somehow fit together. And if you want to make a Hamiltonian cycle, you better fit them together in such a way that every vertex gets degree two. So we call two blocks compatible if you can take the, put them side by side, overlay the right column of the one with the left column with the other one, and then in the middle you get all vertices of degree two. So they're going to be a part of a cycle. So they all have to have degree two. So here are two blocks that are compatible. If you put them together, you get all. If you put them together, you get all the middle column, which is overlaid here, all has degree 2. These are not compatible because here you'd get degree 3 and here as well. These are also compatible. This is a different order from the previous slides, but these are not because here, for example, you would degree 1. Okay, so that's compatible blocks. And then if you you can build up, you certainly get from every Hamiltonian cycle a sequence of compatible blocks, but you can also go the reverse. But you can also go the reverse. So, if you take a sequence of compatible blocks, call them B1, B2, up to BQ, and then you construct the graph the way I just said, where you overlay these columns, right, and it starts with a start block and it ends with an end block, then what you get is you get a partition into disjoint cycles of this graph here, GABN. And what is n? n is qb plus s, where q is the number of blocks, b is the column length, and B is the column length, and S is the length of the last column, which is a bit shorter. Okay, so you don't just get blocks from Hamiltonian cycles, you also, if you put blocks together properly, you get a disjoint collection of cycles. Unfortunately, you don't necessarily get a Hamiltonian cycle. Now, what you know is if you start with something that's a Hamiltonian cycle, then these things in the middle all have to be mid-blocks. So, you start with a start block, you have a bunch of mid-blocks, and then you end. Block, you have a bunch of mid-blocks, and then you end with an end blocks. Unfortunately, that's not an if and only if. You might get disconnected graphs, so you might get something like this, where you have a union of disjoint cycles. So somehow we have to weed out whatever makes things disconnected. So when you put your dogs together, you have to somehow make sure that you're not closing cycles too quickly, too soon. You shouldn't be closing the cycle until the very end. So how do we detect? So, how do we detect small cycles? Well, the key observation is that the cycles are solely determined by the pathwise connected pairs of vertices in the rightmost column of a compatible block sequence. What do I mean by that? Here's a bunch of blocks. Let's say we put together B1 and B4, they're compatible, and we want to append B6. So, here's B1 and B4 put together. We want to append B6. So, you see here. B6. So you see here these two red vertices in the left side are path-connected, and these two blue vertices are path-connected, and they match up with what's path-connected here in this block B6. And when you put them together, you get two small cycles. Now, if we play the same game, but instead we put B2 and B4 together, so here's B2 and B4 put together, now here these two red vertices are path connected, and these two blue vertices are path-connected, and they don't match up with these guys. And that's why you don't get two small cycles. Why you don't get two small cycles, you get one big cycle. So, we somehow have to remember when we put blocks together what in the rightmost column is connected by a path. So, we attach that information to your graph. So, we want to identify paths that may lead to short cycles. We call those the offending paths. So, we associate when you put together a bunch of blocks, we associate with that graph just a list of the rows of the vertices in the rightmost column. Of the vertices in the rightmost columns that are path-connected. So, again, here is just one block, but it's a sequence of one blocks. And here, that list is 0, 3, and 1, 2. We number our rows 0, 1, 2, 3. So here, the two vertices in rows 0 and 3 are path connected. And this one is path-connected, 1 and 2. Here, it's just 0 and 3 because only these two vertices are connected by a path. Here, it's 2 and 3 because only these two vertices are connected by a path. So, you attach to your graphs. Bypass. So you attach to your graphs these lists of rows of what's connected in the rightmost side. And now we want to attach a new block and see if it all works and if it's compatible and if you don't get any small cycles and so on and so forth. And what we figured out, or I should say what Ethan figured out, is that this whole structure of this graph up to here can be somehow incorporated in this new block. So what we're going to do is we're going to define augmented blocks. Augmented blocks. So if you take a block and you take a list of unordered pairs of indices, these are just row numbers, 0 to b minus 1, then here's what you do. Let's say xk is the vertex in the leftmost column of this block at row k. Then whenever there's a pair ij in your list, you throw an edge into the left column. So again, rather than taking in all these words, look at a picture. Here's a block. Let's say we augment the block with this list. What does that mean? Block with this list. What does that mean? Well, we have to throw in an edge in the leftmost column from row 0 to row 1. That's this red edge. If we augment it with this list, we have to throw in an edge from 0 to 1 and from 2 to 3. If we augment it with this list, we have an edge from 0 to 3 and 1 to 2. So these are the augmented blocks. And it turns out that the augmented blocks, when you can combine the two concepts on the past two slides, the augmented blocks Augmented blocks combined with these lists attached to these graphs tell you all the information that you want. So the idea is that you put a bunch of blocks together, you grow a compatible sequence, that gives you a graph G of B, you attach to it the list of everything that's path connected in the rightmost column, and then you take the next block that you want to attach and augment it by that list, and that block remembers everything that's going on in the Remembers everything that's going on in the graph. So, again, let me show you a picture. Here's our sequence so far. We're trying to attach this block. So, what we do is we just attach this block and we make a new augmented block. And this path here becomes this red edge, and this path here becomes this blue edge. Okay, because that's what's path-connected here. Similarly, here, right? So, we have this block here, and we want to attach this block. Well, these two things are path-connected, these two things are path-connected. Are past connected, these two pins are pass-connected. In the new block, they become edges. Here are blocks that we shouldn't be putting together because they give us, well, this one gives us a cycle. Maybe it's a Hamiltonian cycle. So you see here, this red thing becomes this red edge. This blue thing becomes this blue edge. This is what happens when you put them together. And here's the last example. This is what happens to put them together. And now you stare at this and you realize that the entire structure of this graph is somehow encapsulated in this one augmented block. In this one augmented block. For example, there's no cycle here, no cycle here. Here, when you put these together, which vertices are path-connected? The first and last, and these two? And sure enough, same thing here, the first and last, and these two. Here, no cycle, no cycle. First and second row are path connected, third and fourth are path connected. Here, you get one cycle, sure enough, that's reflected as this one cycle here. Here, you get two cycles that's reflected as these. You get two cycles that's reflected as these two cycles here. So you can forget about everything. These previous graphs that you've grown, they could be like arbitrarily big, but you don't have infinite memory. But it turns out that if you augment this one block that you want to attach in each step, if you augment it properly, then you know everything that you need to know, all the information about the previous graph, past collection, cycles, past declosions of it's all carried forward. Of it's all carried forward. That's what this slide says. So, when you append a new block to this graph so far, this augmented block carries all the relevant information. It carries all the information on which paths are going to be connected, which vertices in the rightmost column are going to be path connected through the graph. It contains all the cycles information. So cycles in the new graph correspond to cycles in this augmented block. And it even contains Hamiltonicity information. Contains Hamiltonicity information because if the whole thing is a cycle, which is then a Hamiltonian cycle, then that one augmented block is a cycle. Well, not quite, you have to throw out any isolated vertices that you might get, but once you throw those out, that's also a cycle. So as long as you keep track of all your behavior with these augmented blocks, you know exactly how to put things together. And that gives us our graph construction. So remember the Hamiltonian cycles in our GA. Hamiltonian cycles in our GAB graph, that's our difference necklaces. They correspond to the weight n-walks in this digraph that we're constructing. And this is the digraph that we're constructing. So let's construct this digraph. I don't know where there's a parenthesis here. So there's four flavors of vertices in this graph. You start with the start vertex where everything starts. Then you have vertices that are attached to start blocks. And the start blocks are paired with lists L, where the L With list L, where the L is basically just tells you which of the vertices in the right column of the start block are connected by a path through the block. That's L of B. Then you have pairs of vertices B L, where B is a mid-block. And here, L can be anything. So you endow any mid-block with any possible pair of row indices, any possible combination. And then there's end blocks. They don't have to be endowed with anything. So that's your four flavors. So that's your four flavors of vertices. And now you put them together is exactly according to the recipe that we have. So there's three flavors of weighted edges. The first edge, set of edges, is they go from S to one of these start block vertices. And that's an edge of weight 2B because we're going to have two columns of length B. So here B is a start block and it's also acyclic. If B is cyclic, then your whole graph only consists of one cyclic. Whole graph only consists of one cyclic dock, and that's your Hamiltonian cycle. So that's the short cases. We're not interested in that. We're only looking at the big long graphs. Short cases can be handled with initial values in recurrence relations. So that's the first set of edges. Then you connect edges B L and B hug, L hug, where the right one is a mid block, the left one could be a start block or a mid block. And now you have to put them together in such a way that they're fit. So first of all, of course, the blocks have to be compatible. To be compatible, secondly, that whole path connection business has to match up, has to match up, so you're not like closing cycles too early and so on and so forth. And again, the augmented block, remember the augmented block contains all the information of where the paths go, are you closing a cycle and so on and so forth. If your augmented block is not cyclic, then you're not closing your cycle, you're good. So you're checking if this is acyclic, and if it's acyclic and all this happens, you attach it, you're good. In your butt. And then finally, you need edges into end blocks. So here B is a start or mid block, and then the second guy is an end block. Oh, and for these guys, you always do weight B because you're always attaching one column of B vertices. Here, you're attaching a column of S vertices, where S might be less than B, it might be a shorter column at the right. Again, the blocks have to be compatible. And here, you want to close your cycle because you're at the end. So, again, you need to make it so that the You need to make it so that the augmented right block thrown out all the isolated vertices gives you a cycle. So that's basically the construction. So, again, rather than taking this all in in words, let me give you a bit of a picture. Let's say we're still in the 1,4 digraph, and these are the eight blocks that we're working with. So these are eight blocks. B1 and B2 are start blocks. B3, B4, B5 are mid blocks. B6, B7, B8 are end blocks. The eta n blocks. And let's work with these three augmentation lists here. And then, if you construct the subgraph of our D14 graph just using these blocks and these lists, this is what it looks like. So you have your start vertex here, you have two weight edge vertices to these start blocks, then you have a bunch of stuff with mid-blocks going on here, and here are end blocks. And this guy here, the last column has length one, so this is a weight one edge. Here, the last column has length four, so these are weight. The last column has length four, so these are weight four edges. So, this is what it looks like. And then there may be a whole bunch of combinations where you combine a block here with an L here, but nothing is connected to it. So, there may be a whole bunch of isolated vertices floating around that I just didn't write down. So, once you have a graph, then these walks that you put together in this big, huge digraph correspond to these Hamiltonian cycles put together in these blocks. And then the counts match. And then the counts match up. So the number of these walks is equal to the number of Hamiltonian cycles, which is exactly our count of different sequences. And that's how you get this result. So this is, I'm just repeating the theorem again. And that's how we get this around. Okay, so that's the graph construction. So with that, I will stop and leave you with a last picture of Richard. This was on his 90th birthday. Richard would always celebrate his birthdays with friends at a cabin near Mount Assiniboi. Cabin near Mount Assiniboine. And so, here this is Richard on Mount Assiniboine. And I can take some questions. Yes, thanks, Renata. I don't know if we're doing a flapping. I guess most people are muted. But so are there any questions for Renata? And remember to unmute yourself if you're asking. Oh, I guess there's also chat windows. Is anything in chat? Windows. Is anything in chat? I didn't even check. No, nobody said anything in chat. Okay. Okay, so if there are no questions, let's thank Renata again. And so the next talk starts in a minute.