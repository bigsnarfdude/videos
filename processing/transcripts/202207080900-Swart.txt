Okay, that's cool. I and Es left or right. But contrary to what we had before, the end idea is to rescale all spatial distances with epsilon squared, all horizontal distances with epsilon. And now we are also going to put frames in with probability epsilon. So with probability epsilon, we have both arrows. That means, of course, that. And that means, of course, that now at a single point, they can a single point they can start reading many parts, and the question is how you get an image of that. So, what is your model? You can have two of those at the same time? Yeah, so this is the idea. So, this is the idea. So, it was branching. So, we will now talk about scaling of branching coalesces. And so, what's your discrete model, the drawing distribution? The discrete model is taking odd integer letters. And with probability epsilon, you put both arrows. And with probability a half, one minus epsilon, you put an arrow to the left, and with probability one half, one minus epsilon, you put an arrow to the right. You put an error to the right and set independence for each point in the odd. Now, you can, of course, observe that if you take a typical point here, then there's at least always a leftmost part. So you can decide when you walk up to say, okay, Anagra, I have a choice, I just choose always left. And similarly, you can, of course, always decide to go right. So So uh next slide you so you will be the set of all upput files and go left and right many choices that is a subset of the set of all output buttons all paths in the grazing term now I must actually be careful so that's Now, let's actually be careful. So, let's take a sequence of epsilons tending to zero, and then we have a sequence of arrow configurations. Let's call it omega n and then omega. Un are simply all paths in the error configuration, omega n. But in particular, the subset of that are the left parts. I have a left parts, and you are, and these are your right parts. And the first thing you can check is that if you now rescale usually, losing these episodes ends, which are the same as these lensing things. Then you take all the left parts, you take the closure. Look at the law, and that converges to n tends to infinity to the law of a left Brownian backward. Basically, that means that now instead of coalescing Brownian motions, center Brownian motions, you have coalescing Brownian motions with lift one to the left. That's uh for the rest, this is exactly what we have already seen. So the probe is completely the same. Completely the same, and in the same way, of course, if I make this right, then it's a right web. And so, the first step to finding out the scaling in all parts is to find out how this left and right rep are coupled. So, I mean, they are you know the individual distributions, but you want to know the joint distribution. And one thing you know, of course, is that left parts cannot, I mean, left parts. I mean, left paths, if you have limit, you know that you all have a left path in motion, and then if you have a right path, then yeah, they may hit each other, but then from that moment on, as soon as they hit, the right path must stay on the right, because that's true in the discrete case and also to play. Okay, so now let's see and then write down. So then one way to describe. So yeah, we got to know the interaction and we decide by writing down the interaction between one left path and one left right path. They are given by a stochastic differential equation. So dL T indicator function. So we have two of them two parts now with an R. Two parts now with an RT and an L T and they have a joint S D E. So, this is the probability that L T is not an R T and I have a driving Brownian motion that I will call a left Brownian motion, but it's a standard Browning motion, it's not drifted. Then I have indicator functions that are actually the same, and I use another driving. And I use another driving Brownian motion. That's called VS from the same. And finally, I need to add a drift, so I go minus Vt for the left drift. And then for the right one, I have a similar equation. So now I have the third Brownian motion. So I have three Brownian motions, three left, right? Same. And they have standard Brownian motions. And they have standard boundary motions, all independent of each other. And the fact that these two are independent, in particular, says that if, as long as these two processes are in different positions, they evolve independently, which from the street picture you know they should. And the next step is then to say, well, when they're on the same position, they actually do exactly the same. Sort of. So you just write down indicator function at the same position, dv same. And you have to right-click it. And now, what you can indeed prove is that if you take a left and a right path and you rescale a single one and you rescale them, that the joint law converges in law to the solution of this equation. You can prove that this, first of all, that this stochastic difference equation has a unique in law weak solution. And I'm pretty sure that path-wise uniqueness doesn't hold. Path-wise uniqueness doesn't hold. And actually, to prove weak new uniqueness, Albert Romfeng and I did in the paper about the Bonian F, we rewrote this thing. Yeah, we did a random time change and then we wrote the form of equation with reflection, which I have all here, but for time reasons I will skip it. And that is also very useful if you don't have to show the proof to prove the problem. To prove the conversions, because in this sort of time change version, actually, you can get the path relation. But this is only weaker. But on the other hand, this is the simpler equation. This is extremely intuitive. And you can prove, as I said, this music true. Okay, so let me stick at that. So that's a single one, single left and a single right. And So, some properties of that. Oh, wait, I should say this has a unique solution only if you add the condition that L is less or equal than Rt for all t bigger than tau, which is the infamum of all times big or equal. We had also said Lt is RT. So after they meet. So after they meet, from the moment they meet, on the right, one must stay on the left. If you don't have this equation, this also doesn't have a unique solution. So in practice, will there be a time when they stick? Will there be a non-trivial interval that they'll step? Yeah, I will say something about that. So we can have, it's always interesting to look at the time interval, the set of all times. Both times voltage L T R T and let me define a measure mu i t mu i a the integral of the indicator function of i put a t measure. I put a tiplot technique on the real line, but I restricted to these sets. And now my claim is that, first of all, that I is the same as the support of this measure mu I. First plane and the second, my second plane, that I is nowhere hence. Okay. So the first one says So the first one says that you know if they, as soon as they meet, they actually spend the back time together. But you can't have this hand that they meet in maybe that they reflect on each other for a number of points and that these points have zero or that measure. Because then this measure would be zero, this set would be zero, but I say yeah actually. So I mean one inclusion is clear, but the interesting thing is that every point in here is in this of order. As soon as there is a if you have a point where they end together, If you have a point where they are together, then much around that, yeah, a measure status to the back positive the back measure when they're together. So they actually really stick to each other. And the second thing is it's nowhere damage. That means that, yeah, if you so it's a closed set, but it does not contain an interval of any positive length. So, what these left and right parts are doing, so let me use colors. It's the left one. Let's start for that one over here. Let's start the right one over here. So, they meet for the first time. And now, from this moment on, they stay ordered like that. And now it's sort of they really move together in a sense. And in the long time, of course, you know that the drifts will kick in. So if you look at this long enough, long enough, Lower Vlad's number tells you that they will at one point separate and never see each other. But that tells you that point X is transpositively back down together. And there are long stretches if you do the simulation where it seems like they are moving just as one single Brownian motion. But on the other hand, nowhere then this property tells you that can't be true. So in fact, He tells you that can be true. So, in fact, what is happening is that there are sort of excursions, like there are these moments where the blue one separates and then they meet again. And that happens actually on a dense, it's sort of dense. Both of these discursions are very, very small. So there's here a sort of a dense collection of small open intervals, maybe so there's fractal-like, canto-like. They're all over the place, but they're very, very small, so that the total length is still much less. Is still much less than the total length of the purpose. You still have also black measure, but there are small holes or holes. It's really hard to counter. Okay. Now if you describe the joint motion of one left and one right one, you can actually describe the joint law of these two left. And let me just look at it in words. Sugar in words. What you, of course, want is a different disjoint part of space-time. They must be independent. And that means that if I'm having, say, I'm following a collection of left and right paths that may be ordered like this. This way. Then, as soon as the left and the left one meet, they coalesce. So, and as soon as a right one And as soon as a right one meets a left one from the left, they don't change their order, right? And after that, and these events, they are irreversible. Coalescence or change of order are irreversible. So if I start with finitely many parts, these events will happen only finitely many often. I can cut out up my time interval into these events where a coalescence or a change of order happens. And then between these times, but I see between these times that this left one doesn't hit this one. That this left one doesn't hit this one, this one doesn't hit one, but this one, this pair here, I have to look at the left and right, they can hit many, many times in this sort of sticky way. So, what I can do is I can make sort of couples of left and right next to each other, and all the other ones are single tons, and for the one, these will all not meet each other. So it's enough, actually, and it will be independent because this joint particle stays primarily independent. So, this one is independent of this, it's independent of this pair, and so on. So, it's really enough to have. It's really enough to have the interaction between one left and one right, and then for the rest, it's just you know you cut up the pieces and look like so. So from this one, you can get really the joint distribution that we call the left-right. So that's the first step. But what he of course really wants. Step, but what we of course really want is not only the left or parts and the right parts, we want all parts. And that's the next thing. So now again, you remember that in this conversion school for the Brownian web, I had this W minus and W plus. W minus and W plus, and they were sort of natural lower and upper bounds. And we could do something similar here. The first thing that I'll define: so I fix, I fix, as before, I fix D tool, countable, and then I have so I have a collection I can construct. Yeah, then I have the website, I have all left and right parts starting. I have all left and right paths starting from there. So I now define n minus to be the set of all. Well, first, I take the set of all paths that can be obtained from my left path. So these are the left paths starting in this country will then set 10 big right paths. I could take the same set, I could take a different one. So I got from these parts, I construct these parts by hopping. Okay, and then I take a closer. So let me tell you what I mean by hopping. I have a left path on my left brownio web, then I have a right path on the right or left of it that at some point they meet, they cross and this one goes off. And then I have another left path here that does this, and we have another one here that does this, this one, and so on. And so on. If I have such a configuration, then I believe that if I start off on the blue one up to the first point that these two meet, and then start following the red one up to the first point that these two meet, then follow the blue one to the first point these two meet, and then follow the red one again. That should be a path in my boundary net as well. So I do, I take all the ones that can be obtained by finding. The ones that can be obtained by finitely many hopping at first meeting times between a left and a right path, and I saw them in here and then I take a closure. And the second thing I'm going to do that will be even more familiar to what you've seen is that we send to you all paths by website. I does not enter. This is well now of the form W he had, look at each of these, they have left and right brown, they each have dual, but I also have a left dual web and a right dual web. Because we have each one before the bed. Because as we saw before, the bad and blue and duality almost duly determine each other. So now I'm going to look at benches that look like this with countable n sets. Now I don't need to take a closure to go. So what does that look like? So now I'm going to look again at the ranges, but now they're To look again at the ledges, but now that you know we have this form, so I have a left path and I have a right path on the dual one. So it's going down. So it's good to realize that the left paths forward have a drift like this, and the dual paths they have a drift like that. And if you would look at it from a long time, the law of large numbers that kicks in, then you see that four. Kicks in, and you see that the forward right paths tend to go to the right, and the dual ones like this. So, this is a dual left path. This is a dual right path, which tends to go here like this, but maybe not, maybe it hits this one and then goes on. So, here they stick to each other, they have these small excursions, but they meet they stick, you have positively back time together. So together these two paths define which, same way as before, which is the open set. It lies between them up to the first meeting point. And I say that the path enters the bed if it is first outside the closure of the ledge and then the meeting enters the ledge. And I say that is not allowed. And also you can't sneak in through the bottom, right? That's important. Right, that's important. And if I look at all these parts, that's my second section. And that is already close, so I don't take it close. And then, just as before, there's a statement that says that these two are the same. And this code is similar to what we had before. So let me flow it here. Now I have here a general of pi in this bigger one. And I need to show that it is in the smaller one. That means I need to show that I can approximate this coping part. And before I take the finite number of times and take some positive epsilon. Epsilon, and I say that if I for each finite number of times and each positive epsilon, I can find a hopping path that at least is at least at most epsilon for this path, then I can take the limit useful brightness and show that I can really approximate it. So it's enough to find a hopping path that stays in here. And the construction is very similar. We can now start right paths here. And because of the batch property, they have this. Property, they have to stay on this side, and they can actually hit that path, they can do that. This could happen. Now, I can start something here, or it actually here, so it coalesces maybe here, I can start another one here, another one here, and also blue paths can do the same, coalesce with each other, another one. There's another one. They may actually now below this, they may actually spend some time together because this beds, you know, you're already in the bed, so don't enter it. Okay, so we have all of that. And now we must construct a hopping path. So what we can do now is we start here, somewhere near the starting point of this thing, whatever, somewhere, yeah, somewhere here. We start with a right path. So the right path can't cross the right paths. Right paths. But it could cross this blue path. There's nothing against it. So just before it does, I hop onto a blue path. And just before that one seconds to go out of my interval, I hop onto a right path. So the only thing that could go wrong is if I have these sort of situations where these things become denser and denser, right? If that doesn't happen, then I can reach the top. Happen, then I can reach the top and I have my approximation. So, how do I show that this sort of accumulation points do not happen? I'm already terribly sleepy, but maybe some people are still active enough to know the answer. Maybe you have an equicontinuity from artism or something? Absolutely, brilliant. By equicontinuity, we have shown equicontinuity and improved. Improved the compactness of the Grand Universe. And this would violate the connectivity because these parts, so actually I said this one can hit this one, but the other one can't hit at the same time because that will create the waves. So these blue and red ones, they must stay away from each other. So there's a minimal distance. This would go infinitely many up and back and forth between this positive distance, you would violate if you continue. Violate if you continue. So you reach the end and you have to obviously see. Okay. Right. So let's go to the back to where we started. When we started the first lecture, we had this expanding interval process and the dual one, which would be the branching coalescence. And at that time, I could only, for special initial stage, describe the expanding interval process, which was sort of the continuous unit of a biased proton model. And the dual process, I couldn't tell you very much about. But now I'm able to construct both processes in terms of the. Both processes in terms of the Ramian F. So we fix S measured with one T, I can define a map S T that goes from the compact subset of extendedly aligned itself, and I define it as this. This is S T these are all the points E such that I is an element of N times S. These are the paths in the Brownian. So it is a general notation, you have a set of paths that. Then these are all paths that start here. So these are paths that start intercept A at time s in the Blaumian net, and I ask where they end up. So this is sort of as a function. If I fix S and I move up time, that is a sort of continuous processing coalescence. And indeed, you can let me prove some things, state some things about it. This is actually similar. We had it before we had this coalescing Brownian motion, and we have sort of... So, in particular, I can now define xs, let me define xt A zero node, and this is a vector map of clauses. Which is the branching correlation points? And if you do the simulations, it really looks a bit like Rensselaer and Corley-Singlonian motions, although it's more complicated. So one thing you can prove about this is in particular, I can look at the expectation of x0. X say zero, P, I start with everything occupied and I take the intersection with the finite time interval and I ask how many points are in there. Formally, you can show that explicitly is B minus A E to the minus C minus C minus A. Just to find of square root t over square root of two pi and figure out for minus infinity to x. So x and distribution function of a standard model, and uh, yeah, this is how do you prove this? Well, the basic thing is again similar to what we saw before, if I have my A B here, and I want to know if there exists somewhere in the OV aligner a path in my net that reaches in here. That reaches in here, then it's enough to look at this right path here, starting from here, and the left path starting from here. If they meet before, then they form a wedge, and you will be sure that there can be no paths reaching from here into there. On the other hand, if they do not reach, then you know that any well, no, you don't know. Well, no, you don't know, but then you can do the same construction I showed you before. You can do a hopping construction and show that there is a path. So this slight repeat of the same argument. And you can show that it's an if and only if there is a path if and only at these two documents. So now to calculate this probability that there's a path in here, you have to calculate the probability of two drifted larger motions independent. So basically that one drifted down, the motion doesn't get zero if you start. And then you divide this thing up. And then you divide the thing up into small pieces, you do it for each, uh, take expectation and believe it, and it can be solved. It's uh I think it's uh it's a change of measure plus reflection principle tricks. You can get the exact tools, and in particular, so let's let's look at the formula. So, first of all, it's infinite, so it is still it's still true, like for the Poisson Brown emotion if you come down from infinity. Um, so even if you still have a So, even if you start with everything occupied, then at least positive time you will see only find T many locally. And let's look at the rest. So, this, as t tends to infinity, this goes to zero. This goes to infinity. So, this is a distribution function. So, this goes to one. So, you go to two times this. And, in fact, you can check that this Markov process. That this is a Markov process as an invariant law, which is a Poisson, the load of Poisson points set with intensity two. Which actually you should expect because we knew it's some discrete models where you have a product measure as invariant, or you can actually do the calculation and see that this is exactly the law, the Poisson converse, which you should get out of this law. Actually, based on that, if you believe that. Then, if you believe that this bug, this schematically constrained model goes to a net, then just by looking at the density, you can guess what the right drift should be. Because if I can do this more generally, but the drift of the left and the right are not one. But so if the drifts of the left and the right are more than one, so you say, actually, this intensity is the difference between these two drifts. And the difference between these two drifts sort of tells you how much branching there is. This sort of tells you how much branching there is that you sort of translate into, and by scaling you can see. So, from that, you should be able to guess what is the right constant is. Okay, so let's look a bit more at this picture. So, you can also say start this micro process in a single point. That's what it looks like. We've already seen a fear now, there are a left and a right path that stick together. So, what you will see is that here now, most of the time, for a long time, you see just sort of. The time you for a long time you see just sort of a single particle doing, however, really many of these sort of small excursions, until at some point you get an infinite excursion. And then inside, of course, you know, you start to see this again and you start to see more and more complicated structures. So this is sort of what looks like simulations in the lecture mode. You can see simulations. And so as I said, there are all over the place, they are very small. That are very small bubbles, and on top of them, and that's another thing, at the deterministic time, I see only finitely many bubbles. But this is not true for all times. And that is quite easy to see, because I know that this, I have these sort of excursions all over the place. But of course, on top of these excursions, there's other excursions. So they are very small, but I'm going to draw one much bigger so that you'll see it. And then during this. It and then during this excursion, of course, there's another excursion. During that excursion, there's another. I mean, by now, they should be microscopically small, but they are there. And if you take them, you go on in the limit, you see that there are these points. There are actually a dense set of points where you can find arbitrarily many parts, but you can find points that are infinitely many particles. I mean, we have proved that, you know, even if you do it on a whole real line that are random times, you'll not find that. Times, but you'll not find any isolated points. So it really is. So, but basically, what is basically says, you know, you think of this as branching and coalescing boundary motions. So, coalescing gas has only coalesce, but the branching rate is in, I mean, the number of particles explodes immediately. But then, at a later time, you'll have one. So, this is why it's a slightly tricky process. But if you think of it as failed. But if you think of it as fair as sort of counter-like structure then okay I think I find a managing to go really fast. Okay so then that was then the name of the benefit called Lessons and I can also go away. Now I know so I have here I have S less I have here, I have S less or equal than T enough. Now I'm going to go down. So I fix again a set A, but now my definition orders the opposite order. And I define this to be a set of all the points intended to be aligned for which there exists a path starting at x. X such that T nice and just at H. And then again, so let me place this. If I fix, now I fix, now I can fix time t and S1, so I can define our approaches. So y t I start with some. I start with some line from closed set X and then I find line from T to wait. Do I have it here? U minus T this is again a market. This is again a mark of process, I'm telling you already. I'll prove it later. Taking values in the closed subsets of the extended real line. So what is it like? So here I have my set U and now I'm going to go down in time. I go to some time u minus T and here I have my set A, so it's an interval here. It's an interval here, and another piece of interval here, and I want to know what it is. So, it is the set of all points that are path in the net start that ends up in these things. First of all, for the interval, we've already seen how to do that. So I have to start with the right one here, this left one here, and let's say they don't meet. And here I can do the same. And here I can do the same. Maybe there is actually neat. No, when it's wrong, because you always have to, I mean, if you put, this is dual, right? It's going down. And the way to go upside down is to revocate it over one another. It's not somewhere. So that means that they are not going to cross. And this one is going to stay on this side, makes it coalesce for this one. So it's going to be like this and this picture. Going to be like this and this picture, and here is my final one that does maybe this. So now I can, I know as before, can find out there's points that end up here. So in fact, yes, there are parts that end up here, there are paths that end up here. So actually, the set evolve as this. First, they evolve as two intervals, and the interval. Intervals and the interval, the boundaries of these intervals are drifted around in motion to drift away from each other. The drift one, so it has drift one, minus one here, plus one here, minus one here, first one here. Now, as soon as they meet, they actually become one and it goes on like this. And the other thing, if there would be a wax, so then it would get smaller and smaller, and as soon as you have one point, it's gone. Actually, it's left continuous. This has left continuous and opaque if you look at it. This has left in the central path if you look at it. So, this is exactly the expanding interval process. Let's quickly go back to these things. So, we actually have a bit more. We have not only constructed these map of classes for about This markup process for one fixed initial state and for one initial time, but you can actually start them at any time that you want in any configuration that we want. So we have these maps. These maps have a nice property that they're additive. So S T A union B it takes S T A union S D E and the same for Y as you see there. So actually, yeah, if you You see there, so actually, yeah, you just take the one interval, you take the other interval, and then you take union, you have the process other than union. So, this is this sort of additivity, it's a reflected additivity of the mark, the original discrete time infecting particle systems. And so, the line has the same property, so it's additive. Another property that so yeah, but it's also quite easy to see, is that I have times t1. If I have times t1 less than tn then it's the goal from t1 to t2 and then the map that gets me from t2 to g3 and so on up to minus 1 to tn. These are independent. That is because the Brownian web and the left-right Brownian web and the net they have the property that disjoint charge of space-time are independent. Of space-time are in the band. And to construct this map, I only need to know what happens between these times. And so these maps are defined in terms of flips of space-time that are disjoint, so they must be independent. And the final thing is a distinct actually form stochastic flow. So you have the flow property. So you have that XT is the identity map. Map and if I compose, I first go from time S to time T, then I compose it with a map that takes me from T to U. That is the same as going from S to U directly. Now I must be a bit careful. This is true almost surely for all For all s less or equal and t less or equal and u. So I finished deterministic times s, t and u, and now this is true almost surely. And the proof of that is actually quite a bit of work. And I haven't even given you all the ingredients. I have shown you the special points of the Brownian bag. But now to know this, you would need to know something similar for the net. But you would need to know, and but this is But you would need to know, and whether this is true, is that if I fix a deterministic time t, and I have a path in the Brownian net that comes to a certain point, and I also have a path in the Brownian net that goes out of that point, then the quote determination is also on. And actually, already for the Brownian web, we have seen that this is not true at random times, because you have these funny special points that look like this, like you had. That looked like this, like you had one incoming to outgoing, and the dual picture is because one of the two cases where the dual one hits, the dual one doesn't. So, and likewise, you can show that for the net random times, this property doesn't hold. And I think that means that this can't hold for help. But if you have this property, that anything that comes in, but we have also seen, you know, that this doesn't happen at this deterministic times, you will not see these points because. will not see these points because the fourth and two will not get the same points wasn't using the local finances so also here you can prove this that these things do not happen at times and that means that these are deterministic times and that means that you have a stochastic flow with independent increments and from that it follows in fact that these things are markoff closes that's a general thing so on so i've done So I for now let me look at the probability. So let me look at the property. So I say that let me process define Xt to be S S plus T of A. Here I claim this is a Markov process with. I claim this is a Markov colours with transition probabilities B A and a higher probability, I think S plus T of A I6. And now if you look at the time-dimensional distribution of these things here, look at the probability at that time C1, I'm in some set A1. That's A1 for Tn9. That is now the probability because of the flow property. That first I go from X T 0 from S my. I integrate this over the set A1 and one by definition four. So first, the first map was taken from the initial point, G1, and then I would. And then I must end up somewhere in strategic products, and then I integrate next. And because of the independence, this vectorizes, so you get the usual proper. You can rewrite this because of every use the flow property and use the independent increments, vectorizes out, and you get the usual formula, the integral to go from the so it's first g one minus s. G1 minus S A B one over A and you can get an A transition. So you get a Markov process. And also when you, it's a general thing. If you have a stochastic load in the extended increments, you always get the Markov process. So these two are Markov processes. And the final thing you want to know, so we have already seen that why is these are expanding integral processes. integral process and we defined in the beginning we defined the dual the uh the branching cluster and the branch cluster points that via duality so i'm not proving that this duality really holds so that it's really the same closest at the beginning of the claim via the train that exists so That is the property zero empty, it's the same probability. So why is it true? I look at the event that I go from time here to G. I apply that to my initial condition. I assume that these initial conditions are deterministic. And I intersect it with zero and I want to know if it's non-empty. Now we look at definitions. Definitions. So this is the set of, so let's draw a picture. Then I have here my set here, here I have line g, here I have my set x0. And now it is, I look at all plants in the plan in net and I ask if there is a whether there is at least one. But there is at least one path that reaches into this biasing of states, this interval. And the other one says, well, these are all points that can be reached by paths. All points in the real line where the path starts, that ends up here. That's my definition. So actually, if I go back, so say so. So this probably. So, so this probability that this is non-empty is the same as a probable as the event that exists a path phi in the net, such that phi zero lies in zero and phi t lies in phi zero. But that now I can start here at the top. I can define a proposal. I can define a process why t Process. Y t would be, and take this map that goes from time t. Yes, so now I should say at time s, I think t minus s of y zero. This is now my rural process. I let it run backwards. And I can ask, does that process, if I get it over here, intersect with this set? Then if I look at this definition, that is exactly the same. You think that you can find a You think that you can find a path and a net that connects these two things. So then, these two are almost still equal. I can take probabilities on both sides and get this. So, these two things are Markov processes and they are dual in this sense. And in fact, in the Brownian paper, it's proved that this forward process, this Branson processing point set, it is even a fellow process. Closes so, um, sort of from a microclosure point of view, it's the nicest thing you can get. So, and in the state space, uh, okay, if I restrict it to the non-empty ones, we can see that this, I mean, we have this set. So, this is compact, so that this with the host of metric is a compact space, and the branch-coalescent point set, taking values in here, is then a fellow process with this. Is then a fellow process with this compact state space. So it has continuous sample parts as well. So it's sort of a diffusion-like thing. And in particular, it has a feather property, which means that it's fully generated. There is some generator that you need to characterize. But I can also mention an old problem characterize. generator of uh this because very often i mean for diffusion processes how you construct them standard you you find the generator for browning motion it's a half times second derivative and then you take the closure you say show that it's close closable operator and if it's close you generate a better semi-group now here you know that you have Now, here you know that you have a semi-group. You know there is some generator, which is a closed operator, which you need to determine the whole semi-group. But what is it? I mean, these things are not everywhere defined, they're densely defined. Usually, there's a sort of nice class of functions where you can write the W difficulty. But this process is pretty rough. So, I mean, you can write down a few nice functions where you can see what the generators should do, but they're not enough. So, find a nice class of functions. So, find a nice class of functions that is enough so that you can check the closure or think that it's all. I'm not saying that it doesn't, you've tried the D V a lot. I would, if you want to try it, I would state this duality as a starting point. Because you know, the duality uniquely characterizes the thing. This expanding interval process is sort of easier to describe. So, if you can get enough function so that you can move the duality from the generator, you know, Focus during the generator, we don't have enough approach. Okay. Another open problem that I find interesting is so sort of this process, as I said, you can look at its excursion. You know that here it's for a long time it stays at one point, then it makes excursions away from this, like. From this, like so you have sort of smaller and bigger ones, and they're all over the place. The same way as you would have reflected Browning motion, and it's well known for the reflected brown motion, you have an excursion measure. So, what is the excursion measure for the excursion of the branching person pointed away from the signal balls? And there's actually a conjecture that you can find in this overview article of Emel Sergeant and Sun and Me, where we sort of claim that, you know, these sorts of excursions should be all over the place. See all over the place, and we believe that this type of excursion is still dense, but then as they get more complicated, so if you, for example, want to find something like this, we think these are only finite. And everything is sort of more complicated than this. And so I'm not saying exactly how I define this. But I mean, on top of this, there are, of course, many levels, but that doesn't really change the properties. So we think that all bubble, so that we call these the bubbles and the double hypothesis is that these are the only bubbles. If that is true, that means that you have a very, very good control of the thing. I mean, you say it's a difficult thing, it's called a tractor, but it is a verbal hypothesis hold, and it says that basically it is finite, except that there are these two simple things all over the place. That is something we do not know. That is something we do not know. We have something else that is maybe the last thing about the grounding net that I said, how much time do I have? Five minutes in principle, if it was an hour, we can go up to 11:30. Among 10 people running already. So there are people that will be running for the next breakout. I think that's the certainty. So I say one simple thing about OpenEd and then I go to this constraint thing, and I'll probably take 5. So we don't have a global hypothesis. There's not a thing that we know that also tells you that, in a sense, this process is not as bad. This process is not as bad as you think it is. You can sort of find something definite in it. And that is the following thing. I can take a picture of time S and the time u, and now I can ask how often I can find this sort of thing. I'm looking for a point which has this property. There starts a path in the Brahmian net at time s, it hits this point, and now at this point, if I from this point. If I from this point I follow on the left in the right path, they separate immediately and they keep separating all the way up time u. Maybe after that they coalesce, but up to this time this and these points are separation points, called separation points, and they're sort of the equivalent of the branching points of normal branching coalescent. This is and as I said, they are branching points are lower for the place, but Branching points are lower for the place, but most of the branching points are very insignificant because it will coalesce very soon after. But these are sort of the significant ones. So we call this an SU elephant separation point. And the interesting thing is, you can look at these and you can explicitly calculate their density. It's a sort of point of. So it's a sort of point, and it turns out they have a finite density. The density actually, if you write down the density, they have density with respect to the back measure. This density tends to infinity as you approach S and U, but in an integrable way. So the upshot of it is still that if you look at the finite pieces here, you will see only finitely many of these relevant ones. Which is already extremely helpful because it tells you, you know, if you only interested in very Only interested in where you end up after a final thing. There's only finitely many decisions you really have to take, and all the other ones are irrelevant. Okay, so now last 15 minutes, go back to kinetically constrained.  These are the nearest neighbor order of nearest neighbour pairs on the set of the first time over and you can apply above and kicking. That was the generator of my power. And now I'm trying to approximate this one by a branching coalescence and trying to argue to the plus and e to infinity and scale of property, then say I start with a single one, that this should converge to this branching collection point. To this franchise and coalescing point sets. Strong more generally, I'll probably start more general for concreteness. So, to do that, I can look at the half integers and I will find nearest major edges for that. These are all pairs i j and a half is that such that the half minus j. And I've got the time-branching covalent. That's this. So it will be a process that takes values in 0, 1. And the way it works, so I call it the covering branch in coalescent and generator is So I take random walks on the standard steps of size half only. Coalescing random walks. And these are for I Z. So if I'm in the integer left, then the base, a half b in each direction, I jump either half to the left or to the right. Either half to the left or to the right. If I'm on the odd integer letters, so that's that, then I rate one minus half one minus b, which are all i and j f h i in the z plus half, which are an odd integer. And again, I have this f and walk i j. Okay, I need a third term. And I'll write it here. I have another one. This is called different. So I now have sum over b times sum over i in set of half. I can branch only when I'm at a half integer point. And then there is some map that I explain. This is a generator. Let me now draw a picture. It's going to be an additive process, so I have a graphical representation in terms of arrows. So let me draw the half integers. So these are the integers. And half integers. And so one. That's right. One, one and a half, two, and so on. And so, what are the maps? First, I have random log maps. So, if I'm here, I can start and with a half p, I jump to a half integer, I go on for a while, then actually, with a very much higher rate than p is small, I jump back maybe. But now with the small rate, when I'm here, so actually, I should draw this correcting these errors, so they are coalescing and block errors, which means that it's a blocking symbol. Yeah. And now there's a small chance that I do splitting, and that works like this, that I have two errors at the same time with a blocking here. That means that if I start this process, there's a single line here, and now it jumps here, it's jumped here, it comes here. It's the old here. It comes here and it jumps back. So it's coalescing random walk for a moment. Now it splits. Now we have two of them. And this happens with rate p. So this is splitting and maybe I don't need to write the form of definition into the picture. And then of course these things can coalesce, they can go. And my idea is that this should in first as you can certainly see that this sort of random walk is a good approximation for this one. Because how do I interpret this? Because, how do I interpret this? I had before I had this thing that lives only here, and now it's a certain probability, a branch, so I have another one here, so I have both of them. So I have two particles, and I represent these two by the one in the middle. And then this one, this one kills this one, so I'm back here. That's my interpretation. Or if this one kills the other one, then this one will jump from this out temperature to the inverted state. So in fact, as long as there are only two particles, Are only two particles this uh random walk and the uh branching chemical process, they are fully coupled, they're completely the same. So now, so when you are in the middle, you are interpreting like the situation in which you have two particles, yeah, one particular particle. Yeah, sort of I look at the when it has I start with a single particle and I look at it, and as long as there are at most two particles, then these particles are always when they are there, they are neighboring positions, and when there are two of the neighboring positions. And when there are two on the near position, I call that one particle in the middle, and then I just have this random wall. And now, what this button can, of course, do if there are two particles, it can create a third one, and I represent this sort of. Now I'm making an error. And this is a bit of the question, how you're going to do it, right? Because now maybe this one skills, the middle one, and they end up like this. The middle one and they end up like this. Well, this one ends up like this. So now I have a discrepancy, so these are not exactly on the same portion. And at first, that looks bad. And maybe it is still bad. But a bit similar. First, I should identify sort of the effective branching code. So this the first thing I'm claiming is that I can actually scale this branching code as. This ransom coalescence should be no problem to show that it converges to the branschees coalescing coalescence. I mean, this home reference, the whole graphical representation is edited, so I can in fact show that all paths I can have all space time points and prove that it converges to the Brownian. So, I did the calculations here in these extra notes. You can find it. Of course, this thing has a property that it jumps to its rate P here, here, so it spends a P. Here, here, so it spends a p fraction of its time here, and a one-minus p-fraction here. So, most of the time it is actually at the integers, um, and you have to take care of that, but otherwise it's nearest neighbor, so that's a great thing. It's nearest neighbor, so paths can't cross, you can do several badges, and everything works. And it's not additive anymore, or is still additive? It is added. This one, this one is additive. Editive nearest neighbor, the nicest thing you can get. That's why I say the whole record or the presentation should go to the browser. Or the presentation to go to the Brownian net, and the process itself to go to the Branson processing. And that's basically standard. And then we should find out, so that here you can actually find out the drift also quite easily. For this Z process, you can find out, I should still say how it converges in the notes. So the thing is that if I scale space and time with map like this, each time point is map, I scale time with space with a vector p and time with the half east to the third. And this will be the right scaling. And then as Scaling, and then you can check that this covering principle actually goes to the standard rather and you look at the rightmost path, you subtract the drift and have a marking value, you look at its quadratic variation. It is twice wrong, I think, but okay, so I. Okay, so now let's try to find out the bad school. And as I said, one way to do it, and I should actually double-check, is to look at the invariant law and say that one should go to a Poisson point process with the light intensity. So this one should have invariant law that in the limit goes to a Poisson point process with precisely intensity two, and I suspect this one has intensity a half. So I have another way of looking at this which to give the same answer. And that is by looking at some. And that is by looking at sort of the effective branch. So if I look at this covering branch in coalescence, then at some point I will rate P branches into two particles at a distance one from each other, both of the integers, and then they start as martingales. And as soon as they're on the same position, they coalesce. They coalesce, and from that, you can find out that the probability that they split and they reach on this L. So, the effective, how often do you see that? That is, this effective splitting rate is P, that's the rate at which you see splitting. Well, where the rate Whether it's the it's only when the venue is here, but you set the V fraction of your time here, so you should probably still do like this. And then you have a so but the main thing is that if you once you have this distance one, you have a probability one over L to reach this distance L and And now, if you look at this path, so sometimes you have these three particles in the middle one gets killed. But then, as soon as you're at distance one, you already coalesce immediately. So, there you can check that as soon as this happens, you have a probability of one over L, approximately L minus, one over L minus one to reach this distance L. But you're interested in the ones that are effective over long distance. So it means that this sort of branching should be. means that this sort of branching should be in effect comparable to these even though it seems that they go at a bigger distance so it looks like it creates a bigger drift but they should be sort of comparable but then you check that this happens with rate p this also but i mean the the three particles i mean this uh it's rate p but you have only a p fraction here so you have p square there and here you have the same p square but then that's only the rate at which the frequency at which you expect to see three but then you have Which you expect to see three, but then you have a 50% chance that the middle one gets killed. So this one should effectively have half the branching rate of the other. And so one possible approach to prove this whole convergence, and yeah, this is a bit of a vague idea to explain based on what I mean. The idea is basically that you should first construct this. First, construct this good one, and you know that it's this branching correction point set, which you know is somewhat fractal, it has terribly many of these little things, but on the other hand, you know, it's not too bad, you can control that. And then the idea is that you want to couple that one, so let's make this one red, to the other one. And you know, it's very small times, you can keep them close together. When there is a branching, we think that the effective branching rate of this one. Think that the effective branching rate of this one should be half. So, with 50% of the chance you do this, but with 50% of the chance, only one of the outcoming is really there. So, you want to make some sort of coupling where the covering is more than the other one. And actually, there's freedom in it. I mean, I could try to define this one even bigger, say twice as big, with twice as many particles, if that is somehow convenient. As I said, so far it looked like it almost worked. Looked at like it already wants to work. The question is, how close you can be? So, after this blending, you start to have small problems, but you can still have the hole. Another thing is actually for this blensing, for this bug, the difficult thing to prove is that if this is all empty, that the thing has a drift in this direction. So it's difficult to prove a lower bound on the drift. But the upper bounds are easier. So that you can try to use to keep it, and then you can try to use the structural properties. To use the structural properties of this big thing to say that you know no bad things can happen in a big space, but that's a rough idea, but I believe it has a chance. So I think if you told any one structure, that's a covering brand because you really know those to be using the DTBs. But then what's the how and then you want to couple it to the other one? And the next, there are also theorems. other one and election there are also theorems that are proof that what you can do if you have a brownian net you can induce to indeed do this you can throw each for each uh uh separation point you can indeed you can condition on the whole net for each separation point you throw an IAD coin with 50% of the chance you you keep it with 50% of the chance with 25% of the chance you change it into a right and with 50% into a left there are theorems that tell you yes you Theorems that tell you yes, you this construction gives you a new collection of points, and this is exactly a prime unit, it's half the drift of the previous one. So, the idea is to show that somehow you can embed this realm in the other one so that not all branching points are effective, and that's basically an idea, and then you would have both two conversions of that one as well. Only easy times. Times actually, so a long thing. Uh, soon and I were working on this up to five years ago, and we want to resume it at some point. We had actually, uh, I must say, our strategy from that time was the definition of covering branching quality was considerably more difficult. Um, and that then we had a really a definition that's fully covered, that you could show that really there's nothing going wrong, but then the convergence to the net is modeled. So, I still don't know whether I'm not. So I still don't know whether I'm now standing to think that maybe actually better to take a simple definition for that one that is not fully perfect and try to so that's the open point can also say that I have there are post-work positions that are open postdoc positions at institutes so you can apply so anyone who feels immediately know someone who wants to do this