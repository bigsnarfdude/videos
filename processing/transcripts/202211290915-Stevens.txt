Okay, so thank you very much. And thank you also very much to the technical team here as well, who've sorted out better ways for me to write and so on. So today, so I'm carrying on from yesterday. I'm going to try and talk about three things. So still no local language correspondence today. But so first of all, the Bernstein decomposition and what Sign decomposition and what a type is. Then I'm going to talk about cuspital types, and then finally about covers, which are sort of non-cuspital types. So here's the Bernstein sign decomposition. Okay, so first of all, this is going to be with the complex numbers. So we have a group like we had yesterday. So the group of points are some. The group of points of some algebraic group, connected reductive algebraic group defined over F. And we're going to take so this B of G, this is going to be the set of equivalence classes of pairs M rho. So M here is a Levy subgroup. Rho's some irreducible supercuspital representation. Remember, we're in the complex case here, so supercuspital and cuspital are the same. Okay, so not a sub or not a subquotient of something proper parable. Of something properly parabolically induced. Okay, so the equivalence classes, so what's the equivalence relation? Well, we say that two pairs are equivalent if there is some unramified character. So remember, that means a character trivial on all the compact subgroups, such that if I twist one of my pairs by that unramified character, then I get something which is conjugate to the other pair. So, some conjugation. So, this equivalence relation is called inertial equivalence. And so, these would be called a set of inertial equivalence classes. And this set is called sometimes called the Bernstein spectrum. Okay, so last time we saw, well, actually, slightly stronger than this, but with a but Well, actually, slightly stronger than this, but this theorem of Harachandra, which says that if you have some irreducible representation, then there is some Levy subgroup and some superguspital representation of that Levy such that pi appears as a subquotient, even as a sub, if we want. And so we had the sub, this pair m rho is uniquely determined up to conjugacy. That was the plus middle or. Cuspidal, or in this case, super cuspidal support. So, if we look instead at the inertial equivalence class of the pair, so we kind of add these unramified characters so that we deserve a bigger class. This is called the inertial superclassical support. Oops, no, that's not what I wanted to do. Okay, so here's the theorem then. So, the theorem of Bernstein. So, the theorem of Bernstein is that there is a block decomposition of the category of complex representations of G. Okay, so in the following way. So, first of all, what does block decomposition mean? It means that, first of all, this is a decomposition. So, every object can be written as a sum of objects which are in these categories. And also, there are no morphisms between these different categories on this side. These different categories on this side. And block decomposition means that this is the finest such decomposition. So each of these pieces is indecomposable. So that's what block means. Okay, so what are these pieces? Okay, so they're indexed by this Bernstein spectrum, and it's just the full subcategory of representations. Remember, these might be infinite length, but we can still look at their. Be infinite length, but we can still look at their all of whose irreducible subquotients that should have said. We can still look at all their irreducible subquotients, and so we can look at what the supercussible support of those is, and particularly the inertial supercussible support, and we want them to have inertial supercuspital support. S. And so we actually saw an example at the end of last time. Okay, so if you take in GLN, we take, so this T, remember, is the diagonal torus. Is the diagonal torus. And we take the trivial representation. So that's a levee and a supercuspital of that levee. And you look at the category that you get. Well, it turns out that that's exactly the category which I just talked about yesterday, which is so this is the category of representations which are generated by their Iwahori invariant vectors. Okay. And also, And also, as I said yesterday, this is the same as modules over some Hecker algebra. So, which is some affine Hecker algebra of type A tilde. So, just a little remark. So, this was for complex numbers. If you go beyond complex numbers, so to an arbitrary C, your characteristic L, not zero and not P, then it is definitely more. P, then it is definitely more complicated. Okay, so for GLN, it works. Okay, so this is due to Vinyohas. It's by, again, inertial supercuspital support, which is now different from cuspital support. Okay. But because in GLN, that is unique up to conjugacy. So that's due to VNOS. Inner forms of GLN also, it works. So this is due to Vassant, Seychev, and me. But as far as I know, that's. Uh, as far as I know, that's the only cases that we that this is known, and indeed, as I said, uh, since uh super supercuspital support, or indeed inertial supercuspital support, is not well defined up to conjugacy, um, you know, it's going to be more complicated in general. Whatever block decomposition we get, it won't be indexed in the same way. Okay, so right, so here we have this Bernstein. We have this Bernstein decomposition. And so, what we saw with this torus in the and the trivial of the torus and the Hori was that we found, let me go back, so we found some algebra here so that this block was equivalent to modules over this other category of modules over this algebra. And that's obviously very nice, especially if you can then describe the algebra in terms of relation, I mean, generators and relations, and hopefully actually understand what that. Understand actually understand what that category is. And so that's kind of a goal in general, then would be to for each for each class to try to find some algebra such that the representations are described as the modules of that algebra. Okay, so there is some general nonsense that you can use. Okay, so if you have some pro generator for this category, so I guess that means it generates the category, so all irreducible. generates the category so all irreducibles should be should be quotients uh sorry every everything should be a quotient of a of a of a sum of some of these things and it should be uh projective and probably not too big as well um well if you have such a thing then you can just take the endomorphism algebra of that progenerator and that will work okay this is this is abstract sort of categorical nonsense okay uh because the difficulty then is how Because the difficulty then is first of all, how do you get a progenerator? And then how do you describe its endomorphism algebra? Okay, so getting the progenerator is maybe not so hard. And even in some cases, describing this algebra. So one method, which this is the only thing I'm going to say about the words that are on this slide, which comes certainly from an idea of Bernstein, and then was done by Hyman for classical groups, so symplectic groups and orthogonal groups, and then recently. Orthogonal groups, and then recently by Solovelt in much more generality, is the following. So suppose you have some inertial class, then if you take your supercuspital representation of M and you restrict it to this group M0, which is the subgroup generated by all compact subgroups. So this is the subgroup on which all unramified characters. Subgroup on which all unramified characters must be trivial. Then, if you restrict it and you take some irreducible sub-representation, then it turns out if you then compactly induce that back up to M and then parabolically induce that up to G, then that works. Okay, so that's very nice. Again, it says, I'm sorry, there are other ways as well. You don't necessarily have to do it quite like this, but anyway, and Quite like this. But anyway, and but what's more is that you can then get a description of this of this algebra using intertwining operators and things like this. And yeah, so that's one way that you can do it. And like I said, I'm not going to say anything more about that. Because essentially what type theory does is it looks for a different way to do this using representations of compact open subgroups. Okay, so here's what type of Okay, so here's what type theory is trying to do. Okay, so we're trying to find a pair J and Lambda where J is compact and open as well, I should have said. J is going to be a compact open subgroup of a group. Lambda is going to be some irreducible representation of J. Irreducible representations of compact groups are finite-dimensional. I probably should have said that at some point. With the following property that I can detect. I can detect the irreducible representations in sharing screen stop. Oh, Zoom has... Oh, I think I've left the meeting. Okay. Okay. I'm not quite sure what happened there. Hang on, I think I might know the proper Zoom has Zoom has left me. Here in network. Okay, you need to change the family. Okay. Should we work in the field? Maybe I close it and try to open it again. Okay. Right. Sorry about that. I lost connection. Okay. So I don't know when I lost connection. The only problem is that you can actually see what's actually there and people who are not here can't. So okay, anyway, hopefully some of these Jay Lambda. Okay, fine. All right. J lambda. Okay, fine. All right, I'll say J lambda again. Okay, so so uh so J lambda here, so so look for a pair J lambda, where J is going to be some compact and open subgroup of G, and lambda is going to be some irreducible, so finite dimensional representation of J with the following property that we can detect when an irreducible Detect when an irreducible representation is in the block for S just by looking to see whether or not we can find whether there are any Lambda invariants in our representation. So if there are any non-zero homs from Lambda to the restriction of pi of our representation to J. So exactly, this is so and such a such a pair is called an S-type. So S was the S. So S was the S indexing the block. Okay. And if that happens, then it turns out that we get a nice progenerator, which is just the induced representation, the compactly induced representation of the type. And so then what's my algebra then? So it's the endomorphisms of this, which is usually called Hd lambda. So this is, that's interesting. The A from algebra is. From Algebra has moved up. Oh, yeah. Right, okay, so it's called Lambda spherical hacker algebra. Okay, so why bother having another method? Well, I suppose historically, of course, I think that the ideas of Bernstein probably came first, the idea to do it, but then actually doing it was done, the first examples were. Was done the first examples were done with types, uh, and then late, then Heyman's work, and then Solerfeld's work came came later. So, kind of there is, so historically, that there were both methods anyway. But the type can also give some precise information about somehow about the irreducible representations. And I'll try and illustrate what I mean by that later. And another important thing is that you can. Another important thing is that you can use the same sorts of methods for representations over not the complex numbers. So, with Bernstein's methods, you're kind of using the fact you've got the complex numbers because you're going to use analytic continuity and things like this. So, it's really complex methods. Whereas here, we're using really algebraic methods, so restricting to compact subgroups. So, yes, so a thing to note is that when you do go to represent. Is that when you do go to representations over some C, this induced representation might not be a progenerator anymore? Okay, so it might not be projective, for example, and it might not be a generator. But you can build a progenerator if you want. And you do still get a bijection between the simple objects, at least. So you don't see the whole category, but you do see some of it. You still see all the simple. So how does it have to generate? How is it not a generator? How is it not a generator? Okay. Okay, so I think this depends on the definition of generator. So you let me see. So you won't, no, but so you won't, I mean, so for a generator, you have to, do you not need to see everything as a quotient of a sum of these things? A sum of these things, not just a subquotient, I think. I think so. I think to be a generator, you need to do that. Okay. So let's start off talking about cospital types. And here now C is back to not necessarily being the complex numbers, even though I've not defined really what a type is. Not defined what a really what a type is when it's not the complex numbers, but uh but somehow essentially cuspital types come down to uh really just constructing cuspital representations. That's actually what it comes down to. So here's a here's an important fact about cuspital representations. So suppose we have some compact mod center subgroup now, okay, so J tilde, and some irreducible representation of that. Okay, so then a fundamental theorem, which I And then fundamental theorem, which I think, well, certainly I first seen it, sort in Carioli for the complex case, at least, is that if the compact-induced representation turns out to be irreducible, then in fact it's cuspidal. And so the reason for that is something which I didn't talk about yesterday, is that there's another characterization of cuspital representations. Okay, so cuspital representations were characterized yesterday as not as As yesterday, as not as having trivial Jackian modules or not being sub-representations of parabolically induced things. But it turns out that that's equivalent to being what's called Z-compact. Okay, and that's again, this is not an easy result. But it is true. So what does Z-compact mean? It means that all the matrix coefficients have compact mod center support. So that is, if I take any vector, Any vector in V, and I take any vector in the smooth dual. Okay, so this is the dual space, which has a dual action, but that might not be a smooth representation. So you take the smooth vectors in it. Then the map which sends G to, so this V dual evaluated at pi g of V, okay, this has compact mod center support. Okay, and essentially what you can do is you can see that. Do is you can see that you can kind of construct explicitly, in this case, when this is irreducible, you can construct explicitly a matrix coefficient which does have compact mod center support. And then because of irreducibility, then actually that's true for all, basically. But basically, that's the idea. It turns out in this situation that the compact induction also coincides with the full induction as well. So. So that's that's somehow this is this is the main main thing about how how we construct uh cuspital representations and i guess it's it's expected probably uh that all all cuspitals are constructed like like this can be can be constructed like that rather i should say by an irid as an irreducible um induction from a from a compact mod center subgroup um and for many groups this is known And for many groups, this is known. I will say more about that later. Okay, so I should also relate this to Tit. So this is just recalling what's the previous slide. Okay, so suppose we want to detect whether or not we're getting something irreducible. Okay, well, so we could look at the end of the endomorphism algebra, and then we can use the Machi decomposition to write it as some. To write it as a sum over double cosets of some hom spaces here. In particular, one of these hom spaces comes from the trivial coset. Okay, so that's giving me these endomorphisms. So we've definitely got a one-dimensional endomorphism space. Okay, but if this is going to be irreducible, it has to be exactly one-dimensional, okay, by Schulz-Lemmer. This is an endomorphism space. And so a necessary condition is that all the other spaces. That all the other spaces here are zero. Okay, and a way to say that is though this thing here called the intertwining of the representation. Okay, so the definition is it's the G such that this put what it's supposed to be is non-zero and such that this space is non-zero, that this should be just the group that we're actually inducing from. So in other words, we're just getting this one here. And so I One here. And so, I guess the message is that controlling intertwining is kind of a crucial thing in constructing super cuspidal representations. Okay, so and then how does this relate to types? Okay, so again, this is just recalling what was on the previous slides. So, we have the following theorem due to Pushman Kutsko. To push on Kutsko. So, suppose we're in the situation where we do have some irreducible cuspidal representation like this. So, well, then the group, this is compact mod center, it has a unique maximal compact subgroup. Okay, so which is, if you like, there was this thing that I called, well, M0 or G0 in this case, the group generated by all the compact subgroups. So I just intersect with G0. So I'll just intersect with G0. Okay, that's the maximal compact subgroup. Okay, if I restrict to this maximal compact subgroup and I take some irreducible subrep, then it turns out that actually that gives me a type for this pair. So a G pi type. And I've called it a cuspidal type because pi is a cuspidal of G, G is the group that we're on. So it's the trivial levy, basically. And so again, what does this mean? It means. mean uh it means because there's no parabolic induction happening now so what are the what are the irreducibles that are in this same in this same same block they're just the twists by unramified characters so it's saying that this this space is non-zero if and only if for so for pi prime pi prime some irreducible some irreducible representation of g that that this hom space is non-zero if and only if it's an unramified twist of pi. Okay, so that's the relation between constructing things and finding types. I mean, actually, in lots of cases, so if the center is compact, then compact mod center and compact are the same thing anyway. So there's nothing to do. Okay. Okay, so let me do some examples. Okay, so here's this is a sort of example because there's a cheaty bit in the middle. But so the examples are both going to be in GLN, but I'll say something about what happens in general as well. So here, the first one is the so-called depth zero cospitals. Okay, so what we do here is we take for our group J, we just take the maximal compact subgroup that we saw yesterday. Okay, it's normal. Today. Okay, its normalizer is just it times the center. So we just add, so Z here is just the center. And we also saw yesterday that, so just by reducing mod mod p, we have glm over the finite, over the residue field as a quotient, and the kernel is this pro p radical. Okay, and so what do we do? Well, so for G Ln over a finite GLN, over a finite field, there's also the theory of theory of representations, what are cuspital representations, and so on. It's an algebraic group. And so you can start off with an irreducible cuspidal representation of that quotient. Okay, so these are parameterized, for example, by green, but more generally for other groups by Lustig, essentially, Lustig thing. Okay, so I take some irreducible cuspidal representation of this, I inflate it to J because this is. It to j because this is a quotient of j, and so that's going to be my lambda. Okay, now I want a representation on j tilde, okay, but I just need to extend to the setter. So I just take any extension I like, okay, and then here we have an irreducible cuspidal representation just by compactly inducing this, okay. And somehow this thing about the intertwining being small is exactly controlled by the cuspal. Is exactly controlled by the cuspidality of what's happening in the finite group. So the same idea works for arbitrary G, actually. The same general idea. Okay, so this is my prassert and Boris. Okay, so what do you do? What is one way to describe it? You take a maximal parahoric subgroup. Horrick subgroup, okay, and its normalizer, which will be compact mod center. You take the inflation again. So this maximal parahoric subgroup has a reductive quotient, which is connected because I'm because of what I had the way I defined parahorics. And so you can take an irreducible cuspidal representation of that, you can inflate it to To J0, you can extend it to the center. And then this normalizer might be a bit bigger. So then you can induce up and basically decompose that. And so if I take some lambda tilde, some irreducible quotient of it, then that will induce up to give me a dead serial cuscle. So that's basically how it works. Okay, so that's a depth zero example. Okay, so let's do a positive depth example. So this is an explicit example. So this is in GL4. So we start off with some data. So the first thing is going to be some element which you should think of as being in the Lie algebra of GL4, okay, and for thinking about things more generally. So, but it's just some four by four. So, but it's just some 4x4 matrix. Okay. And it's going to be this one in particular. And so it's something which squares to. So remember, this is a uniformizer of f. So it squares to the uniformizer to the minus three. And so if I look at the algebra that it generates, well, this is a field. It's a ramified quadratic extension of F. Of f with, and here's a uniformizer for it. Okay, so yeah, okay, so I can think of E either abstractly or I can think of E really as being contained in the four by four matrices. Okay, um, then what I can do is I can look at the centralizer of my element B. Of my element beta. I mean, I've written the centralizer of E, but I can think of it the centralizer of beta. So if you're thinking of the Lie algebra, we've got the adjoint action of G on the Lie algebra. So the things which centralize it. And what is that? Well, it turns out that that's just isomorphic to GL2V. Okay, so essentially this comes from, you know, you think of your four-dimensional F vector space that we're. Vector space that GL4 is acting on as a two-dimensional E vector space. So that's how we get this. So this centralizer is isomorphic to GL2D. Okay, so then we're going to take as a compact subgroup. This is the K, so this is a parahoric. This is a parahoric subgroup. It's going to be, well, this one. So these are two by two blocks. And And the important thing here is that if I intersect it with the centralizer and I look to see what I get when I take this identification, I just get a maximal compact hit. So this is a maximal parahoric on this side. And it's important that this is maximal. Okay, so these parahorics had some filtrations, which were indexed by real numbers. So here is one of the filtrations. Here is one of the filtration subgroups, which yesterday was called K1. And so this is just the things which are one, well, as you can say, they're one plus something in here. So I've just increased all the powers of p by one from the original. And then we can use this element beta to define a character of k1. Okay, and how do we? Okay, and how do we do that? Well, it's kind of the same thing that we saw without with multiplicative characters of the multiplicative group. It's the same sort of idea. So we want to define it. So if I have some 1 plus x in K1, so X lives in here. Then what I do is I just multiply it to beta. I take its trace, just the matrix trace, and then I evaluate that on. I evaluate that on this was the additive character of f, which we had yesterday. So this in particular, so psi was trivial on p and was not trivial on O. Okay, and so like this, I get a character of the group K1. And And it's quite nice. So, amongst other things, it's actually a character which is intertwined by all of G prime. Okay, all of this centralized. Okay, so let's keep going. So this is just at the top. This is just a recollection of what's on the previous slide. So we have our G E G beta, our E, our G prime, which is the centralizer, our compact. Is the centralizer, our compact subgroup, and then the character. Okay, so I'm going to do something which might seem a little odd because I'm going to extend things in two steps when, in principle, I could do it in one, but this is because maybe tomorrow I'll want the two steps separately. And that's, and it's also because I have chosen a special case where, for those people who know the construction, one step of the construction doesn't appear in this example. The so-called Heisenberg step is not there because I've chosen things. So, first of all, we're going to extend. First of all, we're going to extend theta to a character of this slightly bigger group. Okay, so what is this bit? This bit is the sort of one plus M2PE somehow, when I've identified G prime with this. That's what that bit is. Which is, yeah. Which is, yeah, so that's that's that's that bit. And so I'm going to extend it to a character of this with an important property, which is that if I just look at this character on this restriction, it should factor through the determinant. Okay, so factoring through the determinant seems like a weird, weird thing. What is it really about? Well, there are two ways to think about it. One is to say that it's intertwined by the whole of... That it's intertwined by the whole of GL2V. But another way is just to say it's the restriction of some character of GL2E, which is the same thing. So you can think of it either way, really. So, okay, so that's this extension to this thing theta. And this thing theta, maybe I will just say in advance, say this is an example of a thing called a simple character. Example of a thing called a simple character that Bushnel and Kutsko defined. Not sure that simple was the right word. Okay, so then what do we do? Okay, so then we extend it to a slightly bigger group, okay, where I now take the whole here of G L two O E. Okay. Okay, so Okay, so extend, I've written extend carefully. Actually, in this case, you don't, I mean, actually, in most cases, you don't really have to extend that. It turns out you don't have to extend that carefully. In this case, you have to be careful when Q equals 2. You have to be careful because there are some extensions which are not the ones you want. So that's because GL2F2 has a one-dimensional cuspidal representation. Dimensional cuspidal representation. That's fine. Okay. So there are not many groups which have one-dimensional cuspids. So that's happy. So we extend it further to a representation of kappa. In this case, it's actually easy to do it, just explicit. Okay, and so somehow this kappa, so maybe I can also use a word, though I'm not sure whether I'll use this again. So this is a thing. again so this is a a thing that the in the in the in the bushnell kurzko language would be called a beta extension okay and then so that's that's somehow one part of going to be one part of my type okay and then there's another part of my type which comes like the depth zero one did okay so how does that come well it turns out that j if i quotient j by by this j zero plus i just get gl2 over the I just get GL2 over the residue field of E of this extension. So now I can do the same, exactly the same game. I can take an irreducible cuspidal representation of GL2KE, I can inflate it to J. That gives me another representation, rho, and then I can tensor them together. And this is going to be my cuspidal type. And if you then want to actually construct the cuspidal, it turns out that this extends to the group E cross J. Group E cross J. So remember, E was just thing generated by F beta, so it really makes sense in GL4F, it was embedded. And then this is irreducible. So that's how the construction, this construction works. And somehow all the constructions are, end up being, one can kind of describe them in a similar way, that you have, so you have these sort of these two bits, you have a Sort of these two bits, you have a bit which has come from some sort of, I don't know, arithmetic data or something, and then you have a bit which has come like depth zero once it comes, so some from some cuspidal of a finite, of a finite productive group. Okay, in fact, however, I've written it down. Okay, so here's the sort of the general idea, which I'm not going to say more about today, certainly. So, is that you take some twisted levee, some Some twisted Levy subgroup. Okay, so that means that if I extend scalars, it will become a Levy subgroup, but it's not not not over the field with the property that the quotient of the centers is compact. Then, as I said, you have some arithmetic data which gives a kappa, which I'm not going to say anything about. And then the lambda is going to be of the form kappa tensor rho, where rho is going to come as an irreducible. Rho is going to come as an irreducible representation of some finite reductive group. So, what's that finite reductive group? Well, that's going to be the reductive quotient of a maximal power Horrick in G prime. Okay, that's where it's going to come from. Okay, so and then, so here's a sort of theorem. So, there's an exhaustive list of cuspidal types. So, in the sense that every, if you have any irreducible cospital representation, Any irreducible cuspidal representation, then you will get it from this list of cuspital types in the following cases. So GLNF, okay, so this was in this kind of it. So when P doesn't divide N, this is older. But to allow all cases, including when P divides N, this is Bushnokutsko. So I've written some things in green and some in blue. The green ones are the complex case, and the blue ones are the case of 3 C. So for GLNF, Bushkal-Kutsko or Vinyohas, for SLNF, I Bushkal-Kutsko or PC, for inner forms of GLNF, for classical groups. So what do I mean by classical groups? I mean, I mean symplectic special orthogonal unitary groups. Okay, so basically things that you get by taking the group of fixed points of some involution and then the connection component when p is not two. And so in this actually now also at least yeah this also now includes quaternionic classical groups as well. So when you have some some Classical groups as well. So, when you have some Quaternion algebra. So, that was done relatively recently by Daniel Skolerak. So that's it. And then finally, well, so the, I mean, let's see, there is a, there's a big overlap between these two, but also, so when G is, maybe the most general is when G is split over some tame extension and P doesn't divide the order of the Weyl group of G. Okay, so there's some tameness condition happening here. Painless condition happening here. So these are due to constructions originally due to U, corrected by, recently corrected by Iska Finson. And then there was a, so the exhaustion result was due to Kim Fen with lots of extra other conditions on P, and then more recently by Yeska Finson in this, in this general hard. And so what's more, so I say there's an exhaustive list. Okay, it's nice to have an exhaustive list, but what you'd also like to know is that tells you you get. To know is that tells you you get everything, but maybe you get some things more than once. So you'd like to know when you get the same thing. And in fact, in all these cases, if you get the same, if you're getting the same cuspidal representation, then the types are conjugate. Okay, so things up to conjugacy. I should also mention, then, so there's a recently, a couple of years ago, there's a theorem of Kuieni Arnami-Construinas. Any other memory consumption, which basically says that actually, in all these cases, you don't need you didn't. So, from this, from this data, and then by doing a bit of extra work, essentially seeing how automorphisms, how this is, these vary under automorphisms of the coefficient field. You can see that actually you didn't need your C to be algebraically closed. Okay, you didn't need to be. And also, so there is, I mean, I think. There is, I mean, I've been talking about cuspital here all the time, but amongst the cuspidals, when there are also the super cuspitals, even the complex case, it's the same thing. So the same thing is true for representations of finite reductive groups, cuspitals and supercuspitals. And so what you might hope is that the time you get supercuspitals is when your representation here of your finite reductive group was actually supercuspital. Reductive group was actually supercaspidal, and it turns out that yes, that is that is what happens as well. So, they also prove prove that. Okay, so okay, so that's that's uh everything that I was going to say about cospital types, and now I'm going to talk about covers. And I'm going to specialize to the complex numbers again, and it's not not. Complex numbers again, and it's not necessary for everything I say, but I want to sort of talk about equivalence of categories still. So, because I want to do that, then I'm going to switch to the complex number. So, here's the idea of covers. So, if we've got some supercuspital pair, so that means M is some Levy subgroup and rho is some supercuspital irreducible representation of M. So that gives us, as we've seen, some inertial equivalence class in the Bernstein. In the Bernstein spectrum for G. But also, we could just think of M as a Levy subgroup of itself, okay? And it's and obviously, Rho is a cut, then and then this is a, and then that gives us a cuspidal inertial equivalence class in the Bernstein spectrum of M. And somehow, and if you if you induce from the the representations which the representations which which you find in the category for M up to D, well, essentially by definition, you land up in this category here. So we have this side of the picture. Now, suppose we also have some type for the Levy subgroup, which we've seen we do most cases. Well, in that Most cases. Well, in that case, we have this bit here. We have this equivalence of categories. Okay, and essentially, what we'd like to do is we'd like to be able to complete this picture into a nice square. So we'd like to be able to find some j lambda here so that, first of all, it's going to be a type for here, it's going to be a type for the inertial class S at the top, so that we'll get this equivalence of categories. And then also, Of categories. And then also, we would like to be able to describe what's the arrow that's going to go here that's going to then make this diagram commute. And the reason for doing that is that then, well, maybe on this side, understanding this arrow is going to turn out to be easier than understanding that one. So the question is: how do we find such a J and lambda? Okay, so here's a definition. Um, so, uh, and this is the definition of a thing called a cover. So we say that some pair is a cover of J m lambda m. I mean, here J M lambda m doesn't actually need to be a type. It's just a compact open subgroup of m and an irreducible representation of it. If, okay, so first of all, we have an Iwahori decomposition of the group J, which um uh and the in particular if i intersect my group j with the levy i just get the i just get the the the the group in the group in the levy okay so that's that's the first thing so this is this it will hurt decomposition so this is with respect to any parabolic with with levy subgroup m and its opposite um the second thing is that we would like our lambda just to first of all to restrict exactly to to to our representation on the levy and then Representation on the levy, and then to be trivial elsewhere. So, in this decomposition, so in other words, these two groups should be in the kernel of the representation. And something which satisfies these two things is sometimes called a decomposed pair. Okay, and actually, so finding finding things which satisfy these two properties is easy. Okay, the the the The problem is then going to be this third condition, which is a which, okay, I've written it down, or at least I've written down. So there are various different ways of stating the third condition. It's some technical condition, but it's kind of the crucial one in the end. So this is one way to state it. It's the way that Bushnel and Kutzko did it originally. So it says the following. Says that we have some. So we look in the Hecker algebra of in the in the hecker algebra of of of of lambda so this is the endomorphism of the induced the compact induced and i can find some element which so um that the hecker algebra again so so by by a junction and mackey i can think of this as functions uh from g onto the space of of lambda which transform on the left and right by lambda okay and so i can talk about and then i can talk about the support About, and then it can talk about the support of such a function, and so um we want the support to be just so it will always be supported on j double cosets because of the equivariance on the left and right. But I want it to be supported on just a single double coset. And what's more, it wants to be on a very particular, particularly nice double coset. So, first of all, I want it to be supported on. It to be supported on some central element of the levy, and I want this central element to be what's called strongly positive. Okay, so what does that mean? Well, that means that conjugating by it, shrink one, if I conjugate one way, then I shrink the unipotent radical of my parabolic. And if I conjugate the other way, then I shrink the opposite unipotent radical. And shrink meaning shrinking to nothing. to to to to to nothing basically to to just the identity um if it if it's if it was just shrinking uh but then that would just be positive okay but strongly positive means shrinking to nothing okay so um i'll maybe say something briefly about why that condition comes in so the the archetype for this is um is that the iwahori the trivial of the iwahori so subgroup so again in tln so remember the iwahori is just things which are upper triangular mod p. Things which are upper triangular mod P. It turns out to be a cover of, so the maximal compact in the torus. Okay, so this is just contained in the diagonal group, the trivial representation on that maximal compact of the torus. And this is sort of easy to see. Basically, you take any zeta where the powers of the uniformizer are decreasing. Are decreasing. That's all you need to take. Okay, and so you can take a nice symmetric one if you want. So that's kind of the first example. Why are we interested in them? Well, so Pushnel and Kutsko proved the following thing. So suppose that we have a cover, and suppose that the thing that we have a cover of was a type for this SM. So M, S, so we've had. M, S so we've had some M and rho. Rho is a supercascital of M, S M is the inertial class of that. Well, then this cover is in fact a type. Okay, so in other words, that's saying we do get this bit of the picture now. But also, there is an algebra embedding of Hecker algebras with the property that if I take With the property that if I take the induction functor induced by this, though, so this is the HOM induction functor. So if I take some module to Homs from the Hecker algebra of lambda to X, where I view Homs as a module over the smaller Hecker algebra. So this depends on this embedding, so how we. On this embedding, so how we see HT. Okay, so I realize I've got some typos here. This is supposed to be M and a G. Then we get this commuting diagram, exactly as we want it. So maybe just briefly to say something about where this embedding comes from and how it uses the conditions. So, if you want to do this embedding, if you just want to look on the positive elements in M, then you essentially you just extend. So if you have something which is supported on some function in here, which is supported on some double coset, it'll be a JM double coset, so it'll be a double coset for the smaller group. Double coset for this smaller group, but on a double coset of some positive element, then you just extend the support by making it a J double coset. It's basically all you do on the positive elements, and on the positive elements, that works fine. But then to extend it to everything, this is where you need to use this element phi. And basically, because it's invertible, you can use negative powers of it or you can use no. Or, to to, or you can use no, if you've got anything, you can use positive powers of it to make yourself get something which is supported positively. Then you can embed it, and then you can use negative powers of it, so it's inverse to get back to actually what you want. And because this is in the center, that actually makes sense, that actually works. And of course, but then on those things, so as I say, what one might think is that this inverse might be very nice and it might be supported. Be very nice, and it might be supported just on the coset of the inverse of zeta. Okay, that's not true in general. Okay, that happens, that happens in very nice circumstances, but in general, it doesn't. So, but for things which are not positive, the support gets messed up. Okay, so and then I was going to finish with an example. Well, more or less finished with an example. Okay, so this is an example in SL2. Okay, so we're going to take We're going to take, and it's sort of the same example, but I'm going to just take it a little bit further. So we take SL2, P is not going to be 2. We're going to take inside this, okay, so not much choice for a Levy. So it's just the torus, this is F cross. And we're going to take the trivial representation of this. Okay, so a type for this is just given by the trivial of. The trivial of the Maxwell compact. Okay, there's kind of no choice, really. So it had to be. And the cover is going to be just the trivial of the Wahori subgroup. That's what it's going to turn out to be. But I'm going to kind of work through and kind of see how we can see this. Okay, so this Wahori subgroup sits inside the maximal compact SL2O. Okay, and Okay, and in fact, I can think of it as it's the disjoint union of just two double cosets, the trivial one and the one coming from the involution. And then what I can do is I can think about the part of the Hecker algebra which has support in this compact maximum. And so if I like, I can think of that just as the endomorphisms of this integration. As the endomorphisms of this integers together. But by reducing mod p, you can see that that's exactly the same as the algebra that you get in the finite group when you just induce from. So if I if I look in, so remember K has SL2 over the finite field as a quote as its quotient, and the image of, or and the image of the Ohori is the Borel, the standard Borel, or if you prefer the Ohori is the pre-image of the standard Borel. So that's that's what. Standard Borel. So that's what this is here. This is the Borel. And so it's just the endomorphisms of this induced. So it's just some finite hacker algebra in some finite groups. And these things are well understood. So this is, it's two-dimensional. It's generated by some element which is supported on the reduction of this double coset of this, and which satisfies a quadratic relation. Satisfies a quadratic relation. Okay, and because this is some embedding, then this corresponds to some t over here, which actually satisfies the same conditions. Okay, so what do I mean? I mean that the support of the support of t is j s j and and of course t plus what t minus q is zero. Okay. But if you remember in in SLN, we In SLN, we get there are non-conjugate maximal compact subgroups. They're not all conjugate to each other. And so this Iwahori is contained in this one, but it's also contained in another one. It's a GL2 conjugate. So this is just the top. This is just recording from what's on the previous page. But as I said, we also have J being contained in. So this is the content. So, this is the conjugate. It's the thing where I have a P and a P inverse here. So, it's the conjugate by this element, which is in GL2 but not in SL2. And you can do exactly the same thing. Again, the reductive quotient is isomorphic to SL2. The K prime is a union of two double cosets. The other one is this other involution given by this other involution. So, it's just the conjugate of the previous one by this element. I think I maybe sort the signs as well. Maybe sort the signs as well, just to make signs come out positive later. And so we find by exactly the same, by exactly the same method as above, we find another element, T prime, whose support is now on this other double coset and again satisfies this quadratic relation. And now we can just multiply them together. Okay, we've got these two elements, we've got this t prime and this t. Okay, so I multiply them together. It's invertible. Why is it invertible? Well, because t and t prime are both. Is it invertible? Well, because t and t prime are both invertible, um, because q is because q isn't zero, basically. Okay, so from this quadratic relation, you can see that they're invertible. Um, and what's its support? Okay, well, so a first crude band on the support is that the support is contained in this coset. And it's just from the convolution formula. It's just uh it's contained, it's contained in that. But now you you play you play with this, okay? And so, what do I do? So, I so I insert an Insert an S inverse. So first of all, I can write J from its Iwahori decomposition as the lower part times the upper part. So I mean, so I'm including the levy part and the upper part together there. Then I stick in some S inverse S's here. And now this blue bit here, okay, so what happens to this? Well, this ends up being contained. This, well, this ends up being contained in j intersect m. Okay, so I just swap, I've swapped lower to upper. And this, on the other hand, side, this side ends up being contained in J intersect, the opposite Borel. Okay, and so in particular, both of these end up inside J. And so I end up with just a single, just one double coset. And so initially, we just knew that the support was bounded by this, but since it's only one double coset, that has to be. But since it's only one double coset, that has to be exactly the support. And what's this element? Well, it's a strongly positive element in the center. Okay, so like that, you can get a you get this strongly you get this element. And then and then we can carry on and we can think about this parabolic induction diagram. Okay, so I've not drawn the parabolic induction diagram again, but so again, this is at the top. This is just recalling what we had. And well, so what do these? We can look at these two Hecker algebras. Okay, so the one at the bottom is in fact just generated by this T and T prime with the quadratic relations. There are no other relations there. So you can see this by knowing what the affine var group is, basically. And the one at the top is just Laurent polynomials in a single variable. Single variable. And then you can look at what the map between them is. And well, it's just going to be Z goes to T times T prime. I should maybe say that in my diagram, I had non-normalized parabolic induction. So this is non-normalized things, which makes things at the end come out a little bit different. Well, it makes things come out less symmetrically. So in some ways, I should have done normalized, but I did. I, in some ways, I should have done normalized, but I decided not to. Okay, so how does this help us? Well, the Hercule algebra at the bottom here, it's easy to see, it has four characters, okay? You just have to say where T and T prime go to, and there are two choices, and that's the minus one or Q. Okay, so you've got four choices, and so those have to be the irreducible subquotients. Oh, sorry, so this is, I should have said this, this is index two. So, um, so So, when I take some irreducible module for the secret algebra and I induce it up, I'll get something two-dimensional. Okay, these will all be one-dimensional, I'll get something two-dimensional. And so these four characters have to be the irreducible subquotients of the reducible inductions. Okay, so whenever I, if induction might be irreducible, but if it reduces, it has to reduce as two one-dimensional pieces, which might be extension or it might be a trace. And so, what do they come from? And so, what do they come from? Well, they come from, they come exactly because we know that Z corresponds to T T prime, and we know what T and T prime have to go to. They come from exactly these four values of Z. I've written minus Q there twice deliberately. But then, so then what you can do is you can then reinterpret this in terms of reducibility of parabolic induction. And so, what does it say? It says that for unramified characters, when is this reducible? Well, there are essentially two different sorts of cases. Two different sorts of cases. So there's when either chi is the trivial or the square of the absolute value, and then you get something which is length two and decomposable with the trivial and the Steinberg as the components, one way around or the other. Or you get the twist of the unramified quadratic character. So this is the character whose value on a uniformizer is minus one, which is unramified. Unramified, so so uh and so the twist of that by the absolute value, and so that's corresponding to these two to the minus q's in the middle, and then you get something which is length two semi-simple, and you're kind of seeing it semi-simple because you've got minus q there twice. So that's saying you've got two sub, somehow it's saying you've got two subs. So that's why you're getting the same thing twice. Okay, so um, and you could do the same thing, we could have done the same story. Uh, maybe I can just say this briefly, where instead of having briefly where instead of having the trivial instead of having the trivial representation here i could have taken the ramified quadratic representation so piece not two so there's only one ramified quadratic character so uh uh well no sorry two sorry um but it just doesn't matter which one you take um oh no it's a type so i've restricted no so i've restricted to the type sorry it's the it's it's the type so that there's only one there's only for jm has only one ramified quadratic uh and and what you see is And what you see is you see essentially the same thing, except the relations here become t plus one, t minus one. Okay, and so but you can do exactly the same analysis and see that actually for both ramified quadratic characters of f cross, you get something which splits as length two semi-simple. So you get the single place where it reduces as something length two semi-simple. So that's that. So that's that. So, as a last thing, so here's a theorem which is slightly vague, but I mean, I'm also running out of time. So, there are constructions of covers in essentially all the same situations that there are cuspidal types now. Okay, except maybe the Quaternion Neonic classical groups. I'm not sure about that, whether Daniel's done that yet. Okay, so there's the list of them. But in general, computing the Hecker algebras and computing their and using this to understand reducibility parable conduction is actually hard. Okay, so there are cases where it's done, where it's known, and yeah, but in general, this is a hard question. Okay, so I'd better stop. In the principle of decomposition, I understand that the X groups also between the blocks are trivial. Yes. Yes. Is that a free characterization of the game or the work required to show? I mean, somehow that's repeating. Okay, so the question was in the Bernstein decomposition that the as well as I said that the hom spaces between the different blocks are zero. Spaces between the different blocks are zero, but also the X are zero. And the question was: do you get that for free? Like, does x zero on high by plus imply higher x okay think about that? It's not obvious to me, but To me, it's not obvious to me that you get it just from the homes, but they might, but I'm not saying that that's that there's not a way that you can see it, but so I don't know. Maybe somebody in the chat knows you get it for free because the safety category has a yeah, you're right. Okay, you're right. So it's a kind it's a weak form of semi-suplicity. So just because you can't find a home between two things, why not? Well, I mean, you'd have to be if to get an X, you have to have some home somewhere, right? I mean, an X is coming from a list of kind of a sequence of homs, isn't it? Yes. So maybe, yeah. So maybe then just from that and the fact that you've decomposed the category. So each of those homs has to. So each of those homs has to stay within one of those categories, one of those pieces. Then to get the hom, the thing in the middle would have to be in the same block as the one on the left, and then the next home would have to be. Yeah, okay. So, yeah, you can. Okay, thanks. Actually, let's have something to do again.