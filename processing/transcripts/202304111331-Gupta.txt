Wonderful location, a very nice format. I'm really looking forward to the discussion. Usually when I give a talk, I always somehow feel that I'm keeping my audience hostage, but I think now I can just aim this no. What if anybody's going to do, right? So, all right. So, I'm going to, so this talk is going to continue the theme that was set by the first two talks of the day. So, I'm also a complex analyst. I'm sort of very grateful to Blake and Russell that. I'm very grateful to Blake and Russell that they did all the heavy lifting in giving you all the definitions that you need for this talk and they've given you plenty of motivation. So I will take the definition of polynomial convexity for granted. I should say that there isn't really any synthetic geometry in this course and I'm not in four dimensions but there's plenty of convexity so hopefully this will still be on them. So all joint work with Russell Jocko. And very broadly speaking, we are seeking a minimal embedding dimension where our embeddings are subject to a certain convexity constraint. So I'll describe the problem. And we've seen lots of questions about embeddings in the last two days, but typically they have been embeddings of n-dimensional things in CN. So this is going to be a little bit different you'll see. So I just want to set some notation for the Set some location for the talk. So for us, capital M will always be a real, so I'll always indicate its dimension. So real n-dimensional closed abstract manifold. And let me say that I am mostly interested in smooth embeddings. So I'll take a smooth manifold. But I might, I will say a little bit about topological embeddings as well. And I'll keep repeating this. And I'll keep repeating this phrase polynomially convex embedding. So, I guess this is almost obvious what this means, but I'm just going to write this down. A polynomially convex embedding, which I will abbreviate to ECE, is also of M in Cn is that embedding. And depending on whether I want a topological embedding or a smooth embedding, I'll sort of mention it. Smooth embedding, I'll sort of mention it, is an embedding from N into CN such that the image is polynomial convex. So that's what I mean by polynomially convex in the way. And as I said, I do not want to go over the definition of polynomial convexity. We saw various characterizations and various ways of thinking about polynomial convexity. But I would like to remind you of one thing, I mean, one of the reasons. One thing, I mean, one of the reasons why people came up with the notion of polynomial convexity was to do with approximation theory. So, let me just quickly remind you that if K is a compact set in Cn, then polynomial convexity sort of lies between two desirable approximation theoretic properties. So, polynomial convexity implies that polymorphic functions on k are approximable by polynomial. By polynomials. On the other hand, if you knew that continuous functions on k are approximable by polynomials, then you would know that k is polynomial convex. And none of these are like, these are all like one-directional implications in general. So that's where polynomial convexity sort of lies. So this has some relevance to this talk. So therefore I'm placing it over here. So what we are interested in is we fixed m, we fixed the dimension of a manifold, we want to say Fix the dimension of a manifold, we want to say something about what this n can be, what can this ambient dimension be over here. So, in the topological category, this is very well understood. And this is something that Russell already mentioned. We know that you can never have so low mids a topological PCB. Be CE into CN. And there are topological obstructions, and that was the result by Browder for orientable multiples and Busham Stout for non-orientable. On the other hand, this is a result due to Bodiverse and Zeidenberg. And I don't remember, I think it's sometime in the 70s. I think it's sometime in the 70s, yes. So every n permits equatological polynomial convex embedding into Cm plus 1. So if you give yourself a little bit of space, then it doesn't matter what the topology of the manifold is. You will be able to embed it topologically into Cn plus 1. Moreover, and this will. And this moreover is sort of important because this is, I think, what they were really interested in. So, polynomial convex embedding means that the image. So, let me give this a name. So, I said that this just means that the image is polynomially convex, but they actually show that the image satisfies this strong approximation property. So, if I look at the space of Look at the space of the algebra of continuous functions on the image, then the polynomials are denser. And why I'm sort of emphasizing this point, because as a consequence, if I look at, and this is really what they were thinking about, if I write down the components of this map, so these are. So these are n plus 1 complex value mass. By the way, we are always looking at complex value functions. So these are n plus 1 continuous complex value functions on n. And what this statement, what this entire thing is telling us is that if I look at the algebra generated by these m plus 1 functions, so I just take polynomials in these n plus 1 functions, then these are actually dense. In the algebra of continuous functions algorithm. So, this is sort of some way of recovering, you know, polynomial approximation on an abstract multipoli. There's no sense of polynomials on m, but this is sort of the closest between the two, and what they were trying to answer is sort of what is the least number of generators that you need on an m-dimensional manifold for this algebra. Alright, so. Alright, so this brings me to the question that we want to ask. By the way, this paper is not very long. They have an algorithmic process of constructing these. But these are highly irregular. These embeddings are highly irregular. And so, you know, one may ask at this stage: okay, these are topological embeddings, what can you say about the smooth embeddings? So, this is the question that. So this is the question that I want to ask. And I don't have we don't have a complete answer for this, but I'll sort of report on what it is that we can say about this. So what is the least n? And I will indicate that small m is fixed. What is the least nm so that every capital M as above admits And then, as above, admits a smooth polynomial convex embedding into a CNN. That's what we want to be able to answer. And maybe let me just add something over here. If you're sort of thinking of this question over here, maybe we want generators for this. Generators for this algebra, and maybe we want nice smooth generators, then this is not going to be enough. We also want that if f is the embedding, if f is such an embedding, maybe we also ask that we have this strong approximation property on the image. So, this is sort of an additional thing that one may. Thing that one, you know, if you can arrange for these embeddings to happen, then can you also further ensure that this happens? And one can maybe attach more questions, but I sort of keep it this way. All right. So one thing we already know is whatever this NM is, it has to be at least n plus 1 because there's a topological constraint. Why should such an NM even exist? So this is something that actually Russul already mentioned in some form. In some form, so what you can do is you can sort of produce cheap polynomially convex embeddings by just taking a Witty embedding into R2m. This is just a smooth embedding and now you view R2m as a totally real subspace. It's just a flat totally real subspace of C2m. And so if I call this embedding capital F, then the Weissstraws approximation theorem. Tells me that if I look at the image, then I really have this nice approximation property on the image, which in particular tells me that this is a polynomially convex embedding. So, all of this is saying that I know that I have an upper bound of 2m. So, I have bounds. So, this is a legitimate question. But when we sort of start But when we sort of started thinking about this question, there was actually already a better bound sort of in the literature. So this is sort of related to another embedding problem, which is very well understood. And so let me talk a little bit about how we can at least improve this bound in sort of also a nice way. So this is related to total real impedance. So totally real submanifolds of Cn have also been discussed in Brussels talks. So here I'm thinking of it as an embedding. So I have M into Cn and I will so here I will abbreviate OTL into PR and remember what does it mean for And remember, what does it mean for this embedding to be totally real? It just means that if you look at the image and you look at every tangent plane of this image submanifold, then that tangent plane does not inherit any complex structure, any complex line from the ambient space. That's what it means. And if you just think about the definition of totally real, it doesn't seem to have anything to do with polynomial complexity. There seem to be Did they seem to be very, I mean, this is like a local definition, polynomial complexity doesn't seem to be, but Russell already indicated, and this is also sort of coming from this argument that we had with the Weiss-Russ approximation theorem. This is just a non-linear version of this statement over here. So you expect something, some connection to polynomial convexity, and indeed totally real nanopoles are locally polynomially convex, but in general you cannot patch up local polynomial convexity to get those. Of local polynomial convexity to get global polynomial convexity. We are interested in global polynomial convexity. However, some good global statements are there, and this is sort of I'm going to state a theorem and I'm going to not state it in a very precise way because I need to revisit this theorem. I need to revisit a newer version of this theorem. So I'll sort of state it more precisely then. So, what this says is that every So what this says is that every totally real, so manifolds right now I'm sitting inside Cn. It is important that L is strictly less than L. So every totally real L in Cn can be perturbed, and this is the part where I'm not being precise, so we'll just leave it as is, to a totally real and polynomially convex. And polynomially convex. Okay, so what this is saying is that if you can get me a totally real embedding, then you can put a bit and get me a polymorphic convex embedding. So this is kind of another way of producing lots of producing at least one global polymorphic convex embedding. And let me also say something a little bit more over here before I A little bit more over here before I say something else, what I want to say. Right, moreover, remember that we are sort of also interested in these embeddings due to these approximation theoretic questions. So, if you add totally real to your polynomial convexity, you actually get very good approximations. What you get is that you can actually look at C k smooth functions. And polynomials are dense in CK smooth functions in the CK norm. So you actually have very good approximation if you are also totally real. Okay, so since we are interested in this question, we want to know the minimum embedding dimension for polynomial convexity. This is one way of getting polynomially convex embeddings. So the question is, what is the minimum embedding dimension? What we do is let's say minimum minimum PR embedding dimension. Maybe that's a better way to state this. And this is well known. Store function of 3m over 2. If you were paying close attention to the first talk, this quantity had appeared. This quantity plus 1 was the embedding dimension for store function. Was the embedding dimension for stein manifolds? And there's obviously some connection over here because totally real manifolds have stein neighborhood bases. But I was trying to discuss this with Marco. I don't actually know how to go from one embedding carbon to another. There is almost certainly a relationship over here because of this number and because there is an obvious connection between torterial manifolds and standard manifolds. But let me just say a little bit more about this. So the fact that you More about this. So, the fact that you do have these embeddings, so existence. So, what does it mean to say that this is the minimum TR embedding dimension for n-dimensional microphones? This is to say that if you give me any capital M like this, then it always admits a total embedding in dimensions this or however, in complex dimensions this or however. So, existence of PR embeddings into Into Cn, where n is greater than or equal to this quantity, is actually a transversality argument, which we may get to visit later on. So I will have to return to this point. And the non-existence, so what does it, so this is just telling us that we have embeddings in all dimensions starting from this. But what does it mean for it to be a minimum embedding dimension? If I take one dimension. If I take one dimension lower than this, then I can always find an n-dimensional manifold that does not consume a perfect TR embedding into that ambient dimension. So non-existence of TR embeddings into Cn where n is 1 less than this number. Well, I haven't left myself any space over there, so I'll just write it here. They are very specific. They are very specific dimensions, very specific examples, and you can find these in a paper by Ho, Jacob, Owens, Land Bega. It's possible that these are not the first set of known examples. So this is 2012. But it's sort of a clean case to look up these examples if you're interested in knowing what these specific examples are for each pen over here. Okay, so if we try to use this result, if we try to use this result to produce our polynomial convex embeddings, then we can't do better than float function of 3 and over 2. But what we do know is that the minimum embedding dimension that we are interested in, we have sort of a better upper bound for it. Okay, any questions, please? Alright, so how can we do better? Because this is still, by the way, maybe it's worth pointing out over here. So we have a lower bound and an upper bound, and so we already have so you kind of already have the best you can do for surfaces and three-dimensional manifolds. Manifolds. So this problem really sort of continues to be a problem for dimensions 4 and 10. And so the question is: can we do better if we don't have totally low embeddings? And so that's going to be sort of our main results that we are able to lower this by one for now. This is something that we continue to think about, but I also. And here also. And here also, I'll sort of say, I mean, I'll of course tell you what the results are, but you're able to lower this and then, of course, there's currently no indication that one cannot improve this any further. So this is probably trying get it all the way up to m plus one, but we don't currently have a way of doing that. But I'll outline a general strategy as well when I sort of discuss the results over here. The results over here. Okay, so in fact, what I want to do is sort of mention a result which is an evolved version of this perturbation result. So even though we are in a dimension where we may not get totally real embeddings, we don't completely abandon this chain of thought over here. There's a reason for that. So this is an So this is an important course. Alright, so why do we not give up on thinking about bothial embeddings? So genetic embeddings of n-dimensional manifolds into Cn. I'm just talking about smooth embeddings. I'm not asking for polynomial convexity. Asking for polynomial convexity or anything, and here m is less than or equal to n are totally real. So, let me say, how should I say this? So, let me say it this way. Images of generic embeddings of M-dimensional manifolds in CN are totally real on open and dense. Yes. So you start with an arbitrary sort of a generic embedding of your m-dimensional manifold in Cn. Yes, it may not be totally real everywhere, but it's still going to be totally real on a large part of the manifold. And so we will still have local polynomial convexity at all those points. And the first thing this suggests is: if you're looking for global polynomial convexity, you're obviously trying to ensure that. Convexity, or obviously trying to ensure that you have local polymer convexity. So you sort of focus at the points where your manifold is not totally real. Maybe try to understand that a little bit better. That is sort of the idea over here. But our general strategy over here, so that comes from a theorem. So this is a perturbation result which started from this theorem over here. From this theorem over here and has undergone a fair bit of evolution. So, this was 94 and there have been many intermediate versions of this. And the strategy that I'm going to discuss today is based on the result due to Alosio and Bool, which came in 2019. And what does this say? Okay, so let me state this. I will state this properly because that This, I will skip this properly because that was done a little bit sort of in a fuzzy manner. So, here let x, again dimension n, be a smooth manifold. And here I allow boundary, okay. So, there drop it down boundary. Okay. Okay. Let f from X into Cn be a smooth, totally real embedding. And here, it is important that m is strictly less than n, so I cannot do this almost equal to n. And I have an additional object over here. I have an additional object over here. I have a compact set sitting already inside Cn, which is polynomial E1x. So let me just quickly draw a picture before I state the conclusion of this theorem. So I brought a picture here so that I can complete the theorem over there. So that I can complete the theorem over there. So, then what we had is that we had a totally real n, and we said that, oh, we can perturb it and make it polynomially convex. What's going to happen over here is you have some n, you could have boundary, and you also have a k which is already polynomially convex. So, k could intersect some part of n, it's just some. This x. Ah, nice. This is x. Yes. Yes. Alright, and so what this is saying is that there exists, so given s greater than or equal to 1, so now I will sort of describe what I mean by that perturbation. So given any s and any epsilon, there exists a smooth totally real embedding, which I will call f epsilon, again from x into c. X into Cn such that first of all it is this small perturbation in the following sense. So basically you can take any CS norm of your choice. Moreover, I don't disturb the manifold on k. So k is something that we do not want to disturb. So f is f epsilon on f epsilon on f inverse of k. So this is technically f of x and this is technically f of n. m and x are sort of abstract multiples for us. And then the most important thing is that after doing this perturbation, the perturbed manifold u to k is now polynomial by x. So what this is saying is that initially you have some Saying is that initially you have some object f of x which is totally real, and you can do a perturbation so that in the end, of course, the perturbed object union k is now called normally. So the version that we had written over there, k was an empty set, but it's really sort of a version of the same theory. Pause here and see if the So, in the original version, k was empty? K was empty. I guess here also you can have a law boundary. I mean, I think the way this was stated, probably for the law boundary, yeah, that didn't matter, but there was no K. So, what this K is doing is it's allowing us to introduce non-TR points, non-totally here ones on the live road. That's the role that we sort of wanted to play. Okay. So let me outline a general strategy over here that this suggests and then I will sort of say, okay, does that strategy work? What can go wrong? Alright. So, general strategy to produce Totally produce polynomially convex embeddings in dimensions lower than the floor function of 3 and 4. So, what you do is, first you just take a generic embedding. So, step one, take a generic embedding. Okay, so then what will happen is that there is some portion, and I'm not going to currently say anything about this portion, but there is some portion of this portion. Say anything about this portion, but there is some set over here and it may not be connected. There is some set where the manifold is not over here, but we know that it's not a log set. Okay, so the point is I'm going to define MPR and I'm sort of abusing notation a lot of times. So M was an abstract manifold for us, but here now M is sitting inside C L. So it's just I'm not going to make a big fuss about that right now. Going to make a big fuss about that right now. So, NDR is what we want to look at. So, this is a set of total points on n. And ideally what we want to do, what we would like to do is, we would like to call the rest of the set, so whatever n minus npr is, we would like to call that RKO. We would like to call that Rk over here. So, if we could arrange for that set to be polynomially convex, then the hope is that, okay, maybe we can apply this particular theorem over here. I mean, with this version of the theorem, there is a slight problem in that if I look at NTR, so let's say K is just a compact set, then NTR is not a total manifold without, it's sort of, you're just removing a compact set from a manifold, so this is a bit of a problem. Also, this is a bit of a problem. And so, to sort of circumvent that problem, what we should try and do is: okay, maybe we don't remove k, but we remove a nice neighborhood of k. Okay? So, this is not our k. Let me call this s. And so the step 3 of our strategy is find a nice. This is just a strategy, so I'm allowed to use vague words over here. Find a nice name. find a nice neighborhood but very important polynomi convex neighborhood u of s. So, what I do is I somehow manage if I can sort of find a nice neighborhood I'm not doing this very well but I'm not sure if I can do it. I'm not drawing this very well, but I want to find this nice neighborhood capital U over here and somehow I arrange it to be polynomial convex. And then 3 or 4 apply theorem, oops, these are all too small, apply theorem to capital K equal to u closure and capital X equal to M minus. X equal to n minus, I guess M minus U closure. Okay, so then M minus U closure, I'm sort of assuming that my boundary, this U is nice, so that M minus U closure is a totally real manifold with boundary. The set K, which is really U closure, that is polynomially convex. So when you do a perturbation, the pink set does not change in this perturbation. The perturbation keeps that fixed, but everywhere else, That's fixed, but everywhere else I get this perturbed manifold, and the new thing is now called modular terms. So that's the general strategy. Alright, so the challenge, as you can see, is really because of this theorem, our focus is entirely on the set of non-token points. So the challenge is really over here. Why can I find this neighborhood which is polymorphic complex? That's sort of like the main crux of the mean the crux of the strategy in some sense. Alright, so let's sort of talk a little bit about the set capital S. We have some sense of what the structure of S looks like. So let me say something about that. Again, I'm going to mention some terminology that did appear earlier. So the set of CR singularities. CR singularities of something like this M playing inside CR. And I denote that by NCR. This is just M minus the set of K d. And here again I'm assuming this is sort of a generic This is sort of a generic embedding. And so this object, we have some understanding of its structure, of its global structure, and that's going to be somewhat useful. So what I can think of this set, it's a sort of a stratified set. So this is not... By the way, the singularities over here, we don't refer to singularities of the smooth, these are smooth embeddings. This is just a singularity of the complex structure. Of the complex structure. So, I mean, this is a word that we are sort of using. I have to be a little cautious over here. But what NCR is, it's a sort of stratified set. So, I'm going to introduce some notation over here. N mu, where mu is greater than or equal to 1, where what is n mu? Cr. It is the set of points in m where if you look at the tangent space, now the tangent space is going to inherit some complex structure. Going to inherit some complex structure because we are not whole anymore. But we want to quantify how much. The dimension of the maximal complex subspace of the tangent space is mu. Okay, so mu equal to 1 refers to those points where the tangent space has one complex line in it, so on and so forth. So where these guys are locally closed. Submanifolds of co-dimension. So, I actually even know a fair bit about them. So, their co-dimension in n is 2 mu n minus m plus mu. So, I know how large they can be. Okay, and in fact, so this is how. So, this is something that one can do by taking the Gauss map. If you're wondering where this is coming from, what you can do is you can map each point to the tangent space at that point, which is an element of the Grassmannian of n-dimensional real planes in Cm. And here, you can look at those planes that inherit complex structures, that's some sort of stratified set. So, this is really, you just borrow that from here. So, this is not something. Something very complicated, but let me make a few remarks based on this description. Maybe something I should say over here. Right. So one thing I can say is that MCR is empty if n is greater than or equal to 3m over 2. So that was the result about both ERIL emphatic picket rates. Result about total real embedded vividity into this dimension. That's just saying that the CR set isn't. So you can compute that from here. In general, this is just a stratified set. So you may not get a smooth sub-manifold if you have CR singularities at different levels, at different mu's. But MCR is just M1 is a submanifold if M. If and these are just things that you can compute based on the formulas I've given over here. So, in particular, we are working in 3m over 2 minus 1. So, we are always going to be in the setting where we only have a sub-manifold of CR singularity. We are only looking at CR singularities of order 1 over here. Alright, so let's come to that case. So, if n is That case, so if n is 3n over 2 minus 1, this is our situation, the situation in which we want to produce, at least try to make the strategy work. Then it turns out that if you look at the set of CR singularities, the dimension is either 0 if m is even or it's 1 if m is 1. So we are going to try and make the strategy work when the set of CR singularities is either a set of points. A set of points, or it is some finite union of curves. That's where we are going to try and make the strategy work. I should also say that in this case, in this dimension, and this is something unique to this, I mean if we try to lower this further, what I'm going to say does not hold. Moreover, the singularities, the CR singularities are what are known as non- What are known as non-degenerate? I'm not going to go into the definition of what this means. There's an analytic description. We also understand this non-degeneracy to some extent geometrically, but it's not going to be very useful for me to tell you what that is right now. But what it means, so all my CR singularities have something over here, which means that i.e. the manifold. Is locally biholomorphically equivalent. So, at each of these non-degenerate CR singularities, the manifold is locally biholomorphically equivalent to a single algebraic model. So, you have some sort of a normal form at these singularities. So, this is something about the local structure of the manifold over these singularities. This model is due to Bereshar-Quiet. This model is due to Bereshopka and Kaufman. It's very easy to write, but I'm not going to do it. It's not going to add that much information. It's a very simple algebraic model. So what's happening is that I have my set of CR singularities. Let me draw a picture. Let me draw a picture in the two cases that we have. This is an odd, and we are trying to. Odd, and we are trying to go into C3K, and here m is even, and we are trying to go into C3K minus 1. Okay? And so what we can do is we can arrange, by taking nice enough embeddings, here we can arrange the CR singular set to just be points. And here they are going to be curves. And we have non-degeneracy, which means that if I take a little name. That if I take a little neighborhood over here or a little neighborhood over here, then there is a local biholomorphism that takes me to the model. That's what I have. That's the picture I can arrange by just doing some quotations. Now, this case, the strategy works great because the models are locally polynomial complex. Are locally polynomially convex. And this is something one can check by hand actually because they're very easy to have easy expressions for them. So by hand, you can check that the models are locally polynomially convex. So that gives you local polynomial convexity at each of these balls. So if I just take the union of these, I have to shrink these balls small enough. We've already seen that the unions of balls are a complex. That the unions of balls are a complicated question when it comes to polynomial convexity. But if I shrink them enough, then I can make the union polynomially convex, and that's all I need. So the strategy works in, let's call this case A versus case B. So let me state the theorem that we get in this case. So, any smooth map from so we have even dimensional, so small m is equal to 2k and I want to go in 3k minus 1 and remember this problem really makes sense only starting with dimension 4 because the 2 and 3 we're already done. Because the 2 and 3 did already done. So any smooth map can be perturbed with these large erasers. So can be put out to a smooth F epsilon from m2k into C3k minus 1. C3k minus 1 can be perturbed to a smooth polynomially convex embedding. So we want the image to be polynomially convex so that the image is totally real except at finitely many points. And in this case, it's not And in this case, it's not hard to also, due to some results from the literature, we also have the strong approximation property. So we can approximate continuous functions with polynomials of these images. So we have polynomially convex embeddings, but we have more. We also have this stronger. Alright, so what about this case, right? So what we have here is we have some local polynomial convexity at each point. And what we want, even if we just had one curve, so let's say we don't have one curve, we want to produce a polynomially convex neighborhood of this entire curve. And as we've discussed before, you cannot just patch up local polynomial convexity to get a full neighborhood over here. Get a full neighborhood over here. So, how does one work with this idea? So, it doesn't, I mean, at least we don't know a way of just producing an embedding directly just by doing some perturbation. We don't know a way of making this neighborhood polynomially convex. So, we have a slightly different strategy in this case. And before I sort of tell you, how much time do I have? So, before I actually tell you how do we sort of work around that issue, you will see that we already this problem that we have that we only have local polymorphic convexity at one point, that we somehow want to create this band which is polynomial convex. So, we are able to do that, but we have to make some assumptions, at least if we want to use the perturbation result that I stated earlier. Result that I stated earlier. So already we will assume that n is orientable. And here again k is greater than or equal to 2, then there exists a smooth polynomially convex embedding f from m to k plus 1. N2K plus 1 into C3K such that I do have nice approximation property that we plot. So you can already see that this is a little bit stated a little bit differently. Earlier, we were always just starting with some smooth map and we were just perturbing and getting our polynomial. In getting our polynomially convex embeddings. So, this was sort of what we were saying: is that the polynomially convex embeddings you were getting were sort of denser. Here, the result already looks different. We are not sort of just taking an embedding and perturbing it. We are sort of producing somehow polynomial convex embeddings. So, how do we do that? Why is the statement of this form? So, I thought I'll just describe the idea in terms of a picture. In terms of a picture. So if you remember, I have my, I take a nice enough embedding in the desired space and I know that I can sort of arrange it so that my set of CR singularities is a union of curves. So I'm just going to draw one curve over here. And what I want is a totally real, oh sorry, a polynomially convex. Sorry, for polynomially convex neighborhood. So I want something like this. I want this to be polynomially convex. I don't know how to arrange it. So the idea is, what if I create a model that is polynomially convex? So I'm sort of trying to create a model neighborhood. So what this neighborhood does is that it's totally real except along this curve. Real except along this curve. This is sort of a model for this picture, but somehow I create this model to already be polynomially convex. And this here, because we have orientability, this little neighborhood, this is S1 cross d to k. So these are just copies of S1 cross d to k. And what I'm going to do is if I have a model like this, and somehow if I can connect, if I look at just the boundary of this name. If I look at just the boundary of this neighborhood, what I will try to do is, I don't know if I have more colours. So I will try to sort of replace this neighborhood with the model neighborhood. And how do I do this? I sort of connect their boundaries. Let's see if I do this right. Of course, mod. Okay, so something, let's see. So the idea is that I want to connect these two. So this is my original manifold, this is my model. And I take the boundary of my model and this little neighbourhood over here. I sort of connect it and I want to erase the old neighbourhood. I sort of want to erase the old neighbourhood. So, I want to erase the whole neighborhood. So, what I want to do is I want to replace the old neighborhood with this model polynomially convex neighborhood without disturbing the topology of the rumbled manifold. But the issue is that I shouldn't inherit new CR singularities in this cube. So, I want this cube over here to be totally real. That's what I need to do. I need to, first of all, I need to make sure that I have these models. First of all, I need to make sure that I have these models over here. Once I have these models, I somehow want to embrace the old neighborhood, introduce the model into this manifold via some protein queue. Okay, and so there is going to be some obstruction in doing that and one tries to quantify that obstruction. So let me very quickly write down where the obstruction lies. So these models, the boundaries that we are trying to connect, these boundaries are S1 cross S2K minus 1, I think. So what I'm in N2K plus 1, actually, right, I guess I have this. Right. And so what's happening is that The obstruction lies in some group of homotopy of maps from this manifold into some Schiegel manifold. So, what is this? This is the Schiegel manifold of 2K plus 1 frames. plus 1 frames A C 3 K. Okay, so this is just to figure out whether or not we can have these tubes and this is where the obstruction lies. This is actually one can compute this, one can compute what these groups are. It differs whether k itself is odd or even. So the answers are a little bit different. And in fact when k is odd there is some torsion over here which did seem like a bit of a Which did seem like a bit of a problem. But if we can produce models for every single element over here, then the edge principle allows us to actually claim these cubes. And so we do actually, and I'll not go into the details, we can construct, so this is sort of the topological part, but even if these obstructions exist, why do I have models for every member of this obstruction class? And remember that models have to be polynomials. And remember that models have to be polynomially convex, which is an analytic feature. You cannot arrange for things to be polynomially convex just by using some topological output. So, the analytic component is that you can construct polynomially convex models for each obstruction class. And so, that is the modification to the strategy, and then you do this replacement, you get these various. You get these various polynomially convex neighborhoods. You can always arrange them for them to be small so that the union is polynomially convex. But you can see that in this construction, we are not doing a small percentage. That is why the main result is just an existence result. So since I'm out of time, let me just say a few things about. I mean, of course, the problem as stated is open. So, can we do better, you know, maybe using this strategy or maybe using some. Strategy, or maybe using some other strategy, you can see that as we are lowering the dimension, the quality of the theorem is sort of deteriorating. Like with totally real, polynomially convex embeddings, we had dense embeddings, and we had open. So, something I did not say is that if you already have something which is totally real and polynomially convex, that is stable under perturbation. Now, the second theorem that we had stated, we did have a density statement there, but we don't know if these embeddings are stable. The ones that we have constructed Stages. The ones that we have constructed, we don't know if we perturb them. Are we still going to have polynomial convex embeddings? So we lose openness at this stage. And at this stage, we don't even know if we have dense embeddings in this particular dimension. So somehow trying to lower the ambient dimension is sort of giving us worse and worse results. But we don't know if that is sort of fundamental to the problem or it's a limitation of our techniques. And one can ask, of course, the same questions for rationally convex embeddings. Rationally convex embeddings, and you can try to embed into other spaces other than CN and ask for holomorphically convex embeddings. I think all of those are open problems. So I'll stop over here. Thank you. Questions or forward? So just uh just one question. So there in this experience, so you know that this is not a generic uh perturbation or I mean No, we do know it is a generic yes, but I don't know if it's stable because now I have introduced CR singularities, right? So once, so I mean this is like density versus openness. So if you give me some smooth map, I can produce some perturbation which is polynomially convex, but it's not going to be totally real at finitely many points. Now if I perturb this guy further, I don't know if that's going to stay polynomially convex. I don't know if that's going to stay bottom-up context. That's the thing I'm going to do. But this course paragraphs and th this result is that basically any generic perturbation so you have a generic perturbation that actually makes it better. This one, yes, yes. Yeah, this generic perturbation. Other questions? Yes. So I was a bit interested in this foster result. So you see, it's a kind of Result. So it's a kind of symplectic formulation of this polynomial. Yeah, okay, so I sort of didn't want to say anything because it felt like cheating a little bit. Maybe it goes back to the Dhubal guy, because polynomial convexity implies rational convexity. So let me, since you've asked me this question, let me say the follow-up. So let's just work in the setting where we have PR plus polynomial X. This is the first generic setting. This is the first merit setting. So you have m dimension in C3 and O2. So of course, rational con, because this is in particular rationally convex and totally real, Duval Lai will tell you that this is isotropic with respect. But you can do better because you actually know the potential. What happened is, remember Russell mentioned that polynomially convex sets are zero sets of Fourier subharmonic functions and look but those Toury subharmonic functions are strictly Fourier subharmonic outside the domain. Subharmonic outside the domain, outside the set. Totally real are zero sets of strongly or strictly Pouli-subharmonic functions locally. So if you combine that, these are zero sets of strictly PSF functions. And so this is the potential that you can use. So you actually get the potential from this defining function for your K-der form over here. And so, of course, the minute you drop this, doing something like this. Doing something like this becomes a problem. But this situation here, the one where we go in 2k into c 3k minus 1, what we have is P R except at finitely many points plus polynomially convex. We are sort of able to do the same thing where we have basically we have degeneracies on the final side. Final life set. So the TR norm degenerates exactly at those finite limit points. And this is not, it's not just a consequence of the fact that you have total except at finitely. In general, that's not true. Just because you have this doesn't give you the structure. It's something to do with the nature of the singularities. And this has a little bit to do with something that Marco had done earlier. He had constructed these special use of amount functions. So one can do that. Functions. So one can do that in this setting when you really have finite continuity or simple actions. But this is a condition. I mean, okay, so I would say then that total real Poland convex implies exact, isotropic, subtletical. But is it commercially so exact if kind of all the symplectic periods among the symplectic action vanishes? Is it non-convex or something? No, I don't think. No, so I don't know. For a curve in C2? Just a curve that doesn't involve any kind of spectral character. And maybe it's... But right, but that may not... Because maybe that's okay, but I'm not sure that will work for... Yeah, I don't know. I don't know if that completely characterizes. So you're saying exact isotropic. You have totally real. Does that give you a real? Does that hit you? It doesn't go in the neural switch. But that's not the only way to. Oh, okay. Good. So there are examples in this dimension. There are examples a little bit harder. But I mean, okay, what I want to say is that in this setting, there are examples of totally real manifolds where the hull is not coming from a disk. And it's not even coming from a Riemann surface. So the people Riemann surface. So the people, in fact, ROCO board have constructed examples where you have Hull, the manifold is ulterior, there's no Riemann surface over here now. No analytic structure. Exactly. So if that's the idea, then I think it won't work. Thanks. More questions? There'll be coffee after the thank you for your course and then there'll be obsession. And then the big obsession. Maybe Tom will say a couple of things about that, right? But first, let's take for a break. Okay, all right. We'll have a sudden break, and then we'll meet up for these problem sessions. You should all have gotten an email to tell you what group to go to, what room. Again, the each group has a nominal leader whose role is to kind of fill the silence if that it starts off that way. Silence if that starts off that way. And so there may be some problems suggested to talk about. You can talk about problems that you, your favorite problems, if you prefer, whatever, you can have your discussions. Ideally, whenever, you know, if there's a way for maybe somebody to take notes or to leave things up on the board and take a photo on the end, it would be nice for us to sort of have some record of what sort of problems people were talking about. And that would be sort of helpful for us. The other thing. The other thing is that you could keep in mind as we go along, we're thinking that on Thursday we'll have another one of these sessions, but we might structure it slightly differently in the sense that today each room is more or less flexible, whatever you want to talk about, that's great. But there have already been some indications that some people might be interested in focusing on particular problems. So for Thursday, if you have a favorite problem, or maybe you want to a friend or something, Or, like, you or a friend or something would like to have a group of people talk about some particular problem, then feel free to send us an email. We could maybe designate it, we could have more rooms, we could designate certain rooms for certain problems, something like this, and we could maybe still have the flexible rooms as well. But please let us know if there are particular problems that you'd like to focus on, and then maybe others that are interested in that problem could gravitate towards removing for Thursday at any rate. For Thursday. Let us know if you're not clear what we're supposed to do. Anyway, first is copy. Okay, I just like to give you the content. Anyone say that the time job is fun?