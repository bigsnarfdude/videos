Okay, well thanks for the opportunity to say something brief and please feel free to interrupt at any point. It's be very informal. Thanks to all the previous talks I think there's very little left for me to set up. So what we're going to be looking at is meeting times for Or the fact that we've just seen. And this is joint work with a PhD student in Oxford who should hopefully be finishing soon. James Air. Okay, so there's some very particular geometries that we treat. So the first one will be a closed interval. A closed interval with no closed boundaries. So nothing moves in or out. So let's just take n sites, wanted to end at k particles. So as we've just seen, it's strictly dynamics. This guy can move to the right. We'll look at both the asymmetric and the asymmetric case. And the asymmetric case. So this guy can move to the right of the portal with E, left report with one minus P okay. And the state space is just, okay, let's say eta is the n times some of eta x. Okay, and as we've just seen. And as we've just seen, so there's essentially two problems with this when you're looking at the mixing time. You're going to start with something which is not belonging to the alcoholic component in the sense that you'll have neighboring sites which are empty. So the first problem then will be, how long does it take to hit something that looks like the algorithm component? And once you're on the original component, how long does it take to hit? Okay, so on the inside. Okay, so on the interval, the ergotic component, what I'm going to call the ergodic component, with I'll try and keep the same notation as far as possible, so that it's E N K. It's just a set of configurations with no two consecutive empty sites. No two empty sites. Do empty size. On the interval, you'll also need to have a particle at either end. Like once a particle is stuck to the end, it's fixed. And both eta one is one. Okay, so that's the first setting. So that's the first setting. And I should say the results essentially follow from comparison in all cases, either with zero range or easier to picture in this case is going to be coupling to just the simple exclusion process. So the results will essentially follow from recent results by This was on the archive, where they did mixing time for the exclusion process on the interval and they covered all various boundary cases, basically all the cases that you could be interested in when you have finite interval. Okay, what's our result? So it was. So the number one says if you take the symmetric facilitative exclusion process on the interval, then so fix n, the size of the lattice, and fix a k bigger than n over two, up to n. Then the mixing time, which is also a bit so total variation mixing time. So demix, say, fixed an epsilon, say water, goes like, so up to asymptotically universal constants above and below, it's going to be like n squared log of n minus k. So exactly what you'd guess is. Exactly, what you'd guess if you were looking at the full spectrum exclusion process, but with the number of particles is essentially k minus n over 2, the number of mobile particles you'll have on the ergotic component. Okay, theoretical two by the same tricks, you can do the asymmetric case. Asymmetrically facilitated exclusion process also on the interval, and then T mix is going to be exponentially large. So what I wanted to do log of T mix over n minus k is going to be log t over q. So long as m minus k is diverging, or n minus k, in fact, I guess must be much bigger than log n, or something like this. As long as you can say what government alert. What's that? Tornado warning. Should we go outside to protect ourselves? I think we're speaking. Keep an eye. That was definitely more exciting than the talk. Okay, that was definitely more exciting than before, so um and stuff there is some constant constants alike. Number two, no constants. This should be. Wait, but with P equals my login but you have to scale up in minus K B the log N, then I think we're okay. One of my keyboards I have. Okay, I contributing. So, again, if you're worried about the details here, if I explain where it comes from for our proof, essentially it's just paper file enough and see if I've been precise enough in the statement. But I think it's this one. Okay, and finally. Right. The final last case we treat is basically the same matrix extremely slowly. Extremely slowly. So it's asymmetric. So you could start, and there's a bias to the right. So you could start with all these particles piloted up on the left. They have to move against the drift to even reach the ergodic component. So this is the reverse bias. And in the simplicity case, which is the dominant part in the simplicity case, reaching the body component or mixing inside the body component? While the other case is reaching the body component. In the symmetric case, if you have closed one-band conditions, you should be able to get the Conditions you should be able to get the cutter, yeah. I think that's pretty much different. I mean, this is already so it's actually alright in the upload component, and it's faster. In the airboard component, it looks exactly like the set, and then I guess it's faster here. Fast there. Okay, so just quickly, the final case is going to be on the one-dimensional torus. So the ring and size. Okay. On the torus, we just treat the symmetric case. So the symmetric facilitated infant process on n. And in this case, And in this case, so the lower bound we can do by comparing with the sort of metric exclusion process on the ring, the upper bound we get from getting a long subtle F bound. So in this case, the bound on the mixing time is going to be, so it's equal to, I don't have any nice notation for this. Or have any nice notation for this? It's up to polylogs. It's again n squared, log, some power, maybe squared, n problem. Okay, I have a lot of bands. So this is a double band, and I have a lower band. Okay, it's constants. Up to some universal constants. The lower band is n squared. Okay, and optimistically, maybe you only lose. Lose a lock again here using the locks of a lot of constant. I have a little hat here because there's a problem still with the proof, which is here we can't treat starting from any initial condition. So this is starting from nice initial conditions. And nice means what we have a bounded number of ergodic components in each. Of got it components initially. So if you look at the ring and you look at the region on the ring, I say I call it in the codic component. If there's a region with a particle either end and in the middle, there is at most an isolated site. So the economic components are separated by empty, at least two empty sites. At least two empty sites. So you can look at the initial condition and you can split it into these blocks of things that look like initial conditions where we have a bounded number of argolic components, but we can't very well control how they interact with each other if you have very many of them. If the number of these initial orgotic components is Of these initial organic components is growing. If you send them to infinity, we can't control how they interact with each other. If you have a band-aid number on them, then we'll see if you just treat them with the same sort of coupling to exclusion process. Sorry, what assumptions are we made on the number of parts of it? That's kind of crazy. Sorry, I've just rubbed it off. It has to be so. In this case, we have to have the density of particles to low k over n is converted to something strictly between the heart and the body in the bump of men. Okay, we can't be close to it. Okay, we can't be close to the the uh on the interval you can be much more precise about controlling what happens close to n over two when close to n but uh because we use this oxobolin uh comparison on the thing we really have to have density space bigger than a half exactly because we want you'll see in a moment uh decay correlations we want things to decorate okay the results that i just rolled off everyone okay happy beautiful Okay, happy. So there's essentially two key observations on the interval. And the first one is, let's do the following. Let's skip all the particles initially at the right hand side. So we have this block of Of k particles here, and we have n minus k sites that are empty here. Right, then I'm going to argue that I can couple this with bijectively like we just saw from the zero range, but with an exclusion process. So the point is: so let's draw down here an exclusion process. An exclusion process on K-man sponge sites. And what I want to do is identify particles in this configuration with sites below. So initially, I have, I'm going to take a picture, just going to draw pictures and run a simulation on the board. So we start with k minus one empty size corresponding to this. Corresponding to this configuration, this guy moves with rate one minus p to here, and what you end up with is a particle here and an empty site here. I identify particles with sites here, and I identify the so that I put a particle on that site if there's an empty cycle of life. So, this moving from here to here with rate one minus p is like a particle. One minus p is like a particle entering from a reservoir on the right here and we take one minus p. Okay, once this particle is in here, it moves according to well, an exclusion process with one particle, so it's important. If this particle then moves here, this one. This one is now empty. The site corresponding to this particle is now empty. The site corresponding to this particle now has a particle on it. That's the same as filling this one. Okay, so this, essentially, you look at this little dimer here and it's moving. Which remote sense, the only other thing that could happen is this could move off again because it's a particle on the light. So it satisfies the constraint, it could move off again, and that's the same. Can move off again, and that's the same as another particle entering from the reservoir. Okay, it's the picture convincing. I don't want to labor too much as long as you understand the picture, right? So, in particular, you're looking at these sort of dimers as moving according to an exclusion process. This is true all the way up until this left-hand particle reaches its boundary. So, it's the same as having an exclusion process on k-1 sites with a reservoir here. With a reservoir here with initially containing n minus k particles. So they keep entering the light. Particles can never leave. They move in until you run out of particles in the reservoir. And then your dimers here just move according to an exclusion process. According to an exclusion process, we have n minus k particles on the k minus n size. Right, so that's almost enough for the bounded interval case. The only other thing is that we have monotonicity, slightly different monotonicity. So a key observation two is that if we label particles from left to right, so this is So, this is particle one in the configuration eta. This is particle two in the configuration eta, all the way over to particle K in the configuration eta. Then we can write down the partial order on the configurations of the FET, the facilitated extrusion process. We say eta is less than or equal to sigma if and only if eta the ice particle is. The ith particle is less than or equal to the particle in theta is less than or equal to the ith particle in sigma for all i this gives me a partial order on configurations and the FET is monotone with respect to this partial order so this is preserved if we couple in the right way and one coupling that works for example is to use Example is to use what you would inherit from this picture if you took the height function independent corn of Lips coupling. So that is equivalent to saying each of these guys tries to move according to independent Poisson clock, say graphical construction, you put independent Poisson clocks on each side. Each site and each one to i. So they're all moving independently unless the same particle is at the same site, and then they use the same parson to box and they move together. It's the same as you can look at, this gives you a height function and you can look at independent corner flip. That preserves this partial order. So we can reduce to just looking at how long does it take to couple started from this, the maximum configuration. Couple started from this, the maximal configuration and minimal configuration where everyone is piled up at the other end. Once you believe these two things and you believe this mapping to the exclusion process, then you just inherit all the results from Gunther, Mr. Reedy Schmidt. Okay, you have to do some work as what you want to couple these two guys, but essentially you wait for this system to mix, then that dominates hitting the good. Hitting the good component. So you've hit the good component, you have the partial order then on the component, and then you wait for this to mix, and that essentially gives you the coding task. Okay, maybe the ring is more interesting. I just want to say something very quickly about the symmetric facilitated exclusion process on the ring. So here there's a little bit more needed. Here, as I say, this is from what we actually get is the log Soberlev constant. What we actually get is the Law-Sovel constant. We could find out the Log-Soberlev constant. And the way we do that is: so look at the Dirichlet form. We want to control the entropy in terms of the Dirichlet form. Look at the Dirichlet form on the torus. This is certainly bigger than or equal to, so I can condition on the occupation of these two sites. Of these two sites here. If I can fix the configuration on these two sites, then what's left is a facilitated exclusion process on the thing with closed boundaries, which is the simple symmetric exclusion process, which I can control the entropy form, which is that one of those exclusion process. So, okay, the Drichley form is one. So the stationary matter on the ring, when it's symmetric, is just uniform on the good component. Okay, we use these sort of arguments to control how long it takes to get the good component. The more interesting bit is when you look at the boundaries, which is reversal on the good component. So this is just uniform. Then we have the rate of going from e to 2 to 5. Time okay, so I combine this follow by removing so that I look at the sum, say this is G0, say that I can't calculate the sum over I equals one to three. There's three good things this could be. It could be either be occupied, empty, empty, occupied, or it could be occupied, occupied. So there's Occupy occupied. So there's three situations I have to sum over. For each of these, I can sum over eta and eta prime in, say, g pi, which are all the configurations where you had to fix the configuration at the top. Okay, and then the same thing. So the only thing, the only reason this is a lower bound is I'm ignoring jumps between these components. These components. Okay, this is the uniform measure, so I can do change of measure with only constant cost if I want to change to the station the uniform measure once I've fixed these particles. So I cannot change measure, but I can think about this as just being the average. The average of the entropy of sorry, we should all be f squared because I want to do logs of bullet entropy of f squared conditioned on, say, G0, the occupation. So pictorially, if I think about my good set here, eta. So the thing is reversible on eta n k with uniform. E to n k with uniform stationary measure. I think about conditioning on the occupation of the top two sites. So I can partition this into the three sets where I fixed the occupation of the top two sites. And on each of these bits, I can control the entropy here using the log-Sobolev constant from the simple symmetric exclusion. Simple symmetric exclusion process on the interval that I would get via this mapping. So let's just call it low i. So each of these can control low i entropy. Sorry, I'm too quick. That's what I was doing here. So I can on each of the so restricted to each of the components, I have the Dirichlet form of the process, which is just Process, which is just a simple symmetric extrusion process on the mean, which I can control the entropy using the logs of a left constant for lamp process with fixed bounding conditions. Okay, I made a mess of explaining that, but hopefully it's clear from the picture. All I'm doing is looking at this partition of the state space, and on each of these partitions, I just And on each of these partitions, I just have a simple semi-tree exclusion process. So I can control the entropy here and here and here, but this doesn't allow me to control the entropy everywhere because I can't control the entropy between these bits. So all I do is condition also on the occupation down here and partition it in the perpendicular dimension as well. Then I can control the entropy on each of these blocks. I can control it here as well, which allows me to control it everywhere. So the only thing everywhere so the only thing i have to do uh so this would be exactly if if this um event so conditioning on uh the occupation of these two sites and conditioning on the occupation of these two sites was really completely independent then the entropy factorizes and it it works so the only other ingredient is that since i know the correlation decays either by equivalent ensembles or just by a Or just by say renewal argument, I know that these sites, if the density is strictly bigger than a half are asymptotically independent of these sites, all I need to do is have some control that says if the events are approximately independent, then I have approximate factorization of the entropy. And that turns out to be true. And there's a reference which is so this is F. So this is FC F01, which I didn't know about until this work, which says if, so okay, this says if they're approximately independent, then this approximately factorizes, and then you're done. So you can prove that they're approximately independent just by, as I say, a renewal type argument. So the trick is that everywhere you have uniform measures. So changes of measure are for free, essentially, you only gain universal instance. So there's universal. Universal constants, so there's universal constants here everywhere. You can definitely condition on something almost independent of this, and then you're done. Okay, sorry, the end was a bit rushed, but there's nothing super technical in any of this.