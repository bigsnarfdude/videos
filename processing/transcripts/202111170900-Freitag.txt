Okay, so what's the talk about? So I'm going to work in the general setting where I throughout will have X to be the solution set of some algebraic differential equation. Yeah, and I'll focus a lot on examples, but But if you're not used to working on, I don't know, problems like this or in this kind of setting, I think it might be helpful for you to think that the field over which things are defined, what I call k, is some field of analytic functions on some domain. And for most of the examples, the field will actually be C or C of T. So So you won't really lose much if you just think of that. And that's fine. So, okay. And so I'll give you some examples next, just so you have a rough idea of what I'm talking about or the kinds of equations I'm interested in. Okay, so right, so here's the setup, and here's some examples of the kind of thing I want to consider. So So, like this first equation is the second Pan-Levé equation with a certain parameter value, five-fourths. This second equation is a Riccati equation, but there's, oh no, I have to change the eraser stop. Oh, okay. Because it's a trick. The third equation is the equation satisfied by the J function. function. The fourth equation is some vector field on rational vector field on affine two space. All these kinds of equations are fine to consider. Okay, so it's some very general setting. And all the ones I wrote here, I think, have coefficients in either C or C of T. And just so that I'm not like lying too much, I'll always assume that the equation. That the equation that I'm considering is irreducible in a certain sense. So, you know, if it's a system of equations, somehow the ideal that they generate in a certain polynomial ring should be prime. And it's usually not an issue because, like, say, the highest order derivative might often appear linearly, and then you would never have to worry about that. Okay, so, all right, but for the way I want to describe things in the simplest Describe things in the simplest possible terms, it's you need to assume something like that, okay? And so here's the central notion of this talk, and yeah, central notion in differential algebra. And so I want to go through it kind of slowly and explain some nuance of it. So, X again is this solution set to this equation. And we say that it's strongly minimal if whenever Strongly minimal if, whenever you take a solution and possibly whenever you take a differential field, so that's just a field where you include the generators of the field, these functions and their derivatives. So you take any differential field extending your field K, then the transcendence degree of the differential field extension. The differential field extension generated by that solution falls into one of two camps. Either it's the same as it was over the small field, or it's zero. Okay, so of course, you can't preclude that. It could be that F it's kind of a hard condition to get used to, but I'll try to get you used to it. Get you used to it. So, of course, it could be that f is just in k1, right? It's some field extension, or it could be that f is algebraic over k1, in which case this would be zero. And so what this condition says, if the condition holds, and it's certainly a very non-trivial condition, what this condition says is that f can't satisfy some lower order differential equation. ordered differential equation basically without becoming algebraic over the that field extension so like of course you might you might think like well what happens like if if f say is an antiderivative of some function in k1 well what this says then is that if k1 is closed under taking derivatives that f is already algebraic over k1 okay so um okay so there's a lot to be said about it and lot to be said about it and it's non-obvious that any equation of order bigger than one should have this property right that's really non-obvious i think so for instance here are the examples i gave on the previous slide the first one is this vicati type equation and this equation is order one so this is a trivial statement for order order one equations they're definitely strongly minimal in this sense minimal in this sense because i mean the transcendence degree of of a of the of the field generated by a solution to this first equation and its derivatives well i mean its derivative is um is written as a polynomial in in the function so it's definitely at most one but it could be zero okay so this is a trivial condition for order one but for order two equations But for order two equations, I mean, this is really non-trivial. How could you, I mean, it's not at all clear how you would even establish something like this. And I mean, for this equation in particular, it took a long time to establish this. I mean, this was a conjecture and a claim of Pan Levé from the late 19th century, and it wasn't fully worked out until the 1970s, right? And 80s. 70s, Rodney? In the 80s. Okay, in the 1980s by the Japanese School of Differential Equations. Okay, so this is a central notion in the model theoretic approach to differential equations. It's hard to establish. And so you might wonder why it's so central. Okay, and I'll try to explain that. Okay, so again, I just have the definition up so that you can get used to it if you've never seen it. That you can get used to it if you've never seen it before. And, like I said, this is a central notion. There's an analogous notion for difference equations, or if you want to think about things in terms of, say, vector fields on a variety, or that's another way to think about differential equations. We'll talk about this condition from that perspective. And there's an analogous condition for, you know, Analogous condition for, you know, say varieties with rational self-maps. Okay, so, and it plays a big role in the model theoretic approach to all these different. Okay, so I haven't defined it for the difference case or the dynamics case, but there's an analogous way to do it. All right. Okay, so yeah, so maybe just again to emphasize some key facts. Key facts, it's not clear, not clear how you should prove this. In fact, in most cases that we know of, it's been really difficult to prove this, and people worked really hard to. So I'll try to explain why we've worked so hard to prove this in a lot of cases. A lot of cases. There's real tangible reasons. Here's some examples of work where it plays a big role, and I just picked some. You can pick many examples. So I'll just say something very quickly about these things. So this is Udi's work around Mannon Mumford and Mordell Lang. This is the work of Ronnie and Anand on Pan-Levé equations. The work Tom and I did on. The work Tom and I did on the J function, and then later the work I did with Guy and Ronnie on Fouxian functions. I mean, it's connected to the sort of things that Rahim was saying yesterday in that examples of certain strongly minimal equations let them build counterexamples to this conjecture of Dixme-Moglin equivalence, the structure theory of those strongly minimal sets. Strongly minimal sets was what let them build the kind of counterexamples that they got. And somehow, the theory of strongly minimal sets also played into the cases where they verified this. There's a certain, yeah, there's certain notion of people would call it semi-minimal analysis. It's a kind of vibration property for dynamical systems, which has to do with strong minimality and plays a big role. And it plays a big role in Zoe and Udi's work on algebraic dynamics. So, and there's many more examples. These are just the ones I chose. Okay, so kind of the goal, I guess, of my talk is to try to describe to you what the condition means geometrically, since many of you are probably not interested, not maybe you're not interested, but you're not used to working with this condition. Not used to working with this condition, I hope you're interested. To describe what kind of important applications there are, and then to describe a certain approach to establishing strong minimality that I've been working on with Rahim and my student Matthew. Okay, all right, so that's the first 30 seconds of the talk. Okay, okay, so the question is, yeah. Yeah. So the question is: why is the condition so central? That's a really, I think, a non-obvious question if you haven't been working on these problems. And I think that there are essentially two factors that explain this, at least to me. The first one has various reasons, but they all have something to do with the ubiquitousness of this condition. So we'll talk about. We'll talk about this condition, and it seems to be a generic condition in various settings. That means if you pick a random equation nonlinear, you should expect that it's strongly minimal. There are even theorems to this effect. I think the first such theorem is by Remy Jowy, and the second theorem, which I'll talk more about in this. Which I'll talk more about in this talk is due to myself and my student, Matthew. Okay. So there are even theorems to this effect. The second point is that even when your equation is not strongly minimal, there are often techniques to reduce certain questions that we're interested in to the strongly minimal case or to something close to the strongly minimal case. I won't talk very much about that point, but it's an important reason. But it's an important reason. Okay. All right. The second, okay. I mean, just because a lot of equations have this property, maybe doesn't mean that we would care so much about it if it wasn't useful, but it does seem to be useful for a great many different kinds of problems. So, and maybe the central reason that that is, seems to be that once you establish the condition, you can apply fairly, what seem to be fairly powerful. Fairly, what seemed to be fairly powerful sort of classification results from model theory, and so I mean, all the model theorists know what I'm talking about, but I mean, things like the silver trichotomy. And I mean, I want to try to give a tangible example where this plays out in a non-trivial way next without lying too much. So, one situation that this is often The situation that this is often really useful for is in classifying the algebraic relations between solutions of equations. And so, okay, I both want to convince you that that's a problem you should want to do and that this condition is really useful for doing that. Okay, so I'll try to give an example, which is maybe familiar to some of you or not. I don't know. Okay, so the example. So the example comes from Dauphinian geometry and o minimality. And there's a number of examples like this now. Okay, so I want to take X to be a definable set in some O minimal structure. Okay, hopefully you have a vague idea of what this is, but maybe not. It's a certain set which it's defined in a certain kind. It's defined in a certain kind of geometry, generalizing semi-algebraic geometry. Okay, don't want to say too much more about that because I want to try to go through the example and not too long. Okay, so then this set, which I call X alge, is some people call the algebraic part of X. It's the union of the It's the union of the connected semi-algebraic subsets of X. And its complement is the transcendental part of X. Okay, and the point for Diophantine geometry is that Pila and Wilkie proved super strong height bounds for rational points on the transcendental part of X. Okay, so here's what they proved. Here's what they proved, and this is like just the simplest case, their generalizations. They proved that for any epsilon greater than zero, there's a constant so that asymptotically, the number of rational points of height at most t on the transcendental part of this set X TR grows slower than T to the epsilon for any epsilon greater than zero. Than zero. Okay, so you can see how that would be really useful in establishing certain Diophantine conjectures, and it has been, but only if you can identify what is X alge. And in most cases that I know of, identifying what X alge is really boils down to classifying the algebraic relations between solutions of certain differential equations. Yeah. Differential equations, yeah. Um, I just want to ask an idiot question. Can you give me just a simple example of a no-minimal structure where you have any transcendental rational points? Any, sorry, transcendental function. Oh, yeah, yeah, like so the real field with plus and minus times in the order and the exponential function, the real exponential function. An exponential function counts as a rational. An exponential function counts as a rational point. Oh, by the way, the graph of y equals 2 to the x. No, o minimally definable set. Oh, sure, the graph of the exponential curve, y equals e to the x. That's an o-minimally definable set. Its algebraic part is empty. Oh, okay. Okay. Thanks. Okay. Well, okay. Well, okay. But the yeah, but I'm demanding that these be connected. Connected and infinite. Sure. Okay, sorry. When I say connected, I don't mean a point. I mean, yeah, I mean, sorry, I mean infinite. Sorry, that's, you're right. That's my fault. So, yeah, so for instance, like the graph of the exponential curve, you can actually take any real analytic function restricted to a suitably bounded domain. Okay, so the only thing that you can't have is. The only thing that you can't have is unrestricted functions which oscillate in a certain way, like the sine function. Okay, so all right. But in particular, you could take the complex J function, restrict it to its fundamental domain. And doing this problem in that setting is how Pilo proved the Andre-Orb conjecture. Okay, so let me. Let me kind of not say all of the details at this part, of course, but in this case, so to prove the Andre-Oort conjecture for C to the N, what you need to do is identify, well, x is going to be the image of some algebraic variety under the j function applied to each coordinate, if you like. You can set it up though. Okay. And so identifying And so identifying what is x alge is exactly the same thing as asking yourself for the coordinate functions of your algebraic variety v, when are j of f1, f2 through fn algebraically dependent over c? These are some functions. They're transcendental functions, as long as the fi's are non-constant. And they also, well, And they also, well, you can see they satisfy some differential equation. And if you prove that that differential equation is strongly minimal, then on very general grounds from the kinds of classification results that we know, it follows that if these are algebraically dependent, then a pair of them is algebraically dependent. And so even if you're sort of skeptical about the usefulness of this condition, you have to The usefulness of this condition, you have to admit it should be easier to classify the algebraic relations between two of these than between some arbitrary number. Okay, and so this is like a concrete example. And, you know, characterizing X alge in this case is sort of equivalent to what people call an axe Lindemann style theorem. And those theorems are being proved in an essential way that uses strong minimality these days by, well, I don't know. These days, by, well, I don't know, people like me, Ronnie, Guy, Tom, Jonathan Pila, and others. Okay, so that sort of ends the example, and I'll go back to the main part of the talk. Okay, so, and hopefully now you are at least somewhat convinced or interested that you want to know more about this condition. Okay, so that spoke to sort of the usefulness of this property, and now I want to talk about. Property. And now I want to talk about the ubiquity. And so it's a conjecture of Boisa from 1980 that generic nonlinear differential equations are strongly minimal. It's not actually clear when you read the paper what Poisson means. Read the paper, what Poisson means in particular. Although it's clear that he must mean one of two things, I think. So he could mean that, because in this paper he talks about both of these things. Maybe he means both, actually. Probably means both. So he could mean that if you take a nonlinear differential equation of a certain order and degree and Order and degree, and it has constant coefficients, which are generic complex numbers, which are complex numbers which are algebraically independent over Q. Then that equation should be strongly minimal. And that has been verified by Remy. So he's done the constant case. For order two for order two equations. So, uh, in his proof, he uses O minimality in a deep and whole different way than what I talked about a minute ago. No, he uses O minimality as well and strong minimality. He's using all the minimalities, I guess. Yeah, so right, so. Right. So, right. But the other thing that you could mean is the non-constant case, non-constant coefficients. Again, you would fix, say, the order and degree of the equation. And then the most natural way to say that the coefficients are Way to say that the coefficients are generic in the non-constant case is to say that they're differential transcendental functions, which are independent from each other. So some people call this, let's see, if, yeah, I just, I don't know if everybody kind of knows this terminology. Differentially transcendental means you don't satisfy any differential equation at all. You and your derivatives are algebraically independent. Some people call that being hyper-transcendental. Being hyper-transcendental or transcendentally transcendental, maybe at some point in the past. Like an example of such a function is the gamma function. Okay, so this case has been done by my student Matthew and I for any order. For any order and degree greater than or equal to two times the order plus two. Okay, and yeah, I don't, we hope to improve that, but I want to explain sort of roughly speaking what went into. Roughly speaking, what goes into the proof? Because I think the ingredients of the proof are like at least as interesting as the theorem itself. Okay, so that's what I'll do next. Okay, so to do that, I want to explain, well, at least from my perspective, like, why is this condition strong minimality hard to establish? And from my perspective, And from my perspective, there's basically two factors which make it difficult. The first one is that you have to think about differential field extensions, and those are very messy. And like say in the difference field case, you have to think about differential or sorry, difference field extensions. Those are even messier. And so, yeah, and so that makes like the kinds of computations. Like the kinds of computations that you want to try just sort of never work, at least in my experience. And then the second question is, well, sort of once you've, okay, maybe you have to extend the field of functions. And then suddenly your differential equation, your solution, it might satisfy a lower order differential equation. But you sort of have no idea about the shape of the equation. The shape of the equation. We don't know a general way to say bound the degree of that equation that you might satisfy. And even, say, in the case of planar vector fields, this is a hard problem, a seriously hard problem. I mean, it's called the Poincaré problem in that case, and it's been open for, well, since Poincaré worked on it. Okay. Now, it's not all bad news. Now, it's not all bad news. There's a certain general model theoretic principle which says that you don't have to think about arbitrary differential field extensions, K1. You can instead think about the differential field generated by F1 through Fn for some n, where these are solutions. To the original equation, like other solutions. That's kind of surprising, I think, but it follows from some very general model theoretic principle called stable embeddedness. And Tom and I once tried to call this the Shella reflection principle, but Anand is really mad about it. And so I'm not doing it. Really mad about it. And so I'm not doing that anymore. Okay. Well, I think Udi called it that first. Okay. So let's talk about what the sort of condition means geometrically. And so for this, I want to think about a variety equipped with a vector field, which varies rationally. So, what you're really trying to do, if you want to prove an equation that's given by a vector field on a variety, is not strongly minimal. Geometrically, what you're trying to do is find an invariant sub-variety. So, I mean a sub-variety, like if this is a surface, say, you're trying to find a curve so that at each point, the tangent space to the curve. The tangent space to the curve contains the vector. This is what I'll call an invariant subvariety of the vector field. Okay, so that's really what the problem comes down to geometrically. And I mean, you can, of course, there's many places where you do the problem in those terms and some geometry helps you. Okay. So if you think about this previous principle, what it means is that you're really trying to find invariant. Trying to find invariant sub-varieties of the product of your variety equipped with the vector field by itself some number of times. And you want them to be non-trivial in a certain sense so that they correspond to a differential equation which is lower order but not algebraic. And what you need to And what you need to have happen is: if this is the product of x, this variety with the vector field on it n many times, then you need to find a sub variety y of x to the n, which is invariant for that product vector field, so that the projections on to each copy of x are dominant. And if you take the generic fiber. If you take a generic point of these first, say, n minus one many copies, and you take the generic fiber up here in this copy. So like I'm picking a tuple of generic points here on these first N copies. And then I need to have the fiber be positive. Be positive dimensional and well and positive co-dimension so that it's not the whole thing. That's what I call a non-trivial invariant sub-variety of this product. And if you can do that, that exactly means that your equation that you started with is not strongly minimal. And if you can't do that, then it means that it's strongly minimal. Okay, so it's a, so there's a very geometric. So, there's a very geometric interpretation to this. And at least from my perspective, one of the big problems in verifying this is that this general approach here, even though it tells you you can restrict to this situation, it doesn't give you any bound on N. So you may be trying this problem in a very big space, and that might make it very hard. At least that's what we thought was true. What we thought was true. But the work that I did with Rahim is exactly to bound the N that you have to consider to verify this condition. Okay? All right. So yeah, so here's kind of, I'm trying to make that point concrete. So we're asking the question, is there some capital N? question is there some capital n so that if you verify there are no non-trivial invariant sub varieties in x to the n x to the big n then there won't be any non-trivial invariant sub varieties in uh x to the n for little n you know larger all larger ones okay that's what we want to know because that will that really helps make this problem tractable and it's the key for instance to the work that matthew and For instance, to the work that Matthew and I did. Okay, so you can phrase this in purely model theoretic terms. Maybe only some people are interested in that. Yeah, so sorry if you're not a model theorist, this has no reason to make sense to you in that case, but you can phrase this in a general, well, we set it up in a general omega-stable context. Stable context. And if you have a type of U rank bigger than one, we call this number the degree of non-minimality. And it's the minimal length of a Morley sequence so that your type P has a non-algebraic forking extension over A1 through AD. Okay, so, right, this has no reason to make sense to you if you're not, I don't know, doing stability theory or something. So, um, Theory, or something. So, okay, feel free to ignore it. That's the case, but it can be set up very generally. Okay, so I can't talk about the entire way in which Rahim and I tried to do this problem. It's not really feasible. But I want to talk about some particular step, which I find particularly interesting. Okay, so we show under really general assumptions that bounding this degree of non-minimum That bounding this degree of non-minimality, finding a bound for this capital N of these products of vector fields, it really boils down to controlling a certain kind of higher transitivity of a certain group action. And I'll try to explain it to you in just a few minutes. And in this case, that group action is the differential Galois group or model theory. Group, or model theorists called the binding group, acting on the solution set of the differential equation. And so, like, for instance, in the case, so this problem is not interesting for linear differential equations, but this Galois group in the case of, say, an inhomogeneous linear equation would be the Picard-Fessio group. So it's something that people. Okay. So suppose that we have a group action G on. That we have a group action g on X, completely general for a moment. It's n transitive if whenever you take two distinct tuples in X to the N, there's a group element which maps one to the other. Okay? Distinct tuples of distinct elements. Yeah, sorry. When I say distinct tuple, I mean tuples of distinct elements. I'm sorry. Yeah, I did that wrong. That's a Sorry, yeah, I did that wrong. That's a, yeah, you're right. Okay, so it should say instead of distinct tuples, it should say tuples of distinct elements. I mean, of course, they don't have to be distinct, but that's not very interesting. Okay, so n transitivity for, you know, values of n like bigger than three is like a hugely restrictive condition and like never happens except for the symmetric group acting now or that. Okay, anyway. Anyway, but I'm not really interested in that. We're interested in actions of algebraic groups acting regularly on algebraic varieties. Okay. And for that, the pertinent thing is a weaker condition called generic transitivity. And instead of demanding that the orbit of G acting diagonally on X to the N is as large as possible, you just demand that it's large. You just demand that it's large, where large means risky deaths, which is the same thing as demanding open. Okay. So this group action is generically n-transitive if the action on x to the n has a Zariski open dense, thus dense orbit. Okay, so here's a picture of the difference, which is due to Josh Wisconsin's picture. So two transitivity looks something like this. Transitivity looks something like this. The diagonal is an orbit, and everything off the diagonal is an orbit. Generic transitivity looks similarly. The diagonal is likely to be an orbit. Well, maybe if the group isn't quite transitive, there's a red part of the diagonal that isn't in the orbit. But off the diagonal, there's a big orbit, but there might be some other orbits, this blue part and things like that. Okay, so it's a weaker condition. Condition, and this is the condition that is pertinent to us. Okay, and what we show is that if you can bound in a certain way the generic transitivity of a group action, then you can bound this degree of non-minimality. Okay, and I haven't talked at all about that step, but I want to say that in general, this bound on the degree of generic transitivity of a group action was a conjecture. Is a conjecture of Borovic and Churlin, is a conjecture of Borovic and Churlin. It takes place in the general setting of groups of finite Morley rank, although you can certainly phrase it even more generally in various ways. And what they conjectured is that if X is n-dimensional, and here, if you don't know about groups of finite Morley-Rank or that setting, just assume that X is an algebraic variety and G is an algebraic group, and dimension means dimension. Dimension means dimension. So if X is n-dimensional and the action of G on X is generically K transitive, then you have to have that K is bounded by the dimension of X plus 2, like no matter what. Weird. Okay, so I mean, if you haven't played with this notion at all, I mean, it's not even clear like what group actions like this look like. So, um Like this, look like. So, here's a chart with some examples and their amount of generic transitivity. So, the x-axis is the dimension of the set X. I'll say more about that in a second. And the Y axis is the degree of generic transitivity of that group action. Okay, so the green dots here are PGLN acting on projective n space. So, when n is one, that's the action of. That's the action of PGL2 on P1. That's actually three-transitive as a group action, not just generically three-transitive. So it's certainly generically three-transitive, and that's why it's right there. Okay. And PGL3 acting on P2, it isn't three transitive, but it is generically four transitive. Okay. And so on. And it goes up this diagonal. Up this diagonal, just like that, the action of PGL on PN. Okay, so I'm just assuming people know what that group action is. Okay, but I think that's safe. AGLN, by that I mean the group, GLN extended by shifts, you know, just linear shifts extended by K to the M. Okay, that's semi-direct product. Semi-direct product. That's a little less transitive, but for instance, you know, AGL1, I mean, which is just the semi-direct product of the multiplicative and additive group, that's two transitive. And it keeps going up. It's generic, here it's generically three transitive, generically four transitive, and so on. And then there's other examples like GLN is there. Is there. You can see that GLN is generically n-transitive because the open orbit is just the set of bases, right? You can take any basis to another basis by a GLN. Okay, so the conjecture of Borvik and Churlin, it's really nice with respect to this little diagram, because what it is, is that there's nothing above this staircase. So the conjecture of Borvic and Schurlin just says there's nothing up there. Says, there's nothing up there. Okay. And so, what Rahim and I showed first was that if you could prove the conjecture of Borvik and Churlin for algebraic groups characteristic zero, then you could bound this degree of non-minimality. Okay, so I'll talk about that in just a second. But I just want to mention that there's a lot of work on this in the general setting of groups of finite Morley rank by people. Groups of finite Morley rank by people like Altonell, Wiscons. Yeah, and Orca. Surely. For instance, this conjecture has been verified in general when X is Morley ranked 2. So maybe, and there's some other notable special cases, although it kind of seems like the general conjecture might be as hard as true. The general conjecture might be as hard as true and silver. I don't know, maybe not. Okay. Excuse me. Is it at all known that there is a bound? Yeah. Oh, that's a great point. I didn't, I neglected to mention that. But yeah, there is a bound which depends only on the rank of the base. There's an argument for that in the original paper of Borovic and Sherlin, but there's no way to calculate what the bound is. Yeah, but you're right. It is really interesting that there would just be, you could just prove that there's any bound at all. Just prove that there's any bound at all, which only depends on the rank of the base. Yeah, that I found that really surprising. That you could prove something like that without, but you don't know what it is. Yeah, so, okay, but it's still very interesting. Okay, so Rahim and I proved the Borvik-Cherling conjecture for algebraic groups of characteristic zero, algebraic group actions. And we should say there's this is kind of like a folklore result in a way. I mean, people said that this should. I mean, people said that this should be true. There's like some people who say there were sketches of proofs, but I didn't think that there was a very complete proof. And we, I mean, okay, maybe somebody who knows a lot more group theory than us could do it very, could do it, could have done it a lot easier more easily, but we had to work pretty hard to do it, I have to admit. So, um, okay, but it's open in characteristic P greater than zero. Yeah, so that's very interesting. And I mean, I could imagine someone. I could imagine someone proving the characteristic P version and soon. Who knows? Okay, so we use this then to show, like I said, that the degree of non-minimality in the setting of differential equations only is the order of X plus one. And we get a weaker result, which, well, depends on this big conjecture in the In the general setting, and the bound is a little worse because we know some tricks for differential equations. Okay, all right. So, oh, I'm sorry, but when should I stop? I should start a bit late, let's see. Five minutes is okay. Yeah, sure. Okay, all right, good. Thank you. So, right, so we proved that this degree of non-minimality is at most the order of the equation plus one. Of the equation plus one. And we have some ideas to improve this bound. I think that we will, but they're, yeah, but they're incomplete, unfortunately, at the moment, and will require some hard group theory. So let's go back to Poisson's conjecture then and talk about how this helps and just the generalities around the strategy that Matthew and I employ. So Poza. So, Poissat's conjecture in the non-constant case has to do with general equations of this form, where here this sum ranges over all the monomials of degree less than d in the unknown x and its first n derivatives. Okay, so this is what we call a generic order n. Generic order n degree D differential equation. And the alphas are a tuple of differential transcendentals, which I understand probably many people are not totally familiar with, but it's a genericity condition on the coefficients. Okay. And so the conjecture is that equations of this form are strongly minimal. And we prove this when the degree d is taken to be large enough. Taken to be large enough, where large enough means twice the order plus two. Okay, so I want to try to explain exactly or somehow vaguely how we attack the problem, what goes into it. So the first thing is we use this bound of Rahim and I to say that you don't have to think about arbitrary differential fields. What you need to really do is think. What you need to really do is think about sort of the invariant sub-varieties of the product of this system with itself a number of times. Okay, so that's what I've written here. Whatever invariant means, because I know this, okay, but I'm lying a little, but that's basically what has to be done. And so then the trick that we do is we say, sort of, if you were to find If you were to find a sub-variety of this system, defined over Q, a joint alpha bar, that's the tuple of all the coefficients, plus this order zero coefficient, which are all differential transcendentals. If you could do that, it would be some differential polynomial with coefficients that are rational functions of the alphas and their derivatives. And their derivatives. And if you wanted, you could clear the denominators in a certain way and make it a polynomial in both the x's and in the alpha. And if you did that, you know, then you could kind of think about the alpha as an extra variable. Okay. So kind of think about this as an extra variable. And of course, An extra variable. And of course, it's a really simple variable because it's one that you can easily just eliminate from the system. I mean, this system is, of course, exactly equivalent to the one where you remove the y's and set the pairs of monomial sums equal to each other. And that is a system of n plus two, many differential equations. many differential equations and it's or sorry n plus one many differential equations in n plus two variables it's an underdetermined system and it turns out that finding an invariant subvariety of the form we were aiming for to start with corresponds to finding what model theorists would call an infinite rank subvariety of this auxiliary system. Right, infinite rank in the sense of Lascar rank for people who are familiar with that. For people who are familiar with that. And it just so happens that my previous PhD student, Jonathan Wolf, was working on a project to calculate the rank of underdetermined systems of differential equations. And so what we show in this case is that there are no proper infinite rank sub-varieties of this system, that the infinite rank auxiliary system has rank omega. Has rank omega for the model theorists. And the way we do it is by going to the differential tangent space and showing that the differential tangent space has rank omega. Because if you have some sub-variety of the equation, then that will manifest itself as having a linear sub-variety of the differential tangent space at a generic point. And we show that there are. Generic point, and we show that there are none except for ones that are finite rank. Um, aren't you? Sorry, yeah, aren't you only interested in things over the like without going to without additional parameters? Yeah, rank omega seems you can do that even over additional parameters, there are no uh yeah, that's right, yeah, yeah, yeah. I mean, there are no infinite rank ones over additional parameters, that's right, where all you needed was over the basement. Yeah, the purpose of this was. The purpose of this was to not have to go to a bigger break. Well, yeah, except that, um, yeah, except, except that the techniques wouldn't work if you extended the field extension and you didn't know that the coefficients remained differentially transcendental. Yeah, we tried that though. Yeah, it's a good question. So kind of related to Miranda's question, wouldn't thinking in terms of differential transcendence degree work as well? Work as well? Yeah, it would. But well, no, I mean, because what could happen is, right, like we know it's clear from the shape of the system that it has differential transcendence degree one, but it could have a proper sub-variety whose generic solution also has differential transcendence degree one. And that is exactly what we have to rule out, precisely that. And so that's what we rule out. And the reason that you need the high degree. You need the high degree is that, well, okay, you might notice that there's a number of equations here. Like the coefficients in this system are not differentially transcendental with each other. The alphas are like repeated all over the place. But when you go to the differential tangent space, you suddenly have fewer monomials because everything becomes linear. And if you have enough monomials to start, you'll have enough transcendence to have enough genericity in the Have enough genericity in the tangent space to make it so that there are no sub-varieties. Because what my previous student, Jonathan, showed is that if you take a generic system of linear differential equations, which is underdetermined, then in some sense, its Lascar rank is as small as possible. In this case, as small as possible means rank omega. Okay. All right. So I think I should stop there since I'm over time. Thanks. Since I'm over time. Thanks.