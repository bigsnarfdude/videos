So, it is my pleasure to introduce Fabio Cavalletti from CISA, who kindly agreed to give the first of two lectures about the introduction to richer retroside on metric measure spaces, the optimal transport. So, thank you to Fabio and yes. Thank you. So, two lectures, but one is given by Danielle and the other one. The first one is. The first one is okay, that's good. Okay, so uh, thanks a lot for uh this invitation. And uh, fortunately, I wasn't able to come to Mexico, but maybe next time, who knows? And yeah, so the plan for my presentation will be to just review somehow the basic motivations and the definition. So, we'll be very Definition. So we'll be very basic. So, no, nothing too fancy for people already is familiar with the CD and RCD theory. We'll just be a very general overview on the theory of these two family of spaces. And so, the plan for my presentation will be to give first a few motivations, so why, from where these two classes of spaces are coming from. Spaces are coming from, and so these two classes are the CD one and the more recent R C D. And my idea was to, anyway, also for historic motivation, to first spend a few words on the definitions on the CD condition and speak about a little bit about what is known for this class of spaces, somehow make a somehow a state of the art for the results known for this class of spaces. For this class of spaces, and then conclude by giving you a few motivations and the definition of the RCD spaces. And then I think that the next seminar by Daniel de Semla will be mainly on the final theory for RCD spaces. Okay, so what is the general motivations from where this theory is coming from? So this is very Be uh, this is very um classical. So, uh, what is known is that lower bounds. Uh, so here the general idea is that you would like to have a description for lower bounds in rich curvature in a synthetic manner. So, uh why do we have this need? Well, this is coming from the ground-of-pro compactness theorem that it's valid for a class of Riemannian manifold having a uniform lower bound. A uniform lower bound on Ricci curvature. And this is coming from the very famous Bishop-Gromov volume comparison theorem. And Gromov introduced a notion of convergence for Riemannian manifold that is called Gromov-Ausov convergence. And he observed, again, from deducing mainly from this comparison between comparing the growth of the volume of both, that if you have a Of both, that if you have a sequence of Riemannian manifolds with a uniform upper bound dimension and verifying having a uniform rich equivalent lower bounds, then this class is pre-compact with respect to this Gramobaus of notion of convergence. So the natural question, what can we say about the compactification of this space of Riemannian manifolds with rich curvature bounded below? And so the quest for understanding this question started as a Started, as I said, in around the 80s. Would be hopeful that then this was somehow hopeful also to establish new properties also for the smooth category of manifolds. And okay, so now it's not moving. Okay. So now on a slightly different with slightly different motivations, so let's say as a side story, what is known is that What is known is that if a Riemannian manifold, somehow, if you are interested in comparison theorems, but if you would like to put on your Riemannian manifold a different reference measure other than the volume one, then somehow if you want to make to generalize the classical comparison theorem, like let's say the spectral gap, so let's say that you want to, for instance, find a lower bound on the first. For instance, find the lower bound on the first egg and value of the Laplacian. So, let's say for a certain number of things, if you want to somehow have a control on some object where whenever you do not just consider on your manifold the reference measure given by the volume one, but you put a weight on the manifold, let's say here I'm denoting with the C2 function H, then the relevant object to control in order to journalize. control in order to generalize a lower bound Ricci curvature is to control the n Ricci tensor introduced by Beckery. This n-Ricci tensor that depends also on H at this strange form. So you will have the Ricci tensor and then you will have the hash of H raised to the one over capital N minus to this small n. So this small n will be the topological dimension of the manifold. And this other capital N, somehow is the behavior, is the change on the manifold manifold. Is the behavior, is the change on the apparent dimension that is caused by the presence of a difference weight function h. And most of the comparison theorems that you can get from the functional analytic point of view can be generalized to this weighted Riemannian manifold just by imposing instead of a lower bound, the Ricci curvature, a lower bounds on this and Richie tensor in. And Richie tensor introduced by Backfriend. And somehow, in order to capture these things of putting a lower bound, the Richie tensor, this then got the name after Backfree and Emory and was called the curvature dimension condition. So C D with the capital K will play the lower bound for this generalized and rich tensor, and capital N is the generalized upper bound on the dimension. So it was for again a long time not clear how to extend. Again, a long time, not clear how to extend to non-smooth space this CDKN. And somehow, seemingly, these two questions all remained somehow not speaking one to each other and both remained unsolved for many years. And somehow the CD theory coming from optimal transport managed to address both stories together and establishing somehow a new theory. And to speak about a little bit. And to speak about a little bit about this CD condition, so this not one for weighted manifold, but this general one holding for metric spaces, what the basic language is the one of optimal transport. Okay, so even if I think maybe for most of the audience, this would be very well known. I decided anyway just to fix notations to write down a few things for the optimal transport. And so with these motivations in mind, so on one hand, These motivations in mind, so on one hand, to understand the behavior of possible rich limit spaces, so the compactification with respect to this Gramo-Wausidov convergence of this family of Riemannian manifold with lower bound rich curvature. On the other hand, generalized this Backery-Emory C D condition for weighted manifold, then we have to use this pseudonym object to have in mind it's a complete and separable metric space, so X D, and we have. Space, so Xd, and we have to put also to fix a reference measure on this space. So this triple will be called always a metric measure space. And here the idea will be to use to build the vastest time space over this space. And so let's speak a little bit about it. So first of all, you have to consider the probability measures. It will be this P2x. So this will be probability measures. So measures mu. Probability measures, so measures Î¼ with total mass one and with finite second moment. And over this space of probability measures with finite second moment, you can define the quadratic transportation distance. So the two buses stand distance between these two, that is denoted by W2 between mu1 and mu2. What you do, we'll just take the infimum among all the probability measures pi over defined over. pi over defined over the product space and what you have to impose is that if you project on the first coordinate you take the first measure and if you project on the second one you take the second measure so these are called transport plans and if you catch the optimal one you are integrated the distance squared you obtain the two buses and distance between these two probability measures and it turns out that in this way you you turn In this way, you turn the space of probability measures with finite second moment a complete and a separable metric space. And moreover, if your underlying space has nice geodesic structure, meaning that if you have between any two points, you can build a curve with minimal length. With the length, I mean, now it's not central to understand how the length is defined on metric space, but you can define it. So, if for any two points you have a curve of minimal length, To point, you have a curve of minimal length, the same can be done also for over the Busestein space, over these two Basestein space. And okay, so what is the idea? So now the idea is to lift the analysis in order to capture, let's say, in order to avoid possible singularities arising on your metric space. So the idea is to look at the behavior of the vastest. The behavior of the vast extended space. So it's to lift the analysis to the vast extended space built over our space X. And the idea to do that is to look at some functionals defined over this metric space, over the two-busess sign space. You have somehow two main functions that you can define on this P2 that. On this P2 that are called the entropy functional. So let's maybe start discussing a little bit with this U infinity, that is the classical entropy that you can, that you coming from Boltzmann. So what you have here, you define the entropy of a probability measure mu that has to be assumed to be absolutely continuous with respect to the reference measure. So it means it is of the form reference measure times. Reference measure times a density. And what you do, you integrate the density rho times log rho with respect to the M. And it was a crucial observation done by Turme and Foranest back in 2005 is that if you just for a moment, if you stick to a Riemannian manifold Mg, then you can correct. You can characterize a lower bound on its rich curvature in terms of convexity properties of the entropy function of U infinity with respect to the geodesics of P2. So this means that if you the fact that your Riemannian manifold has reached a negative, this is equivalent with the fact that as soon as you pick two probability measures that are absolutely continuous with your reference measure, With your reference measure, that in this case is the volume one, and then you take the shortest path inside P2, connecting your first measure to the second one, and then you evaluate your entropy function along this Baserstance geodesic. What you will have, you will have just, let's say, a function of real variable with. Of real variables with real values. So the notion of convexity perfectly makes sense. And so this was somehow this crucial observation that the rich equivalent of your space can be characterized in terms of convexity properties along geodesics over the vastest time space was somehow the bulk for the initial understanding that you can characterize, you can somehow give a meaning. You can somehow give a meaning to lower bounds for each curvature, also to metric spaces. This is a, I mean, you use this entropy if you are not, I mean, this first result by Sturman for Renes in 2005 was not taking into account the dimension. So this was just a characterization for a lower bound on the Ricci curvature. Bounds on the Richie curvature, and but somehow then it was a big leap to arrive to also to understanding the upper bound dimension and how to give somehow to let's say also to understand other properties. So, anyway, in order to capture also the dimensional information of your manifold, the right thing to do is to consider To do is to consider this other functional, this Reni entropy function that is taking that depends on capital N, and in this one, it's taking into account also the dimension of the space. And so, to make a very long story a bit short, is that if you, the definition given by Lodge, Turmer and Villani independently of for this CDKN conditions, the following one, so if you have K and N are two real numbers, so they Area numbers. So they both will have to play the. So this capital K will play the role of the lower bound on the Richie tensor and capital N, the upper bound that I mentioned here. And you see actually that capital R can even be non-integer, non-natural number. And they say that your metric measure space, so this would be a tribal, XD, complete and separable, M radon measure. So you will say that it is a CDKN space if and only if. space if and only if the entropy un so this one is u n so this capital n it's uh entering here is the definition of this of the choosing of the entropy function un this one has to be k convex again here i'm i'm a bit not very precise but this is uh on purpose so we will i will say a little bit more later so for let's say that for the moment we just think about k equal to zero and is k convexity just convexity Convexity. So this is the classical convexity. This function has to be convex along this the vastest tangent geodesic, the vastest and geodesics. So it has to be convex along geodesics in P2. And okay, so I will maybe say a few words a little bit later about this, what happens in the case where, okay, no, let's say something here. So in the case. Let's say something here. So, in the case n is taken equal to infinity here, this k-convexity just means that as soon as you check, you evaluate your entropy function along Basestein geodesics, then you can make two derivative distributionally. I can just say that this two-derivative has to be larger than k. So, in the classical sense, so k convex just means that the second derivative is larger than k. In the case where k in the case where when n is uh is finite it's not infinite then you have to make some uh somehow a comparison with what happens on the on the space form of constant dimension n and constant sectional curvature having richie curvature exactly equal to 2k so just to make a short summary so here you have somehow a very strong interplay between options Very strong interplay between optimal transport, that is the one giving you the language. You have the entropy, there are these functions that you use to check to control the curvature. And somehow the message is that if you check the convexity properties of the entropy functional, if the entropy function is more convex, the space is more positively curved. To make just a simple To make just a simple remark, so if you have, for instance, in the C D 0 and case, this just means that, let's say that you fix mu 0 and mu 1 to probability measures, you have mu t going from one to the other. One, if you think, you can just think about this very silly picture. So you have row zero here, row one here. There is behind a very strong description, a very, I mean, a long story about you can in which way you can describe the vastest and geodesic that. The vast esting geodesic, that here there is no time to review. So let's say just that you evaluate along this vastest angel, the entropy, you still know that this one has to be absolutely continuous with respect to the reference measure. So let's call this density rotive. And then what you have to, sorry, what you have to impose is that this is that the entry, the n entropy function has to be convex, so because of this minus n in front, this just. Minus n in front this just turns out to be these very simple inequalities to this rho t raised to the one minus one over n has to be somehow concave with respect to these initial values okay so this is the definition for this C D theory and so what is the main properties that one should keep in mind when thinking about this condition is that this one is Condition is that this one is a definition for Ricci curvature bounded from below by k and dimension bounded from above by n in an intrinsic way, so you don't have to so it makes sense for any metric measure space. And as I said before, the more the function is convex or along geodesics in P2, the more the space is positively curved. And it also enjoys several nice properties. Nice properties. So, the first one is that it is consistent. So, it means that if you have a weighted Riemannian manifold, so Mg, and then you consider as a reference measure the volume measure tens of density. So, it is exactly the setting of Back Free and Emory. Then, this tribal, seen now as a metric measure space, means that as a distance, you take the distance induced by the Riemannian metric. Then, this one is. Then, this one satisfies this CDKN condition by Lot, Sturm, and Delany, if and only if it satisfies the CDKN condition by Bakri and Emory, meaning that these generalized and rich tensor, depending also on the weight that you put in front of the volume measure, is larger than capital K. So, this is indeed a generalization of the Backfree-Emory construction. Let me also just Let me also just maybe go directly to say that it is stable under measure-grown of convergence of metric measure spaces. So, this means in particular that it also partially addresses the question posed by Brahma for understanding the geometry of rich limit spaces. So, this means indeed that if you want to think about examples of spaces. Think about examples of spaces falling within this CDKN theory, what you have manifolds just with the volume measure. So, as I probably just take mg, the volume measure, with lower bounds of each curvature, one by k, so in the classical sense. You have also Alexandrov spaces, but you also have Normat spaces and Finsler spaces, and limits of these spaces in the sense of metric measure spaces. Spaces. And also, let me mention that this theory also arrived somehow after many years of studying the behavior of certain functionals along the bus stand geodesic. And so, let's say what is called now the displacement convexity, that is, this notion of convexity along bus stand geodesics that was a Geodesics that was firstly introduced by Meccan. And prior to this definition of Lodge-Turmond-BÃ©leni, already a few functional and geometric inequalities were addressed by using the vastest sense space and this notion of displacement convexity. And somehow, these streams of ideas coming from Cordero-Raskan and Schmucken Schlager and Mecca arrive. And McCann arrived also within this theory and somehow permitted to prove many functional and geometric inequalities somehow right away after this definition of CBKN. So there are a list of geometric properties that are really very straightforward corollaries of this definition. And here I can mention the Brun-Minkowski inequality that is relating the volume of the set of intermediate points. Of the set of the intermediate points in terms of the volumes of the initial and final points of two sets. You have immediately also the Bishop-Grommer volume growth comparison theorem, and you can also bound the diameter of the space in the case of the lower bounds K to be strictly positive, and you exactly obtain the generalization of Bonne-Mayer's theorem. So, let's say that you have a certain amount of. Sorry for you, yeah. Sorry, Fabio. Yeah. Is it okay to ask a question? Sure, sure. So, in the previous slide, about the Reni entropy and. Sorry, I guess it's the previous one from this one. So what's the relation between the Rainy entropy and the Shannon entropy? Is it like when you take the limit, when n goes? Yeah, yeah, when you take the limit, you actually arrive at the Shannon entropy. Yeah, indeed, also, there is also other properties. There is also other properties to say here about this CDKN condition is that they are somehow ordered in the right way. So if your space satisfies this CDKN with finite n, then it immediately verifies C D K infinity. And the same ordering holds also for with the lower bound on the Richie curvature. So if your space satisfies C D K1n, then it's also satisfied. n then is also satisfies a C D k 2 n with k 2 higher than k1. So it goes in the in the right direction. So in this sense un approaches from below u infinity when when n goes to infinity. Oh okay thank you. Yeah this is one is actually not precisely the definition of Lot and Villany. They were considering Considering a much larger family of entropy functionals, exactly those ones arising from the works of Meccan that was considering, it was studying somehow the most general form of function that are displacement convex, meaning convex along the vast tanges in a Euclidean setting. So they were somehow taking into consideration a much larger family of entropies. Larger family of entropies. This presentation sticks to the approach of Sturme that realized that it's enough to characterize CDKN just in terms of one entropy function, and this one it's a UN. The two approaches, I think, are not exactly equivalent, but somehow now it's just taken for granted that you just take this UN as the one that for the definition of CDKN. Okay, thank you. Okay, thank you. You're welcome. Yeah, obviously, feel free to interrupt me whenever you want. Okay, so you have good properties, stability, consistency with the classical lower bounds, and plenty of examples filling within this theory. And so now my Let's say that we have introduced a little bit this class of metric measure spaces having these entropy functions that are convex. I just want to move a little bit to more final result. I have, so the idea is just not give you all the details on one particular result, but just to say a few things on a few selected themes. So, first, So, first, I will spend a few words about two geometric results. The one that I have in mind are just the stability with respect to the group action. Actually, Fernando already said quite a lot. So, maybe here we can go a little bit faster. Then there is one property that is called the local to global one. So, it means that this property, this TDKN property, and just the fact that if you check it locally on a space, then you can say that the space. On a space, then you can say that the space globally satisfies this condition. And then we will move a little bit to functional analytic properties. But anyway, so here I also want to say that one leading example for this CDKM condition, a very easy example, is the metric measure space that you can obtain by having Rn with any norm and with the both. norm and with the uh with the bone with the leb measure so this tribal with n so we would stress again here any norm satisfies this cd0 n condition so uh so my here means that you can put as a unitary ball any convex norm that you want so this means that this theory is actually maybe even too general so so the result that we will see are actually not very general so in as i um in in as a as a side effect you you you you will see you will not be able to get very fine results so that it's for instance the one of the motivation for uh somehow refining the theory to uh restrict a little bit this class of spaces by devising this RCD condition so for instance one of the classical open questions here there are no results about the infinitesimal structure of these spaces so if you make the blow up of one point and not solve the metric And I'm not so often metric. So far, there are no results about the structure of this limit tangent space. Okay, so let's start with the state of the art and some of the final results that you can say, that you can obtain. So here, we already know that if we If we have a metric measure space that verifies this CDKN condition, then its group of isometry is a compact leak group. And here, so the setting is the following one. So we can assume for this reason that G is a compactly group and it acts by isomorphism. So it means that if you, for any element of the group, the left translation will be a measure-preserving. Translation will be a measure-preserving isometry. So, this means that it preserves both the metric whenever it acts on both things. So, this is the classical thing for saying that it's an isometry, but also the push forward of this map from X into itself also has to preserve the measure in this sense here. So it means that the push forward of the measure M has to be also the measure M and then you can And then you can take the, you can define, as we have seen, the quotient space, so the space of the orbits, and you can associate the quotient map. So to each point, you just associate its orbit. And in this way, you can also define a quotient measure that it's just obtained by taking the push forward of the reference measure to the quotient space. And you can also define classically the quotient metric by just taking the inf among all the orbits. inf among all the orbits between between the among the element of the of the orbits. So in this way what you have is that x star, d star and m star will be another metric measure space and I think this is very very nice result by Fernando Kell, Mondino and Sosa. They proved that if XDM is essentially non-branching, now we'll tell you what this non-branching means and satisfying. Non-branching means and satisfies these lower bounds on the Ricci curvature in this generalized sense, so it's CDKN, then the quotient metric measure space again will be essentially non-branching and satisfies the CDKN condition as well. So as we have seen, the quotient might fail to be a manifold. And so the very nice things of this theorem is that actually says that if you This theorem is that actually says that if you enlarge the class of space that you allow to be metric measure spaces, so the lower bounds in this generalized sense are preserved. Concerning this non-branching condition, so if you just forgot for one second about this essentially, so this non-branching means indeed that if you have two geodesics, they so let's say that a geodesics cannot have a branch-like structure. So minimizing geodesics cannot just Geodesics cannot just so two minimizing geodesics cannot coincide on a non-trivial open interval. So, if they coincide on an open interval, then they have to be the same, the same geodesic. And okay, so this class, it's closed, so this class of C D Kn of C D spaces closed under the quotient of the action by isomer. By isomorphism. And another, I think, nice result about the geometry of this CDK cognition. It's about the local to global property. So this one has to be understood, as I said before, as a condition for controlling the curvature bound, the rich curvature bound, and the dimension upper bound. So in principle, this one has to be something that you can check logically. This one has to be something that you can check locally. So, in principle, what you would like to say is that if I am able to check this condition locally, then we would like to conclude that the same property is verified globally. So, this is the so-called globalization problem. And the local version of this condition means that for each point x, you take a neighborhood on the space. And what you would like to check is the k-convexity of the entropy functional un. Functional UN inside this neighborhood, meaning for all the vast extent geodesic connecting to reference to measures having support within this small neighborhood. And so you would like to say that if you're able to check this condition logo, then you can pass to the global condition. If you just think about this plane convexity, as we said it before, so it means that you just have k-convexity, no distortion, nothing. Convexity, no distortion, nothing, then this question seems to be very innocent and very, let's say, easy to get. And indeed, in the trivial cases in which this strange behavior of this distorted convexity, it's trivial, means that in those cases where k over n is equal to zero, meaning either k equal to zero or n equals to infinity, then Infinity. Then Villani proved that this was indeed the case. Then there was somehow a counterexample to a Villany conjecture in the more general case, where Villani conjectured that somehow this property can be reduced to a one-dimensional inequality for a certain function. And this was disproved by Deng and Sturme. And actually, then a few years later, Tapio Rajela managed to build a counterexample to this. Managed to build a counterexample to this property, assuming actually the space to be non-branched. Sorry, he managed to construct a metric measure space that was highly branching, so with branching-like structure. And he managed to prove that locally, if I remember correctly, it was satisfying a CD04 and no CD0, whatever condition valid globally. Whatever condition valid globally. And finally, myself, together with Manuel Minman, we managed to prove that, again, within this condition, with this central and branching condition and with finite total volume, if you assume also your support measure to be a length space, so you wouldn't like to have strange things, I mean two disconnected things. If you can check that your space If you can check that your space is CD locally, then you can conclude that the space is C D C D globally. And okay, so this is another maybe geometric properties that it's something that you would like to have for a curved condition. And I actually don't have in mind any other geometric result for this C D condition. So I skip to the, let's say, more. To the, let's say, more gener. I mean, I now move to describing what you can say about the geometric inequalities that you can prove. And that's if you want another way to describe the geometry of the space anyway. All the inequalities that you usually prove in this setting are inequalities in the spirit of comparison geometry. It means that in principle, what you would like to do, you would like to check that. That some functions behave a little bit better than what happens in the model space of a constant curvature exactly equal to k and dimension and with the same upper bound dimension. So my idea was to just quickly review a classical function in geometric inequalities that is the isoperimetric one and more or less the approach. And more or less, the approach to the other inequalities works more or less in the same manner. And okay, so what is this Levy-Bromov isoperometric inequality? Again, I think here everyone is familiar with it, but I will nonetheless say a few words just to introduce the inequality. So, in the classical setting, as I said, this was firstly proved by Levy in the case of the Of the uh of the sphere and then generalized to any other Riemannian manifold with a lower boundary richie curvature by Gromov. And it says that if you have a Riemannian manifold with a positive lower bound rich curvature, this capital K, so reach larger than K times G, with K strictly positive, and if you have a domain with smooth boundary E inside your manifold, then the Levy-Gromov isoperometric inequality asserts. Levi-Romova is the perimetric inequality asserts that the size of the boundary of your region E, so this one is just the size of the boundary of E, re-normalized by the total volume of your manifold M. So this quantity here has to be larger than what you will have on the round sphere with Ricci constantly equal to K and B the spherical cup with having the same renormalized volume. Renormalized volume. So, what it means: it means that what you do, you move to the round sphere, that will be your comparison space. You take a spherical cap, so it means symmetric ball B, having exactly the same renormalized volume of your region E. So the volume of your region E divided by the total mass of your space M has to be equal to the spherical cap divided by the total mass of the sphere. And if this is true, so if you take this comparison. This is true. So, if you take this comparison, then the size of the boundary of the size of the renormalized boundary has to be larger than what happens on the sphere. So, this one is the celebrated Lebigram of isothermometric inequality. This one again was then generalized by, I mean, there was plenty of contributions for these inequalities. It's been generalized in many settings. Here, just for a matter of time, maybe I just mentioned the work by Emmanuel Millman that generalized these. Emmanuel Millman that generalized this inequality to with a simple approach to any range of k, so also with negative k and also actually maybe with negative dimension in a certain sense and also to weigh the Riemann manifold. What he proved, he proved that if you if you let's say that we just state this theorem by making the compare by introducing this function. By introducing this function here that is called the isoperimetric profile function of your space. So, this one is I, depending on your space MG and the reference measure M, of a certain volume V. This one is just the least amount of, let's say, boundary measure that you need to enclose a certain to enclose the volume V. So you take the minimum among all the regions having Among all the regions having volume exactly V. So M measure exactly V, and you take the other Minkowski content. So the other Minkowski content, how this defined? You just take your region E, you make an epsilon neighborhood with respect to the metric G. So you just enlarge it of epsilon. You take the measure M and then you take somehow the derivative of this function. So I mean just you subtract the mass, the initial mass. The mass, the initial mass, and you make the divide by epsilon, and you let the epsilon go to zero. So, this is just a more simple way to describe the size of a boundary of a set E, even when you do not have the necessary smoothness of your domain E. And what proved mean is that there exists a function i depending on these three parameters. K is the lower bounds on the Ricci curvature in the generalized sense. Generalized sense. So, and n will be the upper bounded dimension, and capital D will be the upper bounded diameter. So, there will be this function here such that if your Riemannian manifold, the weighted Riemannian manifold satisfies the CDKN condition in the Bach Riemory sense, with diameter bounded from above by D, then what you have, you have that the lower bounds, that the isoperimetric profile function of your manifold is bounded from below by this function. Bounded from below by this function here, depending on only these three parameters. So, this looks very already written out to be generalized to our setting. And let me maybe first do a few comments. So, in the case in which the lower bound is strictly positive and the upper bounded dimension is an integer number, and one exactly reobtains the Levy-Gromov isoperometric inequality. Indeed, in this case, Isoperometric inequality. Indeed, in this case, this function here, I KND, is just exactly the isoperimetric profile function of the round sphere with the volume measure renormalized by the total mass of the sphere. So, in this generalized sense, you just have, so in this strictly positive k, you just have one model space to which you would like to compare. And actually, in the negative case, there is not just a single model. Case, there is not just a single model space. Anyway, it's somehow there is an explicit model isoprometric profile function. And for each choice of K and D and volume, you have a different model space. But nonetheless, you can always make a comparison with a model space. And so now there was a natural question to understand what happens in the CDKN space. To understand what happens in the CDKN space, and actually, me together with Andrea now a few years back, we managed to generalize this theorem. We indeed prove that if your metric measure space verifies the C D Kn, then the same Levy-Romova superimmetric inequality holds. Again, you have to assume also that the diameter of the space is bound from above by a certain number d. Then the lower bounds for Then the lower bounds for the isoperometric profile function of your metric measure space verifies the same lower bound. So the same function here, I K N D found out by Emmanuel Milman. So whenever you allotch your space, so your set of admissible spaces to this metric measure spaces verifying the CDKN condition, nonetheless, the lower bound doesn't get worse compared to what happens on with. Compared to what happens on weighted Riemannian manifold. And actually, as you know, the Levi-Gromov isoperimetric inequality has a rigidity counterpart that here I was not mentioning. It means that if you have for some reasons you know that there is a region on your manifold M attaining the identity in the 11-Gromov by superimmetric and you put it and this is a result by Gromov, then you're By Gromov, then your space has to be isometric to the round sphere. And here, actually, we were not able to produce the same result here because for the CDKN condition, as I said after the introduction to this definition of the CDKN condition, it's very large, so it's not sufficiently strong to force the rigidity at the level of the metric. At the level of the metric, the things that you can manage to obtain at this level of generality, that the measure somehow has to be a weighted, let's say the measure has to be a spherical suspension. So as to have the same structure of the volume measure that you have on a spherical suspension. So it means that it's somehow a product measure when you make collapse the South Pole and the North Pole in this sense here. But you cannot get at this level of generality a rigidity in. At this level of generality, a rigidity in terms of the metric. So you cannot conclude that if you have a space that is CDKN and gets the equality in the Levy-Grommer by superimmetric inequality, you cannot conclude that this space is isometric to the round sphere. And as I was mentioning before, many geometric and functional inequalities can be obtained following Following one single approach here, that is the main approach that you use in this CDKN business, that is the one coming from convex geometry, and it is called the localization paradigm. So again, here, this localization paradigm, it's a technique that has a very long story, and we just give the last contribution to extend this approach to. To extend this approach to this metric setting, but it has very great people devised it much before us. So it actually, the first people, so let me first say what is this localization paradigm and in which way we managed to obtain, to apply it to the isoperimetric inequality. So the idea somehow is to reduce your problem, your full-dimensional problem to a family of Many of, in principle, easier to solve one-dimensional problems. So, this is actually seems to be a very ambitious approach, and maybe even hopeless, but actually, there was a very nice way of obtaining this dimensional reduction thing. Then it goes indeed by optimal transfer again. As I was mentioning, so this dimensional reduction approach was first devised by, I think, the first people who did it was were People who did it was Payne and Weinberger to find a lower bound on the first Laplacian eigenvalue for a convex domain in the Euclidean setting. But then it was, let's say, developed by Bromov and Vitaly Milma and then was popularized by Carnon Lovats and Simonovic among the computer science people. And they obtained this very general method to apply. Method to apply, let's say, very general recipe to apply this localization paradigm that is called Fur functions theorem. If you google it, you can find in their paper, it's somehow the most general form of inequality that you can prove with this method and actually contains plenty of function inequalities. And somehow, let's say that for these people, they just worked in the Euclidean setting, then there was this breakthrough by Boas Clartag. By Boas Clartag, then realized that actually this dimensional reduction argument can be pushed to remain manifolds by using optimal transport. And finally, me and Andrea, we managed to extend it to the non-smooth setting by somehow finding a different proof on the one of both. So, but now just say what is localization paradigm is. So, the idea is the following one: you take this constraint to be a function f. Trained to be a function f having zero mean. So you take this function f to be defined on a metric space. Again, we always assume non-branching to avoid pathological situation. And what happens here that, okay, you also assume the space to be to verify CDKN. So what you can prove is that you can somehow divide your space into two regions. So this X can be split into this joint region. One is called Z, another. This joint region, one is called Z, another is called this T, capital T. And which properties do they satisfy? So, the first thing that you know that over Z, the function f is equal to zero almost everywhere. So this one, so it's just a subset of where f is equal to zero. And over t, what you have is that this one can be admits a partition of one-dimensional object this x cube that are just isometric to a geodesic. Isometric to a geodesics. So, actually, they are unparameterized geodesics. And what happens happens that this foliation also gives the composition of the measure here is a bit technical. So, let's say this is called this integration, but this means just that the measure M, the reference measure, once that is restricted to, so this strange symbol here means restriction to the set T. This one can be written down like a decomposition of one-dimensional measures, this MQ. So, this. Measures this MQ. So this MQ, they just see what happens over this one-dimensional element of the foliation of your space. So this MQ of XQ is equal to one. So these are probability measures are just concentrate over this XQ. And this measure Q here is just giving you, telling you how much weights you should put on each single element of this decomposition. Okay, so this one is just there is no localization, nothing. You have not done nothing. You just Not done nothing, you've just done a decomposition and then a consistent disintegration. Then the first thing that you localize is the constraints. So the function f that was previously having zero mean globally now has zero mean along each of these unparameterized geodesics. So you have localized the constraint and then you also localize the curvature. So this one-dimensional metric measure space, so XQ, the distance D, because XQ is. The distance d because xq is the it's an unparameterized geodesic, so this means that d is still a geodesic distance over xq that's just isometric to the modulus on an interval. So this and then you put FQ. This one is a CDKN metric measure space. And somehow what you can do, you can somehow, once that you obtain your inequality that you would like to have on this one-dimensional level, you can just then take it back to the to the full to the full to the full measure and okay let's just say that here now maybe it was just I don't have enough time to to let me just skip few things so this was just anyway the general approach to many function inequalities on the CDKN spaces you run you have a constraint in the case of the of the Levi-Gromov isothermetric inequality here this function having Inequality here, this function having zero mean is just the characteristic function of your set E minus a constants that make it to have zero mean. In this way, somehow you localize the constraint of having a certain volume to the same to one dimensional to the one-dimensional family of spaces. In this way, somehow once that you make the trace of your set E intersected with this family. E intersected with this family of one-dimensional object, what you get will be a one-dimensional subset, again, of the same volume of the starting one. So now it's a bit sketchy, but let's say that this is the general scheme. Now let's arrive to Javier, maybe just a quick question. Is it possible to have a localization scale? Localization scheme, but equivariantly, like say you have a group action, and then can you make it so that the partition is by invariant subsets or something like this? Well, I don't know. It's a good question, but well, actually, the problem is that in principle, this family, this foliation. This family, this colliation that gives you the localization is very wild. It's not very well behaved like what you would expect on the orbits of it's not in principle. So let's say that this measure Q, also that is that it's the one that you have on has to be understood as a measure on the space of orbits. Again, also for this one, it's in principle you don't know nothing. it's in principle you don't you don't know nothing you you cannot say that it verifies some uh some regularity properties in terms of uh rich or whatever so the short questions that i don't know uh but in principle i mean with this approach i guess no but maybe it would be interesting maybe there are some other ways for uh for um for proving it so let's For proving it, so let's say that in the smooth case, in the smooth setting, the fact that this one-dimensional object verifies still verifies the CDKN condition comes from the fact that the defoliation comes from the L1 optimal transfer problem from the positive part of the function and the negative part. Because you can measure the positive part. So the positive since the function has zero mean, you can study the optimal transport problem. You can study the optimal transport problem between the positive and the negative one. Then you use the structure of the vastest angelesics that they go, they follow the X, let's say the Vases angels can be written using composing the exponential map with the gradient vector field of a function that has the nice properties. And there you have to write down the Riccati equation for the differential of this map and use plenty of. Differential of this map, and you use plenty of good properties for the optimal transport thing. So, in principle, I think that maybe you can get to localize the zero mean, but for the Kurvado condition would be, I think, hard. But it would be an interesting thing to do to check. I don't know. The answer is that I don't know. Right, thank you. Can I boost up? So, I completely agree with the. I completely agree with Fabio Z. One more thing to add. So, using that when you go to the quotient space, so if you are CDKN and region branching and you quotient, you are still CDKN region branching, you may hope to do the localization at the level of the quotient space. So, if the problem say, but this really depends on the problem that you have in mind, this would be something to try out. Okay, yeah, yeah, definitely. Okay, yeah, yeah, definitely. I'm sorry, but isn't there a problem with the distance on the portion space? Necologically speaking, sorry, I have the camera off. I mean, which distance would you put there in principle? Here, yeah, on the portion space. So, basically, you are putting the distance on the orbit, and I mean, it says it's a indication. I mean, in principle, it could also be identically zero, right? I mean, for all we know, actually, there are examples where it is zero, right? Like the cone, and you localize a lot. The cone and you localize along the radius of the cone, right? Yeah, yeah, I mean, yeah, sure, sure. I mean, it uh, I mean, it is just a recipe that sometimes may give something interesting in general, may not, but something to try. I don't know. Well, I see, I see. I mean, there are geometric issues. I mean, before, I mean, it's not even clear whether the geometric space is uncentered before CBKF. That's what I mean. Yeah, that's what I mean. No, no, no, no, no, no. So, the point is that so, what we proved is that if you have an isomatic group action given by a compactly group. Yeah, yeah, this, I know, I know, I know your result. I'm familiar with the result. I know, but perhaps I misunderstood Jesus' question because it was under the microphone. What I was commenting on, and I was commenting more to Jesus than to you, and Fabio, was the existence of curvature dimension bound on the On the sense, on the space Q, I don't know how to call it. This is very hard. I mean, I was answering to that question. I'm not sure if perhaps I misunderstood the point. Anyway, I think we agree. Yes, I agree. Okay, but actually, I think my time is over, also, my talk, so I think that now there will be the The there will be time so tomorrow for Daniele talk to speak about the overview on the RCD part. So let's just say that I was mentioning before here, maybe just conclude here that let me conclude with this slide. So you have at this level of things, you have many open questions. So it means that for me, at least from my point of view, here in the CD theory, it would be nice to have Be nice to have some information about this infinitesimal structure that so far is missing. And indeed, possibly using this result on the quotient by the action of a Lie group, possibly you can hope to get something, but so far there was no progress in this direction. And yeah, so I was mentioning before, so the point of making the theory a little bit. Making the theory a little bit more finer, let's say to rule out this example so that you can put any norm on Rn that it verifies the C D 0 n condition. These things, it's a bit too general. And then there has been a long list of contributions to address this problem and finally arrive to the RCD KN condition. And I think tomorrow. And I think tomorrow we will see more on that. So, yeah, that's all for my. Okay, thank you very much, Fabio, for this very nice overview on CD annualization and results. So any questions for Fabio, in addition to the one that we already had? Yeah, I have one that has to. So you mentioned that. So, you mentioned that a lot of the examples that come out for the C D D K and condition are limits in the Gromov House or topology. Are there known examples that cannot arise as limits? Yeah, I think this is also true at the level of R C D. You should, I think this was observed by now. I don't remember who was exactly the guy who observed it, possibly also Andrea and. Possibly also Andrea and the topping, and I don't remember. Yeah, okay. That if you uh construct, what was the example that you construct a cone over RP2? No, what was it? Yes, yeah, yeah, yeah. The point is, you have a take a cone over RP2, then this is a three-dimensional RCD space with non-negative riching of dimension three, but it is not a topological manifold because. But it is not a topological manifold because it has a topological singularity at the tip of the cone. But it was proved by Simon in the compact case and Simon Top in the non-compact case that rich limits of dimension three, non-collapsed, are always topological manifolds. And so if the question is, can you, so is it true that the conover RP2, which is a three-dimensional space, which is RCD03, is a limit of Is a limit of three-dimensional manifold with lower bound on the rich sheet. The answer is no, because it would need to be a topological manifold, but it is not. Okay, but still could be the limit of a collapsing sequence in dimension. Yeah, right. So, but yeah, it depends the question that you have in mind. So, if your if your question is uh, it should have any RCDKN are spaced. RCD Kn are spaces with lower bound under each by K and dimension bounded above by n. So if your question is, is it true that any RCD Kn space is a limit of many, of wood manifold with a reach boundary below by K and the machine boundary above by N, then the answer is no, and this is a counterexample. If you ask, is it true that any R CD K n space is a limit of many fold with or bound on the rich, but not per bound on the dimension, then it is. The dimension, then it is not. This is not known. Yeah. Okay, thanks. Okay, I'm here. There are no more questions. Okay, so then let's thank Fabio again. Thank you very much, Fabio. Thanks to you. 