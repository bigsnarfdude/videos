Toys. Of course it is. So without further ado, I'd like to welcome, we're on to the contributed part of this session, sort of building on the analyses and abstracts that have been collected for the seats fish data that GC so beautifully presented. So the first talk we're going to have. So, the first talk we're going to have is by Alexis Colomb. And I will ring my kids' toy at five minutes before, and a two-minute warning as well. So thank you so much. Okay, so thank you all for being there. And most of all, thank you, thanks to all the organizers because I'm very excited about this workshop. I think it's going to be a very interesting week. I mean, it would have been even better to meet you all in. Would have been even better to meet you all in person, but hey, I introduced we have the PRNA and I succeeded to mana to share my screen, so this is gonna be great. So the challenge. So we have two data sets, single cell RNSSEC and SECFICH in the most visual cortex. So you just had the talk, so I won't detail that much further. So there were three Three proposed questions like can we overlay single-cell NSEG data onto a segfish, or what is the minimal number of genes needed for data integration, and can we other signatures of cellular collocalization or spatial coordinates in unspecial single-cell and a sing data? So I had a very data-oriented approach. So first I So, first, I checked quickly for the distribution. So, indeed, the data made available for this challenge were already processed and very well. But just to notice, there were like three main kinds of distributions, like nice simple Booleans, also some nearly normal distributions, and with a lot of minimal values. Minimal values. So I wonder whether it's due to dropout, technical dropout in the simple seller and SSEC process, and then also a bimodal distribution. So it wasn't necessary to process further the data, but I just wanted to check for sanity. And with different transformations, you can see that you don't change Much the repartition of phenotypes, detected phenotypes in TASIC and TOL in the UMAP projections. But when you use other data transformation, you can have some artifact like the center logistic transformation. It will transform any kind of distribution like that, or like this one, or even this one, into two peaks at the minimum and the maximum value. Value. So I just thought that I should be very careful when using data transformations. So then in the first try for the submission, for the challenge, I actually use the same model as in the SegFish publication, so super vector classifier, in a supervised task. So I use So I use the single cell RNA-seq data, single-cell RNA-seq labels as the gold standard and I trained and evaluated the model on the same datasets. And so for the submission some months ago, I was pretty happy because I had relatively high accuracy, like 90%, but two weeks. But two weeks ago I did again I ran again my code and I said oh maybe I should actually use the balance accuracy and then all the score dropped down so I was pretty horrified so I spent some time to look into different hippie parameters and what happens on different accuracy scores. So with the with the So, I used a kernel supervector classifier. So, I was looking for the two hyperparameters, T and gamma. And here you have the map of the best hyperparameter pairs, with in red here the best with the five-fold cross-validation. And with the linear super vector classifier as used in TASIC. As used in a TASIC as used in a zoo and all, in the self-fish paper, you have the paste per parameter around the hair. But when I used so when you look at the simple accuracy, you can see that you actually overestimate a lot the performance of your model. And also, more importantly, maybe that actually your repair parameters, your best repair parameters are shifting. Best superparameters are shifted for the linear supervector classifier. The L C is much higher. And also, here, when you look at balance accuracy, you see that you have to shift your hyperparameters. So, in order to know what was the minimal number of genes to be able to classify cells in safe feed data in Cells in the safe feed data into different cell types. Then, so I did a top-down elimination of variables in a very brute force way. So, from the original 113 genes, I tested successively each gene, and for each gene, I discarded, then I test and train the classifier, and I dropped the And I drop the genes that, when discarded, elites to the best score. And then I update the set of variables of genes until I reach only one gene. And I got this kind of curves. So what is funny is that actually, when you look at the balanced accuracy for the kernel supervector classifier, you have even a you have even a better balanced accuracy when you eliminate enough genes. So maybe because the other genes bring too much noise in the data for the classification. So and here you keep only the most informative genes and your model is more robust. Yeah, I have time. So then when I thought I will keep only 19 genes, although I could keep a bit more to have a slightly more accuracy. But I kept only 19 genes and with the classifier, then you can predict the cell types on the secfish data. And these are the The counts of each cell type. So, this is why, with the simple accuracy, you overestimate the performance of your model because the data set is highly imbalanced. So, when you it's completely it overestimates the performance of your classifier. And for the spatial analysis, so the question is: how can you define spatially coherent Define spatially coherent areas. So, we are on a team, I mean a team where we do a lot of network analysis. So, I thought I would use some networks. And to define a network from those coordinates, I use a Rorano It selection. So, it builds virtual cells. And when cells, these virtual cells touch each other, we can draw edges between them. But the issue is that you have a lot. But the issue is that you have a lot of artifacts like that due to geometrical due to border effects. So you just have to use a distance threshold and you get rid of these artifacts. Sorry for the changes. So then once you have your network, so what I want you to do is to aggregate aggregate the signal for each note aggregate the the signal of its neighbors so for instance for the first neighbors if this is the cell of interest I will take into account those cells and I will stack all the gene expression data so I will have four lines of gene expression data because I have four cells and then I will compute the mean I will compute the mean and, for instance, the standard deviation in order also to have a view or to take into account the variability of a gene in the surrounding of a cell. But you could think of another statistic than the STD, or also you could take the median, for instance. So when you aggregate for aggregate for when you do that when for each cell you aggregate gene expression data and you compute for each aggregate gene stack the mean and the standard deviation then you can project this data with a UMAP for instance and this is the kind of map you you obtain so I tested several clustering algorithms and actually HDB scan HDB scan HDB scan, HDB scan was the war was the most relevant, was the better one. Optics always found too much noise. That's what you can see in grey here. So for instance, so there are many configurations possible, but for the first configuration I tried, like I was aggregating data from Aggregating data from the first neighbors only and with a given configuration for the UMAP projection and HDB scan. I had this pattern. I mean, this is the UMAP projection of the aggregated neighbor's data, and HDB scan detected those clusters. But for several other configurations, I had this spot around. Spot around a bigger area. So we will see that further. So you can also aggregate data for second, third, and even more higher order neighbors. And also you can, so instead of performing the clustering on the two-dimensional UMAP projection, you can perform the clustering on three, four, or ten-dimensional 10-dimensional space of this data, and that will allow ADB scan to detect and to fetch much finer structures. And you can increase the mean cluster size in order to have larger areas in here and in the spatial map. So I told you for different configurations, so either the number of neighbors or the number of dimensions in which you perform the clustering, for instance, you often had this spot that appear. Also, this area, for instance, but it's just because they are very uniform cells relatively. So I wonder why were we detecting of Where we detecting often this cellware. So I wanted to use a scanPy that is a Python library developed to perform a single cell analysis, but I had some computational issues, so I had to do some homemade differential expression analysis, but it's not differential expression because we are not looking at genes, we are looking at variables that are standard. Variables that are statistics on aggregated neighbors' data. So that's not genes. And the most statistically relevant variables were, for instance, those ones. And I will just look at the time I have. Okay, great. And so if you look at their meaning, so you have some genes that tell you that what you're writing. Tell you that what you are looking at are neural cells, so that's good for us. But also, many genes seem to show that this area is involved in something like stemness or regeneration. So, you can see here required for melanation, axon regeneration, plasticity, embryonic development, development processes, etc. So, maybe this part when you So maybe this part when you do the differenti um expression analysis compared to to the surrounding area, when you do that you find that it's more involved in the regeneration. So I think I'm good in terms of time. So yeah, what I would say is that be careful when transforming your data. Also, code review is so important. Is so important. This week I had to rerun the analysis multiple times because I had some typos or more fundamental errors. So I think it's really important for all of us to implement some quick review with colleagues. So it's possible to infer cell types with only 19 genes. I use the network bag aggregation of neighboring cell gene expression data. Sorry, I'm talking a bit fast. Talking a bit fast. So you can use different metrics to capture the global tendency, so mean, median, or mode, and to capture the variability, so either the STD or some more robust metrics like quantile-based matrix. And we obtained some specially covariant areas, and I could perform a kind of Kind of differential expression analysis. So, actually, what I didn't do, I realized it five hours ago, is that I didn't develop the model to map single-cell RNA-seq data onto the segfish data. For that, you will need actually some kind of a mutual put regression model. So, I think the next speakers will talk about that. So, I'm really excited. Speakers will talk about that, so I'm really excited about that. Tech, tech, tech. Yes, so I think that network-based aggregation and clustering could reveal specific cell states, not only types. And personally, and in my team, we would like to apply that for larger tissues, like in tumors with higher-order neighbors. And maybe with decreasing weights, when you increase the second, third, or fourth. Second, third, or fourth neighbors, in order to detect larger areas and larger buttons. What could be interesting is to optimize the clusterization by doing the optimization jointly on the spatial space and also on the UMAP projection of the of the attributes. And I'm very curious about what And I'm very curious about what we would have if we subtract the phenotype contribution in a gene expression data and we rerun the analysis again. Maybe we could have more simple actors that are really due only to the spatial context. But maybe you have some questions. Actually, I have some. I think let's uh switch over to the um questions and um questions time. So, thank you so much for a great talk. Thank you. Um, so uh, we have a few questions. Um, feel free to post. We probably have time for just one or two. Um, so can I actually you rang the bell? Did you rang the bell? Did you ring the bell? Okay, I can yeah. So, one of the first, please put your questions in the chat because we're going to stream them through the chat. Okay. So, the first question is from Kim On and she wanted to know, did you compare your top genes when using balanced and unbalanced classification error rates? Can you repeat, please? Did you compare the top genes that you got when you were using unbalanced versus balanced classification error rates? No, I did. Then I did the rest of the analysis only with the balanced accuracy because the unbalanced was just not taking into account the fact that we had that most of the cells were from two phenotypes and not okay. So for Okay, so for yeah, I had to take to use only a balanced accuracy. Got it. And we probably have time for GC's question before the next speaker. So for spatial clustering, does it matter to use the spatially coherent genes or not? For spatial clustering? Does it matter if you use only spatially coherent genes? I haven't tested that. Actually, I think that what happens is that since when you aggregate, you aggregate by neighbors. Actually, the UMAP has similarities with the spatial map. So it's different. Cells have different positions, but still you have the same order. They are very similar. So you can rotate it. Very similar, so you can rotate it and you have the same order of groups. So, due to the way you aggregate data, you have similarities. Okay, yeah, this is great. Thank you. So, I'm going.