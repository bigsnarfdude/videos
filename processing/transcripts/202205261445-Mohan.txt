Okay, all right. So, thank you for inviting me. I'm pretty excited to be here. So, I'll talk about graphical models and causality for handling corrupted data. So, what do I mean by data corruption? Data can be corrupted in various ways. For instance, you can have missing data, you can have selection bias, you can have interference, like interactions among samples. So, this would actually result in a data being non-IID, and you can have measurement error. So, in this talk, we'll focus on missing data and interference. So, in an Difference. So, in an ideal world, when everybody is very benevolent and happy, they'll answer all your questions and you get this wonderful ideal data set. But in the real world, what happens is, you know, people are reluctant to answer all your questions. So, you end up with corrupted variables, right? In the ideal data set, you had income, but in the real data set, you have a proxy for income, which is corrupted by missing values. So, you can call this proxy. So, you can call this proxy income star as a proxy variable, and M, the red M denotes missing values because this is a missing data set of audience, but still just introducing it. So given this, there are two crucial problems. All right, so the first one is, given a query of interest, obviously we collected this data with the goal of computing some quantity or performance operation on it. So, suppose the quantity of interest is mean of income. All right. And so, given that you know the quantity of interest, So, given that you know the quantity of interest, and given that, given a model, a causal model that encodes both the causal and statistical assumptions about the data generating process, which is a DAG in my case, the question is, can we compute a consistent estimate of the query using assumptions in the graph? So, this also can be called as identifiability. There is a reason there was some confusion, which is why we thought of renaming it as a recoverability. So, in our work, we call it as a recoverability. So, this first part. So, this first part of the question is about whether or not we can compute the, if at all, it is possible to compute a consistent estimate of the query given the assumptions in the graph. The second one is, the question here is, are graph and data compatible? Because you're going to use a graph to talk about data to reach conclusions about the query. So, if the graph and data are not compatible, it's problematic. So, are they compatible? This we call as testability. So, here's our settings. Stability. So here's our setting. We have the ideal world, we have an ideal data set and this wonderful distribution probability over GE and I. But in the real world, you have this corrupted missing data set with proxy for income missing values and this corrupted data set, which we call manifested distribution, probability over GE and I star. Quantities that you are of interest in the mean of income, causal effect of education on income could also be counterfactuals. It could be ratios, anything. Anything. So the main problem, the core problem, is how do we compute the mean of income given that we have access only to the mean of income star, the corrupted variable? How do we go about doing this? Now, if I were to just insist, if it were a classroom, random classroom, and I were to insist, hey, help me compute this, then probably the first thing that you would say is, let's delete all the values, all the rows, get rid of all the samples with missing values. Is this really good? The first problem, and this problem, this is called as list-wise. Problem and this problem, this is called as list-wise division. The first problem is obviously the wastage of samples. Now, let's consider two scenarios. So, missingness is due to the reluctance of people with high income to reveal their income. In this case, income causes its own missingness, right? So, if you eliminate all the high-income people then and use the remaining samples to compute the estimate, you are going to end up with biased estimates. Second scenario is missingness was purely random. So, people just sat flipping a coin, and if it was heads, they answered. In the coin, and if it was heads, they answered the question, otherwise, they just we're not going to answer the question. They chose not to answer it. So, in this case, list-wise deletion would yield consistent estimates. Although with the sample wastage, it's probably going to take a lot of sample set to get anywhere close to the true value. From the two scenarios, what is clear is the underlying cause of missingness. One has to take into account what caused missingness. So, what are the causes of missingness? What are the possible causes of missingness here? It could be that missingness is purely. That missingness is purely random, like we talked about. Somebody just flipped a coin and decided to answer and not answer the question, or it could be that women in the population decided not to answer the question. It could be that the education cost missingness. You know, you probably didn't know how to read or write. And so you didn't understand the question and you just decided not to answer it. Or income cost its own missingness. So, what are the causes of missingness? Now that we know that the cause of missingness is important, the next question is: how can we? Question: Is how can we encode assumptions about the data generating process? So, we're going to propose the use of graphical models for encoding assumptions transparently. And here, I'm going to introduce missingness graphs. All right, so we have this data set, gender, education, and income star. All right, and then we are introducing this RI variable, which is commonly known as indicator. We call it missing this mechanism because we treat it as some sort of a switch. It as some sort of a switch, it goes off, no missingness when it is zero, it's off, no missingness. When it's on, it just makes I star go missing, right? It's sprinkles missing values. Um, in the absence in the ideal world, this would be the graph, right? Gender causes education. So, this is a causal DAG. Every edge has to be read as a the parent is a cause of the child. So, here we are assuming that income is caused by gender and education in the sense that the value of income is determined by the values of gender and education. Values of gender and education, it's a functional relationship. Now, when you have missingness, you don't have I, instead, you have I star, and the value of I star is determined by the value of both I and Ri, which are its parents. So, I star is equal to I if the switch is off, Ri0, and is equal to missing when the switch is on, Ri equal to one. And we use this criterion called deseparation to read conditional dependencies of the graph. So, essentially, what this Essentially, what this says is: every time, every single instance, usually, normally, whenever there is no edge between two variables, then there's a potential conditional independence embedded there. For instance, there is no edge between I and Ri, so I is independent of Ri. It takes a bit of practice to read it, but yeah, in this talk, I would be encoding all, I would be explicitly encoding, stating the conditional independent statement. So, and by independence, I just mean the regular independence, you know, probably. I just mean the regular independence, you know, probability GEIRI equal to probability of GEI into probability of RI. The same thing that we all talk about, nothing different. So there are three categories of missingness, right? So missingness could be purely random, which is called as MCAR. In MCAR, this is a graphical representation of MCAR. What we mean by that is you look at a graph, given a graph, you can immediately tell whether, you can immediately determine the category of missingness. Category of missingness. In the case of MCAR, the R variables will not have parents. So R variables are like random, you know, because the R variable is a cause of missingness and the cause is purely random. So it doesn't have, it's basically not connected to any other variable in the system. So MCAR. The second one is MAR, missing at random. Here, the assumption is that the R variable has parents, but those are fully observed variables in the model. So E can be a parent of RI as demonstrated here, or G can be a parent, or both can be parents. Can be a parent or both can be parents. So as long as parents of our variables are full-ops of variables, we would call it as MAR, missing at random. And the third one is missing not at random. And this happens when the cause of missingness is not observed. So in this particular example, we only have one variable with missing values, which is income. And so income is when you have an edge from income to RI, a parent of RI is a variable with missing values, and therefore this is categorized as missing not at random. Missing not at random. Apparently, missing completely at random is least common, but it is easiest to handle. This is the easy to handle. MAR is easy to handle, but it's pretty unrealistic, but it's one of the most commonly assumed cases. And the third one is thought to be the most common kind of missingness, and it's hard to handle. And this classification is due to journal movement. Due to John Wubin in his biometric paper. So my work primarily focuses on missing not at random, but I will start with a kind of a missing at random example. So again, just a sort of reminder that recoverability deals with, you know, this is a particular question. Given a quantity of interest, some quantity of interest, mean, causal effect, joint distribution can be. Interest, mean, causal effect, joint distribution, conditional distribution, counterfactual, some quantity of interest, and the graphical model that demonstrates the process that generated the data. Can we compute a consistent estimate of the query using the assumptions in the graph? A stands for assumptions in the graph. If it is so, output the procedure. We are not computing an estimate here, we're just saying that this process will yield a consistent estimate. That's it. If it is no, then we will go ahead and explore under what additional conditions. Explore under what additional conditions you can actually facilitate recoverability. So let's look at a simple example. Same gender and income. So I removed the education just to keep the graph small. So the proxy variable is there and you have gender and education. And here is our data set. All right. So the data set is over I star G and R A. So this is all given to us. Now our task is to compute probability of Ig, the joint distribution in this case. All right. And the graph. All right, and the graph, as you can see, there is no edge between I and Ri, and this shows that there is an independence in the graph. So I is independent of Ri given G, and this can this, I read this off the graph using D separation criteria. Now let's look at the recovery procedure. This is the first, I just did a simple chain rule factorization. And then because we know I is independent of Ri given G, that gives us the permission to insert R i equal to zero. permission to insert r i equal to zero. And we know that when r i equals zero, i and i star are the same. So that allows me to replace i with i star. And so now I have an estimand for the query. And look at the right hand side of the equation where every single quantity, every single factor there can be computed from the missing data distribution that we have. So we say that we have established recoverability. And if you want to estimate a particular value, this is one way you can do it. Value, this is one way you can do it, but may it not be the most efficient way. So, but however, this is a so there we have recoverability and here we have estimation. So, in general, so given this problem, you can use the previous technique and then reconstruct the joint distribution like so. So, this we have established a recoverability here. So, the most important point here is that we have actually shown that it is possible to compute the joint distribution using the assumptions in the graph, or the assumptions in the graph are sufficient to The graph are sufficient to allow you to somehow get to the true value in the limit of LAD samples. So, this is a question that we, this is the problem that we looked at. And you can see that we, yeah. So, I will not be explicitly portraying the proxy variables. They don't really, you can actually do the analysis without that. And they sort of clutter the slides. So, we will not be explicitly portraying them. Let's look at a very simple MNAR example now. MNAR example now. So to make this MNAR, you know, the thing, what defines the graphical definition of MNAR is that the parent of our variable should be a partially observed variable, right? A variable with missing values. So we can assume that here, in this case, G is missing and the cause of missingness of G is purely random. So G equals missingness in G is caused by a random process and missingness in income is caused by gender. All right, this graph, the graph on the right-hand side, has two conditional. The right-hand side has two conditional dependencies. One is that income is independent of RI, both the R variables given G, and that G is independent of RG of its own mechanism. So again, the same process, we will decompose it like so. And then using the conditional dependencies, we will insert the R variables. And because when R is zero, you can replace the corresponding variables with its proxies. And you do that, and you established recoverability. You established recoverability. So, this is the simplest MNAR model. However, establishing recoverability is non-trivial even for small models with two variables, as we'll see. When it gets to MNAR, it can get really, really hard. For example, this is the one that we saw, and we saw that the S demand is like so. Now, if I were to just add an edge, you know, the only change I made was there's an edge from Rx to Ry and this demand change. So, you had to use a different algorithm. The estimate chain, so you had to use a different algorithm to actually compute this case. And now, if you have this sort of a graph where you know missingness in X is caused by Y and Y is caused by X, then you have a different sort of estimate. And if to the previous graph, if you were to add another edge, then the joint distribution becomes non-recoverable. Essentially, we don't have enough information to recover the joint distribution. But however, the conditional distribution. But, however, the conditional distribution remains recoverable in this case. So, this is just in my work, I focus on just general solutions. So, for all configurations of the graph, give me a configuration of the graph, and I can tell you, give me a configuration of the graph and a query, and I can tell you whether the query is recoverable or not. So, which is why we have all these, I explore all these strange configurations. What prevents recoverability? What are problematic structures? So, with respect. Problematic structures. So, with respect to joint distribution, if you have a variable with missing values such that the variable and its mechanism are neighbors, so essentially there's an edge from x to Rx, like so, in the graph. So, the graph can have other variables, but if you have an edge from x to rx, then the joint distribution is non-recoverable. Potential case of non-recoverability is like so. So, L1, L2, L3 are latent variables, so we have not measured them at all. Not measured them at all. So, L1, L2, and L3 cause all these variables like so, like as portrayed in the graph. So, usually, if you have latent variables, we denote them with a bidirected edge because they're anyway latent and then we don't know anything about them. So, we just use these bidirect edges to depict that. So, if you if there is a path from X to its mechanism Rx, such that all intermediate nodes are colliders, by colliders, I mean two edges. By colliders, I mean two edges kind of coming together, focusing onto a particular node. So you can see Y is a collider because there are two arrowheads coinciding on Y, similarly for Z and similarly for Z. So all the intermediate nodes are collider. You don't really need a latent variable between X and R Y in order to have the structure. X could simply cost Y. And as long as there are colliders on the intermediate nodes, this condition is satisfied. Intermediate nodes, this condition is satisfied. So, two problematic structures we need to look out for non-recoverability in joint distributions: there's an edge from x to Rx and the sort of a bidirected edge or a path from x to Rx in which intermediate nodes are colliders. So, given that we know this, it's now very easy to look at this graph and determine, look at the graphs one by one and determine whether probability of xy is recoverable. Look at the first one, for instance. First one, for instance, you have an edge from y to ry. So this clearly tells us that here the joint distribution is not recoverable, right? Probability of xy is not recoverable. Look at the second one. Here there is a bidirected path, right, from x to rx, where y is a collider, right? Both the arrowheads are pointing into y. So when this happens, we know that chain distribution is not recoverable. And the existence of such a path is sufficient to make the model non-recoverable. Even if there are other paths. You even if there are other paths, it doesn't kind of enable recoverability. In G, that is the third one in the first column, you can see that there is an additional path, right, from Y to Rx via Z. But the existence of this path does not allow recoverability because there is the path from X to Y to Rx, which in which Y is a collider. Now, such paths don't exist in any of the other graphs. Other graphs, as you can see, B, C, E, F, H, and I. So, in all of these models, probability of XY is recoverable. However, just because the probability of XY is not recoverable, it doesn't mean that other queries are not recoverable. For example, in the first graph, in graph A, conditional distribution is recoverable. In graph D, the marginal distribution probability of X is recoverable. And similarly, in graph G, probability of X is recoverable. So this is a very simple example. So, this is a very simple example of an instance where you can kind of look at the graph and decide whether something is recoverable or not. Here we have a new task. This is slightly convoluted. So, the question that people normally ask me is, why do you need graphs? Wouldn't an enumeration of conditional dependencies suffice, right? So, I'm, after all, just reading conditional dependencies and inserting it, and then somehow running an algorithm and computing it. So, why do you need a graph? I'll just give you a list of conditional dependencies. I'll just give you a list of conditional dependencies and then can you do the same? I'll show you why it is going to be problematic. All right, in this graph, the query we are interested in is probability of x. All right, now you can see that x, so the previous result was that the joint distribution is non-recoverable when there is a path in which from x to rx in which intermediate nodes are collided. So we didn't say anything about probability of x. So p of xy is definitely not recoverable because of the path from. Definitely not recoverable because of the path from X to Rx via Y. So X, Y and the bidirected path to Rx. So probability of XY is not recoverable, but is probability of X recoverable. Now, the way to do this is we would first apply, we would see that Rz is a descendant of Y. And because it's a descendant of Y, you can, sorry, a descendant of Y and hence a descendant of X as well. So you can basically manipulate. X as well. So you can basically manipulate it and doing whatever you do to RC, it will make no effect on X because it's a descendant, right? So using Rule 3 Abdu calculus, you can actually rewrite probability of X like so. And this is equivalently portrayed graphically by removing all edges that enter Rz. So essentially, you are setting the value of Rz to zero. And so Y now no longer has an influence on Rz, and that is depicted by removing the edge from Y. Depicted by removing the edge from Y to Rz. Once you have this, you can see that in this particular graph, in the second graph, the one with the yellow border, you can see that x is independent of rx and that allows you to insert rx equal to 0. You inserted rx equal to 0, and you have, you can replace x with x star, and once you replace x with x star, it just becomes a, you can basically get rid of x, and you have this model. Now it's a regular causal inference identification. It's a regular causal inference identification problem, and using older results, you can just apply those algorithms and you have the estimand here. So, without having a graphical model, you wouldn't know where to intervene. Now, I was able to figure out that I can intervene on RC just because I know that X is a descendant of, sorry, RZ is a descendant of X. So, graphical models are useful in that sense in determining this sort of, in recovering, given the sort of complex situations. This sort of complex situations. What about MNER problems in the real world? We talked about such instances, right? Like people with high income don't reveal their income. Smokers are reluctant to answer questions regarding their smoking behavior. Students who use drugs, for instance, do not answer questions about drug use. Right? So this is how the real world works. Now, and I previously said that when there is an edge between a variable and its own mechanism, then it's not required. In its own mechanism, then it's not recoverable. But then, is there any way we can actually do this under some assumptions? Is it possible at all to recover quantities when such problematic structures exist? So, it turns out that under some conditions, you can do that. So, I will exemplify the simplest case here. Here's a graph where there is an edge from y to ry, right? So, based on the previous slides, it's clear that probability of x, y is not recoverable. Clear that probability of xy is not recoverable. What I mean by not recoverable is for all data generated by the graph, for all parameterizations of the graph, you cannot prove recoverability. But it turns out that for some cases, for some data that satisfies some properties, it may be recoverable. So let's see how to do that. We notice here that the conditional distribution is recoverable. How so? Because the graph encodes the independence. There's no edge between X and R. Independence. There's no edge between x and r y. So x is independent of ry given y. So that allows you to insert ry equal to 0. And once you have ry equal to 0, you can replace y with y star. Now the factor on the right-hand side of the equation contains x, y star, and ry. And x is fully observed. Y star is already there in the data set that's given to you. And ry is equal to 0, which means everything is observed. Look at only those tuples in which variables in which y is observed. So you have established. So, you have established recoverability here. P of x sum over y, this is simple algebra. Now, you can just put it in metrics format. Essentially, you are solving a set of linear equations, and then you can establish recoverability. Now, this depends on the property of the data, which means the cardinality of the variables matter, the invertibility matters, a lot of other things matter. So, in some cases, maybe if you are lucky enough, you can actually recover. You can actually recover for discrete cases. It's slightly easier, I would say, for linear models. I don't have those slides for that here, but in linear models also, whenever a variable causes a missingness, you have methods to determine the mean and variance of the variable. For instance, if this was a linear model and y had another child W, then you could actually determine the mean and variance of Y in a linear model. In a linear model, under assumption that the distribution is Gaussian. Okay, now let's go to the second aspect. So, that was recoverability. Now, let's talk about testability. So, given a model G, when does it have, what do I mean by testable implications? So, by testable implications, I mean some assumptions that are refutable by the data set. All right, so let's look at this. X and Y are two nodes. So, there is no in this graph. Via two nodes, so there is no in this graph x and y independent, so there is no edge between x and y, and there is no missingness. So, the testable implication here is x is independent of y, and the given any data over x and y, you can actually test whether the independence holds or not, right? So, you call it a testable implication. When we have missingness, actually, it becomes really complex. So, you can't randomly take any desiparation, any conditional independence assumption, and then say whether it is recoverable or not. However, it turns out that. However, it turns out that if the conditional dependencies statements satisfy certain syntactic forms, then they are recoverable. For instance, if x is independent of y, given z, and then you have all the r variables, given all the other r variables, and it is testable. If x is independent of r, y, given z, and the r variables corresponding to z and x, but you don't have y there in that whole equation two, you do not have y at all, then it is. Have why at all, then it is testable. And then look at the third format. So it essentially says that the mechanism, the independence between mechanisms of variable X and Y condition on them on a variable Z and its mechanism is testable. So let me exemplify it with an example. Exemplify it. Yeah. So here are the syntactic rules. This model denotes MAR. We know it denotes MAR because denotes MAR because the parent of R variable RI is a fully observed variable E. And either it has no parent or the parent is a fully observed variable E. So it falls under the MAR category. Notice that there is no edge between I and RG, right? Rg is on the left side, and then you have I. There is no edge between I and R G. So this model encodes the conditional independence. I is independent of Rg given E R I. All right, this is a claim in the model. How do you test? Claim in the model. How do you test this? Now, we have three syntactic rules. Now, if you match them, you'll see that this kind of aligns with matches to the syntactic rule two, which is independence between a variable and a mechanism of another variable. In this case, Z in Z in the case of equation two is actually E here, but E is fully observed. So Rz is actually a null set. So I independent of Rg given ERI matches to rule number two. RI matches to rule number two. And we're just expanding it like so. And when we take the case when the R variables are set to zero, we can actually replace the I variables with their proxy. And so this particular, the last equation is the testable implication. That is what you're going to test. Similarly, there is no edge between G and Ri. Yeah, there is no edge between G and Ri, and therefore, in a similar way, that claim is also testable. However, it Also testable. However, it turns out that independencies between a variable and its own mechanism is not testable. So this model has independence between G and R G, G independent Rg, and it also has I independent of Ri given E. However, independencies between a variable and its mechanism are not testable. That is, there is always an underlying distribution that in which these independencies can hold true. So you cannot refute them at all. Refute them at all all the time, so therefore they are called as non-testable. There are two interesting impossibility theorems in missing data. The first one is that look at both of these graphs. All right. So the first one encodes the conditional independence. X is independent of Rx given by. The second one says X is independent of Rx, not given by, but so these. But so these models, both of these conditional dependencies, are non-testable because they are independencies between a variable and its own mechanism. So these two models are statistically indistinguishable. However, it turns out that probability of x, y is recoverable in A in the first one, but not recoverable in the second one. Why is it not recoverable in the second one? Because there is a path from X to Rx in which the intermediate node Y is a collider. So you cannot tell them apart, but the quantity is recoverable. But the quantity is recoverable in one, the joint distribution is recoverable in A, but not in B. So, what this tells us is that no universal algorithm exists that can decide recoverability without looking at the data generation process. In my case, it is depicted by a graph. Another one, it's the same example. So, it has the same set of conditional dependencies. So, these are, and now look at the query probability of x. All right, now it turns out that probability of x is represented. Have that probability of X is recoverable in both, but by different methods, different estimates. The first one, you know, you can look at it. The estimates are different in both of them. So what this shows is no universal algorithm exists that can produce a consistent estimate whenever such an estimate exists. So this allows us to, this makes us conclude that missing data is a causal inference problem. So this was my Inference problem. So, this was my take on missing data. Now, I'm happy to talk a bit about a really new work that we have been doing in collaboration with graduate student Chi Zhang and Julia Pearl at UCLA. So, this is on interference. So, just to start an example again, you have treatment and you have outcome. So, in this particular case, assume the treatment is vaccine and outcome is the severity of the disease. Suppose you have three. The severity of the disease. Suppose you have three samples. Again, it's a tri-example. So, suppose you have three samples, um, and it's all IID, no interference, nothing, perfect data. Uh, this is how they will look. And you can kind of nicely depict it using one graph, right? A Bayesian network. You don't need to independently, you know, show them differently. So, no interference. However, in the real world, that's not how it's going to be, right? Whether or not I take a vaccine, whether or not I am vaccinated would determine whether my roommate gets vaccinated. Roommate gets will determine the severity of my roommate's disease, right? So, all these interactions and edges exist, so there is interference. In my work, we study this problem using linear models just because it's very convenient for path analysis. So essentially, the path coefficient or the causal effect of treatment vaccine on outcome O, the severity of the disease is quantified by the path linear regression coefficient. Regression coefficient A in this particular case, some quantity A. All right, so these are the two equations that we have. So, this is a linear model, and the causal effect of T on O is equal to A, which is a regression coefficient of X on Y. All right. Now, we have interference. So, in this, I'm just assuming that all the edges from T to its own O has a coefficient A, T to O of a different variable has coefficient B, and they just. Variable has coefficient B and they're just between O, those have coefficient C. So the model is something like this. Now the question is: how do you compute? How can you estimate A, the causal effect of treatment on outcome under interference? We want the quantity A, but what we observe with regard to O2 is this combination of all these effects. Look at O2. It is affected by B, it is affected by its own T2, which is A, and then. Son T2, which is A, and then there is a C factor coming from O1. But we don't want all of that, we just want to know the causal effect of treatment on outcome. How can we, so it's almost like you have non-ID data, but you want to compute the quantity query as if it is IID data. This is interesting because when you, when you in randomized clinical trials, you're actually assuming that the subjects are isolated, right? So interference is usually not there. So you want Usually not there. So you want to find the outcome of the query as if there was no interference. Now we have, given that we don't have time to go into details, I'll just discuss a few main results. All right, so again, this is a model that we have. So we have identified graphical structures that amplify bias. So if you have certain kinds of structures in the model, then you are guaranteed to have like You are guaranteed to have like huge bias. So, one such structure is the regular interference sort of model, right? Where an open path from Ti to O J. By Ti, I mean so treatment of unit I to outcome of unit J for any j. For instance, you will have edges from T1 to O2, T3 to O2. So, these are all the kind of paths that would amplify bias. The second kind is an open path from TI to OI. So, here we are. From TI to OI. So here we are talking about edge, like look at T3, for instance. There is a path from T3 to O3, but it goes through a variable of another individual. What I mean by that is look at the Babloo path from T3 to O2 to O3. So there is a directed path from T3 to O3, but there is also another path that kind of goes to O3 via O2. So this sort of bias is actually really bad. So, if you have any of those two structures, then you are guaranteed to have bias. When you have a large number of samples, it may help in reducing bias, but it need not. As long as those structures are always there, you have to be cautious. It's not the case that if you have a large number of samples, it would actually reduce it. But if the connections are weak, like B is very small, then it's still okay. Simulation studies show that it's still okay to ignore interference and just assume the data are IID. Assume that data are IID. Now, how do you actually get rid of bias? Right now that we have this bias, and suppose the bias is high, what is a good de-biasing procedure here? Turns out that if you can pick a set of samples such that they do not form, pick a set of samples and then construct the construct the interaction graph, the graph like the one shown above with a subset of samples. So, you do this using a process called as latent projection. If you can do that, and then that structure. That and then that structure does not have any of these complicated biased structures, then you can use those subsamples to compute unbiased estimate of the query. So, for instance, in this particular case, there are six samples, all right? T1, T2, T3, T4, T5, and T6. In this case, you can actually use samples 1, 4, and 6. So, if I use samples 1, 4, and 6, then essentially they are IID. So, sort of samples, but it need not always be IID. It need not always be IID. There are cases in which O1 and O2 can be connected so long as there is no edge from T1 to O2. So, if it were the case that there was no edge from T1 to O2, then you could use both one and two, samples one and two, to compute this quantity, even though an edge exists between O1 and O2. So, some interaction is allowed. Only these nasty ones specified in. ones specified in point one, if they have to be avoided. It turns out, so this is the formal result that we have where we say that where we actually quantify bias. So the left-hand side expectation over beta yx, that is the quantity that you obtain by that's a quantity that is estimate outputted by linear regression. So essentially you are assuming that non-IID data is IID and you're just running IID data is IID, and you're just running linear regression, and that's the quantity that you get. The left-hand side one. Alpha is a true value. So the difference between that would give you bias, and it's given by these two quantities. So one formed by the kind of direct path from Ti to OJ, and the other formed by, you know, path from Ti to Oi, but going through a different variable. So this is how a bias is quantified in our and these are the three main references. References, which the first two talk about missing data, the second one, the middle one, talks about methods to construct graph given data. I have not covered that in this talk. So there are procedures using which you can actually construct graph, the missingness graph given missingness data, and a few assumptions. It's a little complex, but you can still do that. And the third one is a latest paper which is under review, which talks about graphical models for causal analysis under interference. Analysis under indifference. Thank you.