Conference organizer for inviting me. So, my talk is deal with subdivision schemes which are motivated by classical interpolation problem. So, let me start with interpolation. So, if I'm going to use a Maganji scheme, then you are going to interpolate the function values. And if I'm going to use the mesh, And if we are going to use the mesh using the set on the integers, then we can interpret the function and by pick up the function value set on the integers. Now, not only we can interpolate the function using function value, we can also use the Hermit interpolants. So the Hermit interpolants not only interpolate the function value, and also you are going to use the derivatives. And the most And the most important thing about the Hermit interpolance is that you are going to interpolate the consecutive derivatives. So you can interpret the function value, its first order derivative, and also second order derivative as well. And beyond these two classes, we also have a more general class, which is called the Bakov interpolants. So the only difference between the Bakoff. Only difference between the coffee interpolants is that we are not required interpolation for the derivative, for the conservative derivative. You can first interpret the function value and then you can skip the first order derivative and then you can interpolate the second order derivative. So you are not required to use a consecutive derivatives. So all this Lagrange, Hermit, and Bacoffine Tarpans. Meat and bacoffin tarpens have been extensively studied and well understood now. And for us, we are not only interested in this, we are also interested in the interpolance, which is also refinable. So the refinable basically means we are going to consider a vector function. So the phi is a vector of functions with R component. And also they are going to satisfy the refinement equation. So basically equation. So basically basically means the function phi is going to be reproduced by itself by using a sequence of matrices of this sequence A, which is called the matrix mask and quite often is finely supported. So you may wonder why we are interested in the refinable interpolance is because GNONED have a very nice properties. So if I talk about the general refinable vector function, General refinable vector function, then this again this is the refinement equations. So, through this refinement equations, what we need to know is know the function phi. We only need to know the matrix mask A, which is just a sequence of matrices. So, once we have the sequences of the mask scale, then you are going to see we can compute the refinement function using the subdivision operators. Subdivision operators. So the definition of the subdivision operator is just a map a sequence V. So V is the sequence of numbers and this map into another sequence of numbers. So this is a sort of a discrete version here. And if you are going to use the subdivision arbitrary scale, you can reconstruct this refinement equation so that you can find the solution. So, that you can find the solution to the refinement equation through these identities here. And the most important thing is that most known spline interpolants, they are refinable. And once you are refinable, then you can actually construct wavenites. So, just how come refinable vector functions are linked with the wavening methods in numerical PDE and also their applications in the image processor. In the image process. Now, so what is the subdivision scheme scale? It's starting with the initial sequence of vector scale. So W0 is a sequence of numbers. So genuinely the import data here. So once we have this one, then we're going to apply the subdivision operator. So once again, this is a subdivision operator. Then you can apply to the W0. apply to the W0 recursively n times to get the W1. For example, if n equals 1, then you apply the SA acting on W0 and also you have to scan it by this matrix here and to get the W1. So basically why we want this scanning for the Hermit scheme is basically because you are going to regard it as a sequence of numbers. You can regard this one by putting the W. Putting the w n of k and then associate with the position to minus minus n k. So basically, your data now is in this discrete mesh. So 2 to the power negative n times integer. So you are going to see when this little n becomes larger and larger, you have more and more data. So a natural question is that you want whether this sequence of Sequence of numbers actually convergence into a function. So, this will hope. So, we hope this is a sequence of Wm produced by the subdivision scheme. We want this one, whether they can converges into a function eta and its derivatives to the power r minus one. And here, we do not require this Newman function eta to be interpolants yet. So, what's the So, what's the convergence? So, let me give you the definition of the convergence of the Hermit subdivision schemes here of order R. So, basically, order R means we are going to try to reproduce the function value first-order derivative all the way to the derivative of order r minus one. So, we're starting with the initial for any input sequence of data. Then we apply the subdivision. Then we apply the subdivision scheme to obtain the sequence of numbers. So, what we hope is when this iteration n goes to infinity, then we want this one. So, now pay attention. This every single, this Wm is a sequence, is a vectors with R component. So, this not only a one number. So, every single W and K have a R. Have a R component. So, what do we want? We want the first component converges to the function value eta. And we want the second one convergence to the first order derivative and so on. And the last one converges into the R minus one derivative of the limiting function at us here. So, we're trying to study under which conditions on the mask A because everything here is dominated by this. Here is dominated by this mask, which is a sequence of matrices. So you're trying to calculate under which conditions on the matrix mask, then the Hermit subdivision scheme converges. And this problem in the scalar case, which is called a Magrant case, which R equals one, so means that you have only one component for the function value, have been studied in the 1990s by many, many people. By many, many people. Now, very recently, for the Hermit case, which is r greater than one, means this vector function here. This has been recently studied in the last decade by many, many people, trying to calculate the convergence. And because we deal with matrices instead of schema numbers, so that's how come the study of the Hermit subdivision schemes is only very recent. So, let me present the result. Let me present the results. In order to do this, then we have to deal with two technical definitions here. So the first one is the order of sum rows. So if you are going to give me a matrix mask A, which is a sequence of matrices. So this one has the order M plus one sum row with a matching filter, the VA, if the following two identities hold. Identities holds. So basically, the condition put on the mask A. So I'm using the Fourier notation. Basically, it means that every this little hat refers to a vector of topi-periodic function, and this A hat is a matrix of topi-periodic polynomials. And also the notation of O to the power Kc to the power m plus one, this notation just means. this notation just means the derivative match up to the order m because it's m plus one so it's a shorthand notation so this kind of a summaries basically is well understood in the wavelength analysis and it's very important in the approximation theory because the following fact so for a refinable vector function phi satisfy the refinable equations so under a very mild condition so this condition So, this condition is a very mad condition scale. Then you are going to see the matrix mask has m plus one sum rows if and only if the integer shifts of the refiner function. So this is a refinable function. You are going to translate them by integers. So this form a function space. And this shift invariance space contains all the polynomial of degree. All the polynomial of degree all the way to the n minus one. And so that's how come this is more or less equivalent of the approximation order in the setting of the matrix mask A by putting the condition on the matrix mask A. Because this is more convenient. This is well studied in the wavelength analysis many more than 20 years ago. Another technical Another technical quantity is related to the smoothness. So once a matrix mask A has a summary of order nitro m here, then there is a smoothness quantity measured in the L P space. So the P between 1 and infinity here. And this is defined as 1 over P minus log base 2 of this sort of joint specific. But the definition is very The definition is very complicated. And it's not surprising you're going to see why using the subdivision operators here. So just how come? The subdivision scheme plays a very important role in the wavelength analysis because the nodal properties of the refinement function are calculated by using the subdivision operators. So there are a few important facts here. Facts here. So the first effects is for a refinable vector function phi, satisfy the refinable equation here. Then we can measure. So we first can measure the smallness of function by using the somnif spaces in the LP space and the small smallness exponent is S here. So you are looking for the largest smallness S so that the refinement So that the refinable function phi belongs to the Sovniev space in the LP space, but with smoothness SQL. So this is a critical smoothness of function phi. So if you don't put any condition, then you are going to see the smoothness provided by the mask A provide a null bound for the smoothness of the refinement function file. So it means that this always true. So you are So you are going to know what how small how small the refinal function phi can be. So on the other direction, so if I'm going to put a new condition, so that's called the stability condition. So if the integer shifts of are stable, so I'm using the Fourier definition again. So basically you take the Fourier transform and pick any KC and then you translate this one by integers. This one by integers topic key, and then this is a vector for every single key. This is a vector because we are talking about a vector refiner function. Then you take this one and this one, the whole space CR for any case. Then this is a stability condition. So under the stability condition, you are going to see these two quantities. They are going to be the same. So because so this means that So, this means that this technical quantity, the SM smoothness measured in the LP of A, calculates the smoothness of the refiner function. Not only here, if P equals 2, we can compute it. Basically, we have an efficient way to compute this quantity, and then we can measure its smoothness when P equals infinity. So, this sort of source embedding theorem is always true. Theorem is always true. So the infinity smoothness is always greater or equal to the smoothness measured in L2 subtract 0.5, but in 1D. But in higher dimension, you have to subtract D divided by 2. Okay, so the first result is categorization. So when the Hermit subdivision scheme of order R with mask A is converted. With mask A is convergent with the Nimni function in the Cm. This is a necessary and sufficient conditions. So, this means this mask must be a Hermit mask. So, what is a Hermit mask here? This means your mask, matrix mask, mask has an order M plus one sum row with specific matching filters with these structures here. So, it means your mask A not only A not only has m plus one sum rules, the matching filter must satisfy this condition. And it's not surprising because if you look at Hermit subdivision schemes, we are interpreting the function value first order derivative and all the way to the derivative r minus one. So you are going to see the first component is one plus OKC, and second one is IKC, and the last one is IKC to the power R minus one. To the power r minus one. This related to the derivatives in the consecutive way. The second one, because the Hermit subdivision scheme is required to be convergent with Limit function in the Cm. So this automatically means your function, basis function here must belong to Cm. So there's no surprise also here. This small things quantity, Sm measured in the infinity A is greater than M. Is greater than m. So, this is a necessary and sufficient condition to characterize the Hermit subdivision schemes. So, this results is given in a recent paper. I studied the Hermit sub-subdivision schemes. And we can also use some Hermes blinds to prove the existence of the Hermit subdivision scheme of order R. But this is not the main issue of this talk. Main issue of this talk. So, what we want now is: so, let me give you one example why we are interested in this Hermit subdivision scheme is because most of them have a very close relation to the sprites, which is extensively studied in the past machine series here. So let me give you one example. So, we can construct a Hermia musky with a multimonicity 2 by 2. So, this 2 by 2 means that every single. single every single element here a of k is a two by two matrix so the support is from minus two to two the sum row is greater or equal to seven so the mask is given by this so this is uh this one is just the a minus two and this is the masked component a of two so everything is determined by the the mask and then we can also We can also obtain that so this matching filter must satisfy the necessary conditions. So, in the characterization, you must satisfy this one. So, that's how come I explanation given the matching filter here. Then, according to the results, we are going to have the Hermit subdivision scheme with mass convergence with the Libnan function in C2 for any primary T in this region. And how we obtain this one. And how we obtain this one is basically because once p equals 2, the small things quantity can be exactly computed. So once we have this one, then we use a sonif embedding to make sure this quantity is greater than 2 because we are looking for C2. And this is how come we are going to get the range. So this general analysis apply the results. So the most important thing for us for sure is. important thing for us for sure is sprung. If not a sprung, then it may not be that interesting. So the choice is that if I'm going to take a very particular choice of t equals negative one over seven, then the sum row can be eight, the small things can be six, and the refinable function indeed is a slam. So the expression is given here and then is a port here. So if we take the thickness So, if we take the sixth-order derivative, you are going to see this not continuous, but it's piecewise linear. So, this means that this function, you can take, this belongs to C5. If I'm going to take a derivative, so just how come the lines always have a very nice collection with the Hermit subdivision schemes? So, my motivation here is not the Hermit subdivision schemes. Subdivision schemes is a sort of Helmholtz equations because most of you may know Wiemen's method have been studied to the numerical PDEs, a lot of people have studied this one. And so one of the problem I'm interested in is a Helmholtz equation with non-local boundary condition. So this is the equation of the Helmholtz equation, Helmholtz equation with the boundary condition. So the non-local boundary condition coming from here. Local boundary condition coming from here. So, this illustration. So, this kind of a Helmholtz equation is very important in particular in the military. And you can think about, so you have an airplane flying here. So, you have a radar. So, the information will go to here, right? And then you have this is a horizontal underground. So, this generally, this one is underground here. And then you are trying to characterize. Are you trying to characterize this solution? So, all the information are calculated by the Hampos equation. And because your original domain business needs your union domain is unbounded. So, this is not only here, but also outside. So, generally, any numerical scheme cannot solve it. So, that's how come you have to use the Hunkel functions and using the integrals here and to impose the boundary here. So, impose this string. So, impose this strange boundary here so that you can cut down the unbounded domain into this rectangle here. And you can form the weak solution of this Helmholtz equation, which is given by this one. Okay, so it's a Niblukwick and Helmholtz. So, the difficulty is that you have a non-local boundary condition. Now, not only here, I realized that when people started the cavity problem, actually they're using a Problem actually, they using a very interesting family of splines they call Cm piecewise polynomials. And this is so if you call the function on the integer k to k plus one, then this f is a polynomial of degree m plus one times capital M plus one. However, the total small sis is only Cm. So this means that if you are familiar with the splines, then this corresponding to the special case. This corresponds to the special case that n equals zero. So because if n equals zero, this is one. So the degree of the polynomial match with the smoothness. So this is the spring and the Hermit splanes. But in this cavity problem, actually people using this neutral m to be one. So the case people study as m equals one, but n, capital N is arbitrary here. And to solve the Helmholtz equation. and to solve the helm host equation is hard it's basically because your match size h have to be very very small so this means the wave number kappa so if you go to the helm host equation you have a wave number here so the wave number kappa times the mesh size should be strictly less than one and much much smaller than one so this leading to a huge linear system so quite often you are going to see the linear system you are going to solve is a mean by mean Is a meaning by meaning. And not only here, because if you look at this kind of condition scale, so generally speaking, this G is a complex vanilla function. So if you look at this example, it's a complex vanilla function. And therefore, the linear system is indefinite and heavily year conditioned. So you are facing a situation because the wave number is large, mesh size have to be extremely small. Then you are going to going. Then you are going to get a linear system which is huge size and heavily ear conditioned. So everyone knows that the waveness can provide a uniformly condition number. So just how come? And not only here, and this tensor product says zero piecewise polynomial already used in the finite animals method to solve the problem. So that's how come I hope that women may contribute with a small continuum number. With small condition numbers, so that we can solve the Herm Holtz equations here, right? So, let me just give you one example, have some feeling why it's hard. So, this Hermes equation and the solution is complex valued. So, this is the real part, this is the imaginary part. So, you are going to see a lot of waves here. So, if you are going to capture these waves, there's no surprise on your mesh size have to be extremely small. And your mesh size has to be extremely small, otherwise, you have something in between and you cannot capture the solution. So, currently, for the 2D problem, when people using the final elements or finite difference to solve the problem, the wave number can only be 100. So, the example I provide you using a player trick using the direct assisted method here, which allowed us to handle the wave number 700 because we convert them in. Because we converge them into a 1D Helmholtz equation to avoid solving a huge linear system. So, that's how come solving the Helmholtz equation is a very challenging problem so far, and many people trying to study it. But I should say the progress is not that significant in some sense, because the solution is highly alternating here. The mesh size has to be extremely small. You cannot avoid this problem. Not avoid this problem. Now, here is generalize the Hermit subdivision schemes because I think my time is 20 minutes. So let me go ahead and quick. So we can generate the notion of the Hermit subdivision schemes by using ordered multi-set. So what is this new one to new R? So basically means that if I, for example, if I go to interpret the function menu, then you are going to put a zero here. Then you are going to put a zero here. If I'm going to see, I'm going to interpolate the function menu at a different position, then I can put another zero here for the Lagrange interpolation and different set. But if I'm going to see where my scheme needs to interpolate the derivative of order two, then you put two here. And if I want to see, I can jump to derivative of order five. So this will this set number means. So this number set basically means. This number set basically means collect the derivatives you are going to do interpolate, and you are going to know the derivative to compute, to repeat. Then you are going to see the definition now is almost the same once you have this. So a generalized Hermian subdivision scheme with mask A is the same you starting with the initial data W0 and then you W0 and then you apply the subdivision operator here. Then you are going to be scanning because you are taking derivatives. So this is very similar, just properly rescanning here. Now, remember that this data is set on this mesh size to minus m to z. And we want to study under which condition the wn convergence into a function so that you can match its derivative. So the definition now is very similar. So you are going to Is very similar. So you are going to see a generalized Hermian subdivision scheme of type nominal with mask E is convergent with a Nimney function in Cm. If starting for any initial data W0, you apply the subdivision scheme to generate this sequence Wm, and then you want this one converges into the prescribed derivative of your Lieman function, which is dominated by this. dominated by this. So you are going to see the Hermit case is nothing else here. The Hermit is just a 0, 1, 2, all the way to the R minus 1. And then we also allow the back off interpretation by just demit some of them. So once we have this definition, then the characterization is pretty much the same. So you still, so we have a necessary and sufficient condition. So the general So, the generalized Hermia subdivision scheme of type normal with mask A is convergent with living function in C M if and only if your mask must be a generalized Hermian subdivision scheme with a summary of order plus one with a matching filter have to satisfy this technical condition. And your function must have a smoothness, which means the smoothness of A measured in the infinity should be greater than m. Should be greater than m. So the result is quite similar, but the proof is much more complicated than the Hermit subdivision schemes. So now let me just talk about, let me see, okay, I should have time. So once we are going to impose generalize the notion of the Hermit interpolance, then we can generalize this one to the generalized Hermit interpolation property. Targeting property. So basically, it's quite similar. The only difference here, we allow the normal to be a different collection of derivatives, not only just 0, 1, 2, 3 in 1D. So this is the interpolation property. So this is a generalized hermit interpolant of type number and t. So this t square is up. So let me explain to you a new bit because I pay attention to this case. So let us So let us look the Nagari case. So you put a zero zero zero here. So we piece them. And then what is the T here is we are going to require the Nagani integration on zero and this one. So you are going to have a have intermediate places. So not only the function value on integers, you also require the function value on this dominated by this belongs to the set T. So this, how come this So, this how come this row of t. So, Nagani basically corresponds to this special case and the Hermit interval is corresponding to normal equals 0 to M and the position is only on integers. So, Baikov could be any subset of this. Okay. Now, the definition of this interpreting, so definitely we are trying to calculate this. We are trying to calculate this. This is our goal. So, the Hermit intervene is very important. We're trying to calculate this one. So, this is related to the general Hermit subdivision schemes. And so, starting with W0, you generate this data Wm. So, the mass condition for the interpolating is fairly nearly strange. I mean, it's a nearby complicated. This is because different derivatives have a relation and they have to obey. And they have to obey this. So, once we have this one, now we have a necessary and sufficient condition to calculate a generalized Hermit interpolance of type namel and T. So, the first condition means your mask must be a generalized Hermit subdivision scheme of type Namna. So, the second condition is your mask must be in Tapanitary. So, means this. So means this condition. So not any mask. The mask behaves, looks like this coming condition. And the third condition, you must have the smoothness, as we say before. I think I should change this into strictly greater than m. And also the matching filter have to satisfy this condition. So you are going to see compare with generalized chemical stuff during scheme convergence and the generalized chemical interpretation. And the general terminal interference, the only difference is this condition two, you have an extra condition on the matrix mask A. We can calculate this one. So let me give it now after this technical results. Let me give you one example. The most important thing is that they indeed again, they have a connection with the sprints. So the third we are going to see, we have a function value interpolation. We are going to interpolate the function value. We are going to interpolate the function value second order derivative instance of one. So the point we are going to pick is 0, 0, so means interpolation happen at the integer z. So then we have a generalized hermit mask A of type number. And this is the mask given here. So once again, once we have this one, we can so this have four parameters, t1 to t4. T1 to T4, and we can calculate the convergence of the by-hoff subdivision schemes. So, so this kind of as long as so for this particular choice here, then you are going to see the smallest continuous greater than three, and then the back of subdivision schemes is convergent with limit in three. If I'm going to put a more condition on the parameters, so if I'm going to pick up a T3 and T4. Up t3 and t4 equals to zero, then the mask is in top literatory. And then it's refined function where you are going to get in top literary backhov subdivision scheme with mask A with the limit in C2. Not only here. So this is what is the backhov interpolation property. So you are going to interpolate the function menu and its second order derivative, but nothing about the first order derivative. Nothing about the first order derivative. You can skip the derivative. And not only here, you can also make a specific choice of the parameter scale still using this 0, 2, back of t equals 0, 0. Then you are going to see some special choice of the refinable function need to the splice. And the splice is always preferred in the numerical solution of PD. In the numerical solution of PDs for the fast computation. So you always have a nice collection here. So it's still more or less 10 minutes. Let me go. So because we talked about the C0 Nagrange scheme, and then this kind of scheme was used to solve the cavity problem of the Helmholtz equations. So just how come we're going to construct the waveness? So this is so this wave. So this weld C0 Nagan's basis mask. Then we can construct the low pass filter, high pass filter, and the dual filter. We can construct the biozonal women scale. And not only here, we have to adapt them to the bounded interval because it's a boundary value problem. And this one can be done. So basically, let me put. So, basically, let me put in one short sentence. So, far from any complexness supported by also multi-wavelengths, we can always, so for any given, not only the standard classical wavelengths, any complexness supported by solidarity multi-wavelengths, we have a direct approach to construct all we can adapt. We can adapt these wings to the boundary interval 0, 1, not only to 0, 1. only to 01 we can find all such waitness on the interval 01 using this approach so means any adaption of the waitness from the real 9r to the interval 01 this direct approach can find all of them not just one and we can apply this to the lagarange scheme so you are going to see this is our lagrange basis so it's not surprising so at zero take value one at half equal zero at negative half equals half equals zero and negative half equals zero at the negative one equals to zero. So the second elements at 0.5 take value one and vanishes at any other places. So this C0 not ground and we can adapt them and we are going to have a wavelength set on the boundary interval. So this is a they can also satisfy the boundary condition. So this boundary condition 0, 0 is a denominated boundary condition scale. Boundary condition scale. And this will have a low boundary condition here. So we are going to use to solve the cavity problem. So because we're using a tensor product, so the function in 2D will be and looks like this. So this is a 2D basis. Now, let me spend some time to demonstrate what's the performance to solve the cavity problem. So let me go back and send it to you. So let me go back. I think it should have time. So let us go back to the original problem we are going to solve. So this is the numerical PD we are going to solve. So this Helmholtz equation and this omega is the unit interval from 0, 1 square. So this is the square, unit square. And so on these three sides, so this side, this side, this side, on the ground, we put This side. Underground, we put a genially bounded condition zero here. And only on this gamma here, we have a non-local condition to solve. Okay, so just hard to handle. So we can apply this Nagan C0 Naganji scheme and build waveness and adapt them to the bounded intervals here. So let us look at the comparison here. And I should bring to your attention. Should bring to your attention here. So, the carbon we're going to compute is 32π. It's basically roughly the 100. It's not that large indeed. So, some of you will see where this looks like an easy problem. But the problem is that for all this kappa equals 32 pi, the linear system actually is a meaning by meaning size. It's a huge system. So, if I'm going to use the final elements method to solve this problem. Elements method to solve this problem. So, this currently represents the standard finite element method to solve the cavity problem. And this is a condition number skill. And then, so if I'm going to use the waivers here, so this is the waving method. So, we still use the same, so we still use the same elements. So, both the final. Both the finite elements and the waving scale. So basically, they are using the same function space. So just how come you are going to get the same numerical solution? Because the space used by the final elements and by the wavelengths, they are the same. So the results are the same. But if you know the linear system and the canon numbers, so the wavelengths you are going to see have so if you know Are you going to see so? If you look at this level eight, so the canoe number is only 273, but the final elements here basically you are going to get huge. So this can number ratio basically means the canoe number of the final elements over the canoe number of the women scale. So you are going to see the women have a much, much smaller canoe numbers here. So this is actually. So this is the actually bit final elements with over 800 smaller than the standard final elements here. For sure you can see the similar phenomenon. Once the cover becomes large here, then you are going to the continuum still much smaller than the finite elements here. And it looks like a waves can do better, but it's not indeed. Okay, so let me explain to you. So if I'm going to include So, if I'm going to increase the canoe number kappa from 16π to the 32π cube, you're going to see the same phenomenon. So, if you look this way at the level 8, you're going to the king number now is increasing. And now you're going to see, so let us look at the level 8. So, you are going to see once kappa is increasing here. And if the level J equals 8, so level J basically means the mesh size. Okay. The mesh size okay. This is a little so the mesh size h is 2 to the minus j. So you are going to see once kappa is increasing, the wave, the canonical number of the wing method is also increasing. So this means that if I'm going to see where I want to solve some real world problems, so generally it's probably larger than 1000, then you are going to see the canoe number still will be very, very significant, right? So that's how come. Right, so that's how come is uh so once this kappa is not system will be beyond what we mean by meaning. So the only solver to solve this linear system, you have to use an iterative solver. And therefore, the condition number is very, very important. So just how come we are hope we can contribute by having a much smaller condition number, then we can use the Italian scheme to solve the Herman Holst equation for the very large Canu number. Can you number wave number? However, so the canal number increases with the increase of the wave number. This is one fact. And the second one is that if you are very careful, you may notice that when carbon equals six pin pi, we're starting with four. And for this one, we're starting with the cost scale is five. So it means our weakness starting with j equals five and then go up for this. So everyone knows that we. So, everyone knows that the wavelength still needs to do the decomposition to all the way level as low as possible, right? Some of you will say, Well, you should use the wavings, the cost scale should start with zero all the way to nine. And then your community number could be even better. But the reality is the turns are very agony. If I'm going to use the core scale as zero, go all the way to nine, you are going to the canonum is no longer even from zero to. Know number is no longer even from 0 to 5. If I'm starting with 0 to 5, the Kenyan number is not this. The Kenyan number is huge. So this means that the waitness, the cost scale cannot be very small. And therefore, waitness is only partial successful to solve the cavity problem because not only is capital is large, we cannot offer much, but also the cost scale have to be large. So let me finish my talk. Talk is so Hermian sub-division scheme and the general Hermian sub-division scheme have a very nice collection with Hermian interpolation, Berkoff interpolation, and all this kind of interpolates. This offers us to find a new splan refiner function so that we can build a Wii's to solve the problem. This is our goal. And we also apply the Wiemens method to the Helmholtz equation to solve the problem. So this is the only one. Problem. So, this is the only one we're going to implement so far. But this one has only partial success. So, what is our hope is that using this general splan hemisphere schemes, maybe we can discover new splan basis and then build awareness to provide a better solution to the cavity problem of the Helmholtz equation for the numerical PPD. So, this is my talk. Thank you very much for your time. Thank you very much for your time. Thank you. Okay. So we have time maybe only for one short question. I don't know if there is anybody who wants to ask anything. Or maybe in the audience in the internet? Okay, see if that's the case, we thank a bit. The case, we thank being Han again for his talk. Thank you. Thank you.