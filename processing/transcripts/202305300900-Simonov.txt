His Nikita Skotov from Slovak University, and he's going to talk about stability in Gagliado-Nuremberg Southern Levi Politics. Thank you, Neil. Let me first thank the organizer for the kind invitation. So my voice has improved from yesterday, but it may happen that at some point I should talk like this. So if you don't hear something, please stop me and ask questions. It's not a problem. So actually, in my talk, I will. Actually, in my talk, I will talk about this preprint, which we have written in collaboration with Mateo Bonforte, Jean-Debaud, and Moulon Azare. We have done this work during the pandemic and we have finished thanks to the pandemic. Otherwise, we have really never finished it. It's very long, but my talk will be much shorter than the actual memoir. Okay, I would basically take one part of what Jean presented yesterday. Of what Jean presented yesterday and focus on that one. It will be stability in a particular family of Cardiari nearby inequalities. And in the first part of the talk, I will just present the problem and the main ideas from a very simple example. And the second one, I will mostly focus on our proof. Okay, so let's begin. So probably the best way to start is to look at the sole of inequality. Well, Jean presented yesterday, but everybody. Which I presented yesterday, but everybody knows that. Okay, uh, please bear in mind that in my sober inequality here, um, the gradient of f square control the L2P star norm. So P star is the parameter here, D over D minus two. P star is not equal to two star. Okay, just a disclaimer here. Okay, so we know a lot about this inequality. For instance, the optimal constants and the optimizer, they have been computed by Vental and They have been computed by evental entity and even knowledge before. And they look like this. I will call this an Obentalentif function. Okay, so it's basically a function of decay at infinity with a polynomial decay, which depends on D. In my talk, I will assume D bigger or equal than 3. We can do the same in D equal to 1 or 2, but for simplicity, let's take D bigger than 3. Okay, so when you have the Sobolev inequality, of course. The Sobolev inequality, of course, you can interpolate and prove what we call Galliardo-Nierenberg inequality. So, in a Galliardo-Nierberg inequality, here you have on the right here a norm which I call 2p, which is controlled by the gradient of f and another norm, which in this case would be p plus 1. So, bear in mind that I will consider only this family of inequality. Here, p will be between 1 and p star, eventually included, and on the right. Included and on the right we control the 2p norm and on the left we have the p plus one norm. Okay, so we consider this particular family basically because we know the optimizers and best constant of this family of Galiard-Nierberg inequalities. It's not true that we know the optimizers and the best constant for every Galiard-Nierberg inequality. Okay, it's a different problem. Okay, there's also by scaling invariance of curve, we have Scaling invariance, of course, we have a parameter theta which came into play and is depends on several parameters DMP, but it depends by scaling basically. So, what we know about this inequality here is also the optimizers. So, this is a result by the Pino Law of 2002. And they actually say they proved that the optimizers of this particular family of inequalities look like a mental anti-function. Bentalenti function, mental energy type functions. The only thing that changes is the different decay at infinity. So here you have d minus 2 over 2, and here you have minus 1, p minus 1. Okay, so actually, if you put p star here, you get exactly the original obeying. Now, of course, when you, since the inequalities are invariant by scaling, translation, multiplication by constants, when you have found one optimal function, you can create an entire. Function, you can create an entire manifold of optimal function by applying all of these definitions. So, actually, I will speak about the manifold of optimal function in the following talk. So, let me present you what is the stability problem. Actually, the stability problem is a question which was raised by Brazil and Lieb in the 80s and looks like this. So, consider it was, I will do it for the solar inequality for simplicity. inequality for simplicity for simplicity consider the difference in two in the two terms of the solar inequality so you know that for the solvent inequality you have some optimal functions and suppose that the difference is small can you say that for the function for which the field the difference is small you control the distance from f to the manifold of optimal functions uh in the in the original In the original failure of resistance lip, they proved some kind of stability, okay? Not in Rd, they prove it on small domains, on bounded domains. And the first result which proved the stability result on Rd was the result of Jenke Nel, which basically says that the deficit, I will always call the difference between the two terms of inequality deficit functional. Jenkins proved that the deficit controls a distance to the manifold of the optimal functional To the manifold of the optimal functions. And this distance is probably the best one because it's probably the strongest one. It's the H1 distance, let's say. So it's a natural one. So the result was a key result, let's say. The only, let's say, it was a result which the proof of which was done by contradiction plus some compactness argument. Plus some compactness argument. So we don't know, so it's not constructive first, and we don't know exactly the value of this constancy, which is in front of the distance. At least we didn't know, because actually in 2022, in this paper by Del Bo, Esteban, Frank, Figali, and Los, they gave a constructive proof of the stability result with an estimate on the constant here. Okay, I will explain in a moment why. I will explain in a moment why we focus on the constant and on constructive estimates. But let me just present the problem that I will address in my talk and would be the problem of the stability result, but for the Galiardo-Niremberg inequalities. So I will not talk about the Soviet, but I will try to present the main ideas of our proof for this. So, why we look for constructive results and why we look for an explicit constant? Actually, because for us, functional inequalities, for us, I mean for people who study diffusion equations, functional inequality means rates of convergence towards equilibrium. Okay? Actually, we'll see in our slides that functional inequality really implies some rate of convergence. Really implies some rate of convergence, sometimes optimal. And what we actually will prove is that when you have an improved rate of convergence, you can actually prove that you have stability in functional equalities. So the main idea is that stability, functional equalities, means improved rate of convergence. So that's why we also want constructive results because we really want to understand how to improve constructive convergence for this kind of operators. For this kind of operators, and we actually want to know the number. So let me present one really simple example, but in which we have all the ideas that we need for our proof. This example is just the heat equation on a bounded menu. Yeah, Mateo is laughing because he actually explained this like this, but okay. We have, so let's consider the heat. We have so let's consider the heat equation on a bounded domain with Dirichlet theta on the boundary. Okay, so the quantity of interest here is just the L2 norm. Okay, for instance, we know that the L2 norm goes to zero and we would like to understand how fast it goes to zero. So to understand that, you have the Poincaré inequality. The Poincaré inequality basically says that if you have a function in H1, zero, then the gradient of its function controls the H norm, multiplied by H norm multiplied by lambda one. Lambda one is the first eigenvalue of the domain or the rotation of the domain. Okay, so there is this nice computation that says that if you con if you consider the entry norm of the solution of your of PDE, you derive it in time by some integration apart, you find that actually the derivative is basically minus true gradient of the solution. Now, what you do? Well, you use the Poincaré inequality here. Well, use the Poincaré inequality here. You close your differential inequality by grant one argument. You just say, well, then my L2 norm converges to zero exponentially with an explicit rate, almost explicitly. So you characteristic. And this rate is sharp because if you take the first eigenfunction of the Raplacian, then you consider the initial data as the first eigenfunction, the solution will be e to the equation. The solution will be e to the minus lambda 1t for the first inf function. And so this inequality is saturated by this. Okay? Now, let's take another point of view. Let's assume that we have an improved decay rate for our H normal. So let's suppose that our data, sorry, our solution decays with 2 lambda 1 plus epsilon rates. Epsilon rate. Then, what you can actually prove is that basically, if you differentiate close to zero the edge norm, you find this inequality here. And for t going to zero, you find this inequality here, which you can look at as an improved Poincaré inequality. Improved in which sense? Improved in the sense that we have improved the constant. Have improved the constant. So once you have improved the constant of the Poincaré inequality, it's a really simple inequality here that says that, well, I take my deficit here, so gradient u minus some data one u. I notice it's bigger than epsilon naught. And then I can prove, you can put a distance to the manifold of optimal functions, which here just few on. Okay. Okay, this is a toy example. It's not a good way to prove standard. It's not a good way to prove stability for the contrary in the point. It's actually just a way to present some ideas. And the two fundamental ideas here is that we have first an improved rate and let's say a mechanism or a way to transfer the improved rate to an improved inequality. To an improved inequality for the initial data. And these will be the two main ideas that we'll use in our proof. So now, before going to the real proof, I need to introduce some of the quantities. I will transform our Gagliano-Nierberg family in I will write it in a different way. First, from the multiplicative form, let's say from this formula here, we'll write it on an additive form. So basically, we'll write it like this. Instead of having the product here bigger than this function here, we'll write it like a gradient of f plus b f p plus one controls the normal 2p of f. The normal 2p of f to some power. The two inequalities are completely equivalent because basically, by a scaling argument, you can go from this one to this one and vice versa. So it's just one caveat, something very important, let's say. If the manifold of optimal function of this inequality here, of the multiplicative form, was of dimension n plus 2, let's say. Here, actually, Mistake. Here, actually, the manifold optimal function here is just n plus one. This is basically because you choose a scale, and not every optimal function will have that scale, we'd say. What else? So, and we'll rewrite this, sorry, I will rewrite this with two different quantities, with two non-linear quantities, but which are, let's say, very useful in diffusion equations. In the diffusion equation, we first consider the relative entropy. You can think of it as a distance to your optimal function G as Lp plus one distance, if you want. And actually, by the Caesar-Kulwak inequality, this relative entropy controls a distance to your object function. And let's also consider the relative fission information. You can think about that as your grain. Think about that as your gradient, if you want. So it is a miracle that happens because if you take the difference between the relative fisherial formation four times the relative entropy, actually this difference is exactly the additive form of your Galiado-Nebrukman quantity. Okay, so uh have a lot of computation hidden here, okay, but this is definitely true. This is definitely true. So, our strategy will be trying to improve this constant 4. So, let's say our stability result will reach something like this. E minus 4 controls the relative entropy. Because of X-ray work inequality, this is really a stability result. But we want to improve this constant exactly because we want to have the improved rate. Because we want to have the improved rate. So, constant rate. Okay, this is the link. The problem here, however, is that we are introducing in the relative entropy and the relative formation a new ingredient because we are taking this power of g, g to the power one minus p, which is one plus x squared. So, we're introducing second moments in, let's say, In, let's say, in these two quantities. And this somehow changes the topology. Why I'm telling this? Because actually, we cannot improve on the constant four unless we consider some decay of the function f. And there is a nice control example for that, which is basically you take your initial function g, your optimal function g, not, we say, with full mass. Not, we say, with full mass. And you take two small bumps. You make your small bumps going to infinity. And what happens is that the deficit, so E minus 4F, doesn't see any second moment because there is no second moment in the original formulation. But both the relative enthalpy and the relative Fisher information actually do see the second moment. So you are in some. So, you are in a situation in which the deficit goes to zero, but the relative fission formation goes to infinity. Okay? So, you cannot really improve on the constant four, because, well, e minus four f goes to zero, and zero cannot control something because it goes to infinity, right? So, you really need to ask some kind of decay at infinity. And let me first present our theorem. Theorem basically were able to prove this kind of improvement on the constant under some assumptions. I will not comment this one, but I will commit just this assumption here, which is a measure of the tail of the function, if you want. So these are somehow a very real measure, if you want, let me say that. But basically, we know that our functions are in L2P, so we can integrate them outside of a big ball. Outside of a big ball. And what we want to know is how fast they go to zero. So, how fast this integral goes to zero for L going to infinity. And we ask that it goes with this power here. Okay, basically, what we are asking is that our function f goes to zero as the optimal function. Okay, this will be clear in the method later. Okay, no, actually, this. No, actually, this theorem here can be read in different ways because we have improved the constant on the relative entropy. But once you have obtained this inequality here, you can play a lot with it and receive different results, so different kind of stability. So basically, from this, you can really prove a lot. So let me now introduce Now, introduce our tools. So, as John told us yesterday, our main tool will be a diffusion equation, which is the fast diffusion flow. So, the fast diffusion flow, it's the equation that you will see here. So, generally, it's not written like this. The fast diffusion flow, maybe you don't see it very well, the fast diffusion flow is something that we generally write like this with m, it's more than one. Here I Here, I just say this equation is related to that one by just change of variables, so it is nothing really hard. But I just didn't want to write too much on this slide, so let us consider this equation here. So, this is a non-linear equation. M is below one and bigger than this one here, and this equation admits as a self-similar, a self-similar, okay, it's not self-similar. It's not set on this value, but it admits a solution which is called the parent profile and is nothing else than the obent already profile that we have in the beginning. So this equation here is very nice because solutions C infinity, concern mass, concern first moment, and these variable solutions actually describe the asymptotic behavior in L1 and L infinity. Okay, so now the relative The relative entropy and the fission information are related to the equation because they are actually the relative entropy for the equation, and the derivative along the flow of the relative entropy is actually the relative fission information we have defined before. So you have actually this relation between the two quantities. Now, there is a lot of literature on this equation. I have some I have some. I quoted some people here. A lot of people in the room have worked on that equation and you have different points of view. If you really want to know something more, you probably should go to the two books of baskets, but let's say a lot more is known than what I have presented. Now, what is the strategy that we have? So the strategy is basically So the strategy is basically this one. Consider your initial inequality. So fix one P in the family. Now, the P and M, let's say, from the P, you get an equation. So from the P, you get an M, and P and M is related by this formula. Okay. Now you consider your Cauchy problem with your initial data, and your initial data will be the function that you have here. That will be the function that you have here to the power 2p. Now, you make the evolution, you make evolve this function f along this flow. And what you are trying to do basically is to improve the rate at which the relative entropy decays. So, as I told you before, optimal constants means rates. So, from this, remember. So, from this relation, so relative, the derivative of relative entropy is equal to minus the Fischer information. And from this relation here, the Fischer information controls four times the relative entropy. What you find is that the relative entropy decays with a rate four. Okay, what we really like to know, I mean to prove, is to select some data for which relative entropy decays faster. Case faster. Okay. And after that, we'll try. So, first, we'll try to improve the rates, and then we'll try to pass this rate, let's say, to an improved inequality and the initial detriment. Now, let me explain this implication. So, assume that we have an improved rate. How do we pass this improved rate to the initial data? And we have And this is done, this can be done because actually all the deficits along the floor is decreasing. So not only the entropy, but the entire deficit. So if you have, let's say, at a certain point, an improved inequality, so let's say if you have at a certain point that the relative fishing information controls 4 plus eta, 4 plus eta, the relative entropy, then you, thanks to this inequality here, you can, let's say, take this improvement and integrate it back up to the first, let's say, up to the initial data. Basically, just because you have this relation or for the quotient, you have this relation here. And this is just a kind of Bernoulli OD. You take it and you integrate it back. Get it back. Now, the problem here is the improvement that you get really depends on the time at which you established your improvement along the flow. Okay, so this improvement really depends on T. Now, this is kind of a problem because if we really want something explicit, we really need to estimate this T. Now, I will. I will explain how we SMLT later, but let me first explain how we obtain this improvement along the floor. This improvement along the floor is obtained because, basically, as John explained yesterday, when we converge to our Baromer profile, when we are really close to Barnum profile, we can linearize our fission information and our relative entropy around the Barometer profile. And in 2009, in a paper. In 2009, in a paper written by Blanche, Bofor, William Basket, they discovered actually that if you linearize the relative entropy and the relative fission information around the variant profile, you improve on the constant form. Actually, basically, the linearized quantities that you have after the linearization have a relation, and the linearized relative fission information controls four. Relative fission formation controls for alpha, the relative the relative entropy, with alpha which is strictly positive, let's say, at least in our range of parameters. But this real improvement. The real problem is that in that paper, they know how to do this linearization properly if they have a really strong control on the solution. And the control that they have is basically that. That the oscillation V, so V of T over the bar blood minus one in L infinity is less than epsilon. So this is something very, very strong. It's like saying, like, if you have in mind the heat equations, it's like saying that your solution really resembles the quotient at any scale, because this is an infinity of d. Actually, this resulting. Actually, this result would be false for the heat equation. This is true because we are in the non-linear regime. So, we have then two problems here. Establish this and establish the estimate of the time t at which we can have this for a certain epsilon, at least. And this is something that we have done with Matteo in my PhD thesis and also. In my PhD thesis, and also we have written it probably a little bit better in the memoir, you can say that we can obtain this kind of result under the assumption that our initial datum has a decaying infinity. And this is exactly precisely where this assumption came in the proof. This is the exact assumption that we have in the first theorem that I presented. Okay, now the very hard part in Part in our work was to establish a relation between the epsilon and the time at which we can have this estimate. Basically, what you want somehow is to compute the rate of convergence of this norm to zero. And this depends on this decay at infinity of your initial function, the entropy, and of course the epsilon that you fix. That we fix. Okay? Now, now that we have these three ingredients, what you have basically is that you choose an epsilon, you look at the t at which you have the improvement, and then you get your backlog estimate, and you prove the improvement, the theorem, for your initial data. Okay, so the theorem in the variables related to the fast diffusion equation. Fast diffusion equation will look like that, let's say, with axi, which depends on several parameters. And let me see, let me just say that here is how the original proof, how the original theorem looks like. Okay, so with this, I thank you for your attention. Just say a couple of words. Actually, yeah, the field of computing stability estimates for functional equation is very big now. We have quite a lot of results that I haven't quoted. So less less, but it is something very interesting. Okay. Thank you, Nikita, for a very nice talk. Any questions or comments? So, I'm wondering: is there any results now about when you are doing interpolation between, let's say, bounding the LP norm by a lower LP norm and some higher order norm? Like now you are doing the Gagnon-Nierenberg, right? But let's say, suppose it's not the gradient, that's the W2P norm or something like that. For such interpolation, so well, the first thing is that I'm not sure for that kind of interpolation equalities, you really have optimal optimizers. Optimal optimizer. So maybe it doesn't make sense, but do you know how much you can improve the rate? I mean, for if you wait a long time and then you run the dynamics, do you go to the second eigenvalue, or do you know what the... So it's a nice question. I mean, the improved rate, let's say here, we notice it's optimal sometimes. Does it correspond to next eigenvalues? Yes, I haven't really told this, but basically, let's say among these two inequalities, the constant is zero, and you get this one because you have some, let's say, because basically you have the same mass as your butterfly and the same first moment. So you have already an improvement because of some spectral conditions. Okay, so to go to the second. So, to go to the second one, you need the conservation of the second moment. This is false. Because, you see, you can get that one, but you need to change the flow. Actually, this is what we have done for the SOGLAF inequality. No, well, maybe I'll write something quickly, but yeah, it's fine.