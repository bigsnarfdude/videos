Okay, thank you, Gideon, and thank you everybody for coming. Because I clearly thank Fing for doing basically all the job of the organizers. So thank you very much, Fing. So, but let's proceed right away to the topic, the sampling discretization of the uniform norm. So, some of us already doing discretization, and mostly we are doing discretization of. Doing discretization of integral norms. But the discretization of the uniform norm turns out to be very different. I mean, all the phenomena which we have here in space are very different from the discretization of the integral norm. And I will try to demonstrate this today. Clearly, I will not be able to cover all the results in that direction, but we'll try to concentrate on those which kind of give us Give us qualitative feelings of what's going on in this problem. So, we call this problem the Bernstein problem, because historically, the first result about discretization, and that was the uniform trigonometric polynomials discretization, was proved by Bernstein in 1932 or 1931. So, it goes back to those days. And now, we formulate the general formulation of the problem. So, Bernstein problem, so we define, I mean, we take. Problem. So we define, I mean, we take omega in the compact in like Rd, and we can see the n-dimensional subspace, which usually denoted by xn on this compact. And this is these are continuous functions, so the subspace of continuous functions. And now we ask ourselves if there exists a set of points in this compact such that for all x, we have inequality like that. So this is what. So, this is what we want. So, clearly, this right inequality is straightforward. This is an obvious one. But this is what we need to do. So, we should choose the points in such a way that discrete norm of this function, L infinity norm, this set of points, dominates the L infinity norm. And these are just a notational thing. You write it like this. And first of all, this and first of all let me uh let me begin with with some comments that there are many uh results uh on discretization including discretization of the uniform norm for specific polynomials like for instance multivariate algebraic polynomials now and other stuff and there are very interesting uh recent results like for instance by feng dai by andrashkrov and by andrei primac And by Andrei Primac. I will not formulate those results. I will only concentrate on basically results which I am involved in. But one can find discussion of those results and some other results in a very recent survey paper by Boris Kashin, Igor Kosovo, and Irina Limonov and myself, which is already published, but this year, as you can see in the Journal of Complexity. So then let's proceed right away to the material which we discussed. I will discuss and I will discuss and will concentrate basically on two topics. One is the general subspaces and the subspaces of trigonometric polynomials. But in the case of trigonometric polynomials, we will assume, so we will basically not assume anything about this Q. So Q is just a finite subset of this. So that means trigonometric polynomials with frequencies from a given set. But this set is basically an arbitrary set of given cardinality. Of given cardinality. So, and this makes this problem very close to the general setting. It turns out that the results which you can get here is more like for the general setting too. So, historically, let's just give one remark. So, historically, the most simple and well-known case is when this Q, the set of frequencies for the trigonometric polynomials, is the parallel pipette. So, this is the notation for this parallel. So, this is the notation for this parallel pilot. And it turns out that if, in this case, we take the points, and let me just introduce some notation. So, n, these are natural numbers within these limits. And this is the vector with coordinates, we satisfy these inequalities. And now we set the points like this on the cube with the side 2 pi, that means all like we can say in the We can say in the D-dimensional torus. So, if it sets these points, that it turns out that the Bernstein-type discretization theorem holds for this set of trigonometric polynomials, for this set of trigonometric polynomials, and we have this inequality. Certainly, this constant may depend on G. And what is important here that the number of points which we build, so these points which we build, it is clear that the cardinality of the Clear that the cardinality of this is the product of these numbers, right? Of numbers like 4 and J. So, in that case, if we do what we did with these points, then we will get the cardinality, I mean the number of points which we use basically of the same order as the dimension of this set of trigonometric polynomials. It is clear that just from the very simple linear algebra, Simple linear algebra argument that it is necessary to have at least as many of these points as the dimension of the subspace. So, in that sense, this is the ideal situation. So, here we have a constant which does not depend on the cardinality. And the number of points, again, is bounded by the cardinality, maybe multiplied by some constant depending on t. But unfortunately, we cannot even hope for something like this in a very general setting. Very general setting for general subspaces or for general trigonometric polynomials, frequencies coming from an arbitrary subset. Then the question is: we can sacrifice in two different directions. One direction is to lower this constant and try to have inequality like this. Or try to keep this constant here, but in that case, we need to sacrifice by this, by the number of points. So I will discuss both of these directions. Discuss both of these directions. So, and another remark which we will discuss later: that it is clear that in this setting in our results for these points XN, which we introduced, that these points depend substantially on the vector n, that means of anisotropy of that parallel pipe. So, let's first discuss the issue what I just mentioned. Discuss the issue what I just mentioned: that we will try to have the number of points of more or less of the same order of the dimension, but we are ready to sacrifice but a constant, which is there. So, in that case, and this is what was done by Boris Kashan and myself, and was published in 2018. So, this is for trigonometric polynomials. Let me formulate this problem explicitly. So, SM is annotation. So, SM is a notation for the points which we use for discretization. So, this is the discrete norm. And this is clearly the case. But now we are looking for the quantity like the following. So, if Q is fixed, Q is fixed. And M is also fixed, and M is the number of points which is allowed to be used. So, then you look at this optimization problem. So, for the whole set of trigonometric polynomials, you take a Of trigonometric polynomials, you take a supremum. So, this is supremum of this. So, this is the same as what would be infimum of those constants C1D. And then infimum overall SM. So, this is optimization of all the points, but what is fixed here is the number of points. So, this characteristic depends on this Q. And then another one, which is in a sense more interesting for us, then we take supremum of this extra multiplier, as you will see there. Extra multiplier, as you will see, this factor over all sets q with cardinality n. So then this quantity depends only n and n and m. Clearly, depends on d, but very, sometimes you just suppress the dependence on d. So these are two of the most interesting for us quantities. So what we can prove in that. So as I already mentioned, the condition for proving anything like this is that the Proving anything like this is that the number of points should be greater or equal than the dimension. So, and then for fixed Q, this characteristic guarantees this inequality. So, this is basically what I was talking about. So, the discrete norm dominates this one, but with some extra multipliers. This ideal factor here would be just a constant. And in the case, as I already mentioned, in this classical case, when Gerstein proved this for dimension d equals. Bernstein proved this for dimension d equals one, but it can be easily generalized for arbitrary dimensions. Well, basically, the Bernstein theorem says that in this particular case, this d, this m of order, of the dimension, can be made just a constant. But now let's look at the negative results. So, what we proved with Boris Carson is the following. So, qualitatively, we basically proved that you basically proved that you have this quantity that d and m is of this order if m if you want m the number of points to be of the order of the dimension of the subspace so that means we cannot do better than square root of n and the precise formulation is as follows that means for any constant there exists a positive constant c such that for any pair of these numbers that means Of these numbers, that means n dimension and n the number of points, with this condition, so this m does not exceed n in the sense of order, we have this lower bound. What does this mean? Because g n, remember, this is the supremum over all q, over all subspaces. That means there exists a set of q, which depends on this, may depend on this n, with this property, with q instead of this n. So square root of n, this is what we need to sacrifice. And this is what we need to sacrifice anyway. And another complementary statement here: that, as a matter of fact, indeed, in this particular case, when we are talking about trigonometric polynomials with frequencies from a fixed set Q, we can achieve that. We can achieve the square root of n. So always there exists, and if m greater than this, I mean of order of n, but bigger than something, some constant multiplied by n, then we can do that. Let's proceed. Let's proceed to another interesting case, very special, it seems like a very special case, but it is very important in hyperbolic cross-approximation. And this is, I would say, one of the special examples of trigonometric polynomials, which is important in approximation theory, in applications for approximation of classes of functions with smooth smoothness. So, this is an important one. So, what is that? So, what is that? That the hyperbolic cross polynomials are those which have frequencies from the hyperbolic cross. And the hyperbolic cross in D dimension is this one. So basically the product of this. And we put maximum between this because when k is zero, so we need to bound this, but then we put just one here. So this is the hyperbolic cross. And we introduced two notations. And this alpha D, if you look at Alpha D, if you look at this, it's clearly I make this remark right away that this is of order log D. So one over J, that this is of order of log D. And this is another one, beta D, which is close to D, basically. And it turns out that the following result holds, and I should say that it is a non-trivial bound, and I will mention some trivial bounds, but this was proved by Shen Dai and Draper. Fendai, Andrei Primak, Sergei Tikhonov, and myself. And it is published in the paper, which is a kind of mixture of survey paper and new results paper that was published in 2019. So what is the result? The result states that if G is fixed. Claudia? Yeah. Wait a minute. We had a problem and we didn't hear your last five minutes or so. So just a minute. Maybe go back with the slides and I'll tell you where just one minute. No, no, no, no, go forward, go forward. Did you hear this theorem? No, no, go backward a little bit. Maybe. Maybe we were around there. This is okay. Okay, you can start from here. That's but do you hear me now? Yeah, yeah. We didn't hear you from here and on. Ah, okay, but you think that the problem is resolved now? Maybe you should turn off your camera. The connection will be better. Would be better. There was a problem with the connection. You got stuck first and then you disappeared completely. If you turn off the camera, I think the problem is on that side, right? But if I was on your side or our side, so no, no, everything exactly is internet. Okay, so okay, let's try again. You can continue from here. Yeah, and you have. From here, yeah, and you have five more minutes, even more. Okay, okay. So, these are simple remarks about that quantity, which is DQM. So, basically, this is that extra factor which shows how much should we sacrifice for this particular set of trigonometric polynomials in the discretization problem. So, if you know this quantity, that means you know. This quantity that means we know that there exists a set of points of cardinality m which satisfies this inequality. So, and with this extra factor. So, in the case of what we have discussed before of Bernstein's theorem, when this Q is a parallel pipette, in that case, this is just a constant. It's a constant. But in other cases, we need to sacrifice something. And this is what our theorem is more discussion from 2018 shows. 2018 shows that this theorem, roughly speaking, says the following: that if you want the number of points to be of the order of the dimension, then we necessarily need to have this as square root of n. And also it is sufficient. So square root of n is something, this is what we need to sacrifice. So this is formulated as a theorem which says that this one is greater or equal than this. So that means that if you take. So that means that if we take two numbers which are related like this, then we get the lower bound like this. And on the other side, for any set Q of cardinality N, we can always find the points such that there is a number of points with M satisfying like this and inequality with inequality like that. So in that sense, it gives us the extra factor. Gives us the extra factor which we need to sacrifice in that sense. So, and another example, which is an interesting example, because this is important in applications for hyperbolic cross-approximation, which is important for approximation of functions with mixed smoothness. And this is hyperbolic cross-polynomials. Let's discuss this discretization of L-infinity norm of polynomials like that. So, these are precise definitions. Are precise definitions. So, g these are polynomials with frequencies in this gamma n, and gamma n is the hyperbolic cross. And hyperbolic cross is this. So, this is the product of all these kgs, and this is less or equal than n. And right away, we introduce two quantities, alpha d and beta d, like this, but alpha d is of order log d. So, from here, it's clear that this is of order log d. Log D. And here is the result. And this result was obtained by Fendi, Andrei Primac, Sergei Tikhanov, and myself. And basically, the theorem says that for these hyperbolic crosses, hyperbolic cross polynomials, the number of points M, which is sufficient for good discretization of L infinity norm, is a constant here. C depends on D and does not depend on the number of points. Dependent number of points. And the bound for m is like that: the constant n to the exponent lambda d, this alpha d, and some extra logs. But let's first look at this one. Because alpha d, as I said, is log d. So it's not one, because it would be very nice to have one here and some logs here, because the cardinality of hyperbolic cross is exactly like n log n to the d minus one. However, we cannot do that. We cannot do that. And we cannot do it not because we cannot do it. It cannot be done. I will formulate this result a little later. But this theorem gives us the growth for n as n to the exponent, roughly speaking, log d. So some remarks, trivial remarks. So it is clearly well known that this hyperbolic cross is contained in the cube of size n. So basically this. Of site n. So basically, this is clear that we have that because of the Bernstein theorem. But this means that the number of points which we take is n to the d. But that theorem which I just formulated says that we can replace this d by log d. So it's a huge, huge improvement. But we still don't know if we can, for instance, replace log d by just a constant. It's an open question. We cannot make it one. This is what we. You cannot make it one. This is what we know, and this is what I formulate right away. But we don't know if you can replace this by something growing slower than log D, ideally by a constant. But the lower bound follows from all the results with Boris Cushion. So this trivial result and the dimension of this of this order. So as you can see, this n multiplied by this log n to the g minus one, this is necessary. N to the g minus one, this is necessary. We cannot go without that. But it turned out, and this is what we proved with Boris Casson in 1998, that even n to the exponent one is not enough. So here is the theorem. So if you assume that the set of points W is such that we have an equality like this, you can think about this inequality with alpha equals zero. So that means this is just a constant. If you can bounce. If you can bound the L infinity norm of polynomials from the hyperbolic cross by the discrete L infinity norm, and these are points, W is a set of these points. Then necessarily, and this is what CRM says, that the cardinality of this set W should be bounded like this from below. But say let's substitute alpha equals zero. So if alpha is zero, so this disappears, and we have E to some exponent. we have e to some exponent and log n is there so this all this extra term will be n to some power c and c is a positive number c is a positive number but as you can see here we proved this for two-dimensional polynomials clearly it's the lower bound it holds for d-dimensional but uh there could be a hope that in d dimension we can get something better uh and th this this extra uh factor here growing with d. Factor here growing with D, but we don't know that. So, this is the best what we know. So, and this is what I just said. So, this is what is required. This is necessary with some positive constant C for the number of points in order to have an equality like this without this extra login, just with alpha equals zero. Okay, let's proceed further to another setting. So, let's discuss the following issues. The following issues. First of all, let's talk about universal Bernstein type discretizations here. And I will explain what universal means. And also important issue is how to build constructive sets of good discretization. This is what I will not touch today, because in some cases we can do something, but this is a big question. So in many cases, we can just describe the procedure how to get it, or in the most cases, this is just probability. Most cases, this is just probability or the statistical approach, and you know that this point exists. So, basically, the existence theorem, but you don't know how to construct them explicitly. So now universal discretization problem. So, in the previous one, what we discussed, that was the discretization for each particular subspace. We have a subspace and we build the discretization for this subspace. But sometimes, and there is a motivation, I will not talk about this. Is a motivation. I will not talk about this in all details, but this motivation goes from M-term approximation when we approximate with respect to the dictionary, that very often we want to build something which is good for all the subspaces. So the set, for instance, of points, like in our case, is one and the same for all subspaces. Like this is what we say universal. So we say that this set provides universal discretization. Provides universal discretization for the whole collection, and this is a collection of subspaces. If for each subspace, we have an equality like that. So, see, this set of points does not depend on this J, but it serves as a good one for all of them. So, and what I will formulate, there is not many results, especially for Lantinity. For integral norms, there are some results, and recently we got, I think, pretty strong results with Svengai. Strong results with Fengai, but I will not touch that. But let's discuss just L infinity, a uniform norm, how it is said in the title of my talk. So let's consider the following collection. I already pointed out, talking about the Bernstein theorem, that if you take the trigonometric polynomials with frequencies from different parallel pipettes, then the set of good points heavily depends on anisotropy of that parallel pipette. Isotropic of that parallel pipette. So now we want to build something, some sets which are good for all of those parallel pipettes or for all those trigonometric polynomials or for the sets of trigonometric polynomials. And there is a rigorous formulation. So let's consider this RS as a rectangle of K, which satisfies this. So S is a parameter, not a parameter, it's a vector parameter. So this is an integer positive, non-negative integer. Positive, non-negative integer vector. So, and we build this RS, which is anisotropic. It is clearly, and anisotropy is hidden in this S. So, and now we consider the collection of all trigonometric polynomials like this. So, these frequencies from these parallel pipettes, from different anisotropy. And the condition is this. So, basically, this condition means that the dimensions of all of these subspaces here. All of these subspaces here are roughly two to the n. So these are close to that, these are close to that. And we want to build something universal. So a priority clearly, it's not clear if it's possible or not, but it turned out that yes, it is possible and we do not even need to sacrifice with the number of points. And here is the theorem. So there exists a large enough constant which depends only on D, such that there is a set, and as you can see, M is greater than the set of m. And as you can see, m is greater or less or equal than constant than 2 to the n. And 2 to the n, as I said, this is the dimension of that, provides universal discretization and L infinity for the whole collection. That means there is a set which does not depend on n isotropy, but for each of these R S, it provides discretization of L infinity norm. So this is what was proved, as you can see, in 2017. As you can see, in 2017. And let me explain and describe, I mean, make a connection to some other topics and talks in our workshop. That it turns out that this is closely connected with the concept of dispersion. And this concept was already defined on Monday. And let me just remind that. So, what is the dispersion? So, this is again rigorous definition for that. We introduced For that, we introduced the concept of d-dimensional parallel pipette like this with sides parallel to the coordinate axis. And this is that. And this is the whole set of this. So x, y is just this box, the direct product of intervals. And we consider this collection. So then we define the dispersion of. The dispersion of this set T of points in the unit cube 0, 1, by this formula. So, what is that? That means this is superenum of the volume of boxes like this, which are empty from the points of T. So, this is the biggest volume of the box of this type, which can be inscribed in such a way that it does not contain any points of. That it does not contain any points of this set T. So this is dispersion of T. And certainly we are interested in the number which is like infimum for this overall T. So this will give us fixed cardinality. So this will give us the lower bound for this, the upper bound for this dispersion. And now the theorem which was proved Which was proved basically that the existence of universal setting was a corollary of the theorem, that it says the following: that if the set T with cardinality has dispersion satisfying this bound, so this is a pretty good bound for the dispersion because there is of the same order lower bound for the dispersion for any t with some constant cd. Then there is a constant such that this set. Constant such that this set, that means basically this same set, but multiplied by 2 pi, so they extend it to the cube of size 2 pi, provides a universal discretization and net infinity for the whole collection. So they mean the set which is good for dispersion, that same set is good for universal discretization. So this is in one direction, but it turns out that it is also true in the other direction. It is also true in the other direction. So, if we assume that this set provides universal discretization and L infinity for the whole collection, that it turns out that it must have small dispersion. So it's like here. So that means these two things, the properties for this set of points, either to have low dispersion or to be universal for this collection C and D, these are equivalent. These are equivalent. Indeed, these are equivalent. These are equivalent. So basically, this is what was proved. But then now we need to build or find somewhere the good points with small dispersion. And one of the examples, and this is very non-trivial example, this is the set which is called TRD net. So what is that? At least for the definition. From definition, it's not clear if these points exist, but let's look at this. We consider the boxes of this type. The boxes of this type. So basically, we divide the whole cube into small dyadic boxes, but these are anisotropic. So S is, as before, is a vector, which gives us anisotropy. So in the first direction, this is S1, in the second, S2, and so on. So the intervals of the lengths to the negative S1, to the negative S2, and so on. So these are all the collections. And we want. And you want, so and each of them is of this volume, and you want each of this box contain exactly two to the t points, exactly two to the t point. So it's clearly from this definition, it's clearly a very, very, very strong requirement. But it turns out that this kind of TRS nets, they do exist. And this was proved by, it was. It was proved, I mean, using very non-trivial and number theoretical and basically algebraic theory. And that is very, very non-trivial construction, but they exist. They exist. So this is what I want to finish with that slide and proceed to the next one. So now let's talk about another issue, what I mentioned in the very beginning, that suppose that we That suppose that we want to have inequality with the constant L here. L is a fixed constant. So, suppose we have this. So, what can we say about the number of points which is necessary in order to provide this discretization theorem for this particular and fixed space of trigonometric subspace of trigonometric polynomials? And it turns out that the trigonometric polynomials, the lacunary trigonometric polynomials, they are really. Polynomials, they are really bad from this point of view. That means they are very hard for discretization of L-infinity norms. And here is a theorem which we proved with Boris Carshan in 2018. So if you take the Lacunara sequence, and this is written here, what is that? Then, and assume that there is a set of points, and this everything here is univariate, as you can see here, and this set provides this inequality. So, discretization of L infinity. Inequalities of discretization of L infinity model. Then it turns out that this m is m, the number of points should grow at least exponentially, exponentially in n in dimension of these points. So lambda n is just n, we could write this n, but if you look at this, this is exponential. So clearly if L is allowed to depend on n, then we can kill this n. But if L is fixed, that it is an exponential growth in n. It is an exponential growth in n. And it turns out that this lower bound can be achieved, I mean, as an upper bound, and even in a very general setting. And this is what we did with Boris Kashan and Sergei Kanyayan recently. And this paper already appeared as an archive preprint, but it's not published yet. But it's not published yet. So let me formulate some of those results. Then, what we proved before I yeah, maybe I don't have much time, so let me skip this and go to that theorem. So let me just go to this one. So what we proved. What we proved that for any now it is a general setting. So now xn is any n-dimensional subspace of continuous functions. Then there exists a set of points of that cardinality such that we have this inequality. This theorem and the proof of this theorem is rather simple. It just uses entropy and the points which are Which basically provides the epsilon entropy of the set of this Q and of the unit ball in this Xn. And we just get this bound. So let's comparatively simple. We have another proof, and I may comment on this. But now let's look at the following trade-off, what we have here. So on one hand, this complements the lower bound. Now, this complements the lower bound. So, the lower bound shows that we cannot do better than exponential, and this shows that yes, we can do that and have this exponential. And this is a positive result. But is there any trade-off between like this constant and this number? So, maybe we can do something with smaller points, but then we would like to understand what should be sacrificed here. And there is another way, and now let me let me. And now, let me discuss this in just a few words. So, let me call this like a refined upper bound. So, instead of constant two, we allow now the constant which could grow with n, but then we hope to have a smaller number of points in that discretization. And it turns out that this one, this approach is actually a very natural approach in a sense, but it is closely connected with. Is closely connected with some results in functional analysis, and that was called uniform approximation property. And there are nice results, and one of the papers which kind of connected to that is the paper by Figil Johnson and Scheckman. So using that paper, we can give another proof of that upper bound, clearly not with nine to the exponent n, but with some constant to the exponent n. But anyway, To the exponent, and but anyway, that deep results and functional analysis allow to prove the best possible in the sense of order, I mean logarithmic order or whatever, results for this discretization. So let me explain what's going on here. So what we do, we first for the subspace Xn, we build what usually called the Dirushley curve. So we take any orthonormal basis. So, we take any orthonormal basis. It doesn't matter because this Dirichlet kernel does not depend on the specific orthogonal basis. This is the same. So, we build this. And then, if it is the case, then the property of the Diruchle kernel is that when we use this as a kernel of the integral operator, then this is just the identity operator on the subspace xn. And now we need. And now we need to extend this operator. And I need to write this in this form, not in the operator norm, and I will explain why. We need to approximate this by linear functions of this form. So basically, we want to make out of that operator an operator of fixed rank, maybe big rank, but we would like to have it bounded. There's an operator from LNC. Is an operator from L infinity to L infinity, and one of the requirements is this. So that means we want to keep this good property that f is still like this, replacing this by this approximation. And we consider this quantity. That means we approximate this function, the kernel, by functions like this, bilinear functions with this extra property like this. And we consider that this is related to the operator norm. Is related to the operator norm of this integral operator with kernel like this from L infinity to L infinity. So, this is what we consider. And it turns out, and this is what we proved in our paper, in this recent paper, that if you do that, that we can get the discretization result of this type, that the L infinity norm is bounded by the discrete norm. Discrete norm. And as an extra factor here, we have this quantity which is the best M-term approximation with this extra condition on this bilinear forms. So this is what we prove. And this is what is written here. It is an important point because everybody will ask, what is this M? What is this M? And this M is related to X M is related to some conditions on the subspace Xn, but these conditions are formulated in kind of not a direct way. I will formulate this condition D in a minute. And one of the reasons why I already mentioned that we are talking about functions, because at the end of the day, we will need L1 discretization of some special subspace which is related directly with this Xn. Now, let me maybe just. Now, let me maybe just give you, let me maybe not go into all the details here, but you will see what is that. So if you assume that some of the this function from that class, which I described, is a good one, that means it approximates our Dirichlet kernel with almost optimal, that means times two arrow. Then we build a subspace and this. Build a subspace. And this subspace YS is like that. So this is a span of we take functions from here, this star, we multiply it by F. We take these functions u from the Dirichlet kernel, multiplied by F. So we build this subspace. And it is easy to estimate this subspace, the dimension. And it turns out that in order to prove that result, which I just formulated, we need the discretization of L1 norm. Of L1 norm on this subspace YS. And it turns out, I will not go in those details, that it turns out, so we need a discretization like this. But and this is what we need. So this is the condition. And it turns out that there are theorems, general theorems, which we have, which guarantee that for any subspace, any subspace, and this is very important. subspace and this is very important because we cannot control what is that ys here right we don't know this this function but there is a result that for any subspace we can build a weighted discretization of l1 norm with these conditions with m big enough but bounded by the dimension multiplied by log of this dimension to some exponent like exponent three is is is enough so in that sense the serial diffutization and L1 Of diffutilization and L1 turns out to be very useful in application in this L infinity. And this is just a formulation of this here. This is formulation of this here. And now in order to finish, let me skip some stuff and jump to the following problem, which is easy to formulate. And this is directly related with this stuff. And this is the following problem. And this is the following problem. So, when we are talking about the Tiruchle kernel, so certainly in the case of trigonometric polynomials, because in the previous case, this is a general setting, xn is a general subspace. But if you take as a subspace the trigonometric polynomials of this, then the Dirichlet kernel is this, right? And we need to approximate the dqx minus y in a bilinear form. But we say let's approximate this one in that form because this will. This one and that form because this will give us clearly the upper bound for that approximation in a sense of bilinear form. So, and then the question is, how well we can approximate the Diruchle kernel? So let's just step aside just for a minute and forget about all this discretization, but just ask the following question. So let's assume that Q is given, any, and we build a Dirichlet, and now we want. kernel and now we want to approximate this direction kernel this dirich kernel by exponents so by exponents from lambda and lambda the intersection with q is empty so with all the frequencies which are outside of q but the number is fixed and how well we can do that and this is the question and it turns out and uh this is what uh we proved let me not do this We proved, let me not do this, just skip it. This is what we proved with Boris Kashin and Sergei Gagnagin that it turned out. So, this is the theorem I just formulate this as before, but the interesting result is kind of non-trivial one, is the following, that for any Q, we can approximate in that sense like this to make this. Like this to make this to so, in a other sense, we can build for this Dirichlet kernel an extension to like the Lavo Leposand kernel, but we need to extend, and it is in this theorem it is sufficient to extend to the number of extra frequencies, which is of exponential order. So, two to the four, and this is cardinality of this q. So, certainly, in that case which we started with, with Case which we started with with the Bernstein theorem. You don't need that. We need just because this is parallel pipeline, we can build the Lava-Lippo-Sen kernel using extra points or extra frequencies, which are of the same order as a number of points in the Dirichlet kernel. But in the general situation, when Q is a general one, it turns out that you cannot do better than that. Depending on Q, you can improve, but in general, you cannot do better. Improve. But in general, you cannot do better. Like, for instance, for this Lacunara sequence, you cannot do better. But it is a positive result. It is a positive result. So I think I will stop at this point and thank you very much. Did you hear me in this second half? What is the question? Did you hear me? Was it okay? Yep. Okay, okay. That is that. Okay, okay, that is good. That is great. Any questions from the people here in Oaxaca? I have a question. Okay. Do you know why Gerstein considered his problem? Why it is so interesting? They. They did this basically, not only Bernstein, but also Martin Keich and Sigmund. Basically, they wanted, but that is for the integral norms. Bernstein considered this in two settings right away: in trigonometric and in algebraic polynomials. But I think that is that is. I think that is that is that is I don't remember exactly the paper of Bernstein and Bernstein paper this one that that was published in in in Harkoff proceedings or something so I don't think I even even who saw the original paper of Bernstein but at least as to Martin Kiewich and the Sigmund motivation they did the following so they really started like L1 norm Like L1 norm and so on, but they said that. But what if instead of a Lebesgue measure, we consider another measure, and in this case, it's just discrete measure. They wrote this in a little different way. That means it's kind of still TS integral. But anyway, this is equivalent to that. So that was a motivation. Thank you. Any other questions? Okay, so thank you again. So, thank you again. Thank you all.