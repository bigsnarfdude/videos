All right, guys. Um, welcome to this uh little session. I know you guys have had um uh manifold opportunities to hear so many things about competition advertising. I'm going to start by really uh apologizing that I am not a specialist in this field and I haven't written a single paper in this field. I just happen to have been part of the GDRR program at Sam C. I was one of the leaders along with. I was one of the leaders along with Fabrizio Ruggieri and Rafiq Sawyer and David Rios in Suar from Spain. And then I ended up hanging out with the people in the so-called computational advertising working group. And that's where I picked up some of the ideas and I started looking at some of the things that happened in there. My title is very telling. I'm using words that frankly don't belong with mathematics or statistics or computer science for that matter, except for cursor dimensionality, of course. Cursor of dimensionality, of course, but I'm using those words because I think those words are suitable for what it is that I want to draw your attention on today. I became exposed to competition advertising and I realized it was a bigger, bigger monster than I knew. And I know that throughout the week, you guys have talked about the techniques and the wonderful things and algorithms, you know, collaborative filtering and click-through prediction and all that stuff. They're beautiful. I mean, you know, I studied. Beautiful. I mean, you know, I study attention, I read papers and all this stuff. Those are things that I'm going to call here the blessings of competition advertising. The things that I believe for a scientist are the good things because they allow you to do science, create new algorithms, publish paper, get promoted, on all that jazz, even get a raise, you know, and be considered important. But the reason why this talk is titled The Ways Title is because behind that blessing, behind those blessings of computational advertising, Of computational advertising, there is a curse. In fact, not one, many curses that have been documented, and that I hope that some of the mighty, incredible scientific acumen that people have that caused them to generate the blessings, they will use the same acumens to circumvent the curses. That is my talk. You may leave now because I told you everything. There's nothing else to say. I told you exactly what I'm going to talk about, right? But I About right, but I cannot give this talk if I did not go to Samsey, and that's why I give thanks to Sam C. I dedicate this talk to Samsey, especially because Tampa is terminated. So I'm giving this talk just like my goodbye to Sam C and my thanks to Sam C for all the blessings. I was one of the first postdocs at Sam C back in 2003, and Sam C has been an incredible blessing in my life, getting to know David Banks, a great friend, and his family, and getting to know people like Jim Berger and all that. So that's why I Burger and all that. So that's why I think it's really fitting because I'm talking about the blessings of competition advertising. It's also good to recognize the blessings I received from these people, especially from this great organization, Samsi, and the people who led it. And that's why I'm saying this word. Okay. So I thank David for inviting me to do this. Even though he knows that I'm not a specialist, that I know nothing about competition advertising. I'm just learning. I'm trying to explore what it is. And I want to thank all the guys who co-directed the GDRR with me. And I want to thank the people. With me. And I want to thank the people in the competitional advertising working group because, you know, it's there that I even discovered this existed. And certainly, I want to thank you guys for putting up with me. All right. So thank you. Let's start. These two ladies were the two ladies that brought my attention onto the curses of computational advertising. Two beautiful ladies, wonderful PhD candidates. And I think they're almost on their way finishing something right now. Esne is on the left and Master is on the right. And it works. Masses on the right, and it was with them that I started developing the review paper. That we hope when they are less busy, we will put some finite touches and actually publish it. And then my part in that paper was on the blessings, actually, because I didn't know the curses. My part on that paper was really to come in and talk about the statistics of competition advertising, the grid algorithms, how you make them fast, how you make them good, you know, click through rates, predictions, and all the deep learning stuff involved in that. Deep learning stuff involved in the all the nice algorithmics and all the beautiful things that you guys have talked about at Noseome that I know very little about. And that was my part on the paper. And the two ladies, because they were interested in this, they were interested in the so-called algorithmic fairness. They were interested in all those very interesting problems that are almost like the social justice aspect of our emerging field of statistical machine learning. I owe them to have opened my eyes to some of this. So, thanks to Esny. Some of this, so thanks to Esni and thanks to Masa for introducing me to this. All right, and thank you. Anyway, here is what I said: there's nothing technical in this. There's no formula. I did not put an equation here, which is unusual because I was raised by French people. Everything is a bunch of equations, a bunch of equations and a bunch of theorems. But it is the first time in my life I give a talk where there's literally zero equation. I mean, zero, none, period. There's no one, no equation, because I'm going to be focusing. No equation because I'm going to be focusing on things that I start to believe right now at my age. You see, my beard is gray, that I realize that these things might even be more important than my theorems, far more, in fact, because they justify everything. Okay, so that's what I'm saying. The disclaimer is that this work, this talk is not technical. Some of the things that I see here will shock you. In fact, if you're in competition advertising, you probably know them. Some of them are ugly and some of them are sad. And but. And uh, but but your algorithms are helping that. So, I'm going to be asking you at the end, open your eyes and be a little bit more aware. Don't just do algorithms, do more than algorithms. That's what I'm going to be telling you to do, not because I'm here to tell you what to do, because I think that's what is supposed to be done. We can't do science blindly. We are not blind fools. We're intelligent people. And that intelligence cannot only be used in a raw way, it has to be used in a humane way. Hence, the running title of my talk is human. Running title of my talk is Humane Computational Advertising. All right. So, what are the blessings? The blessings is what you've done all this week, throughout this week. Starting Monday, you have talked about the blessings and blessings and blessings. And what are they? They're all the things that you've done that is some of it is actually captured in this paper from the journal advertising. What this paper is saying, it's saying that they're advancing competition advertising, advancing competition advertising, conceptualization of the field and the future directions. The field and the future directions. Now, you understand that these guys are not mathematicians and statisticians like computer science, like you guys. They're not. These guys are in general advertising. So, but they're talking about conceptualization, right? They're talking about some of the different axes that computational advertising follows. But the sad part of this paper, it's interesting because, I mean, I'm not a specialist in this field, but what's interesting in this paper is that I think it does a good job. It, I think, it does a good job highlighting what it is that is interesting in what I call one side. I mean, the two sides of this is that you do the science, but people use the science, right? So you do the science and people use the science. These are, they're talking about how nice to do the science that people can use. But I don't think I might have misread or I was probably sick. I did not see them mention anything about what it is that Esne and Massa brought my attention to. Esne and Massa brought my attention to that I've since discovered are some of the aspects of competition advertising that are worth effort and time and attention, both from an advocacy perspective, but also indeed from a scientific perspective, maybe borrowing a little bit from adversarial risk analysis and adversarial machine learning to probably circumvent some of these problems really, even algorithmically. Of course, although I recognize that I'm not naive, of course I'm not. I hope not. I recognize that. I recognize that, as a matter of fact, some of the things that I'm highlighting here, some people don't care about it, and some people care, but I think we should care. Okay. So this is a future of competition advertising with view from the point of view of all the blessings, i.e., view from the point of view of all the techniques. And I call them blessings because it's beautiful when you do good math, beautiful when you discover an algorithm, when you create a new estimator. It's wonderful when you improve stuff. It's wonderful when you improve stuff scientifically and get a nice publication and get recognized, it's absolutely awesome. But how people use what you create is extremely important. Like in those days, we used to think that the only science that could be used to create problems was chemistry or, you know, the people who manufacture bones or physicists. But it turns out that there's a lot of crimes that are committed with mathematics. I mean, the mismeasure of man is one of the perfect example where people are using statistics and, you know, Using statistics and in order to do things that are evil, okay. So, here are the blessings. Frankly, I should not spend enough time on the blessings because you know it. You have done this. You guys are specialists. You do this. You guys, I saw the menu of talks. It's fantastic what you guys are doing. It's actually amazing what you guys are doing. So, so here is the definition of computational advertising, right? So, this paper defines computational advertising as a broad data-driven advertising approach relying on advertising approach relying on or facilitated by enhanced computer capabilities, mathematical models and algorithms, and the technology infrastructure. So this is the part of computational advertising that is beautiful, where you are just using your intelligence to find ways to, you know, good market segmentation, good recommender systems and all that stuff. This is fascinating. It's beautiful. And for somebody like me who likes algorithm, I find this very nice. Algorithm. I find this very nice. And in the paper, which you can easily find in this paper, you see, this paper is right here. It's in Taylor Francis' paper. It's quite interesting. I think it's very nicely written. Like I said in my disclaimer, I organize everything around some aspects of this paper and I tease out elements from it in order to present what it is that I wanted to highlight here in the second dimension of it. The second dimension of it. So they're taking the starting from this diagram, what it is they recognize as important aspects of computational advertising. And I'm making the claim that this taxonomy or this representation, this Venn diagram is really wanting. It doesn't have as much as it should. A Venn diagram should contain the aspect of competition advertising that I'm willing to bring our attention in. So these are things that you guys know. So, these are things that you guys know. People spend a huge amount of time in competition advertising, coming up with beautiful techniques for real-time, the so-called personalized competition advertise. The two words that they use a lot is targeting and use targeting and then things like personalized, like they get you information and all that stuff to know exactly what you need and constantly track you down and give you good things. So, I don't know, they're good things always, but. I don't know if they're good things always, but you know, so this is one of the branches of focal points of computational advertising, which again is not something that I can teach you anything about because you know you work on techniques that help you do that. And, you know, and I have knowledge of the way those techniques work. I mean, I've worked myself on many aspects of recommender systems. I teach that every single day that people are trying to come up with recommender systems. Come up with recommender systems that are really more sharper than before and that overcome some of the limitations of traditional recommender systems, including problems like the sparsity. And they can find different ways to solve this problem using non-negative nature factors and a bookload of different techniques and collaborative filtering and all that. So these are the focus. People have done great work. And I'm sure many of you listening in this audience, you have done a lot of wonderful things. You have done a lot of wonderful things, you know, related to this aspect of it. And I know that there's so many things to be done in there. In fact, in my contribution to the review paper that we are finishing, I'm looking at aspects of how you improve those techniques and how I can work with students and collaborators to improve the techniques. You know, another aspect is real time. So, this is all harnessing, as I'm saying, there is something to be said, absolutely, from a scientific perspective. Absolutely, from a scientific perspective, of working harder and understanding, really, this could be a fascinating engine for even understanding human behavior in a wide variety of ways, you know, using real-time bidding system. And I know David and David Angy worked on stuff like that as part of that competition advertising working group at Samsee. And a huge boatload of text mining, sense that a lot of this stuff, the data comes to us in text mining. So we almost have computational advertising. almost have competition advertising to thank for a huge huge amount of extra research that's been done in the field of text mining and text categorization and text analytics in general and some of the demand is generated from that field. So those are blessings. I recognize them. They're fantastic. They give good science and beautiful ways to come up with new algorithms, brain-inspired, nature-inspired algorithms and all that stuff. And all that stuff, and you know, combining supervised learning, unsupervised learning, reinforcement learning is fantastic. And I was talking right at the start of my stuff about click-through rate predictions and stuff like that. And I spent a huge, huge amount of time on this stuff in my personal research. And these are all wonderful things. And, you know, blessing on that. So, here's the point I'm trying to make. I'm trying to say a conference like this is fantastic. David and the people organizer put this together in order to. Organizer put this together in order to highlight some of the statistical aspects of competition advertising. And that's phenomenal. And I love statistics. I can't even hide it if I wanted to. But, like I say, as I get older, I'm beginning to realize that there's more to life than just loving all these Greek symbols and creating Greek theorems, because if what I create turns out to be a weapon, and that's actually dangerous against me and against people, that's not very good. So, these techniques are fine. You know them. And I'm saying I'm making. And I'm saying, I'm making a claim that this diagram I think falls short. I mean, it should competition advertising should contain many aspects that until now overlook. And again, the reason why I'm saying it, I'm saying this in a spirit of adversarial machine learning. Like, you know, you can construct a learning machine that can easily be attacked because it lacks robustness. And now that is probably like, you know, somebody is. It's probably like you know, somebody is very well intended, constructs a machine, but somebody else has evil intentions and comes in and messes up the classifier for malicious reasons, you know, for all kinds of reasons. I don't know. But then people are using the intelligence and combining aspects of game theory and many aspects of robust statistical analysis to construct learning machines that are even preemptively strong against those attacks. As if you construct a robust. Against those attacks, as if you construct a robust estimator, people are beginning to do things like that. What I'm making a claim right here, or even an invitation, is that it would be nice if people designing and contributing to the future of competition advertising will do so with an awareness that they're building things that I would think the source of the richest people in the world right now is those search engines. I mean, when I was a kid, I didn't think that search engines. It, no, you would think that search engine would make somebody a billionaire, but it drives our lives, and many things happen on there. Unfortunately, also shenanigans happen there. So I'm making it claim that nobody, I never claimed that this diagram was exhaustive, but I'm saying that diagrams such as this exist that tend to kind of give a taxonomy of the amount of effort that should be dedicated to components of computational advertising. I'm making claim that this should be a little more elaborate. That this should be a little more elaborate to include that second part that I'm alluding to. Okay, so you will see things like this. People are very fascinated by these subfields that we mentioned earlier, game theory and all that stuff. They construct all these systems. And that's good. That's very good. How then? And here's my point. The second part of this presentation, which I hope is going to be thought-provoking in the most beautiful and inviting and kind. And inviting and kind sense of it. I don't, I'm not a person that tries to shock people. I don't do that. If anything, I try to make people laugh and experience joy. So I'm not here to shock you guys, to annoy people, but I'm here to say that maybe all the wonderful intellectual acumen that people use to derive clustering algorithms, classification and regression algorithms, all the acumen that they use to optimize this stuff. Is it the case that we might want to use it to That we might want to use it to become policemen that will make competition advertising less corrupt? My answer is yes, because the same intelligence that caused people to commit crime, man, they can utilize that intelligence to do good. Okay, so let's use all the power of our brain that allows to do this to make sure that some of the problems that I'm going to be mentioning right now don't happen. Okay, now. Happen. Okay, now the two ladies inspired me. Then, when I started digging in, I found out two other ladies were the ones that pointed me to some of the things that I didn't know. And from there, I went into a rabbit hole of discovering things that competition advertising does that is not really very nice. In fact, I should not be surprised the more I think about it because it's a massive industry, right? There's a lot of money in there. Money in there, and then now that's it. You know, I think there's money and power. So, so unfortunately, when people see money and power, some of them, frankly, cannot control themselves and they do things that are not good because they want to wield power. So, one of the things, these are the things that are missing. And now, somebody may even be annoyed with me and say, hey, Ernest. Be annoyed with me and say, Hey, Ernest, we are at a statistics conference. Come on, you don't come here and tell us stuff that belongs with lawyers and social workers. What's wrong with you? Well, if you think there's something wrong with me, I apologize. But I'm sorry. When I teach my graduate students who are going to the field to work in statistics, there's a class called ethics. Because I'm telling them, people are going to try to make you manipulate p-values. People are going to try to make you manipulate your estimators to suit them. In fact, it happened to me. Estimate is to suit them. In fact, it happened to me. I was a young faculty member. Somebody came and gave the data, and he, in fact, I never met the person. What happened is that he, people told him, oh, there's this guy who just arrived in Rochester, blah, blah, blah. Talk to him. And then they give me a portion of his data. Then when I got him on the phone and he asked me, so what about data? So what were you trying to do with this data? I asked him. He said, well, I was trying to get this. Well, but you know, your stuff is not significant. And he asked me. Is not significant, and he asked me, What do I do to make it significant? I said, What do you mean? What do you mean to make it significant? It's not. So, that's what we teach in ethics. You don't let people make you manipulate science. When I read The Mismeasure of Men by Jay Gould, I was shocked. I cried. I'm going to tell you the truth. Because when I was a kid, as you can tell, I'm a very intense person. I came into science. I wanted to be a scientist because, in my family, everybody did mathematics, and I thought it was clean and Mathematics, and I thought it was clean and pure. Unfortunately, people use science to lie, people use science to make dirty money. It's very sad. I mean, when I started discovering that, I mean, it's a miracle that I never quit science because I quit science. Where am I going to go? That's what I like. So maybe I should stay there and do something nice. So anyway, some of the things that the first part of this talk, what people do a lot in science, and this is not just competition advertising, by the way, this happens everywhere. It happens with chemists, with pharmacists. Chemist, what pharmacist, it happens everywhere that people can use science to do things that are ethical. Now, I'm not going to go ahead and try to define ethics for you. We have like a gentleman's understanding, ladies and gentlemen understanding of what I mean when I say ethics. Inclusiveness, my goodness, this word, I could write essays on it for the rest of my life. And fairness, and sustainability, and moral rectitude, and diversity, and virtue. My goodness, I could just make a Virtue, my goodness, I could just make a long list of this. Now, you may wonder what does that mean? Well, until you see an example like this, this is an example that was an eye-opener for me. There are tons of them. I'm not going to waste people's time on this because I'm sure many of you have come across some of the pitfalls of competition advertising. And, you know, like I see, these are commercial software that do this. The commercial software do this. In fact, if I were young and I saw this, then I'll start praying for God. Saw this, then I'll stop praying for God to make me a white, light-skinned man. I would. Because if you see 0.8% and you see 34.7%, I'll pray for God not to make me a dark woman, black woman. I won't. I would say, please, don't do this to me. And these are well-meaning people. Like I say, some of these things is, in fact, I since I spend a lot of time now with people who do this, I organize my own. Now, with people who do this, I organize my own little conference here in New York, in Rochester, New York. And the last year when I did Upstart, it was all on social justice. I never thought in my life I would be interested in these issues until I came here and people started telling me, oh, Ernst, you're very naive, blah, blah, blah. And I start learning that, okay, you don't just do algorithms. There's some things that happen. Now, when you see something like this, it's kind of shocking. It's kind of shocking. It really is shocking because. It really is shocking because some of it is malicious, though. That's the problem. Some of it is malicious in the same way that somebody will try to perturb or rather fragilize, if you allow the term, I just made up a term. That's terrible. Fragilize a deep learning machine to make it classify a dog as a cat or a lion or something like that. It's the same kind of things, right? But that is one side of it, is where the algorithm is weak. Is where the algorithm is weak because it's weak. But here, the culprit is in the house. There's somebody trying to convey something, something sinful, something cruel. And that's wrong. And my hope is that the people who are capable of designing real-time algorithms and estimates the click-through rate very accurately, they can use the same intelligence to solve this. To solve this problem, to circumvent this curse of the algorithm. Something that is supposed to be good for the human family turns out to be an instrument to inflict some kind of pain, spiritual and psychological pain on people. This is cruel. This is cruelty worse than what happens in the Nazi camps, I think, because that one was overt. This one is insidious. And scientists, And scientists who deem themselves honorable should work hard around the clock to circumvent this nonsense. They should. Or else their science is useless. It doesn't help because they don't understand. The real reason why we do this stuff is not for some power. And somebody who doesn't understand that you try to exclude some people. That's stupidity. That's not intelligence. I don't care how beautiful the algorithm is. If the algorithm is causing Algorithm is if the algorithm is causing people to create this kind of cruelty, it's bad. And as a matter of fact, these two ladies, these two ladies, because I, you know, it's not like I'm surrounded by ladies. This one, she, I mean, she was just graduate student when she did this. She found this out and she seemed to be working hard on something that she called the Algorithmic Justice League. I mean, she actually really became an advocate. When you read the details, When you read the details of this stuff, it's heart-wrenching, to be frank. I mean, it's heart-wrenching for me because when I started off in science, I was very gullible. I had this naive understanding that there was something called the purity of the scientific exploration. And I've since realized, well, yeah, I mean, some people had heard of that, but others are bloodthirsty and they want to use science to affirm some power, which I think is just. Power, which I think is just useless. There's no human power, it is nothing. So, I think that scientists who care to be counted for anything should work hard to make sure that these shenanigans don't happen. Because an engine is supposed to do facial recognition, but it's actually doing something more and something evil. That's why I call it a curse. That's the reason why my title is what it is, and these two ladies. And these two ladies that started with this paper in the proceedings of the Journal of Machine Learning Research, it earned them jobs, but it earned her also to be fired. How sad. It earned them jobs and recognition. But the thing I'm saying is that there are so many atrocities that are done in the name of this, that you use the algorithm, you create an algorithm, somebody tweak it. You know, like now, there is a civil. Now, there is a civil lighting here though. BBC, this thing that I saw was absolutely a shock to me. They've seen, I mean, the Google has since corrected it. I mean, I don't know if this was the BBC side or if this was Google. This probably was the BBC side, but the Google site is a little better. So when you do this on the Google side, you get slightly better. Because on this side, from this article on April 14, 2017. In 2017, when you type babies, it gives you the impression that there are no black babies, no biracial babies. And that's why the article is, is artificial intelligence racist? How to avoid racist algorithms. I mean, you would think that this would be topics for people in social science, but the topics are visiting us in statistics. And I know the few of you in our. And I know the few of you in the audience today you are too smart to let nonsense like this happen. It's an insult to the intelligence of a scientist that they will even participate in such a scandalous thing. Anyone who participates in this is dead. His science is useless. He belongs in jail for crimes against humanity. I say with authority: if your science is not going to serve humanity, it's nonsense. Is not going to serve humanity is nonsense. I don't care. Don't work. Don't work. Now, the good news is that when you do this now, if you go, if you go back here, the BBC, this article, if you change here, I think Google got the app together. If you change this and instead search Google, you get something better. A baby's, oh no, it's terrible. Why does it give me that? Earlier, it gave me, oh no, because I didn't ask him for images. Okay. Images okay if I ask him now it seems like this is a little more representative of the population that makes Google rich, right? I mean, it makes sense because can you imagine a kid searching that website on that April 2017? You have just implemented, you have just installed in their mind that only Caucasian babies. Only Caucasian babies are worth being shown. It's an implicit cruelty of the worst kind. Who does that with the intelligence that God gave them? Who does that? Only a blind fool and a bloodthirsty criminal. Who does that? That's why this young lady, she didn't even have a doctorate yet. Straight yet. When she caught that stuff about the faces, now she's turned this into a career because she realizes there's something important there. The algorithms that we build are dangerous weapons. They are. In the same way that the hypothesis testing we perform, people try to corral young faculty to make a thing significant when it's not. So we got to be very careful. And I know many of you here are well-meaning people. That's why I dare to talk to you. That's why I dare to talk to you. And this lady, I've learned somewhere that you shall know the truth, and the truth will set you free. But it tells me here that you know the truth, but you can't tell it. If you tell it, you get in trouble. She told them that there was a problem and they got rid of her. That's sad. Well, they give all kinds of explanations that, frankly, don't need the Of explanations that frankly don't meet the sniffing test for me. That's what it is. Here's what I'm trying to say: I'm trying to say I'm privileged to be talking to an audience of intelligent people. But my definition of intelligence goes beyond the mechanics of intelligence. I want to talk about the spirit of intelligence. If people are going to tell me the intelligence, the intelligence has to go beyond the ability to prove theorems. Ability to prove theorems. It has to go beyond. It has to embrace something greater than theorems because they're axiomatic. They die. Gerdel told us that. They can't stand. You remove axiomatic, they fall like a deck of cards. So I'm hoping that this is being recorded. And most people will hear this and understand there's a statistician who is lividly angry at. Vividly angry at seeing how algorithms, estimators, and stuff are used in the most insidious, dirty way. It's terrible. It's terrible. It kills my childhood dreams of the purity of things. Maybe it took too long to be wise. But wise, now I am. Look at this list of references. This list of references of the things that happen with algorithms that you built, that I built. And for Pete's sake, yes, I do have the acumen to build algorithms, but I want them to support the human family, not to hurt it. That's why I like this person, artificial unintelligence. If you use your acumen to hurt, it's not acumen. It's not a document. It's a curse for you, your family, and everyone associated with you, including the human family. So let us wake up, statisticians, computer scientists, machine learning. If you want to call yourself someone whose contribution is worth even talking about in public, then you better do something that protects the dignity of human people. Don't do garbage that only people with no brain do. A racist, a person who has no brain. A racist, a person who has no brain. It's a dead person, dead men walking. That's who they are. I say it, I'll see it anywhere. And don't you dare use an algorithm to do this kind of evil, stupid things. Cruel. When I read this paper, I thought, really? You do this? A hundred times would have used that engine. Somebody forces me to see what they want me to see. We better find ways to robustify algorithms to make them transparent so that this kind of shenanigans don't happen. If you call yourself an intelligent person working in the field of computational advertising, you better make sure that when your album goes out, you give it robustness so that no one, not even Google, not Amazon, no one, not Bing, not Microsoft has a chance to do this. I know it's difficult. Don't get me wrong. I'm not naive. Wrong. I'm not naive. I'm not a naive fool. If these algorithms can't protect people, and if they sneakily, insidiously do crimes like this, twisting the root to truth, leave it to politicians, to dictators, to bloodthirsty criminals. Leave it to them. A scientist should be a pure person. That's what I'm saying. Because this is shameful. But it shouldn't be surprising when people start courting money, they will do shameful things. But not us, we shouldn't do that. Some fraction of this society has to remain pure. Some fraction. And I'm counting on you to be part of that fraction, please. Some fraction of this has to make sense. What is intelligence if it hurts people? That's not intelligence. That's ultimate stupidity because all hatred is self-hatred. Use an algorithm to steal money from people, to hurt people, to inflict inferiority complex, to exclude the people who make you rich. You call yourself and tell you, oh, wise, I can sneak and do that. No, those are perishable things. All your money will perish. We should do this. We should do this with more emphasis. That's why this is humane computational advertising. If you deem yourself a good expert in this field, let your algorithm be smart enough to solve this problem, or at least contribute to solving them. Don't ignore this problem. It's almost like constructing a very weak and not robust algorithm, and it will break. The outliers, the attackers will come. So, construct algorithms that are good. So, construct algorithms that are good. And this started in 1977. I didn't realize this article. I don't know the date of this 1977. So, this problem has been around that people have manipulated things, but they're using us scientists. They took the product that we said, we day working night and day. I want to make this happen real fast. I want to conquer this. I want to find new ways to regularize and to conquer the sparsity and produce better bids. Better bids and better prediction of click rate. And you're doing all this in your naive understanding that is to create better product for people. People take that, tweak it for selfish aims. Here is my deal. And I'm going to rest my case. I told you, I didn't come here to shock people. If it comes across that way, I'm sorry. But I want you to know that I'm very indignant. I'm not going to hide it. I'm indignant that algorithms are used. That algorithms are used this way, that learning machines are used this way, that statistical estimators are used this way, and that hypothesis testing is used this way for selfish aims that end up hurting people in the most atrocious ways. In fact, this article in Nature is very appropriately titled, Is Facial Recognition Too Biased to Be Let Loose? And this guy, this subtitle is exactly the title of my talk, right? So there is a people are getting sharper and sharper algorithms better. But how are people using it? How do people take it and tweak it for very cruel aims, extremely cruel? Things that you think should stay in a Things that you think should stay in 1800, people are dragging them from politics into science, inflicting them onto algorithms. That's shocking. Yeah, this is, frankly, the person was shocked. I mean, you look at this, this stuff happens, and oh, it's, oh, my link is dead. But I was, this link was, I think it was interesting. This link was, I thought it was an interesting link because it was over in London, the BBC, and they were doing so many things. And these algorithms, these algorithm racists, well, what they're stored in the algorithm is very weird. In fact, I remember one time when my daughter came home and she told me that her classmates, by default, assume she's an angry person. I said, well, I say, well, can she be indignant? Anyone who knows me, Ernest Fouquet, knows I am probably the happiest person on this planet. Joy comes to me naturally. But today, since discovering this, I'm indignant. I'm entitled to my indignation. My right to be indignant, especially when I'm not trespassing somebody else's right. But you know, the adjectives that are associated with me. Associated with me as a black man, they are the worst adjective that are attributed to oppression. People see me, they see a rapist, they see a thief, they see a man with low intelligence, they see an idiot, they see all kinds of things. You search it, you'll see it, the search engine will confirm that. And it will perpetrate the sense that people that look like me do not belong to society. There was a time when I was three-fifths of a person, there was a time. Person. There was a time I was nothing. And you hope that this thing will stop and people have some intelligence to stop this nonsense. But they use science to perpetuate. Even after 1930, when it was discovered the mismeasure of man was a scam of using mathematics to confirm stupid criminal things, people still do it with such engine in broad daylight. Matter of fact, in this case, very insidious. In those days, it was a work. You could count. You could count somebody that you didn't like for nothing today. Well, there's some policing out there that prevents you from doing it. But yet, then science does. Look at this. You tap it. Why black women are so look at the list? Angry, loud, mean. There's a nice one there, attractive. Not that that one. Lazy, annoying. Who does that? My goodness, we should know better. Scientists should. Scientists should, you know, should do something. When I come to school, when I come to class to teach my students, I want to make their life better. When I sit down to work on an algorithm, I'm hoping that my tiny infinitesimal contribution will make this world a nicer place. I came to this conference because I love my friend David Banks. I enjoy being with him. I was hoping to be there in Canada and be with people because I just love seeing people. I'm fascinated by people. I'm fascinated by people so much. People, fascinated by people, so tall, short, but I'm just fascinated by unfortunately. There are quite a number of people out there who are now, and they perpetrate things like this. Seriously? Who does that? It must be somebody who is very, very diminished inside, and he thinks that by putting somebody else down, it makes him feel good. No wonder people come up with this kind of books. Mrs. Noble came up with this book. Came up with this book, Algorithms of Oppression, because she looks at so many things that are done on those search engines and those computational advertising. So anyway, that's my take on it. And there's even an aspect, there's so many aspects that I explore with the girl, with the ladies. And then we were seeing that, you know, the sustainability, this is what Timit did and caused her problems at Google until she was terminated because she was raising the attention. She was raising their attention on that, you know, you're just doing these things, you're not aware of many aspects of you know, racial buffalo, your algorithms. She was even telling them something scientific and technical that your algorithms are going to do what you want them to do, but what you're doing is not right. And plus, it's not even sustainable. And they didn't like that because I learned that you should know the truth, and the truth shall set you free. Unfortunately, you know the truth, but if you tell the truth, the truth will get you in trouble. It shouldn't be like that. Shouldn't be like that. At least, not in science. Maybe at least politicians and other people do that. Okay? Anyway, this is my conclusion. The algorithms that we construct are powerful, very powerful, but they're also dangerous, very dangerous. Because people can use them to do all kinds of things. There's almost a social justice, a criminal justice now involved with algorithmics because people can use them for. Because people can use them for kind of things. It's not the day when only chemists, because people thought with chemistry you could create bombs and Ayberghanistan and other people had to fight hard, but people still use them to destroy Hiroshima and Nagasaki. But things like that, atrocities like that are happening with algorithms. The sad part is that with algorithms, it's insidious. You don't see it. So it's even more dangerous, I think, as far as I'm concerned. So here's what I think. If you see something, say something, that's what they say at the airport. We should start saying that for algorithms. If you Algorithms. If you see an algorithm is biased in some sense, ask the guy, is this bias intentional or no? Just the same way that Joy and Timothy asked the people. And then, you know, when I say activists, I don't say you have to go there with some flags or some stuff. I should just do what you teach this stuff, man. We have to rise. This is too petty. Frankly, I mean, I don't even, this thing does, I mean, it used to anger me. This thing does, I mean, it used to anger me. It saddens me more than it angers me because I equate intelligence with also emotional and spiritual intelligence. So when somebody, when somebody said, this guy is very bright, if he doesn't love people, I say he's no bright, he's a fool. A person whose only claim to intelligence is his ability to manipulate large equations or code, to me, that's not an intelligent person. That's a fool. It's not useful for humanity. Person, that's a fool, it's not useful for humanity. So, if you're useful to humanity, you should be humane. You should even understand that the only wise people in this world are people who know that we are all one. I know this is complicated for most people to understand. When you hate people, it's yourself that you hate. When you manipulate people, you're manipulating yourself. In the end, you lose. Unfortunately, you cause others to lose as well. So, if we have to be intelligent and good statistician, scientists, we have to heed one of these six points. We have to heed one of these six points, if not all of them, or else there's no science. It's a waste of time. It's a waste of time. If what I do doesn't elevate people, it demotes them. And I don't want any part of it. So we're going to take the risk to say that there's something wrong. Am I my brother's keeper? I say yes. Thank you.