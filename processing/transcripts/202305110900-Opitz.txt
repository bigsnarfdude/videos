Okay, so the last talk for today is by Thomas Obit. He will be talking about bridges from spatial experimental theory to classical geostatistics. Yeah, thanks, Rafael, for the introduction, and also to all the organizers for this very nice conference. It's very nice place. Yeah, so if you look at the communities of geostatistics, spatial statistics on the one hand, and extreme value theory on the other, there is some overlap, but it's not very strong. So what we also see is that often geoscientists, when they have some basic training in geostatistical tools, but maybe much less in extreme value tools. So this means. So this means that it's definitely important to build bridges that are stronger, wider between these two communities. And well, for instance, these models of Usler Reis and Bron-Resenek type that we've seen this morning, they are very interesting candidates for this. And so my talk is also about this model class and About this model class, and how we can use very classical geostatistical tools with these models. Classical geostatistics were formalized around 60 years ago by Georges Materon. So that's the guy here from the Paris Mines in this book from the 1962-63. And there he formalized all this variogram analysis and all. Vargogram analysis and also this idea of cracking predictions. But of course, from extreme value theory, usually we know that we should not apply these classical geostatistical tools directly to extreme event data. So that's true, but I mean, here I want to say how, under certain conditions, maybe we can. So, if you look at the classical asymptotic frameworks in the two cases, so let's consider an IID, well, this series of random variables, the axis here. So, classical statistics, geostatistics, we look at averages, then we do some location scale normalizations, and then we have the central limit theorem. We get something that is Gaussian. We get something that is Gaussian, we have the sum stability, and we can extend this to spatial settings by using Gaussian processes, by doing geostatistics. Now, if we look to the extremes, here we would rather look at, well, maxima in the classical setting. So here we have the extremal types theorem that tells us, again, if we do a location scale renormalization, we can get some nice limits. Get some nice limits. So these are the max stable, the extreme value limit distributions. And there are the spatial extensions. Well, these are max stable processes. And we have spatial extreme value analysis, spatial extreme value theory, well, to work with them for statistical applications. So if we look on the extreme value side, there are actually different ways to well. Yeah, to consider the data and to model the data. So, the classical one is about block maxima, but you can also look at extreme event sets E and count the number of occurrences. Or that's the approach that we will privilege here and look at threshold exceedances. So, we always allow for this linear rescaling so for this location scale transfer. For this location scale transformation of our original data. And well, with the maxima, we get max table distributions. With the occurrence counts, we have the so-called Poisson process approach. We get Poisson process limits. And with the threshold exceedances, we get generalized variable distributions. These three types of limits are equivalent and they are actually very closely intertwined and also, well, parallel. And also, well, parameterized by well, in the same way, by this exponent measure lambda. And well, this lambda has this nice asymptotic stability property. So we take any event E and any constant positive C. Well, then we can always find these alpha and beta, well, location scale transformations that we apply element-wise. that we apply element wise on the well on the yeah on the on the set E and then C times the measure of E is equal to the measure of the transformed set E so it's all about this this asymptotic stability in extreme value theory now if you want to model dependent extremes and we often standardize the marginal distributions so this gives So this gives rise to theoretical formulas that are much simpler, much nicer. And in practice, well, for statistical inference, this can also simplify things because we can separately do the inference for the margins and the dependent structure. So two-step approaches. And well, the standardized scale that I choose here is. Scale that I choose here. It's the SADA Pareto scale. So we transform like this. So here the P subscript, superscript for the Pareto. And well, actually, you can also interpret the standardized scale as the scale of the return periods. Because say we look at an independent copy of our XJ and then well the probability And then, well, the probability of this independent copy being larger than our original XJ, given the original XJ, it's just one over this standard Pareto variable. And so if we have this formula for the probability, it means that what we have in the denominator here is the return period of the event. So, in some sense, the study. Event. So, in some sense, the standard Paretos scale, we can interpret it as the return period of the event that we have observed. Okay, so now we do not want to work in a univariate setting, but rather in a multivariate or even model, especially in a spatial setting. So, we want to work with thresholding sequences. So, the big question. Threshold exceedances. So, the big question is how we can define threshold exceedances in a multivariate in a spatial setting for working with dependent extremes. Well, there's no unique definition, of course, of multivariate spatial threshold impedances. So what we do is we choose a risk functional, so we will call this R, and we say that an extreme event occurs if this risk functional. This risk functional, so this structure variable exceeds some threshold mu, some high threshold mu. So this gives quite a lot of flexibility. You can see several examples here. In terms of the maximum risk, we have the exceedances like here. The sum risk we have the exceedances up here. Or we can look at exceeds. Look at exceedances at a fixed component. So that's essentially the conditional extremes approach that we have already seen several times today. So there are many interesting choices. So for the asymptotic theory to be valid, so what we will require is that this risk functional is continuous and so it maps the well. maps the well the x here so the spatial field for instance to a non-negative value here so that's our requirement well if the input is non-negative because we're on this standard Pareto scale again so there are many different examples like for these r functionals we put like minima maxima specific components that are the conditional extremes are brought Whereas the conditional extremes approach, and we can look at different types of averages, like arithmetic averages, or also the geometric average. And so in the following, we will have a closer look at the geometric average. And of course, we could also choose any norm. So this would also be a possibility. So the geometric average is nice. So, the geometric average is maybe a bit less known than the arithmetic one. So, if we compare the two, so if we have constant values in our T components and T locations, at T spatial locations, and the two are the same. So, differences arise when we have different values in the components xj. And actually, if we have relatively strong variability in this xj. Variability in these XJs, this geometric average will be lower than the arithmetic average. So it means we will see exceedances in the geometric average when we have extreme events that are relatively widespread. So when we have situations where the spatial dependence among the extreme events is relatively strong. For instance, heat waves are a good example of this kind of. Good example of this kind of behavior. Okay, so later we will work with these geometric averages, but first I will recall these R periodal limit processes. So you've already seen them different forms here during the week. So we have well this random field X or random element with X or random element with the index S. So we do this marginal standardization to the standard Pareto scale. So we have this XP and we condition on an exceedance of a risk functional above a threshold mu. We normalize the process with this risk functional and then if this converges to some limit process YR, this limit process. It's a limited process, it's an arboretal process. This arboreto process has well nice pixel-fresh on stability property. So it means that, well, if we take an arboreto process, for instance, at the place of x, we directly take an arboreto process. Well, then we don't have a convergence here, we can actually Convergence here, we can actually replace it by an equality. We can look at extremes at higher thresholds, we just rescale by Î¼, and we get the same distribution as the original extremes. That's a very nice mechanism for doing extrapolation towards more extreme events. And due to this stability, we have nice decomposition into a scale variable and a profile variable. And the two are in. Profile variable and the two are in a profile process W. The two are independent. So the scale variable, it's just simply the risk. And the profile process, well, we get it when we normalize the original process by the risk. So we project on the unit sphere with respect to the risk. And yeah, so in practice, what is very interesting is. So, in practice, what is very interesting is that we have this independence between the risk, the R functionals, the aggregate, and this profile process W. Okay, so at the beginning, I yeah, I already mentioned these links between well, fresh olive series as Poisson processes and max level processes. And max level processes. And well, if we have an arboreto process, then permanently we also have a Poisson process limit. The Poisson processes, they're actually quite nice to construct or to simulate these arboreto processes. Because we can take the Poisson process representation of our model. So here I won't detail it for reasons of time. And then so if And then, so if we retain only the Poisson points, so here the points are spatial fields for which the risk functional exceeds one, and we get realizations of our Arpurito process. So that's a very nice way to simulate Arboreto processes for all various kinds of risk functionals, R. So that's what's illustrated here. So, in the three illustrations, we have the same point point as realization, but we take different risk functionals. So, the one and then in the color with the three colors, we have the three most extreme realizations. So, in the middle, we have the geometric average. So, that's the risk function that we will use later. So, you can see that. So you can see that the functionals, the functions that are extreme, they do not vary too strongly here. And on the left-hand side, there's an example where we condition the value at a fixed location, marked by this blue line here. And on the right-hand side, we condition on the mean return period. And yeah, the mean return period, well, it's also. Return periods, well, it's also possible to sometimes have relatively small values at some locations, even if the mean return period is very high overall. Okay, and so now we want to use this framework with the Brown Resnick models, and the idea here is to use this geometric. Average of the return periods as the risk function of okay, so these are the rise of Brown Resnack models that have already been very nicely presented this morning and in the first session. And they have a very nice hidden Gaussian structure. So if we look at the Pareto process for the For the risk functional chosen as the geometric average of the return periods. So, what we get is that it actually is a log Gaussian process. So, it's not a very classical stationary process. It has a kind of bit of special structure, but it's a log gaussian process. So, we can well. Well, what we need to construct this, we need any centered Gaussian process G, and then we have to subtract the spatial average and we also have to subtract a deterministic constant. So, this deterministic constant, well, I didn't give it explicitly here, but it's easy to calculate, and it depends only on the Depends only on the semivariogram matrix of our Gaussian process here. And that's a very nice result. And actually, you can derive it or get it relatively straightforwardly if you look at some of the papers from and the papers here from Sebastian, Marco, and their co-authors. Well, actually, um yeah, so this works with geometric averages. It also works with wavy geometric averages, so it's even more general. And the classical conditional extremes model, that's a very special case. You condition on a single location, so that's a very special case of a geometric average. But we can generalize this result. Generalize this result by not doing single side conditioning. Always a bit tricky because you don't know how to choose the single side, but you can condition on a spatial average. And then you still get this nice Gaussian process here. And so this means we will be able to work with the usual Gaussian tools. And so what is also very interesting, if you look now at this. If you look now at this semivariography of well of this Gaussian process, which well has a bit of a kind of a weird structure. Well, if we look at the semivariogram of our log W, of our log profile process, and actually it's the same as the semivariogram of our original Gaussian process G. So that's very nice. That's very nice. And so it means if we want to get information about this original Gaussian process G, then we can just do total classical barogram analysis. Okay, so I did a small simulation study. It was also to see a bit what so it's maximum likelihood well for various Well, for various configurations of the stable covariance function, well, 100 locations, 100 independent copies of this profile process, and yeah, there were 100 repetitions of this simulation re-estimation procedure. So, I was also interested to see how the simulation performance is impacted by the fact that we do not have the That we do not have the original Gaussian process G, but this transformed process where we subtract the average and where additionally we have this constant here. And so in general, the performance between having data from the original Gaussian process or having data from the Arparito process, so this transfer. So, with this transformed Gaussian, non-stationary Gaussian, it's very similar. It's only in cases where we have very strong spatial dependence that we get a bit stronger variability in the results for the Arboreto process. So these are these configurations, five and six in particular. These are cases when you subtract the average from your process, you remove a lot of information. So there is strong dependence. Because there is strong dependence, strong spatial dependence in the process. But in general, the estimation works very well, and we can use a simple Gaussian likelihood to do the estimation. Okay, and now I have a small application example here. So we look at all the ideas to model heat waves and Well, the idea is to model heat waves in France. And we here look at daily reanalysis data. So we have pretty data from this French Saffron model. It's an 8-kilometer resolution. It's data for approximately 30 years. And here I looked in particularly at summer temperatures for the months from June to September. So how do we do the modeling in practice? The first step is to do this marginal transformation to the standard burrito scale. Transformation to the standard burrito scale. There are different solutions for this. GAM-based models, generalized additive models, or do it pixel by pixel, use empirical transformations. So there are various solutions for this. So that's not the focus here. Then I also didn't want to look at the whole territory, which is very large, and we probably have some non-stationarities, also in the dependent structure. The idea here is to focus. The idea here is to focus on separate administrative regions, and for each region, we fit a separate model, and then we compare what's going on between the different regions. And yeah, so we look at the daily risk exceedances by using the geometric average of the return periods for each day. So that's our risk functional. So, here the analysis is purely spatial, but we know, of course. Spatial, but we know, of course, that there's quite strong temporal dependence in temperature data. So, here, what we can do is do some temporal declustering by this for this Rance method that is quite classical in time series analysis of extremes. And here we have the time series of the risks, and so we can apply this temporal declustering on the risk time series, and then for a cluster for a Flaster for a heat wave, we only keep the day where we had the highest risk. That's the idea here. And then we can do the maximum likelihood estimation of the dependent structure by using this Gaussian log profile process. And here I'm again using this stable covariant function that I've already shown before. Okay, so that's the study domain. So there are 22. So there are 22 administrative regions. It's not the current ones, it's the one from the time when they started generating this data set. So we have these 22 administrative regions and we'll fit a model in each of these regions here. And well, that's about the marginal model. You see, for instance, for the shape, oops, for the shape. For the shape parameter, it's quite non-stationary, yeah, with heavier tails here in the northeast, but also in the south. And if the margins are quite non-stationary, then you could also expect that there are quite strong non-stationaries in the dependence. So that's also one of the reasons for doing this space partitioning and for fitting these local models in the different regions. Okay, so we're doing this likely maximum likelihood estimation with Gaussian log profile processes. And yeah, so here what you can see on the right, it's the variograms that we estimate. But there are quite a lot of them, but what you can see is that, for instance, these more reddish-pinkish colors. So, here in the south, for these we have quite strong variability, so quite large variogram values, while these rather well greenish-brownish colors, they are more in the center and in the north. So that's where we have weaker spatial variability, so stronger spatial dependence in during the heat waste. During the heat waste. So instead of showing variograms, we could also show this tail correlation function. It's just a transformation of the variogram values. So these are the ski functions. So here they look like this. And of course, if we have large variogram values, we will get smaller tail correlations. Tech correlations because higher spatial variability means weaker spatial dependence. And yeah, on this slide here, that's a focus on some more specific sub-regions. So here I looked at the regions in the north, on the left, the regions in the south here, the middle figure. Middle figure and the Atlantic coast regions here on the right figure. And so the continuous lines, it's the fitted parametric variograms. And the empirical dashed lines, these are simple empirical variograms that you can calculate with any geostatistical package. Yeah, so the slight difference. Yeah, so the slight differences is that for these empirical variograms, I mean, we only exploit the dependent structure in the data, while for these fitted parametric variograms, there's also this Gaussian mean constant that depends on the variogram. So we have some additional information. For instance, when we're doing maximum likelihoods, we have some. Maximum likelihood we have some additional information, but what is yeah, what is reassuring to see is that in general the fit looks really good. So if you compare the empirical variograms, the parametric fits, they match quite well. So for all of the regions that we have looked at here. And yeah, like I already mentioned before, in these southern regions, the variograms, they have a higher slope, so stronger spatial variability in these southern regions as compared to the northern regions. Okay, um yes, so yes, all these spatial extreme value models there are in general quite technical and also difficult to fit. But here we have seen that well under certain conditions it's actually possible to well to use very classical geostatistical tools, Gaussian tools. So they also work So, they also work for extreme event episodes. So, that's something that's very nice, and I think this can also help to communicate more easily results to geoscientists and can also make it more easy for geoscientists to actually do extreme event analysis. For instance, by just calculating an empirical barial graph. Well, these models rely on this fixed over threshold stability. So, well, let's say often it's a reasonable assumption, but there are also cases where, well, we may tend towards asymptotic independence. And well, in this case, there are also more flexible representations that are possible in this conditional extremes framework. And the remaining issue is that for the conditional extremes framework to be valid, usually you should condition on a single conditioning site. So it would be interesting to see how this conditional extremes framework would maybe also find a solution to condition on some spatial average of the observations. There are also some other ongoing projects. So there's one with John here. With John here, so where we use similar models, but we're more interested in the temporal dependence during the heat waves and the duration of the heat waves, and we want to do the analysis in a Bayesian setting and then have space-varying parameters. It would also be interesting to move towards space-time models, maybe even multivariate space-time models, because I think compound extremes can be quite interesting. Compound extremes can be quite interesting. Then there's also in this setting the problem of the scalability of the estimation techniques because you will have lots of observations. So that's a project with my colleague Vinylar. And yeah, one interesting thing is also, well, these are very fair processes. They tell you what's going on inside an extreme map. What's going on inside an extreme episode? So, like, what's the spatial variability during a day where we had an occurrence of an extreme episode? More generally, then it would also be interesting to better explore the occurrence pattern of these extreme episodes. So, on which days, and for instance, in which of these 22 regions do we observe extreme episodes? And yeah, for these questions, you'd like to explore some point process techniques and work with them on networks, like networks of different regions. And so also get a better idea of the space-time structure of the occurrences of these threshold exceedances of our risk. And here I started with the mines of Paris, and that's And that's the idea was also to kind of close the loop and end with the minds of Paris. So that's one of the open PhD projects that we currently have at this new chair of cheerlearning that is coordinated by Daniela. Okay, thank you.