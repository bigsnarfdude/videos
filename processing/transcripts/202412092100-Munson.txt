Today I'll be discussing quantum uncomplexity. In particular, I will be talking about how this lack of quantum complexity is a resource for quantum computation. And if it's not already known, I'm a PhD student at the University of Maryland, co-advised by Nicole Younger-Halpern and Christopher Jarzinski. So let's begin. So, before we talk about quantum uncomplexity, let's just talk about quantum complexity. So, here, by quantum complexity, I simply mean a quantity or that quantum complexity quantifies the difficulty of preparing a given state from a simple reference state. Generally, we just take that to be a tensor product state. And in particular, for an in-qubit system, we often will just take the We often will just take the all-zero state as our reference state. So, as an example of one of the ways that we can define complexity, we can begin with exact unitary complexity. So, in this case, it's just what corresponds to your intuition. If we have a state psi, then its exact unitary complexity will just be the minimal number of two qubit gates in a circuit that will implement that implementation. That'll implement a unitary that'll take the all-zero state, our reference state, to the state psi. And we're just going to denote that exact unitary complexity by C of psi. So why do we care about quantum complexity? So quantum information, it's been shown that quantum complexity quantifies the difficulty of discriminating states and of preparing superposition. It's also made inroads into It's also made inroads into condensed matter physics, where complexities that scale linearly with a system size have been shown to distinguish topological phases. And it's even made an appearance in high energy theory. So there, there's a conjecture in the ADS-CFT correspondence that if I look at the wormhole connecting two black holes, then the complexity of the field theoretic state dual. Of field theoretic state dual to that wormhole will be proportional to the wormhole's length. So, across a number of different fields of physics, quantum complexity has been making an appearance. So, now you might ask, okay, this talk is about quantum uncomplexity. Why do we care about the un in uncomplexity? So to ensure that quantum uncomplexity is not a good thing. To ensure that quantum uncomplexity is a well-defined notion, we need to first establish that quantum complexity can take on a maximal value. And by a simple counting argument, or let me say a straightforward counting argument, it can be shown that an in-qubit state rho has a maximal complexity, which is proportional to e to the n. And so what's most important there is that. Most important there is that maximal complexity exists, and from that we can define a quantum uncomplexity. So, the uncomplexity of a state rho is the difference between the state's complexity and the maximal complexity. So, C max minus the complexity itself. Now, to see that uncomplexity, to motivate uncomplexity as a resource for quantum computation, we observe first. We observe first that quantum complexity has been shown to grow in systems undergoing random dynamics for times very long compared to other observables, in particular, like thermalization. And so, in that sense, quantum complexity can be thought as a parameter by which we can track the growth. The growth or the evolution of a system undergoing random dynamics. Furthermore, we can think in the case of quantum computation as that the useful states in some context are blank qubits. An analogy here is that if we have blank paper, then pencil writing is useful in that way. We can manipulate it. You know, manipulate it. So, in this case, having these uncomplex qubits that are easily manipulated in the laboratory can be kind of our blank slate upon which we can create more useful states. And then lastly, going back to the high energy motivation, there is a conjecture by Brown and Susskin that uncomplexity can be formally understood as a resource. Normally understood as a resource in quantum computation. And so that is the conjecture that my collaborators and I established in the so-called resource theory of uncomplexity, which you can find at the archive link below. We also published it in Physics Review A. So if you have access to that, then you can also find it there. So let me give you. So, let me give you a roadmap of this talk. First, I'm going to define the resource theory of uncomplexity. And thereafter, I will introduce operational tasks defined within that theory. From there, I'm going to take a detour and introduce a quantity called the complexity entropy. Quantity called the complexity entropy, which we will then use to quantify the optimal task efficiencies of the operational task. So let's begin with the resource theory of uncomplexity. First, I just want to establish what a resource theory is. Theory is. So, in a resource theory, an agent can perform any chosen operation that satisfies simple rules. You say, okay, so why do I, what makes it a resource? Sorry. So states that are difficult to prepare become scarce resources, and that can facilitate the performance of operational tasks. So some states. Task. So some states will be easy to access and others will not be so easy to access from the operations in the theory. And an important qualification here that will come up quite soon is that a theory is defined all and only by its allowed operations on a given set of states. Of states. So, to give you some intuition about more well-known resource theories, I'll begin with the example of the resource theory of entanglement. So, in this case, our freely accessible states are just separable states, and our free operations are LOCC operations, that is, local quantum operations with classical communication. So, in this situation, we can In this situation, we can easily prepare separable states, but entanglement is the useful resource. And importantly, our free operations can't generate entanglement. So if I have two agents, Alice and Bob, they're able to perform local quantum operations in their respective laboratories. And they're also able to communicate with each other classically. But they can't perform any full-fledged quantum communication that would enable them to generate entanglement. To generate entanglement. So, in that sense, they can begin with entanglement and then utilize that as a resource to perform operational tasks, but that's entanglement will be a scarce and therefore useful resource. From the field of thermodynamics, we also have the resource theory of athermality. So, in this case, the states are, or each state is a Is a density matrix paired with a time-independent Hamiltonian. Okay, so in this case, the abstract state is that kind of Cartesian ordered pair of the density matrix and the Hamiltonian. So the free states here are states in thermal equilibrium or just Gibbs states. And the free operations will be processes that conserve total energy under system bath exchanges. Under system bath exchanges. So here it's actually the lack of thermality, which can be used as a resource to, say, extract work in a thermodynamic protocol. So now let's turn to the resource theory of uncomplexity. So I need to introduce a primitive before I define the theory, and that is the primitive of a fuzzy gate. The primitive of a fuzzy gate. So here, a fuzzy gate, u tilde, is a gate which is, in a sense, an approximation to a desired gate, u. And so it'll be implemented with respect to a probability distribution that is within some epsilon ball of the desired gate U. And we just impose a couple of conditions here. A couple of conditions here. So it needs to this epsilon ball is with respect to the operator norm. So u and u tilde need to be within epsilon distance of the operator norm. And also the probability distribution needs to be non-vanishing on some open set around you. So that's to say that it initially spreads in all directions. Spreads in all directions from the gate to you. And physically, this is really just a model of noise of implementing exactly some gate U. So whenever we apply u tilde, there's just some noise that is associated to the implementation. And so, as I stated before, a resource theory can be defined solely by the intro. Can be defined solely by the introduction of the allowed operations, the definition of the allowed operations. And here, these are so-called fuzzy operations, which are simple to state given our primitive. So a fuzzy operation is just a composition of fuzzy gates. So, unusual in the resource theory of uncomplexity. Resource theory of uncomplexity is the fact that there are no free states. As I stated before, this is perfectly allowed, but it is atypical among resource theories. So we can see that there are no three states in the theory by way of a simple argument. So first we consider an n plus m qubit system. Okay. If we consider the maximumly If we consider the maximally complex state on that system, then by the counting argument I referenced before, it will have a complexity on the order of e to the n plus m. However, if we were to allow the tensoring together of a maximum complex, or rather, if we tensor together a maximum complex in qubit state, in a N-qubit state and a maximally complex m qubit state, then we'll see that the complexity of that tensor product will have a complexity on the order of e to the m plus e to the m, which in general is smaller than the previous exponential. And so that would create a problem because in the resource theory we'd be able to basically, by tensoring on together states, we'd be able to generate complexity out of nothing. To generate complexity out of nothing, and that's the one no-no cardinal role in establishing resource theories. Okay, so as a result, we see that tensoring on creates uncomplexity, and therefore we can't have any free states. Otherwise, we would violate this condition. So, now I want to discuss the operation. Now, I want to discuss the operational task within the theory. So, there are a couple that we introduce, which are in some sense dual to one another. First is uncomplexity extraction. So, in this case, we start off with some given state and we try to extract these simpler, simple, uncomplex reference states, the zeros. Reference states, the zero states. Parallel to this is uncomplexity expenditure, where we begin with some amount of uncomplexity, say states that are near the all zero state. And from that, we want to expend it in order to create some state of interest. So let me begin with uncomplexity extraction. Complex uncomplexity extraction. So the procedure is simple. We begin with some state rho, and we apply to it a circuit of at most R fuzzy gates, and we select some number W of the qubits. Our task is to perform the above such that the selected qubits are delta close to Delta close to the all-zero state in trace distance. So, importantly, we allow some amount of error in the creation of our uncomplex state. Uncomplexity expenditure requires a little bit more setup. Here, I need to introduce the notion of the complexity of measurement operators. So, in this case, we're going to have our simple measurement operators denoted by the set M0, which Set M0, which will consist of tensor products of one of two single qubit operators. So either it'll just be the identity operator doing nothing to the state, or it'll be a projection onto the zero state. And so you might have something like the zero projector tensor to the zero projector, tensor to the identity, tensor to the zero projector, and so on. So the set M0 has all such. Not has all such projectors. And then an R complexity measurement operator will just be a simple measurement operator. So from the M0 set, kind of pre-processed, quote unquote, by our fuzzy gates. And so the setup for uncomplexity expenditure is that we Is that we begin with a computationally limited referee who wants to distinguish between our state rho and the maximally mixed state with a measurement operator that is at most R complex. And this referee wants to guess rho correctly with probability at least eta. So that's our intolerance parameter. In your job as the agent who knows the measurement operator Q. knows the measurement operator q is to fool the referee with some similar acrom state r tilde okay so our procedure for uncomplexity expenditure is straightforward we will borrow some uncomplex zeros from some uncomplexity bank along with some unknown n minus Some unknown n minus w qubit state. So that's kind of like our junk state. So you can see this in the diagram here. So we begin with our zero states in the junk state, and then we apply our, at most, our fuzzy gates to the joint state and yield our simulacrum, rho tilde. And we'll succeed in this task if we have the referee, upon receiving our simulacrum of rho tilde, guess that it is row. Guess that it is rho with a probability at least eta. So, as with uncomplexity extraction, we don't need to, we have some error with which we can successfully perform the task. So, now let me turn to the complexity entropy as our interlude. And to motivate this quantum, And to motivate this quantity, I want to remark that entropies such as the Shannon entropy are often used to bound the efficiencies of operational tasks. In the case of the Shannon entropy, it's used to bound the efficiency for data compression. However, in general, many or in practice, many In practice, many entropies are defined with respect to the set of all measurement operators, assuming that we can perform any measurements. And as a result, it doesn't adequately account for complexity constraints. And so we want to know how uncertain a state looks to a computationally limited observer, not an observer who is capable of any sort of measurement. Any sort of measurement. So the definition of the complexity entropy for an n-qubit state row is as follows. So we have two parameters, r and eta, where eta is like a probability and r is our complexity parameter. And you see in the middle here, we have the logarithm of the trace of some measurement operator q. And so I want you to think of the measurement operator. And so I want you to think of the measurement operator Q as something like the reciprocal of a probability. And so the log of that reciprocal probability is like a surprisal. So this minimization is really like the maximization of a surprisal, but just constrained first by the By the complexity constraint, so Q needs to be an M of R, and also by this intolerance constraint. So we need the trace of Q rho, so the probability that the measurement operator Q identifies rho, to be at least eta. So that's the first constraint. And then the second constraint I just mentioned is really. I just mentioned is really, for those who know, it's a type one error constraint. And so, in this sense, the complexity entropy takes both of these constraints into account and then gives the minimal possible uncertainty that one can have in the type 2 error. So, let me give you a little bit of intuition about the complexity entropy. Intuition about the complexity entropy by looking at limiting cases. So if we look at a low complexity state, so our state, say, the alt zero state, then it can satisfy the trace constraint for some measurement operator Q. And it'll, in that case, we can take, we can. We can take Q as this conjugation of the zero projector. And we find that the complexity entropy is equal to the log of trace Q or simply the log of one, which is zero. So this comports with our intuition that if we have our lowest complexity state, then the complexity entropy will yield a The complexity entropy will yield a value of zero. And in the opposite regime, where we look at a high complexity state, then that state may satisfy the constraint possibly only for the identity operator. So any state will satisfy the constraint for the identity operator. We can only get a lower value for the complexity entropy if there are more performable measurement operators. Measurement operators than just the identity. But in the case that the identity is the best that we can do, then the trace of Q will be 2 to the N, and accordingly, the complexity entropy will just take a value of N. So that will be the maximal value for the complexity entropy. So for those who are familiar or interested, there's a simple relation between the complexity entropy and the hypothesis. complexity entropy and the hypothesis testing entropy, which is defined down to the right. So the hypothesis testing entropy is a well-studied quantity that quantifies the uncertainty in a hypothesis test between a state rho and the Maxwell mixed state. And you can see that it's almost identical to the complexity entropy. It has this type one error. It has this type 1 error constraint, but it allows the minimization to range over all measurement operators as opposed to just those of a complexity at most r. So in this case, the complexity entropy is a hypothesis testing entropy with computational restrictions put in by hand. And so finally, I want you to see how the complexity entropy can be used to quantify the optimal tax efficiencies for both complexity expenditure and complexity extraction. So there are two theorems, one for each of these tasks, and the theorem establishes both the existence of a prototype. Both the existence of a protocol achieving the task and the near optimality of the protocol. So, first, we'll look at the theorem for uncomplexity extraction. We begin with in n qubit state rho, and we have a complexity parameter r and our an error parameter delta. And we assume that delta, r, and epsilon are Are related by a simple inequality. And we find that for a range of eta, there exists some protocol that extracts n minus the complexity entropy number of qubits delta close to the all-zero state. And conversely, we find that every uncomplexity extraction protocol must extract. Must extract at most n minus the complexity entropy number of qubits. And so to get some intuition about this result, we'll look at the low complexity limit, which we find that some protocol extracts in qubits, where every other protocol will extract less than n qubits, which is trivial. In the high complexity limit, In the high complexity limit, we find that all protocols extract no qubits at all, which comports with our intuition. In that case, the state is just so complex relative to our ability to probe it that it'll be impossible to extract any uncomplex qubits. In the case of uncomplexity expenditure, we have a similar result whereby we start again with an arbitrary n qubit state row. In qubit state rho, we have our complexity parameter r and error parameter delta. Again, we assume some relationship between the parameters. And we find that for every eta and for every junk state, sigma, that our state rho can be successfully imitated with n minus the complexity entropy number of uncomplex zeros. So again, we'll look at the low and high complexity. So again, we'll look at the low and high complexity limits. In the low complexity limit, we find that rho can be imitated with in qubits. So in that case, actually, we need as much uncomplexity as we can get in order to differentiate the actual state with our symbol acrom, because we already, the referee can do such a good job of. Can do such a good job of distinguishing the two. But in the case of the high complexity limit, the referee really can't distinguish states very well. And as a result, we can get away with far fewer qubits. And in the limit of high complexity, actually, we can successfully imitate the state row with zero qubits. So, as a summary for this talk, I first defined the resource theory of uncomplexity. After that, I discussed operational tasks defined within the theory, had a short interlude to introduce the complexity entropy, which was thereafter used to quantify the optimal efficiencies with which we could perform the task. Future research includes. Includes determining properties and applications of the complexity entropy. So, my collaborators and I have recently placed, put a follow-up work on the archive. So, it's kind of this comprehensive, kind of sprawling paper about the complexity entropy and its application to thermodynamics. So, you can find that on the archive and soon in PRX Quantum. PRX quantum. And we can also look at the so-called phases of uncomplexity extraction. So we had these parameters R and eta and R, eta, and epsilon. And we can ask in what regimes and what combinations of those parameters will we be able to extract any uncomplexity at all? At all. And so that's an interesting question that's related directly to the resource theory. And then lastly, there are connections to black hole physics that are worth probing. As I mentioned before, much of this work was motivated by questions that came from the high energy literature, particularly the work of Brown and Susskin in the second law of quantum complexity. And so it's working. And so it's worth asking if this resource theory can be of use to probing questions there. So again, this is the work. And yeah, I invite any questions. Thank you for listening.