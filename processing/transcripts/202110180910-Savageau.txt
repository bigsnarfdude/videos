I want to thank Thomas, Steve, and Constantine for organizing this wonderful meeting. And I love the three questions that you posed to get us focused. And very quickly, my response are, you know, what role does mathematical modeling play in systems biology? And I feel it's essential. You don't have systems biology without predictive modeling. Biology without predictive models. As far as challenges, I've tried to address those, and you see it in my title, and what we can do to overcome those. I'm making one proposal that's in a class, I hope, that there might be others. With that, I should say that I've noticed so far in the talks, I haven't been able to pay as much attention as I was like. I'm just recovering from some surgery, but. I'm just recovering from some surgery, but I think that you'll find that this is very different from the previous talks. But nevertheless, I think you'll find that there are some similarities as well as differences. So, my little thing doesn't seem to be working. Try clicking down on the arrows on the lower left-hand side. There we go. There we go. Okay, so here's the take-home message, if you like, that this phenotype-centric approach that we've been working on is based on linear algebra in a log space and avoids dense sampling and numerical simulation. The strategy is especially useful in the early stages of investigations when little is known. And it provides an efficient, what I would say, early, a fail-early method for hypothesis testing so that you don't waste a lot of time. And for a given And for a given model architecture, the strategy starts without kinetic parameter values and ends with predicted values for the realization of each of the phenotypes. And properties of specific phenotypes, as well as relationships among phenotypes, are related mechanistically to genotype and environment. So, what do I mean by architecture and what can it tell us about phenotypes? So, I think of the architecture as, you know, who are the players? As you know, who are the players and who's talking to who, and how are they doing it, and what are they saying? And can this information alone tell us anything that's really informative about phenotypes? And the second question is that what can phenotypes in turn tell us about their population dynamics and evolution, if possible? And so these are the two questions that I would like to address in a three-part presentation. To address in a three-part presentation, beginning with stuff that's a bit review and older stuff to stuff that's in progress. So, starting with the underlying mechanisms, which I think are the key to this problem of relating genotype to phenotype, and of course, it's always genotype and environment to phenotype. That's one of the grand challenges in modern biology. Mechanisms, I would claim, provide one of three critical mappings. Provide one of three critical mappings between genotype and phenotype. There's a mapping that goes from DNA sequence to kinetic parameters of components. And then there's a mapping from the kinetic parameter of components to the biochemical system phenotypes. And then there's another mapping from these biochemical phenotypes to what you might say are exophenotypes or organismal phenotypes. And biochemical systems theory is the domain that governs this intermediate mapping. Mapping. I think biochemical systems theory, its scope, includes mechanistic models governed by rate laws. Rate laws are the power functions of chemical kinetics and the rational functions of biochemical kinetics. And these functions and conserved quantities are integrated into a network by means of Kirchhoff's node law. And the result is a system of differential algebraic equations. Now, without loss of generality, the differential algebraic equations consisting of these Algebraic equations consisting of these power functions and rational functions can be recast into a more uniform generalized math faction form consisting only of sums of products of power laws. Now, when we look at this mapping from all the way from genotype to phenotype, we have a nice generic definition of what we think of as the genotype and the gene sequence with some caveats. Sequence with some caveats. But in terms of phenotype, I would claim that there's no comparable generic definition. Most things are ad hoc and descriptive. Certainly historically, it's been size, shape, number, bristles, something present or absent, and so forth. So here's an example of people who've lived in a microbial world as you leave a petri dish out on a windowsill, you forget it there, and you come back a week later, and you see these beautiful patterns. Beautiful patterns. And they're a property of the genotype, the kind of organism that was in that petri dish, and the environment. What were the nutrients in the plate and how long it had been desiccated and so forth? But even overnight, you see differences in smooth and rough colonies that are diagnostic for disease used throughout the clinical labs in the world. So I would claim that without a generic definition of phenotype, you can't really predict phenotypes that you've never always. Really predict phenotypes that you've never already seen. So, here's my definition of phenotypes: it's a valid combination of dominant processes involving all concentrations and fluxes. So, this is just saying it in words conceptually to begin with, and later we'll see more mathematical detail in a concrete example. But this is not a modularization, it's not leaving out anything. All the edges, all the nodes, all of the processes. All of the processes are involved in these definitions. So here is the generalized mass action equation: sums of products of power functions. These are horribly nonlinear. You can't do hardly anything analytically. But if you pick a dominant one, one of these many in the sum, and take that as the dominant process, and take one of the negatives as a dominant process, you get something which is still a non-linear differential equation, but it has some very Equation, but it has some very nice properties in that it has steady-state solutions that are linear in a log space. Moreover, the test for validity is that you have to put this back into the original system and verify that it is the dominant among all the others in that sum. And so you have a whole system of linear inequalities in log space. And these together, the linear solution and the linear inequalities, rigorously define linear hyperplanes in Hyperplanes in phenotype boundaries of polytopes. So we can explore these definitions a little more generality, if you like. So as I said, a phenotype is the set or sets of concentrations and fluxes corresponding to a valid combination of dominant processes functioning within an intact system. We talk about a qualitatively distinct phenotype as the characteristic phenotype that exists through. Phenotype that exists throughout a region of validity, that is a polytope in parameter space. And then a phenotypic repertoire is the collection of all the qualitatively distinct phenotypes integrated into a space-filling structure, the system design space in buff parameter values. So we talk about phenotyx at many different levels and in different contexts, if you like. We can talk about the mechanism itself and that. Mechanism itself, and that means we're talking about the portions of the system's mechanisms that are being exercised in a given genetic and environmental context. We can talk about the equations for a phenotype as those S-system equations. We can talk about the geometry, the boundaries, the volumes, the robustness in design space. We can talk about design in terms of the design principles, in terms of the parameter sets that are required to generate that phenotype. And we have behavior qualitative. And we have behavior, qualitative, and quantitative. So we can go back and forth amongst these different domains, but they all are ways we're describing the phenotype. Now we have a design space toolbox that automates the prediction of phenotype characteristics. And that's freely available as a Docker image that you can get downloading from my website here, if you like. It automatically gives us the repertoire. Gives us the repertoire of phenotypes. It's dependent only on the architecture. It predicts parameter values for the realization of each phenotype, predicts all the concentrations and fluxes in steady states. It predicts global robustness or tolerances for each of the parameters of each of the phenotypes. It gives you signal amplification factors, your input-output gain factors, eigenvalues for local dynamics. And a new direction we're trying to push this is that can. New direction we're trying to push this is that can tell can it tell us anything about mutation rates based on polytope volumes and centroids? I'll get to this later in the talk hopefully. So this tool enables a very different modeling strategy from what I grew up with. And what I have on the left is the way I've done this for most of my career is start with some conceptual model, my hypothesis. And the first thing I'm confronted is with is all these parameters I don't have the values for. And so I go to For. And so I go to some experimental system, maybe that's well studied, and I get some of them. And maybe there are some parameters in different organisms, and I cludge those together and I estimate things if I've got some data that I can fit, and I guess for a lot of other things, and eventually I get a parametrized model, then I can explore its behavior by simulation. In this phenotype-centric approach, we flip everything on its head. Instead of getting the practice, Instead of getting the parameter values early before you can do anything, we get them at the end by predicting them. Instead of getting the estimate of the phenotypic repertoire at the end, we enumerate that in the beginning. So it's really putting everything on its head. So the first things we do is typically we take our model, we formulate the model, and then click a button and then Click a button and it evaluates the repertoire of all the phenotypes for that architecture. And it gives us different kinds of phenotypes. And I put in parentheses, physiological phenotypes, maybe better to say well-defined, well-characterized, well-behaved phenotypes, if you like. They're the normal ones where everything in the linear algebra is perfectly determined. It also gives you cyclic phenotypes where you have rapid equilibrium. Phenotypes, we have rapid equilibrium and that has a degenerate rank deficient linear algebra that you can repair. And then there's a rare but important class of co-dominant phenotypes. But I would say these are all well-behaved. And in some sense, you could say those are physiological, but some of those in particular context might be pathological. But in contrast to those, there are really pathological phenotypes. Are really pathological phenotypes, phenotypes that essentially don't exist. It's a region in design space where things are exploding or imploding. That is, there are concentrations going to infinity or going to zero. And we like to identify these fragilities in our models. So it's important that we can characterize these pathological phenotypes as well as the well-behavior. Then this list of the repertoire can be very long, even for relatively simple. Be very long, even to relatively simple systems. And so, the task, really, and we've got this is an ongoing task, is to develop various filters that we can automatically pick out of that repertoire things we're interested in. So, already we've got filters that pick out all the multimodal phenotypes, all of the oscillatory phenotypes, all of those that exhibit some complex logic in response to an input of, say, output variables that go up and go down in some. Go down on some as a logical function. And this is where we see it's a failed early hypothesis testing method because if you don't find in this list any phenotype that you're interested in, then you can take that hypothesis and reject it and modify it and so forth. But you can do that in the very early stage before you waste your time doing any analysis or measurements and so forth. So here's just a couple of examples of this, small examples of how. Small examples of how we use this to use it. Here's a simple model if you can see my cursor up here of two transcription factors, X1 and X4. And there's logic by which they both influence their own transcripts. And there are four possibilities of mixing their interactions at those sites. And that's the general model for all of those cases. And when you analyze that, And when you analyze that, you find that there are 16 different logic designs, if you like, by these parameters, pi, and delta. And for each of those choices of logic, we get a number of potential phenotypes. That's the denominator in this ratio. And of that potential, only a certain number are valid. So we can get six out of 16 here and 10 out of 36 here. 16 here and 10 out of 36 here. So each of these designs has very different repertoire, if you like, of valid phenotypes. Moreover, in those that are valid, you can ask how many are oscillatory phenotypes. And what you see is in some designs, you don't get any at all. Others, you get one. Others, you get two phenotype regions that are valid for oscillation, and one that has four. So down below here is the way you can explore that. You also have another button you can click. That. You also have another button you can click to plot the phenotypes as regions in the design space. And moreover, in this case of four, you could say, suppose those four are isolated in different regions of design space. And how could you see all of them? Well, here's a command that says co-localization, and you ask, can I co-localize all of these phenotypes? And if it can, it will do it for you. And so I've done that, and it turns out these four can be. That and turns out these four can be co-localized with a certain set of all the parameters in here. And this green region, this orange region, yellow, and blue. And they all can be linked together. And you can verify that each of these are oscillatory by pressing another button, which simulates the full system, not my dominant phenotypes, if you like. Not my dominant phenotypes, if you like. And you see that each one of these is in fact oscillatory. So we verified that. So here's another. This was a little synthetic circuit, a pair of synthetic circuits that were realized, and that if you looked at the function you'd predict by using all of the standard biochemical kinetics for these, it doesn't generate the behavior that you predict. And so the question is: well, what's missing? And so we have. What's missing? And so we made up hypotheses by including other known interactions that can occur beyond the canonic ones here. We can have read-through, for example, to different cistrons. We can have a nonspecific binding of regulators and so forth. We put together a bunch of those to come up with 40 alternative hypotheses. And then we run those through our repertoire. And what we found is that only five of those Hypotheses could generate results that would match the experimental data, okay? Match it in a qualitative sense. But the question here was: what are the parameter values required to produce that logic? And the point is, you could have parameters out there somewhere in infinity that are unrealizable. And you can then put constraints on the parameter values when you do your repertoire and say, I only will include in my repertoire. Include in my repertoire parameter values, say, a binding constants between that of lack and something else, say very tight binding versus no binding. And when you put in biologically relevant constraints, those five, of those five, only one of them would match the logic of these circuits. So very rapidly, you could boil down 40 alternative hypotheses that you wouldn't want to test experimentally all of them, but if you did some reduction, you might want to test the five and so forth. You might want to test the five and so forth. Michael, can I ask a question? Is there a way of telling whether those parameter regions for things that match some set of experimental phenotypes are close to each other? Is this the plot that I'm seeing in A and B? In A and B, what you're seeing are, these are some of the lifetimes of these two transcription factors. Two transcription factors because, in the synthetic constructs, the way you do it basically is destabilize these with co-repressors or co-inducers. Got it. And these are proxies. I mean, the proxy would be concentration of IPGG, for example, on an axis. Got it. And if you go forward a slide, you said that you can add constraints here to the parameter space. Is there a way to map where the parameters live? Map where the parameters live before you actually put those constraints and ask whether those parameter regimes are contiguous or disconnected? Well, for each of those five, for example, you would find that there is a polytopen design space out there somewhere, and you would predict values. But they could be all over the place. I mean, it could be that they're, you know, like a 10 to the 17th. The 17th. Got it. Got it. And we're not interested in those, so we put inequalities on the parameter. We don't have to know what they are, but we can say, I want them to be between these extremes. Got it. And it does the same thing, and it finds the phenotypes that would fit that. Thank you. Okay. I've also got a quick question on that slide. What is your data matching criteria? Your data matching criteria? This is a logic function that these generated. So, in other words, that it should say that when you have IPTG and ACT, ATATC in different combinations of high, high, low, low, one, high, one, low, and so forth. What would the outputs be for these green flushing protein? So, it's a lot of okay. So, what you're, I see. So, what you're looking at. I see. So, what you're looking at are effectively steady states in data. Yes. Okay. Thank you. We'll see later what goes on in state space, but right now we're focusing in the parameter space. I guess while I have you here, do you match oscillations in any way? We don't match the oscillation in terms of amplitude and frequency, but we predict where they are and then we verify it. And then we verify it. And then all of the head early. We view this as something you want to do early in your analysis. And once you get yourself in the right polytope, the right area, you can use all the other methods you have to optimize something, to maybe fit the amplitude and phase and so forth. So I won't be talking about those, but all the standard methods that we use in the simulation-centric approach can be brought to bear once you're in a region where you want to use them. Uh, once you're in a region where you want to use those, does that help? Yes, it does, thank you. Okay, so the second thing is once you're in the right region and you've got phenotypes you're interested in, you can predict all kinds of properties. Let's say, say, steady-state solutions, input-output amplification factors, eigenvalues, kinetic parameter values. And the boundaries are really important because right away they give you the notion of global robustness. They tell you how big the volumes are for these human types. Big the volumes are for these phenotypes. So, if you're in a real tiny phenotype that's a little sliver, that's not something that's going to be very robust. If you're in a big fat region, that's going to tend to be robust to environmental and genetic variation. The other thing I would say, all these boundaries represent bifurcations in a sense. As we'll see later, some of these are standard bifurcations that you've seen in dynamical systems, and some are more subtle bifurcations that maybe you wouldn't call them traditional bifurcations. Traditional bifurcations. And then boundaries really give you design principles. If you want to design something to have this particular property, the design principles tell you all the regions of parameter space, all of the limits on parameters and so forth that you need in order to achieve that design. I'll try and illustrate these as we go along. So here's an example, a little cube model. And so here is So, here is, and I should say also the design space, we often plot different kinds of parameters on these axes. And sometimes we'll have an environmental parameter here on the x-axis and a genetic parameter on the y-axis. And then the phenotype is the z-axis, if you like. So, we can plot on the z-axis all kinds of different properties of the system. So, we could plot the concentrations of the heat map, for example, on here. Heat map, for example, on here. Here, I'm plotting, all I'm plotting here in the z direction is the number of eigenvalues with a positive real part. So, all the C of blue are steady state. And these red regions, these spheres, those are three overlapping phenotypes that have one eigenvalue with a positive real part, and that's a switch. So, you see those immediately. And the L region is an unstable focus, too. Two, it's a pair of complex Kaji and eigenvalues that got positive real part. And so if you compare, for example, if you're in this region of this switch over here and you look at it in state space, you can see the isoclines for the negative regulator in blue here, continuous line, and for the negative regulator in red here. Red here. And the dotted line are the isoclines of the particular, the three different phenotypes. Here for this phenotype, it's the straight line across here and the vertical line. So it's exactly matching here. For the unstable manifold, it's this sloping line here and the vertical matches exactly there. And for the lower manifold here, it's the straight line and this vertical line. This straight line and this vertical line intersecting here in the same place that the actual system does. And you can see the flows. So it matches very closely to the behavior of the full system here, except for these little divots in the corner here. We tend to overestimate, you know, here and here. So, in that sense, we think of our methods as conservative. If it tells you that you're going to have a switch, you know, if there is a switch in there like this, you'll find it. switch in there like this you'll find it. Here is the case if you were in the oscillatory region. You have the isoclines of the positive regulator and the negative regulator in red. And you have the two isoclines, the dotted ones, of the S system. And again, they match this unstable focus. And you get the limit cycle behavior here. And of course, for this one, it's very much like this, but the whole But the whole pattern is shifted over by two log words. Now, the other thing you can do is, well, I mentioned how this is similar to some of the bifurcations in dynamical system theory. If we titrate across up here, we go across this switch behavior here. And this is what you're seeing here. You go along to stable, steady state, and you reach this point here, and it drops down. And if you go backwards, you go back to a different point where it jumps. You go back to a different point where it jumps up. And again, we overestimate a bit, so it's conservative. This is more interesting if you go through here. You get a rich behavior where you first go through a saddle node kind of bifurcation. You have a sub hot bifurcation here, and you get oscillations. And then you get a SNCC. You get a SNCC bifurcation down here. Here as it intersects with this switch. So here's another example. This is a real toy synthetic circuit, which is a three-state counter designed by constructing certain kinds of hybrid molecules. And here's the state space for this. And so if you're in one steady state here and you perturb it by a pulse. Perturb it by a pulse, it goes up and comes back to a new steady state. So that's going up here, if you like. And now, if you hit it with the same size pulse, remember these are log spaces. So if you hit it with the same size pulse, it looks smaller, but it's the same size as this one. You hit it with a second pulse, and it crosses that boundary and goes to this point. So this is like going from one up to two. Here, if you go in the other direction and hit it with. If you go in the other direction and hit it with the negative signal with the first pulse, it goes up and goes to the second value of second to fixed. Oh, yeah, I'm going, I'm sorry, wrong direction. Down here. Start down here. I was up here. I'm now starting here. I hit it with a negative pulse and it goes up and falls back into this domain. Hit it with the same size pulse. It now goes up and comes back into here. So you can see a whole pattern of hitting it with a A whole pattern of hitting it with a positive thing, and you go up and hold that steady state. You hit a negative one, it comes down, positive one once, positive ones twice, negative one, that, so forth. So it can count in three states. So it's a toy, but it shows that you can, again, pick out how many fixed points there are for a given model. And then you can ask behaviors about those. And this is looking at it in state space, basically. Basically. Okay, so that's the first part. Just telling something about this biochemical system theory, how we define phenotypes, and how we get modeling strategy out of this. And we talked about design principles, but I haven't shown you any yet. So now I want to see if we can't take this a little further and push this into see if we can say anything about mutation rates between phenotypes. So, what I'm going to claim is that phenotype-specific mutation rates are based on four factors. The volume of the recipient phenotype, that is, if you have a phenotype in one, that's in one region of design space and you mutate and you change the genotype and you move it to a different phenotype region. I want to know what the volume is of the recipient phenotype. The second is the distance between the centroids of those two phenotypes. Of those two phenotypes, the donor and the recipient phenotype. And the third would be a size scale, that is, how probable is it that you will go that far to go between those phenotypes? And finally, a directional bias, which is sort of entropy, whether that is in the direction of increasing entropy or decreasing entropy. Okay, so here's a trivial little thing, two phenotypes, if you like, the simplest case you can imagine. Simplest case you can imagine in design space. And there's a boundary between them. And they have different volumes. As you can see, volume one is much smaller than volume two. So the idea is that we can get these volumes from our analysis. And we see that genotype two is larger than genotype one in volume. And so just from that alone, we can say that mutations from a large space to a small space are going to be rare, and those from a small space to a large space are going to be frequent. This is like throwing darts at people. This is like throwing darts at this space if you didn't know anything else, and all the mutations are random. You end up with more darts landing in the V2 volume than in the V1 volume. Okay, so that's part of it. The second part is that the distance between, say, a point in this space and a point in this space, that the That the probability is going to be related to how far apart those are. And we're going to be averaging that over these whole volumes. And it turns out you can do this just like you do the center of mass calculations in mechanics. So we can get the center of volume as the centroids of these phenotypes. And we'll measure the distance between those as the size of a mutation, if you like, the average mutation that goes from one to the other. From one to the other. And there is a size scale factor lambda that says that it's much more probable that she has small mutation effects than large ones. And there's experimental and theoretical data from population genetics that I won't go into, but say that it indicates there is an exponential kind of distribution that they fall off in that way by some factor they don't know. And this is a parameter we can't get from design space, but we can get it from experimental data for something like Experimental data for something like the lack repressant. Can I ask a quick question? Just a kind of technical question. So, we, I mean, we thought about similar issues, obviously, with other, so question, is it sometimes these domains could be unbounded? Is it the case or not? Like the yellow domain. And so then we always run into trouble to figure out what is actually the volume and what is the centroids because these do not have a proper definition. Yes. Yes. That's a very good point. Yes, that's a very good point. When we press a button to construct a design space, you like in the very beginning for enumeration, we put a bound on the box. That is, we're going to say the parameters don't go to infinity. It's not open-ended. We put it just the way we put bounds on a parameter, if we want it to be within the physiological range, we can put a bound on the whole design space to say that for every parameter, we're not. That for every parameter, we're not going to allow it to go to minus infinity or to plus infinity. We're going to have some, you know, we're going to some, you're going to restrict it to some, say, six orders of magnitudes or 12 orders of magnitude, whatever. You have that choice. You can pick it when you design or construct your design space. Does that help? Yeah, yeah. We always struggle with, I mean, this is maybe better because in the log space, these are linear bounds, right? So we struggle with the following. If I take the bounds, Following that, if I take the bounds, and this is a mathematical question, right? And you scale the bounds up, is it the case that the volumes of the individual parts are scaling proportionally to that? If that's the case, it doesn't really matter what the bounds is. If I take a box of size one or box of size 10, I'm not biasing kind of the volume choice. Well, it does absolutely make a difference. Yes. And that's one of the choices that we make. This is a stuff that's kind of in progress, but. This is a stuff that's kind of in progress, but the way we decide on that bound, how we're going to bound the whole box, is to say we want it large enough to include all the phenotypes, but not so large that it just, because once you get to the edges, you're getting everything unbounded, basically. And that would just shrink down all the interesting things almost to a little node in the middle of the design space, and everything would be these unbounded things. So that's too far. Things. So that's too far. So what we say is we want to take the minimum amount that'll include all of the phenotypes and not leave out any phenotypes. But all those that are on the edges, if they would go unbounded, they are going to be artificially bounded by a limit. And this limit we'll pick to be roughly the minimum we can do to make sure we include all phenotypes. Okay, that makes sense. Thank you. Okay. Okay, that makes sense. Thank you. Okay. Okay, now here's the directional bias parameter, and that is that the probability will be larger when the parameter increases in a direction that increases entropy. So we'll put this factor delta in the denominator of the exponential. And the probability is smaller when the parameter increases in the direction of decreased entropy, and we'll put the delta in the numerator. Entropy, and we'll put the delta in the numerator. And again, this is the parameter that we can't predict from our design space, but we can estimate that again from something like data for the lack operon, as we'll see. So those are the four things we include. And this is how we start to put them together. We say there's a mechanistic contribution from the mechanistic parameter, capital K, in the mutation going from I to J. There's going to be a There's going to be a distance between their centroids, and it's in log space. And there's going to be this Lambda scale factor, so they'll drop off slower or faster. And there's going to be a directional bias depending on when a mutation is in the I to J direction, it may be more prevalent than in the J to I direction. So then we take those mechanistic contributions, multiply it by the volume of the recipient phenotype, just the non-bias. Recipient phenotype, just a non-biased part of the probability. And we then normalize that product over all the possibilities. And from that, we get a phenotype-specific mutation rate between I and J. And then we get that to be a real mutation rate by multiplying that by the global mutation rate that's measured genetically. Genetically for an organism to like E. coli and so forth. Okay, so that's how we put it all together. And then there's how do you use this information? So if we could predict these phenotype-specific mutation rates, these Kijs, and we have the population number, the number of each of the different phenotypes, and we're doing this. And we're doing this in a particular case, steady-state exponential growth, which is the best-defined physiological state for single-cell bacteria, which was shown way back in the 60s by the Danish group. And so this is very nice. It gives you nice steady-state properties. The disadvantage of expressing it this way is that all the concentrations are continuously growing. Are continuously growing, so everything's going to infinity. But if you express them as relative frequencies as the number of phenotype I relative to all of the phenotypes, then you can rewrite these equations in a form which has a nice steady state behavior where it goes to a steady state relative frequency. So, mu's are the exponential growth rates of the different phenotypes, the relative frequencies of the different phenotypes of the R's, the The R's. The phenotype-specific mutation rates are the small K's, and the general mutation rate is M. Okay, so that's kind of how we're deriving the mutation rates and putting them in the equations, how we express the equations so that we can, as we'll show, we can test these in chemostat experiments with single-cell organisms growing exponentially. So, let me try. So, let me try and explore what some of the implications might be for the population dynamics and evolution of such a system. And so, here is, I'm considering a very simple case where if I think of the circadian clock module, and this is, Jay, I asked very early in your talk, what happened to the positive? And you said, no, no, it's there. And this is something I think is found in nearly all organisms as a module, if you like. But I'm going. You like, but I'm going to consider sort of a precursor module that I'm hypothesizing. That in evolution, when this first started, it didn't start with this whole thing, it had to start with some linking up of a small number of factors and with very limited cooperatives and so forth. And but as we'll say, it has to have some negative feedback in it. So that's our model, if you like. And this is the context we're talking about. We're talking about we can look at this kind of a clock in an oscillatory and a non-oscillatory stuff in the way here. Remind you. Oops. Pull that out of the way. Okay, now I can go back. I have another thing that's interfering with my screen here. So here's the idea. I want to look at oscillatory and non-oscillatory phenotypes and how they respond in a selecting and non-selecting conditions. So here's the idea, then an environment which is cycling between light and dark, I would say that's a selecting environment for the oscillatory motion because even though it's not a sustained oscillatory, It's not a sustained oscillation, it can be synchronized to that light-dart cycle, and you get a sustained oscillation, if you like, here of the oscillatory phenotype. But the non-oscillatory phenotype would just be constant. And that's in the mechanism. And then, if you looked at the population, the idea would be that this module, when it can sink to the light-dark cycle, and I'm assuming it can link to the metabolism, that that would have a selective advantage and it would increase in the population. advantage and it would increase in the population. Its relative frequency would increase, whereas the non-selecting, the non-oscillatory phenotype would be selected against. However, in a non-selecting environment, say constant light, then both in the mechanism, both the oscillatory phenotype and the non-oscolatory phenotype would eventually become constant. And in the population, again, there would be no selection difference. And Jay mentioned this, that if you knock out these clocks, for the most part, these cells grow. For the most part, these cells grow without too much problem. So that's sort of the way I'm thinking about the experiments that we might want to do. And so what is the mechanistic kinds of prediction? Well, here's that model, I say, and here's the way I'm going to represent it in the simplest sort of Hill function sort of thing with a minimum and a maximum expression and a certain stoichiometry n, which is going to be small. Which is going to be small, two in my example, and the rest of it is there's some first-order protein translation and degradations and so forth. Anyway, there are four variables in this model and 12 kinetic parameters. And I don't know any of these. So I do my repertoire. And this is just a small sampling of what you get out of the repertoire. This is actually a huge table where your first column is just listing the phenotype. First column is just listing the phenotypes by number, these are just arbitrary, and it's really listing only the valid ones. So you'll see some numbers missing because they're invalid for mathematical reasons. They're just impossible. It's not impossible because it's a pathological physiology, just mathematically impossible. So you eliminate all those and you're looking at only the valid ones. And you get a signature, and this is really telling you what parts of the mechanism are being exercised for that phenotype. For that phenotype in that genetic and environmental context. And I won't go into what these all mean, but you learn to see what parts are being exercised by just looking at the terms in each of the equations that are dominant. Then I've plotted here things about the eigenvalue. So I'm looking at the positive real part, and you can see that all of these are stable. There's none of them have a positive real part. And all of them lack a complex conjugate except for one, and that's phenotype 7. So that way I did. Phenotype 7. So that we identify as a possible oscillatory phenotype. Now, when I'm doing other things and I want to filter this repertoire, I might have lots of other properties of phenotypes listed in this table. And the whole thing is just like this. You want to filter it to find out those that are interesting and ignore the others. Can I ask a quick question? So, if you, the equations you have are kind of simple. So, what is the if you So what is the, if you look at which of the two pairs dominate, seems like there's, do you look at the first equation, the alpha constant? No, here what you're saying is that I'm showing you this in the rational function form, right? Right? Yes. So what we would normally, what the toolbox actually does is you want to convert this to the generalized mass section form, so it's only sums of products. So, it's only sums of products. And you can actually see sort of what's going on, even in this rational form, because what your possibilities are for dominance here, you can say, I'm going to have the first term in the numerator be dominant and the first term in the denominator. Okay? That's saturation at the max. You're ignoring the other parts. Okay? Or you can say, I'm going to have the second term in the numerator. term in the numerator up here be the dominant term in the numerator and one will be the dominant term in the denominator and I'm going to get a rising function with a slope of n in the log space so that's a regulatory region and then if I say it's these last two that are dominant then they're going to cancel out and you're going to get the minimum you're going to get the floor so So the four choices, the four choices, exactly. And only three of them are mathematically possible. Because if you tried the other one combination of the four in here, it wouldn't give you an activation or it wouldn't give you a repression, which is what this is. It would give you an activation, which violates your architecture. Okay, got it. Thank you. Okay. Yep. So, anyway, you get this at seven, is the one of interest. Seven is the one of interest, so we predict the parameter values for those for the realization of that. And here I'm plotting now different properties of that phenotype, if you like. And I'm doing it not only for that phenotype, but for all of them. So here is the design space when I'm just plotting the identity of the phenotype. So there's the oscillatory one here, this angled rectangle. And then I have these other eight surrounding it. So here's an example where you could say, It. So here's an example where you could say if you increase his right-hand boundary out to infinity, you would have all the phenotypes, but you just have this one, five, and six be exaggerated to the point where they're meaningless because it would have parameter values you'd never realize. So I'm limiting it here to some value three, three orders of magnitude. Okay, so that's just the identity, which is giving you the volume as well. And that's going to be important for how you mutate. Important for how you mutate from one of these regions to another. Here's another thing: which is I'm plotting in the z direction the concentration of the activator plus the repressor. So I'm calling this protein burden of the clock. So if you deleted the whole clock, there would be no protein burden. If you have, you can actually measure what the levels of the, as I say, you could predict the concentrations for all these phenotypes. And so we can now plot. And so we can now plot that concentration of the sums of those proteins in this design space. So you can see that there's a very low amount here and very high amount, very high burden here. Okay. And then, of course, we can verify that this is an oscillation by picking a point in a phenotype seven. We could take the one that it predicts for, so we could predict any one in here and simulate the full system, and you verify that it's oscillating. So it's the Oscillate. So it's the activator and the repressor. Okay? So here's getting at an idea of what we mean by a design space. That in this particular case, you can actually take and reduce a 10-dimensional parameter space to an invariant two-dimensional parameter space that's determined by two fixed parameters. Two fixed parameters, rho and of n and p. These rows are the regulatory capacities, the difference between the minimum and max that I was showing you in the equations. If you fix those two parameters, the whole design space in 2D is totally fixed. There's nothing you can change about this design space. So if you want to move in this design space, you have to change one of these parameters here. And these parameters are these just dimensionless groups. So if you want to change A degradation of the message for the activator. You're going to have to change pi. So it'd be changing over here, going in the vertical direction and so forth. So you can move around in this invariant design space by means of the individual parameters affecting these dimensionless groups. The other thing is that to realize this oscillatory phenotype, This oscillatory phenotype, you have to be within these bounds. And those boundaries define a design principle which says that all those parameters have to fit with some very specific set of functions with these exponents and be between one and these regulatory capacities. So, this is something that I really like that in these systems, there are design principles that you would never find by trial and error. By trial and error. And I don't see many other ways in which you'd have these come out as obviously as they do from the boundaries in design space, the way these do. We got the very first one of these years ago when we were looking at the induction of prophage lambda, and we found that the activation constant had to be within a narrow window of values in its design space, and such that if you went outside of that window, you would either be. If you went outside of that window, you would either become locked into the genome and you could never excise, and that would be the end of that tempered virus, or it could be above that region and you'd be locked into a temperate virus state where you could never integrate into the DNA and you'd always be growing as a lytic virus. So these are useful. Yeah. May I ask a question here? Because I'm getting a little confused. So you start with a system. You start with a system architecture for a negative feedback loop with two proteins and two messages. And you model that with Hill function nonlinearity, so it looks like biochemical reactions. And all the parameters on the left-hand side of this diagram are defined in terms of those Hill functions, if I understand correctly. But then you get these system design principles. system design principles and and the and all these other things from from this approximation using s systems do i understand correctly s systems plus all the inequalities which are extremely important because if it were just the s system you would find that not all the parameters and i mean yeah not all the parameters concentrations and so forth would would be in that description but together with the boundaries everything is included yeah Everything is included. Yeah. But these limits on your design principles, let me put it this way, are derived from an approximation of the continuous biochemical, let me call them, with the Hill functions. Right. Correct? So then I guess the natural question for me is, is how good do these system design limits in the lower Limits in the lower right corner correspond to what you actually see when you solve the Hill function equations numerically, when you do the simulations. How predictive are they? Right. Yeah, you can have a good question. And that is that this is an approximation. So this is why I say this is what's important to use these methods early in a stage when you don't know anything. And what this allows you to do is to get this, what I would say, a design principle. And then you can go in and explore. And then you can go in and explore how accurate is that design principle. And what we find is that you're close, but you're, as we saw in the switches, you get these divots where we've overestimated in a sense. So the design principle, I would claim, will be within these bounds. These are conservative bounds in the sense that if there's something inside of there, if there is something, it's going to. Inside of there, if there is something, it's going to be inside of this. Okay, and then the other question is: if I understand what you're doing, when you predict oscillations with the approximation, they're damped oscillations. In this model, you got a complex conjugate pair with negative real power. But you are looking for sustained oscillations. So, you're just hoping. I maybe confuse you. I'm assuming in this primordial state that you don't have. Mortal state that you don't have enough cooperativity and enough interactions to get a sustained oscillation. Okay. But certainly in the system of nonlinear ODEs with the Hill functions, I can get sustained oscillations out of that. Absolutely. If you have enough steps in the loop and you have enough cooperativity. Well, yeah, and you certainly do. There's four steps in the loop, and there's arbitrarily large hills. Arbitrarily large Hill exponent. So, I know, no, no, that's what I'm, John. I started with an assumption that in this primordial state, I'm assuming that it's going to be, there's only going to be a very limited amount of cooperativity. You're not going to have evolved very highly complex of molecules in this. I'm assuming the simplest kind of starting place. And so, the maximum I'm allowing here is an n of two. Okay, okay, thank you. You didn't say that, so I just. You didn't say that, so I think I did, but I probably brushed over too quickly. I missed it. I'm sorry. No, it's probably. Okay, so maximum just to be specific in this model, and that's why you see specific numbers in the exponents in the designs principle here. Yeah, is that the n is two for each of these transcriptions, and everything else is first order. So the cooperativity around the loop is only four, and there's four steps. And so Four steps, and so you know, I think you proved this as well as we did. We proved this many years ago that that can't generate a sustained oscillation. Yeah, sure. Okay, thank you. So, yeah, but you're absolutely right. If I increase these ends to three or four, then this will give me a sustained oscillation. But I'm trying to get at the idea here that it's not really, it's a really poor oscillator, but in the beginning, it can synchronize with the light third cycle and create a strong enough oscillation. And create a strong enough oscillation to drive metabolism as if it were a sustained oscillator. Okay? That's the idea anyway. So let's see what we can say about this in this first go at it. So we need these two parameters, lambda and delta. And so we don't know what those are, but I'm going to say if we look at the lac operon, there's this heroic study that was done back in the 90s where they Back in the 90s, where they basically replaced every amino acid in the lap repressor by an alternative. And then they tested those mutants, those phenotypes, if you like, or tested those mutants for their phenotype. And they asked, are they wild type in the sense that they are still inducible or repressible? Or are they constitutive? Or are they super repressed? So they have three sort of constituent phenotypes, if you like. Phenotypes, if you like, that they're going to group them into. And what they found for the lac repressor that out of some 4,000 mutations, essentially doing this fine-structured mapping of the repressor, that 67% of the phenotype positions could be changed with no change in the phenotype. 31 of them led to constituent expression, and 2% were super-repressed. Okay, that's a specific protein. Okay, that's a specific protein. And for other proteins, it could be very different, you can imagine. But what they also did is to say, let's look at the a lack family of proteins. Now, these are not all transcription factors, but there are other kinds of metabolic enzymes and other kinds of things that are in this family somehow. And they looked at the evolutionary alignments of their genetic maps. And what they found is that there were 61% of the sequence, which residues which are Which residues which are not conserved. That corresponds to the wild type not changing. So they're allowed, if you like. And there were 39% that are conserved, which is sort of the sum of these, if you like, in that if you mutate those, you get a defective phenotype. So maybe for other proteins, this kind of set of numbers might not be too far off for different transcription factors. For different transcription factors. But in any case, what we've done is for our end gene in our clock, we're going to vary these two parameters until we can match the LAC request. And we can do that with these two values, a lambda of 0.6 and a delta of 1.85. Okay? So this is something we have to get from data. So now, here's one other thing. Now, here's one other thing that I want to use later, and that is there are alternative hypotheses concerning neutral and protein burden fitness effects in the non-selecting condition. Okay, so here's our oscillatory phenotype and all the others. If they all grew with exactly the same growth rate in the non-selecting condition, we say that's neutral. There's neutral fitness effects that those phenotypes have in that environment. Have in that environment. On the other hand, as we saw, there's a protein burden, and that would allow them, if you take estimates from, again, a lac operon, you can estimate how this might affect the growth rate. And there are small variations in the growth rate then for each of these phenotypes based on what their burden is relative to the oscillatory case. So there are some that would grow slower because they have a higher burden, or some would go slower because they have a higher burden. Or some would go slower because they have a higher burden, and some would go faster because they have a lower burden, and so forth. Again, in the non-selecting environment. Now, the alternative hypothesis here is that it's effectively neutral because there are other burdens which swamp out this little protein burden. And the alternative hypothesis is: well, there is some maybe some kind of a burden, but this is on top of that, and this maybe makes some difference. So we'll look at that later. Later. But I want to show you now the different contributions to the equilibrium distribution. So, this is a steady-state distribution after long-term growth in a fixed set of conditions. So, if we just looked at the volume effect, okay, then what we'd see is all of the different phenotypes, and this is in the neutral fitness condition, what you see is they all. Uh, what you see is they all grow at the same rate, but the mutation rates are going from the smaller, are taking you from the smaller volumes to the larger volumes. So, you get a little distribution here where the phenotypes for the largest volume is going to have the most, have the highest frequency, and those with the smallest volumes will have the lowest frequency in the distribution. If it was just that totally neutral, throwing them darts kind of thing. Now, if you add in Now, if you add in the length effect, lambda, and the directional bias effect, now you get this gradient in the distribution where you've got things that are moving in the direction of higher entropy up here. And higher entropy means that the transcription factors are poorly binding or not. Factors are poorly binding or not binding at all if you really go out here. So these are the higher entropy and lower bent are the really tight binders down here. And so you're combining this now with the volume effect and the distance effect and the scale effect and the bias effect. So you're getting a gradient here now in this distribution. Now, if you put in the protein burden, You put in the protein burden and look at this in the protein burden fitness effects. What you see is starting here, if the protein, and now we're looking at this with different mutation rates. Before it was all with the same mutation rate, with no mutation rate difference, the non-selecting condition. So here you have different mutation rates. And if you had a mutation rate that is Rate that is very low, then you get this profile, which is very much like the neutral what we saw before, which is the black line here. But as you increase the mutation rate, I'm sorry, decrease the mutation rate, then you take it, you move it toward the The shift of peak of the distribution to the lower entropy states over here. Okay? So high mutation rate, 10 to the minus 4, is randomizing things and giving you the effect of the neutral. And as you lock them in, you can. You lock them in, you can trap those higher, the lower entropy states over here to some extent. Okay. And then the far right is now we're going to include not only robustness and entropy, but let's look at different degrees of selection. And now this is difference between the growth rates of the oscillatory phenotype compared to what it is in the non-oscillatory. In the non-oscillatory or in the non-selecting condition. And so now we can take it from what we found over here and pull it to the right by selection. So mutation can drive it to the, lowering the mutation rate can take it to the to the left, and increasing selection can take it to the right. So you can get a mutation selection balance kind of idea out of this, which you find in. kind of idea out of this which you find in population genetics. So you can simulate the time courses as well in the now this is time and the evolutionary time scale if you like and you look at it in the different with different fitness effects either the neutral or the mixed and pick a different mutation set of selection coefficients and run it for different And run it for different amounts of time. And what you see are that all these different phenotypes change their relative hierarchy in the population. There's crosses of crossovers at various places in time. And eventually, of course, it stabilizes in a new steady state. And you look at the time scale to go from a non-selected condition to imposing selection and going to a new state, and compare that time scale with the removal of selection starting over here. removal of selection starting over here and going backwards you're starting these are different you're starting with these values here and then it goes back and these are much slower when you move selection by a couple orders of magnitude which is kind of interesting and finally we haven't been able to predict anything about what the selection is on these different phenotypes but Different phenotypes. But if you could carry out this kind of program that I'm mentioning here, what you can do is you don't know the selection coefficient, but you can run the simulation through different values for the selection coefficient. And this is the case, for example, for the lac operon or for our n-gene in our model. And you ask, you know, at each value of the selection coefficient for the oscillatory phenotype. Uh, oscillatory phenotype. What is the relative frequency of the, for example, the wild-type lack repressor or the oscillatory? No, I've got to do this right. I'm doing it for the oscillatory. I'm better doing it right. So the green would be the oscillatory phenotype at different selection coefficients. The super repressed would be these blue ones as a function of different selection coefficients. A function of different selection coefficients, and the constituent, when it's always on, would be the red. And you can sweep through this, and so that's the neutral fitness background, if you like, where it assumes that all of the phenotypes grow at the same rate, except now the oscillatory phenotype, which has a selective advantage. In the mixed phenotype, the protein burden, you start off where all of the phenotypes have some difference in growth rates, and if you start off. And if you start off with no selection for the wild type or for the oscillatory phenotype, what you find is that they're mostly constitutive, ones that are the highest frequency. Then you have the constitutives of the lowest and the oscillatory ones are low, but in the middle. And then as you sweep across, increasing the selection coefficient for the oscillatory phenotype, you follow this behavior. And then I've drawn these lines in here. And then I've drawn these lines in here where I'm saying that's just a prediction from the mutation rates alone, and I don't know what the selection coefficient is. But if I put in here the values for the lac operon of the 60% for the wild type oscillation, 30% for the constitutive, and 2% for the super-repressed. And I match those, that tells me what the That tells me what the selection coefficient would have been to generate that particular set of results, experimental results. And when you look at it over here, if you ask, can you match the 60% for the oscillatory frequency? You can't match then the values for the super repressed and the constituent. In fact, they're the opposite directions. So, in that sense, only the neutral hypothesis would be consistent. Would be consistent with this sort of idea that we would have gotten from the lac opera. Okay, so I'm probably running out of time here, but let me just summarize what I think the key attributes of this phenotype-centric modeling strategy is and the toolbox that automates it. It's based on linear algebra in a log space, and it tends to avoid sampling and numerical simulation, except for verification. It's especially useful at the early stage of investigation. Useful at the early stage of investigation when little is known, so we don't have to know any of the kinetic parameter values to begin with. It's an early fail-early method for high hypothesis testing so that you get it right away from your repertoire of phenotypes. If your phenotype of interest is not in the repertoire, you stop with that hypothesis and move on. So I say it doesn't require the parameters in the beginning, but it can. Require the parameters in the beginning, but it can realize predictions for the parameters at the end. Now, that may not predict exactly the parameters of your experimental system, certainly, but it puts you in the right ballpark. So, there are a lot of optimization methods that are very efficient, but they require good starting guesses for your parameters. This should help by putting you in the right polytope to get that kind of thing started. And finally, we hope that it's going to be able to predict systemic properties. Well, we know it does predict specific systemic properties. Predict specific systemic properties of particular phenotypes, and as well as relationships among phenotypes in terms of design principles, and hopefully, maybe mutations between specific phenotypes. And these are mechanistically related to both genotype and bioenvironment. So, these are the folks that at various points have developed important ideas in this biochemical and assistant theory. Ebhard Foyt, Sakamur. Uh, Debhard Foy, Sakamoto, Soribis, Sharishi, Halifazek, and Naomius. And the definitions of phenotype and global tolerance, Peter Kwalla, and Dean Tola. And the design space and stoolbox thesis were Vasani, Lomnitz, and Valderama Gomez, with support from NIGMS and NSF over the years. I'll thank you for your attention.