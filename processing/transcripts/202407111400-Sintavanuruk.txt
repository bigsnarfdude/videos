Okay. Uh so sorry, give give me a second. All right, so um thank you. So first I would like to um thank the organizers for giving me opportunity to participate in this workshop. So unfortunately, I cannot be there in person due to my reason. There in person due to my visa application issue. So, my name is Aiden. I'm a second-year PhD student in applied math at Penn. So, I'm excited to share with you some early stage work where we explore the morphogenesis of neurons. So, this is to work together with Professor Mori and Professor Katifori. So, we just started this a couple months ago. A couple months ago. So, so this is very early. So, your feedback will be very important for us in shaping the direction of this work. So, to set the stage, you guys hear something? Okay. So, I'd like to begin the talk with this time-lapse video, which is owned by Letisha Beris. So, this beautifully illustrates the morphogenesis of hippocampal neuron. So, this captures remarkable dynamics. Remarkable dynamical complexity of neurons as they develop into characteristic neuronal shape that we know and love. So, at the beginning, we saw that there are multiple neurides, which is the protusion of the structure that protudes from the cell body. And one of them is fast-growing. This is axon, and the rest are the dendrites. So, these neurites are capable of growth and branching, and the dynamics of these are not very. Dynamics of this are not very well understood. So there's no doubt that uncovering this, what is the principles that govern the morphogenesis? So this will be very important for neuroscience. So as an applied math student, I want to look for the problem like this that I could formulate into math, formulate mathematically that would buck. Formulate mathematically that would spark development in math and science. So I feel like this is a good setup for me to get started and visually look fascinating. So I want to capture this in a simplest model possible while still give us some insight into how the neuron, a neuron looks the way it does. Oh, yeah. So I do realize that this work currently focuses on Focus on a tree-like structure of single neurons. So it may seem a little bit removed from the looping networks theme that we have in this workshop. But I believe that this could have some overlaps with formation of various biological networks, especially those that rely on transport and assembly of materials, which is the main aspect that I would like to focus on. So what do we understand about the neuronal fortune? About the neuronal morphogenesis. So, we know that neurons develop their morphology through the dynamics of specialized structures called the growth cone. So, these growth cones can be found at the tip of neurites. So, this is the site where material such as cytoskeleton, new membrane, assembled into a neurite shaft, while the growth cone migrates away, possibly leaving behind some membrane protusion that could stay. That could stabilize and turn into a new branch. So, this is the biological basis of the elongation and branching underlying the morphogenesis. And there are previous researchers that investigated this morphogenesis computationally by considering the dynamics of growth cones. So, some of these describe the dynamics as something that is influenced by external factors like Influenced by external factors like a growth factor or interaction between neurons. And that's also one of the specified rules that allows them to replicate some experimental observation at various scales. And there are also some that approach a little bit differently into morphogenesis, such as this one, which describes the morphogenesis as pattern formation that arise from class. That arise from classical Turing instability, and also ones that use that is based on the optimization principle of material cost, conduction time, energy efficiency. But still, so these descriptions are mostly phenomenological. And so overall, we're still lacking models that describe at a mechanistic level. And so we think that perhaps to gain more. That perhaps to gain more insight into the growth mechanism, we can take into account the fact that the growth cone requires material to elongate. So notably, in particular, we think about the microtubules, which is cytoskeleton that not only provide the structural support for the whole neuron to maintain its shape, but also act as highways for cargoes of other essential structures. Essential structures, including mitochondria, vesicles, mRNA, and so on. So, the transport, so, so, this also involves in transport. So, note that the orientation of mycotubules is also important. So, we can identify the plus n and minus n. So, plus n is where it polymerizes and elongates. And this will tell you the direction where it needs to transport the cargo, which is carried out by two types. Which is carried out by two types of motor molecules. One of them, kinesin, is going to move toward plus end, and the other, the dynine is going to move toward minus end. And this orientation is not uniform. Some of them is uniform. So in axon, the orientation is going to be plus n pointing outward. So this is plus n, this is minus n. So minus n is pointing toward the soma. Why in the dendrite? The soma, while in the dendrite, we have a mixture of polarity inside. So, what this means is that in terms of transport, we expect that the exon is more effective, while the dendrite has enhanced diffusion as a result of mixed polarity. And the important point here is that the production of most cargoes that we have are going to involve synthesis of soma at some point and then transport to the distal part. So, for MicroTuber. So, for mycotubu, for example, the tubulins, which is the monomers for the polymerization, are synthesized at soma and they're transported as short polymer or feed tubulin to the sideway needs. It is needed. Yeah, so overall, we would say that intracellular transport is the limiting process that drives neuronal growth. And we want to take this into our model. So, just a review. For the data model that models the elongation dynamics, especially this one, which taking into account the assembly of tubulin at the tip of neurite, and they describe the elongation dynamics as one-dimensional free boundary. But still, this does not have branching, which is the aspect that we also want to include as well. We also care about the shape of neuron. We also care about the shape of neuron, and there are also some work that describes more mechanically that describe the force generated by growth cone, but still this doesn't address transport or the shape of neurons. So as far as I'm aware of, despite the importance of transport mechanism that I told you, its influence on the neuronal shape is still unknown. And this is something that we want to explore. Explore. Oh, not again. Okay. I'm sorry about that. Oh, what happened? Sorry, I'm facing technical problem. Okay, so where we're at? Okay, so yeah, so this is where we came in. So our current objective aims to bridge this gap by developing the mathematical framework that is simple, but describe how intracellular transport contributes to the neural nerve growth and branching and give rise to the shape. The shape. So, by we hope that the toy model that we have will eventually help us gain some deeper insight into the fundamental principle of neuronal development. We hope so. So, let me describe the model. So, we're going to assume that the elongation and branching is going to depend on material, especially the concentration at the tip. The concentration at the tip of the material. So, this material, we do not model explicitly what this is. We're going to keep it simple. We want to think of it as a cost graining of microtubule based transport into a single model unknown. And this will be the transport of this will be described as diffusion advection process. Well, advection is going to represent the interaction between the motor and the omicotubule. Interaction between the motor and the omega-tubu, which gives you directionality by S, depending on the polarity and the motors. And also, we also have diffusion, which is going to represent the free moving material and also some mixed polarity of the microtuple. And we also assume that this is synthesized at the soma and then need to be transported by advection and diffusion rule that we set. We also, okay, so this is the Okay, so this is the nice part that I don't know if it's good or not, but certainly it simplifies things a lot. So we do not care about how neuron is embedded into any geometric structure. So this means that we don't describe something like branching angles, curvature, or contact between neurides. So we don't care about this. We're going to strip it down to the minimum where the neuromorphology only contains information about distance between two points in the branching structure. Points in the branching structure, which also give rise to topology of this space. So, to be more precise, we can write down diffusion equation for the material rho with the advection rate A and diffusion coefficient D. And these parameters can be especially inhomogeneous to reflect that neuron and exon and dendrite are quite different in terms of microtubules. So, we also have. So we also have the production rate S, which we concentrate at the origin zero, which represents the soma. And this equation is described in a time-dependent domain, omega, where this is one-dimensional branching structure that I was talking about. So basically, so we describe it as metric graph. So what this means is that this is the collection of Collection of multiple intervals that including the soma, and these are glued together into a branching structure like this. And the gluing is just symbolized by this equivalence relation. So we want to think of it like this, like we glue the L2 interval into the L1 interval, for example. And the L describes the dynamic length of the branches. And this is described. And this is described by the second equation, which describes the elongation rate as a growth rate constant gamma times the tip concentration. And the elongation problem is then closed by the boundary condition for the flux J at the tip when a material is going to move along the moving boundary. And we have the parameter kappa that is the construction cost. That is the construction cost. So this says that as neuron grows, the material is going to be consumed proportional to how much it elongates. Oh, and by the way, this differential grade can be made well defined by specifying the condition at the vertex. So the vertex means the joining, the gluing, the Joining the gluing, the branching point of this structure. So we require that we need to have a continuity condition for rho and we have Kia Hoff condition for J. That is important. Okay, so finally, we describe the branching process stochastically by having branching points on any pre-existing brand repo-song process. So if we take any branches and we have branching points along this. have branching points along this this this branch um so so this is described this is assumed to be poisson process of rate um some constant beta times the tip concentration tip at that point at that time when when it becomes a tip so um so once that branching event happens um that the the the model is going to give you a new um uh interval to to be to be glued interval to be to be glued to the major structure. All right, so it is important to note that this description, this stochastic description relies on some simplifying assumption that so right now we are taking the gamma to be positive constant. So this means that this neuron is ever growing. So the length can only be strictly monotone increasing. So this is not at all. So, this is not at all realistic since we know that a branch of neurite can alternate between elongation and retraction back to parent branch, and this is known in literature as dynamic instability. Well, in fact, we kind of have seen that happen in the video that it showed you earlier. But anyway, for the sake of simplicity, we're going to proceed as is and see what happens. Aiden, you have about four more minutes. Four more minutes. Sorry, you have about four more minutes. Can you speak to the microphone? We have about four more minutes. Four more minutes. Okay, thank you. Yeah, so to summarize, we have three models that describe transport. And we also have parameters that describe the growth and branching, the growth corn dynamics in a material-dependent manner. Okay, so this is. So, that's also a challenge about this. So, despite the fact that we have a few numbers comparing to those of a pre-existing model, these are more interconnected in the sense that if you want to say, for example, if you want to fit experimental data to number of branching, for example, instead of tuning one or two parameters that directly control the rate of branching, we have to simultaneously fit all of these. Since they all contribute to the concentration dynamics, and that's going to determine everything. So, that's a challenge that we need to work and also work with our experimental collaborators. So, this is the main thing I want to show is other than the model is some cool video. So, this is the animation that came about this model. So, this video shows simulation of a density. So, this video shows simulation of a dendrite, and by dendrite, I mean it's characterized by olive diffusion, there's no advection, and we see that it elongates and there's a branching at the tip as it grows. And we can also do the same for axon, which is characterized by weakly diffusive neurite. And that's it's more evictive. So, we see that the concentration of material is going to be pulled up. Of materials going to be pulled up at the tip, and we see this growth pretty fast, and there's a lot of branching going on. And we can couple them together. So what this is, is that at the beginning, we have two stem. So at the middle is the soma, and on the left stem is the axon, and the right stem is the dendrite. And we kind of see that there's a lot of growth and branch. A lot of growth and branching in axon that we saw that happen in the video that I showed you, and we have less growth and branching going on on the dendrite. Here's another example. The same condition. Again, we see a lot of growth and branching in axon and this is dendrite. So still, these are, well, that's something a little bit different that cannot be kept. Bit different that cannot be captured by this model. So let me look at the first video. Let me play this to you again. Let me fast forward a little bit. Okay, so now we kind of see that the new axon have two main branches. And then that's this one growing. And then what we see is that while this is growing, these two guys, oh, okay, so give me. Um okay, so give me a second yeah so so these two guys uh start to to um stop growing and and some even even start to shrink. So this this cannot happen in our model. Um so we asked whether if we include that, is there something that is interesting that we can we can ask about if we can include that into our model? So we we we start to modify uh the model a little bit. The model a little bit. So, in the elongation rule, perhaps we can include some disassembly parameter that we allow for the length up to the nearest branching point. And we do not allow the retraction to go back further away from the nearest branching point. So, with this, we also have to modify the stochastic description. So, when it retracts, it kind of So when it retracts, it kinda, we gonna make it forget the branch that is deleted. So we have some retraction period, some period that is forgotten by retraction, and the same description is gonna be described when we subtract that regions. And here's some speculation that comes from our discussion with our experimental collaborators, Raisa Faradiva. So perhaps, maybe if we allow a retraction. Maybe if we allow a retraction, we can say that we can expect that the max path length of the neuride may be enhanced if we allow a retraction. So this may not seem surprising. Like if we allow retraction, there's going to be more material that's going to be used by one of the new right, but still, we also allow it to give more. to to to give more it more chance to to branch so so they this this is also shown by this paper that show that if we allow retraction then we can generate a lot of branching um so so this is not um entirely trivial um so so this is something that we are investigating so in conclusion we we have a model that represents neuronal growth um mainly topology of neuron as the family of metric graphs that random metric graphs Random metric graphs as a stochastic process that satisfies the diffusion infection dynamics of material. So, the current direction, we want to improve the numerical method. So, we want to make sure that what we see numerically is something that represents the description that I told you, not some artifact that generates from numerical methods, especially if we think about it. Like, everything is going to be determined by the tip concentration. That's very sensitive. The tip concentration that's very sensitive condition. So, so we want to examine deeper into this, and we also want to work with our experimental collaborators to verify this. And we have some speculation that we can work on, and we can perhaps explore this mathematically, considering that this is relatively simple. I hope so. Okay, so thank you for listening. And this is our collaborators. This is our collaborators from Fat Iron Institute. Thank you. Questions? Okay, so I have a question because maybe I didn't get it. What is controlling the direction in which your peaks are going? Oh, so the direction, we don't have. We don't have embedding of this new right structure into any space. So the only structure we have is going to look like. Yes, but these are some nice figures, right? With some, I don't know, it looks as if they had some shape. Oh, oh, yeah. So the shape is actually decided to actually decided to we just spread it out just but but but the the the location where it is doesn't matter in in this model no so are you saying that this is just a multi representation but the actual shape doesn't matter um so so the length the length is represented here the branching points and and where where these new branches are connected are represented here but but the location exact location the angle this doesn't matter uh this this is This doesn't matter. This is not exactly.