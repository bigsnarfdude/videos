Perfect. Thank you for the introduction and thank you to the organizers for inviting me here. Very nice. So I don't, I'm curious what the decision was on the clicker. Okay. Occasionally. Let's go back though. Nope. Yeah. Okay. So maybe the first thing I want to say is so. The first thing I want to say is: so, this is on adversarial training, and there are connections from adversarial training to optimal transport. And I will basically not be touching those. But there are definitely some other people in the crowd who would know something more about that. I'll be talking about some joint work with Leon Bunger, who he's at the University of WÃ¼rzburg, and then Tim Laux, who is not here, but he's at the University of Fregensberg. Yeah, okay, perfect. Yeah, okay, perfect. So, also, credit to Leon, I stole two of his pictures at least. So, okay, we've at least seen something about supervised learning in Matthias's talk, I think. And maybe just to sort of set the stage, typically what happens is we're given sort of a distribution that's telling us how we're likely to classify something. And this is captured in this measure row. Measure rho. And the goal that you have in this learning task is to sort of come up with a general hypothesis, such that if you take any point in your feature space, omega, you can come up with an appropriate classification label. So here, you know, what you should be thinking of in application is where you have some sample points, and these you use to construct your distribution, row, and then you sort of want to. Then you sort of want to find a hypothesis, which is basically given by the shaded blue region and the shaded red region. So you want some scheme to do that. And one sort of standard way to do this would be risk minimization with an L1 loss. So this is sort of the easiest option we could choose. You just minimize the expectation distributed according to this measure of U minus basically whatever the likely classification is. Whatever the likely classification is in that region. Now, risk minimization is accurate but not stable. Basically, it's doing the best it can given the information you have. But if there is some sort of perturbation in something, it's not going to necessarily behave well. And so, this is where I've stolen a picture from Leon, which he loves classical music. So, it, of course, has a violin. So, if you have, So, if you have this picture, so this is basically X. This is your feature. And your label is violin. So, this is what you would want to be labeled. But if you add a small perturbation of your feature, and so here, you know, just some small parameter and then some bad data that's potentially well chosen, you can actually just destroy your classification. So, you can make it so that your model thinks that this violin. Your model thinks that this violin is a sea lion. And so, the language we use to describe this is: this is an adversarial attack on your model. And it's only using a small perturbation of your feature, which is on scale epsilon, which is referred to as the adversarial budget. And then, okay, yeah, by just making these small perturbations, you can sort of destroy your classifier that you got from risk minimization. Minimization. So, an alternative approach, the sort of just plain old risk minimization was proposed. I think, okay, I mean, I think there were things that were previously hinting at this in the literature, but by Madri in 2018, and this is to look at a more robust optimization problem. And this is a min-max type optimization problem. So, here we're still infamizing over possible hypotheses, u, and we're Hypotheses, U, and we're minimizing the expectation. But now inside the expectation, we're taking a supremum of something. And so, okay, let's just slowly work through what this supremum is. So, here you want your classifier at a point x tilde, which is in some epsilon neighborhood of your original point x, to be close to whatever the likely guess is for the classifier. So, in principle, Classifier. So, in principle, what this is saying is this is saying your classifier should be good at x, but in all epsilon perturbations around x, the classifier should still be good. And so, in particular, hopefully, we can sort of have a slightly better optimization problem that withstands sort of these adversarial attacks. Yes. Okay, so this is motivational. I assume we're all very motivated now, and I'm definitely. I'm definitely coming at things more from the analytical side. And in particular, some relatively recent work by Leon with Nicholas Garthiotrios and Ryan Murray in 2022 showed that if you're in the binary case, there's a very nice complementary perspective on this min-max problem. And so, in particular, you can break up this inf, and then, okay, you have a supremum on the inside, which maybe you. A supremum on the inside, which maybe you don't want. And so you can break it up into the minimization of the sort of expectation, so just the standard risk minimization, plus a non-local functional, which I've written as TV epsilon here. Yeah. You say that again? In this case, it's going to be L1. In this case, it's going to be L1, basically. But typically, you have to, you can impose a class on your function here. But in this case, so now that we have this side of the energy, I mean, we can use, what was this? It was MF, meaningful, right? Uh yeah, there's a little epsilon in here. So, this is also not the standard TV. All right, so just to write it down, I don't know if this is helpful. So, here we haven't managed. So, here we haven't managed to entirely avoid supremums. Okay, and this should be the essential supremum also. But so, the TV functional here is actually going to, okay, and this is why it's a TV type functional, is it's going to compute the sort of difference quotient of the essential supremum of U in this T epsilon ball, that epsilon is so small, versus the center point. And then, okay, difference quotient, so it's on order epsilon. Quotient, so it's on order epsilon, and similarly, you would have the difference of u epsilon minus the essential inf. And sort of here, this supremum one lives on the region where, yeah, okay, perfect. It lives on the region where you're interested in the classifier zero. And the essential infimum lives on the region where the classifier is going to be like one. Would you buy this? Okay. For now, it's one of these magic black boxes we'll just have to trust. Yeah, exactly. Okay, so yeah, it's a, so we have this non-local sort of total variation. And okay, how close it is to a total variation is, I guess, up for debate at this point. At this point. But maybe to get slightly more intuition on what it's doing, it helps to just plug in a characteristic function. So, if our hypothesis class is restricted to be characteristic type functions, for which that minimization problem is actually okay, we can just define the epsilon perimeter to be a TV evaluated associated characteristic function. Okay, and I'm using chi's because Italians, and I think some people would use ones. I think some people would use ones. Okay, so this perimeter functional, at least for nice sets, so suppose your A has a nice regular boundary, then actually it's just given as the integral over the sort of row zero distribution, so where you want things to be zero classified, and row one and over two different regions. So the row one, you're going to end Uh, row one, you're going to integrate on the inside of your set A in an epsilon tube of the boundary. So that's what I've drawn here very rigorously, an epsilon tube of the boundary. And similarly, your row zero is going to be integrated over the outside of the boundary. And okay, so maybe the first thing to note here is you wouldn't necessarily expect this to be isotropic, because if you flip the orientation, Because if you flip the orientation, you're going to be integrating a different density on the outside and inside. Yes. So now, okay, so now we've sort of seen that this adversarial training problem is connected to at least a pseudo-geometric quantity like a perimeter. We can sort of just ask some general questions for the binary classification problem, which are like, how does geometry influence the decision? Influence the decision boundary that you find in adversarial training. Does the perimeter give rise to a classical perimeter as sort of this adversarial budget epsilon vanishes? And then, okay, this is nice and all, but that would just be studying this part of the problem. And then there's the question of how can you understand the full training problem if you understand sort of what's happening here for small epsilon. Okay. Okay. Any questions at this point? No. Okay. So I would say on first look, the problem looks quite easy, at least for identifying the limit of this non-local perimeter. So here, the perimeter of A is just, you take some fattened region of the boundary and you integrate row zero over that region. And the fattened region is of width epsilon, and you rescale by it. With epsilon, and you rescale by epsilon. So this looks a lot like a Minkowski content. And similarly on the other side. So the sort of naive guess would just be that the perimeter will converge to row 0 plus row 1. But it's maybe not quite so simple. And if the boundary of the set you're considering is not regular, or perhaps more interestingly, if the densities are not regular, and you want to consider And you want to consider densities that potentially jump or are discontinuous, then this convergence is not going to hold. And so, to actually study this, we use gamma convergence. And I assume at least five people here are familiar with gamma convergence. I'm not sure how often it's used in optimal transport. But the only thing I actually care about in this is sort of gamma convergence tells you that you have convergence of variational problems. It tells you that if you have a minimized It tells you that if you have a minimizer for one energy and it converges through this other one in the tenth of gamma, then the minimizers also converge. Okay, and so what we showed was if you now have this feature space, omega, which is just in the Euclidean setting, and you have densities corresponding to the classifiers 0 and 1, which are Bv, and their density is bounded away from 0, the cumulative sort of. Away from zero, the cumulative sort of density, so the sum of them, which just means that at every point in space, at least you're likely to classify it as zero or one. So this is sort of a reasonable hypothesis, but it's critical for our compactness. Then this epsilon perimeter, gamma converges to a sort of a standard perimeter functional, which I call the zero perimeter. And the zero perimeter is given as the integral over the boundary of A. The boundary of A with respect to a surface density, theta. Now, this beta looks terrible here because there's a minimization over, you can't even tell how many terms because it's hard to see where the commas are. So it's over three terms. And I'll break it down in a sec, but maybe these sort of two things I want to note are just some notation. So here, in A is the inner normal along the boundary of A, and that's popping up in the And that's popping up in the energy. And a rho superscript n is a one-sided limit for a rho at the point x from the direction in. And those are popping up in this surface density. Okay, we'll come back to actually breaking down what the surface density is doing because it's much easier with pictures. And maybe I just want to make some brief comments on the results. So the first thing is the limiting. Oh, sorry. Is the limiting oh, sorry, yes, yeah, and well, and this is actually the interesting for me at least, this is the interesting part of the result. If they're smooth, it's boring, exactly. Yeah, yeah, yeah. So assuming I get to it, we'll get to something where it's still interesting even when things are smooth. But yeah, this is a very important point, which is if things are smooth, you don't see what adversarial training was doing. What adversarial training was doing for you. Whereas, if they're discontinuous, you can still see even in the limit what adversarial training was trying to do. Okay, so I don't even know if I, it's anisotropic, and we'll see this in a sec when I go through the surface energy. And this is why you need to know the normal direction. But okay, only anisotropic because they're not continuous densities. Related results. Related results also hold for the TV functional, which you can just do using sort of Coria type things. And this is my necessary optimal transport shout out here. We can also prove convergence on graphs for the related functionals. And here we use the TLP framework of Garcia Trios and Slepchev. And I apologize for no accents. But yeah, and so there you need a little bit of optimal transport, but for us, it was. Of optimal transport, but for us, it was mainly a tool. And then the proof, which I'm not going to touch at all, actually takes some ideas from image segmentation that Fonseca and Liu used for a Mumford-Schaw type functional, and then some work from some ideas from Schambol, Lizzini, and Lussardi for Minkowski contents, which were defined with respect to convex false. Okay, so now the fun part, which is an So, now the fun part, which is interpreting the surface density. So, here I've drawn sort of this row one is telling you whether or not you're likely to be classified as a one, and row zero is telling you whether or not you're likely to be classified as a zero. So, when you do this minimization problem, what you hope for is you hope for your set A to be aligned with row one, which I've at least drawn perfectly in this picture. So, now, if adversarial training didn't perturb this decision boundary, This decision boundary at all. What will happen is you'll pick up the price of sort of an epsilon neighborhood of the boundary. On the outside, you'll pick up row zero and on the inside, you'll pick up row one. And so the cumulatively, this is a relatively large price you're going to pay. But if you just shift the decision boundary in a little bit, you see that you can immensely decrease this perimeter cost. And so now you can pick up. And so now you can pick up basically row zero from the inside by shifting the decision boundary. And this is sort of the optimal choice in this picture. And this is sort of showing you, at least the surface density is showing you that adversarial training is making these sort of preemptive perturbations to sort of stabilize your classification region. So I don't have a picture for the other region, but the other option is you shift things outside. Things outside. But what you can't do is entirely flip A, because this would basically kill your fitting with the fidelity determined. And so that's why this becomes anisotropic, is because you can't just reorient your surface. Okay. Perfect. How much time do I have now? Okay. Perfect. That sounds great. Perfect. That sounds great. Yeah, I think I'll even be safe. So now, okay, we have a nice sort of understanding for what's happening to this perimeter functional. And it'd be nice to understand the general training problem. And here I've written the adversarial training problem with a rescaling. So I just divided everything by epsilon. Previously, there was an epsilon in front of here. So this has the same minimizer. So one option that you can then sort of use to interpret this energy. Use to interpret this energy is you can just replace this one over epsilon by a fixed parameter lambda. And this is something that some people have explored and called the trades algorithm. And basically, when you have this parameter lambda, which you fix, you're basically choosing to balance between sort of accuracy and robustness. And this is one thing to do. And so, if you then fix this, then you can just do gamma convergence of the total energy. This is just a continuous perturbation. Alternatively, if you want to keep the epsilon, you can impose a source condition. And this basically says that there is a Bayes classifier, which is sufficiently regular. Okay, and I'm not going into gamma convergence, but basically you just need to know that you can construct an appropriate recovery sequence for the Bayes classifier. And a Bayes classifier is just a minimizer, it's a minimizer of the risk minimization problem. So without the perimeter, none of that. Okay, and so if you have Okay, and so if you have a source condition, you can actually show that minimizers of the adversarial training problem will converge to perimeter minimal phase classifiers. This has actually been improved very recently by Morris and Murray in a paper that came out this year. Okay, and then finally, the other option would be to interpret this epsilon as a time step parameter. And this is more in line with what we saw yesterday in Matthias's talk, where one of these parameters was interpreted as a time. One of these parameters was interpreted as a time step. And okay, if you're looking at this, you're like, ah, it looks close enough to minimizing movements. We should probably try to see if it's minimizing movements in some capacity. And it would be a minimizing movement scheme for the perimeter functional. And so it turns out adversarial training has actually been connected to curvature flows before. So initial conjectures sort of didn't know what to do analytically, but they were like, ah, adversarial training seems to be doing well because it's Training seems to be doing well because it's minimizing the length of the decision boundary. And then in 2022, okay, I think that's when it was published, Garcia Trios and Murray actually showed that there was a rigorous connection between curvature flows and adversarial training. In particular, if you started from the base classifier, in other words, the minimizer without the regularization, if you started from the base classifier, you could get to a minimizer of the adversarial. Minimizer of the adversarial training problem if you evolved by a curvature flow that was parameterized by epsilon. And okay, that's cool mathematically. And then sort of the interpretation in terms of the adversarial training problem is, okay, since curvature flows are basically gradient flows that locally minimize perimeters, that adversarial training is really minimizing the Minimizing the decision boundary line. Okay, and so then we came at this problem and we were like, we should just do the almost obvious thing and try to use a minimizing movements type scheme and introduce sort of an iterative adversarial training scheme. And okay, so maybe, yeah, yeah, exactly. So we start from the Bayes classifier also. And now we just consider the adversarial training scheme. Just consider the adversarial training scheme, but instead of comparing to the previous classification, the information you had, you insert your previous classifier, your previous best classifier. There's also something that maybe is blaring there, which is this distance function. So the distance function, from the point of view of application, maybe has two motivations. The first is if you don't include the distance function, the scheme will stagnate and it will no longer update your set. So maybe you don't. Your set. So, maybe you don't want to do this. You can also think that sort of the distance function vanishes near the boundary, and this is where you're least interested in enforcing the fidelity term. And you're more interested in making sure that the decision boundary is regular. On an analytical level, it was essential for us to prove convergence. If you have seen the Lukas-Dersenhecker scheme for mean curvature flow, you'll know why we needed it. It. Okay, and then you can also do a bit of interpretive dancing to sort of at least motivate the scheme a little better than saying, I just want to find a minimizing movement scheme with this. But I'll leave that as it is. Okay, so then what you can do is you can take this time parameterized scheme, or you can take this scheme and then give it a time parameterization, which I do here with these functions a up. Which I do here with these functions a epsilon, which are just a k epsilon in the correct interval. Then, what we showed, now this one is with Tim, we showed that if you have a solution of mean curvature flow on this interval zero to t, and it's a solution of this weighted mean curvature flow. So, here the velocity is given by a weighted mean curvature. Yeah, and this is the surface velocity. Yeah, and this is the surface velocity. Okay, so if you have a solution of this curvature flow, then actually these time-parameterized sets coming from the adversarial training scheme will converge to a solution of your mean curvature flow. So yeah, for us, I would say that this is tightening the connection and showing that with a slight modification of the scheme, you actually have that. And this is sort of an un, I guess it's. This is sort of an unI guess it's still a little conditional. It's a adversarial training is connected to sort of minimizing the length of the decision boundary. Okay, a couple comments on how we did this. We had to introduce a bunch of properties for the sub-differential of this non-local total variation functional and try to deal with regularity properties. If you've ever done total variation regularization, basically, if you minimize with Basically, if you minimize with a fidelity term that has Lipschitz data, your minimizer will also be Lipschitz. And this is somehow entirely non-trivial. It's not like elliptic theory. At least in bounded domains, it's non-trivial. And we can actually do this. We can't show that. Where's Job? What is this? So the sort of a natural thing you would hope is if you just do this silly thing right here, u minus f squared. thing right here u minus f squared plus total variation epsilon of u you would hope that a minimizer of this would be Lipschitz if f was Lipschitz but we don't know how to show that so we can show it's almost Lipschitz up to a small error depending on epsilon basically and this was sufficient to prove convergence I our result's an interior result we don't know how to treat Neumann boundary conditions okay that's a technical point Um, okay, that's a technical point. I, and also, another technical point is our proof is just in the strong setting. I, and this is due basically to this non-locality and the fact that minimizers are just not regular enough to quite get the right representatives for sets you need. And so, it should be connected to sort of generic BV or barrier solutions for mean curvature flow, but we didn't make that gap either. Okay, so leaving you on those very Okay, so leaving you on those very positive notes about what we didn't do, thank you very much. Uh-huh. Yeah. I mean, so this is what we are doing, but sort of, I mean, we're obtaining it as the limit of this minimizing movement scheme. Correct. And it's entirely because when you do. Yeah, okay. So at least what we were running into. At least what we were running into was if you wanted to use, we were so it's a okay, so this is maybe a little misleading the way I've written it. So, are you familiar with like the shambol type scheme? Okay, so we're using the shambol type scheme to actually get existence to select a sort of a unique minimizer. And then there, at least as far as I'm aware, to actually connect it to sort of a weak solution theory for mean curvature flow, he's using. Curvature flow, he's using regularity properties of perimeter minimizers. And yeah, I would have to double check. But we definitely tried to do this. And this was sort of the problem. And there's potentially ways around it, but sometimes they're hard. Like this minimization problem, showing that things are Lipschitz here and bounded domains is surprisingly difficult. And Chambol has a proof in dimensions less than eight where. Dimensions less than eight, where you use Coary formula and use regularity for minimizers of the perimeter functional. And then you know that if you have a minimizer of the perimeter functional in dimension less than eight, you have no singular points. But doing it in higher dimensions, just to say that this is ellipsis, I think this was much more recent, like in last five years, maybe. I guess the time keeps going. So maybe past six. Uh yeah. But I'll have to double check. I'll have to double check. Yeah. Yeah, yeah, yeah. So I didn't emphasize this. I should have. Yes. In that picture you drew with the book where you explained the NS project. Could you just point that again? Yeah, yeah, yeah. This one. Yeah. Okay. Yeah. So the you have the So the if you have the row one and row zero on the top, what if the mark up top? Ah, sorry, this is just so this is telling you the limit from one direction. So this one is the limit from the inner normal, and this is the limit from the outer normal. So this is just sort of like a, yeah, this is just the graph of row. I could even erase this and just this is this red line is the graph of row. So if you're at a point in this region, the likelihood that you're going to be The likelihood that you're going to be classified as one is whatever this small value is. And if you're in this region, the likelihood that you're going to be classified as one is this value. And what's happening in the, yeah, so the reason I write these ins is basically it matters what the one-sided limits are. So these could be more squiggly and less flat. And so let's think. The here basically Here, basically, the surface energy has a couple options it can pick up. It can either shift the boundary in, shift it out, or leave it perfectly aligned and try to decrease energy that way. And if you do the perfectly aligned case, so this non-local perimeter, it picks up something on the outside and the outside corresponds to row zero. So you pick up this synergy. And so then, yeah, the reason it's anisotropic is because you basically Because you basically because you have some sort of L1 convergence, you can't flip the orientation. Because if you flip the orientation here, that means basically you'd put a hole in here, and then you'd have two more boundary points that you'd have to pay the price of. So in your results, do you need any like structure of the discount views of row zero and row one, or just any? No, I think, I mean, so we really use BV because we have to use slicing theory to do it. Yeah, yeah, exactly. So generic. Yeah, yeah, exactly. So, generic discontinuous functions, I don't, I wouldn't know how to do. Because you, I think, and BV is very natural because, in the end, you're going to get a perimeter type functional, and you need whatever your function is to live on surfaces. And BV is nice because it's defined hn minus one almost everywhere, hv minus one almost everywhere. And is it mostly interesting when the basement is both functions? Line up. Yeah, exactly, exactly. So, it's a it's kind of a silly. Exactly. So it's kind of a silly result in some regards. But it's very cute, but it's sort of very specific. Yeah, I think this would be a natural argument, which is you don't necessarily expect, if you're quite confident this should be a one over here, you're probably not also quite confident it should be a zero. So yeah, exactly. You would expect there to be some incoherence between the two. Incoherence between the two phases? Yeah.