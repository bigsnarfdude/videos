Not videotaped correctly. So he's going to repeat the talk, and it's going to be videotaped this time. So that's going to be from 8:15 to 8:45 on Friday conference time, which I remind you is probably not your time if you're outside of that time zone. Time difference. During the talks today, you can ask questions in the chat. And if it's felt by someone who's running the workshop that this is worth interrupting the speaker. That this is worth interrupting the speaker for, we will, or if you really are sure, then you can. I also want to remind the speaker they don't need to look at the chat if they'll find it distracting unless they really want to. And something I'll announce again later around Sam's talk is that after Sam's talk, there will be a photo session. So please stick around for that. With that behind us, let me introduce the next speaker, Darry Grinberg, who will talk about a little some. Actually, let me start the recording first before we start the introduction. Hold on a second. Start the introduction. Hold on a second. So I'm starting the recording. Please ask the host to give your permission to record. So I need that from one of my fellow organizers. Let's try that again. No, I still don't have permission to record. Why doesn't Jessica just do it since she's the host? If you don't mind, Jessica, that'd be fine, or we can make me co-host and I'll do it whatever you prefer. Co-host and I'll do it, whatever you prefer. This meeting is being recorded. Okay. So, our next speaker is Dari Grinberg, who will tell us about Littlewood-Richardson coefficients and birational combinatorics. Thank you. So, this is a bit of a strange talk. First of all, it has way too many slides, and I'm going to rush through a bunch of them because there is a lot of technicalities involved. We just have 25 minutes. Have 25 minutes. Secondly, this is not yet dynamical combinatoric. It's borrowational combinatoric that looks like it should have a dynamical definition, but I'm leaving it as an exercise to actually find it. I would be rather interested in your solutions to that exercise. So the slides are online, the paper is online, it's on the archive, it's submitted. So what am I going to talk about? I'll briefly review the Little Von Richardson coefficients, basically just introduce. Basically, just introducing notations and some of their classical properties. Then I'll state a pretty new property that has just been found a few months ago by Pelletier and Resser and outline a proof. And the whole point here is not the property itself so much as the proof, because the proof is one of the nicest examples I know where rational combinatorics really helps combinatorics out. In the end, it's a bijection that I would. In the end, it's a bijection that I would have never found, let alone prove to work, without first lifting to the birational length and then just taking the particular case in the tropical semifield. And I think you can, if you ever want to use this method, this would work as an introduction to them. So, here is a bunch of references. You can click on all of them if you open up the slides. So, I work with an arbitrary So I work over an arbitrary ring, but it's fine to make it z over or q. Lambda is the ring of symmetric functions, so symmetric bounded degree power series and infinitely many variables. If lambda is a partition, then the Young diagram of lambda, you all know what it is. All I want to say is that I'm drawing it in English notation. So top row is the longest row. And the semi-standard tableau of shape lambda is a way to fill this Young diagram with positive integers, such that the integers are weakly increasing in each row, 2 is less or equals 3, less or equals 3, and strictly in each column. 3 is less than 5. So here are two examples. If you have a partition lambda, the corresponding SURE function S lambda is the function S lambda is the power series that you obtain if you take all semi-standard tableaus of shape lambda and multiply for each of them the addant is the monomial that you get simply by taking all the entries and multiplying the respective x's so for example for s32 you take all possible semi-standard tableaus a b c d e and you're multiplying x a x b x c x d x e i'm be i'm curious I'm curious now. Four messages in the chat? Anything I need to know? Yes, you need to know that you'll have five extra minutes since we started five minutes late. Well, oh, yes. Thank you. So this is an example of a sure function. There is many other ways to define them. Here is another example when the partition has just a single entry, which of course means a single non-zero entry. We don't need to write the zeros down. You know, there is always Write the zeros down. You know, there is always a trail of infinitely many zeros at the end. Then the Young diagram has only a single row, and this row is putting a Young tableau means just filling this row with entries in weakly increasing order. So the Schur function will then be the sum. And this has a different name. It's called HN, the complete homogeneous symmetric function. By the way, do you all see my slide correctly? Are there any problems with the words here? Any problems with the words here? Looks good. Okay, because on my screen it's blocked by Zoom itself, so I'm hoping that Zoom is smart enough to see behind its own shadow. So some very well-known facts are the Shure functions as lambda are symmetric, so they line lambda, and they form a basis of lambda as a k-module. Moreover, this is just one of many definitions of Sure functions. Many definitions of sure functions. Here is another way of defining them: namely, so this here denotes the evaluation of the sure function at n variables. This means that you leave the first n variables intact and you replace all the other variables, the xn plus 1 and so on, by zeros. This is a symmetric polynomial in those n variables, and that polynomial you can obtain it as a fraction of two determinants. The denominator is The denominator is the classical van derman determinant, so that of xi to z minus j. The numerator is the same van derman determinant, except you change the exponents. And this doesn't immediately describe as lambda, only its evaluations at n variables. But if you let n go high, in the limit, you will just recover as lambda. So the infinitely many variables are in a way just handsy to. Variables are in a way just a handsy tool. Any symmetric function is described uniquely by its evaluations at n variables for all n. So, see, there's many texts about symmetric functions. I particularly like Mark Wildman's notes. They are shortened to the point. Now, what are the little Wood-Richardson coefficients? They are the answer to a very natural question. If you multiply Sμ by Sν for two partitions mu and nu, you get a Mu and nu, you get the symmetric functions because the symmetric functions form a ring. But we know that the S lambdas are a basis of the symmetric functions. So this symmetric function can be written as a linear combination of S lambdas. Those coefficients in this linear combination, they're called the little Wood-Richardson coefficients. They're integers, as you can easily see, because this whole argument works over the ring of integers. So as it So, as an example, if I multiply these two partitions, I get a sum of many S's, and the coefficients in front of those S's are exactly the Lord-Richardson coefficients. So this gives a one here, and this gives the two here. There is a a celebrated theorem says that these coefficients are non-negative integers, and there is many combinatorial ways to describe them. There is the so-called Wood Richardson rules. So-called Wood-Richardson rules. Each of them says it is the number of some kind of objects. And the objects can be very different. They can be tableaus with some properties. They can be hives. They can be points in the polytope. So I'm not going to go much into the combinatorics. In a way, what I'm talking about is how to avoid the combinatorics, because the combinatorics here is hard, usually. Here is a bunch of properties of this little Wood-Richardson coefficients. With Richardson coefficients. First of all, if the size of the thing on the top is not the sum of the sizes of the things on the bottom, then the coefficient is zero. This is because the symmetric functions are a graded ring. Next, there is a certain symmetry. If you transpose all partitions, so in terms of Young diagrams, you just flip them across the main diagonal like this. Like this, then the coefficient stays the same. This is a first nice example of how such property can be very hard to prove combinatorially, but fairly easy to do algebraically using the symmetric functions. Next, commutativity. This is obvious from the algebraic viewpoint. Sμ Sν is as nu as mu because the ring is commutative. But if you write this out and if you expand this, you get this equation. If you expand this, you get this equation. There is more. And for this, I need a notation. Par bracket n is going to be the set of all partitions with at most n non-zero entries. And if I have a partition in par n, I will usually write it as an n tuple. So even it even if if it has less than zero entries, I will nevertheless write its first zero its first n entries, so including some of the zeros if necessary. Including some of the zeros if necessary. This is just basically normalizing them in a way, making them standardized. Now, if I have such a partition in par n, and if I have an integer k which is bigger than all its entries, well, greater equal, then I can define a new partition called lambda check k. So, formally speaking, this is what you get if you take lambda, if you reverse the order. If you reverse the order of its entries and if you subtract each of them from k. This is called the k complement of lambda. But a picture says more than a thousand words here. So if you have, for example, if n is 3 and k is 4, and here is your partition, you draw its young diagram. Let's make it blue. And you draw the rectangle that has three rows and four columns. And four columns, and you cause the rest as yellow. And then you throw away the blue part, and you look at the yellow part. This is not a young diagram, but if you turn it upside down by 180 degrees, it becomes one. And this is exactly this complement. This is why it's called complement. It's a complement with respect to a rectangle. And it turns out that once you start complementing partitions, you will get a lot of the same little Wood-Richardson coefficient. A lot of the same Little Wood-Richardson coefficients. This is one of the symmetries. If lambda mu and u all have at most n entries and all their entries are less or equal k, then all the six coefficients are the same. There is ways to prove this. Again, I find it easiest to do algebraically, but there are combinatorial proofs too. There is yet another complementation symmetry. So note that here you don't complement all. Here, you don't complement all of the three partitions, you only complement two of them. Here, you complement all three of them, but you complement them with respect to different rectangles. And sometimes the result will not be partitions. Sorry, sometimes this will not be well defined, then it's just zero. Another symmetry, another example where Lodrichetson coefficients are the same. So, just recently, So, just recently, Emmanuel Brion and Mercedes Rosas have tried to classify symmetries of Little Wood-Richardson coefficients. So, they fix an N, just as we did here, and regard only the partitions with at most n entries. And they have tried to find all possible symmetries of them. They used a computer. This problem has been made uh computerable, so people have worked a lot to really make this decidable, but it's decidable now for every fixed N. Decidable now for every fixed n. And they have tried n from 3 to 7. Now from n, for n from 4 to 7, I just noticed I have a dot dot dot here, which is perhaps not as useful as it looks like, but why not? They only found the complementation symmetries above, plus a trivial symmetry that's basically saying we can add one to each entry of lambda in nu, which is combinatorially obvious because one of the young diagrams just gets shifted. One of the young diagrams just gets shifted. For n equals 3, however, they found an extra symmetry. And seriously, I have no idea what this really means. I would really love to hear a proof of this. This is not just computation with polytopes and case distinction. So you can probably regard this as a question. So somehow the entries get mixed around wildly, and sometimes the things. Around wildly, and sometimes the things will not be partitions, even. In which case, you should read the C as zero. So, I don't know how to prove this properly. They do it by computer. So, now I'm going to talk about some of the identities that I've been studying. Here is again, here is a bit of a motivation first. This is a formula found by Cochira and Zuber in a physics paper. So, if you have So, if you have two partitions mu and nu with at most n entries and with all entries less or equal to k, then this sum equals this sum. And this has been proved combinatorially using what's called Seigen-Stanley internal RS insertion. Now, here is the way to interpret it in terms of Sure polynomials. Again, the Sure polynomials are just the Shur functions where I value. Functions where I evaluate them at finitely many variables. So the Sure functions form a basis of lambda, whereas the Sure polynomials form a basis of the symmetric polynomials in n variables. Now, the theorem above says the following. If I multiply S mu by S nu, or I multiply S complement of mu by S nu, and expand the result in the sure basis, but only in the first. But only in the first n variables, I throw all the other variables away. Then the results will have the same sum of coefficients. Strange, right? Why should this be the case? Somehow, I mean, it's kind of clear if you complement everything, but why does this happen if you only complement mu, not new? Now, so Pelletier and Resser have asked themselves: could it be that they? themselves, could it be that they actually have the same coefficients, not just the same sum of coefficients, but the same multi-set of coefficients? And if you experiment with Sage, for example, you will eventually find a counterexample like this. It's not true for n equals 5 at least. So here is a question I don't know the answer to. Is it true for n equals 4? Well, it is true for n equals 3. It will follow from what we do below. But Pelletier and Rissay haven't given up with the counterexample. They have noticed that sometimes it is true. Namely, it is true when μ is what they call a new rectangular partition. A partition that begins with A plus B and then has n minus 2 copies of A for some A and B. Notice that its complement is also a new rectangular partition. It's A plus B and then N minus two copies of B. At least when K is A plus B. It doesn't matter what K is really. B. It doesn't matter what k is really. Those things can easily be translated onto each other. So here is our conjecture restated. n is a non-negative integer. Nu is a partition with at most n entries. A and b are non-negative integers. Alpha and beta are these two new rectangular partitions. They're called mu and mu check k here, but I will call them alpha and beta. Alpha because it has many a's and beta because it has many. It has many A's and better because it has many B's. Then this multiset equals this multiset. In other words, they judge that there is a bijection from partitions with n entries to partitions with n entries that satisfies this equation. So it is a partial symmetry of the Wood-Richardson coefficients. It's not a symmetry between any two of them, but it's a symmetry for Between any two of them, but it's a symmetry for that holds for many of them. It's still an infinite family. This is just the same conjecture repeated. So I have proved that this is true and actually constructed this bijection more or less. More or less, there is a technicality here. The bijection sometimes takes you out of the set of partitions, in which case you should read this coefficient as zero, but you can you can basically push it back in into partitions if you really want to. In and to partitions, if you really want to. So I'm going to be very terse here because there is a lot of technical things here that you can read up in the paper, or you can look at the slides. So what are the main ideas? First of all, I realize that alpha with its n minus two copies of A, it's probably better to view it like this. It is B, n minus two copies of 0, n minus A, plus A. Minus a plus a where plus a means you add a to each entry and similarly you can do the same for beta so this suggests that maybe we should allow partitions with negative entries because zeros are a lot nicer than a's right i'm going i'm gonna call them snakes stembridge used to call them staircases but staircases mean something else these days so formally a snake is a weakly decreasing Formally, a snake is a weakly decreasing n-tuple of integers. A partition with at most n entries is a snake, and a snake is an n-tuple, but these are proper inclusions. So, snakes can be used to index rational representations of GLN. See Stembridge's famous paper about them. So, some standard notations: lambda i will be the i entry of lambda, lambda plus a means add a to each entry of lambda, lambda minus a similarly. A similarly and we have defined a sure polynomial for every partition with at most n entries. We are just going to call it s bar lambda. The bar is just so that we don't forget it's a sure polynomial, not a sure function. We only have these n variables. So what happens when you add A to all entries of lambda? The sure polynomial simply gets multiplied by this monomial. Knowing this formula, you get an You get an idea how to extend those Schur polynomials from partitions to snakes. Because a snake is just a partition with all entries lowered by some number a. So if you want to define the sure polynomial for the snake, you add a, so you get a partition. You take that sure polynomial and then you divide out by this monomial, by the monomial that you would otherwise have here. Now, this is not a polynomial anymore. Now, this is not a polynomial anymore. This is a Laurent polynomial, but it's just as nice. It's symmetric. And yes, the formula using the van der Monde determinant still applies to the snakes. So you could just as well define them this way. Now, so the point of this here is that this S-bar for B0 and minus 2 minus A can easily be described in terms of the complete homogeneous symmetric functions. Symmetric functions. Except you have to use both the plus versions, which are the H's in the axis, and the minus versions, which are the H's in the inverses of the axis. Note that this would not work for finitely many variables, but we have infinitely many variables here. And therefore, you get S-bar alpha and S-bar beta described pretty explicitly. This is useful because we are in. This is useful because we are interested in multiplying by these things. Now, how do we multiply by these H's? Here, the Perry rule comes to the rescue. Recall, to multiply by a sure function, you need the Lilwood-Richardson rule. I mean, it exists, but working with it is pretty nasty. Whereas, working with the Piri rule is pretty nice. Here is what happens when you multiply a Schur polynomial by an H. You get a sum of. You get a sum of Schur polynomials over all snakes that are bigger by k than lambda and that satisfies these interlacing inequalities, which are saying each mu1 greater equal lambda one greater equal mu2 and so on. And I'm going to introduce a notation for these inequalities. I'm just going to call this mu harpoon lambda. This is saying this chain of inequalities. This chain of inequalities. By the way, you probably know this under the name of μ over lambda is a horizontal case strip. I don't feel like working with strips here, so I'm just giving it this name. There is a very similar property, there is a very similar formula for multiplying with h minus k, so with the h of the x inverses. So here you would add a horizontal strip, here you would remove it. Strip. Here you would remove it. So instead of summing over mu's that are bigger than lambda in this sense, you sum over mu's that are smaller than lambda. And as a corollary, you get a combinatorial formula for what happens if you multiply s bar mu by these two h's. And therefore, you get a combinatorial formula for the Little Wood-Richardson numbers that you're interested in. It's a difference of two sizes of combinatorial sets. Two sizes of combinatorial sets. It's not very intuitive, but it's these are manageable things. Okay, so I'm going to skip over a bunch of things. So I need a bijection. Remember that maps two little Wood-Richardson numbers to each other. I'm making a substitution, it becomes a bijection that satisfies this equation. I make some assumption here. Assumption here. So here is what comes out in the end. So mu is fixed, it's a snake. I want a bijection F that sets a snake gamma to a snake eta with the following properties, that if mu harpoon nu and absolute value of mu minus, well, basically, if you have this bunch of conditions, then after the bijection, you will get this bunch of conditions and vice versa. Now, let me forget about these equations and only look at these conditions. These conditions, you can rewrite them as a bunch of inequalities. And these inequalities are saying that nu i lies between a certain maximum and a certain minimum, and nu n lies just between this minimum and minus infinity. And similarly, you get conditions on the zetas. Now, you want a bijection that has this property that elements in this interval go to elements in this interval. To make such a bijection work, it would be great if the side intervals would have the same size. So, one would just be a parallel translation of the other, and you could just parallel translate as a bijection so. So now some people will probably be recognizing these things because these are very similar to toggles in on to toggles in PL row motion. You want this to hold and also this condition because of the sizes. So here is an example. I think this is the main takeaway. Here is a system of equations that we want our bijection to satisfy when it sends Bijection to satisfy. When it sends gamma to eta, this equation should hold. I'm going to simplify them a bit. I'm replacing maxima by minima. Now this is a set of equations that involves plus, minus, and minimum. And the trick I'm going to use to solve it is detropicalization. So detropicalization means that you take your system of equations that uses plus That uses plus and min, and you view it as a system of polynomial equations over the so-called tropical semi-ring, z-trop. This is a semi-ring in which addition is minimum and multiplication is plus. So it's basically a ring without subtraction. It's a strange ring. It takes some getting used to to actually work in it. But once you've gotten used to it, you start thinking of minimum as addition. Of minimum as addition and sum as multiplication. And if you don't have any other operations around, I mean, okay, minus is reciprocal. But if you don't have any other equations around, you think immediately that the system should generalize to the summary. And so once you have stated the system in terms of the summering, you can try to solve it over a more familiar summering, like Q. Q and then you check if your solution somehow still happens to work over the tropical semaring, maybe because it's so general that it works over any semi ring. This is called detropicalization. So here is my system again. Here is what happens to it when I detropicalize. This is a system of algebraic equations. I'm renaming everything and I'm Everything and I'm giving it to a computer because computers are good at solving these polynomial systems. They can probably not solve the system like this, but they can definitely solve a system like this. And I get two solutions, in general at least. Now, over a semarine, you don't have minuses. So the first solution, you can throw it away. This minus is not actually realizable. But the second solution looks But the second solution looks nice because it has no minuses, it has cyclic symmetry, which you wouldn't expect, but which is always nice. And it has a pattern that you can easily generalize. So, okay, I think I barely have any. How much time do I have left? You're out of time, actually. Okay, so basically, this is what you get if you look at if you spot the pattern and generalize it. And this ends up being the bijection you need. Okay, sorry for going over time. Thanks to everyone, and thanks for the invitation. Well, let's thank Dari for his talk. Questions? Yeah, Dari. That was a great talk. Thanks. So, those more classical symmetries that I'm more familiar with, they reflect geometric things. And so, most of them have k-theoretic extensions. Do you know about these weirder symmetries? No. I mean, it would be a good beginning to see what this alpha and beta really mean geometrically. Mean geometrically. These are some shubert cells, probably some pretty nice ones. Do you recognize them? I mean, there are some shubert cells. Yeah, but which ones? So you don't know any data on whether this, like this weird sum formula, you don't have to hold for Got Index? Good question. No. I don't know. I don't know. I have a question. Did someone else have a question before me? I have a question. That's for the lead book reset coefficient. We have a computer model to compute the lead book reset coefficient like the set of skew double. Like the set of own skill tableau of some skill shape, and we contain something and satisfies the Jamaluchi condition. And my question is that if you can find the biology between two Kamiaturo says based on Joe Akiman here? No, I mean, or I haven't tried to be honest, because what comes out of my geotropicalization formulas. Tropicalization formulas is a bijection that is not. I mean, here is the definition back in the on the back in the non-tropic, back in the tropical semmering. Here is what the bijection looks like. And this is not very understandable combinatorily. So I forgot to say, I really hope that there is a toggle description of this, because it very much looks like raw motion in terms of pass, and there should be a way to describe it in terms of toggles. But I don't see. But I don't see how. I also have a question. In the letter, you mentioned about the semi-ring with plus maximum or minimum, and multiplication is a plus. And I have watched that. If the proof is some idea from tropical geometry, no, the proof is just computation. Yes, lots of inductions and computations. So, in particular, the proof works over any semi-field. You don't have to move around between semifields. It's just completely formal. And how do you get the idea of the proof? I mean, a lot of these equations. A lot of these equations are really just found by solving the system and checking for obvious properties. And then the proof was a matter of finding the right induction hypothesis. I don't really have an intuition behind what's going on there. I think we should stop there because we are five minutes behind schedule. So let's thank Dari again. Thank you.