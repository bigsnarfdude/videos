To start us off with, the main goal where I want to end up is a singularity theorems for some world volume cover jump bounds. But for this, we need some setup. And since this is a comparison geometry workshop, I will go in a little bit more detail on these comparison results. Contrary to when I talk to more physics audiences, I focus more on the more physics audiences and focus more on the singularity theorem parts obviously so i'm very happy to get to talk about the path in a bit more detail um yeah we will need some setup we will figure out our two-sided error comparison and well actually one side is standard it's just the other direction that is new and figure out how to go from volume integral bounds to integral bounds along geodesics all of this is in the Lorentzian setting um then talk about Think then talk about singularity zero and a bit of an outlook. So this to start us off with the wrong direction, start us off with the introduction. Why would anyone like the singularity theorems? Well, they are from a popular science perspective very beautiful theorems from Lorentzian geometry that really kind of have wide physical influence. Kind of have wide physical implications for the existence of things like black holes or big banks or big crunches. I highlighted the big crunch because the setup that I'm doing mathematically is the one that corresponds to this big crunch physically. Of course, as with most popular science, this is an oversimplification, which in this audience I don't have to stress that much, but what we really get is geodesic incompleteness. Of course, here everybody knows what geodesic incompleteness means. Completeness means. And perhaps for this audience, the better introduction is the top differential geometry one telling you that there are Lorentzian analogues of well-known Riemannian results like our Bonnet-Meyers theorem. And probably everybody here at least likes Bonnet-Meyers a decent amount, else we wouldn't have ended up in this field. And also their importance physically has been recognized by the physics. Has been recognized by the Physics Nobel Prize for Roger Penrose. And this also shows you these theorems go back to the 1960s. So, of course, since then, a lot of things have happened. And also, a lot of things have happened in Riemannia in comparison since Bonnie Meyers. And we have heard and will continue to hear a lot more about this. And also, clearly, there's some very nice research ongoing by all of you and collaborators. So, let's talk about. Let's talk about the Lorentzian setup, and also Nicola gave a very nice outlook on some of the current issues and research directions in global reaction geometry. Anyways, we have also come a long way since the first singularity theorems. I want to give you a little bit of what has been done. We have splitting theorems. Again, remember Nicola's talk. We have triangle comparison. We have triangle comparison results again. This also came up already. And then this did not come up so much and will also not really be the focus of my talk. Of course, there's a lot of these results in Lorentzian geometry are very close to the Riemannian counterparts, and that's beautiful because we know how to work with them. But then there are also some more uniquely Lorentzian phenomena that are very interesting to me as well. Interesting to me as well, and there was a lot of people have worked with. Of course, conformal geometry is also a thing in Riemannian geometry, but in Lorentzian geometry, of course, you have this light cone structure that is conformally invariant, which gives you more control. And also, I should mention I'm listing some names. I'm not listing all of the names by far because else I would have like from the 1960s to now a hundred slides just filled with names. Hundred slides just filled with names or something like that. And as I said, research is ongoing. There's a big push towards this Lorentzian Alexandrov and curve virtual dimension theory spaces with a ton of people involved. And this seems to be ever-growing and really very successful on handling the time-like case. There's also in parallel something that I've been somewhat more involved with, a push. More involved with a push towards looking at low regularity metrics on smooth space-times. Again, we have also seen these efforts in Riemannian geometry that they can persist in conjunction with this more synthetic approaches. And in the Lorentzian setting, a nice thing is also that perhaps these low-regularity metric approaches stick a bit closer to what physicists would care about, but of course, mathematical. Of course, I'm mathematically. I'm also a big fan of thisory and black people. There's a lot of different approaches out there now, and it's not clear that anyone is better than the other, and it's just fun to see what's all out there. Yeah, and also people are still working on improvements upon classical results in the smooth setting by, for example, relaxing curvature conditions and Curvature conditions, and that is what I'm focusing on today. Yeah, then let me give you the Riemannian context for what I will tell you in Lorentzian geometry. So there is a not too old, but also not too recent result by Spraus. Yeah, it always surprises me that 2000 is by now a long time ago. But that's But that's how it is. Okay, so if we have a complete Riemannian manifold with a lower bound on the Ritchie curvature, notably, this is a negative lower bound, so this is not what you would usually see in Mayas' theorem. Then for any radius and any small delta, we can find some epsilon such that if this supremum over the average of the Over the average of the negative parts of Lichy compared to n minus one. Yeah, the supremum of the average of this n minus one compared with the negative part of Ritchie. Of that, the positive part is less than epsilon. It's a mouthful to read it off, but essentially what it tells you is that if Ritchie is close to being Close to being non-negative, and ah, sorry, Ritchie minus here is not the negative part of Richie. That's why I was confused. It's the smallest eigenvalue of Richie. Later on, it will be the negative part of Richie, but of course, this with the negative part of Richie doesn't matter. Yeah, so the smallest eigenvalue of Grichi should be close to n minus 1 in an integral sense. Then you can still get that mg is compact with this. That mg is compact with this diameter bound by pi plus delta. So, depending on how close you want to be to pi, you need to make this closer and closer to this virtual n minus one. This should be a minus. So, this is the positive part. So, we're only looking at the part where. Looking at the part where the smallest eigenvalue of Richie is less than wait, I think maybe I've got a copy and paste it. Let me go to the blackboard. So we are only interested in things where we have n minus one. one minus actually minus is greater equal to zero. So this would be that n minus one is greater equal which minus yes. So the we have some subset where this is greater than equal zero and then we are looking at how big Are looking at how big this difference is. So essentially, we want that the smallest eigenvalue of Gritchy is smaller than n minus one only on some very small subset and only not too much smaller. So then I think this works out exactly with the size. Okay, and the proof of this theorem by Splouse is based on going from these volume integrals to integrals along geodesics, and this Geodesics and this uses something colloquially known as the segment inequality. I'm not sure, I don't think this was called that in the original Chiger Kolding work, but yeah, and this is also a mouthful to digest, but essentially what it tells you is so first I should put on the blackboard what this gamma xyzet is. So gamma. So um gamma x y would be the set of all minimizing geodesics x to y, the unit speed hence there are too many and of course for most x and y this will be exactly one except when we're dealing with cut points but they have When we're dealing with cut points, but they have measure zero. So essentially, this is just we take all the possible geodesics, so we have some A1, some A2, and then we take all possible geodesics going from any point in A2 to any point in A1 and vice versa, because we are in yeah, or we are integrating over all sort of the possible connections between points in A2 and A1. Between points in A2 and A1 by the geodesics. And then we integrate along each of these geodesics our function evaluated along this geodesic. So we integrate along a bunch of geodesics with all kinds of initial and end points. And then we can bound this again under a litching curvature bound. Okay, again we have a Ritchie curvature bound globally, but again this is a negative bound and then we can bound this by an integral over the function itself on the entire so all of this is supposed to take place in some large ball and then instead of integrating over all the geodesics we could just integrate over the ball and also the areas pop up but the ball Up or the volumes of A1 and A2 pop up there, and we have a constant that depends on the radius on the dimension. And if we have a rich recoverage bond with K, the K would also go into this constant. So this relies on. So first I should mention two things that I want to mention is the proof of this Giga folding uses a two-sided Bischoff-Gromov estimate for the area. Of Gromov estimate for the area element. Well, really, we go only one way, so it's a fun argument. I don't remember the details, and also I still probably won't have time. So, but it somehow it splits these geodesics in half, and for the upper half, it uses estimates starting at P but going backwards, and for the lower half, it uses estimates starting at q. It uses estimates starting at q, but also again going backwards. And of course, this is a supersymmetric situation, which makes everything work out very nicely. Yeah. That's the main thing I wanted to mention. Then the other thing to tie us also again back to Nicola's talk: this segment inequality is to the very end where he mentioned some ongoing things we are looking into, which may Things we are looking into, which may or may not, which hopefully will work out. This is one of the things that were used for the Riemannian almost splitting zero. So probably if everything else works, at some point we might need a Lorett symbol. Okay, then what do we want? Our goal is to apply a similar strategy as in this theorem of Sprause to Hawking singularities. Of Spraus to Hawking singularity theorem. So the variant of Hawking singularity theorem we will be looking at is the following. So we have a smooth space-time and we can show that this smooth space-time is future-time-like geodesically incomplete. If we have non-negative Ritchie curvature for all time-like vectors, we have a smooth space-like Cauchy hypersurface. I will say a bit more about that in a second, and the mean curvature vector. And the mean curvature vector of sigma is pass-pointing time-like. Or, in other words, the scalar mean curvature when computed with the future unit normal is strictly less than zero. Yeah, there's a bit of a fun sign, but the sign is just works so that the mean curvature vector is exactly the scalar mean curvature times the filter pointing unit normal. That's how the Yes, I should also write this down. Tau is, I think Nicola also called it D, or L, I think, was, yes, L was essentially L from Nicola's talk. So it's tau sigma supremum over the integral state of G. Of G gamma dot. Also, I should mention I'm used to the opposite sign convention of Nicola. So we have negative for time-like vectors and positive for space-like vectors. Suprema over this integral, E to B, where gamma goes from sigma to P and is future directly time like So, this is essentially the Lorentzian distance from any p in the yeah, at some point there should also power a sigma. Take a second black button to draw a sigma sigma. Then we have all the points which are in the future of sigma. Future of sigma, and this is a bad drawing, and we'll see why in a sec. So, NAP, and then we look at all the future-directed geodesics that go from sigma to p and we take the separate flags. And again, as in the Riemannian case, one can show that any curve realizing this supremo must be a geodesic and start orthogonally sticker. So, what we get really. So, what we get really is a bound on this distance to sigma for anything that's in the future. So, really, this Hawking singularity theorem is an inherently asymmetric situation. As you can also see from the mean coverager bound, if we go the other way, we will exactly have the wrong cover bound. And so, really, Hawking singularity theorem. Ah, thank you. Really, Hawking singularity theorem can. really Hawking singularity theorem kind of more corresponds to a Myers theorem with boundary situation than to the classical Myers theorem. Of course also if you have a Riemannian manifold with boundary you can do this distance to the boundary estimates and you see also the curvature properties that we say. Okay so this is what we want to do. I promised you to tell you what it means to be a Cauchy hypersurface. This is related to global hyperbolicity which also played a role in Cauchy. Which also played a role in Nicola's talk as kind of cheekily said, an incomplete replacement for completeness. So incomplete in the sense that it does not, so first off in the sense that space-times do not have to be geodesically complete just because they're globally hyperbolic. These are two completely unrelated notions. And also global hyperbolicity is very nice, but it still does not give you quite as much as because in the Riemannians, I think it does. As topic because in the Romanians, I think it doesn't. However, for the existence of this distance-realizing curves, it does exactly what you need to. And on the other hand, you get some very nice things that you do not necessarily have in Ibnania in case of completeness. For example, you get a topological splitting because you can just use the flow of some time-light vector field split. You can even get a smooth splitting. Even get a smooth splitting because you can find some. Well, a priori a Cauchy hypersurface need not be smooth, but you can find some smooth hypersurface that's when you work with the original one, and then you can split the metric smoothly. This is actually fairly recent, so and it will be even more fun because there will be even more recent results that deal with this actually very old Lorentzian condition. The third one is it gives you. The third one is it gives you compactness of these causal diamonds and non-existence of closed causal curves. That was Nicola's definition. This is also what the footnote will say once it shows up. It also guarantees the existence of maximizing geodesics and it also guarantees existence of length maximizing past direct time-like geodesics from P to sigma for any time, which is exactly the situation we are observing. The situation you observe it, and this third condition is actually equivalent to the usual one. And this is now actually still recent. In 2019, it was shown that funnily enough, for n greater than equals 3 and n non-compact, it is even sufficient to just assume the compactness of these positive ionons and you get causality just as a side of the mark. Side of the mark. Yeah, yeah, yeah, yeah, yeah. So other than that, you can't say anything, but you do not get any constants. The orphanal splitting, which is still very nice. Yeah, so this is our global hyperbolicity. So let's talk a little bit. Let's talk a little bit more about the setting, the notation, and the exponential coordinates that we are going to use. So, which areas do we want to compare now in our Lorentzian setup? Well, clearly, let's actually put this on the slides. We can start in sigma, use the future exponential map to get coordinates at least near sigma. This will break down eventually, but for now, let's see what we get. See what we get. Then we can split the metric near sigma as this minus dt squared plus some Riemannian metric one sigma t. We can split our volume element in the area element on sigma and the dt and then we have so really what we have if we want to think of it this way this area this ATX. This aerial, this ATX vector times the d sigma is the aerial event of each sigma t. Yeah, and we can also define a mean curvature on each slice, which we all know very well, exactly as in the Riemannians. I think this is just the derivative of the area element divided by the area. Yeah, I think that's all. We have a future unit normal vector field at each point. Field at each point, calling this U. This breaks down once we hit cut points, just as a Romanian setting. And so, really, what we will be focusing on, and this is a bit unfortunate, and I'm somewhat still unhappy with this only really working as long as we stick to things where we don't hit cut points. But, well, as long as it still gives us something, why not? So, little. Why not? So, really, what we are focusing on, and this is a bit of a weird notation, is we want a subset of sigma which are all plus eta t. So we want to have some sigma capital T and then we have some sigma t plus eta and really this set should be everything where these coordinates work perfectly. coordinates run perfectly fine until t plus eta. Possibly we have a cut point at t plus eta, but not for that. Something like that for the foliation. Yeah, I think that's mainly it. What we should think about, so is eta being a lot less than t, but it's not really a requirement. I can't really call it that well. I can't really call it that well. But we need some, we need a little bit extra of not having contributed points that just capability. And the ether will also empower. Yeah, we'll check the time. Started at 20. Okay. That's good. Okay. And then now what the comparison estimates, we have the same setup, so The same setup, so with our sigma smooth space like Cushy hypersurface, all riching curvature bound, and also, I guess I forgot to put this down again, h less equal, less equal than beta less than 0. And T equals 0, so for the original sigma slice, yeah, it was necessarily And then we get the following for any such t and eta, we can have some positive constants such that we can estimate the mean curvature on each of these level sets from below and from above by constants. And actually, for the steep and violent. C and why are they called C box? Because this is also the Dalamberschi of the distance function, as we have seen. Also, the C box plus is actually missing B dump that is the standard thing. So n cut bar equal n beta equal to minus right is n minus one cap bar hyperbolic content transfer I should like this that essentially and And sorry, let's not forget the minors because the minus is kind of important. So, how do we get this? This is actually not very difficult, and it's really just in the assumption. So, as I said, this estimate is classical, and you also have a classical estimate. This, if I remember correctly, is hyperbolic tangent and Hyperbolic tangent, and this will blow up in finite time if beta is too negative. Sorry, if beta is too close to zero. Other way around. If beta is too negative, the more negative beta is, the more initial contraction we have. So in particular, we can start our standard forwards comparison argument at sigma t. Sigma t of So we get if the forward mean curvature at T is less equal than this cotangent or less equal than minus So that minus for pen trend. Well, I'm I'm forgetting sometimes. It should always be this n minus whatever. Yes, uh proton transfer kappa the beta. So if at t I am contracting too much, then I will run into problems before t plus eta. So I cannot be contracting too much at t. So we get that So we get that then cut point eta. So of course if we assume no cut points before eta we get gala specific quality. Yeah so this is really both of these are not that difficult but one needs to sort of think a little bit about what the current set of Little bit about what the correct setup for this is the problem. And from this, we can get in sort of the standard fashion the area comparison result because we know the derivative from that we know this mean coverage estimate from that we can get that the area is non-increased area. So this is again relatively relatively standard. Relatively standard. I mean, for the lower bound for the CA minus, what we are doing is we again start at sigma t. Now we have for sigma t, if we go to the past directed mean curvature, we have that the past directed mean curvature will then be minus the future directed mean curvature. So this will be less equal than a hyperbolic contention. Hyperbolic contention squared kappa ether roughly, and then we can run our area comparison in the past direction. We just use this as our initial mean curvature condition. And all of this always uses this point-wise riching curvature bound that gives you some control on things not expanding too fast globally. Yeah. Yeah, yeah, yeah, yeah, yeah, yeah. Yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah. Sorry, what quick page? Yeah, yeah, yeah, that's exactly what we are we are using. Yeah, yeah. Yeah, this is really a like facial glory engagement or whatever inflation you like. Call it. That's behind that. Yes, that's exactly what's in there. That's exactly what's in done. Okay. So then we have this. And the nice thing is: so, the important bit is, of course, this is something positive. I mean, I've put it here just for completeness, if someone wants to know it. It's not as ugly as it could be, but yeah, it's some hyperbolic sign terms. As always, it's the hyperbolic functions that show up. Okay, so in particular, this is a uniform. So, in particular, this is uniformly greater than zero, and that allows us to do a similar thing as in this segment inequality. Because also there it uses that you bump the area element from below because you go backwards. It's just here you can't go backwards to the initial thing because then you blow up, because you start at the point. Here in this hypersurface case, it's in some sense simpler because we can really go back all the way Really go back all the way to the initial hypersurface because we don't have a blow-up. Yeah. Okay, so we get our Lorentzian segment type inequality. I should also say this asymmetric comes at the price because also all Lorentzian segment inequalities are symmetric because we really only look at geodesics starting at sigma. At sigma, and we go backwards. So, again, we compare an integral over some function over a volume of this entire cylinder with the, well, we have already estimated with the infimon, but you could also still integrate over all the geodesics. Then you could replace, instead of dividing by one over, this should be a signal. By one over this should be a sigma of the area of B. So this is a one over the area of B. If you ignore this on the right-hand side and instead of the integral, then you would here get an integral over b. This perhaps segment inequality thing. Yeah, and you exactly get this hyperbolic sign term involving any kind of button at the right side. Yeah, there's not that much to say for this. The proof is a bond liner using writing the volume integral in this exponential coordinates and pulling out the area element, which can now be estimated by this constant. That's exactly what you want. Please interrupt me again if you are pressing it. So, what are the consequences of this? Well, the consequences of this are, again, unfortunately, not quite as strong as I would have hoped for, because we don't really get a theorem like Strauss did, because the problem is exactly somehow this asymmetric thing. What we let me tell you first what we do get, and then I will try it. First, what we do get, and then I will try to tell you why we don't get anything better. So, we have the setup, we have our global Ritchie-bound curvature assumption for some potentially variant negative kappa, and we have the mean curvature bounded by beta for some negative beta with beta not too negative. Again, this is just ensures that we don't anyways get singularity theorems already by the usual ones. Theorems already, but the usual ones. And then, if we have the bound on the average of the negative part of the Ritchie curvature, if we insert this time-like vector field by this appropriate constant and this other well-known term that usually appears, then our set B cannot have been in the regular set, and I should. Regular set, and I should briefly tell you what if we have something here. Okay, this picture is getting overloaded. But let's say my sigma continues a while, and let's say we have a set B here, which is perhaps not in the like plus eta. Then, how is this cylinder defined? Well, this cylinder is just defined. We are going. We are going until we either cannot continue the geodesic because it's incomplete, or we go until time t, no matter whether we hit the cut point earlier or not. So potentially in this, yeah, I I hope the picture makes it somewhat clear what this omega is. We either go to the where we can't continue or we go up and to capital T. Or we go up down to capital T. Of course, since the inequality is that this average should be less than, we always only overestimate by counting the things after the cut points twice. So we could equivalently just look for the cut points. And perhaps nicer way to read this is that if we have any subset that is in this plus e dot t, so if we have any subset where geodesics do not angle. Subset where geodesics do not encounter controversial points until some rather large t plus eta time, then the area of this subset must be relatively small compared to the integral of the vigilant traverture bond. And this is somewhat similar to the singularity theorems, but not quite as strong, because for the singularity theorems, really, we would want to have that eventually for large enough t and beta, this has measure zero. But we never Zero, but we never actually get to measure zero unless this integral over the negative part of which is zero. But then, if the integral is zero, then the function must be zero everywhere anyways. So then that does not give us anything at all. So yeah, but it does somehow allow us to quantify how much error we are allowed to make in the RICHI coverage in an integral sense and how. An integral sense, and how much error we get from having zero measure to having some small non-zero measure. That's kind of the moral of this story. But again, it's not quite the singularity zero. In particular, it also does not imply geodesic incompleteness. We could have perfectly fine geodesically complete space-times where just the area of the subsets that live for a long time. The subsets that live for a long time shrink very fast, for example, as you go further in time. And somehow the problem kind of is with this asymmetry because if we want to, yeah, it's a bit difficult to see unless they don't have a 100% clear picture about exactly. Clear picture on what exactly goes wrong, but the problem is somehow we can we can never go back. Because either we really go to all the points that have distance t plus eta, that is then relatively nice in the sense that it's, I think one can show that at least if the original sigma was compact, then these must also be totally hypersurfaces, for example, but they will not be smooth and we have no control on the mean curvature. I mean you can. No control on the mean curvature. I mean, you can also already see somehow what happens, even if I just draw a Riemannian picture. You could start with something like very nice, and then you take all the points that have a certain distance, but then eventually all the points that have a certain distance to this nice set will have some weird curvature, some weird caustic. And then, if you want to go backwards. And then, if I want to go backwards from this set with my unit speed geodesics, then what do I do at this point? Well, I need a lot of geodesics, starting at a single point, to get the entire area back. And it's a bit hard to control. I mean, in the Riemannian case, and this also goes to a problem that Nicola mentioned, in the Riemannian case, the unit sphere is compact, so at least you know you have compact Li many in the Lorentzian case. I mean, we also know it must be somehow. I mean we also know it must be somehow compact because we still have global hyperbolicity. So the J plus intersected sigma, so we know that this set here must be compact. So then also the initial data must be, but we have no control over how large of a compact set it is, essentially. So this is somehow the issue why the argument of Spraus doesn't go through fully. Because in the argument of Spraus, you would have to go back. You would have to go back somehow from this one over sigma b to one over the volume of the space-time, and we can't estimate this in this direction properly. Yeah, that's that. So, this was our first consequence. And I will tell you, and once I get to the outlook, I will tell you that we can still do something with this. We can still do something with this, so it's not completely useless. Just in and of itself, it's not as nice as hope. The other consequence is an actual singularity theorem. It is much more complicatedly formulated, so I'll present it piecewise. The thing is, this goes back, so I should also have mentioned this at the beginning. This is all joint work with Eleni, Alexandra Kotou, Aga Mohanian, and Ben. And Eleni Contrutu really comes from a sort of physics perspective, and she kind of gave us some direction on what bounds physicists would expect to get for this integral riches. And apparently, it is something like this. Or ideally, it would be again I would also say this in the outlook. Ideally, we would not just have a first derivative of f here on the right-hand side. Derivative of Fp on the right-hand side, but we would also allow a second derivative of Fp on the right-hand side. Again, if so, the theory here is that the kappa is again negative, potentially very large, and also this point was bound physically we still don't quite like, but it is what it is for now. The Q1 and Q2 should be rather close to zero. Close to zero because this doesn't really work, but not exactly zero, because then, of course, you again get the limits of negative. Also, if q2 were equals to zero, then this would again give you a pointwise bound because yes, I should also have said somewhere ah no, I have the L2 norm on this side, so it's okay. But else it would be for things with um L2 norm equals. Um L2 equals one. So somehow the problem is if we want to localize this to get a pointwise bound, then this term here will blow up. Because if you think of an spare antigen of a function that goes to like a delta distribution or something like that, then maybe this term behaves nicely and can remain bounded, but then this derivative term goes up. So there's some sort of balancing immediate. Yeah. That was the That was the time-like unit normal backlog here. Yes, and M plus, I should have said, is the future of sigma without the cut locus. We need our F to stay away from the cut locus, away from the cut locus. I have a for each of this. For each of this, I should put it a picture I have a few. So, really, it's a time deliverative. And then the third one, and this is the worst part of it. So, the mean coverage of sigma now has to satisfy some bound. Usually, this entire Some bound. Usually, this in terms of the kappa and the time when we expect our distance to end. So, this is just the standard bound that immediately gives you, that you immediately get just from this point-wise litching curvature bound. And this is sort of the new bound, which for small q1 and q2 will be better than the old one. And it looks very ugly. And I said. And as it's also a bit tricky to analyze, I mean, you can clearly see that if all the Q's are equal to zero, then this gives you something a lot nicer. It gives you back exactly what you would expect because you can just take the tau node equal to zero and then you get this n minus one over t, which is exactly what you would get for the cheat zero. It is what it is. There's not that much to say. But really, this minimization procedure comes from, of course, the fact that while initially in our thinking eta was a lot smaller than t, really you can really split if you want to show that you get singular. That you get singular, or you cannot be distanced, realizing after this time, you can really choose where you put your midpoint. And it's with this expression, it's not at all clear what the optimal split into t and eta would be. You could, of course, just take eta and t be tau half or something, then it simplifies a bit. But who knows? Okay, um, let me say maybe one word about how we got this. Maybe one word about how we got this. Yes. Okay, one word about how we got this. And again, the idea was to play it back to the world line case and for the world line is physics speak for an integral along a single geodesic. This was then the world line case was treated by Q step. So once we have here an integral not over the entire manifold but Entire manifold, but I can never find the find up, not over the entire manifold, but along a single geodesic. And here we also only have compactly supported functions on an interval on the right-hand side, wherever the geodesic is defined. We know how to do these things. So that's the idea. We do our thing. We take, and again, this is a rough argument if one wants to do it besides a limiting thing or something, but roughly they. Or something. But roughly, the idea is we localize it to some single geodesic, and the single geodesic should be exactly supported where we have this infigone in our segment quality, ideally. And then we plug all the things in. And the thing is, that happens is so really the issue is on the right-hand side with this derivative because there are. Derivative because there we have a so we have two things on the left hand side. We have a space-time volume and we need to get rid of the area element in the space-time volume somehow. So it is a bit of a different concept. But to get rid of the area element in space-time volume, we pack the area element into our test function. But when we pack the area element into our test function, Pack the area element into a test function. Once we take the derivatives of the test function, we need to take the derivatives of the one over the array element. And when we take derivatives over one of the area element, we get exactly this mean curvature term. And for that, we use the estimates that we had and some like a plus b squared inequalities that are right line into and then what we just think that is already available. Things that is not really available. Okay, and I think that is the main part of what I wanted to say. I do want to give you a bit of an outlook and some follow-up projects. So some of that I already mentioned. With this, we can plug in some more or less motivated numbers for massive non-minimally coupled scalar fields in Einstein-Klein-Gordon theory, which Um, which I still don't know very much about, but probably this audience doesn't either, so I'm very happy. Yeah, but our estimates are not optimal, so I've been told. And really, we would need to allow higher order derivatives on the right-hand side. But then, if we want to do the same trick, we would get derivatives of the mean curvature which we need to estimate and not just the mean curvature itself. So, if anyone So, if anyone, so this is a mathematics question for the audience, I guess, if anyone knows in this setup how to estimate not just the mean curvatures, but how to estimate the derivatives of the mean curvatures using some sort of ideally not evolution equation because we don't want to put in an exact Ritchie curvature equal to this or that model, but using some Ritchie inequality, then that might be helpful. Yeah, and a way to get rid of the pointwise bound. But that we have some ideas, but it doesn't seem super straightforward because there's also work again in the Riemannian case for Paterson and Y using L P bounds on the Ricci curvature for sufficiently large P that give you this diameter bounce directly without the additional pointwise bound. And a big question, and this is also a very general. Is also a very general question about all of these developments in Lorentzian geometry, but about the null case. So, like I said, in the beginning, a lot of things recently have fallen into place for stuff to work beautifully in the time-like case. But what about the null case? Because really null geometry is somehow one of the defining features for the Lorentzian setting. And of course, you capture this null geometry, we know kind of what null geodesic. Kind of what night geodesics should be because these are exactly points that can be connected by a causal curve but have like zero time separation. But then how to parametrize these things and how to get like estimates of and what does the affine parameter mean for non-geodes and also how good could a two-sided Lorentzian segment inequality work and will this eventually be useful? Will this eventually be useful for the Lorentzian almost splitting? And lastly, I promised you that also the first thing that I told you, despite not being quite a singularity theorem by itself, has some applications, and namely it has applications to low regularity singularity theorems. And this is some work in progress with Matteo Calisti, Edo Arvo Haven, Michael Kunzinger, and Roland Steinbauer, where we look at, well, Where we look at, well, for now, Hawking singularity theorem for local ellipsis metrics. It's a bit, well, like Nicola mentioned, there's by now also hopping singularity theorem in the synthetic setting. But the other thing is it's not quite yet fully understood how this distributional curvature bounds it. These distributional curvature bounds interact with the Lorentzian, with the synthetic Lorentzian Riggy curvature bounds. And funnily enough, in the Riemannian context, there was a very recent preprint by Andrea Mongino and Vanessa Nybols, where they showed that this RCD bounds and the distributional curvature bounds really fit together very well up until the lowest regularity. You could even define this distributional curvature bonds for rich products. Curvature bounds correctly. What I noticed, I only had the chance to glance at that briefly, is that their work uses or requires some bound on the volume growth for the Riemannian metrics and getting bound some volume growth usually involves some of these things. So maybe this would also be useful to establish some of these volume bound growth. Volume bound growth conditions, and yeah, I think I should stop here. I mean, maybe why is this useful? Because, of course, we can approximate all of Polyllips metrics when approximating we make some error, but now we know exactly how this error interacts, and so we can take a limit and get back whatever we want. And with that, I thank you for your attention. 