Much for the invitation to join you. As I say, I am sorry that I have been to Burrs before and I know it's a great place, so I hope you're all enjoying that. So, I'm going to talk today about a moving mesh finite element method for modelling defects in liquid crystals, as my title says. Unlike Apala, I'm not brave, so I'm only doing pneumatics, no smectics here, but hopefully, I'll be learning something about smectics this week. So, to start with, I have a motivation slide. To start with, I have a motivation slide, which I realise is probably entirely spurious for the current audience. Basically, saying how important defects are and the fact that they have the distortion over very small length scales compared to the size of the cell, of course, gives significant challenges for standard numerical techniques. So, we have looked at a finite element approach based on adaptive moving mesh models, and that's what I'm going to talk about today. Models, and that's what I'm going to talk about today. I should have said this is joint work with the former PhD student, Craig MacDonald, and my colleague John Mackenzie, who's a real expert on the moving meshes. My next slide also seems to be a bit spurious because of Palace just giving such a nice introduction to Land Degen theory. However, just to set notation and so on, we'll just go through this. So, essentially, I'm going to use the same Q tensor representation that Apala was talking about. That Apala was talking about. So we're going to represent the average orientation of the molecules in this form, where the angle brackets are averaging. And then we can write this using the orthogonal eigenframe in this form, which Apala also showed you. And S and T are the uniaxial and biaxial order parameters. So if we consider a uniaxial distribution where T is zero, then we get a zero, then we get our order parameter plus n, which is the tie to the liquid crystal director. So we've got this symmetric traceless tensor. It's got five degrees of freedom. So I'm going to represent this for computation using a basis of five linearly independent tensors. So this is my notation, so very slightly different from a palace. She called these q11, q12, q13 here, but it's the same principle. Three here, but it's the same principle in that we only need the five unknowns because it's symmetric and traceless. So these guys are all accounted for. So, in terms of our PDE model that we're going to start with, then we have these five unknowns. How do we set up the Q tensor equations? Well, we have expressions for the bulk energy and the surface energy, which we can write down in terms of Q and the gradients of Q. Gradients of Q made up from the different energy components. In what we've done, we've always applied strong anchoring, so there's no contribution from the surface energy in that case. So this term for the purpose of this talk can disappear. We're going to write down the bulk energy equations, and then because we're looking for the solution with least energy, we're going to solve Euler Lagrange equations. So, what to So, what do the energies look like? Well, once again, Apala has set out quite a bit of this, but just to keep things in context. So, here's my elastic energy, which comes from distorting the Q-tensor in space. I've got a thermotropic energy, which comes from this nasty polynomial again that Apala highlighted. And then I've got an electrostatic energy coming from an applied electric field E. Electric field E, although in fact, I'm going to be solving for the potential U here, which looks like this. So I'm sure I am the person, well, I can't say the person in the room, the person almost in the room with the least knowledge of where these equations come from and how they are derived. But we can take them for a numerical method and try and set up a system of time-dependent PDEs because we're interested in. PDEs, because we're interested in the movement of defects here. Okay, so that's what I'm going to do. I'm going to set up a dissipation function with viscosity coefficient nu that looks like this. And that's going to enable me to write a set of time-dependent PDEs for my five unknowns, these q's, which looks like this. So from this, we can get PDEs to represent the time-dependent. The time-dependent Q-tensor behavior. So there are five of them, one for each Q. This is three-dimensional. My numerical examples will just be in 2D, but this formulation is 3D. So that's the three subscripts here. So we can write the derivative of the dissipation like this, where the notation is described here. Basically, derivatives of the bulk energy with respect to the Q's, the derivatives of To the q's, the derivatives of the q's, and then I can write combining equations, manipulating terms, because I had a PhD student who worked very hard and tore his hair out with all the horrible mess that is these equations. And actually, we can write them in a very nice, neat fashion like this. So, we've got one PDE for each Q here, and that's what we're going to solve. Coupled with that, we've got the electric field effects. So, I'm going to have an Effect, so I'm going to have an additional unknown. As I said, that's going to be the electric potential. And assuming we've got no free charge, we can solve Maxwell equation, which I'll write like this for the electric displacement D. Again, sweeping all the details of that under the carpet. Here's the important bit from my point of view, which is we've now got a final set of time-dependent, what we'll call physical PDEs. We'll call physical PDEs. So they're the ones that represent our physical problem. There's five of them plus the equation, the Maxwell equation involving U. So we're going to solve for six PDEs in six unknowns. So obviously for any sort of realistic problem, this is going to be quite a large simulation. And how am I going to solve it? As I've already told you, using adaptive finite elements. Using adaptive finite elements. So typically, there's three different ways of doing grid adaptivity in finite elements. You can either use H refinement, which means you're changing the size of your grid locally around the action, either coarsening or refining, and this is usually based on a posteriori error estimates of some sort. There's the method of p-refinement where you change the Where you change the order of the local polynomial approximation. Again, either increasing or decreasing in accordance with the solution error. So you can use higher order polynomials where you need more accuracy. And then the third is R refinement, which is what I'm going to talk about. And that's where the original mesh points are moved to areas where high resolution is needed. So all of these methods have been tried by various people on liquid crystal problems. On liquid crystal problems, and the advantages of moving mesh trees from our point of view is that the connectivity of the grid doesn't change. So the number of mesh points stays the same, the way they're connected stays the same. And so that means there's no need for interpolation from old to new meshes for time-dependent problems. Because if you're using the other types of method, then you've generally got to interpolate in between once you've moved the mesh here because we're just moving the mesh points about the conic. Just moving the mesh points about the connectivity all remains the same. So, the focus that we had was on using moving mesh PDEs, and there's an excellent book with all the details of this by Wang and Russell. So, how do we set about using mesh movement? Well, we've got to do two things. We have to adapt our physical PDEs to account for the fact that the mesh is moving, and then we need to. Is moving and then we need to decide how to move the mesh. So, first of all, I'm going to talk about that first aspect and how we're going to adapt our physical PDEs to account for the mesh movement. So, the way it works is as follows. We're going to have some physical domain, which are called omega, and then some computational domain, omega sub C, and we're going to map in between these domains. So, specifically, our original coordinates x, y, are going to be mapped to. x y are going to be mapped to coordinates psi eta in computational domain using these bijective mappings okay so particular so which depend on time and they depend on psi and eta and although i've not said how we're going to move the mesh we're going to assume it's moving so we can then define a mesh velocity x dot here in this fashion and we incorporate that into our physical PDF. Physical PDEs by using the chain rule for derivatives in computational space, which gives us the derivatives in xy space plus this extra term involving the mesh velocity. Okay, so that's the key. Moving the mesh adds this sort of additional convection-like term to the physical PDEs. So we've got extra term in our physical PDEs because our mesh is moving, even though I haven't told you yet how. Even though I haven't told you yet how we're going to move it. So, to finish off with the physical PDEs, then this is what our new set of equation looks like. This is our extra term to account for the mesh movement. And I'm going to solve this using finite elements. Again, with zero details in the usual way, we're going to choose basis functions and multiply by a test function and integrate. So, here's the weak. Integrate. So here's the weak form of our equations. When we do all the discretization and follow everything through, what we're going to end up with is a non-linear differential algebraic system, which can be very large and very horrible to solve for physical PDEs. Okay, and I'm going to use in the examples later, I'm going to solve these equations using quadratic finite elements. Right, so now we're going to park. Right, so now we're going to park the physical PDEs for a moment and go back to the idea of the moving mesh. So I've told you it's moving, but I haven't said how we're going to move it. And what we're going to do is we're going to use the moving mesh PE method. So we're actually going to set up a separate set of equations for moving the mesh itself. So it turns out that the best way to avoid mesh crossings in this method is by evolving the inverse mapping, which the mapping AT, which we Which the mapping AT, which we talked about before, and what we do in practice is we choose a mapping Ïˆ for a fixed t to minimize this expression here. And how we have influence over exactly how the grid moves comes in through what's called the monitor matrix. So there's a matrix here, which will either be 2x2 or 3x3 in 2 or 3D, which is going to allow us some flexibility in choosing how the mesh. In choosing how the mesh moves, there's lots of sort of practical things associated with these moving mesh methods that are well understood by the experts. So to keep things robust, we actually evolve the mesh using gradient flow equations, which look like this for their two coordinates. And you'll see here that we've introduced two user-specified parameters into the process now. So we've got a temporal smoothing parameter tau here and a spatial. Tau here and a spatial balancing function p. So you'll see these later on. So we do have to prescribe these, but in general, the community of moving mesh PDE people have good ways of choosing these and there's good rules of thumb. So I'm not too worried about the fact that we've got these parameters because we're going to be able to pick good values for them. So I mentioned this monitor matrix G. We're going to use a specific form of that. We're going to use a specific form of that, which is called the Winslow monitor matrix, and that's the simplest form in a way because it's diagonal. So, we're going to use the same function to evolve both our coordinates. And in practice, when you actually go to code all this up, it turns out the way to do it is we interchange the variable roles in the moving mesh PDE. So instead of solving for psi, we end up solving for x and y in the original space. In the original space, and we solve this expression here. These are our temporal moving parameters, spatial balancing parameters again, and these are just come out of transforming the derivatives and so on. Okay, so nasty looking things, but given we know our equations, of course, we can write all these down and calculate them. There are lots of other bits and pieces to be done when you're using an MMPDE. We're going to discretize in space using linear finite elements for the mesh. We're not so bothered about the accuracy for the mesh, as long as they're more or less in the right place, the points, that's going to be fine. So we don't want the expense of using quadratics. The time discretization we do using backward Euler scheme, so quite straightforward. To get boundary conditions in a 2D problem, which is what I'm going to be showing you in a moment, we actually use a 1D remesh PDE. Use a 1D remesh PDE along the boundary, we solve that to match boundary conditions. And to avoid solving non-linear algebraic systems, we basically fix coefficients and iterate through. I'll show you a summary of the algorithm in a moment. The linear systems themselves are large and can be very hefty to solve, so we use an iterative method, by CG STAB, with an incomplete LU preconditioner. Incomplete LU preconditioner. And finally, there's also some adaptive time stepping built in based on computers solutions at previous steps and error estimation, which I'm not going to talk about today. So just in summary, without all the details of the MMPDE algorithm, this is what it looks like. We set up some initial mesh with an initial guess and our cues. We start at some initial time. We start at some initial time and then we evaluate this monitor function. So, this is our Winslow function at the time Tn. We integrate the moving mesh forward in time to get a new grid. We integrate the physical PDEs forward to obtain the new values of QU and then we loop around. Okay, so that's the general setup. What I haven't said is how we're going to choose this monitor function. Going to choose this monitor function. So essentially, it's got two sorts of components: there's the form of the function w itself, but it's also dependent on some specific input function, which I've called t here. Okay, so in this presentation, I'm going to show you results using three different forms of monitor function. So we've got, first of all, based on the arc length of whatever input function we choose, okay, that's A L. Okay, that's an AL, and then there are two monitor functions that called Beckett-McKenzie functions. That's my colleague John McKenzie was involved in suggesting these initially. And so, BM1 is based on first-order partial derivatives of T and BM2 is based on second-order partial derivatives of T. Okay, so what to remember here is we want to move points where the action is, right? So it Is right, so it makes sense if we have some input function, which is going to be a function that varies rapidly where we want the points, then we want to make a measure of how fast that's varying. And these BM1 and BM2 monitor functions have additional scaling parameters in there, which regulate mesh clustering. Because that's one of the difficulties with moving meshes: it's all very well to say put all the points here, but then there is still the rest of the grid, you don't want to starve. The rest of the grid, you don't want to starve the rest of the grid with too many points. So, this alpha term essentially says you've got to leave some points behind when you move them all. And this M helps to also regulate the mesh clustering. So, all of this is fairly standard in moving meshes, but the question is, what is this input function going to be? And that's where, of course, the knowledge of liquid crystals comes in. Of liquid crystals comes in. Because what we need for the input function, as I just mentioned, is we need a function that varies very rapidly where we want the points. And so if we're interested in defects, we have looked at two different possible functions here. First of all, the scalar order parameter, S, which varies rapidly at a defect, again, as Apala was talking about. So here we're going to base. So here we're going to base our input function on the trace of q squared because in a uniaxial state then we have this relationship here. Okay, so our first input function is going to be the trace of q squared. As a second input function we're going to try this direct invariant measure of biaxiality because we know there's biaxiality happening at the defect. So this measure here, again, based on a trace of q squared, q. Of q squared, q cubed in here, and this parameters the value of zero for uniaxial up to one fully biaxial. Okay, but here's the key point: both of them have extrema at the center of a defect and vary rapidly in the immediate area roundabout. Okay, so they should be good candidates for this input function. So, I'm going to show you two numerical experiments. The physical PDEs we have non-dimensionalized with respect to length and energies. We're going to use triangular grids with quadratic functions for the PPDEs and linear functions for the MMPDE. So quadratics for the actual what we're interested in and linear is for moving the mesh. And I'm just going to show you a selection of combinations of all these things. So we've got the arc length with the trace of q squared as the input function. Squared as the input function. We've got the Beckett-McKenzie one with both input functions, and then Beckett-Mackenzie II with biaxiality. So I'll show you these results in the first experiment for these four different combinations. And all of these experiments are just done in that value. So here's test problem one, a nice straightforward one, a stationary defect. So there's no defect movement going on here. Here's a half defect and there's Here's a half defect, and there's an eigenvalue exchange which takes place along the line y equals zero here, which is demonstrated here. Okay, so typical adapted grid for this looks good. We're putting all the points at the middle where the defect is, so that seems to be doing the right thing. Here are typical solutions. The one on the left is a plot of the scalar order parameter, and the one on the right is the And the one on the right is the biaxiality. And again, this is all looking good. In particular, you get the little biaxial volcano shape here. So you can see it's zero right at the center here, and then it's one right round here. So we're picking up all of this structure in the solution, which looks good. But the real reason we wanted to look at this straightforward problem was to try and look at convergence of our method. Convergence of our method. Okay, so here's an illustration of the estimated rate of spatial convergence. We've looked at it for three of the components: Q1, Q3, and Q4 here. And this is calculating the L infinity error compared with some reference solution. And so you can see, hopefully, from this, here's a reference slope. It looks like all of our components are essentially converging spatially at a region. Emerging spatially at a rate order capital N to minus G. So capital N elements on each side. I should have said that. So this is optimal for second order elements, quadratic elements. Okay, so we convince ourselves that we're on the right track, our method must be doing the right thing, and we've got the right sort of convergence. What do the actual solutions look like? Well, this is just to give you an idea. If we look at the scale. Idea. If we look at the scalar order parameter along the center line, that's the blue line, and then the red circles, which hopefully you can see, are where the method puts the points. Okay, so four pitches. This is with arc length based on trace of Q squared. This is BM1 with trace of Q squared. And the bottom two are based on biaxiality. This is BM1 and this is BM2. So just looking at these, you can pick which one. Just looking at these, you can pick which one you would like best, but it looks like the BM2B has the most sort of uniformity of points out width and lots of points where the action is happening here. Okay, if we do a similar thing for biaxiality, as I mentioned, that's got this sort of volcano structure, which should be harder to capture. So it's the same four combinations. And again, it probably looks like BM2B is doing the M2B is doing the best from the point of view, it's at least getting some points right down here into the well of the volcano, which, for example, have been missed here. Okay, so it looks like the BM2B combination is going to be the best one, but of course, this is only half the story, the accuracy, because the methods have different costs. So it's also important to look at the computational costs of each method. Computational costs of each method. So, two plots here: this one for the Q1 component, this one for the Q4 component. They're both very similar. And what the plots are showing are CPU time versus L infinity error for the different grid sizes, okay, and the different combinations up here. So, what we can see is both in terms of error reduction and computational cost. Reduction and computational cost, BM2B, the red line here, is again performing very well. Okay, so I'm going to declare this to be my combination of choice for my real example, which I'm going to do now. So here's a test problem where we've actually got some moving defects. So this is what we aimed, this was our starting aim to be able to model this problem. It's taken from this paper here. It's essentially This paper here. It's essentially a two-dimensional pi cell geometry. Excuse me. Electric field applied parallel to the cell initially. And what we get is we get an inhomogeneous transition mediated by the nucleation of defect pairs moving together and annihilating each other. So numerically, this is quite a tricky problem because we have to pick up the creation of defects and their annihilation and what happens afterwards going back to normal. Our initial director angle, what we're going to do to kickstart the thing, is put a sort of sign profile in the center of the cell. This perturbation comes in right at the beginning of the simulation just to induce some solution gradients so that something happens. So, here's a schematic of what the problem looks like. We've got a pre-tilt angle at the boundaries, here's the electric field strength. Here's the electric field strength, and then you can see this is just an obviously diagrammatic, but we've got some sort of sign perturbation in the middle here to kick things off. And I'm just going to show you some pictures of how the solution to this evolves. So the three pictures here, this is the scalar order parameter, this is the biaxiality, and this is the mesh which was used to calculate both of these. So this is after 12 microseconds. So you can see. So you can see there's some sort of signy shape in the middle that we've imposed to get things started. And the question is: what's going to happen as time moves on and how is this going to evolve? So that was at 12 microseconds. If we move on to 15 and a half microseconds, here we've got a direct to picture. And hopefully you can be convinced here that what we've got is in the center, we've got a plus half. We've got a plus half defect and a minus half defect, which have appeared and are moving towards to annihilate each other, and then similar things happening here across the periodic boundary so that this guy and this guy are going to annihilate over there. Okay, so this is what we're looking to see from our numerical method. And here are the order parameter pictures. So the first one is at that time I've just shown you the directors from, and then slightly later and slightly later still. And slightly later, still. And what you can see here is that we seem to be picking up exactly what's happening. So, here we have the formation of the two defects, and they're moving closer together here as time goes on. And eventually, they're going to annihilate and just go back to a uniform grid. This is the same pictures, but in terms of biaxiality. So, we pick up the same structure as the two moved here. As the two move together and then eventually cancel each other out. And these are the grids which captured these features. So you can see that we've got what we want in that we're moving points into where the action is happening without leaving this area too starved of grid points. And in particular, when, for example, here there's no longer anything of interest, we can see the grid is relaxing back to a quasi-uniform. Back to a quasi-uniform state here while all the action is contained where we want it. So our summary then is that we think we've got a nice new efficient moving mesh method for Q-tensor models of pneumatic liquid crystals. We found biaxiality to be a very good choice for the monitor input function. There's been other people have also done work on this with various input functions, but this one. Input functions, but this one really seems to pick up exactly what we need in terms of defect modelling. We were able to demonstrate the optimal spatial convergence, which was nice. And for this particular problem, then we've managed to resolve the movement and the core details of the defects, including these difficult problems of creating and annihilating defects in the time-dependent problem, which was also good. So, as always, future challenges, of course, extend. Of course, extending to more irregular geometries would be nice, as would obviously more realistic three-dimensions. I don't know if I can add smectics to this list, but if anybody has a problem, they think that this might be applicable and it would be interesting to see whether the same sort of ideas would transfer in that situation. And maybe something I'll find out this week. So, thank you very much. Great, thank you, Allison. Any questions from the audience for Allison? Could this be combined with a moving boundary that required by one of these immersed boundary methods or otherwise, so we could see a colloidal particle with a defect moving around? That's not something that I've done, but I suspect it could in that my colleague John Mackenzie has done a lot of work with moving meshes in biology and modelling cell movement, and they've certainly got a lot of moving boundaries in those problems. So, I would be not at all surprised if the same techniques would work in this sort of situation. Any other questions? Tim? Yeah, thanks for the fantastic talk, Allison. This was so helpful to me. Like the fact that you've unpacked so many elements of this algorithm. Could you give us some overall advice for choosing these monitor functions from your work? Like what sort of thing, you know, if we were looking beyond Looking beyond the very challenging problem you've solved, like what sort of insight do you get for choosing monitor functions for these kinds of methods? Yeah, I mean, I think the main thing to think about, the standard sort of monitor function types here are all based on these input functions. And you can see here it's all about the change. So whenever something is changing rapidly and has gradients, which Changing rapidly and has gradients which you can capture, then that's where the points are going to go. So, I mean, it's not very deep insight, but basically, you just need to have some sort of input function that really is just going to capture that behavior by changing rapidly where you want the points to be, because that's what all of these different monitor functions are doing, albeit in a slightly different way, depending on arc length or the derivatives, so more directly. The derivatives, so more directly based on the change. Well, one question then, so let me push a little further. Like, one thing that we already compute is the local energy density. So what if we used the energy density in place of like as a monitor function? Yeah, I guess that would be a valid choice. Again, it's not something that we've Again, it's not something that we've looked at. You also need to bear in mind how easy it is to access these things and how complicated they are to compute and so on. The nice thing about the ones we've chosen is that they were basically cost-free because you've already got all these terms to set up your equations and so on. So that might be more tricky, I think. Right, any other questions for Allison or anybody on the line? No, I don't see anything online. Okay, if not, well, then let's thank Alison again. Thank you. Great, so we now have a coffee break and then we'll pick things up again at 15 minutes past the hour unless you're in. Great. What's that? Five zero minutes past the hour. Excellent travel. Those who are interested in joining on a bus right to the lakes in the afternoon.