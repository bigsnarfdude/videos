Me, I wish I could be there in person, but I'm gonna try to make the best of it. So, today I would like to talk about adaptive approximation schemes for dynamic matching of cues, which is joint work with Ali Oat and Amin Saberi. So, probably I do not need to tell this audience, but a lot of matching markets are dynamic. And when I say dynamic, I mean that new agents continuously arrive on the market, and also they continuously abandon the market. Abandon the market. For example, if we think about organ donation systems, we have new patients becoming in need of an organ every year and continuously. Also on the left-hand side, we can see the life expectancy of people who have renal failure. And this pink curve here, it shows that the life expectancy of these patients is much lower than other people. So if they wait too long for If they wait too long for a transplant, their health conditions may become too worse to be eligible for a transplant or may die and they may leave this system. So this sort of continuous arrival and abandonment of agents is a prominent feature of many other examples such as right-hailing and emergency response. If you think about right-hailing, we have customers or passengers that we have to match them quite quickly. To match them quite quickly, and also we have drivers that we cannot keep around forever, and we have a like limited timeframe that we should match them. And also, in emergency response, our goal is to match volunteers to patients who are in need of urgent medical treatment. And there are these sorts of dynamics at play again. And conceptually, we can think of this problem as an online matching problem, but with queuing agents. So, again, if you think about So again, if you think about organ donation, we have patients arriving continuously and they queue until they are given an organ. And unsurprisingly, this issue is related to two very rich literatures on online matching, which focuses mostly on the design of competitive algorithms and considers less this sort of dynamics. And also, we have the matching cues literature and stochastics that focus And stochastics that focuses more on the dynamics. I want to also point out to this very recent and beautiful line of work on the design of very strong low-regrade algorithms for dynamic matching. But one crucial issue is that we need to have patience agents. And without abandonment, we can get these low-regret algorithms. And there is a recent line. And there is a recent line of work that is trying to study this dynamic matching problem and devise efficient algorithms for this problem. However, when we were trying to think about this problem and going through this literature, we realized that most of the work in this area focuses on static policies. When I say static policies, I mean the ones that do not look at the state of the system or who is waiting in the system before In the system before making their matching decisions. And yet, these policies are enough to give us constant factor guarantees. And then it made us think, can we do better? Can we achieve optimality? This is exactly the title and subject of my talk today. And we are trying to develop near-optimal algorithms for this dynamic matching problem. And our main ingredient for this goal. For this goal is a new set of linear programming relaxations called a dynamic LP that allows us to devise adaptive policies and get near optimal approximation schemes for constant size networks and Euclidean networks. I'm going to explicitly define these later. And along the way, we realized when and how this adaptivity can help us for the design. Can help us for the design of better algorithms. And one of the main insights was that we can use adaptivity via a hybrid approach, which marries dynamic programming with a fluid drift design. So let me get into the model and feel free to ask any questions. If you were here in the morning for Tristan's talk, the model is very related. Related. So the first element is that we have a bipartite type graph where on the left hand side we have servers and on the right hand side we have customers. And then matching a server of type I to a customer of type J, it creates a cost Cij. So if you think about a Euclidean graph, this cost could be representing the distance between the customer and the server. And then like in right-hand, this could correspond to the pitch. Right hailing, this could correspond to the pickup time of that customer. The second element of the model is the dynamics that governs this system. Namely, we have servers of type i, they continuously arrive according to a Poisson process with rate lambda i. So when they arrive, they wait in the system, they queue up, but they're going to wait around for some random amount of time. And this random amount of time, And this random amount of time follows an exponential distribution that we know the distribution, but not the realization. So this is one side of the market. We have people coming, they wait to be matched, but they may abandon at some rate. The other side of the market, we have customers, and they continuously arrive with rate gamma J. So type J arrives with rate gamma j, but they are very impatient. Very impatient. Whenever they arrive, we have to match them immediately, or else they're going to just abandon the market. So, if you think about right-handing, we have passengers coming, we have to match them very quickly, but the drivers are going to stick around for a bit longer, but not like an infinite amount of time. So, this is the dynamics. And please let me know if there were any questions. And our goal here in this problem is that by criteria Is a bicriteria optimization. Namely, we have a throughput constraint where we want to have a sufficiently high rate of matching. So we have this target tau star, and we want our match rate to be at least tau star. However, these matches are costly, and our second constraint is that we don't want the cost rate to be above C star. So we are given this target of So we are given this target C star and tau star, and we want to satisfy both constraints simultaneously. So this is a bit different from the classic reward maximization objective that we have seen so far. But I should point out that this is a bit stronger in the sense that if we can solve this problem to optimality, we can solve the reward maximization problem as well. Cool. In this work, we are. Cool. In this work, we are interested in satisfying these two constraints up to an epsilon factor. And because epsilon can be very small, this gives us a near optimal guarantee for constant size and Euclidean networks. Any questions on the model? Cool. So let me tell you a bit about the design of adaptive policies. The first question. The first question is: Okay, we want to be near optimal, but do we need to be adaptive? Or can we get it by static policies? And the upshot here is that if you want to be near optimal, we have to be resorting to adaptive policies. So we can see it by a very simple example. Let's assume that we have only two customer types and just one server type or one queue. The arrival rates are The arrival rates are fixed, the costs are fixed, and the abandonment rates, mu, we're going to vary it and look at different values. On the other hand, we have a fixed throughput target that is given to us. And for each value, for each level of abandonment, I'm going to consider the best static policy and the best adaptive policy. When I say best, I mean in terms of having the lowest cost. Then I'm going to compare them. Then I'm going to compare them and show the ratio of the costs here. So this plot gives us some very nice insights. First of all, when mu is very small or very large, then this gap between static policies and adaptive policies is very small. Intuitively, when you have very patient servers, they arrive, they're going to wait around for a very long time. Well, you can be static and obtain the same sort of guarantees. And obtain the same sort of guarantees. And also, if they are very impatient, whenever they arrive, they're going to be there just for a very short amount of time. You cannot afford to be adaptive. However, in this interim regime, the gap could be quite large. In other words, there is a regime where the optimum static policy has a cost that is double the optimal adaptive policy. So it shows that if you want to be arbitrarily close to optimum, If you want to be arbitrarily close to optimal, we have to be adaptive. You define what adaptive is. Sorry, can you say again? You define what static and adaptive are here? Oh, yeah, sure. So adaptive policies are the ones that look at the state of the system or the queue length before making their matching decisions. But static policies decisions is independent of the length of the queues. Now, so here's the plan for today. First, I'm gonna focus on the case where we have only one queue. And even this setting is gonna give us some very nice insights. And for this case, we're gonna devise a dynamic linear programming relaxation that is quite different from the previous literature. And it's giving us a near-optimal algorithm for this case as well. algorithm for this case as well. And then we're going to try to think about more general cases when n is bigger than 1 and we have multiple qs. And we're going to see that we need some new ideas and new techniques to solve this problem. And afterwards, there's a problem on how to implement or online around this network LP, which is our policy priority rounding. So let me start with the case of a single queue. With the case of a single queue. So, recall that we want to characterize the optimal policy. And we were thinking about this problem. And one thing that could help us was to think about what does a real optimal policy do? How does it behave? And the first piece of information that came to our minds was maybe the state of the system is a very central piece of information for this optimal policy, and it may use it quite heavily. Use it quite heavily. So, in this very simple example, we have just one queue. And on the left-hand side, we have one driver waiting. So, the queue length is one. And on the right-hand side, we have four drivers. So, L is four. And this optimal policy looks at this state of system, but it is facing a set of potential customers. So, if you look at these customers, these are not actual arrivals, but these are Actual arrivals, but these are just potential customer types that could arrive. So the optimal policy observes the state of the system and the set of potential customers, but not the realization. And then we were thinking about, so what is the decision of this optimal policy? And one way to think about it is that the optimal policy looks at the state of the system. And before observing the next arrival, the next customer, it's going to Customer is going to decide on which customers it's willing to serve. In other words, I do not know who is arriving next, but in my mind, I can decide if that type is arriving, I'm going to serve it, or not. And in this simple example, it may correspond to some sort of like neighborhood around my drivers. And I would determine this neighborhood and only serve a customer if that customer lies within that neighborhood. Customer lies within that neighborhood. Therefore, it's conceivable that maybe my neighborhood depends on the queue length. So if you have only one driver, you may become very picky and only serve customers that are very close to your drivers. However, if you have more drivers, you may be a bit more open and even serve customers who are further away from you. And just a piece of notation. Just a piece of notation, I'm going to call this neighborhood, which is the set of customers I commit to matching. I call this my matching set. So just again, to reiterate, M is a subset of customer types that I commit to match. I do not observe them yet, but if they arrive, I will match them. And here is a quick question. Is this without a generality that the optimum online would not observe which? Would not observe which types are going to be realized to decide the set that is going to be matched. I'm sorry, can you say again? I did not follow. So you said that the adaptive policy is going to make the decision which types are going to be matched before realizing the types. But is that seem to be without loss of generality for the actual optimum? Yeah, it is without loss of generality because the observation, I mean, you can forecast that and make that decision. Forecast that and make that decision up front. Yeah, arriving one at a time, is it? Yeah, yeah, one at a time. These are Poisson processes. But just forecasting, I mean, shouldn't your decision be a function of the set of types that are realized? Yeah, so before observing the next one, you decide on your matching set. Because the version that has no loss is that you observe the types and the Is that you observe the types and then, based on that, you decide whether you match them or not? It's like a good tension. The one is like the example, but you can think of it as state-dependent. So, in a given state, if a particular thing happens, you decide ex ante in this state, here's what I will do. But that's the same as if you were deciding it exposed, because the state conditioning already. Yeah, thanks, Daniel. So, yeah, I think I understood correctly. So, let's say I observe type one, and if I decide whether to match that type one, I could make the same decision before observing that type as well. Is that clear? No, but we can't take it off. Okay, sure. Okay, sure. Yeah, okay. So with this intuition, we can write an exact dynamic LP for the case of a single Q. And the decision variables of my LP are of the form XML, where recall that this L is the same length of the Q. So this is the state, and then M is the same matching set that I had. The same matching set that I had before. And then XLM is the probability that my system is at state L, and I'm going to commit to set M as my matching set. So this is the probability. And admittedly, this is an unusual way to write a linear program, but the reason is that this stationary probability is a highly non-linear object. A non-linear object. And this formulation allows us to characterize the evolution of the queue as a linear program. Is this definition clear? Okay. Having this intuition and definition in mind, we can write our objective. So what is our objective? We want to minimize the cost, and we can write it as, And we can write it as, let's think about different customer types. They arrived with rate gamma j. Type J comes with rate gamma j. And what is the probability that this customer of type J is matched? Well, the probability is the same as the matching set containing type J. So I can consider all different queue lengths and all different matching sets that contain type J, and there are some of X. And their sum of x values is the probability that the arriving customers of type J are matched. And whenever they're matched, we incur a cost CJ. So this is explaining the cost rate of my policy. Of course, these x values cannot take any arbitrary value, and they should be describing my birth-death process. And this Q is exactly explaining that. Explaining that process where the constraints are nothing fancy. I'm not going to get into the details, but basically, these are just detailed balance. And also, because we have a probability measure, they should sum up to one. Of course, we have another constraint, which is just we need to satisfy our throughput target. So I'm going to let it be here for a second. So we have this sort of LP, which is characterizing the optimal. Characterizing the optimal policy exactly, like there is no loss as of yet. Right now, this LP seems a bit hopeless, right? Because we should be tracking an infinitely many Q lengths. And also, even for a single queue length, I have to consider an exponential number of matching sets. But interestingly enough, we Interestingly enough, we were able to give a fully polynomial time approximation scheme for this like huge LP. And so you can imagine that we had two hurdles. One of them was the infinite Q length. And the way that we solved it was to show that if we truncate the Q by a polynomial range, we lose very little. And this was a very non-trivial thing to do because thing to do because it's true that because we have abandonment we can truncate and lose a little but that truncation would not be polynomial so the polynomial truncation is quite hard to get and the issue with the exponential matching sets we resolved it by giving us an efficient separation oracle of the dual LP however if you look at it carefully you see that the proposition is about solving the actual problem About solving the actual problem and not just the LP. And the beautiful thing about our dynamic LP is that a very natural byproduct of it is a policy because it's going to give us the matching sets automatically. So here is how the algorithm works. First, I'm going to approximately solve my dynamic LP. And whenever a new customer of type J arrives, I'm going to look at the state of my system. Look at the state of my system, which is Q length L. And then I'm going to draw my matching set with a probability that it's proportional to x lm. The denominator is nothing fancy. It's just a normalization. And it's a bit similar to what Trisson had in the morning in the proposal probabilities. And then once I have my matching set, I'm going to match the customer if and Match the customer if and only if J is in my matching set M. And it's not difficult to see that this algorithm, if we do this, the stationary probabilities are going to be exactly described by XMLs. And so the performance of the optimal policy is the same as the objective of the dynamic LP. And this is going to give us an FP task for the case of a single queue. FP task for the case of a single queue. Now, I would like to talk about the second problem, which is when we have more than one queue. Here we have a network LP, and when we were thinking about this, a new challenge arised. So in the case of a single queue, we had only one issue, which was whether or not to serve that customer. But now we have a bunch of different queues. So even if we were queues. So even if we were to serve that customer, there is a problem which queue gets to have this customer. And I call this issue a contention between different queues. And another way to say is that there is competition between different queues over this customer. And this turned out to be quite a difficult and important issue. And the way that one could solve this is to realize that her cues are living Realize that our cues are living in two totally different time scales. On the one hand, we classify the Q's into short Qs and long Qs. And intuitively, we want the short Q's to be by definition short and the long cues to be by definition large. But ex-ante, it's not clear which cues are short and which cues are long because whether or not they have people in the queues. Not they have people in the queues, it depends on the policy. But our design only cares about the arrival rates in the sense that short queues, we have this parameter, truncation parameter lambda bar, and I define a short Q if the arrival rate is smaller than lambda bar. On the other hand, I define a Q to be long if the arrival rate is bigger than lambda bar times one over epsilon. times one over epsilon. Of course, if you take lambda bar to be sufficiently large, all the q's become short and it's a bit boring and intractable. But our lambda bar here is going to be polynomial. Any questions? So this doesn't partition the cues into two partitions. It does. Well, if you choose this lambda bar carefully, then it's going to partition. And yeah, we should have a partition. Partition. That's a great question. Yeah. If lambda is basically lambda power and lambda bar over normal epsilon, what would you do? So we pick this lambda bar in a way that there is no arrival rate between these two. I see. Yeah, that's a great point. Thanks. Okay, so let me delve a bit deeper into this definition of short versus long. So the intuition behind short cues and the way to think about it. Cues and the way to think about it is that these guys have low arrival rates. So, regardless of the matching policy, the abandonments are going to make them short. And because there are few people in the queue, we can efficiently track their states. And when I say track their states, I mean that we can again write a dynamic programming formulation with variables of the sort XML. So you can observe that this L is tracking. And you can observe that this L is tracking their states because my decision, again, depends on the state of these short cubes. There is a subtle difference between this guy and the case of a single queue, which is here M should it corresponds to the matching set for all the short queues. Before it was just for one queue, now it's dictating that for every queue. And also L is the state of all the short queues. And you can imagine that here adaptivity is... Here, adaptivity is baked into my formulation because these dynamic programming variables are adaptive. And another intuition is that these are scarce resources because these are short, like they do not arrive very frequently. So we have to be adaptive for them. We cannot afford to mismatch them. On the other end of the spectrum, we have long cues. And so these have high And so these have high arrival rates. And therefore, we may not be able to track them efficiently anymore because they could grow very large. And so we cannot be tracking them efficiently. And therefore, we keep track of only one statistic for them. Like, yeah, only a small number of statistics for them. Namely, we're going to have a bunch of fluid variables where yij is the average match rate between qi. match rate between QI and customer J. So for each long Q, I'm going to have a bunch of YIJs. And obviously, for these values to explain the optimal policy, we must have flow preservation, meaning that the aggregate average match rate should be smaller than arrival rate. Okay, now imagine that we have a stat. Imagine that we have a static policy that matches to the long queue with a constant rate of lambda i, which is like some of the aggregate match rates. So imagine that we have a static policy that does not care about the system, the state of the system, and always matches with rate lambda i, with rate at most lambda i. So let's consider the evolution of this Q under this static policy that observes the plot preservation. that observes the plot preservation. So the q goes up by one with rate lambda i. It goes down with matching rate lambda i, at most lambda i. And there's an abandonment rate as well, which is proportional to the number of people in the queue. Now, let's say lambda i is very large. So around zero, around like small values, the evolution of this queue is very similar to a symmetric round. Is very similar to a symmetric random walk, and we know that it hits zero with a very small probability. So if I have a long q where lambda is very large, the static policy is going to make this queue almost always non-empty. So it rarely hits zero. So intuitively, if I have a static policy that observes this flow preservation, we are always ensured a match because we barely hit zero. be barely hit zero. And with these two sets of dp variables and fluid variables, we again can write our network LP. So again, we have an LP where the dynamic variables correspond to short cues and the static variables correspond to long cues. Our objective is again to minimize cost, subject to a set of global balance equations, nothing fancy, just describing this Markov chain. Describing this Markov chain. And also, we have another constraint which corresponds to the throughput target. Now, let's say I solve this network LP. The second important question is, how can I round it? How can I implement it in practice? So I have my instance, and it could have a bunch of short queues, it could have a bunch of long queues. You could have a bunch of long queues, so the problem is difficult. But I claim that if we only had short queues, the problem would have been very easy. The reason is that my network LP is giving me my decisions already. Just, I mean, remember the case of a single queue. I had a very natural policy, which was just to implement the dynamic LP. If I only had short queues, I can do the same thing. I observe a customer, I look up. I observe a customer, I look up the state of my system and pick a matching set according to the LP solution and then make my matches. The problem is easy here. Now, on the other hand, if we only had long queues, again, I claim that the problem would have been easy because, well, we can be static and the queues would rarely be empty. And it's very, I mean, I'm not going to explain the details, but it's very easy to have a static policy that is almost optimal. Policy that is almost optimal. But the problem here is that in an instance, we could have both short queues and long queue. And here, that contention issue rises again, and we have to solve it. The way that we solve this problem is that we give a priority rounding policy. So let's say a customer arrives, and it could be that the short cues want this customer according to the LP solution. The LP solution. And also, it could be that the long queues want this customer as well. And when I say want, I mean based on some randomization that is corresponding to the fluid decisions. But the details is not important. It just says that it could be that both the long queues and the short cues want this customer. Now, what we do in this case is that we always prioritize the short cues. Remember that these are the scarce resources. We cannot afford to mismatch. Cannot afford to mismatch them. So we're going to match this customer to the corresponding short queue. But what about the long queues? Because we have promised them a certain match rate as well. So I have a virtual queue for them, and I'm going to schedule a match for this long queue to this customer type. This is sort of a deferred match that I have to compensate in the future. And later on, if a time comes that the same customer type comes that the same customer type arrives, but the short queues do not want this customer. I'm going to look up my schedules and see if I should match this customer type to a long queue or not. And if so, I'm going to make this match and remove that schedule from my virtual buffer. And then one question becomes whether or not this virtual buffer blows up or not. And a Lyapunov analysis shows that this scheduler is going to remain bounded. Scheduler is going to remain bound. And using this priority rounding policy is going to give us our near-optimal policy for the case of constant size networks. So here, the number of queues is just a constant, and we can be near optimal in this setting. And as applications of this model, we can think about organ donation, where we have a limited number of compatibility constraints like blood type. Constraints like blood types and tissue types. So, we can apply this methodology. And if we use this algorithm as a subroutine, we can give a near-optimal approximation scheme for Euclidean networks as well. Where here, you can think about right-hailing or emergency response as the applications. So the takeaways would be that we have studied the dynamic matching problem with abandonment. Problem with abandonment. In the case, and we have observed surprising tractability when we have a constant size of queues or a Euclidean network. And the main way to achieve this, the main technique to achieve this was our hybrid LP design and the priority rounding policy, which conceptually corresponds to having a thick market versus a thin market. And then we had to combine dynamic programming with a fluid analysis. Fluid analysis. And as Tristan presented in the morning, for more general networks, we can reach one minus one over the approximation by correlated purple results. And with that, I conclude my talk and happy to take any questions. So in the interest of time, let's take one question before I I guess let's just end up. And I've been reading a program with you if you're here. Pardon them with you. If you're here later on for this workshop, I can try to partner them with them if you have more questions. They'll ask them. Do you really need random M's? And also, would the M's be a monotone set in the key length? I see, very interesting. So, in the case of a single Q, yes, M sets would turn out to be monotone. You had another question, right? Question, right? Oh, do they need to be random and the amount of tone reduces the complexity? Uh, you're saying they should be random or not, right? Yeah, you have to have these be random. Is that mean it? Yeah, so for example, in the case of a single queue, you need to have some sort of tiebreaking to get exactly the throughput target because you don't want to get more than your throughput, right? But in the general case, But in the general case, I imagine that you need randomness because I mean, at least to get this near optimality, because the optimal policy would be deterministic, but I am not sure, I'm not aware of a deterministic policy for this. Okay. Thank you very much, Alera. Thank you so much. Hopefully, we can catch up with you later. All right. Thanks. 