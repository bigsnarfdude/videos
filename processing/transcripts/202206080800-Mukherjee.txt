Thanks so much. Yeah, fantastic. Thanks very much for the invite and for putting this really sort of cool event together. And yeah, I'll keep this sort of pretty brief and do sort of let me know when I'm sort of five minutes before then. But the story here is really about leveraging machine learning type ideas for causal structure learning. And in the talk, what I'll do is I'll start with a little Talk: What I'll do is, I'll start with a little background on causal structure learning and then sort of explain the sort of classical way of solving these types of problems and then move on to the machine learning view in the title. And this is joint work with a number of people listed here. And I'd like to thank also the various funding bodies. Okay, so some background causality, and then a little bit about the sort of classical graphical models-based approaches, and then on to the. Models-based approaches, and then onto the sort of scalable deep learning architectures. So, causality, you know, I think everyone here knows is sort of fundamental to discovery in biomedical domains. And here's a picture of a protein signaling network. And so clearly, these sorts of networks carry causal semantics. The idea is that the parent nodes have some causal effect on the children. You could think of sort of similar networks that you see in different areas of. Similar networks that you see in different areas of biomedical discovery. So we're not just interested in sort of, you know, in prediction and multivariate modeling, but in really sort of doing causal learning in one way or another. You know, I think as everyone in this audience knows, this is a different kind of task from sort of within distribution prediction, because you're asking what would happen if I changed something in the system. And so this notion of intervention, of external manipulation, is crucial. And, you know, I think. Crucial, and you know, I think most of you are probably familiar with the sort of uh famous chocolate Nobel Prize plot, and so the idea here is that you know, if you plot chocolate consumption against Nobel Aureas per unit population, you get this sort of, you know, you get this correlation. But the question is, what does it mean? And you could sort of imagine, you know, a couple of different models, one where, you know, the association is confounded maybe by national income, and another one where it's really causal. And the key point here is that if you care. The key point here is that if you carried out an intervention on chocolate consumption, the interventional distribution after the interventional chocolate consumption would look very different depending on the underlying causal model. And so that's sort of sketched here in red. And so the key point is in this sort of causal model, you're really interested in what would happen under an intervention. And so that intervention regime, so the distribution shown in red on the right, isn't accessible to you at the time of analysis. And so that's sort of the key. Analysis. And so that's sort of the key distinction. And so that again, sort of in terminology, that's sort of saying that if in causality, you have sort of, you consider causal regimes, you know, maybe different interventions or combinations of interventions, and these give rise to different distributions, but you only have access to some of them, maybe only the observational one. So a kind of a very standard way of doing causal structure learning. So causal structure learning. So, causal structure learning means the particular subset of causal learning tasks where the goal is very much to learn the graphical structure. So, who causes whom? So, where the emphasis isn't so much on the estimation of a quantitative effect, but just a claim about the relationships, the causal relationships between the variables. So the output's a graph, a directed graph of some kind. One way to do this is to use graphical models. And so, one scheme would be to say that, well, Scheme would be to say that, well, you know, in the forward model, is that I have a directed acyclic graph whose vertices are associated with variables in the problem and the edges carry causal semantics. And then, you know, I could specify a statistical model. I'd have to make some assumptions. And then I could carry an inference within that model to try and understand the structure. Of course, you know, these kinds of models have real issues around identifiability. Generally speaking, you can only Generally speaking, you can only identify to an equivalence class. There are all kinds of subtle issues to do with how you integrate observational, interventional data, etc. So, this type of approach, this sort of, let's say, more statistical approach, is one that we've worked in for many years. And I just show you sort of some, just a sort of personal history in some ways and things that we've worked on in the past on sort of using linear and non-linear models, modeling interventions, you know, inferring multiple networks simultaneously, etc., etc. And, you know, And one of the key things in this area is that it's very, very difficult to really test the assumptions underlying these methods. So assumptions, you know, maybe on latent variables or on model specification and things like that. And so empirical assessment is really important. So in a particular setting, you'd like to sort of convince yourself that the modeling approach actually works. And so that's something else we've paid some attention to. So how do you really check empirically whether something is well? Whether something is well behaved. So that's a little bit of sort of a very, very brief look at how standard sort of statistical causal structure learning works. And again, you know, the key emphasis here is on setting up, you know, these sort of forward models that you then try to invert to get the structure. What I'd like to do now is sort of change direction and sort of show you how you can reframe this type of problem. Frame this type of problem from a machine learning type of view. And the motivation here really is the following: that the catch, in a way, with these sort of graphical models and other approaches that I've just mentioned, is that although many of these schemes have beautiful theoretical properties, and you can prove their ability to recover certain structures under explicit assumptions, it's very hard to check those assumptions in practice. In practice, and there are real issues around scaling to very large problems. So, if you have very large numbers of nodes, you know, maybe thousands, as in omics-type problems, it's not so easy to even do, you know, the carry out the inference using these kinds of schemes. In many cases, you know, algorithms just won't run. And so you have kind of real scaling issues, both computational and statistical. And so, I'd like to try and reframe these types of problems from a sort of machine learning perspective. Types of problems from a sort of machine learning point of view and see where that gets us. So the starting point for this is to think of any causal structure learner, so any scheme that is outputting this graph that is meant to have carried causal information as a maping from a data space X to a graph space G. So that's what's shown in the first line here: G hat. So the idea here is. Here is Ghat. So the idea here is that if you had, so to give one example, you know, we've in the past worked on things like, you know, elaborate schemes where you have a non-linear ODE trying to sort of explain some chemical reaction, and then you try to determine through that scientific model, you know, where the edges in the graph are. Now, that's an elaborate scientific story that leads to some claim about A causing B, but whatever the pipeline, you could view it as a mapping from some data that's input to the algorithm. That's input to the algorithm out to a claim about the graph structure. So, in that sense, from x to g. And so, the idea is that essentially any causal structure learning could be viewed this way, whether it's based on a scientific model or some statistical tool or some machine learning approach. So once you have that perspective as a mapping from a data space into a graph space, it's natural to ask the question: how good a mapping is J-Hat? Is this an effective mapping to the graph space? Mapping to the graph space. And what we did in a paper a couple of years ago, so this is with Marko Eigenmann and Marlus Mathas, was to try and look at this from a sort of expected loss risk point of view. So the idea is that the expected loss associated with this causal structure learned G had is the expected value of a loss. So that's the function L that compares the graphical output G had with Output G hat with a true data generating causal structure G star. And the data that's fed into G hat, so that's on the right-hand side, that X has a sub H and N because the data that's fed into the estimator is obtained under certain specific causal regimes. It might be observational or it might be under certain interventions, and those regimes are collected in this. Are collected in this term H. N is then a vector of sample sizes for the different regimes. So the reason it's important to have both of those terms in there is because, of course, the efficacy of a particular estimated jihad is going to depend on the kind of regimes and the amount of data you have available. So you might have a particular workflow that works very well if you have enough interventional data or enough data under certain conditions and less well in other regimes. So in other words, In other regimes. So, in other words, looking at this risk function, you see that the sort of performance efficacy is in general going to be sort of not one size fits all, but will depend on these factors. So, the optimal mapping will depend on these factors. And this notion is, of course, very, very familiar from normal regression, machine learning, and so on, where you have no free lunch theorems and so on. And so, we're very familiar with the idea that in a particular setting, there might be a function that does particularly well at mapping. Particularly well at mapping, and in other words, a different one. I have a couple questions. Sure. I'm sorry, I can't. Yeah, so now I can ask my question. So my question is, do you consider the regime age to be data dependent and random? No, mostly we'll consider the regime age to be fixed by. Consider the regime age to be fixed by experimental design. So that in a given setting, there'll be particular regimes that happen to be accessible or that were included in the design. But you could extend this framework towards a more sort of active learning sort of scheme where you populate the set age with regimes that you expect to be informative, given the model you have up to that point. So you could extend these kinds of schemes. And in fact, there are a couple of recent papers sort of in that direction where you sort of Paper sort of in that direction, where you sort of pick an intervention, say, to maximize information gain, given the model you have up to date. But throughout the rest of the, I'm going to assume that H is fixed by some design choices. Thank you. Sure. And so, yeah, so once you have that risk function, the natural thing to do in a sort of standard sort of machine learning scheme would be to take a sort of adaptive approach where you come up with a function f that minimizes and That minimizes an empirical analogue of this risk, you know, subject to some constraints. And so, once you look at it from this point of view, which is in a way sort of discriminative rather than generative, you know, this opens the door to using all kinds of scalable and more automated machine learning tools to do this mapping. So, you know, this now looks like a sort of familiar type of problem. One immediate point to note here is that. Point to note here is that this scheme of trying to find some function that does a good job of mapping to the graph space is limited relative to a sort of the fuller causal learning that you might get if you really model the structured equations and things like that. The reason is that even if such a scheme was successful, all you're able to do is make claims about the structure of the graph. You don't sort of get access through that to all the objects like post-intervention distribution. Objects like post-intervention distributions and so on. So, in a classical causal learning framework, you know, at the end, you have access to all of this stuff. But here, you know, all you're getting is the graph structure. And so, the idea here is you give away some depth in a way. But the hope is that then you can sort of scale to challenging circumstances. Okay, so with that, we can now sort of. That, we can now sort of make a problem statement. The problem statement is the given some data X on variables in a set B and some background information pi that tells us at the beginning the causal status of some of these variable pairs. So we know at the beginning that A causes B or C causes D. And that could either be from scientific background knowledge or from interventional experiments that were carried out in the same system. Given those two elements, we then want to learn causal relationships between all the other. And causal relationships between all the other pairs. So, we want in the end to be able to make statements about all the pairs of variables in the system. And, you know, of course, the assumption here would be that these sets T and T prime are disjoint. So you don't have any prior causal information available on the pairs of interest. So if your query in the end is, does C cause D, the assumption is you don't actually have the intervention on C that might allow you to read off that statement, right? So we're very much in that regime where you're generalizing. That regime where you're generalizing to sort of new interventions. The meaning of the edges in this sort of scheme would depend on the meaning of the information in pi, because we're going to learn patterns, you know, based on a machine learning scheme. Depending on the initial patterns that you sort of feed the machinery with, you're going to learn different kinds of structures. So the semantics will depend on the problem setup rather than being inherent to a generative model. Okay, so the first scheme I'd like to show you that's sort of within this general framework is called Manifold Regularized Causal Learning, so MRCL. And so the details are in a JMLR paper from a couple of years ago. So this was with Steve Hill and others. And what this amounts to is basically minimizing that empirical analog risk function in a semi-supervised framework. So the idea is that The idea is that the causal edges that you know the status of are the known labels, and the huge number of edges whose status you don't know are the missing labels. And so the semi-supervised idea is that you construct a featurization that applies to all pairs. And then for the pairs where you know the label, that's the labeled case. And for the large number of pairs where you don't have the label, you have to. Where you don't have the label, you have some data, but you don't know whether they're causal or not. So that's why it's semi-supervised. So you have in the end a setup where you have a large number of objects without labels and a smaller number of objects with labels. And then you'd like to sort of propagate the information. So this is in this particular paper, this is done in a very classical semi-supervised framework where you essentially penalize neighboring points in the feature space. Points in the feature space that have the label moving too quickly, in a sense, right? So you don't want that neighboring points in the feature space should have different labels. And so the learning scheme amounts to sort of learning a function that achieves that. And yeah, what I'll show you now is some empirical results from MRCL. And these compare MRCL with a number of existing methods, including PC, GIES, RFCI, etc. GIS, RFCI, et cetera. If you're familiar with these, these are all different kinds of causal learning methods that make different assumptions. Some of them assume no latent variables, some of them allow for latent variables. And the comparisons are not always one-to-one because these different schemes sort of require different inputs and have slightly different outputs. But we've done the best job we can to sort of make a fair comparison. And the real data here that I'll show you results from are yeast knockout data from the Hallsteader lab. So these are very well known. So these are very well known in the sort of causal field where you know these are large-scale experiments where you knock out genes one at a time and then keep track of the transcriptome under each knockout. So they're very convenient for studying these kinds of problems because you can sort of, you know, you can treat the gene knockout experiments as new regimes. An important point here is that in all the empirical examples you'll see, the model Examples you'll see, the model claims, whatever the method, are always tested against entirely unseen interventional experiments. So that means that the data that's fed to the models never includes an intervention on the edges, you know, on the nodes whose edges are going to be checked. So if I'm going to check a claim A causes B, I won't have the intervention on A in the data that goes to the model. So here's one curve for a small problem with video. One curve for a small problem with 50 variables. And what's plotted is a kind of causal area under the curve. So this is, you know, think of constructing an ROC curve, but where the labels are the sort of the true edge status in the graph as obtained from the interventional experiments. And, you know, so the area under the curve has the usual interpretation. And the horizontal axis is the amount of label information provided at the outset. Did at the outset. And what you see here is that MOCL certainly does better than both some of these classical methods like IDA, but also than just doing regressions or correlations and so on. And it's not surprising, by the way, that IDA doesn't work very well here because this is a setting where we're looking at 50 genes, which are just randomly sampled from the yeast genome, meaning that. The yeast genome, meaning that there's a huge amount of latent variable sort of action going on here. So it's not a particularly sort of friendly setup in some ways, but nevertheless, MRCL is able to detect something and at least do better than random. The catch with this scheme is that it doesn't really scale to higher dimensions because it turns out that the computational demands of that manifold learning scheme become pretty severe if you have very large numbers of objects. If you have very large numbers of objects. Now, imagine if you wanted to solve a genome-wide problem. You end up having a sort of genome-by-genome matrix, so a very, very large number of objects. And this is difficult for the sort of scheme I just described. So what I'll show you next is the scheme that gives the title of the talk. And this is basically replacing the manifold learning step with a deep learning architecture F. So this is going to sort of map the data to the graph. You know, the data to the graph space through a deep architecture. And the reason this is attractive is because the computational burden is dominated by learning that mapping function f. But once you've learned it, it's rather easy to run it over large numbers of pairs. So this scales very well to large problems. A key observation is that the featurization that's used here is asymmetric in the sense that it's Asymmetric in the sense that it's not the case that the feature for the ordered pair i to j is the same in general as the feature for the pair j to i. That's very important because in causal learning, you want, of course, these directed claims. You want to be able to say that A has a causal influence on B, but perhaps B doesn't on A. So, if the features were the same for both directions, then you'd be doomed to learn a symmetric object. So, you don't want that. that um and so there's a kind of there's a sort of um uh these this architecture is not invariant of that kind of flip um so the graphically the way the architecture looks is the following there are two arms one is a is a cnn type approach that runs on um kdes of bivariate distribution so these are these are sort of you know you you take the data for a pair of interests and there are some other channels that And there are some other channels that do a few other things, but essentially it's using that as information on distributions that you can see in the data that you have. And the other side is a graph neural network that's operating on the graph structure. So it takes a seed graph, which we call G-hat zero, and then it does operations on the graph structure itself. So the main difference between the two arms is that the lower one is operating on the data, whereas the upper one is operating on the graph, and then the things are merge to give an output. To give an output. And so, in notation, what this amounts to is that you're labeling these causal edges using the output of this neural network with parameter theta. And so this is just spelling out what we just looked at. But the key point here is that at the end, you now have output that covers all pairs, including those for which no interventional data was available. So you can now test against entirely unseen. Against entirely unseen interventions using the output of this scheme. So that's what's shown here. So this is a larger scale problem with a thousand variables. And we've plotted the ROC curves. So these are true positives and false positives with respect to these causal structures. And you can see that there seem to be substantial gains from using different flavors of this deep approach versus IDA, LV, IDA correlations, etc. And I won't go into sort of different flavors of the And I won't go into sort of different flavors of the deep schemes, but these first few of different combinations of GNN and CNN with different seeding schemes, etc. So this seems quite effective. And I emphasize, you know, this is a regime with a thousand variables where we can't even run MRCL, so the manifold regularized causal learner. We then went up to a more or less sort of whole yeast genome example. And so this is 5,000 genes. And there's not really a drop. And there's not really a drop in performance. So it's sort of able to cope with this relatively large-scale problem. And again, this is a regime where it would be very, very hard to run something like a DAG estimator or, you know, a lot of the graphical models-based tools will be very, very tough to make work here, leave alone things based on non-linear, you know, sort of chemical models and things like that. So, this is nice in terms of scalability. One of the concerns is. One of the concerns is that this kind of scheme, because it's doing machine learning and it's using input labels, that it might be very sensitive to that. So we did kind of experiments where you perturb the labels, where you artificially corrupt the input information going into the network to see what happens. And so these are the orange bars a performance with labels that are perturbed in the sense that 10% of the input causal information is corrupted. So if A causes B, we correct. So, if A causes B, we corrupt it and say, well, A doesn't cause B to sort of mislead the networks. And so, you see that they're sort of reasonably robust. So, you'd have to do a lot of input corruption to really damage the output. So, that's an important point, I think. Okay, I think I'm pretty much out of time. Let me wrap up here before taking questions with a few conclusions. So, causal learning is a and remains an enormous challenge at the sort of intersection of AI. Enormous challenge at the sort of intersection of AIML stats in various applications. In the biomedical context, of course, this is a, and I think I need to emphasize this to this audience, that it's a sort of key issue to be able to learn in the end causal molecular networks that are specific to particular diseases or particular strata and so on. And so we need to be able to do this sort of going forward in a data-driven way. Graphical model-based approaches are powerful and elegant, but they do face challenges in certain large-scale applications. Challenges in certain large-scale application settings. So, what we've done is reframe this as a kind of AI-type task, and it turns out to be useful in terms of scalability, albeit at the cost of giving output that's less rich than a full causal model. And so the results so far are promising and to what we're doing next, pursuing various applications in cancer, brain diseases, etc. So, I'd like to thank you for your attention and be very happy to take any questions. Any questions? Thank you very much. We have time for one quick question. Does anybody have a question right now? Are you able to stay for the discussion that is happening at the end of our morning? Dr. I'll be able to join you then. Taking a look. Anybody online have a question? Yes, okay. My question, very nice talk. My question is about how do we learn from this ECE data about whether these assumptions hold or not. Can we draw any conclusions about those based on the empirical studies on EACE data? Yeah, that's a great question. So it does look as though some of the sort of traditional schemes run into difficulties. So in terms of whether the scheme So, in terms of whether the schemes I've been discussing here, whether the fact that they work on yeast data implies that they work, say, on human data, I think this has to be studied empirically. It may well be that there are factors that are different between different organisms, different genomes, and so on, that make it more or less challenging in different settings. So, I think one of the things we're going to need to do in the next years is really try these kinds of schemes on different kinds of. Different kinds of interventional data and different kinds of regimes to really empirically test that. But I don't know. I don't know whether these kinds of schemes will work in different settings. We'll have to find out. Thank you.