Okay, so that should be working? Yes, looks good. Okay, great. So the plan is that I'll have my iPad on the right that I'll write some more on as I go along, and then the screen on the left will have the same thing, but just so I can have another page of, like the previous page as we go through. So thanks, everyone, for coming, and thanks. So thanks everyone for coming and thanks to the organizers for organizing this great summer school and for inviting me. So I'm going to be talking about uniform spanning trees and with a particular focus on the high-dimensional case. Actually today I'll mostly be talking about sort of general background on the uniform spanning trees that's not so particular to the high-dimensional case and then we'll get more into high-dimensional things. Things tomorrow. So we'll start by looking at sort of the definition and the various sampling algorithms that we have for the informal spanning tree. And these are very important for us, not only if we actually want to sample them, but also theoretically. So these sampling algorithms give very close connections between uniform spanning trees and random walks that we then use to prove things about the spanning tree. About this mounting tree. So let's start with the basics. So we'll start by just looking at finite graphs. So we'll have a finite connected graph G. Now, if I have a finite graph G, I always have a finite set of spanning trees of the G. So what is a spanning tree? Well, it's just a connected subgraph of the graph that spans, i.e., contains every vertex. Vertex and it doesn't have any cycles, i.e., it's a trick. So it's just a tree that spans inside G. Okay, and of course, every finite connected graph has a spanning tree, and there are at most finitely many because they're at most finitely many subsets of the edges. So it makes sense to talk about a uniform spanning tree as just a uniform random element of the set of spanning tree systems. Now, of course, that's a definition, but why should you care? But why should you care? Well, there are actually quite a lot of reasons to care about uniform spanning trees. So they turn out to be very closely connected to many other interesting models in probability. Most notably in these lectures will be loop-resp and random interlacements, but there are many other things as well. So, for example, dimers and L2-Betty numbers, and the abelian sandpile model is a And the abelian sandpile model is another good example. So, in fact, I probably won't really talk about it due to lack of time, but the results that I'll tell you about high-dimensional spanning trees can be also used to prove similar results, for example, for the high-dimensional abelian sandpar. Okay, so this is a model with many connections to other things that people care about in probability. For me, maybe the main reason to be interested in the model. Me, maybe the main reason to be interested in the model is it's kind of a non-trivial example of a statistical mechanics type model that is nevertheless much easier to analyze than basically every other statistical mechanics model, particularly in dimensions larger than two. Okay, so what does it mean to be a statistical mechanics model? It's a bit vague. I don't think that uniform expanding trees really arise in any physical context that I'm aware of, although they're related. Context that I'm aware of, although they're related to these other models, which maybe do describe really real physical things. But that's sort of not the point. The point is that it gives us a setting where we can explore and understand a kind of model example of a statistical mechanics model that we can actually prove things about. And this has been very productive. So, you know, most notably, Odo Tram developed the theory of SLE. The theory of SLE, really, in his effort to analyze this example. And you know, this was the uniform spanning trees and the closely related loop over and walk were really the first things that motivated the definition of SLE and also that were proven to converge to SLE in two dimensions in Unit. Now we also know that many other things do, but this is really the seed of the idea. Also in three dimensions, Also, in three dimensions, the uniform spanning tree remains a rather mysterious object, but nevertheless, we understand it much better than basically any other critical three-dimensional model. So, for example, in particular, it's now known that the scaling limit of the 3D loop rates, sorry, the 3D uniform spanning tree is well defined. This is a very recent theorem from this year or last year. This year, or last year, well, several people who were in the call. So, Angel Croydon, Fernandez-Torres, and Shereishi. And this is based on this earlier results of Gaudi Cosmo, which says that Luke Ray's random walk has a world of landscape. So, there are a huge number of open things. There's still a lot more we'd like to understand, but nevertheless, we know way, way more than we know about basically any other sort of non-trivial critical model in 3D. Critical model in three-dimensional. And similarly, you know, the story I'll be talking about here is the high-dimensional setting, and we'll be interested in proving the sort of mean field behavior in high dimensions and looking at logarithmic corrections in four dimensions, things like that. And I'll come back to this in more detail later. But that's sort of the big picture motivation for the story. So, you know, when I just write down this model, we have the definition, but it's not clear that it ought to be a tractable model. I mean, there are many similar things I could write down. For example, if I pick a spanning forest rather than a spanning tree uniformly at random, the definition seems equally simple, but in fact, that model is extremely hard to study, and there are very few things known about it. On the other hand, the uniformly It. On the other hand, the uniform spanning tree has lots of special properties that connect it very closely to random walk and will let us prove things about it. And these connections are best illustrated through the sampling algorithms. So let's imagine we have a graph and we want to choose a spanning tree of a uniform neighborhood. Okay, so one way you might think to do that, which is maybe one of Might think to do that, which is maybe one of the most obvious ways you could think of, is via some kind of Markov chain Monte Carlo. So you set up some kind of Markov chain on the set of spanning trees, which has the uniform measure of its station distribution, and then you run that for a long time. You'll at least get an approximate sample. Now, it turns out for the spanning tree, there's a good way to do this via what's called the Markov chain tree theorem. So what we do is as follows. So we take our finite graph G. Follows. So we take our finite graph G and we define a Markov chain on pairs X T. So Xn Tn will be the state of the Markov chain at time n. And it's going to take values in the product of the vertex set and the set is boundaries. Okay, and the way it evolves is as follows. So the first coordinate is just doing a random. So in other words, if I give you xn and tn, then to take, to find xn plus 1, you just... To find xn plus one, you just pick a uniform random edge emanating from xn and you move xn along. So xn is just doing a random walk, and it doesn't care what t is doing, it just evolves as a random walk. Now on the other hand, we're going to, given xn and tn and xn plus 1, we're going to compute tn plus 1 via a deterministic procedure. So this sort of Deterministic procedure. So, this sort of random walk is kind of driving the Markov chain, and the tree is going to be updated as a function of it. And the way we do this is: well, we're going to try to force this edge xn x plus 1 into the tree. Okay, so we can imagine doing that. We have some spanning tree t here, and we have some new edge that we'd like to force into the tree, xn plus 1. Now, there are two things that can happen. One thing is that this edge. Happen. One thing is that this edge we're trying to force in was actually just already in the tree, and that's fine. We just define tn plus one to be equal to tn like it. So we just do nothing if the edge we're trying to add is already in the tree. Otherwise, what happens is we, when we add this edge, we create a cycle, right? Because we had a tree. If we add any extra edge, we're definitely going to create a cycle. And in order to fix this and get the tree again, we have to delete an edge from the tree. Have to delete an edge from the cycle. And the way we do that is we delete the other edge in the cycle that's adjacent to xn plus 1. So in this example, we have this tree here, we add this edge, and then this edge here is going to be deleted to get the new tree of TM positive. Okay, so this is a well-defined operation, and we call this Markov chain xn. This Markov chain XNTM, the UST chain on the graph. Now it's a non-obvious but fairly elementary fact that this markup chain does what we want to in the sense that if you run it for a long time, you will get approximately a uniform random spanning tree in the second coordinate. Okay, so more precisely, the Okay, so more precisely, the Markov chain tree theorem, which is a kind of folklore theorem, by the way, I don't really know that there's no standard person that this is attributed to. It says that the unique stationary measure of this Markov chain is the product measure where the first coordinate I just choose the vertex according to the stationary measure on the graph, i.e. proportional to its degree. Highly proportional to its grain. And then in the second coordinate, I take a uniform spanning tree. Okay, so in particular, it says that this mark of chain is irreducible. So it has exactly one stationary measure, and it's this product measure. I should mention, by the way, that in this part of the course, I'm not going to show very many proofs, but if you would like to see proofs of these things, Of these things. One place where you can find them in basically the same development that I'm showing here, but with more details, is in the lecture notes that I have available on my website. If you want more background on the uniform spanning tree beyond that, Lines, Paris, Probability on Trees and Networks is also excellent resource. Okay, so that's one way of sampling, or at least approximately sampling. Approximately sampling aspect. Now it turns out that you can take this sampling algorithm, the Markov chain tree theorem, this MCMC algorithm, and in fact turn it into an algorithm for exact sampling. Okay, and this is what's called the Albert Spreger algorithm. And you can think of this as a kind of a primitive version of coupling from the past or an instance of coupling from the past. Or an instance of coupling from the past. It was discovered before the general phenomena of coupling from the past was, but it is sort of an instance of it. So how's this going to work? So again, we take a finite connected graph G and we're going to take a random walk on G. So again, random walk on G, it's just at every time step it's picking an edge uniform. Time step, it's picking an edge uniformly, emanating from where it currently is and jumping on there. Again, we can start this from any vertex we like. Now, what we do, for each vertex v of x, we define this thing here, e v x, to be the oriented edge that is crossed by the round walk as it enters v for the first time. Okay, and note that this is defined. And note that this is defined for every vertex other than the starting points. Of course, the starting points, you don't cross any particular edge from the first time. And we define AB of X, so AB for Aldus Broder, to be the set of the reversals of all these edges. So every time we enter a vertex for the first time, we look at which edge we used to do it, and we include that oriented edge backward. Edge backwards. And the theorem of Haldus Produs says that if you do this, then start when you start the random walk at some vertex v, then this function abx of x is in fact a uniform spanning tree of g. And it's oriented towards the starting vertex. So every edge has an orientation so that the head is closer to v than the tail is. Okay, so if I have a tree and a vote. So, if I have a tree and a vertex, I can always orient to the vertex. So, this seems like kind of an amazing thing. It's not too hard to see that this collection of first entry edges will be a spanning tree. That's actually true point-wise. If I give you any path that covers the graph, it doesn't have to be a random walk, and I compute this function of it, I will get a spanning tree. It seems a priori that there's no It seems a priori that there's no reason whatsoever that I should get a uniform randomness factory if I take a simple random walk and apply this procedure to it. But in fact, you do. This is sort of the starting point of all the many sort of magical, miraculous things that occur when you study the last time. So let me briefly outline how you prove that the Aldersproderatham proves that the Aldersproder algorithm works. Sproder algorithm works given that you know the Markov chain tree thing. So, this is how it works. So, what we do is we consider a doubly infinite random walk on the graph. So, what this means is I take x0 to be distributed according to the stationary measure on the graph, and then I take the positive and negative parts of the random walk to just be independent simple random walks as well. Okay, now. Okay, now it's a standard thing, but it's not too hard to verify that if you do this, if you take this double infinite random walk, then it's a stationary process. So if I shift time, the distribution of this sequence of locations doesn't change. Okay, and that's obviously to do with the fact that we took x0 to be distributed according to the stationary random walk. Okay, so take this double infinite stationary random walk, and now do the following. Random walk, and now do the following. So, for each n, we define en of v just like we did before. So, for every vertex, the vertex is entered for some first time after time n, and we write down env to mean that edge. But dually, we can do the same thing with the last exit edges. So, for every vertex v, I should say. Vertex V, I should say these are both defined for V not equal to Xn. Okay, so if V is not equal to Xn, then there's some last time where you entered it before time n, and then you look at which edge used to exit. Now, what you can do is you can suppose I look at this pair. A pair of random variables. So I have xn and I have this collection of all the last exit edges. Now, if you look at what happens when you do this one step in the future, you'll see that you're actually doing exactly this computation that we did when we defined the UST chain. So, you know, the first coordinates just The first coordinate is just doing a random walk, and the second coordinate is being updated exactly according to this algorithm where we force the edge to be there, and then we break the cycle. So you can verify that these two definitions, this one and the one from before, are actually doing exactly the same. So this is just the US teaching. Except the way we've defined this, or at least it's evolving, the transition probabilities. Evolving the transition probabilities are the same as USCG. But this double infinite random warp was a stationary thing, right? And here we're just computing some function of it that's defined in a translation invariant way. So that means that this process here must also be stationary. But if I have a stationary process that's evolving according to the transition rules of some Markov chain, then it must be modular. Its marginals at one particular time must be just the stationary measure of that Markov chain, right? So that means that we apply the Markov chain tree theorem, we get that this pair of random variables must be distributed as this product measure of the station measure on the graph times the uniform spanning tree measure, right, for every M. Okay. But on the other hand, by reversibility of the Random war, you can check. You can check that this guy that we defined in terms of last exit edges actually has the same distribution as this guy defined in terms of first entry edges. Just because everything is sort of invariant. If I flip time, nothing changes in distribution. And I apologize that my E is an L's look quite similar, but this is an L and this is an E. By the way, I actually can't see the chat, but my handwriting is not always. My handwriting is not always that great, so if there's anything that cannot be read, please don't hesitate to let me know. So this is actually the proof of the other spreader. If you want to do it formally, there are not really many extra details that you want to use. So one very nice corrosion. One very nice corollary of the Elder Sproger algorithm is that the parts in the uniform spanning tree are distributed as loop-raised random walls. So let me tell you what that means. And I apologize, I'm going to use the same notation L again, but it doesn't mean the same thing as in the previous grip. So suppose I give you some path in a graph. You have some path in a graph. And for the loops, I'm going to define the loop region now. And this is going to be well defined provided either the path is finite or it can be infinite as long as it doesn't visit any vertex more than finite demand. So we call these transient paths, so that allows finite or infinite, but not visiting any vertex. Okay, now what we do is we define Okay, now what we do is we define a sequence of times recursively by setting L0 to be zero, and for each n, ln plus one is one more than the last time that you revisit where you are at l okay and then we define the looperasure of x to be this path in the graph that you get by taking x at time 0, L1, L2, and so on. L1, L2, so on. Now, this is the formal definition. The way you would usually describe it is that you say that you erase loops chronologically as they're created. So, let's see an example of that. So, suppose I give you this path on the right, on the left, sorry. Okay, so what's going to happen is I'm going to follow this first part along, then I'll keep going around here. Then I'll keep going around here, except when I get here, I come back on myself. So you could imagine if these are the sort of different steps of the random walk here. For the first few steps, ln is just going to be equal to n. Then I get to this one. And now I revisited later times. So I'm going to erase this whole part of the walk, and then I'll carry on like this. I'm not revisiting myself. I'm not revisiting myself, I get to here. This gets revisited later, and then I keep going like this. So, if I take this path on the left and loop raise it, I get something like this. Okay, so in a more complicated example, what's going to happen is I'm going to first do this bit, and then I'll come back here, and that bit will get erased, and then I'll keep going. Tool here, and now notice that I did actually intersect the path here, but I intersect a bit, I intersected part of the path that I already erased, so it doesn't matter. This doesn't get erased. Then I do this bit, I come back on myself, so it gets erased. And then I finish the path like that. So this path gets sent. So the loop raisier of any path is going to be a simple path. It's not going to revisit the same buttons. Now, it turns out when you compute the Albertus Productor algorithm, if you run the Albert Sproder algorithm, then you compute the path between two vertices. Between two vertices, you're doing almost the same operation as those. So let's see an example. So suppose this is some vertex V and I want to know what the path in the uniform spanning tree to some other vertex U looks like. Right, so what happens? First of all, I only have to run the random walk up until it hits U for the first time, and that's actually already going to determine what the path from U to V in the tree is. From you to be in the tree is. Okay, so suppose, let's say I take this same example here. D. Okay. So what happens when I compute the ALBAS program? Let's say I add some new vertex vertices so you can see what's going on. Okay, so every vertex is going to look at the edge that the random walk uses to enter for the first time and put an oriented edge there. So zoom in. So this edge, this one picks this one, this vertex picks this one, this vertex visited for the first time along this edge, this one this edge. This one, the search song. I don't add the edge here because this one's already been visited. Okay, and then this one. This one's already been visited, so I don't add anything. This one's already been visited. So I don't add anything. This. Okay. Now, if I follow, if I want to find the path from u to v, I know that I just have to. U to v, I know that I just have to follow these arrows starting at u until I get back to v. Okay? So let's see, go here, go down here, and now you might think, well, I just said something about these paths being loop raised around the walks, but this path is not the same as the one that I got before. But in fact, it is a loop raised. But in fact, it is a loop raised random walk, but it's the loop razor of the random walk where I've reversed the time. So I have to, if I want to compute the path between u and v after I apply the Alders-Broder algorithm, what I do is I run, start the random walk at V, run it till it hits U, but then loop raise the backwards version of the part. And you can check that if you do that, then Check that if you do that, then the definitions work out, and it's really the same thing: computing the path in this oriented forest using Albert Sproder and just loop raising the backwards path. Okay, so that's summarized by this statement here. So if I apply the Albert Sproder algorithm to X, the path from starting point to V is equal to the loop ratio of this path here, where it means I run. This path here, where it means I run the random wall until I first hit v. So just to change, this is x0 in this notation, and this is v. So I have to run the random walk till I hit v for the first time, and then I flip the whole path, and then I compute the equation. But it's a fact, it's a combinatorial fact due to Lawler, it says that in fact. It says that, in fact, distributionally, the loop praisure of the walk and the loop praiser of the flip walk are the same. So point-wise, the statement is about reversing time and then applying loop praisers. But in fact, the distribution of the path that you get is the same. Okay? So if you put these facts together, you get exactly this corollary that I claimed that the parts in the informed scale tree are distributed as Libra's rather. Distributed as a good praise random. Okay, so more formally that means if I want to know, if I want a sample of just the path between u and v, I can start to run and walk at u, run it till it hits v, and then do crazy. That has the same distribution as the path in the triple. Perhaps seeing as we're half past, I can take this. Half past, I can take this two-minute break in case anyone has any questions. Sounds good. So if there are any questions, please ask on the chat at this point. And if not, we just take a quick break and then continue. Uh By the way, so what's the so how old is this Markov chain result? So you said it's not clear who to attribute this to, but I I guess the early eighties are older. So I do you remember what Alderson Broader say about this in the paper? Say about this in the paper? I'm not sure. There are a bunch of references in 90s pairs that discuss this. But it's one of these things where you can find the earliest papers that you can find, but they don't claim to be the originators of it. Right. Oh, there is a question in the chat. In the chat? Yeah, so there's a question about this cycle breaking thing. So the answer is no. So you don't choose it randomly. There's always exactly one way. Oh, I see what you mean. Yeah. So if you have a multi-graph, it just means you have to define the random walk differently. So if you have a multi-graph, you have to think of the random walk as, for example, a graph homomorphism from a line. A graph homomorphism from a line graph into the graph. So the random walk should have this extra information of actually which edges it's crossing, as well as just which the sequence of vertices. But for the purpose of these lectures, I'm just going to assume the graph is simple because then you don't it really only changes things notationally. So I hope that answers the question. So, should I should I start again? Um yes, I think we can continue. Okay. Um so so we've just seen um the other spread of algorithm this corroborate that the Algorithm and this corollary that the parts are distributed as loop arrays random walk. So, what I'll show you next is Wilson's algorithm, which somehow directly builds the uniform spanning tree out of the loop raised round board. So, I should mention David Wilson in his original paper, he proves this, he gives a direct proof that this algorithm works. What I'll show you is a deductible. Show you is a deduction of Wilson's algorithm from the Elt's program. Okay, so again, this is really a magical thing that this algorithm works because it seems like it has no right to work whatsoever. So again, we'll have a finite graph and we'll enumerate the vertices v0 through to vn. Okay, so what we'll do is we'll build up a sequence of trees. Sequence of trees iteratively. So we start by taking the tree that has one vertex, v0, and no edges. And if we're given Tn, what we do is we start a random walk, xn plus 1 from vn plus 1, independent of everything that's happened so far, and we run it until we hit the set of verses that are already included in Tn. Okay? And then we define Tn plus And then we define Tn plus one to be the union of Tn, i.e., this part of the tree we've already generated, and the loop raiser of this stopped random wall. Okay, so what Wilson's theorem says is that if you run this n step so that you include everything, then what you get is distributed, is actually a uniform spanning tree. Okay, so it's sort of obviously a spanning tree. A spanning tree, amazingly, it's a uniformly random spanning tree, and this actually happens no matter what the enumeration is as well. So, we're free to choose whatever enumeration we like. We always get a uniform spanning tree. I should mention here that if bn plus 1 was already in the tree, this walk is going to be stopped at time 0, so you don't actually do anything with this. So, let's just see an example of how this works. See an example of how this works. So, you know, first I have v0, then I have v1, so I run this random warp until it hits v0. And then I compute the loop ratio of that, which I'm not going to do because I made the drawing too complicated. Maybe it's not too bad. And then we add that part. And then we add that path to the spanning tree. And then we start at v2 and we run. Maybe we go and hit this path first, but we don't care. We wait until we hit the loop race path, and then we add that, and so on. Okay, and so I actually have a video you can see of doing this on a square grid. So this video. So, this video is due to Mike Bostock, and he has lots of great simulations like this on his website. So, you can see the part of the tree that's already generated is in the right, and this pink path is the loop race running walk, sort of as running until it hits the set that's already been added. We can see that this potentially takes quite a long time. The first few steps are kind of heavy-tailed, and I pre-recorded this one because it runs in a reasonable amount of time, but sometimes it takes much longer to generate the first few steps. So if you want to generate fresh ones, you can So, if you want to generate fresh ones, you can do it on this website. Okay, cool. So, what I want to tell you now is we're going to see how we can actually deduce the validity of Wilson's algorithm and this theorem from what we just saw about just the statement that one path is a literature on the walk. And actually, this is not too hard. It's just going to be a consequence of this fact, together with what's called the spatial Markov property of the uniform spanning triple. So what the spatial Markov property says is that, suppose again, as usual, I have a finite graph, blah, blah, blah, and I take some set of two sets of edges A and B. It's a mocker property that says that. It's a mocker property that says that if I condition on every edge in A being in the tree and every edge in B not being in the tree, then the conditional distribution of the tree is the same as if I take the uniform spanning tree of this graph G minus B over A, where this means I take G, I delete every edge in B, and I contract every edge in A. Okay? And of course I have to add in these edges A, which I already conventionally. Edges A, which I already conditioned were in the tree. Okay. So, in particular, if I just condition on one edge being in the tree, it's the same as just contracting that edge and then taking uniform span tree on this graph with the contraction. And similarly, if I condition on one edge not being there, I delete it and take the uniform span tree for what's left. Okay, and this is something you can prove by induction on the size of A and B. It's an it's an elementary term. So it's an elementary term. Now, similarly to how for sort of Markov chains, there's the Markov property and the strong Markov property, we have a similar thing in this spatial setting where we also have a strong spatial Markov property. The strong Markov property is defined in terms of stopping times. Of stopping times, the strong spatial Markov property is defined in terms of the spatial version of a stopping time, which is what's called a local set. There is a question from. Yeah, so there's a question about whether the sequence V should be fixed at the beginning. In fact, you don't have to fix it at the beginning. You can keep choosing which vertices to use based on what you've already seen. Based on what you've already seen, even there's a huge amount of flexibility, in fact, with Russell's algorithm. I'm just going to focus on this because it's the only thing I need. But these more general statements basically follow from the same group. So, as I said, a local set is going to be like the spatial analog of a stopping time. So, remember, a stopping time for a Markov chain is some random time where Chain at some random time where if I observe the Markov chain up to time n, then I know whether t is less than or equal to n. So local set is similar. So it's going to be a random set of edges defined on the same probability space as the spanning tree, such that if I know what T restricted to some set W looks like, then I know whether this set K is contained in W or not. So formally, we say that the Normally, we say that the event that K is contained in W is measurable with respect to the sigma algebra generated by the restriction of TW. Okay, so an example of a local set is you could take K to be the path connecting U and V. I know that there's at most one path because it's a tree. So if I give you some set of edges, then W, then what case contained in W if U and V are. If U and V are connected inside the intersection of T with W. An example of a set that's not a local set, for example, if I take all the edges which are in the tree and are adjacent to the origin. Right, because if I just give you that set, I don't know whether it's I can't check that that's what I claim to be without also observing some other edges, right? Without also observing some other edges, right? Maybe the other edges adjacent to the edge. So again, you should just think of this as the spatial analog of the stopping tangent. And the strong spatial Markov property is exactly like the normal spatial Markov property, but it allows you to take one of these random sets. So if I have a local set K, and I condition on the value of K and the restriction of T to K, then the conditional distribution. Then the conditional distribution of t, well, I have to add in all the observed edges that I know are open because I saw them in K, which is this K O. And then I take a uniform spanning tree of this same thing as before. So I delete every observed closed edge and I contract every observed open edge. Here I just open and close means whether it's containing or something. Okay. And now you can. Now, you can prove the strong spatial Markov property from the spatial Markov property in essentially exactly the same way that you prove the strong Markov property from the Markov property of the Markov chain. So you just condition on value of K and you sum over all the values and you just check that everything works. And again, all these things I'm going over quite quickly here, you can see in more detail in my lecture. Now, what I claim is that Wilson's algorithm, the validity of Wilson's algorithm, follows from this corollary that I showed you earlier together with the strong spatial Mocker property. Why is that? Well, it tells me that, first of all, you know, I have V0 and V1, right, then I know that the path between V0 and V1. V0 and V1 is a Looper's run. But now this path is a local set, so I'm allowed to contract it. And I get that the rest of the tree is just a uniform spanning tree after I contract this thing. So that means if I apply corollary again. I get that the conditional distribution of path, call this first path gamma, from v2 to gamma is Lucretia's random walk in the contractive graph, right, where I contract everything this path gamma down to one vertex. Down to one vertex. Okay, but that's actually the same thing as just running the random walking gene until you hit gamma. Because until you hit gamma, you just don't, you can't feel the difference between whether you contract gamma or not. And you can see how the rest of the proof is going to go. How the rest of the proof is going to go, you're just going to do induction. So every time you add an edge, there's some part of the tree you've constructed already. The rest of the tree conditionally is the same as the uniform spinning tree when you contract all of that down to one vertex, you apply the corollary, and so on. And you get the Wilson's algorithm work. And, you know, Wilson's algorithm is an incredibly powerful thing. And when, so it was introduced by David Wilson in 1997, I think, and it really sparked a huge boom in the uniform spanning tree industry, where suddenly people could prove way more than they used to. And um and you know this led directly to SLED and so on as well. Um so um so what I want to do next is um briefly tell you how you can use Wilson's algorithm to understand a theorem of P-mantle, which says that there's a That there's a sort of a transition between connectivity and disconnectivity in four dimensions for the uniform standard wave. So P. Bantel actually proved this in 1991, so before Wilson's algorithm was known. It's much easier once you have this. Okay, so in order to discuss this theorem, I first need to tell you about how to define a uniform. Uniform spin trees in infinite graphs. Okay, so suppose I have so the setting I'm going to be in from now on is I'll have an infinite graph which is locally finite, which means that all the degrees are finite, and is connected. So the main example to have in mind is just the hypercubic lattice Z D. Now when I have such a graph, I can take an exhaustion of it by finite Exhaustion of it by finite connected sets. So, this just means that Vn is an increasing sequence of sets. They're all connected and they're all finite and connected, and their union is the whole button set. Now, given such an exhaustion, for each n, I define g n to be the subgraph of g induced by vn. So, in other words, g has vertex set Vn and it has edge set equal to. edge set equal to the edges of G that have both vertices in V. On the other hand, I can also define this graph g n star by taking everything outside of Vn and contracting it down to one big book. Okay, so you can see an example of this here. So here G is sort of the square red, and I have some set V. And I have some set Vn inside it, which I've shaded in blue. And Gn is just the induced subgraph of Vn, so it's just, as I said, it's all the vertices, the green Vn and the edges between them. And then Gn star, I took everything outside and I squished it down to this one vertex of very high degree, okay, which I call data. So what we can do is we define two is we define two different kinds of infinite volume limits of uniform spanning trees. So there's the free uniform spanning forest, which is defined to be the weak limit of the uniform spanning trees of the sequence of graphs Gn, and the wide uniform spanning forest, which is similar, but we take Gn star. So let me remind you what does it mean to have a weak limit in this context? It means that if I take any finite set, then the distribution Set, then the distribution of the restriction of the tree to this finite set. If I fix the finite set, it converges, right? So, for example, if I say what's the probability that some particular edge is contained in the tree, then the limit will be the limit of the probabilities that it's contained in the uniform spinning tree in this finite graph. Now, of course, it's not obvious that these limits are well. Obvious that these limits are well defined, but they do. This is the theorem of P-Mantel. It's actually, this is not particularly difficult, but it takes us down a route, a slightly different route than we're taking to do practically. So in general, we have these two different, potentially different spanning tree measures with different background measures. Background conditions. And they always exist and they're always independent of this choice of exhaustion. So, in particular, that's going to mean that if I take Zd, then these limits are both going to be translation and variant volumes. And in fact, for Zd, these two, the boundary conditions don't matter. So I can take the limits in either way, and I always get the same. Again, this is the theorem of P matter. And this is a very general thing. In fact, most transitive graphs are the same. They turn out to be different if and only if the graph admits a non-constant combined function whose gradient is in L t, which most graphs don't, it turns out. So this is nice. This is nice because probably, if you haven't seen this before, you'll think, well, this definition here with doing all this contracting is a bit weird. But this seems like a much more natural thing to just take the induce subgraph. But in fact, the wide spanning forest is much, a much easier thing to understand. The free, there are far fewer tools available to analyze it. So in cases where they're different, generally we know much more about the y than the free. We know much more about the white than the free. But luckily for us, if we're interested in Euclidean masses, they're just the same. Now it's a theorem of Benjamin E. Lyons, Perez and Tran that there's a version of Wilson's algorithm that works for the wired uniform spanning forests on an infinite transient graph. So I should say in the recurrent So I should say in the recurrent case, so recurrent means that the random walk visits every vertex almost surely, in that case you can do both Aldus Broder and Wilson's algorithm in exactly the same way as you did in the finite case and everything works. In the infinite case there's a problem that if I try and do Wilson's algorithm like I did before where I start with some vertex V zero and then I run a random walk, well it might just never hit that vertex and then it seems like things are not really qualified. Are not really qualified. But this is, in fact, not really an issue. I just have to do things slightly differently. And what BLPS did is they said, you know, you just do Wilson's algorithm rooted at infinity. So you think of the set V0 as being just the one vertex infinity. So there's a question in the chat about the general condition for this equality. So I said this, but let me just write it. So I said this, but let me just write it down to generally it's easier to say first if three is not equal to the wired if and only if there exists a norm constant harmonic H. So harmonic means that at every vertex the Means that at every vertex the value of the function is the average of the values on its neighbors, such that if I sum over all edges, or say x adjacent to y, hx, h y squared, then this is phi x. Okay, so this probably seems like a bit of a weird condition, but in particular In particular, so in particular, if G is an amenable transitive graph, then the two forests coincide. Sorry, then they are equal. Sorry, then they are equal. But in fact, most non-amenable graphs are equal as well. The inequality is related to having positive first altitude betting numbers. So this is something sort of geometric group theorists are quite interested in. For this course, I'll be mostly interested in the Euclidean case. But if you're interested in this, you can look in Lions Paris. Lines powers. Okay, so as I said, what we're going to do is do basically the same thing, except we're going to think about the root being an infinity. So we start by taking F0. So a note on terminology, by the way, is that, you know, I switch from calling these trees to forests. And this is because in the limits, they might become disconnected. So this terminology is not really that great because they're not. is not really that great because they're not really a uniform they're not a uniformly random spanning forest which is another model you consider that's a completely different thing they're really infinite volume limits of uniform spanning trees that may become forests in the limit and we'll come back to this so I'll take f0 to be the empty forest so it has no vertices already now given fn I let as before I take xn plus 1 to be a random take xn plus one to be a random walk started at vn plus one independent of everything that's happened so far and i stop it if and when it hits the vertex set of the forest part of the forest that i've already generated okay now this might not happen you might just never hit in particular this definitely happens at step one because there's nothing to it if you don't hit what's already there you just run for it okay and then as before we take fn plus one to be the We take fn plus one to be the union of what you've already generated at time n with the loop ratio of the new part. Okay, and the theorem of BLPS says that if I define f to be the union of all these partially built forests, then what I get is distributed according to this wide uniform span of forest. In fact, In fact, this is not too hard to check using the definitions. It's an exercise in all the standard facts about weaken voting. Now, I won't have time to go into the proof of this today, but this Wilson's algorithm rooted infinity naturally leads to this theorem of P-Mantel, which says that the uniform spanning forest of Z. That the uniform spanning forest of Zd, so again, the free and wide are the same, so I can just talk about USF. It's connected almost surely if the dimension is at most four, and it has infinitely many components, almost surely, in dimension five and above. Okay. And you can see that this connectivity versus disconnectivity has a clear interpretation in terms of what's going on in this algorithm. Because every time I do another. Because every time I do another step of the algorithm, I create a new component if and only if the random walk that I run doesn't hit what's already generated. Okay, so this certainly happens in step one, so I have at least one component. And then at every subsequent step, if I hit what I've already generated, I do not create a new component. If I do not hit what I've already generated, I do create a new component. Okay, so that's going to mean that. So that's going to mean that this theorem of P-mantle is very closely related to this older theorem of Erdős and Taylor, which says that two simple random walks on Zd intersect infinitely often, almost surely, when the dimension is at most four, but they only intersect finitely often, almost surely, and in particular have a probability positive probability to never intersect when the dimension is larger than zero. When the dimension is larger than there. Okay, so in the next lecture, I'll prove this theorem of Verdish and Taylor and tell you a bit about how we deduce the theorem for the output. I guess I'll stop there for today. So thanks, everyone, again. Thanks, Tom. So at this point, we'll unmute everyone to thank Tom. Everyone to thank Tom