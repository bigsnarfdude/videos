Equations. Thank you very much. You can see my screen without any problem, right? I mean, like, because sometimes the windows with the faces actually casts a shadow. Okay, so thank you very much for the invitation. It would have been nice to finally get to Banff, actually. But in fact, it's not only the pandemic, I'm also detained. Only the pandemic, I'm also detained in the United States at the moment because I'm still waiting for my green card application, so I can't even travel. Okay, so a disclaimer: this is not going to be, it's related to elliptic partial differential equations and parabolic partial differential equations, at least in the sense that some of the methods are coming from or inspired from that field. But unfortunately, the best topic that I had to talk about was hijacked by Matteo Focardi who. Was hijacked by Matteo Focardi, who spoke about it on Monday. Okay, so what is it all about? Let me just actually minimize the windows over here because it's rating troubles to me. Okay, so now it's much better. So we are talking about the incompressible Eudel equations. But the Navier-Stokes equations will actually lurk in the background as a motivation for the problems that I'm going to tell you. So I'm going to write the Navier-Stokes and ordered equations on a period. Stokes and Euler equations on a periodic three-dimensional domain. So the unknown is a vector field, a three-dimensional vector field, and a scalar field, which is the pressure. And of course, the vector field is the velocity of an incompressible fluid. And the equations are the ones over here. So the first equation is given by the conservation of momentum. And it tells you that the advective derivative of the velocity plus the gradient. Plus the gradient of the pressure is equal to the viscosity term. And you see that I put an epsilon over here. This red epsilon is actually positive in the case of Damien-Stokes, and it's equal to zero in the case of Euler. And then, of course, we have the well-known constraint that the divergence of U is equal to zero, which encodes the incompressibility of the fluid. Okay, so these are very well-studied equations. And one of the main players. Main players in the PDE theory for these equations. Actually, some people would even just say that it's absolutely the main player, and that all that has been done is essentially going around this identity, but I don't share this extreme opinion, but certainly it's one of the most important identities. So, if you have a classical that is a regular enough solution, and you multiply the first equation, you start multiply the first equation by u, you derive. The first equation by u, you derive a conservation law, which is nothing else than the local conservation law of the kinetic energy density for the fluid. So you see over here, you have the time derivative of modulus of u squared divided by two, which if you think that the constant density of the fluid is normalized to be equal to one, it's nothing but the time derivative of the kinetic energy density. And that is written in terms of a flux. This is like, you know, the flux, which is Like the flux, which is induced by the advective derivative and the pressure. And then on the left-hand side, you see what is actually happening with the viscosity term. Well, there's something which can still be written as a flux. And then there's a quantity which is negative, which is exactly responsible for the local dissipation of energy when epsilon is positive, when you have Navier stocks. And if you integrate this in time, and here we are in the periodic domains. And here we are in the periodic domain. So, if you're smooth, you can just integrate in time and throw away the divergence terms without worrying about decay at infinity. If you are in an unbounded domain, then you would have to deal with that. So, if you integrate in space, what you will find is that the total derivative of the kinetic energy is dissipated by this quantity over here. In the case of Navier-Stokes, this is going to be positive. And in the case of Euler, since epsilon is equal to zero, that's going to be equal to zero. Equal to zero, that's going to be equal to zero. And so solutions of the Euler equations, which are classical, actually conserve the energy. Okay, so now here is a very natural question that you can ask. If you have a weak solution, which means if you just assume that the momentum equation and the conservation of mass equation are satisfied in a suitable weak sense. And of course, I mean, like as PDE people, we're just used to thinking. As PDE people, we are just used to think about this concept of solution as simply saying, okay, you're a distribution of solution, you multiply your equation by a test function and you integrate by parts. But in fact, from the point of view of continuum physics, it makes a lot of sense. For instance, if your weak solution is continuous, being a solution in our usual sense distributionally is exactly equivalent to actually say that the conservation of mass and momentum laws actually hold for every fluid element. Actually, hold for every fluid element, at least for every fluid region which has a sufficiently smooth boundary. So, now once you have actually these two identities, can you infer the energy identity or the energy say or something somehow for the time derivative of the kinetic energy density, even though you don't have enough regularity? And the very surprising answer, there was a very surprising answer back in 1993 by Schaffer, and the answer is that for And the answer is that for the Euler equations, even if you are in two space dimensions, this is actually not correct. So the fact that you're assuming conservation of mass and conservation of momentum on a sufficiently irregular solution will not guarantee you anything at the level of the energy. And what is maybe even more surprising, and this was a result by Bachmaster and Biko in 2017, is that this is not. Beacon in 2017 is that this is not even true for the Navier-Stokes equation. I mean, the Euler equations is kind of obviously not very nicely behaved because it has some kind of hyperbolic flavor. Anyway, there's like some sort of free transport or transport inside it. But of course, in Aviastok's equation, you would believe it has some of the features of parabolic PDEs. And so this actually, I think, this came as generally as even much bigger surprise than Shepard work in 1993. And Schaffer worked in 1993. And in fact, the Bamax-Derebitol and Vicol paper is in three dimensions, whereas Schaffer's paper is in two dimensions. And of course, we know that two dimensions is slightly much better. For instance, classical solutions of Navier-Stokes in two dimensions exist globally, and even classical solutions of Euler exist globally. But even for Navier-Stokes, the answer is no in two dimensions. And this is an even more recent paper by Cheshkidoff and Louis. Even more recent paper by Cheskidov and Lua last year. Okay, so now the solutions constructed by Scheffer and Backmaster Biebo actually violate uniqueness besides violating the energy identity, and in fact can be even non-physical in a very strong sense, meaning that the kinetic energy can even increase. Now, that's like, you know, if you have energy non-conservation for Euler, since Euler is actually time-reversible, it's obvious that you would. Reversible, it's obvious that you would have even something which increases the energy. But for Navier-Stokes, it's even more puzzling because you can't invert time for Navier-Stokes. Of course, a much more reasonable solution, notion of solution is what you have from Lirais' seminar paper in the 1930s. So, in the 1930s, in three dimensions, Lirais was able in his pioneering work to use the energy inequality to give an existence theory for weak solutions. An existence theory for weak solutions which satisfy, in addition, a weak form of the energy identity. So, in this case, what more or less it satisfies modulo technical details is that the total kinetic energy of the fluid is dissipated as least, I mean, at least as fast as it is dictated by the viscosity term on the right-hand side. So, of course, there is an inequality, so it might even dissipate faster. Okay, so this is this. Okay, so this is like very natural because once you actually have a solution of this type, you are then in the so-called energy space. I mean, you will be uniformly bounded in time with values in L2, and you will be L2 with values in W12, meaning that the total L2 norm in time and space of the space derivative of the function u squared is finite. Okay. Is finite. Okay, so the Schaeffer and Batmaster-Bikl solutions actually do not belong to the energy space either. So, of course, the next question, which is very natural, and you would ask, is if you have Liray's condition, or even if you just have membership in the energy space, can you actually hope that the type of degeneration shown by Schaffer example and Buckmaster Vico or Cheskidov Luo does not exist? Does not exist. Okay, so this in the case of Euler, this was already answered back in 2000 by Schneerenmann and then by Laszlo and myself, by Laszlo Zekaihidi and myself in 2007 in the case of two dimensions. And the answer is again, no. I mean, even if you impose a Liray type condition for Euler, that in that case, of course, epsilon is equal to zero. So you would just impose that the energy, that the kinetic energy is decreasing. That the kinetic energy is decreasing, you can't actually infer anything more than that. I mean, at the local level, there's not going to be a law like you know, the local energy dissipation as I showed you. Like, you know, there's not going to be a conservation law, which is in the form of a PDE or a partial differential inequality. So, the total integral, the information that you're given in your definition of solution is all that you can actually infer. Now, this is actually completely open for Navius talks, and there's a very good reason here. Talks, and there's a very good reason here. Liray solutions, actually, from the seminal paper of Liray himself, are known to have regularity on a dense open set of times. In fact, he even gives, even though he's not using that language, he even gives an estimate on the Hausdorff dimension of the set of times where the solution might be singular. So, Lydia solutions have a lot of epochs of regularity, as they are called in the literature. Now, once you have an epoch of regularity, Now, once you have an epoch of regularity, of course, you have a classical solution for a small time. So, at that point, if that classical solution remains classical or smooth for all times, then of course you just have the local energy identity. So, the only way you can violate the local energy identity is as if there were a formation of singularity. So, this question that I had over here: so, does Le Ray condition make solutions more reasonable? Is almost equivalent to the Millennium Prize question in the sense that if you Price question in the sense that if you actually find a counterexample, then you actually must have blow-up for Navier stocks, starting from some classical initial data for the classical solution, which as long as it is classical and regular is actually unique. Okay, so now, of course, the negative result for Euler is less surprising, right? I mean, in a sense, it is less surprising because while the Lehre paper from 1930, it actually shows you that once you It actually shows you that once you impose the energy inequality, you have some form of compactness. The Euler equations don't have that form of compactness. So just having a bound on the total L2 norm for a sequence of solutions of Euler is not going to tell you that the solutions are converging in a strong sense. In fact, they might converge in a weak sense. You might actually easily make examples. And the paper by myself and Laszlo back in 2007 implemented. Laszlo back in 2007 implements a construction technique which is known as convex integration nowadays. And I will comment actually, I will give you some ideas on how this works later. But one of the tenets in the literature is that convex integration actually only holds or, you know, it's a sign of the fact that there is an absence of compactness in the PD. I mean, like this kind of tenet in the literature essentially starts from the work of Tartar. The tenet actually is incorrect. I mean, it's true. Actually, it is incorrect. I mean, it's true that if you have some lack of compactness, you can hope to construct badly behaved solutions by using these convex integration methods. But the fact that you can implement these convex integration methods does not actually necessarily imply that there is a lack of compactness in the space of solutions with that a priori estimate. So there are papers by Luigi de Rosa, Maria Colombo, and myself. Maria Colombo and myself, which actually show that in a suitable intermediate regime between other and aviation stokes, and that means if you allow a fractional dissipation and the fraction, the exponent in the fractional La Laplacian is small enough, but still positive, you actually have at the same time both the existence of badly behaved solutions, which you might actually create with this convex integration methods, but you also have compactness of any solution which satisfy this. Of any solution which satisfies this a priori estimate. Okay, and the convex integration solutions have the a priori estimate as well. So you have like a situation in which the two things coexist, which I think is actually the first example in the literature where that happens. Okay, so this is what I was actually hinting at. So this result that I have with Maria Colombo at the beginning, and which was then refined by the Rosa later on, is that if you actually put That if you actually put a fractional Laplacian in Navier-Stokes, and this actually has been done in the literature already way back in the 60s in work by Jacques-Louis Lyons. Now you are interpolating between the Euler equations and the Navier-Stokes equation. You might think that as alpha approaches zero, you actually go towards the Euler equation. It's not completely true because this term would survive. You wouldn't have u equals zero and. u equals zero. And I mean, on the right-hand side, we just have u. So it would like converge towards some sort of dampening of the Euler equations. And as alpha actually approaches one, you have the Navier-Stokes. And now it's actually not difficult to modify Liray's seminar paper itself to show that Lirais solutions actually exist, are compact, and satisfy also the Wickstrom uniqueness for every positive alpha. I mean, as soon as you have a classical solution, the Lyra solution has to coincide. The Lyra solution has to coincide with it. Nonetheless, you can actually apply convex integration techniques as long as your alpha is not too large. I mean, as long as your alpha is less than one over three. And therefore, you can prove actually that Le Rais solutions, if alpha is not sufficiently large, don't have any hope of being unique, starting from a general initial data. Okay, so now what else can you do? Else, can you do? So, you can actually make your solutions even more reasonable by asking that there is a local form of the energy inequality. And this is, in fact, what was done in the pioneering work of Schaffer in 1977, and then was taken up by Caffarelli Kohn-Niedenberg in their famous paper in 1982, which still famously gives the better known regularity result in terms of partial regularity for some. Some globally defined weak solutions of the Euler equations in the three of the Navier-Stokes equation in three dimensions. Now, what actually Schaffer introduced in 1977 is the notion of suitable weak solution, which means that the energy identity that you have for classical solutions is enforced for suitable weak solutions in the form of an inequality. And again, Of an inequality. And again, that is enforced in the sense of distribution. Now, this is again like essentially by following Le Ray's paper itself, you can prove that the solutions which are created by Le Ray, in fact, by his algorithm, they are satisfying the suitable weak solution constraints. So they really satisfy even a local form of the inequality. Okay, it's very important to understand that in the case of Navier-Stokes equation, these Navier-Stokes equation, this is a very natural thing to write down, even because you have a priori estimates in the space of Le Ray solutions, which tells you that U is in L10 over 3 and depression is in L5 over 3. In particular, there's enough summability to actually make sense of this non-linearity over here, right? And so this is well defined. Now, for the Euler equation, you could say, let me put epsilon equals zero, and let me just, even for the Euler equation, impose that, you know, a weak solution is. That a weak solution is suitable in the sense that the inequality holds. And this was proposed by Duchon and Robert in 2000. But that's a little bit less natural from the point of view of a priori estimate, because if the only a priori estimate you hope to have is the total kinetic energy, which is finite, which is coming from the energy inequality, you're not going to know that there's enough summability to make sense of this non-linearity. So you actually have to kind of impose, if you want to write this identity for. If you want to write this identity for the Euler equation, that the solution is in L3. And this is not coming from any estimate. So now you have, of course, yet another sophisticated question that is, if you have admissible solutions, do they actually behave better than general weak solutions? So, for instance, can you now hope that if you have admissible weak solution of Euler in the sense of Duchon and Robert, can you hope that you actually have Can you hope that you actually have the, for instance, I don't know, uniqueness of the Cauchy problem? And I mean, Euler is so badly behaved that again, by a paper by Laszlo and myself, right after the 2007 paper, we were able actually to show that this is certainly not the case. I mean, you might even have known uniqueness, even if you restrict your class of solutions to the ones that satisfy a local form of the energy inequality. And so, why, so, what is one of the reasons why we actually bothered about these sorts of questions? Well, one of the questions that you might ask is that should we even expect somehow energy conservation for solutions of the Euler equations in general? Of course, if they're smooth, yes. But I mean, is this even like a natural expectation? If you're starting, for instance, from an initial data, which is not too regular? Well, there's a well-known A well-known fact in the physics literature, which was put forward by Kolmogorov in 1941 in his famous papers about the theory of turbulence. And what is one of the tenets of the theory of turbulence in the physics literature is that actually typical solutions of Navier-Stokes are expected to dissipate energy at a rate which is independent of the viscosity. So even though the total kinetic energy is dissipated apparently at a rate which is given by this. Rate, which is given by this epsilon over here. So you would expect that if I take a sequence of solutions of the Euler equation and I let epsilon go to zero, I converge to a solution of the Euler equation. And if it's a reasonable solution of the Euler equation, which is energy conservative, whereas epsilon goes to zero, maybe the right-hand side, the total integral of du squared remains bounded and then therefore it vanishes. In fact, what the theory of turbulence is forecasting is that typically Forecasting is that typically for say a random solutions of Navier-Stokes with the epsilon very small, the total kinetic energy is dissipated at a rate which is actually independent of the viscosity. So this big O of one just means that even though I take a solutions of Navier-Stokes with a sequence of epsilons which are going to zero, I typically don't expect that the right-hand side is going to zero. So I typically expect that it remains bounded, which of course means that the L2 norm. Which of course means that the L2 norm of the first derivative of u has to be of order one over epsilon, essentially, for this to be true. Now, if this is correct, the limit of most sequences of solutions to Navier-Stokes with vanishing viscosity can't be energy conservative and solutions of Euler. So, there's something which is going to happen, which is either you're not converging to a solution of Euler because maybe there's weak convergence, or if there is convergence to a solution of Euler, this actually has to be a known convergence. Solution of Euler, this actually has to be a non-conservative solution. Okay, so this is a very big open question. From the point of view of a pure mathematician, what would be a very satisfactory theorem is just to produce even just one sequence of solutions to the Anavier-Stokes equation, which is like, you know, exhibiting this behavior. And this is largely open. So now, in connection with the Onsagras conjecture, with the connection. On Sager's conjecture with the Kolmogorov's theory of turbulence, Onsager advanced this conjecture back in 1949. So, if you have a sufficiently regular solution of Euler, and sufficiently regular is like much weaker than what you would expect to make your computation with the energy, I mean, this Hilder 1 over 3. Whereas, if you make the computation with the energy by multiplying, say, the momentum equation by U and carrying on classical calculus computations, Classical calculus computations, you would imagine that you need C1. Then, if you are below that threshold, you're not actually energy conservative. Whereas if you are above that threshold, you are. So now this was proved by EZAT in 2016. And this came after a history of papers that were in the literature and that got sort of successive improvements, starting from a paper of mine and Laszlo Zekay. Starting from a paper of mine and Laszlo Zecahidi in 2012, in which we proved actually that there are non-conservative solutions of Euler, which are just continuous. So there was a history of improvements over here, and I don't want to bother you with what happened. But the only thing that I want to tell you is that one essential ingredient of all these proofs is some of this convex integration scheme that I'm been talking about, and for which I will give you at least a little flavor in the next couple of slides. In the next couple of slides. And this has its roots actually in this first paper in 2012 by Laszlo and myself, the C0 paper. Okay, so of course, a very natural question is, before I tell you how to get to these solutions, is, okay, so this is nice. You have a solution of the Euler which is not conservative, but what you really would like to produce is a solution, is a sequence of solutions of Navier-Stokes, which is maybe landing on a solution of Euler, which is non-conservative. Solution of Euler, which is non-conservative. And can you do that? And that is extremely open. So we don't have the faintest idea whether that can be done. Backmaster and Vico actually showed that, yes, these solutions of alert can be approximated, but just by Navier Stock solutions which are weak, so which are it's which are themselves kind of you know unreasonable in as I told you at the beginning. And so the real question is. And so, the real question is: can any of these solutions be a limit of Lyrae or even suitable weak solutions with vanishing viscosity? And of course, if you were to have something like this, then you would know that the limit would be either globally distributive, if you're just like, you know, taking a limit of delay solutions, and we know that that actually can be imposed, or if you're even expecting to be a limit of suitable weak solutions. Of suitable weak solutions. And at any rate, Lyra solutions on very large set, actually, they're suitable weak solutions because they're classical. So the expectation is not too crazy. Then, of course, the limiting solution of Euler has to obey this Duchamp-Robert inequality. And if you think that they should even exist in the Hulder space, of course, there's not going to be any problem in making this multiplication over here between U. Multiplication over here between u and p. Okay, so now solutions of Euler which satisfy the first inequality I'm going to call globally dissipative and the other ones are going to call locally dissipative. So as I hinted at, actually you can prove a stronger form of the Onsager conjecture, like you know, like you can prove a form, a stronger form of the, sorry, of the Isetz theorem by showing that when you are below the threshold, there are actually globally dissipated weak solutions with that regularity, with that Holder regular. Regularity, with that Holder regularity. And Easen in 2017 proposed to study the same question but with a local form of dissipation. And I mean, there's still something that can be done. As I told you in our old paper in 2008, we could actually produce bounded weak solutions which dissipate the local kinetic energy, but are unreasonable. And ISAD in 2017 was actually able to produce solutions. Solutions which are like Alpha Hurdler with alpha less than one over 15, and which are both at the same time locally and globally dissipative. Okay, so he conjectures, as one would naturally expect, that in fact there are solutions even at the threshold one over three, which are at the same time locally and globally distributive. And thus far, on this kind of stronger form of the Onsager conjecture, the best that we can actually achieve is a theorem by Hyun Ju Puan and myself from last year. And the threshold that we can actually achieve is this 1 over 7. It's still a technical exponent. It's of course better than this 1 over 15. And my feeling is that 1 over 3 is probably reachable, but I mean, it's not an impossible problem. But at the moment, we're Possible problem, but at the moment we're still far from getting it. I mean, like, maybe we have some ideas on how to progress from this one over seven, but one over three seems at the moment still elusive. Okay, so now what is this so special about the exponent one over three? So let me just give you a little bit of the mathematical content. So first of all, if you try to prove energy conservation, there's a way in which this exponent arises very naturally. Arises very naturally. So, and it was proved by Konstantin A and T T that if you are above this threshold regularity for Hulder solutions, then you're actually energy conservative. And the proof by Konstantin A and T T is actually very, very neat. So it goes via regularization. So essentially what you do is you take your weak solution over here. You take the equation for, I mean, you take the momentum equation. And what you do is what you would naturally do when you're trying to actually prove. Do when you're trying to actually prove or justify some identity, you're trying to regularize the equation in some way, and the way they regularize it is by convolution. Of course, if you regularize by convolution the term, the nonlinearity over here, which is u times u, the convolution of it is not equal to the nonlinearity applied to the convolution. But what you actually do is like you write down your regularized, I mean, your equation for the regularized u as the other equation. As the Euler equation with the right-hand side. And at the right-hand side, you see that there's a commutator. The commutator is just responsible for, like, you know, commuting the product with the convolution regularization. Okay, so now you can multiply by u epsilon on the left-hand side. And the manipulation that you needed actually to derive the energy identity when u is smooth, they're only using the fact that u is divergent. Using the fact that u is divergence-free, and that is actually preserved by the convolution operator. And so, after you multiply by u epsilon this equation over here, what you're going to get is like, you know, the left-hand side of the energy identity. But then, of course, you're going to get an error term on the right-hand side, which is this red term, which is multiplied by u epsilon. And there's something funky happening, like, you know, if you are better than one-third. Better than one-third holder, this commutator t epsilon is actually going to zero. And I mean, how can you understand that? Well, one way to understand that would just simply be the following kind of very heuristic argument. So the term on the right-hand side is trilinear in U. And in some sense, you have one derivative over here, and you have like, you know, a trilinear expression. And what you're able to do by some funky, say, algebra. Some funky, say, algebraic identities is to sort of distribute this derivative, one-third of each derivative, to each of the three factors in your expression, right? So that if you have a third of derivative for these factors, if you have a little bit better than a third of derivative for these factors, you can actually prove that this commutator goes to zero. Okay, so that's actually beautiful and neat because the proof is also kind of I mean, the commutator estimate is very nice to prove once you actually understand how to do it. Now, what is convex integration doing? So, what is actually happening when alpha is less than one over three? Well, in a nutshell, if you want, so one provocative way of saying what convex integration is doing is actually telling you, is actually kind of producing your Euler, your solution to the Euler equation through a Through a regularization, which is bad. So, I mean, like here, instead of having a regularization in which on the left-hand side I have this commutator, I just have some term which is regularizing the order. And I'm choosing this term. I mean, it's the divergence of some tensor. And the idea is that it is possible to choose the divergence of this tensor in such a way that when I multiply by VK, the commutator that I have here on the right-hand side does not go to zero. Go to zero. Even though the Rk goes to zero, the commutator that I have does not go to zero. So, one of the ways you could actually think about the convex integration technique is that it's producing a solution through a regularization scheme, which is actually bad enough to violate this commutator identity from constant in ANTT, which is actually letting the commutator go to zero. Now, what is really happening is. What is really happening is something of the following type, though. So, there's a wavelength epsilon k that you can actually compute for vk. So, at the Fourier level, somehow the regularized solution is in Fourier modes supported in lambda less or equal than epsilon k to the minus one. And the regularization procedure, like you know, the convergence to the Euler equation is actually achieved by producing a new VK plus one. A new Vk plus one, which is much closer to be a solution of Euler, that is like, you know, the right-hand side is much smaller in some sense, but it's much smaller in some negative Sobolet space. And the way you're actually doing is to add very fast oscillating solution to VK. I mean, like you're adding a very fast oscillating correction, in a sense. And the best regularity that you can achieve is by like, like, keep. Is by like keeping the size of the perturbation very small while you're actually increasing the frequency as little as possible. I mean, if you're increasing the frequency very fast, then you can make your right-hand side very small all of a sudden, but then like, you know, you're not getting something in the limit which is that regular. Like, you know, the fact that you're getting a certain Hilder exponent means that you have to balance how large is the frequency of the perturbation that you're adding with how. That you're adding with how small is the size of the perturbation that you're adding. Okay, so now let me just tell you in a second what is like, you know, the main obstacle to reach one over three. So why can't we pass from this one over seven to one over three? So in this paper with Hyunju compared to the paper of Phil, we actually have a quite efficient perturbation, dk plus one minus. Perturbation dk plus 1 minus dk. And this is actually built on a paper by Daneri and Zakai Hidi, which is also used by EZ to solve the Onsager conjecture. Now, the problem of this perturbation is that it's actually very nice. It would be very nice if Euler were stationary, but there's the time and there is the advection. And what you actually have to do is you have to take this perturbation and you have to advect it along the Vected along, like you know, the previous iterate. Now, the flow of VK has actually very good estimates for only a short time, right? I mean, only for a time which is inverse proportional to the derivative of, I mean, to the C0 norm of the derivative of VK. And this is already a problem even if you just want to produce a continuous solution without any local dissipation, just if you want to produce a continuous solution of the Euler equation without bothering about the energy inequality. About the energy inequality. So, this was one of the main issues that we had to resolve in the C0 paper back in 2012. So, we can't actually advect the perturbation VK plus one minus VK by VK. But what we can do is we can kind of approximately advect it. And the way we approximately abvect it is essentially to, like, you know, in different regions in space, to advect it for a short time and then make a partition of unity and. A partition of unity and, like, you know, patch everything together. And each chart is like small enough in such a way that on that chart, we actually have a good control on what the flow of decay is doing. So the chart is essentially as large as this quantity over here. Now, in the proof of the on-sagreg conjecture, the beauty of Phil's work is that he found a very different way of advecting officially the perturbation. Advecting officially the perturbation. So, what he was able to do, it was actually able to completely cut away this partition of unity that we have with the idea that between perturbing by the convex integration, I mean, before perturbing with the convex integration, it's actually gluing actual solution of Euler so that this error term that you do on the right-hand side, which is what you want to sort of eliminate at the next step, approximately, is actually. Approximately, is actually localized in these joint strips, which have exactly the correct width in time. I mean, the correct width for which you can actually like advect the solution, I mean, advect the perturbation. Now, this is wonderful because at that point, the patching and the cutoffs, which were introduced in my work with Laszlo and which were then refined by subsequent works, don't have to be used at all because this gluing. To be used at all, because this gluing technique is essentially localizing in strips which have already the correct width, so that, like, you know, you have good estimates for the transport equation of the previous iterate. And what is missing actually, at least the thing, the main thing which I think is missing for understanding how to make a solution locally distributive is actually to build a gluing technique which is also respecting the local energy inequality. Local energy inequality. And this is what we are trying to do in a work in progress with Hyunju and a PhD student of mine, actually, Vikramgiri. But for the moment, we don't have any progress to report on. Okay, so that is actually just a couple of minutes extra time. I'm sorry for this, but this is all I wanted to tell you. So thank you for your attention. Thank you very much, Camillo, for this great talk. Is there any questions from the audience? So you you say Kevino that there is a gap that you don't know how to fill between one over seven and one over three, but that maybe near one over seven you there would be hope to to to to get it that'd be one over seven plus an epsilon or plus an epsilon or equal to one over seven. No, I think if we I mean I think if we understand how to make I mean how to make at least a little bit of this gluing of this gluing step, there's going to be a substantial improvement between that exponent and the next one. So it's not going to be an absolute improvement. It's going to be a substantial improvement. But to me, the main point is that we still don't understand even how to make this gluing step so to get the one over seven. So if we were to understand how to make the gluing step How to make the gluing step and be able to do the one over seven, then I expect actually that there's going to be a big improvement. And it might possibly go all the way to this one over three, as it actually happened in the original Onsager conjecture. But what we don't really understand is how to like, okay, so this gluing is really gluing solutions of the Euler equations. So it works perfectly well with the momentum equation. It works wonderfully with like, you know, the divergence equation because it's gluing only in time. So there's no. So, there's no like, you know, patching in space. But unfortunately, it doesn't interact well with the energy inequality. And it's kind of a mixed feeling. I mean, it's unclear. Maybe there is something like that, you know, the energy inequality is really adding to the problem. So it might also be that it's not only a technical problem, that there's like, you know, some extra obstacles that the local energy inequality makes. Even though I don't think so, I can't be absolutely sure. I can't be absolutely sure. Right. Camillo, just a technical question, because you mentioned this proof by TT Constantine, which is in fact using, I mean, this commutation, I mean, this commutator on the divergence. And it's actually based on the fact that if you have a Hilter continuous function, then you can, let's say, carefully I mean, you can carefully describe how its full derivative blows up when you take the convolutions, essentially. Yes, yes, yes. That's exactly. Okay, this is okay. It's a simple inequality, of course. Let's say that if U is elder continuous, then its convolution with rate epsilon is blowing up as one over epsilon, one minus one-third or whatever. And that's what they actually use. And then you can, okay. Actually, so then you can okay. Actually, but you need sorry, uh, sorry, uh, Rosario, but you need some special algebraic structures, meaning that there must be some cancellations, otherwise, you wouldn't be able to put on a general bilinear operator. And that's where, like, somehow there's a beauty of it, because you know, you're like which are the cancellations, otherwise, you wouldn't be producing all this mixture. But exactly, the real point is that you can actually characterize how the real derivative blow up and then. Real derivative blows up, and then since there are three, then it's one-third. And this is pretty much convincing. Okay, maybe, okay, this is actually something deeply, okay, it's something very simple, but it's also connected to some facts in Lider-Rudd-Peley theory that when you do this, this so is there a description of this progressively, I mean, I mean, perturbations of DK in terms of little Pele theory. Yeah, okay. So let me, let me, that's a, that's a very, yeah, so that, that, that question is really very much up to the point. So first of all, Onsager apparently, I mean, it's even more than apparently because they digged actually his computations. So Onsager actually understood the energy conservation in terms of essentially little wood-Peley theory. And And yes, I didn't know. So, yeah, there was actually a predating paper to the one of Constantine A and T, which appeared almost the same, you know, it appeared maybe a few months before. And Constantine A and T actually were inspired by this paper. And this was by Aink, who actually digged the original computation of Von Sager and proved the energy conservation in some, you know, little Wood Paley space in which there is a one-third of a derivative. But, you know, it's not like the Hilder space. Not like you know, the holder space, uh, but yes, our actually iterative construction has a lot of this little wood paley flavor in the sense that you know the the next perturbation that you add, it's living in a certain annual eye. Yes, yes, because this is actually a geometric way of redoing Fourier decomposition, which is more flexible. That's nothing else, yes, uh rather, but but then like you know, the Fourier, the Fourier coefficient. like you know the fourier the fourier coefficients are kind of modulated like you know they're slowly varying instead of being constant and actually that that degree of freedom is like you know what really allows you to um to make the um to make the um the um um argument go and if you want one of the i mean one of the like you know if you want to reach one over three because these these constructions it's true that they go through some sort of this convex integration they go through some sort of um payle little wood similar uh kind of constructions Similar kind of constructions, but they are very lacunary. I mean, when I was actually hinting at the fact that there's a frequency, like the next one is much bigger, and so in a sense, the to get. You are not able to describe, let's say, the little pale decomposition on each annuli, but only on a few annuli. Yeah, I kind of okay, so for technical reasons, I always have to be like, you know, a little bit further away. And, you know, if you want a very, I mean, the cheaper you want to be to just, I don't know, get continuous or get uncertain hold of regularity. Or get uncertain hurdle regularity, the more you would actually leave space between the various frequency shells. And I mean, the more you want to get to one over three, the sharper you have to be and like avoid to lose space between the frequencies. And can you imagine that there is something behind the C one third? Because there's always a limiting description around one point. So it's not one third, but you could put a log or a different. Or a different border index or something like that. You could actually be bold enough to say, and that is what, for instance, Phil believes, and it's believable, that, you know, Little Hulder is actually energy conservative. And, you know, Hilder, I mean, little holder, one-third is energy conservative, and one-third is actually energy decidative. But that's you know, the little But that's, you know, the little holder is conservative, you can actually prove, but this decipative at the borderline case is okay. Little elder, I think it's a modification of the proof of constanting. Yes, exactly. Little Elder is a modification of the proof. That's absolutely not surprising. The other one would be very, very... Yeah, the other one is, I think we're light years from there. He has a, you know, he has a logarithmic improvement on the, you know, he has a On the, you know, he has a logarithmic loss on the one over three in one of his papers. Okay, okay. So that is, there is exactly what you would expect. Yeah, and then I don't remember if it is like, you know, log square or something like that. That is what you can squeeze from the art. That's typically the second index in the Lorentz scale or PSF or whatever. Gatsien. Is there any other questions? If not, then let me thank very much again Camille Yo for this very, very nice talk. And as this was the last talk of the workshop, let me thank all the participants for attending the conference. And let us thank the organizers for all the hard work, actually. Thank you. Thank you very much, everyone. And yes, it would be nice to meet in person at some point. Yeah, that would be some point.