I learned a lot so far, including the coating section. So this work is a joint work with my former postdoc, Daniel Nevo. He's currently a professor in Hebrew University and also the other two collaborators are Chuyoshi Hamada and Shujio Tojino. They are epidemiologists. They are epidemiologists based at Harvard. So, the Shuji asked me questions which motivated this research. So, as Tanya mentioned, this interassrame is really, it's not really my primary research area, but I worked on measurement error correction methods. It's very related to this. So, basically, I will apply a method used for measurement error correction to in-homme sensor. So our goal of static analysis is to study the relationship between time-dependent binary exposure and the survival type. So for the binary exposure, it starts with 0 as a value and then it will become 1 at some time point during the study duration. So, for example, a treatment may be administered at a different time for each patient. So, then we say at different times the treatment will become one from zero. And if the exposure is HIV status, for example, we started from be free of HIV, that would be zero, and then once the participant becomes an HIV patient, we HIV patient, it will become one. Once the participant becomes one, it won't change back to zero. For all the motivating examples, aspirin initiation is exposure, and the survival among correlated cancer patients is the outcome. So that's after correlating cancer diagnosis is the outcome, is time to event outcome. And the exposure again, aspirin initiation. Once the aspirin is initiated, it's dispatched. Initiated, this value will be one going back to zero. So, in our study, again, this is the study, so the most patients, so this study is among CRC, the protocol cancer is CRC, among CRC patients, starting from a diagnosis type. So, at the beginning, once the patient diagnoses diagnoses, the patient usually The patient usually undergoes a surgery. At that point, usually a clinician will advise the patient to stop taking aspirin, even if the patient was taking the aspirin before dialysis. That's because usually, yes, aspirin may cause bleeding after surgery. So, once the surgery is done, so patients usually initiate aspirin at some time point. There is no universal role. There is no universal role when to start the SPIN, so patients will start SPIN at different time points. So our data is based on nurses' health study and the health professional follow-up study cohorts. Those are observational cohorts. So we have this number cancer cases. And among these cases, we have this number of events. So follow-up time is. So, follow-up time is 10 years. So, our exposure data is collected through questionnaires. So, that's the typical method to collect data in cohort studies. So, it's every two years, patient answers the questionnaire data. So, we include our utilifestyle questions, and every four years we collect dietary questions. So, the diet or the aspen intake is included in lifestyle questionnaires. Lifestyle questionnaires. So we collect every two years. For example, a participant may report it one year after diagnosis, she's not taking aspen because questionnaires true every two years. Maybe after diagnosis, the first questionnaire this patient answered is one year after diagnosis. And then the second questionnaire after diagnosis, maybe it's 2.5 years after diagnosis. This apart 1.5 years. Apart 1.5 years apart. So the two years is roughly two years. For some patients, for some participants, maybe shorter than two years, for some other, maybe more than two years. Also, depending after they receive the questionnaire, when they answer it, I sent back. So, in this case, when did the patient initially ask? So, this is typical of This is typical locations for time to event data. So, T is the event time, C is the sensoring time for the outcome. So, we have observed the event time and the sensoring indicator. So, RXT is a binary exposure status time. This is a true S plane intake, X T. And we have Z, our additional covariance. So we have a time-varying covariance here, right? The exposure is time-varying. It changes over time. Vary. It changes over time, starting from zero and over time will become one, or for some participants, always zero. C is also can be time early. So this is our main model, the regular proportional hazard model. So this assume we know XT. So we know the XT when S being initiated, when at beginning 0, and then at some point begin 1. So our parameter of interest is. So, our parameter of interest is beta. So, this is a regular partial likelihood. This is a partial likelihood when you have time varying coherence. So, it's a product of this term for cases. For each cases, this event time is Ti. And then the number will sum over the participants in the risk set. And for those in the risk set, for cases defined as Ti, so the exposure is. So, the exposure evaluated as TIC, the event time for the case. So, the YI is at risk indicating. So, back to our exposure, so our question. So, we don't know exactly when the S-green was taken, if reported one year, S-M. Reported one year as no taking ethanol and two or five years after diagnosing reported ethanol taking breath. It could be anytime in between 1 and 2.5. So the standard approach that we use currently for our core work is loss value carry forward. So we keep X T to be zero until the first time the participant reported as SP Twitter. Yeah, take it tweeter. So it's zero. For this example, for example, Xt will be equal to zero ft less than 2.5 and equal to 1 after 2.5. That's left of value carried for LBCF. Another regular standard method is made point imputation, right? To use a midpoint between 1 and 2.5. So a lot of time. So, a lot of time, so the exposure is right sensor. So, we don't have our value for 2.5 at infinity, so hard to find the midpoint. So, those methods are potentially biased. This has already been showing those figures. So, for example, to show what our data look like, this is three examples, three different participants. For example, the first one. For example, the first one reported, the first questionnaire return is at 0.75 years after diagnosis. In that questionnaire return, the participant reported aspine taker. And the participant died at time 2.5. The second participant reported as no SP initiated at time 1 and then 2.5. 2.5 reported as SP initiated. And then FOLAP stopped after time five. So the third one reported as no SP initiated for these two questionnaires. The first one at 1.5 years after diagnosis, the one three years after diagnosis. And then the last, the patient lost to follow-up at time four. So how to give So, what's their real, like a real XT look like? So, we need to define Vi. So, Vi is a true time to X fan initiation model. So, for the first patient, we know that that initiation time Vi should be less than 2.75. For the second one, we know must be between point one and two point five. And for the last participants, we know Vi must be larger than three. Be larger than 3. Okay, it can be, if never initiated, it can be infinity. But we know Vi at least larger than 3. Yes? So can Vi be negative, or do we assume that baseline is it? Yeah, non-negative has yeah, we assume baseline always zero because for surgery, baseline is a surgery type. So you see how to stop it and then initiate again afterwards. Gotcha. Again, otherwise. So, what's our strategy? So, we will use observed partial likelihood. So, that's based on observed hazard function. So, remember, our interest is per parameter beta in that true hazard function. The true hazard function has already conditioned on the true intake x t. So, the observed hazard function will be conditioned on. Has a function will be conditioned on the observed questionnaire data for the exposure. So that the coefficient of those questionnaire exposure, questionnaire reported exposure is not beta anymore. There's no parameter of interest in this observed hazard function. But we will start from this. To define this, we need to define this history of at-risk particular I up to time t. Participant I after time t. We need this notation. So this FIT includes this indicator for participant I is at risk. So that's typical for surveillance analysis, the history includes at risk indicator. And this is... You mean at risk in the sense of being alive? Yeah, for this particular motivating example, our event is that. For example, our event is that. That's for the initiation of SP. No, that's for outcome. The T is for outcome. The bigger T is event that, I mean, outcome. And the WT is the last time the S-pre-initiation status was measured before time T. This is the last time quite near return for the ICE participant. That's before time T. Given a time T, so we Any given time t, so we define this. And this is the corresponding measurement from that passionier return and other covariance and some other covariance. And not only does it include other like a previous passion or return theta for this purpose. So this observer, again, this is the observed hazard function, that's the definition of hazard. So observed hazard function can So, observer has a function condition on this observer data, right? This is including the at-risk indicator. So, remember, our goal to estimate the parameter in the true hazard function. So, that's why we have to have this XT. Because that parameter we are interested in is the coefficient of the true XT. That's why, but there is no XT within this history after observer data. So, we just add this XT. So we just add this XT into the condition and the average out the expectation of this XT condition condition on whatever already there in this condition. That's FIT. We have equal sign here. So this is basically hazard. So we have this can be written as this conditional expectation of the hazard function condition. Heather function conditional xit and the history and this other variable. And this we plug in back to the proportional hazard model behavior. Expectation of this hazard condition of true XT and the observed other observed data behind us. So we already use our assumption here. Yeah, the assumption is that this Assumption is that here we have XIT and observed exposure data from questionnaire return. So here, when we plug in these two models, it's only conditional XIT nu, like the other observed data from question narrator. So this assumption is very typical for measurement error literature. It means that once you know the true exposure, the mismatch exposure The mismatched exposure doesn't contain further information about the relationship between the true exposure and outcome. So, we call it a third-distance assumption. So, I think there's also a reasonable assumption to be used here. Once you know the true status of aspen initiation, the additional one from the questionnaire data doesn't add any further information about the outcome. That approach is called regression calibration formation. Calibration for measurement and error literature. The first paper published for that topic, this paper is now for time varying with PODER by the idea of sim. So now we have this observed partial ideal point. So you can see now we have the parameter of interest beta, although this is based on observed Hazard function. Okay, next we need to estimate this. Okay, next we need to estimate this expectation. This is because XIT is just a binary data. So it's very easy to write out this expectation. So in measurement error literation, usually X is a continuous variable. So we have this, and then now we need to estimate this probability. So this needs to estimate it for each case time Ti, for case time Ti, and all those participants in the same risk set will be measured at that case time. So that's one participant need to have a few different disproportionately calculated for each case time. So that again, we need to estimate this expectation, can be written as so this. So this is within this F, big F, we have the questionnaire return date. So we can call it interval sensor, I guess. So if the, remember this W bar is the time of the last measurement before time t. So now given a t, we are using. So now given a t, we are interested in this probability for time t. So given that t, we have the last measurement time w bar. So if at that time the participant reported as been taker, so we know that the probability would be equal to one at time t because time t is after that. Yeah, the w bar. And if the last measurement time that participant reported as non-taker, Reported as non-taker, so as equals zero, that condition on the is that or equals zero this time point, so that would be the probability that participant take aspen taking status equal to one at time t. So it has to be to start to take aspen within this condition on this larger than that. Down top. So, this conditional distribution is a little bit complicated because ADN includes a risk set indicator in the partial likelihood. Yeah, in the hazard definition, it has this in the condition. So, it's even, yeah, if simple my unconditional function is, yeah, I know this. So, but we can estimate this. So, but we can estimate this. So, the first solution we have is just to estimate the probability VI involved in this interval without conditional on the resident set indicator. So, this is just a regular interval sensoring approach. So, for example, we can use non-parametric MLEs, more like an extension of Kaplan-Meyer approach, or using Meyer approach or using a parametric model or using proposed hazard model with some career suggested there in some publications. So what have we included some covariance in this probability x equal to one estimation? So would some covariance help with that estimation? Help with that estimation. So, first from our data example, our real data example, we look at whether aspirin taker before diagnosis is useful to predict the probability of that aspirin intake after diagnosis. So, as you can see that, so this black curves, so the solid black curves is for non-parametric estimates for. Estimates for survival probability for aspirin intake. This is not a survival probability, it's for exposure. No, we assume aspirin intake is more like an event. We treat the estimate intake as an event, forgot about the outcome, the survival outcome, the survival after CRC diagnosis outcome. So, this is a solid line from non-parametric approach and dotted line from parameters. And dotted align from a parametric approach based on weightable distribution. So the black curves are based on all the data, and the blue one based on those participants who took aspirin prior to diagnosis, and the red ones among those who didn't take aspirin prior to diagnosis. So, as you can see, that for those not taking, oh, this red body is taking diabetes. For those taking diabetes, the problem. Taken diabetes, the property dropped right away. So those participants retook aspirin shortly after diagnosis, after the surgery. And those not taking aspirin before diagnosis, actually, they may start to take at some point later. So this important means to adjust for this prediagnosis aspirine taking status. As we can status in this model for a sculpture, that probability model. So our procedure will be first to choose a non-parametric or parametric or semi parametric model for this valuable function for ISP intake. Okay, we fit those models from the interval sensor data. Sensor data using the exposure data only. For all those i in risk at time t, we need to calculate this probability based on this probability. After we have s, we can calculate this ratio. And then we plug in this p-hat back to this partial likelihood to obtain the regression coefficient in the hazard function. So good news is that. The good news is that we can show that this estimates converge to this beta star. And it has a sympathetic normality property. And yeah, can be estimated consistent from the data. That's the good news. But it's not so good news is that the value is converged to is not really the true. Converted to is not really the true beta. Actually, that's because this violation of these two assumptions. So the first L shadel violates the independent interval sensoring assumptions. For example, for our motivating example. So when, I mean, if exposure deaths is associated, for example, if aspirin initiation reduces the risk of correlating CRISPR. Of correlated CRC deaths. So then, the more likely that among those non-initiators, they are more likely to be right-sensor. How that would be die earlier, so no chance to really take the SP or reporting ticket. So, more likely to be right-sensor. Another reason is that we didn't include this condition when calculating the Condition when calculating the probability. But these are not equal to each other. If this T, the outcome, the survival outcome, and the exposure is correlated. Sorry, can I just say, what is beta star? Beta star, sorry, yeah, it's the true coefficient of X t in that hazard. I mean, in the proportional hazard. Oh, no, that's beta zero. Oh no, that's beta zero. Yeah, I you yeah, I used to write about write it as beta, right? Actually, it's a little bit confusing. It's a beta or beta zero. Okay, and then what is, and you have beta star and non-equal star. Yeah, beta star is converged to beta star. So because there is a limit of this stimulus. Yeah. There's a limit, okay? Yeah, the limit. So the limit is not necessary. But would you say that it's consistent then? Can you say that it is consistent then? No, we can. It has to be actually really converged to the true parameter to be considered. So some good news is that the beta star is pretty close to the true beta if under one of these three conditions. So if we have a real outcome. For corporate studies, that's often the case. So in that case, everybody had this conditional disc. Have this conditional this is a basic condition for everybody. So under a rare disease assumption, or if the association is not strong, or it's just totally no associations and everything outcome is not rare, the soil outcome, the event is not rare, or the association is strong. Association is strong. So, the solution can we can use risk set calculation. Again, that's also in the literature for measurement error correction. So, basically, the idea in the literature is not the same. It's here, actually. So, basically, actually, we can estimate that probability condition on the risk set indicator. Basically, we can refit the calibration model in each risk set. So, that will solve that problem. That will solve that problem. So, in that case, it means that we can estimate this condition on this risk set indicator. That's only different. That's risk-asset calibration approach. So, that's our simulation study. Can you go back? Yes. So, what are you doing differently here? Oh, the only difference here is that we have. The only difference here is that we have we before that we ignore this conditional we include everybody just use that data to select a treaty we forgot that's also common at all to use the normal sensor approach to estimate this level for for V actually only include those that are stronger. Yeah, yeah, subsets like yeah well we have to combine actually because sometimes the resource I take is small for some Sometimes the resource are taking small for some T. So, in that case, we have to combine the resources. It's just a help a little bit. So, the simulation study can show that what's so, so for example, when we said if the effect is not strong, so it ends in this in the first section. This approach, so non-conditional risk flat indicator is called ordinary calibration. Indicator is called ordinary calibration. So, this SC means risk cell calibration conditional risk cell indicator. This is the left value carry forward LBC. So, there's a number of measurements points. So, if we have like 10 years for lock, about 10 years for lock, we have only two measurements, assume. So, the interval is wider. When we have five measurements, we have a smaller interval. So, you can see that the L V C L. The LVCF approach, Anderson actually is not that bad in terms of point estimate and coverage probability. And this ordinary and the resource that calibration works well. But reduce efficiency, of course. And then when we have some effect, this has a ratio equal to 2. I see the non-U methods that will be more biased. That will be more biased. So, this true beta is this value, 0.7. So, this is a, we shouldn't call it an evil method, it is just LBCF. So, get this point estimates and this ordinary, and this risk calibration approach. Both worked well, actually, and the coverage probably not bad. Although, theoretically, both are biased, but this RSC is a bad word. But it will still bias. So but it will still bias because most likely after condition on the reset indicator, the model is still a little bit misspecified. The probability model for this country. But the bias is not that bad. And then this is when we have file measurements, you can see LVCF is improved a lot. And the both semester is much better than the LVCF. And then we will have And then when we have stronger, stronger in fact, this is hydro issue equal to 5, this is hydro issue equal to 7. You can see when we have a smaller number of measurements, so the ordinary calibration approach starts to show some bias. But when we have five measurement points, the audio even though the effect is relatively strong, this ordinary calibration gave, yeah, I think okay as Gale, yeah, I think okay. I think so. And probably reach probability is fine too. And then when this effect is very strong, and with only two measurement measurement points, this urban calibration is even more biased. And yeah, and RST improves a lot, but still not that satisfactory because the data limitations, the interval will be very wide. Very white. So then, back to our data example. So again, we have this number of, yes, this is a sample size. So we want to estimate the association between post-diagnosis initiation and survival time. So these are risk factors for survival time. We will control for in the outcome model. The outcome model. That's again, we will conduct the analysis with the subgroups of data based on biomarker, like the tumor markers actually for CRs. So first let's look at the calibration model results. So we include these variables in the calibration model. So there's an important point here that from our theory, so actually I From the theory, you can see that the expectation or probability has to be evaluated conditional on whatever condition in the CAPS model for the outcome need to be used in the measurement, not measurement, sorry, in the this exposure model, the calibration model. Exposure mode, the calibration model, yeah, in this calibration model. So, yeah, you have, for example, tumor stage in our study here, included here, that tumor stage should be here. Unless the coefficient of tumor state is almost zero, that means conditional be independent from X T. Yeah, if that coefficient is zero, it doesn't matter if it's input or not input. But you need to consider all those variables. Consider all those variables, including the outcome from this one, to make the theory correct. So we actually use this. The other variables in the outcome model is not that informative and the coefficient close to zero. So we didn't report, and then the final model is this. So pre-diagnosis aspirin is important. And this is for the result from the outcome model. So, yeah, this is in the subset of tumor subtypes, three tumor subtypes, small sample size for each one. So, you can see there's not much difference between first ordinary calibration approach and risk-side calibration approach. I think this is because our questionnaire needs. And this is because our questionnaire data collected every two years is more like a, this 10-year rollout, is more like a file measurement, similar to our simulation study with file measurement. In that setting, we found the automatic calibration risk calculation not that bad. And also from our simulation study, we found that LBCF also not that different from the calorie picture approach approach. So that's the conclusion. So the paper is published in biostatistics. I think it's 2000, 2001. So our package is available here. It's reproductive. You can have all those programs for simulation study for all this example. Yeah, probation. Example is a data of results that have questions just