Thanks so much, Guigo, for the very kind introduction, and thank you to all the organizers for inviting me to speak. It's great to be here today and to see you all, meet you all. Yeah, today I'll be talking about groups and symmetries in Gaussian graphical models. Gaussian graphical models. Yeah, please stop me at any time if anyone has any questions. I know this is an audience with mixed backgrounds, so happy to take questions anytime. All right, so the outline for my talk. Well, firstly, the starting idea is that groups and symmetries motivate many new and old statistical models. So this is a So, this is an idea with some history. The groups and symmetries come in either in terms of parametrizing the model, so the group allowing us to move around the model, or in terms of the invariance that we want the model to have. So, if we apply some element of a group, then our Element of the group, then our model shouldn't change. But I'll go into a lot more detail in the rest of the talk. And I'll be talking about two new families of statistical models that we've been working on with my collaborators. So, the first we call RDAG models. So, this is based on our joint. This is based on our joint work with Yizu Makam and Philip Reichenbach. And here are pictures of them. And that's in this paper here on symmetries and directed Gaussian graphical models, which we just posted on Archive a couple of months ago. And the second type of model that I would like to tell you about are Gaussian group models. And this is based on this joint work here with Carlos and Mendela, Catherine Cohn. With Carla Samendela, Catherine Cohn, and again, Philip Reichenberg. And for both of these types of models, I'll tell you about the groups and symmetries that are involved in them. And my focus will be on maximum likelihood estimation and how the maximum likelihood estimation is aided and improved by using this group or symmetry structure. All right, so before getting into All right, so before getting into our DAG models, Gaussian group models, I'd like to start with a recap of DAG models, or it's okay if you haven't seen these before. So I'll start with a DAG or a directed acyclic graph, and let's say it has M nodes. So here's an example with four nodes. Then I can associate to this graph a statistical model. A statistical model defined by the linear equation x equals lambda x plus epsilon, where lambda encodes the weights that relate the different random variables. So we have a random variable xi on each node, and certain xi's are related by edges in the stack. So the condition we have on the matrix lambda. We have on the matrix lambda is that it must be zero unless at the ij entry, unless there's an edge from j to i. Okay, so that's the lambda part. And then we also have a noise term in this model, which we'll call epsilon. And we can assume many things about epsilon or not so many things about epsilon. Here I'll make quite a few assumptions. So I'll assume that the noise is That the noise is normally distributed with mean zero and covariance omega, where omega is a diagonal matrix. So this says that the error at each node is independent. All right. So one assumption we can impose on our directed graph is called transitivity. So we say So we say that G is transitive if, whenever there's a directed edge from K to J and one from J to I, then together these imply that there's a direct edge from K to I. So, for example, this graph here is not transitive because there's a edge from one to two and an edge from two to four, but not a direct edge from one to four. One to four. Okay, so transitivity is a condition that we could impose, and we could wonder what the statistical implications of such a condition are. And okay, why am I telling you about all this? Well, to give the first example of the kinds of models that I was talking about. So if our DAG G is transitive, then the resulting model that we get from this linear From this linear structural equation with these assumptions on the error, is not only an R DAG model, but also a Gaussian group model. So these DAG models are well studied, and I'd like you to think of them as a sort of starting point for RDAG models and for Gaussian group models in two sort of different directions. Okay, and what do the probability distribution Probability distributions in this model look like? Well, we have Gaussian noise, so we can sort of rearrange this equation here to see that the random vector x has a multivariate Gaussian distribution with mean zero and concentration matrix given in terms of lambda and omega by. Lambda and omega by this formula here. So the concentration matrix is the inverse of the covariance matrix. So it's a sort of slightly unusual way to parametrize a multivariate Gaussian, but you just take the inverse of the covariance. And we can write the concentration matrix in terms of these parameters, lambda and the parameters omega. All right. All right, so since we're dealing with multivariate Gaussian models, I would like to set up some notation and tell you how I think about these models. So I already said that I'd like to parameterize the densities in terms of the concentration matrix. So that means that this formula looks maybe a tiny bit different than the standard formula because we've got a psi inverse here and a psi here. And yeah, we can assume that. And yeah, we can assume that its mean is zero. So, this means that our multivariate Gaussian model can be thought of just as a subset of the positive definite cone, where the subset is the set of concentration matrices that are in the model. All right, and this is a cartoon picture for the setup. So, this represents the positive definite cone, and then this is our model. So, these are all possible concentrations. Model. So these are all possible concentration matrices of the densities that are in the model. And the reason that this is my cartoon picture for the positive definite cone is because here's a more realistic picture of the positive definite cone. So it has this triangular kind of shape. Okay, so for example, one possible model we could Possible a model we could consider based on the DAG model I was telling you about is all those psi that factor in this form for some lambda and some omega. So maybe that's this set here. That's our model. Okay, so I said I was gonna focus on maximum likelihood estimation. So what do I mean in this context? Well, now we have our This context? Well, now we have our model M, which is a set of concentration matrices in the positive definite cone. And I'm looking for the point in the model that is most consistent with some observed data. So here's my data point here. And I'm looking to search over points in the model to find the one that's the best fit. And a maximum likelihood estimate is a point in the model that maximizes the likelihood of observing the data. So maybe for this cartoon picture here, this is my maximum likelihood. This cartoon picture here, this is my maximum likelihood estimate or MLE. Okay, so this is the picture to have in mind throughout. Okay, and then in the multivariate Gaussian setting, what does this look like? Well, I have some data samples, which will be some vectors in Rm. Then I can compute the likelihood, which takes the product of the densities evaluated at. For densities evaluated at my data samples. Here's a way to rewrite the likelihood, which emphasizes how maximizing this likelihood is equivalent to maximizing this function here, log depth psi minus the trace of psi sy, where sy is all we need to know about our data for the purposes of maximizing the likelihood. And it's called the sample covariance matrix. Okay. Okay, so for various s y's, I'm looking to maximize this function here. So an MLE given y is the maximum of this function as we vary over possible psi that lie in the model. Okay, so this is the objective function, and then we're maximizing just over those. We're maximizing just over those psi that are in the model. All right, and as we do this optimization problem, there are various possibilities for what may happen. So the worst case scenario is that our likelihood function or its slight rewriting in this form here is actually unbounded from above. So as we attempt to maximize it, it just goes off to infinity. A better situation would be that. Situation would be that it is bounded from above this function. An even better scenario is that not only is it bounded, but it actually attains its bound. So in this case, the MLE exists. This is the point that attains the maximum. And even better, maybe the MLE exists and is unique. All right, so these are. All right, so these are the four possibilities we'll have in mind. And now let's go back to DAG models to introduce our DAGs. All right, so here's an example of a DAG. We have this graph here on three vertices, one, three, and two. Then the DAG model, as I said before, consists of the concentration matrices, which The concentration matrices, which factor in this form, where lambda depends on the graph. So lambda ij is zero, unless there's an edge from j to i in the graph. So what does that mean for this model? Well, it means that lambda takes this form here. So there's only edges from three to one and three to two, which means there's only non-zero entries in lambda. Entries in lambda at 1, 3 and 2, 3, so that's these two here. And then omega has to be some diagonal matrix. So here are its three diagonal entries. All right, so then what's an R DAG model? Well, it's defined on a DAG together with a colouring, which I'll call C, of the vertices and edges. And edges of the DAC. So, for example, we can colour vertices one and two blue, or I made them circular in case the colours don't show up. And we can colour, let's say, both the edges to be red. And then the third vertex has its own colour. All right. So then the The parameterization of this model is quite similar to this one, but the colours impose some extra restrictions. So if the two edges are the same colour, this says that the weights on those edges have to be the same. So that's why this lambda one and lambda two has been replaced with just one lambda. And if the vertex colors are the same, then the corresponding entries of the matrix. Matrix omega have to agree. So that's why now we just have omega, the same omega here on both entries one and two, because one and two are both blue, and then some other possible variants omega prime at the third vertex. Okay, so we can see that imposing these colors has made our model smaller. So we used to have five parameters. So we used to have five parameters. Now we have only, let's see, one, two, three. And the idea behind RDAC models is to be able to restrict your model in this way, so to have a smaller possible space to search over while not imposing too much sparsity in the graph. So we have the same edge structure. Same edge structure in the two graphs, that's helpful because we don't want to impose too much conditional independence between the variables. But it's good to have a model that's quite small if, for instance, we don't have too many samples. I see there's a question in the chat. Dido asks, what does R stand for in RDAG? Thanks a lot for the question. I will explain on the next slide. Next slide. Are there any other questions? Okay, great. So, all right, so in our DAG model, we fix a DAG and the colouring of its vertices and edges. So, this is the example we saw on the previous slide. And now, to give a more formal definition, the RDAG model is the set. The ERDAG model is the set of concentration matrices that factor in this form, which where lambda and omega satisfy the following conditions. So firstly, we have this condition from our usual DAG model, which is that lambda ij is zero unless there's an edge from j to i in the graph. But now we have some extra conditions. So we impose that lambda ij has to equal lambda kl. Whenever edges Whenever edges j to i and l to k have the same colour, so that's like our two red edges here, and omega i has to equal omega j whenever vertices i and j have the same colour, so like one and two. Okay, so here's our example from before, and we can see that this parameterization exactly arises from this graph by imposing these three conditions. Three conditions. Okay, so our DAG models generalize usual DAC models. So why is that? Well, we can always give each vertex an edge, a unique color, and then these conditions don't impose anything, and we just have usual DAGs. So that's always a possibility. Okay, why do we call them R DAGs? Well, probably the DAG part is clear. The DAG part is clear. So, this is Guido's question of why the R. Well, they were inspired by their undirected analogs, which are called Archon models, which are defined in this paper of Heiscart and Lauritsen. And their use of the letter R is to stand for restricted. So, you're imposing extra restrictions from the colours. Colors okay, so that's a that's two uh questions that give a bit of context for these models, and then finally an assumption that we really needed in our study of these models. We always had to assume that the colouring of the graph was compatible. So this means that whenever our two edges, j to i and l to k, have the same colour. Have the same colour, this implies that I and K also have the same colour. So that holds for this example here. So the edges three to one and three to two have the same colour. So that means that one and two, the children of the edges also have to have the same colour. So this is a condition that we're quite curious about statistically, but from a mathematical perspective, we really needed that in our. If we really needed that in our study of these models, okay, so now how do we do maximum likelihood estimation in RDAC models? Well, this is essentially linear algebra, but slightly complicated linear algebra. Okay, so we have our data matrix here. So each column of the data matrix is a sample. The data matrix is a sample, and each row corresponds to a particular variable. So, y1 is all our observations at the first random variable, and ym is all our observed data at the nth random variable. And how we do maximum likelihood estimation is not involving. not involving the matrix Y directly, but by building what we call augmented sample matrices from Y, which we denote by MYS, where the M just stands for matrix. We have one of these sample matrices for each vertex color. And here's example to see how to go from a particular graph to its augmented To its augmented sample matrix. So, this is a particular combinatorial recipe. So, we start with our graph. So, here we have some graph on seven vertices where each vertex and edge has been assigned a colour. And then at the blue vertex colour, we construct our augmented sample matrix. So, the rows are indexed by the vertex. Rows are indexed by the vertex color and all the edge colors. And then the entry of the matrix is given by the sample row vector at the parent of the parent to that edge. Okay, so I mean, it's a little bit complicated to explain. To explain in words, but it's a procedure that takes the rows of this matrix and sort of populates them as the partial rows of this bigger matrix. So for example, if we look at red edges, here we have blue vertex one and blue vertex two. So we want to look at red edges. We've just got one red edge and it comes from three and it goes to one. So that's why we put a y3 here and nothing here. Here and nothing here. And okay, let's look at orange. So now we have no orange edges to vertex one. So this is zero. But we have three orange vertices, three orange edges that go to vertex two. And they come from three, five, and six. So that's why we have y three plus y five plus y six appearing here. Okay, and maybe I'll spare you the remaining three rows, but hopefully the recipe is. Hopefully, the recipe is clear for how to construct these matrices. Okay, so here's our example augmented sample matrix. And then we can relate the properties of the likelihood function to these augmented sample matrices. So the right-hand side, maybe. So, the right-hand side maybe looks a bit complicated, but it's all just linear algebra. So, we have that the likelihood is unbounded if and only if the first row of one of our augmented sample matrices is in the span of the others for some colour. So, for instance, if this row here is in the span of these other rows, once we plug in our values at these, all of these y i's, then the likelihood is unbounded. Conversely, if Firstly, if the first row is not in the span of the others, then the MLE exists. And the MLE exists uniquely if this augmented sample matrix MYS is full row rank for all colours S. Okay, so this gives a test where you can tell what's going to happen to the likelihood. You can tell what's going to happen to the likelihood. You have your data, you construct these augmented sample matrices, and then you can test their rank, compute their rank, or compute the span and compare it to the fast vector. And that tells you whether the likelihood exists or not. And this generalizes what's known for usual DAG models. And also, this perspective with the augmented sample matrices gives us an algorithm. Matrices gives us an algorithm to actually compute the MLE. So the algorithm works like this for each vertex colour. You project the first row of your augmented sample matrix onto the span of the others. And okay, this gives some projection that I'll call PYS. Then if PYS is equal to the first row, then the MLE does not exist. That's what I said before. Does not exist. That's what I said before: that the first, if the first row is in the span of the others, then the MLE does not exist, or even worse, the likelihoods are not even bounded. Oh, sorry, going backwards. Otherwise, the MLE in the lambda parameters are the coefficients such that we can write this projection as a sum of the other rows, as a linear combination of the other rows of the matrix. So that gives us our MLE. matrix so that gives us our MLE for the lambdas and then we get our MLE for the omega part by applying this this formula here. So that's our projection. That's our first row. This alpha S is the number of vertices of colour S. And that's just a linear algebra projection and then formula to get the. And then formula to get the MLE in these models. Anna, can I ask you a quick question? Hi, yes, sure. So I wonder about the relationship of the existence of the MLE and the number of data points that you have. Maybe if you don't sample sufficiently, this may not exist, but as you sample more and more, can you comment on that? I mean, maybe. Yeah, yeah, thanks a lot for the question. So that's exactly what was. That's exactly what was really motivating us in this study. So, in general, for these multivariate Gaussian models, we have, let's say, an M-dimensional Gaussian. As soon as we have M samples, the MLE will generically exist regardless of our model. But we're often in the case where we make many, many observations, like one for each gene, but we don't have that many observations. That many observations. So we're often in the situation where we have fewer than M. And then we're really interested in models that allow us to still find the MLA from relatively few samples. And even more, I mean, is it possible to know essentially the sweet spot N, M, the number of samples that will, with high probability, guarantee the existence of the MLE? Is there work on that regard? Yeah, yeah, exactly. So for Exactly. So, for usual DAG models, this number is known. So, this sweet spot, as you say, is the threshold. So, the maximum likelihood threshold. So, you can think about an existence threshold or a uniqueness threshold. So you can have two different thresholds. In the case of a usual DAG model, this is known. So it's the maximum indegree of the graph plus one. Degree of the graph plus one. So that tells you how the structure of the graph relates to the number of samples that you need. And what we were very interested in doing for our DAG models is to also work out a formula for this threshold or for both of these thresholds. Usual DAGs, the thresholds are the same. And for our DAG models, For RDAG models, we don't know the thresholds exactly, but we were able to find upper and lower bounds on the existence threshold and the uniqueness threshold, which we were quite happy with because it shows how the colours sort of help you. In the threshold, you end up dividing by the number of vertices of a particular colour, for example. And then that shows you that as your number of vertices of that colour increases, it helps your threshold to decrease. Threshold to decrease. So, yeah, I'm not going to talk. Okay, sorry. Thank you very much. No, I'm really happy to take that question. That was a major source of motivation for us in these models. We want pretty dense graphs that nonetheless have low thresholds. So how can we make the thresholds low despite having dense graphs? We can say, okay, all these edges have to be the same colour, all these velocities have to be the same colour, and so on. Thank you. Yeah. Thank you. Yeah, thanks a lot. Are there any other questions? They don't have to be the question that was the secret motivation for the whole project. They can be any kind of question. Okay, all right. So that's our, yeah. Yeah, result on the existence of the MLE and then also the algorithm to find the MLE. I'd now like to switch over to talking about Gaussian group models. So here we start with a group, which I'll call G, and it's a group of real invertible matrices. So what makes it a group? Well, if we have two elements G and H. Element G and H in the group, then their product is also there. We also require the identity to be in the group and that inverses should lie in the group. And based on this group, we define a Gaussian group model to be the set of concentration matrices that are of the form G transpose G, where G is an element of our group. So taking G transpose G makes sure our matrix is positive definite. Positive definite since the matrix is invertible. So, this gives our model, our multivariate Gaussian model. Okay, so some examples of Gaussian group models. I already said that a DAG model, if the graph is transitive, is a Gaussian group model. So what's the group? Well, the group is the set of invertible matrices whose sparsity reflects the structure in the graph. Reflects the structure in the graph. So where gij is zero, if we have some i and j not equal with no edge from j to i. So there's a few things to show here. We want to show that this set of matrices is a group and we'll see how the transitive condition comes in there. Well, we won't see because I won't explain it, but then one could see how the transitive condition comes in. And then also we want to see that the set of matrix. That the set of matrices we get by taking G transpose G for this group does actually agree with our factorization of the concentration matrix with the lambdas and the omegas. Okay, so that's a first example of Gaussian group model. Also, some of our RDAG models will be Gaussian group models, and it turns out to be those that are transitive, for which also this criterion, which I won't define now. Which I won't define now, but we call the butterfly criterion has to hold. So, this is a certain condition on the colours that are present in the graph. And there, the group is sort of similar to the uncolored case. So, not only do we have this condition that gij is zero, but we also have that gij equals gkl whenever these edges have the same colour and that the diagonal entries have to be the same whenever i and k have the same colour. Whenever I and K have the same color. So, yeah, you can ask for which graphs and which colourings is it the case that this set of matrices here is actually a group? So we asked ourselves this question and we came up with this transitivity condition and this butterfly criterion. Yeah, you might try it and come up with something else. Okay, and a last example that I wanted to just mention briefly of Gaussian group models. To just mention briefly of Gaussian group models, our matrix and tensor normal models, which we discuss in this paper here, and were also subsequently worked on by Ham Dirks and Bijan Makam in this paper, and then by the same authors plus Michael Walter in this paper, where they use this group perspective that we introduce here to find the maximum likelihood thresholds for these models. For these models. Okay, so maybe in the interest of time, I will skip my example of a group, but happy to come back to this. So the purpose of this example of a group was to motivate these stability definitions that arise in invariant theory. In invariant theory. So you'll just have to take my word for it that these stability definitions I'm about to define are sort of important and interesting in the study of groups. So the setting we have is that a group acts linearly on some space. So that means we can just think about the group as being a set of matrices. For example, if this is, if the space V is R. Uh, if the space V is Rn, then I'll just think of them as real n by n matrices. Then the orbit of a point under the group is the set of all points I can reach starting at some V and then applying elements of the group. So maybe I start at this point V and then move around by applying various elements of the group. And maybe this is what the orbit looks like. And here's my space, which I think here will almost always. I think here will almost always be Rm. So here's my vector space Rm, and then here's the orbit. All right. And the capacity of the point V is the closest distance that I get to the origin as I travel around the orbit. So it's the infimum as I range over G of this norm squared here. So for this example, Norm squared here. So for this example, the capacity is this length here, or maybe this length squared. Okay, so now some definitions. We say that a point is unstable if the capacity is zero. So if I can get arbitrarily close to the origin as I move around the orbit. And the set of unstable points is known as the null cone. So it's a set or variety. Set or variety of classical interests in invariant theory, and it's the collection of points where all my invariants or all homogeneous invariants of positive degree, but basically all non-trivial invariants will vanish. Okay, conversely, we say that a point is semi-stable if the capacity is strictly positive. So if I can't reach zero by traveling around. Can't reach zero by traveling around this orbit. So the opposite of unstable is semi-stable. And then we have two possible successive strengthenings of semi-stability. So we say that an orbit is polystable if v is not equal to zero and the orbit is closed. So you can check that polystable implies semi-stable. And then even better, a point could be stable if Be stable if not only is our point polystable, but also the stabilizer, so the set of all G such that G V is V, is a finite set. Okay, so these notions of stability arise, for example, in constructing moduli spaces. And if you haven't seen them before, it's sort of nice to work out how they specialize to particular examples. So we can take, for example, So we can take, for example, G to be a finite group. We can let G be all of GLM and have it act on Cm or Rm. Or so first interesting example, we can take a product of special linear groups and have it act on M1 by M2 matrices by left and right multiplication. So then we can ask which points, in this case, our points will be. In this case, our points will be matrices of size M1 by M2. So, which of them are unstable, semi-stable, poly-stable, and stable? Okay, so the main topic we were looking at is the connections between this invariant theory picture on the left and our maximum likelihood. Left and our maximum likelihood estimation picture on the right. So, this is what the connections are. So, on the left, we have these four notions of stability that I just mentioned. And then on the right, we have these four possibilities for what can happen as we try to maximize the likelihood function. And essentially, we say that there's a correspondence between these four notions here and these ones here. And today, I'm focusing on the multivariate Gaussian. I'm focusing on the multivariate Gaussian setting, but this correspondence also applies in the case of discrete log linear models. So we discussed that in this paper here. Okay, so more precisely what are our results. Okay, so we have our Gaussian group model, Mg, coming from our group. Uh, group, then our theorem says that with some assumptions on the group, so it has to be what's known as reductive, we have these if and only if implications between the different notions of stability and the likelihood. So it's unstable if and only if the likelihood is unbounded, semi-stable if and only if. Semi-stable if and only if the likelihood is bounded, polystable if and only if the MLE exists. And a point is stable implies that there are finitely many MLEs and in fact a unique MLE. But we don't have the converse implication of this fourth one, which is okay. And the stability is under the group G intersected with. The group G intersected with the special linear group. And mostly I'm focusing on the case where we have some real point and then a real group of matrices that move that point around that act on the space. But if we replace everything by complex groups, then we get equivalents of all four of these conditions. So we get the reverse implication in this last one as well. Okay, and the proof. Okay, and the proof idea is: well, this is what the log likelihood looks like. So, this is the function that we're hoping to maximize. And if our psi here can be written in the form G transpose G, then we can rewrite this function to be a function of G. And this is what it looks like. So, we have log det now instead of psi, we have g transpose g. Of psi, we have g transpose g, and then this term here can be rewritten to look like the norm of g dot y. So that sort of highlights why we have the connection to minimizing the norm of this point gy as we vary over the orbit g the orbit under the group g. Okay, and then the connections also give rise to some Give rise to some algorithms. For example, as the algorithms explored in these papers here of Bergeser, Franks, Garg, Oliveira, Walter, Wiggerson, and Ramachandran. So on the invariant theory side, we have geodesic convexity that holds in this setting. And then we can use these geodesically convex algorithms to actually find our. To actually find our MLA on the statistical side. Okay, if our group is not reductive, then we have this weaker statement where we have if and only ifs for the first two, but only a false implication here. And this implication disappears in general. Okay, so then how does this tie back into our DAGs? Well, we have this. Into our DAGs, well, we have this set of matrices here where we have conditions on the entries depending on whether we have an edge in the graph and also depending on the colours in the graph. So, unfortunately, when this is a group, it's not a reductive group. However, we are able to show that for these RDAC models, provided the graph is transitive and it has this multiply criterion, then we have, in fact, if and only if. Then we have, in fact, if and only ifs that relate all of these notions of stability with the properties of the likelihoods. And in fact, the theorem even holds when the set of matrices G isn't actually a group in some sense, although these notions were only really defined for groups. But yeah, I won't get more into that now because. Into that now because that's what I want to say. So, thanks. Thanks a lot. They get their degree, and then they go out a doctoral exit survey. And so, that's data we haven't really provided on a high-frequency before. Thank you very much, Anna, for your talk. This is very intriguing indeed. So, the whole analysis of Indeed. So, the whole analysis of restricted types of models and restricted weights-that's something that, of course, we care a lot about in all kinds of applications. And so, try to see if one can align those models better with the types of data that we're trying to fit and thereby try to be able to use fewer data points. Yeah, so that's quite nice. I truly enjoy that. And then the whole And then the whole discussion about the existence and uniqueness. So, when you're thinking about this, of course, you took this perspective of groups and stability. But, you know, just kind of from a very kind of naive standpoint, I mean, like, I like to think, for example, about exponential family models. And so, you know, if I take this kind of equations or linear equality constraints among the coefficients, this is as if I'm looking at some. This is as if I'm looking at some affine subspaces or some sub-families, you know, sub-exponential families. And so, you know, so I guess the kind of the main challenge here is to try to integrate the structure of the restrictions into the properties of those subfamilies rather than saying, you know, I have a subfamily of a certain dimension and therefore something. Yeah, yeah. So, I mean. Yeah, yeah. So, I mean, if I understand, you know, a question or comment exactly, we have some exponential families either in the multivariate Gaussian case or in the discrete log linear case. So while we're talking about how these both fit into the framework of exponential families, we're quite curious that somehow these connections between stability and properties of the likelihood hold in the log linear case. Hold in the log linear case and in the Gaussian case. So, we're quite curious about whether they hold more generally for exponential families. So, that's something that we're really interested in for future work. Then, yeah, imposing these restrictions. So, either in the RDAG's case, by imposing colours, or I guess in the Gaussian group models, you can consider a subgroup, and then that will give you some restriction to your. To your model. What we're really interested in is restrictions that give structure that hopefully is still quite interpretable for some application. So you can, so you can take this model, for example, if we ignore the colors, then this will be some, okay, seven plus one, two, three, four, five, six, seven, some nine-dimensional model. Is that right? And here we've Model, is that right? And here we've picked some. Now we just count the colours. So like one, two, three, four, five, six, some. Okay, I think I can't count. Okay, hold on. We've got nine. Anyway, we have some model or something. In the uncolored case, we're counting the vertices plus edges. Okay, yes, that's a lot more. And in the color case, we're just counting the number of colours. So the idea is to restrict the model. To restrict the model, but to do so in a way that hopefully still gives a nice interpretation. So, in this case, we still get some graph, so we still have that the conditional independences are imposed by the adjacency of the graph and that these edges have the same colour. So, we can say that the influence of this variable on this one should be the same across these three edges. So, we're selecting sub-models that are hopefully as good as this. Are hopefully as good as the originals in terms of what they can do and how we can interpret them in the context of the data. Do we have more questions for Adam? Maybe I have a question. It was a fascinating talk. Thank you very much. I'm really very interested in this, and I have been for several years. In this, and I have been for several years, but I've never really understood. So maybe I'll try to delve deeper into it. But I guess my question at the moment is: how do you see your work at the moment in this, what you've presented today, say, relating to analysis of causality using DAGs, as you just mentioned, influence. And I think that these are objects that are very used in that direction. And I'm just curious to know what you think. Yeah, yeah. Yeah, yeah. I mean, I, so, okay, so a major context in which these types of models are used, these diagon models are used, as you say, is in the context of causality. So, we interpret this edge to mean something causal, that three has some causal effect on one. I think in that setting, two, we want to learn the graph of dependencies between the different variables. Variables. And I, yeah, I see RDAGs as really fitting into that context as well, where now we're wanting to learn some causal pattern. And there, the presence of colours also has a causal interpretation. It's saying that, for example, the way five influences two is the same as the way six influences two. So we can view these as having some causal interpretation, and then we can interpret it. Causal interpretation, and then we can intervene to try to learn the structure of the graph, and then to do this maximum likelihood estimation problem to estimate the weights on the edges and the variances of the errors on the vertices. So, yeah, I'm very excited about applying these graphs in these sorts of causal contexts. These sorts of causal contexts.