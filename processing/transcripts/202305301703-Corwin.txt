Corwin will be talking about stationary measures for open boundary KPZ models. Okay, so Timo, it's been a pleasure. Recently we haven't traveled as much together, but there was a good chunk of viewers where we would meet on every which way of the globe and hang out in the lounges together. So it's a pleasure. Okay, so what I want to talk about is the effect of boundary conditions on particle systems stationary. On particle systems, stationary measures. We know for a lot of the integral models, or for all the integral models, that in the full line you have nice product invariant measures. But when you impose boundary conditions, the structure of stationary measures becomes considerably more complicated. Also, the structure of the kind of physical nature. You have interesting phase diagrams, you have non-trivial mixing diagrams, all sorts of interesting phenomena I'd like to point to as well. The only game in Game in town, or at least for the last 30 years, is something called the matrix product on stocks. This is a method that was developed by Dairy Dive and Saikiman Pasquier. It works, well, you can apply it to things like OpenASAP systems where the occupation variables are 0, 1 or some finite number of occupation variables. It's an algebraic setup and it involves finding representations of quadratic algebra. The route to eventually The route to eventually get to probabilistic content is long and arduous and has only been done in some very specific cases. So, the point of this talk is to describe another approach, one that yields immediately a very nice probabilistic description, not quite as nice as product invariant measure, but if you think of a product invariant measure as some sort of what I'll call one-layer Gibbs measure, I'll describe what I mean in a moment, then this is just one level more complex re-involve what are called two-layer Gibbs measures. So there should be. Two-layer Gibbs measures. So there should be a general approach, a structural approach that uses certain integrable information to produce stationary measures of this slightly more complicated yet still very probabilistic. And that's what I want to describe. And I'll describe this primarily for the geometric LPP. I'll also, in the end, mention that the exact analog of this works for log gamma polymer, and doing it for other models is something that is in process. This is also work with Yom Barakand and Zong Ru Neng. Jong Barakand and Zong Ru name. I've got to name it. Okay, so the model I'll focus on is geometric LPP, but I'll do it in a strip, a diagonal strip with N. In order to define the model, I save myself a little room, so you start with some initial data on the bottom, let's say. You could do this on some other path, but and we call it G0. I'm going to take G0 to be 0, just because there's no value in that. There's no value in that. It doesn't really figure in. And then you apply the log gamma recursion. First, you have your usual weights, these wij. In the bulk, we'll take them all to be a squared as the parameter, geometric of the parameter a squared. On the boundary, left boundary, a times cl, and on the right boundary, a times cr. You can actually introduce horizontal and vertical inhomogeneities into the model and characterize stationary measures as well, but I won't go in that later. Can I ask? Yep. So the boundary is fluid? Yeah, yeah. Well, because this is the natural thing to do. No, no, because if you took a vertical strip, all the paths, they always go up and to the right. So they would eventually just... They wouldn't feel the... So this is, if you think from a vertex model perspective, like six vertex model, this is also the right thing to do. Time is always in the diagonal direction. Okay. Okay, so we need to make some assumptions that just require that these geometric parameters everything is your own. Otherwise, the model makes no sense. And then the recursion relation, which of course if you repeat, you get a last passage model, is just that if you're in the bolt, you take your weight and then you add the max of the two predecessors, left and below. If you're at the boundary, you take your weight and you add just the thing below, or here, just the thing to the left. So, of course, if you recurse this, you get that. If you recurse this, you get that the GNM is the max over all paths that go back and hit sample one value on the boundary. So the definition of stationarity is very simple. An initial data, G0, so this should be a random process, random set of variables, is going to be called stationary if when I go up to level little n and I look at the sequence of increments, but The sequence of increments, but the way I'll do it is I'll look at g n plus k n minus g n n. So I look as I march across horizontally, I look at the difference between the value on the left boundary and the values that I see along the map. And if the law of that collection of random variables is independent of the height, then I say that my initial data was a stationary initial data. Is that clear? Is this really the same thing? You should think of, you could also phrase it in terms of increments, each increment. Each increment. And the increments of the last passage time are exactly akin to occupation variables in an exclusion process. So this is the same notion of stationary. Ivan, is it important that you took horizontal slides for stationary? Not a measure rather than like this. Not at all. So actually what I'm going to describe is the stationary measure on any downright path. So let me describe it. So the I'll give you a theorem right down here, but let me define something now. I'm going to call it a two-layer Gibbs measure. I'm going to call it a two-layer Gibbs measure. So I need to fix a downright path. I'll choose my favorite one, whatever the one I wrote in my notes was my downright path. And what I'm going to do is I'm going to describe to you a measure which will give me the stationary measure on that downright path. And obviously, if I took my downright path, it'd be horizontal. Obviously, if I took my downright path to be horizontal, it will be the correct thing, but it's actually valuable to know it on every downright path. Because the proof I'll give you is an inductive proof. We show that you move between these stationary measures. So the way that you do this is you just take this path and you copy it with a little rotation. So I had a down and then two overs, so I'm going to do a diagonal and then two ups, and then I had a down. So I have one word. So this is what my top layer of the graph, so I'm defining a graph. The graph, so I'm defining a graph, and then I'm going to draw another copy of that beneath it, and now I'm going to decorate this. So this is, I'm describing the sort of nearest neighbor points in this, and then I finally augment this with these little curls. So I'm going to. Curl. So I'm going to call this a two-layer graph. All I've done is I've, again, rotated, shifted, and drawn in some diagonal dotted lines in these two lines. So now given that graph, I can call this a two-layer graph gamma. Now given the graph, I'm going to define a configuration. So I'm ultimately going to define a Gibbs measure on this configuration on the graph. This configurations on the graph. And a configuration is going to be a pair, I'll call it xy, where I think of this as x0, x1, I guess up to xn, and then y0, up to yn. So these are numbers. These are going to be natural numbers. So each xi and yi are going to be in C. So each vertex of So each vertex of this graph will be assigned an integer. And I wanted to give you the probability measure, or in fact, it won't be a probability measure, it'll be an infinite measure. I want to give you the measure associated, the Gibbs measure associated to a configuration. The usual way that you define a Gibbs measure is by specifying the weight of edges. And so you see there are different types of edges in this picture. So one type of edge Vegetable. Let me write the measure first. So I'm going to define for a given graph gamma. I'll say that the measure assigned to the state x, y, a configuration, is going to be equal to the product over all edges in gamma of the weight of that edge. And so I need to tell you what the weight of an edge. So for a given configuration, of course, the weight of the edge in the Of course, the weight of the edge with this configuration. So the idea is the following: so the weight of, let's say, having x and then y in my configuration. So this is a local product over all these edges. This is going to be given by the same weight as having this picture. And that's going to be given by a to the x minus. Going to be given by a to the x minus y times the indicator function that x is bigger than or equal to y. So basically, when you move down on a given layer, you need to be ordered, so you need to decrease or increase weekly, and then you get a factor of a to the difference. Between the layers, you just have indicator functions. So you have an x and then a y. X and the Y. This is just an indicator function that the X is bigger than or equal to the Y. So this value needs to be bigger than or equal to these two values. So that will force that the configuration on the top curve is weakly bigger than the configuration sequence on the bottom curve. So it's some sort of non-intersection conditioning. And finally, the weight of these edges at the corner, so if I have x, y. So I have xy on the left side. This has a weight which is CL to the x minus y. And the weight on the right side is CR to the x minus y. So maybe the easiest way to think about this is the following. Imagine that I didn't have anything except for this top layer. So then the top layer would be a product of geometric parameters, you know, these a to the differences. And you can think Differences. And you can think of the configuration as some sort of unpinned, you know, starting at any point, unpinned geometric random log. Where sometimes you go down and sometimes you go up. And the same for the second layer, except they're conditioned to not intersect, and they have some energetic interaction at the starting and the ending point. This is actually what you would call a zero-temperature 1D movie of quantum gravity with boundary conditions. And yep. And I will collapse the A into the boundary and just because it goes too small. Boundary and just because it was each one. Yep. So the so here's the theorem. I think you don't, I just don't think. The model looks very simple. If you put if you change ad equal 1, in the bulk, you don't, it's meaningless. But the bulk parameters are a squared. But the bulk parameters are a squared. For exponential, it would be different. For exponential, you probably could do something with the content, you know, some sort of scale invariance of exponential. So the theorem says the following, which is if I have my measure, so if I look at the measure, again, infinite, this is infinite y? It's infinite because everything depends on differences of the x's and the y's. And so if I add a million to everything, I get the same. A million to everything, I get the same value for the product of weights. And so it obviously needs to be an infinite measure. But if I look at this measure and restrict to the situation where I set x0 equal to 0, so I just, I say, well, okay, let me just say that this is, I'm going to pin this. And then I look at the marginal. So then I, so under this restricted, first of all, this can be normal. Be normalized to a probability measure if, so this theorem only applies if the product of C L and C R is strictly less than one, in which case then the marginal law of the X X I minus X 0, so the X I process is the stationary measure. Okay, then just to characterize here by stationary for an arbitrary directive path, downright path, it means that I can translate that path. Yeah, so do you generalize an initial So you now start with an initial dwell. Either you start with the initial data that you get from taking the gamma, which is horizontal, and then you just look on another downright path and you say, what is the measure there? And it will be this. Or you say you start with that measure on this path, and now you translate by one, or two, or three, or four, and you have the same measure. So, okay, this is chicken scratching on here, so let me just say it in words. So, again, the first claim is that if I fix this value to be zero, This value to be zero, that the sum over all remaining variables will be finite only if the product of C L and C R is less than one. And the reason why this restriction is in place, and this is a restriction, the reason why this restriction is in place is because imagine that they're both bigger than one, then these two points want to actually repel each other. They want to spread out, right? Because you get more benefit by being far apart. By being far apart. And so actually, even if I pin this to be zero, the other one will kind of wander as far down as to minus infinity and get bigger and bigger contributions. And so you can't re-normalize it. If you have this restriction, then there is a pinning that is in effect, maybe it's not on both sides, but there's a net pinning that's enough to hold it together. Provided that's the case, then you can renormalize the measure. And if you look at then the marginal law of the top curves increments, okay, the top curve. Curves increments, or just the top curve, because I fixed this to be zero. That's the stationary measure. It's stationary under the dynamics of a quarter or under a quarter. It's stationary under the Markov, under the Markov process given by this recursion. Which is equivalent. Okay, so one remark, so I'll give you a proof of this in a moment. One remark is that this condition is, you know, this is a real condition. This is a real condition, but a little bit later I'll tell you that you can get around this condition. You just need to reinterpret this in a slightly different way and use some handle with continuation. So there's a, we have actually, for all parameters, we have a character C. So I think I missed something. What's the, X is this, the points on the downright path, right? X is the configuration. So it's a collection of numbers indexed by the points along the downright path. X by the points along the downward path. And this would be your stationary. And now I look at the measure restricted to this fixing a point. I renormalize it to be a probability measure. And then under that probability measure, I look at the law of the top variable. That's the stationary measure. So, what's the information? The information from Y is perverse. The information from Y is, in a sense, forgotten from the perspective of the stationary measure. It does have meaning, and it really. Stationary measure. It does have meaning, and it will, this is not something we include in the paper, but it relates to the stationary measure for a pair of polymer paths. You can do the same sort of thing for, you know, dub, sort of two watermelon paths. But this is not something we can prove. Okay, so I want to prove this. 20 minutes, 15 minutes, whatever. So the idea of the proof is actually not that complicated. It follows ideas that are somehow prominent in the study of Sure processes and two plus one dimensional dynamics. And so the first step is to prove something structural, which is a special case of a Cauchy or a Littlewood identity. Now that might sound scary, but it's not at all. I'll tell you what it is. It's not a hard thing to prove. It's really just a change of variables. So this is a fact about the weights of this. About the weights of this, about these Gibbs weights. So it's the following identity. So imagine that I take my two-layer Gibbs measure, and I have a configuration, you know, in, so this is, I'm taking kind of a little snippet of it, so I've restricted myself to some section. And let's say that I have values x, y, x prime, y prime. prime, y prime, and x tilde, y tilde. These are the configurations. And I can look at the weight of this, and then I dotted things. I can look at the weight. And it's just clear what that means. It's just the product of these things. And I sum out over x tilde and y tilde. So now I have something that only depends on x, y, and x prime and y prime. And the claim is that this is equal to the same sum where I've inverted my Where I've inverted my graph locally. So I still have x, y, x prime, y prime, and I'm summing over the middle point. So I have this identity. You really just write it down and you do a change of variables, and it's an immediate thing. It's a special case of a Cauchy identity for Sherpollen, for signature index Sherpo. Index church polynomials, but this is really not necessary. There's also a little wood, so the little wood identity is a statement about a similar sort of effect at the boundary. So if you have a situation where your graph, you're at the left boundary, the internal configurations, x tilde and y tilde. So I compute a weight. Or your red thing, the zero? Yeah, so I'm using these weights. Maybe I didn't need the colors, but I'm using the weights associated. But I'm using the weights associated that I just described here. These are Gibbs weights. I put in configurations: x, y, x prime, y prime, x total, y prime. So the weight of this would be the product of the weight of this edge, this edge, this edge, six edges. And the weight of this edge would be the indicator function that x is bigger than x tilde times a to the x minus x tilde. And the indicator, you know, the weight of this edge would be just the indicator function of order. It's a product of six numbers. It's a product of six numbers. I sum over these intermediate numbers, these intermediate variables, and I get the same result as if I summed over these intermediate variables. There's a boundary version of this as well, which is that if I fix x, and y, and then I sum over the weight now of this curve is exactly dl to the x minus y, or I guess x tilde minus y tilde. X tilde minus Y tilde, and these are the, I have my dotted things, and I have my horizontals, and I sum again over X tilde and Y tilde, that this is the sum where I've now flipped myself around and I've kind of moved my curl up on top. So, what you should think about what this is doing is Is these moves that you're seeing from the left to the right, these are equivalent to local mutations on the graph here, on the downright path? If I were to change this and move it so that it looked like that, that would correspond in my graph gamma to the change from this state to this state, at least in the graph gamma. And if I were to do that sort of mutation, say, over here, so I changed a down step to a right step, well, okay, that would. Well, okay, that would correspond to a reflected version of this. There's an equivalent identity on the right-hand side. So these are the two structural identities. And they follow very easily. They follow more generally from the Inn-Baxter equation. But I won't go into this. I think it's formal and formal adentitudes, formal primarily identities here. Well, you can formulate as such, I think, but these are just new. I think, but these are just numerical identities. If you assume the conditions on A and C, then these are convergent. Yeah, yeah, these are converged or can be formal. Okay, so step one is to identify these essentially some conservation. Step two is to use these to construct Markovian dynamics, local Markovian dynamics. Dynamics, local Markovian dynamics that preserve these two-layered Gibbs metrics. So what do I mean by this again? I have my graph gamma, or I have my path, and I do something. So maybe I change it by adding a box. I do a local change. I have a gamma prime. What I want is a Markov transition probability that will map me. probability that will map me from this infinite measure to the infinite measure gamma prime. And I want it to be local in the sense that I don't want it to change. So what did this do in terms of my graph? It changed these to up, move these up, and I want it to only update the values that are at these vertices that are being updated in the graph. So you can state this as some general property. Some general property, but what it boils down to, this preservation both of the Gibbs measure and the locality, it boils down to local relations on these weights. So in particular, let me describe what you need for the bulk. So what you want is you want to have a transition kernel. So let's say I'm going to go draw this here. So imagine that I'm in a state. State, I'm going to actually now use lambda. So lambda 1, lambda 2 will represent the heights of the top. Lambda mu1, mu2, so instead of the axis, and then kappa 1, kappa 2. So I want to, the transition probability that this becomes locally lambda 1, lambda 2, mu1, mu2, and then say pi 1. u2 and then say pi 1, pi 2. I'm going to call this as a probability, I'm going to call this something, and then I'm going to tell you the property I want. I'll call this u pi given lambda kappa mu. So this is the thing I need to give you. And what property do I want this transition probability to hold so that I preserve this class of measures? It's the following. So if I look at the weight of this initial picture, This initial picture, pi kappa mu, and I multiply it by the transition probability, u sorry not pi lambda, given lambda. So I want to sum to pi and lambda given kappa and mu. If I sum If I sum over kappa, I want that weight here to equal the weight of the new configuration. Okay, so what's stated here is I need, if my u satisfies this equation, so if I can find u's that are transition probability, so given lambda, kappa, and mu, if I sum up, Lambda, kappa, and mu, if I sum over all pi 1, pi 2, I get 1, and it's positive, strictly positive. Then if I sum this against the weight of this configuration, summing out the old value of kappa, I want to get the weight of the new configuration, the new graph with pi. This is the property that I want. So I want this. I want this to hold. If this holds, then it will preserve, these markup dynamics will preserve. These markup dynamics will preserve these Gibbs metrics. This is a pretty easy thing to see. And I also want some version of this at the boundary, where I need a transition that tells me the transition from a configuration like this to a configuration like this, and I need to preserve the weight in the same sense. So let me just write this equation. So the question is, how do you solve this equation? How do you find such a thing? And the easiest is what's known as block push dynamics, which is to assume that mu doesn't actually, sorry. Doesn't actually, sorry, U doesn't actually depend on kappa. You can also do an RSK type dynamic, but if you assume that this transition actually forgets what the state was, it only depends on lambda and mu, then you see that this actually factors out and you get that this is equal, that this equation that you're looking to solve is a statement. Now it looks like this. So the thing you want needs to solve this equation, because now it doesn't depend on capas. I factored it out. But of course you can move this over to the denominator and now you have a formula. And by the Cauchy identity, you know that this is a probability measure. So this formula actually is, it seems complicated, but it's super nice. In the following sentence, this is step three. In the following sentence, this is step three, which is to observe that if you look, so restricted to the top level, we get LPP. So how does this work? Well, again, this transition probability is the ratio of this weight divided by something that doesn't depend on pi. So this weight depends on, well, it's the thing. Well, it's the thing I just described before. So it's pi1. There's an interaction between pi1 and lambda 1, and an interaction between pi1 and mu1. But there's no interaction between pi1 and anything else. So pi1 only feels the impact of lambda 1 and mu1, but lambda and 1 and mu1 were both once pi 1s as well. So marginally, this is Markov. And in fact, if you just write down what these transitions, so there's this interaction by this. Transition. So there's this interaction by this A. So if I look at the probability of pi 1 given lambda 1 and mu1, this is proportional to, you get a factor of a to the pi 1 minus lambda 1, and then a to the, and there's some indicator function, that pi 1 is bigger than lambda 1, and then an a to the pi 1 minus mu 1, and an indicator function again. You see, this is You see, this is again proportional to a squared raised to pi 1 minus the max of the two. And then an indicator that pi 1 is bigger than the max. But that exactly says that pi 1 satisfies the max of the two predecessors plus an independent geometric. And that's the recursion relation in the bulk for geometric W. At the boundary, the same argument will apply. The weight, you know, you use this skew coach because you use this. Use this skew coach, you use this little wood identity, and you end up with something where now you have the weight of this type of configuration, and you see that there's only again an interaction between this one and this one, mitigated by an extra factor of the C. And so, okay, with a little bit of massaging, you see that it exactly gives you the boundary interaction, this recursion with this extra geometric. So, once you've observed this fact, then This fact, then it really follows quite easily that the infinite measure, follows immediately, that the infinite measure's marginal law, which is still an infinite measure of the top curve, is invariant under LTP, or stationary neural L T P. To get that this is normalizable is pretty easy. And then to get that when you do the renormalization and you look at the marginal, this is also pretty easy. So this is the proof of this thing. So this is the proof of this thing. Okay. Good. The um any questions about it? But the infinite measure there? Where's the infinite? This measure is infinite because it's shift invariant. You can shift everything up and down. But again, once you pin one value, then in the case of C1 less than C, the product of the C is less than one, you can show. To the C is less than 1, you can show that it actually becomes a finite measure, and then you can renormalize it and look at the law, and just the same thing implies that. But what I want to address now is this question about the restriction of the C. Because this is, you know, it would be a little unfortunate if we could only do, because the product of the C is less than one. You end up with Gn0, and obviously the boundary part. You could also end up at the boundary. You could also end up at the boundary, the right boundary. What was the question? But you have to end up at no point, not on the right boundary. You can end up, so that this is giving you the law of this stationary measure on every point along here. And I'm just renormalizing by the value on the left boundary. I could have renormalized by the value on the right boundary. You could also end up like one above Gn0. The red curve. The red curve would end up, would go to the right, you said. The red curve is not the last passage path. Not the last passage path. I'm just looking at a sequence of, I'm looking at the stationary measure on a downright path, restricted to a downright path. Whether it's end? The downright path, I take, well, it needs to go downright, so it needs to go from one side to the other. I could, there's no way, you know, of course it could, I could leave it and not consider it, but can you go straight? Of course. Yeah, so any downright path. So I could just go like that. And that's the way the proof works, right? The proof works. And that's the way the proof works, right? The proof works by saying that exactly the measure that I wrote down here, if I do this change and I use the LPT recursion, I get to the new measure. I get to the restricted measure. Now where I've changed the graph. So I'm flowing through these graphs. I'm flowing through these Gibbs metrics. And I'm proving it by a local relation, which is purely based on this identity set. Yeah, measure you guys just the the Lebesgue measure on the version? Yeah, so so it's a Lebesgue measure, you know, multiple you know, some scale version. Now, there's a really interesting question, which is what happens when the product of the C is equal to one or exceeds one. Now, if they're equal to one, it turns out that you have product measure. This is not an obvious fact from looking at this nature of this. For instance, let's say that they're both equal to one. For instance, let's say that they're both equal to one, not just the product, but they're individually equal to one. Then you see that this interaction becomes trivial in some sense. There's nothing pairing them together. And then it becomes plausible that they'll separate and you'll just see a Gibbs product form measure on the top curve. But showing that when this product is one, but they're individually not one, not obvious. And moreover, it's not at all clear what happens when the product exceeds one. Right? Because you kind of imagine what. Right, because you kind of imagine what they separate is when it equals one, so it should still be product one. But this is just patently false. So here's what happens. So, what you can do, so this is now extending to C L C R A bigger than or equal to 1. So, what you do is the following. So, you take this infinite measure and you rewrite it in terms of the difference across. I'll call this delta. The difference, the thing that will blow up when you pass this product equaling one distribution. And then in terms of some increments, so maybe we call L1 of i is equal to xi minus x0, and L2 of i is xi minus y0. So I look at the increment processes of the top two curves, and then the difference between them at the left. This is fully. Difference between them at the left. This is full information. And it turns out that the structure of this measure is very nice, and you can actually integrate or sum out over delta. And when you do that, you get the following formula, which is that the law, the probability distribution for L1 and L2 is equal to, or equations are proportional to, there's some finite normalization. C1, C2, CL, CR raised to the maximum. To the maximum of L1 of now I'm going to turn it right off the maximum of her i of L2 I minus L1 I minus 1 C2 to be L2N minus L1N times times the probability under what I'll call geometric random walk law of L1, L2, where this is the law that L1 and L2 are both marginally just geometric random walks with parameter A. So geometric random walks with increments of geometric parameter A. So there's an underlying law, which is just two independent geometric random blocks. This is like the station, you know, this is like. This is like the infinite stationary situation. I should say that what I'm describing right now is for gamma, which is horizontal. You can do it more generally, but you get a slightly more complicated formula. So this is really the stationary measure for this G naught that I initially talked about. So you take this independent geometric A random walks, this thing that we love, know and love, and then we pervert it. We twist it by a radar-nicotem derivative, which is of this form. So the product raised to max. So the product raised to the max of some function, difference of them, and then C2. And one thing that you immediately see from this is if that the product is equal to 1, this term goes away. This is just a reweighting by the endpoint. So you end up with the two things are independent geometrics, one which has A times C R, the other which is A over C R. So you get the stationary measure just for free in this case. And of course it depends on what is the value. This case. And of course, it depends on what is the value of equals CR. But then this also gives you, if you see, it makes sense, perfectly fine as long as these initial, you still need this to hold, but there's no restriction on the product. Now, you can do this. So the way that it works, of course, is this the stationary measure. I've just integrated out and then kind of extended the formula. So we know that this is true when C L times C. That this is true when Cl times Cr is less than 1. This is true just by summation out. But is it true that you can extend it? The answer is yes, because the relation of being stationary is a local relation. It says that I take my measure, I apply one step of this geometric RSK, and I get a new measure. So it's an equation. Both sides, you can check, are real analytic functions of the boundary parameters. One is a power series and it One is a power series in it that's convergent given those conditions. The other is just literally a function of this function. And so, by this uniqueness of analytic continuations, real analytic functions, you get this extension. So, I probably run out of time, but let me mention a few remarks. So, one is that this whole story works for log gamma polymer. So, of course, you need to change these to inverse gamma random variables, and you have some additive structure on the boundaries, and there's some other. Additive structure on the boundaries, and there's some other conditions. You do the usual thing. All that changes is that indicator functions become these double exponentials. That's it. Nothing else changes. The analytic continuation argument is slightly harder because it's not power series. You're integrating over reals and you need to do some more rarest theorems and topics and others. Otherwise, the proof is essentially identical. The mechanism that's behind this is really something that will apply to all. Is really something that will apply to all of the integral models. It's this local version of this skew, Cauchy, and Littlewood identities, and this is something that's present in all of the models. So I anticipate that this will give us a way of accessing for other models like ASAP or the higher stochastics at Vertex or these higher spin models, higher rank models. The nice thing about this is that it's very straightforward now to do asymptotics on this type of thing. And you can do this, and you can prove, you know. And you can do this, and you can prove limit theorems and all this stuff. The one limit theorem that you can do, not from this, but from the log Ma Polymer, is take the limit of this to the KPC equation. The analog there, so you have these boundary conditions, you know, that the derivative of h at 0 or an endpoint L is equal to u or minus b. The condition of the C's was equivalent to the condition there that u plus b is bigger than 0. So this is like C L. Than zero. So this is like Cl times Cr less than one. And in this special case, we did with Elisa Kniesel, we did prove a formula, and then there was additional work of Verpan and Le Dussal and Wislowski and Wang that wrote things kind of in this form in some sense. But it was a mystery because nowhere along that process did you get anything in this form. Nature StrataCon didn't produce anything of that form. So this reveals the That form. So this reveals the structure. And moreover, getting beyond this condition through the matrix break concept proves, well, I don't know how to do it. You can imagine somehow analytic continuation in the continuum, but it makes no sense. So you can actually do it here. And you can get this. So the hope is that now this is a method that is kind of more probabilistic than matrix product onsets. I remember, I think, Timo, you've asked me actually about matrix product onsets and kind of complained that it was. And kind of complained that it was this non-probabilistic and abstract algebra thing. So, okay, so no, this is a gift. All right, thank you very much. So, in your original proof, the CRCL dentist was used only for those identities to converge, or that where was actually used? No, you don't need it for the identities. No, you don't need it for the identities. What you need it for is in order to actually get to a probability measure. So if you're content with kind of an infinite measure being, you know, stationarity of an infinite measure, I don't think, well, no, I think you probably still need it. But it's in order to define a normalized probability measure, right? You fix a point, you kind of look at the increment away from that point, so you fix the point. And in order for that to be well-defined probability measure, you know, normalized to a probability measure. Normalized to a probability measure, you need this condition. And again, the reason is that otherwise the second curve will just want to run away from it, and it will contribute an infinite sum. You sum out over all x and y aside from x0, you'll get still an infinity, and you won't be able to re-normalize to a probability measure with that condition. It's a slightly subtle thing. Yeah, so just to make sure I understand what you said at the very end, so the scaling up for ACEDic issue, it can't be zero, right? Easy, right? And then you can take a scaling limit here and you're building the same thing? Yeah, so you can take a scaling limit not of the geometric but of the log gamma polymer. We don't, you know, there are techniques. So in the half-space, Schwann has, and Shalin have worked about, and I also have some work about scaling limits of half space. You know, first in the full space, you have to average kind of bustled. Nobody's actually done this for the polymer model in a strip. There's some subtle, you know, you need to do a lot of heat kernel estimates and stuff. A lot of heat kernel estimates and stuff. Undoubtedly, it's true, so we don't prove that. But modulo that convergence in sort of intermediate disorder scaling, then we can prove the u plus v negative KTZ stationary measure. But you get everything for the discrete models, and then you need to work a little bit to get to whatever continuum limit you want. And that one has to work a little bit more. Sure, if you just look at the structure of the stationary mode. Just look at the structure of the station images themselves that have a scaling. Oh, yes, yes. So, you know, what I can say is the following: so, this structure, so, what does this become for KPC? It becomes a very simple thing. So, for KPC, you have two Brownian motions that are in an exponential interaction. So, they, you know, it's exactly like in the O'Connell-your, you know, in this line ensemble, you have this exponential interaction Hamiltonian. Interaction, Hamiltonian. And then, in addition, you have a linear interaction. So, you basically measure the distance between the starting point multiplied by u, the distance between the end point multiplied by u, the integral of the exponential of the difference of the heights. That gives you an energy of a configuration, and you define a measure which is e to the minus that energy. Again, that's an infinite measure because the thing shifted up and down, but if you fix and look at the increment of the top curve, that can be renormalized a That can be renormalized assuming u plus v is positive to a probability measure, and that gives you the stationary measure for KPC at the top curve. Now, the restriction about this u plus v being positive is more substantial now. You can still do this integration out trick when u plus v is positive using some gamma function formulas, and you get some variant of this type of formula. Actually, something that goes back to Haria and Yor from about 20 years ago. 20 years ago. But proving that that is analytic in the boundary conditions of ASAP, and for that matter, that the stationary measure of KTZ is analytic in the boundary conditions for this SPDE, I don't know how to do that directly. But I do know how to do it for the discrete models or for log gamma. So that's, in a sense, that's one of the advantages of going to the discrete. Of course, the other advantage is that you have a notion of infinitesimally moving through these. Moving through these stationary measures. So, a nice formal proof, something that would be very nice to see, is to take this measure that I described, hit it with the sort of generator of KPZ, and prove that you get zero. That's essentially what we're doing. Well, you know, you need to hit it with more than just the generator of KPZ. You need a two-layer version of KPZ. But if you hit it with that, at least at a formal level, you get zero. And that's what we show at the discrete level. So you mentioned briefly about more than two layers.