Thanks for the introduction, David. Big thanks to the organizers for inviting me. Despite the conditions we actually face here right now, I really enjoy it very much and I'm looking forward to the week. So thanks a lot. I'm also happy to be able to report on a joint work here with my PhD student Jakob Stjan. And yes, so in order to fix the notation, To fix the notation, let me briefly recall what is the Golden Watson tree. So, a Golden Watson tree is a branching process whose realizations can be viewed as rooted tree graphs, and the whole process is governed by a random variable Z, which specifies the number of offsprings of a given vertex, or the number of children. So, down here, this is the rule. So, down here, this is the root of this tree, and there is an independent copy ZO of this random variable Z. In this realization, omega here, the number is 4, so there are 4 children. And then you go to each of the children, say you go to vertex U, there is another independent copy of this random vertical Z called Z U now, and in this realization, it happens to be 3, so U has three children, and so. So, you have three children, and so on, and this defines this rooted tree. The p k's here, which are the distribution of the random variable z, so p k is the probability that a vertex has exactly k children. In case that p0 is positive, this means there exists no vertices without children, which are. Vertices without children, which are leaves, and in my example, apparently, this is true. If P1 is positive, there are vertices that have just one child, and apparently, this is also true in my example here, because here is a linear piece in this graph. Okay, the joint law for these trees is G star. The star is there because we will get rid of it in a second. Of it in a second. Mainly now. So the average, the mean value of the distribution PK, so here is the mean value, determines whether this Golden-Watson branching process is subcritical or supercritical. If the mean value is smaller than one, then with probability one, the branching process dies out and all trees are finite. If the mean value is large, If the mean value is larger than one, then there is a non-zero probability such that the branching process does not die out and you have infinite trees. And this is the case I will be interested in throughout the talk. So I will assume that this mean value is bigger than one. And since I only want to deal with infinite trees, I will now condition this measure G star here. This measure g star here on the event that our trees are infinite, and this restricted this conditional measure, this is what I will appear in the rest of the talk, and is called G. Okay? Any questions so far? I forgot to say if you have any questions or if I'm too fast or whatsoever, please interrupt me at any time. I'm speaking about time, I should just have a chat here. Good. Here. Good. So, next term in the title: random walk. So, here we have a simple random walk on our Golden Watson tree. Here's again a realization of the Golden Watson tree. And so, the simple random walk may only jump along edges of the tree, so it may not jump from this vertex to that vertex up there because there is no edge. If it sits, say, at a vertex U, then the probability on this Then the probability on this realization, omega of the tree, to go from u to v in one time step is one over the vertex degree, which is four in that case. And the vertex degree is one plus the number of children, except at the root, because the root has no ancestor. This is why there is an indicating function for the one if you're not a the walk can go backwards? The walk. The walk is allowed to go backwards. Yes. Is allowed to go backwards. Yes. Here, in this case, with three-quarters, probability three-quarters, it moves up one generation, and with one quarter, it goes down one generation, whereas at the root, it can only go up. Okay. I will be interested in the annealed law of the random walk on these Golden-Watson trees, which means that, okay, I take an event of the random walk on a particular realization omega of the Golden Watts. Realization omega of the Gordon-Watson tree, calculate the probability of that, which depends now on the shape of the tree, and then we take the average overall trees. These are the supercritical trees. Okay, so both Golden-Watson trees and simple random walks are fairly basic quantities, and so is the return probability. Is the return probability, the annealed return probability? I forgot to say I will always start at the origin. It's on the transparency, but I didn't say it. So this is the return probability to the origin, because we start at the origin, and at time 2t, because I always need a number of even steps to go back to where I came from, I want to be back at the root O and I take this average with respect to the need measure. Also, this is a very And these measure also, this is a very basic quantity, so one should expect, and at least I have to say I did, that that problem of what is known about this anneal return probability should be entirely solved. But that apparently isn't true. So here is what is known. And these results go back to DT Pure from 98, Ann's Improbability, who discusses these cases here. So apparently, the first case in black is different. The first case in black is different from the other cases because here you see you have matching exponential upper and lower bounds, whereas all the other bounds here are not exponential, they are sub-exponential with t to the one-third. Okay, so the first case, which is, as I said, different, is for the special case where there are no leaves and there are no linear pieces. Okay, so the tree branches at least the Each vertex has at least two children, and you can imagine it's very easy for the random broke to get lost in this more and more exponentially expanding tree, and therefore it's hard to come back to the origin. This is different in the contrary, if the assumption, if you take the contrary assumption where at least one, p0 or p1, is positive. In that case, there is Case, there is, these are standard arguments, there is a lower bound which is sub-exponential with t to the one-third, which tells us immediately that such a behavior is ruled out, because this is much bigger, this lower bound is much bigger than that upper bound. So, apparently, this is different. So, of course, when you see this lower bound, you guess, can we get a matching upper bound? Yes, for Yes, for P0, if there are no L's, this is known. So the upper and the lower bounds match with the exponent e to the one-third subexponential. In the other cases, less is known. In the general case, the upper bound is bigger with sub-exponential being t to the 1 over 6, whereas there is a slight improvement in the case where the sub-exonic. In the case where the support of the number of offsprings is bounded, which means the vertex degree is bounded, where the exponent of the upper bound is t to the 1 fifth. Okay, but the conjecture is, as usually in this game, that the lower bound, which is the much easier quantity, that this should capture the correct behavior, and therefore there should, in all cases, there should be. Should, in all cases, there should be an upper bound that matches the lower bound. Or when you take double logarithms to extract the exponent here, this would be this weaker formulation for the exponent one-third. This is expected to be sharp, this upper bound, unless we are in the first case. There is not sharp because we know it's exponential. Good. So what can we do? So, what can we do? We will have an improvement in this case, and we will have an improvement in that case. There we are. Okay, so good. So, assume we are in this case, the PKs have bounded support, then there is an upper bound which has the optimal exponent. That's one result. That's one result. The second partially improves this general case here. When I say partially, because we need to assume a very fast decaying offspring distribution that decays, if you wish, super Gaussian, or nu equals 2 would be Gaussian, but we will need an exponent of nu bigger than 8. So do you think you will need two different C's? In other words, will the Luminf and the Lum Soup there down there need a... Different C's, you mean there? Yeah, the C prime and the C prime. I would expect that you can get even the same constant without logarithmic corrections, but that's hard. It's not no. It's not a problem. That would be even stronger. But that's, I mean, it's further off. That's further okay. Yes, Jacob. Yes, of course. And so what then would these bounds mean? Like some form of transport exponential? Yes, I mean these bounds with the exponent, so this sub-exponential with exponent one-third corresponds to a Lipschitz state of the Laplacian at energy zero that behaves. Energy zero that behaves as exponential to the minus energy to the minus one half. That's the corresponding quantity. So it's just related to the asymptotics of the spectral density, and this has to do with this new. And that's this has to do with this engineer that's okay. Good. So, uh where are we? Yes, here. As I said, we have to assume a really strong, strongly decaying offspring distribution. And the nu bigger than eight is here simply because you see that the exponent that we get for the upper bound, this exponent is only positive if nu is bigger than eight, otherwise it. Even use bigger than eight, otherwise it would be useless. So, this is why we just second from it. This is why we need, and the question is: when does it improve the known exponent one over six by PO? This requires new bigger than 16. So that's more kind of an addendum. So, I think we are more fond of the results for the bounded case and that position. Yes, please. Yeah, yes, please. Yeah, my question was in if I assume that actually log pk grows, I mean modulus log pk grows to infinity faster than any polynomial, do I get rid of the new over there? No, no, it's good, yeah. This is what we have down there. So here we the psi grows faster than any polynomial. Morally, this is as if you get the results up here for arbitrarily large nu, and then upon taking the logarithm. And then upon taking the logarithm view, you can boil it down to one thing. So, but that's a con it's this is a consequence of what I yes. Thank you. Yeah. Good. Okay, so there is some time left, that's good. So what do I want to do in the rest of the talk? I would like to give you a feeling why this exponent one third occurs. That's one thing. Occurs, that's one thing. And the second goal is to show you the strategy that is underlying this result here for bounded support. I'm not going to say anything on that piece for the fast decaying ones. That's the goal for the rest of the talk. One third is the optimal exponent? One third is the optimal exponent because The optimal exponent because you see you have one-third here for the lower one. Okay, so so, and this one-fifth is ah, okay, this is that's bigger, that's a bigger upper bound than this upper bound. Yeah, exactly. Exactly. Okay, good. Okay, so let's first turn to this lower bound, the sub-exponential lower bound for the return probability that is supposed to hold. That is supposed to hold all the time when we are not in this exponential situation, no leaves, no linear pipes. Good. So, the idea, and this is what makes the lower bound easy, is you can always restrict to a subclass of your trees that you like and that you can work on and do explicit computations. And this is exactly what one does. So, here in the case where P1 is positive. P1 is positive, we restrict to an event I call LL. The cap L stands for linear, so that we are linear, that the tree starts with a linear piece of length L, and then what happens up there, I don't care. Well, that's an event of positive probability. And well, you know what the probability is. Well, one child, one child, one child, one child, so it's P1 to the F. That's the probability. To the n. That's the probability of this event for the tree. Okay, so that's in this case, well, that's more, this is a more general condition here. What happens if, say, P1 is 0, then in any case, P0 has to be positive. And then the situation may look like this. So think that P2 is also 0, and then P3 is the smallest one, which is positive, that you can construct. Positive, then you can construct a interested in trees that have this structure up to height L, where each of these has three neighbors, which is equivalent to saying that, well, you have this linear structure that is decorated in the same way at every level, and this case is very similar to treat with that case. Therefore, for the purpose of the talk, I will not be interested in this now and just focus. Interested in this now and just focus on the case where we have this linear piece. Okay, good. So, how do we argue in the case where we have this linear piece? So I said we restrict to that event. Well, here we do. Bounded from below. So here is the additional constraint that we restrict to this event. And I rewrite this probability of joint occurrence as a conditional probability times the measure of the condition. Measure of the condition as usual. Now we already said that this probability is for the occurrence of these trees with is P1 to the L. And well, L is T to the 1 third, so this has already the right dependence. This is good. So what happens now to this conditional return probability? Well, let's assume now we have a tree omega that looks as in this. That looks as in this example I showed to you. Then I make another bound from below by introducing a new constraint. And the new constraint is I ask my sample paths not to reach height L before time t. Remember, I have to return to the origin at time t. So if my paths are forbidden to reach height L, the paths will never see that there is something. Will never see that there is something beyond the linear piece up there. So the random walk on such a random on this, on one of these realizations, is the same as a random walk on the natural numbers, because the random walk doesn't see what's up there. And again, I write this probability of joint occurrence as a conditional probability times probability of the condition. Now, okay, here we have the random one-dimensional random walk just on any. One-dimensional random mode, just on the natural numbers, which is reflected at zero. And so the condition is we do not reach height L, that sets a random wall that only lives on a finite number of vertices, namely L. What's the probability, at least for long times, to hit one vertex? Say the root? It's one over the number of vertices which are allowed. This is one over L. L, so this is algebraic in T. So, this is algebraic in T, and an algebraic dependence in T is boring in view of this behavior out there. So, let's forget about this, and we only have to concentrate on the probability that we do not read heish L. And what do we do there? Well, I would like to write this probability as up there as an L power of some quantity. How can I get an L power? Well, I think of the Markov. Well, I think of the Markov property and I divide my time interval from 0 to t into L pieces. Now L is t to the 1 third, so each of these pieces, I know this is pretty small down there, each of these pieces has length t to the 2 thirds. Okay, and the event is I start at 0 and I'm not allowed to reach height L. So maybe I do something like this. So maybe I do something like this. Okay, I introduce another restriction and get a smaller probability. The other restriction is now that at each of those instances here that cut my interval into the smaller parts, I only want to live or I require to stay in the lower half. Why that? Because it's convenient. Because then, what is the probability? Because then, what is the probability to start in the lower half? And this, in view of the Markov property, you start at time 0 in the lower half. x0 is less than l over 2. You want to end in the lower half at time t to the 2 thirds. That's this condition. And you are not allowed to reach height L in the meantime. That's this condition. This condition. Why is this good? Because everything here respects Brownian scaling. Brownian scaling, time is position squared. Time, t to the two-thirds, position L, T to the one-third. So you can scale time out, and this is a quantity of order one that is independent of t. But the whole probability The whole probability is a product of these objects for each of these slices. So you get a number, you get a quantity of order 1, say e to the minus a, to the power t to the 1 third. So you get the same kind of behavior here. So for this quantity as a lower bound than you get here, and this gives this lower bound. So you see, that's in a way the idea where the t to the 1/3 comes from, namely the behavior, the one that. Namely, the behavior, the one-dimensional behavior on linear pieces. That's in a way the, and that's a standard argument. I mean, that's very old. Good. So we have 20 minutes left. Yes, good. So in the remaining time, I would like to give you now an idea what happens to get this upper bound in the case where the offspring distribution has bounded support. Distribution has found its farm. Okay, the basic moral is that isoparimetric inequalities give you an exponential upper bound, give you exponential upper bounds on the heat curve. So just to repeat this in a way, do I mean by this? Let me first say what does it mean that a graph satisfies an isoperometric inequality where you take such a ratio where S is a normal. Where S is a non-empty, connected and finite vertex subset of here an arbitrary graph G, not necessarily a tree. In the numerator, you have the cardinality of the edge boundary of S, so the number of edges that connect S with a complement in the graph. And downstairs, you have the vertex degree weighted volume of the set S. Volume of the set S. So the number of the vertex degrees added up for all vertices in S. And if this quantity has a positive infimum, this infimum is the isoparametric constant. Or it says the graph satisfies an isoparametric inequality. Okay, this is good because of the following. If you introduce the Markov operator of the graph, whose major Of the graph, whose matrix element in the Hilbert space L2 over the vertex set of the graph, again, the vertex, every vertex weighted with its degree. So the matrix elements of the Markov operator are given just by the one-step probability of the random walk to go from u to v in one time step. So you go from u to v in one time step. Delta u is the vector in the little L two Hilbert space that is one at vertex u and zero everywhere. One at vertex u and zero everywhere else as usual. Okay, and because of the weighting here in the Hilbert space, you have to divide by one of the degree. That's a bit artificial. If you use the unweighted Hilbert space here for the scatter product, you get rid of the one in the degree. But I wrote it in terms of the weighted one because of the next theorem, which is standard. Namely, if you have an infinite connected graph with isoperometric constant Q, then the operator. G, then the operator norm of the Markov operator as a bounded linear operator from this Hilbert space into itself is strictly smaller than one and given by this quantity. This is good because if you now look at the heat kernel, namely the probability to go from u to v in t time steps, this is determined by the matrix element from u to v of the tth power of the matrix of the Markov operator. Well, and now you Well, and now you estimate the scalar product norm of this vector, norm of that vector, and the tth power of the operator norm of the Markov operator. But the Markov operator is bounded, so I mean the square root, this is bounded from above by 1 over p of g squared divided by 2, so you get this exponential upper bound. So, more you do t time step on a graph with isothermometric constant q, you get an You get an exponential decay in T. And this is universal in the sense that the only quantity that enters is the isoparametric constant. This is something I will stress. I want to stress because I need it. So is it greater than zero or is it greater than, I don't know, some fixed epsilon? What? Is it greater than zero or greater than? Yeah, yes, it's greater than J. So that's why this is greater of some fixed epsilon. So we be saying No, no, I mean if it's greater than zero, then it's just I mean it's the value, I mean it's just the value enters. So if you know if the if you know this this is greater than epsilon yeah yeah that then you can insert that here. Yeah good. Okay, now for Golden Watson trees, unless in this particular case where we have the exponential decay in time, this is doomed to fail. In time, this is doomed to fail. Because, well, think of, well, in almost any realization of the Golden Watson tree where this does not hold, you have linear pieces of arbitrarily large length. Such pieces make you the constant being zero. So I'd love. What other dreams? I mean, in the late 90s, Benjamini, Lyons, and Schrum came up with something better that is also suited for those cases. And that's in a way a modification of the isothermetic constant. They call it anchored expansion. Anchored makes sense because here you fix a vertex V that the set S has to contain. Don't ask me why it's called expansion. Don't ask me why it's called expansion, I don't know. I mean, it's an analogy of the isoparametric constant, except that you where one vertex is fixed. And this will turn out to be positive also in the Golden Wall space. Okay, this does not work, it does not immediately translate into a heat kernel bound as in the other case. And it took quite some work of Barlin Virag in 2000. Barlin Virak in 2000, who showed that if you have a graph with such an anchored expansion where this is positive and the graph has bound to degree, then your heat kernel obeys an exponential bound with exponent one-third. And the constant is explicitly given. So, can you use this for the Golden-Watson trees? In view of this result, I claim yes for the quenched return probability, but unfortunately. Quenched return probability, but unfortunately not for the annealed return probability. Why? So it's by now a classic result by Chen and Paris from 98 that for g almost every Golden-Watson tree, this anchored expansion constant is strictly positive. So that's why the quenched result works. Why does the annealed result work? Well, at first there is something which is very good. There is something which is very good in the direction for the indeed result because whenever P0 is positive, you can use a later proof by Lyons and Paris for the same results and boost it a little bit and show that even the G-essential infemum of all these gamma omegas is strictly positive. So this is good for the allele result. However, there is one problem left, namely, in the result by Vera. In the result by Virag, there is an initial time. And the result here only holds for times at least as big as the initial time. And the initial time cannot be controlled. Sorry, the dependence on the realization of the Golden Watson tree is not controllable. At least not with what Birak did. But what one has to do, or what turned out works, is replacing his deterministic arguments by certain probabilistic arguments. Listic arguments, and that's what we have done. Okay, so I have 10 minutes left. Yes, that looks good. Somehow that still seems doable. Okay, so think of fixing a number q between zero and one. And let me divide the graph, the golden Watson tree, into good parts and bad parts. And bad parts. The good parts I call the Q oceans, and the Q oceans have the property that they give rise to isoparametric ratios that are bounded below by this Q here. That's good. The bad parts, the complement of the Q oceans, by the way I call it I don't call it Q ocean, but Q oceans, because the Q oceans have different connected components. Have different connected components. So the bad parts, that's in a way the Q land under maximal connected component, but the Q land is a Q island. And usually I write C for Q islands. This C is the complement. Good. So now we do the following decomposition of the return probability while having still fixed a realization of the tree. Realization of the tree. First, we say, well, we go back to the origin, but in addition, we stay in the oceans, but not of Q, but of this Qt. So let me first say we fix the T, we choose a Q smaller than 1, and also smaller than gamma. 2 thirds is just for fun, but it has to be smaller than gamma. Remember, gamma was essentially femum of the Ankart expansion constant. Essentially, the femum of the Ankart expansion constant for the Golden Watts and truths. And then I define Qt as a numerical pre-factor that I don't want to write down, but it's smaller than 1, times Q times T to the 1 third. Good. And now here I return to the origin, but in addition, I require that I always stay in the Qt ocean. Whereas down there, that's the complementary. The complementary event, there exists at least one time where I hit the Q line. Good. Now, what can I say now? As long as I stay in the QT ocean, this means I do T steps in the T ocean. Remember the bound. Remember the bound. E to the minus T. E to the minus t, and then you get the isoparametric constant squared divided by 2. The isoparametric constant here is qt. So qt, t to the minus 1 third, t to the minus 2 thirds, you get t to the plus 1 third. That's what you want. And as I stressed, this is uniform in omega because the only thing that enters this Because the only thing that enters this bound is the isoparametric constant. And the isoperimetric constant is given by this q, which is fixed. That's a property of the whole ensemble. And this numerical prefactor I did not write down. Okay, so you can already, since this was so simple, we can guess that all the mass is hidden in the second term. And in order to do something with the second term, Second term, I ask you to believe me this little lemma down there, where we have two parameters, q and q prime, where q prime is smaller than q. Then the lemma says, whenever you have a q prime island, this q prime island is also part of the q land. It doesn't have to be an entire q island, but it's part of the Q land. And in addition, The island is not small. It has volume at least 1 over q prime. Now we want to apply this lemma with q prime being qt, because qt is smaller than q. Okay, so what do we require here? We require that this is the random walk that starts at zero. So within t time steps, the random walk can only reach an island that An island that is at most a distance t to the root, because the other ones are too far up. So, this is why here we have dist O less than or equal to t. On the other hand, we know, we applied, so using this result down there, we say any Qt island we hit here is also part of a Q island. So, So this AQT here is a union of all Q violence. They have to be close enough to the origin and their volume has to be big enough. Q prime is Qt. Okay, so that's the probability now. And yes, the question is, can we get this? Can we extract such a behavior here for that probability? Answer is no. That probability. Answer is no, not in generality, not in general, because we have to exclude some unfavorable trees. And so what is a good scenario? A good scenario. Now remember, here we had isoparametric constant Qt. Here we have isoparametric constant Q, which does not depend on T. So in order to get a bound, A bound e to the minus t to the one-third, you do not require t steps in the q ocean anymore. You only require t to the one-third steps in the q ocean. Because the q ocean, if you have t to the one-third steps in the q ocean, this is the upper bound on the return, on the probabilities. Number of steps, isoparametric constants. Isoparametric constant square. So the good scenario I'm interested in is the following. So down here is the root. Here is an island sea from here or from here. And I want to have a safety corridor around this island. Well, this safety corridor, this is the lagoon. This is the lagoon of the island, which I call L C and the width of the lagoon is such that you do t to the one-third steps in the Q ocean. Why do I stress t to the one-third steps in the Q-ocean? Well, the sea is not an arbitrary island, not an arbitrary island. Island, not an arbitrary Q island. These are just Q islands that are big enough. So here there could be smaller islands hidden. If you have to cross such an island, it's not good for this decay. And therefore, the corridor here has to be wide enough so that you do t to the one-third steps in the Q ocean, regardless of how. Ocean, regardless of how many islands you have. If you have many islands, smaller islands here, you have to make it bigger so that you get teacher once headsteps in the ocean. Okay, that's the good scenario. And this is what I've written here. Except what I have not told you yet is, so what makes the probability of hitting an island large is if there are many such seas, so this is C one and this is C two. C1 and this is C2, and the lagoons, and there is C3, and these lagoons all overlap. Because then once you are in one of the lagoons, you have different options to hit an island, and this makes the probability larger. It turns out that it's enough to require that there are at most T such islands where the Where the corresponding lagoons are volatile because of the following. So, first of all, because of this, what I already told you, that's this result. You do at least t to the one steps in the q ocean, that's this bound. And that's uniform again because the bound only depends on q, irrespective of the of the realization of omega in this good scenario. Omega in this good scenario. The second result is that this good scenario is sufficiently general because it's a complement where the good scenario fails. And this is where we need that the Q is less than gamma. Otherwise, the only thing that the beer is. So this is where we need that Q is less than gamma. Is that the probability to find trees that do not respect this? Trees that do not respect this scenario is again of this form. So, where does this come from? Just telling you in a way the idea. I mean, there's nothing. Remember, I mean, when you do, I mean, the point here is when you do the Lyons-Paris proof of this result that the anchored expansion constant for Golden-Watson trees have a G, positive G essentially in females. G essentially in FEMA. The lines in Paris show that I'm done in a minute. That's here. They show that if you happen to have a large subset S, which in a way beats the gamma, that gives rise to a smaller isoparimetric ratio than this. Parametric ratio than this gamma. This occurrence is exponentially small in the size of this subset. Now here the size that I've written in the top line, I just repeated the definition of AQT, the size is 1 over Qt. So the size is proportional to T to the 1 third. And therefore, Lyons-Paris says the occurrence of this. Says the occurrence of the complementary event of this as a probability at most e to the minus size of the islands, and that's t to the one-third. So this is where this bound comes from. And basically this closes the circle in the sense why these anchored expansion constants are good in order to obtain upper bounds on the return probability. On the return probability in the case of Golden Watson trees. So, all in all, when you just put everything together, here you have the annealed return probability, you have the average over the trees, you split the average up in two parts, the good scenario and the bad scenario. In the bad scenario, you estimate the probability by one, so it's gone, so it's just the probability from here. In the good scenario, you have to. So you have to add up this term, which has the right form, and that term, but that term also has the right form, and therefore adding up, you get what you want. And so I'm two minutes over time. But I said everything I wanted to say. Thank you very much for your attention. Are there any questions? Are there any questions? What is the optimal? So you dealt only with the bounded case. What happens in the unbounded case? Yes. So in the unbounded case, I can only tell you what we do. I mean, from what we get, you already know this cannot be, I mean, this is maybe not the best strategy, or we couldn't make it or turn it into a good proof. But I want. Proof. But I want to tell you what we do. So here's the root. Here is level T of the tree. First of all, we restrict to a class of T's where below level T the vertex degrees or the number of The vertex degrees or the number of children, so z x of omega is bounded from above by some number that depends on t. And since this affects only a finite number of vertices, that's still an event of by choosing t, excuse me, by choosing the set t appropriately, you can make this still Still, an event that is sufficiently large. Okay? But then still, so we are bound. In this way, we are bounded down there. Okay, so you reduce it to the bounded case. Yes, we bound it down there. But here we're still unbounded. But on the other hand, the random walk doesn't reach this region. So what you do is, up there, you replace, you simply replace the whole tree by something which is bounded. Sounds simple. The problem is, in a way, the technical problem is this may change islands that traverse this line here, and this has to be controlled. But it can be done. But you conjecture that the exponential constant will be the same for the impounded case. You mean the C it- Well, at the exponent. The exponent, I'm 100% sure that the exponent is the same. One sorry. So what are what surprising that bound is bound with case behavior? No, because you see, I mean, if you are unbounded, unbounded means you have many, many children. That's in a way good for getting lost somewhere. And this is responsible for even an exponential decay of the return probability. Decay of the return probability, but we haven't been able to exploit this appropriately. So, you say that the main contribution in any case comes from a boulder piece? Is it boulder? Because in a way it's kind of I mean it's a discrete disorder to Addish Reni grass. In fact, these Golden Watson trees occur as the Benjaminish Rum limits of sparse, really sparse Addish Reni grass, where the number of edges Number of edges is of the same order as the number of vertices. This is the case that none of really many papers that have been written on spectral properties of Addish-Rinigraph by, say, Auntie Knowles, by Laszlo Adish before, and others. They have never been able to treat. The difference is that, I mean, Is that, I mean, in cases where you have more ragges, there is more randomness, more things to exploit than in this more than weak case of disability. It would be a great result. Is there a reasonable way of asking about the return to a model boot vertex? Vertex, ask me the question, is it interesting? No, it's not much different because it's, I mean, the other vertex is at a finite height, and in a way, I mean, you fix, you specify a vertex, and then it has a given height, and then in a way you trans, I mean, you just adapt everything accordingly. It has a different vertex, it has a vertex. It has a vertex degree. I mean, you could view it as a root, but then it has one vertex degree that is one bigger, but that's not in a way the problem. I mean, that in a way it's legitimate. What Mirab just said. Well. Because this is te it's technic it's technical enough to sh to show it in this case and instead of then dealing with with I mean Instead of then dealing with your, I mean. Yeah. Dealing with that in addition. I mean, if you, what I say is, if you understand this case, you understand the other ones. This is basically the. So do I understand correctly that the answer to David's question basically hidden in the definition of down-coid expansion? There was also an arbitrary V and because in downcorret expansion, so take any vertex and say, okay, now these are. No, this is this is part of the yeah this is an aspect of the coffee break until three thirty and then Daphne will give the next one.   Buttonic components, right?