Okay, so today I'm gonna switch problems. So, if you were not following the previous lecture, you shouldn't miss too much. I'm gonna talk about spin classes and Glasses and some algorithmic aspects. Yeah, so I want to be self-contained, so let me start from the beginning. I'll introduce two spin glass models. In fact, one is a generalization of the other, but let me start with the simplest one, that is the Sherrington-Kilpatrick model. This is a model for a random energy function over the hypercube. Okay, so it's a function from plus minus one to the end. From plus minus one to the n to the reals. And the function is simply a quadratic, a quadratic function, a quadratic form, sigma w sigma, where the ideas w is a geoimatrix, Gaussian orthogonal ensemble. And I already defined this in the last lecture, but one way to construct it is simply you construct an array of n by n array of standard normal random variables. Standard normal random variables, and then these ones, and then you take g plus g transpose and normalize it. One more abstract way, but you know, sometimes more convenient way to think about this is that h sigma, the values h sigma indexed by the upper group form a center Gaussian vector in the process with this covariance. With this covariance structure. Okay, fine. So the covariance, the important thing is that depends only on the scalar product sigma dot two. One generalization of this model is given by what's called the P-spin model, and the most convenient way to introduce it is again as a centered Gaussian process with covariance that now is more general. Now is more general, is n times a function of sigma times two divided by n. Okay, and here the scaling is chosen in such a way that you have a nice limit as n to infinity. In particular, this psi is a function that you should think of as a function of minus one, one. And notice that its argument is in the interval minus one, one. Okay, and then I scale by n in such a way that you know the Such a way that the maxima of this process are over the n. And Ïˆ is a function that is analytic with the non-negative coefficients CK square. In fact, you can always think that this is the polynomial if you prefer. The model is rich enough if you just think of a polynomial. In fact, there is not a lot of to begin. Of to begin to look at general analytic functions. The special case of the Sherrington-Kipatric model is recovered if I take, of course, the function psi of x equal x squared over 2. Now, this is the abstract way of defining it. Of course, you can construct this process explicitly, and this is actually kind of important for. important for what we'll talk about and it's important remark you can construct it as okay now the normalization depends a little bit on on the special case wk times sigma tensor k where w k now are a sequence of independent so this is a Ah, so this is a tensor Gaussian tensors and I will not bother to define precisely what is the the normalization of the entries of these Gaussian tensors, because you can probably figure it out by yourself since I gave you the covariance of the process. You, the covariance of the process above. So, these models are interesting because are you know kind of canonical models for a rough energy landscape, in particular, okay, there is all sorts of results about having them having many local minima and the complex and the complex structure. Here, what are so, so they are non-convex in particular. And many local minima. Okay, so here what I'll be talking about this lecture. In this lecture, is the optimization problem, I mean the computational problem of maximizing this energy function. Okay, so what we want to answer about this problem, well, at high level, what we want to, the question that we want to answer is, can we solve it approximately? In polynomial time. Okay, and you know, if you want to be a little bit precise, what I want, I want a polytime algorithm that take input, you know, the sequence of tensors wk. Of tensors WK and speed says output a plus minus one vector that I denote by sigma alg and such that Let's see. Let's see the probability that this energy function at sigma alg is bigger than then the optimum. Optimum. So if it's a one minus epsilon fraction of the optimum, I want this to go to one as n goes to infinity. Okay, so this is the problem, the problem that I'm interested in. And of course, now about the epsilon, is this possible? Is this possible for any epsilon positive? And if not, what is the best possible epsilon? Let's say is it possible for all epsilon bigger than some epsilon star that is truly positive? That is truly positive. Okay, and what is the best epsilon star? Now, I would like to, I hope the question makes sense. If it doesn't, please let me know. Of course, this is not the only computational question that can ask about this problem, and I want to take a little parenthesis to mention a couple of other interesting algorithmic questions that can ask. Algorithmic question that you can ask. One can ask the question, of course, of exact optimization. So here we admit a positive epsilon error. For instance, is there an algorithm such that the probability of Hn sigma alg? Sigma algae equal the max over a sigma of h n sigma goes to one and of course there are all things in between where epsilon goes to zero with n the all of those questions are all interesting so these are two extremes and then there is another type of question that is a little bit like question that is a little bit less familiar to mathematicians or to physicists is the question of refutation or upper bound so I'll call it okay let me call it a refutation but I think a more intuitive name for a non-computer scientist is upper bound and what is this question you want an algorithm That spits a number given a sequence of tensor w's, wk's, that are indicated collectively as w, is pizza number, a real number that satisfies two properties. One, the algorithm, this number is always an upper bound on the value of the optimum. This always the optimization is over the hypercube, the Hamming hypercube. And second condition is that it's precise, an accurate upper bound, a tight upper bound when W is random. So under my Gaussian model for the W, the probability that tag is Okay, so you want an upper bound that is always an upper bound, but for random instances is as precise as possible. Okay, these are two interesting questions. Okay, these are two interesting questions per se that I will not address, but you know, it's just an example, I think, of a very rich area. And okay, before dwelling into more detail, let me mention what we know from computer science, at least from worst case theory, from complexity theory. Theory. So we know that unless so consider the quadratic problem, so the SK model, but now the matrix, the matrix coefficient is not random, is adversarial. So to emphasize that, I will not call it W, call it A. And we know that unless P is equal to NP, P is equal to np. So, unless you are able to basically solve in polynomial time mode problems, no algorithms can achieve, let's say. So, I'll call this A instead of W again because it's worst case. Can achieve better, so there exists the real quantifier is there exists a positive C such that. Positive C such that unless P is equal to P, no polynomial time algorithm can achieve this one over log n C to the C approximation. So all algorithms are bound to have worst case approximation where I show that is very large. It's not even a bounded constant. Is there an analogous term for the lower bound as well? Lower bound as well for the lower bound as compared to the upper bound. I don't know, that's the question. Yes, as it compared to the upper bound. Yeah, here I stated a problem that is this upper bound problem. There is no, you know, the two things are not symmetric because, you know, the problem that the way I start. The way I stated the search problem, or the problem that I look at is what in computer science is called the search problem. That problem immediately gives a lower bound because any algorithm, you produce a sigma, you evaluate h on that sigma, that is a lower bound on maximum. So the question, the old question is that the two things are not symmetric, because certifying a lower bound on the max is easy. Bound on the max is easy, just give me a configuration. Certifying an upper bound is not easy, right? So, for an idea of what an algorithm like this might look like, if the algorithm in the case of the SK model, the algorithm that computes the maximum eigenvalue of the matrix W, that is That is a refutation, gives an upper bound because the maximum eigenvalue is always computable in polynomial time, is always an upper bound on the max over sigma of h of sigma. And okay, it doesn't achieve one plus epsilon for any epsilon positive, as we will see. And then is little n equal to big n here? Ah, sorry, good question. Yeah, this is my fault. So this is my fault little n is of course equal to big n. Okay, so this is a little bit of background. Yeah, so here I stated there is a result and just to remind you, I'll be, you know, try to be consistent with my convention of not giving references to save time and you'll find them in the notes that we post. Okay, so. Okay, so now another piece of background that is important, and again, you know, some of you might know well this already, but it's about what is the typical value of the maximum, and this is given by Paris's formula. So, let me write down the formula because this plays a role in what follows. This plays a role in what follows. So I have to start by defining a functional space. So this is the space of function from 0, 1 to R to the non-negative real that is known, that are non-decreasing and such that they have finite integral. Your screen is frozen for me. Is it frozen for anyone else? Oh, it's frozen also for me. Okay. Let me try to close and share it again. Good. Okay. So the typical value is given by Paris's formula. Is given by Paris's formula. So you define the space of function, non-decreasing, non-negative, finite, not less than one, but less than infinity. Okay, please let me know it with freezes. And for any such function gamma, you consider the following PD.  So, this is a P D that you solve backward on the interval. So, you solve it on 0, 1 or 0, 1 open times real with boundary condition at 1 okay, and call phi gamma. And call phi gamma the solution of this. Okay, so you can prove existence and uniqueness in weak sense and all sorts of nice properties. And then using this, you construct the following functional of gamma, that I call p of gamma, which is the value of this guy at 0, 0 minus the integral of This linear function of gamma. Okay, so this is a formula. Yeah, okay, so you have to prove that this PD is well defined, etc. But it's well posed. But what is sorry? What is Xi? Yeah, XI is remember is so here we are looking at. Remember, is so here we are looking at the P-spin models, and Ïˆ is what gives you the covariance of the of the Hamiltonian. So, the way the covariance of the Hamiltonian, this is, if you remember, this is n psi of 2 t sigma divided by okay. So, in particular, yeah, it's a for S case. Yeah, it's a for us k is x squared over two, so it's a simple quadratic. Okay, so now what the theorem goes again, I cited without authors, but it's easy to find out to prove this from our note, for instance. Look at the maximum of this Hamiltonian and the Hamiltonian and the value of the maximum is given value of optimum is given by the inf over gamma in this space u of p of gamma. Okay, so you know describing you know this theorem where it comes from is far beyond the scope. Is far beyond the scope of this lecture. Let me just stress for whoever never saw this is that this is a beautiful thing, right? I mean, there are so many mysterious things going on. First of all, we start with the very simple quadratic function with GOE, and we ended up with partial differential equation and variational problems over this space of function. This is mysterious. Another small mysterious thing is. Another small mysterious thing is that you start with a maximization problem and this formula gives its asymptotic value as the result of a minimization problem. Yet another mysterious thing is that this minimization problem has a lot of interesting structure, right? In particular, we know that so let me state another. That so let me state another theorem that this function gamma p gamma is strictly convex and and infimum over the space U is achieved It's a unique gamma star. Okay. Okay, so we started with the non-convex maximization problem and we ended up with the convex minimization problem over a completely different space. So, where does this So, where does this come from? And yeah, okay. Some of where it comes from should be somehow one idea is given by what I'll talk today and tomorrow. So before, okay, perhaps since this is about half of the lecture, I want to stop one minute to check whether there are more questions. Oh, there's not currently any, but we could wait for a few seconds. If not, so now I want to open another parenthesis and describe a little bit the interpretation. Okay, we just got a question. Is there an intuitive explanation for what gamma is? For what gamma is? Ah, excellent question, because this is the next thing that I was going to talk about. What is the intuitive explanation of what really the minimizer is? Now, I will talk that trying to solve this algorithmic or this computational query actually gives rise to another interpretation of what gamma is. But I'll tell you what is gamma as it appears in Parisi formula, in particular what is the interpretation of the minimizer that I call gamma. Of the minimizer that I call gamma star. Now, I will not be very formal here, I will just quickly describe the idea. Again, you can look at references for theorems. But the interpretation of gamma is that it describes, at high level, it describes the structure of near optima of this function. And one way to think about it is to consider. Is to consider the Gibbs measure. So there are a couple of ways to think about near maxima of this minimizer. The one that is, you know, the favorite one in statistical mechanics is to construct a Gibbs measure. And so by this, I mean this. And so, by this, I mean this probability measure that is one over z. Okay, so think of beta as a large constant and I look at a weight configuration by that thing. Now, a more natural way. Now, a more natural way perhaps for some discrete mathematicians or computer scientists, this would be to look at the super level sets. So, this is the set of sigma. That are at least bigger than one manuscript of opt. Now, the two things are related, and again, let me a little bit informal, but are related in the sense that mu w beta is expected to be approximately, you know. Approximately, you know, the point is that conditional on the value of h, Î¼ is uniform. Okay, so Î¼ is really a convex combination on uniform measure on two slices of constant H. Therefore, you know, now H, you can prove that it concentrates both under the uniform and under. Under the uniform and under the superlevel set measure. And therefore, this is about the uniform measure over the superlevel set for a certain epsilon, when epsilon is some epsilon star of beta. So you can think of the Gibbs measure as basically the uniform measure over a super level set where I tune carefully what is the epsilon corresponding to beta. Epsilon corresponding to beta. So beta large corresponds to small epsilon. Okay, so now this is one way to probe or two ways to probe, you know, near optima. And now how do we probe the structure of this? Okay, there is this idea that again comes from physics is that the way to probe the structure, probe the structure of this near optima is that you take two configurations, sigma one, sigma two. sigma one sigma two that conditional on w are independent draws from from the gibbs measure okay so why is this a good idea well because think for instance of a convex function a strongly convex function right if you take you know two near optics Too near optima, uniformly at random, they will be very close to each other. Think instead of so, this will what will happen, you know, for you know, if your function h of sigma is like this, if I sample two optima, near optima, sigma one and sigma two, will be always very close to each other. If I instead look at a function that has this structure, a sample two near optima, A sample two near optima, with probability, you know, with some probability they will be close to each other, and for some probability, will be very far from each other. Okay, so taking two independent rows from this Gibbs measure tells me something about what is the structure of linear optima. Okay, so in particular, what you look at is: okay, so I'll call it P beta. Beta and the law of so you want to look at how far on the or how close they are each other. Since these vector sigmas have norm square root of n, I can equivalently look at the angle between the two vectors. So I take the scalar product and divide it by n. So this is what's called the overlap. So, this is what's called the overlap. And then you take the limit as n goes to infinity of this. This converges to some measure on zero, one. And what is my gamma star now? Okay, the gamma star, the optimal gamma in the Parisi formula of T, is just the C D F associated to nu beta up to rescaling. Okay, so it's the limit so this is the interpretation of Of of what is this object. Now, what is going to be quite important for us is what is the structure. Of gamma star. And in particular, you know, we are going to think about two different possibilities. Possibility number one is what we call an overlap gap. Option and this means will mean that gamma star is strictly increasing on zero one and then there is the complement of this Overlap gap is that there exists t1, t2 in the interval 0, 1 such that gamma is flat, okay? So increasing, okay, so gamma But uh okay, let me write it perhaps better. Is increasing in sum but this But it's constant in this interval. Okay. So the figure is this novel of gap gamma. Gamma typically will look like this, and so this is no gap, and with the gap that is constant between okay, so so why. Okay, so so why is is what is this difference important? Well, if you think of the interpretation, well now again I'm gonna be a little bit sloppy, but let me let me look at the corresponding assumption at finite temperature. So if you think of the interpretation, what this means, it means that this is the probability that means that this is the probability that if you take two near optima at a distance between T1 and T2. So in the first case, the CDF is strictly increasing. So the measure nu as support nu beta as support everywhere on the interval 0, 1 means that you can find near optima that are at all possible scalar product, at all possible distances between them. There are near optima that are. There are near optima that are orthogonal, but there are also near optima that are almost aligned, but there are also near optima that pairs of near optima that are at angle, I don't know, 30 degrees. In the second case, in which there is a instead there is a gap, means that there are near optima that are very close to each other or very far to each other, but in between there is a gap. Okay, so just if we want. So, just if we want to write a little bit more precisely this, okay, we can say, okay, we can think of the corresponding assumption at finite beta. The corresponding assumption of finite beta is that new beta is strictly increasing. Four T actually finite temperature is some interval zero Q star and is and is constant above Q star. And the consequence of this is that if you look at the probability that there exist two configurations, sigma one, sigma two, in the super level set epsilon for some epsilon that have overlap that is about Up that is about t this goes to one okay so if you have this assumption this is true for any t so we have a question uh do we expect to have one gap or can there be multiple gaps in principle in principle there can be multiple gaps In principle, there can be multiple gaps, right? So, yeah. In principle, there can be multiple gaps. So, in general, at least, you know, for this, there is a whole class of spherical models for which this is studied in detail, and there are all sorts of examples. For this Ising model case that I'm studying here, we don't really have a lot of knowledge on what is gamma star, right? You know, on what is gamma star, right? Once you solve the variational principle, it's difficult to say something qualitatively about the structure of the solution of the variational principle, but we know a bunch of things and the analogy with the spherical model suggests that there can be examples with multiple gaps, with no gap. We're doing gap with no gap, etc. Okay, so now I did this long detour about the structure of the optimizer, the typical value and structure of the optimizer. So let me get back to algorithms for optimizing this. And for that, I'll I'll begin by defining another function space that is a superset of the set U. So I call it L. And this is the space of function, a function from 0, 1 to reals such that, okay, I want the following two conditions to hold: psi second times gamma. Second times gamma in total variation over the interval zero t is finite for any t and then the integral let me write This gamma t dt is also finite. Okay, here the notation is that psi prime, xi second is the obvious thing. Okay, so now. Okay, so now what can I say about this remark? Of course, this is a superset of U. Why? Because remember that what condition had is that gamma is non-decreasing. So by total variation 0t, I mean total variation over the interval 0t or total variation of the restriction of the interval 0. Variation of the restriction of the interval, the function to the interval zero t. So since gamma is non-decreasing, xi second gamma, xi second is also non-decreasing. So xi second gamma is non-decreasing, so it's finite total variation overall interval. And okay, xi second is bounded over the interval 0, 1. So here we had the other condition that the integral of gamma t dt over 0, 1 was finite. Was finite and since xi second is bounded, actually is bounded below and above, these two conditions are the same. The integral of xi second gamma and the integral of gamma are comparable. Okay, so this is a superset, and what is really changing here is that, in fact, once you add a non-decreasing condition to L, you get u. So, u is just L intercept. Is just L intersection with the non-decreasing function. Okay, notice that the fact the non-decreasing constraint in the Paris formula is directly related to the interpretation of gamma. So the whole story that I told you about what is the interpretation of gamma is possible only because gamma is the CDS. Because gamma is the CDF, is a distribution function. Okay, so now what we know about this space L, why we were interested, the space L. The following theorem is true. Assume that the infimum is achieved. Then for any epsilon positive there exists an algorithm and this algorithm has linear complexity So linear means time that takes to read all the tensor w, or in fact also the time that it takes to evaluate the gradient of h at a point sigma such that you can achieve this if. Okay, so. Okay, so this says that it gives a class of algorithms that achieves a value of energy that is given by Parisi by a formula that is very similar to Parisi's principle, Parisi's formula, except that the infimum is over a larger set. So of course, we have, okay, of course things are in the right order, so infimum. So, infer is less or equal. Okay. And by the way, this gives you always a way to prove an independent lower bound on the value of the optimum. And of course, it's interesting to ask ourselves when the two coincide. When the two coincide. And the answer is kind of clear, right? Here you have two variational principles. One is a restriction of the other, is obtained by imposing a stronger constraint. Okay, so you have the set of all functions in L. And intuition is that you have a smaller set in U. You have a convex function, so P gamma is convex in this domain. In this domain. And, you know, what is the intuition is that if the minimizer over U is achieved in the interior of U, then it will be a minimizer over all the set L. So if gamma star is in the interior of U, then this will be also the minimizer over the larger set L. If instead the other picture, so this is the The other picture, so this is the first scenario. The second scenario is that okay, this is L and this is U. And now, okay, I draw them like that, but they are really convex sets, right? And if instead gamma star is on the boundary of U, then chances are that the minimizer over L is different than the minimizer over U. Okay, so the first. U. Okay, so the first in the first scenario inf over u is equal to inf over L, and the second scenario, chances are that inf over L is strictly smaller than inf over U. Okay, so this means that in the first scenario, the algorithm that we constructed basically finds the optimum, in the second scenario, no, it doesn't. No, it doesn't. And there is a strict gap between the two. And in fact, this is not only the intuition, but this is so first scenario is the. So now, so this is this is so this is in the first scenario we have okay here the algorithm achieves Here, the algorithm achieves a near optimum. Why it's not right anymore, and in the second scenario, it's a constant factor approximation. Okay, so now this is not just the intuition, but this is actually what happens. Now, what does it mean? What does it mean? Let's think for a moment. What does it mean that it is in the interior of the set U? The set U is the set L plus the non-negative, the non-decreasing constraint. In the interior means that the function gamma star is strictly increasing. In the other case, the function gamma star is not strictly increasing. So these two scenarios correspond to the overlap gap and overlap gap picture, and indeed this can be made precise. Be made precise. So if no overlap gap then inf over gamma in L P gamma is equal to inf over gamma in u p gamma and And the corollary of this if no overlagap there exists a linear so for any epsilon positive there exists a linear A linear time algorithm that solves our problem. Now, one might wonder: is this okay, too natural question is, is this case empty of novel LAP gap? The answer is that no, no, but at least in physics, a widely believed conjecture, and this is really one of, I think, most interesting open problems in Binglass II. Open problems in spin glass theory, you know, for SK model, there is no overlap gap. So the simple quadratic optimization problems, simple, simple in quotes, has no overlap gap. Okay, so this is one conjecture would be interesting. So this would say that the Would be interesting. So, this would say that the theorem at least is non-empty. The other question is: is there is no overlap gap? So, this corollary goes the other way. If there is a velop gap, then okay, generically, there will be a gap between what this algorithm achieves and the optimum. And what might wonder is this novel up gap condition tight. And this is an open problem, but okay. Problem, but okay, there is evidence that this is indeed the case. So, a second conjecture for whoever is brave enough. If overlap gap, and to this conjecture, there is partial evidence coming from the analysis of other algorithms as well. If we were a gap-gap. No polytime for any epsilon positive unless okay, and you know people have analyzed special algorithms of other types. Special algorithms of other types in this case, and you can get proof that those algorithms fail. Okay, so that's the result. Now, what remains to do is explain how to prove this theorem. And okay, now it's I'll do it in the I'll do it tomorrow. I'll describe the proof tomorrow, but let me prep. Tomorrow, but let me perhaps give the high-level picture or what will go into the proof at very high level, and then we'll fill the details. We'll construct an AMP algorithm. That is very similar to the ones that I described in the previous lectures. So, let me write down the structure for SK. The structure will be pretty much the same that we wrote in the last lectures. So, for SK, the data consists of a matrix and And will be of this form. And the algorithm will be such that if I define the z, so one you know important. So, one important ingredient is that. So, conceptually, what we'd want to do now is choose the function, any such algorithm we can analyze precisely, and we can choose the function f in the optimal way. So, our objective would be choose the function f in such a way that you achieve the maximum possible value. Now, this is a difficult task. You know, a difficult task. It becomes easier if one simplifies, somehow reduces the space of algorithm. And a good way to reduce the space of algorithm is to impose a martingale structure. Okay, and the martingale structure is that. The increment of this z must be orthogonal to the past. So you will impose constraints of this type. So we will not impose the constraints, but we will look for algorithms that have this special thing. So this is, I know Eli Ran talked about related things in the landscape of spin glasses, and one intuition. And one intuition comes in particular from that work, and that work shows that you can think of the landscape of spin glasses with full replica symmetry breaking as not landscape, but the level set, the low-lying level sets as trees, and trees that have the specific property that the branching happens always orthogonally. So once you arrive at So, once you arrive at a certain branching of the tree, to go forward, you have to move orthogonal to previous steps. So, here, conceptually, what we are trying to do at high level is trying to follow one of the branches of the trees, and it's natural to try to do this by imposing this orthogonality condition. Now, this is the only point at which we really use an intuition from physics. We impose these orthogonality conditions. Once you do this, Multi-conditions, once you do this, the space of algorithm simplifies and in particular simplifies. And what we do then will do then, again in the next lecture, is take t instead of taking it one to n, I'll take t that takes value in. You have a discrete process, I can indexed by whatever I want. So I'll indexed by a grid for some constant small delta. Delta depends on my approximation ratio that I want to achieve eventually. And then I'll take delta goes to zero and I'll obtain a precise analysis. I'll describe a precise analysis of this algorithm and limit delta to zero. Limit delta to zero and the analysis, the evolution of the algorithm, the state evolution gives rise in this limit to a stochastic differential equation. At this point, you will be left with some freedom, in particular freedom on the drift coefficient of this stochastic differential equation and some other coefficients. Coefficient. And what we'll do is that we'll choose coefficients of the STA optimally. And this amounts to solving a stochastic optimal control. Optimal control problem now. Okay, and we'll see that solving the stochastic optical control problem gives rise immediately to this modified Parisi formula. So, the value of this stochastic optimal control problem will be. control problem will be this inf of p of gamma. And really the value, the reason why the max becomes an inf is exactly here because you start with the stochastic optimal control problem in which you are choosing your algorithm to get the maximum possible value. And what this inf is is the dual of the stochastic optimal control problem. So this kind of duality is also present at the level of the classical Parisi formula. Classical Parisi formula, but here this is a slightly different optical control problem and gives rise to a slightly different formula in the sense that the constraint set is different. Okay, so I'll try to fill this in the next lecture. Okay, thanks, Andrea. We're gonna unmute everyone who's thinking, Andrea, and then we're gonna go for some, stop with the recording and go for some questions. Stop with the recording and go for some questions.