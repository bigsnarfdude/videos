This is the last talk of the morning session. So Aranimo is going to talk about on the profile of trees with a given degree sequence. Well, thank you very much. I'm willing to be here. I see all you guys after a couple of years. And so I'll talk about a joint work with Osvaldo and Tunsio, who's sitting right here, front row center, on the profile of trees with a given degree C. On the profile of trees with a given degree sequence. So, let me explain the title. So, I think if we're here, we all like trees. I particularly like these ones. And so, I'll really be talking about the ones on the right. And so, here you realize in this tree, I like trees with a huge number of vertices. And you see these blue patches. So, what are they? So, in this drawing, So, in this drawing algorithm that we used, if you have an individual or a vertex with a huge amount of offspring, so a hub, it draws us this blob of ink, right? So, we're interested in scaling limits of trees where the number of vertices is going to infinity, and where you only not only get some leaf-dense trees in the limit, but also. Trees in the limit, but also hubbed dense trees. So, this is what we're interested in. And you might have seen pictures like these if you've encountered stable trees. So, I'll talk a little bit about that afterwards. So, the person responsible for decorating this wall must have read our paper because she really expressed the idea well. So, what you do is you consider a tree. We're going to consider a tree, or maybe even a forest. A tree, or maybe even a forest, and what we're interested in is in the profile. So, this is a rooted tree, it has some generations, and we're interested in the sequence of sizes of generations. And our technique is based on associating to this tree a random-looking path. And then, by a procedure that we'll explain, we're going to sample this path, or we're going to time-change it. Path, or we're going to time change it, to get exactly the profile of the trees. So that's how we'll study a profile of trees. So let me explain the variety of trees that we'll be considering, and that will be rooted plain trees. So they'll have a root here on the bottom or on the left if I draw horizontally. And what makes them plain is that you have an order for the detail. You have an order for the descendants of each individual, right? And we're going to order them. So the first one is going to go to the left, and the ones that have a greater label are going to go to the right. Or if I draw horizontally, the order will increase upwards. So the reason I like to draw them horizontally is because then you have immediate access to what You have immediate access to what the profile is. So the profile is, as I said, the sequence of generation sizes. And here, what you see is this random looking function again that begins to emerge. And what we'd like to do is to describe what the profile looks like for a very big tree. Good, so once we have an order for Once we have an order for the individuals, for the descendants of each individual, what we can do is canonically associate to this tree or look at this tree as a sequence of words. So for example, 2 to 1 here means the first descendant of the second descendant of the second descendant of the root. So in this way, you can state the formal definition of what a root of plane tree is. And this is, I think, the definition that probabilists. That is the definition that probabilists prefer. So, what is the profile? Again, it's the sequence of generation sizes, meaning that for generation K, we're going to count the number of individuals in the tree which belong to generation K. And the generation is actually just the length of the word that represents each individual in the tree. So, finally, I just So, finally, I just have to tell you what the degree sequence will mean. And so, what I did here is I labeled each vertex with their number of the sentence. And what we're going to do is the debris sequence is going to be the sequence of these NIs, where NI is the quantity of individuals with I children. So, if you do the counting, you'll notice that there's eight individuals with zero descendants, eight leagues, zero individuals with Zero individuals with one descendant, etc., and that there are zero individuals with four or more descendants, meaning that this degree sequence will just have a tail of zeros. So, this degree sequence satisfies that the sum of the ni's is equal to 1 plus the sum of i times n i's. Now, there's a way to understand this simply. So, every individual in the tree has a number. Every individual in the tree has a number of descendants, right? So it'll be counted when we sum the announcements. So this is just the size of the tree. And on the right, every individual except for the root is descending from someone, and so it'll be counted when we sum the i times the ni. So this is just two ways to express the quantity of vertices in the tree. And conversely, if you give me an integer C. If you give me an integer sequence that satisfies this relationship, we can build trees with exactly this degree sequence. Not only that, but there's counting formulas for how many trees have this degree sequence, and well, you could do all sorts of stuff. And what we'll be interested in is given a degree sequence, in considering the uniform distribution on trees which have exactly that degree sequence. Which have exactly that degree sequence. Good. So, simple example, right, that will be k are the trees, where your degrees will be either k or zero. And if you choose n vertices to have degree k, then you have to choose this number of vertices to have degree zero so that this sequence of two numbers and the whole bunch of zeros is a degree sequence. Is a degree sequence. Now, the size of the tree that you'll get is here. And you can generalize that a bit. In practice, what we do to construct degree sequences, we just choose ni's for i greater than or equal to 1, say belonging to some set of admissible degrees s, and then you just choose n0 to be this one n so that it becomes a degree sequence. So the main question is, fix a degree sequence denoted here by s. Degree sequence denoted here by S, how does a typical tree with degree sequence S look like? Meaning a uniform tree with this degree sequence, right? So I'll denote by PS the distribution of the uniform distribution on trees with degree sequence S. Now, there's one simple reason you might be interested in the uniform distribution, and that's been explained a little bit by Parabasi and Albert in this influential. Parabasi and Albert in this influential paper of 1999, when they studied real-world networks, they looked at several characteristics of these real-world networks. And for example, the vertex conductivity of the vertices seemed to follow here a power law. And so they just said, well, we take this degree sequence of this network that we study, and let's just look at the uniform distribution of all graphs having this. Distribution of all graphs having this degree sequence. So, this is a little bit of one reason why we would be interested in that. But I'll be explaining more probabilistic reason afterwards. So, here's some pictures for what these trees with a given degree sequence look like. So, we chose here the degree distribution so that the resulting tree has a certain number of hubs. Number of hubs, but not too many. Here, we chose again a certain number of hubs, but we didn't put enough other individuals in the population, so that the hubs seemed to clump together. So we have to be careful about that inner limiting regimes. Here's one without hubs, and this is the kind of picture that you get when you simulate the continent random trend. Simulate the continuum random tree about this. And that's no mystery. Actually, you can get the continuum random tree also as a limit of trees with a given degree sequence. And finally, this is the tree that I already presented to you, this hub-dense tree. And the characteristic that we'll be looking at is the profile. So let's look at what the profile looks like. What the profile looks like. So it looks like this random function here, where you see that it has some upwards jumps, which can be explained as, well, you're exploring generations, you encounter a generation with a hub, and then the next generation is just going to have this big jump upwards. But somehow, downwards, it seems to be continuous, right? So that's what it looks like. And my objective is to explain to you what kind of stochastic process this is. What kind of stochastic process this is? So, actually, it's linked to another function that doesn't look like that random, and that's the cumulative profile over here. And the way you get this one is by just considering the partial sums of the profile, that's why we call it the cumulative profile, and we just scaled it so that it goes from 0 to 1. So, here, for example, you'll notice that there's around You'll notice that there's around 300 generations in the tree. Maybe the biggest generation had like 900 individuals. And if you look at, you know, maybe here, you'll see that 40% of the population is at generation 75 or low. So that's how you read these two things. So I'll give you an explanation for what these two things are. Analysis dependent, scale dependent? Scale dependent in zooming out. Yes, exactly. So we're going to be interested in scaling limits of trees with a given degree sequence. Exactly. So finally, one motivation to study trees with a given degree sequence is given by Galton-Watson trees, which were already mentioned yesterday. So you fix an offspring distribution at a Distribution and a finite tree. And you want, so I'm going to tell you what the Galton-Watson tree with offspring distribution μ is looks like, or is defined by. So that's a random tree theta, and it's characterized by the fact that the probability that this random tree equals a deterministic tree tau is the product over all vertices in tau of what the offspring distribution assigns to the quantity of. To the quantity of descendants of the vertex beat in the tree tau. So that looks something. Let's look at an example. So you have here the tree tau. And if you look at the degrees of the vertices, you'll notice that it's this sequence. And so the formula is telling you that you need to multiply mu3, mu2, mu0, etc. Now, of course, you can factorize. And once you do that, you'll notice that it's just mu0 to the 4, mu1 to the 1, etc. The four, mu 1 to the 1, etc. And these 4, 1, 2, 1, what they are is actually the degree sequence of this tree. So there's a different way to write this formula as, well, if your finite tree tau has degree sequence ni, you're basically going to be multiplying mu i to the power ni. So that's the Right, so that's the formula for the genus. And the obvious consequence now is that this is the same for all trees with the same degree sequence. What that means is that if you condition a Calton-Watson tree by its degree sequence, then it'll be uniform. So this is one way you get trees with a given degree sequence out of Galton-Watson. Given degree sequence out of Galton-Watson trees, and you can even do this for conditioned Galton-Watson trees, meaning for Galton-Watson trees conditioned to have size n. They're also trees with a given degree sequence. That's my probabilistic motivation to study trees with a given degree sequence. So, what kind of asymptotic regimes have been considered? So, in so I'll just consider the So, I'll just consider the case where this offspring distribution μ is a finite variance in this celebrated container random tree trilogy. And in the second paper of that trilogy, he conjectures that the profile of a conditioned Galton-Watson tree would have a scaling limit, which is given by, sorry about this, the total local time of the normal. Of the normalized Brownian excursion. So, of course, now you mentioned local times and Brownian excursions. It seems that it's going to be very technical. And indeed, so Germanic Gittenberger in 1999 proved this Aldous conjecture by using methods of analytic combinatorials. So that was the first proof of the conjecture. And then around the same time, there was this. Around the same time, there was this manuscript circulating by Kirsting where he used more probabilistic techniques to get the same result. And funnily enough, with those techniques, you didn't even have to consider local times. So I'll be talking more about this type of methods. And then also in this manuscript of first thing, which was then afterwards available on the archive. Then, afterwards available on the archive in 2010, he considers a case where this offspring distribution is in the domain of attraction of a stable law, of an alpha stable law, where you can take alpha to be something between 1 and 2. So this regime is very important. It's the one that gets you to stable trees and not only to the continuum random tree of autoscope. To scroll. And so we're going to get these two results by our methods using trees with a given degree sequence. So one thing, I mentioned that Galton-Watson trees and conditioned Galton-Watson trees are mixtures of trees with a given degree sequence. And what that means is that if you prove theorems for trees with a given degree sequence, by just mixing, you can get results for Doubts and Watson trees. So that will be our approach. Our approach. So let me explain the approach in detail. So it goes through breath first walks and the relationship to profiles. So here's a tree. And what I'm going to do is to, it's a plain tree, meaning that individuals are ordered from left to right. And what I'm going to do is I'm going to consider the breadth first labels for the birds. What you do is Verde is what you do is well you assign the root label one and then you go generation by generation as assigning successive labels, right? So this is so one, two, three, four, five, six, seven, etc. Now you're going to define the breadth first walk as follows. You're going to start at one and then your ith increment is going to be the number of descendants of the ith vertex minus one. So this was minus one. So this was the number of descendants of this individual was one. So when we subtract one, we obtain an increment of zero for the breadth first walk. So this is how you define the breadth first walk. And it turns out that you have access to the profile and to the cumulative profile in the breadth first walk. How? Well you just define c of 0 equals z of 0 equals 1 and then what you notice is that the size of Is that the size of the nth generation is whatever the breadth first watt assigns to the cumulative population up to generation n minus 1. That's something you can prove. And then of course cumulative generation up to generation n is whatever you had up to generation n minus 1 plus z n. So this is illustrated here, where, well, the cumulative population is Well, the cumulative population is easy to read in the tree. It's just this sequence 1, 4, 7, 9, 10. And then if you sample this breadth first walk at 1, 4, 7, 9, and 10, what you get is exactly the profile of your tree. So this is our method. And this would be great if I could give you a description for what the breath first wall looks like. Yeah, but this is an interesting relationship anyway. And let me just bring it to the center and tell you how we'll be able to get scaling limits. So, question. The first and the last graph, the first and the third, maybe this is just one example here of it. Look like the ages are swapped. Okay, so yeah, I didn't really talk about this one because it's just an Really, talk about this one because this is the dev first walk, and it's not going to give you access to the profile. It can give you access to the profile, but in a very complicated fashion. You have to construct from this what's called the height process and then the local times of the height process. And that's what makes the analysis with the depth-first work too complicated. So, yeah, the point here is that they're different. Not the same, but they'll turn out to have the same block. Good. So, what So, what does this relationship between breadth, first, walk, and profile actually look like? Well, if you write it down, it's Zn equals W at Z0 at the sum of Z0 up to Zn minus 1. So if you define this as C, well, this looks very much like a derivative. So the kind of relationship is encoded in this type of ordinary differential equations. So our method to get at scaling limits for the profile. At scaling limits for the profile will be to consider scaling limits for the breadth first walk and then to consider solutions to this equation. That's a method in a nutshell. So let me start with the details. First, I'll give you a description of the breadth first block. So you give me a degree sequence, S, consisting of the NIs. The sizes of the trees that we'll get is just the sum of the NIs, and we'll consider And we'll consider uniform permutation on the integers from 1 up to the size of the tree. Now, what these parameters indicate me, I'll construct what's called a child sequence, which is just a sequence with n00s, n11s, n22s, etc. And I'll permute that uniformly using signal curve. And consider the sequence of partial sums of this uniformly permuted. Of this uniformly permuted child sequence, well, I'll just subtract one because of important technical reasons. Also, I'll start it at one so that when I finish exploring the tree or when I finish with this construction, I end at zero. So, what you end up if you do this is with a path that looks a little bit like this. So, it's random, it starts at one, ends at zero. Random, it starts at one, ends at zero. It has only upwards jumps. Downward jumps are only of size minus one. And well, it doesn't look like a function that codes a tree. It doesn't look like the breadth versus walkthrough of a tree. However, what Luigi and Dario Veri proved in 2012 is that if you take a tree with a given degree sequence equal to s, and if x is its breadth first law, then x has the same law as what's X has the same law as what's called the Verbat transform of this exchangeable increment process X. So, what is this Verbat transform? It's a way to turn this bridge-like process into an excursion which actually codes a treaty. What you do is you find the position of the first minimum of the process, that divides your trajectory into the pre-minimum and post-minimum parts. And post-minimum parts, and then you just interchange them. So that's a probabilistic description of the breadth-first walk of a tree with a given degree sequence. So let me just remind you, after we have access to the breadth-first walk, we get access to the profile by just following this research. And in the limit, we would expect to have a limiting. To have a limiting breadth-first walk and to be able to solve these kinds of equations. So, let me tell you about the scaling limits of breadth-first walks. Sorry, can I ask the question on the previous slide? And why is that it's not zero to kilo? Oh, yeah, because when you take scaling limits, time becomes continuous, and then that's right. And then the last you exactly. So this is, if you call this Ct, this will be actually it's complicated because you see this function has jumps, right? So it's not continuous. You can't just differentiate its integral. But you can take the right-hand derivative of the n. Derivative of the integral, and then this will be your differential equation. So let me tell you a little bit about the scaling limits of breath versus walks of trees with a given degree sequence. So first, I'll talk about the scaling limits for the bridge-like processes. So you're going to have a sequence of degree sequences, which will give rise to a sequence. Which will give rise to a sequence of child sequences. And then, what we're first going to do is we're going to order these child sequences. So, the individual with the largest amount of offsprings will have this quantity of descendants, right? So, this is the largest quantity of descendants, the second largest quantity of descendants, and so on. We'll get to this in a minute for why we need to order. So, as before, we get As before, we then get a sequence of these bridge-like processes, of these exchangeable increment processes, and our assumptions will be that, well, the sizes of the tree that we want will go to infinity. Second, there is an assumption on the hubs, and that is that there is a characteristic hub size that is going to infinity. And why do I call this a characteristic hub size? Well, because Well, because the i-largest number of descendants in the nth tree is of size approximately dn, in the sense that the quotient goes to some beta i, which is necessarily non-linear. So that's the assumption on the hubs. And then I also don't want the hubs to clump together or to be, you know, too spaced out. So what I do is an assumption on the rest of the population, and it looks like And it looks like a variance assumption. It's the sum of i minus i squared of nin is will be of order one of b n squared. And that has to go to a quantity that will contains the sum of the bdi's, contains the contribution from the hubs, and does not stray too far apart from that. So those are the assumptions. And under those assumptions, Ari Callenberg in 1973 In 1973, proved that when you have these bridge-like processes, what you have to do is you have to scale space by the tree size and time by the characteristic hub size. And what you get is a limit, which is also bridge-like in the sense that it starts at zero and then is at zero, where the limit is actually an exchangeable increment process. Increment process. And Callenberg had already characterized all of them. And in this case, what we get is that your parameters from the assumptions allow you to construct this bridge-like process as follows. The sigma is going to multiply a Brownian bridge, whereas beta i's will become jumps of the limit. So the second part of the process is just a superposition. Process is just a superposition of very simple processes that look like this. So you start at zero, you decrease linearly, then at some uniform point ui, so this is ui, you're going to jump upwards by a magnitude of beta i, and then you're going to decrease back to zero. So a superpositions of these kinds of processes give you the most general possible scaling limit. Scaling limit for your bridge-like processes. So I'm almost giving you a theorem for convergence of breadth-first walks, but for the breadth-first walks, we need to do this Lampuri transformation. And to do this correctly, what you need to study is these types of exchangeable increment processes. How do they reach their minimum? Do they reach their minimum continuously, or maybe they could just. Or they maybe they could just jump into the minimum or jump out of the minimum, right? So if they jumped exactly at the minimum, you would have a problem in applying the Lumperti transformation and in deducing from this limit theorem a limit theorem for the breadth first watts. So we need to add an extra assumption. And the simple one to add was an unbounded variation assumption. Sorry, previous slide. Under your none have assumption. Under your none-have assumption, you have the beta i's are in the space A2. Yes, necessarily. Necessarily. And at the bottom, I see a sum. Is it a finite sum? How are you going to say A of 1? So that's a very good point. So this sum is typically absolutely divergent. So that's why you need the compensation for the coming from the T and not only the indicator for the uniform random variable. So that's a very good point. Good. So the extra assumption that we need in order to be able to consider scaling limits of breadth versus watts is exactly this unbounded variation assumption, where the sum of the beta i's is infinite, or you have a Brownian bridge component present. And under those two assumptions, you can prove, okay, we're almost done. Almost done, you can prove that the minimum for the exchangeable increment process is achieved continuously at a unique place, and that therefore you can apply the Verbat transformation to prove convergence of breadth first once. So, I'm going to skip this one and this one and this one and go to and this one too. Oh, wait, and go to the main theorem. Main theorem, which is as follows. So we're going to use all of Callenberg's assumptions plus our unbounded variation assumption and an extra one that has to do with the top of the tree. We want the top of the tree not to be too thin. And under these assumptions, and actually, well, you might say, and how am I going to prove this? Yeah, so. Yeah, so there was a previous slide where I gave some conditions for that to hold. But anyway, under all of these assumptions, if you take a tree theta n with a given degree sequence Sn and you define C tilde n and Z tilde N to be their cumulative profiles, its cumulative profile, and its profile, and you scale them as follows. So the temporal scaling is the same for both, and it's the For both, and it's the quotient of Sn over Bn, of total size of the tree over current, there's the cup size. And then the spatial scaling is what is different. For the cumulative population, it's the size of the tree, and for the profile, it's just the characteristic hub size. Then these two things will converge. And what is the limit? So the limit is what's So the limit is what's called the Blanc-Berry pair, which is one very particular solution to the equation z equals right-hand derivative of C equals scaling limit of breadth-free function applied to C. So one particular solution to that equation is called the lempere repair. And what we proved was joint convergence for breadth first block profile and cumulative. First block, profile and cumulative profile to this trip. So I think I'll leave it at that, and thank you very much. Right where uh David told you about a question, there were two that could be uh There were two types of VN. So Vn are the size of the hubs, the proportion of the hubs. You were also having a PT being the Brownian discoursion. So is this kind of the same V or they have an you have the slide where there is a PN and a V. Oh, I didn't quite get that. Let me edit it. Let me go to the correct slide, which I think. Go to the correct slide, which I think is this one. Yeah, yeah. You see, the one in the center corner has a V D, but you said this was a Brownian bridge. A Brownian bridge, exactly. If you applied the verbatim transformation to a Brownian bridge, you would get the expression. Okay. But then this V E is not as a proportion of the. Is not the proportion of the hub. No, no, no, exactly. Yeah, that's the question. One more question from Mom and we have lunch and we resume again at one thirty. One thirty. 