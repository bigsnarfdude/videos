But mainly what I will talk in today will be connected with works with Lubinstein, Florentine and Segel. Hila Bareli was my student, and Shazadowski also my student, and Kasha Vicasani. I'm not sure I will get to the last part, which is more Shai and Kasha involved, but I hope so. Right, so I chose as my starting point, Pekopalander-type inequalities, which is. Point by Copelando type inequalities, which have appeared in this conference quite a few times. So you can look at this project from many kinds of points of view. So this is just as good as any other. So I put here on the slide the Burmikovsky inequality, which we have seen many times. I put it in this one-of-ran homogeneous form, which, as Galia told it, itself improves to this form any other concavity result which you prove for volume of complex bodies. For volume of convex bodies. And I put Pricopp a Leonard inequality over here in this form. So you have three functions, f, g, and h, which are positive. I don't assume anything about them, except that they satisfy this inequality that h at the average is more than, h at the arithmetic average is more than the geometric average of f and g, and then you can conclude the same holds true for their integrals. Okay? And this inequality is many times thought of as a functional version of Pominkowski, in particular, a plugin indicator. Brunkowski in particular, planning indicators, you can conclude Brunkowski inequality, of course, in geometric form, which self-improves, like I said, to this form. Okay, and another thing to mention is that integration here, I wrote it with respect to a vague measure, but you can integrate with respect to any low-concave measure. But this is not really a big deal, because when you plug in here a low-concave measure, you can just multiply its density with H, F, and G, and the condition automatically works as well. So this is not such a big deal. Now, yesterday, Lilan was talking about differentiation. Lilang was talking about differentiation of Brouco-Palangel inequality, and we'll get to that a little bit later today. And what he mentioned was that when you do this, then the gradient comes up. And one of the things we will see is why this happens and how similar things happen in similar situations. Okay, but let me just mention that when you do this correctly, when you differentiate this inequality, when I say differentiate, I mean in the simplest way. So lambda equals zero is an equality, okay? So you can differentiate at lambda equals zero and get an inequality. So when you do this properly, what you can recover for What you can recover, for example, you can recover many inequalities. One of them is the Log-Soble equality for Gaussian measure, which is, of course, in itself very important and has to do with concentration, with many other interesting things, such as hypercontractivity and I forgot what I want. Oh, yeah, and soil cost entropy inequalities and things like that. Okay? And this has been discovered many, independently, many times throughout literature. So I'm not giving any specific references. So, I'm not getting any specific reference here. Right, so now I'm moving to another Picopa-Landler type inequality, which relatively recently we proved together with Dan-Filotin and Alex Sega. And now here I again have three functions. I'm assuming that they have values in 0, 1, so a little more restrictive. And the inequality I assume that they satisfy is kind of weird if you haven't seen it before. But of course, Pukopolando inequality, it's also a weird condition, but we've just been staring at it for many, many years, so we're used to it. For many, many years, so we're used to it. So, this, you know, don't analyze it right now, but this is some inequality that the three functions have to satisfy. And when they satisfy this, then also the integrals satisfy a kind of concavity inequality. This time it's respect to harmonic averages. Again, here, the integration can be with respect to any log-concave measure, and here it doesn't translate, so you can't just plug in the density into the condition and see that it also works. But the proof does follow through also when you integrate with respect to a low-concave density. With respect to log concave density. And again, from this, okay, so this is what's written here. And again, this, if you plug in the right functions, then you can deduce from this the Brumikovsky inequality. Of course, in harmonic form, but it self-improves, like I said already three times. Okay, so this can also be thought of as a functional version of the Brominkowski inequality. Now, what happens when you try to differentiate this inequality in the equality case, which is a very natural thing to do, which was actually suggested to me by a To me, by a Galena at some point. So, when you do this, a funny thing comes up. So, instead of the gradient, which pops up, and I will explain why later, for the first group of land inequality, for this one, what comes up is what is called the polar gradient. So, it's some rescaling, weird rescaling of the gradient, which also came up in this work that I had with Joni Obinstein, which I will also comment about a little bit later. But I just call this for now the polar gradient. So, also, you can prove all sorts of inequalities. And also, you can prove all sorts of inequalities, which we call sort of Log-Sobelev type inequalities, but instead of the gradient with this kind of weird rescaling of the gradient. And this is the work in progress actually with Dan and Alex, which we have not written up yet, so we should. But Dan gave a talk about it in Rio a few years ago. But before talking about, before explaining where these things come up from, I want to discuss for a little bit the natural classes where one thinks about these inequalities. Even Bruninkovsky, right, it's true. Even Bruninkovsky, right, it's true for any three sets, but we usually think about convex sets. And there are many different proofs which apply to the convex situations. That's kind of a natural realm in which to consider it. And Precop√©ler, it's natural to consider it for log-concave functions. And this inequality, as I will explain, it's natural to consider it in some subclass of convex functions, which we call geometric complex functions. So let's do that first for classical epicopernet or again, things that, a lot of the things I'm saying you probably know, but I just want to put everything in somehow the same setting. The same setting. Okay, so first of all, what is this class? Class of convex functions, they have to be proper, not always plus infinity. They have to be lower, semi-continuous, and they have to be convex, which is this inequality. But in terms of the epigraph, I can just say that they have an epigraph, which is a closed, convex, non-empty set. Okay, that's the way to define this class. And on this class, there is an order isomorphism, very famous. It goes back to Legendre, the Legendre transform, which is written over here. And actually, it's unique, as I proved together with Milman and Unique as I proved together with Milman already more than 10 years ago among all ordinary firsting isomorphisms on this class. And this Lejeune transform, well, it behaves very nicely. So if I start with two functions in the Pacopolander inequality, f and g, which are e to the minus the convex function, okay, in this log concave world, and then I look for the minimal function which will satisfy the condition of Pacopolander inequality, then this minimal function then this minimal function, well, if I write it as e to the minus eta, then this eta will also be a convex function, and it will be the inf convolution with weight lambda of phi and psi. Okay, this is very obvious from the condition. But actually, this inf convolution can be written as an average of phi and psi, but in the dual world of Legendre. So I first apply Legendre transform, then take the usual average with weight 1 minus lambda and lambda, and then go back to my world. So this is exactly this eta, which e to the minus eta is the best function you can plug into. Theta is the best function you can plug into Picopolando inequality. And in this sense, in this class of e to the minus complex functions, Picopolando inequality can be written in a very close and beautiful form. So you can just say that it's a concavity result about the addition operation in the dual world, in the world of Legendre transform. And it can also rewrite it using that Legendre is... Oh, sorry. I knew it would happen to me. Using that Legendre is an evolution, you can also write it like this. Just substitute a 5 with Legendre of 5. Substituted phi with Legendre of Phi and Psi with Legendre of Psi. Okay, so this is a very concrete form of Picopa-Lander inequality for functions in this specific class. But now when you differentiate this inequality with respect to lambda, so the right-hand side is very easy to differentiate, right, as a function of lambda, it's super simple. On the left-hand side, well, first of all, I have to differentiate inside the integral sign. So I know Levan explained to us this is highly non-trivial, but I will assume, as everybody does, that we're in a good situation where this is not the issue. Okay, so I differentiate inside the integral sign. So I differentiate inside integral sign. But what's more important is I have to differentiate inside Legendre transform. This already is very, you know, if you've seen it for the first time, it's not exactly clear how to do this, how to take the derivative inside the Legendre transform. And this is exactly where the gradient mapping comes in. And we shall see that shortly, but most of you probably know this, but I will explain this in a few slides. Okay? Anyway, moving to this other Picopolander type inequality that we proved, well, it also can be viewed in Proof, well, it also can be viewed in a very similar way. So now you have to move to a smaller set of functions, geometric convex functions. These are convex functions, but they have to be non-negative and vanish at the origin. For this class, okay, so here's a picture. For this class of functions, it is invariant under Legendre transform, and we can think about it inside convex functions as usual. But actually, there is another order-reversing isomorphism for this class of functions. This class of functions, and together with Vitali, we proved that they are the only ones. And this other order-iverson transform, we named it the A-transform or the Polarity transform. It has this formula that's written over here. Now, I do want you to remember, well, not remember the formula, but sort of visualize the formula so when it will pop up again, it will look familiar. But don't use it to understand what the transform does. Because what the transform does is very easily explained geometrically. You take the epigraph of the function, it lives in Rn plus 1, you take its dual in Rn plus 1. Take its dual in Rn plus 1, okay, just the dual set. This will be somehow something pointing downwards because 0 is at the origin, and flip it back, just reflect it with respect to this Rn, and you get the epigraph of a function. This is the epigraph of the A transform. So it's a very geometric definition of the A transform. If you write it as a formula, this is the formula you come up with. So this is this Polagi transform or the A transform. And now, going to this Procopolander type inequality. This Procopolander type inequality, if your two functions are geometric convex, are e to the minus a geometric convex function, then the minimal h which satisfies this weird condition, well, you can write it like this, okay? It's just taking logarithms basically, or minus logarithms, but you can also write it in a very concise form this way. So it's averaging in the dual world where duality now is taking this A transform. So A transform gives you new geometric complex functions. Now you average them the usual way. Now you average them the usual way and go back. Okay, so this is this weird operation. Of course, the way it was is that we first looked at this and then we found that it has this formula. And for this averaging, now I can write my theorem in the following way. So in this world of averaging in the A world, volume is concave in this specific way, with harmonic average, which is the best thing you can put here. This is a good way to remember the theorem. This is a good way to remember the theorem as well. And now, okay, I can also write it like this again using that this A is an involution. So now differentiating the right-hand side with respect to lambda is very simple. Okay, just a simple function of lambda. But here, when I differentiate with respect to lambda, what I have to do is I have to differentiate inside this A transform. So this is, again, the same kind of thing. We turned off for Legendre transform. This was very classical, how to differentiate inside it. This goes back to, I guess, you know, when they saw. I guess, you know, when they solve these Hamilton-Jacobian Monster-type equations. But for Adron's form, we sort of had to develop the theory in itself. This is something that we did with Yoni W√ºbenstein when we did this work of trying to see really what are the analog theorems to those for Legendre transform that it linearizes certain partial differential equations. What are the analogous theorems for A? So we sort of built up the theorem the theory ourselves. I don't want to go into this, so I don't I'm not even quoting our theorems which correspond to this, and they're also second order equations and so on. Order equations and so on. But what I want is, I want us to look at this whole thing from a different, from sort of a different perspective, a perspective which gives you many other order, many other order reversing isomorphisms. So you can ask, okay, you have two Picopolando, or maybe three, if you include Promikovsky, three of these types of theorems, are there more? Where do they come from? Or can we find more of those? And that's a good question. I mean, I don't know the answer to it yet, but I can give you a very nice source for many order. Very nice source for many order-reversing isomorphisms on certain classes. Okay, so I'm just speaking very quickly. Let me take a breath. Okay, so we're switching a little bit. I just want to describe now something very classical, which is some source for finding order reversing transformations. Okay, and this source comes actually from optimal transport theory. So assume you're given some cost, which at the moment can be any cost you want. I did it on Rn times Rn, but it could be on more general spaces, X and Y, it doesn't really matter. And I allow my cost. And y, it doesn't really matter. And I allow my cost to be infinite, so some moves may be illegal. It just costs me infinite money to move this particle from here to there. I don't want it to be minus infinity. So I can gain things from moving particles, but not infinite amount of gain. That just doesn't make sense from a technical point of view. And now you're given two probability measures, and you want to map them one to the other, okay, and check how much this costs you, and maybe do this in an optimal way. So what does it mean to map them one to the other? So when we're not going to use an actual map, we're going to use We're not going to use an actual map, we're going to use something more general, which is a transport plan. So, a transport plan is a measure gamma on the product space, R2n in this case, whose marginals are mu and u to the two corresponding Rns. This is a transport plan. When you're given a transport plan, you can check how much it costs you to use this plan to take mu to nu, okay, to take all these particles from mu to nu. So, this is the total cost corresponding to a transport plan gamma. It's the integral of the cost, of course. The integral of the cost, of course. And then what you want to really do is you want to find an optimal plan. And under very mild conditions on the cost, some kind of semi-continuity, you can prove that there is always an optimal plan. But how do you estimate its cost? And one simple way to do this is to pick two functions, phi and psi, phi on the space x, on one on the Rn below, and psi on the second space. And assume or try to find the pair of functions which is less than the cost, so phi of x plus. Is less than the cost. So phi of x plus psi of y is less than the cost. Then no matter what plan you choose, in particular the optimal plan, you always have an inequality like this. So the integral of phi plus the integral of psi, you can write them as an integral with respect to gamma because mu and mu are the projects, are the marginals of gamma. And phi plus psi is bounded by c, so it's bounded by the total cost. So this integral is a lower bound for the total cost or from the informal cost. Okay? So in particular, supremum over all of these integrals, find Over all of these integrals, fine psi, supremum going over all of these types of pairs, is a lower bound for the total cost. Okay, now this wouldn't be so nice if we hadn't had Kantorovich-Duality theorem, which actually tells us that this supremum equals this. Well, this is actually a minimum because there is an optimal plan usually, but under very mild condition, here you have actually equality. So this gives you, makes you start thinking about these optimal pairs. How can I find, about these pairs, or admissible pairs as well? Well, pairs, or admissible pairs as we call them. How to find them? Okay, so here's a definition. I'm having this cost which I fixed in advance. An admissible pair is a pair which I can plug into this Kantovich-Duality theorem and get a lower bound. And if I want to get the best lower bound, then of course I want to pick the largest phi and psi. So let's say if I fixed phi, I want to pick the biggest friend, psi, for which they're an admissible pair. And the largest admissible pair, I can write a formula for it. Admissible pair, I can write a formula for it. The largest admissible pair, well, it has to always satisfy that it's less than the cost minus phi, right? So it has to be exactly equal this if it's the largest possible. Okay? So every function phi has a largest admissible pair, phi c. It's the cost transform. But here you're seeing that I'm taking a function, I'm producing a new function. This is a transform on functions, okay? And you can see that it's sort of reversing, right? There is a minus sign. So the largest phi is, the smaller its largest admissible pair is. Its largest admissible pair. So this produces an order-reversing transformation. And what's even nicer is, well, let's do this in some steps. So first of all, any other admissible friend is less than phi c, right? We chose the biggest admissible friend. And from this, I can conclude that phi itself is less than when I do it twice, this cost transforming, right? Because phi and phi c are an admissible pair, and phi c is the biggest admissible friend of phi c. Admissible friend of phi C. Okay, so I have this kind of inequality, but now when I have this inequality, well, I can plug in phi c into this inequality, and I get, and if I plug there phi c, I get that phi c is less than phi c, and then two c's, so phi triple c. But the other thing I can do is I can look at this inequality and just apply the cost transform to both sides. Okay, cos transform reverses order. So I get that phi c is actually more than phi cc. So they're equal. Okay? So by this, you know. Okay, so by this, you know, it's extremely trivial, okay, but what I really get is that on the image, on all of phi C's, when I go on all possible phi's and I apply the C transform, so this I call the C class, on this, the cos transform is an order-reversing involution, actually. Okay, so the C class is the image of the C transform, and on the C class, the C transform is actually an order-reversing involution. So, this is a source for order-reversing involutions. Okay, a very good source, actually. I was teaching it very. Good source actually. I was teaching a graduate course in the first semester, and I gave it an exercise for the students to just choose their favorite C and compute these transforms, and they got very interesting answers, some of them, not all of them. Okay, so this was the definition. Let's just check a couple of examples. Let's not go through the computation because they're really very simple. So one trivial, one not trivial, one important example to consider is minus x dot y is your cost. Minus x dot y is your cost. This is actually almost the same as taking quadratic cost. Let me not explain why. Okay, and when you apply really the definition, you really get, right, you apply this in FEMUM, you take the minus sign out, you get a supremum, and this is really the Legion transform in here. So for this cost, what you get, up to a minus sign, this is the Legionner transform, this cost transform. And the class you get, of course, are, well, it's minus, so it's concave functions, not convex functions. Functions. Okay? And the same is with the quadratic cost, but we not go over this. Another interesting cost, we call it now the polar cost, as you will see in a minute, why, is this minus log x dot y minus 1. Notice that this cost is sometimes plus infinity, okay? So it has its own problems. But nevertheless, when you compute what you get, you write this formula, the infimum, you use the properties of log and take the minus the outside, you get minus log supremum of x dot y minus 1 divided by e to the minus 5. This is exactly the formula. This is exactly the formula for the A transform. Not of phi, but of e to the minus phi. Okay, but you also have a look. So what you really get here is that the cost transform up to taking e to the minus or taking minus lambda, whichever you prefer to think about it, this is really the A transform. So these cost transforms are a source for both of our order reversing involutions that we discussed. And okay, let me skip this, but you can also find the cost for which you get polarity for norms. So for which the C-class is a class of all norms, and the transform is polarity. It's, you know, usual duality. It's, you know, usual duality polarity, what do you say, for norms? Okay. Okay. Some fun facts in general about the C-transform because it's really quite fun to work with. So if you want to analyze what is your C-class, well, there are basic functions that are always in the C class, which is taking your cost and just plugging in one of the arguments to be fixed, okay? And also up to constants as well. They're always closed under in FIMO, so in FIMO of functions in the C class is always in the C class, like convex functions, in FIMO of convex functions, for instance. Convex functions, for instance. It is still convex. And in fact, this characterizes C-class. So functions are in C-class if and only if they are infremum of these basic functions. So this is a nice way to analyze your C-class if you found a cost. Okay, now going back to Gondorovich duality, if I really want to analyze when do I have equality here, and if I moreover want this to be a maximum, so I want to really find a potential, a pair for which you get equality here, well, this is not always possible. Equality here. Well, this is not always possible, but pretend that you're trying to do this. Well, if you're trying to do this, then first of all, of course, when I fixed phi, I just increase phi if I choose it to be phi c. Okay, so I always may assume that I'm actually dealing here with a pair phi and phi c, and because I can replace it with phi c and phi c, I can also assume that my phi is in the c class. Okay? But there is much more than that, because if you look at this chain of inequality, this chain that I showed you before, there is actually inequality just in one place. Is actually inequality just in one place. So if gamma is the optimal pair and you want this to be equality over here, then you actually have to have your measure, gamma, this optimal measure, concentrated on the set where these two things are equal. So it has to be concentrated on the set where phi of x plus phi c of y is equal c of y. This is a subset of R2n, which is rather small. So this motivates the definition of the C subgradient of a function. Gradient of a function. If you're given a function in the C class, the C subgradient are exactly these pairs for which you have equality. And if I want to think about it as a mapping, then I can fix my x and just look at all of the friends, its friends y for which you have equality over here. Note that this really means that in the definition of phi c, which was an infimum of c minus phi, in this definition, the infimum is attained at x. Okay? So this set may be empty. There may be x's for which they have no friend, y. No friend, why? Okay? So, this is, in general, this really can happen, but nevertheless, in many cases, it doesn't happen. So, in many cases, this really produces a map. So, one important case is the case of Legantre transform, this cost that I discussed just now. And in this case, again, let me skip the computation just because of time consideration, but it's really just following through the definition of what it means phi C and moving things around, you really just get at the end the definition. Just get at the end the definition of the subgradient, the usual subgradient. Not of the function phi, but of the function, you know, the convex function associated with it, which is the minus. Okay, so the subgradient, the c subgradient of phi for the quadratic cost, or in this case it's this almost quadratic cost, is really the usual subgradient of the function psi of minus phi. Okay, so this is also the reason for the name, C subgradient, of course. And this is manifested in this famous Brinier theorem, which you know is a cornerstone in our theory and can use for many things, in particular for It can use for many things, in particular for proving Pakopahendel inequality in like a one-line proof. Because what this Manner theorem tells us tells us if we have two measures, what we want to do and what we can do according to this theorem is we want to find a transport length supported on the graph of a gradient. Okay, now because the measure is absolutely continuous, you know, convex functions, they have subgradients, but almost everywhere they have gradients. So you can actually decide that you want this to be a gradient. And this is not just any transport plat, this transport plat is on. Transport plat, this transfer plat is optimal with respect to this cost, or the quadratic cost. It's the same in this case. Okay, now of course there are many interesting things to say about this, and there are theorems about regularity which are very important for other applications. But in general, this theory is very much connected to everything that we have been discussing. And in particular, we would like to understand what happens here if I change my cost from quadratic cost to this polar cost, which is so much connected with the A transform, and see what this means. Okay, so to understand this, I have to understand. Okay, so to understand this I have to understand what is the C subgradient for the polar cost. Okay? So again it's a computation. In this case it's a bit more tedious. It was also done in this work with Yanil. So the polar subgradient has to do with the gradient of this geometric convex function associated with phi. So my phi is minus log psi for a geometric convex function if it's in C class. And this geometric convex function, it has a gradient, but this is not the gradient, it's some rescaling of the gradient. This is what I told you before. And it's rescaling by the Legend. Told you before, and it's rescaling by the Legendre transform. Okay, so it looks like, okay, I didn't do much because all I did was change the gradient to some kind of rescaling it, but this rescaling is very important. And actually, any cost you take, what you will get is a C subgradient will be related to the gradient. The gradient just appears there because this C subgradient means that your X is optimizing phi C of Y, it's where the infimum is attained. And when infimum is attained, this means that a gradient vanishes, right? And the gradient here is, well, you have the derivative. Here is, well, you have the derivative of c, but you also have the gradient of phi. So you always have something involving the gradient. This is always what you'll get as a c subgradient. The question is, what, you know, what kind of rescaling or function of the gradient you get. Okay? So, yeah, okay. Let's do this slide, even though I don't have time. So I can I rewrite what I wrote in the in the previous slide. Now I I exchange phi for phi C for my own reasons, but it's really exactly the same thing. Reasons, but it's really exactly the same thing. So, this is something that has to be satisfied by the gradient mapping, by the C-sub gradient mapping, which now I call it y of x. Okay, it's some mapping. It's not always well-defined. Sometimes you don't have this y of x, and sometimes y of x is many points, okay? But in some natural situations, you can expect it to really be a real function, a real mapping, okay? And now, if you go back to my original motivation in this talk, which was to differentiate Precopelander over some other version of Precopa Lander, then what we really have there is a way. Then, what we really have there is a one-parameter family of functions. What we had there was this one-parameter family of functions, which was linearly changing. But there was some magic that both convex functions and geometric convex functions, their linear structure there exists. For other classes of functions, it's not always the case. But never mind, it doesn't matter if you just have a one-parameter family of functions, anything, and now you want to differentiate with respect to the parameter, then you can always, and you have this sub-graded mapping in your hand, and you can write the equation for the subgraded mapping. Write the equation for the subgradient mapping, what it means. Now, my y depends on x and on t, because for every function I have a different c subgradient mapping. And now, when I differentiate this equation with respect to t, let's see what I get. So I get the derivative of phi with respect to t and the derivative of the c transform with respect to t at the point y, but then I also have an inner derivative here, right? So I have to differentiate my phi c with respect to the space variables and multiply by the chain rule, by the time derivative of my c subgradiate map, which in general may be very complicated. Map, which in general may be very complicated. I don't know what it is, okay? But on the right-hand side, I'm also differentiating with respect to time, so I get this product of two derivatives. And by the definition of the C subgradient mapping, these two terms cancel. So what I'm left with really is that the sum of these two equals zero. So the time derivative of my function and the time derivative of the C transform, in other words, differentiating inside the C transform, is the same as differentiating without the C transform, up to a minus sign, but... Up to a minus sign, but not at the usual point at this C subgradient mapping. So for Legend transform, this is just the gradient mapping. This is why we get gradient, this is why we get, you know, things like Log Sobolev, which include which use the gradient. And this is why when I differentiate the second Pergoppin-Andro type inequality, which corresponds to the A transform, I'm having a different cost here. So I have a different C-subgraded mapping, which is the C-subgraded mapping corresponding to the polar cost, which is this rescaling. So this is where it comes from. It comes from. Okay, I have two more minutes, so I maybe say something about it, but I wanted to. Right, so oh, and now moving to the spoiler class, which is our main interest, I want to explain what it means geometrically. It's very simple. So if I have a geometric convex function, then it's actually, well, any convex function is a supremum of linear functions, right? But because it's geometric, it's actually a supremum of these truncated linear functions, okay? Which I truncate them to be positive. And this is it's, so in the log world, this is like the basic. In the log world, this is like the basic functions for this class, of every function, like this supremum of these functions. And now, if I want to find out what is the polar subgradient at a certain point x, well, I look at the point at the value of the function, I look at actually the supporting function there, okay? So this looks like the usual gradient I'm looking here, but I'm writing it in a different way. I'm writing it as some beta, some number times x dot y 0 minus 1. So I'm writing it in this, like this cost. The cost was with the log, but I moved to the convex world, so I did e to the minus log. To the convex world, so I did e to the minus log ever. And this y0, this guy is what's important, not beta. So if I multiply everything by five, I'm changing the gradient a lot, but I'm not changing the polar gradient. Okay? Because in the log world, it means like adding a constant. And adding a constant doesn't change your gradient. Okay, so this is the polar subgradient. It's this y0, which really corresponds to where this line intersects the x-axis in this one-dimensional picture. And now the question we asked ourselves, and this is the topic of my talk, We asked ourselves, and this is the topic of my talk, of course, my time is nearly over, is which measures can be mapped to one another, not using a Branier map with the usual gradient, but using this polar subgradient? Okay, or maybe more generally a C subgradient, but we're concentrating on this because we have this inner feeling that this cost is quite important because it corresponds to these geometric complex functions. Okay, so now let's not go over this definition, but it's not very hard to find a necessary condition. So not, and it's not like with Reijang, it's not like with Wayne. And it's not like with Rejunct, it's not like with Wayne. Not any measure can be mapped to any measure, even with a just with finite cost, never mind optimally. Because there is a restriction. Because of these infinite costs, some things you cannot do. So this is a necessary condition. It comes from Hall-Merriage theorem in the discrete case. And let's not go into it. So you can, it's a simple observation to see that this is a necessary condition. But unfortunately, it's not sufficient. So we have even a one-dimensional example which shows... I'm sorry. Which shows that it's not sufficient. Okay, I will not go over this example, I'm sorry, although it is instructive, I think. Basically, you build, you just, you build a set on it, you put a measure, you project it, you see that there is a transport plan between them. This means that they are polar compatible, but there cannot live a polar subgradient on this set because it approaches this blue thing, which is x dot y equals 1. thing which is x dot y equals 1, which is kind of a bad set. So I had a nice explanation for this, but I mean for time considerations I won't go into it. Really in one dimension we understand a lot. In more dimensions this has to do with this cyclic monotonicity which you probably know from the Legendre world where the cost is just quadratic cost. But when you move to a general cost, well the definition stays the same. A set is called, this is now a subset where the plan lives, a subset of Rn times Rn. Subset of Rn times Rn. A subset is called cyclic nomonotone if, whenever I pick an n-tuple in it, it's an n-tuple of pairs, okay? So this pairing is the optimal pairing among all permutations. It's a very natural thing to consider for optimal transport things. And again, it's classical and very easy to see that if you're already included in the graph of a C-subgradient, then you must be C-cyclically monoton. It's a one-line proof, but let's not do it. But what's interesting is the converse. What's interesting is the converse. So if you are included in a C-tycli monotone set, can you find a potential? Are you already forced to be, like in the Legendre case or in the quadratic case, are you forced to be the gradient of a subgradient, the C subgradient of a geometric complex function? This was the proof of this easy observation, so I'm skipping it. And the answer is no, even in one dimension. In one dimension, C-ticky click-level just means decreasing, just like Okay, just like the usual one means increasing, being the gradient of a convex function means you are increasing. Being the cistern gradient means you are decreasing, actually. There's a unique way to map a one-dimensional measure to another in a decreasing way. Okay, just take all the mass from the left and move it to the rightmost you can do. And this explains this counterexample, which I didn't have time to discuss. But in general, being seatically monotonous does not mean that you have to be on the gradient of a convex function, but if you impose On the gradient of a convex function, but if you impose one more condition, this is the condition over here, that you are far from the bad set, x dot y is always more than 1 plus t for your set, then it is true. Then this set is polar cyclic homonotone if and only if you can find a potential, a geometric convex function, such that you live on the graph of a T-sub. Maybe this is the theorem with Hilena. The meaning of good here I did not explain, but you can take that this projection is connected or something like this. This is very mild, even less you can take. Even less, you can take. In certain situations, these can be removed. For a finite set, for example, everything works perfectly. And in dimension one, if the projection is connected, not like the example I showed you, then also you can remove this condition. Okay? And okay, I had some explanation about the finite discrete case, which explains what does the polar compatible come from, but let's not do this. This has to do with Hall-type theorem. And because this T enters, this actually brought us to think of a variation of. brought us to think of a variation of the A transform, which we call the AT transform, which is very curious. It really looks exactly like the A transform, but you supremise not over x dot y more than 1, but x dot y more than 1 plus t, this tiny difference, which forces it to be like in the Git set. Now it looks weird because this looks like a supremum of linear functions, so it should be convex, but actually not necessarily convex because of what happens below the supremum over here, and as you can see in this picture around here. So we are considering this, this is in this work with Chai and Kasha. In this work with Shai and Kasha. And we are considering what is the C-class and how they look. There's an easy answer, there's a more difficult answer. Really, when t goes to infinity, t goes to zero, they really look like geometric convex, very similar to geometric convex functions. And we are even able to show that contrary to the case of t equals zero, where there are two order isomorphisms in geometric convex functions, Legendre transform and A transform, when you take t positive, then actually you just have this AT, you don't have more than this. Have this AT, you don't have more than this. This is still a work in progress, and hopefully, you understand more about these polarity transformations. So, thank you. Questions? In your initial inequality that you have wrote at the start of the shortcut,