Thank you very much for having me. Although, as you will quickly see on my slides, there's not so much statistics, to be honest. So it's really a purely deterministic formulation. But well, my goal with this talk is to maybe attract your interest in looking at these minimization-based formulations and way. And maybe there's a chance to get in some statistics which would be needed in particular to get proper models for the noise in the data and also possibly proving something about convergence in the usual statistical sense. But for now, it's really just deterministic. And I would like to start off with the classically reduced, then all-advance formulations, and then going. All-advance formulations and then go into variational or minimization-based formulations of inverse problems. Then, of course, inverse problems are always ill-posed, so we have to do some regularization, and our regularization here will mainly be, sorry, will mainly be by iterative methods. Okay, so that's the overview. So, I will start off with some examples for a motivation. I will spend a bit Motivation. I will spend a bit more time on a particular example that I like very much. That is taken from a paper by Colin Fogilius of 87, which is already quite many years ago. But it's a really nice and neat formulation, which is basically the motivation for was the motivation for me for studying minimization-based formulations of inverse problems. And then most of the talk will be taken up by looking at. Will be taken up by looking at iterative solution methods, not just iterative solution methods for optimization problems that they have been around for a long time, but for ill-post optimization problems that arise from such minimization-based formulations. Okay, this has been funded by the project by FWF, and there's also additional funding to be acknowledged by our doctoral school. Okay, let me start off with some examples so that you have something in mind before it becomes a bit more abstract, namely parameter identification or coefficient identification in PDEs. So here's a classical example one could call it the ABC example, because all kinds of coefficients pop up here. It's always an elliptic PDE. We might be after the diffusion coefficient, the space-dependent diffusion, or some potential C, or also just simple. Potential C, or also just simply a source term, or maybe combinations of these. And while in practice, usually one has boundary observations, there are some practical situations where also one has interior observations of the state U. One particular example is electrical impedance tomography that you have already seen in this workshop. So identifying the conductivity as it's now called, sigma, this. As it's now called sigma, this before it was a diffusion coefficient, so this sigma in the same elliptic PDE, there are no other coefficients, it's just equal to zero. And what we have is really boundary measurements because it's tomography, so it's looking into the body from outside. And the usual measurements that we have is combinations of currents and voltages, ideally all possible combinations of currents and voltages, which corresponds to the number. Which corresponds to the Neumann-Dirichle operator, but in practice it will be finitely many, hopefully, many, hopefully, sufficiently many. One can do things also for time-dependent problems. I will not go into detail about this in this talk, but there's also some advantages of these formulations for time-dependent problems where one has a volutionary PDE or ODE. So, if F over here also contains a spatial differential. Contains a spatial differential operator. This could be a PDE, parabolic PDE, or if you look at the reformulation as a first-order system, it could also be a wave-type equation. And then there's some parameters, possibly also infinite-dimensional parameters in this right-hand side that are supposed to be identified from additional observations. So these observations in time-dependent problems might take the form of continuous in time. The form of continuous in-time observations, but practically more relevant will be discrete observations. But this is just a sideline. So now let's become quite abstract right now after these few examples and write them more generally as systems of operator equations. So what we always have is a model such as a PDE or ODE which contains a state U. Which contains a state u and a parameter q, or a set of parameters denoted by q. And in addition, we have observations. There can also be written in terms of an equation. Y is the data that we really observe. And observations are usually taken of the state. There might also be some parameters involved in the observation operator, unknown parameters. But for simplicity, I will just stay with such a state-dependent. Just state-dependent observations. So, usually these are objects in function spaces, more abstractly, Hilbert or Banach spaces. Slightly more concretely, this A will be a differential operator. For fixed Q, it will be a differential operator acting on the state U. And C, as mentioned, is an observation operator. So, the classically reduced approach is to To eliminate the state here. So we say we know the model is true, and then we to a fixed parameter Q, we assign the corresponding state such that this model is satisfied. And this assignment is done by what is usually called parameter to state map or in optimization community control to state map. And its concatenation with the observation operator. Coordination with the observation operator gives us a forward operator. And this combined model and observation system can be written in this reduced form as an operator equation just for the Q with the forward operator F. Alternatively, one could also go ahead and stay with this system of model and observations and also write this as F of something is equal to Y, where this something still contains. Where this something still consists of both of the state and parameter. And then, even more generally, one can go to minimization-based approaches. But before showing that, I would like to motivate a bit why sometimes it might make sense to avoid this parameter to state map. So, quite often it's numerically quite expensive to evaluate because to evaluate the parameter to map maps. Because to evaluate the parameter to state map, one has to solve a PDE. It might be a non-linear PDE, it might be a system of PDEs. Also, well-definedness of the parameter to state map can sometimes be a problem or can be too restrictive. And this is, for example, the case if one deals with parameter identification or optimization in the context of singular PDEs. So here's an example, a very simple example of a Simple example of a static MEMS, so micro-electromechanical system model, where one has this potential singularity in the denominator. So if u goes close to minus one, then the denominator gets very large. And on the other hand, the Q here is the parameter or control that we want to design. So we have to be very cautious with the set in which we allow our Q to be in order to stick. Allow our Q to be in order to still have a well-defined parameter to state net. Also, in the context of time-dependent problems, it's well known, of course, in PDE-constrained optimization for time-dependent problems, there's this forward-backward coupling via the adjoint PDEs. That's to some extent unavoidable. But the question, of course, arises how strong does one want to follow this scheme of forward and adjoint coupling. The theme of forward and adjoint coupling. And this can also be circumvented or avoided or relaxed to some extent by using volatile formulations. Actually, in the PDE control community, these are methods of that kind of known as one-shot methods in the context of time-dependent PDEs. So, the goal of that project that I mentioned was to derive formulations of inverse problems that avoid the parameter to state. Avoid the parameter to the state map to some extent. And this can be achieved also, among others, by minimization-based formulations. So coming back to this general setting slide with this model and observation operators and the choice between reduced and or advanced approach. A minimization-based approach can be derived from that in a very simple-minded way by trying. simple-minded way by just replacing these equalities these or these equalities by minimization or least squares minimization problems so this is back to our original formulation and of course clearly this is equivalent this equation here is equivalent to minimizing the residual in an appropriate norm so one might choose this norm as well which gives additional possibility of tuning one can also go One can also go for this or advanced type formulation and then do the component-wise, so to say, least squares minimization in a combined cost functions. Of course, one can play with weighting parameters here. One can put one of them as a constraint. Typically, one will do so with the model. If one assumes the model is exact, then one would demand this to hold with equality and then minimize. Quality and then minimize the data misfit. But one can also go ahead and switch roles and say we minimize the model misfit such that the data are exactly met or exactly fitted. Well, in the context of noisy data, of course, it does not make sense to fit the data exactly, but of course, there's many other versions of doing this. One can relax this constraint, for example, which amounts to more rosy. For example, which amounts to Morozov regularization, one can put additional regularization by constraints, which amounts to Ivanov regularization, and so on and so forth. But even before adding regularization, there's many more versions of reformulating inverse problems as minimization problems. And I would like to spend a little bit of time with the example that actually originally very much motivated me to look in what... Motivated me to look in more detail into this type of formulations, namely the variational formulation of electrical impedance tomography by Kom and Fogilios in this seminal paper of 87, and of course many follow-up papers. So I will actually follow the exposition in this paper by Khon and McKenney of 90, but there's also other reformulations and also applications to other problems. Also, applications to other problems, not only electrical impedance tomography. So, you have seen electrical impedance tomography, of course, formulated many times. You have even seen it a few slides ago, formulated as an elliptic PDE coming basically from a combination of part of Maxwell's equations together with constitutive laws. So, let's go back a bit to what comes more directly. To what comes more directly from Maxwell's equations, namely first-order equations. First of all, this current balance equation. So the divergence of the current density is zero. And on the other hand, the curl of E of the electric field vanishes. So these are the two, so to say, balance equations that we have. And the constitutive equation linking them is this one here. So the current. This one here. So the current is proportional to the electric field via the conductivity Ïƒ as a proportionality factor, so to say. And the conductivity is space dependent. That's the quantity that we are after here. Now, due to these two equations here, here the divergence vanishes, here the curl vanishes. Of course, we can write things via potentials. So we have the electric potential for the electric field, and we have a Field and we have a potential also for the current density in three space dimensions, it would be a vector potential in two space dimensions. One can write the curl like this, and then it's also a scalar potential. Let's call it psi and phi. And also they have indices attached because we have more than just one measurement. So we have, say, capital I excitations by boundary currents, which leads. Currents, which lead, of course, to different current currents and electric fields, but it's always the same conductivity, of course, that we want to observe. Now, with these potentials here, we have already satisfied these two first equations. Now it's just this third equation, the constitutive equation that we still have to write down. Still have to write down. We write it by replacing j by this minus curl of psi and e by minus the gradient of phi. And we somehow symmetrically distribute this vector sigma. On one hand, we have a vector sigma on the on the e side, so to say, sorry, and we have a one over square root of sigma on the j side. So that's these equations up here. Equations up here. Additionally, let's recall that we have boundary currents and voltages. These translate into theoretically boundary conditions for these potentials. So, of course, the voltage on the boundary is just the value of the potential on the boundary. And if we integrate the boundary currents in tangential direction, this is what is done down here, then we get Dirichlet boundary conditions for the potential for the current density. Current density. And so we get this reformulation as a, so to say, well, first order differential equation, a system, because we have different possible excitations. And now instead of assuming equality here, we just minimize the L2 residual in this equation here. So that's it. So that's it. That's not yet the end of the story. We can still multiply out this square here under the integral, and that's actually the reason why we have distributed this sigma like this, because if you take the mixed term, well, of course, there will be a term sigma times the norm of the gradient of phi i squared, and there will be a term one over sigma times the curl of psi i normal. Psi i norm squared and the mixed term will be minus two times nicely sigma squared cancels out and then we multiply a gradient with a curve. Integrating over omega, this gives zero or almost zero, zero up to boundary terms. So it more precisely gives the boundary integral of the voltage against the current. And that's something that we know. So in our minimization problem, we can neglect. In our minimization problem, we can neglect this, it's so to say constant, and we end up with this neat almost quadratic formulation. So, it's well, since sigma, phi, and psi are unknowns, it's of course not quadratic, but for fixed sigma, it is clearly quadratic and has nice convexity properties. So, it's a reformulation of the EIT problem that you probably know much better. Probably know much better as an inverse problem for elliptic PDE. And actually, looking at this minimization problem and writing down the Euler Lagrange equations for this minimization problem, of course, one ends up with the second order potential equation, but the sort of more original one is this one here. Well, one could now go ahead and add regularization. Add regularization by means of Tikhonov, so adding a penalty term over here. Possibly adding constraints in order to additionally stabilize the problem, which would be even of regularization, relax these equality constraints, because anyway we will just have noisy data here. So the VI and possibly also the gamma i will be contaminated with some noise, so it doesn't make. It with some noise, so it doesn't make sense to assume equality here. So then let's relax this to this being in some, so to say, delta tube around the measured values, which corresponds to what is called Morozov regularization. And then apply standard optimization tools for solve this, for solving this. So we have done so, and other people have done so before, we have done so, including proper regularization. So, including proper regularization and analyzing it. But what I would like to show you today is not so much adding regularization and then optimizing and then applying standard optimization tools, but leaving more or less up to, of course, inserting noisy data here, this inverse problem formulation as it is, as ill-posed as it is, and regularized. And regularize by iteration, namely more precisely by early stopped iteration. And there's actually two versions that I would like to look at as far as time permits, namely gradient-based methods and Newton type methods. So first of all, let me set the stage, and it's again about abstract formulations, not just this EIT problem, but abstract formulations of inverse problems. Formulations of inverse problems is constraint minimization problems. So we minimize some cost function j such that our unknown is in some set M, some admissible set M. And now our unknown X might contain just the parameter Q, but might also contain in a sort of all-advance formulation both state and searched for parameter. The X solution is denoted by X dagger. is denoted by x dagger. And let me just state the first order optimality condition provided j is differentiable, it looks like this. So in our conversions result, we refer actually rather to the first order atomality condition first of all rather than the minimization itself. So we make some assumptions on these items, of course. First of all, as a sort of normalization assumption, As a sort of normalization assumption, we assume that the cost function is always non-negative, at least on our admissible set. We assume, of course, that our exact solution is admissible. Otherwise, of course, it could not be in solution of this minimization problem. And the minimal value, which is supposed to assume at this exact solution, we assume it to be zero, which looks like we have already solved our optimization problem. Well, we know the minimal. Problem, well, we know the minimal value, but of course, we don't know the optimal solution. This makes a lot of sense in the context of reformulations as least squares problems, because then you know you want to get the residual to zero, at least for exact data. You want to do that, and this corresponds to the optimal cost function value being zero. That's not the end of the story because we just have noisy data. Because we just have noisy data. So, this is still just a theoretical formulation because, in computations, we don't have the exact data that might enter our formulation here. So, for example, in the EIT formulation, here it's still exact data that would enter the definition of our admissible set in these constraints here. But we only have noisy data usually, so we Data usually, so we have to modify our cost function possibly and/or our admissible set. So then we have to carry over our normalization assumption. Still, we assume that our cost function is non-negative, but we don't assume that a minimizer really takes value zero, but we relax this a bit by some. Bit by some, so to say, tolerance value that might depend on the noise level that we have in our noisy data. And it depends, it usually will depend on the noise level in the sense that it's supposed to tend to zero if the noise level tends to zero. So the noise level tends to zero, at least in our analysis. Unfortunately, it doesn't always do so in practice, but still, if one wants to analyze the quality of a regularization. The quality of a regularization scheme. One looks at what happens if observations get better and better, the noise level gets smaller and smaller, and therefore we will also study convergence as this noise level tends to zero. And also my results that I'm going to show, or our results actually that I'm going to show, deal with this question of what happens if the noise level tends to zero? Do the minimizers that we reconstruct The minimizers that we reconstruct, or actually the iterates on the way to these minimizers, do they converge to the exact solution of the inverse problem? So as already mentioned, the goal is to look at iterative regularization methods for such problems where the steps are defined by either gradient or Newton type paradigms and the constraints also have to be taken into account. To take be taken into account, and there's also several options known from optimization. Probably this most simple one is just to take steps and then after each step project what the outcome onto the admissible set. Or, especially in the context of Newton type methods, one can also do the minimization that is underlying actually the Newton step as a constraint minimization. And there's, of course, And there's, of course, from these two by two choices, there's in principle four combinations, but we only looked at two of them: namely, projected gradient methods and Newton-type methods, namely constrained Newton-type methods in the sense of sequential quadratic programming. This is possible in general Banach spaces because the structure is somehow more general for doing projected gradient. For doing projected gradient methods in principle, one could go to Banoff spaces as well, but things would become quite messy quite quickly because to work with gradient methods in general Banner spaces, one always needs to map between the space and its dual, because the gradient is first of all an element of the dual space. So if we want to take gradient steps, we have to somehow transport them to the original. Transport them to the original space, and so that's necessitates the use of something like duality mappings, which sometimes make the problem more non-linear and more non-smooth, actually, as well. So, I don't want to do this here. So, let's keep Hilbert spaces for those gradient methods. And the important thing is we want to apply them just to the unregularized problem or maybe to just a little bit regularized. To a just a little bit regularized version of the original problem. So, regularization should actually really be done by iterating, or actually by not iterating, so stopping the iteration early enough. So, that's sort of a regularize then, no, a regularize by iterating, but by not iterating paradigm as opposed to regularizing the minimization problem that we deal with a well-post minimization. Problem, then we deal with a well-posed minimization problem, and then we just apply standard optimization tools. So, that's not the topic of today's talk. The topic of today's talk is regularize by iterating. Let me start with the projected gradient method. So, and recall that our aim is to solve this possibly already a bit perturbed minimization problem. So, that's not the original inverse problem, it's the inverse problem with noisy data in it. Problem with noisy data inserted, possibly both in the constraints and in the cost function as far as this data appears in the cost function. And then projected gradient descent is very simple. We just take a gradient of this cost function for this purpose, of course, it should be differentiable in some sense. And then we project this, the outcome. So we do the gradient step, and afterwards, we project into the admissible set. As mentioned, regularization is done by early stopping. So here we do early stopping by the discrepancy principle, which is a very simple to implement method because it's just a stopping rule. It tells us to stop the iteration as soon as something is below something related to the noise level. In this case, this something is the norm of the gradient. Well, in unconstrained minimization, the norm of the gradient. Minimization: the norm of the gradient would just tend to zero. So it makes sense to stop as soon as the gradient is small enough. And then this quantity on the right-hand side is related to this tolerance, eta of delta, that we have imposed on the, so to say, on the way in which the exact solution solves the minimization problem. So it doesn't solve it exactly because the optimal value might be zero or something close to. Or something close to zero, but it just solves it with some tolerance eta of delta. And so it doesn't make sense to make the cost function value smaller than eta of delta. And with a similar argument, it doesn't make much sense to make the squared norm of the gradient smaller than, much smaller than eta of delta. And that's what we are doing here. So that's our stopping criterion. Okay, of course, in order to prove something. Of course, in order to prove something about this method, we have to make assumptions, and not surprisingly, in an optimization problem, we have to make assumptions on convexity of the cost function. Here it is made in terms of monotonicity assumptions of the gradient. Well, of course, convexity of a functional corresponds to monotonicity of its derivative. And so this is clearly a monotonicity condition. Clearly, a monotonicity condition on the gradient, it's even a uniform monotonicity condition. The usual monotone uniform monotonicity condition would arise here if instead of this square norm of the gradient, we would have the square norm of the difference between x and x dagger. But it turns out that looking at the gradient norm as a lower bound makes much more sense in the context of ILPOS problems. Pause problems. Additionally, we also assume that our exact solution is an approximate stationary point for a cost function in this sense here below. There's also a possibility of a combined condition. Combining these two together, we get this condition here. And it's a somewhat weaker condition in the sense that assuming both of these. Assuming both of these. No, sorry. Well, it's a weaker condition than this one. I think it's because it's just an additive combination of those. Okay, but that's actually the condition that we are going to use in our conversions analysis. Okay, so these two conditions together imply this one. Conditions together imply this one. So, it's this way. Sorry. We also need some, well, sort of differentiability on the J in order to form gradients, and also some weak continuity and conditions on the gradient and also on the admissible sets, closeness conditions on the admissible sets. Sorry, and it's some kind of collective closeness. And it's some kind of collective closeness conditions because the admissible sets vary, and this M here is only, so to say, the limiting admissible set. So what one can get out, and this is basically follows from Opiol's lemma, is that in case of exact data, one really gets convergence of the sequence of iterates, of these projected gradient iterates, to a solution to an admission. A solution to an admissible point that solves satisfies the first-order optimality condition. So, a stationary point of our optimization problem. For noisy data, we just have weak subsequential convergence. So it's always just weak convergence, but in the noisy case, it's just weak sub-sequential convergence of the iterates. Sequential convergence of the iterates stopped according to the discrepancy principle, and it's again convergence to a stationary point. If the stationary point is unique, then by subsequent subsequence argument, one gets weak convergence of the whole sequence. So one can replace this stationarity in both assertions by minimality or also by the condition that the norm of the gradient has to vanish. Of the gradient has to vanish, which is, of course, natural in the context of least squares formulations, but possible also others. And the advantage of these two replacements is that uniqueness is, of course, easier to achieve if one assumes more. If one doesn't only assume stationarity, but even minimality, then Then there's hopefully less points satisfying this. So one gets uniqueness more easily, and then one might get this whole sequence conversions more easily. So the argument of the proof is basically a monotonicity argument combined with Opiel's lemma. It can only be applied in the noise-free case because in the noisy case, there's no possibility of showing any monotonicity. Of showing any monotonicity of the error in terms of delta. Of course, it's always monotone with respect to the iteration of the index k, so the iteration index, but it's not necessarily monotone with respect to the noise level. Just to give you an idea of the proof of this monotonicity, well, maybe depending a bit on time, but how much time do I still have? I have no idea. I have no idea. Maybe five or six minutes. Oh, that's not much. Then let's maybe skip over this proof. So, just to well, this was just to show that one can prove something about this. What I would like to spend, however, a little bit of time is these convexity conditions. And I would like to just illustrate them in terms of the most simple-minded least squares formulation of least squares minimization formulation of the inverse problem. So the inverse problem. Of the inverse problem. So the inverse problem itself reads as f of x equals y. And then we just reformulate this as a minimization problem by means of taking the sum norm, L2, also possibly some negative norm, of this residual squared. And then this condition, our convexity, combined convexity stationarity condition reads like this. Well, it still looks like. Well, it still looks a bit strange, but a more well-known, more familiar, sufficient condition for this is the tangential cone condition. Or this in this setting, it's a weak version of the tangential cone condition because we don't take norms here of this Taylor remainder, but we just test it again with a very particular test object. And this needs to be bounded. And this needs to be bounded by some constant between zero and one times the squared norm of the residual. These two conditions are known to be sufficient for weak convergence of Landweb iteration, so gradient descent for this classical formulation of the equation-based formulation of the inverse problem. So, in this sense, Inverse problem. So, in this sense, we are still in the framework of what can be done in the literature, but we are extending it in the sense that we can take more general cost functions. There has been work on gradient descent methods for ill-pulse problems or for minimization-based formulations for ill-pulse problems by Stefan Kinderman back in 2017. And he can even show a Even he can even show a convergence with more general than these complexity conditions, but it's not, it doesn't contain the constraints. So, in this sense, we have added a bit. And let me also point out, although this looks very much like a reduced formulation, it applies to both the reduced and the all at once least squares formulation, minimization formulation of the inverse problem. So, let me just skip over Newton's method. Skip over Newton's method. It also comes with some convexity conditions. Let me just go straight into the application of diffusion or impedance identification because that's what I have some numerical results to show about. So we are back to something related to impedance tomography because this looks like what you have seen on the, I think, second slide as a model for impedance tomography. But the goal is now to really do the reformulation as in the confugelius approach, not only for this EIT problem, where it has already been done, but also for the EIT problem with what is called complete electrode model, where one just doesn't assume that everything is continuous over the boundary, but really one has physical electrodes on the boundary. Also, another version of tomographic image. Another version of tomographic imaging related to it, also going for the impedance as an unknown, space-dependent impedance, but with different observations, namely the power density, which is basically the, well, it's actually more an energy density, namely what you have here is basically J transpose E, which is the electrical energy density, and this one can actually be measured. Can actually be measured by appropriate methods. That's called impedance acoustic tomography. And then there's also a nice related problem with where one just really directly measures phi. It has been mentioned actually in Richard's talk, or Richard's talk, I should say, as Darcy's problem. And so this is also something about, of course, diffusion coefficient identification. Coefficient identification. So it's all about this simple elliptic, or maybe not so simple elliptic PDE, it's about this elliptic PDE, just with different measurements. And this leads to many possible minimization-based formulations of these three applications. The cost function part will always be of confogalius type. So it's recall that we have the square root of sigma times gradient of phi. Gradient of phi minus one over square root of sigma times the curl of psi. Let me call this again E and J. And then depending on which application we look at, we have these different observation functionals as part of the overall cost function. And what we are going to minimize, or what we're going to consider as minimization-based formulation of the inverse problem. Based formulation of the inverse problem of impedance tomography, impedance acoustic tomography, or ground water filtration is combinations of these model and observation cost functions. Okay, and actually we have more than one observation, or actually more than one excitation, so thinking of impedance tomography, one really needs more than one of them, and then one just does a sum over these components. Over these components. There's also several versions of treating these unknowns. So we have actually three or actually one plus two times i unknowns because these capital phi and capital psi are actually vectors of states. One can treat this in an all-advance fashion by just minimizing this combined cost function with respect to sigma phi size simultaneously. One can also One can also eliminate this sigma. It's easy to see that keeping phi and psi fixed and minimizing the cost function with respect to sigma, one can do this explicitly pointwise in space. And one gets this pointwise in space expression for the sigma. It also takes into account possible bounds on the sigma that we are going to impose, an upper and a lower bound. And the classical approach. And the classical approach would be to eliminate the states, so eliminate phi and epsi, and then just minimize only with respect to the parameter, which is sigma in this case. So the mapping that takes sigma to the corresponding phi and psi parts of the potentials, they of course involve these elliptic PDEs again with prescribed boundary voltages or boundary currents, depending. Boundary currents, depending on whether we go for the so well, whether we go for a Neumann or Dirichlet problem for the phi. Correspondingly, there's also a problem for the psi of sigma, where we have a curl-querl equation, but since it's 2D, it's just a potential equation with the reciprocal impedance here. Okay, just to give you an impression, of course, you're not supposed to read this. Of course, you're not supposed to read this. These are all the meaningful combinations of these pieces into cost functions and constraints, so into minimization-based formulations for these three applications. And what I would like to do in the remaining, don't know, minus three seconds. Just one minute. One minute. One minute. No, then I will just show you one impressive picture of what Carr has achieved for impedance acoustic tomography. Groundwater filtration all at once is not so great. Impedance acoustic tomography is really good. This is just one inclusion. That's maybe not. This is just one inclusion that's maybe not that exciting. We have different versions of taking into account one or more excitations from left to right. The noise level is increasing. You see, we get quite clear pictures. What is quite spectacular, I find for the all-it-once version, we have pretty bad run times. So it's really 34 hours, but doing But doing the eliminating sigma version, we get quite neat results as well. And although it looks larger, it's a factor of 10 in between in the cost, in the computational cost. So the formulation really makes a big difference. Also, the classical one, basically, the reduced formulation works well for different noise levels. It also gives huge computation times, by the way. Of course, that's due to the elliptic. By the way, of course, that's due to the elliptic problems that we have to solve. But we can also do other combinations of inclusions. So, these cases don't work well with EIT because it's just too ill-posed, but they work really nicely with IAT, even with relatively large noise levels. And let me just finish the talk with this impression of nice results, I think, that Carr has. Nice results, I think, that Carr has obtained. So, thank you very much for your attention.