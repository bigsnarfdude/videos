Oh, great. Okay, so each of your black edges, each of your black edges is an actual line somewhere, right? So the red edge gets labeled with the equation of that line. So here the edge label is X in both of those sort of parallel cases. Here it changes. So then when we draw our graph. When we draw our graphs, we don't care about drawing the graph perfectly in space, but we have stuck on these edge labels that are very important and encoding the geometry. So you start with a flat graph, then you choose some red graph, and then you attach the label. Yeah, I mean, well, that's if we're, we sometimes just start with the red graphs. But if but if we were talking to you, then we would start with a black graph and we'd figure out what our. Would start with a black graph and we'd figure out what our red graph is and we'd pick up the labels. Yeah, yeah. Well, so that was actually so that was also the content of this bullet point right here. And what else? Oh, yes. So R. R is the smoothness. And if you'll notice, my R is one higher than your R. So for the rest of this talk and probably my life, sometimes I'll say R. probably my life. Sometimes I'll say R and I'll mean either R or R plus one or R minus one, depending on whichever one is supposed to be there, right? And then finally, degree. So you would usually think about degree D. We can just say, okay, I mean like in, so it's sort of funny, right? Like in cohomology, we're usually like, ah, look at everything all at once. At everything all at once, and oh, you have a module basis, and you can just scale by polynomials and change your degree, right? But we both can restrict to degree and just say we're only going to look at the things of degree less than or equal to blah, blah, blah. And like, honestly, in practice, we often do restrict because we ask questions like, you know, we will use degree in order to sort of figure out whether we have a complete set of. Whether we have a complete set of module generators, right? Like you might bootstrap up from lowest degree to higher. So, first off, degree, we can just restrict. And for the algebraists in the room, you can also use a quotient ring as your coefficients, and then you don't have to restrict, but you get rid of all of the higher degree stuff, and that can be a useful. Stuff, and that can be a useful trick, but it does mean that your coefficients may not be a domain anymore. So that's kind of fun. We'll just drop that comment. Okay, so computational tool number one. So this is a sort of a different kind of homogenization. And so describing some work here with Shaheen Nazir. Here with Shaheen Nazir and Anna Schilling. So, Bele talked a little bit about homogenization as a trick used in commutative algebra, algebraic geometry. This is a pretty classic trick. So, like if you have a polynomial like this, right? So this is degree two, but the individual terms may have degree less than two. This is messy. You might need to analyze it with cases. And if you just stick. And if you just stick in an extra variable, you can make it so that every term has the same degree. And then you can make more nice, uniform statements about it, will always factor things, will always have these sort of degree properties. So that is your classic way to homogenize. And on the one hand, you get some like uniformity of the way you can treat things. But on the other hand, you gained a variable which makes any specific calculation. Any specific calculation harder. So that's like not what I'm talking about. And what I'm talking about is something a little bit more like your classic, like what you would do in linear algebra if you were like homogenizing a system. So here is a particular linear system that has like non-zero scalars on the right-hand side. And there is the homogeneous system that is related to it, where I just erase those and make them zero. And as we know, these solutions are like closely. As we know, these solutions are like closely related to each other. So, like, this is a good convenient. I mean, this is how you would teach a linear algebra student to solve a system of linear equations. So we do have a linear system of equations, but yes. Sorry, it's a completely stupid question, but in which sense are the two solutions of the two linear systems related for me? For me, they are just different. The solution space. And they're a translation of each other. So, if I have a particular solution here, and if I know what all of the solutions are here, then I can just translate and get the whole solution space here. So, yeah, like if I needed to solve this system of equations for a whole bunch of different constants on the right, I would probably prefer to solve it once homogeneously and then find individuals. Because on the right hand side, you have only the trivial solution. Yeah, it's just normally I would not. It's a big matrix. I just couldn't draw a big matrix on the board. It's not a square matrix. No, not a square matrix. No, that's, yes, right, right, yeah. No, no, no, you're right. You're right. No, it is like not a square matrix. This is for. This is right. Yeah, okay. Point made. All right. So, yeah, so what is the matrix that we're thinking about more? So I think Bebe actually also drew this equation also on the board. So each face of my graph, which is interior vertex of, say, your triangulation, so it imposes a condition on splines, right? So the Lines, right? So the condition that I think of as saying, let's see if this will work. All right, so this condition, which I sort of think of as GCAM condition or spline condition, right? So given like a nice little face like this square, so on the one hand, I can think of zero equals any one polynomial minus any one polynomial. But on the other hand, I can sort of create this like sort of telescoping little sum where I've got. Telescoping little thumb where I've got first the difference over this edge on the bottom, and then the difference over this edge on the left, and then the difference over this edge on the right, and then over here. And so each of those individually is one of those spawn conditions. So here's the bottom edge and the left and the top and the right. So if I add those all up, if I add those all up, then I should get zero. And now that's not like so if we take if we assume that sort of underlying our edge labeling, we have some sort of equations like x plus some scalar multiple of y plus some scalar. Y plus some scalar, then we can just start collecting all of our like terms. So collect all the like terms, and we get for this first, so for this first base, right, like here is the equation that I wrote out for the first face. This equation is satisfied for all possible choices of x and y. In other words, we really have two separate equations, one for x squared, one for y squared. And so here's this linear system of equations. This linear system of equations. Yeah. And then here's me doing the same thing on that larger face connected to the square, where you can see I now have my degree two homogeneous equations and then all of the non-homogeneous equations. And there's my coefficients over there on the right. And like it got worse. Worse. Yeah, well, it got worse. All right. All right. So then to give you my computational trick, I'm just going to take some shorthand, this sort of matrix of coefficients. I'm going to write it with, so I'm going to be calling it like this extended. So the graph theory is kind of related to eighth cycle. Is kind of related to a cycle basis on the graph. So we're sort of thinking of it as an extended cycle basis matrix because you have all of these expressions, one for each of the little faces. So by construction, what we said was splines on this graph of degree less than or equal to two are the kernel of that matrix plus the constant splines of degree less than or equal to two. And so if I want to, so I'm going to give myself an extra little. So, I'm going to give myself an extra little piece of addition of notation, and I've got my whole coefficient matrix. And then I've got the piece of it that just has the homogeneous degree two parts. And so this is like the matrix that I get by just erasing the constant everywhere. So then here's like the theorem is that the kernel of these two matrices are the same if you start with a graph. If you start with a graph that's a dual to a triangulation. So, yeah, and if you are not just interested in stuff that actually exists, you can generalize the graph condition. So, the main issue is that each face individually needs to be able to be translated to the origin, so not necessarily simultaneously. So, not necessarily simultaneously. So, again, in this example that we are looking at, here's sort of the graph corresponding to this graph that we started with. And then what happens when we do this sort of erasing trick? This thing on the right is the graph that actually tells us still the same, has the same content or information. Has the same content or information. And if you sort of look at how the labels around this second face look, it's, I mean, I think like what it is doing is taking the two interior vertices of the original triangulation and just superimposing them all and superimposing them all on the origin. And I have no idea if there's some way of interpreting that geometrically because. Interpreting that geometrically because it doesn't seem like it to me. But so, okay, so then that here is so the point is computational trick number one is really essentially you can simultaneously translate all of the interior vertices to the origin. And that's fandy. It like homogenizes the problem in some literal sense because Literal sense because all of the terms that show up are now like these degree one homogeneous terms. This is only for degree two. Well, yeah, so it was actually like, yeah, I didn't put a slide here. So I think we can actually generalize this to all degrees, but I'm not positive. I think I can. What is special about the degree two? Yeah, I don't think there's anything special about degree two, and I think I can generalize it to all degrees. I would not promise that I could generalize. I did not promise that I could generalize it to all Rn, like all number of variables, but I don't know. I believe I can take the general list to all degrees. Yeah, I don't think anything is special about it. But at a certain point, you need this assumption in your proof. That, oh, oh, yeah, well, we were actually only thinking about things that were, we were only thinking about degree twice blind. Therefore, like, we. Use blinds. Therefore, like we only thought about it there. And yeah, I don't know. I can try to follow up. Why don't I be ambitious later today with a final report? But yeah, I think this generalizes. Okay, so computational trick number two. So computational trick number two, which I'm thinking is what I'm talking about. Which I'm thinking, it will call contractions. So the point is, like, some parts of the graph are easy to work with. And so, like, whenever you have just like a little path, or like, you know, if you have a bunch of triangles like this, and they're not glued in with any interior vertices, then it's really easy to sort of figure out what the splines are there. They're essentially like there. I'm going to use the word free. Word free. And, you know, like all spawns on this particular graph, this path, you can get them just like a sort of very classic upper triangular basis in linear algebra, right? Just keep moving things around. So with computational trick number two, I am going to get rid of all of the easy parts and just remember what they contributed to the entire spline ring or spline module. It's more supply module. So I'm taking a little sigh here because the next two or three slides might be profoundly uninteresting to some portion of the group. So these are like technical conditions that I would feel bad about saying anything without saying, but like, so they care a little bit about having an induced subgraph, meaning like Meaning, I'm going to look at subgraphs, but I don't want to allow there to be extra edges in the big graph. Really, I'm going to try to say I want to just restrict to places where there's some triangles that form the footal strips and only pay attention to those. So, what is a contraction? Well, what a contraction is going to do is it's going to take this subgraph and it's going to squish everything to a point to a particular vertex. So, here is this. So here is this pink subgraph, and it's going to squish down all the way to that point. And now you could have all sorts of edges still looping into that vertex, including, so over here, this was a nice, ordinary, well-behaved graph, and now this is a multi-edge, two different edges going to the same vertex. There's no reasonable way to interpret that as a planar anything. Like it does. Or anything. Like it does. Like, once you contract, you have done something fundamentally horrible to the sort of underlying, like that, to whatever dual object that you started with in the plane. And then, oh, and then finally, so we have a couple of different maps on splines that we can use. So whenever you have a subgraph, you get a map. Whenever you have a subgraph, you get a map on splines just by forgetting anything that's outside of the subgraph. But when you have a contraction, you also have a map the opposite direction. So this is going from the contraction into the big graph, where you just take whatever value was on that magic contracted vertex and you put it everywhere in the subgraph. And so, like, it still satisfies all the conditions. Satisfies all the conditions because you still got the same edges, right? You haven't really done anything different in any kind of, in any sense other than record keeping. So the theorem with Eric Ramos and Jacob Mathern is like going to be a twofold theorem. So the first is basically that if you have a tree as an induced subgraph, and I don't have Graph, and I don't have any paths within between different vertices of the tree, except for what's in the tree, then the so then restricting to the splines on the tree, from splines on the full graph to splines on the tree, restricting just to those vertices gives you a surjective map. And the kernel is the collection of splines you get from the control. Why is you get from the contraction map setting the contracted vertex to zero? So, this is sort of like a first isomorphism theorem statement where I'm saying I can tell you what the image of this map is, and I can tell you what the kernel of the map is. So that tells you the whole spline. So, here's sort of what it looks like in a particular example over here. So, let's first focus on this corner. Corner. So, this corner, here is my original graph that I start with. The pink is going to be what I am, that is my subtree. So, on the one hand, I get a map down just by like kind of I just grayed out a whole bunch of my graph, and I'm just ignoring parts of this line. And so, and also in gray, there's like a little picture proof of surjectivity if you're. A little picture proof of search activity if you're worried about that. It's essentially the statement that we had on the board earlier. I can just, since there's only one, there's no paths in the gray between vertices dangling off of different parts of the graph, I can just sort of continue values up each of the gray paths. Okay, so that's you have a tree, you can just restrict and forget all of your spine values off the tree. Get all of your spine values off the tree. But then the kernel of this map, that's this piece right here. So here, if I take my contraction and stick a zero on my contracted vertex, then the contraction map is pulling into zeros everywhere on the tree and thus manifestly moving down. If I push that further down, it would be part of the kernel. Push that further down, it would be part of the kernel. And so the statement is: all splines are this sort of combination of one of one type and one of the other type. So splines on trees are easy, and thus we can ignore them and still recover everything that we want about dimension, about generators and bases. You can like follow the generators and bases through this process. Okay. Okay. I'm actually going to finish in the next few minutes. Okay, this is a terrible slide, also picture-wise. So I'm going to do something very, very, very similar. If my graph has a path, and my requirement here is I have a path. All of those intermediate vertices on the paths, they're all degree two. There's no other edges out of them except for what you see on the path. And I'm going to assume that the endpoints of the path have. That the endpoints of the path have at least one other path between them in the graph. So, in this case, what I'm going to do is I am going to project to the contraction and just slightly modify my edge labeling by putting in a sum of ideals there. So, same style of results. This projection map is surjective, and the kernel is this inclusion. This inclusion of a different contraction. So that's technical details that I can share, but let's look at the picture. So here is the graph that we started with. And I have two paths, this path around the left of the square, the red square, and this path here around the right, around this giant face. So these are both paths that satisfy my conditions. So, these are both paths that satisfy my conditions. And so, if I contract, they each turn into a single edge down at the bottom. And I have to record, so I have to change my edge labeling. And now I'm actually edge labeling by ideals rather than individual polynomials. Again, this process just became like, I think, deeply algebraic and Deeply algebraic and unmoored from geometry. But there it is. This is, in fact, an accurate object. So what's the kernel? So the kernel is it's all the places that so it so the kernel is take these paths and make the endpoint zero and then the kernel is whatever you whatever whatever kind of splines you have just Whatever kind of splines you have just on those paths with the endpoints being zero, and you can map those into the original graph. So, those things in the top left, those are sort of by construction, always splines on a triangulation with just one interior vertex. So, this part is sort of This part is sort of kind of well understood, right? So Schumacher breaks this out. And now this part is the part that is a little bit weird. In this particular case, if you have a whole bunch of edges, then like the splines on a whole bunch of edges between two vertices is just, it's like the, that is a, there's an intersection condition. So in this particular case, we can like write out what it is saying. We can like write out what it is saying. Did you get those ideas? How did I get these ideals? Yeah, this ideal, this is the ideal generated by all the edge labels over the path. So like the one on the left is we had a y squared and an x squared. So it's the ideal generated by x squared and y squared. And over here, I had x minus y squared, x plus y squared, x squared. x squared and they were repeated a couple of times uh yeah you don't have to include the repeated ones those are those are going to be ideal yeah exactly exactly yeah this y squared is exactly what it is and this y squared is exactly the original stuff right so and so sort of in general you know in general you could do this sort of one at a time along you could first go along the left graph and you would have just one edge show up Graphs, and you would have just one edge showing up. Why would we have an intersection? So, the intersection is just in this particular example. If you have a multi, if you have like a multi-edge, like if you have two vertices that have more than one edge between them, and your condition is the polynomial here and the polynomial here differ by the multiple of each edge, it's just intersection, but geometrically, like property, geometrically, not possible. That's right. So, we shouldn't worry about that. Well, so actually, uh, so. Actually, so what a leading question. Should you worry about it? So you should not worry about it in the sense of like, will I ever draw a picture that does this? But I might argue actually that you should consider worrying about this because this is what's governing the splines that you're thinking about, right? So, like, whether or not you draw the picture, this is what's happening to your spline. To your spines. Yeah, well, like, even, yeah, right. Before you contract, this is still going on. And it is, so you can see, like, with this sort of intersection, you can actually see how your degree constraints might jump or not jump based on, like, right in this case, y squared is in all three of these ideals, so nothing changed. But if y squared is not in those other ideals, then when I take this intersection, it's going to bump. So, yeah, so I would actually. Going to bump. So, yeah, so I would actually, I might even reframe this differently. There's a bunch of, so, like, what is a contraction? Like, a contraction is a natural thing graph theoretically. It is not a natural thing geometrically for this kind of contraction, but it is encoding something that is like intrinsically intrinsic to the structure of the geometry. So, so here's the So here's sort of the main point of the two of these together. Given any graph, there's a reduced graph of the same genus whose splines are determining the splines that you started with. And so what these words mean here. So reduced, in this case, so I think topological group theory, people think about reduced graphs. Graphs, uh, some tropical algebraic geometry, people over it. So, so the uh conditions we're thinking: all vertices have a degree greater than or equal to three. There are neither leaves nor bridges. A bridge in the graph is like an edge you can cut to disconnect it. So it's like it's like a triangle whose removal will not lead any edge-connected paths. Um, the genus, uh, the genus is like the number of holes, but for But for the graph, so that I don't have to worry about it being planar, it's number of edges minus number of vertices plus one. So this is like then a fixed determining quantity. And so sort of things other people have told us, like there's only a finite number of reduced graphs of each genus. And so there's a sense in which what they're doing is they're forming these templates for all possible splines. For all possible splines. So, like Michael and Bailey had the ah, you were talking about this yesterday, Tanya, the result about graph triangulations of this sort of form. So this graph is this test. Is this template that I'd like to drew up on the board? Like I sort of, if I drew it the other direction, it would be a theta. You should probably draw it here because they would. Yeah, yeah, yeah, yeah, yeah, yeah, yeah. So yeah, yeah. I'll draw it on this like little thank you. So right, so here's So here is the exact picture I just drew, more or less. And this is the template in this case that's sort of determining the calculation of the spines. So that's where I got my voltage completely. Yeah. Thank you. Thank you very much for the very nice and inspiring talk. If not, I have to say a comment. Oh, there's a comment. I would like to say thank you for picking me up where I was before. Yeah, so this was really very helpful for me. Thank you. Perhaps a very basic question is, you choose a very high level of abstraction for all these considerations. Might it be that this very macroscopic view is too distant to get specific results? Or do we expect something very concrete coming out of it? Something very concrete coming out of it, yeah. Um, so great question. Uh, but it's philosophical, so I get your response. So sometimes right, yeah. And I could say more at a coffee break or something, but yeah, she doesn't want to be recorded on that, so yeah. So I have a question and two comments. So as for the comments, say your red graph, that actually it reminds me, so it is there in the construction of the spline according to one in the first papers that say in the 80s. No, no, just exactly the concept. No, no, just exactly the conception of an element that you start from one say triangle and then you move around adding exactly as you did. Adding, of course, it's not as nice as you presented, it's a little bit more computational, but it's exactly this conception. And also, I think that some one of your treatments that you you said about the homogenization, or it is a little bit maybe in a different way, present in the Present in the papers about dimensions just to reduce the complexity of the linear system. And I have a question. So as about the dimension, so a nice situation is when, say, an interior vertex is connected to the boundary by a straight line. Actually, in the picture that you showed you, the previous one, please. Okay, this one, as an example, here in your black plot, every galiometric is connected to the boundary with the straight line. And this usually helps a little bit in the, this is a special case and usually helps a little bit to understand a little bit more about the dimension. Maybe I missed, but can you catch this? Can you catch this in your special fact in your maybe Anisa? Because it is related actually to the equation, not only to the combinatorics. So, okay, and to your remarks, I'd also like to add, by the way, that Valera and Valera and Rose also sort of think about they do work like that. I rely on. Like, but I rely on them when I say that my splines are the same as classical splines. So I did not add all citations, but yeah. Um, in terms, so I don't think I can let's see, I have not thought about this question. So it was a question really, can I detect? Ah, yeah, I guess I can detect in my graph if the interior vertices are all Are all distance one from the boundary? Yeah, I guess I think you off the top of my head, I think what it would mean for my graph is that every face has a boundary edge. That I think is yeah, sure. So, what Carla really means here, I think, anyways, because that's a great question, Carla. If you Great question, Carla. If you turn this age over here, right? It's not the same anymore. That becomes much more complicated. I think she's right that you need a place on a bulbari edge for the red. Can I just write a quick slope? Just change the slope. The equation is actually the same. The rest graph is the same. The rest scale is the same. The graph is the same, right? But you change the school. Okay, yeah, I changed the label. Oh, oh, so then. Oh, wait. So you're just saying if I pull this over to here, like, is this? Sorry, this is not. No, no, no, no, no. No, you changed the equation of that ray at one. No, no. Did I go too far? The labeling was there as squared, right? Yeah. But now, if you if you make this line a little broken and change the labeling to like. It and change the labeling to like 3x, yeah. Yeah, yeah. Can you can something dramatic is it gonna dramatically affect more interceptions? And because it should, yeah, right, right, right, right, right, right, right, right, right. Right. So, so it would, it would change your edge, not from like 3x squared, it would go from like x squared to like x plus y squared or x plus 0.000y squared. And yes, that would have a profound effect. I mean, actually, you could sort of see it also like, yeah, it could, it could. like yeah it could it could have a profound effect as like right here if i change this to like x you know a tiny multiple of x plus y squared then the intersection would wildly change this one should perfectly say it's actually the other one i think it's not this is not uh that's not the one that one's fine the the bad one is uh square well you can make a left change yeah i mean i think i could i can make a budge really I can make a budget, really. From our standpoint, these two are fine. It should not affect the applications very much. But it's only that left mode is going. So everything else should be okay. Why don't I propose that we work out this example after? Because I don't know. The line you have, the line is squared, it comes from here to straight line, so actually get counting the dimensions on the right side. The dimensions on the right side is a little bit far. So if you change that, that line themselves change the configuration, we know, but if you didn't, if you change the edge that you suggested, then nothing, I mean, this configuration doesn't change. I'm going to propose that. I think actually, if I'm understanding the question, I think in this particular example, then changing this line or this line could make a difference if you do either one of them without the other. Of them without the other, but like you can change the vertical, yeah. So the horizontal. So you want to connect the horizontal line. Oh, but changing the horizontal will change it for one hundred. No, no, no. Okay, maybe we can discuss more about that because we don't know which part. Okay, so uh if there are no more comments how about online, do we see deep nails answered zoom questions? Deep nails. I share two questions. Questions? Are there any questions? Don't read the button. Does the subjectivity hold only for degrees to the sprines? For all degrees? Oh, yeah. The surjectivity result is for all, that's all splines. And it's sort of more general framework for coefficients. Is there natural reasons to focus on the Reasons to focus on the people? In the first part of the talk, I believe no, and I believe the result holds for all degree, but I have not. Later today, more follow-ups. Yes. Okay. Close by the questions. Okay. Thank you. Thank you again. Thank you. 