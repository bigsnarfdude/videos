For me to talk about some new work and show off some software. So, this is a live coding demo, so it's a little risky, but hopefully, everything will go relatively okay. So, just to give a bit of background, so we're interested in some complex value sequence with its generating function f of z. And as most people here are probably familiar with, we call the sequence p recursive if it satisfies a non-trivial linear recurrence with polynomial coefficients. And that's equivalent to the generating function being d. And that's equivalent to the generating function being d finite, meaning it satisfies a linear differential equation with polynomial coefficients, contributial differential equation. And I want to focus on two questions, at least at the start. So how do we find asymptotics of a p-recursive sequence? And how can we test when a p-recursive sequence has all positive terms? Now, positivity is a big area of numerative combinatorics, and a lot of people here might be interested in it for various reasons. I have a particular application that I think is pretty interesting that got me fixed on this, which is looking at a Fixed on this, which is looking at a specific model for biomembranes, so predicting the shape of biomembranes like blood cells. So it's a very interesting problem, actually. You know, if you look at the shape of blood cells, so here are human blood cells on the left, here is a daunted blood cell on the right, you see it has this famous shape. That's kind of a weird shape. Like, if it was a sphere, maybe you'd see why that happens, because spheres have a lot of nice properties. But why do you get this really weird shape coming up? Turns out that all mammals, except for camels and llamas, have this shape. Camels and llamas have this shape, also. All healthy eat mammals, like they're single cell and things like that. So, it's some kind of universal thing. How does this come up? So, there's this model called the Canham model, which was influenced by this paper here by Canham, who's near where I am at Waterloo. He's in London, Ontario. And it was observed many times that if you deform a blood cell, like you put it through a small pipette or something like that, it springs back into this shape. So that suggests there's some kind of energy minimization. So that suggests there's some kind of energy minimization principle here. So you should come up with some kind of energy function, and the minimum of this energy function should be this shape. So this leads to what's called the Canham problem. So you fix a genus of your surface, and you fix the isoparametric ratio, which is basically something that relates to the area and the volume. And if you fix these two things, the problem says you want to find a surface that minimizes the sum of the principal curvatures squared as you get. Squared as you do this integral over your surface. And so people have worked for a long time proving that there's, trying to prove that there's solutions, this existence of solutions. Uniqueness of solutions is also very interesting because, as I said, pretty much all mammals have the same shape. So if you have a model that predicts the shape, there should be a unique solution. And recently, for the genus 1 case, so this is not for blood cells, of course, blood cells don't have a hole in them, but for the genus 1 case, there was a gigantic breakthrough. There was a gigantic breakthrough. You know, it's the kind of paper that was in Anals of Math, and they have whole conferences about every year now and stuff like this, that would show that there was solution existence for genus 1 surfaces. And so here is a plot of the solution, something called the Clifford torus, with different isoperometric ratios. And here is actually, under a microscope in a lab, what a genus 1 biomembrane looks like. You see, it seems like it's a pretty good model. Anyway, so that's existence. And then now you could ask about uniqueness. Could ask about uniqueness. So there was a paper recently by Thomas Hu and his co-author Chen. And Thomas Hu is a professor at Drexel University, and I was a postdoc at Penn working with Robin. So I gave a talk about analytic combinatorics at a seminar at Drexel. And Thomas came up to me afterwards and he told me about this problem. And it's like the dream thing, right? Someone comes up to you with this amazing problem and they say, I can show that there's a solution to this, but I have this pre-recursive sequence I need to show it as positive terms. So it's like exactly the thing you work on. Someone comes up to you with this amazing problem. On someone comes up to you with this amazing problem. Can you help me with it? So, in particular, it's a p-recursive sequence of order seven. Here are the initial conditions, and these polynomials are fairly large, but of course they're explicit, and I'll show them later in stage code. And you might wonder, like, how is this connected at all? But basically, this big breakthrough result that shows existence gives you some kind of characterization. So, you can characterize the solutions in terms of a certain parameterization. And if you take the derivative, And if you take the derivative of that and you expand it as a series, it has these coefficients. And so if you show all these coefficients are positive, if you substitute any positive number into the derivative, it will be positive. And therefore, you get some unique results. I'm not going to go into the full details, but that sort of goes. So I thought about this for a while, and I talked to Mark Azarova, who's in France, and also my academic brother. We're both supervised by Bruno Salvi. And we were able to show using techniques that I'll explain. Show, using techniques that I'll explain in a little bit, that the sequence has all positive terms, so that this result holds as a uniqueness for solution, at least for a certain large range of isothermometric ratios. And then working with a master's student, Ruin Beng, we extended this to general p-recursive sequences with some caveats that I'll talk about later, and we gave a Sage implementation, which I'm going to show off for you today. Ruin was a master's student, so he's got Dicole Polytechnique, and in the French system, you have to do all these research internships. You have to do all these research internships. So he was supposed to come to Waterloo to work with me, but fortunately, because of the pandemic, the delay to get the visa would have been longer than the internship actually, like after the internship was over. So he stayed in Paris and we kind of worked virtually. He's at Oxford now doing his PhD and he does a lot of interesting work in the complexity of linear recurrences and decidability of when to solve and say things about solutions. So if anyone's interested in that, you should look him up if you're looking for a speaker in your seminar. Okay, so let's get to the actual software part. So this is our first The actual software part. So, this is our first goal: being able to show positivity and things like this. So, the first thing we want to do is we want to model a p-recursion in software in Sage. So, we do this using a member of what's called the shift algebra. So, you can think of this as being polynomials in two variables, s and n, but they're not commuting variables. So, s times n is n plus 1 times s. And these encode a recurrence because if you have a polynomial like this, you think of n applying to a sequence, you just n applying to a sequence, you just multiply every term by n, or the nth term by n. And the shift shifts your index of your sequence, so it moves everything over. And this is why we need this commutation rule, because if you multiply by n and then shift, that's the same thing as shifting and then multiplying by n plus 1. So now I'm going into Sage. So there's the Sage Bori algebra package. This is not built into Sage. So if you want to run this, you have to install it yourself, or I'll talk about that a little bit more at the end. So here I'm just importing the package and defining this ring of In defining this ring of indices, so polynomials in n, and the shift sn. Ori algebras are more general structures that satisfy certain computation rules, but the most important cases, the cases I'll be talking about, are the shift algebra and the differential algebra, the model to define equations. So this supports algebraic simplifications. So if I, you know, if you take s n times n, it moves all the s n terms to the right-hand side. This is kind of canonical order. And so of course it's pretty fast. If you do this, you just have the 10 and it simplifies. 10 to 10, and so applies. Yes. So the package can do a bunch of different things. So, one thing it can do is it can generate terms efficiently. So, if you give a recurrence, this is the recurrence satisfied by the central binomial coefficients. So, you can give enough initial conditions to specify your sequence. In this case, it's an order one recurrence, so you only need the first initial condition, which is just to say that the zeroth term is one. You can ask for ten terms, and it gives you the first ten terms, and this matches central binomial coefficients. Central binomial coefficients. Of course, it's sufficient, so I could ask for 100, it could ask for 500, and I could probably ask for 10,000, but I obviously wouldn't be able to see it. Something else that's extremely nice is that it can also guess p-recursions for you. So if you take a sequence, so let's suppose I take the first 10 central binomial coefficients squared, and I don't know what my sequence is, I just know the terms, I generate them in some way, and I think it might satisfy a p-recursion. And I think it might satisfy a p-recursion, then there's this command guess, and it will actually guess a recursion for me. Now, of course, if you just take a finite number of terms, you can always guess some kind of recursion that the sequence satisfies. But it's a little smart, so you can imagine roughly that, you know, say you generate 100 terms, you guess a recursion with the first 50, and then you verify that the second 50 still satisfy that. So that's not exactly how it goes, but there are some checks so that it doesn't return just like garbage recurrences. If you put in two little terms, or it's not confident, it will give you an error and say that I. We'll give you an error and say that I don't have enough information to really make an educated guess about this. So now I just want to show an example, like an actual example, of how you could use this to go from the definition of a problem to getting your computer to do all the work for you to find asymptotics, aside from a few things that you have to go and verify, other ways. So as many people in the audience know, I'm very into lattice path enumeration, or I was at one time anyways, working in this a lot. And so here's a nice lattice path problem. Here's a nice lattice path problem. You take walks that start at the origin and take north, south, east, west steps, and they're restricted to the non-negative quadrant, the first quadrant. So here's one such walk of length, something, 100, 100, something like that. So, okay, let's see if we can, without really thinking, just getting our software to do all the work for us, let's see what we can do. So, you build this function that just takes the definition and generates terms in your sequence, right? So, it builds a walk recursively. If you have negative indices, Walk recursively, and if you have negative indices, we don't allow that, so you return zero. Otherwise, you return sort of by recursion a walk of length n, it's a walk of length n minus one followed by a single step. So you build this thing here, and then you can generate your counting sequence. Again, you could generate a lot of terms here, and just make it fit on the slide. So now I can generate the first 50 terms, and I can ask to guess a recursion, and it guesses the recursion. So you can prove the recursion in this case. This is a powerful tool called the kernel method that allows you to prove these types. The kernel method that allows you to prove these types of results for these blocks. But for now, let's just say that I'm just exploring, so I'm going to take it on faith that this is true. And again, it does some checks, so if it returns something for you, you can be fairly confident that it does satisfy this. And now let's ask, okay, how can I find asymptotics of my sequence? So I have a linear recursion of order 2, a p recursion of order 2. So since a p-recursion is linear, its solutions form a vector space, in this case of order 2. So what you can do is you can version 2. So, what you can do is you can compute what's called an asymptotic basis, or some people call it an asymptotic basis. So, it's a basis of solutions whose series expansions, as n goes to infinity, you can compute to arbitrary order. So here, what this command is telling me is that there's two basis elements, and one of them has this expansion as n goes to infinity, and the other one has this expansion as n goes to infinity. And again, I'm keeping numbers small here so I can actually put it on the slide, but you could go a lot farther and compute more and more terms. These things are extremely efficient to do. Are extremely efficient to do. And so, what does that mean for my sequence? Well, my sequence satisfies this recursion, and I have a basis of elements. So, my solution is a linear combination of the basis. And so, that means there are constants, so that lambda 1 and lambda 2, so that my solution is lambda 1 times the first basis element, and lambda 2 is times the second basis element. So, I have, up to these constants, this asymptotics of my sequence. Asymptotics of my sequence. But the problem is, how do I find these constants? This is the so-called related so-called connection problem. It's a solid connection. Where? It's lambda 2 times minus 4 to the m over. Oh yeah, it should be m cubed. Thank you. Let's just fix that. Thank you. So how do we find lambda 1 and lambda 2? And in particular, how do we prove, in general, you want to show How do we prove, in general, you want to show and say that this is the dominant term. It's like 4 to the n over n. So how do we prove that this is non-zero? In this case, it's easy because if this was 0, you'd grow like negative 4 to the n, and it's a counting sequence, so that can't happen. We know that this must be non-zero. But in general, you'll have some dominant term. You want to show the coefficient in front of it is non-zero to show you actually have that asymptotic behavior. So the idea to find these coefficients, it's actually hard to do from the recursion side, so you should move to the differential equation side. So you can model differential equations. So you can model differential equations, definite equations, just like you can model occurrences, using this Fourier algebra framework. So now you have polynomials in variable d and z, and your commutation rule is a little different because of the product rule for functions. So your commutation rule is like this. So now I'm defining this, and again, it simplifies these right for you. And at this point, you can either use the guessing function to guess a differential equation satisfied by the generating function. Satisfied by the generating function. So, this is still the lock generating function. Or you can automatically convert from a recurrence to a definite equation and vice versa. So, you could either convert or just do the guessing on the differential equation. And so, again, a definite equation is a linear equation. So you have a vector space of solutions. And again, you can compute a basis of solutions that is convenient. So you can find series expansions on them. So now what that means is you pick a point of the complex plane. Of the complex plane. So in this case, the origin, z is equal to 0. And you compute a basis of three solutions. So some order three are correct, so you have three solutions. So we have three solutions, and their expansions at the origin start like this. And again, you can pick different points. So if I take z is equal to one, then here's a basis. There's a basis of three solutions that start like this. In this case, these are all power series. So you have a basis of analytic solutions. But at the origin, we had some singular solutions. And again, I could change. Then again, I could change this 5 to like a 20, and it would give me something. It would just not fit on the slide really. So, what we're going to do is we're going to represent our generating function that we're interested in in terms of this basis. Now, if I take the expansion of the origin, I know how to do that, because I know how to compute the series expansion of my generating function. The terms are just the counting sequence, so I can compute it to any order. And if I look at this basis of solutions, well, there's something that has logs in it, so my generating function must be zero times that. My generating function doesn't have any logs in it. times that. My generating function doesn't have any logs in the origin, it's not a power series. Then there's something with a 1 over z. My generating function, it must be 0 times that because there's no 1 over z, it's a power series. So then my generating function is a multiple of this. In this case, it's actually 1 times this. So the basis element that's H generated is actually this generating function. And you only have to look at the constant to see that. In general, you might have a few series at the origin that are power series, and then you might have to look a few coefficients in to see how you get your generating function, but you can always do it. Do it. Okay, so in terms of this basis, I can write it in these coefficients: 0, 0, 1. So now there's a really beautiful set of tools that have been developed in computer algebra and numerical analysis, studio ODEs, that allow you to give practical algorithms to relate the basis of solutions at different points. So very roughly, you take your basis of solutions at the origin, and you can compute the series expansions up to some order. Series expansions up to some order, and you can approximate the coefficients with rigorous error bounds, and you can approximate the term, the first error term that you don't have using things like Cauchy's method of measurements, which are fairly classical. And you can do this close enough to the origin. So you can say take a basis of solutions at the origin and take a basis at a point nearby and write your basis at the origin in terms of the basis of this other point. So you can compute the change of basis matrix from one to the other. And then you can take this basis of solutions, do another point nearby. Basis of solutions, do another point nearby, and so you can chain this together and get a numeric analytic continuation. And the key thing is you can actually do this into a singularity as well. So, we're not going to get too much into the theory here, but I'll just show how it actually works on this case. So, the first thing to note is that we're looking for singularities of our generating function. And a very classical theorem in differential equations is that the only singularities that can come up for a defined function are roots of the leading polynomial. The leading polynomial, so the polynomial beside the highest order derivative that appears. And this is in Fledgeland Sedgwick and many other sources dealing with these kinds of generating functions. And so what we do now is, okay, if we look at the singularities here, there's a singularity of a quarter and a singularity at negative a quarter, a potentially singularity at zero, but we know there is a hope for our generating function. And this corresponds to this, you know, 4 to the n and negative 4 to the n that we saw before. And so we can compute this change of basis from the order. Of basis from the origin to the point z is equal to a quarter. And when we have the basis of the origin in terms of this new basis, the change of basis matrix, then we just multiply by how we represented our generating function in terms of the basis of the origin. And that gives us our generating function in terms of the basis at z is equal to a quarter. So that's a little fast, but what you get is you get a singular expansion of your generating function, but the coefficients here, Function, but the coefficients here, they're coefficients up to some accuracy. So you see here it says negative 1.27 plus minus 3 times 10 to the negative 3. So it's telling me there is, so it does rigorous numerics using interval arrays and things like that. It tells me there is a constant that lies somewhere in this interval of width 10 to the negative 3 that goes in front of here. So the singular expansion, it's like a log z minus a quarter with a constant in front. Now you'll notice it has an imaginary part here that it says it's quite small. Imaginary part here that it says it's quite small. Of course, we know that there's not going to be an imaginary part, so you can sometimes throw away things just from whether things are real or not. And again, I want to stress that this is, I put it at two, you know, order two accuracy just to plot it here, but it's very efficient. I can ask for 20 bits of, or 20, yeah, 20 digits of precision. I can even ask for 200. So here you go, it's 200 bits of precision. And then knowing the singular expansion, I can compute the asymptotics. I can compute the asymptotics, and I just take the real part because, like I said, we're going to do the magnetary part. So I know that my dominant asymptotics will be 4 to the n over n times this constant here, which, again, I don't know exactly, but I know it rigorously to three decimal places here. Of course, we started by guessing as differential equations. So when I say rigorously, it's you have to use the kernel method or something to prove that. And again, I could go to like 200 decimal places and, okay, I don't know it exactly, but I think you agree that's probably sufficient. But I think you agree that's probably sufficient to be confident about what the behavior is. So, the question I want to ask now is going down: what if we want explicit error balance on the terms? And because we want to prove positivity. So, to prove positivity of the sequence, what you can do is you can show it's asymptotically positive and then have an error bound that's explicit. And then, with an explicit error bound, you can say that you can really compute an index n and say from n onwards it'll be positive because my dominant asymptotic term. Positive because my dominant asymptotic term is bigger than the error. And then up to that term, you can just compute all the terms and check that they're positive. So finding positive, proving positivity is the same thing as finding asymptotics with an explicit error instead of a big O error. And then of course you could also ask about what is this constant, and that's something we'll get back to later. So these transfer theorems that are laid out so beautifully in Playlet and Olympico, they, in principle, give you explicit upper bounds. The errors are all certain integrals and Are all certain integrals, and you can, in principle, bound them by trying to bound some analytic function. So you split it to three regions. You have a big circle, circles near your dominant singularities, and these lines that go out. And so you could try and give explicit upper bounds, and maybe some of us here have tried to do it. And if you do, you realize you quickly hate yourself because you have some analytic function on some circle and you want to bound its modulus. Maybe you get some hyperbolic sine and cosine and you have to look up all these identities and it's so painful. Identities, and it's so painful, even for rational functions, you are, and you just behave yourself quickly. As you can tell, I've done this before, and maybe if you have too, you'll know what I'm talking about. But the idea is that everything here is definite, so we can use these tools for rigorous numeric analytic continuation to bound things. So near the singularities, well, we can compute series expansions and use these bounds using like quotient-massive major intens and things like that. On the big circle, we can cover the big circle by overlapping rectangles, and we can use these numeric tools. Rectangles, and we can use these numeric tools to give upper bounds on each of the rectangles. There's a finite number of them that cover the big circle, so then you can just compute an upper bound numerically to whatever axis you want, essentially. And so when you combine all these tools, then we can make this in principle explicit upper bounds actually explicit and put it in Sage. So now no one has to worry about it again. You don't have to kill yourself if you're doing something SP5. You can just use this package to do it for you. So here I'm just importing all. So, here I'm just importing all this stuff from the package. So, here's back to our lattice path example. So, I just put in the definite equation again. So, now we have this command. This is new to ORI algebra from what we worked on. Mark and Rouen spent a lot of work doing this. So, it's a bound coefficient. So, you put in the differential equation. You put in the first three terms in this case to specify which function we're interested in. We ask for an order of expansion and some precision. And I hit enter. And I hit enter, and you'll see in a second it should come back. So I have this expansion here. So it's 1 times 4 to the n plus some error term here, n to the minus 1. And then you'll see there's plus another term. And then you'll see there's this b here. So b, instead of big O, it's a b. And so b is not a big O. B is an explicit error term, so it's this constant in this interval. Constant in this interval, log n over n cubed, but the bound is only active when n is bigger than or equal to 7. So you need to have some kind of bound, some kind of lower thing on your index. Again, I could ask for more accuracy. That's for 200 digits, and this should hopefully not take too long. You could ask for higher order. So I could ask for order five. And now you see you get more terms. So now if I figure out where the heck my E is. Where the heck my B is. So here is B. So you'll see that the constant is a little bigger because we have higher order terms. So something else that you might want to do is you might want to say, okay, one of the reasons this constant is big is because it holds for all n bigger than or equal to 13. But you can also relax that and say, I only want a bound that's, you know, when n is bigger than or equal to 100. And so if you allow yourself to go higher in the index, then you can get smaller coefficients on your. Smaller coefficients on your bound. Yeah, so in this case, it proves, I'm running a little off the slide here, so I'm with that. There we go. So it's still a little off the slide, but there's just log n over n cubed over there. So you get basically an interval that you're guaranteed to lie in. And so you can very easily show now that all these are non-negative. Of course, it's trivial because it's counting sequence. It's non-negative. But you can use this. But you can use this if you didn't build that before to prove it's non-negative. Going back to our biomembrane example, so we have this, this is the actual differential equation that we want to show. So we had this sequence, and if we can show it has all positive terms, we prove uniqueness for this Kenham model for biomembranes. So we want to show this is non-negative. And then, so we can do that here, and in a second, it will return. The original paper that Mark and I put out about this, we That Mark and I put out about this, we did it a little bit more by hand, and then we realized that it could be more automated. So here's the expansion by hand, and we can flip through it. But the point is just that you actually get this explosive error bound that holds for n bigger than or equal to 50. So you can just show from the way the error terms work out that for n is bigger than or equal to 50, it must be guaranteed to be positive because of this. And then you can just check the first 50, you know, everyone can compute them for the recurrence. And you can see they're all non-negative too. So we put this on negative, and then we prove that this model. And then we prove that this model for biomembranes has gained signation. Okay, so there are two caveats that I want to mention. So the first is that you might have to worry about cancellation. So if you have multiple dominant singularities, you add up the contributions of each of them. And it can be extremely hard to decide if you get cancellation between these terms. In fact, this is related to something called the Spellum problem. And it's essentially been open for 100 years whether you can do this for unitary rational functions. Can do this for unitary rational functions. So that's an extremely hard problem. We're not claiming to touch that, right? But the nice thing is that you actually really don't have to worry about this in enumeration. So there's this kind of meta principle that there's never, no one ever knows of an example in the literature of a combinatorial problem where you have a generating function with natural number coefficients that count something that is not a special kind of function called n rational function, which are not just the class of functions with non-negative coefficients. It's kind of a bad name. Coefficients. It's kind of a bad name, but they're basically the generating functions, enumerating regular languages. And there's this nice principle that for n rational functions, you don't have this very topological behavior coming up. You can figure out when you have cancellation, you always have some curiosities, and you can figure those out. And as far as I know, people have given survey talks about this in the International Congress of Math and stuff like that, saying that they've never seen a real example in the literature of a rational generated function that's not nrational, that actually is. That's not n rational, that actually is enumerating a class. So it seems like this doesn't actually, this difficulty is not really actually a worry for us if we're interested in the functions. There is another difficulty, though, which is a little bit more worrying. So this is what I'll call certifying singularities. So consider now the sequence that satisfies this p recursion, so it's an order 2 recursion. It's generating function, you can get the differential equation using The differential equation using just converting from the recurrence to differential equation satisfies this differential equation. You'll see here that if you look at the leading term, there's singularities here. So it looks like there's a singularity at z is equal to 1, z is equal to 2, and maybe the origin, but we know our generated functions have that. But the problem is, the singularity at z is equal to 1 actually is not a singularity of the generated function. So it's a singularity of other solutions to the differential equation, but not of the actual generated function. The actual generator functions. And so if you run this code that we have here, we ran it to a thousand bits, so it takes a second. But you'll see here that it tells you that you get 1 times plus or minus 10 to the negative 300. So it knows it's something between negative 10 to the negative 300 and positive 10 to the negative 300, but you don't know that it's 0. I mean, morally, you probably would suspect it's 0. You probably would suspect it's zero, it's zero to 300 decimal places, but you don't know for sure, right? So, this is related to this thing called the connection problem, where you want to decide basically when these co-efficients are zero or not, to see if you actually have a similarity at a certain point. Now, this is, again, an extremely difficult problem. People don't know if it's decidable in general. But in some cases, you might know that you're generating functions analytic at a point. So, as part of this bounding procedure, you can pass in nodes. This bounding procedure, you can pass in known analytic points. So it automatically always says that the origin is analytic when it runs the code. And here we can add the point set is equal to 1. And if you do that, then it will give you an actual bound. In a second. So it says it's basically 2 to the negative n times 1 over n. And indeed, this recurrence was cooked up. So the actual sequence is 2 to the negative n over 1 plus n. So it is thread as a 2 behavior. So again, we can't actually. Here. So again, we can't actually solve the connection problem right now because this is extremely difficult. But if you know for other reasons that it's analytic at this point, like maybe it would have a negative term in the dominant asymptotic, so you know that can't happen, or you can do other bounding methods, complimental arguments, you can tell the software that, and then it will be intelligent enough to. Or maybe you don't know, but you just want to get it bound that's reasonably accurate. Like if it tells you it's zero to 300 decimal places, you probably could say, okay, I think it's zero. Maybe I just want it bound. I think it's zero. Maybe I just want it bound, assuming that it actually fits. Okay, so this arises a lot in lattice path enumeration. So here is similar to what I showed before, walk in a quadrant, except now you have north, southeast, southwest. So you have the north and the two bottom diagonal directions. So if you do this, then you have three steps. So if it was unbounded, if you weren't restricted to a quadrant, you'd go like three to the n. Read it again. And the definite equation has a singularity at z is equal to a third. But if you try and do this, oh, I ran this code. This was the code I was supposed to run beforehand. But it's okay because I basically played at the end. Fuck now. So this one actually takes about two minutes to run. This is the one cell that I was supposed to have run beforehand because I didn't want to do it here. But thanks to the software presentation tomorrow, I'm going to skip the second half of my talk now and do the second half of my talk on the software presentation. So anyways, in a second, when this finishes, you'll see that it will have the same problem. It'll think it's 3 to the n. Will have the same problem. It'll think it's 3 to the n times a constant that's very, very close to 0. So you could say, how can we actually show that it's 0? How can we give dominant asymptotics? And how can we sometimes find these coefficients that we don't know and we just go numerically? Well, you need a new representation. You need analytic combinatorics in several variables. And that will now be in the software representation tomorrow. So thank you very much. Any other questions? Just a reminder that for those who are interested.