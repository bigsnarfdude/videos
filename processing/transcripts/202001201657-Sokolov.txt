If you want to ask some questions, it's better to use your voice. Like, if you will raise your hand, but I will not see you anyway. Yeah, well, today I will talk about some semi-algebraic plus all plus minus one variables. Well we just switch with the range of our variables. Usually we talk about Boolean variables, but now you can do plus or minus one. You can do plus or minus one. Some notation, well, we will see some system of polynomial equalities and system of polynomial inequalities. I will always use these two letters, F for equalities and H for inequalities. And we assume that we have some range axioms. For Boolean case, range axioms for XI variable. xi variable s standard like xi square minus xi and for plus minus one basis we will think that uh xy square equals to one do you really mean that the inequalities are strict inequalities uh don't care about it so all results will work for any notation yeah uh again sum of squares Yeah uh again sum of squares pro system uh here we uh already uh uh expand oh sorry yeah expand this representation to squares and we have seen that polynomials from each part of our system may appear more than one type. Okay, and polynomial calculus process And polynomial calculus pro system is just a sequence of polynomials. And uh each polynomial is either uh how we can generate these polynomials. We can pick uh either any action, so from our system or range action, or we can derive polynomials from previous polynomials. So first rule is just multiplication rule. We pick previous polynomial and multiply it by a variable. A variable, or we can sum two previous polynomials with some coefficients. And yeah, about this rule, we have some field that we choose before the start of the proof. And this coefficients alpha and beta came from this field. Any questions or definitions? And in the end, we want to derive polynomial that equals one. Small example, like we have a system of equalities, and here is the proof in polynomial calculus. Then we assume that all variables are plus minus ones. So we start with this axiom, we multiply it by y. Here we use Here we use linear combination and we derive this polynomial from these two polynomials again. We use linear combination and we derive these polynomials and in the end we'll derive one. Okay, so we have some hierarchy on pro systems. So here we have some V pro systems, resolution and most of them. Here we have Most of the size. Here we have very strong proof systems. Ideal clue system and confluence system. Difference between arrows, here I mean that we can simulate it but only for proper field. Here I mean we can simulate it if we use real numbers. Uh it's some analog of ideas, but when you can use inequalities instead of equalities. Well, uh I'm not sure that here I need some presentation about motivation why we care about proof complexity, but anyway, my personal motivation that for weak proof systems it's enough to prove lower balance to prove lower bounds for monotonal computations for strong enough. Computations for strong enough proof systems, it's enough to give lower bounds for general computations. So, it's some natural way how to prove lower bounds for circuits. What can we do? So, for a lot of proof systems, we know that we have some general technique that give us lower bounds. It's a restriction technique. It can be the like simple restriction technique called some switching lemma or trade-off. Switching lemma or trade-off that was presented in previous talk. But anyway, we made some restrictions. And another general technique is monotonic interpolation that also sometimes can help us. I don't want to say that this is all techniques that we can do, but it's general techniques that works for all kinds of proof systems for which we can. Proof systems for which we can prove our bounds. Okay, and if we allow plus minus one variables, uh we don't know how to use both both kind of these techniques. So for monoton interpolation we cannot do anything for polynomial characters. For and restriction technique also not clear how to use. Is there anything common in all kind of these pro systems? Kind of these proof systems. And surprisingly, yes, so we have mod P gates that we can parallel in each line of the proof we can see a lot of mod P gates. And it's a serious problem, so we don't know what to do with it. So should we be afraid of this dragon? Yes, it's actually dragon. So you don't know how to prove lower bots. And now some theories. What can we actually do? If you have some system of equalities and inequalities, we can lift it with a simple gadget with majority of three variables and we can prove size lower bounds in the sum of squares. Another thing. Another theorem that if we pick random formula, and actually it's 11 random CNF formula, then we can prove both kind of lower bounds, sum of squares and polynomial capals over any field. And the same for P. John Cole principle, but it works only for polynomial calculus. That's not really a surprise because for sum of squares we have upper bound. Of squares, we have upper bound. And it's upper bound since it has degree 2. So we can switch between bases more or less for free. And this theorem actually says that we can separate sum of squares and polynomial calculations. Any questions? Nothing. What's the F in the first theorem? In this theorem, oh, it's sum of squares, so they need some good fields, so they need to deal with inequalities, so it's real numbers. No, but is it a specific system in mind or any system lifted by the numbers you can develop? Oh, system. System can be any polynomial system. Yeah. This results for formulas, but here we can consider any polynomial system. Okay. Uh now, if you don't have uh any questions, we'll try to understand the strategies. I'm confused about the statement of the first one. Yeah, it's uh if you have some system of polynomial equalities and inequalities such that you have good enough lower bound on the degree, then you can lift it, that means that you replace it. Lifted, that means that you replace each variable by majority of fresh variables. I see. So it's an if of the second sentence and flies the first. Yeah, yeah. Uh for resolution in particular, we know that it's enough here to have parity and you can lift like width width lower bound to size lower bound. Here, by obvious reason, parity will not work. Yeah, and we will see it later. Well, but you can simulate mod2 gates with this system, so parity will not work. So parity will not work, but majority will. Okay. Uh it's not only for majority, we have some simple properties. Are these kilometers independent or will one follow from another? Oh, sorry? What? They're independent or oh, uh the the these two uh the same th more or less the same strategy works for for both theorems and it's a bit different and here we need uh your result. we need your result, your previous result, we need properties that we can make some assignment that not reduce the degree too much. Here we don't need any complicated theorems. Okay, I will focus on the second theorem now. Two words about size measure, well, you can think about Well, you can think about the usual monomial size, but uh we assume that all operations that we do are modular ideally generated by rejections, so nothing really special. This reduction by ideal can only decrease the size. So, general strategy. Let's start with some strategy that works for 0, 1 basis and assume that. And assume that we have polynomial calculus proof. For some squares, it works even in a bit simpler way because we don't need to care about different fields. And we have some bunch of monomials that has really huge degree. And we want to make some restriction that kills all these monomials. So if proof is small, that we have not so much monomials of big degree, they can pick the most. Degree. They can pick the most frequent literal that we can see in the proof. And we want to assign this literal. It's not a variable, it's a literal, so it can be either a variable or negation. And we want to assign this literal to zero. And this separation kills all terms of big degree that contains x. And after restriction, it's still a proof, but the proof of a system. A system of after restriction, and we need to take care about hardness of the system. So, after restriction, our system should still be hard in terms of degree. It's kind of magic because it seems that we don't have any freedom. We pick the most frequent literal and yeah, but we want to try to avoid local. We want to try to avoid local contradiction, and here we usually if you're familiar with closure operation, here we use closure operation. If you're not familiar with closure operation, you can think that we want to use some kind of self-reducibility. So here we want to shrink our formula a bit such that it's still like a random formula, but of smaller size. And we repeat this operation until we kill all terms in set H and after that we kill all terms of big degree. But since we can do this magic, the remaining formulas or remaining systems still require proof of large degree. That means that original proof should be B. And the degree is the source of hardness. Well, if we want to change our bases, the only problem that we have is like this step. We cannot assign literal to zero. Any questions? No? And why we cannot assign it to zero? Well, if we assign it to zero, we immediately violate some action. Action that means there is no chance that the remaining system after this assignment will be hard in terms of degree. We need degree one to prove. Second attempt that we can do, we can try to assign our literal in both ways. We can assign one and minus one, consider linear combination of the proofs, and if it's still a proof, we can assume If it's still a proof, we can do everything. Well, we have a problem. So, if we start, if we can derive some polynomial, we can multiply it by x variable, and we can multiply it by x variable one more time. Since all our operations modules range actions, we just erase x variable. Well, what happens if we apply our tau operator to all lines of the proof? Well, if Well, if polynomial p was independent of x variable, it remains the same. But unfortunately, this polynomial xp goes to 0. And from 0, you cannot derive polynomial p again. Well, it's a general problem. Like in 0, 1, we don't see these phenomena, but in plus and minus 1 variables, multiplication of variables. Variables multiplication operation is invertible operation. Well, maybe our attempts are wrong and we cannot use degree. And yes, we know actually we have some conterexamples. And if you consider such a formula, we know that it requires a linear degree, but we still have very small proofs in all kinds of All kinds of proof systems that we consider. But what else we can do? Let's try to find another source of hardness. And we know that multiplication is ineversible. Let's try to use it. In which cases, we really can reduce the degree of polynomials that we can see in our proof. Let's start with some polynomials that are just product of. Polynomial that is just product of variables. Can we, if you will see this polynomial in the proof, we can reduce the degree of this polynomial. And by a very simple operation, we can multiply it by variables, by all variables, and we can reduce it to one. But what if we will see another polynomial in our proof, like product of all variables minus one? Can we do the same trick? Yeah, well, we can try, but we can Well, we can try, but we can reduce degree, but not really up to n over 2. It's still linear. Well, we can try to use another source of hardness instead of degree. We can consider all polynomial that you can see in the proof and try to understand the symmetric differences between terms in the degree. What is the symmetric differences? What is the symmetric differences? If you will see, we have a proof, and for each polynomial that we can see, we can define a square of this proof. And we want to understand degrees of each terms that we can see in this square. So, at this step, we don't allow to use any cancellations. Any questions? You're taking the whole proof? Yeah, we can see the whole proof. We can see the sum polynomial in the proof. And consider all possible pairs of terms that we can see in the proof. All possible pairs of terms. For a single line. For a single line. For a single line. For a single line, yeah. Yeah, it's maybe it's convenient to think about this quadratic representation that for single line in the proof we have set of all possible pairs of terms that we can see in this line and now we want to apply tau operation but we want to apply tau operation not for regional proof we want to apply tau operation We want to apply the operation for the quadratic representation of the proof, because we know for original proof we can do it, but quadratic operation somehow capture the new source of hardness. But we don't have an access to the quadratic representation of the proof. We can manipulate with original proof somehow. And we have very strange operation that definitely do what we want. Definitely do what we want. The separation applies tau operator to the quadratic representation of the proof. And the separation operation, we pick each line of the proof and divide it by two parts. Path that depends on x and part that doesn't depend on x. If you will try to compute these pairs again, you will see that in the quadratic representation of the proof, we exactly erase. Of the proof, we exactly erase all terms that contain x variable. Okay, any questions? So in the usual random restriction case, when you substitute for a variable, it kills a certain number of monomials. So there are some monomials in the original proof which are just not there after substitution. Yes, here it's not true. If you consider the original proof, the separation looks completely crazy. We don't decrease the size of the original proof. What we change, we just reorder it in some crazy way. But if you consider the quadratic representation of the proof, we really decrease the size of the quadratic representation of the proof. But but so like but at some point that that should translate to a size reduction in the original group and so that can be. I will say if you were on the next slide about it. Well this pretty perfection unfortunately uh somehow affects our system but uh yeah uh we will think that if we apply uh this split situation to the proof um To the proof, the result is still a proof, but of damaged version of our polynomial system. So, what's the general strategy for plus-minus-1 basis? If the proof is small, that size of the quadratic representation is also small. So, we pick the most frequent literal that we can see in the quadratic representation of the proof and apply split operation. Split operation to the proof and see what happens in the quadratic representation. In the quadratic representation, we queue all terms that contains this variable. What happens now? Now we have damaged version of our system, and again we use the same kind of magic to avoid local contradictions. And we want to repeat until we have terms of big degree in the quadratic representation. Well, in the end, we want to satisfy all broken constraints. Broken demonstrates the same. Well, this step is completely fails if you consider session formulas. There is no way how to satisfy all broken constraints. To satisfy all broken constraints for Jason formula. So it should happen at some moment because for Secret formula we have upper bounds. Something should run about it. And yeah, this step is wrong for Saysian formula. But it works for random CNF and it works for Edron Hall principle. Well, w w what's we have in the end? In the end. In the end we have proof such that quadratic representation of the proof Quadratic representation of the proof doesn't contain any term of big degree. Does it mean that the original proof contains a term of big degree? We want to say yes, and this lemma says yes. If we know that in the quadratic representation of the proof, we can play somehow with our proof and change it, and the remaining proof will have small enough degree. Well, it's wrong. Well, it's wrong. Uh how much time do I have? Uh five five five minutes. Yeah, we'll have just few words how to fix it. Uh in order to fix it we need to use uh lazy representation of polynomials. That means that uh at each line of the proof we should care not only about this line but also about both predecessors. And uh Predecessors and compute quadratic representation of these three polynomials simultaneously. We want to take care about all pairs of terms that we can see in current moment and in two predecessors simultaneously. This is the meaning of lazy representation. And a fixed quadratic representation is just a sequence. Representation, it's just a sequence of these lazy representations of polymonics. And now this lemma is true. And why it's true? Because if you have any term, and we know that the quadratic representation of this term doesn't contain any monomial of big degree, what does it mean? That means that we c can consider polynomial Si. This polynomial Si also has low degree, because Also, has a low degree because we can see all these pairs in the quadratic representation. And polynomial Pi can be considered as some term of maybe big degree times some non-trivial term of small enough degree. And the main idea of this lemma is that we can erase this big term in the beginning. And I I don't want to I don't want to explain how, but it's not so complicated. So if you have for new quadratic representation, we know that there is no terms of big degree in new quadratic representation, then in the original proof we also can change it somehow such that we will not have any terms of big degree. And some open problems. What can we say about functional digital principle? Surprisingly, this last step when we want to fix broken constraints, it's also not true that we can do for functional version of pitch and hole principle. So this step will not work, and current technique will not give us anything for functional version. Well, actually we want some technique that not go through the degree. And the most famous formula for which we don't know how to reduce our lower bounds to the degree, it's weak Pigeon-Hall principle. So can we prove any lower bounds for weak Pidgeon-Hall principle even for zero, one basis? Or plus, minus one? It's also interesting. It's also interesting. And the last open problem: can we simulate resolution in plus minus one basis? Because now it's not so clear. Well, this technique that I presented also works for generalization that for each variable we can use both encoding, 0, 1, and plus, minus 1 simultaneously. But We have lower bounds, but what if we allow only plus minus one variables? Can we assimilate in this proof system resolution? It's not clear. Yeah, thank you for your attention. Looks like you're going to answer something more general, or I believe it's more general than your. I believe more general than your questions for you. Do you know of any separations between these two importings, or plus minus one and zero, one? Is there any separation? In one direction. In other end, no. Says the formulas are hard for 0, 1, but easy for plus minus 1. And in the other direction? In the other direction, no. And and uh it uses uh so if you have a if you have a negative answer to question over three I think it will use pressure. People on it now, but in 0, 1 we have very nice property that we can make simple restriction that kills a lot of terms. For plus minus 1, uh we use another trick that we can invert multiplication that really helps us in That really helps us in the final lemma. If we allow in particular one and two, uh we're in trouble. And trouble more generally than we can think about it, because now we can use non-multilinear polynomials. And non-multilinearity can help us to shrink seismic groups. Why not? Because if x is either 1 or 2, x squared is either 1 or 4. Yes, but still x minus 1 times x minus 1. 2x minus 1 times x minus 2 is 0. Yes, yes. You can reduce model this ideal, but after reduction, size will blow up exponentially. Size will blow up after model. Yes, yes. Also, like if the values are from like a a multiplicative group, then maybe you can generalize like quadratic representation to the order order of the Yeah, uh maybe. I mean for six. Yeah, yeah, yeah, for finite field it's not a big problem. Like uh the biggest problem that you deal with for field of hexages to zero. For real numbers it's the main problem. Yes. More questions. Is there a paper on this? Yes, there is a paper. Yeah yes, there is a paper uh uh I probably will submit it online in two or three weeks. And so we are software taking there as a language. How did you want to say something? Oh yes, uh so uh we still try to uh organize uh diets uh on Wednesday because it's Wednesday and it's just uh Monday. But it's good to know what people want to do and uh also if uh if we have uh cars. So I know one car is possible to rent a car downtown. Yes, it is, yes. So it's not even But it's not really whether we really need uh uh to use cars, because uh there are some standard uh hikes uh I don't know how many of you normally have been here. So the simplest one is the Tunnel Mountain and this is this mountain is uh you go uphill here then this is uh an easy hike 45 minutes slow walk in the summer in summer. Summer? In summer. And today check the path. It's okay, except that it's slippery, so that's one problem, especially going down. So this is something that everybody can do during the more uh a longer uh height is to the sulfur, uh sulfur mountain. Sulfur mountain is uh So Turmountain is driving in this direction on the other side. It's the highest mountain there. And there is a nice view from there. And there is also a gondola going there. So you can use gondola going up and down. You can walk up and use gondola down. On Wednesday they they should uh operate until uh eight thirty or something like that, th so there is no danger that you So there is no danger that you would have to try the button. And then there is also some western part there. So this is another possibility. And then if we take cars, then the two standard places or the the one the two that uh that I know is uh the area of Lake Louise. the area of Lake Louise. So it it it's uh I don't know how how long drive up an hour or something like that. Uh and so there is a lake, you can walk around the lake, but you can also walk to the mountains around, so it's a nice thing. I also don't know how it looks like in winter, but definitely around the lake it should be easy. The rim of the lake you can walk around. Of the lake, you can walk around. It depends on the amount of snow. It might be just the, and the lake's frozen probably and covered improbably, based on paths. So it's just the snow and you see parameters around it. Another popular thing is called ice fields, which I think is essentially a glazer. It's one way. And this is a longer way, at least one hour drive, or maybe. No, no, it's it's one way. No, no, it's longer than that. And I don't find it so exciting. So, in the winter, it's going to be sort of less exciting. Being out on the ice in the middle of winter on the glacier is probably not quite the same thing. One other thing that I was just randomly checking, so they don't have cross-country ski rentals here, like you can't get them from the Sally Gordon building. The Sally Gordon building, but there are cross-country ski rental places downtown, and one might be able to ski in the valley. There are some trails that are actually in the valley that aren't too bad. And some of them are a couple spots where they say, go through this area quickly because of what might be a shoot or avalanche, but that's but in general there's very little elevation. There's very little elevation gain or loss on these trails. It's probably along this river here. There are multiple trails. There's one along the river by the hotel and another in other directions. I haven't actually scoped them out, so I would love, you know, if anybody else has done it here, that would be so. Anybody would be interested in skiing for Sunday skis? We uh have lunch until uh like one PM and uh the sunset is uh six thirty thirty five percent of for security and so both 