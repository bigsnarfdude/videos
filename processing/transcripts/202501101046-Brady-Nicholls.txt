You have an acronym? Where is it? Diff! Hello, everyone. I'm Devi. I'm a second-year PhD student at AMLGB Harvard. I'm going to be presenting our work that we are able to do this week on mechanistic filters apparently. But so, the problem that we try to look at in the stack group of ours is The spacious group of ours is glioblastoma. So, GBM is one of the most deadliest cancers, as you guys know. Here's the image right here. You can see an even contrast with resection cavity and some hyperintensity values around it. Standard of care for treatment is usually surgical resection, chemotherapy, radiotherapy, one combination or the other. And the outcomes are very poor. As you know, that GPM is a death sentence. The median survival time is around twelve to fifteen months. Around 12 to 15 months. If you're wondering where I got the top and my from, it's for one of my papers. I guess I don't think afterwards, but sorry for the shameless bug. Anyways, so medial survival time is 12 to 15 months. So what are we trying to do here? What can we do here? So predicting location of recurrence is what we thought would be a relatively, considering the time and the resources and everything we had, would be a relatively achievable target. That is, we can try to predict where, because in GBM almost all patients record. All patients recur. The question is: Can we predict where they recur? And if we can, we can potentially use that as a point of care decision support tool for clinicians or physicians to provide more tailored regimens, better patient managements, and hopefully potentially leading to better outcomes. So, this was the problem that we are trying to solve here. And this is the framework that we could come up with. So, just I'll go through it quickly and then I'll go to the individual parts as well. So, we have the first and one of the most integral parts. The first and one of the most integral part of the whole framework is the first part, which is getting the flow field. So, this is led by Dr. Lockney's work. We use Cindy to estimate the flow field from the DCE images, which essentially tells you how things are changing spatio-temporally and across the image. So, we use SINIG, we get the concentration heat map of. So, right now, this is for CAR T-cell therapy, but we are planning to actually. But we are planning to extend this to RT radiation therapy as well. So, from the CINDI, we get the flow field, we get the concentration heat map that essentially tells you where the most interaction is, so to say. So, we get this, and then we take the structural brain MRI, the underlying structure Brain MRI. We pass that into Brainiac. We'll come to what Brainiac is later. So, we get latent feature representation for both the concentration heat map and the Heat maps and the underlying structure MRI. So, this for now we're looking into FLAR and T1C, which is like the most used standard of care sequences for GVM treatment. Then we plan to merge those two filters that we get from the two arms using a mechanistic approach, a mechanistic filter, and we plug a decoder at the end to get the location prediction, which is we get the heat map here. We get the heat map here. So, if you can look at it in a more 3D sort of way, you can see that there are two features here. You merge them together, you get an output feature, which is a 3D block. You pass that into a decoder that essentially upscales that 3D block and comes up with a location, like a heat map, so to say, that can tell you where the tumor is going to recur. So, you can tailor your therapies more accurately. So, this is how the framework looks like. Like the whole thing, part of it is trainable and part of it is fixed inputs. I'm going to come to that later. Oh, sorry. So let's start with Cindy. One of the most important part of why the whole thing is even possible if it is possible. So Cindy is basically regression over a function, in this case over transport equation applied over to a Flight over to PCE images for GBM patients here. So, what we get is essentially a flow field out of this. This is mostly led by Dr. Rocknis work. So, we use SININ, we get the equations, we run the simulation and get the concentration heat map here that you see here. So, this is essentially what we get, that this map tells us where the area of activations are, which we hope to, which we Which we hope can inform us to predict where the recurrence is. Because in a very layman sort of way, you can think that if the areas of activation are here, you would think that recurrence would be around this region. So the heuristic behind the whole approach is that if we can know how things are happening by a single image across the brain, Across the brain, you can use that and use data modeling techniques using Brain Yak or whatever machine learning models to basically predict where recurrence is going to happen. So, first part is Cindy, second part is Brain Yak. Brain Yak is basically nothing but a big foundation model and by foundation model I say it's a simple ResNet trained over 50,000 brain MRI scans using contrastive learning approaches. I didn't get a lot of details onto it, but for A lot of details onto it, but for the sake of time, I'll just say that the output of the brain yak is a feature. So you can think of brain yak as a big dimensionality reduction technique where you have 3D brain MRI volume of, let's say, 128, 128, 128 puxils, and then you essentially reduce that into a very small latent representation that is very information rich and contains only the features that are relevant to the downstream classes. So just as the V-Train brain AI 100. Just as we train brainiac on a ton of images using contrasted learning and then validate in a ton of different settings. So that is the part that I worked on during my PhD. And coming back to the framework, so we have CINDI, we get the flow field, we get the drug distribution by running the equation that we get from Cindy and then simulating it. We get this. We have the underlying structure MRI, which could be T1 CE or a flare image. We pass both of them. Image. We pass both of them into encoder and these two you can think of it as just the feature dimensional detection techniques. We get the filters, we pass them into a mechanistic filter, which is the parameters here are what we're trying to learn as well when we train. And then the output features get passed into a decoder, and then you predict the location. So how to implement this? This part is fixed. This part is fixed. The only training pipeline here is these two. So while we train, we predict the parameters of the mechanistic. Parameters of the mechanistic filter, and we're learning the parameters of the decoder in a one-training objective to predict location. So, that is how our approach goes as of now. Measurable outcome, we're still aim for our, so the reason we aim for a paper or like I said, abstract here is the combination of mechanistic modeling, Cindy, and using deep learning. And using deep learning convolutional networks to come to merge together and turn it into a solution-based network is pretty novel, in our opinion. To our knowledge, there is not a framework that exists which does that. So we aim for a journal submission, hopefully in July. Coding part, me, Sarah, and Jana would take care of it. Consultation map, Guerna, Russell, and Matt are leading RT extension, Jana and Sarah, writing Philip, Jana, and everyone will contribute. And then at earliest, Will contribute, and then at earliest, we'll try to get a blog post out of it. And I'm out of time, so thank you. All right, any question? How did you choose the equation for that mechanistic filter? This equation? Yeah, the F of V C. I would like to direct you to the brilliant mathematicians and weakness that we found we set a few properties that we wanted to have. A few properties that we wanted to have. So we know, for instance, if there's no tumor cell, there should be no chance of recurrence. So we had four properties for it, where if you look at input being C, the concentration of drug, and B, the volume of the tumor, we know certain properties. And then we took those four properties and we asked, chat, check, continue, create function. And then we verified that that properties were like. That's graphics contact. Because it does have some properties of convexity or concavity and the right properties, but logical. I think we said it needed to be differentiable as well. We want nice functions to do this. Thank you so much. All right, next up. Mechanism on network nets. Try and be both as fine. No step. No, what I desire is either. Well, there we go. Just refresh the last one and try to switch. No, there's a television. And I'm representing the mechanism-informed neural network. I think it's very similar to many of the approaches that you've been taking. Okay, so, but I wanted to be very explicit about our aim. We're going to look at a particular application, and so that's this DMG, this pediatric diffuse midline gliomas. And we want to understand the effect of radiation. And then a longer-term goal would be. A longer-term goal would be to, from that machine learning insight, develop a mechanistic model. Okay, so let me tell you a little bit about these diffuse midline gliomas. So they're quite rare. There's only 200 to 300 cases each year in the US. And this is again in pediatric cases. And the overall survival is only 11 months. So it's not very exciting. And they're in. And they're located in the brainstem, these tumors, specifically the pons, and resection and drug delivery is very difficult. So there's no cure, but the standard treatment is radiation therapy. And MRI is what's used for diagnosis and monitoring. So that's the data we're going to compare against. So the data set that we have available to us has 40 patients and it says T2 flare. And it's this T2 flare MRI, and they have one image taken at the time of diagnosis, and then they get radiation therapy, and then four months later, they have another MRI. And our goal is to decide exactly what the effect of the radiation therapy is on the tumor. So, we're going to have a mechanistic model for the tumor growth, and then we're going to have a machine learning effect. To have a machine learning effect for the intervention. So we have this invasion, proliferation, reaction, diffusion, partial differential equation. U is the amount of tumor, and it depends on space and time. And so this is our mechanistic model. So these models have been developed for quite a while, and we're learning about which versions of those models are most appropriate for the brainstem. And then we're going to say we don't know what this term is. To say we don't know what this term is, this intervention term. The work that we've looked at, not specifically for brainstem, but other tumors, is that is just proportional to U. So we're going to say, well, maybe it's not so simple, maybe it's not just the linear term in U. So let's represent that with the neural network. So u is input, it's a single number input, and it's the number at that position, that local position in space. Space. We're not going to be too ambitious, so we're just going to have a small, relatively small neural network. What we've been playing around with is just 2x4 hidden layers. And then there's a single number output, the intervention term at the particular point in space. And then we think of this as the MRI data at the long time, the end time. And this is the solution coming from. This is the solution coming from solving the partial differential equation, and we just compare those in the L2. We sum over all the patients, so we're implicitly making the assumption that the effect is the same across all patients. And then, yeah, and then this is our loss function. So we want to make sure that the model prediction is as close as possible to the data. Okay, so we're going to take a non-pins approach, right? We're not going to solve the We're not going to solve the partial differential equation with a neural network. We're going to solve it with the traditional numerical method. So we're going to use finite differences. We'll start off with constant diffusion, just because it's a little bit simpler, but in principle, our method will still work if the diffusion varies in space. And so we just have a uniform grid, and then the finite difference coefficients distenciles 1, 1, 1, 1, 1, 1 minus 6. And so that's those terms. We treat the diffusion term, this invasion term, implicitly because it's quite numerically stiff otherwise. And then the growth term, this proliferation term, and this unknown intervention term are treated explicitly. And then what does this look like? This looks like as you step through time, you have to solve a linear system. So all the non-linearity is hidden in these. Linearity is hidden in these two terms, which you treat explicitly. It's called an IMEX scheme. It works very well when most of your stiffness comes from the diffusion, which is the case here. And this is a sparse banded linear system. So that means it's relatively easy and efficient to solve. In particular, because we're going to try and train a neural network on these coefficients, we have to watch how the solution depends on the parameters of those neural networks. So, in principle, that's fairly difficult to track. That's fairly difficult to track if you're going to do it by hand as you solve how the gradients change. But PyTorch, and in particular, this function torch linadls.solve does it all for us. Okay, so we only, you know, we started writing the code two days ago, so don't be too excited. So these are just preliminary results. So we're not training anything yet. We're just doing the forward. We're just doing the forward solve, just solving the differential equation with different intervention terms. So set the term equal to zero, set it equal to c times u, this traditional description, and then try cu squared to see what happens. And then the tumor is going. We're solving in 3D, but I'm just showing you a 2D slice. And then this is like somehow some identification of where the tumor location is. So with no intervention, the tumor just keeps. So, with no intervention, the tumor just keeps growing. With this linear intervention, the tumor shrinks and disappears. And then it also shrinks and disappears with this term, but it goes sort of slower. You can see that this drops away faster. But that's just because u is between 0 and 1, and I use the same value C. So I'm not really doing any, you know, I'm not to say that this is a better treatment strategy. I'm not hoping for this. It's just like, you know, I'm just trying different things to see what the effect of solving. Different things to see what the effect of solving this way is. Okay, so what's our outlook? So, we would really like to write a paper on this, either a conference paper or a journal paper. That seems like a pretty reasonable goal for the people involved. Our largest challenge will be keeping everyone engaged. You know, people are going to go home and return to their normal lives, and so we're hopeful that we'll stay engaged. But we've scheduled by But we've scheduled bi-weekly meetings, so hopefully that'll help with that. And then we have a rough timeline of when we want to start comparing with data and then writing some manuscripts. We've assigned some tasks, so roughly based on our skills. So I think that's, yeah, anyone have any questions or comments? What kind of data were you pumping? What kind of data were you hoping to train a neural network? Oh, ah, so before and after the reduced transition. You think that two time points is enough to fit the end of the. That's what we have, so we can only work out this. Because typically, all these methods need more than two time points, right? Yeah. Well, we're not being very ambitious. So we're learning a one function from one. So we're learning a function from one variable to one variable, and we're saying it's the same function across space and across all the patients. So I don't know, is 40 enough? I could have all of that. Pardon me? We have a lot more of the same for later on to get the cache. Okay. Yeah, around 150 more. Oh, that's good. That's like three times a night. Great. Thank you. Thank you. Thank you. Thank you. Now we have the group that has the acronym that no longer fits with the name thing. You guys will see what this is for. This does not work. It's built. It doesn't work. Okay, let's do it with that. That's funny you can't see the slides. Yeah, that's all folks. Okay, so we are the in-silico clinical trial. Clinical trial group. Here's the list of participants that I'm speaking on behalf of. Rebecca is our peer list leader. So we are motivated by trying to take the idea of what happens in a clinical trial and seeing how we could translate this into the virtual or computer-based setting. So this is something that everyone probably knows, but the main thing to sort of summarize here is the clinical trial pipeline required to get any new therapy through, requires enrolling many, many participants. Many, many participants, right, at many different stages. It's very time-consuming, it's very expensive, and the failure rate in each of these steps is very high. So, right, the idea of in silico or virtual clinical trials, we had a conversation about the name, and then we're going to land on virtual for going forward instead of in silico, is right, we can work with much larger numbers of patients. We can better capture heterogeneity, it would be much cheaper, cost-effective. Cheaper, cost-effective, quicker, and all that. So, there's a lot of benefits for trying to bring modeling-based approaches into the clinical trial realm, and this is not something new. So, our focus was really modeling has happened in sort of this virtual clinical trial space for a while. What is the role of machine learning at different stages of the pipeline? So, we've proposed a pipeline here. It looks linear, but it's not. It's just our visualization right now. So, what we're going to do is sort of go through each step of this pipeline. Is sort of go through each step of this pipeline and ask the question of where do we think machine learning can best integrate into this pipeline. Unlike the other groups, we were not doing a research project, so our measurable outcome was a perspective article. We have a target for now of submitting it to a special issue of mathematical biosciences, and we feel like we're on track given the deadline for this is December 31st of 2021. So, what I'm going to do is sort of briefly go through each stage of this pipeline. Again, remembering it's not really linear, like I'm going through it, and tell you sort of the goal of each step and where we thought machine learning can fit in. So, the first step, which is not necessarily a step everyone is doing, but right, it's possible the first step of the pipeline could be identify drug targets for your trial, right? You might already have a target in mind and not actually need this step. So, what challenges arise at this step? So, what challenges arise at this step? Right, so it's obviously expensive, it's time-consuming to identify drugable targets. So, then we ask the question at the step and of every step of where machine learning can be fitted. So, you could obviously train machine learning models on, you know, the signatures of tumors to try to identify druggable targets. You could also use machine learning to try to repurpose existing drugs, and there are actually great nonprofits out there that are working on doing exactly that. So, what challenges do we have with this step? So, you're going to need very large data sets here for training, and also you run a high risk of identifying targets that might have really bad toxicity, right? If you're only screening for advocacy, for example. So, we sort of followed this format three-choice through. And I should say, a lot of what we do at each of these steps involves stuff the other groups are doing, right, and their projects. And you all had more expertise than we did. So, we're super open if you think. So, we're super open if you think other ideas could be added in here, or our ideas are not good. So, at this step, this is where we need to develop our model for actually simulating virtual patients. So, that's the goal of this step. So, the challenge at this step is the challenge that we have of building models. We all know those challenges. So, as has been talked about here, there are a ton of different methods out there for identifying the right equations for your data. So, I think the groups are all familiar. I think the groups are all familiar. I think we've heard Cindy, we've talked about U-Pins, BINs, all these different ways we could possibly build models. And I think from the challenging perspective, right, is these methods, these machine learning methods, require an awful lot of data. And from our group's perspective, it was unclear when this would be superior to just writing down a mechanistic or a semi-mechanistic model. And I think it's a philosophical question I'm still leaving with from this: is right, when machine learning versus traditional modeling. Traditional modeling. Okay, so we have our model. So, next thing we need to do is calibrate that model to available data, right? So, we want to make sure the model accurately describes your training data. So, we all know the challenges of calibrating models to data, right? So, we won't quite go through that. And there's a lot of machine learning approaches that are being proposed here for parametrizing models, using neural networks, for example, and other things I'm not super familiar with, and deep reinforcement learning. Familiar with in deep reinforcement learning. Again, the challenge here, right, requires a lot of data. Your data can often be noisy and sparse. And again, the question of when should I just use FM and Con and MATLAB, sorry, I didn't use MATLAB, right, to do this, right, versus these more fancy things, right, is a real challenge here. So next step, we've calibrated our model on training data. We have to validate our model, so we want to make sure the model has good predictive abilities and data it was not trained on. Trained on. Same sort of challenges that we've seen at the other steps do arise here. We had a little more trouble actually looking at what the validation step would look like from a machine learning perspective, but a few interesting ideas came up. For instance, if you had a spatial model, you might be having then predictions of spatial distributions. Could we have like similarity metrics to compare images that come out of a spatial model with images that you actually have from the clinic? There's also similarity. There's also similarity metrics for comparing time course data. That's better than looking at mean squared error, say, as your comparison. Okay, so those are our challenges. Next up is creating the virtual patients themselves. So what we're looking for here is what we're going to call plausible patients. So these are realistic parameterizations of your mathematical model. You don't want parameterizations that don't represent what your patients could actually do. So the challenge at this step of the pipeline comes At this step of the pipeline, comes if you've built a really complex model. If your model is not that complex, there's not much of a challenge here. Is that you're going to have to do many, many random samplings of your parameter space to see if your patient sort of fits the constraints of a plausible patient, yet solving the model over and over again is really computationally intensive, and you end up throwing away parameterizations. So, the place we saw machine learning really being able to help here is with surrogate models. So, you train a surrogate model. Models. So you train a surrogate model to just answer your question, which is: is this parameterization allowable given my constraints or not? It doesn't have all the dynamics of your true model, but then we can use it to rapidly pre-screen parameterizations and say, is this a plausible patient? The challenge we saw here is you need to run your original model a lot to create your surrogate model. So where's the trade off on right training the surrogate model computationally versus the time you save on generating your patients? On generating your patients. All right, and then the last step of the process is now that you've actually, oh, I should say, the next step of the pipeline is conducting the trial. That's just solving your model. We're not putting machine learning in there. Okay, good. So the last step is to then analyze the data that comes out of your virtual clinical trial. And in many ways, right, this is sort of a standard machine learning problem. You're going to get high-dimensional data that depends on a lot of parameters. Depends on a lot of parameters, right? And we want to interpret that. So, in many ways, like this is where we saw very standard machine learning, clustering, feature identification, right, to be able to really differentiate, say, responders, partial responders, non-responders, based on model parameters that actually led to that response. And sort of standard machine learning challenges here, but we thought probably this is the most traditional place for machine learning. So, here's our timeline for Beyond the Workshop. Each group member has been assigned. Workshop: Each group member has been assigned one part of this pipeline, and we're going to try to write our sort of section of the perspective piece. We have the blog post deadline in March, and our goal is to try to prepare the perspective between people and me. And I think the challenges of the project I sort of tried to hit on as I was talking, we were mostly not machine learning experts in our group. We had a lot of modelers. So, I think we had to understand a lot of the things that were happening here and then sort of. A lot of the things that were happening here, and then sort of philosophically grapple with what is this stuff better than what we've already been doing, or what is the right role for it. So I think that's what I had to say. Thanks. So, in the beautiful talk, by the way, in the creation of these virtual cohorts, do you see, or have you discovered any metallic? Or, have you discovered any methodologies that also focus in on the tail-end, like more extreme cases of these distributions? We're solely just focusing on what is considered the average representation of disease. So, I mean, the question is, and this is really a design question, what are your constraints you're imposing on a plausible patient? If you are really sort of greedy on that, you might end up allowing a lot of things that you don't see in the population, but if you restrict it too much, Population, but if you restrict it too much, it might be just as restrictive as a clinical trial that holds 50 people. So that's a really tough question. So I know what some people try to do is, after they have imposed those constraints, match the distribution of the features of the patients with patient distributions. But again, if you don't have large enough numbers for that, you're going to leave people out. So I think it's a tough question without a good answer. Alright, next up, UDE is right for the UV. Where do I change it? Just the next step. Okay, I'm part of this TUV versus UPIN group, and the first thing I want to say is that it's been a great pleasure to work with this bunch of clever and friendly youths that made the whole week really pleasant and enjoyable. And I think also it's been a real privilege to be here with all of you this week. To be here with all of you this week in this amazing environment, and I really want to thank the organizers for putting this together and for inviting all of us. It was a really nice meeting. So our work as modelers is to find terms in equations that allows us to understand interesting things about biology. And, you know, traditionally we just guess terms and try to fit them to data. And here I show one of these examples that is used as a toy example in these cases of hybrid models where you have some differential equations and neural nets, and you can guess different types of growth terms, different types of interactions, and then. And then you feed them to data, and you could also try to do some model selection and see what's better. But you might not have the right errors. So now we have a bunch of other methods that allows us to let the data speak from the beginning and try to estimate those terms. And we wanted to compare the different approaches here. Here we have Approaches here. Here we have tried to summarize our understanding of all these things. So on the top, we have the neural differential equations that are lighting outside. So that's the less constrained. So we put the right-hand side of the differential equation as a full neuron, and we try to estimate that. Then we have Then we have a bit more constraint where we have some partial knowledge, universal differential equations, and new hints. The difference between these two is mostly on the loss function that is used. So in one we use just a mean square error, so we want to approximate our data well. And here in the UPINs we use two terms, one for the data and one to satisfy the equation. And want to satisfy the equation to penalize solutions that do not satisfy the equation. And then the more constrained of these two is the case where you constrain the equation and you try to estimate parameters. So here we'll be discussing these three. We'll be working on these three. We have set up different tasks. We will work first on simultaneous integrity data. So in the first task is Is a completely unknown model structure. We will use neural differential equations and U pins for that. And then in the second task, we have some knowledge, correct knowledge, partial knowledge of the equation. It can be, for instance, these growth terms are known. And in the third task, we will do that, but we will put an incorrect term. It's not exactly the one we have used to simulate the data. Exactly, the one we have used to simulate the data. We'll be doing this with a model, a competition model, similar to the Locabolterra equations, but where we have actual data to play with. So we can also do it with real data. This data coming from a paper of Ludi and Gatengi and collaborators, where we have two different cell types, sensitive and resistant to radiotherapy. Radiotherapy, and in the paper they show that these data well described by logistic growth with competition. So, we'll like to use the model cultures of the two different cells to estimate the growth terms and have that as a part of the equation that we know and try to see if we can estimate the competition terms and test all these different methods and see what are the pros and cons of the different. The pros and cons of the different options. We also would like to maybe in the second step try to incorporate additional information. In this case, this comes from pre-treatment of these cells. So, these cells are being pre-treated with different doses of radiation treatment. So, one of the ideas is to try to incorporate that as a covariate. As a covariant of your neural net, so that you're not estimating the same neural net for all the conditions, for all the experiments, but you are sort of trying to guess also how the previous radiation is affecting the term, the interaction terms. Maybe also the growth terms as well. So that's something we. So that's something we've been discussing a little bit this week as well. It's an extension of things that people have not done before. And here are some of the measurable outcomes that we have been discussing. So we will write a phone pro blog post discussing our understanding of all these methods. And then we plan to write a paper as I have described before with the synthetic and simulated data. One of our challenges was agreeing on Agreeing on what software we want to use. So Julia versus Python. And in the end, we came to Julia. There are some of these notebooks that people have used before for some of the methods. And some of us have been writing code the rest that were only for Python to make it in Julia. But that's been a bit challenging. So in the week, we have made these codes for. week we have made these codes for neural Ds, UDs, and UPINs on simulated data. And our plan is to have a next meeting at the end of January, try to have the Mathon proposed by the end of February and let's say by late spring, try to have a sort of at least draft of the paper and see how it goes. Any questions? Do you have an answer to the previous talk about when to use which method? Not yet. That's exactly what we want to figure out. But what we have learned this week. So we have learned things like you know, um it's it's true that knowledge matters. So you have little data, the more knowledge you put, the better. Data, the more knowledge you put, the better. Noise, so things are sensitive to noise quite a bit. So you have noisy data, you might be in trouble with all of these methods, but still it's much better than using, for instance, plain Cindy on your data. So doing two steps is much better. So you might consider doing two steps or something. Thank you. All right, then AI and mechanism and all right. Hello everybody, I am Ari Burnett. I'm a second year PhD student at Mopit Cancer Center. This is our lovely group, Minus, our most senior research manager, and we are the generative AI group. We are the generative AI group. So, when we first started coming up with ideas for this group, we thought we were going to be super novel and do radiation therapy. And a lot of groups have done radiation therapy. So maybe not as novel to just do that, but hopefully we can convince you. So radiation oncology, for those that may not be aware, is essentially the application of radiation for the treatment of cancer processes. So when you apply radiation, you result in single-strand and double-strand. You result in single-strand and double-strand DNA breaks, and then the overall attempt to repair this damage is how we see the response in cancer. So radiation is usually given five days during the week in a lot of standard of care cases with weekends off. There's a lot that actually goes into the pipeline clinically for radiation patients. And mostly within this pipeline, there's three main ways that we Pipeline: There's three main ways that we can overall change and tune how we deliver radiation to the patient. So we can change the overall dose that's delivered to a patient or the fractionation in how that dose is delivered. And finally, ultimately, we can change within the planning process how the dose is distributed within the cancer and the surrounding tissues to potentially achieve a better outcome. And what we kind of tried to focus on throughout this week is how we can apply a lot of our How can we apply a lot of our individual research methods in tandem and sequentially to achieve maybe a good clinical decision support style of system? So within the process, obviously after the consultation and simulation of the initial imaging collection, there's contouring, planning, and delivery, where the tumor and organs at risk are actually segmented. The treatment is planned by dosimetrists and medical physicists to ensure the best optimal result can be. Optimal result can be received. And then finally, the actual delivery of the radiation. And we're going to focus on this latter half here. So, to kind of cover all different areas for this workshop itself, the first aspect that we could do is more of a mechanistic modeling style of approach. So, in my dissertation, I'm specifically going to be looking at probability convolution and how, by looking at the input distribution of a single parameter within your magnetistic. Of a single parameter within your mechanistic model, how we can actually then predict an outcome probability distribution. So, in a very quick summary, what we can actually do for it is given a mechanistic model solved in terms of the time to an actual event for a Kaupe and Meyer, we can then apply probability convolution to achieve what we believe is the outcome, the analytical solution of the outcome probability in terms of the Caplifier results. And what we've been able Meyer results. And what we've been able to show is analytically, you can do this quite well and match Kaflam-Meier results. So you have some idea of not only the average response for this parameter, but some influence of the variation of that parameter and how we see patient responses. And then from that, mechanistically, we can use that to try alternative treatments through a very standard approach utilizing commonly available functions. And there's just one way that we can do this. So now passing it on. So, now passing it on to another section. Hi, I'm Zifan. So, what is this slide about? So, in the context of this seminar this week, it highlights a tiny but important component providing inputs for mechanics model building. And in many different projects, we always believe 3D measurements are always more informative than 2D measurements, which are still being used in some applications to measure two measurements. Some applications to measure tumor size. Secondly, for those who haven't checked out our poster yet, please consider this as a 30-second advertisement you cannot skip. And I appreciate your time. So we have been working on different body visual segmentation of different tumor types. And as we know, many data sets have different images, which are very diverse from different pigments. So basically, we developed a general So basically, we developed a general pipeline for volume matrix segmentation, integrating the tumor cell type clustering based on radiomix. So here I just highlight two models, one for pediatric brain tumors, another one for adult glioma, but in a very limited resource country setting, so from sub-Saharan African populations. So these two models were both top performing models. Top-performing models in the well-established international REST segmentation benchmark. So feel free to scan the QR code, you will arrive at our web application. And if you click on the instruction link, you will find all the code papers. Thank you. And now to get to the list of our topic, generative AI. As you hopefully see in my poster, what we can actually do with this very cool We can actually do with these very cool novel generative models is to have an input image and try to change something in it, specifically the tumor size, so we can actually simulate how it grows spatially. And the way we do this at the moment is by having this input size and then a target tumor size that you want to see. So, what actually happens is that we peek a bit in the future and we see how big. In the future, and we see how big that tumor is, so we use kind of information from the future. And I think this is exactly where mechanistic modeling can come into play. So, if we go to the next slide, yeah, basically what we're trying to do is now to put together all of the pieces that we've kind of covered and how we can have mechanistic modeling help generative AI and how generative AI can help mechanistic modelling. So if we quickly go back to this example, instead of actually looking into the future and getting this tumor size, what we can do is actually fit a mechanistic model. We can have previous time points that we can get using very good segmentation models and use a mechanistic model to infer the next point. So, like that, combining this mechanistic model. Combining this mechanistic modeling part and the generating AI part, we can generate a tumor at the next time point. And actually, it would be maybe even cooler if we could include, for example, those distributions into all of this pipeline. And now R is going to discuss basically how we're going the other way. So, in the kind of realm of going the opposite way, a common problem that we see as mechanistic modelers is sometimes Modelers is sometimes we have data, but the data is very sparse in nature. So, one way that we may be able to go about this is using these diffusion-based models to then help interpolate in between treatment sessions or imaging sessions so that we have a little bit more information on the uncertainty in the gene size in that model. So, instead of these wider prediction codes, we have much smaller prediction codes, which would also then help us to kind of narrow. To help us to kind of narrow down the underlying distribution of potential parameters, so maybe we have something that's more clinically relevant in the end when looking at more historical data cohorts. And then so finally, our future timeline is, so after this, we're going to essentially formalize our proposed framework with a proof of concept, so utilizing both of our dissertation projects as well as segmentation in some type of overall decision support dashboard. Writing a prospective blog post. Writing a prospective blog post on the potential of generative AI methodologies and mechanistic learning, specifically in radiation oncology, and how that can be used, hopefully, to be done by the end of February. And then finally, working on another prospectus paper, one conversation we've had a lot during the week is really defining the role of a quantitative oncologist in a multidisciplinary team and how we can contribute not only as an additional scientist within the broader hospital, but have a seat. The broader hospital, but have a seat at these tables to have our voices heard as well to help overall patient care. And with that, thank you. Any questions? Thank you. All right. Alright, so that brings us to the end. We made it. We just want to say a big thank you to all of you for participating, for coming, for engaging yourself in all of these different discussions throughout the week. I know it might have been intense for some of us to be in hours and hours. One practical question, would it be possible to share a list of simple errors where people don't think and then just to repeat the large question? And then just to repeat Laura's content, let's thank the organizer about the Yes, I mean I hope I had a good time. I think we as the organizers had a good time. You were a great participating audience. I think this is also not easy to forecast how the dynamics of the groups are going to work together. I think we have some amazing outputs. I'm looking forward to these six papers. Papers that will be coming from this. Or at least the blog post. Or at least the blog post, yes. So we have a few impressions from what happened during the course of the week. I'm still amazed by this. This Morten was a shot, like a legitimate shot. He has discovered a new ability, I think. Sir, we were up 3-0. Yeah. But yeah, thanks. Thanks a lot to everyone. A little bit about what's next, I think, would be helpful if we have one key contact person for the groups. If you don't send us the contact for one person, we will just pick one or we will just randomly spam everyone. We will also try to have a follow-up call because we saw that a lot of your teams are going to continue along these lines. So we thought it might be nice to check in at some point to see where things have been. See where things have gone with your short version and where not everyone is going to be able to make it. But maybe some of you would be available. And then the blog post, just here as a formal thing or to give you a timeline, we discussed with the MapUncle blog team that we would submit them by mid-March. So here is also a link to how you can submit them. It's just a normal format, which is quite free to how you would like it in the worst. To how you would like it, and of course, you should all have the link and these slides so you can still see them, and there's also the special issue link here again. And then with that, one last final time for feedback, because we would also like to see what you took from this workshop and how things worked out for you. And I think you'll have to see. So, once you scan it, maybe we swap that note now. There are so many MAPs here. You can only choose one optional, right? Oh really? Do you like it? Yes. Oh well then that was a fail. Well just pick your most important one then. And I will show the results maybe only a second. Everyone got it? That's new collaborations, which was Start new collaborations, which was what we were hoping for. Now we want to bring you together. Well done. And then the last one: this is just feedback, pros and cons. So we would appreciate your feedback if you have any suggestions if you were to do this again. Maybe not the three of us, but maybe someone else was inspired, like we were in the last workshop, to move on with this. And apart from that, thank you all for coming. Have a safe trip back. And yeah, we look forward to meeting very soon. Yeah, we look forward to meeting most of you again in a variety of combinations. Thanks, Jean. Too often. We'll just leave this up for discussion for development, which makes a lot. This one I didn't know like if that was if I was