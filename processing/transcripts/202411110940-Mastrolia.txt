You trade your book and you remember the condition X capital T is equal to zero, so I assume that you fail and there is a remaining. And basically what happened is that at the end of the day, exchange opens an auction where people can trade and can liquidate their volume, but in a different kind of mechanism, which is not a limit order, which is an auction. It's something which is more and more developed. There is a recent exchange at San Francisco, the LTSM, who is working on this kind of stuff. So we try to understand. So, we try to understand the limit of this mechanism and what we can do with that, how we can calibrate the fees and the different overparameters. This is a joint work with my first PhD student at Berkeley, Sotien Ricu, who will graduate very soon. We did the first paper more in the discrete setting. I will spend a lot of time on this paper. The version is an archive. The second version is based. Is an archive, the second version is better because we try to make everything more endogenous, less exogenous. And one is in preparation. Basically, we just have to do the numeric because you will see that we have to deal with, as soon as you increase the number of players, the number of difference in homogeneity between all of them, you have more variables. So, stochastic control, you have a PDE with large dimension. And since you have jump, this is an integral partial PDE, so this is even. Integral partial PDE, so this is even worse in terms of access the control in the suprema. So that's still in progress. I will start with a quick overview of what is an auction market. I'm not sure that you are familiar with that. So usually I spend time to explain everything. After we see some property of this market, so what is the clearing rule and the clearing price? And we see a kind of manipulation of this market and some remedies for that with fees. For that with fees, and finally, we'll finish with the calibration of this fees. So, batch trading, this auction market is in the category of batch trading. Unlike the limit order book, the main difference is orders are not executed right now. They are delayed, the execution is delayed until the end of the auction that we call the clearing time. When the auction opens, you have offers accumulating all the time, so this offers that can be. Time. So, this offers that can be similar to limit order, where people propose a price at which they are willing to buy or sell with a volume, and aggressive order, which are more just a volume to buy or to sell during a period, a duration that we call the auction duration. And at the end of this duration, the exchange closes the auction and fix a price to buy or to sell the asset for the different participants, optimally in the sense that the exchange wants to maximize the number of trades. Number of trade. So before going further, I just want to explain the clearing rule is pretty. I mean, now people understand how it works. You understand that the number of buyers, this is a decreasing function of the price, and the number of sellers is an increasing function. So if everything is linear somehow, if you want to match each order, this is a min-max between the supply and demand curve. So you are basically finding a price which makes the number of people who want to buy a The number of people who want to buy and the number of people who want to sell equal themselves. So, you want to do this number of buyers, this number of sellers, the mean between the two curves are the number of orders you can match, and the mean max, this is exactly the equilibrium point. So, that's how people fix the clearing price. So, it has been understood a long time ago, 20, 30 years ago. The clearing time, this is more something that people see. mean something that people set as random. Usually what the exchange do is to randomize this clearing time. So we try to understand this randomization. I know it solves some issue with auction market. Some examples, I do not say everything, this is the most accurate note. I want to speak more about the LTSC, I'm in contact with them. So they offer an auction-based market structure for matching orders and this is something that they want to develop more and more. Develop more and more, especially in terms of fragmentation of market, just to be more competitive, to propose new market design. It's interesting. So, this is a little bit more than that. So, why people are studying auction markets, there is a very famous Buddhist Canton Manschiman. I stopped to go too in deep in that because I have seen that it generates a lot of debates in the community. So, basically, they explained in their paper that the limit order book has mechanical arbitrage and an auction as soon as you open an auction and the duration is. You open an auction and the duration is more than 100 milliseconds, the arbitrage disappears. They show that, I mean, empirically, they show that there is a breakdown in the autocorrelation between two exchanges, or just paying the spread is an inherent cost of the limit order group that the auction, I mean, delayed, basically. It's not exhausted, as you see, it has been studied a lot. So, the price formation mechanism, what we call the clearing. What we call the clearing price. It has been studied by Gerd and Sieber and Frik and Gehrig. More recently, I did a first paper on the efficiency of an auction with respect to its duration with Projusa and Mathieu Rosenborg, and we have studied what was the optimal duration of an auction. We based our study on data from Euronext, the French market. So today we'll more have a look to the last two, which is a kind of the last this. A kind of the last this one and this one, sorry. When you have strategic trading in an auction, so there is a recent paper of Geduk and Nadochi about the topic. So this is quite similar, excepting that here we try to go in depth in terms of calibration of the fees, calibration of the rebates for this kind of market. And um a very recent paper I did with uh Geoffrey, Mathieu and uh Dimitrios Cavatas, who is working in the company in Hong Kong. Who is working in a company in Hong Kong is about the role of the transaction fees in an auction. So, what we prove in this previous paper is that basically when you have a perfect symmetry between the players, there is no transaction. Because they will have a tendency to propose a price which is very high if they want to sell or very low if they want to buy. So, adding transaction fees optimally calibrated for them to reduce this price of all. So, this is what we explain in this previous paper. Let me Let me just focus on the main mechanism we'll study today. So, first, we'll study how we can randomize the clearing of an auction. So, that is, instead of saying that the auction stop at 10, it stops at 10 with probability p. So, you just randomize it. This is a Bernoulli distribution. You can do something more sophisticated. But as a first step with Generali, we did this very simple example to understand what is the behavior of the trade. Understand what is the behavior of the traders in this case. After we see the calibration of the fees and recently, so this is a work in progress, we are studying the rebates. So, rebates, this is a redistribution of the transaction fees among the market participants. So, this is like a market make-take fees problem. So, you give compensation to market maker to just enhance the quality of your market by being sure that the order flow increases. The order flow increase. So we study that. Just to start, so we consider an option with a duration of T. T will be later. I mean, I alternate between different notations since in two paper and so in that there is a lot of typo. So sometimes I will write capital T and sometimes tau clear. Tau clearly. That's the same. Okay. We address the optimal arrival in an auction of a strategic trader facing with non-strategic traders. Again, this is. Strategic traders. Again, this is the first step. We are assuming that you have a crowd of people sending orders in the auction. Not strategic, but you have one which is more strategic in terms of arrival in this auction. And how you monitor that, what is the behavior of this trader. And at the end of the talk, we will see an ash equilibrium between everyone in a continuous setting. What we want to investigate in the market efficiency. So the market efficiency is basically the difference. Basically, the difference between the time, the clearing price of the auction, this is the price that the exchange will fix at the end of the period, at the auction duration, with an efficient price, the equivalent of the mid-price of the limit order book. It's a kind of spread or a kind of market impact where you want to just be sure that the price of your auction is not degenerated in terms of the true price of the asset, the fundamental price of the asset. Price of the asset with some metric F. Again, same thing, I'm very sorry for that. I realized it a few days ago. We call it market quality and we want to minimize the market quality. So it's very unfortunate, but it's an indicator for the market quality, and we want this to be as small as possible. So that's the goal of the auction, because there is also some relation which says that if the spread is reduced, the order flow mechanically increases. So that's the motivation uh behind that. So that's the motivation behind that. In terms of models, the efficient price, again, this is the discrete model in the first step. This is a normal distribution center at mu star with some volatility sigma star. And during this auction, we assume that you have a strategic trader. So this is a kind of block trade, arriving in the auction with a volume given by a supply function, which is this one. So this is the linear supply function. The linear supply and demand function, as in the paper of Gehrig, Fricer, or Gaber, and Silver. What does it mean? It means that if the price PI that is proposed by the trader is smaller than the claiming price, they are willing to sell the asset and so to send the volume which is positive. And conversely, if it's smaller, that will be negative. So each trader in the auction sends a limit price. Send a limit price PI at which they are willing to buy or to sell the asset. This family PI will assume that they are independent, normally distributed, and they have full information on the efficient price. So they know mu, they know sigma star. Again, this is a first step in this uh direction. This order arrived in the Poisson process with intensity lambda t. We'll see after when we add the fees that this intensity is modified. This intensity is modified, that will be decreasing with respect to the fees. And in front of them, in front of this crowd, you have a strategic seller, so someone who wants to sell. The seller sends this quantity, but only at the condition that the clearing price will be higher than the price they are proposing. Otherwise, they cancel their order. They say the price is too low for this auction, I don't want to sell. Auction, I don't want to sell. You have some lost. So, this is also a first step in the direction of cancelling order in an auction, which is still an open program so far. And we assume that they propose a limit price, which is a normal distribution of parameter mu and sigma star. So, same sigma, but mu is controlled. They control the mu, which is the kind of the spread with respect to the mu star. The seller uses the information available at time t to determine μ t. To determine mu t, so what is the drift for the price, and this mu t can be viewed as a function, a feedback function of the time, the order flow, and the price proposed by the order trader along the time. In terms of the clearing price, so the clearing price set by the actions that I tell you, you have to do buyer equals seller. So, this is an algebraic equation, and when you solve it, you solve an inequality between the number of buyers and the number of sellers. Between the number of buyers and the number of sellers, this is just the sum of K, P clearing minus P is equal to zero, and you find this condition for P, but up to the condition that you are willing to be more competitive and to sell comparing to the other agents. So that's the clearing rule, which is the same as the previous paper I did with Matthew Zenbon and Porjusna or in Gehrig and Frica. And given this clearing rule, we try to understand the behavior. We try to understand the behavior of the market maker in terms of new, but also the arrival of the strategic trader in the ocean. At what time the strategic trader should arrive. So, the problem of the strategic trader is to solve this optimization. You want to optimize on mu, given tau, your arrival time, the clearing price minus the price you propose times the volume. So, what you want is to be sure that the clearing price is always. That the clearing price is always bigger than the price you propose, so that you can sell at a better price, and the volume is proportional with respect to your clearing price, and you want to be above the official price. In this case, when you solve that, so you get an optimal function mu, which depends on tau, and you get a price, which is a normal distribution, center at this mu tau. And what we want to do is to find the optimal tau, the optimal arrival time in the auction. House the optimal arrival time in the auction. So, again, this is a very simple model. This is a level zero of optimal stopping. Here, you have the choice to worry about 0, 1, 2, 3, 4, 5 until 10. So, we discretize everything. If we do that, what we have observed, and it's very easy, I mean this is just a very simple computation of conditional expectation. You always have an interest to arrive as late as possible. This is a tautology, you have more information. The tautology, you have more information, so with more information, your optimizer will be better. And we can prove that and we see the impact on the market quality. So now, if we focus on the exchange, the exchange, we take two metrics for the market quality, either the pure distance between the claim price and the optimal price, or P star, the efficient price, or we take an exchange which is exponential risk averse with all, just to see if a kind of robustness with respect to the criterion, with respect to the efficient price. Respect to the criterion, with respect to the function F. When we do that, we have some data. So, the data we take it from Lobster or Young Finance, I don't remember. It's not me, it's Canadian. We did that. So, you see that when the strategy seller arrives more at the end, the market quality is bigger, which is bad. The delta, which is the equivalent of the spread, is bigger. So, basically, the later this. So basically, the later the seller arrives in the auction with an asymmetry of information. Here we assume that your trader underestimates the price of the asset, it creates a disbalance in terms of the auction. So that's the issue. The issue is that here you have a kind of market manipulation, we did not say it like that, but the exchange would prefer the strategic seller to arrive as soon as possible. Seller to arrive as soon as possible, not too late. So, what we propose for that first is to randomize, yes, can I ask some does this mean that the optimal behavior for the statistic server is to arrive late? Late, yes, just before the closing, which is obvious, right? But we quantify it and we just have a model which reflects that. Yes, is your result still robust on the fact that the volume is not an? On the fact that the volume is not a linear function but has some convexity? Okay, so this I don't know because we take something which is classical in auction market is to consider linearity. If it's convexed, that will be more difficult because I think that in this case the clearing price, I mean this is not clear what is the we I don't think if you take a function which is convex you can still have an explicit function for the clearing price. That's an equation that you have to solve. But yeah, it's not a problem. And it's more complex for the dynamic optimization. But my feeling is that the volume will not be linear, right? Yes, yes. I agree with that, yeah. As I say, unfortunately, again, this is a first step in this direction, and I hope again. Yeah, this is, I mean, I want to understand even in a simple direction before taking uh everything. So same thing, randomization, we decide that you randomize with a Radmar distribution uh Distribution, either you close the auction at time 9 or you close at time t with parameter p and the exchange maximizes p. So when we do that, we see that, and in fact this is interesting, this is how we see that, just to, I know that there is some talk about the what make a game exciting, this is randomizing the time at which you stop the game. Because here you see that a small randomization, so when you decide to close the auction with a property zero, To close the auction with appropriate 0.08 URIA border to minimize the market quality. So, this is for this parameter. It's not for zero. It's not to say that I will close the auction at 9. I will give an uncertainty to close the auction either at 10 or 9 with parameter 0.08, which minimize the spread, the market quality. So, the clearing which is applied by the exchange, the exchange randomize the clearing of... Exchange. The exchange randomizes the clearing of an auction. So the clearing is efficient in terms of reducing the spread between the clearing price and the efficient price. So that's the first remark that we have. The second remark is about the fees. So in the first paper, in the first version of the paper, I mean, we have been destroyed by the referring by that literary. So we forgot to consider that everybody was paying a fees. So we have a Dimitri in the second version. It was not too hard to modify, but whatever. Too hard to modify, but whatever, it's all the referry process works, right? So, the exchange designed a transaction fees for all the traders in the auction given by CITE. And we assume now that traders arrive in the auction with an exponential function decreasing with respect to these fees. And we will index this fees, so what we propose is to index these fees on the time at which people arrive in the auction. So, the later you arrive in the auction, the bigger will be the fees. Bigger will be the fees. In this case, the strategic trader wants to maximize exactly the same thing, excepting that you want also to minimize the fees that you are paying. So it gives you an incentive to arrive earlier in the auction, not too late. If we do that, so when we submit, we get a mu hat, we get a tau hat. The problem of the exchange is to minimise either the spread minus the average fees, because we are looking for one asset. We are looking for one asset, so we just renormalized by the number of people in the auction, either for the quadratic matrix or for the exponential matrix, for everyone. So, again, we solve it numerically, but you see that if I stop here, the problem is pretty degenerative because then we say, okay, if you want to minimize that, you take psi is equal to plus infinity. You pay your fees, which is plus infinity. You do that, nobody will go in your auction. Every people will leave your market and go somewhere. Every people will leave your market and go somewhere else. So, you need a constraint on that. So, the constraint first is that you have to be sure that the site you propose allows your market participant to find an optimizer. This is what we call the incentive compatibility condition in contract field. You want to be sure that there exists an optimizer for people who are working for you. The second is the reservation utility. You say to the market participant, okay. Okay, if you trust me, the fees that we propose you will be enough competitive such that if you go on the limit order book and you want to trade on the limit order book, you will not have a higher interest. Your value function will be always bigger than what you will get. Trade the same volume on the limit order book with a tick size of gamma. So, gamma is basically if you trade at the best bid for the same. The best bid for the seller, you will win this quantity. So we make the auction competitive with what we call a reservation utility. So if we do that, we choose, unfortunately, this is a principal agent problem, it's a contract theory problem. In the discrete case, we have to choose a class of functions. We have not been very far. We have choose either a quadratic function in time or a linear function in time. Quadratic is better. Above quadratic, this is impossible. Above quadratic, this is impossible to ensure this condition, so we cannot. So, quadratic is a kind of limit case. And if we calibrate the L parameter, so the optimal fees, we see that we have an optimizer, which is 0.0120, 0.24, whatever. Again, if A is equal to 0, this is bad for the exchange. There is no fees, and the goal of the fees is to give incentive to increase the market quality by reducing the spread. And if A is too big, this is bad, because A is too big. This is bad because A to B, less people in your auction. So we really have a convex function in terms of the shape of the inception. Okay, we'll have to finish soon, so that's perfect. I have a few time for the work in progress. So now the next part is to make it even more endogenous by just redistributing these fees among the market makers, among you remember, the non-strategic people. Now I will make them strategic. So what we do is that we take the fees of naive traders. Naive traders saying, I want to go in this auction and to buy or sell, whatever is the price, I want to be buyer or seller, and they pay a transaction fees. And this fees, you just redistribute it among all the players. So that's what we call a rebase for an auction. In this case, we consider two strategic traders. So they are not necessarily buyer or seller because they send limit orders, they want to maximize their PNL in an auction. Ended in an auction. Each of them proposed a price which differs from the efficient price with a spread, mu T, so they are controlling mu T. They control the arrival intensity, lambda P and lambda Q of order MP and NQ in the auction. And we consider market taker investors, they just want to buy or sell their volume of assets in the auction, their intensity of arrival. Their intensity of arrival is decreasing with respect to the spread set by the market maker. So, if they see that they have opponent proposing a price which is very high, you expect to have less buyer in this case. Conversely, for the seller. And which is also decreasing with respect to these transaction fees. It was my excitement before. Change of rotation. And we also assume that they send a volume which can be cancelled at any time in the auction with a parameter theta and with a control variable Ai. With a control variable AI. So, whenever they want to cancel it, and we expect that this cancellation is less likely to happen when you approach the maturity. So, if they arrive close to the maturity, they are less likely to cancel their order because they have more information. In this case, the claim price is a little bit different, so we still have linear supply demand, but everything is different from the different participants. So, we get this formula for the claim price. I should write P clearly, but it was. I should write p clearly, but it was not enough on the line, and I'm still at slash tiny in terms of p tiny. In this case, if we focus on the problem of the market maker, so they want to optimize given the rebate and the fees proposed by the exchange, their P ⁇ L. So their P ⁇ L is given by this function here. I may not detail it, but it's a function with the clearing price and also NPMQ, plus the rebate I got. Repay they got, and minus a kind of Algonquis criterion when they want to liquidate in the auction, given a benchmark Londas Europe. So the epirulic cosinus signers that you have seen, for example, in the talk of Ulrich just before. So both traders do that simultaneously. This is a Lash equilibrium. This Lash equilibrium we can prove as usual that this is connected to a class of multi-dimensional BSD. So the value function of both participants. The value function of both participants can be decomposed by this. So basically, what does it tell you? It tells you that you give incentive to participants with respect to all the state variables. So with respect to the arrival of the investor, with respect to the arrival of the market maker, the efficient price, and so on and so on. And now the problem of the exchange is to maximize on the rebate and the fees, to minimize on the rebates and the fees the spread. The rebate and the fees, the spread between the clearing and the efficient price, plus the rebate. You want to minimize the compensation you give to participants, and you want to maximize the transaction fees up to the consolidation of the order. And this is a work in progress because, of course, this is now you have understood that all these horrible things here are state variables. So we have an LGB equation in dimension 6 or 7. Six or seven, integral partial because you have jump, so no access to the jump. So, for that, we are developing. Again, we are developing. Tienry is developing a deep gallery method to solve this high-dimensional PD. So, hopefully, we'll have some results before the end of the year. And we'll have all the incentives. So, we are developing the numerics right now. And thank you. Yes? So we should have. So we should everybody just want to make sure that are you working on the general link process or is it only the Poisson jumps? Only Poisson jumps, yeah. Inhomogeneous but Poisson jumps. So then you really don't have the integral term but instead of some summation. Yeah it's I mean it's a false integral partial. This is just x plus the size of the jump minus you have x. So you have summation and then but you can still not have access to it. When you write the P D. Not have access to it. When we write the PDE, this is no close formula for that. There has been some works in that area, then in terms of jobs. Yeah, yeah, there is some area. People have studied DBLTNATO for this kind of PD, so we are just right to meet. One of the questions, you characterize this nature equilibria by two-dimensional BCU structure. I lied. I have to say that I lied. No, I will tell you. Indeed, the fact is that the existence of the NASH should be equivalent to the existence of a 2BSD, but because of the principal agent problem, the exchange in fact forced the existence of this 2BSD by proposing a contract which ensures the existence recontrols. So we are relying on the existence of an ash equivalent to. The existence of an hash equivalent to the existence of a multidimensional BSD, but this multidimensional BSD, if we write it forward, the existence of a Nash is equivalent to the existence of a system of coupled SD, which is easier. But this is really because we are controlling the terminal condition. So we propose a terminal condition which ensures the existence of an ash equilibrium and so the existence of a two BSD of a multidimensional BSD. So you don't use the BSD. So, you don't use the BSD tool? No, we don't use the BSD tool at all. Yes, exactly. No, this is a very good point. And in fact, this is also the point right now, this is also the difficulty in principle in general, that if we are not able to solve the PD at the end, we usually try to have theoretical result, but we want to be sure that the contract we propose is admissible in the sense that the S D or the t B S D admit a solution for this contract, and this part is difficult. And this part is difficult right now. There are no other questions. We should thank the Teboi for this nice talk. Thank you. 