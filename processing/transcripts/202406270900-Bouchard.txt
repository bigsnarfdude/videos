To the organizers, things together. It's a lot. So, this is John Kork with Ce Rutan and Jinjing Mo is doing his PhD with Zeew Lu at Chinese University of Hong Kong. And, oops. So, the motivation here is basically what is written here: try to replace C12 regularity by C01 regularity when you want to apply. When you want to apply your tools, Nima. So imagine you have, I don't know, for instance, you want to price an option, you look at the edging price. Okay, you are in a complete market. In that case, what you teach in master programs is Utos formula and C12 for C12 functionals. But at the end, you know that you will have a market value. Okay, so the malted variation part is just zero, and you are absolutely not interested in, let's say, composition. I mean, what is the time derivative? What is the maladiability? Maybe you are for. Maybe you are for risk purposes, but in terms of hedging, what you care about is the decomposition of the material part, okay, which is the only part she that is remaining. Okay, so in that case, the mantra regularity is actually at first useless. What you would like is just to have a derivative, the delta of the option, but it's very different. It's the same when you look at many optimal control problems. And I will show you one example here: a verification argument. Typically, if you just control the drift, Uh, typically, if you just control the drift of the diffusion, what you care about is actually the first-order derivative. Okay, you, if you don't control the volatility, you don't care about the semantic order derivative. And if you write down the decomposition, the optional decomposition of the value function along the path, you know that you would have, say, a supermarticle or sub-martigan, depending whether you're maximizing or minimizing. And knowing that the bounded variation part is monotone is, in general, just enough to construct a verification argument. Okay, you don't care about what. Arguments. You don't care about what it is. I mean, you just need to know that this is increasing on the liquidity. And on top of this, if you look at the path along the optimal strategy, you know that you have a mapping. Okay, so this boundary variation part is just zero. You don't care about. Okay, so again, trying to convince you that in many situations, I don't care about someone derivative or time derivative. Okay, I really don't care about that. I just need to know what the bridge is. And this gives me the marking value. That is, and this gives me the mathematical decomposition. Okay, this is the idea. And actually, all this works, this series of work we did with CRU came from studying a dual formulation for a perfect aging problem in a model with market impacts, where we wanted to prove a dual formulation. And it appeared that doing a little bit of CALTUS evaluation on the dual problem, we saw that we could actually construct the aging strategy. But the thing is that this rule formulation was an optimal control problem. Formulation was an optimal control problem, and it was hopeless to show that it was C2. Okay, so we started to delve on these things because we knew that we couldn't prove C2 regularity. So we proved C1 and it was actually a path-dependent functional. It was a non-marketing setting and this was enough to prove the Glauge formulation, which by the way gave some results, new results on second-order backport SDs. You know the story about second-order backport SDs. There is a third version and the second version. Is a first version and a second version, the first version. So, and in this case where you have pass-dependent functionals, you know actually that proving C12 regularity will be very difficult, okay? Because we named the Markovian setting, you know that if you have uniform electricity, then you have the smoothing effect and candidate solution for PDE will be smooth, even if the coefficients are just all the continuous. You don't need more. Okay, if you have degenerate components like for a region options, for instance, you are not. instance uh you are not completely smooth okay you know that the time derivative or the derivative with respect to the mean part will not be defined this is possible okay unless the coefficients are very smooth but you don't care about them because actually if you apply toes member you should apply a total in a good direction and in that good direction you are smooth okay and typically actually for those who know these things if you look at the pd for agent options and you reframe them in terms of dupe derivatives then the dupier derivatives are well Then the Dupier derivatives are well defined. Okay? The Markovian derivative are not defined, but the Dupier derivative is what it is. Okay? But apart from this kind of situation, for pass-dependent functionals, there is no result about regularization by the noise. And most probably it's not true in general, okay, because it's kind of very rigid aesthetic. So we worked on this. I will comment on it in a minute. And today I'm more interested. Uh and today I'm more interested in uh Machinblas of optimal control problems and again if you have MacInblas of type LBs you know that uh showing regularity might be might be quite difficult unless you put a lot of regularity on the coefficients. Okay, so this is the motivation to actually try to remove this amount of regularity into zero and regularity in this in these situations. And I already mentioned the classical Markogan framework. We know that this is possible in that case. And let me immediately return actually to this situation. So I start with the Markov density because I need to introduce some notations and then I will pass to flow of conditional distribution. So in the Markov density setting, there is a lot of work around Russo with different quarters. And the C01 ito's formula is in the paper by Guizi and Russo, for instance. And what the Rousseau and his co-tours developed. The Rousseau and his co-authors developed this concept of stochastic calculus by regularization, okay, using a notion of weak directly processes. And I will show you how it works. You will see this is a very powerful tool to actually obtain optimal decompositions with the material part that is explicit. Okay, so let me introduce some definitions first for if you don't know these things. If I take two CARD-like processes, I'm not asking them to be similar. Processes: I'm not asking them to be semi-martial. Okay, I take two catalog processes, then what they do is that they define the brackets of x with y this way. So, you look at you integrate increments of x against increments of y on a small time interval of size epsilon. You restate by one over epsilon and you let epsilon go to zero. This is what they call the bracket. And it's very easy just by using integration by part to show that if x and y are solid matrix, then this is the usual bracket. Then this is the usual bracket. Okay? But it might be defined also you are not x and y are not similar. The integral is up to t or to epsilon. No, no, it's up to t. So this is a bracket at time t and you integrate up to time t. Okay. And if this guy is converted through cp, we call this a bracket. So x has finite quality valuation if it's quadratic violation. So co-quadratic with himself is finite. Polarity with himself is finite, this is as usual. And another very important concept is the concept of auto-bannon process, or it's also called weak energy process. This is those processes such that if you take its characteric variation with local continuous martial n, then the bracket is okay. So n can be bounded. Okay, you can guess against actually the bounded martigles, it could be the same deep ones localization. Localization. Okay, and finally, what is a weekly reclaim process? Weekly reclaim process. This is an extension of summary martingals, actually. So you start with an initial point, then you have a local martingale path. This is a local, usual, as usual, local martegga path, and then you have an orthogonal process. Okay, so it's a generalization of the market. You have to be very careful. I think I will mention it again later. If X discontinues, there's the This continuous, this decomposition is unique, and if this is a special Dirichlet process in the sense that A is also predictable, not only autograph, but also predictable, then the decomposition is unique. The way the decomposition is not unique, then you have to be very careful if you have jump synics, because look at the definition of orthogonal process, you have to be orthogonal to continuous particles. Okay, so if you take A to be a pure jump particle, for instance, it will do the job. Okay, a pure jump particle is an orthogonal process. Is an auto-blank post. Okay, so you see, you cannot have uniqueness because if you have germs, the current mathematical pen linear or pen linear. Okay, and if it's here, it's not good for you, okay, because you don't have a good mathematical decomposition. Okay, so here I will only use continuous processes, but if you don't have continuous processes, when you write down such a decomposition using this version of Pippo's lemma, you have to be clear about the To be clear about this guy is predictable, okay? Because if this guy is not predictable, again, you can have a pure discontinuous particle part in it, and this is not a good decomposition you're looking at. So the theorem is this. So it's not very, I mean, if you don't know, you don't know, but so if I take a functional that is C01 and I take with the retro process X with the composition n plus A, then I n plus a then i have the uh traditional uh part in uh it was mr so the multiple part which depends only on the block okay and then here what the role of the bounded variation process uh is just process gamma which is not a bounded variation process in general but here everything is continuous so this is a continuous orthogonal process okay so it's a immediate extension of of formula um Papito's formula. As I said, you can add this also when you have a Georgian Market part for processes with gems. In that case, you have to work actually a bit hard to obtain that. So you have a Marketing part that is showing up on top of this for the germs, and you have to work hard to show that the gamma you obtain is actually predictable. Okay, but this is what's been that before. And again, And again, if V is Martin R, then you know that gamma is zero. So this is a traditional Vitos formula. And otherwise, in control problem, you know that gamma exists or non-increasing or non-increasing. And very often it's just a mass for what you want. And yeah, I already mentioned it. So you have a version of this for path-dependent functionals. And in that case, the formula is. And in that case, the formula is the same. The difference being that here, if d depends on x at 2 t, or on the path of x at 2 t, then here you have to take the vertical dps derivative. That's all. Okay, that's also where the formula is exactly the same. For path-dependent function also, there is another condition only that I don't write here. But in all applications we add, we could check it, but that's a little bit more difficult. Thank you, Mighty. Little bit more appropriate from that point of view. Okay, so let me now continue as a case of functionals that flows of semi-martial distributions. So then I have a lot of notations to introduce. I'm sorry. Okay, so yeah, so I will so for the process X. So, for the process xx here will be a will be a cinematical, okay? We don't know how to probability this is just a really rigorous process. So, this x guy will be a cinematical. So, you have a, which has bounded variation, a martial part, and the material part is decomposed in two terms, one material m and another one that is just a stochastic integral with respect to another material m zero. So, the reason why we write it like this is that we are thinking about Are thinking about midfield control with common noise. Okay, so M0 will stand for the common noise, okay, and M will be the geosyncretic noise, okay? And the reason why we write this part this way is that, well, sigma zero can be in a bigger fluctuation. So the G0 will be zero as well. Okay, so this will be the fluctuation generated by the common noise. Equation generated by the common noise, okay, and I will use always this notation. So, e0 is the expectation conditionally to the passive colonized, okay. Uh, the reason why I introduce this is that I will actually look at the distribution of this guy conditionally to the colonoise, okay? Um, then I can afford for having a multi-normal situation with a continuous quickly replay process. So, this time you are the martingalp, and this guy here is just an automatic process. Is just an automobile process. So, as I said, Sigma 0. So, this is the reason why we write the common noise particle part this way. Sigma 0 can be in the big filter. Okay, it's not in the filtration of M0. So, this is what is written here. Here, we need a little bit of integrability condition, or at least locally, and And yeah, and the idiosyncratic noise is orthogonal to the common noise. This is what is written here. Okay, and then we have this H hypothesis, which says that taking conditional expectation with respect to the path of the common noise up to T is the same as knowing all the paths. Okay, this is very important to work for. And finally, I define the conditional distribution. So mt is the law of x t given the path of the common lens. Okay, so very. Okay, so very traditional sense. Okay, so this I think you everybody knows. Okay, so linear derivative as usual. P2 is the set of probability measures with the two passage instance. Linear derivative, linear derivative as usual. Okay, these are standard notations. And so the result is this. Result is this. Let me put it up. So, okay. So, I take a functional that is C0 with respect to time, C1 in space. This is for the Y component, and C1 in terms of the measure. Okay, I need a little bit of integrability condition on the Yolt derivative. Okay, here these are the little interpolation that you use in the proof. That you use in the proof. And so the theorem is this: this is what you expect knowing the results for the Macron setting: that if you take a transformation of Y and so Y is the Dirichlet process, and that is a conditional law, what you get is the Mapping Gala part coming from the increments of Y. And then you have the usual mapping parts coming from the move of the conditional. Okay. Okay. And all the other terms, singular terms, and time derivative are hidden in that guy, gamma t, which is just an atomic post. Okay, so here in that case, it's continuous. I don't have problems with terms. And I guess you can probably have similar results if you have to add gems into the picture. So let me show you how it works so that you know what are the arguments using this. What are the arguments using this stochastic calculus via regularization? You will see it's very powerful. I mean, you can adapt it to many, many situations. The relation between X and Y, they are arbitrary. It's arbitrary. Yeah. M is X. M is a law of X. You can actually take Y equals X if you want. Okay, there is no relation. Okay. Okay. Okay. So if you want Y to be X, So, if you want y to be x, there's no problem. Yeah, comments: sigma zero is in the big reflection because it's an application. You want sigma zero to be a functional of x, y, blah, blah, blah. Okay. So, yeah, I look at it as a process, but it can put a control or whatever we have done. Okay, so I think the setting is pretty general. I mean, the main improvement would be to consider that X is just a weak debt reproduction. To consider that X is just a weak depth process, okay? But we could not regard this case for the moment. Okay, so let me show you how it works because again, the arguments are not difficult. So it goes back from the work of Russo and his workers. And this is something you can really adapt to many, many situations once you have understood how it works. So, okay, so I have to show that, say, F. Show that, say, say, F of M0 is equal to 0. Anyway, I don't care about the initial point, I can always put it in the orthogonal part if I want. So, what I want to show is that F of M T is equal to that guy. Oh, sorry, for the poll, I consider F depending only on M. Okay. Just for simplification. Okay, so I want to show that F of M T is equal to this marking of parts plus the guide that is an automatal process. This is what I want to show. Okay. Is what I want to show. Okay, so showing this is by definition, I take any continuous marginal n, you can take it bounded if you want, okay, and I have to show that the brackets between gamma and n is zero. Okay, this is the definition of an orthogonal positive to the common common artist, right? No, no, no, any, no, no, any, and any, it's in the And any uh, it's in the big filtration, yeah, yeah. Orthogonal, it means in, I mean, I don't refer to the so the first thing you can observe is that if you take the increment of gamma, so the increment of gamma, this is an increment of M, of F, sorry, minus the increment of this marketplace. Okay, so actually, I have to look at the increment of F and I have to show that this. And I have to show that this limit here, when I look at the increment of F, is the same as the limit up to the sign when I look at the increment of this guy, okay? So that the difference will be zero at the limit. And for these guys, this is pretty easy because this is already marked up. Okay, so if you look at the increment of this mark angle test against the local mark angle, what you will have is just a bracket of the two, okay, because we are still marked. So again, this guy is this one minus this one. This one minus this one, okay. Sorry, minus this one, and uh the limit, the bracket of this mark angle part with the local mark angle is just the bracket, yeah, a bracket of the okay. So, what I have to show is that this term here compare just UCP to this data. This is all I okay, so uh Okay, so now two small technicalities. You are almost done because what you do is that so you have to look at this guy and find the limit of this term when epsilon goes to zero. And then you do as usual, first to introduce the linear derivative. So you rewrite the increments as the integral of the linear derivatives at the middle point, I mean at intermediate points, times the increment of the measure. Measure okay, so you will say this, I think you know, but because you integrate with respect to these measures here, this is the same as evaluating this quantity at x at time s plus epsilon, minus evaluating the same quantity at point x s. Okay, conditional things. Here you have m is a conditional law, okay? So, this is the conditional expectation, and now you do as usual, you linearize with spectral. You do as usual, you linearize with respect to X. Okay, so you have the neurons derivative training and you're done. You have to look at the limit of this line up. Now, by continuity, I mean this intermediate points, m lambda epsilon and x eta epsilon, they're very close to ms and xs. Okay, so I can forget about this detail. Okay, it's the same as looking at Looking at so I remove the lambda and epsilon, okay, and I just have to look at the limit of the cell. Okay, and now it's very easy because here you have a semi-martigan. So if I look at this term, I decompose it into, so I have three terms actually, the bounded variation parts, the geosyncretic material parts, and the common node stars. So this one here, I have a mounted variation product. So this one here I have a multi-variation process. Okay, so the bracket with the continuous local mark angle will be zero. So this guy will vanish. Here I have an increment of the geosyncretic parts high condition with the common noise, but they are orthogonal. So this term is actually just zero. Okay, and for the last one, again, for the last one, this one, this is the same as this one, because I'm conditioning with respect to. And then we respect to v0, so I take it to stochastic integral outside. Sigma 0 has to stay inside because it's not adapted to the smoke equation. And now this is just the quality violation of these two guys, which is exactly what's okay. So you see the proof is pretty straight. Okay. And if you have a y in the picture, you take the derivative with respect to y, you play exactly the same game and what's your problem. Okay. I think we will have a break after my question. I'm close by the assumption two. Assumption two? Yeah. This one? No, about the sophomore assumption assumption. Yeah, yeah. Sorry. It's a Um, so that okay, what any is GVO, right? TV, yeah, units. Ah, okay, okay, but uh, yeah, yeah, what so is it different from the also the knowledge you proved in the serum, right? I know I said what? Okay, come. I just want to have a scan. Typically, what I want is to have a hairbone emotion that is independent from the common body. This is what I want. Okay, I see. This is what I want. Okay, I see. Yeah, no, it's not. I mean, it's orthogonal in the sense that it's a robot. It's not an orthogonal process in the sense I defined before. Orthogonal processes are defined in the B filtration. Okay? Yeah, yeah. Here, I have just two markers that are alternative in the traditional sense. Okay? Okay. I want to have full independence between the two. Okay. Okay, so let me show you how you can use this for a class of McIntosh often control problems. This is a case where we will actually control only the drift. And if you control only the drift, you know that you need only the first upper derivative to write down of the repetition arguments. You don't need to write the other ones. And actually, you can mimic BSD's arguments in that. BSD's arguments in that setting. Okay, it's working perfectly well. So it's a mix between IGB and BSD verification arguments, if you want, whatever you mean. So everything is written as usual in the Greek formulation. So we will have two spaces, I mean, two canonical processes, X0 and W. So X0 will be for the common noise, and the W will be for the idiosyncratic noise. Um, so they will live in the on the product space f0 of x0, f1 of w, and uh, those spaces are with the uh corresponding penalty. Okay, okay, so my collection of controls, so yeah, I take controls that are in the filtration of the command house, okay, and then uh okay for the control process. The control process. So, I consider all the laws for which this can only fall process X0 can be written in that form. So, you can use something more than all here if you want. The important thing is that you are controlling the grid. So, X0 is a grid part plus brand and washing part, okay? Where WP0 motion and the P0, this is very natural. And then on the product space, omega 0. product space omega 0 omega 1 well you just consider the laws that are generated by your control laws and the linear measure for the read okay so once you have this you can actually introduce the control machine bars of SDE so I have defined the possible loads of these guys this is the common noise okay and I will play on with drift And yeah, that's all. And rho will be just a conditional rho given the filter of the common prison. Okay, so now I'm almost done. I'm sorry for the inficience, but if you want to write things, this is the way to do. And finally, all together, the control laws are the control laws of X0, W, X, and Rho. So I put them together. So the W would be. Put them together so the body would detect emotion in a way. Uh, and okay, I combine all these guys together. So, what's the control control UDP? X okay, let me come back. What you control actually is this guy, P0. Okay, that will give you the composition of X0. Yeah, this is your degree of freedom, okay, and all the all. Okay, and all the all, I mean, but then you have to uh to write on things, you have to control, you have to define what is load of all these processes, okay? Okay, so you take these guys as a panel process, but the load that you really control is one with zero and then you control the bit, okay? So, and I want And I want to look at this optimal control problem. So I take the supervisor all my control laws, and here I have just the running costs that depend on my control, that depends on the conditional law, given the noise. And then I have a terminal value that depends on the terminal law, conditional law, given the problem. Exactly, in terms of both the loop or cloud loop, it's neither now, yes. Because it's a kinometer space of X. Kinometer space of x0. Well, at the end, at the end, if v is uh c1 with respect to n, the optimal control will be given only by the gradients. I'm just thinking of the result, the information and the control depend on the x0 plus x. The control depends on the x0 process, yes. X0 plus not as an x plus no, x0, yeah, yeah, yeah, you see the common x. Yeah yeah, you see the analogs. Yeah. Okay, so again, sorry for the notation. So see if you see that guy, actually I don't use it right now. Well, no, yes, I use it because P is one of those guys. These are just set on the measurable maps, okay, on the product scale. Okay, and for this problem, you have the Hamiltonian as usual. Okay, so you want to maximize with respect to the value of the control. With respect to the value of the control, this quantity H, and H is what? This is your running cost over there, L. Okay, and here this is the grid term that will show up in the PDE, okay, that depend on the control. And here, this is actually the conditional expectation of the gradient multiplied by sigma zero, okay, and you take the conditional expectation with respect to the green. Okay, so I got because I will have to, I mean, most probably, you know, the same. I mean, most probably you know this thing, but you have to play with these quantities all the time, so okay. So, um, and here what we do actually is introduce dual problems. I mean, the verification argument goes with jolty arguments, it goes together. And let me put the whole slides. Actually, you could also try to use BSDs for doing this. Here, we don't do that. BSDs for doing this. Here we don't do that, we use stochastic target problems. Okay, and this is very in the spirit of what I did with former PhD students, where we were showing actually that whatever control problem you take, I mean, in a major form, okay, you can always rewrite it as a stochastic target problem. And this is what we do here. So the two stochastic target problems are as follows. So the first one is I look for the minimal initial condition B1. minimal initial condition V1, so that if I take V1 plus this term, so this term is the term you will actually get essentially from the Prometheus lemma. But I don't take the gradient of the value function here because I don't know whether it exists for the moment. I take a function, okay? So a borrowed measurable map, okay? And I want my control is actually this map. Okay, so it's not a control in the traditional sense, it's a map, and I'm choosing a map, okay? And I want that for a certain map, I have this. Want that for a sentence map? I have this super aging feature. H also depends on that map. And I want to have it p-bar for any control loop. Okay, so I want to have a map that is doing this for any controller. The second one, which is it's pretty clear that it's equivalent. Now I take V2s. V2 is the infimum jet. We have the same terms here for a step and map. Okay. But now in that term, I maximize. Now, in that term, I maximize the edge. Okay, so it takes the amid one. You can see that here you want it to have it for any control low. Here you just optimize about the control low and the beer from here to the okay. It's quite clear. So let me first show that D2 is bigger than D1. This is quite obvious. Again, I mean, D2, you have to separate the Hamiltonian. So different maximum. The Hamiltonian, so different maximizing of the probe. So, clearly, you will do better. I mean, big H is bigger than small H. So, if you can do small H, you can do big H. Okay, this is what is written here. Yeah, honestly, I'm not sure. Yeah. Okay, so you have B1, but this term, this is what you have to do if you start from D1. Okay, with 0, I wrote what it is. If you replace D0 by what it is in terms of D0 by what it is in terms of alpha and dw, you get these terms. Okay, and now you remember what is written on the board. So actually, this part, well, what is it? Okay, so what I did is that h minus this part, this is h minus this part, okay? So this is L. Hiya, I was confused. Okay. And then what you have is that you see that, I mean, this is a traditional argument. If you start from V1 doing that job, then V1 is bigger than this expectation, whatever the control is. Okay, so if you maximize on that side, you get the value function of your optimal control problem. And the fact that D2 is bigger than V1, I can explain you why it says this is a class. Okay, so you have this first inequality. And then what remains to show is actually that V is bigger than D2. Okay, and this is where the verification argument applies. So the verification argument is this. So if I assume that V is C01, so just continuous in time as continuous non-derivative, a little bit of boundedness, you can do it locally if you want. Then we'll have actually the duality. So I already know that this guy is smaller than the other ones. I have to go show that the opposite. To go show that Lyoposit inequality. And now, if you take a maximizer for the emit volume, okay, then from it you will be able to control to construct a control load. Okay, and this control load will be up to you. Okay, so you see, it's, I mean, you could do this with BSDVs. Here you would have a Z process somehow. Okay, so here it's a mix because we use the functional form of this guy. Okay, so it's between PDVs and BLDVs. Between PVs and the LPs. So V comes as a solution. So is a value function? Sorry, yeah. You see on two plus V is a solution, ID value function. Okay. Yeah, side remark: obviously, if you have compactness, you'll possibly continuity, you will find a guy doing the job. Okay, so I have to show that D2 is less than D, so the second adult formulation. And if you know this argument from DSVs, this is really the same. So remember that V is expectation G M capital T plus integral T capital T M. Yes, okay. So, what you know is that v plus integral of e over t l d s will be a supermarketable, okay? Because if you add this term, you add it here, you start from zero, and then because you have a third, you have a supermarket, okay? So let's call it S. So I know that B plus the running cost gave me a supermarket, okay, whatever the lowest control low is. And now I know. And now I know on top of this that I have assumed that V is sigma. So I can use my ITOS formula. And the only thing again in that Italus formula is that I know that the process gamma is actually minus the non-decreasing process. Okay. So I combine the two, gamma-tagger property plus my intos formula, and I get this. Okay, now V at time capital T, this is the terminal payoff. Okay, Okay, so this guy, which is here, minus something that is non-negative, is bigger than V at time capital T, I mean, S at time capital T, okay, and S at time capital T, this is V at time capital T plus the brain cost time capital T. Okay, so S at time capital T, this is okay, so you write S capital T equal S capital T. Okay, you take the formula over there with You take the formula over there with the terminal condition, this is this, and the formula here, and you withdraw the A process. Okay, and now you replace dw by dx0. So you have the formula over there. Okay, if I change dw into dx0, what I am adding is exactly this term. Okay, so I have L plus this term. And this term is H. Okay, so I have this inequality. So, I have this inequality. So, V is the group that we have this term, this marketer part here is bigger than this guy. Okay, so I can take expectation. Well, actually, first what I can do is, oh, I didn't take expectation, but what I can do is that I'm playing with any control law. Okay, so I can take a control law that is epsilon optimal here. Okay, so for I can reach the value of the Hamiltonian if I want. And sorry, I didn't, no, I would have to take it. I didn't know I would have to take this prediction actually. So, this means that if I start from D0, I have this control, I reach my target, okay? And this means that I actually do the job with respect to the definition of the dual problem D2, and therefore D0 and 0 is BGLD. So, and I had I already knew that D1 is less than D2 less than V, and I just put that V is because. And I just put that here than D2, so I have the job. Okay. Okay, now for the verification arguments, I play again with my supermarket. So now all this key term that kills in Postman I call it L, okay? Because otherwise, too big. Okay, so again, you play something that is quite traditional. So you look at the supermaterial process. So, you look at the supermaterial process corresponding to your optimal control problem. And what you know from dynamic programming is that this bounded variation product here, this non-integrating process, you know that if you take the overall control loss of the expectation of that guy at uncapital t, it has to be zero. Okay? It has to be zero. This is very classical. So keep this in mind. And now this is a usual thing. Usual thing. You write down the decomposition of V. So you see, it looks like a backbone, actually. So you have the terminal value, the H guy, the non-decreasing process, and minus this term here. This is the composition we will be at. Okay. You can write it under P bar. You can write it under P at. So P at I define like the condivate to be the optimal control law. Okay. And now. Okay, and now you rewrite it in terms of p-bar somehow, and you keep this line and you replace h for the optimal control by h for the control under p-bar. Okay, this guy is maximizing this quantity h, so you have an inequality. Okay, and uh, what does this argument? It's uh, you look at the first and the third line, okay? These two guys are the same, these two guys are the same, uh, these two guys are the same, the only difference is that. These two guys are the same. The only difference is that you have AP power, and here you have AK. Okay, so you have an inequality. You know that somehow along the optimal path, the banded variation, the non-decreasing process A is minimum. Okay, so this is very classical. Okay, now you remember that if you take the intimum expectation of all the control laws of these guys, this is zero, okay? For this, you don't need to have an optimal control number, see. You don't need to have an optimal control on it, so what's okay. But here I am only on the grid, okay, and everything is bounded, so all the control laws are equivalent, okay. So if you have the infimum for AP bar, you have the infimum also that is APR. But if you have the infimum of all the control laws, the expectation on this control law of API is for zero, then APAT has to be equal to zero actually, because all the laws are equivalent and you really control the densities of one with spectral. The densities of one with spectral. So it's an easy argument. You just use the reverse order inequality, okay, and you show that it's just zero. Okay, so now you go back to this line. Okay, V0 is equal to this quantity, but now you know that this guy is zero. Okay, and if you take expectation, you will have expectation B0, that would be the expectation of this guy. zero that would be the expectation of this guy plus the expectation of this guy minus expectation of this guy and the difference of the two in expectation is actually your running cost exactly your running cost this is what i write here uh in a dig0 i removed the market part okay so i guess h minus l h minus l is actually the running cost and you're done this shows you that p at is actually uh okay So again, here, this is kind of BSD argument, honestly. Okay, but the starting point is more. Sorry, where is it? Yeah, the starting point is more a PDE argument. Okay, I'm really maximizing the email in the PDE using the fact that I have a first-order, and I try with that. Also, because the control is not on the diffusion term. Exactly. Yeah, yeah, this is. Yeah, this is crucial for that. Yes. If you control the diffusion term, you're better. Okay, so let me show you one toy example in a case where you can obtain C1 regularity, but you know that in principle you will not get C2. And here, this is a typical situation where you won't have a Is a typical situation where you won't have a regularization by the noise, okay? So, if you want to obtain C1, you have to put C1 regularity on the coefficients, okay? If you want to obtain C2, you have to put C2 regularity on the coefficients, okay? So, it's a very simple case. So, you can obviously do marginal very 0.0 example. So, the relativities are just one. Okay, so you just have a common noise that is volume and the one and so. I will take A from X. I will take A convex, it's compact, and the running cost is a very simple one. It's just a function of your wave loss, okay? And the only thing that is very important here is that it's strictly concurrent. That guy has to be strictly concurrent. This is crucial. And for the terminal payoff, I take a functional of some, I integrate some functional and then say conditional law at time capability. Okay, so I take kind of a non-linear moment, a function of the non-linear moment. function of the and and and this is here you have to assume that g bar and uh this function pi are c1b okay if i put c2b i can get c2 with c1b i will get zero okay so in that case b is uh c01 actually let me put all the whole slides so what's going on in that case is that and this is crucial to get regularity from the regularity of the coefficients is that you have a unique optimal control That you have a unique optimal control, okay? And the unique optimal control comes from the strict conquerivity here. Okay, so the optimal control problem in terms of the payoff, terminal payout, it's linear in the probability measure. But the running cost because of strict concurrency is strictly corporate. Okay, and this is a Markov projection argument, which is quite normal. So once you have the uniqueness, I mean, you have the I mean, you have the envelope zero, which is working, okay, if you have uniqueness. So, actually, the gradient is actually the gradient of the gain functional at the optimal points. Okay, so this is the gradient of the gain functional if you take the gain functional at p at, but by uniqueness, it has to be the gradient of the value function as well. Okay, so I don't expect you to look at all the formulas, but this is what it is. This is what it is. Okay. Is it possible to construct an example such as that? The coefficients are unique as smooth for the mean user C1. Yeah, sure, sure, sure, sure. Yes. Yes, I guess so. Yeah. To be honest, we were pushed to write down an example and we wanted to have it as short as possible. 0.0 example. But here, yeah, you can actually. Yeah, you can actually settle in generalizes. Yeah, because this is a regularity more like the ordinance. You make it a signal nose. More intrinsic. No, but here the regularity will come only from the coefficients. Okay. You can show that the gain function of the general role is not similar. Okay. Thank you very much. If it's non-convex, you will be in difficulties because the proof goes as follows actually when you take two control blocks. Two control blows. Okay. Yeah, you get a convex combination of the two, actually. So you need convexity of A to ensure that you are still in A. And if this is the case, actually, because you take kind of convex combination and then you have to project again, okay? Because you do it in a bigger space and then you project by taking conditional expectation on the smaller space, which is your original space. But this works if a Uh, but this works if A is context, otherwise, you get outside of the set A. Okay, and this is why you get if you have strict conquerivity here, you get uniqueness because you go through Jensen inequality when you do the projection. So, this is an assumption in the example, but in the general result, we don't care what A is, right? No, no, in the general case, no, we don't care. Yeah, yeah, in the paper, we put it compact, but this is for simplicity. Anyway, you can extend this to include the law of the control, also in the dynamics or in the costs. Well, this part, I don't know, for sure. And the other part, why not? Why not? Why not? Yeah, I don't see the problem. Yeah, yeah. You take a more general gift, you have to write down the toss formula for this more general guy. What I really like in this approach by Roucho is that really the proof, once you have understood how it works, it's really straightforward. I mean, you can apply it. I mean, you have to work a little bit on the technicalities, but it goes through all the time. But it goes through all the time. My experience is this. And it's really powerful. So V is continuous in time T, right? The V. Yeah, V is continuous in time. So what about the derivative with vector May or V? What is the continuity of the derivative with vector T? It's continuous in T and M. The derivative is also continuous in T and M? Yeah. Also, continuously TIM, yeah, yeah, yeah, yeah, because well, if you look at that example, if you change the original starting time, I mean, those functionals are continuous, okay? So if you forget about the fact that the load will change, it's continuous, okay? But you have uniqueness in the load. So anyway, if you take a sequence of optimal controls along the sequence of time, for instance, because you change the original time, you know that the sequence will actually converge to the The sequence will actually converge to the optimal guy corresponding to the unit point. Okay, this is all those. So, because you have units, once you have uniqueness, you can forget about the because in your decomposition, you only need the integral respect to the double, right? For common noise. The derivative is inside. So, as the integral, you only need the measure, right? Sometimes. That's like a noise. It's like a no, I don't get your point. What do you want? So, sometimes if we don't get that BSD, that gradient of the value function is just a miracle with respect to T, right? Ah, yeah. Yeah, yeah, yeah, yeah, yeah. Yeah, if you, yeah, okay. But yes, what I said, I want to have a formulation that is more a PDE-like formulation because I want really to put my M on what is the optimal control. And then if I don't have If I don't have continuity of the brightness, I think as a proof, it was from ETO's lemma. We require that the director would be continuous. We have some approximation. Ah, yeah, yeah. Okay, yeah, maybe you can need it. There's some type of jokes I usually. Oh, yeah, it's okay, okay. Do we have sufficient conditions to show that the V the and C is the other one? Because the Lipsheets is a typical A is easy, yes. Yes. You mean for this kind of problems? No, we did not look at, but I mean, if you put the regular return coefficients, it should. Yeah, that's our coefficients. Yeah, for the moment, we just looked at this model. But you can actually, we are working on a module setting. Marginal setting up. So I think we will come up with that. Any other questions? If not, let's send, you know,