Hello, everyone. My name is Shweta Rai. I'm a third-year PhD candidate at Colorado School of Mines. I work with Dr. Dagnanjka and Dr. Shotir Bhantasarte. And today, I'm going to give you an overview of my first project, which is fast parameter estimation of generalized extreme value distribution using neural networks. So, generalized extreme value distribution or GEV distribution is a very common distribution. Is a very common distribution. It's used to model extreme events under univariate setup. Because of the heavy tail behavior of GEV, it is favorable to model extreme event using this distribution approach. So like any other distribution, it has three parameters, the location, the scale, and the shape parameter. And what we're trying to do is estimate these parameters using neural network. But first, I will talk about the challenge. So, G, we discussed. Challenge. So, GeV distribution challenge with GeV is the likelihood expression of GeV does not have a closed form. And since it does not have a closed form, doing a maximum likelihood approximation approach involves numerical optimization, which is okay for small sample size, but if they work with a large sample size or a large run, it could be computationally expensive. So, what we aim through this project is to Aim through this project is to speed up fitting GAV using neural network but to retain the accuracy of maximum likelihood. So we are using neural network and here is the network architecture. So we are using a feed forward neural network. So in a typical feed forward neural network, we have input layer, hidden layer, and then the output layer. So this is a feed forward neural network. So it transforms the information from the input layer. From the input lid through the hidden lid and then the output layer in a forward direction. So, towards the end, we have three outputs, which is the parameter estimates of the GEV, which is the location scale and the shape value. And for the input, we have 11 neurons, which I'm going to talk about in the next slide, but why we have an input of that size. So, when we talk about doing inference using neural network, we are doing that by training the network. Are doing that by training the network based on simulation study? So, here we have an overview of the model training. So, since JB has three parameters, the location, scale, and shape, first we have to define the range of those parameter value to do a simulation study. So, we are working with this range of the parameters, and this is based on what we see from climate data. Once we have defined the parameter configuration, next we have to do is generate the GEV sample on those parameters. the gv sample on those parameter configurations and then instead of tweeting the entire uh instead of feeding the entire sample to the neural network we extract some summary statistics which we think might be informative uh for gev samples and the summary statistics we're working with are extreme quantile values since gev has like right skewed or left skewed based on the shape parameter so we are focusing on lower and upper extreme quantiles and also the cubic Extreme quantiles and also the Q1, Q2, Q3 value as summary statistics. So we extract the summary statistics from the standardized sample and then we feed this to the neural network to train it. And once we have the network trained, it's available to fit to extreme events. And here we are working with a training size of 300,000 parameter vector. And then, like, yeah, so that's the model. Like, yeah, so that's the model overview. And this is the implementation of our model. So, what we are trying to do here is to validate our neural network model. So, in order to do that, we fit GEV on community climate system model version 3 runs for 100-year of annual maximum temperature. And this is done under pre-industrial setup where the CO2 concentration is 280. Where the CO2 concentration is 289 ppm. So the first column shows the result of the maximum likelihood approach. That when we fit a GEV to the 100, sorry, 1000-year annual maximum temperature, then we have the parameter estimates across the spatial location. And this column shows the output of the neural network approach. And the last column shows the difference of the neural network from the maximum likelihood. Neural network from the maximum life state approach. So, if they look at the first and the second column, it looks like it's just a replicate of one another. So, we think that the neural network approach does a good job in reproducing the maximum likelihood estimate values. In conclusion, we can train our neural network model by simulating our values. Simulating our values from the GEV sample, and we can work with as big a streaming sample as we like. And once the network is streamed, it's available to fit GEV distribution to extreme events. And we see computational efficiency. We work with bigger sample size. So if you want to know more about my research, please come and visit my poster during the session, which is from 2:30. So thank you. Thank you.