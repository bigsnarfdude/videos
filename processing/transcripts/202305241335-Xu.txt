Okay, so yeah, I would like to thank the organizers for the very kind invitation and thanks Sandra for the introduction. The title of my talk is Theoretic Homogenization for Dynamical 542. So that's an attempt to bring together a problem in homogenization with a problem in singular SPDs. Because I'm mainly from the singular SPD. I'm mainly from the singular SPD background, and I see there's another very fast developing field in the interface between analysis and probability. It's one is singular SPDs, and the other is sort of homogenization, which I also learned something. And it's natural for me to ask questions. So what happens if you combine them together in the same problem? And that's mainly my motivation. So the content of my talk will be our first introduce some examples of singular stochastic. Examples of singular stochastic PDEs, and then I will introduce what periodic homogenization is about. And finally, I'll introduce the toy model that combining both in one problem. Oh, by the way, so this is a joint work with our PhD student, Chang Yi Ling, at Peking University. So I guess these are some familiar examples to some of the people in singular SPDs. There are three things: one called KPZ. three things one called kpz the second is the five four d equation where d the dimension d is two or three and the third one is the parabolic anderson model also in dimensions two and three so the problem with these equations is that there is a very bad singular random force term on the right hand side so in the first equation the first two equations is the space-time white noise called casi and in the third equation is the space white noise Is the spacewatch noise, which we wrote as eta. So because these random forcings are very singular, so as solutions to this parabolic equation with random forcings, they can't be too regular. And it turns out that in these specific dimensions, all the solutions, so their derivatives appearing in the equations, they all happen to be distributions. Oh, except the third one. The third one, the solution u is a function, but also. Is a function, but also has a problem because you so in the KPZ case, you expect the solution h to be at most holder one half or slightly less than that. And then in the equation, there's a derivative of h, which is going to be a distribution, not a function. So you can square it. And in the second equation, one dimension is two or three. We see the solution phi is also going to be a distribution, and it doesn't really make sense to talking about phi cube. Talking about phi cube. And in the third equation, in dimension 2 or 3, the solution u is kind of sort of C1 minus or C1 half minus. And since the one noise eta is singular enough so that you can't multiply U and ETA in the third equation. So all these problems is that because the random forcing is too singular, so that the solution is going to be also quite rough and you can't multiply distributions. And we see there's a And we see there's a red constant C on all the right-hand side of the equations, and intuitively, because when you multiply distributions, infinities appears. So heuristically, you also want to take the C's to be infinity to cancel out those multiplications, the infinities that appear coming out of the multiplications. So here is a rigorous theorem to making the heuristic quite a mathematical statement. A mathematical statement: it's a theory of regulatory structure developed by Martin Harrel and also parallel control distributions by Kubernetes in Pala Perkovsky. They show that for all these three equations and actually for a much larger class of equations like Kaochen talked about the Yamius ones, things we so we see the problem is that really that cassa and ida are too singular. So the natural way to deal with this problem is that you Deal with this problem is that you make a smooth cosine delta or you take a smooth eta delta to approximate cosine or eta. While for each delta, this cosine delta and eta delta are smooth approximations at level delta to the one noises. And so once you fix the positive delta, everything is going to be smooth. So your solution H delta, phi delta, or u delta are all going to be smooth. So there's no problem in defining the solution, actually defining the smooth solution for each fixed. Defining the smooth solution for each fixed delta. But the problem becomes as if you want to send delta to zero, you want casi delta to approximate casi, and you want either delta to approximate either. Then the problem appears in the limiting procedure. And as said in the previous slide, you sort of need to take c to be infinity to cancel out those multiplications. So what happens is that if you multiply, if you square dxh delta, you will diverge as delta goes to zero. And for the second equation, And for the second equation, if you take the third power of phi delta, you will also diverge as delta goes to zero. So consequently, you sort of also need to take c delta going to infinity as delta goes to zero in such a way that these divergences or these infinities are cancelled out by this counter term C delta. And there is a very natural way of doing this. So that's guaranteed by this theorem. And furthermore, You can choose C delta in such a way that all the limits you obtain by H delta, phi delta, or U delta, it actually doesn't depend on how you approximate the noise. So, for example, if you choose one approximation, Casa delta to Kasi, and you choose another approximation, Casa delta to Kasi, these two approximations will give you the same limit of H deltas. So, since the limit doesn't really depend on how you approximate, you can basically define the You can basically define the limit to be the solution to these equations. And here is, we give you an idea. So, how large the size of C delta is in these situations. So, in the KTZ case, C delta is sort of leading order, it's one over delta. And in the 542 case, C delta diverges like log delta. Yeah. What does this mean? What is the psi delta that gives you this? Sorry. What is the regularization that gives you these particular numbers? The xi? Oh, yeah. Oh, so the order are actually determined by the level of singularities. So the leading order, basically, so in KPZ, the leading order is one over delta. So basically means that if you square dh delta, it's of order minus one, something like that. So, one important point is that the limit of these regularized solutions, they don't depend on the precise approximations to your noise. So, even if you change, you do various approximations, you get the same limit. So, you can basically define the limit to be the solution of these equations, or otherwise, there will be ambiguities. And a remark is that. And a remark is that here the operator is the heat operator. Basically, the elliptical operator is Laplacian, which is very nice. But we can also replace Laplacian by a smooth coefficient divergence operator. If you replace Laplacian by something like divergence A of gradient, and as soon as A is uniformly elliptic and smooth, there's no problem of proving the same theorem. Yeah. What is the order for PAM? I don't know if there is one. D equal to two is oh, so PAM is the same as five four. So D equal to two is log delta. D equal to three is one over delta plus a log. Yeah. So that's the singular SPD part. And we see that there is a very singular right-hand side. There is a very singular right-hand side. So, there is a modification parameter we call delta, and there is a procedure of sending delta to zero, taking a singular limit. And along the procedure, you also need to do some renormalizations. And that's a general statement for singular SPDs. And now we turn to periodic homogenizations. It's another type of problems, which also involves some singular limit. But this, so in SPDs, there is a very So in SPDs, there is a very nice elliptic operator, Laplacian, or given by smooth coefficient divergence form operators, but very singular forcing on the right-hand side. But for homogenization problem, it's the other way around. So on the right-hand side, we can always assume F to be smooth. It doesn't make the problem easier because the operator is going to be highly oscillatory. So you take a very nice operator A. Oh, it's not from R. A, oh, it's not from Rd, Rd to Rd. It's actually from Rd to Rd squared. It's the other way around and also not Rd times Rd. So you take a very nice matrix A, and you assume it's uniformly elliptic, smooth, and also one periodic. So it actually doesn't make the problem easier, even if you assume A being smooth. It doesn't make it easier than just assume. Then just assuming it should be bounded, as we see, because we rescale A by epsilon. So if you want to use any derivative of A, you will explode in terms of epsilon. So that's the setting of periodic homogenization. So the right-hand side is smooth, but the operator is highly oscillatory. And the basic question is that if we have this equation u epsilon, and what does u epsilon look like as epsilon going to zero? And now we see so the operator is highly alternative, but it has a weak limit. So A epsilon, which it defined like Ax over epsilon, actually converge to the average of A on the torus weakly in L infinity. It doesn't converge in L infinity, and it actually doesn't converge in L G for energy. It just has a weak convergence slightly. It's just below L infinity. And the main statement is that in this situation, as long as A is nice and one periodic, u epsilon will actually converge to a unique limit u as epsilon going to zero. And the limiting u actually solves the constant coefficient elliptic equations. So the limit u will satisfy some elliptic equations where the operator is a divergence form and the elliptic. And the elliptic matrix A bar is actually going to be a constant matrix. It doesn't depend on the location x anymore. But the interesting thing is that this A bar is not the average of A. It's not the average of A. So as we can see from the results that the limit ting procedure is also singular because the limit of the U is not the U epsilon given by sort of the limit of A. Given by sort of the limit of a. So you basically cannot swap the order of the limit. And so the statement is that a bar is actually given by the average of a and plus some corrections. So if we don't have this red term cosi, a bar will just be the average of a. But it turns out that as long as a is not constant, a bar is not going to be the average of a. The average of A, I mean, I mean, this chi is not going to be zero as long as A is not constant. So, the setting of periodic homogenization is that you have a very nice right-hand side S, but you have an oscillatory coefficient A. And the result is that you have some convergence to U, but the equation is not given by the average of A itself. And some remarks is that it doesn't matter if you add some nonlinearities of U on the right-hand side. non-linearities of u on the right hand side for example if you can you can add u epsilon cubed yet it wouldn't change the theorem as long as the thing you add yet doesn't involve the derivative of u epsilon it wouldn't really change the problem so uh and also there is a quantitative theory for periodic homogenization developed in the past 10 years by ling and zhong we shun and also here we assume this coefficient a to be deterministic coefficient a to be deterministic but periodic of size one there's also recent works in the in the recent 10 years by that you can replace a to be a random coefficient that goes to stochastic homogenization in instead of periodic homogenization and there is a very complete theory developed in the last 10 years by two two groups of people it's it's it's gloria otto and armstrong kosimo hot on the quantitative More hot on the quantitative theory for stochastic homogenization. So, my motivation to do these things is that so you see in singular SPDs, there is a regularization parameter, delta going to zero, you take a singular limit. And in periodic homogenization, there's an oscillation parameter, epsilon going to zero, which you also take a singular limit. So, what happens if you combine these two singular limiting procedures in one single problem and how do they interact? Single problem, and how do they interact with each other? And that's the question what we ask for ourselves. So, if we want to understand this question, we want to find what to do. And the most natural thing to do is basically that you take some singular SPDs you are familiar with and replace Laplace M by these oscillatory operators. So, that's the problems which we can think of. And now we see. And now we see there are two parameters: one is epsilon and the other is delta. So there are various ways of taking joint limits. Then there are two most natural ways, which are sort of the two extreme ways. The first one is that you take epsilon to zero first, you fix a positive delta, you take epsilon to zero first, you get a limit, and then you try to send delta to zero. And the second one is that you fix epsilon first, you take delta to zero first, and you get a limit, and then you try to self-defense. And you get a limit, and then you're trying to send epsilon to zero seconds. So I'm not saying these are the only true ways of taking limits, but these are the true extreme ways, which are also very natural. And we try to get a dense. So there are four limiting things. So we basically take whatever the solution, phi epsilon delta, which we mean the solution to a singular SPD regularized at delta and has an Regularize at delta and has an oscillatory coefficient at scale epsilon, and we see what happens. So the first one is dot of you trying to take epsilon to zero first, you get some phi delta, and then you try to send delta to zero. You hope to get a limit here. And the second one, and the second order is you can basically you fix delta or you fix epsilon and send delta to zero first. You get something. first you get something called phi epsilon and then you're also trying to send epsilon to zero here and let's take a look of these four arrows and see which are sort of can be done and which and which are within the framework of the current theories and which are sort of slightly out of out of the scope which we sort of need to work hard to figure out and let's put the the arrow at the top we are fixing delta We are fixing delta. Once we fix delta, everything on the right-hand side is smooth. That's going to be a very standard homogenization problem. So you send epsilon to zero here, you get a limit, which is phi delta. That's very standard periodic homogenization. And once you get this phi delta, we remember in homogenization, the coefficient is actually to be constant. It doesn't depend on x anymore. It's going to be a constant. So once you have a constant, So once you have a constant elliptic operator, it's again standard SPDs within the framework of standard SPDs. So you can sort of, this is standard homogenization, I would say. And that's standard SPDs. So you basically here, you can get a limit, which you call it phi. There should be. There should be not a big problem on these two arrows. And now we look at the other direction. Singular. Standard singular. SGDE. Well, I'm also not saying it's standard, but it's within the framework of the currency theories. Theories. So let's look at the other direction. If we fix epsilon and send delta to zero, so if we assume a being smooth and we allow the estimate to depend on epsilon, this is also not a problem because you are just replacing Laplacian by smoothing by an elliptic operator with a smooth coefficient. If you allow all the estimates to depend on epsilon, and if you make some smooth And if you make some smooth assumptions on A, so that direction is not gonna be a problem if you allow A. You allow epsilon in your estimates. But now the last arrow will become a problem because in the end, you get very, very singular right-hand side. It's already renormalized without a delta. It's very, very singular. And now you actually have an oscillatory coefficient. And you need to do homogenization with a very, very singular. Homogenization with a very, very singular right-hand side. That's sort of out of the scope of the current frameworks. And so that's the question we ask for ourselves. So in this arrow, so does the limit exist? And if it exists, are these two limits equal to each other? And if the limit doesn't exist, probably there might be a way to take joint limits somehow in some In some sense. So that's what we sort of want to understand in the general singular SPDs with oscillatory coefficients, what happens in these diagrams. It's not only these two extremes or the limits. So if this arrow goes wrong, what happens for something in between? And so that's the question we ask for ourselves. We ask for ourselves. That's the well, let's skip these slides because this slides is basically what we do on this board. And let's see. So in the last arrow, let's see why it's sort of difficult and why it's out of the scope of the current theories of singular SPDs. So in many situations in these singular SPDs, there is something that we rely on very much on the electric operator, which is the shoulder estimate. Operator, which is the Scheller estimate. But here, if you want to have uniform in epsilon estimates, there is actually no uniform Scheller estimates, which doesn't depend on epsilon for this operator, dt minus L epsilon. As we can see here, so let's just consider this simplest example. Let's say a linear equation dt u epsilon equals L epsilon u epsilon plus the smooth right-hand side of f. So no matter how smooth f is, no matter how smooth f is u epsilon will actually has at most one derivative if you want to it to be uniform in epsilon if you take one plus alpha derivatives things will actually just explode in epsilon even if f is smooth so you just so you just can't have any derivative which are more than one so there are actually no uniform shadow estimates for this operator and the other thing is that so in both situations either in singular spds or Either in singular SPDs or in homogenization, you actually need an answer to solve the problem. That is to say, before you prove the theorem or before you prove the convergence to the limit, you actually need to have a correct guess on what the equation or what the solution looks like. And that guess is called the answers. So the pro yeah. Yeah. So I think that your fight for anything that they For anything, the public part is already done. We actually did it for 542, but if you allow your bound to depend on delta, the upper part is no problem. Yes, for bounds with that. We don't know. We haven't written down 543, but I expect. Written down 543, but I expect it's also the same because right hand because the right hand side is smooth, it doesn't see difference between dimensions. So as long as you add a sort of smooth nonlinearity, it should be fine. And for example, the power of phi is a sort of a very nice nonlinearity. Cancel, right? I can see what what is the thing from uh yeah okay so the other so one difficulty is that there is no uniform shadow estimate and the other difficulty is that so in each problem there is an answer and these two answers they don't look similar to each other or or they actually look very different. If you want to do something you sort of need to combine these two answers in a way that allows you to understand all these limits. To understand all these limits, and since time is almost up, let me just state our results in this thing. So, together with Cheng Yiling, we did the simplest model, which is dynamical 542, which is sort of the first one you want to consider in singular SPDEs. And we just replaced Laplace M by L epsilon. And in this situation, we can show that these two limits actually commute to e and actually commute. So you can take. And actually commute. So you can take the limit in the last line, and these two limits of these two orders actually agree with each other. And if we want to prove in one sentence, it says that even if there is no uniform shadow estimate in this situation, but you actually really don't need the real shadow estimate, or the consequences you need are true in this situation. So that's the result for the first model. And so together with Span Fuhrman, we are investigating what Investigating what such a model. So, we are currently trying to understand what happens for parabolic analysis model in dimension two. So, that's sort of in progress. And I think I'll stop here and thank you very much. So, here you are in the national tool. So, in this framework, you are really in the regular question. regulated stuff i mean you can use uh the product in this one we didn't use we didn't use yeah yeah yeah yeah it's the product yes oh that's a good question because i was asked more than once uh Was asked more than once. I would say that's mainly our curiosity. I don't really know any physical meaning for that. It's just our curiosity, and we want to understand. So, you have two singular. So, you have two procedures of taking singular limits, and it's natural to ask ourselves, if you put them in one problem, how do they interact with each other? So, I don't know real physical meanings so far. Add a third one. So at the bottom of the diagram, you can see how to figure out does this the alpha still take a similar form to 05%? In this situation, that's a good question. So it depends on to what extent it is. What extent it's going to be similar? So, if you just want the first-order approximations, they are the same as periodic homogenization, and that's enough for us to show a convergence. But if you want to ask deeper questions, say, do they approximate in derivatives? And here, it doesn't. Yeah, it also depends on what's your requirement. And here, it doesn't. What is this A bar exactly? Is it is it the same as the one that we wrote for the bar here? Oh yeah, A bar is the same as the coefficient we wrote at the beginning. So A bar actually just depends on A itself. It doesn't depend on what the right-hand side is. This is possibly a very naive question because I don't know much about the liberalization theory. I was wondering why does the solution become smoother if if you make the uh this A over epsilon uh equation like uh Equation like more complicated, like if it's a more complicated lipic operator, how does it help solve the equations? Like, does it smooth out some singularities or something like that? No, it doesn't make things better, it makes things worse. Oh, okay. Makes sense. No, it doesn't make things better. So, if not, thank you to the last speaker. 