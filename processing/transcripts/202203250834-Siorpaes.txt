The linear constraints. Thank you so much. And thanks for the organizers for putting together this wonderful conference, by the way. I really enjoyed it. And yeah, for giving a chance to talk. So this is joint work with my PhD student, Marco Masa, who's finishing his PhD towards the end of this year. All right, so I'll briefly introduce the setup as one slide. You all know this stuff, but at least it introduces the notation and so on. Introduces the notation and so on. So, okay, so I will work in a separable Bananax space. Frankly, you can take RN, but it doesn't cost me anything to take a banana separable space, so I'm not as well. And so I consider autonomous transfer problems. Normally, they're done in a Polish space, but I need additional vector space structure. So I'll work in a Banach space. So I'll consider two probability measures on the space with finite R moment, R. With finite r moment r bigger than one, normally one takes one or two, um, and then a transport from mu to so given these two measures, a transport from mu to new is you know is a joint law that has those two as marginals, okay? Um, so the two projections give you those marginals now, or in other words, is well, is the law of a couple of random variables, each of them distributed like mu and mu. And new and given a cost function v, the optimal transfer problem is defined as follows. So I'll use this notation right here: p is for primal, if you want, or problem. And right, so if you take the rth power, then of course this object here is to the power one over r is the vast distance. All right, which has many applications in all sorts of fields, engineering, logistics. All sorts of fields: engineering, logistics, economics, machine learning. All right, now, and often one takes to be continuous, or you put some bound to make things nice. Now, the optimal transport problem admits actually many interesting variants. And so, for example, you can consider mu and u defined on different spaces, or consider many marginals, or consider two measures that are not both probability. Consider two measures that are not both probability measures, they have different mass. And you could also consider variants that impose additional linear constraints. And of course, you take the constraints to be linear so that you're still dealing with a linear optimization problem, which the originality problem was. So you don't want to drastically change the nature of the problem. Now, some examples that appeared in the literature are the following. So, and there are probably others. And there are probably others. So, alternative transport with capacity constraints. So, here you assume that the transport on the product space is absolutely continuous with respect to the Lebesgue measure on that product space. And moreover, its radon equal intensity is bounded above by some constant. Now, the invariant optimal transport. The invariant optimal transport. So you consider only transports that are invariant under the action of some group. Or the martingale alternal transport, which is the one that I'll focus on in my talk, where you consider only martingal transports, or if you want, joint laws or random variable X and Y with a given marginals, and such that the X and Y satisfy this relation. So the condition. So, the condition expectation of y given x is x. One could of course consider the cows out optimal transport. And here is the definition. I will not really go describe in any more detail any of these problems. I just wanted to mention that there are a number of variants actually that one can consider. I know these ones, there are probably other ones as well. And here I give some references for mu. Some references for who's interested. I'm only citing one paper per topic. Of course, there are many papers for every given topic, so this is an extremely rich summary, especially for MOT. There are quite a lot of papers. But yeah, so I had to stop somewhere. Okay, so far I talked a bit about OT. Now, let me talk of something that at first looks completely unrelated, and then I'll put the two together. So I'll talk about the discretization of measures. So, given a measure on your balloon space, how can you approximate it with a finitely supported one? Now, normally you're interested in an approximation that is optimal in some sense, perhaps among all the measures that are supported on most k-points. Now, if to measure the optimality, you use as metric the Wasserstein distance. Metric the Wasserstein distance, you obtain the so-called optimal R quantization problem of order K. So you take this, you look at the problem where you have a measure mu, you want approximate, so a probability mu, you want approximate to the probability mu hat, which is supported on most k points. And the approximation is done in the sense of the waster than distance, and you want to minimize this. This was This was well studied in the 50s at Bell Labs, and it's important in signal processing and in information theory. Now, discretizations often exist discretizations that satisfy additional constraints. For example, in the case of finitely many linear constraints, Chakalov's theorem says that sort of you can given a measure mu and finitely many functions. Mu and finitely many functions that are essentially your constraints. What you can do is you can find a discretely supported probability mu hat which gives the same integral to all of those functions. So this has m components. So this is actually m equalities. And this is finitely supported. And in fact, you can bound above the number of points on which it's supported with something that depends only on n and on m and even better you can choose And even better, you can choose the support of Mu Hat to be included in the support of New Hat. Now, there's also a martingale version of this result, much more recent due to Beigebock and Knutz, where they say if you consider X0, the family of laws of martingals, such that they start from X0, then mu, given the law of a martingale like that, you can approximate it with one that is fine. You can approximate it with one that is finitely supported and such that everything else holds here. The only difference is the number of points, which, of course, has to become a lot larger. And what's remarkable about this result is that the martingal constraint corresponds to infinitely many linear constraints. And nonetheless, with this special type of linear constraints, they were still able to prove this result. Okay, now let me conclude. Okay, now let me connect the two topics: optimal transport and quantization. Given finitely supported measures, optimal transport is a finite-dimensional LP, so it can be solved numerically with great efficiency, especially if an entropic regulatorization is considered. It is then very natural to compute the optimal value to construct finitely supported probabilities that converge to the original probabilities. And then this object here, one can compute with linear programming, and hopefully, taking limits of these, you can recover the original optimal value that you're interested in. Now, the question is then, okay, so this was of course commonly done in optimal transport. The question is, can you adapt the amount of methods to the case of constraint optimal transport? Transport. And analogously, about the optimal quantization, what happens under the presence of constraints. So let's call theta C the set of constraint transports. I'm being vague here about what type of constraint. It's up to you. I gave several examples before. Here, I just give questions so I don't, you know. All right, so I say that a trans, sorry, the two marginals are viable is if there exists at least a constraint transfer. If there exists at least a constraint transport from one to the other. So, in this case, you can ask questions like: okay, given a viable input, so viable measures mu nu, can I find viable finitely supported measures that converge to the original ones? And how can they be computed? And if you know, if I take such a discretization and I define the constraint optimal. Um, optimal transfer problem, right? Um, then, does is it true that the optimal value they converge, okay, when you apply them to the discretized quantities that converge to the other quantity. And if you can do all this, can you perhaps do even better? Can you choose this discretization so that it satisfies some additional timality property or some additionality? Property or some additional constraints. Now, I'll, so this was kind of general, right? But what I've actually done is only work on MOT. So I'll consider the MOT marketing LTL transfer problem. As I said, if these are finitely supported, this is an LP. It can be solved efficiently with an electropic regularization. There's a paper on the March that kind of explains how to do this numerically in a stable way. A stable way. And let's consider then the set of martingal optimal transports as the set of constraint transfers that I consider. So the red bit is the unconstrained and the blue adds the constraint, right? So if a Martingale transfer, then it means you initially need to ask this condition. Or once you have a transport to make it a Martingale transport, it additionally needs to satisfy this condition. And of course, trust in theorem characterizes the Trust in theorem characterizes the when is that two measures are viable. The set of autonomous transfers is not empty if and only if there the measures are in convex order. Okay, so then the questions that I stated before in a kind of general abstract setting become, given two measures in convex order, can I find finitely supported probabilities that converge to those measures and are still in convex order? And if so, how can one compute them? Now, this has been done in the literature. This has been done in the literature in several papers. So the first idea, which describes the ideal scenario, at least from my point of view, is to be able to define a discretization operator, let's say, that given a probability returns a probability supported on k points. And this operator has the wonderful property that preserves the convex order. So if you spit out to measures that are in convex order, the discretizations are also in convex order. Convex order. Well, it turns out that one such thing exists in dimension one. This was due to Baker, and it's done very explicitly in the following way. So this is the CDF, so cumulative distribution function of the measure alpha. You define some numbers in this way, and you take the following discretization: is a sum of deltas all with equal weights centered at this point. This is the discretization operator. And as you see, it And as you see, the definition itself uses, well, sort of, it only works for one dimension. Okay, so you can't, it's not even obvious how to generalize this. Now, Paget and Wilbert, the same year, came out with a paper where they worked out their case in Rn. However, so they do give this critization operator, which does make sense in Rn. However, oddly enough, However, oddly enough, it only preserves the convex order in dimension one. And moreover, it has other downsides. It only works for probability that are compactly supported and does not generalize when instead of having two marginals in convex order, you have finitely many. So are there other ways that perhaps instead of using this idea, some other ways to produce mu k and mu hat and mu hat like that? Well, we could apply different operators to. Well, we could apply different operators to mu and mu. Why not? And perhaps you could also relax the convex order according to the Martingal constraint. So instead of asking that these are exactly in convex order, you could say, well, they're almost in convex order. So the first approach was taken up by Alphonse, Robert, and Journal in this paper where they do something that I think is marvelously intuitive and at the same time not trivial at all to work out the data. Not trivial at all to work out the details. So, given two measures in convex order, what they do is just take two arbitrary financially supported measures such that this converges that. Now, these are not in convex order, so what do you do? You make them in convex order. You project the first one on the set of measures that are smaller than the second one in convex order, where you take the Wasserstein distance. You know, the Basterstein distance, and then you prove this projection, it exists, it's finitely supported, blah, blah, blah. So everything works, and you have actually convergence. Very good. And of course, you can do the same thing with the other way around. You can replace the second measure here with the projection of the first on the set of measures that are bigger than the first in convex order. And you have analogously this result. So I think from a kind of theoretical point of view, this is. Kind of theoretical point of view, this is very, very pleasing. There is a bit of a problem that how do you compute these things? Now, essentially, beta hat can't really be computed, whereas alpha hat more or less can, in the sense that if you take mu hat to be an empirical measure and analogously new hat, then the corresponding alpha hat that you build this way solves a quadratic. This way solves a quadratic optimization problem with linear constraints, and so you can actually compute it numerically. And then you can show that these random measures converge to these deterministic measures almost surely. So it's more or less a law of large numbers, right? Okay, so this is quite good. It does, if you want, have a bit the disadvantage that these are, you produce random measures instead of kind of. Random measures instead of kind of deterministic ones. Now, as for the second approach, if you remember, here I said you could relax the convex order Martingale constraint. Now, I'm going to say very little about this. So there's a paper by Gua and Auboy where instead of asking the Martigl constraint, they ask this quantity here to go to zero instead of being exactly zero. And well, and they work in that setting, since it's not too closely related to what I do, I'll kind of. Closely related to what I do, I'll kind of just mention this and move on. All right, now, what is that we did instead? So instead of looking at measures, the whole idea is very simple. Instead of looking at measures, remember Strassen Theorem, look at random variables. When you look at random variables, everything is pretty much obvious. So given two random variables, so random vectors, I should say, such that Say, such that they're a martingale. How do you build finitely supported approximations such that they're still martingales? Well, everyone knows how to do that. You take conditional expectation with respect to a finite sigma algebra. So you take a partition of the space made with k elements. You consider the sigma algebra generated by this partition. You call it BK. Since the space B is separable, there exists. B is separable, there exists some such choice such that when you take k to infinity, this sequence of sigma algebras, the soup is the boron sigma algebra on this whole space. Now, what happens? So, and I choose CKs in such a way. Of course, there's many such choices. And then what you do, okay, you define sigma k of x as the pullback of this sigma algebra, and analogously for this, as you do. Obviously, for this, you do the pullback using both random variables. And so it's the smallest sigma algebra that makes X measurable with respect to this finite sigma algebra on the image space. And then you condition. And then what happens? Well, this is made by most k points because you're conditioning over a sigma adjacent generated by a partition that has k points. So just by definition of condition expectation. Just by definition or condition expectation, you can write it explicitly what it is, and you can actually compute it also by taking integrals. So, this is finitely supported. Analogously, this is finitely supported. You can compute them explicitly. The tower property of the conditional expectation gives that these are martingals. And since the sigma algebras converge, then by the martingale convergence theorem, these random variables converge to that random variable. So, I mean, really, once you have the right idea, it becomes very simple. Now, this has advantages, but also disadvantages. So, and it's not quite so obvious. So, let me point them out. So, a pro is, of course, the simple proof. It's almost no proof at all, really. Another is that it works in infinite dimensional without any additional work. It gives an explicit expression for xk and yk. For xk and yk, and so for corresponding further measures, you just compute it by taking calculating integrals, which you can do numerically. And yeah, so that's what I wrote. And it outputs no random approximations. Now, what are the cons? There's one con that is actually quite big, but is not obvious. When I did this stuff, I did not start from X and Y. From X and Y separately from two random variables with laws mu and u. I started from the joint, from the couple xy. So, and when I took condition expectation, I mean, I'm really using the fact that I know the joint law of this thing. So, essentially, what I'm doing here without really saying is that to do this stuff, you actually need as an input a martingale transfer between those two measures. So, mu and nu are the inputs. You know that the martingale: Are the inputs? You know that the Martingale transport exists, but to actually compute one, well, that might be non-trivial. Now, if you're given one such transport, then you can very easily essentially calculate mu k mu k as i have written here. But what if you don't, right? So, well, in one dimension, the good news is many people have come up with ways to explicitly construct martingale transparency. Explicitly construct martingale transports between two measures in convex order. In RN, I don't know of any paper that does this, but I had a conversation a while back with Pierre Laboder. He told me that he was extending the bus construction to the case of RN. And I leave it at that. I don't know if it's finished or not. I don't think any paper is out about this. I might add that in many I might add that in many examples, when people normally build examples, they start not from UNU and convex order, but actually from a Martin L transfer, because it's, you know, by far the easiest way to check the two measures are in convex order is actually to start from a martigal transfer and take the marginals. But if you actually start from numerical data and you need to build the transport, well, then that's not obvious. Now, so I don't have so much time, plus, this theorem. Time plus this theorem, I'm not so sure if it's new, frankly. It's new to me when I wrote it, I thought of it myself, but I don't know quantization that well. So I think it's likely that this theorem was known before. What does it say? It says that there exists an optimal choice, or so there exists a choice of finite partition of the space which minimizes this object here where x. This object here, where xk is, as I've defined before, the conditional expectation with respect to the sigma algebra. And this, and moreover, one can explicitly say what is such a partition. Such a partition is given by the optimal Veronoid two quantization of mu of order k. Now, I won't really give the proof, but the proof, I mean, I just wanted to show you the proof is really quite simple. And by the way, I've been a bit sloppy because in the statement, I should have assumed that mu has density. And I should have assumed the mu has density. So let's say if you're sorry, I mean a REN density respectively Lebeg measure. And but you know, the proof, as you can see, is just a couple of slides. It's really a full proof. It's quite simple. The only property that is really using is the fact that the condition expectation in the case of R equal 2 is a projection, right? Okay. Now, one can generalize a little bit what I've done. One can generalize a little bit what I've done. So, before I took yk to be you know constructed using the condition expectation and xk to be defined, sorry, let me show you like this, okay, starting from x. Okay, however, um, I could have actually equally put y instead of x here. I would have got the same result thanks to this assumption. So this. This assumption. So, this suggests that you could consider an arbitrary finitely valued random variable that converges to y. So this doesn't need to be obtained taking condition expectation. And then what you can do, you define xk in this way using yk, not using x. And then what happens is then this forms a martigan by construction and they converge to what you had before by the same proof as before. What you had before by the same proof as before. So it's, you know, it's kind of nice. Okay. This generalizes things. However, it also has an additional benefit. So if you want to do this stuff numerically, it's a bit of a problem that, as you might have noticed before, the number of points in which the second random variable is supported grows with a square respect to linearly. And in practice, this means. this this means you know if it becomes harder in in dimension bigger than one um to you know to compute things um so um so what happens um here by choosing yk differently you could choose it to be a multiple of k say 10 times k 100 times k instead of k squared and in that case you know this approach would numerically You know, this approach would numerically be better. However, the link with optimal quantitization will be lost. I also mentioned some sort of possible extensions one could consider if you want, you could consider additional constraints since you know that by Chakal's theorem, you can discretize a random variable and still satisfy the constraints. Though, in practice, how do you actually accomplish some such YK? I mean, in Such YK. I mean, in the case of no constraints, I told you how. In the arbitrary case, Chakalo, as far as I know, it's a kind of abstract type of result using Karate-Alduris theorem and so on. But there's no, I don't know if one can really compute things explicitly. And analogously, the Martingale version of that using Beigerbukenut's result, you can assume this and this. Now, finally, there's for For optimal martini and optical transfer, there is a stability result by Huyo and Pammer where everything works as well as you might hope. However, they do this only in R. And then they say, we think that our approach can also be adapted, cover higher dimensions. And well, we'll see if someone does it. But it's a bit too Um, but you know, it's a bit too outside the scopes of this paper, but uh, I wanted to put it here because um, the whole point of discretizing was you know, that it's useful because you can calculate this explicitly. And so if this converges to that, then you can also calculate that explicitly. This is a somewhat silly remark, and since I'm late, let me skip. So, as a summary, we found the simple construction, they split. Construction that spits out discrete, you know, finally supported measures that converge to given measures such that it preserves the convex order. This construction emits several variants. These can be chosen to satisfy some optimality property. For example, this is the for non-equantization of mu. In other words, it's the measure that minimizes this. And while we are working on some additional constraints, optimality properties, and actually also some numerics. And I And I hope that within a couple of months we should submit. And this concludes my talk. Thank you for your attention. Sorry, I went a bit overboard. Okay, thank you very much for the nice talk. Are there any questions or comments? Yes? Yes, please. Yeah, no, can I ask you how to do any research actually because Because it would be interesting to compare other approaches in particular. We've already done some numerics, it's just I haven't shown them yet. But for example, in a paper by Alphonse, he considers an example where he has two uniform random variables, one on a larger set, so they're in complex order. And well, we essentially using our construction, we've also Our construction, we've also more or less obtained similar results as he has. Okay, so we've um, and what I mean is that not only we, you know, we illustrated convergence here, but actually in that setting, we also showed that indeed, you know, this converges just numerically, okay, it's not a theoretical result, but in that setting, this works. And the interesting bit for us is that this is the first result in multi-dimension, really. Multi-dimensional, really. So, we're trying to get the numerics to work at least in R2. But if you do that and have the issue of the k-squared that I mentioned before, then we don't quite get to k being big enough that you have convergence. So we are now trying to either use some other YK or new entropic regularization to see if things speed up a bit more and then we get there also in higher dimensions. Do you have any idea on the relation between? The relation between the speed of convergence to the distance between your original vertical transport to the optimal vertical transport? Here, I don't really. So, what is that we do? Let me think. I can see if you have we don't use the optimal martingale transport. However, yes, we do have some but We do have some bound, kind of a formula, let's say, for the, if you remember, the Warsaw Stein distance, right, between these two objects. This bound uses some quantity that you calculate using the transport pi that essentially you assume given when you really start this construction here, right? Right, so. What happens is my interest would be that this theta is close to being the optimal marginal transport bound. Right. And then discretized ones should also be close to the discretized. What happens is if sorry. That's it. I was just saying that somehow how well this will perform for a given marginal option. So the only thing that we notice in that case that is special, let's say, is this result that I kind of skipped because I was a bit in a hurry. Essentially, if you start with the theta that is already optimal when you do this construction, what happens is this result that is what you want actually holds just for the very specific discretization. Specific discretization that we build, whereas back of and PAMER they use arbitrary sequence that are discrete and converge and so on. Here instead, just at the mu K and U K they converge. If they're built using already the optimal transport, then actually the limin of the inf equals this object here on the right-hand side, because of course this equals that. But I don't see this as being a useful result because the whole point of discurtizing was you want to call. Was you want to compute the optimal value. And so you discretize, you compute the optimal value in the LP, then you take limits, and in the limit, you get the other one. But if you already need to know what the optimizer is to actually do this, then it's not useful. The same time as Junior Goodwood, also showing this stability. Johannes Wiesel has a paper on this. Yes, I see. Okay. The audio is terrible, by the way, Jan. Okay. Martin, you have a question? Yeah, so there's a comment you said. So regarding the stability, there's a recent paper by Nicolas Julier and Martin Brokerhov, who essentially showed that stability of martinget transport in high dimension does not work. Aha. Okay. Good question. I also want to excuse me. Yes, I also wanted, excuse me, the interruption. I wanted to remark the same thing. Of course, in the case of stability, you cannot choose the mu k and mu k that's the problem. They are given to you. Okay, so what you mean is you like if you take arbitrary ones, then you don't have convergence, but for special ones, you might have convergence. So it might still be that in this setting here, things work, but okay, thank you. I didn't know about that. Okay, thank you. I didn't know about that. I'll definitely check it out. Okay, other questions or comments? No, so if not, let us thank the speaker again. And I think we can switch to the next speaker. 