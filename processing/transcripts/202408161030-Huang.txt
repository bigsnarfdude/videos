About some recent work on algorithmic thresholds for the random perceptron. And this is joint work with Mark, who we heard from earlier this week, and Nike, who is attending this conference remotely. So here's a brief outline of this talk. First, I'll introduce the random exceptron and related projection to the seed problems. Then I'll state our main resolve, which is an algorithmic threshold for these problems for a class of stable algorithms. Of stable algorithms. Then I'll talk about the main ideas of the proof of hardness. Towards the end, I'll talk about how we get matching algorithms and some applications to specific models. So let's get started. We'll start with the projection pursuit problem, which will turn out to be a slight generalization of the random presumption. So this was introduced by Diaconus and Friedman. The problem is: suppose we have a cloud. Suppose we have a cloud of m points living in n dimensions. Then, if we project the set of points onto a low-dimensional subspace of our choice, what projections are possible? So, the original motivation for this was in some data visualization applications. So, thinking of how to visualize a high-dimensional data set, and the way to do it is to kind of project it onto one or a couple of dimensions. Of dimensions. Throughout this talk, we'll collect these endpoints into the rows of this m by n matrix, which we'll call capital G, and a projection simply amassed by multiplying this by some other matrix. And we'll be mainly interested in the case of one-dimensional projections. So this projection can be thought of as a unit vector. So formally, the problem is as the vector u ranges over the vector u ranges over the phoenix sphere. What are the possible empirical measures of inner products of u with these books? So here, this delta of j dot u, this means the delta mass with value out of j. So this is some empirical measure, and throughout this talk we'll abbreviate this as the law of capital of G times V. We'll study the setting where the entries of V or IAD. Where the entries in the V are IAD Gaussians. So the points in this point cloud are IAD samples from an isochron Gaussian or V. Then in this setting, it's known that if the aspect ratio M over N diverges, then the work of Diaconus and Friedman showed that in the limit, the only feasible empirical measures of inner products all limit to a standard Gaussian. So this behavior is not that. Behavior is not that interesting. But it's known that in the proportional regime where M and N are of the same order and both divergent, then non-Gaussian projections do exist. So this is the regime that we'll study in this topic. This is closely related to the random perceptron model that we heard about many times earlier this week. So, as a reminder, this is the interception of either the Boolean cube or some Boolean cube or sphere of radius root n with some IAD random absences. So formally we can define this as follows. We let G be this IAD Gaussian matrix and kappa be a real parameter standing for the margin of these half spaces. Then every row of G will determine a half space, namely the set of all x whose inner product with that Gelsha scaled by root n is at least Kappa. Is at least Kappa. So the random perceptual model, which we call it SMG, is just the subset of a sphere cube surviving all of these perceptions. So a very basic question about this model is, is this solution set not empty? And the connection to the protection of soup problem is, well, modulo some rescalings of variables. Rescalings of variables. This is just asking in the perfect setting: is there a feasible empirical measure that's supported on the set kappa to plus infinity? And the perceptron problem also has several applications. So its original motivation was a toy model for a single layer of neural network. Think of the variable x as representing a configuration of synaptic weights and the rows of the matrix. And the rows of the matrix G as a collection of random patterns you want to memorize. So the random perceptron model was exactly the set of neural weights that successfully memorized all of these patterns. So we can also define a symmetric version of the random conceptron where the constraints ask that all of these inner products lie in the whole minus kappa to kappa. So this was introduced by Aubin. This was introduced by Alvin, Will, and Severova. And this is exactly an average-paced version of the well-studied discrepancy harmonization problem, which goes back to the work of Spencer on six standard deviations of this. So, there's been a lot of work on this random perceptual model. And historically, most of the work has been about statistical properties of the model. So, questions about this. So, questions about the typical size and structure of this solution set. So, one well-study problem is the capacity problem, which asks: is there a critical constraint density where this solution set goes from non-empty to empty with a high probability? So, if there's not a lot of work on this, in this talk, we'll mainly focus on the algorithmic properties of this model. Model. So here are three related formulations of the algorithmic problem, and we'll end up getting algorithmic thresholds for all three. So in all three setups, we fix some constraint density, alpha, and we have this IAD Gaussian matrix. And our goal will be to algorithmically find a point X with certain properties. So in the projection pursuit setting, we're given a target measure of U. Measure of μ. And our goal is to find x algorithmically so that this empirical measure of inner products is close to μ in, let's say, Wall Street distance. And to determine for what targets mu this task is possible. In the constraining satisfaction setup, so this is close to what Shaw Pen was talking about earlier this week, we're given some subset I of the real light, and our goal is to find x. And our goal is to find x so that all of these inner products land in the side line and to determine for what constraints of these is possible. So the classic perceptron corresponds to I as the interval kappa 2 plus infinity. And finally, the optimization setup. So this is close to the random optimization problems that Mark was talking about. Here we're given some activation function phi. Some activation function phi on the real line, and our goal is to find x optimizing this Hamiltonian, where you sort of add up the evaluations of phi on these inner products. And all three of these setups can be stated with x constrained to the cube or the sphere. So these are called the easing and spherical setups. The way to think about how these three setups are related is, roughly speaking, the Roughly speaking, the projection pursuit setup is the most general, and the other two are kind of special cases. So, namely, the constraint satisfaction setup asks, is there a feasible empirical measure that is supported on the interval kappa 2 or on the interval I? And we can reduce optimization to projection pursuit because if we understand what set of empirical measures were feasible, then optimization just amounts to Maximization just amounts to maximizing the integral of phi against the visible order of all metrics, as long as phi is regular cross. Maybe say a little bit more about this first case. So X is deterministic or depending on coupled with G or what's the situation? Right. So good. Here, think of G as the input of your algorithm. Then your algorithm receives G and it wants to. Algorithm receives g and it wants to output a point x solving one of these cortes. And when you say the first one, law of this, this is considering what is written right here. X or gene X is a pair? So I mean this is like the law of the empirical distribution of their products. So the empirical empirical thing. So this is like let's write it down because throughout the blog. Using this throughout the block. Yeah, this is a good place for questions. So, are there any more questions? So, roughly speaking, our main result will get an algorithmic threshold for Algorithmic threshold for all three of these problems. So we'll first state this for the projection pursuit setup. So for any constraint density, alpha, we characterize as a function of alpha the set of achievable empirical measures of our products, where x is output by any member of some class of, say, wall things. And this works in both the sphere and Q Z. Settings. In the spherical setting, the optimal algorithm was also obtained in recent independent work by Monten Orientel. So our work gives the maximum hardness result and the algorithmic threshold. And this is stated for perfection pursuit, but it also implies algorithmic thresholds in the algorithm settings by the productions that I talked about over. The algorithmic problem has also been the The algorithmic problem has also been the subject of a lot of recent work. So, there's been work on algorithms and partners' results for a variety of random perception models. Just to highlight a few of these, the work of Ahmed Al-Alawi and Mark also develops an incremental type of incremental AMP type of algorithm for the negative sterile perceptron. For the symmetric EasyMPTRON, a pair of papers by Gemarnik. Of papers by Gemarnik, Will, Kizilda, and Shu shows Hardness results for stable and online algorithms. And in the asymmetric ising perceptron, so Xuan Ping talked about this very nice work earlier this week, which gets strong algorithms and Hardin's results for IPS. And a salient feature of many of these works. Feature of many of these works is that algorithms seem to succeed even though the solutions is very clustered, with typical solutions being isolated. So, as we heard earlier this week, this violates a long-standing intuition that the clustering of the solution space causes hardness and sort of force the community to rethink the source of algorithmic hardness. And in light of these phenomena, physicists came to predict that algorithms That algorithms find certain rare dense clustered substitutions. And the presence or absence of these dense clusters is maybe responsible for algorithmic trajectory. There is some rigorous support for this picture by these works, which we also heard a bit about early this week. So next I'll talk about our main result, which is this algorithmic threshold for these problems. For these problems. So, recall that we have this IID Gaussian matrix, and our goal is to characterize for x output by some stable algorithm the set of achievable empirical measures of airport x. So, our result will be a sharp algorithmic threshold for a class of Lipschitz algorithms. So, we're thinking of an algorithm as a map from the space of m by n matrices to r to the m. To R to the M. And we're asking that this map is below 1 Lipschitz for some big constant below 1. And this class of algorithms includes many of our favorite algorithms, like gradient descent, electronic dynamics, and AMP for constant time, but not things like SOS or Liberty Paul models. And we'll see that the optimal algorithms will follow the incremental. Will follow the incremental AMP framework developed by Montavari and Columbiers. So, this is a class of iterative algorithms which will sort of start at the center of the sphere, or start at the origin, and explore outward by these little orthogonal steps towards either the surface of the sphere or a corner of the cube. And the hardness will follow similar ideas to the branching of the GP framework that Mark told. Framework that Mark talked about earlier this week. So here's our main result. For any X output by a Lipschitz algorithm, the set of achievable empirical measures of components, so this will be some function of the constraint that's in the algorithm, is given by some explicit stochastic control. So just to unpack a little what that means, we define some stochastic differential. We define some stochastic differential equation whose coefficient processes have to satisfy certain constraints. Then any given choice of coefficient process will drive this SDE to some random variable at time one. So then these constraints induce some sort of set of feasible random variables you can get at time one. And the claim is that the laws of these random variables are precisely the set of achievable cohorts. And it'll also follow over analysis that elliptics algorithms find some sort of dense solution cluster which gives evidence for this sum of physics heuristic. So the SDA description is slightly complicated to state. So I'll first state it for the simpler case of the symmetric spherical model. So here x lives on the sphere, and the simplification is that instead of Simplification is that instead of asking for the set of feasible empirical measures of the components like we have here, we consider a symmetrized empirical measure where we sort of drop the sign and ask for the absolute values of the components. So we'll show this as described by the following SD. So it's initialized at zero. Here Bt is a standard Brownian motion. So this is just some diffuse sync cartigal with With diffusive parameter sigma t. Here, sigma t is some progressively measurable process satisfying this important budget constraint that I'll talk more about in a second. It's a random process. It's just a one-dimensional number. Yes. Yeah. So our main result for this setting is that. Our main result for this setting is that the achievable empirical measures are precisely of the form of law of absolute value x1, where x solves this SDE for some legal control signal. Any questions about the statement of this? Rensive just means adapted to VT. Module is on measure theoretic issues. What's alpha? Alpha is the constraints. comes very nicely. Or also achieved? Yes, it's a two-sided statement. So all of these walls are mu. So I should think of mu as the solution, right? The problem? Yes. So mu is this. Yes. So every solution is of that form, ideal of that form, somehow means this little thing you find who's identifiable. Say that again. Say that again. And that form somehow was equivalent to what you call dexter solutions? Yeah, so that will turn out to be true. I think of the budget constraint as something about a testimonial energetic cost of exploration. Yes. I'll say more about that in a second. I imagine this is maybe coming later, but does this I imagine this is maybe coming later, but does this contain any like discrete measures? Right, right, right, right. So this is like a discrete measure, and this limiting measure is not necessarily discrete. So when I say achievable, I mean in like an approximately. So my question is, does this class that you define contain, for instance, anything's one or two points? Is it possible to force for Possible to force, for instance, that your empirical measure is supporting a two point? So you can definitely force it to be supporting at one point. If alpha is less than one, then you can take Sigma to be the all-zero process. Two points, I think is probably doable, but I don't use them. Any more questions? Okay, so here's how to sort of interpret this SDE, which I've rewritten here. So let's consider this XT process at some time t. So this is some random variable and some law. Then we can think of this probability distribution as some collection of particles. Then roughly what this Then, roughly, what this budget constraint will say is that every particle in this probability distribution wants to evolve like a standard drop-in motion. But we have some amount of power to make some particles go faster or others go slower. So here, the cost of making a particle move diffuse with speed sigma t is this sigma t minus one squared. So you can diffuse. So, you can diffuse with speed one for free, but to go either slower or faster, you have to pay some cost. And this budget constraint says you have some amount of total budget that you can allocate over all your particles at any given time. So, in this picture, maybe the current particle density looks like this, and we want to make the particles in the middle go a little faster, and the particles on the sides go a little slower. Go a little slower. So we apply some control within this bug constraint because that. And then if you evolve this for a little bit of time, then after that, maybe the particle events influence on this. Let me emphasize here that although this SDE is sort of stochastic, the resulting description is the determinants of one. So think of this SDE as describing a set of kind of legal ways you can manipulate. Ways you can manipulate this evolving measure. And the evolution on the space of measures is a deterministic one. And there's some space of legal evolutions on measure space. Questions about the state? There's a way to choose sigma t to make it actually have bounded support or one-sided? Yeah. Yeah. Yeah, yeah. So, for example, you can freeze, like, you, you can say, like, if a particle reaches like 10, then you freeze it. As long as that's within the budget constraint, then you freeze it. Yeah. So, the asymmetric, so the general stereo perceptron, where we don't impose any symmetry, can be addressed by a slightly more complicated version of this SDE, which is as follows. This SDE, which is as follows. So now this SDE will have both a drift piece and a diffusivity piece. And now there's sort of three things you get to input. So you get to pick progressive, so adaptive processes Bt and sigma T, which will kind of control a drift and variance, as well as an arbitrary increasing indifferentiable function p, whose meaning I'll talk about later on. Later on. But these three inputs have to satisfy this slightly more complicated function constraint. So, our main result in this general setting is that the achievable empirical measures are precisely the form law of x1, where x solves this SDE for some valid inputs, B, sigma, and P. And the relationship between this and the earlier SDE is if you plug And the earlier SDE is if you plug in p to be the all-one function, then p prime is zero, so everything simplifies if you exactly recover the simpler SDE. We also get a slightly more complicated result for the easing percept problem, which I'll talk more about later. But roughly speaking, it will be a system of two coupled STs. So next, I'll talk about the main ideas of the proof. Talk about the main ideas of the proof of hardness. So just recall that we want to determine the set of empirical, or feasible empirical measures for x output by a Lowstrip's algorithm. Then one of the main ideas of the proof of hardness is that every algorithm can be associated to a certain dupe parting. So to set this up, let's define a matrix value Brownian motion. Valued Brownian motion Gt. So this is just an M by N matrix where every entry is a standard Brownian motion. And at time 1, this of course has the same law as our problems is. Then we define this Dew Martingale XT to be the conditional expectation of the algorithm at time 1, given the Brownley motion revealed to time t. So at time 1, this is the So at time one, this is the algorithm output. And this will, Duke-Martingill will sort of start at the origin and gradually explore to the surface of the sphere. So that's the Duke-Martingill. And the second key idea is to follow a certain evolving empirical measure. And this is also how the SDE will enter. So let's define the empirical measure mu t at time t. Empirical measure of mu t at time t to be this empirical measure of inner products of the Dube-Martigal at time t against the rows of the measurements around the motion at time t. So at time one, this is the thing we eventually care about. And as time goes from zero to one, this will trace some path in empirical measure space. And the main point will be that our SDE will exactly That our SDE will exactly describe how this measure can evolve over time. So we'll see that, more precisely, mu t will be the law of xt for some x that solves this s. And in particular, the budget constraint that I showed you will describe how this empirical measure can kind of change in a short amount of time. And as a result, well, And as a result, well, any algorithmically achievable by elliptics algorithm is of the form μ1, so it's described by the law of x1 for some estimation. One crucial property of this Duke-Berningale will be that it has some concentration properties that we'll be able to exploit. And one consequence of this concentration will be this orthogonal increments property as well as. As well as let's consider any 2 times s and this inner product of this increment against xs. So by elliptic concentration, this inner product concentrates near its conditional expectation, which is zero dynamic value. So this means that if you take any kind of macroscopic but smaller discretization of time, Discretization of time, then this Duke Martingale will, if you like, trace the positions of this Duke Martingale at those times, then you'll get this path of this kind of small orthographical increments. And this looks like the, qualitatively, like the behavior of the spin-glass algorithms, like incremental A and P as France algorithm that we discussed earlier. And this is sort of an important intuitive reason. Sort of an important intuitive reason why these algorithms end up being the best among the TRIS algorithms. It's also related to the main ideas of this branch of OGP framework that Mark talked about. So if you recall from Mark's talk, the idea there was to kind of construct this correlated ensemble of problem instances and then run the algorithm on each one to get this constellation of functions. Constellation of functions, then the overlap between any pair of points on the right will concentrate near some number. So this constellation assumption I'm treated. And then you can exploit the fact that the algorithm has to work on all of these points to extract some kind of algorithmic hardness result. So in this talk, we'll be able to extract the algorithmic hardness directly from the Directly from the concentration and mardingality properties of this new martingale, so this tree construction for the most part won't appear. Okay, so the main work in the hardness bound is to determine the possible evolutions of this moving empirical nature. And the way we'll do this is by determining what evolution Determining what evolutions are possible in a small number. So, if we know the current value of, we want to answer the question, if you advance time a little, what empirical measures are possible. So we can visualize this empirical measure as a collection of m particles, so just the m atoms of this empirical measure. And these are exactly the entries of this record. Then, if you advance time by a little bit, each of these particles will move to some new location. So, our goal will be to determine what types of particle evolutions of this form are possible. The way we'll do this is by discretizing space into some little buckets. Some little buckets. And for any increment of this type, we can define a sort of bucket-averaged drift and variance. Then in the limit, when you take the space and time discretizations to zero, these will limit to genuine SDP coefficients. And that's where this stochastic control description will come from. Just as a note, so all this analysis will happen at the level of bucket aperture. Analysis will happen at the level of bucket averages. So we'll end up getting not a pathwise description, but a description at the level of evolutions of measures. So Fonker Planck equations, if you know what that is, but if you don't, that's okay. Okay, so next let's see how this how we trace this evolution. So we'll do it for, we'll first do it for the simpler case of the symmetric struggle model. So, okay, recall that we have this measure Vt, which is the law of GT times T over N. And tracing the evolution of this is slightly complicated because there's two moving parts, namely the Gaussian and the T molecule. But it turns out that for the symmetric case, it suffices to track a sort of simpler A sort of simpler empirical measure called utility, where the Gaussians are sort of already equivalent. And the only moving part is equals. So roughly speaking, this is because in this symmetric setting, the optimal Duke ordeal will stay close to the origin until like time, very close to one, so time 0.99, and does all its movement in the last. In the last typing of the time. So then, if your Doom Ordingo looks like this, then over here, you can think of the Gaussian as being already revealed before the Doom Ording does anything interesting. Okay, so then let's track the evolution of this simpler empirical notion. Let's say at some time t, the particles look like this. Particles look like this, and I've drawn in here the boundaries of the buckets. Then we can define a bucket average drift and variance as follows. So here, this quantity inside the sum is the sum rescaling of how much the ath particle will move into this time interval. So we have this potential. We have this picture of here are the particles at time t, and here are the particles at time t just as m. Then each of these increments is like ga changing x over root n. So this is just some rescaling of that. Then we define the drift of a bucket to be Of a bucket to be the average of this increment over the atoms in that figure. And the variance of that bucket to be the average of those increments squared. So these are the things that will eventually limit to SD coefficients. Then the main thing we want to determine is what drifts and variances are possible. This is sort of a key type. It turns out that in this setting, all the drifts are zero based on concentration. Hard concentration, so there's nothing interesting happening with the drifts. But the variances are genuinely non-trivial and need some work to be understood. So let's simplify further to the case where all the particles live in the same bucket. So let's forget that there are multiple buckets. Let's think about this thing. Then the set of possible variances will come out of a random variance computation. So this variance is just some quadratic form. Variance is just some quadratic form of some unit vector against a Boucher matrix. So we can understand the set of possible variances will just lie in the spectrum of this Boucher matrix. So you've got some set of allowable variances. And you can rewrite this, the result of this Montana-Pasteur law as this interval. This turns out to be equivalent. And you can recognize. And you can recognize this as some simplified version of the budget constraint, where you have a diffusivity minus one square type of possible element. More generally, this random matrix, a slightly more complicated random matrix calculation will also address the case of many buckets. So here the variance of each bucket is the inner product of a unit vector against some. Against some which are matrix corresponding to the bucket. And we want to determine what tuples of variances are possible. We'll do this by bounding, we'll determine the feasible set of these variances by bounding all linear combinations of these variances. So for any scalar weights here, we can look at this linear combination of gamma B times variance B. Of gamma B times variance B. And okay, so this is the quadratic form of the same unit vector against this linear composition matrices. And so it's bounded by the top eigenvalue of this. And fortunately for us, free probability tells us exactly the value or the top eigenvalue of this. So then this gives us a bound for each of these linear compositions. Then, if you kind of intersect all of these high probability bounds, then you end up finding that the set of feasible variances lies in this complex one. And you can recognize this exactly as a discrete version of the budget screen. So, you have this average over particles of this diffusivity minus one squared. So that's So that's how we derive this discrete budget constraint. And then when you take all the discretizations to zero, you end up with this spherical symmetric testing that I showed you earlier. So these variances will exactly limit to this progressive control process. Okay, so that's roughly how we get this SDE and like. This SDE and budget constraint in this metropolis. One point that I glossed over is how to go from this discrete particle process to this limiting SDA description. And this is one of the sort of key technical challenges of the paper. I won't say much about it today, but just some of the key ideas. First, from some textbook type of First, from some textbook type of Koblorov estimates, this discrete process will limit to some semi-varnial, but it's not clear that the semi-varnial is the solution to some STE. So the way we extract the STE is using some fact that if the occupation density of this semi-Martingale is regular enough, then we can read off SDE coefficients that will have the same time, or the resulting SDE solution will have the same time. Or the resulting SV solution will have the same time modules as I said working. I won't get into that in this whole group. So that's kind of how we get this SDE description in the symmetric piece. And in the general case, the derivation will follow most of the same ideas with a few more tricks. So in this, let's stick to the stirable model, but now no longer. The spherical model, but now no longer impose any symmetry. So now we want to track this more complicated empirical measurement too, where both the Gaussians and the X are moving in time. So now the increments of these entries will have a slightly more complicated form. So it will turn out to decompose as a sum of three terms, whereas previously we only had. Whereas previously we only had this middle term. And this middle term was a controlled diffusivity, but now these three terms will be a drift, a diffusivity, or a control drift, controlled diffusivity, and a fixed diffusivity. So this last term is sort of a Gaussian that you can't do anything about, but these first two terms can be controlled through the choice of the press. So we'll again want to do So, we'll again want to determine the set of feasible drifts, variances, and covariances. So the drift of a bucket is kind of the bucket average of the drift term. The variance, as we saw before, is the bucket average of this diffusivity squared. And the covariance will be the bucket average of these last two things. So if we understand kind of the feasible set of these three things, then we can again extract the last two. Excrap the ST. And we're able to do this using a slightly more complicated version of the thing we saw before. So we'll determine the set of feasible quantities by determining or by bounding all linear combinations of derift squared, covariance squared, and variance. So this is some slightly more complicated free probability calculation, but each of these linear combinations turns out to be bounded by the top eigenvalue of sum. Bounded by the top eigenvalue of some spiked random turns. So we can calculate that with frequency. So we get a bound of this form for every possible linear combination and intercept gives us our budget string. So if you do all that, then you get this more complicated SDE for the general spherical perceptron. For the general spherical perception, and we showed that this SD describes the achievable piracy measures by motion software. So, up to now, I haven't really talked about the physical meaning of this p function, so maybe I'll say a little bit about that. So, the p function will turn out to parametrize a certain radius schedule of the algorithm. So, let's define this radius schedule, chi, to be the Schedule chi to be the expected square norm of our Duke Martingale overhead. So, this is some measure of how far from the origin of the algorithm is at Kai. And okay, it turns out by Lipschitz concentration that the square norm of this du-Mernegel concentrates near its maximization. So this will genuinely characterize with high probability where the algorithm is. With high probability, where the algorithm is of every kind. And it sort of makes sense that this should be an input to the SDE because remember the SDE is tracking the possible evolutions of this type of empirical measure. And this has two moving parts, the Gaussians and the DuMartigil. So this describes how fast these two things move relative to each other. And we show that if we're in the symmetric If we're in this metric case, that the optimal choice of chi is the backload one, which is zero for most of the time, and rapidly increases to one corresponding number. This corresponds to the choice of P is one. In that case, this recovers the simpler SD. I'll just say a little about the easing perceptron. So, here we need to track, when we're dealing with ising spins, we need to track We need to track the evolution of not just this empirical measure of products, but also the coordinates of our iterative XDE. So this will result in a system of two SDEs that interact through a shared budget constraint. So I'll just state the result for the symmetric case. There will be another result for the general piece. Now we have two STEs, the X process. The X process governs the evolution of μ, and now there will be a new Y process governing the evolution of μ. So this Y process will be another diffusive cornea. And the main property is that it needs to be a plus minus 1 at time 1. So this is because we have to end up at a 1 or a minor Q. And then these two SDEs. And then these two SDEs interact through this shared budget constraint, where the control of the Y process determines how much budget you get in the consequences. So that's the flavor of the result. And we showed that this describes the feasible empirical measures for this measured using Conceptrum. And for the general using Conceptrum, it's a simpler kind of result. Okay, in this last Okay, in this last part, I'll talk about how we get matching algorithms using some approximate message messing. So, recall in the hardness proof, we had these two protagonists, this matrix Brownie motion and this Duve-Martingale. And we said this Dude-Martingale comes with this algorithmic radius schedule, chi, which is shown here. And in general, this is a kind of arbitrary increase function. Per increasing function. Though, in the case of symmetric models, the optimal choice will turn out to always be the backload infrared, which is zero for most of the time, and then rapidly increases. And this Dube Martingale does this kind of orthogonal steps, which looks like the behavior of long system oxales. So, okay, what is So, okay, what is approximate message passing? So, Alex talked about this in his talk earlier this week. It's a class of first-order iterative algorithms following this type of general template. So the main kind of procedure is applying the sort of entry-wise nonlinearity and doing a latrice modification, then correcting this type of non-profit recovery. The limiting behavior is well understood thanks to the state evolution construction of volatile AIT Montenars. And incremental AMP is an implementation of this general template, which can simulate certain SDEs. So this was introduced in the work of Montamari and used in the recent paper on spherical projection pursued by Montamari and Mitchell. Their algorithm consists of Their algorithm constructs a sequence of iterates so that these impervable measures can simulate our STP with kind of the backloaded radius of chi is approximately zero. So this will get the optimal algorithm for the symmetric perception and match our hardness result. We introduce a slightly generalized incremental VMP. Slightly generalized incremental VMP, which can simulate this SDE for a general rating schedule. So, the main difference with the earlier SDEs is that in these first-order iterations, we don't always use a fully revealed disorder matrix. Instead, recall that we had this matrix Relev motion, which at time one is the disorder matrix, but earlier on is this kind of partially revealed version of the disorder matrix. Then, in our AMP, each of these first-order steps will use some partially revealed version of the gene that gets more informative over time. And we show that this can simulate this general radius schedule and thereby match our general order schedules. So, although the algorithm is just given the disorder matrix, it can kind of generate for itself this matrix rounding motion by these. Itself, this matrix brownie motion by deciding to it a brown equation. And it's sort of interesting that the algorithm is doing better by, you know, in earlier iterations, kind of hiding some of the information from itself. But that is holding fine. Okay, in the interest of time, maybe I'll skip this section on dense clusters. So if you're interested in this, ask me a point. Finally, Finally, we can specialize our result to get algorithmic thresholds in some specific models. So there's been a lot of recent work on algorithms for various perceptor models, as well as Hartmann's results. So I've diagrammed some of these results here. And Shan Ping talked about these last two diagrams in her talk over this week. So So, one result that I'll highlight here to refer to it later is in the symmetric easing perception, the best algorithm is by Gonzalo and Spencer, and it works up to constraint density about kappa squared, whereas the best hardness result is by Gemarnik, Will, Kislda, and Shu. And it shows hardness above this kappa squared long one over kappa. So we'll end up closing this gap. And alpha cat was where there's solutions? Yes. Yeah, so alpha capacity is much larger than either of these. So we specialize our model to our result, to the constraint sets of functional setting. So recall, this means we want to find x so that all of these inner products line somewhere there. And we'll consider the choices of i being i. The choices of I being either the symmetric interval minus kappa to kappa or its common. So this means we want all these inner products to land in or out of this symmetric interval. Then our main result implies some abstract description of the algorithm threshold in terms of these STEs that we've got. But in these symmetric models, we'll be able to extract asymptotics for Kind of extract asymptotics for this algorithm threshold. So because the interval I is symmetric, we can use a simpler symmetric SP, and this makes the analysis tractable. So we study eight symmetric models, which are described by choices of whether you want to be in or out of the interval, whether you have spherical or amazing spins, and whether kappa is a small or big constant. And we kind of Constant. And we can get asymptotics on the algorithmic threshold in all of these subs. In particular, in the case of staying inside a small interval with ising spins, we showed that the algorithmic threshold is, in fact, of orb over kappa squared log over kappa. And is there a strategy for sigma to just stop me at the end of the interval? Right. So. Right, so in this easing case, there were two SDs. Right. So yeah, the control for the X SD will be used when you hit the function control. But it takes some work to figure out the right control for the Y STL. Yeah, so in this case, we have a lot of the same But yeah, so in this case, we showed that this log is real and get an improved algorithm over that of one side specific. So this, I think in another work of Gemarnik Will, Perkins issued, they showed that online algorithms have a threshold of kappa squared. So this also says that non-onliness stuff truly helps you. Okay, I'll conclude. So, we get a sharp characterization of the achievable measures by Lipple's numbers in terms of this STE description. And this algorithmic threshold for the projection-pursuit problem also implies thresholds for the omnibus future and constraint satisfaction setups, as long as the subset of the real line or the activation. Or the activation function are regular enough. The main idea in the proof of hardness was to follow the evolution of this mu T empirical algebra. And on the algorithm side, we developed a new incremental AMP algorithm that follows this same system. I'll conclude with a problem, which I think Will already mentioned earlier this week, which is can we show hardness of finding isolated solutions even in the region? Isolated even in the review or finding age. So at the very beginning with the projection pursuit, you said, okay, you project to like D dimensions and you set a 50 plus one. Is there anything interesting or non-trivial if you take 50 is two or three or four? So I think the paper by So I think the paper by Andrea and Kantia studies D potentially bigger than one. And they get some more complicated SD description of that case. So it's certainly possible. But is there like, do you suspect there's similar behavior? Like even the capacity question or something like that, is it going to be similar behavior to the the usual beep? Um I think at the level of algorithms. I think at the level of algorithms, the SDE is sort of similar. At the level of capacity, I'm really not sure. So, one feature of the SDEs is that this specific case that the mean is zero. And I think somewhere along the way, that maybe was a result of assuming the flip sheet value flip sheet is still the case. Ah, okay, good. You can flip shoots concentration on increments, or is there something else you have? So there is a sort of There is a sort of this is not a priority, obvious. So we got some, let's just return to this general SDU. There's an even more general version of this SDU where the mean is not zero. So our proof strategy starts by deriving that SDD. And then we look at that SDD and we say, oh, the optimal choice is obviously. Choice, obviously. So, ah, but you specialize to the specific. Yes. Okay. Or even in general. Even in general. Ah, okay. Well, okay. Like, then this is an average over the disorder that we should be zero. But, you know, for a given disorder, then obviously zero enough. And is that somehow a function of the fact that you're restricting the literature's algorithms, or is there something more inherent to the problems or something like that? Which part? Wait, so average over the disorder. So, average over the disorder, it's sort of clear that you want your mean to be zero. At least in the sphere, you write your mean is faster, and then you're kind of forcing yourself onto some smaller sphere. Go back to that number line slide. This one? No, the almost at the end of the time. Oh, okay. Yeah, I. Oh, just one. So roughly weighted there, is there an estimate for where all the solutions become isolated? So at least in the symmetric Easy perception, the vast majority of solutions are isolated, even at any rate. Oh, even there. Yeah, like any constraint density. Any constraint density, they're all isolated, and yet you're finding the dense points. Okay, so what then is the point where they seem to run out, where all solutions are isolated? Say that again. So there'll be a different spot where every solution is made. I remember solutions. Never happened to me. That never happens to them. Not until they're not. Ah, okay. But wait, so you said earlier that there's speculation that maybe the point where every solution is isolated might be the limit where algorithms could have succeeded? The point where algorithms succeed through speculation is the point where these dense clusters start, like, no longer exist. Well, I don't think it no longer exists, but it tests their diameter or their structure. They're always going to be dense clusters because you can imagine solutions for a little bit bigger margin. Okay, so where on the number line is this point where that thing happens that leads you to think that might be where low numbers exist? So at least um for one notion of um you know dense clusters stop existing. That cluster stop existing, it corresponds to our algorithm threshold. Okay, so this is a little bit different than Freeset then, where the frozen solutions complete, the unfrozen solutions stop existing long past the standard thresholds and so on. Uh yeah, that's right. That's right. So there really is good reason to think that maybe no solutions at all exist as this k squared over log kappa squared over log kappa. Because at that point, all the solutions are these ones that seem hard to find? Sorry, since the other one. So I get the impression that there's a class of solutions that look like they'd be really, really hard to find. After kappa squared over log kappa, every solution. Okay, more questions? Not then, let's take rice again. Since this was the last talk that we take this opportunity and suggest uh that we give a round of applause for Tyler and Round of applause for Tyler and Will and Mark, as well as Jenny and Bergmond, for putting this all together. Thanks for coming.