Welcome to the second talk of our session this morning. It's a pleasure to welcome Jack Jeffries. We'll be talking about, if I can get this right, he gave me a can you read me and what about me? We'll be talking about a Jacobian criterion and mixed characteristics. Oh, great. Yeah. Well, yeah, thanks, Kevin, for the introduction. And I'd also like to thank Lin Chuan, Luis, and Carl for inviting me to speak here. It's been a lot of fun and enjoyed the. lot of fun and enjoyed the the mathematics so far um uh yeah so um oh yeah and also thanks for for uh um letting us keep the windows open during the talk um uh this is uh yeah something i've uh yeah strong strong feelings about um and stories about from the weekend before last so maybe maybe we'll talk about it afterwards um all right so uh yeah um so i'll be um yeah talking about uh joint work with um Yeah, talking about joint work with Mel Hawkster. And well, rather than a title, let me just jump in with a theorem. And let's just dive all the way. Um and let's just dive all the way all the way in and yeah, go for the general statement. So let's let's take a um um yeah definitely unramified DVR mix characteristic. Okay, and I'll be interested in presenting some rings as quotients of, well, yeah, not just polynomial rings or power series rings, but even why not take them both together. Okay, so take some ideal pure height H over minimal primes of height H. Okay, right. And yeah, calling for this as a presentation of something. Then let's be wasteful. And then one can describe the singular locus of this ring. Well, for primes that don't contain p, then basically we reduce to an old story. So, this is the place that I want to be amongst the primes that contain p. Contain P. So this is the singular locus is cut out within R by, well, yeah, P, of course. The H by H minors of, let's start with something familiar. So, if we were talking about a complex variety, then this is what we would write. We would end the story here. We are not. So, we need something else. And in the continuing the theme of Elisa and Alessandro's talks. Um, Alessandro's talks: the something else is a p-derivation, okay. And um, perhaps, um, okay, if I assumed that k was perfect, then I would not write much else. Um, but I don't even want to assume that k is perfect, so we might need some other things. Which needs some explanation. One of those things is peak powers. Okay, so the delta here that we need is any p-derivation on S. We'll underline this to let us know that we'll discuss this more, remember this better in a second. And actually. And actually now, yeah, now we've left the old story, so let me write it like this, and then we'll explain this in a bit. And these partial lambda twiddles are just lifts of derivations on k. So this is a set of lifts. So, this is a set of lifts of a basis. Grammatically, this ends up a little weird, but of the derivations on K in the sense that I have a derivation on K, then by base change, I just get. And then by base change, I just get something from power series polynomial over power series over k to itself. And I'll write this funny, permit you to use this funny notation for avoiding the bees and whatever. S certainly surjects onto this, right? And since at the end of the day, I'm going mod P, then I only need to be, you know, I'm well-defined enough here. Yeah. Okay. I'm more excited about this part of the story. Sorry for writing down low. So sorry. Should I move something to the side? Okay. We're excited about this part of the story, so let me go here, remind us what this is. Depends, depends, yeah, yeah. So if so if K is F finite, then it is, otherwise it's not. Yeah, yeah, yeah. That's right, that's right, yep, yep, yep, yeah. So any, I mean, I could put a Z here. Yeah, you're an F P. Yeah, yeah. You're an FP, yeah, yeah, yeah. Yeah, why not? Yeah, yeah, doesn't suppose down that should be so. Okay, um, so yeah, sorry for starting out with such a beast. Um, yeah, let's break down some parts of it and then give it a spin. Um, I used a number, right? Oh, maybe I didn't use a number, so let's let's not number anything. Okay, um, yeah, so um, Yeah, so recall, and I'm recalling a bit more generally than we called the first time. So let's say a function, a function between two rings, R and S are rings. It's a p-derivation. It's a p-derivation if um well, same three properties as before. Okay, so before right, we saw this with r f equals r, but it doesn't really matter. I want to send one to zero. Right, we can't stop here, so this is the We can't stop here, so this is the weird thing about p-derivations is that they're not additive. So where let's just write up here, but this is a thing that we can explicitly write down, right? Just a polynomial expression in terms of x and y. Let me write it slightly different than we saw it before, but it is exactly the same. Than we saw it before, but it is exactly the same. Every intermediate binomial coefficient is a multiple of p, so this is something that makes sense in any ring. Okay, so explicit polynomial expression. And there's something like a power rule, product rule. Sorry, there's also something like a power rule, but let me write the power, just the product rule. So, in the same way as derivations, right, we can break apart, if we wanted to evaluate something, we could break apart anything according to the rules, the ring rules by which we made it. Maybe for the purposes of let's go. Maybe for the purposes of what's going on over here, let me note that, or at least talk about start with DVRs first. Okay, so this is right by notation definitely unramified. Jack? So, how does rule number three make sense if R isn't equal to S? Isn't equal to S? Ah, yeah, yeah. So image of X, right. Yeah, so we're, so, so if R is not equal to S, S should be an R algebra. Okay. Yeah, yeah, sorry. Yeah, yeah, thanks. Yeah. Yeah, thank you. Thank you. Not just any two random rings. S is in our algebra, and we just judge X as the image of X. Yeah, thanks. Thanks. Yeah, thanks, thanks. At least if V is complete, I can say it has a P derivation. Okay, but if not, I at least get one modulo p squared. Okay. And can I write another line? Okay, just yell out one if you object. So let me say. A p-derivation from a ring to itself extends to any polynomial ring or power series ring over it. And I guess. And I guess, well, maybe it doesn't literally follow from what's written here, but in particular, along similar lines, there always exists a delta like so. Okay. So this is not vacuous. Okay. We saw an example. We saw an example over Z. Let me just soup this up just a little bit. And so, an example of a p-derivation on a polynomial ring over Z. If you'll let me indulge in a little bit of shorthand, it's written conveniently like so. Take pth powers of the inputs versus take pth powers of the outputs. These most agree mod P because for Benius, right? And so this is a legal thing again. And this is a p-derivation from r to r. We'll use this one later. Yeah. Okay. Yeah. Let me say just a couple more nice things about these before we try this out for a spin. I found this very terrifying at first, and I somehow find it less and less terrifying the more I play around with these things. Let me give you a concrete way to a concrete step to being less terrified about this, if you are. Okay, right, these are non-additive, but controllably so. But controllably so. I mean, there's a formula, but let's make it even more useful sounding. Let me make these f actually. So if I had a sum of things and I wanted to take a p-derivation of the input, this is how the degree to which this is not additive. The failure is in the ideal generated by the inputs, always, in fact. And this is just an easy induction on formula number two, since that thing on the right-hand side is in X and Y. If these are. If these are something like derivations, derivations behave well with respect to orders, like iadic orders, that sort of thing, right? They only decrease iadic orders by one. So let me only consider ideals that contain P. And let me just write this with squares. So it keeps things in squares of ideals, keeps them within ideals and returns a well-defined p-derivation, like so. But also, derivations are useful, at least our favorite derivations and polynomial rings and power series rings are useful because they not just because they don't decrease orders too much, but they do actually decrease orders. And in particular, p-derivations are useful for decreasing p-iadic orders. For decreasing periodic orders. I can cast out a power of p and somehow get something nice on the leading piadic term at the result. Okay. Good. Good. So good things flow from these axioms. Let's see. Need like four more boards. Okay, let's. Yeah, this is probably. Okay, so that's a lot of just words so far. Let's see some variables and numbers. Yeah, so I want to try this out in a case where we know the answer and things are already, I think, a little bit fun. That's yeah, rings that we've probably seen before. I want to try out this criterion on these rings. So, of course, we'll present these as quotients of a polynomial ring in one variable over z. And in the case, n equals one, I'm interpreting this as saying, give me another square root of one. Okay, just for completeness sake. Likewise, another. Yeah, give me another square root of one. Or when n equals zero, give me another. Or when n equals zero, give me another square root of zero. Yeah, other than one or zero. Okay, okay. Just so we can, yeah, not worry about degenerate cases. Okay, so yeah, so if we think about it for a second, we'll recall when these are regular. Of course, these are one-dimensional, right? So regular is as good as normal. And I shouldn't be adjoining anything that has repeated factors, right? That would definitely mess up our integral closedness. But also, if we remember further, maybe from a number theory class, there's also something funny about the congruence class of n mod 4. So, this I claim we know, and hopefully, we get something similar, or at least we don't contradict this at the end of the day. But before the end of the day, let's try the classical Jacobian, what we would get if we just tried to do the classical Jacobian criterion in the setting. And in doing so, maybe we'll see why we want something in additional to the usual tools that we consider. Okay, so the classical Jacobian matrix of this presentation is 2x. 2x. Just one by one matrix of 2x. So let's, yeah, this is a hype one idea. We should be looking at the one by one minors of this if we were just following the classical Jacobian criterion. So we should be looking at the vanishing locus of 2x and R. So either two, they either contain two or X, that's for sure. Okay, and now to understand this further, I might care whether n is even or odd. Okay, so if n is odd, then it's as good as one, x squared. Then it's as good as one x squared minus one is a square. Sorry, I should have left myself more room. Okay. Okay, ends up the other side like so. Okay, and then. And then n is even, x squared is x squared, and n and x is already accounted for here. Okay, um, so what do we get inside of R? X is root n now. Yeah, okay, um, which are always Which are always non-empty. There's always something here. So, this is not telling us about the regular lepers. Of course, this is telling us about what primes ramify inside of R, what primes of Z ramify in here. And the ones that count for two and the divisors of N. So the classical Jacobian criterion, of course, is telling us about smoothness over Z or ramification over Z. Okay, right, which is not what I'm looking for here, right? Instead, I'm looking just for singularity versus non-singularity, regular rings, that sort of thing. Intrinsic properties of localizations of R. Okay, so let's see what the other one tells us. I have to choose a prime now. To choose a prime now. Somehow there's multiple choices, but one is more interesting than the others. So let's just look for the singular primes that contain two. Um So, our mixed Jacobian matrix, there's nothing funny about our residue fields here. So, just looking at a p-derivation and the derivation of x at x squared. Again, we look for the one by one minors of this matrix. And again, I should only look above two, right? The two derivations shouldn't tell us anything about three, right? All right. Let's see what we get. What we get. Let's pull it back to S. Okay. I'm going to kind of switch some sides here. Squaring at the end of the day, geometrically doesn't matter, right? Because we've got this two here. All right, to compute this thing, I was told that we could choose any p-derivation, two derivation that we liked. And of course, we like the one that's on the board, right? So. So I should raise my variables to the pth power before and raise my function to the pth power after functioning. Take the difference. Right, this is that point we are. Yeah. About five more boards. All right, so let's clean that up a little bit. Okay, um, right, two NX in the middle over two, yeah. Um, just after a little bit of cleanup, um, again, maybe it helps to know whether n is even or odd. All right, then is odd. We'll do this again. Okay, and and even x squared, yeah. Even x squared. Yeah. Okay. And now finally we get to a point where we want to know more about our number, as we should have, right, if we believed our answer at the start. To decide if this is even or odd at the end of the day, then I need to go a bit further and look at the congruence mod four. Okay, so if there weren't enough cases yet. So if n is congruent to one mod four, then we've got one plus one over two is one taken in the suitable places. Okay, something survived. Okay, something survives. Whereas if n is congruent to three mod four, three plus one over two is zero. One, one's in here, right? We also have to play the same game if n is even. If n is congruent to two mod four, then and we get one if n is congruent to zero mod four. Zero mod four, okay. Then we get something else, then we get something non-empty again. Um, so I know this is a lot of numbers and letters. Let's go back here and see if we agree with what we get. Well, at least from what we can tell about looking over two. If we mess this up, the weird condition, then we've definitely picked up a singularity. And then Okay, and then well, this going on here, this is this is kind of reflecting the lack of square freeness, right? If you're a multiple of four, you're not square free. Okay, so if we wanted to complete the story, we would chase around the primes that divide and, but this is this is the essence of, it looks about the same, yeah, yeah. I feel like this is the exciting part of the example. Okay, um, see, any questions on this? See, any questions on this? Okay. Okay, so I guess the point of this example is that this is all really, yeah, all really concrete and in some sense and easy to get one's hands on. And easy to get ones hands on. Yeah, I think so. Yeah, yeah, yeah. Oh, actually, before we end, yeah, thanks for asking a question. Reminds me to point out something in here that's an interesting part of this example. Sort of at the end of the day, this was the fun part, right? This is the this part is just the two derivation of minus n. So somehow, oh, darn it. Yeah, so somehow this business about, yeah, one mod four or three mod four is kind of coming from the fact of whether whether your number is derivative is zero or not mod two. Or sorry, in the two derivation sense. Yeah. Sense. Yeah. Okay. Let's see. So interesting. Yeah. Let me okay. Yeah, let me briefly touch on the so-called affine case of the proof, or what I want to call the affine case. So let's take an unramified DVR with a perfect residue field to avoid all the funny derivations at the end. And just polynomial variables, no, no power series variables.  So, this concrete starting point of the theorem can actually be proven by basically a very concrete and hands-on way. And sometimes, since I can't stop myself with these calculations, let's try it out. Yeah. So, okay. Okay. So, to prove to prove this, it's a very important thing. To prove this, it suffices to check. Suffice it to check for maximal ideals, right? Our singular locus is at least closed a priori. And the equation is a very important thing. And the equations should be cutting down the tangent space as much as they're cutting down the dimensions. We wouldn't end up with a regular ring at the end. So they should be the right image is how much the equations. How much your equations are cutting down the tangent space, and we should be doing it. Same amount that the ideal is cutting down the dimension. And by our algebraically close, so I said perfect before I really went algebraically close. We can write down our maximal ideals explicitly now from the Nelson Saud. So we can choose elements like so that witness our point and give these shorthand names. Let's just compute some stuff. Yeah. So I'm going to start by taking a Taylor expansion of F to get a hold of what it looks like near Z. Starts off like this, and everything else is in the square of n, the squares of the x's. All right, and to get an understanding what the p-derivation is doing, I want to try this out. Right, I get a well-defined map like so. Excellent. Well, I'm taking a p-derivation of a sum, which is a little bad, but not too bad. So the non-additive terms, well, right, since we're a point containing i, then our function value has to be a Then our function value has to be a multiple of p. All of these things are inside of n. So all the nonsense is inside of n. Okay, this is good. Wasn't able to save everything, so now we'll just have to use our memory. Let's bust this up using the product rule. Yeah. And sorry for jumping over this. Jumping over this. This is the one I wanted to save. This is not just to annoy you. Yeah. Okay. So we'll all right. So when we product roll these things, what do we get? So we get some sort of pth power of this times p power. Of this times p-derivation value of the xi twiddles. That looks like it's worth keeping. Yeah, not that. What else do we get? Pth power, Peter iterations of this. Oh, this is an N, right? Of this, oh, this is an n, right? So that term's garbage, okay. The third term, p times product of the p derivation values, oh p is garbage. Okay, so this is it plus nothing. And this. This was a multiple of p. So, I'm, and this is just the thing inside of p, right? This is a multiple of p. So, this is looking pretty good, yeah. This is the X part. We write fj of the value of our function at b as p times something, p times something, that's the something, right? Mod b and hence mod n. There we go. That's the same thing. Okay, and the point is of all of this part was just to say that at the end of the day, I can more or less solve for the plug-in, you know, the evaluation of my function. Or at least once we've casted out the multiple of them. Cool back to back to n mod n squared, where all the action was. Hard to argue with this. So I'm just rewriting the Taylor expansion we had from before. Then substitute in here. Let me put brackets here. Okay, then we get some sort of formula and we ask if it was worth anything. And we asked if it was worth anything. Let's see. It looks probably pretty good. Here we have some sort of basis for n mod n squared, right? Then fj, the coefficients of fj in this basis are given by a tuple. Are given by a tuple like so. What is this tuple? It's pth roots of the columns of its corresponding column in the Jacobian matrix coefficients of j are the jth column. The jth column. Oh, wait. Row. Sorry. Or the jth row of the mixed Jacobian matrix. Okay. And yeah, k is definitely perfect, right? The rank of this is equally good as the rank of the Jacobian matrix. Yeah, mixed Jacobian matrix. Matrix. Yeah. So at least in this case, one can get to get at this just directly in a hands-on way. Which sorry I couldn't prevent myself from doing. Of course, yeah, it's a special situation where you can really get your hands on the maximal ideal. All the maximal ideals is concretely into this, right? So you can deduce the general case, at least. With K perfect by neuron Popaski's one the singularization argument. Namely, view, you know, test as a as a as a direct limit of smooth V algebras. And I should say that this is not straightforward. A lot of properties have to be kept track of in a subtle way to do something like this. So yeah, so this was the first way that we got to our result. And then another way. Another way comes from, yeah, something else that one would obviously want to consider in a situation like this with Jacobian matrices, of course. With Jacobian matrices, of course, right? The classical Jacobian matrix presents Taylor differentials, which represents an interesting functor. Likewise, these Jacobian matrices present matrices that represent interesting functors as well. And that objects that one comes across, we found out were studied a bit earlier under a different name by Dublikatz Rabanoff and Zerk Brown. And we're also considered again by. Um, and we're also considered again by um Takeshi Saito. Um, and oh, I actually should have said at the beginning that um uh Saito has uh obtained um related results to theorem. So let me go back to the beginning and see. Yeah, also see Saito. Yeah, um, um, yeah, sorry about that. Um, yeah. So why not? So, um, there's something that's sort of like a linear linearization of this very non-linear notion of p-derivation that we took the opportunity. That we took the opportunity to go for a portmanteau here. This is a function that well we're going to linearize. These formulas that we had before. Of course, this is not linear, right? This should take something in the image of alpha, right? So alpha p actually makes this work out nicely. Actually, it makes this work out nicely. And well, P is zero. P times anything is zero anyways, right? So don't have to worry about what's next. Don't want this anymore. So this somewhat generalizes p derivations. So if our target is R mod P, Is R mod P and alpha of P is one. This is the most interesting value. Then this is the same as a p derivation from R to R my P. Whereas if alpha of p is zero, then we get something that's additive. And this looks very much like the usual product rule, except with pth powers. This is a derivation into a Frobenius pullback of a module, right? So let me say alpha. Sorry, push forward. Geometrically, yeah, algebraically inclined in terms of directions. So when you consider this as a map to funky structure on M, then it becomes a derivation, actual derivation. So there is a universal object for these things. There's also a relative notion that I don't want to bother with in six minutes. And in the main setting, it's given by the code. In the setting that we started with, it's given by the co-kernel of the Started with, it's given by the co-kernel of the mixed Jacobian matrix. At least the module part is given by the module part is given by the So, maybe let's just theorem two and then say a couple of words. And there's also, yeah, so Saito also has a version of this theorem, and ours is just a bit more general. So again, unramified DBR of mixed characteristic. And yeah, we're going to want an F finite residue field for reasons that will be obvious in just a moment. So given a local ring of mixed characteristic, essentially a finite type over a complete noetherian. A algebra. Then, yeah, so of course the advantage in this setting is no funky unmixedness rate conditions on the heights of the minimal primes. The cost being this, and the statement obviously being that this module is free of the correct rank. Correct, Rank. And to be correct, then we'll have to call upon F finate for that. Okay, then little k is becomes f finite also. And this is the correct rank to talk about. And okay, in this setting, one can give it the. Setting one can one can get at the proof in a way that looks at least different on the surface to what was going on though. And in the affine proof, though, of course, the spirit is very much the same when one boils down into it. These things satisfy first and second fundamental sequences in ways that are compatible with first and second fundamental sequences of actual Taylor differentials in equal characteristic p. Characteristic P. And then, yeah, one can, well, let's just say, play those things off of each other to get where one is going here. Yeah, so maybe I'll stop there. Thanks. Omega R is free. Does that have any implications for? Does that have any implications for not necessarily a finite rank? So it certainly won't, yeah, yeah, so it's certainly not enough, right? You can be free of the wrong rank and it's not be regular. As for the ones that are free of the incorrect rank, I'm not sure off the top of my head what I would say about it. Yeah, sorry, I'd have to think a little more about it. Yeah. Is Omega Artilda generally Is omega R tilde generally finitely generated? You said you always have this module, but in like in the non-affinic, like, is it finitely generated? Yeah, I don't, I don't. Yeah, that's a good question. Yeah, I'm not sure actually, and outside of the F finite, yeah, outside of the F finite starting hypothesis. Starting hypothesis. It's certainly not finitely generated in an obvious way. Oh, sorry, I'm looking at the computer instead of at you. Okay. Yeah. I don't, yeah, I don't know. I don't know. Yeah. Okay. Yeah. And I guess then you wouldn't know anything about it. And if it's, you don't know that it's finitely generated, then since you need to just know the rank here, then knowing that it's flat probably is. Rank here, then knowing that it's flat probably isn't particularly useful. Yeah. Thank you. Yeah, yeah. Yeah, yeah, sorry. I'll have to think about think about that some more. Yeah. Thanks. Yeah. Oh, yeah. Is there a notion of higher order parameters? I wish, yeah, I wish I knew what to try. Yeah, so this is all very... Oh, yeah, sorry. Is there a higher order notion of Higher order notion of perivation or these things. Yeah. No, and we, yeah, not that I know of, or as far as I know, anywhere in the literature. We've hit our head against the wall on it a few times. But yeah, it's somehow the, yeah, the, yeah, you really kind of have to be going mod p squared to get a handle on, or start off mod. To get a handle on, or start off mod p squared, to get a handle, or something that's you know, factoring through on mod p squared to get a handle on the on make something reasonably linear at the end. Um, as far as yeah, as far as we know. So yeah, yeah, yeah, no, it would be great to have one, but yeah, I don't know. I don't even have a guess for what it should be. Do you have a mention of physical parts? Do you got the notion of principal parts? Yeah, so Luis asks in a similar direction: is there a notion of principal parts? And yeah, likewise, likewise, no for the same about the same reason. Yeah, yeah, yeah, yeah. Yeah, yeah. Can one think about these as some sort of, I don't know, lips of twisted maps that factor through Frobenius or something? Is there some connection to the lips of Fabenius for these twists? Yeah, it's not clear to me what a correct statement would be. Yeah, possibly, but yeah, again, sorry, yeah. Sorry to not have an answer. What was this called the deal setting? So there's a, yeah, total p-squared derivations. Total P squared derivations. Fw derivations for Benius bit. Yeah, well, you know, the literature wasn't cluttered enough. So, yeah. Any other questions from the room? Maybe I'm just curious: what did they use this for? Yeah, so actually, so yeah, so they were interested in. In um uh well, I didn't write it here. So they're they're interested in using these things to understand existence of lifts of Frobenius mod p squared, um, or equivalently p derivations on rings. And yeah, so it fits nicely into this story and the first fundamental sequences. Um, so there's sort of a special case of the first fundamental sequence where Fundamental sequence whereby you've got a map where the first thing is just a copy of your ring. It maps to this universal object, which then maps to the Frobenius pullback of the Kayler differentials on the ring mod p. And then that split exact if and only, and this with and then if and only if there's a p derivation on on r and that and basically the And that, and basically, the p-derivation is the splitting. So, I think that was the main, that seemed to be, to me, their main motivation in splitting this. Yeah. Does this give you a nice notion of curvature? I don't know. Yeah, haven't considered it. Yeah, yeah. Maybe so. Yeah, maybe I'll say that William has been interested in notions of curvature in the Of curvature in arithmetic directions. And yeah, by looking at p-derivations and sort of analytic continuation of p-derivations, if you switch to different primes. And even he and this student have a paper where the title is The Integers Are Curved. So definitely they've been using these things for curvature of some sort. Yeah, I haven't looked at it myself, but yeah, there's a notion of curvature. But yeah, there's a notion of curvature, at least coming from p-derivations. For the principle parts, would you take, for example, the co-kernel of some mixed Jack with Dave principle? Yeah, but it's yeah, so Danielle is suggesting for the principal parts, can you take a co-kernel of some mixed Jacobi-Taylor matrix? Yeah, presumably something like that, but it's unclear which one. Yeah, it's unclear what exactly it should look like. Right. Yeah, I mean, there's certainly things one can write down, right? But as for like whether they, as for whether they do anything, we haven't been able to write one down along with a reason that it does something meaningful yet. Yeah, yeah, yeah. Oh, yeah. Oh, yeah. Because we've been sessed that p is in the max, that that we're that we're taking a point of mixed characteristic. Right. So yeah, yeah, that's the analog. Yeah, that's the analog. Yeah, yeah, yeah. Oh. Um, yeah, nothing. Yeah. Yeah, nothing. Yeah. All right, I got one more for you. So, at least in this local setting, would you also suggest looking at some sort of modified Nash blow-up by blowing up this module instead? Agreed, yeah, yeah, yeah. In particular, if you extend and look at fork-like varieties, possibly where P is one of the parameters, so things look different. Parameters, so things look different, right? So, these arithmetic work things, right? Do you get a similar description from the previous talk? Yeah, so yeah, so certainly the thought has crossed my mind. The catch, though, is that these things really live on our mod P, right? And so it's not sure to me how to make them jive then in that case, right? Right. Yeah, perhaps there's a reasonable There's a reasonable sort of analogous universal property that one could rig up. But at least for most directly, for the most direct comparisons to the ways that one realizes Snash blow-ups in terms of Kaler differentials, it's yeah, something is different at least. And haven't gone into depth into saying what you can try to do. But yeah, yeah, I mean. But yeah, yeah, I mean, I agree with the sentiment, but it sounds like fun. Yeah. Okay. Check the chat with one time. Yep, we're good. All right, and with that, let's thank Jack. Okay.