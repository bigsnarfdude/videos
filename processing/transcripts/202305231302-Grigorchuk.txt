Um operators are coming from everywhere and one of the sources of uh operators is a spectral theory of graphs. So for the moment let gamma be a graph. This set of vertices B, set of it just E. A graph can be finite or infinite. And then we can consider the input space H L2 on the set. L two on the set of vertices, I consider the most comfortable sets. And then one can consider operator in this space m I denote applied to function f evaluated at vertex x is one divided degree of x, sum of values of functions at Functions at vertices adjoint neighbors of X. So everybody, I consider not oriented graphs. In principle, one can consider oriented as well. So each vertex has degree of valency, number of edges incident to this vertex. And so, what we are doing. And so what we are doing uh for each uh S, we take neighbors and su uh summation uh some uh uh take uh sum of latitudes of function in the neighborhood of points and then average. This is what I will call a Markov operator. Yeah, my top my lecture is addressed mostly to students, sorry, for mature mathematicians, so will be very Documentations, so we'll be very elementary, at least today. I hope the introduction is still correct. You should be aware that the chair of this session is strong. So discipline, I am sure discipline will be one. Marco, I call this Marco operator. This Markov operator, in particular, because it is related with a random walk on this graph, or simple random walk, in which we start with some vertex and move in all directions with the same probabilities according to the degree of vertex. And in one of the talks, already graphs were presented, diamond graphs, as far as I understand the degree of I understand the degree of these graphs was growing. In principle, when we deal with infinite graphs, we prefer it's not necessary, but we prefer to deal with graphs of uniformly bounded degree, or even better when degree is a constant function. So we call such graphs regular graphs when the degree is constant, some value. Constant some value, I don't know, C greater than equal to. Okay, and so we have operator. By the way, it is a self-disjoint operator. So spectrum is real. And we are interested to know, first of all, to know, to have information about this spectrum, are there eigenvalues in L2 or larger spaces? By the way, time to time I will see. By the way, time to time I will switch to notation sigma of m because preparedness talk. I was looking particularly in my paper with Rogue, and now I have a mixture of notation in my mind. And also, the so-called spectral measures. I do not define today, but next time maybe I will define spectral measures new. Okay, so this is Okay, so this is one thing. A closely related operator is identity operator minus n. So this is identity operator in our space. It's called a discrete Laplacian. Discrete Laplacian operator. And of course, Operator. And of course, study of M or study of delta are equivalent things. I prefer to deal with M first of all because of this relation in the random box. Also, one can put weights on edges and consider more general collection. Now let me give a simple example. Let us consider group Z and what we call K. Group Z and what we call Kraph of Z. So it is generated by element 1, we can include minus 1, and so K graph, which I think identified soon, looks like a one-dimensional grid. And if you have a function f of n, so this is point n, somewhere is point zero, n f at point n is one over two. A graph is two regular. to regular fn plus 1 plus f n minus 1. So this is our operator. Now what we can do instead L2 z we can replace by L 2 on 0 to pi applying Fourier transform. So function f of m will now be presented by By series, and after such Fourier transform, our operator M becomes operator of multiplication by cosine theta in the Hilbert space of square integral function or integral to p. We know the range of values of this function and from this. Of values of this function, and from this we immediately conclude that spectrum is, which, by the way, usually I will denote sigma. Sigma is interval minus one line. And this is, by the way, maybe not bad exercise for students to apply to check this works. Now let me consider slightly more Let me consider slightly more complicated graph. So it has loops, it has double edges, double edges are not forbidden, loops are not forbidden. How do you get the cosine there? Let me ask you a question. And for z squared, what do you get for m for z squared? You can apply still Fourier transform and get operator multiplication by function. Now function will be into variables and the range of values, the essential range of values of this function, will be spectral. In the obvious theory term, that is called the forward shift and the backward shift. Shift and a backward shift. The backward shift is the start of the forward shift. If you have a two-dimensional thing, you have a shift in x-direction, a shift in y-direction. And the spectrum is still minus one. Okay. So that means go back. Um you see it's dangerous to give examples, dangerous to connect theorems. From the rings. It's better to give empty talk. Okay, now we have another graph. It's still irregular. Degree is constant. It's 4. The difference is that while this graph is just periodic, if you apply shift, you get the same graph. This graph is too periodic. Too periodic. Do you agree with Santiago? Do you agree with Santiago? Yes, I am. Okay. And so Fourier transform doesn't work immediately, but there is a so-called Bloch Flouquet theory, which nicely is described, for instance, in the book of my colleague, Very Kerkov and Peter Fuchsman. And it's very classical, that you can apply and easily compute a spectrum, and in this case, a spectrum. And in this case, a spectrum will be a union of intervals this one plus this one. I will come back to this important example later. Now, what are other sources of examples? Now, okay, if we have a group gene and If we have a group G and have a system of generators S and uh we prefer to have this finite system of generators like in previous uh talk uh they can we can associate uh with this square a graph that is called KD graph and a set of vertices is just set of elements of a group and set of edges consists of pairs G and A S where the groups of the groups of the Where a G is the element of the promoter, and A is a generator, or maybe generator is invested. Yeah, so this is a Kelly graph. You mean A G A G? Or A S. In the edge, in the definition of the edge. Okay. Okay, uh telegraph. And uh the feature of this graph is that it is very homogeneous, very symmetric. This is a left version of the graph, a multiplication of the group on the right x by automorphism of the graph, so vertex transitive action of group on B itself. There is a right version of this definition, then left action. And by the way, another And by the way, another important filter that can be associated with the group is a regular representation. So we will deal a little bit with representations. Unitary representations. So a homomorphism from G to the unitary operators, group of unitary operators on the hiltered space U. So this called unitary representation, and one of the most important is And one of the most important is left, say left or right, right to left representation where the lambda evaluated on G applied to function f belongs to L small. I consider countable groups, finite or countable groups and topological groups. On G, so uh evaluated at point H is F G divides H left regular representation, similar in define the right regular representation, this is unique representation. One important example, another important example of representation. Examples of representations are so-called regular quasi-regular representations. Now assume we have subgroup H in G and lambda G of H in X in vector space on the set of cosets. So this is judgmentation of the set of left cosets. Set of left cosets and group X, a group X. So if we consider left cosets, a group X on this set by multiplication on the left permutes coset, so we have permutational action, and this induces corresponding unitary representation in A2 on this space of process. And if And if H is trivial group, we get back a regular representation. Now going back to parags, but now uh additionally adding subgroup H as before subgroup H uh we can build a graph. Uh we can build a graph which depo uh depends on on this data that I just produced. Arguments uh which will be called Scholar graph and now as a set of vertices is again the set of cosets and And a set of edges consists of pairs cos z when the difference between them is a generator. Okay, again, A belongs to S, S inverse, G is missing here. So this leads to much class, much larger class of graphs. Our graphs. They are not so nice, maybe, in general, as scalar graphs, because a group of altomorphism can be trivial. But they serve a larger area of mathematics, and the works of Lordena, Crasher, Statiana, and many others confirm this. Unfortunately, I was planning to combine screen presentation. Screen presentation showing nice pictures of KD graphs, share graphs, but then realized that one has to make one of choices. So as for KD graphs, okay, like three albedo kerographs of three albelian groups, or we take three groups, absolutely free group, and then like for two generators, we have infinite regular rooted tree, then a group. Then a group of acting on cray disk surface groups give some nice pictures, but more complicated group is more complicated graph is. Share graph, the situation is that even very complicated group may have quite simple Share graphs, which nevertheless, in a certain sense, keep all information about the group. About the group. Again, so far, I do not consider my definition of graph. At the moment, they are unable. There is no labels on edges. But you can add additional information, and for instance, for this edge, so joining this A G H. A GH, you can put label A, showing how transition we generate the blue. So with label graphs, usually you can reconstruct group. If the action is faithful on the set of vertices, you can reconstruct the group. And uh yeah what is good still with Shrayographs, they still they are regular. They are regular. And degree degree is just double double the negative generated cell. Let's go back to unitary representation of a group and let us consider group algebra, say with complex coefficients. Elements of these algebras are formally linear combinations of elements of a group with coefficients, which are complex numbers. Are complex numbers. We can restrict ourselves to real numbers. Only finitely many coefficients are non-zero. And clear way how to multiply them. Just multiply like algebra, usually algebra, and then using multiplication in the group. So this is very well known an undergraduate course concept. But then you can associate to this representation an element of group. An element of group algebra operator, rho of n, which is the sum, the same sum, only we replace each element of a group by corresponding operator. Rho G is some unitary operator. You take a finite sum of these unit operators with some coefficients. You get a bounded operator in unit space. And this is one more very rich. And this is one more very rich source of m of uh examples of operators. And we will see this uh this kind of operators uh are related to operators arising from LMARC, Laplace operator, and so on. Yeah, and one more important class of uh examples is uh Is a Koopman representation. So given a triple G X mu, say X mu, let it be for simplicity probability space, space with measure, and root act on this space by measurable transformation. We now uh denote in this way. denote in this way through action and we assume that measure μ is G in vector meaning that measure of set equals measure of image of this set for arbitrary element and then we can consider Higgins space A2 X mu and action I will denote maybe pi Phi open representation so phi g unionly represent space H just pi of g applied to function f evaluated at point x is f g inverse x. So group acts on functions by Uh rook acts on functions by shifting argument. And G inverse uh uh inverse stays here just to get in representation, not anti-representation. And because measure is invariant, these operators are unitary, so you get unitary representation. Next time, I think I will consider more general case when new is not just G invariant but quasi-invariant. Invariant, but quasi-invariant, but for the moment, this isn't today lecture. Yeah. And by the way, so the title of my talk was given, but alternative title could be Alternative title could be Renor method in joint spectrum problem. So now I'm going to approach this alternative version. And let me discuss a little bit self-similarity. So the topic of self-similarity in group theory was touched in Bogota talk, maybe in summer. Other talks, let me pass very generally. Very generally to describe the concept. So assume we have x some topological space, for instance, interval or count of set or whatever. And assume we have a sequence of partitions C N A sequence of partition of this space on smaller pieces. And these smaller pieces are naturally homeomorphic to the original space. And if you consider family f of all these x, n, i, all these sets taken over union over n and i, you will get a rich set, such sets, at least such sets. Set, at least such set that generates a topology of the space of a sigma algebra of measurable sets, Braille sets, and so on. So the idea of the concept of self-similarity, yeah, and assume now we have a group acting on this space X by a homeomorphism. The concept of self-similarity can be described in the following term. Describe in the following way. We have X, we have, we take arbitrary Y belonging to this family, we consider stabilizer of this Y in the group G, etc. Sorry, so what is F? F is a family of subsets X and Y. We have sequence of partition for each N. Sequence of partition for each n natural number n space is a joint union of subsets. I consider finite partitions. And then f is just a family of all these sets, of all randoms, atoms of all partitions. Yeah, for any y we now consider stabilizer of y in group G meaning set stabilizer, and so not point y stabilizer, but Not point fly stabilizer, but third stabilizer. It's a subgroup. So this, I don't know, for the moment, let me denote it H. So this H acts here inside. It also could act notrially outside, but at least it preserves this. And then we can consider homomorphism from this group onto another group, just restricting action of H on this Y. H on this y. And this will be the rejection on certain subgroup, I don't know, that we denote it hy and now we have, as I told, we assume that every element y of f is in certain sense isomorphic to the whole space by some natural isomorphism, natural homeomorphism. And maybe a few violets. Maybe a few while we do note. And if it happens that this projection, the projection is still a subgroup of original roof G, if we identify a subset with the whole space, then we say that action is so similar. Just can you repeat that last part? So if you identify y you take y, you identify it, you take hy, how do I get hy subset of g? Of y subset of G. Together, so we have this set F of subsets, and I take arbitrary element Y and also I assume that each element of our partitions is somehow homeomorphic to X, by some natural homeomorphism. Then I restrict X of the group from. Of the group from X onto this invariant subset Y, I get a group acting on this Y. It is a quotient of this group. I denoted it in this, so it's just a homomorphism of restriction. I denoted HY, but now using identification of Y and X, I can view it's like let's go to the whole set. And after that, if it happens that it is a sub of PNG, we are happy. Of engineer, we are happy. We say that action is so similar. And if action is faithful, we say that the book is so similar. I have a question. So about the sequence of partitions, do they have to separate points or nature? Is it rich enough to generate sigma algebra for L sets, for instance? It's a restriction on any atom, right? The partition is we will deal just with two examples. Again, interval for simplicity interval 0, 1. And Cm is, so we divide, we fix D equal to greater or equal to, for instance, for simplicity equal to, we divide in two parts. We divide in two parts, and this gives us a delta one consisting of two pieces. And then we iterate this process and for level n we get, so C n will consist of two to the power n sub intervals of interval zero one and of binary partitions, sequence of binary partitions. And this is a good example illustrating what I said before. So we have this sequence of partitions. In atoms data, we can call them by binary sequences, I1, In, where Ij is Ag0 or 1. So this is example of family F. And another nice example now, we consider D D, D Rever, rooted tree, for instance, again. For instance, again, let me draw terminally. For instance, T3. And it has, we can associate alphabet. Now X is not a set, so sorry. But alphabet, maybe A, I don't know, 0, 1, and so on. 0, 1, 2 for terminally. 3 for A. Tree for instance. And we can consider any end in this tree geodesic range adjoining root with infinity. And this will be represented by ternary sequence, infinite ternary sequence, and we get a boundary of our tree, which in fact is just a direct product of this alphabet over natural numbers, space of sequences. Numbers, space of sequences. And this space with natural product topology is just a counter set, one of mannerizations of a counter set. So this is the boundary of our tree. And we can consider new any Bernoulli measure on the boundary, putting probabilities to symbols of alphabet, but we prefer to work with a uniform Bernoulli measure. Uniform Bernoulli measure when we put equal probabilities, and then we get uniform Bernoulli measure on the boundary of the root tree. And now we consider root. Yeah, and what is partition of the boundary? In this case, so there are levels, root vertex, first level, second, and so on. First level, second, and so on. And level n. Maybe let me denote. So V is the set of vertices of this tree. It's a dejoid union of Vn, spanning from zero to infinity. Vn naturally can be identified with A to the power n, so we have alphabet, and reconsider strings of length n over this alpha, this is our answer level. and level. Okay, and for each n, we can consider partition Cn of the boundary, of the boundary. So if you take vertex V belonging to level N, we consider part of the boundary which is below this vertex V. So it's part of counter set. We have D to the power N such cylinder set, we call them cylinder sets, so atoms. Intercepts of atoms. D is coordinated of our alphabet. And this is example, another example of similarity structure on our space. So our space in this case is a canton set. We have a sequence of partitions of different lengths. It's rich enough. And there are natural identification. This interface of sub-interval with the whole interval. Of sub-interval with the whole interval, just applying natural transformation. Or this part with the whole part, just because every subtra is natural, here is the motives of the whole thing. Uh this uh uh yeah. Okay. Uh I will present some examples first acting on uh on interval uh then uh on rooted tree. So in general we consider subgroups in the full group of automorphism of such rooted tree. It's an uncountable group. You can imagine that it fixes a root and permutes and each vertex it somehow permutes edges. It's uncountable. Aegis, it's an uncountable group, it's a compact, totally disconnected group in natural topology. So, profional group, and basically all profinal groups, embedding groups of this type, at least when we consider more general type of trees called spherically homogeneous rooted tree. Okay, so we are interested in subgroups of this group. They will act by optomosis of the tree. By automatism of the tree, this will be fixed fixed vertex. Always all levels will be invariant sets. Maximum transitivity that can be achieved is level transitivity. But this level transitivity can be transferred into language of action on the boundary of the tree. Namely, it is equivalent to ergodicity, to unique erodicity, to minimality. So this is a pretty important assumption which quite often we assume and Quite often we assume and which works, level transitivity. It's not necessary, but it is good to have it. Now, okay, if we apply this idea of cell similarity in a situation where the group acts on such a tree, so what it means? We take arbitrary vertex and our arbitrary element g and g, so g x on the Uh Gx on the tree, Gx on the boundary of the tree, action of the tree induces action on the boundary of the tree by homeomorphism, in fact by withromatic isometries, so-called solenoidal maps. So we are interested in both and the idea of self-similarity here just means that okay, any vertex V under action of G goes to its image. And the action of G goes to its image, is clear G here. But then sub tree with the rooted V goes here and here to this sub tree. And so how one can visualize this action? Okay, to know this is a permutation on level M, if Valentax V was belonging to level N. Some action by permutation. Action by permutation. But what is happening here is action inside sub tree. Is this action inside sub tree? We denote G V. G V. It's a cold section. Section of projection. Section of projection. So if we apply this just to the first level, level one, it means that every element G of our group can be presented in the form G1. In the form G1, Gd sections. At these vertices, followed by epsilon element of symmetric group of degree d. This epsilon shows how element permutes vertices of the first level, and these sections explain what is happening inside. And now, And now, so similarity means just that this section still are elements of G. If we identify sub, so this is sub tree resolved at time. If we naturally identify with the whole tree using natural similarity, this section again is element of a group G. So the group uh is so similar if uh it it acts basically on the rooted tree and satisfy this condition. I asked a completely naive question. Yeah. So the action of the group is self-similar. Does it mean that the group itself in some intrinsic way is self-similar? Behind you is Wolfman who answered no. But I am thinking of what what to answer. Please explain why no. Well, you can ask if something. Ask if sometimes admits a socioleaction, which don't, but there's no kind of complicated models. And then which are many inequalities in reactions. Three groups is pretty material. Yeah, even finding a solution reaction for a previous material, but then classifying them is beyond. Okay, now uh ex uh it is time to give some examples. Time to give some examples. Let us consider interval 0, 1 and the transformation A, which consists of permutations, ideally the dyadic rational points. And so let the P written over any interval mean permutation of two halves of the interval. Oh, people from analysis, I just draw a graph of this transformation. This is the graph of this transformation. And B, now I define in the following way. I divide, divide, divide, and I continue this process of division, and I write just sequence P and so on. Periodically repeated. Now, this is an example of self-similar action because Um because uh if you're uh okay, if you uh what are sections of element A? They are presented by this graph is kind of identity transformation. So the sections are identity. We write so-called risk recursion that A is one one followed by epsilon, where epsilon is permutation of two halves. Well uh B if you restrict on left side we see element A. We see element A, and if we restrict on the right side, we see B itself. So it means that for B, this reserve condition is A followed by B and here followed by identity permutation of two symbols. Okay, now we have two elements, and we can generate a loop by them using composition of transformations. It's easy to see that. It's easy to see that they are involutions. A square equals B square equals identity, identity element. They are invertible. And in fact, a group generated by them is infinite dihedral group, which I will denote D. Infinite dihedral group. It requires to understand that A D is element of infinite order, but it is. So here you have an example of a Of a well-known inherent group can be realized as so similar to acting on integral 0, 1. Alternatively, you can realize it as acting on binary 2D3, where A just permutes these two vertices and B it fixes this infinite ray and then. And then X here as A, here as A, S A, and so on. This is basically the same action, but here from interval we go to counter set, which sometimes is more convenient. Okay, what we can do next? Next we can uh still keep Still keep A as before and now consider three more generators, B C D again I repeat this procedure of division to the right as before, but just write sequence P I P I so P I So P I periodically repeated, will be written. And here, I T I P will be periodically repeated, written. And in fact, and for T it will be P periodically repeated. So I made just a slightly more complicated example. Okay. Okay, I'll explore. And I is the identity. I identity, yeah, sorry. Students ask good questions. I is identity, so I forgot to say. So in fact, it's easy to see that D is product of B C and P and C commute. Why D is product? Because P by identity is P, identity by P is P. Identified by P is P. So, in fact, we don't need a generator D. The group is free-generated. And P, C, and D, together with identity, just give plan 2, Z2, plus Z2. But okay, let us keep. So this is another example of similar action. And again, you can transfer it into action on the rooted tree in similar fashion. Now, so I denote this group in straight annotation, G0, 1 infinity. Then another group G. Again, it's generated by A B C D is the same A, but uh P C uh C and D are d defined using sequences uh P P I, periodically repeated P I and P. Repeated P I P periodically repeated IPF periodically repeated and another notation is 0, 1, 2, infinity. And one more group, again, generated by A B C D, but now sequence I what is sequence now? P I I I P E I P E No I I P I I I P okay so we have three constructions and three groups and these are highly non-trivial groups first of all we observe that infinite diagram group embeds into this group because we have A and T We have A and D. So this group is not torsion. It contains the hydral sub. This group is torsion, it's so-called group of precise type. Every element, for every element, you can find some power type 2 to the power n, which gives you identity elements. There was a precise problem, very famous in group theory. I was not the first constructive example, but in certain Constructive example, but in certain sense, this is the simplest one. This is called overgroup, overgroup, and this group embeds, embeds, as well as the hedral group embeds. Product of P C is element D here. Or vice versa, sorry, product of P C here is element D here, something like that. So this group embeds here. That. So, this group embeds here. But the most remarkable property is that all these three groups have the so-called intermediate groups. So, if you have a group with a system, finite system of generators, you can build function gamma n, which counts the number of elements of lens not greater than n. Number of elements g in a group with Length with respect to generating system not greater than n, or just. Of just a size of the pole, number of elements in the pole of ratis n in Keri graph. And it has a growth intermediate between polynomial and exponential. Additionally, these three groups are branch, just infinite, finitely constrained, rigidly finite, and so on. So many interesting properties. What is interesting with this example? What is interesting with this example, yeah, is this with this example it is interesting that at the right at this moment, this is a group which has the smallest intermediate growth. No. Its growth is like exponent n, 0, 7, 6, 7, 5, something like that, some constant, universal, not universal, we don't know, but at the moment null is known. Example, just intermediate growth below. Just intermediate growth below growth of this function. These two groups have much higher growth, but still intermediate, intermediate sub-exponential growth. Also, this example is interesting that it can be gained from Moore's substitution, from Moore's substitutional system, and vice versa. Moore's system can be gained from this example. There are uh other uh examples very interesting like L Z L and Plight, the group risk so-called risk product of Z2Z. Hanoi studied by many people. Okay, Hanoi Taver groups it acts on terminally three, here's a ramsonic. Collaborated with me on this example. Basically, he invented them. Iterated monodromy group of polynomial z square minus one. Originally, it was defined without any idea of iterated monodromy group, but which played a very remarkable role now. In particular, in Dumper theory and the whole microdynamics, iterated Mondor-Romi group of C square plus I. Of C square plus I studied by Sunik and Southuk, Southjuk, Metro and Sunik, and many other examples, but they cannot be described as simply as I did just previously, like showing how they act on the interval. This requires a little bit more work, and I will define next time, but But what? But now I have to give the main definition of this conference. I was sure that this definition will be done much earlier. But, okay, don't project to spectrum. Yeah, you know that if A is the operator, then Operator then uh spectrum of A is a set of lambdas such that A minus lambda identity is not invertible. Now, if you have bench D tuple, so now A is A1 A D d tuple of operators in Of operators in public operators, say in hippocamps space or elements of one algebra, say unit of unit, and so on. And then you can consider pencil, linear pencil. Here are complex numbers, linear combination of operators, we say, like variable. like variable Zi and define joint spectrum which I use a different notation. So this definition was given by Rodway, Young, and I use a different notation. So set of Z here is a double of Zi, so it's element of C to the power D. C to the power D, uh, set of Z belonging to D-dimensional composite space, such that A of Z is not invertible. It's not invertible. And zero, of course, belongs to this set. But if Z belongs to sigma A, then Tz also belongs to because of linearity, so Linearity, so therefore we can consider factor we can consider factor sigma A. I put like a p projective, so it is a sigma a characterized by non-zero. Non-zero integers, and this is projective projective joint projective spectrum according to Rondui. And it sits in it's a subset in what in CP D minus one, projective space, topwood projective space. And moreover, Rodway proves that it is compact. Glow compact, non-empty compact subset. So, this multi-dimensional version of spectrum because of this wonderful definition. Can I ask a very dumb question again? It's a non-empty compact. It's a non-empty compact subset. Isn't it algebraic? It's a variety. It's a variety, so it's focused on empty and compact. No, because he's talking about operators, infinite dimensional space. Oh, okay. Not in this case. Oh, okay. Not in this context. If you deal with finite dimensional hippers, yes. So to reconcile it with the classical definition, one has to take the couple A and B identity, right? Yeah. So this general concept, but if one says the first one operator is just identity operator, and if it happens that you have some operator, say Mark operator, such that for Size that for certain values of Z1, Z2, Zt and you can get M as a linear combination of A2 AT. Then from the joint spectrum, you can find spectrum of M, just you have some strange subset, and you cross by a line, and you get. And you cross by a line, and you get spectrum of your parameter. Okay, and now maybe last minute. I'm risking a little bit, but now let me call, say that, so we have a joint spectrum problem, generally, like spectral problem, joint projective spectrum problem, invented by Adon Quay. I call I hold that this problem is renormalizable if there is R map from projective space to itself. Is the property that R inverse I just denote sigma, as I said? The image of sigma is sigma. So, So sigma is R in variant. R invalid, and moreover, I prefer R to be a rational method. In the sense of algebraic charms, it's not just a defined. Yeah. Okay. Yeah. So this problem is re-normalizable if there is such original transformation. Original transformation R, and not everywhere defined, but for which sigma is invariant set. And then, if this happens, we are in a situation we have R and we are obliged to find a suitable invariant subset. So, when you take R inverse, are you taking the closure of the inverse image? Or are you taking it's typically the indeterminacy order, as Putin mentioned too. Deterrency orders, but mentioned too. This is not a rigorous definition. At the moment, we have a bunch of examples and some minor variations appear from example to example. So I don't want to give rich distribution, but this is the idea. Idea of renormalizations comes in this way to this spectral problem. And next time I will give notrival. And next time, I will give notrival examples of application of this idea. And these examples are coming from my joint works with Alaron Batoidi, Takliana, Voloida, Zoran, Metrosov, Chukhazo. McMilla. Okay, thank you. Sorry. Took too much time. Thank you, Stephen, for the talk and the end question. Maybe just a comment regarding the questions. Usually we consider where R has only a finite number of singularities. And it's called a rational map. Some people call it a neuromorphic map. I am sure the rational map. The operators A1 up to AD, do they have to commute or not necessarily? Absolutely, no. Any other questions? Costumes? Would we define those three groups by permutations on the interval? And you said that the first two were contained in the overgroup. Was this... Sorry, I think that's what you said. Is this overgroup? It's not canonical in some instance, is it? Maybe not. Okay, nevertheless. I don't I you ask I brained because I had mentioned this group. Dihedral loop uh embeds into the fa roof Into the group associated with the Morse system, it embeds an overgroup, and the group with the minimal growth embeds in overgroup. Okay, we were just calling it an overgroup because of the other sort of embedded inhibits, right? Such name was given, and one can use, one can decline. Feel free to answer this question if you need to get out. But what do you mean by renormalizable? I will try to start the next lecture because I'll say that one. I guess the rational map is regular and never became the signal. In the examples you have, the rational map is regular and neighborhood signal. The singularities are not in the signal. The singularities are not the same. So the singularity becomes a part of the tribute. The singularity is considered as a tributary. So I mean. I do. I'm extra second. Will you reveal to us the second part of this five minutes relate to the first gift process? Yeah, sure. Like how this self-similar groups relate to the joint spectrum. So we're looking forward to the second part of the second one. And we see the mid forward. I'm preparing to do it. So you can remember that. So if you can somehow think about any algebraic system, algebraic. Okay, six-based months. So I'm going to use it. All the similarities can be matched as if you might have a rationale. All the examples of this. A rational example of this do this actually is one of the binaries. So, the question is: if you have a rational, always, of course, one example of a close rate. The map parts very difficult for the slide as well. They are easy to write, you can easily write. There are also cheap patterns. 