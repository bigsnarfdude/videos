Yeah, I mean, I think it's possible. Okay, uh, before we continue with uh the second part of uh Ben's tutorial, Second part of Ben's tutorial: I have a very important announcement regarding coffee, an important subject to most of us. So, the coffee machine over there, like it's the spreadsheet of the genome, blah, blah, blah. Unfortunately, they asked you to make a small donation to the center if you use it. I think it's five or six dollars. There's a sign there which specifies the prices. So, if you use that machine, please make sure to also leave some cash over there. But the coffee over here, like the filter. Coffee over here, like the total coffee is for it. So, yeah, just if you add a coffee from the other machine, these are the elimination of it. Yeah, now we can continue with Ben's second point. Okay. Thanks for coming back. Okay, so I'd imagined at this point I was going to have already explained what KO is to record. It's recording. It's recording. Yeah. Yeah. Did they come back? What did we on your Zoom? Ah, let me see. I'll let you know in a second. They're all there. It's fine. All right. So I imagine by now I was already going to have told you flow K codes. I told you all about those. But now that's going to be quite a big part of it. This was how it was going to go in my head this morning. My head this morning was: I was going to save locate codes, and I was going to try and push this. I want to have these sort of demystified in a way a bit by showing you them in the space-time picture, because really they end up looking exactly the same as error correcting with the surface code or with the Raussendorf model, just up to some slightly different geometry in this 3D space-time. So that's the thing. So that's the space-time. And then I also wanted to, like, the other reason why this space-time picture is nice is because it sort of shows us how things work when we try and do logical gates with these codes. Like, so far, all I've really talked about is memory with codes. But, yeah, in the space-time picture, you can really see how gates go wrong and how you make sure that they're tolerant to a large number. They're tolerant to a large number of errors. So I have a few things to say about that. But I'll maybe talk about lattice surgery. And again, everything, I'm trying to push everything back into this space-time picture. I should have just, this is in space-time again. And what I thought I was going to have a bit more time to do was talk a bit more about sort of open problems. More about sort of open problems in logic gates with LDPC codes. And because there are all kinds of interesting questions there, I think, where we really need to think in this space-time picture for how we get the most out of those. Because we have this really nice theory of these good codes that encode n logical qubits with n physical qubits, and they all have distance n. But I think there are some questions. But I think there are some questions to ask about that, just like how big do we need the distance to be anyway? And are we really optimizing the right things? But we also need a better theory for logic gates of those things, LDPC codes, because it could be that all the savings we get for storing our qubits in LDPC memory are just lost because we don't have a good theory or any good LDPC gates. But if I have time, I might say at the end, well, we often call it a Larry. What we often call it Larry Gates. This is, I'll be telling you a little bit about one of my papers. So, Larry Lawrence Cohen is the first author on this paper. So I sometimes get called Larry Gates. But this is really a generalization of lattice surgery to LDPC codes that does, you know, can work in a fairly resource-efficient way and certain limits in a way. We could come up with some practical. A way. We could come up with some practical things. But the main trick in designing these Larry gates is really a trick by Hastings using what he calls weight reduction, where he had this idea to reduce the high weight stabilizers of some non-LDPC code with this trick he calls weight reduction. And we found we could use that to design LDPC code lattice entry operations. So if I have time, but this is a. I think I can talk about these two things for a main part. These two things for a main path. Okay, so flow K code. Floquet code is, yeah, I want them just demystified a little bit. Again, they're very cool. I don't want it like diminished how exciting they are in terms of practical error correction, but I feel like the theory around them should be kind of a bit more, yeah, like you should line it up with the. Yeah, like you should line it up with the existing theory and sort of stabilize the picture that I've been building up. But yeah, so the idea of a floquet code, so I don't even like the word floquet code because floquet, you know, it's a nice word to kind of market your ideas. And floquet in other parts of physics is exciting, periodically rhythm. But I mean, they're not really, it doesn't. They're not really, it doesn't, the periodicity isn't actually that important to their construction. Like, it's nice to make them periodic because they're easy to sort of reason with. In practice, you don't need periodic sequences and measurements to make these things work. They're more like, I call them dynamically driven or maybe measurement driven. In fact, a paper by Margarita Davidova and some others, they talked about what they call automorphism codes, and they said. Automorphism codes, and they said it was really important to kind of floqueify a color code, and they deliberately make it non-periodic because that helps with gates. Yeah, that's what that is. Okay, but what I want to do is I want to show you how LDPC works. 4K code works. I want to explain it in terms of a code deformation, which gives me a chance to tell you a bit about subsystem codes as well. And code deformations. Just a special case of those. Special case of those. And yeah, and then I'll map it into the space-time picture, and then I'll get on to some lattice history. So, okay. So, the way I'd like to think about, so here's the code I have in mind. I have a hexagonal lattice that I can three-color such that every hexagon has a color, and no two touching hexagons have the same color. Hexagons have the same color, so that can be red and blue, red, green, and blue, like this. So, yeah, so we talk about fliquet codes. We call them instantaneous stabilizer groups, or ISGs. But really, this is just a stabilizer group. It's not any, it's just a fancy acronym. Any, it's just a fancy acronym for another thing we already have. Okay, but so let me let me explain the stabilizer group to you though. So, well, one instance of this. So, flow K code works as follows. We have some code and we perform some sequence of measurements such that stabilizers are read out and the code is kind of dynamically changed. So, it's a little different from the stabilizer codes before because before I was just measuring these stabilizer operators that communicate. Stabilizer operators that commute activity on the code state, and so nothing is really changing. In flow K codes, I measure some, so I keep running measurements that don't commute with the stabilizer group at some given instant, and that transforms the code a little bit. It projects it onto a new code, but it projects it onto kind of itself, up to some spatial translations and relabeling a paleophyte. Relabeling a pally operator so you can kind of find you then complaining about the instantaneous stabilizer group because it is instantaneous, huh? I mean, it's yeah, it keeps changing, but an instantaneous, an I, an IST is just a stabilizer group at some given point. But we keep changing it with measurements. Yeah, that's true. Okay, so this is the flow K code. It has, on the red faces, we have just one Pally X stabilizer. We have just one pali x stabilizing like this. On edges, so that this would be a red, and this would be a red, and this would be red, and this would be red, and this would be red as well. So on edges that connect a red face to a red face, we have a stabilizer there as well that looks like XX. Yeah, one here, one here, and there's one here, and there's one here. And that these are all red as well. These are all red as well. These are all red edges because they connect red to red. Now, on all the blue and all the green faces, they have two kinds of stabilizers. They have an X stabilizer and a Z stabilizer. By which I mean, so the qubits from the vertices. I didn't even say the qubits from the vertices, but that's where they call me aspects. I forgot to mention that. Okay, so on the green and the blue faces, they all have an X stabilizer, and they all have a Z stabilizer. There. And they all have the Z stabilizer on those placets. Okay. And right, so what I'm going to do is I'm going to do, I'm going to make a code deformation, which is where you measure a bunch of, so code deformation is a way of transforming stabilizer codes. And the way you do that is you just make a bunch of measurements that project it onto the thing that you want. That could be a terrible idea. You can make a big measure. That could be a terrible idea, you can make a big mess. But if you choose a code deformation in a smart way, it can tell you things about stabilizers, it can help you do logic hates, all kinds of things like this. Uh-huh. I was just confused. You have X and Z letters for every packet? Except the red one. The red ones have only an X. And that's because on these red edge terms that are two body XX terms, I can't make this XX term for me with a zeplicate on a red face. On a red face. Is there just one red face? Well, there's one here. I mean, if I drew the lattice bigger, there'd be one here as well, and there'd be one here. I mean, I'm not going to. I don't have time to draw an infinitely big lattice. Sorry, I didn't hear. I guess I'm just give you um some I'm confused about how this is constructed, but Distance structure, but uh drawn this like matching line the red faces are the ones that the red ones the red ones red edge a red edge has a red face and a red face at both of its endpoints. So it has a blue one to one side and a green one to its other side. But th I mean this is just th these things have to exist for the three colorability to to work. Vulnerability to a web. Uh-huh. I mean, why is it called like code deformation and what is deformed? Deformation is just like change. And I project it onto a new state. But I have to do it in a clever way. It's just like applying a clipboard to I wouldn't want to think about it that way. I'm just measuring a bunch of paleo operators. Okay, but like several things can happen. Okay, but several things can happen, right? So the goal of this code deformation is to measure some stabilizers, to actually initialize some new stabilizers. But in doing this operation, I also kill some old stabilizers. So what I'm going to do is I'm going to, here I have, it's going to confuse the value of those contrasts. Okay. So what I want to do now is I want to, I'm going to measure, I'm going to take exactly this lattice. I'm going to take exactly this lattice, and what I want to do is I want to measure the blue edges. I'm going to measure ZZ on these blue edges. So everywhere I've done a blue ZZ every blue, I had to have colored in. Measure is easy. Measures easy. Okay, I think I got them all. Yeah. Okay, so that does several things. So, first of all, I'll start with the bad news. This is actually going to kill some stabilizers off. So when you measure in the stabilizer formalism, the first thing you do is you look for, you make a paleo operator, you choose the paleo operator you want to measure. The Pali operator you want to measure, and then you look at your old stabilizer group before you made the measurement, and you look for all the stabilizers that don't commute with that PALI measurement. And essentially, you throw out all the stabilizer generators that don't commute with that measurement. And well, that's all you need to know. Okay, so because there was a Z stabilizer on these blue placets, Sorry, an X stabilizer on these blue placets. But because I'm measuring, because my X stabilizer here is not communing with, say, my blue H term here, all of the blue X pliquettes get kicked out. So the way I'm going to represent that on my diagram is I'm just going to draw a Z on these guys. This indicates that the Z stabilizer over the C survives. The Z stabilizer over the C suffice because these are Pally Z stabilizes and they can meet with Pali Z measurements. So I do remain in an I have a plus one eigenstate if my Z plaquette stabilizes on each of these. Okay. But now I do also get to initialize some new stabilizers. Okay, so let me just say, so loop X stabilizers are dead. Are dead under this transformation. But some good things happen as well, because if you remember on my replica, I only had one X-type stabilizer. But in fact, I can take the values of these blue edge terms, and their product gives me the value of this red Z stabilizer as well. You can see that because if I measure Z. You can see that because if I measure ZZ times ZZ times ZZ, then their product gives me the product of, yeah, it gives me the value of the plaquette that wraps around the red faces. What's more, obviously, because this is a two-body ZZ measurement that shares support of two qubits on the red pliquette, I get to keep the X stabilizer as well. X stabilizer as well. So to show that I have an X and a Z in this new model, I want to color it in, I'm going to color it in red, represent that. Now, the last thing is, so, okay, so red, Z stabilizes, these are initialized. So So this is important for making a detector later on, in the way that I was describing with the stabilizer codes at the beginning. You explained this beautifully, thanks for this. And I mean, there's many nice explanations of flow K codes and what the internet stabilizer group is and what the detector models look like. But I find it not so obvious to find an automated construction scheme for flow. Automated construction scheme for floating codes. People cook it up and then the IBC CBA schemes and so on. And then they discuss them, but I mean, I wouldn't know how to make a one-size-fits-all procedure of generating cooking codes. No. It doesn't seem to be much lifted on this either. It's not something people do. It's a bit of an art. Yeah, but why? That's why the question is a bit about my code switching dangerous, like, there's certain conditions. Like, there's certain conditions need to be satisfied for you to even preserve the logical information. Like, it doesn't have to be an isometry having input and output to be the same, each other. It's something that we, you know, would be. Yeah, well, that's true. So when I make these transformations, something I'm really glossing over is that the logical information does survive, but it's actually transforming in quite a non-trivial way through steps. Right, and somehow like these trivalent lattices provide natural ground where all this focus. Is provide a natural ground where all this code switching works out magically. Okay, I know it, I get it, but I want no matching for a change. I do too. And I don't want tri-vale. I'm tired of tri-vale. Yeah. All these emotions, yeah. Well, I can maybe say a little bit about the maths of the component information in a moment, too. Let me, can I do that later, though? I don't know if you go. Sorry about the pause. Don't say sorry. Okay. Uh but uh okay so the last thing is I also want to measure some stabilizers uh to check that I've got to check for errors as well, otherwise there's no point in this whole exercise. So if you remember I have an X and a Z stabilizer on my green pliquet. Well because I already knew the value of this green pliquet when I infer its value by looking at this ZZ times ZZ times EZ I know that I should recover the value of this stabilizer Recover the value of this stabilizer that I had in my last step. So by comparing the products, by inferring the value of this pliquette, by taking the products of these blue terms, I get to determine if any errors occurred on that green pliquet. Yeah, between having prepared that green stabilizer and measuring it by inferring it from the values of the blue edge tent. Okay, so I'm going to. Okay, so I'm gonna the green uh Z stabilizes measure. Okay, so I guess I think I didn't explain this ever so well yet, but that there's a distinction between so when I because I was already in an eigenstate of those green Z stabilizes, when I measure them again, I get to double-check that I got the same value as That I got the same value as I'd prepared. When I measured these red Z stabilizers, I've used the word initialized and not measured here. I've initialized them by measurement. But because over here I wasn't in an eigenstate of this red Z stabilizer, when I took the product of these, when I inferred its value by taking the product of these three blue terms, I get a random outcome. It could be plus or minus. It could be plus or minus one. And that's fine. I can work with that. If I had a, there's nothing to say that the stabilizers in my group have a plus or minus one sign in front of them. Again, this is why this detector language is quite useful because it doesn't, I don't really care if it was a plus or minus one at the beginning. All I really care is that that value hasn't changed when I come to measure it again. Yeah, so the point is, when I initially The point is, when I initialize this stabilizer, I'm not using it to detect any errors just yet. I'm just getting some random outcome that I just have to write down somewhere. Because in this case, I've really created, I've measured, I've completed a detection cell again, because I was already in an eigenstate and a green instead stabilizer. So when I measure it a second time, I expect the eigenstate to be unstable. Okay. So, what's to say about that? So, you can maybe convince yourself that I've really, you know, up to some minor details, I've really almost, I've transformed the code, but I just want to convince you now that I could do this over and over and over again with an appropriate choice of measurements. So, I went for this instantaneous stabilizer group, stabilizer group with red X. Group with red XH terms having been measured. There are my stabilizer groups. And now I have transformed into this ISG with the blue Z stabilizers having been measured. These ones. Oh, so it's worth mentioning that I'm no longer in an eigenstate of these red edge stabilizers either, because they don't commute with my blue X stabilizers. Okay, but you can really think of this as being the same as this model. Is being the same as this model in the sense that, well, now on two of my placets, on my red pliquettes and my green placettes, I have an X-type stabilizer and a Z-type stabilizer. Now that's kind of the same over here, except in my original code, it was my green and my blue stabilizers that had two types of stabilizers on them. But if you were, if you're happy, just to. There's a color symmetry here, right? So, like, up to some color permutation, I've kind of recovered. Mutation, I kind of recovered this model again. And likewise, in my first version of the model, I was in an eigenstate of an X stabilizer on the reds. And now I'm in an eigenstate of just a Z stabilizer on the blues. But again, like, we all understand, well, there's like a symmetry of these Pali operators. And if I just relabel Pali X to Pally Z and blah, blah, blah, then essentially this model is the same as that one. The same as that one, up to Pali relabeling and colour relabel. Maybe the spatial transformation. Uh-huh. Sorry, I just wanted to see if I'm following. But like what happens to the logical code space when you change the stabilizer group? It's not the same. It does have some commonality. So let me. So let me. Okay, maybe now's a good time to talk a little bit about subsystem codes. So now. Is it variable subsystem codes? Kind of, yeah. So what I've done here is I've projected, I have one stabilizer group at the beginning, so let me call that the red stabilizer group because it has the red edges in it. And then I project it onto a new stabilizer group. A new stabilizer group with the blue edges. Let me put the red X and then the blue Z. Okay. So there is a, this is a code deformation. So there is a, you can kind of come up with a theory a bit later. So the point is, so more generally than stabilizer codes, we have what we call a subsystem code, where we have what we call a gauge group. And the gauge group is And the gauge group is, yeah, it has a bunch of non-commuting checks. But from the gauge group, you can infer it has some stabilizer group that is kind of related to the stabilizers of these guys. But the stabilizer group of this subsystem code is the stuff that commutes with the gauge. With the gauge and is also included in the gauge. And likewise, I have some logical operators that, well, they also commute with the gauge, but they're not themselves members of the gauge. But the whole point of having your stabilizers that can even Your stabilizers that commute with the gauge group means that you can measure these gauge terms without violating your stabilizers. Gauge group is defined by both, by both stabilizer groups. Yeah, that's right. So this is that's right. So yeah, so the yeah, for this particular code definition, exactly. So I can think of this as being this stabilizer group as being, sorry, this gauge group as being the union of both of these. As being the union of both of these. Like that. It's not a group. What do you mean? But they're still just subgroups of the Pali group. Martin is right, they could be subsets now. Yeah. So you take the group generated by the union, or? Yeah, yeah. I just want to combine the list of all those operators. I wasn't trying to say anything too. I wasn't trying to say anything too. Oh, then I took it as on a group? Why not? It's just. Usually, when I take the union of the subgroups, I don't get a group, but I can't take it generated by that. I don't know what you mean. It's just a bunch of paleo brain. Like, there are some. Like, I have the two-body checks here, I have some two-body checks here, I have some forget terms here, and I have some forget terms here. I just care about all the stuff I can generate out of this. All the stuff that I can generate out of those terms. Yeah. Oh, okay, yeah, sure. Take the generators of both of these guys, and I get whatever group I generate out of. Yes, both of them. Yeah. So this is just, like, I don't know how you want to write that down. I just want to say that. Like, like that? Thanks. All right. Sorry. Yeah, that's right. So the log without I can work out what it is if you want to, but there are some logical operators that are consistent through this transformation from here to here. And I can work out what they are if you want to. Something like, yeah, just don't talk. Don't talk, well, don't talk, I'll just go work up there. So it'd be something like, yeah, okay, so it would be red Z and blue X. Okay, so both of these models, like the group of both of these stabilizers, there is a Z, there is a Z modical that runs through the right edges, and that commutes with the stabilizer loop, and it'll This stabilizer group, and it also commutes with this stabilizer group, and that will anti-commute with the X stabilizers that run through the blue edges. So the blue edges would be, so that was my, where's my, yeah, perfect. So like, this guy made out of X's is gonna, like this. So I guess the point is, uh, uh Like through, no, so in fact, in this code deformation picture, the logical operators aren't really changing very much or at all. I have these two operators, a string of Z's running through the red edges and a string of X's running through the blue edges. These logical operators are the same in both the before code and the after code. Can I ask? So I like this perspective where you have like this subsystem code. Perspective where you have like this subsystem code to define the transition between one ISG and the next. But then if I so I've got like ISG one, two, and three, and then if but then if I so I have a subsystem code defined by like the consecutive ones. Yeah. And then the interesting thing, I think, is like the intersection of these two subsystem codes, and that's where like the logical reps change. Well, I'm saying I'd rather not talk about that. That's why I've only talked about two and not said one. Like when I came, if I were to come to When I came, if I were to come to do a trend, when I get to this picture, I'd really just prefer to talk about, but it doesn't really, like, the third instantaneous stabilizer group we have doesn't really care about the first one. Like, I can describe everything going on here. I agree. I think you should have like a subsystem code for each two consecutive. Yeah. And then, and then it's like, but then you do, like, to answer this question about, well, to try and make progress on where's the trivalence, like, you don't really need trivalence, you need this like change. You don't really need trivalence, you need this chain of subsystem codes where they've got like a kind of like overlapping gauge choices. And then, and that doesn't really require trivalence, it's just the trivalence allows you to construct subsystems. Uh-huh. Yeah, sorry. But well, yeah, sure. But I guess the point is I had logical operators that commute, yeah, they survived this transformation. Yeah, I guess the point of a gauge, sorry, the whole point of a subsystem code is I can selectively measure different. Selectively measure different parts of the gauge group to, you know, for whatever means I want. Like in this case, I'm showing you very explicitly that measuring the blue Z edges is going to give me a certain amount of stabilizer information. Uh-huh. So in this subsystem code, I mean, because the Gaussian is larger, right? I mean, is there like less logic information in this? Less logical qubits? It depends on the battery conditions. But so another thing I want to show you is that this. But so, another thing I want to show you is that this is also just a Tara code. Yeah. This is a Tara code. Okay, but look. Yeah, so by which I mean it depends on the boundary conditions, how many logical qubits this is going to encode. But for now, if this were periodic boundary conditions, you get two logical qubits. Uh-huh. Uh-huh. Basic question. What is the advantage of this code over the Tori code that you just showed? Well, as I said, the implementation is more practical. There are lots of experimentalists that would like to be able to do everything just with two-body measurements. Whereas it has six-body measurements. Yeah, but in this code deformation, I've just measured blue ZZ edge checks. So that's in the Toronto code you have the four. Yeah, four body stars and pliquettes. That's right. And that, you know, so the apparatus, the circuit to measure that is quite significant. So basically, the whole point of this is that you now get away with like doing all your stabilizer measurements with these like two body things at the cost of that having to check out the code changes. Yeah, that's right. That's right anyway, right? I mean, just a classic classical process. Yeah, in a way, that's right. Well, in the space-time picture, yeah, everything. Time picture, yeah, everything just looks very boring again. So, I want to get to that. Sorry. I mean, you're pushing the code out into another space, but before the errors were doing that or anything. So, like I said, you have to keep track. Yeah, yeah, you have to track it. Because you're always moving. Now you're just helping move the space. That's right. Okay, so let me try to give you a picture of how error correction is really running here. So you can come up with, you can see that there are a lot You can see that there are lots of different choices I can make. I can choose to measure Pali X or Pali Y or Pali Z edge terms. And I can choose to measure them on the red edges or the blue edges or the green edges or Ivy Light. Right, and different sequences of these are going to give you different types of measurements. So I've explicitly talked about what happens if you go from red X to blue Z, and these are the changes that happen. The blue X stabilizers are destroyed. The blue X stabilizers are destroyed, the red Z stabilizers are initialized, and the green Z stabilizers are measured. Okay, but if you want to run error correction, I hope I gave you a sense already that I want to be measuring all the stabilizers, as many stabilizers as I can in all the different bases as fast as I can. So you want certain sequences of measurements that kind of go through all the stabilizer measurements I would want to make before. To make before something catastrophic happens. Right, so there's a bunch of these codes. So, like, these were introduced by Hastings and so they began by introducing the Honeyco code, where essentially what they do is they have this sequence, where they measure red X, and then they measure the green Y edges, and then they measure the blue and Z edges, and then back. The edges and then back again. I want to talk about CSS floquet code. Several people discovered this kind of simultaneously, including a paper I have with Jens and some people at Sydney and some people at Jens's group. So we call this the Flo K color code because of how we came. Color code because of how we came up with it and sort of a very physical picture. So, what we measure, the sequence we measure here is going to be red X, and then blue, say green Z, then blue, X, red, Z. Can you see the pattern? The colours go red, green, blue, red, green, blue, and I keep alternating X, Z, X, Z, red, Z, green, X, blue, Z. And then back again. So, yeah, these are periodic sequences. So, let me try to show you what a detector cell looks like in this picture. Okay, and I want to concentrate on a, let me see. Okay, so here, over here, I've kind of drawn this to make life a little easier. So, I'm going to talk about one blue cell, okay? And I measured a hang on, let me just see. So I've got my blue cell here. And I start off by measuring these red X edges. These are red X. So I'm at this step right now. Red X. This is my space. I I drew this before the toolkit settings. For the torque static is, I thought it would take a long time in the middle. So, time is running up. So, here I measured some red xx edges, like this. So, what I've done is I've initialized the blue x pathetic at this time. So, there's now an x check here. And at some later time, throughout this period, I'm going to double-check this to see what errors might have occurred over the space-time. So, I just want to. Over the space-time. So, I just want to go through what happens as I go through this. So, an important thing we have to check is that this blue X stabilizes, survives until I double check it. Like, if I measure something that doesn't compute with this check and it dies, then I can't use it for action anymore. So we're going to see that that's going to be okay. But let's just see what else happens, right? So I measure my green edges, and these are ZZ edges. So you should be a little bit cautious because these. Bit cautious because these maybe don't, well, this is an X stabilizer, and I'm now measuring Z terms, but you can see that the green edges overlap with the blue plaquette on two sites everywhere, so they're immune. Then I measure some blue XX edges, so they come in towards the touch this placet on just one site at a time. But because this is an X stabilizer and these are blue XX checks, everything's still connected. Everything's still curved, so I still have an aggregate state of this guy. So we're nearly there now. The next step, I measure red ZZ checks. And just like the blue ZZ checks, the red, the two-body red terms, they're commuting with the six-body X check I initialized in the beginning. And then finally, I measure green XX. Green XX at this final top step, and this double checks it like this. So this is, so now I can compare the value of my blue I can compare the value of my blue X check that I made at this final time to the blue X check that I made at this time and as I've argued through all the steps in between here and here. Through all the steps in between here and here, all of the edge checks I made commute. So I really had to detect it from here to here. And then finally, so then I killed it, right? The last step is to measure this blue ZZ, which, okay, my volume periodic, so this ZZ term, this actually destroys my detector. So that's dead, and I have to re-initialize. So that's dead, and I have to reinitialize it again at the next step. So, this is my detector in the 3D space-time. Any errors that occur between the time when I measure my red X checks and my green X checks, that's when I'm detecting Z errors. If a measurement error occurs when I make any of these edge checks, then that's also going to violate this detection cell. So, let me just say a little bit more about this space-time picture. Bit more about this space-time picture to show you really how arrow function is done. Because first you have these detectors, it's like parities of stabilizers. You also have detectors that you don't have stabilizers. Because you said this whole thing is a detector now? Yeah, that's right. It's a little bit more general. Yeah, that's right. It's a little bit more general because now. So you agree with me, though, that the product of these x checks should be the same as the product of these x checks. So there is a constant here where you know something should be the same at an earlier time to a later time. Yeah, but you're right, it's a little bit more general in the sense that now my detector depends on three measurements at the beginning and three measurements at the end, whereas before my target benefit stabilized was just one measurement and one measurement. With just one measurement and one measurement. So it's a little different, but it's in principle kind of similar. That's another question. It doesn't always say no because how can you ever be sure that you have all detectors? I mean, I see your detectors, the dimension, but something I'm often wondering about, like you have detectors, but then there could be others. Is there a way of ruling out? You can generate more. I mean, I. I mean, of course, this is a construction. Of course, this is a kind of generator, but independent ones. I would argue that it's kind of obvious that in this case that we have all the detectors from the, and I would argue that from this Rassend light picture where I have, you know, like, so I can make a measurement-based version of this as well, and it looks just like the Rassendorf model on a The Rasmalt model on a different lattice geometry. And yeah, whereby you kind of have one stabilizer per cell. And this would be the same. And then if you can convince yourself, if you're satisfied that there should be one detector per cell, and that should generate all the possible detectors, then I don't think you should get any more. It's very very simple questions, but um I mean like worse than the like the definition of what a detector actually is. Like uh this is like a time-like stabilizer or yeah yeah that's right. Um okay sure it's good I'm getting lots of questions. Okay, so let me so I want to argue so here's here's the thing with this three-man lattice, right? I want to persuade you that error correction is just going to show up exactly the same way as am I for time. Am I for time? Am I only gonna? When did I stop? So you still have like 20 minutes? 20 minutes? Okay, forget all these things. Oh, but we were just in the second path. That was an open problem session. I can keep going in an open problem. That's fair. So here's the thing. The structure. The structure of this code is as follows, right? I've shown you one detector, and I'm going to argue I don't have to care about the x and the z checks because there's a symmetry between x and z. And the way we do CSS codes is we tend to just say, well, the x checks deal with the z errors, and the z checks deal with the x errors, and then y errors are just one of the product of both types of errors. So I'm I'm not gonna I'll argue that the x and the z are the same, so if I teach you how the the z checks work, then I've told you how the x checks work by symmetry. You have the x-checks float symmetry. Okay, and then here's the other thing: every single qubit touches a green, a red, and a blue cliquet. That's just a feature of this graph. Okay, so now what I want to do is I want to make this try and talk about what this detector does. Like, I want to talk about a green detector, a blue detector, and a red detector altogether. I don't want to argue that in this picture, That in this picture, every single error, be it a measurement error or a physical error, we're just violating two checks at the end, which is exactly the same as the Tauric code detectors that I talked about at the beginning, and also the Raspendal checks that I rushed through at the end of the last one. So, okay. Next, I just draw a few things. Not sure if I did enough. Okay. So Okay. Do X, do Z. Okay, so this is my sequence of checks, and time is running up the bullet again. Okay. Green, Z, green, X. And I want to just draw one detector. So I'm going to concentrate on this detector, this detector, and this detector. And they're all touching the same qubit. And they're all touching the same qubit. Okay? So the one I've just described to you is as follows. I measured the blue zone here. And at this time, when I measured the red x's, here, time is going up. So I measure my red x's. So this is all a blue cell blue base. Here I measure a blue X check, and then I make. And then I make the greens, the X's, the red Z's, the green X's, and that's where I double-check it. And then at this stage, I kill it. And then I do it again. So red X, up to that, like that. So that's what this cell is doing in 2D picture. Okay, but likewise, if I were to do this with, say, the green checks, I would have prepared it here. Have prepared it here with the blue X ones. It would be fine through the red Z, the green X, blue Z, red X, and that's where I measure it. That. And then I kill it, and then I make it again. And then it lives up to that. And then I would have been one here or not. Okay? And then lastly, on the red X checks, what did I do? I made Checks, what did I do? I made, I prepared it on the green step. I ran it for a while and I double-checked it on the blue extens, and then I killed it when I measured the red seeds. And then I'm gonna draw it's gonna be helpful if I just draw the I think I'll stop. I'll start down there with the screen. That would just be extra. And let me just redraw these blue ones again next to the red ones, because that's going to help. Yes? Okay? So now watch what happens. So remember, these are all, these detectors are just sitting on one qubit. Again, it's just this one, this one, and this one. So the first thing I want to argue is that if a physical error Physical error occurs on this qubit, the Z error shows up on that qubit. There's always two detector cells. There's always two detector cells here to pick up on that, right? So if an error shows up between the red X and the blue X, so this is where I destroyed the green check, the detector on the green cell. So there's no green cell there to detect it, but there is a red cell. To detect it, but there is a red stabilizer alive, a red detector cell, sorry, and there is a blue detector here. So if I were to, if a Z error were to happen at that instant in time between the red X and the blue X, then these two detectors got violated by that. Okay, what if it happened a little bit later? Well, look, if it happened later on, if it happened after the blue eye. Where, if it happened after the blue X check, where the red Z kills my red detector, well, everything's still okay because as soon as I turned off this red detector, when I measured these red Z checks, the last time I checked it was with these blue X checks. So there is a gap here now. But as soon as I measured these blue X checks, I also reinitialized this green detector. Like this. So if the error occurred after these blue X checks, the detectors I would see like that. The detectors I would see light up are this green detector and this guy, like that. Yeah, so what this picture is trying to show you is that at any given instant, there are always two detector cells that are monitoring a qubit for errors. And if any error shows up, it's going to violate those two detectors that are available at that given time. It just depends on what time the error occurs that determines which specific detector cells are going to light up. But I mean, that's kind of. Going to light up. I mean, that's kind of, you know, that's pretty obvious, right? Like a detector cell should just live there for a finite amount of time. But it's the same in the Tori code. If you remember these pictures from before, they're like, I have my four keyboards and I measure a check and I measure a check and I measure a check. You want these to be double checked very quickly because you need your error rate to be low. If I took a very long time between these guys, then there would be a long time for errors to rack up. That would be bad. So these detector cells just live a finite time before. So these detector cells just live a finite time before I kill them, and then I reinitialize them again. But what's going on here is, yeah, every time I kill a stabilizer, every time I kill a detector, I reinitialize a new one of a different color, and every single qubit is going to be monitored by two detectors at any given time. Now, likewise, how do you deal with the measurement error? And that's kind of the same again, right? So I nearly said it, I pretty much did say it before, right? I pretty much did say it before, right? So here, let's look at this point here, right? What does a measurement error look like? Let's say one of my green X checks got an error on it. Right? So when I measured this green edge check, this green X check, well, I made my final reading on my blue detector. So I've just completed measuring this blue detector. But so I've just double-checked that. And I'm about to kill this. Back, and I'm about to kill this blue detector. But when I measured this green X check, I also re-initialized my red X check. And I did that with the same, that two-body term has done both things at the same time. It's double-checked the blue face, so that completes the detector, and it then initializes the detector on the red. So, for example, this is where that green edge may have happened. Right there, where I get finished double-checking the blue detector. I get finished double checking the blue detector, and I reinitialize the red one. So if there were a measurement error on that green edge, it would make a violation from here to here as well. So again, a measurement error just looks like a string running from one cell to another cell. It just violates two adjacent cells. One where it was destroyed, and then the next where it was reinitialized. Yeah, so just to say, I mean, I think. Yeah, maybe I can push my problem with it with logic aids. But I guess what I'm trying to tell you here is you can really view you can view this a lot like these detector cells are a lot like the cells I talked about before, where this cell is adjacent to some cells at an earlier time through these edge measurements. It's adjacent to some different cells through the Some different cells through the physical qubits. And well, what am I trying to say here? Yeah, I'm looking for a more general picture. Like, I've shown you this space-time picture in several different ways with just repeating stabilizers in a repeating stabilizer measurements in an ordinary stabilizer code. I talked about the Tauric code. I argue that we have these same detector cells in this Thousand North model. And I'm arguing that these detector cells are cells. And I'm arguing that these detector cells are behaving in exactly the same way as well, where measurement errors create two defects. Physical errors create two defects between two adjacent cells. And yeah, so like, again, this was my aim, right? I was trying to show you that really when you look at any of these kinds of codes, the story is the same. It's just a different geometry, and we sort of tell it in a different way because of different physical notifications or funky functions. No, these are really just. Oh, these are really just. Ah, okay, yeah, let me. If I have time, let me just show you that. This thing is really the target code. Yeah, I had just enough time to show you that this is the target code. So let me pick what color it's still. Okay. So hopefully, so this thing, so let me go back. I'm going to try and argue to you that this guy is radiant to So, again, using exactly the picture I gave you at the beginning with qubits on the edges. And I put vertices on the six-body terms. And I also put vertices, so there are these two-body checks as well. So there's like an XX stabilizer here, and then there's a star operator here that goes next. And what's this? So in this model, I have this 6-body X stabilizer and these 2-body X stabilizer. X stabilizer and these two body X stabilizers. So those are supposed to be stars. So if I put a vertex here, drag it now to that, drag it in all the directions, there to that, there to that, there to that, there to that, and there to that. Thanks, because this is, yeah, this was something I didn't want to say, and I was getting a bit back to the other things. And I do the same from here to here to here. So I've drawn, this is what I've So I've drawn, this is what Moada's drawn, I've drawn it on top. Okay, and remember, so this is taking care of a six-body leg, one, two, three, four, five, six, which is this X hexagon right here. I also have this two-body term here, right? Because there's this red XX check there in this instantaneous stabilizing group. So this vertex is taking care of that. It's the X on this edge and an X on this edge. So it's a weird style. It's like a two-body style where I've just split an edge. I've just split an edge. There's also the text here for this red edge, one here for this red edge, and so on, right here, here, here. And then my Z checks, they're just these six body terms. Remember, plaquettes are just Z stabilizers on the boundaries of the plaquette. Well, there is a Z stabilizer here, which is, well yeah, it looks like Z, Z, Z. What is the vertex there? Z, Z. What is the vertex of Z? Z. And there's maybe if you had just one other question, which might be, well, why is there also an X check on here? Well, that's fine because I can generate this six body X check from these two body X checks. I know if that's a little bit of the magic of where the K codes come from, but somehow these two body terms give you some kind of extra redundancy, these little two body codes. There's some interpretation of these things where there's a subk code. Some interpretation of these things where this is some concatenated model. Some extra degree of freedom that she makes these transformations by measurements. But yeah, you can see pretty clearly that this is a tarot code model. I'm just, you know, honest to goodness, you know, cellulation of 2D manifold. And you can see I'm just transforming between it. So, like, to answer your question, like, do you get funky anions? Well, you get anions, you get in the quirk. Well, I think that's. I think that's kind of the signature in the space-time picture as well. I think that brings me to the end of the time, eh? Yeah, perfect. Yeah, thanks. I mean, we already had plenty of questions, so but I don't know if they're in class. So Martin has wondering about the batch address of the base code. Bettages of the two-phase code. So you said that measuring two-body simple might be easier. I think you still need to consider for simple record. Any comment on this and also on other advantages? I mean, I would say this is the main advantage. Let's see. Yeah, I mean, I think I'm probably not very good. I think I'm probably not very good at commenting. I think you should go to an experimentalist and ask if they're very good at having, say, a native two-body measurement or not. Like, yeah, one way you can make this two-body measurement is by introducing an anceler qubit and coupling and then destroying it. Yeah, yeah, but maybe your qubits have some native way of making this measurement. And that could, you know, your thresholds will improve a lot there because there's less. Will improve a lot there because there's less qubits on your device, so there's less apparatus to do these kinds of things. But it depends on having some actual device that can do that. I guess maybe closer to theory, like another advantage of this is that you don't have to worry so much about hook errors. Like in the case of the Torrek code, you have this four-body check and something that occurs in the middle makes some big two-body error. Make some big two-body error. That's annoying. But if you have a smaller stabilizer readout circuit, the amount of errors that can propagate onto your data qubits is reduced. I don't have a good way of quantifying that. Yeah, this is something you might imagine. But yeah, no, I think the interest here is practical. I mean, a lot of. But yeah, I think these things are really cool. I sort of maybe object a little bit to how they were introduced. They've kind of been sold as this new paradigm of codes, and maybe there's a whole bunch of things that we can do with measurements that we can't do with regular stabilizers. I don't really buy into that. I think this is a really cool, the codes, floquet codes, it's a really cool result in the sense. Codes. It's a really cool result in the sense that we have a very nice, practical way of realizing codes. I don't completely subscribe to them being something completely new. What I've been trying to argue here is that I think we should be trying to pull them back into some more familiar language. This code deformation, some subsystem codes, if you use this formalism appropriately, it doesn't look anything too special to me at all. And likewise, this space-time picture is, yeah, this kind of unit. Yeah, this kind of unifies everything between all the three, all the different models that I've been discussing. And yeah, like I say, the model we're talking about is really just Torrecode model just on a strange lattice geometry. So yeah, that's a good question. These are still very new. And maybe I'm wrong about this. Francis Pose OKs are the same as for Tori Pros. Yeah, yeah. Yeah, yeah. Now, so there has been a lot of follow-up work on these things, and there was a sort of spate of flocaifying the color code. And this has a lot of transversal gates too. And specifically that Davidova reference, Davidova L, they showed how to do all the transversal gates in the color code through measurements, and they did that by, you know, breaking the periodicity of their. Breaking the periodicity of their floquet checks. Yeah, and so they've got floating operations this way. So that's kind of neat. But yeah, no, it's not too surprising to me that you don't get significantly more interesting gates than what you would with regular. Actually, if I got to the latte surgery part, we would see that these were all exactly the same. In the space-time picture, it would be exactly the same again. This game again. Sorry, I got a little tight ahead fast. Sorry, yeah. Milad, so isn't the fact that you are making your stabilizers or AJMS time-dependent and that allows to have a logical update or something that you cannot capture if you don't have time-dependent stability? Yeah, well, that was kind of part of the mystery of that that was kind of put forward in the beginning. It was kind of written like, well, look, if we tried to treat this thing like a substance. This thing like a subsystem code where our gauge group includes everything you can generate by all the edges measured over all the time, then you just get nonsense. If I were to take a gauge group that's the X and Z checks on the reds and the blues and the greens, I just get nonsense. It doesn't have logical operators, it doesn't have stabilizers, it doesn't have anything. But if you just concentrate on one transformation at a time, I don't know, it seems a lot more reasonable. I don't know, it seems a lot more reasonable to uh just consider it as like a a code deformation of the in the subsystem code feature. I guess I'm just saying that the so this is was this captured with the previous, let's say the quick quote switching or using the subsystem feature. Even in that feature, you need time dependence on our logical operators, right? Yeah, well th th this kind of goes to to Michael's point a little bit as well. Uh yeah, over all the time you've got to be a bit careful about You've got to be a bit careful about letter transformations at multiple times. It's not. Yeah, no, there is something pretty smart about how these two buddy checks evolve the system over time that enables these kinds of things. Like error correction in this way. Yeah, I don't know if I have too much more to say about it. But yeah, I feel like. I guess I just wanted to highlight this new aspect of this. The time dependence allows you to do some logical object that is not necessarily captured by just looking at the subsystem for a specific time. Yeah, that's true. So it's not only about the physical implementation, also like conceptually the fact that when you're spreading over time, you have enough space to track your logical operators. That's not true. Yeah, so like I tried kind of ducking the question. I tried kind of ducking the question before with Victor or I don't know or by saying, well, through one transformation, there is a constant pair of stabilizer logical operators that just survive. But to go from the next transformation from, say, you know, instantaneous group two to three, then I need to like deform those logical operators to find the new logical operators instead of the next transformation. But they're they're in there. It's just I don't have to do these tricks. Like a discrete version of berry phase. Like if you go you start it and go three cycles and go come back to where you started, you can have it audible, right? They have a go up it, that's what they call it now, right? Yeah, yeah, they did. But like the thing they get isn't that much different from if I just say had the torrek code and then I just did a a hadama, a transversal hadamad and a swap. Like y you get a torrek code back if you do that. Um and you get the same oltomorphism. You get the same automorphism. Your Pally X is in your Pally Z's 12. But I guess I thought it'd be nice to connect this to Berry phase and fault R and gates you get in fractional quantum Hall physics. Because there, it's the same kind of thing. You do something, you come back to the code space, but up to a little transformation that only depends on the force details, the topological properties of the path, not the geometric details. Here it's kind of a discrete version, but it'd be nice to make that. Yeah, I guess. Yeah, why not? Maybe there are some logic aids you can get out of it, too. I mean, as you know best, I mean, like, letter searcher is very much intimately tied to boundaries. So I wouldn't quite know what letter searcher would mean in the LDC context. Can you give like the A one-line summary of what you did? Oh, yeah, no, that was. So, and the third thing that I didn't get to. Yeah. Yeah, no, well, that was, so we, yeah, like, Larry's paper, it's like this, right? I can do Clifford logical gates by measuring Pauline logical operators. So if I have stabilizer code S, there's a stabilizer code. S, that's a stabilizer group. And I want to measure logical L. Well, here's the trick. I make a new stabilizer group, S. I don't want Latin to see because I'm holding on. And I want S and I add to it the logical, and I put this in the stabilizer group, like that. So now this is a thing that I'm measuring. That I'm measuring. I've taken the logical and put it into the stabilizer group, so it's something I measure. And now I apply Hastings's weight reduction trick onto this new stabilizer group. Now, if this were an LDPC, these are all already low weight, so I don't care about those ones. I just weight reduce this guy. Oh, really low weight of the. And yeah, and it turns out that that's the same as doing lattice surgery. And that decreases the distance? If you use the. If you use the, if you use the, you can do it in such a way that it doesn't reduce the distance, but in general you have to use a lot of extra qubits to make sure that's not the case. That's why it's still a bit expensive to do it this way. Time for one last question. Yeah, maybe it's a little out here, but do you think there's a way to talk about necessary and sufficient conditions? I don't know. I don't know. That's a good question. Maybe you should talk to Alex. Maybe he needs to tell somebody about that. Benny Yoshida has a paper about that. I was also wondering the same exact thing, like, there should be some conditions on this space-time circuit stuff. So maybe just uh one announcement before we head off to lunch. So we lunch is from until one. Uh From now until one, uh, and then we have one hour of discussions or free time. Uh, and then we're gonna take a blue picture at two. So, it's gonna be outside. Make sure you bring some warmth clothes in your most photogenic self so that we can do it quickly. Uh, and uh, yeah, we can take it then the cross as you can take another question. I told you to like Maybe I don't know the difference between a unique and two size. No, I I I I know I know my clients take I don't see that. 