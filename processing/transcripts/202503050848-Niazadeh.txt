It comes from me trying to teach online matching in my PhD course and going through the hazard of hey looking at all these different algorithms and different primordial analysis, they all look different. And why do they look different? Shouldn't they all be kind of like the same under some unification framework? And in this tutorial I'm trying to actually talk about that unification framework through convex programming, which might be a little bit new perspective added to this tutorial. New perspective added to this initiative. So, before getting into the details, let me tell you about various models I'm going to talk about today. So, I'm going to, in particular, start from the very basic ones. By no means, this tutorial is exhaustive, so I definitely am not talking about all various online bipartite matching models, but definitely I'm covering the very basics. So, the most basic one goes back to the classic work of Cartwright-based learning. That's the online bypart matching. This is the one that you see This is the one that you see here. And what is the model? Imagine you have offline notes of a byproduct graph, and then online notes arrive. And an online algorithm should match these online notes in an irrevocable fashion to the offline source. And for the purpose of this talk, we are going to focus on fractional allocations. That means you have one unit of order, but you have to allocate this fractionally to the offices. All right? So that's kind of like the model. And a beautiful paper by Carpazier and Mazzi. Beautiful paper by Carpazzi-Vazzioli showed that there is an integral randomized algorithm that achieves optimal competitive ratio for this problem, which is one minus one over, and the competitive ratio is defined as the size of the matching that you get divided by the optimal matching in the graph. There was another paper which looked at the fractional version, had another algorithm which we will see throughout the talk called Royal Filling, which gets the same competitive ratio. Interestingly, the fraction Competitive ratio, interestingly, the fractions generated by the water filming algorithm are not the marginals generated by that optimal competency grammarizing the logic model. Now, looking at more extended models, the online vertex weighted B matching is another interesting model where you have capacities on the offline side, B1 to Bm, and each offline node has some weight, W1 to WM, and the goal is to maximize the total vertex weight on the uh in the object objective object. In the objective function. And this model was studied in various forms. So there is kind of a related model called budgeted allocation or adverts, as was studied in this classic work of Mehto Sabari Rani Vazirani in 2007. And the primal dual perspective by Bookbinder Noor. And then the vertex-weighted matching, the integral version was set in this work of Agraval Guel, Caran de Meth in 2010, and a very useful. And a very useful randomized primal dual analysis species indeed that's related to what I'm going to talk about was discovered by Devon or Jane and Kleinberg in 2007. So it's kind of like an overview of the Linux. Okay. So now we go to kind of like the higher dimensional version of the problem, and that's edge-weighted online matching. This is basically the same model, but now you have edge weights. And if you have edge weights, there are simple examples that show you cannot get any bounded component evaluation. Sure, you cannot get any bounded competitive ratio, but the moment that you start adding some more power to the algorithm, in particular, you let the algorithm to cancel the previous allocation for free. Then the problem becomes amenable to constant competitive ratios. And in particular, there is this beautiful paper by Ferdman, Corolla, Mirocky, Mutu, and Martin Paul that shows there is an optimal one-mythonic competitive algorithm. Optimal one-minute competitive algorithm for the fractional version of the problem. And to this day, it's open whether he can get the same competitive ratio by integral algorithm. We know it can beat half, but we don't know exactly whether 1 minus 1 over is H. And to just formalize this model, because it's going to play an important role in my tutorial, so once the node arrives, again, you have a refraction, you allocated the offline nodes. But on top of that, you have another decision to make, and that's the cancellations. So you allocate one offline node that it's So, you allocate one offline node that it's already been used using its capacity. Say capacities are one. If you over allocate, now you have to cancel some of the previous allocations, and these previous allocations have happened at different weights. So, you need to decide which weights you should cancel, and then the time moves forward, you go to the second time, and you make allocation decisions and cancellation decisions. Right? And there is this kind of like extension of this model with costly cancellation. So, I actually have a paper on this, which is exactly the same model as before, but this time when you cancel the weight, you have to pay a cost, which is exactly equal to F times the weights that you cancel times the amount of cancellation. When F is some parameter called buyback parameter, and it connects basically this literature to another line of work ECS on the problem called buyback problem. I will probably. I will probably tell a little bit about this in the second part of the tutorial, but today I'm mostly going to focus on the first model, the unweighted online reported matching, and the edge-weighted online matching between. And I'm going to show you a very maybe dry but mechanical way of coming up with the algorithm and also analysis for these problems. And I claim that this framework can be extended to almost every Can be extended to almost every extension that you can imagine. And the model of all extensions is this problem called configuration allocation or whole page optimization. And here, this basically extends all of the models I mentioned earlier. Again, you have an offline site, you have an online site. Imagine the online nodes are pages that the publisher is sending to the ADEX platform for displaying ads. Displaying ads, and the platform should decide what configuration of the advertisements you should decide on that page. So, there's this abstract notion of configuration, so there's a set of configurations. Every time that the page arrives, you have to attach a configuration to that page. And then based on the configuration I, the configuration C, the node I, and each offline node J, you have two numbers. So, one is the reward that you get per unit of supply that is allocated to that page. To that page. And there is also a rate of consumption of supply for that page. And then the offline nodes have some units of supply. And here, everything is very abstract. What does supply mean? It can have different meanings, but the meaning of a configuration, it can have different meanings. But at the end of the day, so you have units of supply that they should be allocated. These are my nodes arrive. You attach a configuration. Once you attach a configuration, it's clear what's the reward that you make per unit of supply from each of the Supply from each of the offline nodes, it's also clear how much you are going to consume the supply of that offline node. So, this is the way our model includes assortment optimization, edge-method only matching, tree disposal, etc., which I will give as an exercise at the end of today's tutorial for you to solve. All right, so let me get into the details. So, how you can design optimal competitive algorithms in this one. Optimal competitive algorithms in this one. So I should have mentioned this earlier. These are the kind of models that you make no assumptions on how these online nodes are arrived, for example. It's a fully adversarial model. And therefore, because a fully adversarial model, as an algorithm designer, you kind of have a trade-off that you need to decide how to handle. On one hand, you want to be greedy as much as possible. I said you want to maximize the immediate reward every time that you see an opportunity for an allocation. See an opportunity for allocation. On the other hand, you want to hedge against the uncertainty because you know there is more coming in future, so maybe you are better off using your supply in a more balanced way so that once new opportunity comes, you can actually match them in future. So there is this trade-off between greediness and balances. And the question is, how to have this trade-off? And then you look at this literature, there are values. Literature, there are various ways that they look at how to handle this trade-off. They typically find this notion of a score, a balance score, which is capturing the immediate value of the allocation together with the opportunity parts of the allocation. And then they say, hey, fractionally allocate to the offline node with the maximum score and make the allocation. And I think the people who invented these algorithms, they were so smart, they had much better intuition than. Are so smart, they had much better intuition than I have, so they could see through everything and could come up with the right notions of a score that would give you actually up to a competitive algorithm. But let's say you want to start from a scratch, and you want to design an algorithm here that has greedness and balances. But the first attempt is just let's be greedy, right? And let's actually write down a linear program for the greedy allocation. So I'm looking. So I'm looking at the onend bipartite matching profile at some time i when node i arrives. Let's say the state of the system is captured by this vector y1 to y1. So what is yj? So this is the amount of allocation so far to offline node j. So now the gradient allocation is very simple. So you're trying to, for the node i, you're trying to find allocations xij to different j's so that you maximize summation of xij subject to matching constraint. Basically, you have To matching constraint, basically, you have one unit of order to allocate. And also, you don't want to over-allocate any of the other often. So, xij should be at most 1 minus yj for every j. So, this part of this program that you see here is essentially the greedy algorithm. But you want to add more balancedness, and there are many ways you can think about it. If you're familiar with optimization, the first thing that comes to mind is that let's actually try to regularize the greedy algorithm using some convex regularization term. Convex regularization term. And in particular, I'm going to add this term to the object. So basically, function capital F, imagine the primitive function of some function little f of z. So little f is non-negative amount of increasing. Therefore, capital F is going to be strictly convex. Now I'm going to add this regularization term, which is the following. So you're summing over all the offline nodes. F of yj plus xij. Of yj plus xij, and this is the initial allocation level. Yj plus xij is the eventual allocation level. So basically, you are regularizing in that way. And to just give you some context, for example, if this term did not exist, then the solution would have been the most balanced allocation. And here you are going to get something between balancedness and goodness. Yes? Which I believe. So I arrived. At the time that I arrived, I write this convex program to decide on the allocation. No waits. No waits for now. Also, I hear you're looking at the model with bybank or with? No, no, just like the vanilla online bipartite matching process. Fractional. Fractional allocation. Number of types is highlighted. Number of times. Is primary. Number of times of types. Types. Types. IJs. IJs. Right, so yes, so the number of offline nodes is finite, so it's a finite model, so you have a finite number of offline nodes, and therefore the summation is always finite. That's what you mean by fine. Yeah, I mean, like, uh, for i, the value of i that the node can take. It's just one. So this is a matching problem, like an unweighted matching problem. Matching problem, like an unweighted matching problem. So if you allocate i to j successfully, if you add a frac, allocate a fraction of i to j, x fraction, you get x in the objective. But this convex program is just for the algorithm design. This is not the objective function you're trying to maximize. That's important to. Is there some compatibility in this something? Like I is only able to be matched with some subset of the GC? Yeah, so it's going to be captured automatically in the sense that these summations are uh over the neighbor. Over the neighbors. So, yes, I think it is. So, there is a neighborhood. So, IRS, there is a neighborhood that is going to be revealed to the online algorithm. You can only allocate to those. And the neighborhood is arbitrary. It's arbitrary. It's arbitrary reductivity. How is that character? And there's no character to you, it's just I should have said j such that iij is in neighbors, right? Oh, and then and then, yes, it's sorry. Thank you. Thank you. The setting you had it, this is with some budget, right? With each each. So, budget is now one. So, each offline node has a capacity of one that can be used for fractional allocations. And then the y is going to get updated every time. Yes, exactly. So, you make this allocation, and then y is updated. This is the state of the system, and then you get to the next one. So, basically, if we start and all the y j's are zero, the first allocation will just be uniform across the. Would just be uniform across neighbors, right? Right. Because CF is. If you have access to the neighbors. Yeah. And in fact, if you so two notes about this algorithm, it doesn't really matter what function else you use. If you pick any strictly convex function here, then the algorithm is waterfilling, which means that every time that nobody arrives, you're going to allocate to the fractionally, you're going to identify the offline node with the smallest button node and then continuously bring up the identity. Continuously bring up the allocation level of that until you run out of that interpolation. But I intentionally want to deviate from that interpretation. I just want to think about this convex properties. So focal results, the greedy algorithm, when you don't have that convex term, it's going to be half competitive. And now I'm going to show you that this algorithm is going to be 1 minus 1 already competitive, which is the best competitiveness you can get for this one. And the way to think about this analysis is typically a primal dual analysis. That's, I think, expected. That maybe coming up with a dual certificate for the primal algorithm would be a good idea to establish the approximate optimization of the primal. And what I'm going to show you is how you can actually find that dual certificate. But before that, let me formalize what I mean by primal dual. For the offline problem, you can write down a linear program that maximizes the size. A linear program that maximizes the size of the matching. This is the one on the left, maximizing summation of xij subject to the matching constraint on the online side and offline side. I'm using I for the online side and J for the offline side. And then the dual of this simple LP is basically the vertex cover problem. So you're trying to minimize summation of alpha i plus summation of beta j, subject to a covering constraint. For every edge in E, you want to make sure alpha i plus beta j is at least small. That is small. And of course, both the primal and dual libraries are going to be one. So the goal is to construct a certification in the following sense. For the experts, this is called dual fitting, like for those that are familiar with primal draw. There are different styles of primal draw. This is the one that's called dual fitting. And the idea of dual fitting is that under constructed dual assignments, alpha i hat beta j hat such that the objective value of The objective value of the dual is equal to the primal. And second, the dual is approximately feasible. So if the dual is feasible, then this is basically saying that the primal was optimal, which can't be true. If the dual is approximately feasible, then you can imagine that if I divide the dual variable by this factor of one minus one over E, then the dual becomes feasible. But in terms of objective, you are not going to lose the factor of one minus one over E. The factor of one minus one over e. So, therefore, if you have such a dual certificate, this is going to show that your primal algorithm is a one-minute one over E approximation of the object in terms of object. And no one forces you to construct this certificate in an offline fashion. In principle, you can design it in an online fashion. You can design it offline. It doesn't really matter. But it turns out that for the purpose of these algorithms, it is easier to think about constructing these certificates in an online fashion. Constructing these certificates in an online fashion, I'm going to show you how, but using convex programming. Alright? So every time that you see a convex program, just write down the KKT conditions first. That's definitely going to give you a lot of insight about what's happening in that convex program. And this is exactly what I will do. So we have this convex program. I'm going to try to write down the KKT conditions in the way that Rod learned KKT. So I'm going to. Learned KKT, so I'm going to write down the Lagrangian function, and then I write down the KKT conditions based on that. So the Lagrangian function here is basically the following. So summation of xij minus this term. So this value in the object of the primon. And here I'm not talking about the LP opter, I'm talking about the convex program optor, like this term. Alright, and then you're logged ratifying the one constraint corresponding. The one constraint corresponding to the total allocation of one. So that's going to give you alpha i times one minus summation of xljj. Then we are going to have this other constraint. So it needs to be a summation here. Sorry for the slide form. So summation over j, beta j one minus by j minus xij, and then summation over j, theta j xij. So the dual vibrations are affois, beta. Variables are alpha's, betas, and tetans. So this corresponds to the constraint that XH should be non-negative. This is for the capacity constraint and often selected for the capacity constraints and non-finance. So KKT conditions, if I look at the gradient of the Lagrangian with respect to, say, the primer, X. If you set everything at the equilibrium, X star, theta star, alpha SR, theta star, this should be zero. Okay, so you can do the gradient in your head, or you can trust me that this is actually the gradient equation. With respect to xij, if the gradient is 0, that means 1 minus f of x s ij plus yj minus alpha s r minus beta jar plus theta j is equal to 0. Alright? Very simple. You have complemented your slackness. We have complementary slackness, my favorite KTT conditions, because sometimes we ignore them, but they are playing a very fundamental role. If an offline node doesn't use capacity in that round, then beta JSTO should be equal to zero. If an online node doesn't use capacity, then alpha JSTOR should be equal to zero. Cool. Any questions about the KPT conditions? Now we go to the point that you want to construct a dual solution. Node IRI. You make the allocation, the primal allocation, using the context program. Now you want to decide how to set your dual values. And my suggestion is that in all these models, always do the following. Set alpha i hat, the dual variable corresponding to the phi node, because exactly that. Note because exactly the answer is coming from the convex program. This is the takeaway message from this charge. If you come up with this convex programming-based parameter dual, write down the correct convex program, find alpha s third, the alternative memory corresponding to that constraint, and set alpha i had to be exactly equal to that. The rest comes very mechanically how you should set beta. For example, this is the choice of beta. There are other choices of beta that doesn't work, but I think this is the most natural one. But I think this is the most natural one. I'm going to increase the beta based on, so every time I know I know dars, I'm going to update my beta j hats. So I'm going to update the beta j hat by this quantity, which if you think about it a little bit carefully, it's kind of a charging argument. So you know that the correct assignment on the eye side should be alpha s star. So the remaining left is 1 minus alpha s star that should be somehow covered. And I'm going to proportionally distribute that between my Distribute that between the offline notebooks and the amount of outage. This is essentially what this means. Yeah, so imagine that, let's say primal made an allocation of one. So therefore the dual, because you want to do dual fitting, should make a total allocation of one as well. And now you have to distribute that by somehow between your online node and offline node. So I'm going to say, if I know this is the correct assignment, which this part, I mean, I don't have a good. Which this part I mean I don't have a good intention for. I mean I have good algorithmic intuitions, but for now, let's say Rod's message is you're forced to set alpha hat into alpha i star. You just want to decide how to update data. Then I say, okay, so one minus alpha i star left that you should distribute between the dual variables so that the change in the dual and the change in the primal are equal to each other. Let's do that proportional to the alpha variables. Right. So the idea there is that you're So the idea there is that you're irreparably making the position for the I, that's why you're fixing it. Whereas the beta, you're building up pressure on it, that's why you're screening it. Yes, on the primal side, I'm making my altitude convex programming on the dual side, I'm bringing up these prices, essentially, on the off-hand side. And this is how you update the prices. If you sum over, like, is it obvious that that's feasible in the sense of if you sum over the I of Xij star? Xij star 1 minus alpha i star. So if so if some of the Xij stars are strictly less than 1, like if they don't add up to 1. Yeah, so the primary halvid is feasible like constants. Feasible, but like the summer bar i xij star may be strictly less than w, right? It might be. And in that case, do you still get enough weight at your sign? Uh yes. Let me show you one. Uh yes. Let me show you what. Okay. You have to use confidence as like to see that one. Okay. Yep. Uh good. So to formally answer the next question. Yes. Sorry, good question. Sorry, is there a simple, I just help you to understand, is there a simple f that reduces to that alpha hat and beta hat equal to alpha and beta star? No. No. And in fact, there's No. And in fact, there is a fundamental difference between beta hat and beta star in the sense that beta hat is gonna play the role of an approximation to beta star. If you could set beta hat to beta star and you could make everything work, that would have been a proof of optimality, actually. But you're choosing the function little f, right? So is there like a... So far I haven't told you anything about the little f, right? So I was like, hey, for any f, solve the convex program. The form of the form of the dual. The form of the dual has nothing to do with that. But what are we going to put here as alpha star has to depend on S. I see, I'm just saying, intuitively, what type of F makes alpha hat and alpha star closer to each other? And what type of F makes it far away? So alpha hat and alpha star are always going to be exactly equal to each other in this construction. I'm suggesting a dual assignment. I'm saying alpha a hat to be called to alpha s star. Okay, okay, my bad. I'm thinking about. Okay, okay, my bad. I'm thinking about the dual for the for the fluid for the fluid problem for the for the the this is the this is the environment and then you had late earlier you wrote the L V. Yes What is the connection between the two? Both alpha ST and beta STAT and beta hat that you construct in this three are some sort of a gap recognition to the offline dual elements but not in a But not in a very formal way. In the dual-fitting way. So let me keep it at that. So you think of it as like you're trying to find some approximations to those quantities that only give me review that time can. There's a table, right? It's fit to just star class inside JSTOR. No, no, no. So this is the so I'm updating the beta house. Oh, I see. Well, it is amount. So beta SR doesn't play a role in this. So, beta SR doesn't play a role in this object. Only alpha S star. So, the only thing that you're going to borrow from the comics program is alphas. The rest I'm just going to ignore. They're going to play a role in the analysis, but not in the construction of the alpha star is the optimum solution, not the one minus one over the E because. So, alpha star is the optimal dual variable for the convex program for I. Convex program for i. So it's kind of like related to Yeho's point. It has some sort of connection to the global optimal dual for i, but it's not that point. Is there some intuition as to why like the alpha hat i was the right one to fix the alpha star versus alpha beta to be this one? Um not something I can explain easily. So it's not an intuition. So it's not an intuition. Yeah. I don't think I have a very so you're not going to change it later. You're a very decision. So somehow you're fixing that tool variable because you're fixing the decision of round I. Right, because yes. It's all nice. I don't have IRI, so I'm going to construct these two of them by each. The real clarification to this B beta J hats, do they all start at zero? They all yes, they are initialized at zero. Thank you so much. I definitely needed to mention that following the concept. So let's answer Daniel's question why the primal and the dual are equal to each other. In fact, I'm gonna show that every time that you make an allocation and construct the corresponding dual variables, the delta in the primal and the delta d in the dual are equal to each other, regardless of whether you fully allocate or you partially. Whether you fully allocate or you partially allocate. So changing the prime one is always equal to the summation of x star ij over all j. Changing the dual, so alpha i star. By the way, so when I say change in the dual, I mean the objective function, the summation of alpha i plus summation of x star. So then the change in the dual is going to be alpha i star plus, so you're updating all the dual vibrations corresponding to j, sum over all j, x square ij, times 1 minus alpha x star. You just rearrange the term, so it's going to be alpha. Just rearrange the term, so it's going to be alpha i star times 1 minus x star, summation of 1 minus x star ij, plus the delta x prime. And I claim this is going to be 0. And this answers Daniel's question. And the reason it is 0 is because of confirmation, the slackness of the comet program. So either this term is a smaller, either this term is 0, or if it is not 0, then alpha s star should be 0. Yes? I guess I don't understand. I guess I don't understand what alpha I start we can do it for because the application is based on the convex program, right? So is this just for analysis or is this a problem? It's just for the analysis. Just for analysis. Just for the analysis. So you solve the convex program, that's your algorithm. And lowercase f for the uppercase f, you haven't specified what it should be. No, and in fact, for this particular problem, regardless of what f you use, you get the same algorithm. But it turns out in the analysis, you need a particular f which I'm going to. The analogies, you need a particular s which I'm going to specify in a setup. All right. So now let's think about the coverage, which means I have to show you that for every edge ij in the graph, alpha i hat plus beta j hat is at least one minus one away. So let's look at that. Okay, so alpha i hat plus beta j hat is going to be alpha j star plus, you look at beta j hat, I'm actually going to look at beta j hat. I'm actually going to look at beta j hat at the time that I arrived. And after that, it only increases. So, therefore, I can lower bound beta j hat by how much you have increased beta j hat so far, which is a summation s from 1 to i. For online node 1, you had some increment, 2, you had some increment, all the way to i. And each time you change beta by x star is j times 1 minus alpha s star at the time that At the time that you allocated. Is that clear? Alright, so now let's see if we have a good understanding of here. So when you look at X star, SJ, 1 minus alpha S star, you look at the complement S lackness, let me actually focus on these. Uh what is S and L? Uh S is an online node that arrive before I. Like some number between one to I minus. Alright, so here's an actually interesting point. I should have maybe said that also as a fourth complementary slackness. So if x star ij is greater than zero, then theta j star should be equal to zero. Alright, okay, so good. So therefore, if I'm trying to lower bound this term, I can say two cases, this term, I can say two cases is going to happen. Either XS star is 0, then I am not worried about any lower bound. If XS star is greater than 1, then I can basically say 1 minus alpha SS star is at least this quantity. And this is coming from the fact. And this is coming from the fact that here, if you set this zero and you rearrange the terms, then one minus alpha a star is going to be basically f of this thing plus beta plus beta j star. So therefore it is at least f of x star ij plus y j. So this is a, again, I'm using confirmative slackness here. All right, okay. Uh all right, okay. Uh so what is this quantity? This is basically the allocation level after you finish allocating S. Let me introduce a notation. So that's called y superscript S, a subscript j as the allocation level of a fine node j after you finish allocating a line node i. Then essentially this quantity is going to be the difference of the allocation, and this is little f at the final outage. The capital F is a convex program. The capital F is a convex program. So if you this geometric picture would be very helpful. So if I look at y superscript s minus 1j and its improvement to y superscript sj. So this quantity is basically this length times the slope of this line. And this is always an upper bound on the change in the actual function f because of the convexity. So therefore, I can say this whole thing is greater or equal than greater recall than if capital F of yjs when you minus capital F of yjs minus one and I have now this telescopic summation which is quite nice but if I do the telescope then I'm gonna get alpha star plus f of yj superscript i design minus f of 0 and f of 0 by definition is 0 depending on the integral from 0 to x of p to f all right so we are all Alright, so we are almost there. Alpha IS, let's do some case analysis. So, two cases: either the Hij that you're looking at, the capacity J was fully allocated. In that case, you can say YJi is equal to 1. Or it wasn't fully allocated. In that case, using complementary slackness, you can say that alpha is again greater than 1 minus F of Y. is again greater than 1 minus f of y j i. And it comes from the fact that if beta j is equal to 0, if you move things around, this time alpha s itself is going to be greater or equal than 1 minus f of y j. The literature f of y j. I'm just using complementary stacks, nothing fancy. All right? Okay. Right? Okay. So that gives you basically two bounds, and you can say you are always bounded from below by the minimum of the two. So, on one hand, I can just say my lower bound is capital F at one, because yji is not equal to one. On the other hand, I can say my lower bound is one minus this f of yji plus capital F of yji for some yji. So, this is basically all you need to finish the analysis. Maybe all you need to finish the analysis: if you set capital F to be the integral of the exponential function, it turns out, I mean, if you do the math, it's going to be basically 1 minus e to the power y minus 1 plus e to the power y minus 1 minus e to the power minus 1. This is going to be this time. So, this cancel is going to give you 1 minus 1 over e. And f of 1, if you calculate. And f of 1, if you calculate the integral, is going to be basically e to the power of 1 minus 1 minus e to the power of 0 minus 1, which is 1 minus 1. So therefore, you get a 1 minus 1 recompetitive algorithm. Yes. This is the derivation of f. Basically, you want to basify that f that ideally these terms become a constant and you get the same. And you get the same constant, and it turns out that if you set f like this, it's a differential equation. So you're saying you can write it as a differential equation. You can write it as a differential equation. Yes, let's say you have a differential equation where you want f1 to be equal to 1 minus 1 over e and you want these things to be constant, let's say the unique solution is exactly a function of this. That's the boundary constant. How do you know that you want capital F to be 1 minus 1 over E? What if I don't know the factor? What if I don't know the factor? Let's say it is some constant C and you want this thing to be the same constant C. Then if you solve that again you get this integration and the best constant C that you can get is that one question so the final optimal solution is an integer for but this these solutions are not necessarily correct so so it's it's fully convex programming absolutely yeah so this approach essentially gives you answers in problems where you have large capacity In problems where you have large capacities, therefore you can round these fractional solutions with a little bit of loss. For integral solutions, it's a different. How does this interface? Because I now found a pair of alpha hat beta hats such that the change in the dual and primal in every step is the same. Therefore, the total dual objective is equal to the total primal objective. And also, my dual variables are approximately. And also my dual variables are approximately feasible, and that gives you what you want. And if you want to I mentioned a proof of this fact, basically what you need to do is divide the dual alpha hat by this factor 1 minus 1 over E. Now you are going to have a feasible dual. But your feasible dual in terms of objectives has a gap of 1 minus 1 over e to the primal. Okay, so primal is at least 1 minus 1 over e times some dual. Some dual feasible in terms of objective. And any feasible dual is an upper bound and optimum offline. So data, for instance, you probably forgive this. That's really really cool for a review. Second, I didn't, I just do things that are intuitional. So first, I didn't see where you used the fact that changing the prime modity would great change in the true prime modity proof. Secondly, so the final step of that proof is just kind of think of it interpolating kind of sums. Kind of song. It's very similar to that. Is that where people start from to prove these things and then kind of work back to get the right module out of the whole data? No, I think this complex programming view is kind of like new in the sense that originally people. If you look at the original lines of the proof, it has some similarities. I can't even find a one-to-one map between those. Maybe Rogan has a better idea, but I do think it's slightly different. And then the first question is: Did you use the fact that I mean obviously? Did you use the primal sequence? I mean, obviously, it's good if the change is the primal sequence of the change in instead of not escaping from each other. But is that going to use the proof? Yeah, so therefore, at the end of the arrival, I can say the total primal object is equal to the total dual object. And that was one criteria that you needed for the dual fitting analysis. So let me show you the more interesting one. Edge-bated matching with three cancellations. I probably won't. I probably won't have time to go over the proof. I'm going to cover the proof in the second part. But let me tell you the comics programme perspective and how you can design an algorithm here. I think it took a long time for research in this area to come up with the correct algorithm for this problem, but if someone had known these complex problems, maybe this seems very natural now. Now that you guys see this, I hope that when I show you the complex program, it feels natural. So this problem is a higher dimensional version of the previous problem. This problem is a higher dimensional version of the previous problem in the sense that the state of the system this time is going to be the distribution of weights for each offline mode. So if I look at arrival i and I look at all these offline modes, you can attach a distribution somehow to each of these offline modes, which basically tells you what was the weight distribution you got from the previous allocations. Right? So you have these objects, Y say J supers. I say j superscript i minus 1 omega, this is or w, this is basically the distribution of j before i als. So this is the initial state. And now you have two decisions to make. So you have to decide, first of all, how to allocate i fractionally. So these are the decision variables vij. You should also decide how to cancel some of the previous allocations to make room for this new allocation. Allocations to make room for this new allocation if needed. And cancelling allocations is equivalent to saying that, hey, look, my estate was some yj omega. I'm going to change it to another estate called xj omega, where xj omega is always less than record than yj omega. In this way, I'm getting rid of some of the allocations at different rates. And you have to make a decision in the middle of the market. And in cancel, I cannot reallocate proteins or. No, no, so you're going to lose the weights, and those guys are never going to be that fine. But you only do that if there is a reason for it. So that means the new allocation has generated much lower rates. So you never cancel at the lower rate than the current allocation rates. And you have no different cancels. You have no different cancels. So basically, at the beginning, you will allocate to the full because there's nothing to do. All right. So it's exactly as before. I claim that you only need to regularize in a kind of a high-dimensional way. And let me show you what will be the result in Karma. Let me first ask you to ignore this term fully. And so the recipe is the following: write down the linear program for grid album. For greedy algorithm. And the greedy algorithm here is an algorithm that decides on how to allocate and how to cancel in the most greedy fashion. This is kind of related to Yosh point that I can cancel, but I will only cancel if it makes sense, if the new allocation is happening at a higher rate. And this can capture by a simple linear program. So the decision variables, as I said, are going to be Zij and FjW. So the input to the linear program is the current state, which is this YJW, so Fj. Which is this yjw for every j. And okay, so my goal is to maximize the objective that I get at time i. So that's going to be summation of zij, sorry, wij minus the amounts that you cancel. And when you think about this cancellation, so you have these distributions that you're dumping them at different rates, so the total rates in ex, or let's say expect. Total weight in extra expected weight that you cancel in some sense is going to be the summation over all of signals. And then you have to take an integral from 0 to infinity and see how much you're canceling at that particular W. This is the amount of loss that you make in the objective, and this is the amount of cancellation that's going to be there. And you sum them up. So this is the objective function, and then in the constraints, so again, the total amount of allocation should be at most one. That was one. You are not allowed to cancel more than you had. And finally, after you cancel, you are not allowed to violate the capacity constraints. So the amount that you allocated plus what you decided to be the state after cancellation should lead to a capacity less than one. There should be no more. Sorry, what's done? So it's the age-waited downline. So it's the H weight is a downline matching problem. So imagine these are different types of weights that you might see. So essentially any number from 0 to infinity might be a possible previous weight. And based on the weights that you have allocated up to time i, you are going to have some distribution over all possible weights. If that makes it easier to think about, imagine weights are either number one, five, or six, and then there was a set of like finitely many weights, and this integral was just a summation over all possible weights. All possible weights. But we need to calculate how much of each of the weights has been allocated and how much of each of the weights is cancelled in this time. Right, so if, for example, it is just one weight, it's essentially the previous model, then you need to just look at the total amount of allocation. But if there are possible weights, then this is going to be fault. Default. Alright, good. So, this is the Kilgreed algorithm. Now, what I'm going to ask is this regularizer term, as I promised. And if you think about it, it's actually having a kind of a similar form. It's a summation over all of line notes, so it's a separable regularizer term. And then I'm looking at the integral from 0 to infinity, capital F, and here is the Here is the final C D F of the allocation, essentially, or 1 minus C D F. So X J capital X J is the integral from W to infinity of detail X J tau, D tau, and this term is essentially the y minus C d of the allocation after you make the allocation. Exactly the same as before, so you plug this as an input to F and you regularize in this. And if you are interested, in the second part, I'm going to show you how you can have. How you can have a higher-dimensional version of the previous parameter analysis and some of this extension to other problems, and I leave one problem as an exhaust. Thank you. We have time for one of the questions while we set up the other talk. Sure, what's the interpretation for that? Just It's some sort of like penalty function. It's some sort of penalty function. It's like you're penalizing the greedy algorithm by the amount of imbalances that it generates.