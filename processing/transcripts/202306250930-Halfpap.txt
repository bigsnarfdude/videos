I'm giving kind of a coda slash elaboration to Corey's talk. Corey is now, I guess, my ex-advisor. I just finished with him, but this is work that we've been doing together for a couple years with Nathan Lemons there as the co-author of this first paper that this arises from. But this is, as maybe you have, a very new and rich vein of potential problems. So this has also spun off into a few projects already. Spun off into a few projects already and might be a source of accessible and interesting help if you like this kind of thing. So let's get started. I might just click through these first few slides quickly because I'm just reminding you of some definitions that before I spent a lot of time talking about. We're going to be, again, working in this situation where we always have a r unifel hypergraph, which I call r graphs for short, and I'll at least try to write r And I'll at least try to write our edges instead of just edges, but I might say edges if it's clear what uniformity we're working in. And remember, we're going to be talking about co-degree questions, so instead of trying to maximize edges or maximize some sort of what you might think is a more natural idea of degree, we're going to be thinking about situations where what I want is these r minus one sets where r is my uniformity to be in lots of edges together. So the code and r. lots of edges together. So the codegree of an r minus one subset is just the number of r edges that contain it. And the minimum codegree, of course, you just look over all the r minus one subsets and you find which one is in the fewest. So you can say formally biggest integer k such that any r minus one subset of your r graph agent you choose, it's in at least k r edge. Cause it of codegree, again, we just allow you to have zero, that's okay, but if you're in zero, that's okay, but if you're in at least one r edge, then you should be in at least k r edges. And then this function that we were talking about at the end of Corey's lovely talk, the positive code of reach random number, we choose some forbidden R graph F. And I like to sort of pin it down by writing this maximum here. But S here is just all of the N vertex constructions that don't. Constructions that don't have any copy of f in them, and you look at the minimum positive code degree over all of them, and you want to find the biggest one, and that's this positive code degree trend number. Let me note here, as Corey noted and we were alluding to at the end, you can certainly consider this for families of more than one R graph that you're forbidding simultaneously. We will hopefully, time for meeting, talk about that a little bit at the end, but just to sort of Bit at the end, but just to sort of simplify notation and thinking about things, I will mostly just write single F's in here. But the things that we're talking about will extend to forbidding finite values. And what I want to talk about today is, is this co-plus ex a well-behaved function? So, Corey talked about several, maybe we could think of the general properties of these Turan-like functions. Density limit exists. Density limit existing, whether things jump, whether there's stability, whether there's supersaturation. In particular, I want to talk about the existence of this density limit and a general supersaturation result. Before I actually talk about sketching how these things are proved, I maybe want to just say a couple more words on why I think these are desirable properties that you should work hard to prove, and that if they didn't happen, you by the way. And that if they didn't happen, you might be worried that you're sort of looking at an extremal function that's not very good. Maybe some of this will echo stuff that Corey was saying, and some of it's my own kind of take on it. The first thing, if you're thinking about this scale density limit existing, is this is something about how predictable and how quote-unquote smooth the code degree, positive code degree to random number is. And I have smooth in quotes here because I don't want you to think that I'm. Smoothing quotes here because I don't want you to think that I'm an analyst, you know, that would be horrible. I'm not talking about something being continuously differentiable many times. I'm just talking about pictures that look kind of like this. So here, we were discussing the K4 minus just a few minutes ago, and I've drawn just some, for some very small values, plotted n against the extremal number, and also the scaled. The scaled density where we're dividing by n. And you can see, well, on the left here, this dashed line is n over 3, which we said is what the positive code rate to rand number is. But we don't actually get all of our points nicely on this dashed line. If you think for a second, it should be clear that that wouldn't happen because these extremal numbers are always integers. So if you have some line with a A line with a rational slope, you're not always going to get integer points. So, actually, what we get is the floor of n over 3 here that we're plotting. And then when you divide by n, you have this kind of wiggly thing where this dashed line of 1/3 is the limiting density. But when we start at 0 and we jump up to 1 third, and then because we're having these four things, we wiggle down a little bit, and we jump back. We wiggle down a little bit, and then we jump back up, and then we're going to wiggle down a little bit. That's going to be less than the first wiggle, and you're going to kind of count this. So we do approach one-third, but we're not, in any sense, doing so monotonically. This maybe gives you an idea of why it's a little bit different than just showing that the scale density limit for the turret situation exists. But okay, what is this saying? If I take off my glasses, these dashed lines are the truth. Are the truth. As you go out, you could think of n over 3 as being a really good approximation to what this actual function is. And especially because, as we've alluded to, these divisibility criteria, you have all these headaches of dealing with floors and ceilings, and probably these functions are never really going to be honest to goodness polynomials even. You might prefer just to think about the idealized polynomial. One thing that such a density limit existence would say is that everything, if you take off your glasses, does look like just some linear function. And all you really have to do to understand it is figure out what that smoke should be. Which might be easier than figuring out the exact, you know, what happens when n is congruent to 7 mod 16 or whatever. Mod 16 or whatever. Well, what about supersaturation? Well, we both, I think, are using the word phase transition. Again, that's sort of in quotes. One way that you could think of supersaturation is saying something about the strength of this parameter. I've heard, Van said that all talks should include a proof and a joke. I've heard they should all include a proof, a joke, and a lie. These are slightly Lie. These are slightly lying graphs, or at least you would have to be much more precise to say exactly what we mean by these graphs, but this is the intuition that you should have, that super saturation says, okay, how few copies can I have at certain minimum positive code degrees? Well, for a while you can have zero. And then when you hit your extremal value, you're going to have to have some. But what we want is that there's a sharp increase. Is that there's a sharp increase, and in a small sort of increase from your extremal value, you have to have somewhere on the order of n to the size of your forbidden construction many copies. You don't have this kind of meandering slowly upward where, yeah, okay, it's monotonically increasing, but it's not that dramatic. In some sense, super saturation says, Not only is there a threshold where we're Only, is there a threshold where we're guaranteed to get these forbidden things, but we're strongly guaranteed to get these forbidden things above that threshold? I can also mention supersaturation just for quality of life reasons. It has many interesting, it gives lots of structural guarantees and it's a very useful kind of theorem to be able to apply. And we'll talk about that in a bit. So, if I wanted to actually do the necessary work to establish the supersaturation. Work to establish super saturation and the existence of density limit, what kind of things would I do? There's multiple avenues that we know work. You could come at it from a very probabilistic, non-constructive way. But what I'm going to talk about today is actually a pretty concrete way that we could understand this working, and I hope it emphasizes some nice features of mid-lump positive codegree. The arcings I'm going to talk about today would not work for ordinary codegree. And let's start. And let's start with the supersaturation. Well, what we're going to first start with is actually something called a hypergraph removal lemma, which, okay, I've written in terms of deltas and epsilons, but if you hate deltas and epsilons, you can squint your eyes and not look at this slide. What this is saying is that if I fix a positive, but as small as I want, epsilon, and say I would like to be able to have a graph that maybe has some sub-graph. It has some subgraphs I simulct to an F that I don't like, but I'd like to be able to remove all of those subgraphs without deleting a huge number of edges, I can do that as long as I didn't start with too many of these bad subgraphs. So formally, if I want to remove at most epsilon n to the r edges, I can do that as long as I have at most delta n to the v of f copies of my bad construction. Again, this delta is dependent on whatever. And get this delta that's dependent on whatever epsilon I want. Now, why is this relevant? Let me first state what our supersaturation theorem is. Again, we do have deltas and epsilons, but this should look similar to the supersaturation theorems that Corey was flashing up in the last hour. So here we fix an epsilon rating zero, which is going to be the proportion by which we exceed our positive code rate to random, and we say, Number. And we say that there exists a positive, could be very small, delta, depending on this epsilon, such that if we exceed our positive coherent number by at least epsilon n, then we have at least delta n to the v of f copies of our forbidden graph. So very, very similar to what supersaturation looked like for Terrand numbers in graphs, for instance. And the idea is: okay, to prove this theorem, what I have to do is. Okay, to prove this theorem, what I have to do is you hand me an epsilon and I hand you back a delta, and I argue this delta works. I'm going to choose delta based on the removal lemma in the last slide. Remember where I said, okay, you hand me an epsilon, and there is some delta that works. But maybe it's a little bit misleading, because I'm not going to choose a delta based on the removal lemma, where the removal lemma has an edit distance of this epsilon that I want. I'm going to choose a delta based on the removal lemma to guarantee that if I have at most delta Guarantee that if I have at most delta times n to the v F copies of F, then I can actually make my H F free by removing alpha n to the R edges for some alpha that's way smaller than this epsilon that I ultimately want. I'm not going to say what way smaller means, but think way smaller. Okay, I can certainly. I can certainly do that. The removal lemma has been proved by famous people. We think it's correct. Why would I care about doing that? Well, the idea is, okay, I start with a small number of copies of this forbidden graph. I do a small edge edit to delete them all. What I would love it to be true is if doing a small edge edit like that basically maintained my minimum cost of code. That is sadly not true. However, a great thing about minimum positive codegree that's not true about ordinary minimum codegree is that if you have a set which has low codegree and you don't like it, you can fix that set by just deleting every R edge that contains that set. And so there's sort of a cleanup lemma that says, if I make a small edit in the number of R edges, Edit in the number of bar edges. I delete a small number of bar edges. Maybe that wrecks my minimum positive codegree, but I can make a few extra smart deletions to sort of clean up all the local places where positive codegree dropped low, but it's not zero, and make it zero there. And then I'll get an even smaller sub-R graph where the minimum positive code read is approximately whatever I started with before I made that initial small deletion. You have to be careful tracking the drop here, and it's a little bit more complicated than I'm making it sound in terms of how you do this smart deletion, but it's possible. And so the idea is that we start with our H, which didn't have too many copies of this forbidden subgraph, and we do this two-step deletion to ultimately get a subgraph which has two properties. First, the first deletion First, the first deletion step using the removal lemma guarantees that I don't have any copies of my forbidden graph anymore, and I didn't delete too many edges to do that. Then, the fact that I didn't delete too many edges to do that means I can apply this cleanup level, which I haven't stated formally, and get this, after the second deletion step, something which has minimum positive code degree close to my original thing. What is close to mean, in this case, it's bigger than. mean. In this case, it's bigger than minus epsilon n from the original, where that epsilon is the epsilon that I'm having of my super saturation statement. And so this is a contradiction because I've removed all of my copies of my forbidden graph, but this H2 that I've arrived at, which now has this minimum positive codegree condition, still has minimum positive codegree bigger than the extremal value. Than the extremal value for F. Okay, so one nice consequence of supersaturation theorems, sort of in general, it works here too, is the following corollary, which talks about the relationship between the minimum positive codegree to rand number of the Trand number of an R graph and its blow-up. Blow-ups, remember, just sort of look like that picture over there. You maybe start with a small construction, and then you replace all the vertices with big independent classes of vertices. And I'm denoting a blow-up where you have t total vertices by f brackets t. Well, it turns out that the positive code-meter-and-number of f brackets t. Turan number of f brackets t is bounded between the number for f and the number for f plus some error term, which is sublinear. I'm not going to prove this. This is kind of a thing where if you study extremal graph theory, it's pretty standard to pass from a supersaturation argument to something like this, but it's really nice. Why is it really nice for us specifically? Well, in the last couple minutes, I know I only have a Couple minutes, I know I only have a few, and so we're not going to talk about loads of details, but having that sort of relationship between numbers for a graph and its blow-ups is going to help us, among other things, prove the existence of this density limit. So that's the limit I would like to show exists. What I'm actually going to show in my paper, not today, but what I'm Today. But what I'm going to sort of talk about showing is that there's a special family script F, which is determined by this forbidden graph that I want to understand, such that that limit exists. And actually, that limit is going to be equal to the limit I want to show the existence of. So, how do I figure out this problem? Let's first talk about if I didn't use that. Let's first talk about if I didn't use that forbidden family and just tried to instead use my F that I care about. Well, I'd like to show that the limb soup of this sequence of ratios is actually the limit of that sequence. So I can find some construction where, you know, that's the extremal construction for, say, m vertices, and it gives a value close to my lunsu. And the idea of this argument would be that if I take balanced lower, That if I take balanced flow-ups of this one good construction, so first every vertex gets replaced with two vertices and then gets replaced with three vertices and so on, you can do some analysis that shows that, well, blow-ups often inherit lots of the properties of their base graphs. And so balanced blow-ups of this one reconstruction would have this ratio equal to what the ratio is when you look at the Ratio is when you look at the minimum positive code degree of H and divide by M. And so that's sort of a witness to the fact that you have these different points separated by a constant distance in this sequence, which all are close to this Matsu L. And then do a little bit of analysis, some elementary combinatorial bounds, and a little bit of stuff about like summing the harmonic series to show that for large enough n, if we go up far enough in this If we go up far enough in this series, or this sequence, the nth term of the sequence isn't too far from the nearest knth term. So, really, having these special values that are close to L means that eventually everything is pretty close to L. And then this would suffice to show you the limit. What's the problem? Well, the problem is that you would hope that if I take a blow-up of H, it remains F free, because H was F. F free because H was F free. Unfortunately, that's not always a property that gets inherited by the blow-ups. There are some examples of R graphs F where all blow-ups of an F-free construction remain F-free, and there's some examples where that doesn't happen. So instead, I'm not going to read exactly what this family is. I'm going to define a special like blow-up containment family based on my forbidden F. And basically, this is stuff of specially. This is stuff of specially bounded size, such that if I blow it up, eventually it will contain my forbidden graph. And I'm going to forbid all of these things simultaneously. Well, F is in this family, so it's harder to avoid everything in this family all at once than just to avoid F. But on the other hand, sort of using an extension of that corollary that said forbidding a blow is pretty much the same as just forbidding the base graph. Forbidding the base graph, there can't be too big of a gap between the number for f and the number for this family. And so, because I have this nice sandwiching, it would suffice to show that this limit exists. And that's all I have written, I think, about this argument. But basically, you do some analysis of the blow-up family to show that what you hope happens actually does happen, and that if I say, oh, this is specially. Say, oh, this is specially constructed to. Sorry, I don't know what that was. People now know what music we listen to. This is specially constructed so that it sort of spurred to this issue of, hey, I could not contain F, but then if I take a big blow-up, I could contain F. Well, if that were the situation, that would end up implying that I contain some member of this blow-up family. Blow up thing. And so, actually, doing that is this very nice constructive thing where we can say, not only does this limit exist, but we can kind of approach it with these blow-ups that just go up far enough, you get a good construction, and then you can take these blow-ups and asymptotically it works. Okay, well, thank you for your attention. I know people have to go check out, but if you don't have to right away, I'm happy to answer any questions you might have. Well, let's thank the speaker again. People want coffee. People want coffee. Coffee is leaking.