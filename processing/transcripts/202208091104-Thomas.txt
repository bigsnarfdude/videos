Thanks for giving us the opportunity to do a joint talk here. We'll just go back and forth. So, the first thing to start off is with the observation that Shannon's original theory for communication succeeds in large part because it is a syntactic theory and he put aside questions of semantics or meaning in order to construct the theory that we all know in life. It has bothered me for a long time. Bothered me for a long time that in biology, signals mean things to organisms. And there ought to be a way to bring semantics back into the framework of information theory so that you could take into account the fact that some signals matter more to organisms at different times than others do. But it's hard to do this, and there have been a number of attempts. So, when Max and I met at the biotic conference. Biotic conference that he organized two and a half years ago in Arlington. And some of you were there too. Some of you were there. That was the last conference. It was in January of 2020. And so it was the last face-to-face conference that either of us had for a long time. We were sitting together at the bar and drawing pictures on a napkin. And we came up with a model system that I think is useful for sharpening the question of how you could reintroduce. Of how you could reintroduce notions of subjectivity into the information theory context. And so, our goal for today is to present this model system for you as a way of stimulating further discussion. And Max has kindly agreed to spearhead a discussion on Thursday during the breakouts about subjective information. So, this is sort of laying the groundwork for all. Thank you, Peter. So, we actually were not two people, but we were three because my student was there too. Good point. There too. Good point. And oh, yes, it's working. So, as a contributor, my student Tyler Barker, who's a graduate student in Nebraska at his probably last year of PhD now, helped us trying to understand how to build a toy model that could enable us to understand what is subjective information and if it's. What is subjective information, and if it's a thing, and maybe even how to define it. Okay, so just as a brief outline, we're going to take turns, giving a little bit of background to set the stage for the toy model. And in the interest of time, I think we would just get started. Okay, so I'm not the only one with my species. We have a community that is called Microcommunication Theory. Communication theory or a research branch, and what we do is that we study communication channels where molecules and chemical reactions are involved. And some very good representatives are also here in the audience of this community. And we always start with the thought that a molecule is actually carrying information. It's the smallest identifiable unit of a substance that actually carries information about the substance. About the substance property and the ability of engaging in chemical reactions in different environmental conditions. And so, out of that, we actually built a branch of communication theory where we study these channels that are composed of molecules, chemical reactions, and molecule transport. So, this theory that is directly related to the molecular communication theory in electrical engineering. Communication theory in electrical engineering actually is very well suited to look at what happens in biology. And we all know, and we are talking about it all day long, that information permeates biology at all fronts and sides and scales. Information storage in DNA genes, functional relationships in DNA. There will be a talk this afternoon about this. This afternoon, about this information photogenoscription and translation, but also communication between organisms, between cells and all the multicellular organisms. So information is a little bit about, is a little bit everywhere. And the microcommunication theorists try to apply communication theory to understand this. Okay, so applying information theory in So, applying information theory in biology goes beyond just the molecular level, just to indicate the breadth. Here's some figures from papers that have, over the years, that have successfully applied optimization of some sort of information measure to explain the structure of receptive fields in early vision, the structure of auditory receptive fields in early auditory processing, the patterns of DNA variability in Tom Schneider's work, and things like work and things like infomax versus versus info taxis versus chemotaxis in searching for a target. So you can find in the literature enthusiastic expressions that amount to saying if only you can figure out how to maximize the information in a system, then you would understand the system and why it does what it does and how it works. There's lots of examples. Christoph is here, I think. Is here, I think. The discovery of the genetic codes to mention the fact that information is a central pillar in any attempt to understand life. Daniel Polanyi couldn't make it. We invited him, but he wasn't able to be here. But I would have quoted him there as well. Julian Nebenmann, likewise, wasn't able to join us. But he puts it very succinctly, life is information processing. And in Andre's talk, Andre, are you out there? I just took this right from your abstract. In the most fundamental sense, biological processes have evolved to use organic. Process has evolved to use organic matter to generate, preserve, and transmit information. So, the reason I'm putting this up there is because I want to give you a counterexample that helped motivate the toy model that we later developed. So, about 10 years ago, my colleagues and I put together a simple model, simple enough that we could treat it analytically and exactly. And it is a creature navigating. Let me take the pointer for this. Go down laser. Okay. So, there's a creature that's living in a one-dimensional rainbow. A creature that's living in a one-dimensional ring, a discrete world, and it is trying to find food. So the creature C for creature, creature, creature, creature starts with C. The source of the food is what it's looking for. The source emits a diffusible chemical, and so just like in chemotaxis, it can detect the local concentration. Now, it knows all the physics of the world that it's in. It knows everything it needs to know, except it doesn't know where the source is, and so it happens to know how far it is from the source, but it doesn't know. It is from the source, but it doesn't know, for instance, if it's here, the source is here or there, right? Two different points equidistant that would have the same concentration signal. So we endow the creature with the ability to make observations and it can move around, it can remember what it's seen in the past, and then you can build something which is a little bit analogous, but I think simpler than what Sarah Marzon was talking about yesterday with coarse grain information states. You can think about, given all of the observations up to the present, what does the creature know about where the source is located? Where the source is located. There are essentially four possibilities of matter. If it knew exactly where the source was on the last time step, what the source does is it does a random walk. So with probability x, it moves to the right, with probability x, it moves to the left, and with probability 1 minus 2x, it stays put. And so this little distribution, you know, if x is between, say, a third and a quarter, then you have a little distribution like this. If it knows that it was in one of two adjacent places, then the distribution looks like so. And if it knows it was in one of two places that And if it knows it was in one of two places that are further apart, it looks like this or that. So you've got these states that represent the posteriori information that the creature has about the location of the source. Now the creature can move around according to different strategies. You can write down the information optical strategy, which would guarantee that the creature has the most information about the source. Namely, if you figure out where the source is, you move right next to it, so that way, no matter where it moves, after you make the next measurement, you always know where it is. Measurement, you always know where it is, but you never land right on top of the source, except sometimes by accident. You could also have a strategy which has not tried to maximize information, but has tried to maximize food, maximize the probability that you land on the food. Think about a lion hunting zebras. The lion could stalk the zebras all day and always know where they are. Or it could pounce and then maybe it gets a zebra, or maybe they run away and then it doesn't know where they are. If all it cares about is information, If all it cares about is information, why ever counts? So we were able to construct these different strategies, the information theory creature, we call it, the maximum likelihood creature that always goes to the most likely place that the food is, and then a hybrid creature that sort of goes back and forth. Question? Why is sitting on top of it, not also? You could. Because on the next move, it either goes right or left. Move, it either goes right or left, and so then you don't know where it is. Whereas if you start at one next to it, then on the next move, it's either zero steps away, one step away, or two steps away, and you know exactly where it is. All you have is concentration. All you know is the concentration, that is to say the distance, but not the direction. Just like a bacteria. It knows the concentration, but it doesn't know the vector. And on three, why do it equal problems in the model? Oh, that's just a model. Oh, that's just a model. Let's keep it simple. I mean, the whole world could be rotating, but that would make me dizzy enough. And so, what this gives is it gives us a closed description of a Markov process where in the Markov process, we have a description of the information, the state of the creature's information, the location of the creature, the location of the food, and we can solve the Markup process exactly to get the behavior in the long term. So, let's see. All right, so. Sorry for that. Clarification question. So the source is moving and it's keep diffusing, but well, the source is constantly moving. Yeah, we assume it diffuses and that the diffusing particles sort of reach equilibrium, and so there's no leftover sort of molecule signal from before. So at each time step you get a fresh measurement that basically just tells you the distance. I see. Thank you so much. Okay, so you can, because you can solve the model analytically, you can calculate exactly what is the mutual information. Exactly, what is the mutual information, or what is the uncertainty that the creature has about the source? We manipulate the source movement so it moves more randomly or less randomly. And the information theory creature, which was designed to be information out tool, surprise, surprise, it always has the least uncertainty about the location of the source. As you make the source movement more random, it slightly decreases. The greedy creature, which is just trying to get food and doesn't care about the information per se, it of course has the worst information. It of course has the worst information, and the hybrid creature is sort of in between. But then, if you ask, how much does the creature get to eat? Does it care about information or does it care about surviving? I would claim that in biology, sometimes you care about survival. And for this simple model, which I mean, it's very simple, but it's analytically tractable and all these results are exact. There are no approximations once you start with the model. If the source is moving at the most If the source is moving at the most random, it can move, then the information theory creature does the best in surviving, but only in this narrow parameter range. If the source is moving in a sort of intermediate range of randomness, then the creature which greedily jumps on top of the distribution gets the most food. And if you make it move the most predictably or the least randomly, then the hybrid creature, for some reason, does better. There is no rhyme or reason. There is no rhyme or reason. There is no simple relationship between the information that you get and your survival, your utility, the food. There just isn't a simple relationship. Even though everybody, all the great people that we've quoted, are always talking about how important it is to analyze information. Okay, thank you, Peter. So let's take a step back. Great question, please. Or make a comment if you wish. So it was a nice paper by Stan Weitz. A nice paper by Stan Leipard at some point and people with his group, where they looked at what strategy, kind of conceptually, maybe in a similar vein, what strategy is best? Is it sensing the environment or it just the kind of view or Dervinian view where in a kind of classical Dervinian theory there is no real sensitive environment, it's just the diversification of properties and some get collected and some die out. And some die out, but the population doesn't track the environment necessarily actively. So it turns out in their analysis that the sensing, the active information about the environment versus passive diversification could be optimal strategies depending on how frequently the environment varies. So, you know, sensing is also not always the best option in a very generalized sense. Option in a very generalized sort of sense of this pure Darwinism versus sensing environment and trying to adjust that with Darwinism. So I wonder, you know, your claims are pretty pagorical, saying that, look, you know, in many cases, it's a very narrow zone, but it might be interesting to understand a little bit better, and you'll get to that under what conditions, maybe it makes sense, it may. Maybe it makes sense to sense an environment or it doesn't. Maybe a condition of how quickly the environment changes or some other requirements on top of that. Again, just to kind of inspire it. Thank you for the comment. What we're going to do is we're going to show the next generation of this kind of model, which Max is going to present, which takes us in the direction towards subjective information. And this question that you're addressing. That you're addressing might be a good one to follow up with the discussion later on. Thank you, Andrea. Thank you. So let's take a step back and see what has been done so far, at least for our knowledge. So imagine we have substances in the environment, we have a couple of cells, and so we know that if there is too little information, some cells will not survive because they didn't have enough. Because they didn't have enough information, too much information cost. And so, if I get too much information, individual can spend too much resources and have problems because of that. And there is also the just enough information. This is under the paradigm where we look at fitness versus information cost. And of course, this is justified on many fronts. It justifies a trade-off found by evolution. It justifies and also defines. Is justified and also defined through the Gold Can information as a trade-off between the fitness value of information and the information itself and all the information available. So increasing fitness results in an amount of information. And there is also another work or another set of works where we talk about the emergence of semantic information. So we start giving meaningful information. Information A or information B have a different meaning for the survival. Have a different meaning for the survival of the cellular system of the organisms. And in this case, there is also the quest for finding the minimum information to ensure organism maximum viability or fitness. So then the question is, is more relevant or semantically relevant for fitness information always better if it does not cost more? So if we remove the cost out of the equation, does nature always? Does nature always optimize a communication channel given some constraints on the cost of information? If it were the case, our perceptions will be all the same. We will have the same eyes, we will see the same colors, but it looks like it's not the case, right? There is a diversity in perception and sensing, as also was evidenced in the previous talk. And so, what we propose is a shifting constraint. So, instead of looking at information cost, let's move it from the equation. Cost, let's remove it from the equation and let's look at instead having an organism that is capable of opportunistically manipulating the information channel in a way that follows some semantic meaning of information, but without the constraint of information cost. And the constraint is only the survival, the thickness. So this is the time model that we built to answer that question. So we have a two-research foraging model. We have a motile species in our We have a motile species in a 1D environment, very similar to what Peter explained before, but this time we have two nutrients, A and B, and distributor at different concentrations. So the organism absorbs A and B concentration at any location dependent on the concentration they are at that location and can divide only when both stored A and B are over a threshold. So it has a storage that accumulates and then it divides. And it senses A and B gradient. A and B gradient through chemical receptors, and we have a binomial in the middle, so a binomial channel, and then it moves proportionally to the steeper gradient that is sensed through the receptors. And it constantly, of course, consume A and B for living, and any time they become zero, either one of them becomes zero, the cell dies and removed from the environment. So we have two possible strategies. We have the same number of receptors, total number. Number of receptors, total number of receptors for each cell. So that is a given number and it's constant. But the equal receptor allocation assigns half of the receptors to sense the gradient of A, enough of the receptors to sense the gradient of substance B. Instead, the adaptive receptor allocation reallocates every time the number of receptors to sense the gradient of A or B with respect to the need. And the need means the The need, and the need means the scarcity of one or the other in the reservoirs that are inside the cell. So, we measure two performance metrics. We built a simulation-based tool and we measure information efficiency, which is an average neutral information of all these channels throughout the population of cells. And then we measure the growth rate, which is similar to the average W rate during the simulation of the cells. And so, what we observe. And so, what we observed, first of all, I have to say that we distributed also a little bit intelligently the concentration of AMD following a home missus distribution. So practically, our 1D environment is periodic, and these are the distributions with the maximum entropy over a periodic support, and they are maximally separated inside that support. And so, here we see the trajectory for. Here we see the trajectory for an equoreceptor adaptation and adaptive receptor adaptation of two cells, respectively, in each one of them. So, cell one is the purple, cell two is the green-blue. And every time there is an X, there is a division happening, cell division. And here we can appreciate the difference between two strategies, especially on the cell density. We'll see how the eporeceptor allocation has a density that is more uniform. Is more uniform. This is at the end of the simulation, by the way, at simulation time when the situation is about stable. And this is instead what happens for an adaptive receptor allocation where we see that the cells are a little bit more adventurous. So they move between A and B. So do cells overall grow better in one or the other? Yes. So what we see here is the growth rate. Is the growth rate as a function of the cell stress? So look at the right-hand side first. Cell stress is the rate of consumption of A and B, so how much they eat actually. And so we see that the adaptive receptor allocation for each cell stress that we tested actually has an edge on the growth. So it grows better. Does it mean that it gets more information? No, it gets less information. So this is a plot of the mutual information of the cells. Of the cells with respect to the cell stress. And we see how the adaptive receptor allocation is actually getting less information overall, but it's growing better. Why? It's because by adapting the receptor, it's actually weighting message A and message B differently with respect to where it is and in the environment and what are the reservoirs, what is the feeling of the reservoirs of A and B inside. Reservoirs of A and B in cycles. So, this is what I just stated. How do we, so we think that there is an emergence of a subjective information because thanks to this adaptivity, the channel of the cells is actually diversifying. By changing and reallocating the reception, we have a channel for A and a channel for substance B of receptors. For substance P of receptors that are different. In the case of adaptive, obviously, in the case of equal receptor allocation, we have a variability that is zero. Here is just the standard deviation of the neutral information throughout the simulation. But for the adaptive receptor strategy, we see that the standard deviation is actually higher and also increasingly higher. And also increasingly higher in some sense. Here we can also appreciate the dependence with respect to the noise factor. This is just we increase and decrease the noise within the binomial distribution, just transforming it into a Gaussian and playing with the variance. And we also see here the dependency of the subjective information and also susceptibility that is reached. That is reached for a high noise factor on the subjectivity of this information on the standard deviation or the variability of perception. This is actually the variability of perception of each single cell in, of the ensemble of cell within the cell community. Okay. So what did we learn? Maximizing information efficiency can result in a lower growth rate. And so evolution can enable a diversity. Can enable a diversity of perception, and we build a toy model to understand that. This can lead also to new bio-inspired models, and then the provocative sentence, which is life, can potentially suggest some concept to information theory. Okay, and so that's just the final remark. So, we would like to take your suggestions at this point. Your suggestions at this point, maybe using this toy model as inspiration for what would be ways that you might want to define subjective information. Subjective. We like this toy model very much, so we're going to leave it there. And it's online. If you go to the paper, you can download from GitHub and you can play with it. Do you have, so you have these two models, the information optimal, the other strategy? Optimal, the other strategy. Is the other strategy fitness optimal? Do you know what the fitness optimal strategy is? So, in general, the fitness optimal strategy would be the solution of a Markov decision process, which in a very large state space. So, we have no idea what the truly optimal behavioral strategy is, but it suffices to show that it's better. So, to clarify, you found one solution that does better than the but you don't you don't have any idea what the option structure is. You don't have any idea what the object strategy is. Right, right. For now. We have a lower boundary. Yeah. Just to understand, like, the concept of subjective information, does that hint that when we are now working on experiments, we can do some kind of constraint-based optimization? So we are not just trying to think about information, but certain constraints and then try to optimize that. Is that kind of like a realm or premise of what this theoretical model is? I'm not sure what the take-home for experimentalists would be. Home for experimentalists would be yet. In Purshotum's talk, he talked about these internal states. If there was a way to measure an internal state and then look at the conditional mutual information experimentally conditioned on that state, while the state is dynamically fluctuating because of chance events happening to the cell, that's the kind of thing. But I don't know any example where people can measure that. And if anybody has ideas, I'd love to talk about it. I mean, I was also thinking about this during the recent. Thinking about this, I think single cell RNAC on Singapore is a way of a proxy for presumably state-up properties. Maybe a quick comment also from me. Sorry. I don't even know if you can see me. Yes, we can see you very small. Presence, ghost-like presence they have. Anyway, so I think it's super interesting. It's kind of hard. It's kind of hard. There's a reason Shan didn't want to deal with semantics. And historically, people have been really talking about two schools. One is, as frequently the case, one British, one American. American is all about numbers, values, and so on. British is more about semantics, again, in keeping with tradition. I think D2, as frequently is the case, is very hard to deal with semantics with different signals. Because different signals may mean different things to different recipients. And therefore, for example, in some cases, I agree, you can make an argument that maximization of growth or increase in food consumption may be a reasonable strategy to optimize. In many other cases, things may be a bit more complex and hard to divine, so to speak, speaking of experimental analysis. Analysis: What really matters for the cells is not always very clear. So, dealing with numbers is safer, perhaps, but probably agree a bit less interesting than dealing with semantics. But also, there's a challenge. There's always a challenge of meaning, in part because interpretations of signals that may be common may be very, very different for different cells. It's a kind of a big question of what matters. The other thing I want to say. Of what matters. The other thing I want to say is that there's another example that may be worth thinking about, and that is a very simple example of yeast. If you expose yeast cells, they will grow the pregnant, but if the amount of thermal becomes really huge, they lose the sense of where the mating partner may be, where the thermal is coming from. And instead of doing that sensing, they actually randomly form projections in various directions. Do various directions absolutely randomly because they know that the partner, mating partner, executing pheromone, is probably nearby because the fermont is so huge. And there is no hope of figuring out where, but random strategy of just doing that still probably is a good strategy, a winning strategy. So, I think a fundamental question you are trying to ask is great. Under what conditions I leave? It's part of the question. We are part of the question. Under what conditions sensing, active sensing of the environment makes sense, and under what conditions you can dispense on that, and perhaps maybe that are not dissensed environment. Picking though, I think, should be coupled in some way to the environment. If you're completely decoupled, your chances are going to be slim to survive and to do well. That's it. Sorry to take your time. Andrew, just one comment from me. So you said. From me, so you said it's true that it seems like with this model it's uncoupled, but indeed, the reservoir here, so the quantity of A and B, depend on where the cell was in the past. So there is a coupling with the environment. It's not totally uncoupled. The strategy is uncoupled because it uses these indicators, but the value of these indicators depends on the Depends on where the cell was in the environment during the previous time frame of access. Wanted to say that. Sarah had a question, if there's time. Yes, yes. Okay. Well, this is something that I would like to talk about climbing a little bit more about, but what do you think about sort of like a rate distortion theory of this? Aha, yes. That's a good point. Yeah, so we've talked about, so rate distortion theory is where you have an objective function and you want to look at the maximum value of the or minimum value. Maximum value of the, or minimum value of the objective function given a certain rate, or vice versa. Here, the objective is changing dynamically according to the internal state of the cell. So if you're about to die for lack of nutrient A, then finding A becomes more heavily weighted in your objective function. If you're about to die for lack of nutrient B, then you would adjust, you know, you would reparameterize your objective function. So there is an element. Function. So there is an element that's similar to rate distortion theory, but it's a kind of rate distortion theory where the objective function is dynamically changing as a function of the cell's internal state. And as far as I understand, the classic approach to rate distortion theory doesn't cover that. You could do something like a trajectory thing and what a super screw would be in order to think of this. I would love to think about how think through how to do that. There would be paths on the roles. It would be a lot of fun. But I haven't tried to do it. I haven't tried to do it. Thank you. Well, we'd love to continue the discussion over lunch and also on Thursday. Please sign up. No, they don't have to sign up, right? Just show up to the semantic information mini workshop, mini workshops. Whatever, the self-organized thing. Yeah. Thank you. Thank you.