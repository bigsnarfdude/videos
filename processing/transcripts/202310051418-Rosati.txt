Right, and the regularity, uh well, you can do some sort of power counting which tells that the regularity is sort of just barely uh smaller than minus two. So what this means is that well, it's something a little bit more than two derivatives of something that is actually a function. But the way we actually want to interpret this regularity is to say that if you look at the solution to the heat equation driven by a space-time-like noise, then this is still a Gaussian sort of process. This is still a Gaussian sort of process, but this process will not be a function. I mean, this process here will, at any given time, be something that is just barely not a function. So it's something that is a distribution. So this x, this debiotion, but it's not. So there is a blow-up in the covariance that is not as strong. Blow-up in the covariance that is not as sharp as this as this, but somehow originally blow-up. So, the second assumption is that eta is a perturbation, and by this we mean that eta is just smoother than its space-time right now, and how smooth doesn't really matter. So, we just put a little bit more than minus one. And then, okay, first we have. Uh and then uh okay, of course we have to put some sort of initial condition. Uh so the initial condition will be either in L two uh or we put some sort of subject something like C minus one plus gamma in H for some So this is the setting in which we are going to work and in setting the main result that I wanted to present you is the following so So there is inherently some probability space which supports this random variable ψ and in this probability space we single out this null set. So there exists some sort of null set inside your omega. This is going to be your probability space. And it's an outset, so this probability of this length is going to be zero such that Such that for every sort of realization of your noise that doesn't sort of belong to this null set, apart from this particular space, you have two results. First, for every sort of initial condition in your sort of sub-critical space, and for every eta, again in your somehow suitable space, there exists a unique noble. There exists a unique noble while solution to the stochasticist equations. And so this will be fedantic, but if you can also start in L2, and you can start with an eta, it doesn't sort of matter. But if you start in L2, you have a unique global weak solution. But weak is not really. But weak is not really so the problem is that here weak solutions you have to define them somehow Because your solution is never going to be really something that lies in L2 because the solution is too direct at the time so so weak this has to be somehow explained what it means so this is why it's a second one okay so this is the main result and in a way a lot about this A lot about this model is already known. So second bit is about context. And here the main reference is a famous result by Pratt and Kebus. And this is from 2002. And they essentially almost have the same result. So they prove sort of two things. They prove local well-positiveness for this equation. So again, local well-positiveness takes this formula at least an outset such that for every sort of initial, for every sort of noise that doesn't lie exactly this position, there is There exists a unique logo. So, and here the initial condition has to be set up. And the way you what this means is that with local, it means that it can blow up. So it's defined sort of from zero to some sort of final time. And this final time will depend both on the realization of the normal. On the realization of the noise and non-mission. And then the second result is that if you don't start with a fixed initial condition, but you start with a random initial condition, so if u0 is distributed according to a law, and this law is just the solution, it's the stationary solution to this equation. So if you start sort of this linear. We start sort of this linear equation. So you should imagine that there's always a delay projection everywhere, because I would forget it everywhere. So to start this equation at invariance, at invariance for the linear equation, and then there exists a unique global solution. And the reason why this second result holds. The reason why the second result holds is that you actually have that the measure that is invariant for the linear dividend is also invariant for the non-linear divide. This works because let's call it mu. So this law, this mu is invariant. So the proof is not exactly obvious because you still have to prove something, but more or less the idea is that if you start that invariant, you will not blow up in finite time because after finite time you still just and these sort of arguments need to be very close with the part and the push but of course there also works by Pokemon somehow with the same on program. Someone is the same approach. So this is result by the part and the bush. And so what is interesting, what can we do this? So let me give the So, um let me make some remarks. Uh so the first is that uh you can actually extend this. So we can extend this to prove that for every initial condition uh state minus one plus kappa the probability starting from this initial condition that the blow-up time is finite, so that the blow-up time of time is exactly all. The way you do this. You mean one? One. No, zero. You that probably. So this is just this the Prato-the Bush argument plus sort of the strong Fellow equation. So you know that somehow this probability is zero for a About this probability zero for a weird set of initial conditions, which are almost every initial condition is written according to the law of so it's a very weird strange set in your state space, but this strange set is sort of dense. And in addition, you know that this probability is continuous in the initial component. This is part of the second probability. Um so if if you do these two somehow together you get that if if you start with a fixed initial motivation, um you don't block them. You don't block them. The second remark is that this result, I haven't written this explicitly here, but it only works if you don't perturb the wave. Only if it's exactly equal to zero. So if you put the perturbation, it breaks because you don't have anymore any access to the entire dimension. And so our internal. Um and so our interest was to somehow find a different argument to prove global repositiveness that would not rely on explicit knowledge of the environment. Rainbow some other kind of difference, but that's not for now. An explicit knowledge and environment. Is is there a reason you couldn't just pierce out off in a way? Yes, you can, but so what's the disadvantage of that? Sorry? What would be the disadvantage of just Piersadoff it? So it it works for certain eta, but not for all. So in the in the so the theorem has eta in sort of Sort of a slight perturbation of your noise. So the reason why the details in the theorem is to say that we are not proving something to you, it's just to tell you that you cannot get down to it because it's not an automaton market of the noise. And you also cannot put it equal to zero, so you don't have the explicit very much. But otherwise, from now, I mean, it's just to say that we are proving something in real, otherwise the perturbation doesn't matter at all. Right. Right. So, until when do I have time actually? I'm not recommending. Yeah, so it's until 3 or 5 because we'll start to go recommend. Okay. So, okay, so before I tell you somehow about the motivation, let me also observe. So, this is somehow clearly. So, this is something that is interesting. So, if you somehow change a little bit the equation, you don't have any more global positions. But this is also sort of. Appositness. But this is also sort of a drawback. So, here, what happens when you start with a fixed initial condition, you somehow get a null set outside of which you somehow exist for all times, and this null set may depend on the initial condition. And you can actually construct examples of finite-dimensional, two-dimensional dynamical systems where this property sort of doesn't imply that you have an outset that doesn't depend on the initial nouns that doesn't depend on the. Okay, so let me motivate this work. So for us, unfortunately, because it's Navier-Stokes, the motivation does not come from fluid dynamics. It comes from studying sort of these in general and certain sort of In general, and certain sort of SPDs. So there are a few facts that so I have just there. So local well positives This is local well positives for SPDs. This is somehow almost completely understood. This is almost completely understood and the first work was maybe something that somehow is topped out of the book. Somehow, this is the product in the bush, but then you can somehow build this entire theory that tells you whenever you expect to have a solution through some sort of scaling argument, then you actually can build a local solution in space and time. But global solutions are much less understood. And there's only a few examples where you can say something. So here are some examples. The first is the Carda Paris exam equation. So this means that we have This means that we have some models for growing interfaces. So again, you have somehow a heat equation, and then you have some non-linear term, which is the square of the derivative. So this is in one space for dimension, and then you have some additive mass. And this equation you can linearize it. So if you define b to be b to the h, then v let's be will solve a linear equation. And linear equations you can solve. And linear equations you can solve for all times. So, this argument somehow is the only argument you actually have for global and time solutions. So, then you can try these 5,4 equations. So, this depends on the dimension, and the dimension will be less frequent than three. And this means that you have uh kind of heat equation, but you have a nonlinear time, you know. Equation, but you have a non-linear term, you know, and then you have some additive noise. And again, here, because this term is sort of you have this very strong negative drift, even also here you can sort of construct all the solution and then nonlinearity in a way helps. And one of the interests in this equation is the constructions of the construction of the invariant meta. So So for large times you somehow expect to obtain, and in fact in these cases you obtain an invariant matter so that phi t should sort of be distributed according to some invariant matter which has a certain Gibbon structure, which is reposed maybe related to the talk before, where the energy in this case is just the row of five to the power of x. Or if this is all formal, but this is somehow what you uh But this is somehow what you expect to obtain. In a way, one interest in this equation is being able to say something about it. And then, so these are all cases in which we can say something. Yes, this is one dimension. But you can, yeah. And then so So the last example is young Meals and here we actually can't say anything and even an equation I can't really understand it myself. So it's somehow an equation where you have an energy which determines your flow and you have some additive noise. And again, the thing that you're interested in is the construction of the invariant matter associated with the collection. And for us, I think the motivation was this. So you want to study situations where you want to construct environment measure. And in both the case of Young Meets and the case of FIFOR, the environment measure is sort of the interesting object. And you can construct it externally. And you can construct it externally in some cases, but not always. So, for example, in this case, in dimension 2, there is a construction of the Yaningel's magnet. Dimension 3, not, and 4, I think, it's even higher. But so dimension 2 and 3 would be sort of a minimal, and they didn't have in principle. But what is the problem? So you have a stochastic partial differential equation, and you want to prove that it has some sort of invariant nature. And the question is, The question is: first of all, do we have global solutions? And this is what motivates us. So, can we study some of global positions for stochastic partial differential equations which have a certain structure? And the structure here is actually very similar to the one in Nari-Stokes. So, you have some sort of energy which decreases in time if you have a deterministic redirection. And to this, you add some force. So, for this reason, we looked at Navier-Stokes, which is a famous and interesting model in itself. But in this case, here the environmental. But in this case, you know, here the invariant measure is explicit. Here, the aim is to construct the invariant measure. So, so the point is to find a way to prove global well-positiveness, which doesn't look at the invariant measure. So, this is why we wanted to go through all these problems. Of course, you can come as our motivation, you can come also from the stochastic Madder Stocks equation itself. And there's a different sort of way And there's a different sort of way to come to it. So the way we look at this is that we somehow take a smooth equation and we think of the noise becoming more irregular and we look at the first case where problems occur. You can also come from somehow a very opposed equation and then just try to look at that equation and this is some of the approach from Martin of Manova June June in a series of different papers in the Series of different papers in the last years. So they study somehow, for example, the 3D stochastic microscopes equations, and they even study a case which is supercritical. Supercritical means even supercritical in the sense of, so where you don't even have local positions for the equation in some sort of sense. And they construct solutions, global solutions, through convex integration. But through convex integration. But of course, these are irregular and they are non-linear. So this is going to be okay. So now something about projects. So I would write against the questions. I will write again the equations in with the Liray projections and so P now is the Lyrie projection here. So we start with these equations and eta we will forget about the visibility. And our aim is to close somehow an energy estimate the same way you would do it for the topics. Our aim is just Our aim is just, and this is perhaps not particularly structure, but we just type a brute force close enough to energize it. And in a way, the thing that will appear is that if sort of if ψ is smoother than exactly the regularity that we're looking at, then it's straightforward. Then it's straightforward to blows its energy as to it. And if ψ is more irregular, this is sort of widely open. And this is actually the most interesting, but we didn't mention anything about this. And also, our approach in the end will now. Approach, in the end, was now followed by somehow dividing some of high and low frequencies, so there's some sort of scale separation. And we discovered different moments that this is related to some sort of similar approaches in different contexts, such as one by Gala, Erin, and Shon in 2002, which somehow where they treat sort of the noise. They treat sort of the Sox equation with L P based sort of critical initial conditions. So P is representative. And also this we discovered that I discovered only a few days ago, Fukato. So there is another approach from Tao who Is another approach from Pau, who, someone in 2009, studied some version of the Navier-Stokes equation, someone just barely subcritical, so someone like log subcritical, supercritical, barely supercritical. And these are all related, so this in particular, the logarithm you see that it's, well, you don't see it anymore, but the logarithm here is related to the correlation function of the loads. function of the solution to the linear equation. And this will be why we will get a lower level. So these are the closest things to what we do. So now I will just guide you through our several failed attempts to close this energy activity and this sort of works. So the first thing you can try Well, this has to fail immediately, is that, well, you somehow want to differentiate the two norms squared of U. And that okay, you can always be the one. And of course, this fails because the solution is not inelectable. This is just the solution is barely just barely not a function, so there is no way that you can. So at least you have to throw away. But then you can follow somehow the same way in which you prove local solution to this PDE, which is to follow this degree push approach. So you define u. So you want to see u as a perturbation of the somehow equation where you don't have the object. Because on small scales you would think that somehow the noise is the most irregular term. So you somehow say that this u is a solution. That this u is a solution, the solution x, the one that I wrote before, so this is just a solution to the heat equation driven by the noise plus a perturbation v. And now you want to study v rather than u. And this you can do. So now there is an easy equation for v. You have v plus the divergence of v cos x and so squared cos v. So this means that now here, and you can somehow try to guess the regularity of V. I will not do this. So V is actually more regular than U. It will be C1 minus. Beta is 0. It doesn't matter. So here you actually have an alpha norm, so you can try to compute the revert of normal square of V, but of course it will break because what you expect to see here is somehow Break because what you expect to see here is somehow the H1 norm of E on the right-hand side squared. And then you'd have some sort of quadratic form which involves the divergence of x times V and then you'll have some other terms. So of course this doesn't work because V is not differentiable, so this guy here is infinite. At the same time, Infinite. At the same time, the solution lies in the tool, so something sort of must happen. And the point is that you have somehow, there is some sort of what one should expect is there is some sort of stochastic cancellation going on between the H1 norm that one sees here and this other collatic form. So in theory, the Lapland should somehow be the leading, should somehow be the thing that regularizes, but the two terms somehow are of the same one. So here this Same one. So here this guy should also be in infinite, and hopefully, they are somehow infinite in a way that exactly cancels each other out. So to see this cancellation or to somehow remove this divergence, you have to look a little bit deeper into the structure of the solution. So this was exactly the approach that was taken by the Pradhan Book to solve the equation, and this is enough. So it's enough if one observes that Enough if one observes that, so here I dropped the term which is arguitive, it doesn't really matter, which contains the square of x, which is something which one has to define at all. So, until here one can follow that approach by Bush, but now if one wants to look deeper into the regularity, into the structure of V, you need somehow tools from singular SPDs. Although for the local repository theory, Although for the local repositiveness theory, we don't admit this at all. So now you say that u is actually x plus v, but v has a particular structure, so you look at this equation and you single out the most irregular term in the equation. And the most irregular term is exactly somehow the divergence, something that involves the divergence of V and sorry. V answer hash one for something smoother. So this is the most irregular terminal equation. And in particular, you can look at this product here and decompose it into spady products. You can decompose it into spady blocks. So you see that the first term is actually the one. So these spadi blocks allow you to tell which term in your product is covering. Which term in your product is covering the regularity? So you decompose a product into three terms. So here, what I mean is that you sum sort of the payd blocks in such a way that the high frequency term lies on the x. So here, i is less than j minus 1, and this is somehow the resonant one is the one where there are. Is the ones where they are of the same one. And this is just opposite. So in this term, the regularity comes, is inherited from the x because the frequency comes from the x. So this is the most irregular thing. So actually the answers that you have is that your solution looks something like something that is controlled by a stochastic term in a not really in a but really additive way. Not really in a battery additive way anymore because you have the V inside it, plus something that is. And now you want to somehow compute this, so the thing that is smoother, if you call it V sharp. And the only sort of idea that one has here is to say that you are trying to disentangle two bits of your solution. So you are trying, as we did in an additive way before, you are just trying to somehow say that We are just trying to somehow say that there is the stochasticity that governs the small scales. And then the macroscopic behavior should all lie at something small. So this should somehow be a small scale term. And this should be the macroscopic term. So, and by this we mean that, well, this term we don't really. That, well, this term we don't really care too much about. We hope that it's somehow controlled, but we want to somehow look at the energy estimate for V-sharp. So, V-sharp is the one where we somehow want to still see some of the global aspects of narrative sources. So, then you try it once. So So and when you try this you you almost you almost succeed. So you have uh so this V sharp will solve this V sharp will solve exactly the same equation that you had before for excessive varieties. You can see that it just solves exactly the same equation as you had before, but instead of the full product you have only the bits of the product that are actually uh smooth. Smooth. So here you have sort of V shar a son and product, you think, then you have V shar controlling the irregular bit, but you have lost the other one because that counts because it's actually. And then of course it's still narrow stocks, so you have still had the trilinear term, so the V linear term. So in here, you can exchange V and V. So, in here, you can exchange V and V characters with no matter. But the important thing to note is that in the nonlinearity, you somehow still have the origins. So, now when you try to close the energy estimate, you get something that is, well, here you have the divergence of V squared, and then you have a bilinear form which is just V sharp, and then you have And then you have this tool somehow with your products. So now the point is you have removed something irregular. So you have the original problem when we did the L2 estimate was that there was something that went wrong in the sporadic form. So now we have removed the linear product. So actually the sporadic form is fine. We have this poradic form here. We have this product form here is great. So Naussian V sharp has the divergence of V sharp x. This is this you can control. So you have managed to control the choratic form, but you have paid the price, which is that now in your in your linear term, which you are extreme linear, you have you have still the original solution. Original solution to the equation. And so this doesn't cancel because it's not exactly different. So you get a bunch of, of course, a bit of it cancels. But so for example, what you get out of this term is terms that look like your sharp, and then you have the divergence of the somehow high-frequency component of your V square. Where I call this guy here. And of course, if you look at the structure of the frequency components, since it's not additive anymore, but it's multiplicative, this is still a term which formally is of third order. So this breaks your energy balance, this makes your brain kind of pattern to break the wrong estimate. But you have a freedom of choice, and this freedom of choice is actually very natural. Freedom of choice is actually very natural in some ways of solving these equations. So you have one parameter free. You can somehow smoothen your noise at any level. You can somehow split your noise into something that is low frequency and something that is high frequency. And the level at which you split is somehow an additional degree of freedom in the way that you solve the equation. So nothing prevents you from somehow taking this noise and projecting it onto frequencies higher than some sort of thread. Frequencies higher than some sort of threshold number. So, what is the point? To control such a term, we want to impose that this high-frequency term That this high frequency term is not somehow linear in V, but it's of first order in V. We want to impose that this guy here, so V minus inverse divergence of V controlled by the high frequency projector on some lambda because I introduced this new degree of freedom. This is a norm of order one, in some norm. And these. And this just means that here you have projected, so here you have a set k for k sort of larger than minus. And the way you do this is that you choose lambda sort of, you can just impose this proof of it by choosing lambda sort of dependent on the solution. So you just choose lambda to be something that is proportional to the norm of V. And so, if you do this, this bound is somehow imposed because you can always lose a bit of regularity. So, perhaps you can put some power A here, which is somewhat suitably large. You can always exchange a little bit of regularity of the X to gain powers of lambda, because you're protecting high frequencies. And then, by wiggling around with the regularity, as long as you're removing something from the order, this will be avoid of function. So, in this case, if you choose this definition, If you choose this definition, so with this definition, but this term here will just be of order of first order initial. So this will be of somehow sort of this is somehow for the norm and this is somehow bound that will be bounded by some sort of So the last bit is that now we have somehow described the thing we started with. So I have now changed the definition of V sharp. So somehow I have now changed also the equation that we sharp satisfies. And of course I have to pay a price for the fact that I have projected on very high frequencies. On very high frequencies, and the price is that you get back in this term actually a bit of your product, the one that we have, that depends on the low frequencies. So this is the last bit, so I guess it's so to close the estimate. So to close the estimate, you now look back. You have decomposed your V into something that is low. Into something that is low frequency and something that is high frequency. But now the projection will depend. We have chosen the projection to be time dependent on the non. So now the equation satisfied by the low frequency component of your solution will be something that involves, well, a bunch of terms that you can control, and then you have And then you have the low frequency component times the low frequency projection of x. So the projection of frequency is smaller than the threshold lambda that you've just now raised. So this is the function V. And then there's a bunch of other terms. And the other terms you have just now made it so, forced it so that they somehow are controlled. Everything else. Everything else, you have no control. So now you do the energy estimate, and now you have something weird. So you have that this is bounded by well, you have now a quadratic form which looks a bit like this. So you have the Laplace and then you can get away you can symmetrize this operator. You can symmetrizes this operator, so you can just make it some form of symmetric gradient of this low-frequency projection of L of light to B. So that's the symmetric function of variations. And then the rest, as we said, is controlled. Of course, this guy in as lambda explodes is not controlled anymore. Because you have the same problem you had before. So this this process is uh too irregular, so this whole thing So, this whole thing lies in C minus 1 minus kappa, which is exactly the regularity things below. But this is five minutes? Yes, it's going to be some time for plus and so. So, the end is that so what you have here, this operator is a smooth version of an operator of which you can make. Of an operator of which you can make sense as lambda goes to infinity. The only thing you have to do to make sense of this, and this comes from, I think, one of the first applications of this theory of singular SPDEs, is that you have to remove a renormalization constant. So if you remove a constant that depends logarithmically on lambda, this operator will convert in some resolvent sense to some weird version of the limiting operator where you have some of the properties. Operator where you have some also property, some information. And so this randomization, you don't see it in the equation, you don't see it when you do local oppositeness or anything. But to close our bounds, we somehow use it. We use this fact that if you subtract block lambda, you actually get a quadratic form that is bounded from above. So we get an estimate in the end, which depends. We get an estimate in the end, which depends. We get an estimate in the end, which will be of the form, well, the two norms squared of V up to some constants, one plus the logarithm of the normal v. Because our lambda was exactly chosen to be the logarithm of lambda. Is it E L or P? Yeah, sorry. It's sort of, it doesn't really depend, but it doesn't matter because. The it's not doesn't matter because this high frequency component you have imposed into the order one, so they're almost the same. And so yeah grows now double exponential in time essentially. But that's uh that's it. It only grows double exponentially in time, it doesn't blow up in time at time. And this is how you go somewhere else. I have a very naive question, so I don't work in customers. But if I look very so I I saw your lo you were kids in C C minus one plus alpha, correct? Correct. Yes, okay. So for now, it's an I'm supposed to have imposing V minus one. Well, that's X also C minus one. Would you have? I think what happens the mouse is I think th th so I'm not sure about the uh the end point, but just beneath, so But just beneath, so when the alpha is just beneath zero, I think two and two have proven non-uniqueness. So, yeah, so it was a few months ago. So, I'm not sure if they managed to go. I think so, yes. It's a bit on the lines. I think a bit on the lines of the deterministic analogus of this result. So, the there is the deterministic analogus that I mentioned. No, so I think it's more. I'm not sure. I think it's more complex integration. But then I'm not sure about the end point. So I'm not sure whether the end point is what. So yeah, I think it's I think a little bit, whatever you can do in deterministic, you can also push here. Because also like weak solutions at the end, once you take away the high frequency, the weak solutions are the same uniqueness, you prove the same way. Uniqueness, you prove the same way, it's like it feels like you can do it's the same. So my question starts first. Alright, so first question. It was the existence of the environment. The existence of environment measure is green and yet I think. So the environment measure is not constructed through stochastic mathematics, it's constructed through by constructing the map. It's a function of the theory. It's a function of your faster. It's not faster, but it's also complicated. I think it's Liam and Ya. I'm saying that that was one of the motivations. So, which you have to try your mindset. Yeah, we're trying, we're trying, yeah. Something I'm thinking about, but uh it's hard mostly because I don't understand it way. I don't know. Uh if the equation is difficult. The equation is very difficult. Um I'm thinking it's too difficult. Yeah, it's mostly matrix but it's not that it's just that you have this it's not parabolic. So you if it's parabolic, if it's a modern change. You can make it parabolic, right? Yeah, you have to add this detergent term. But then the detergent term is non-limited. Yeah. So because right, you try to make an energy estimate. You try to make an energy estimate. Yeah, it's difficult. It's not satisfied because maybe it's not satisfying. Yeah, and there isn't divergence for you, which I don't understand. I know it's complicated. Because yeah, no, I don't know what it is, because I don't understand. So the whole thing is like even the energy that you control, it's like the norm of the curvature. Of the curvature, this doesn't control the atron. So, here the thing that you get, the breezes, so there's some degeneracies. I'm not saying that it's not sort of, it should, in principle, it should fall in the same sort of range of results. Even feeling local imposedness, no, this is one line for a status signal, it's actually not so easy for me young nerds to put local line. Yeah, but it's not a short thing, it's not. Yeah, but it's not it's not a short page, it's not something that you ride in London. So there is something that's just inherently difficult to deal with. But I don't see why there is a in principle thing that fits more like that there is a technical stuff. Yeah, we're thinking about it, but uh but it's uh yeah, we're everything here, it's a long time. No, actually it's uh it's yeah, it's kind of It's part of the motivation, so it doesn't the motivation doesn't come from fluid dynamics at the end of the day. Because you just want this model. I think this is how they so the way they approve things is through an some sort of energy estimate. But then you have, right, if you do the energy estimate, you get a mind result. Because the minus of four. And the other one is still minus of four. So you think it's just a matter of time. But our methods some of you are don't have votes, so we are in the same votes. You don't have the same votes. So you you because there is no in the sense yeah in the sense that it's uh you can do much more in Python. So what they prove is like that you go you can go all the way to some criticalities actually of Google solutions so I think probably the easiest technological. So you say Well, you know what I mean? No, no, I'm trying to say that's the derivative. Yeah. So it used to be okay. So then maybe after one last talk, we just switched to that or even unit. I don't know if this is. Or even unit. I don't know if this is really needed for turning the matter. I will just uh assume in the keyboard. I should assume the key and we won't be storing. Have a backup pointer. Have a backup pointer. I have a chart now, so I have to do it. I want to teach you how to do it. I'm not sure I also need like Mac because Mac usually much better. Just ignore something. What about we try? Usually, you know, just uh. How do I get it out? I also have to check. Yes. I I can do that. Is this which one? Is it really a mathematical? How big is this? How do you point if there's also like a light? Yeah, there is, but that's not working. But that does nothing to do with the computer. It does. It's special software. Ah, because it's one of these. Yeah, it's like a super intelligent one. Then what about you? So I downloaded something like version and that would work here. Sure. But then I would have two versions of this. I'll have two. Not necessarily. It's not that fine. Maybe just use this one. It's like chopping the holes on the car. Oh, uh also we have that.