Well our next speaker is Tara Isa, who is a postdoctoral fellow in applied mathematics at CU Boulder. Awesome. Well thank you so much for having me. I am really excited to be presenting something that I think complements a lot of things that we've heard about but from a different perspective. So hopefully I will convince you today that we can consider networks in terms of cognition and behavior. So moving Cognition and behavior. So, moving kind of into the realm of, I guess, social sciences, psychology, meets, biology. Okay, so I just want to sort of start by placing this work for everyone because obviously not everyone loves brains as much as I do. And so, I want to imagine that you are a zebra. And in this case, right, you're a hungry zebra. You're a hungry zebra and you want to decide where it is that you want to eat, right? So, what are some factors that you think you might have to consider? Well, it's probably how much food there is someplace, chance of predator getting you, but also like how many other zebras are in the area, right? That could be a benefit or not. But the important thing here is, right, we have to consider our context when making a decision. So, a lot of my work is interested in how our environment impacts. How our environment impacts our decision strategies or cognitive strategies. So, right, you could be a zebra foraging, or maybe something like this: how do you decide what clothes to put on? Obviously, you're going to choose differently if it's the middle of summer versus if it's the middle of winter, right? So this is another form of environment, quite literally. But environment in context can mean something else, right? Let's imagine that you play sports and you're deciding: do I pass the ball or do I run the ball? Do I pass the ball or do I run the ball down? And so now we have yet again this context where we have to consider what is important. And this doesn't just mean from a value perspective, but you know, perceptually what is important to my decisions and how do I learn about my environment. So overall, my big questions that I tend to focus on are how we can infer our environment and then how that modulates both our behavior and how your brain. Behavior and how your brain can adapt to that. So, today I'm going to specifically just talk about what happens in the brain, since this is networks-themed and it felt very fitting because the brain is a network full of neurons. But the real underlying question of this is, how do I learn about this environment in order to do this? So, the way that we approach this is we're actually going to start with behavior. So, in order to ask how we learn. To ask how we learn important aspects, we first need to understand what are the limitations. Can we even learn things about our environment? And what is salient and important to us? So in this case, we're going to talk about working memory. So just in case, I don't know, has anyone heard of working memory? Okay, so working memory, we all know we have memories, right? Though we have memories, right? We can recall things at a much later date. Working memory is a very short-term version of this. So it's something like: if you were to see a bird in the sky and I asked you immediately after this, oh, well, what color was that bird, right? That's working memory, where we actually can retain the information in a much more active form. So we're not necessarily storing it for later and recalling it again, but it's something that we're retaining in our memory. Retaining in our memory. So we're working on it, right? It's much more active. But the really interesting thing about working memory is that it actually comes with some really convenient aspects. So there are limitations to our working memory, right? I can ask you to do a task and I can see how well you do on it. And this tells me something about what you're actually inferring from the environment. And so we can use this as a behavioral paradigm to start to understand: oh, well, you know. To understand, oh, well, you know, people make mistakes in this way, or people, you know, can do these things well. And that tells us a lot about the kind of cognitive strategies we use. When is it important for us to pay attention to something? What kind of things do we care to pay attention to? All of this is important, and then you can move forward and say, okay, well, now that we know these are things people care about, how would your brain actually consider these things, and how would that influence your brain's behavior? And how would that influence your brain's behavior? So, first thing we want to do is just talk about a basic working memory task. So, this is called a delay response task. And in this task, what happens is a human or a monkey is shown a fixation point. So, you were to look in the middle of the screen, there's this plus sign, and you're shown a Q. So, in this particular form, we get an item, and we have a color associated with it. So, now there's Color associated with it. So now there's two features that are important: the location and the color. So I'm going to take away the item now, and you're going to sit there for, let's say, three seconds. Three seconds later, I'm going to ask you, what color was that item? So now you have to recall this feature that was actually given to you originally. And you can do this in a lot of different forms. Right here, I only gave you one item, but what if I gave you three items and I probe you on the location, right? Now you have Probe you on the location, right? Now you have to remember multiple things. And so we can use this as an important way to bring these ideas together. So the data that I want to talk about, and I guess I forgot to mention this data came from our collaborator, Tim Bushman at Princeton. So they did this task with humans. And this work has been done between me and my advisor, Zach Cole Patrick. But they gave this task to humans. But they gave this task to humans, and what they did was exactly this. They said, here's the color, tell me what color you think it is. And what's really important is they sampled colors uniformly across space. But if we look at this, this black trace is the sampling of the colors. And what we notice is this density here is representing subjects' responses. We see that it doesn't match. Not only does it not match, but it has these distinct biases. So people are. To biases. So people are responding for particular colors more than they should. And so initially you see this and you say, oh, well, this is a limitation, right? We obviously are bad at this. Most often, this is considered as suboptic, right? Oh, maybe there's something wrong. But there has been research that has shown that actually we can think about this a little bit differently. And if we have a biased memory, A biased memory, and we retain certain information better, we can actually improve our memory. And the reason for this is if we kind of go back to when we were talking about noise yesterday, right? We don't remember our memories perfectly. There's some amount of noise in this system. But if we have biases, we can think of these as attractors. And so now all of a sudden we can reduce the amount of noise that's impacted. And so we're going to come back to how that works in this case. But this really suggests that maybe. But this really suggests that maybe there's some sort of an efficient reason for this. And so, this is what I want to explore today and focus on: is how these biases may not actually be sub-optimal, but may actually be a way for us to improve our understanding of the world around us. So, I told you in this case, they sampled all the colors uniformly. The colour does not have uniform colors. So, it's actually been shown that there's an over-representation of certain colors in it. Over-representation of certain colors in our environments, and conveniently they seem to match up with where these systematic biases are. But what's more interesting is this isn't just colors. The example I showed you is colors, but the same thing happens with cardinal directions, and we see the same biases. So what this suggests is that actually these systematic biases might be a reflection of us learning about our environment. And so this is what I want to model today and discuss how we're learning this. And discuss how we're learning this and how our brain could implement that. So, how do we model this? Well, we now know what our task is, right? We look at an object, we have to remember certain features about it. In the brain, the way that this works is that we have two types of neurons in your brain. Excitatory, which are actually going to, in this case, have a preference. So, excitatory neurons send activity and fire. So, neurons fire, they send messages. Neurons fire, they send messages with information, but they have preferences. So, an excitatory neuron with information might only activate if they see a color that they prefer. So, not all neurons fire for everything. They have particular features that are more salient to them. The second group is inhibitory neurons. And so, what inhibitory neurons do is that they kind of retain this information. They keep things from running rampant. As we talked about yesterday, right, synchronization in the brain is bad. Synchronization in the brain is bad leads to seizures. And inhibition helps to modulate this so we don't have too much firing and we can actually read out information. So, the way I like to think about it is excitatory neurons, if we were to read a page in a book, excitatory neurons hold the letters. Inhibition is where the spaces are, so that we can actually decipher that information and make words out of it. So, this is what a neural representation would look like for this color. And if we were to actually think about what this looks like. And if we were to actually think about what this looks like in terms of activity in a network, we activate our excitatory neurons, and only those that have the same color are going to activate, and then they're going to retain that information and fire in time. And so what we can do is think about that in time, we have some amount of noise that we're moving with, and we could read out the response, right? Which neurons are activated at the end. But we can take this one step further, because this is a pretty complex system to try to model. So instead, we can use a much more Model, so instead we can use a much more simplified version. We've talked about particle representations quite a bit, in which in this case we can talk about our particle as being the memory and the energy landscape as being the connections between our neurons. So this is what's called synaptic connectivity. So the reason we want to talk about this simplified model is that we care about how these neurons are connected. And we can have two hypotheses we can pose about how and why we have systematic. About how and why we have systematic biases. On one hand, we could say that maybe the energy landscape is flat, right? In which case, our particle is only impacted by diffusion. There's only some amount of noise. So what this would mean is that our particle, which is equivalent to that little activation bubble, right, of neurons, are going to shift in time. And so we just have some amount of noise in the system. But the other option Option is that maybe we have these sort of attractor levels, right? Now we have this heterogeneity in our energy landscape, and so now we can have a drift component as well as distribution. And in this case, what we're really saying when we have this heterogeneity is that we're saying that certain neurons have more communication between them than others. So they have stronger connectivity in certain regions than others. And so if we were to look at this, what we see is that. Look at this, what we see is that now in time, along with the noise, we're being drawn to particular points, right? There are these attractors. And if those attractors are at the same points as our preferences or what the environment is representing, we now have a way to try to minimize our noise for things that are important. So, how do we do this? Well, we can just compare, we'll look a little bit closer at how these particle models would compare to our environment. Compared to our environment. So here, if I put the wells of our particle model landscape at the same point as those peaks, we can now compare how much error do I have. And the way that we're going to compute error in this case is literally just to think about it as distortion. So what was the color that I started with? How far is this color in circular space? Because they give these as rings. So you have a ring of colors, and you have to pick it. Ring of colors, and you have to take it. And in the case where we don't have any sort of heterogeneity, we get something that makes pretty basic sense in our response distribution is going to be spread the same for a common color in our environment as it is for a rare color. And so there's no benefit in our distortion, there's no changes. But if we incorporate this heterogeneity, now what we see is that for a common color, I have a much That for a common color, I have a much narrower response distribution. So I have less distortion for things that come up often, but at a cost. Because now, since we have this drift component, if I have a rare color, I'm going to be drawn to either of these attractive ones, right? So there's a trade-off. And now the question is, is that trade-off still beneficial? Is it still worth it to have this sort of a structure? And so we can ask this. And so we can ask this just by comparing: well, what does my environmental landscape look like? What would my synaptic connectivity look like? So our landscape. And we can look across all of our different values of theta, so all of our different colors. And what we see is, of course, that at these rare points, we have the highest amount of distortion. So this is our distortion metric. And it is minimized at these points. Minimized at these points. If we look at this overall, we see that having any amount of synaptic connectivity that's heterogeneous is already going to be beneficial. And so what I just want to point out here, this is relative distortion. So we're saying if I had a flat landscape versus a heterogeneous landscape where we vary the number of wells. So it doesn't need to match exactly the environment, but have any number of wells. We see that. Any number of wells, we see that that in itself is enough to still be beneficial. And here, what I've done is I've plotted this for multiple delay times. So, how long do you have to keep this memory in your mind? So, first question is answered. Yes, having this sort of heterogeneity does benefit us in terms of retaining these memories. But how do we learn what is an important feature? And so, we want to take this one step further and move beyond just saying, okay. Move beyond just saying, okay, well, this is beneficial, and come up with a way to interpret why we end up with these sort of biases. And so, in this case, what we're going to say is it's going to be an experience-dependent belief updating. So, for the other person participation things, here you go. So, we're going to imagine that now you've never seen a color before in your entire life. And I show you this color, and I say, here, remember this color. We can think about this as now your belief. About this, as now your belief that you can see this color again in the future is increased. So, we can think about the probability of this as now being a peak. I'm going to incorporate that peak. And correspondingly, I can think about this as building a well into my landscape, right? So now I have one belief. I say, oh, okay, well, green came up. I must be able to come up in the future. That's an important color I'm going to build in this feature. Now we see another color. So we incorporate yet again another piece of information. Yet again, another piece of information, and so on and so forth. So that by the end, what we end up with is wells that correspond with the peaks of our environment. And our beliefs about the environment and the probabilities are going to match pretty well. And what we see is that if we look at how distortion changes, so how well do we do, we see that it very quickly drops as we're learning close to what happened when we had the case where we already knew. Case where we already knew exactly where those groups were. So this suggests that, okay, we can learn this, and that there's a reason and a motivation for this based on experience. But now we have the question, do humans even show a sign of this experience-dependent learning? So conveniently for us, the same data set that had those initial results did a second task where they showed two items. And so it's the same idea. I show you two items, I take them away. I show you two items, I take them away, I probe you for a location, I say, tell me what color it was. But instead of sampling from a uniform distribution, they now have an environment where there are certain colors that are overrepresented. Now, what's really important about this is that every subject got a different set of colors that were overrepresented. And the reason that this is important is because we already saw we have particular biases, right? We have a preference. Biases, right? We have a preference. But by setting that offset randomly for every subject, we now can ask: well, can you actually learn? What if I gave you an over-representation that doesn't match with what you believe in the environment? So we can compare those responses to the responses from a particle model where we have a few different flavors of landscapes. We have our homogeneous and our static heterogeneous. We're going to have two forms of the learning models. So in one case, Learning models. So, in one case, we have an experience-dependent version in which the target is the only thing that's going to update, right? I'm going to only update my belief after I've given a response. But in the other case, well, what if I update before? What if I think that both of these pieces of information are important? The target and the second distractor item? So I can update it with both. So, if you go through and you fit all of the subjects that they have, what we see is that. Have what we see is that most of these subjects apply a learning model, and so that suggests that they actually are updating based on their experiences. And so you could say, okay, well, maybe, but is there any more proof? And so we asked, okay, what were the offsets that these subjects were assigned? And what we find is that for those that had an experience-dependent updating, most of those subjects had offsets. Those subjects had offsets that were drastically different from what the initial biases are. So, this is suggesting that we actually have flexibility in our behavior, reflecting this sort of a hypothesis. So, this suggests we have these cognitive biases. We use them, we're learning about our environment. What it doesn't tell us, we used a very simplified version of how the brain might be implementing this. So, we want to go back and now say, Back and now say, all right, can we build a network representation that is also capable of doing this using biologically relevant mechanisms? So we back up to where we were before. We remember is we have our excitatory neurons, they have a preference for a particular feature, we have inhibitory neurons that are going to modulate that and keep our information retained. And so we can model this in terms of a neural field model. And what this means is that we have our Q. Is that we have our cube, and we're going to consider neural activity. And so we can think about it as just a line of neural activity. We're not going to actually model individual neurons in the network, but instead look at, oh dear, well, hopefully that will correct itself. Can everyone online still hear me? Yes. Okay. Cool. So the important thing here is that now So the important thing here is that now we have our average neural activity in our network. And then we have to look at what is the conactivity, how much activity are we seeing, so the firing rate of all of our neurons together. We have some amount of noise and that input, right? Our initial activation. But what's important in this case is that we can take this one step further and say, okay, so now we're in our delay period. I don't have any more input. My neurons are doing their thing. But what if instead of just having But what if instead of just having regular homogeneous synaptic coupling, I incorporate this spatial heterogeneity? So now I have certain neurons that are going to have stronger connections to one another, and I can decide where those are. So just to give a more visual representation of what this means, here's our road. This is my beautiful network of brain, obviously. And on one hand, these red bars are going to show us: well, what is the connectivity? Us well, what is the connectivity from the excitatory neurons? So we see that they're nicely evenly spaced. Our inhibitory neurons are a little broader, just like we saw it on our schematic. When we have that periodic spatial heterogeneity, we see that the strength is now modulated. So there are positions that have stronger activity than others. So this is our model. We now have a whole network of brain. But does it actually do what we suggested based on the simplified model? We suggested based on the simplified model. And so, what we can do is first look at the homogeneous case, and if we have a common color for our environment, we say it's just noisy activity like we saw initially, same for the rare. But in the heterogeneous case where we have this modulation of our synaptic connectivity, we now see that the common color is again retained more directly as in memory without as much noise. Our rare items can deviate, and they're going to wear. Can deviate and they're going to where those stronger excitatory connections are. So, this is suggesting to us: great, we can incorporate this sort of strengthening of connectivity, but how do I build this? How do my neurons know that they should be connected in different ways, right? And so we can now say I'm not going to just have a spatial heterogeneity, I'm going to modulate it in time, just like we did with our beliefs about the environment. Beliefs about the environment. And the way that we can do this is through biological mechanism. So now, when I activate my neurons, I have my excited growing neurons that like a particular color, we're going to incorporate a plasticity role. What this means is that there's potentiation. So neurons, there's a phrase, neurons that fire together, wire together. So if they activate, and so they have similar preferences, they're also going to strengthen. They're also going to strengthen their communication with one another because they think that the other person might have some relevant information, right? And then we need another component here, which is the homeostatic plasticity. And what this is really just keeping us from doing is having runaway excitation, too much connectivity in the brain, all of these things. We've got to keep things level. So if we were just to envision what this means, let's say that just like before, I have my first item. I've never seen colors before. I've never seen colors before. I activate these connections. Now, when I see a second item, I'm going to have the same thing, I'm going to connect my neurons, but I'm building these connections. And so over time, as I see the same colors over and over again, those particular connections are going to be strengthened much more than a rare color. So if we do this many, many times, what we see is that now we have these modulations, just like when we built it. Modulations, just like when we built it directly. And so we have a way that we can actually build this mechanistically and based off of what we saw from the cognitive strategies. And main question after that is, okay, well, does this actually benefit us? And we can see just like what we predicted with the behavioral side, we get this reduction in distortion associated with this learning. And so this is suggesting that, yeah, we actually have a mechanism by which our brain can implement something that we see. Brain can implement something that we see in terms of behavior. Good timing because now here we are at conclusions. So, hopefully, what I've convinced you of today is that we can use human working memory biases to learn about our environment and that humans specifically show this experience-dependent learning of the environment that's really important and allows us the kind of flexibility to do complex behaviors. The other half of this is The other half of this is that we can actually see this based off of some sort of environmental and experience-dependent plasticity. We can have a network mechanism for how we have this kind of flexibility in our work. And so with that, I will finish up and take any questions. Okay, maybe we go to the virtual group first. Are there any questions online? Not yet. Yeah, let's give the virtual folks my name. Okay. I have a question about the very last part. How did you incorporate simplicity kind of this whole chapter? I guess you had an equation up early on that was so you here, what is that, neural activity? Yes, so this is the average neural activity. So this is the average neural activity at a particular time point, but you also have, so because we can think about this as like a sheet of neurons, right, we can also have this discretization that allows us to have points. So neural activity at a particular point in time. Even though they're not specific.