I want to thank Rebecca. What I'm going to present, the new stuff is largely from her PhD dissertation that she's been working on. This is my great collaborator, Mike Gold, and Libbyn was a joint postdoc with me and Mike, and Libbyn did the majority of the experimental work, which will pop up here in a minute. Okay, so okay. So, okay, looks like the audio cut out. Oh, everything's red now. Which is what it's supposed to be. I think we just should stop looking at the color because I'm not sure it means anything. But we'll also not see the explained. We'll just see us in the middle. Oh, that's a good point. That's the main issue. Yeah, Peter Kramer wrote in the chat, no slides, no speakers, no sound. All right. No sound. Yeah. Peter's seen me before, so probably doesn't. All right, I didn't say anything important up to this point. And this slide really doesn't say anything important either, except just to emphasize that I'm going to be talking about immune cells as my model system here, although this is really a talk about particle tracking. About particle tracking. And particle tracking, where we label up individual, in this case, it's a B cell receptor, where we label those individually with fluorescent tags and then image them, typically in TERF microscopy, and see them moving around on the surface of the cell. And then we'd like to make some kind of inferences about how that impacts their function. And it's known that if you get the B cell receptors close. Get the B cell receptors close together, or in the case of a T cell, the T cell receptors come close together. That kind of clustering can drive signaling, and that's an important part of how immune cells regulate themselves as well as how they generate immune responses. So, I've been working on spatial dynamics of immune cell receptors for a while. And sort of when I started looking at this way back in 99, we would have these. We would have these kinds of slice confocal images where the green here are actually T-cell immune receptors, the reds are actually adhesion receptors, and they sort of rearrange over a period of time, and we all had fun making models of that. And then a bit later in 2005, the exact same experiments, which are here done in sort of slice focal, were repeated using turf microscopy. And you can see that this kind of blurry stuff was resolving itself into clusters. Resolving itself into clusters of surface molecules on the cell that were rearranging over the process of a few minutes. And then, not very long after this, we started looking at what I was describing, which is single particle measurements. So, there's basically just been an increase in spatial resolution. And I don't know if it's made modeling any more fun, but it means you have to do different kinds of things to model. Things to model. So, this is the sort of thing that we do. We take an antibody which can bind to a receptor on a cell, we digest it, so it's monovalent rather than bivalent, and we add Psi3, and then we label up the receptors on the cell at pretty low density, because if we labeled them at high density, all you would see would be blurry colour. We want to actually resolve these things individually, and then we take a Things individually, and then we take a movie of this in turf. And this is the kind of thing that you see. And the colors here are the tracking that you can do on those blobs. So you start off with the blobs, and you acquire the blobs, and then you do your best. Well, you have an algorithm that does its best to track those over time. Okay, so the data that comes into the Into the oops. I'm not quite sure what happened there. But the data that comes into the model is basically these series of x, y positions as a function of time. Plus some information usually about an estimate of what the error would be in the positions. Okay, so these are tiny microscopic objects, so the right thing to do with these would probably be to try to fit them to Brownian motion, as sort of a start. Motion as sort of a starting point. And so this has been a traditional thing. And as Bill was showing earlier this morning, in a very different context, you can take some diffusive trajectory. I simulated one here. And you can take every possible displacement of length n out of your track. So all the displacements of length 1, length 2, length 3, and you can stack them up like this. And you can generate this thing which we would call the mean square displacement curve from a single track. And the expected slope of that would be a curve. And the expected slope of that would be, in two dimensions, would be four times the diffusivity. Okay, so we fit a line through that, and naturally it's pretty good in this case, right? But as Bill's already laughing because he knows that, you know, so one thing we find though is that if you only take the first 10 points, you actually get a much better estimate rather than taking all of these points. And then there's this question of whether downward sloping MSD plot from a single MSD plot from a single trajectory is actually diagnostic of anything, including anomalous subdiffusion. I think most people will agree that it isn't because all I do is I simulate five or six or seven tracks or whatever I did here. And you can see early on they kind of look the same, but after a while you start to see. And you would need to generate millions of tracks for these points to really have any value. So you're better off just picking the slope out from the first few images rather than going. Images rather than going through many, many images. So your mean is okay if you have many tracks, but your standard deviation is much tighter. And in fact, and I'm not going to step through this, but in fact you can basically verify that the maximum likelihood estimator is what you would call the single step MSD. So in other words, you get rid of the whole MSD plot except the first point. Okay, so this, yeah. This is the MLE for the diffusion. The MLE for the diffusivity for just vanilla brownie motion. Vanilla Brownian motion, yeah. That's not a mean square displacement sort of calculation. No, no, this is just what it is, yeah. Okay, so then one of the issues though. Just a quick comment, doesn't that allow you to ascertain that it is diffusive? I mean, it allows you to reject diffusion if you have enough, and you could make that, what I just said, more precise. Ballistic motion. More precise. Like ballistic motion. Ballistic motion will go like this, but if you only have one track and it's going like that, we might want to, you know, that comes up more with people who track animals and stuff like that. Because we can always go back in the lab and get more tracks, whereas the animal people have difficulty doing that. So the next thing that you should think about, though, is the fact that, especially in the kind of microscopy I'm talking about, we're at poor signal. Talking about, we're a poor signal-to-noise ratio, and so we should realize that our measurements don't have infinite precision. Okay, so the first thing is that if you just image one of these blobs, one of these fluorescent dots, then I went to great lengths to zoom in on the pixels here, and this was one frame of one movie, one dot that I zoomed in on. Okay, and so I think the best way to estimate what the static error in the position of a particle is is to get a particle, stick it down. There are different options for doing this, but drying it is not a bad one. And then just see what you get. Just run it through your whole algorithm. Image it, track it, see what you get. So we did that, and you can see. And you can see that the particle, which I put in a red circle, is wiggling, right? Because our imaging doesn't have infinite precision. And we're actually tracking it here, and you can see the track gradually appearing. And this tells you what your precision should be. And for a fab, an image at 30 Hz with our microscope, our tracker, and all these kinds of things, the standard deviation is about 40 nanometers. So each pixel here is about 100 nanometers for us. For us. There's a second particle. Sorry? It's a small, I say, it's maybe 10 nanometers or something. So it's just flopping up. It's probably flopping around whatever it's holding it in place. The other thing, the other kind of error is beyond the static, just simple point spray function type error, is the dynamic error due to the fact that we're operating at very poor signal-to-noise ratio. So we don't take an image and So we don't take an image and then just wait and then take another image and wait and take another image. We have the shutter open as much as possible. So the shutter is open, you know, for 29 milliseconds out of 30. And then one millisecond is needed for the camera to refresh the registers. So we're actually keeping the shutter open as much as possible. And so there's this notion that you're getting a blurring error. And in fact, if you look at again one frame here, you can kind of see maybe this is sort of an ellipsoidal thing. This is sort of an ellipsoidal thing, so maybe this particle was taking a little step at this time, you know, so you're blurring it out. So, if you if you kind of just just to emphasize just to emphasize that a little bit more, okay, so I just simulated a track here. This is just a Brownian motion track imaged at some arbitrary sort of frame rate, okay. And then, you know, so if you average that, say, instead of getting to take, you know, if you average over every 50 steps, If you average over every 50 steps, you sort of get this thing, which looks a bit different than the blue thing, right? And if you then proceed to add an error to every one of these acquisitions, then you kind of end up with the yellow track, which ends up looking quite different from the blue track. And so you should incorporate this when you're trying to estimate parameters from your data. Okay. So fortunately for us, this was all explained in 2010 by this guy, Berglund, who wrote By this guy Berglund, who wrote this lovely paper, which even has sort of efficient ways of calculating things. He validates that the maximum likelihood estimator is a really good estimator for the parameters you want to get here. And it's just lovely. But it's all for single-state diffusion. So in a sense, the single-state diffusion was sort of solved in 2010. It took us until 2015 to actually implement what he was doing, but that's a whole other matter. Yeah, I always say this, and everybody knows this, if you have small numbers of tracks, you have to be careful, right? So sometimes I ask people which of these tracks is a drift diffusion process, and which of these tracks is a barrier, is there a barrier which it hit? And which one is transient confinement? So this one, oh, it's confined here, and then it hops out and it's confined here. And of course, these are all just random tracks, right? So if you have small numbers of tracks where you can start using your eyes, Numbers of tracks, so you can start using your eyes, you're going to run into difficulties. Single tracked inference is risky. What I want to move on to now, so to develop from the single diffusivity, vanilla diffusion, is to go on to multi-state diffusion processes. So what if the particle can actually transition between, say, free diffusion, and then maybe it binds to a relatively massive binding? Binds to a relatively massive binding partner and it slows down. It binds to something which is maybe tethered to something else within the cell and it slows down. So we started doing this about a little over 10 years ago with my postdoc at the time, Dodo, and Chris Cairo, who's still at the University of Alberta. And Chris was labeling this adhesion receptor on the surface of a T-cell. Receptor on the surface of T cell line. And this is kind of the model he wanted to explore. This was actually the model we sort of ended up with: that the receptor itself could exist in multiple conformations and that their ability to interact with the cortical cytoskeleton might be different. If there wasn't a direct interaction, I think that we knew about, but we suspected there were sort of indirect interactions between the receptor and the cytoskeleton. And Chris had. And Chris had taken a whole bunch of data where he'd labeled these receptors and tracked them single particle star. And this was a paper that he'd already written with David Golan and other people, where he did particle tracking under control conditions with cytokalasin, where the cells were pharmaceutically activated. And he sort of broke his tracks up into like he. He took his single-state diffusivity and kind of said, Well, there's some higher ones and some lower ones, and he kind of divided the cells up into both, and then he looked for differences, right? And this is great, except it's very static because he was extracting a single diffusion coefficient from each track. And then this is what shows up over here on these histograms. The tracks all the same length? Yeah, he was using bead labeling here, so all his tracks are a thousand hertz for five seconds. 1,000 hertz for 5 seconds, so 5,000 frames. Every track's the same length there. And so he had sort of published it like this. And we said to him, Hey, how do you know, if you think you have this interaction, how do you know that all your tracks are entirely in one state or entirely in the other state? What if you're having dynamic transitions in the middle of your tracks? And so this was the model. We said, sort of, suppose LFA1 binds and unbinds from something like the cytoskeleton, and this is sort of a. Something like the cytoskeleton, and this is sort of the hidden Markov model where the particle can be diffusing in a quick state and then it can bind to something and then it's diffusing in a slow state for a few frames and then maybe it goes back to the quick state. And can we extract that from the data? And I think most people here have seen me talk about this before, but you can construct the likelihood for this thing, and then you can do this sort of dynamic programming approach to optimize, to calculate the likelihood efficiently, and then you can optimize that with NC. Efficiently, and then you can optimize that with MCMC. And this was the figure we came up with. So, this is some subset of Chris's data, sort of in the way that he would analyze it, and we can break it out, and we can actually find that these two diffusive states actually explain the data pretty well. So, we get pretty good estimates of the diffusion coefficients. We get sort of generally flaky estimates because you don't see very many transitions. You don't see very many transitions, so it's hard to estimate the transition rates. If, and we could show sort of formally that if D1 and D2 are about the same, then this thing whole cleanly reduced down, and it would basically tell you a one-state model. We did that with simulated data. And we had a statistical test which told us whether we had a one-state model or a two-state model, which was based on an information criterion approach. Okay. So that was. So that was sort of where it sat until about a year ago, which is a bit embarrassing because we had this for like 10 years. Another group reanalyzed Chris's data and said, hey, you guys should think about errors. And they were right. So we've now come up with an independent way of including the errors in. So basically, we take the error model that I had before of static error and dynamic error or blurring error and we can build that in. And there's a lot of details that have to happen for that to get built in. That to get built in, but it can be done, and Rebecca did it. And so, again, we can calculate things. And I can, so this is a table. I hate doing tables of data, but we do simulated data here, and we have two algorithms. We have the SPT2-State algorithm or the SPT2-State with Errors algorithm. So this is Severka's new thing, this is Dodo's old thing. And we, oh, yeah, so So hold on a minute. Signals your error parameter? Signals the static error parameter. But there's also dynamic error that you can't, that isn't written on here, but there's dynamic error as well, which is due to the shutter being open for the whole time. So that's error that depends on the previous, it's some sort of, has memory to it then? Yeah, well, any kind of error in your positions basically means that the subsequent... means that the subsequent displacements are not independent. Yeah. Because they're joined here, and if this one's wrong, it changes both of them in a related way, right? Yeah. So basically if we fit the data, and this is exactly what I showed you with that kind of picture where we had the precise track and then we sort of messed it up by adding errors, you can see that the first diffusion coefficient was supposed to be 1 and the second one was supposed to be 0.1 in some units and we had some transition rates. And basically, you know, we just And basically, you know, the we do a poor job of reconstructing this over different sigmas. And if we then build the errors in, well, I could just have put a bullet point. Our algorithm works, right? But it works and it works considerably better than this. And this was with good simulated data, so we knew examined what was going on. So how did you fit this new? There's more parameters in the dynamic error, right? The static error is sitting. The static error is sigma. Well, there's only the shutter parameters. I'm just saying the shutters are open the whole time. Okay, so there's no more. There's no additional parameters. There's no additional parameters, yeah. Yeah, if you want to do some funky shutter thing where you open it for a third of the frame and then close it for a bit and open it again, then you have to redo this into more parameters. So we're now looking at some of the data I showed at the beginning. This is I showed at the beginning. This is fluorescent antibody labeled B cell receptors of the IgM type imaged in TERF. And our previous two-state result was that the slow state was, these are different scales. So the slow state here is, you know, this is a ten-fold scale less than this, was about this, and the fast state was whatever microns squared per second that is. If you include the errors, basically, it says either the particle's moving or it's not moving. It basically It's not moving. It basically reduces your slow state down to just an immobile state. So this is actually kind of different. It sort of makes me think we should have looked a bit more carefully. It doesn't mean the particle is necessarily moving, but it's that the motion of the particle is indistinguishable from the static error if it's in the slow state. And just to show an additional experiment here, again, this is the two-state model. The two-state model. This is the two-state model for data where latrunculin is added, which generally speeds things up a bit. And you can see that we actually see a bigger change in the fast state because it's not having to take up the slack for the sort of inadequate slow state. Alright, so we have this two-state model, and I'm still a big fan of this, even though I've discovered that for some data sets, the Set, the addition of errors kind of changes the way you want to look at things. But I still think it's a useful thing to do. And you need to be careful with the errors. That's kind of my discovery over the last few years. But I want to ask now, how restrictive is the two-state model? And I'll do that if I have a moment by way of a short anecdote. So Dodo, right, he was working with the two-state model. And we kind of showed that it was better than the one-state. Showed that it was better than the one-state model by running it, by comparing the likelihoods for the two things and then making the correction for the number of parameters in each model. Because the two-state model has four parameters, the one-state model has one parameter. So we made sure that this was sort of preferred. So I then, one day I was in my office, and I said to Dodo, why don't you code up the three-state model and see if it's better? So he did that, and lo and behold, it was better. It was better. And then I said, we should probably stop doing this if you, because otherwise, we were going to end up with a four-state model, and then we didn't know if it would stop. So things sat like that for about five years. And then we read this lovely paper from Steve Prestet, who's now at Arizona State, about his use of the infinite hidden Markov model for molecular dynamics kind of things. And it was one of those. And it was one of those moments where you read the paper and you say, aha, this is just exactly what I need to address this problem. It's been bugging me for the last little while. So Steve has some data which looks like this, and he believes that this is a fluctuating molecule, and he believes that the data comes from sort of different conformational states, which are reflected in the data. And he doesn't know how many states they're supposed to be, so he sort of allows the data. Supposed to be, so he sort of allows the data to sort of pull out that there's five states in this blue trajectory here. The orange is the fit, right? So clearly we could do something similar with our diffusion problem. That's not infinite, that's just fine, right? Yeah, but in principle it's infinite. So basically, the infinite state model, it's never infinite, because that would be difficult to compute. But what it really is, is when you What it really is, is when you're in the process of generating this fit, as it were, or this model, you potentially have infinitely many states. Now, in practice, you sample so you only deal with sensible numbers of states. But in principle, it's infinite. Like, if the data supported it, you could have 100 states. You get a single optimum for the number of states. You hope. Well, you hope, yeah. Sometimes it could be sort of in between. Yeah, sometimes it could be sort of in between two, right? Okay, so I think, in the interest of time, I'm just going to skip over a little bit of the details of how exactly this works. But the sort of main ingredients are that the state transitions are governed by some matrix. And the issue is, is the matrix, you know, which is, can you go from state one to state two? That matrix changes in size according to how many states you have. And then And then the positional changes or the steps in the track, given the state that you're in, come from some diffusivity. This is still vanilla diffusion, except there are different diffusivities, right? So the particle can transition between these different diffusivities. Okay. So broadly speaking, how it works is: you know, as you're going through, you've got some estimate of the number of states, you've got some estimates of your States, you've got some estimates of your transition matrix, you've got estimates of your diffusivities for your different states. And the sampler basically tries to pull, it tries to, there's a condition, but it basically looks to see if another state is warranted, then it runs with that state for one iteration, and if it turns out that that state was not needed, then it contracts back down again to sort of the same number of states it had before. And then there's the potential to just keep doing this, right? Potential to just keep doing this, right? There's a little bit of interesting distributional stuff because you're not just sampling a distribution, you're sampling a distribution of distributions so that you can get this transition matrix because it keeps changing size. So if you run this, so this is on simulated data, and we start off with some number of states sort of up here. So we start off with plenty of states to make sure we're not underfitting. To make sure we're not underfitting. And then basically, if we have one state simulated data, then it converges basically to one state. But you can see there's still a little bit of uncertainty, right? It's possible that data came from a two-state thing. So if you wanted to be completely thorough about how you analyze this, you would report sort of 1.1 states, I guess, or something like that. If it's two-state data, it converges. If it's three-state, so we made sure that the model works on simulated data. Simulated data. And it is able, with high-quality simulated data, to pull back, if you feed it two-state data, it gives you two states. If you feed it three-state data, it gives you three states, and so on. You'll note here that the states are pretty well separated in diffusivity. If they're close together, it starts to have trouble, as you would imagine. So going back to that same set of B-service. Back to that same set of B-cell receptor data that I showed you before, when it's labeled with fluorescent antibodies, basically it converged down to four states. Okay, so Dodo didn't actually have to worry because if he had gone from three to four, it would have gotten better. But hopefully, when he got to five, it would have been worse. It definitely would have been worse for him, and it would have taken a while to run. But he would have gotten it, right? It's very likely that the highest diffusivity state that's being picked up here is probably tracking errors. So it's basically where one of these particles fades away for a frame or maybe it's bleached and the tracker tries to pick up another one. And if you look at the occupancy of this state, it's low, it's like 1% or something of all the transitions. So it's sort of reasonable that that would actually be tracking host. So biologically, you've sort of got Biologically, you sort of got immobile, I have a low and a high kind of state. Okay, so can anyone guess what I'm going to do next? Okay, so let's just re-recap. We had one state diffusion, we had one state with errors, we had two state, we had two state with errors. Now we've got infinite state, what are we going to do next? Infinite state with errors. Infinite state with errors. We're going to do infinite state with errors. But one slide of infinite state with errors. So it's painful, but it can be done, and basically. And basically, on three different days of data, we basically come back to including the errors, basically, but it basically pulls these two together and sets them to a very low diffusivity. Because this guy is actually so low that it's hard for it to distinguish it from the sort of noise border that it's bearing. You can see on one day it reports four states. One day it reports four states, but if you look at what the actual states are, they're not wildly different. Okay, so basically, in a sense, if you agree that we don't have tracking errors, if we could somehow throw out any tracking errors, like have a really, really great tracker that never made a mistake, we'd probably lose most of this. And we would be left on two days with a two-state model, and on one day with a three-state model, but where two of the states are actually pretty close. But where two of the states are actually pretty close together. So maybe the two-state model was actually sort of okay after all. Anyway, that's my hierarchy of SPT models. And this may be the last thing we do on this. I say that SPT is an entertaining and very powerful technique for assessing single molecule transport. It's probably the only technique we really have for looking at certain questions. You can address different hypotheses. You can address different hypotheses around modes of mobility. You can do multi-state models. You've got to be careful with errors. What I didn't show today is we have done some work on diffusion slash, where you have one stateless diffusion and one stateless diffusion infection. Okay, and you can imagine trying to build that kind of thing in. What I also didn't show today is once you fit, you can go back to your track and do your best to label it as fast bits and slow bits, and fast bits and slow bits in your track. And fast bits and slow bits in your track. And if you could do something spatial with that, you might be able to start to look at whether you're actually seeing some kind of confinement in certain regions. If you had a very long track that revisited the same point multiple times and was slow consistently, and that is possible you might be able to do that. And identify spatially heterogeneous things. David Holtzman's group did some nice work. I forget exactly what they were tracking, but it was on some kind of mirror. But it was on some kind of neural cells. Dendritic dendritic spite. Dendritic spite. Yeah, and they were basically doing a kind of combined PAM SPT experiment where they would activate some fluorophores, track them until they bleached, and then activate some more and track them. They were able to repeatedly sample the diffusion on sort of a geographical basis. And I've seen that, I think, from another group since then. So, yeah. So, anyway, that's my talk, and thanks for your attention. So while we wait for the speaker to come on for questions, Pete Kramer raised the interesting observation that the estimates they never underestimate the number of states. It's like the uncertainty only went sort of one way. Like when it was one, it would sort of jump up and down. It would go back up by one. Yeah, so it never goes. Yeah, so it never underestimates the number of states. That's true, that's true, that's true, that's true, that's true. We have the speaker here. And then, Scott, what did you have to say? Oh, Scott can. There were questions in the room too, Jay. We're still waiting on the speakers, so we'll get to you guys in just a second. Alright, so who's first? Just a second. Alright, so who's first? We have to go first. Significance. Are you just seeing that receptors are kind of bumping into spatular membrane and slowing down slip? Or is it really that there are four very different states of these receptors that do different things? Well, you have to poke up the system, right? You have to do perturbations and see what happens, right? Yeah. But I think at the end of the day, with the B cell receptors, I think the moving of a knot is pretty much a Moving of a knot is pretty much a good approximation of what's going on. And if they're moving, then they look, yeah, but this is transient, they do get stuck. So, what they're bumping into and sticking to, that would be the next thing to look at. So, we did the LFA experiment, and I haven't actually haven't analyzed that with the full errors and SPT model. Cool, thank you. Do you know if there is, can you quantify the relationship between Quantify the relationship between the error in system and how well it can distinguish different states. So, basically, okay, so because with different imaging modalities, there's going to be probably different errors associated with that. And being able to distinguish is not just for the low ones, too. It'll be like they're too high for safety. Absolutely. So, actually, we use that to our advantage. The convergence plots I showed were accelerated quite a bit by Accelerated quite a bit by sort of man, not manually, I have to say manually, but we introduce a compression step in the algorithm that if two states are close together, we merge them out, we merge them, which is a sort of a hands-on bit of sampling that we're doing, right? It's merging the states together rather than letting the system take another 10,000 iterations to figure out that it should get rid of one of them and merge those together. We're still waiting on the speaker, sorry. Is there another question in the meantime? So it sounds like what you're saying is that what's probably going on is there are two states, moving, not moving. That sounds like track, continuous time, random walk. Yeah, it could be. I mean, which is which, but there's a difference between continuous time, random walk in that the there's a distribution of trapping length times. Distribution of trapping link times. That could be anything. It's not a model. It's forced to be exponential in this model, right? Sure, okay. Yeah, that's what we're fitting it with. That could be an extension to try to see if there's evidence for something different. In the interest of complete full disclosure, there's always some dots that just refuse to move, and we throw those out at the beginning here. So those could be a population of things in a long, that are going to. The long that are going to stop moving a minute from now, but we only image but 10 seconds, right? It's like they're trying to turn the speaker off. So let's please be patient with them. Do we have any other questions in the meantime? Sorry. So Scott mentioned that Dave seemed to be. I'm sure the speaker isn't gone. I'm sure the speaker isn't on? Oh, it is now. Thank you. All right. So, who was first? Peter? Yeah, I'll then roll first. Okay, sure. Nice talk. I really, really enjoyed it. I have a couple of questions, but I'll just ask one of them and maybe I'll try to ask you some other ones offline. Offline. So, how important is the assumption that you're really looking at two purely diffusive states? For example, we often are interested in things that we really know are binding to cortical actin filaments. And when they're bound to actin filaments, their emotion is definitely not diffusive. So, how would you apply a similar formalism to something where you know that one of the bound states One of the bound states is not diffusive. Yeah, so we did that for a diffusion-drift diffusion model. Did it a long time ago. Unfortunately, the data that we had at that time, it was basically, oh, we looked for it and we never found it. And Biophysical Journal in their infinite wisdom said, well, that's not good enough. And so it didn't get published. But I have it if you want to look at it. We do it in the Bayesian way, right? In the Bayesian way, right? We don't do the way that you do the calculation works a little bit differently than how we do it for two diffusive states. Maybe we can sit down and talk. I'd love to think your brain a bit more. Sorry, who's speaking? Ed Monroe. This is Ed Monroe. Oh, hey, how are you? I wasn't sure who was here. Yeah, maybe I'll send you an email or a chat where we can talk. Maybe we can talk in the That would be great in the gathering. All right, who's next? I've got a question. This is Will Hancock. So we've been doing tracking with gold nanoparticles that are just on motors. It's just fantastic. And in principle, we could go to 10,000 frames a second or even higher. Even higher, or else you could just do a thousand frames per second, but you would do one, your open time of your shutter would be one tenth. And so my question is about sort of scaling. And, you know, for your approaches, what would you rather have? Would you rather have as high a frame rate with the camera open, with the shutter open the whole time? Or and then And then, if you had that, would it be better to just average down, for instance? You know, oversample, average the position to improve the position error? Or is there a bang for your buck on the basically flashing so that the shutter isn't open for very long. If you had a If you had whole new technologies available to you, which ones would you want the most in the way that you mentioned things? I can't tell you the answer to that for sure without looking back at some formulas and thinking. But my gut reaction is you would, unless you wanted to probe something that really was at 10,000 hertz, you'd be much better off working at 1,000 hertz with the shutter off, as it were. I'm assuming that you still. I'm assuming that you still have some static error, right? Which is probably comparable to ours. You have a gold nanoparticle, and your static error is probably still a few tens of nanometers? No, it's actually better than that. I mean, at a thousand hertz, we can get a couple nanometers, actually. That's amazing. There's a lot of length. We're not photon limited. Yeah. That's the difference. Yeah, I would need to look, but I still feel like unless the I still feel like unless the biological phenomenon you wanted to look at was at 10,000 hertz, I would probably sample at a lower rate. But yeah, it would be really fascinating to see you do it both ways and see if there's any differences in your conclusion, right? Yeah. Yeah. And we have run into trouble with just too much information at those high frame rates. And yeah, yeah. Okay, great. Thank you. I really enjoyed your. Okay, great. Thank you. I really enjoyed your talk. Yeah, thanks. Pete Kramer? Just a basic question. I think this was implicit when you said, but I wanted to just check. If I just had a four-state monitor and pretended I didn't know it was four-state, and if I ran IHFM on it, you're saying that it would be faster, it would run faster than if I ran a one-state fit, a two-state fit, a three-state fit, a four-state fit, a five-state fit. State fit a four-state fit, a five-state fit, and the state PIC likelihood comparisons. That would probably be faster in terms of computation time, but I don't know. I'm always, I've got to tell you, Pete, I'm not the biggest fan of information criteria. Like, I use them as a last resort when I don't know what else to do. Some of them are doing model selection, so I don't know what procedure you're using for doing that. I'm just seeing that it's chaotic to do it with just the price end to end. Has to be good with just the price MM, even if the low-order model in reality isn't serial model sponge. Yeah, I think it would be computationally faster to do that. But I refer you to John Fricks, who I had a great conversation about this with, but I forgot everything he said. But I do remember knowing understanding for a while what was going on. I don't know how he feels about the Bayesian uh model selection and stuff though. Yeah, actually I don't know. Di that was before this, yeah. That was before this. Sorry to be uninformed, NPP, but that's all I got. Thank you. R. Peter? Hi. Really nice talk, Dan. Thanks. I had a technical question. I was wondering, like, how many tracks do you typically need, and how long the track should be in order to be able to? The track should be in order to be able to get a proper analysis with your new method? Yeah, so the data I'm showing each day is probably a few thousand tracks, so we really crank the cells through. And we typically, I can't tell you for sure from the data I showed, but we typically get rid of any tracks that aren't at least 100 frames. Least 100 frames. So that's kind of what we're looking at. So about, you know, a few hundred frames and a few thousand tracks for each day. That's what we report, yeah. And are you using 30 frames per second approximately? Yeah, if we try to go to 50, we run into real problems with tracking. 30 is pretty much the limit for us. Okay. Yeah, but by the way, I probably should have referenced you on some of those slides, but I didn't. Slides, but I didn't. So in the longer version of the talk, I have a bit of discussion of you and those people that made Smug and that kind of thing. Right, right, yeah. Okay, thanks. No, I'm very intrigued by this and I'll be looking into it more. Yeah, great. Hope to be in touch about that. Yeah, maybe get a chat later. Thanks. Thanks. Alright, the speaker. Let's thank all the speakers today. There was a lot of great talks today. Today. See you bright early.