To have today Professor Katie Craig with us. She is an assistant professor in UCSB and she received her PhD from Rutgers University. And then she was an NSF postdoc at UCLA and also a UC President's Postdoctoral Fellow at UCSB. And then she stayed in UCSB. And then she stayed in UCSB. And we're very happy to have you here joining us today. And you're going to talk about the blob method for degenerate diffusion applications to sampling into later neural networks. So thank you very much. Well, thank you very much for that introduction, for inviting me to speak. Please let me know if at any point the technology, the glitches occur in the technology. I'm actually on sabbatical at UC Berkeley at the moment, and there has been some internet. And there has been some internet glitches here and there. So I'm happy to, luckily, I can resolve them, but you just have to flag me if they happen. So, and also please, at any point during the talk, please feel free to unmute yourself or type a question in the chat. I think I may rely on Pablo to read anything that appears in the chat that I don't immediately notice. But I'm writing here on the iPads. Um, but I'm writing here on the iPad, so my goal is that if you have a question, I can actually sort of stop and write, and we can discuss. Um, so, uh, like was already said, the subject of my talk today is a blob method for degenerate diffusion and applications to sampling on one hand and kind of these toy models of two-layer neural networks on the other hand. And this is based on two joint works, the first with Jose Antonio Currillo and Francesco Patakini, and then the second with Karthik Alempas-Huti, who's a second with Karthik Alembaz Huthi, who's a postdoc at UCLA, Matt Haberland at Cal Poly, and Olga Turanova at Michigan State. So here's an outline of my plan for today's talk. I plan to begin by talking about some motivation for the problem that I want to consider. And basically my goal is to develop an algorithm that on one hand could work for sampling a given measure, but on the other hand could also But on the other hand, could also be used to control a fleet of robotic vehicles or a robotic swarm. So, a model problem you might have in mind in this case is, suppose we want to use weather balloons to distribute internet signal in a rural area. And you want to do this in a robust way so that, for example, if one of the balloons goes offline, the other balloons can kind of adapt based on local information around them to still move their evolve. To still move their evolve their locations to keep optimizing the internet signal. So, on one hand, sampling, you know, which is basically approximating a measure by an empirical distribution and this type of robot control problem, particularly robot coverage problem, you want the robots to evolve their locations to some sort of coverage distribution, may at first seem a bit different, but I will describe how you can put them in the same sort of mathematical framework. And my specific And my specific goal in approaching these problems and with my collaborators was that we hope to develop a PDE-principled algorithm for solving these objectives. And the PDE that we will propose is a degenerate diffusion equation. In some ways, it has a lot of similarities with the classical Fokker-Planck equation, which is sort of the underlying dynamics driving Langevin dynamics, I'll describe in a minute. I'll describe in a minute. But it also has some key differences from this type of Fokker-Planck equation. So, one of the similarities, though, is that both the equation that I will propose, this degenerate diffusion equation, and also the Fokker-Punk equation have something that's called a Vosserstein gradient flow structure. So, I'll say what I mean by that. What does it mean to be a Vosserstein gradient flow? And then, how does the fact that this PDE has a Vosserstein gradient flow structure help us? Gradient flow structure helps us to accomplish these specific tasks at hand, either to develop a sampling algorithm or to develop a robot coverage algorithm, on the other hand. And the reason why is that PDEs with a Vasserstein gradient flow structure naturally lend themselves to what I'll call particle methods, which is basically approximating the PDE by evolving a spherical measure. The Vasso Stein gradient flow structure allows you to Structure allows you to easily pass between the discrete level of the particles, which are driven by a system of ODEs, and the continuum PDE itself. So, I'll talk about how that works, but a key assumption in making this work is that the velocity field arising in your PDE or kind of in the other hand on your system of ODEs has a global Lipschitz assumption. This is a pretty strong assumption. In fact, it completely fails for the type of PDE. Completely fails for the type of PDE that I want to study, this degenerate diffusion equation. And so the key contribution is that we describe how you can develop an appropriate regularization for your PDE so that it can be approximated by a particle method. In any sort of particle method combined with regularization, I'll call it a blob method. So basically what we develop is a blob method for this degenerate diffusion equation. For this degenerate diffusion equation. And then, you know, this blob method allows us to have a nice spatial discretization of the PDE that we can then use for these sort of sampling or robot coverage tasks. Why it's called a blob method dates back to kind of classical vortex blob methods for the Euler and Navier-Stokes equations. This term was introduced in that context for any sort of regularized particle method. Particle method. And then I'll close. So, by introducing this regularization, we were able to develop a particle method. And our main result is that indeed this regularized particle method converges to a solution of our degenerate diffusion equation. And then I'll close with a few numerical examples illustrating properties of the method. Okay, so like I said, I'll begin with a little bit of motivation for the problem. Okay, so in both these sampling applications or in a row. Sampling application or in a robot coverage task, you consider a desired target distribution rho bar. So I'm going to assume that rho bar is a probability measure. If you come from the sampling community, you may object at this point. This is, for example, saying that I know like the normalizing constant for the measure that I want to sample. But perhaps we can discuss this issue a little bit more at the end. It turns out that if you guess the normalizing constant wrong, it just affects basically the time scale of the algorithm. Basically, the time scale of the algorithm. And since, at least in some cases, we could hope for exponential convergence to equilibrium, adjusting the time scale by a multiplicative factor isn't like a deal breaker. Okay, so suppose I have a target distribution that's normalized to be a probability measure. The key question in sampling is how can we choose samples? In other words, we want to choose n vectors in d-dimensional Euclidean space so that with high probability, they accurately represent this. They accurately represent this desired target distribution. On the other hand, from the perspective of these robot coverage algorithms, the question might be: how can we program robots to move so that they distribute their locations? Again, we're thinking of sort of in robots that are distributed in d-dimensional Euclidean space according to the desired target distribution deterministically. Okay, so clearly the key distinction that I'm making between these two objectives is that These two objectives is that, on one hand, because sampling is something that is done numerically, it's fine if your algorithm only works with high probability and maybe you have to do a few runs to get the best samples. But for a robot coverage algorithm, you know, ideally you don't want to have to drive the balloons around multiple times. This is something that's kind of happening in real time, and we would like a deterministic algorithm. Ideally, the dream, we're not quite there yet, but one with We're not quite there yet, but one with convergence guarantees. But at least, you know, something deterministic is more important in this context. Okay, but aside from this distinction of either something stochastic or deterministic, in both cases, we seek to approximate this desired target distribution by an empirical measure. So that as the number of either samples or robots goes to infinity, this better approximates. Infinity, this better approximates rho bar. So the spirit that motivated this work is that PDEs can inspire new ways to construct this empirical measure. Now, on one hand, this is extremely classical, and I'll describe how you could interpret what I just said in the context of Langevin dynamics. So, from now on, in today's talk, I'm going to suppose that my desired target distribution is log-concave. In other words, log concave. In other words, it can be written as the exponential of negative v, where v is a convex function. And just to emphasize, this parameter here should be greater than or equal to zero. So in fact, many of our results do work for more general rhobar, but maybe I could talk a little bit more at the end about what does and doesn't go through for more general rhobar. Okay, so in this nice Okay, so in this nice case, one of the most classical approaches in sampling is to sample rho according to Fokker-Planck dynamics. And so up here at the top, I have the Fokker-Planck equation. It's an evolution equation for this density rho. So, you know, rho is a function of space and time, and it evolves according to this TDE. So I've written it in kind of a weird way right there, but if you expand out the right-hand side, There, but if you expand out the right-hand side, maybe this looks a little more familiar. So, we have the time derivative of rho is Laplacian of rho minus divergence of rho times the gradient of log rho bar, where rho bar is your desired target distribution. Okay, so solutions of the Fokker-Planck equation play an important role in sampling because they converge to the desired target distribution very quickly. So, we normally think of this as an initial value problem. So, you initialize rho. So you initialize rho in some configuration, and then you flow it along the dynamics of this PDE, and it will approach rho bar. How quickly does it approach rho bar? Well, one way to measure the speed of its convergence is in terms of the KL divergence. And we can say, for example, that if the target distribution is strongly log concave, in other words, if V is lambda convex for lambda strictly positive, then we actually get exponential. Then we actually get exponential decay of the KL divergence. In other words, the difference between the solution of this PDE at time t and the desired target distribution can be bounded above by e to the negative lambda t, KL divergence between the initial data and the desired target distribution. Okay, so this says that solutions of this equation are converging very quickly to the desired target distribution. And this is what makes these dynamic. This is what makes these dynamics a natural choice in sampling. So, if you look at this PDE, it's a nice linear PDE in rho, a linear diffusion equation. And so, we have a well-developed theory of stochastic particle methods for this PDE. And so, you know, here's the corresponding stochastic particle method. And if you, for example, evolve in particles according to this method, you can show that as n goes to infinity, this empirical measure converges. This empirical measure converges to a solution of the PDE. So, if you take n sufficiently large, you get close to these dynamics. And then we already know that if you take t sufficiently large, you get close to your desired target distribution. Okay, so this is the kind of a basic principle underlying the success of Langevin Dynamics: is that as long as you take in big enough and time big enough, you can get close to this target distribution very quickly. This target distribution very quickly. Okay, so this is kind of the classical setup here on the top. So on the bottom here, I'm going to propose a slightly different diffusion equation for accomplishing a similar task. So here's the equation that I want to consider. This is a degenerate diffusion equation. Now, if you look, put this and the Fokker-Planck equation side by side, they actually look pretty similar. Down here, it's basically as if I just deleted the log. It's basically as if I just deleted the logarithm from the top. And so you might think, okay, well, logarithm is bad, it has a singularity of the origin. Maybe if I get rid of it, the PDE will get nicer. Unfortunately, the opposite is true, which can especially be seen. So if I expand out the right-hand side, it gets a little messy. So I'm just going to expand out the right-hand side in the case that rho bar equals one. And in that case, the right-hand side looks like this: one-half Laplacian of rho squared. Rho squared. So because it's Laplacian of rho squared instead of Laplacian of rho, that's why we call this a degenerate diffusion equation. And it turns out that solutions of this equation are not nearly as nice as solutions of the Fokker-Planck equation. In particular, they have much worse regularity properties. You kind of, in general, expect a singularity in the first derivative at the boundary if the initial data is compactly supported. Okay, so at first, this PD seems kind of. At first, this PD seems kind of like a bad PD, but it does still have one nice feature in common with the Fokker-Planck equation, which is that again, if rho bar is strongly log concave, it turns out that the solutions of this PDE also dissipate the Kohlbuck-Leibler divergence exponentially quickly. So somehow solutions of this PDE are also converging to the desired target distribution just as fast as solutions of the Bokker-Planck. So this So, this motivated the question of: Is it possible to develop, just like we have, you know, Langevin dynamics for approximating solutions of the Fokker-Planck equation, could we develop a particle method for approximating solutions of this degenerate diffusion equation? Now, at this point, it would be very natural to object because you might say, Katie, come on, we already have this really nice linear PDE where we have this beautiful theory of stochastic particle approximations. Everything is really Approximations, everything is really well developed and works nicely. Why on earth do you now want to study this different PDE, this degenerate diffusion PDE, where we can't do this the same approach because clearly this PDE is non-linear. And so let me give you a few reasons for why you might be interested in this degenerate diffusion equation. Okay, so the first motivation for studying these dynamics that I'll propose, especially kind of given I'll propose, especially kind of given the audience, is that I claim that these dynamics are interesting from a sampling perspective. And that's sort of for two reasons. First of all, there was recent work by Chui et al., which identified that you can think of stein variational descent, sine variational gradient descent as a type of kernelized version of these dynamics where you kind of insert a kernel here. So, you know, okay. Um, so you know, okay, clearly that's a little different. I don't have a kernel there. Um, but in this paper, they make the argument that better understanding these dynamics and particle approximations of them have the potential to kind of shed light more on the success of stein variational gradient descent. Okay, so if you're interested in that, maybe you could think of this as a toy model for that and a better understanding this model can shed light on the general case. Um, another motivation coming from Another motivation coming from sampling is that it turns out that these dynamics have a close relationship to the chi-squared divergence. I'll talk about this in more detail in a few slides. But the Fokker-Planck equation turns out to not just dissipate the KL divergence exponentially quickly, it's actually dissipating the KL divergence as quickly as possible with respect to the Vosserstein structure. In particular, solutions of this PDE are gradient flow of the KL divergence. Gradient flow of the Kl divergence in the Vacher in the Vosserstein structure. On the other hand, solutions of this degenerate diffusion equation are dissipating the chi-square divergence as quickly as possible with respect to the Vosserstein structure. So I would argue that if you had a kind of sampling motivation where it was more important to you to be approaching your desired target distribution in this kind of chi-squared sense as rapidly as possible instead of the KL, then these are the dynamics you should be wanting to follow. You should be wanting to follow. And if you want to follow these dynamics and actually, you know, make this a method you can implement in practice, you kind of need some sort of spatial discretization of it, like a particle method. Okay, so those are the motivations from sampling. On the other hand, maybe like me, you come from a background in kind of nonlinear PDE and numerical analysis. In that case, you might recognize this PDE as something that shows up in models of fluid flow in a porous media, also by. Flow in a porous media, also biological swarming. And so, if we could develop a particle method for this, that would help more generally in numerical simulation of PDEs of this type, you know, whether it's in kind of biology or fluids or anything like that. A third reason that you might be interested in this PD comes from, you know, this motivation that I described at the beginning in terms of robot coverage algorithms. So, maybe somewhat surprisingly, the particle method that we come up with for this degenerate diffusion equation is a deterministic particle method. And so, you know, that has benefits in terms of these types of control theory applications where you don't want to have to average over many runs and you might even hope for convergence guarantees on the first run. And then the final motivation I'll give for studying these dynamics is that it turns out that the part Is that it turns out that the particle method that's sort of naturally associated with this PDE, when you kind of introduce an appropriate regularization, like I'll describe, turns out to have the exact same dynamics as training a neural network with a single hidden layer with a radial basis function activation function. So we kind of realized this once we wrote the particle method down. And so in this way, our convergence result for the particle method to this PDE sheds light on how these Sheds light on how these dynamics of training a neural network with a single hidden layer behave in the over-parametrized limit when the number of neurons goes to infinity as the variance of the radial basis function goes to zero. And in particular, one of the things that we're able to identify through our convergence result is under what hypotheses on the data distribution and the target function does convexity emerge in a limit? And so this, you know, she. And so, this sheds some light on these long-time behavior properties of these toy models of training neural networks. Okay, so I hope now that you no longer think it's quite so crazy to be studying this degenerate diffusion equation instead of this nice linear diffusion equation. Okay, so like I said at the beginning, a key property of this equation that we masked it. Please mask it. May I ask that question? So as you mentioned, the degenerate diffusion is actually the gradient flow of the chi squared divergence. I was wondering for your convergence estimation. So in terms of K L, do you have like exponential decay in terms of the chi-square divergence? So I would say, let's see. Let's see. I think there's hope that one could do that, but we don't have that. We don't have that yet. Yes, but I'd say as long as there's, you know, you're happy to put some sufficiently strong assumptions on the data distribution, I would say yes. Possibly even more interesting, or something along these lines of this question that I'm interested in, and this is, we're sort of following up on this now. Following up on this now, is I'm really interested in getting away from this log concavity assumption. And something else that I like about these dynamics is these have been, you know, this degenerate diffusion equation, while it may look somewhat exotic, depending on, you know, maybe from a sampling perspective, has actually been, you know, studied a fair amount in the kind of PDE community. And there have, you know, been developed kind of sufficient conditions on rho bar. Conditions on rho bar for which you can get polynomial convergence to equilibrium, and those are weaker conditions than log concavity. And so, I think an interesting direction that we are currently pursuing is understanding kind of both what happens when rho bar is really nice. Do you get this exponential k, for example, in the chi-square divergence, but also for can you say? For, can you say, can you still get something like polynomial decay for a more general class of rhobar since, you know, in practice, you know, we can confront many types of rhobar? Yeah, yeah, sure. But in terms of if V is not convex, then the problem becomes very challenging. Like people using the simulator dealing algorithm to solve global optimizer. So people know it won't be a polynomial time to converge. Well, and indeed, strongly complex, yes. How many come back? Yes, well, and it's not going to be so. Uh, the analogy would be for how for the Fokker-Planck dynamics, we know we can still get exponential convergence to equilibrium if rho bar satisfies kind of a Poincaré inequality. Sorry, a log Sobolev inequality, we get exponential convergence in KL. And so, similarly, and so that is something that is weaker than being strongly log concave. And that is the analogy. And that is the analogous thing that I would be saying down here. It would be the analog of a log-Sobolev inequality in this case. So, a slight weakening of this kind of log and cavity assumption. Though, indeed, as you say, sort of for general V, you will be able to come up with examples. Yeah. Yeah. Thanks. Thank you. Okay. So, yeah, please, again, thank you very much for the discussion. Much for the discussion, and I very hopeful, please jump in more. Okay, so let me tell you a little bit more about the Wasserstein gradient flow structure for this equation, which underlies how we're able to approximate it using a particle method. Okay, so, you know, Vasserstein gradient flows are something that have become more popular in recent years, but it's still somewhat of a niche field. So let me say a little bit about what I mean by a Vasserstein gradient. About what I mean by a Wasserstein gradient flow. So, I think everyone in this audience is extremely familiar with gradient flow. You know, okay, basically, you have some sort of energy and you want to do gradient descent on the energy. So that was my energy, E of X. And let's say maybe X lives in the plane. Then, if I do, oh, this is a really beautiful plane that I just drew. Then, and there it went away, whatever. So, if So, if doing gradient descent is just sort of evolving in the direction of steepest descent of the energy. And the key thing to, I guess, a perspective that I find useful for thinking about gradient descent with respect to other notions of distance. So in this case, I'm talking about with a respect to this Foster sign distance of optimal transport. Is what you're doing when you do gradient descent is you're moving perpendicular to the level set. Perpendicular to the level sets of the energy. And so that's where you see the role of the metric: is the role of the metric tells you what does it mean to be moving perpendicular to these level sets? And so in that sense, you know, there's many different choices of metric that you could choose here. PDE, there's a long history of looking at gradient flows with respect to Hilbert space norms, for example, L2, H1, H minus 1. But more recently, One. But more recently, especially over the past 20 years, there's been a lot of interest in kind of gradient flow structures that just arise from some metric space. So this is the kind of framework that I'll be talking about today. And it turns out that all of the equations I've mentioned so far, like both the Fokker-Planck equation and this degenerate diffusion equation, have this Vosserstein gradient flow structure. So in the case of the Fokker-Planck equation, like I already In the case of the Fokker-Planck equation, like I already said, it dissipates the Kolbach-Leibler divergence exponentially, or excuse me, I'm saying the wrong thing. It is the Wasserstein gradient flow of the Kolbach-Leibler divergence. And similarly, this degenerate diffusion equation is the Wasserstein gradient flow of the chi-squared divergence. So I'm going to do a small manipulation to the chi-squared divergence to make it a little simpler to write on some of my future slides. On some of my future slides, I'm going to take this chi-squared divergence and I'm going to expand the square. And again, because I'm making this assumption that my rho and my row bar, everything here is a probability measure, I end up being able to express my chi-squared divergence as something of this form plus a constant. Because I'm going to be doing gradient descent on this energy, that constant goes away. It doesn't matter. Okay, so I'll often say that this PDE is the gradient flow of this energy. Gradient flow of this energy. And I think the reason I like to write this energy is it's reminiscent of these Regni entropies from statistical physics, which have been kind of well studied in the context of fossil-style gradient flows. Okay, so great. So, okay, both of these energies are, or both of these PDEs are dissipating these energies as quickly as possible with respect to the Vassarstein structure. I will mention one more, or actually two more, PDEs that have a... PDEs that have a Vosso-Sein gradient flow structure that are going to turn out to be relevant in my talk today. The first is called an aggregation equation with drift. And this is the Wasserstein gradient flow of this energy, which is interaction energy with an external potential. This arises a lot in models of biological swarming and in gas dynamics. And then the last example. And the last example of a type of PDE that arises that has a Wasserstein gradient flow structure are these kind of toy models of two-layer neural networks. And so this kind of connection to Wasserstein gradient flows was identified somewhat recently in several concurrent works. I'm just going to talk about it in a certain special case. And that is the case where the energy you're considering is You're considering the quadratic loss. I have my data distribution nu here. I have my activation function here. And there's a variety of choices of activation function phi. It could be maybe the reloactivation function or radial basis function activation function. I have my rho. Rho is the measure that tells me how I'm weighting each of these parameters x in this parametrization. And my goal is I wanted. And my goal is, I want to choose my row so that this parametrization approximates my target function, f naught, as accurately as possible, kind of with respect to this notion of loss. You know, when you take the square and then integrate it over the data distribution, new. Okay, so it turns out that if you are interested in the dynamics that people use to kind of train these types of two-layer neural networks in the mean field scaling convention, it's exactly the same. Field scaling convention, it's exactly the Vasserstein gradient flow of this energy. I didn't write down the PDE here because the PDE gets a little long, so I just wrote the energy. But you can kind of guess what the PDE is. And so why did I write down this energy? It turns out that this energy is going to arise again when I tell you the particle method that connects to this degenerate diffusion equation. And so in order to see that connection, okay, I kind of did some expansion, but in order to try to be brief. But in order to try to be brief, I'm just going to point out two key things. So, if you sort of expand this and rearrange things, and you're in the special case of a radial basis function activation function, then it turns out that this first term in the energy, after I've kind of expanded the square, I can rewrite in this way as the integral of my radial basis function activation function convolved with my parameter measure rho squared d nu, where nu is my data distribution. And then the kind of the And then the kind of the cross term when I expand the square basically just looks like an external potential v of x integrated against rho. This is really easy to deal with. Yeah, whenever you have something that looks more like an interaction potential and then something that looks more like an external potential, this is always where the trouble lies. And then that is typically more routine. And then, okay, a constant, which we don't have to worry about when we take the Vossostein gradient. Okay, so the reason I mentioned this is just to keep it in the back of your mind because. Just to keep it in the back of your mind because this energy is going to appear again in a few slides. Okay, so now that I've explained a little bit more about what I mean that this degenerate diffusion equation has a Wasserstein gradient flow structure, let me tell you why that structure helps us develop a deterministic particle method to approximate its solutions. Okay, so the key reason why, or maybe The key reason why, or maybe the first reason why, is that all Wasserstein gradient flows are solutions of continuity equations. In particular, if you look at all of these PDEs, the three PDEs that I mentioned on the previous slide, you can see that these are all examples of continuity equations for a certain choice of velocity field V. And so I know this notation is a little weird, so just to kind of emphasize, like in this case, my velocity for this one, for the aggregation. Velocity for this one for the aggregation and drift, my velocity field would be negative k convolved with rho minus grad v. Okay, so this is why I emphasize the dependence on rho, because we see that the velocity field, the dynamics really does, especially in this case, it depends kind of non-locally on the dynamics, on the value of the density rho. So each of these equations, you know, if you, for an appropriate choice of velocity field, can be written in this way. Velocity field can be written in this way. And so, once you can write a PDE as a continuity equation, a particle method becomes a very natural way to discretize it in space. So what is the general recipe for a particle method? So let's consider the case where we have a really nice velocity field. So let's suppose that we have a continuity equation with a uniformly Lipschitz continuous velocity. And what I mean by that is not only is this globally Lipschitz, it's a Lipschitz constant. Its Lipschitz constant is bounded uniformly in row. So we can use the same Lipschitz constant for all choices of rho. This is too strong of an assumption, and we will talk about how to remove it in a moment. But under this assumption, so we consider a solution of a continuity equation. We're thinking of this as an initial value problem. So we have a density at time zero, and then it's evolving according to this PDE. And our goal is to develop a particle method to approximate the solution of this equation. Approximate the solution of this equation as it evolves in time. Okay, so the first step is that we did in this kind of general recipe for particle methods is that you take the initial data and you approximate this initial data by an empirical measure, by a set of direct masses. Incidentally, everything that I'm going to say today works just fine if you don't want the Dirac masses to be equally weighted. For example, if you would rather get rid of that and multiply them by some constants, MI, that's sum to one. Okay, but for simplicity, Sum to one, okay. But for simplicity, I just always write it as they're equally weighted. Okay, so you approximate your uniform measure by a sum of direct masses, and then what you do is you take the locations of these direct masses. So you imagine these are the particles that you're using to approximate the dynamics of this PDE, and you evolve the locations of these particles according to this ordinary differential equation. So again, my notation here is a little weird. This probably doesn't look Is a little weird. This probably doesn't look like an ordinary differential equation, but it is. It's a system of ordinary differential equations for each of the particles x1 through xn. Though, and here you see that the velocity now, rather than evaluating at the density rho, which I kind of no longer have access to, I'm evaluating it at the evolving empirical measure, sort of the next best thing. And so, in general, this velocity field, you know, it depends on the locations of all of the particles. So, the motion of the ith particle. Of the particles, so the motion of the ith particle will, you know, could very well depend on the motions of all the other particles. So, this is could be a coupled system of ODEs. Um, and so what's really nice about particle methods for approximating PDEs of this type is that letting the particles evolve according to this system of ODEs is exactly equivalent to saying that my empirical measure is a weak solution of the same continuity equation that I had above. So, in other words, this particle method perspective. So, in other words, this particle method perspective kind of allows us to sort of seamlessly pass between the world of ODEs and the world of PDEs and work sort of on whichever side is easier at the moment. Okay, so we approximated our initial data with these particles. We let these particles move around according to the system of ODEs. Does this actually, in any reasonable way, approximate a solution of our original continuity equation? And the answer is yes. So the So, because I impose this really strong uniform Lipschitz assumption on the velocity field, you can see that the Vosserstein distance between my evolving empirical measure and the exact solution of my PDE can be bounded above by E exponential of the Lipschitz constant times time times the Walser sign distance between my approximation and the exact initial data. And so, this at least tells me that as long as And so this at least tells me that as long as I'm on bounded time intervals, as I improve this approximation, rho naught of n converges to rho naught, my empirical measure at time t will converge to my exact solution at time t. Okay, so this is sort of the general recipe of whenever you come up with a continuity equation, how you could approximate its solution by a particle method. But of course, as you know, we're very worried. And we're very worried about what happens when the velocity field is not uniformly Lipschitz, doesn't satisfy this very strong hypothesis. And in fact, for both of the kind of key PDEs at the heart of this work, the velocity field does not satisfy any sort of uniform Lipschitz bound for general solutions rho. On the other hand, this other PDE that I mentioned that arises in kind of models of biological swarming and Models of biological swarming and gas dynamics, this velocity field will satisfy such a condition as long as the Hessian of this interaction potential and this external potential are bounded. So kind of as long as these are nice enough. So a question is, how can we somehow approximate these dynamics in a way that makes it a little bit more like these, where we can hope to have these types of Lipschitz bounds? Schittz bounds. And so we could make sense of a particle method. And the way we're going to do that is by introducing an appropriate notion of regularization. And so here's where we get to a regularized particle method, which is known as a Blob method. So at the top, I have the PDE we're interested in, which is the Oserstein gradient flow of the chi-squared divergence. And here is the regularization we consider. First, we regularize it at the energy. We first regularize it at the energy level. So we take this energy, which is kind of the sort of expanded out chi-squared derivence. And what I'm going to do is, you know, I really want to evaluate this energy along particles, you know, when rho is a sum of drag masses. But, you know, okay, that clearly doesn't make sense. You can't take rho to be an empirical measure and then square it. But, you know, there's no notion of that. So I want to regularize this energy so it behaves better along these empirical. Behaves better along these empirical measures. And so, how we're going to do that is by convolving rho with a mollifier, phi epsilon. So, you can think of this as kind of like a kernel density estimate of an empirical measure. And suddenly, this is something that makes perfect sense to take the square of. It's also reminiscent of those aggregation drift energies that I mentioned on the previous slide. Okay, so if we make this approximation, and we're thinking of And you know, we're thinking of phi epsilon as, for example, a Gaussian with standard deviation epsilon. And in that case, as epsilon goes to zero, as long as rho was smooth, we would have some hope that, or okay, it doesn't even have to be, as long as rho is something reasonable, we would know that phi epsilon convolved with rho, converged with rho, converged to rho in an appropriate sense as epsilon goes to zero. So, you know, for example, if rho evolves to belong to equal to equal to 0 example if rho falls to belongs to any lp space phi epsilon can volunteer with rho we converge to rho and lp um okay so in that sense there's hope that as long as rho were sufficiently well behaved as epsilon goes to zero this energy would converge back to that energy so the question is is can we look at the vosserstein gradient flow dynamics of this modified energy and can we show that those dynamics in also as epsilon And also, as epsilon goes to zero, converge to the dynamics of the original PDE we were interested in. So, if you want to write down the Wasserstein gradient flow of this energy, here's the PDE you get. Okay, it's a little bit of a weird PDE. We've got this sort of double convolution and that sort of thing. So it looks a little crazy. But the good news is that this PDE does satisfy the key hypothesis we needed for a particle method to be well defined. In particular, the velocity here. In particular, the velocity here will be globally Lipschitz on bounded sets, though, of course, that Lipschitz constant deteriorates with epsilon, which is what we would expect. As we remove this regularization, the Lipschitz constant goes away since, after all, it's not there in the limiting equation. Okay, but at least for positive epsilon, we have that this velocity field is globally Lipschitz. So now we can go back to that general recipe I gave. Back to that general recipe I gave you for particle methods and just turn the crank. We have a well-posed particle method, and we know that for any fixed epsilon greater than zero, as n goes to infinity, this will converge to a solution of this PDE. Okay, so that's fine. So we know we have a particle method for approximating solutions of this PDE for fixed epsilon greater than zero, but that's not what we wanted. What we really wanted was a particle method for approximating solutions of this PDE. Solutions of this PDE. So, the key question is to ask: what happens as n goes to infinity and epsilon goes to zero? At this point, I'll just make a brief connection back to those two models of two-layer neural networks. It turns out that this energy here is exactly that first term in the energy that appeared in those two-layer neural networks with the radial basis function activation function. The key distinction is that now my target. Now, my target measure, rho bar, plays the role of the reciprocal or is the reciprocal of the data distribution, nu. And then, of course, in those mean field models of neural networks, we also had an external potential term. But everything that I'm saying today works just fine if you want to add in an external energy. I'm just leaving it off for simplicity of notation, but all these convergence results work just fine if you want to add something like. Results work just fine if you want to add something like that in. Okay, so in this way, by our study of this limit as n goes to infinity and epsilon goes to zero, exactly sheds light on the over-parametrized regime in these toy models of two-layer neural networks as the variance of the radial basis function goes to zero. Okay, there had been several previous works actually on this exact sort of regularization and particle method. Of regularization and particle method. That probably seems a little bizarre since it's such an odd-looking regularization and particle method, but in fact, we were not the first to consider it. Though I will say that all of the previous work considered the case where the target measure, rho, was identically equal to one, the uniform measure. So, you know, for lack of time, I think I will not go to too much detail on these many previous works by Olschlager, Leon McGalik, myself with Carrillo and Padakini. With Carrillo and Patakini, and also Jovan Mardmodelli and Montginari, especially focusing on the application for neural networks. But I will just say that much had been done in the case of a uniform target, and kind of the key contribution of our work is the extension from the uniform case to the log-concave case. And what we are able to show is that for a log-concave target distribution, as long as the target is not confused As long as your approximation of the initial data, so as long as you're kind of laying down these empirical measures to approximate the initial condition of your continuum PDE, you have to approximate that very quickly with respect to your regularization parameter epsilon. Particular has to be little o of e to the negative one over epsilon to the power d plus two. So in other words, this is saying that the In other words, this is saying that the number of particles in your approximation has to grow very quickly with respect to epsilon. I expect that this is not optimal. This is definitely just a technical result, or this is just because of technical limitations of our proof. And I anticipate that I can talk a little bit more about the optimal scaling between n and epsilon that we observe in our simulations. Observe in our simulations, though I believe that a kind of a different proof technique would be needed to reflect that at the level of the assumptions of the theorem. But okay, with these things in hand, so as long as n is growing sufficiently rapidly with respect to epsilon and your target is log concave, then we succeed in showing that solutions of this deterministic blob method converge to a solution of the PDE on bounded time intervals. On bounded time intervals. In terms of the connections to two-layered neural networks, this is saying that those dynamics and the over-parametrized regime when the variance of the radial basis function goes to zero converge to solutions of this degenerate diffusion equation. And then by inspecting the degenerate diffusion equation, we can identify when are those dynamics convex with respect to the Bosserstein structure. And in particular, our result shows that they're convex. Our result shows that they're convex as long as the data distribution is log-convex and the product between the data distribution and the target measure F naught is concave. Okay, so this generalizes the previous work, which only was only considered the case of uniform data distributions. Okay, so I'll close with a few brief numerical simulations illustrating some properties of the method. So here So, here, what we have is we have three different target distributions. So, these are my row bars. In this case, row bar is just a uniform target. Here, it's a log-concave target, as fits within the scope of our theoretical result. And then here, we have something that's sort of obviously not log-concave, sort of piecewise constant target. In these three cases, what I'm illustrating at the top is assume that we initialize We initialize our dynamics with a uniform distribution. Rho naught is a uniform distribution on the interval negative 0.5 to 0.5. So we're considering the same initial condition in all three of these cases. And then these top plots show how the dynamics evolve over time, time zero, you know, all the way up to time one. And what we see is indeed the dynamics are kind of a Indeed, the dynamics are kind of approaching a solution of the desired target distribution. So that's good. In this case, this was done for 100 particles. At the bottom, what I'm illustrating here is these are actually the trajectories the particles follow. So I only plotted, we only plotted about 20 of them here. But it kind of gives you a little bit of the idea. So, you know, we're Of the idea. So, you know, we're basically sampling this uniform distribution with 100 particles, 20 of them plotted here. And then this shows kind of the trajectories they go. It looks like they collide here. They actually don't. They just get very close to each other, which is good, because if they collided, then our particle method would not be well posed. But sort of the length scale of the collision depends on this regularization parameter, epsilon, and how it relates to the number of particles. Relates to the number of particles. So, or the link scale at which they appear to collide, the length scale at which they get close, they don't collide. And in all of our numerical simulations, we see very good behavior in one dimension. If we take epsilon to be one over, you know, basically a little bit bigger than one over n, one over the number of particles. In higher dimensions, basically, epsilon just has to be a little bit wider than the average interparticle spacing at time zero is what we observe. At time zero is what we observe well, performs well. A nice thing about our numerical scheme is that, if you remember, one of the reasons we were even interested in this degenerate diffusion equation is that it does, it dissipates the KL divergence exponentially quickly in time. And we observe that even at the discrete level of our regularized particle approximation, we're still seeing that exponential decay of the KL divergence in time. Though, of course, for smaller and smaller particles, Of course, for smaller and smaller particles, the discretization error saturates earlier and earlier. But as you kind of make the particles, the number of particles larger and larger, you're able to prolong that exponential decay for longer. We can look at the rate of convergence in terms of how many particles it requires in order to approximate our desired target distribution. What is the error between those two things? And we see that this error scales about linearly in the Scales about linearly in the number of particles. Okay, I'll close just by briefly sketching some of the questions for future work. One, as I've said, is to understand better a case of more general rho bar. On one hand, we think that our result on our convergence of the particle method to solutions of the PDE really should hold for general rho bar. And we have some ideas on how to do it. It's a little technical because you lose some of the nice stability properties. You lose some of the nice stability properties of the PDE, the fewer assumptions you require in rho bar. But I'd say for general C2 rhobar, there's a lot of hope for proving convergence of the particle method to the PDE. On the other hand, as is already discussed, for general rhobar, there's less hope that solutions of the PDE are actually converging to the rhobar you want. I'm sure we could construct kind of adversarial rhobars where for certain initial conditions, And where for certain initial conditions, there's no hope that the PDE would converge to them. So then that relates to kind of trying to understand through appropriate analogs of logs-Phobilev inequalities for these dynamics, what are weaker criteria that the rho bar could satisfy, weaker than strong cavity, that would still ensure that solutions of the PDE converge either exponentially or maybe even just polynomially quickly to rho bar. Some sort of quantitative rate to rho bar is what we would hope for. For. Another thing is, so, you know, basically, you might ask from a control theory background: what exact information do each of the robots need to have on their kind of surrounding information in order to follow this control law? And so the kind of the exact information is sort of, you can see here, this appears in the velocity field driving the robots. And so basically, you need to be able to, if you think of, okay, in all of our simulations and in our theoretical. Of our simulations, and in our theoretical result, we take phi epsilon to be a Gaussian. But if you considered phi epsilon to be something compactly supported, then the key thing is that a particle at location x needs to be able to observe the target distribution, or in this case, actually it's reciprocal, in kind of a neighborhood around x. And it needs to be able to kind of compute integrals against it. So this is a little bit different from Langevin dynamics, where the particles need to be able to compute. Where the particles need to be able to compute gradients of the logarithm of the target distribution. So, in this case, but you know, in some ways, it's kind of a complementary information in this case is needed on the desired target distribution. While we do have a convergence proof, our proof is done using gamma convergence techniques. We have nothing about the rate of convergence. It would be really interesting, especially with an eye towards utility and applications, to get quantitative rates of convergence. Applications to get quantitative rates of convergence depending on n and epsilon. I think, as I already mentioned, one interesting direction for considering different modifiers, phi is considering compactly supported mollifiers. Another interesting direction is looking at how better choice of these mollifiers, these radial basis functions, can lead to faster rates of convergence, perhaps even fighting against the curse of dimensionality. I can say a little more about that later if people are interested. And then finally, because our And then finally, because our method is truly an interacting particle system approach, it naturally has order and squared computational complexity if you have n particles. Okay, this is bad maybe compared to Lashman dynamics, just order n. On the other hand, it's deterministic. But at the same time, there's maybe some hope that using recent work on related kind of non-local interaction equations, strongly inspired by stochastic gradient descent in Inspired by stochastic gradient descent in kind of the optimization literature, that by entry, if you were in a scenario where you could cope with some stochasticity, for example, in a sampling context as opposed to the robot control context, there's perhaps some hope that by kind of computing the velocity field in batches, you could lower the complexity while still preserving the long-time behavior, while still preserving that it converges to the right target distribution. Okay, thank you very much. Well, thank you very much. That was a wonderful presentation. Thank you. It's covered so much ground and so many interesting ideas. And yeah, it's a lot of material, but it's very fascinating. So I would ask you to join me in thanking Professor Craig, but also if you have any questions for experts in the area, I think Rony might already have a question. So maybe. Yeah, go ahead. So, maybe, yeah, go ahead, Roni. Yeah, yeah, okay. This is a nice, very nice talk. Uh, can I ask you a small question in terms of numerical space? In your one example, you did show that for this non-convex or non-lot concave, this non-convex function still works reasonably okay. Do you have any comments about that? Yes, I mean, I think, like I said, we could clearly come, you know, an important part. You know, an important part here is that the particles have to be able to sense the target density that they're converging to. You know, you can kind of even see this in the control law. Somehow, if the target density didn't give any, you know, was sort of kind of constant in a large region or kind of not giving any information to the particles, we could construct examples where this didn't work. But I guess what I, on the flip side, I, I, what we observe numerically is that when the particles Is that when the particles are sort of well initialized so that they are able to kind of observe, you know, all of the kind of key structural features of the target density, that they kind of, you know, we do indeed see convergence to the right thing. So, yeah, I think that's where I guess I feel like there is some hope that, yeah, that maybe for some rho bar that are a little bit farther than the line. Rho bar that are a little bit farther than the log concave, we may still be able to prove that the dynamics converge to the right thing. I see, I see. So, could you show 1D case? How about this performance in a slightly higher dimension? I know it's curves of dimensionality issue. How about 2D, 3D? Yeah, so I didn't include any simulations for, I don't think I have any simulations from 2D in these slides. But so, like I said, the basically the subject of my talk today is kind of split between two different papers. The first paper, Two different papers. The first paper, we only considered the case of a uniform target distribution, but we did do simulations in two dimensions, and we observed very basically the exact same properties in two dimensions, you know, just sort of taking to account the scaling of dimension everywhere, but you know, similar rates of convergence and that sort of thing. So maybe just because I find this topic, the relationship with the curse of dimensionality so interesting, I will take your question as an excuse to elaborate a little bit. Question: Is an excuse to elaborate a little bit more on this, which is okay? So, like I said, our method is strongly inspired by classical vortex blob methods for the Euler and Navier-Stokes equations. And there was something really interesting about the type. So, in that case, they have already succeeded. The theory is mature and they have quantitative rates of convergence of this blob method to solutions of the PDE. And something that's very beautiful about the quantitative rates that they are able to prove is that the rate Able to prove is that the rates are of this form. So n is the number of particles, d is the dimension, and this parameter m here, which I haven't told you about, m has to do with the choice of the radial basis function. In particular, the radial basis function, when convolved with a polynomial of degree m, has to preserve it. And so you can kind of cook up convolution kernels in this way. There's sort of an algorithm. Like first, you cook up one that Like first, you cook up one that preserves polynomials of degree one, so like any symmetric one. And then you can go up and up to higher and higher degrees. But what's interesting about this is that by picking smarter and smarter convolution kernels, you're able to fight against that curse of dimensionality. So, as I said, we have nothing quantitative in our case, but I think this question. But I think this question of understanding the relationship between the choice of convolution kernel and the type of rates and their dependence on the dimension is an interesting question. Thanks. Very interesting. So I'm usually like a smoothness, but here is you sort of characterized by the convolution kernel behavior, which may also relate to the smoothness of the well. So for the convolution, honestly, the convolution kernels that I have in my Honestly, the convolution kernels that I have in mind are all smooth, like these ones that, you know, that preserve a polynomial of degree M, you know, they're all going to, all of the ones that I have in mind are always C infinity. But here's how you can maybe, here's a simplistic way to think of this connection is that for proving these quantitative results in the fluids case, they're really just tailor expanding. And so that's why being able to preserve That's why being able to preserve polynomials through convolution would lead to better error estimates because it kind of preserves the Taylor expansion to higher orders. Thanks. Thanks. Very interesting. Does anyone else have a question that they would like to ask our speaker at the moment? No? So I have maybe a couple of naive I have maybe a couple of naive questions. Say, what would happen if you were to work on the round two sphere? And then in that case, the Wasserstein space also has some nice structure, like it has an Alexandrov space structure, and then you can still work. I mean, to what extent is like assuming that you're on Rn as opposed to some manifold with some curvature change some of your results? So that's why I'm asking just about like, say, S2 with a round metric. like say s2 with a round metric yeah so this is something that um uh has been studied though i i would have to think i would i would have to think a little bit to send you the exact right references um but uh definite certainly um so like i said so uh maybe for if if you'll grant me one simplicity let's just say that our for a moment that our our target distribution is uniform um and so uh we'll just change the underlying Uh, we'll just change the underlying space for a second. Um, and so, in that case, the dynamics that we're trying to approximate are the gradient flow of this energy. Um, and so this energy actually is one of a wide range. I guess I should have put a one-half here. Um, so the types of things that people look at would be this when m is greater than one, and then just the usual. Greater than one, and then just the usual entropy when m is equal to one. And it's been a there's been a lot of work done looking at how the convexity properties of these energies depend on the curvature of the manifold, the underlying manifold on which the Bosserstein metric is defined. And so I would say kind of because for us, it's convexity properties of the energy that are allowed. Of the energy that are allowing our dynamics to converge quickly to equilibrium, the curvature of the underlying manifold would play an important role in that sense. And so I guess that's easy for me to see in the case when rho bar is identically one. And then I would have to think a little bit more for more general rho bars. So like on one hand, like there's a potential it could help you. You know, like I think if the curvature was going in the right direction, it could give you better convexity properties. And so the dynamics would converge faster. And so the dynamics would converge faster. But I think there's just an interplay between the choice of target density and the curvature of the underlying space and how that affects the long-time behavior. So that's talking a little bit about the long-time behavior of the degenerate diffusion equation. In terms of our blob method approximation of it, there's only recently actually been some work looking at these types of interacting particles. Types of interacting particles from the Wasserstein perspective on more general manifolds. And unfortunately, let's see, I'm blanking on the quantization of measures on Riemannian manifolds. Well, I think for them, they're really just looking at the behavior of the dynamics and the so for. And the so for basically looking at these types of let me go back this type of equation. This type of equation was when poses of Wasserstein gradient flow in a non-flat manifold. I'd say, yeah, results in that, I'm really kidding myself that I'm blanking onto this name, but results of that on that sort have only are only kind of just coming out. Yeah. Yeah, I think um Villani and Figali and Isabella, Jacob Litro. And Jacobeli, probably, or some. I think they've worked on like some of the positive curvature cases, but maybe you're thinking about something else or some other work. Yeah, and I'd see. I would say the there's definitely, I guess, the work that I think of, you know, by sort of Ville. Sort of Villany and Savare, I either think of the work kind of done for the general Wasserstein gradient flow structure, of which a lot has been done. Like given a general energy, what is its Wasserstein gradient flow? What are the sort of stability properties you can say under various convexity assumptions on the energy? Or for the type of renewed divergences that I was writing, things like this with powers M or entropy or external potential. I would say less has been done in the general metric. Been done in the general metric context for energies like that, like leveraging specific structures of this energy. Like in particular, we're often interested in like, you know, like, okay, maybe if K is convex, then it would be more of a consequence of the general theory that you were explaining. In our case, I'm thinking of K as being a Gaussian, so something that's not necessarily convex. And so, yeah, that has been Yeah, that has been emerging more recently.