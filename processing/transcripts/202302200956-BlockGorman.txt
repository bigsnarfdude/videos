So our second talk this morning is by Alexis Clark Roman who will talk on TikToking nine for Bukhi Automatic Sets of Real. First, thank you, thank you to the organizers for organizing this wonderful conference and for the opportunity to speak. Both the ones here and the ones who are in that. Right, so I guess I'm going to start by recalling, you know, sort of automata for those who haven't seen models of computation in a while. Yeah, so I'll start with the formal. Yeah, so I'll start with the formal definition, since I'm among logicians. And so an automaton is technically a very special 5 tuple, right? Q sigma delta Q0F, and that's exactly how we think about it. Well, no, not exactly. Not exactly how we think about it. So, oh, wrong way. I have a picture of, you know, how do I interpret the picture that I have below the technical definition? So, Q is the set of states. Q is the set of states, right? You can see in my diagram, I sort of have circles for my states. Sigma is a finite alphabet. We often use 0 and 1 because that's sort of like the language, the alphabet that computer science learns. So delta is my transition function. And in my diagram here, delta is indicated by arrows, right, labeled arrows. So delta goes, takes in a state and a character. A state and a character, and we think of the second input in delta as the character that you're reading at the time when you're running the autonom. And it outputs a subset of the set of states. So when our machines are deterministic, we actually just allow delta to give us one state, but we're going to work in the non-deterministic. But we're going to work in the non-deterministic setting. So we'll allow Delta to give us multiple options, basically, right? For any given input, you know, state qi and character sigma i. Delta will give us some options and we're allowed to sort of follow any one of those options during our run on the automaton. Sorry, Broadway. Right, and then Q0 is just the initial state in my diagrams. It'll be labeled with an arrow, it'll be indicated by. An arrow, it will be indicated by an arrow labeled start. And then F is the set of accept states. So in my diagrams, it'll be denoted with a bold circle. So like here, one is the only accept state. But in the literature, it's often double circles. Okay, so that's the crash definition. Can one automaton be transformative for deterministic, phinitistic one autonomy? I mean, which is actually. Yes, right. So it depends on the type of automata, but in the traditional automata, this is absolutely the case. So, right. We'll also think sort of, you know, interchangeably, we'll think, we'll associate Automata and the languages that they recognize more or less interchangeably. So for a finite alphabet, we'll let sigma star denote all strings sigma generates. We call this liquidity star. We call this liquidity star. And we'll call any subset of sigma star a language. And we'll say that an automaton A recognizes that language if for every single word that's generated by sigma, when we run A on that word, it will only end in an accept state precisely when L is in the language, sorry, W is in the language L. So as an example, this automaton that I started. So, as an example, this automaton that I started off by showing you, the language that this one recognizes, well, we can just read off, okay, if we're reading a string from the start state, if it has zeros, if it has a zero, it stays in the start state. If it has one, it transitions to the accept state. And here we see delta is sort of a partial function, because once we're in the accept state q1, if we ever read another one, the run just stops. And if a run just stops, then And if a run just stops, then we consider the string rejected. If the run is able to continue and terminates in an accept state, then we consider the input accepted. So our input will only be accepted if it has exactly one one. And we can write the language, or we will write the language that corresponds to the strings that this automaton recognizes as 0 star 1 0 star. 1 0 star, which is just our notation core, some number of zeros of 1, some other number of zeros. So for a non-deterministic machine, it has to, all ways it takes, it has to stop in an accept state to accept? Right. So for non-determinism, you just need one valid path, right? It doesn't matter how many invalid paths that don't end in the accept state. You can have as many as you like as long as there's one that ends. Transition function doing on Q1 when you apply one? Yeah, exactly. So that's why it's a partial function here because there is no transition when you read in one. And so we consider that just like an invalid input that ends the run without accepting. Yeah. But this is crucial. The fact that we are allowing ourselves to restrict delta to be a partial function is actually quite crucial to the Crucial to the sort of variant of autonda we're going to discuss next. So I'm glad that you served this. Right, so now regular languages, the subsets of sigma star recognized by some automaton. We might not know which a priori. It might be hard to write down an automaton for just some subset of sigma star that happens to be recognized. But these are nice because they're closed under our favorite operations, which are. Closed under our favorite operations, which are those: complementation, union, and intersection, concatenation, cleany star. So, just taking sort of as many words from, so start with some set of words and just consider all finite concatenations of words from that language. That gives you the Klany star. And the class of regular expressions, so stuff that looks like this, eightway. This, vaguely, generated from your alphabet sigma via union, concatenation, and clean E star. This is actually equivalent to the class of regular languages. Have this nice, like two sets of things. We can look at the automata or the languages, and we have a translation between them. Okay, so just sort of giving a little motivation, I guess, telling a little bit of a story. You a little bit of a story. So, in, I think it was 2005, 2006, Rakim Musa and Top Sgeman, they defined this notion called F sets, which are sort of relevant in this context of looking at Morde-Lang, the Morde-Lang conjecture, and saying, well, in the, I guess in the isotrivial case, in the characteristic p case, where you're over, right, a finite field, You're over a finite field, Mordeu Leng, the sort of usual statement, doesn't quite work. It's not, it doesn't work as stated the way it does over the complex numbers. But so Musen Skanlin defined sort of a new language to think about sort of these semi-abelian varieties in order to basically unify the. In order to basically unify the special isotrivial case of order line in characteristic P with sort of the non-isotrivial cases. So what's the relevance of this? So then in a subsequent paper, Jason Bell, who is my collaborator, I should have said at the beginning, that I was working with him on this stuff. So he and Enrahim Musa showed that these F sets are actually recognized by finite automata in a particular situation. Automata in a particular set, right? You have to say what that means, of course. But so, what came up in this research that Jason and Rahib did is that in the characterization process of these F sets in terms of automata, they utilize this notion of sparseness, which is related to sort of topological notions of sparseness. We've heard of sparseness in the topological setting. In the topological setting, this is right, sort of the notion in the automatic, the automata setting, is named because there's a connection. So what we say is that a language L, and again this sigma star, the set of all words generated by sigma, is sparse if the number of words in L of length n, or sorry, I'm going to say of words. Or, sorry, I'm going to say of words at most n, doesn't actually matter, grows at most polynomially in n. So you have polynomial growth of words of length. And this sparseness will be a very useful notion in the setting I'm about to pivot to. So, right, Buchi automata, these differ from traditional automata in that instead Traditional automata: in that instead of just allowing finite inputs, we're actually going to allow infinite length. Well, okay, ordered by omega, right? I'm not going to do more complicated ordinals than omega for this talk. So we're going to allow omega-ordered, right, and omega-length input strings for our PUGE automata. And so when we allow And so, when we allow infinite-length strings, obviously our notion of acceptance has to change because the string will never terminate in an accept state because the run doesn't terminate. So how do we adapt our notion of acceptance? Well, there's the most naive adaptation you can make, which is actually a very interesting one as it turns out, which is that we'll just say an automaton accepts a string precisely if there exists a run on. Precisely if there exists a run on which it enters an accept state infinitely often, right? Some accept state. Or some slash any accept state infinitely often. From a moment on. You could still have exceptions, or do you say this one and zero such that from that moment on, it's always accepted. Or another state? Oh, no, no, no. Yeah, just just like there is, you know, a a a co-final subset of the run in which it it reaches the next running. It reaches an excess, right? But finites, so co-final substitutes. Well, so it won't be, because you might have something, right, where you can go back and forth, right, infinitely often. You might have one accept state, and then you'll be in a reject state infinitely often, but you'll also be in an accept state often, right? You prioritize. Not all status priority, right? Yes, yes. We use the same setup, we use the same automata, we just change our acceptance condition so that we can allow for infinite runs on infinite strings. But everything else stays the same. Exactly. Some of the meta stuff changes though. So, right, Amadora was saying before, well, if we have sort of our classic automata. Sort of our classic automata, whenever we have a non-deterministic machine, we have an algorithm for converting it into a deterministic one. With BG automata, this is not the case. And it does make things more complicated, that we can't just convert our non-deterministic BG altomata into deterministic ones. This is a serious pickup. Right, so now new automaton. Let's change. Let's change our perspective. Let's just shift our brains, right? From thinking of this as a finite automaton to thinking of it as a Buchi automaton. So now instead of thinking of, okay, if I have some finite string, where will it end? Think about if I have some infinite string, what strings will allow me to circle back to an accept state infinitely often? Which ones, right? Which ones, right? So, okay, I'm going to now ask us to make another leap and say we're thinking about infinite strings. What are infinite strings we like and care a lot about? Well, decimal representations, or binary, or what have you. So now let's view the input strings of this automaton as corresponding to ternary representations of real numbers. You just take the You know, take the string of the infinite string of digits and you add a decimal point or a radix point in front. And that's all you have to do to sort of think of them as being representations. In this case, maybe ternary because our alphabet is 0, 1, 2. Right, so if we have the digits on some expression of x in terms of negative powers of 3, we just think of the automaton. Think of the automaton running on X as the automaton running on the string of digits, the ternary representation prompts. So we'll say, now we're going one step deeper, we'll say that a subset of the unit interval in the reals is k regular. If there is a Buchi automaton that will accept an input precisely if that input is some base k representation. Is some base k representation or base k expansion of an element of the set x. Once you generate element one, you can kind of you could also just generalize it to r by taking the r and then run it in base k and then you could just add a rad x point. My reasons for considering just the unit interval is really just historical ones. Too much on the k-base. Okay, baby. Yeah, so for a subset of the rationals, for a subset of the rationals, you'll have multiple. But actually, this doesn't matter. And it's not true. Doesn't matter anymore. Well, because you can come up with an equivalent automaton that actually does accept or reject both. Two, it's a a nice subset of irrationals, thankfully. So yeah, you can always come up with a bigger automaton that. A bigger automaton that agrees on all representations. Perfect. Sorry, any other questions about this? Right, so now what about this particular automaton using our, you know, thinking of it as a Bucci automaton frames? So this automaton accepts an element of the unit interval precisely if the ternary expansion has Precisely if the ternary expansion has only zeros or twos as the coefficient on each power of one-third. So we wind up getting the Cantor set. This is, I guess, maybe a reason to believe the Cantor set is nice, or maybe it's a reason to believe that K-automatic sets are nice. Unclear, right? It's one or it could be one or the other. So, regular omega languages. Regular omega languages, these are the subsets of sigma 2 omega. This is exactly what they should be, right? Just omega index sequences of elements of sigma. Recognized by some Bucci automaton. The nice thing is that when Bucci introduced these automata, he also gave a super nice characterization of how we can think about these regular omega languages in terms of traditional regular languages. Like traditional regular languages, the kind that we know and understand super well. So for every regular omega language, or L in sigma to omega recognized by a Fuji automaton, there exists normal regular languages that are composed of all finite strings, V1 through Vm and W1 through Wm, so that we can express L as a finite union of just take. Union of just take one of your finitely many sort of you know normal regular languages and concatenate what we call an omega power of some other normal regular language. So we sort of have a way of thinking of it as like a regular language prefix plus a regular language omega power, and this allows us to understand these regular omega languages way more. Uh, regular Omega languages way more slowly. But what converse? Hmm? Canvas canvas? Each such a set is recognized by. Yeah, yeah. So, so, right, this is even only. Oh, oh, I see, yes. Um, ah, right. Yes. Yes. When you're a double right, you do the omega, so it measured a sequence of words from. Exactly. It's just an omega sequence where each element of the sequence is a word. Where each element of the sequence is a word in WI. Yeah, that's great. So, examples, right? For the Kandra set, we can see this as it's just V1 and W1. V1 is the empty string. W1 is 0, 2, the language with 0 and 2. So now I'm going to introduce the dyadic rationals, restricted dyadic rationals, actually. So the restricted dyadic rationals will express as. Dyadic rationals will express as the V1 is now 0, 1 star, right? That's just in normal regular language. And then W1 is just 0, taking the omega power. So these are two examples we'll keep in our minds. So, connections to first-order logic, right? Why is this a setting that model theorists would want to consider? I gave motivation. Consider. I gave motivation for like normal regular languages, but not these special regular omega languages. So we're going to define a ternary predicate, VK, on the reals, such that it holds for a triple xu d precisely if u is some negative integer power of k and the coefficient. And the coefficient on u in the base k representation of x is the digit d, the last thing in my terminal. So what's compelling about this ternary predicate? Well, some computer scientists showed that a subset of the 0, 1 box is k regular precisely if it's definable in the expansion. If it's definable in the expansion of the real additive group by this ternary predicate. So we have a correspondence between K-regular, basically compact K-regular sets and zero-definable subsets of this structure. So what is K-regular n-tuple? You define what is K-tuple? Yeah, okay. You just expand your language to be like, you know, an n-tuples of digits, you know, 0 through 1 minus 1. And what is k? K? Right, right. So k is just the number of digits, right? So you have 0 to k minus 1, those are the digits, and then you take your alphabet is n tuples of the digits from 0 to k minus 1. So then, as a corollary, we get that this theory is decidable in a very powerful way, actually. I'm trying to wrap up. So I'm going to quickly introduce K-sparse. So we say I said is K-sparse if it's recognized by the Bucci automaton A, and the number of prefixes with infinite prolongation accepted by that automaton grows polynomial in N. So the natural version of sparseness in the setting of infinite strings. We're just concerned with how the length. With how the lengthened prefixes grow where some infinite prolongation is exempted. So we show that this is equivalent to looking at all chaotic representations that are like finite unions of, yeah, finite unions of sets with base k representations in this particular form. Where these words are just These words are just coming from sigma star. They're just finite words. Because if you have a set which is recognizable by a parallel automata, I mean, it's gonna... I mean, even if you do these star things, you won't have finitely many possibilities, which would be sparse. No, so the canter set is very non-sparse. Right? So here, we're just allowing one word to be repeated some number of times, whereas the canter set you can alternate between zeros and twos as much as you can. Between zeros and twos, as much as you like. Here, we don't get that sort of alternation, right? You can't have two words of the same length that alternate sort of infinitely in any pattern you like. It's a set of prefixes of a regular set, regular? Yes. Yeah. Well, because that comes from this structure theorem. Yeah, yeah. Right, right. Yeah, right, right. So it is the natural, like, equivalent, right? It is natural in that way, exactly. So examples include, say, negative integer powers of 2, or, say, 1 minus integer powers of 3 union integer powers of 3 scaled by a half. These are just some random examples. Non-examples are stuff like canter sets, dyadic rationals. These are not good case scores. Our case scores. Okay, I really need to wrap up, so I'm gonna be super quick. So the expansion of the real additive group by 2 to the z is definable, and in fact, it's what we now call t minimal, thanks to what we show is that if x is in the unit square, if it's k sparse at infinite, then actually the expansion of the real additive group by a predicate for our set defines the same things as sort of one of these. As sort of one of these well-understood deminimal structures that look like the expansion by negative sort of powers of k that are also sort of multiples of n. And so as a corollary, we get d minimality and nRP. It's very good. And then I'm going to skip the definition of Housework dimension, I'm so sorry. But so Horonomy and Wahlsberg show that when we expand And Wahlsberg showed that when we expand the real additive proof by a canter set, we have TP2. It's very bad. And so, as a result, this is the last thing I'll mention. So, what Jason and I show is that if you have a subset of the 0-1 interval that's k regular, and the closure has no interior, then the following are equivalent. The Hausdorff dimension of the closure is zero. That's equivalent to That's equivalent to the expansion of the reality of group by the set being D minimal, which is equivalent to it being NIP, which is equivalent to it having TP2. So it's a very stark dividing line. Either you're D minimal and NIP or you've got TP2, and everything goes horribly wrong from a neostability perspective. And this is all I have time for. I'm sorry to rush. I had some in-progress stuff, but I'll skip. Questions? What happens if you add a non-sparse cell to players? Yeah, yeah, right. So if you. Yeah, right. So so with a canter set, we have sort of very bad behavior. And so right, the the circle. Always very bad. What do you mean, always very bad? If you add non-sparse. Yeah, yeah. Well, so actually, this is the in-progress stuff. I don't think so. I don't think it's always very bad. I think as long as you add something that's either sparse or looks like cosets of the k rationals, then you're fine. Because you can add stuff that just looks like a sufficiently nice subgroup of the real additive group and should be. And like you should be fine in that setting. So there is some sort of intermediate thing. When you just look at closed sets, yes, we have this exact dividing line, but when you allow non-closed sets, somehow, yeah, the topology makes things a little more interesting. Yeah. So if in the definition of sparsity you were to restrict even further, so say the growth rate is even slower, so like, I don't know, logarithmic or something, do you think? Logarithmic or something? Do you think you can say stronger things about it? You get finite things. Thank you. Probably. You get finite. Yeah, yeah. So there's nothing infinite that is simpler than sparks. So, in the bad case of this equivalence on the last slide, do you actually interpret the power set? And there are worse properties than TP2. Worse properties than TB2. Yeah, yeah, fair enough. Right, so this is coming from the interpretation of the monadic second-order theory of the naturals. Yeah, I mean, I guess by that measure, it's pretty bad, but it's still decidable. So there's sort of this very funny duality. So you do get interpret this structure. Yeah, yeah, right, exactly. When any one of these fails, you interpret this structure. Is exactly right. You interpret this structure is exactly right. Perfect, thank you. Does your work with TakeSunpool allow you to come kind of a person of Cobam in these? Yes, yes, so we do have a little section in our preprint that's coming out about a version of Cobham's theorem where you have, in this first setting, you have some nice bounds on what these intersections of like K and L simultaneously K regular and L regular sets look like you have an out. L regular sets look like neoconatans on. If they're sparse, how big they? Does the set C? I mean, these K regularity and L regularity? I mean, does the set? I mean, in the sense that what you showed is that adding this set, which is going to be K automatic, or UTK automatic, it's going to be equivalent to the function DK, right? Yeah. Or some function. So that's. So that's actually a really good question. That's also ongoing work. So this, yeah, when do we. So I don't know if this is exactly. So, I don't know if this is exactly what you're asking, but one of the things I'm working on now is when do we get definability of this ternary predicate? So for some cantor sets, this is known. It is not known for the expansion by any k-regular cantor set, whether you can find it. My guess is yes, and we're working on that. Questions? Thanks again. We're at the coffee break and resume as the orders. What? So let's get 30 minutes. 30 minutes? Oh, oh yeah, sorry.