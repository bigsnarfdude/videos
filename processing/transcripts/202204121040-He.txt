is that with these two operators we can um we can with these two operators we can study on the comp we can construct another q operators as the composition of them but in different orders so y is this operator t k sub t sub k nu which is defined as the composition of i and i star so according to our definition of i and i star Or the definition of I and I star this TK operator is the operator from L2 of mu to L2 of mu. And in the other direction, we can compose this I star and I so that we define this S operator and its operator from the RKHS to the RKHS. So we can show that both these two operators are self-adjoint, positive and compact operators. Operators and um and we can and with this property according to the spectral decomposition we could um we could have a spectral decomposition representation for these two operators and meanwhile we can also show that they share the same non-zero eigenvalues and eigenvectors um so so so then um since they only share the Since they only share the same non-zero eigenvalues and eigenvectors, we would like to know when they don't have zero eigenvalues, right? So we can, so there's like some sufficient condition can guarantee that these two operators are strictly positive so that they don't have zero eigenvalues. For the operator S, we know that when this kernel k is continuous in both. Kernel K is continuous in both parallels, and the probability measure Î¼ has full support. We on this S operator is strictly positive, so it does not have zero eigenvalues. And for the other operator T, we know that when this kernel satisfies what's called the integrally strictly positive definite condition, which is defined as this. So the integral. So the integral of the kernel in the two variables with respect to a finite Boras sign measure row is always positive for any finite Boras sign measure row. Under this condition, we can show that the T operator is strictly positive. So with these two conditions, we know that both operators only have positive eigenvalues. So we So we can, and according to the spectrum on decomposition theorem, we can have a spectrum decomposition with both operators, and the eigenvalues can form a known basis in on either the space of L2 and the space of RKHS. Okay, with all this knowledge on the RKHS and on those. And those operators, we can look at how that can imply some relations between the RKHS and the space of L2. So, the first relation I want to emphasize here is that we can see that the RKHS is actually included in L2 and it stands in L2. So, it's an inclusion, it simply follows from that I operator is inclusion. And it's dense, it's because under that ISPD condition, we can the I star operator is injected, which can imply that the RKHS is stands in that space L2. And another important fact is that with the spectrum decomposition, we are able to interpolate between any functions. In L2, or any functions lie in L2 but not in the RKHS via this T operator. So the T operator is an operator from L2 to L2. And we have this spectrum decomposition of T operator with lambda i being the sequence of eigenvalues. And we order them in the decreasing order. And all the eigenvalues are strictly positive. And this EI. Positive. And this EI is the sequence of eigenvectors, and they can form an autonomous basis of the space of L2. So for any function f in L2, there always exists a prime the gamma lying between zero and one half, which is strictly positive, so that we can represent f as the gamma's power to the operator tk. To the operator Tk act on a function H and that function H lies in L2. So why I say this is the interpolation between the RKHS and L2 is because when we consider the limiting situation with gamma equals to zero, this is trivial saying that F is actually in L2. But when gamma equals to one half, F equals to that T operator to the power one. equals to that T operator to the power one half f done f. And if we use that spectrum decomposition, you can represent it as this summation right here with square root of lambda i as the weight. And we can show that this with this weight, this F is actually in the RKHS. And what this gamma or this parameter gamma is actually a parameter that can help us to Parameter that can help us to distinguish any function in the gap between this lying L2 but not in the RKHS. For example, if you if an F lying here, which is in L2 and not in the RKHS, then you can always find the gamma strictly between zero and one half so that the F is an image of T. It's an image of t to the power of gamma at on a function h, and that function h is in L2. Okay, any questions for now? My question is: why this gamma thing, why is that true? I mean, where does it come from? Sorry. Sorry, can you repeat it? I can't hear you. So the fact that for any F in L2, there exists a gamma such that F is equal to T gamma H. Where does it come from? Where does it come from? Yeah, it's um it comes from that um It comes from the Stainworth book support vector machines, and it's also used in several previous papers where they use RKHS to study some good or fitness testing problems. Okay, so it comes from your fact that H is denser than two? Right. Okay. And also for the, so the, and if gamma is equal to one half, then F belongs to H. Why is that true? Yeah, so this is because there is what's called the Mercer's decomposition theorem for RKHS. So when you can represent a function. Your function in RKHS. That is because, so actually, according to the Mercis decomposition, this square root of lambda IEI is like a forms author basis, orthonormal basis in RKHS. So when you have this, so then you can show that this element is typically. Yeah. Okay. So now we go to the second part, which is the formulation of a regularized state variation of gradient descent. So recall that our goal is to generate samples following a certain distribution pi, which is proportional to e to the negative v. And here I'll call the function v to be the potential. The function v to be the potential function. And as Adil introduced in yesterday's talk, so there's an optimization formulation for this sampling problem. So we consider we update in the algorithm, we update our particles or random variables following this map capital T, which is defined as X T of X equals to X. x p of x equals to x plus epsilon times phi of x. So we can understand the epsilon here as a step size, and the phi here is a vector field. And our goal is to find the optimal vector field phi star so that the tail divergence from the push forward map from rho by this capital T to the target distribution pi. The target distribution pi decays fastest. So, according to this optimization formulation, like in Changlio et al. 2016 paper, they show that the optimal vector field phi star can be represented as in this way. So it's the arcmax vector field. It's a vector field, a fee within. It's a vector field of phi within this choreographic set F so that this expectation of that stain operator reaches its maximum value. And there are some constraints on the vector field phi as well, the vector field phi as well. And usually that constraint, they constrain the phi in some unit ball in the space of in the space curve graph F. Cliograph F. And this S operator is called the stain operator and is defined in this way. It depends on the potential of the target distribution. So ideally, we want to choose according to that formulation, we should choose the parigraphic F to be the L2 space with respect to the probability measure row. And I have this. And I have this upper index D here is because all the functions are valued in R D. And the constraint is that the L2 norm of that vector is less or equal to one. So it's within the unit ball in that L2 space. So with the choice of this function space, we can compute that the optimal We can compute that the optimal on vector field is actually proportional to this negative gradient v minus gradient rho over rho. And in the other way, we can write it as negative gradient of log rho over pi. So this tells us that if we want to update our random variables, our particles, we need to, in the next step, we update it as x minus epsilon times gradient. X minus epsilon times gradient of log of rho over pi. And when we consider the time step, epsilon decreases to zero. So we can recover a PDE, which describes the evolution of the distribution. And the PDE is given this way. So we can see exactly the Foker-Planck equation to the long-vinc dynamics. But the drawback of this formulation is we cannot really update our particles according to this function capital T because this requires a full knowledge of the distribution row at time t. So we don't have access to the full knowledge of the distribution row. So we cannot update it in this way. Updated in this way. And so, in the other way, so that's why for the Laundering Monte Carlo algorithm, it's not actually a discrete particle deterministic particle algorithm. So it's a stochastic particle algorithm. So it's like a disqualization to the Longvin dynamics. Yeah, as for the SVGD, as is mentioned in yesterday's talk, instead of choosing the function f to be the L2 space, we choose it to be the RKHS with the constraint to be on the vector in the RKHS. And it's also in Liu Chan et al. 2016 paper, they show that. 2016 paper, they show that this optimal phi star is actually proportional to native the I star operator at on gradient log of rho over pi. So recall that I star operator is the integral operator respect to the kernel, integral operator, which is defined as the function times a kernel integrated with respect to the probability measure row. So with this result, we update our particles according. We update our particles according to this map t. So at each step, we minus epsilon times that I start on gradient log of rho or pi times x. And it's because of the RKHS property, we can write it explicitly in terms of the value of x at time t. We don't need the full access, full knowledge of the density. Full knowledge of the density rho at time t. And when we let the time step those decreases to zero, in Lou et al.'s 2018 paper, they show that the limits, in the limits, is a limiting situation, the distribution can be described by this PDE, and they call this the mean field PDE. And they have a compared to the And they have compared to the Fokker-Planck equation to the London dynamics, they have this actual operator I star here. So with these two formulations for the long living related, with these two formulations, if we compile the SD more carefully, we can see that, so they for both for both PDE, they actually Um, PDE, they actually um, they can they actually are in the form of the divergence of the product between rho and the vector field. And in the Langevin situation, the vector field is purely gradient log of rho or pi. And in the S V G D situation, the vector field is I star times gradient of I star act on gradient log of rho or pi. And we can observe that we can understand the gradient log. Send the gradient log of rho over pi as the identity operator act on gradient log of rho over pi by assuming the gradient log of rho ri lie in the space of L2 with respect to the probability measure rho. So this assumption is kind of reasonable because it's actually equivalent to we recall the feature information from row to pi is finite. And on the other hand side, because according to Other hand side, because according to our previous relation between the RKHS and the L2 space, we know that this I-star acton gradient log of rho ra pi actually not only lie in the RKHS, but it also lies in the L2 space. So in this way, we add an inclusion operator in front of to write it as the T operator at the gradient log of row over pi, which is It's with output lying the space of L2. And in this way, we see that the vector field are two different operators act on gradient log of rho or pi. One is the identity operator from L2 to L2, and the other one is the TK operator from L2 to L2. So if we try to interpolate between the long-dividing situation and the SVGD situation, we want to come up with want to we come up with this new operator um which is also from l2 to l2 which uh and it's defining this um it's defining this red box so it's the composition between uh t plus nu i inverse and t operator and because of all the good properties we have introduced for the t operator this inverse operator is well defined and that i operator And that I operator is identity operator in L2. So we hope that we can control this parameter positive parameter new so that it can interpolate between the Langevin and SVGD. So with this operator in mind, the question is: how can we formulate the regularized SVGD to get a and to have the limiting situation to be the PDF? Situation to be the PD we want with this corresponding operator. And here is what we have done. So we still choose the space calligraphic F to be the RKHS, but we have a different constraint. Our constraint is given by the parameter new. So we recall that new times the RKHS normal phi squared plus. fees squared plus the L2 normal fees well is less or equal to one. So similar constraint has been used in Krishna et al. 2017 paper when they study the goodness of fit testing problems embedded in our KHS. And let's see why this constraint is useful. So for the constraint for the If we look at the constraint, we can write the left-hand side of the inequality in this way. So by simply using the properties of RKHS and the joint relation between I and I star. So we can write it as the inner product between phi and this operator act on phi. And meanwhile, if you look at Meanwhile, if you look at the object we want to maximize, which is the expectation of that state operator act on phi with a random variable x following the distribution rule, we can write it as the inner product between phi and i star act on gradient log in our KHS. So with these two equations, we can immediately get the Can immediately get the know that the optimal direction or the optimal vector field should be proportional to this inverse operator composed with I star act on gradient log of rho over pi. And according to the definition of all those operators, we know the value on the phi star is in the in the space of RKHS. And also, because our knowledge on the RKHS and LO2, knowledge on the RKHS and L2 we know that it's densely under all those appropriate assumptions is on densely embedded in the in the space of L2 so we can so on we we add an inclusion operator in front of it to define our optimal vector field to be proportional to this I operator comp on to this inclusion operator composed with this inverse operator composed with this This inverse operator composed with this i star integral operator act on gradient log of rho over pi. In this way, we assume that we consider the phi star is a vector in L2, in the space of L2. And there is a relation between this complicated operator and this operator. So we can use some simple calculation, show that this operator Calculations show that this operator, these two operators are actually the same. And the operator on the right-hand side is nothing but the operator TK plus nu I inverse composed with TK, which is the operator in the previous slide we want to use to interpolate between SVGD and the laundry. So, any questions? Okay, so so with this, um, yes, uh, so so why do you interpolate this way? I mean, you want to interpolate between uh T, between TK, TKRO, and identity, right? And the way you do it is to say, okay, I will introduce this character that depends on you, but there could be. but there would there could be there could have been another other ways to interpolate between identity and c right yes so why so why is this choice um i would say it's more more likely we want to um we want to formulate another algorithm in this dimensional formulation way and so that it can And so that it can, the limiting situation is the longer win dynamics, so that in the analysis, we can take the advantage of the fact the limiting is the longer venue to get some better result or to understand why there's a gap in the analysis in terms of SVGD compared to long-term dynamics. Okay, if I take, for instance, complex combination of identity and t for instance. Of identity and t, for instance. Like new identity plus one minus new t that'd be another way to incarcerate. So why, I mean, why this one is, I guess the one we propose is better, but why? Yeah, so yeah, I haven't seen about the other, the operator you are mentioning just now. Maybe we can still form. Maybe we can still form we can also formulate we can also formulate another version of Rugless SVGD in that way so that the limiting situation is what you just mentioned. But I believe you have to choose the constraint differently. Ah, okay, that's good. Okay. Maybe it's because the constraints are simple with this one? Yes, yes. Okay. Okay, okay, see. Okay, okay. Yeah, so any other questions? Okay, thanks. So with the knowledge of this optimal vector field or optimal direction to update our particle, we can get the population limit. The population limit is described in this equation one. So it tells us that how we what's the relation. That, how we what's the relation between the so it's a setup when we consider we have disqualization in time, but we don't have particles. We have a infinite many particles. And it tells us that the population at the end plus one step is updated by this push-forward map, this complicated push-forward map to the distribution at the end step. And this H is a time step, and we allow variant time step. And this equation 2 is the mean field PDE is the issue. It's a setup when we consider the time step decreases to zero and we have infinite many particles. So we can see the vector field inside this forensic is described. Described as that operator we just mentioned is so this I composed with I star is actually the T operator and last is this finite particle system so for this finite particle system we consider both disqualization in time and finite particles and we have this equation three because we start if we start from this equation we start if you start from this equation one you can you can represent that inverse operator and that ii star operator um in the finite particle setup directly so there is no approximation from one to two if you assume that your row n is an empirical measure from all those n particles so this capital k n in the finite particle system is Particle system is the gram matrix with all the entries being the evaluation of the kernel at different particles. So next I will present some of our analysis on the mean field PDE first. So this is our mean field PDE. So I will first introduce the existence. Any questions? So, how does this recall the previous page? Sorry, I didn't hear you. Can you go to the previous page? Yeah, yeah, yeah. Last equation. How is this recovered on John? Yeah, so from the finite particle system, we cannot. So it definitely cannot recover the Longerian dynamics because we formulate our algorithm in the same rational way and we take advantage of the structure of the RKHS. So it's a deterministic algorithm. As you can see, you update a particle at each step. Particle at each step deterministically, but for longer than it's a stochastic update. So you add a noise at each step. But if those two infinity in the in the original formulation shouldn't be recommended. Yeah, we hope that so currently we don't have to analyze this finite particle system directly is hard, but we hope to look at that population. We hope to look at that population limit or the mean field PDF to see how that relates to the long-mean dynamics. If you take mu equal to zero in equation one, okay, that will be the simplification between the two operators, right? The ii star, that will be simplification. So you obtain, you will obtain, sorry, take, sorry, take equation two, sorry, equation two. sorry take equation two sorry equation two take zero you obtain the pt and that pt is the pte of the is the is the dynamics of the measures of lange equation yes but not of the not of the particles of the measures it's the pte of the measures yeah but i was talking like how can you approach that stochastic as well you don't want to have a stochastic as a We don't want the random stochastic. We can discretize the same PDE using multiple ways. Yeah. So basically, if you discode it, it's the It's not designed to recover Langevin multi calculus or the discrete algorithm in the particle setting. It's not designed to do that. We don't want to do that because we want to have a deterministic notice. They discretize the PD, whereas the non-algorithm is a discretization of one SD. Discretization of one SDE that corresponds to the difference. I was just curious about what will happen if you goes to infinity. So when you goes to infinity, you're recognized in GT, right? But what happens? I think it goes to zero, you cover it. And I'll just use it for the particles and I'll see you. Yeah, so just from the. So just from the values of new, so it interpolates between new equal to so if new equal to zero, that means it's block, right? If new equal to zero, okay. And the other side is mu equal to infinity or mu equal to so what's the risk? So my question is what are so this this equation two interpolates between the GT of Rangeman and the GT of And the PT of SPG. So, what are the corresponding values of mu? So, I know mu equal to zero for record. And the other side is mu equal to infinitely technically. Okay, yeah, I guess when new equals to zero, it can interpret the. it can interpolate the longering dynamics and when new is just of order one is just some constant it can also interpret the SVG as well and also so if you in equation three if you take nu equal to zero in equation three okay maybe there's a matrix that is that is uh that is not uh regular let's say we can let's say it's well defined so you recover and blue districts So you recover the new displacement of the for Kaplan. Yeah, yeah, I know, I know. Let's assume that the matrix you can compute the ingress of the matrix. And this would be a good idea, right? So we have this good display of what it's just like. So, is there any other question? The normal questions will be proceeding. Okay. Yeah, so I'll present. Yeah, so I'll present some of our results on the mean field PDE. So, first is the existence and uniqueness of the weak solution. And second, it's the stability result in terms of the Watson p-distance. And last is the KL divergence decay result and the feature information convergence result along the solution of this PDE. So, for the existing unique case of weak solutions, This is a unique case of weak solutions. So we first define the weak solution in this way. So we require the solution to lie in the space which is continuous in the time variable. And in terms of the x variable, it's a probability measure so that this PV norm we define here is finite. P V norm we define here is finite. And remember that V is the potential of the target density function. And when you apply test function on phi to be smooth and compactly supported, so you would this equation is satisfied. And same definition of weak solutions used in Louis et al.'s paper when they studied the mean field PD. The mean field PDE for SVGD. And here is our result. So if you have under some assumptions on the kernel K and potential V, if initially the initial condition row zero lie in the space of that PV, so there exists a unique weak solution to the mean field PDE1. And moreover, we have this estimation of the weak. Estimation of the weak solution up to time t. So the PV norm we just defined for the solution at time t is upper bounded by the pv norm initially times this exponential factor. And the exponent is some constant times t to the negative one half. And this constant t is complicated and is depending on the kernel, the potential function, the initial condition, and our parameter new. So, I will not introduce the full proof of this existence results. I would simply just introduce the idea of the proof. So the proof relies on take a lot, make use of another differential equation, which is the characteristic gradient flow induced by that mean field PDE1. So, the coordinator gradient flow is given by this equation 2. So, as you can see, this capital phi function is a function of a rubber T and X. And when we fix T, it's like a map from a D-dimensional Euclidean space to a D-dimensional Euclidean space. So it satisfies this first equation here. And when we fix an internal And in terms of the x t variable for fixed t, we define this row t here to be the push-forward measure from row zero by this by that map, capital Phi of T. And when t equals to zero, this map just stays at well, and this x-variable indicates well it starts from. Where it starts from. So when t equals to zero, this map stays at point X in the Euclidean space. We can, it's proved also in this paper that this current gradient flow, when this current gradient flow has unique solution, there is a weak solution to the mean field PDE. weak solution to the mean field PDE1. So we can turn to study when does this equation two has a unique solution. To do that, because this is like an ODE system in terms of the function capital phi, so we have an integral formula. We have an integral representation for the solution as phi of t, the capital phi at time t can be represented as in x minus that integral from 0. Minus that integral from 0 to t. And we can define the right-hand side to be a map curvy F act on that capital V function evaluated overall with T and X. So the next step is to show that the map curvy F is actually a contraction from some space. A contraction from some space y to y. So we need to find some reasonable Banach space y so that a lot of a class of capital P could lie in that space and the map F is the contraction from Y to Y. And it turns out that to show the contraction, we need a lot of knowledge on, we make use of a lot of property on the RKHS and the info and what we previously introduced. What we previously introduced about that, those operators t and i and i star. And it's worth to mention that it's hard to show the global existence of the weak solution directly. So we first we show that f is a contraction up to time on t when t is small. So we show local existence and uniqueness of the weak solution. And after that, along that local Along that local weak solution, we have an approximation for our weak solution in terms of that PV norm. And with that, we can show that we can extend our local solution to a global solution so that we can show the existing case for the global weak solution. So after this, we also show the stability in terms of the Watson PD sense. In terms of the West and P distance for that mean field P D1. So for the stability here, we mean if you start, if you have two initial conditions, row one and row two, so how far is your solution at time t, or how far is your solution at time t in terms of the Western P distance? And here is our results. We show that Show that there is a we can bond the Western P distance between the two solutions uniformly in the time interval from zero to capital T by some constant C times the Western P distance between the two initial conditions. Also, this C depend on a lot of, depending on the kernel, the potential, the two initial conditions, the capital T and our parameter mu. And the reason why we want to show this stability result is. To show this stability result is if we choose for one, if we choose row one and row two, like for one, for row one, if we choose it to be a distribution new zero, and for row two, if we choose it to be a distributed empirical distribution by capital M fat particles, and if all those particles are, say, I d follow from the distribution mu zero. From the distribution mu zero, so that we could show that row two is actually what goes to row one when capital N, the number of particles goes to infinity. And with this stability result, we could bump that empirical distribution. We could bump that solutions to that mean field PDE uniformly up to time capital T. And we can also show that uniformly when capital N goes to zero. When capital N goes to zero, uniformly in that time interval from zero to capital T, the Western P distance between the finite particle solution and the infinite particle solution goes to zero when number of particles goes to infinity. And next, we studied the KL divergence decay along the solutions of the PDE. So this is a This this is uh this is also on this follows exactly what people do when they study the long-term dynamics. So if you take the derivative of KL from the solution rho T to the target distribution pi, you can show that on the derivative actually equals to this inner product here. And we define it as the new regular stain feature information. It's easy to show that it's It's easy to show that it's negative, so that the KL divergence actually decays along the weak solution to that PDE. But we would like to know more about that new regularized state infusion information to try to have some try to quantify the decaying rate for the KL divergence. So here is some properties we have for the So here is some properties we have for the new regular stain feature information. So first we have a spectrum representation for it because we have a spectrum decomposition for that t operator. So if this lambda i start the eigenvalues and the i start the eigenvectors and the also known basis for the L2, you can represent the new stain feature information in this way. In this way, as you can see, without this weight here, it's actually the actual feature information. Without this weight here, it's actual feature information. And when this weights, when the parameter new goes to zero, this weight becomes to one. So it goes to the actual feature information. And when new is of constant order, so this would, since lambda i goes to zero, when new is just a constant, say one, this will behave similar. A constant say one, this will behave similar to the stain feature information, which is defined when people study SVGD. And another property is by using the spectrum representation, we can approximate the feature information by changing, by making new small enough. So, here is some simple calculation. So, first, it's obvious that the regularized It's obvious that the regularized stain feature information is smaller than the feature information. And meanwhile, you can write the feature information as the regularized stained feature information plus this remainder term here, which is given in this summation. And for any probability measure nu, so that gradient log of mu or pi lies in the L2 space of nu, we can. Space of mu, we can find that parameter gamma between zero and one half so that the gradient log is actually equals to the TK operator to power gamma act on a function h, which is in L2. If we use that property here, we can upper bound the feature information by the regularized feature information plus a remainder term. And that remainder term is represented as the parameter nu to the power of two gamma. To nu to the power of 2 gamma times the L2 norm square of that function h. So, as we can see, when it decreases Î½ to 0, the lower bound of the regularized then feature information will also go to the feature information. So, with these two properties on the regular feature information, now we can have We can have some result on the decay of KL divergence. So the derivative of KL divergence could be under the log stop-level inequality assumptions because if you assume the target distribution satisfies the log sub-level inequality with parameter lambda, you can upper bound the KL by some constant times of feature information. And in that way, we can upper bound the derivative KL. way we can upper bound the derivative Kl by negative 2 lambda times Kl plus that remainder term. So that by using Groundwork's inequality, you get the Kl divergence from rho t to pi is actually bounded by the right-hand side of this first equation. So the first term decays exponentially fast and initially is just a KL from the initial row zero to pi. The initial row zero to pi. And the second term is the integral with respect to t. And you have this RS, which is the which is the A, which corresponds to the H we used in the previous discussion. But this time is depending on time. So it's the L2 norm of the image of the pre-image of that function h. function h from the operator tk to the power lambda t. As we can see now, if you push this new to zero, you will see a vanishing bowels and you get an exponential decay property for the KL divergence, which is exactly what we have for the longering dynamics. And meanwhile, in terms of the convergence of feature information, it's also from the same inequality if we Same inequality. If we don't use the groundwork inequality, but we integrate it directly, we have this inequality here. We can hover around the integral of feature information by KL plus that integral. And when mu goes to zero, the integral on the right-hand side vanishes. And you can see that since if the initially the KL divergence from row zero to pi is finite. From rho zero to pi is finite, we will see the feature information converges when t goes to infinity. And we also look at try to look at the relation between our mean field PD for the regularized S V G D and the Fokker-Planck equation to Langevin directly. So we assume nu t is the solution to the Fokker-Planck equation to Langevin dynamics with the initial condition nu zero. With the initial condition new zero. And we try to study how the KL divergence from rho t to nu t behaves when t increases. And we found that if we assume that pi also satisfies the logs of inequality, if we can choose the initial condition for the Fokker-Planck equation, nu zero, so that along the trajectory Trajectory along along the trajectory for all nu t, it also satisfies a log sober inequality. Then we can have a control on the KL divergence from rho t to nu t. And the upper bound is also have it also has two terms. The first term decays exponentially fast when t increases, and the second term could be controlled by our parameter nu. Of parameter new. Yeah, so next, we also look at the population limits for the regular SS VGD. So we've got the population limit is given by this equation here. And we have this assumption A1 to study the convergence result for the population limits. So similar assumptions were also used. Similar assumptions were also used in Anna and Adils adult's paper, 2021's paper. But here, our assumption three is a little bit different. So in their paper, they will require the same feature information is finite at all the iterates. And here we require the feature information to be finite at all the iterates. And other than that, we have some smoothness and conditions on V. On conditions on V and gradient conditions on V. And we have that and we also recall the gradient of the kernel has finite RTHS norm. So with this assumption A1, we have this theorem one, which tells us how the KR divergence decays along the population limit. So we can, so here, so the serum one says that if we assume that the target density satisfies a lot of The target density satisfies a lot of living quality. So, theoretically, you could control the parameter Î½ at each step and the step size at each step. If you make them small enough, then you can have a decaying property for the KL divergence along the population limit. And decaying is described in this equation for so. So here the R is the upper bound for the initial K of divergence from row zero to pi, and the Hi is the time step, which is and the lambda is the logo-life constant. But here we for some for some good starting point, maybe we can choose the time step to be fixed so that it could decrease this exponentially. Could decrease this exponentially fast polynomially. And for general initial conditions row zero, we may have to decrease the age fast enough. And it's not clear when this, like at what kind of initial condition we can show that this KL divergence actually converges to zero. And we also have this serum too under the same assumption without assume, but without assuming the log sublime inequality. So, this describes the behavior of the feature information along the population limit. And as you can see in the upper bound, the upper bound depends on a lot of parameters, including the parameter new, which is the parameter we could choose at different steps, and also the parameter at the step and also the prime step size. And also we have this gamma n on the right hand side. So the gamma n is that power between zero and one half we use to characterize the gradient log of rho over pi at different steps. And it's also hard to track how this gamma would evolve when we have different initial conditions. So, lastly, the future work, we also want to analyze how the finite particle system would behave in this regularized state-member circulation setup. But it looks difficult for now because it's not even clear in the SVGD situation. But we expect to analyze the finite particle system, the difficulty would be comparable to that. Probable to that to analyze that in the SVGD. Yeah, so that's all my talk. So, any questions? Okay, any questions from the audience? If no more questions, then we will break for lunch and reconvene at 12.30 for the open problem session. Let's time the speaker again.                              