So I would like to speak about automatic differentiation, but I'm not at all an expert in this topic. It's just a couple of years that I'm working on it. And actually, the main goal was to try to express some of the algorithms that are at the core of automatic differentiation from a linear logic perspective. Perspective. Okay, so this is mainly joint work with Alois Brunel and Damiano Mazza, both in Paris. So I will try to be not technical, to give a smooth introduction to the subject as far as I can. So what is automatic differentiation? AD for short. Well, it is a field that provides tools for transforming a program computing a numerical function. Computing a numerical function, so you have a program F computing a function of a real or complex number, into another program that we call it Grad F, we call it Grad F in this talk, which computes the gradient of the function whenever it exists. And of course, this kind, it's a field that exists since half a century, and it has a lot of applications because it can be used in the optimization program. Use in the optimization problems. For example, in the gradient descent algorithm, you can try to find the local minimum of a function by following the direction given by the diverse, the opposite direction given by the gradient computation. But why the programming language community is showing more and more interesting in this topic. Topic for the following reasons, as far as I know. So, one of the most recent applications of ADE is in deep learning, where again we have another example of application of gradient descent algorithm. So here you have a piece of code from PyTorch, which is one popular library for deep learning. For deep learning. Here you have a program which I call the model that is not specified in this part of the code, which define a neural net which is computing some which is taking as input huge vectors over real numbers and output another vector over real number. Another vector of a real number, and then you compose this neural net to a loss function, which is another function that takes the output of the model and an expected result, a measure in some sense how different the expected result is with respect to the outcome of the neural net. And the decomposition of the model and the loss function give us a program F, which is a numerical function with respect. Is a numerical function with respect to which that we want to minimize to find the local minimum minima. And in order to minimize it, we computed the gradient and we updated the parameter in the opposite direction with respect to this gradient. And the computation of the gradient, that is the beauty of this kind of framework, is done automatically, so not by hand, just by calling a method. In this case, this back. methods in this case is this backward methods which is just implementing one of these ad transformation transforming f into a new program computing the gradient of fight that's again why programming languages are interested in this kind of topic well because 10 years ago 20 years ago the the model and the loss function that were used in this kind of application were quite basic Were quite a basic composition of elementary functions over real numbers. So it was very primitive programs that has been called computational graphs, mainly composition of basic function of real numbers. While since decades, neural nets are more and more defined dynamically by true programs, so where you can have return. So, where you can have recursion, branchings, or even complex data structures like tree, list, dictionaries. So, now the idea is that this transformation really is a kind of compilation process that takes a quite complex program synthetically and rewrite it in something that should compute the gradient. They should compute it very efficiently because, of course, this computation should be iterated several times. For example, in a learning process. In a learning process. And so it's natural to try to see whether some of the techniques that are developed in the programming language theory can be applied to these kind of settings. So great. Now let me stress a point that has been also mentioned briefly by Toma in his talk. You can see that here what we are That here, what we are speaking about are gradients of numerical functions. So we will always work with derivatives over the standard topology of real numbers. So there is not exactly, there are no, there is, in this kind of works, there are no use of derivatives over high order types, okay, like the derivatives that you can have in. Derivatives that you can have in a differential lambda calculus or in differential linear logic or in differential categories. For the moment, maybe one time at a certain point we will understand how to use a kind of guided descent on high order types, but for the time being, we are not able to do that, and especially not in this work. Okay, so I will speak about linear logic, but not about differential linear logic. So great. Logic. So great. What are the goals of our contribution in this kind of topic? Well, they are twofold, foundational and importing new tools. Foundational means we are interesting to take the algorithms that are at work in this kind of libraries like PyTorch and try to abstract them to a formal framework. A formal framework so to lift them to some formal system like simply type Lambda Calculus or some variance of it or idealized algorithms or some ideal programming language and be able to prove properties by theorems. So because usually the properties of this transformation are just tested experimentally in the... In the field and not studied from a theoretical point of view. So, this is a first, let me say, goal. And the second one is to try to see whether some of the tools that are quite natural in these abstract settings, in the theoretical setting, can be can give some hints about some improvements or clarification in the In the implementation of the actual algorithm of AD. And we will see, for example, even if it is well known since a bit of time, the usefulness of functional programming, so of lambda, the abstraction, and one of the most specific contributions of us if to show how one can use a linear logic. One can use a linear logic in order to explain some performances of the back propagation algorithm. Great. So let us give a bit more detail. So let us fix some notation for this talk. So all over the talk, I will speak about a program as a term of PCF. So if you know what is a PCF, if you don't know what is a PCF, it is an extension of simply type lambda calculus, which is totally complete. Which is Turing complete, so you can compute the fixed point, you have a recursive functions, and it has ground types for working with basic data types like natural numbers. In this particular setting, we extend the language with the ground type of real numbers with some bunch of basic functions of real numbers. And then a program for us is a term of PCF, which has a sum of three variables of ground type, which are the input of the function. Other the input of the function and as the only output earlier number. So you can think of it as, if you wish, to come back to the deep learning application, to the loss function of a neural net. And the parameters here are the learning parameters of the neural net. So it might be possible that the dimension of the input is very big. Of course, any such program compute a numerical function which might Which might be partial because the PCF language is too incomplete, so it might be possible that f diverge on some of its inputs. And then in this testing, one can define the gradient of this function on some input vector r as simply, I will consider the gradient of such a function as simply the vector of the partial derivatives of this function whenever Of this function whenever the gradient has a meaning. That means that f might be a very exotic function, and there are examples of very exhaustive functions. And so it might be possible that f is not differentiable everywhere. But I'm interesting in the behavior of the AD algorithm only on the inputs where the gradient of the underlying function is well defined. Well defined. Okay, so outside the differentiability domain of F, I don't care what happens at the level of this program transformation. I want to study just this program transformation when the gradient is well defined. So what does automatic differentiation? It takes this term f and it gives us a new term that I call a grad F that takes the same inputs and computes a tuple as an output. And this tuple is supposed to And this tuple is supposed to be exactly these vector of partial derivatives. Which are the kind of properties that we want to study? So, the first property that we want to study is soundness. So, is it always the case that whenever I take a vector in the differentiability domain of the function, grad f actually really computes an approximation of the partial derivatives of the function, of the gradient of the function. And well, it is well known. Well, it is well known in AD that some programming primitives breaks some S. Okay, so there are some mistakes. Not always we compute the correct gradient, but this is not so bad because actually the set of possible errors has total bag measure zero. Okay, so there can be some mistakes, but if you take the inputs of your Of your function at random from a uniform distribution, the probability that actually you take exactly one input vector where AB fails is zero. So we don't care very much about this kind of problem. Okay, so we have what we call a kind of almost everywhere salmon. So this was well known by the AD community since the 70s. What we did was to prove this result in these four. Result in this formal system coming from PCF, so from a high-order Turing-complete language. But let me try to explain where is the problem with an example. So here we have a simple program. There is a silly way of computing the identity. So you have a branching, you take an input, x, you test, you test if it is equal to zero, you return zero. Otherwise, you return your input. So of course, So of course, semantic extensionally, this program is equivalent to the identity. So from a mathematical viewpoint, it's gradient, this is derivative, it's just one everywhere. While if you apply the transformation that are defined by the AD algorithm, you can see that the grad of a branching is more or less, okay, I'm a bit imprecise there, the There, the conditional of the gradient of the two branches. Okay, and then, of course, in the then branches here, we are computing the gradient of a constant function, so it is zero, so we get something like that, which is almost equal to one, but for zero. Okay, and zero is an example of problem. But of course, this is a simple example, but then the question is: what happens when we add fixed points, when we add Lump abstraction application and all the primities that are expressed in PCF. And well, the result remain the same. I mean, we can prove that if you take a term of PCF of first order, well, the set of vectors in the differentiability domain in F such that the Grade transformation. And the grader transformation does not compute the gradient. We call it the failure of f, is negligible. Okay, it's total Lebanon is zero. It might be uncountable, but it is negligible. And in order to try to formalize the theorem and prove it, it was not so trivial to extend the original result known for a basic imperative language in the In the and was a result given by Joss in the 70s for a basic while language. In order to try to generalize, to get this result, we had to give, in some sense, a more precise characterization or geometrical characterization of this set of errors by introducing a notion of quasi variety. So we said that this set of errors is a quasivity, and what is for other Is a casivarity, and what is for us a casivarity? So it is an ad hoc definition. It is a subset of a countable union of the zero sets of maps which are given by the basic functions that you are introducing PCF. So, if you remember, I told you, we consider PCF extended to real numbers. So, you add your numerals representing your real numbers. Representing your numbers, then you add a set of basic functions. Well, the errors that can be generated by any program generated by this language are just a subset of cantable union of zero sets of these basic functions, or of composition of these basic functions. And of course, in order to go from cadivarity and to conclude to negligibility, you have to add some To add some hypothesis on this set of basic functions. And the hypothesis is that it forms an admissible clone, meaning that all these functions should be, the basic function that you consider should be continuous on the domain, and the zero set, if not identical zero, is negligible. And that is trivial going from calcivarity to negligibility. And just I wanted to underline that these hypotheses are fairly not at all irrestricted. Are not at all restrictive. In particular, even if the basic functions of your language are continuous at the domain, you can introduce non-continuous functions just by using the standard programming primitives of PCF. So for example, here we have an example of a function which is not continuous, which is not differentiable in zero. Okay, this is an example of a result we can have by having Can have by having such a theoretical approach to automatic differentiation. And I would like to give you another one, this time a kind of quantitative result. So we can compute the gradient, great, but how we are, how it is our what is the complexity of what is how efficiently okay. How efficiently? Okay, so actually, AD has different ways of transforming a program F into a program grad F. And it has mainly two ways. One is called the forward propagation, and the other one is called the backward propagation. So in this talk, I will write simply GradF when I will state a property that hold for both of these two transformations. Of these two transformations, like almost everywhere soundness. But if you wanted to speak about complexity, you need to make a distinction between these two transformations. So what we have proven two years ago was in fact a result that is known for AD algorithm, but now we have extended that proof to algorithm. To our version that was purely functional and expressed in effect-free extension of Lambda calculus. And it is that the forward propagation gives us a program that computes the gradient in time which is n. Time which is n times the runtime of the original function. Okay, so where n is the number of the dimension of the domain. And on the contrast, the backward propagation computes the gradient in linear time with respect to the runtime of the original function. And this is due to the fact that we have a function which has a A function which has a scalar codomain. In the case the codomain has dimension m, we will have here a runtime which is in O M times the runtime of f. So in deep learning, as I told you before, this f is a loss function. So usually it has a huge n and it is as a codomain just scalars. So this is the reason why usually So this is the reason why usually you see in the deep learning frameworks always use the backwater method as in the example I gave you at the beginning of the talk with this piece of PyTorch code. This is another example of a foundational result we can have by expressing this algorithm in such a theoretical, in such a formal Such a theoretical in the formal setting. What about importing new tools? So, in order to do that, I have to go a bit more in the details. So, actually, the two transformations, as we have defined, okay, so now until now, we have presented things that are known and our contribution was just to try to restate the results in a purely functional language. So that they were mainly known for imperative. Mainly known for imperative languages. We stated them for PCF. Now I change a bit the perspective because now I will take a precise definition of a precise way of encoding the AD algorithm in the simpler-type lambda calculus. So the two grad transformations are actually defined on the top of a more basic transformation that is this D. Transformation that is this operator, okay, and both in the forward and in the backward version. And here is the warning that I have to underline. This D here should not be confused with the D that you find in differential under calculus, for example. It is the derivative in the case, it is related to the derivative in the case F is a first order. A first-order term, a numerical function, but if f is a piece of is a generic term of PCF, so this D is commutes with all the programming construct of PCF, so if D is a generic term of PCF, the meaning of D is not very clear. So it's not at all the derivative of a higher-order problem of PCF, in particular. PCF in particular. So how it is defined is T? Okay, so the idea of D is just to turn the chain rule into a compositional look, in a compositional program transformation. So the idea is that you have your program F and you would like to define a D of F. This program F is very big. It's just a composition of some smallest pieces of code. And you would like to define a D of F as Like to define D of F as the composition of D applied to these small pieces of code. In particular, the basic pieces of code that you can have are the basic function of a real number, and the basic programming primitive that you can do in the functional programming is composing functions. And of course, from mathematics, we are able to define the partial derivatives of a composition of function thanks to the chain rule. So here we have the partial derivative of The partial derivative of a compositional function out from the but the problem is that this definition is not compositional because here we in the right-hand term of this equation we have the partial derivative of the components of the composition but also the values of the inner function. So if one wants to turn this rule into a compositional transformation, you have just a two instead Transformation: You have just to, in some sense, to transform the basic data type of real numbers into a pair of two values. One value, this x here, is carrying the original values of the function, and the other value, this red x here, is carrying the partial derivatives of our intermediate computation of the gradients. Okay, so if you want. Okay, so if you want to so this D transformation acts at the ground level by splitting the values in two parts, one which is the original value and the other one that should bring, that should in some sense record the intermediate computation of the gradient. If you wanted to use an ID terminology, To use an ID terminology, one call this blue part the primal and this red part the propagator or the cotangent in the case of the forward mode propagation. Okay, one specificity of our approach is actually to be able to type this kind of object. And so we are not the only one who gave a typing definition of this transformation, a typing setting for. Transformation, a typing setting for this transformation, but we use the linear logic types, and I will explain why in a while. So, in particular, the primers have the ground type, as expected, while the propagators, the type of the propagators depend on which mode of IDE we are using. The forward mode mainly is just the tuples describing the gradient we want to compute. And the backward mode is a kind of continuation. So, it's a function that the way. Continuation. So it's a function that waits for a scalar in order to give that gradient. And here you have the definition of D when it acts to a basic function of your language. So imagine that a G is a multiplication of sine or any basic function you introduce to your language. What is a D of this basic function? Well, it is a pair. The left component of the pair is just the standard computation. And the right component, well, it depends from the mode of From the mode of the IDE transformation we are using. In the case of formal mode, it's just the computation of the application of the chain rule, where we have replaced the inner functions with the primers and the derivatives of the inner function with the propagators, giving the right projection. And so that is completely standard and quite natural. And what about the backward mode? Well, we have Backward mode, well, we have more or less the same stuff. It's just that now the propagator becomes a function that takes the partial derivatives of the outer function. And then we transform this application of the back propagator to this multiplication also as a kind of continuation that will wait the computation of the previous partial diagnosis that will arrive later in the. In the backward mode. Okay, so here we have an example of this D transformation for multiplication, but this is not important. I don't think I have much time. So what I wanted to underline is why actually the backward mode should be typed with in our setting with the linear type and not just With a linear type and not just with an intuitionistic type, as it would be standard in functional language. Before going there, let me just underline the fact that this definition is purely functional. So you see, there are no memory references, no exception, no effect at all. Okay, so we are just using lambda abstraction. Just using lambda abstraction, you see how natural for the backward mode is to use lambda calculus and applications, and then the basic operation you have over real numbers. But what, sorry? Two minutes. Ah, okay. So let us go, let us conclude. So why linear implication is essential? Because if you apply these backward, as I told you before, the backward mode should be. the backward mode should be linear, the runtime of the obtained program should be linear with respect to the runtime of the original program. Now, if you apply the transformation as I give you before, actually you are exponential in general. So let us see the problem with an example. Here you have a Python program that takes two inputs, make a subtraction and multiplication, and then the sign of the result. If you apply the transformation that I gave you before, Transformation that I gave you before, well, you get a program like that one. So you see here that the input has been split into the primal and the propagator of the first input and the primal and propagator of the second input. And you see that all the sub-expression composing this F has been transformed into pairs. Here are the primers associated that are the original function you have in the program. And here you have this back propagator that are the lambda. Propagator, that are the lambda. Now, the problem is that in this programming, we have a variable that is used several times. So, you have a contraction. So, you have a result that is used several times. And that means that in the transport net program, you have a back propagator that appears several times. Now, if you try, so if you compute the if you compute this program D of F is able, of course, to compute the gradient of F on some inputs, but if you But if you apply the standard operational semantics of Python, for example, you will see that you will have to duplicate this propagator twice in order to apply to these two occurrences of the bed propagator associated with zeta one. And this is a problem. Okay, this example is not a huge problem, but I can design some more involved example. You can find the details in the image. You can find the details in the paper that I mentioned at the end of the talk. And with more involved examples, you will have some B of F whose runtime is exponential with respect to F. How we can solve this problem? Well, we can solve it by remarking that actually these back propagators are added together and we know that they are linear functions, okay? Because they are typed by these linear errors. By this linear error, and because actually they are computing derivatives of a function that we know that there are linear functions. So, we can introduce a new rule by writing a sum of two occurrences of a web propagator as the web program propagators of the sum of its arguments. And so we can solve this problem of a useless duplication that is generated by several occurrences of the same result in the Occurrences of the same result in the original program. And so we can rewrite this program something like that. And this program here is assured to be linear in time with respect to 12f. So then here we have to extend this d operator to all the primitives of PCF and this is done by just commuting with the original construct of PCF. And I don't have time to detail of this, so I can stop here just by giving the details of the Here, just by giving the details of the two papers, where there are the results that I mentioned in this talk. I can stop here, Rika. Thank you, Michola. Let's all unmute and thank our speaker. Thank you. Are there any questions? Remember, please hit the raise hand button if you have a question. Have a question. Okay, so thanks again, Mikola. And we will, oh, sorry, before that, the organizers would like me to announce that if you are a speaker, you have been sent to 