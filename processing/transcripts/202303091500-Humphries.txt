Okay, let's start. Um, three o'clock. So I'm very happy to introduce, I think, the last speaker of the week. I cannot believe the week is passing by so quickly, but I'm having a good time and I hope so are all of you. So, Chung Lee, Tom Fried, from McGill. So, I really like the blood production talk, you know, intro talk that he gave. You know, intro talk that he gave on Monday. And I think there's more coming on Thursday. So I'm interested in that, you know, because it's in multiple myeloma and diabetes, what I'm more interested in. But now I'm just talking about delays in mathematical physiology, something more general and basically everywhere. If you want a control system, that's what you have. And I would love to learn more. So thank you, Tony. Thank you very much for the introduction. And thank you also for the invitation to be here this week. I've had a great week as well. Great week as well. So, we were asked to give overview talks on sex differences in our area of math or in our area of research, and I didn't really have any. And the people that chose to be in my group this week all were interested in delays. So, I thought some of the rest of you might be as well. And if not, I'll just talk to my group. So, I thought I'd give you an overview of how delays arise in mathematical physics. How delays arise in mathematical physiology, and the other thing I said in the abstract was that there's this competition or there's this tension between the analysts who want to do everything in banach spaces and use all this notation that even I can't understand. I've been working on this stuff for 20 years, and the need to make the math understandable, right? So, you know, you've got three levels of Three levels of math. You've got kind of what the analysts do, what we can do, but then even what we can do, we need to be careful when we present that to the biologists. So I've learned, you know, I've become a, I used to be a numeric analyst, now I'm becoming a real applied mathematician. And I've learned that the secret to doing good science is to use the smallest amount of math possible to solve the problem. Don't ever use any more math than you need to. Ever use any more map than you need to because all you're doing is diminishing your audience. I mean, like the quant size of your audience, not now I right, okay. So, okay, so delays. So, delays arise a lot in science and physics and engineering. They're often due to transport, communication time, processing time. And in engineering, they're often very neatly delineated. They're often very neatly delineated, right? So, if you send a space probe to Mars, there's a communication time to send the signal, get the signal back. There's an amount of time it takes to process the signal as well, and all of this stuff. Now, when you click the right button and point it in the right direction, you get to the next bit. Because in physiology, everything gets mixed up. And so, your delays are often a blend of all three. So, a hormone or antigen must be produced. Or antigen must be produced, then it has to be transported to a receptor. And when it binds with the receptor and gets internalized, that generates a signal. So there's production, there's transport, there's processing all mixed in together. Maturation and incubation delays are often significant. And also delays occur at many scales, from you know, they're in sub-cellular processes all the way up to population. Of processes all the way up to population level processes, and you have to decide what you're modelling and what delays are important for you. And it's a modeling choice to incorporate a delay rather, yeah. So what we often do is we incorporate a delay because we don't want to model all of the details of that Jackstat signaling process or whatever that's leading to some. That's leading to some signal being produced. So you have a cascade of cytokines doing things, and time tour later something happens. I just want to know time till later roughly what happens. I'm too far away from this, right? Am I pressing the wrong button? You want me to move it? No, I can do it. I'm going the wrong way as well. I think it's this button, it's not very sensitive. I think it's this button, it's not very sensitive. Right, there we go. Okay, so let's have some examples. So, here's a subcellular process. If you have an operon which is transcribing and translating mRNA, so there was an ODE model of this due to Goodwin in the 1960s. Of course, translation and transcription takes time. So, there was a delayed version of the model produced in the 70s and 80s, and recently. And recently, we have added state dependency to the delay by introducing a threshold delay. So, if you imagine a strand of mRNA being translated or transcribed, there's a certain length A that needs to be done, and you do it at a velocity V. So if you finish transcribing at time t, you start it at some time in the past, where that time in the past is the integral of the velocity over the length of time. Of the velocity is over the length of the strand, and so you end up with this type of threshold. Burns and Tannock described the genome cell cycle model for the cell division that goes back to 1970. Already by 1970, Already by 1978, Mike Mackey had formulated this as a delay differential equation. So here you have kappa, the stem cells, which are differentiating into more mature cells. And then at some rate beta, they enter into this cell cycle here. And then time tour later, they exit the cell cycle. And there are roughly twice as many of them, minus a small amount that die during the process. Process. So that is the Burrs-Tanner cell cycle model. It actually can produce very interesting dynamics. I wrote a paper on that recently. If we get on to hematopoiesis, which Anita wants to hear about, your body produces more than 10 to the 11 blood cells every day. That's an enormous number. So that's 10 to the 11 of those burns, tannic cells. To the 11 of those burns-tannet cell cycles per day, and each one of those burns-tannet cell cycles involves a lot of proteins being synthesized. That's the Goodwin model as well. So, if I put all of that together, I've got 10 to the 20 differential equations with just as many delays, and it would be hurry. So, if I want to model the production of white blood cells, I want some kind of macro population scale model, and here's one of our Model, and here's one of our models of white blood cells from 2016. In fact, this is not all of the model, this is just the stem cells, the mature neutrophils in the reservoir, and the circulating neutrophils. And most of this is driven by this cytokine G, which is a granulocyte colony stimulating factor. And I haven't included its equation. And there are various delays involved in this model as well. And I'm not going to go into full details of all of those. You might have noticed this ratio of V terms here. It was also in the Operon model as well. We'll get to that in a minute. But before we do that, I want to show you an application of this model for the neutrophils for the white blood cells. So this is data from CHOP14, which is a chemotherapy protocol. Chemotherapy protocol, which involves giving a cytotoxic drug to kill the dividing cells to tackle your cancer. Cancer is really hard to monitor, so I don't do cancer. But what I looked at instead was the side effect of the cytotoxic drug killing the precursors of the white blood cells, because that's what they're doing, they're killing dividing cells. And often that's actually the dose limiting for the therapy. So you have to stop the chemotherapy. You have to stop the chemotherapy because the number of white blood cells goes very low, and you get into neutropenia and you get sick. So, this is the data, and then I know it's because I've put my glass of water in front of it. This pink line is not a fit, this is just simulating our model, including. Our model, including the cytotoxic drug killing the neutrophils, and we think that's pretty good. I mean, it should be pretty good because we have the cytotoxic drug and then we have addition, you know, exogenous GCSF dosing to stimulate the production of white blood cells. But anyway, we were really pleased with this simulation. Now, because the simulation was so good of the protocol, we Of the protocol, we could then change the protocol in our numerics. And we found that if you gave GCSF later in the cycle, you could give less of it even, but you got better outcomes in terms of the neutropenia. So the problem is, is the GCSF stimulates the production of new white blood cells, but it also stimulates the white blood cells in the bone marrow reservoir to be released into circulation. Into circulation. So if you do it too soon, you empty the bone marrow reservoir at exactly the same time as the precursor cells have just been killed by the cytotoxic drug. And now you've got no cells in the bone marrow and no cells coming into the bone marrow. And so you have a problem. So it's quite similar to the situation we were hearing about with the bone this morning. Now, amazingly, this is the only time it's ever happened for me. Happened for me, there was actually clinical confirmation of what we were suggesting. I don't think that it's too soon afterwards for them to have read our paper, but maybe, I don't know. But anyway, they did cite us, which was awesome. I'm gonna go understand it in just so I don't know where the detective is. Nobody told me. I'm pointing at the laptop. Maybe it's over here. Maybe it's over. Yeah, nobody said anything. Okay, so main types of delay. So most people are aware of constant delays. So you have a fixed delay tour, and then you end up with terms like u of t minus tour in your differential equation. You can also have time-dependent delays. You can also have time-dependent delays. So, a tour could be a given function of time, in which case you end up with this, and those also arise. So, yeah, not as often looked at these days as these ones. More interesting are state-dependent delays, where TOR depends on the state of the system. There can be some issues with these. And you can also get some more weird things. You can also get some more weird things like I recently worked on a climate problem with a delayed state-dependent delay. So the delayed Tor2 was a function of the solution u at some time in the past. Got two delays there, one determining the other one. And then you can also have distributed delays. These are the ones which are often the most realistic in physiology, but you avoid them as much as possible because they're a bit more work. So here you would have You would have in your differential equation, you'd have terms where the dynamics depends not on u at one fixed point in the path, but on some function of u over some interval of vase. And then you can get the threshold delays that I was mentioning earlier. So let's go into these in a bit more detail. So the idea here is Detail. So the idea here is you have your fixed distance or maturation size you have to reach, and you want to find out, or you want to define the delay as the time you started maturing, given that you finished maturing at time t. And then all you have then is you have that the delay tor is implicitly defined by this integral where integrating from t minus tor to t of the state dependent velocity or growth rate, if it's match rate. Or growth rate, if it's maturation size, is equal to this given constant A. Now, if V is constant, then this is very simple. You're back to a constant delay towards A over V again. But it becomes much more interesting when V is allowed to vary. We typically keep V bounded away from zero. That ensures that your age is strictly increasing and also that your delay is bounded. That's also an optimum. That's also enough to imply that t minus tau is a monicing function of t, which gets you away from many of the bad things that can happen with arbitrary state delays. So this is a nice property to have. And if you have this kind of threshold delay, which is kind of natural, it happens naturally as well. Now you have to take some care when you model with delays. So suppose I have a differential equation with a constant. Have a differential equation with a constant delay in. So tor here is just A over V. And here is a differential equation coming from a model which was not one of the ones I put on the earlier slides, but it's going to work for us. And we want to be adventurous and we want to go from a constant delay to a stake ended delay. So it would be very tempting just to do this and have nothing happen. Happen. Right, do this. So I change the delay to the threshold delay, and all I do in the model is I say, well, the delay now is very. I've written it as a function of t here because I want to keep out of the planet spaces, but really as a function of u of t over the whole time. Okay, so if you write this down, it's wrong. And the reason why it's wrong, you should think about when you get home and you're waiting for your luggage. You're waiting for your luggage to come off the conveyor belt. So imagine you add bags to a conveyor belt at your favorite or least favorite airport at a constant rate and the conveyor belt goes at a constant rate as well. It doesn't matter what it is. Then if I put the bags on at one a second this end, they will fall off the other end sometime later once they arrive one a second as well. Okay, more realistically, if you Okay, more realistically, if you put them on one every five minutes, they come off the other end once every five, one every five minutes. But now we can be, we can have some fun with this, right? What happens if I put the bags on one every minute and then before they get to the other end, I double the speed of the belt? Well, now they're going to fall off two every minute until you get to such time as the ones that were put on at the highest speed start. That were put on at the higher speed, start falling off, and then it goes back to one a minute. So, what this means then is that when you do the model, you have to have this correction term for the production. So, when you have the threshold delay, the number of cells being produced ends up being multiplied by the ratio of the velocity of the belt at the time when they're falling off divided by the velocity of 1A. Lost here one day. I think it's the button next to which is very good. Right, here we go. Okay, so another thing that's interesting: if you have this threshold condition, if you differentiate the threshold condition just using Leibniz rule, if the ratio of the velocities is positive, velocities is positive, then it turns out that this is the same thing as d by dt of t minus torr of t, which gives you that this is going to be a monotonically increasing function of t, which is what I said before. So now I've just shown it. The other thing that's interesting is I can do this derivative and I get 1 minus d by dt of torr of t. So if you take this one equal to this one, you actually get a differential equation for the delay, tor. So what you can do So, what you can do is, if you don't want to have to solve some kind of integral problem at each step to figure out what the delay is, you can replace this delay by this differential equation. Now, you have to be a bit careful when you do that because you've differentiated so some information has been lost. So you have to be careful to use the right initial condition. So, you have to satisfy this with the initial function to start with at the beginning. And then, what we do is we use this a lot to do the We use this a lot to do the solution, and then once we found the solution, we go and check these integrals just to make sure that nothing went wrong. It's possible to get some drip through the solution. Okay, so in a 2016 paper in BMB, we derived this velocity correction from H-structure PDEs with careful treatment of the boundaries instead of this simpler argument. Argument. This velocity ratio appears in problems. So, some authors neglect it, they don't realize they need it. But as far back as Papers Smith in 93, I found it really. Okay, so my original training was in numerical analysis and dynamical systems. So, I often analyze my differential equations as dynamical systems. My differential equations as dynamical systems. So I want to think about how these delay differential equations behave as dynamical systems. And the thing to be aware of here, of course, is that for a unique IVP solution of my differential equation with a delay, if I want to solve for t greater than or equal to t0, it's not enough to tell me the initial point u of t naught. Because when I start integrating, Because when I start integrating, I'm going to need values of the delayed solution. And as I integrate over my time interval, I'm going to end up needing all of the values between T0 minus score and T0. Which means that the initial data you need to specify is a function over this time interval. And in a dynamical system, your phase space is basically the space of the initial conditions or the initial. Space of the initial conditions or the initial functions. So that means that as a dynamical system, the phase space is not Rd when u of t belongs, but it's this space of functions defined over a time. So typically the analysts use this notation, they use u sub t to describe the functional at the time t. functional at the time t and basically u sub t is just a snippet of the solution going from u of t back to u of t minus tau. Now in general this thing is not differentiable when t plus theta is equal to t naught because you choose your initial function phi to be whatever you want and then your solution could go off a different direction and there's no reason why u dot of t and phi dot of t have to agree at t zero. Have to agree at T0. So usually the solution is not differentiable, or this segment's not differentiable at this point here. And so you end up with a phase space of continuous functions. Now, of course, the space of continuous functions includes all the polynomials, and so this is infinite-dimensional even for scalar problems. Now, you can look at that in two ways. Now, you can look at that in two ways. Infinite dimensions, closed and bounded, is no longer equal to compact. Ah! Well, we're not going to do any Banach space analysis anyway, so let's not worry about that too much. Look at it the other way around. If my scalar delay differential equation is infinite dimensional, that means that unlike a scalar ODE, it can have some interesting dynamics. It can have periodic solutions, it can even have chaotic solutions. Chaotic solutions. So here is the Mackie-Glauss equation, which was the first equation basically to show chaotic dynamics in a delay differential equation. And it's very simple. It's actually a qualitative model of blood cell production. So it has a rate of production, it has a loss, and then it has the number of cells being produced is some function of the number of cells you had at some time in the past because it takes. Some time in the past because it takes a certain amount of time for the cells to mature, and then there's a functional that describes that. And you know, if you choose nice boring parameters, you get a steady-state solution that's stable. If you turn up the nonlinearity, you can get half-bifurcation periodic solutions. So, here are some periodic solutions. You get period doubling, and eventually, you get chaos. So, here's a period doubling chaos. So here's a period doubling cascade to chaos. Here is a stranger tractor. And the yellow and red bits you can see are some periodic orbits embedded inside it. Okay, so if I have a dynamical system, let's look at the simple case. If I have a steady state that I want to linearize, well, I'm assuming you all know how to linearize around a steady state. You all know how to linearize around a steady state in an ODE. If you linearize around a steady state in a DDE, it kind of starts out similar, right? So here's my differential equation. If I assume that f of 0, 0 is 0, and I want to linearize around this, well, I'm going to end up with this being the Palstrider F with respect to U at 0, 0 and the one with respect to V, where I differentiate F with respect to its first argument or its second argument. Second argument, the first argument gets multiplied by u of t, the second one by u of t minus 12, and then higher order terms. So you end up with, since these things are just numbers in a scalar equation, you'll end up with your scalar delay differential equation having this as its linearization. And then, wow, what does this mean? Okay, what does this tell me about the dynamics? Well, you do exactly what you always do. If it's a linear equation, Do. If it's a linear equation, the solution is going to be an exponential. Throw that in the equation, and now it gets exciting because the t minus torr term here, when you put the exponential in, gives you an e to the minus lambda torr term in the characteristic equation. So this is where things get a little bit interesting because I don't get a polynomial anymore from my characteristic equation. If I look for characteristic values in the complex plane, I let lambda equals Complex plane, I let lambda equals x plus pi y, throw that in here, take real and imaginary parts. Real part gives me this, the imaginary part gives me this. I can say some things about the solutions. In particular, if I rearrange these so the cos term is on one side and the sine term is on one side and square and add, then you can get a formula for y and you find that all of the roots lie on this curve. This thing inside the square root. This thing inside the square root better be positive, and this gives you an upper bound on x. It actually turns out not only is there an upper bound on the real part of lambda for any characteristic roots, but if you do talk to an analyst, they'll tell you that in fact there are finitely many roots to the right of any vertical line in a complex plane. But in general, in the complex plane, there are infinitely many roots. It's a transcendental equation. Dental equation. So you get this nice situation where you, and I should have had a figure with this, but I didn't do it. You have an infinite-dimensional dynamical system, so you have infinitely many eigenvalues, but most of them are off at minus infinity. So you're not interested in them, right? You're interested in bifurcations, you're interested in ones that cross the imaginary axis. And only finitely many can ever do that. So basically, much of the time, you just look at the interesting. You just look at the interesting bit, the dynamics, and it's finite-dimensional. And the rest of the dimensions are all collapsing to zero as fast as you want, and you can now if you want to do linearization in RD, you can do that as well. It's exactly the same, except you end up with matrices. Let's skip that slide. If it will let me. All right, so let's talk about numerical math. Let's talk about numerical methods. There are IDP solvers for DVE with discrete, constant, and state-dependent delay in MATLAB, Julia, Fortran, or whatever your favorite programming language is. We've been using MATLAB and Julia in my group this week. I've used Fortran in the past. Those of you that have used XPP Auto or MapCon or other things to do bifurcations, that stuff all exists for That stuff all exists for DLA differential equations as well. And the package is called DDBiffTool. And that's a MATLAB suite for continuation and detection of bifurcations and solutions. And I know there are some people here from Lervan this week. This was originally written by a prof in the computer science department at Lervan with its PhD student. Although it's now run by Jan Sieber out of Exeter, and it's still being maintained and extended. Maintained and extended. You want to find those characteristic values we were talking about, and you don't want to deal with these transcendental equations, don't worry, there's good solvers for those as well. Now, one issue though, I've been working more and more with these threshold and distributed delays because I think they're the most realistic in the biological problems. But the standard solvers have all been written for discrete delay, and so they don't apply to these. Laid and so they don't apply to these problems directly. Okay, but as I already said, we can deal with a threshold delay as an initial value problem just by differentiating the threshold condition to get an extra differential equation. And as long as you take care to get the initial condition right, that works really well. And if you have distributed delays, you can often do similar tricks by defining an extra variable. By defining an extra variable and differentiating it to get an extra differential equation, and my students do it all that kind of stuff. Seems like we're not going any further. Alright, okay, so now linearization. With a threshold delay, okay? So linearization is okay for a boring delay. For a boring delay, but people kind of throw their hands up in the air and say, Well, if I have something like this, where are we going to start to linearize? Okay, so I wrote a paper recently, it came out in January last year, it's a very long paper, and there's like 15 pages of appendices of appendices where Hans Otto Walter does the linearization of our problem in Blanach space in some generality that I can't understand. That I can't understand. Here's the same thing in four lines using nothing more than advanced calculus. Okay, so if I want to linearize and I have this, right? So at steady state, the velocity is going to be constant. So if I have steady state u star, then the delay tor at the steady state, which I'm going to call tor star, multiplied by the velocity at the steady state is equal to A. That's all that reduces to. Now let's consider a small perturbation of the steady state. Perturbation of the steady state. And as we always do, we're going to look for a solution where the small perturbation u of t minus u star is epsilon eta lambda t plus higher order terms, which we're going to studiously ignore. Okay, so if I'm going to linearize this, I'm going to start with the function inside the integral. V of u of s is v of u star plus u of s minus u star times v dash. This is just boring data series. Okay, u of s minus u star is. Okay, U of S minus U is this, throw that in. And now A is equal to this at steady state, so that's one way. On the other side, A is equal to this. Now throw your definition of V in here, you get this. And now you just do the integral. This is a constant integral integrated over a constant integrand integrated over a time interval of length 4 of t, so it's just that. If I look at the second term, I have to integrate the exponential. I have to integrate the exponential, I can do that, and then we ignore the higher order stuff. Rearrange a bit, and you end up with this relationship between the delay at time t away from its steady state value being related to the solution. And then you get these extra terms here. And then you have to linearize the, you have a differential equation defining u, you have to different differential, you have to linearize. Different differentiation, you have to linearize that as well. Combine the two, you get characteristic equation, you're done. So it all kind of works out without too much difficulty if you just know a little bit of math. But the nice thing about that is it's not rigorous because we're ignoring the Vaddex spaces, but we get exactly the same. Actually, the first time we did this, we did not get the same answer as Ansel and Walter, because he'd made a slip in his analysis. It was very simple. Yeah, it was a very simple one right near the end, and we spotted it very quickly once we knew it was wrong. But yeah, that was really good. Okay, I've got 10 minutes left, I think, or five or something. So let's talk a little bit about unbounded delays, because these come up a lot. So threshold delays are examples of distributed delays. And let's look at some infinite delay problems. So here is a problem where So here is a problem where I have du by dt is f of t, u of t, and then u over all previous time intervals back to minus infinity. And I have some kernel g in here. And g is going to be a probability density function. It's going to be non-negative. It integrates to one and the mean value is the delay tor. So here the dynamics of U of T is determined by a distribution of all the previous ranks. The previous labs. Okay, so you cannot integrate such a problem using off-the-shelf numerical software. We should also, if we're going to consider this, we need to choose a particular probability density function. So the one that most people use for the reason that will become very clear when we eventually go to the next slide is this, right. Is this right? Okay, so this. Oh, I finally found a graph, it doesn't work right. So my lines here are too narrow for this. But what I have here is I have this function here, the blue one, which corresponds to 2. And then as the p gets larger, the functions are starting to coalesce and converge to a delta function around tor equal to 3. So what I've taken as my probability density function is. Taken as my probability density function is the gamma distribution, which is parameterized by this power, well, it's parameterized by several things, actually, A and T. A and P. We're going to specify the mean delay to be tor is P over A. So if I fix Tor, then if I move one of these, I have to move the other one. So basically, I get one parameter to play with. And so what I did here was I was varying Tor, but I was also varying A to keep the, so I was. varying A to keep the sorry I was varying P but I was also varying A to keep tor fixed okay and the gamma distribution is called such because this capital gamma at the bottom is the gamma function and the gamma function is just a generalization of the factorial function. In fact, for an integer n, gamma of n is n minus 1 factorial because the people defining the two things didn't real definition. But the interesting thing about the gamma distribution But the interesting thing about the gamma distribution is it does not require an integer to evaluate. So it's also defined when p is a real number. And the Erlang distribution is a special case of gamma when p is an integer. So if I have one of these gamma distributions, it has a couple of nice properties. The first one is if I take the limit as p goes to infinity with tau fixed, then With tau fixed, then the standard deviation here goes to zero, and so the gamma distribution goes to a delta function. And if you have this in your delay differential equation and this goes to a delta function, you just go back to a discrete delay problem. So you can think of your discrete delay as the limit of this problem as you take the power p to infinity. The gamma distribution also. The gamma distribution also has this interesting differentiation property that if you differentiate the probability density function with a power p, you actually get that it's defined in terms of the density function with power p minus 1 and p. Basically, you just have to use the product rule on this. It's a bit different when p is equal to 1, because when p is equal to 1, the t term is not there, and so it's just defined in terms of it. And so it's just defined in terms of itself. And that property means that if p is an integer, this is basically a closed system. So if I start with p some integer, then I get the function related to itself and the next one down, and then I keep going all the way down to get to p equal to 1. This is really useful if I have a differential equation. A differential equation with one of these distribute delays. So here's a distribute delay differential equation. Okay, and what I'm going to do is I'm going to get, is I'm going to say, well, my collaborators don't like infinite delays. Let's make this disappear. So you make it disappear the way we always do in math. We just define a new variable to be it. And now it looks nice. So Tn is going to be defined. Tn is going to be defined by this when I have n in here, but I'm also going to define all of the tj's for j going one up to n to be the same thing, but just with a small power here. And the reason I do that is because of that property we had with the differentiation. If I have this now as my differential equation, well, I can differentiate these integrals by differentiating through the integral spine. And when you do that, you find that the tj is. That you find that the tj are all defined in terms of itself and the next one down, except for the one at the bottom, which is defined in terms of t1 itself and a. So when n is an integer, this is a closed system. And so we've reduced our horrible looking distributed delay differential equation to an ODE. So if n is finite, which isn't an ODE, this is an n-dimensional ODE system. And now you can kind of see. And now you can kind of see what I was telling you before. When I take n to infinity, I go to my discrete delay problem. So this ODE system kind of goes to the discrete delay problem in the limit as I take the dimension n to infinity, which kind of makes sense because the delay differential equation is infinite dimensional. This is finite dimensional. So this linear chain technique was first called that by MacDonald in his 78 book. Interestingly, the earliest version of Interestingly, the earliest version of it appears in this paper by Vogel, which presented a kind of height of the Cold War time rates around the Cuban missile crisis. And they had this conference in Kiev, and they got all of these American mathematicians to go. There was even a young postdoc called Steve Smal there, and the luminaries of the time were all there as well. So what goes around comes around again. What goes around comes around, I guess. Although none of us seem to be going over to Russia for conferences at the moment. Now, the ODE is a transit, it's basically a transit compartment model. These go back 98 years to McKendrick, in his paper, one of these transit compartment models. And so, distributed delays are often obscured by writing them directly as that set of ODEs. Now, there's a danger in doing that. Now, there's a danger in doing that because when people do that, they lose sense of what the delay is, the average delay, and what the variance is. And I've seen papers where that's led to issues of misinterpreting the variables. The other thing that's interesting here, of course, is you can only have an integer number of compartments. But if I have an estimate of the delay and estimate of the variance, And estimate the variance, there's no reason to suppose that the tor squared over sigma squared, which is n, should be an integer, right? These are both going to be real numbers. You divide real numbers by each other, you get a real number, not an integer. So typically, when you do the compartment models, if they work from data, they have to round to an integer. Whereas if you go directly to the distributed day differential model, you can work with the real number. You can work with the real numbers. Okay, I'm going to skip that because I'm out of time and just say at the end. So, there are some papers I've written on various issues of this. Delays allow to simplify physiological modeling because I'm going to skip modeling some really complicated process. I just want some function that kind of gives you the output, time to all later. They define infinite dimensional dynamical systems, but these are tractable numerically and theoretically. Are tractable numerically and theoretically. Even scalar delay differential equations can display some very interesting dynamics if you want it to be. And equations which depend on distribution of past state values or whether the value of the day's street depends on the state of the system are both interesting and tractable. And you'll notice I said nothing about sex in this. That we've done a mathematical model. We've done a mathematical model of erythropoies, which is sex and gender-specific, and we'll be presenting that tomorrow morning. So, I'm going to save all that stuff for tomorrow. And thank you very much for listening.