Pleasant experience. It's been great to see old friends as well as meet new faces in formal geometry. So yeah, at the core of today, I'm going to be talking about geometric inverse problems. So as a broad introduction, given some quantities, some collection of quantities, some function on a manifold, a Riemannian manifold, can you recover g from those quantities? So I'll give a few general examples. So maybe the most classic one, can you hear the shape of a drum? Can you hear the shape of a drum? Which mathematically means: does the spectrum of the Laplacian on a manifold actually determine the metric itself? So this was answered as no in 1964 by John Milner. He constructed two 16-dimensional tori, which were not isometric, but they were isospectral. They had the same eigenvalues. People still posed the question in lower dimensions. So then finally, in R2, Gordon Webb and Bolberg showed in. Gordon Webb and Holbert showed in 1992 that there are kind of two families of polygons in the plane which have the same spectrum of costume, but they're not isometric. To be isometric as a subset of R2, you actually just have to be the same up to reflection, rotation, and translation, and you can see that these are not. So let's consider a different problem, maybe using distances. So suppose M is a manifold with boundary, you could ask if Boundary, you could ask if I tell you the distance between any two points on the boundary, can you actually determine the metric itself? So, a very interesting question maybe comes from some sort of echolocation or some sort of X-ray transform motivation. And the answer is yes, at least locally near the boundary. This is work due to Stefano, Ullman, and Bashi. And so, maybe if you've never seen such a result before, it's kind of surprising. Knowing distances is kind of a Knowing distances is kind of a weak quantity, but somehow knowing them between any two points gives you enough information. I'd also like to talk about kind of a version of these problems using minimal objects. So maybe instead of eigenvalues of the Flaution and eigenfunctions, you could consider an analogous quantity for the area functional. So suppose you have a metric on S2, and you know that each simple closed geodesic has length. Each simple closed geodesic has length 2π. You might guess that the metric is just a standard bound metric. But the answer to this is actually no. And in the early 1900s, Otto Sol constructed these families of metrics, which really look like this. They just come from drawing a certain curve in the plane and then rotating it around the z-axis. And all the simple opposed geodesics have length 2π despite not being the same shape. Okay, and then I won't go into this deeply, but there's I won't go into this deeply, but there's kind of a similar question for these things called p-widths, which are kind of like eigenvalues for the area functional, and they arise as sums of areas of minimal surfaces. So I have some work on this, kind of a similar isospectral problem, and there's also work by Ambrogio, Marcus, and Mephis. So I won't talk about it now, but feel free to ask me later. Let's start with some positive progress, though, in the setting of minimal surfaces. Though in the setting of minimal surfaces. So in 2018, Alexaki, Spielhowski, and Nachman had this very interesting result. So they considered B3, you know, manifold of the boundary compact setting, and they suppose that near the boundary, so some open neighbor of the boundary, there is a foliation of that neighborhood via minimal surfaces. Given this foliation, which has to happen kind of at every point near the boundary, it turns out that if you know all of these areas, Turns out that if you know all of these areas of those minimal surfaces and the foliation, you can actually determine the metric globally. So, this is a very strong result, especially since the foliation only occurs near the boundary. There are a few caveats. So one, it's kind of a perturbative result around the Euclidean metric. So G has to be close to the standard metric in some C3 sense. Essentially, they need this to invert some sort of DRS shaded annoyance operator for the Japanese services. Yes, Steve? Yeah, Steve. Sorry, just trying to understand. Why should I not think that I could add a compact variation of the making far enough inside and it wouldn't change it? I think it's something to do with the abundance of the minimal surfaces. I don't know the exact details. There are further restrictions when you do it globally, but in many reasonable cases, they only get the local result. Not Einstein, just compact setting. Okay, so this is a very nice result, though there are some restrictions. And I've kind of been interested in expanding this. This is also inspired by kind of this ADS-CFT correspondence, which Steve talked about a little bit a few minutes ago. And my goal is to kind of expand such a recovery result to the asymptotic hyperbolic setting. So, in general, I'm interested in this question of when do areas of minimal surfaces determine the metric. Of minimal surfaces determine the metric. But in these conformally compact Einstein settings, these asymptotic hyperbolic, conformally compact settings, we don't have area. We have a renormalized area. So my answer in the asymptotic hyperbolic setting is that the renormalized area of minimal surfaces determines the asymptotic expansion of the metric near the boundary. And again, this is kind of motivated by the ADS-C of T correspondence, where somehow the remote. Correspondence, where somehow the renormalized area represents an entanglement entropy of regions on the boundary. So this is a product of the CFT, which then is telling you something about the bulk metric in the interior. So something about the CFT determines the ADS metric in the interior, but I'm not a physicist, so I won't go too much deeper into that. Okay, if you wanted to think of this more in terms of inverse problems, you could also frame this as the Diarchlet-Neumann map for the The Diertlei to Neumann map for the asymptotic plateau problem that actually determines the metric near the boundary. And why is this? Well, the Diert-Leight-Neumann map for minimal surfaces in a setting actually gives you the first variation of a normalized area. And I'm able to show that if I know the first variation, I can actually recover the metric from there. And then if you wanted to abstract this even further down to elliptic PD, you would think that this is some sort of asymptotically Hyperbolic Calderon problem, right? Revolved Calderon problem, right? So if you want to solve Laplace U equals zero, but U is equal to F on the boundary and recover dear Trillion line return, then that information is equivalent in kind of an abstract sense. So the setting for my theorem will be conformally compact asymptotical hyperbolic metrics. Steve talked about these and Yuju also talked about these on Monday, so I'll try to go through them quickly. Through them quickly. So we have a complete manifold with some topological boundary at infinity. To me, asymptotically hyperbolic means that the sectional curvature tends to minus one as you approach the topological boundary. So here are two examples. This one is coming from general relativity. If you consider the path of a particle with constant acceleration in space-time, maybe you take this, you rotate this around the z-axis, and then at infinity there will be two copies of S1 as a topological boundary at infinity. Topological boundary end of the. So, this is an example of a conformally compact passenger hyperbolic manifold. You could also just consider a non-compact hyperbolic 3-manifold. So, these show that hyperbolic geometry, type model theory. Okay, also another motivation are these Poincaré sign metrics, which, again, I'm very thankful that Steve has talked about these as well as Yaju. So, for me, the motivation of this is determining conformal invariance. Conformal invariance. Suppose you have a closed manifold n with some, again, Riemannian metric. What are the conformal invariants of the metric? In the 80s, Pfefferman and Graham set out on this project that says, okay, given N and H, construct an Einstein filament, a conformally compact Einstein filament. So the topological boundary is at our initial data, and with respect to some boundary defining function, you can restrict the x squared times the original metric to the boundary. x squared times the original metric to the boundary and you recover the original conformal class. Okay, then the Riemannian invariance of M and G, your Einstein metric, actually descend to conformal invariance on the boundary. So this would is a way to find the conformal invariance of any closed manifold. Of course, this raises the question, or such a manifold is called a Plancker-Einstein manifold, as we discussed, but it raises the question, you know, given a closed manifold, can you always find a feeling? Always find a feeling, right? And this is an extremely deep question, and you know, maybe the life work of Alice Chang. Also, I would say kind of the state-of-the-art conjecture that people still believe at the moment is that suppose H has positive Umabi invariant, then there should always be a filling and it should be unique. I believe that's what people still hope. Okay, so again, these are one examples of conformally compact asymptotic. One example is of conformally compact asymptotic hydrofoil metrics. And many people have studied these manifolds. So if you're registered for the conference, especially in person, I tried to check a few words on Congrat metrics. But then I'll at least emphasize Ed Witten, Anderson, Alice Chang, and Paul Yang, Jia Ching, as people whose work I've read a lot of. But y'all are up here too. All right. You say that the conjectures of your positive. Right. You say that the conjecture is if you're positive Yamabi invariant on the boundary, then you can always find with it. Uh yes, if H has positive Yamabi constant. Is it the counterexample of Gaussian? I was describing the topology I'm concerned. Right. Right, so you could ask, like, what type of filling? Like, does there exist a single manifold, or can you do it with a particular topology structure? Yeah, lots of questions in this area still, all very hard. All very hard. Okay, and then as UI Ju talked about on Monday, two examples of concrete anti-metrics are ADS short shield and as well as hyperbolic space, which will kind of be our recurring example today. So just getting into the definitions a little more formally, what does it mean to be conformally compact? We have a function x, which is non-negative on the compactification, and it satisfies these three things. These three things. So it vanishes on the boundary, it defines the boundary. As Steve said, this metric g bar x squared times g is a metric on the whole manifold, the compactified manifold. And for me, it's very important that we satisfy this equation. So the norm of dx squared with respect to g bar is 1. So you should really think of x as kind of like a distance function, right? It satisfies the eichenhall equation, and this holds in any boundary. And so, again, as you did on So again, as you drew it on Monday, you take a hypergolic 3-ball and you consider x is equal to 1 minus r over 1 plus r. This is a nice example of a conformally compact manifold with a special boundary defining function. We can also refine a definition of asymptotically hyperbolic. So as in Steve's talk, there's a splitting of the metric. So in essence, it looks like dx squared over x squared. So kind of the salient direction in hyperbolic. Kind of the salient direction in hyperbolic space, plus a bunch of tensors acting on the boundary direction. And given such an expansion, we'll define the conformal infinity. So if you have an expansion like this, the conformal infinity is just a conformal class associated to this lowest order tensor, omega naught. Again, it's a tensor, it's a metric on the boundary. And in general, you can get it via this procedure. So given some asymptotic hyperbolic metric, Given some asymptotically hyperbolic metric, it always uniquely determines a conformal infinity. And on the hyperbolic 3-sphere, the conformal infinity is just the conformal class of the round sphere minus 2. And so with such an expansion, if you remove the odd terms, you can talk about our normalized volume. So we've seen this. And this form certainly shows up in Coggrind's same metrics of high order. Hot grinds and metrics by order, but just looking at maybe a metric which is units of order M. This was discussed in work by Bahald, Mazeo, and Wolgar, and it'll be the setting that I'm working in. But this is just to say if I have an M-dimensional minimalistic manifold, even to order M, then I can define some sort of a normalized volume via a sequence of cutoffs. So we've talked about this a little bit, but here is a picture. So you can imagine this happening in So, you can imagine this happening in, say, the half-plane model if you want. y is my minimalist manifold, and I have some boundary defining x. I look at all the parts of y that lie more into the interior, besides x equals to epsilon, and I compute some sort of Laurent expansion in terms of powers of epsilon. So, I want to throw away all of these divergent terms. In this case, it's only one divergent term. And then I send epsilon to zero. So, I also throw away all the o epsilon terms. So, this constant. All the O epsilon terms. So, this constant term that remains, that is the renormalized area. And as Steve mentioned, it's independent of your choice of x. So, as long as x is a special boundary defined function, you get the same answer. Okay, let's do an example. So, I think UEJU computed the renormalized volume of a Punker of hyperbolic 3-space, or maybe 4-space. But I'm going to do the renormalized area of H2. So, this is the minimum. Of H2. So this is the minimal disk lying inside H3. And just using polar coordinates, it's really a computation. So again, this is our choice of boundary defining function. And you try to expand, convert between r and x, and expand the integral of all the points lying or such that x is greater than epsilon, you get some sort of divergent expansion, and you throw away this one over epsilon term. So the renormalized area of units is lying inside H3. Of units is lying inside h3 is minus 2π. Okay, and this fact will be important for us later as well. Okay, so instead of just the disk, you might want to do it for other minimalist manifolds of these Ponker-Einstein conformally compact asymptotically hyper-log spaces. And in 2021, I did a lot of work about the regularity of such minimal submanifolds. So generally, if you give me some bound, some sub-manifold of your Sub-manifold of your boundary, and it's sufficiently regular. I was able to show that, you know, well, there's always a minimal filling. That comes from kind of some moduli theory that I did. But I was able to compute a polyhomogeneous expansion of the boundary. And in particular, I'll emphasize that this worked in high codimension. As long as the C-manifold is even, our work was to show that such an expansion, such weak regularity holds for high codimension. Regularity holds for high co-dimension. And this is in contrast to kind of co-dimension one, where there was a lot of work done by Lin, Juan Sprat Sapiel, and Sonagawa. So they kind of used more classical PDE methods attuned to maybe a degenerate elliptic system in codimension one. But here we really had to use microlocal analysis because the minimal surface equation in high codimension becomes a system. And handling a degenerate elliptic system is much harder. Is much harder. Oh, sorry, so high codimension, as long as m, as long as the sub-manifold is even-dimensional. So it could be 4 inside of some m7 or something. Yeah, so here, Y solves our asymptotic plots problem. If you give me a boundaries to manifold, there's a filling, and I can tell you about the regularity of the minimal filling near the boundary. The regularity of the minimal filling near the boundary. Okay, so having defined a normalized area of submanifolds, I also refer to it as volume of submanifolds. I also want to talk about some of the significance of this quantity. So for me, one motivation is this notion of entropy. So in 2020, Jacob Bernstein introduced an analogy of entropy for surfaces, microbial space. So if you do mean curvature flow in RN, the entropy Flow in Rn, the entropy is often defined as you integrate over your surface the heat kernel at time one. And Golding and Nicozzi had a lot of work to show which surfaces are stable for this. They give a very nice classification. So Jacob defined a similar quantity in hyperbolic space. It's what you think. You take the heat kernel in a hyperbolic space and you integrate it over your submanifold. And then he showed that this entropy is always, or minus 2π times this entropy, is always bounded below by. Is always bounded below by the renormalized area for just 2D minimal surfaces. But if you care about mean curvature flow and hyperbolic space, which I think some of you do, then you might care about renormalized area. There's also an analogous monotonicity formula for minimal submanifolds in hyperbolic space. So you compare this ratio of how much volume of your minimal surface lies inside a ball of radius R over kind of the standard volume. Kind of the standard volume of a ball of radius R hyperbolic space, and this quantity is non-decreasing. Moreover, when m is equal to 2, you can take the limit as r goes to infinity, and minus the renormalized area provides an upper bound. So if you think about mean curvature flow or minimal surfaces in hyperbolic space, you might care about the renormalized area. There's also this connection to type 2b string theory due to Ed Witten, and as I said, And as I said a few slides ago, the renormalized area of y kind of represents the entanglement entropy of the region it bounds. And so this is a big paper due to Ryu and Takeanagi, and I think 2006. But if you care about conformal geometry or topological invariance, then you might care about this proposition, which is kind of a Gauss-Bonnet formula for a normalized area. So this is work due to Alexander. So, this is work due to Alexaki Senizeo in 2008. And essentially, if you have a two-dimensional surface in a Poincaré-Slay metric and it meets the boundary orthogonally, then you can compute the renormalized area in terms of all these integrals. And so this is topological. This integral and this integral are conformally variants. Often we'll be interested in the case of animal surfaces, in which case h is equal to zero. So the Gauss-Binet formula really tells you that the The Gasponet formula really tells you that the normalized area is composed of some topological quantity plus some conformally varying quantity. Okay, oh, I'm sorry, for notation, so K is my second fundamental form, and K hat is the trace-free second fundamental form, and Wm is the vial tensor on the ambient metric, and we're tracing it over our second fundamental form. Okay, so let's focus on the case when M is hyperbolic space. Hyperbolic space, so there the ball curvature tensor is zero, and h is minimal, so then h vanishes. And our formula just becomes this. So, even simpler if you're working in a hyperbolic space. And it turns out that there is a global upper bound. So, the normalized area of a 2D surface in a hyperbolic space is always less than or equal to 2π. And the equality occurs in the case that we computed at the beginning. So, it's exactly when your surface is a hemisphere and the boundary is. Hemisphere and the boundary is some round circle. So, okay, maybe you think this is easy to prove since this integral has a sign, but it's unclear how, maybe you prove this if your surface, say, had genus 1 and this integral was quite small. So this bound is actually due to the same paper by Jacob Bernstein, and it was very useful for my work. Okay, so this is kind of the end of the background. This is kind of the end of the background. Are there any questions about things I've introduced so far? Also, what if I think if your boundary curve is at least C2, then the formula should work. Yeah. Good question. Good question. Okay, so I have this very nice Gauss-Binet formula and actually this rigidity phenomena. So this universal upper bound for the normalized area. And I want to leverage this, in particular the rigidity, to tell me something about the original metric when we're not in hyperbolic space. So, how can we use rigidity as well as variations over normalized area to determine the metric? To talk about this, I'll talk about a similar problem, but in the geodesics setting. So there was prior work by Graham, Guillermo, Stefanov, and Almond, and they considered a similar renormalized length functional on geodesics and asymptotic overball spaces. So it's computed this way. And they were able to show that if you know the renormalized length on all geodesics in your manifold, then you can actually determine. In your manifold, then you can actually determine the expansion of the metric near the boundary. So, very, so a result that I would like to have. But there's a caveat. So, renormalized length is not conformally invariant. It really depends on the choice of boundary defining function. If you know about this field, then a justification I would give to you is that geodesics are one-dimensional. And renormalized volume area quantities are often only conformally invariant for even-dimensional objects. Even dimensional objects. So being one-dimensional really helps them. And also, I guess, knowing the boundary-defined dimensional helps them. Okay, but nonetheless, I'm able to extend some of the metric determination results that Grammy, Armeni, Stefanov, and Olman had to the setting of even minimal submanifolds using renormalized area. So, the theorems that I'm going to talk about today. And also, this is a little more difficult because, as I said, renormalized area is conformally invariant. Area is conformally invariant. So we have to work through that invariance. One theorem I have is that if we have a conformally compact asymptotically hyperbolic metric, you could just replace this with Ponker-Einstein if you want, and you know the renormalized area of two-dimensional surfaces, minimal surfaces, then you can recover the conformal infinity, right? So the most basic conformally invariant information about the metric you can recover just from knowing mineralized error. Just from knowing the normalized area of all these surfaces. And then assuming you know the conformal infinity, and if you know also renormalized area, or say renormalized four-dimensional area, for minimal surfaces of some even dimension m, you can actually recover all of the other terms in the asymptotic expansion of the metric. So recall that the metric, for me, looks something like this. It has a similar Looks something like this. It has this omega naught term. It has these higher order tensors acting on the boundary. And I'm saying that if I know the normalized area of all minimal surfaces which are asymptotic to the boundary, then I can recover omega naught, I can recover omega 2, omega n. I can even go past the critical degree of like n or n plus 1. I can recover higher order terms. And yeah. Sorry, I've confused my areas and maybe you can have a look at that. Oh, sorry. So if I'm testing higher dimension, I want it to be even to order m. But if I'm just using two-dimensional surfaces, I want even to order two. That's a type of one. Thank you. Okay, so we have a kind of a recovery procedure of the asymptotic expansion. And in some cases, we can upgrade this to full metric rigidity. So suppose I have the same manifold, two Uh, same manifold, two different metrics, and they're conformally compact, asymptotic, hyperbolic, even order two. We'll just work with surfaces, okay? Suppose that if I fix one boundary curve, you know, I find two potentially different minimal fillings, right? Because the metrics are operating different. But it turns out if those renormalized areas are actually the same for every boundary curve and every minimal filling, then the two metrics are essentially the same. Metrics are essentially the same. So, in the case in which the normalized area of these surfaces coincide for all curves, gamma, then we can find some diffeomorphism, which is the identity on the boundary. And the pullback of one metric minus the other is essentially the same up to infinite order. So if you tried to take an asymptotic expansion of this difference near the boundary, it would vanish to infinite order. And then, if you want to get real fancy, if you assume that your metrics are real analytic, then it's an expansion. Real analytic, then it's an exact equality. So agreeing to infinite order, when you're real analytic, actions and sensitivity are the same, and you can propagate the information everywhere in the material as well. Okay, so a lot of words, but this picture hopefully encapsulates what's happening. So same manifold modeled on half space, but two potentially different metrics. Given these two metrics, I choose the same boundary curve, and I find two fillings which are a priori very different. Very different, right? But if I know that there were normalized areas that are the same, then actually those metrics had to be the same from the start, and those fillings have to be the same from the start. Yeah. Right. So that's something I'll talk about on the last slide of the presentation. Is there any sort of quantitative stability or rigidity in the lyzer? But that's a great question. Or rigidity normalizer? But that's a great question. Okay, so if the words mean nothing to you, then this is the pit you should try to keep in mind. And so there are some nice applications just dealing with, in addition to rigidity, we can go back to the Ponker-Einstein setting. So Steve mentioned this, but if you have a Ponker-Einstein metric, you actually have an even expansion to very high order. And then there's this one term at order n. At order n. And so essentially the idea is if you have a Poincaré Einstein metric and you know omega naught, then omega naught determines omega 2, it determines omega 4, all the way up to omega n minus 1. And then this omega n term is some non-mobile term. So it's not determined by the conformal class on the boundary. But if you have both of these, then they determine the entire isymptotic expansion. And actually, in a lot of work about showing compactness of Macher-Einstein metrics, Of Mark-Einstein metrics, not having control over omega n or even it being non-zero is a big obstruction to kind of showing an existence a phenomenon. Okay, I would not call this the obstruction tensor, though, which is a point of clarification. Okay, and then just from the previous result, we can apply our results about recovering the metric with renormalized area to the Ponker-Einstein study. And so this would say if we know the renormalized area, We know the renormalized area on all minimal surfaces, or some higher-dimensional analogy. Say we know the conformal infinity plus the renormalized, say, four-volume on all minimal forces of manifolds, then we can recover this non-local term, right? And so we know that whole extension just by knowing omega naught as well as omega limit. Okay, so that's an overview of the results. The remaining time I'm going to Results. The remaining time, I'm going to be going through the ideas of the theorems. But before that, are there any other questions? No, I think in the interior, right, you just have a minimal verifold. So in low dimensions, like dimensions less than eight, which should just be smooth. But if your boundary curve is something weird, you might have weird behavior at the boundary. Behavior of the boundary distance. Oh, sure, sure. And high codimension, I guess the regulatory theory says you might have singularities at most, or of to codimension too, right? Yeah. They were just solid for budget problems, lots of budget problems that they are isolated singularly. Uh Sure, I guess you could phrase it that way. There's a chance that solutions to the asymptotic plateau problem have singularities in the interior, but I would have to double-check. Renormalize the volume or like possibly singular? No, I think you don't need high regularity to compute minormalized area at all. You really just need some. Normalized area at all. You really just need to know some regularity near the boundary, which we have in the firework. Yeah, good question. Yeah, as long as you have some regularity near the boundary, you can do my argument. And I think as long as you're verified on the interior, you're totally fine for computing. You presumably only need enough of these things, right? You can look at sort of a caller neighborhood. They have everything you have nice. Right, so that's the other part, which I'm not going into details. It's like, I actually don't use. Going into detail is it's like I actually don't use all minimal surfaces. I use minimal surfaces, which are in some sense perturbations of hemispheres. And they're all, you can restrict them to, as Sean said, kind of an arbitrarily small colony of the boundary. So you really need less information than I'm claiming. Okay, so the idea behind this, and this is a recurring theme in this conference, is a blow-up procedure. So let's say this is our So let's say this is our conformally compact asymptotically hyperbolic manifold, and I take some point on the boundary in some open neighborhood. I'll dilate that neighborhood by some factor delta inverse. And in these rescale coordinates, it turns out that the metric looks much closer to a hyperbolic metric just by nature of the asymptotic hyperbolic form. Okay, so what do I mean? This is our original expansion for an asymptotic hyperbolic form. Expansion for an asymptotic hyperbolic metric, which for our purposes we'll assume is given to 1 or 2 and do the analysis there. So we have dx squared over x squared plus some tensors on the boundary. If I replace x with delta times x tilde and all the y's with delta times y tilde and re-express this metric under this change of coordinates to lowest order, it really looks like hyperbolic space. So dx squared plus some symmetric positive definite tensor, right, plus terms that are hyperbolic. Right? Plus terms that are higher order. They're O of delta squared. So by rescaling, I've made kind of the higher order terms in the expansion, as well as the derivatives of omega j. You could try to expand this in some coordinates smaller. So by rescaling, you look closer to just the hyperbolic metric in kind of this half-space model, so neighborhood of a half-space model. Okay, and so then in order to determine In order to determine omega naught, write this constant coefficient tensor now up to some scalar factor, or sorry, if we can determine this omega naught up to some scalar factor, then that'll be the same as determining the conformal infinity, right? So we know the value of omega naught at every point on the boundary up to some constant, then that's the same as determining the conformal infinity, the conformal cost itself. Okay, so that's our first goal. Okay, so that's our first goal. And the way we'll do this is considering a special family of minimal surfaces. So, very broadly, I'll take kind of a circle on the boundary and I will continue to shrink it in radius. Okay, so for each of these circles, there exists some sort of minimal filling. And then now I want to take the limit as delta goes to zero. So somehow the radius of the circle is going to zero, but then you can imagine if zero but then you can imagine if you dilate if you blow up by the same factor of delta you'll actually get a minimal surface in some limit and that surface will be minimal with respect to our limiting metric which is hyperbolic space okay so here if we send delta to zero up to a change of coordinates we get the hyperbolic metric and I guess similarly I'm saying here if you send delta to zero but rescale by the choice of coordinates you get a minimal surface in hyperbolic space okay so one Okay, so once we have a minimal surface and hyperbolic space, we can use our rigidity formula. We can use our Gauss formula. So the factors are off here. But in particular, once I have some limiting minimal surface, I want to check to see if its normalized area is minus 2 pi, because then I know exactly that my limit surface is the hemisphere. Okay? But somehow, if I was able to construct the hemisphere, then I actually had very good. Sphere, then I actually had very good choices of coordinates of y on the boundary. So my boundary coordinates actually really produce a circle and the limit. They don't produce something like an elements. Okay? And so once I know I have a good choice of boundary coordinates, well then that means my boundary tensor, omega naught at the point P, really just looks like Euclidean metric up to some scale of factor. Oh, okay, okay, sorry. Oh, okay, okay. Sorry. Basically, it's the shape of this limiting paper. Exactly. And just from classical geometry, you could choose some coordinates where a circle becomes an ellipse. So you don't know if you chose the right coordinates. But if your limiting minimal surfaces was the hemisphere, which is geometrically detected by renormalized areas minus two pi, then your circle actually had to be a circle with respect to the boundary metric remote bar nine. With respect to the boundary metric, I did not catch. So you assume you have such a family of things. I'll justify the existence in one second. Yeah, good question. Did you use rigidity normalized volume? You were just talking about what you just did. No, so this was the Gauss-Binet formula that Rafe and Spears proved. And then Jacob Bernstein's theorem, which says that minus 2π is always a universal. Minus 2π is always a universal upper bound, and there's equality exactly like. Yeah, no, no worries. Other questions? Okay. So this is the general idea, and I'll try to sketch it more in explicit coordinates. So again, I can consider a family of boundary curves. I'll call them S1 delta. So some with respect to my choice of boundary coordinates, a sphere of radius delta squared. And then if I rescale. And then, if I rescale y to y tilde, then this becomes a sphere of radius 1 with respect to the rescale coordinates. Okay, so then just pulling back the metric and doing the change of coordinates, my minimal surface then now looks like some minimal surface over this boundary curve, which kind of has constant shape. So even though I'm actually shrinking the boundary curve by pulling back, it looks like it's the same object. And so then now I'll take a limit as delta goes to zero. Now, I'll take a limit as delta goes to zero of the randomized area of this surface, and I'll compute it with respect to its pulled back metric, which is equivalent to, or sorry, this should be with respect to the original metric. And then by framing things in terms of the pulled back metric, this converges to the randomized area of some minimal surface with respect to G0, which is a hyperbolic metric up to a change of points. And there we can apply the Rich A theory. Okay. Okay, and so how do we actually use this rigidity phenomenon? So, if our minimal surface in a hyperbolic space has a normalized area of minus 2π, then we know the surface has to be a hemisphere. Moreover, in our choice of coordinates, which again are not ideal, we know that the limiting metric looks like dx squared plus some positive definite 2 tensor. And so then it might look like dx squared plus a times. like dx squared plus a times d1 tilde squared plus b dy tilde 2 squared. But again, if a and b are not the same, then this boundary curve is geometrically an ellipse. It's not a circle. So if a and b are not equal, then this boundary curve is geometrically an ellipse. Okay? But if we knew that the normalized area was minus 2 pi, then our ellipse had to have been a circle, right? So our coordinates actually had to have been quite nice. And this would tell us. Nice. And this would tell us that we know that omega naught, which is kind of standard Euclidean metric, up to some scaling factor A. Okay, so now the game that I'll play to determine omega naught is I do this procedure of constructing these boundary curves, shrinking them, sending delta to zero, and I always start with some choice of coordinates. And I essentially vary one of my coordinates until the limit. Until the limit of my renormalized area quantity is exactly minus 2π. And once I get minus 2π, I know I chose the right coordinates and I have recovered the conformal point exactly. Okay? Right. So by this shrinking procedure, this is how we determine the conformal infinity. What about higher order terms? Okay, so we've been able to recover. Okay, so we've been able to recover omega naught via this complicated limit procedure over normalized areas. How would we get omega 2? Well, let's just go back to the change of coordinates. So if I rescale all the coordinates by a factor of delta, then I get such an expansion here. So the omega 2 x squared term, except a factor of delta squared. And again, if I evaluate at delta equals to 0, I get the hyperbolic metric. Makes sense. If I take two derivatives, though, If I take two derivatives, though, then what do I get? I get the Hessian of omega naught plus omega 2. Okay, so somehow if I'm able to recover the second derivative of the metric in this change of coordinates, and I also know omega naught, then I'll be able to recover omega 2. And so then, how do I recover this second derivative? Of the metric? Well, the idea is that to recover derivatives of the metric with respect to delta, I want to take higher order delta derivatives of the renormalized area. But I also want to vary the curve. So somehow if I just took a kth delta derivative of the renormalized area in this previous construction, I would recover a trace. So I would recover a trace of omega k or a trace of omega 2. So at some point I want So, at some point, I want to, but I really want to recover the individual components. I want to recover omega 2 in this direction, omega 2 in this direction. How do I do that? I shear the boundary curve. So, instead of working on some class of nice circles, I want to induce an isotropic. So, some asymmetry. I'll share it into an ellipse infinitesimally in the y1 and y2 directions. Okay, why do such minimal surfaces exist? So, in either the sheared setting or, as Jinjia was saying, perturbatively, as you send them to zero. So, I claim that for each delta, we can always find a minimal filling in the rescaled coordinates. So, why is this? Well, G delta, as we showed before, is a very small perturbation of a hyperbolic metric. Perturbation of a hyperbolic metric. We have an existence theorem saying given any curve in the boundary of hyperbolic space, there is a minimal filling. And now you could just do some perturbation argument. So now if you have a metric which is close to the hyperbolic metric, then you should also be able to find a unique minimal filling with respect to your perturbed metric. This perturbation theorem works for surface or high dimension? It works for high dimension as long as you're. High dimension, as long as your starting submanifold is non-degenerate. So, in my case, the hemisphere in any dimensions is a non-degenerate minimal submanifold hyperbolic space. So, any dimension. So, you need to invert a Jacobi operator at some point and solve. And yeah. Well, I guess in this case, since you can do the inversion and solve for your Since you can do the inversion and solve for your new surface graphically, you wouldn't know there's applying a perturbation and a colour game. Exactly. Exactly. So, in this case, there's no issue of singularity since our boundary geometry is well controlled. Okay, so I can find these perturbations of our minimal surfaces in hyperbolic space. They're perturbations since they come from this G-delta metric, which I viewed as a perturbation of the hyperbolic space. By the way, so for the perturbation term, for Further, you do need to use weighted space or something. Yes, you do. So you need to work in some L2 space and make sure that your Jacobi field at least vanishes at the boundary to high order. Yeah. So some x to the delta L2 or something like that. Good question. Is this perturbation? Oh no, this is in my paper. I think it's not difficult analysis, but it wasn't written out. Yeah. Okay, so now that we have that these. Okay, so now that we have these perturbed minimal surfaces, I'll show you the formula for the second derivative of our normalized area. So you don't have to understand this integral or notation, but notice that in this computation, the trace of omega 2, so the trace of the second delta derivative of g actually shows up. Okay? So if we compute the second delta derivative and send delta goes to zero of this renormalized area quantity, we can Error quantity, we can hope to recover the trace, assuming this integral is non-zero. But again, that's not enough. So I don't want the trace of omega 2. I also want omega 2 in all directions. So I'm going to take this derivative, and now I'm going to vary the boundary curve. So if I actually am able to change the boundary curve, then this new renormalized integral now picks up a factor of phi dot, and phi dot is some Jacobi field on whatever my limiting minimal object is. Okay? So now for me, Object is. Okay? So now for me, the problem has reduced to what are the Jacobi fields on the hemisphere in hyperbolic space. We actually have a lot of symmetry here, and you can compute them explicitly using separation of variables. So this Jacobi field just comes from extending the hemisphere, right? But this Jacobi field here comes from, say, shearing in the top direction. Okay? So if I'm able to shear in the top direction, then actually I'm able to. Shear in the top direction, then actually I'm able to kind of weight this integral differently and recover one of the components of omega 2 as opposed to just the trace. So geometrically, this is kind of what happens when I vary the boundary curve. Again, I shear the hemisphere. And then computationally, if I choose the correct Jacobi fields, I can say recover omega 2, 1, 1, and omega 2, 2, 2. And then using the other Jacobi field, I can recover their difference. So I know all these quantities. So, I know all these quantities on the left side, right? The oracle has given me normalized area for all scales delta, all times t on the left. So, I can actually compute this sum and this difference. Okay, but now I can take the sum of these two equations, or the difference of these two equations, and recover the components of the tensor individually. Okay, so I've one, I've computed omega two, and really this generalizes to higher dimensions, it generalizes to the higher order tensors. It generalizes the higher-order tensors which show up in our expansion. Interestingly enough, I had a huge computational roadblock where I had to learn about hypergeometric functions, which show up in the Jacobi fields, and also, I guess, combinatories. Okay, so this is the end of the sketch of theorem two. And in the last few minutes, I'll just talk about some future work. Okay, so I asked this question on Monday, but can we determine rigidity, some sort of upper bound? Rigidity, some sort of upper bound for a normalized volume of higher-dimensional minimal sub-manifolds. Okay, so there was some upper bound coming from the Gauss-Cranet formula and also Bernstein's work. And if you had a similar upper bound for, say, four-dimensional sub-manifolds, then I could probably determine the conformal infinity using four-dimensional sub-manifolds. Okay, so that's something that's very interesting to me. Something else I would highlight is there's a lot of work in. There's a lot of work in the closed Riemannian setting talking about, say, stability of minimal surfaces. So, for the area functional, can we port any of these stability ideas to the renormalized area setting? So, renormalized area is kind of non-local. It seems difficult, but it'd be very interesting. You could even, if you don't care about sub-manifolds, you could just think about Ponker-Einstein metrics. Like, has anyone ever computed the second variation of the Meromois volume of a Ponker-Einstein metric? Just had to add. Symmetric. It doesn't have to have any geometric meaning if it's always positive. You could even pose this for Q-curvature. So I think these things are doable, but I don't know if you can get any tractable results if there's some non-vocal terms which appear. Okay, and then the last thing that I would pose is kind of a radon transformer for minimal surfaces and asymptotic log spaces. So, in the work by Graham, Yarmouth, Stefano, and Allman that I mentioned, they have this inverse problem. They have this inverse problem for normalized length in geodesics, but they also develop an X-ray transform. What does that mean? If you have a function on your manifold, suppose you know the integral of that function over all of the g dasics, or somewhere normalized integral. Can you actually recover the function itself? Very interesting problem. Can you do the same for minimal services and asymptotography and block spaces? I think even if you work on H. I think even if you work on H3 and you consider two-dimensional surfaces and you define an appropriate integral, this isn't known. But I think this would be very cool from the perspective of people who care about X-ray transforms or micro-complexes. Okay, but that's it for my talk. Thank you very much for listening. 