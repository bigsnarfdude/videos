We're very happy that Cliff is in journalist venturi, and Cliff is going to tell us about actual dilettant a dark host for the dark sector. Take it away, Cliff. Thank you. Thank you. Thanks. I'd like to start thanking the organizers, of course, for the chance to speak and also for their generosity in accommodating the family health issue that kept me from being there. I really wish I could have been there. That sounds like you're having a good meeting. And this talk. And this topic is really right up my alley in the sense that I'd like to talk about axions and dilettons, and I'd like to talk about our basic problem with them when we're looking at, we're in this time where we're testing gravity and we're looking for things that we could, we're measuring gravitational waves, looking for things that we could constrain. What kind of physics could reasonably be there to be constrained? There to be constrained on one hand. On the other hand, we also know that there's things like dark matter that needs to be understood, and we don't have a lot of theoretical guidance. So, I'd like to describe a cluster of ideas which are aimed at focusing or providing some ultraviolet input into the kinds of questions that we're asking at low energies. And so, that's going to involve the axon the dilaton, and the title is elliptic. Dilaton, and the title is a little bit provocative, but it's going to head towards a place where perhaps we have the whole story for both the dark energy and the dark matter coming from the two things that we're going to need to test gravity that I'll get to. So the theme is kind of a, it's kind of reminiscent a little bit of the Swampland program in the sense of trying to use ultraviolet physics to get at low energy physics. And so I want to contrast this with that because I think this is the opposite of the swampland program. That because I think this is the opposite of the swampland program. I'd like to call it the Hidland program. And I can kind of go into that in more detail if someone asks. Oh, and please, if people have questions, please interrupt me because it's really hard to read a room online. And so if you shout the question out, then it'll be better to deal with it immediately rather than have me steamroll or pass something. Anyway, the second, somebody turned down the lights. It's hard. So the main distinction I'm making between what I'd like to do and the Swampland program is the Swampland program is a statement about what predictions at low energies are ultraviolet sensitive. And I'd like to just restrict myself to general kind of standard symmetry arguments that are using approximate symmetries that are generic coming from string compactifications is ultimately where it's going to come from, which will speak to that half of the room. Come from, which will speak to that half of the room. But it's meant to be extracting out approximate symmetries and how they can be relevant at low energies. So it's work done with a bunch of lovely people. And it's kind of a cluster of ideas. And so the main developments were from a number of years ago. And they're aimed at these symmetries that I want to exploit. And the main one will be approximate scale invariances, which I'll motivate. Scale invariances, which I'll motivate when I get there. You'll see that once we get to the place we're going to get is that you're going to expect to have light scalars. And so there's an issue of how you, you know, why don't you see them and tests for general relativity. Part of the motivation for thinking about this is to think of things that you could be looking for and test general relativity. And so the ideas that I'm going to talk about involving screening and things like that are done with Philippe and Fernando. And then the cosmology side of things that I'll Cosmology side of things that I'll close with if there's time. We're done with this larger group. And so I probably have too many slides, and so I won't get through all the topics. And so it's best if you interrupt me with questions that we'll just kind of get as far as we can and then I'll pick and choose as to where we get to at the end. Okay, the starting, I should mention that the underlying symmetries that I'm talking about goes back to earlier work with Sven and Mikoli and Michael and Fernando. And Michael and Fernando. Okay, so the three parts of the talk are: I want to first start from the point of view of if you're looking to test gravity, and I don't know about you, but I always find that the models that people are testing them against don't, they're models only a mother could love. So I'd like to kind of ask the question, what would you expect at low energies to compete with gravity, given that we're only doing our tests at low energy? So I'm going to just basically do power counting with scalars and the metrics. Us as scalars and the metric, and identify the interactions that we should be expecting to be competitive with gravity and low energies. And the upshot here will be: I think we're looking for the wrong things as a community. And so, and you'll see why when I get there. The second thing I'd like to get across is the various models I'm going to talk about are going to be motivated by at low energies, naturalness is a big question for scalars. And so there's a mechanism for suppressing scalar potentials, which the string theory. Potentials, which the string theorists have found and then they buried in their literature around 2005. And it's not so well known outside the string community. So I'd like to describe that mechanism because that's the one that I'm going to be building on. And then the last part will be more of a discussion of where those things go and what the phenomenology, what are the things that you could look at phenomenologically. And it's very much a work in progress so that this is just be a snapshot of kind of things we know now. Of kind of things we know now. Let me start with the first part. So, what kinds of things should you expect to be competing with gravity at low energies if you're testing it, such as with gravitational waves? So, I'm going to be looking at the class of theories, which are scalar tensor theories. And so, first thing you have to do for a rule of particle physics is kind of put aside the prejudice. You shouldn't beat any scalars at low energies. And it's not like that prejudice was a crazy prejudice, but it's true that it's not completely. But it's true that it's not completely airtight. So, I want to argue as part of the story, what will come out if I had to summarize in kind of a nutshell what I'm going to be saying. A lot of the intuition about the scalars being light is coming from the fact that you think you're just doing more and more tuning. You had to get the vacuum energy to be small, and you had to make the scalar mass small. And it just seems like you're doing epsilon squared or epsilon high power physics. But it's really, if you can kind of understand. Really, what's if you can understand why the vacuum energy is small, then it's actually true that scalars, the intuition of whether or not there should be light scalars or not changes. And so, one of the things I'm going to head towards is that, that once you've understood why the vacuum energy is small, the lightness of the scalars needn't be additional tunings. Hopefully, there won't be any tuning at all, but the prejudice about what's a tuning partly is coming from our sense of hopelessness in the face of the cosmological. Sense of hopelessness in the face of the cosmologic constant problem. I'm going to argue that the interactions that are important that want to compete with gravity at low energies, you won't see them if you only have one scalar field. And so it's because they involve sigma model interactions involving two derivatives. And so unfortunately, our whole investment in single scalar fields, which kind of was done naturally on a simplicity grounds by the people in the community, has had the unfortunate Has had the unfortunate side effect that it's thrown away the interaction that's probably the most interesting one. And so then I'll talk about the kind of models you've led to about low energies. So if you're talking about the low energy limit of scalars coupled to gravity, this is kind of generically what the Lagrangian looked like. I've written a derivative expansion out here. And so the first term is the no-derivative term. And I'm mostly what I want to show you here is that this field I'm looking at, the scalar field of fields, I'm thinking of them as being dimensionless. And so V here in this expression is setting the. V here in this expression is setting the energy scale of the potential. And I'm imagining that that function u is some order one function when phi is order one, that u is a generic function. And that's the class of functions I'm going to look at. And that's not quite the functions we normally look at when we're doing particle physics, but it's the kind to which if you're going to ask naturalness questions, it's a natural class of interactions to think about. So in particular, if phi gets very large, the potential is not getting very large. So large fields would be consistent with low energies. And so you could ask questions about whether or not large fields are allowed at low energy. Questions about whether or not large fields are allowed at low energies. Then there's the two derivative terms, which are the Einstein term, and then there's the sigma model interactions amongst the scalars. I'm imagining I'm in the Einstein frame, so I haven't written anything funny in front of the R term. And then there's the higher derivative terms, which I'll come back to later on. I'm going to choose the normalization of the kinetic terms for the scalars to be the Planck mass. There's nothing unnatural about that. And I'm going to be interested in gravitationally a couple of things. And so that's just a choice. Now, the generic problem, as you know, for these things is that the potential is a dangerous thing. So, the thing that wants to win at low energies is the no-derivative term. And so, if it were true that v was the Planck scale, then there is no low energies, and so there's nothing you can say. So, we're always interested in this limit where V is much smaller than the Planck scale, and then typically the Hubble scale or the scales of our low energy world are going to be suppressed compared to the Planck scale too. And typically, if they're coming from V. And typically, if they're coming from V, then the Hubble scale would be of order V squared over M Planck. And I'm going to be working largely in a regime where there's only one low energy scale. So I'm going to call it H because I'm thinking it's of the order of the Hubble scale, but all the low energy scales in the problem will be of that size. Now, the first observation is that once you've made V small, that tends to also suppress the masses of the scalars if those scalars have Planck's normalized kinetic terms, if they're gravitationally. Normalized kinetic terms, if they're gravitationally coupled. The generic size you expect for the masses is of the order v squared over m Planck. And so, if you really did have a world where V was set by the dark energy density, that would be of the order of the Hubble scale. That would be an incredibly light field. And the lightness of that field is completely coming to you from the smallness of the potential and not from additional tunings, really. It's that structure, v to the fourth times a function of phi, which is an arbitrary function for order one phi's, that is the thing that's making these things generic. That is the thing that's making these things generically small. Okay, so now what I'd like to do is power count with this Lagrange, and I just want to say what you know, what should we expect? How do we expect these various terms to contribute to correlation functions, let's say? And I've written a few more terms here. I've written the things, the Kirbicher cube term, the sample one, just to underline that as soon as you have a term with a mass in the denominator, like this one does, the M that goes there is never the Planck mass. You're integrating out a bunch of particles. You're integrating out a bunch of particles, and in a numerator, the large mass wins, but in the denominator, the small mass wins. And so, if the last particle you integrated out in the UV was the electron, it would be the electron mass that would go there. And so, our intuition as to how big these terms is should not be driven by the Planck mass. In string theory, this is what happens. And then it's the string scale that would appear here if you're looking at the higher dimensional action you got by integrating out the strings. But it's a special case if it's just a generic dimensional statement. So I want to keep that in mind that that's a fairly small mass scale when I'm doing this power counting. Fairly small mass scale when I'm doing this power counting. So now we just do some graph. It's the usual story of power counting. We have E external lines, we've got L loops, we've got Vn vertices involving DN derivatives, where N labels the interaction in the problem. It has Fn fields converging at that vertex. A low energy scale, I'm going to call it H, and it could be a derivative of a background field, or it could be a momentum of a fluctuation, but I'm going to assume that they're all the same size, the low energy fields. And then it's just a dimensional. And then it's just a dimensional analysis argument. The things are subtle when you have more than one low energy scale, but if there's just one scale of low energies, then you can identify where all the terms in the Lagrangian go just from the Feynman rules. And then dimensional analysis tells you where the H's go. And so the answer I'm going to quote to you is essentially arrived at level. So you can get it by power counting Feynman graphs in flat space, but it's really a dimensional argument. So it's not, you can do it in curved space as well. And this is what you find. So the correlation function. The correlation function depends on these various scales in this way. And I want to go through what all these various terms are telling us. So I'll just rewrite it. Here's the formula again. And so each of these factors tells us something. So the main one, the one involving the number of loops is the one that you expect to be there. That's the one that just says that the loop counting parameter is the low energy limit in gravity theories. And so, you know, if you're doing semi-classical... You know, if you're doing semi-classical, using semi-classical tools when you're doing your cosmology or your test of gravity, you have no options about the low energy limit. That's the thing that's justifying why the corrections to your classical limit are small. The second thing is all these contributions from dimension, four-derivative and higher interactions, they're there. And you see that they involve this light m, but they always involve also an h over m Planck squared as well. So I've never seen a way to find an I've never seen a way to find an observably big contribution given that that scale M is smaller than the Planck mass, but it's, I don't know that you can't do it. But it's the thing you're fighting is that there's these additional, in addition to the loop contributions, you're fighting always an H over M Planck squared on top of the H over little M contributions. Now, that means that if you're a cosmologist, and there may not be cosmologists in the room there, but they often write down F of X theories where they keep all powers of the same. X theories where they keep all powers of the single derivatives and they throw away double derivatives. That never makes sense in this kind of a power counting. And the only exception I know to that is the DBI action, where you can actually make sense of that as a systematic expansion, even though you're using the derivative expansion as an important thing. And that's because it can be recast as a speed of sound expansion. But that's, I think, the only example I know where that can be done is the DBI case. It doesn't mean it can't be done in other cases, but if you're living off, if you want to use these more complicated higher derivative things involving Complicated higher derivative things involving lots of derivatives, the burden is on people to justify why the semi-classical methods being used are under control. The scalar potential being dangerous is what this last one does. This last thing is coming from the vertices from the scalar potential, and so that's why it's got the v to the fourth in it. And it's the only place where h is in the denominator. And so that's showing you that the scalar potential is trying to undermine your low energy expansion and your semi-classical expansion. And it's the reason why classical intuition is often wrong when you put scalars in because the Often wrong when you put scalars in because the scalars, they're likely that what you think is going to be small because of the loop effect is going to be amplified by the fact that it's a scalar at low energies. And so that's the dangerous thing. And that includes within it the naturalness stories we normally tell about masses and vacuum energies. But it's kind of more of a systematic statement that if you're working to some fixed order in these small ratios, the scalars are trying to undermine that expansion at all times. It's often not a problem. So if you're doing inflation or something and you're really working in a regime where H really Working in a regime where h really is given by v squared over m Planck, then that ratio v to the fourth over h squared m Planck squared is order one. And so there's no specific amplification in that case once you've decided why v is as small as it is. So it doesn't mean that everybody who's doing inflation is wrong. It means that you've got to be careful about checking what these corrections are if you have a particular model. Now, things that are not suppressed, there's nothing here that suppresses large fields. As long as the large field is not large energy, The large field is not large energy, which the form for the potential I chose is making true. There's nothing wrong with large fields, and so that's kind of why trans-Plankene issues are really not an issue as far as the low energy theory is concerned. Another thing that's not suppressed is two-derivative interactions. They cost you nothing. They'll enter the answer, but they're not costing you systematically powers of energy. And that's kind of why the non-linearity of general relativity can't be neglected just because you're at low energies. You're really stuck with the whole non-linearity. You're at low energies, you're really stuck with the whole non-linear thing. But the same argument means that it's these two derivative scalar interactions are the ones that are scaling in the same way as general relativity is. They're the ones that want to compete with general relativity at low energies. Those are the ones, if we're going to find something that's making a deviation from general relativity at low energies, it should probably be those ones. If we find general relativity competing with a higher derivative interaction, that means that probably the derivative expansion is failing and we were doing the wrong thing by thinking about it classically. About it classically. So that's great. So there's a that's very nice. There's a nice class of interactions that we should be thinking in detail about because those are the ones that want to compete with general relativity, these very low energies we have access to observationally. Now, it's kind of been known for a long time that the coefficient that function GAB of phi, you can think of that as a target space metric for your scalar fields. And all the various physical field redefinitions. All the various physical field redefinitions are like coordinate transformations in the target space, and physical things just depend on the geometrical things like the curvature. And so, if you happen to be in a world where your target space is flat, then you can always do a field redefinition that makes GAB into delta AB, and then those interactions are not present. So, these interactions that we're looking to compete with gravity at low energies are going to have to require a curved target space. And the bad news is that if you specialize to single fields, all of your target space are flat. All of your target space are flat because you can always just do a value, you can always do a redefinition that makes the fields canonical in that case. And unfortunately, when people made in the early days of, say, the Euclid collaboration, when they decided to set up benchmarks for what modifications to gravity they could look for, one of the first things they did is they said, well, there's a lot of things. We've got to choose start somewhere. Let's start simple. Let's just take one scalar field. And unfortunately, by doing that, they threw away the most interesting interaction. And that's kind of why when And that's kind of why, when you look at the literature of testing gravity, there's a lot of the stuff where the people are trying to compare to higher derivative interactions, like the whole Horn Desky program. And it's kind of a struggle because in order to get an effect that's big, you're always making the derivatives extremely large, or the coefficients are unusually small, or unusually large. And what you're fighting there is that if you get an observable signal, you're really fighting the whole semi-classical approximation is in trouble. So it's, I think, much better to be thinking about. It's, I think, much better to be thinking about these two-derivative interactions because they could be competing without at all threatening the semi-classical tools that we're using to do the analysis. Okay. So what should be our benchmark theories to think about then if we're thinking about things with two derivative interactions? We have to have at least two scalars to have that happen. So what are the simplest things we could be looking at? Are there things that are as simple as the things that are looking at for single scalar fields? And there are, and I'm not going to tell you that, I'm not going to give you the most. are and I'm not going to tell you that I'm not going to give you the most general thing but I want to now work towards a very well-motivated class of things that probably are worth exploring in more detail. And the reason this comes up is that I'm interested in these models for other reasons. And I had thought that when we were trying to test them, that we could just use all the tools that were developed for Euclid about how you test the how you compute observables in gravity using modifications of gravity. And unfortunately, you can't use any of them because the tools are all derived for single scalar models. So I think Scalar models. So I think those tools, building those tools is a useful exercise, I think, in its own right. So the first observation is that if you, let's say we have multiple scalars, the first observation is there's nothing about, we want the potential to be small because that's a dangerous thing. So we're usually looking at Goldstone bosons or pseudo-Goldstone bosons. And there's nothing inconsistent with that, that you can have shift symmetries that are making your potential small, and you can still have non-trivial target space metrics for that. That's the, you know, the two-sphere is the obvious example. You know, this two-sphere is the obvious example of that. So, now to narrow down the kinds of class of things you could be looking at, if you're just looking at two fields, then there's a function of the two variables. You could always go to a frame where the metric is conformally flat in two dimensions. But a particularly interesting subclass of that are the ones where there's an axial symmetry. So, one of the fields is got a Honest A God shift symmetry, and so it does not appear in the metric. For that kind of theory, there's only one function. Theory, there's only one function that you're talking about, which is kind of as simple as the things that people look at for single-scalar fields. And that shift field is going to look like an axion or like an ALP at low energies. And so that's kind of how it plugs into the axiverse. You also have to choose how this thing couples to matter. And so I'm not going to talk much about how the axion couples to matter, but when push comes to shove, what I'll do is what everyone else does is I'll imagine that it couples to some bilinear of particles. And so it's effectively. Bilinear of particles. And so it's effectively appearing as a field dependence to the masses of the particles, possibly linear, possibly quadratic in the fields, and then things are slightly different in those two cases. But the other field, chi, which you're going to see, I'm heading towards a place where that will be a dilettant for a scale invariance. I'm going to assume that it couples. This is what's going to happen in the cases I'm interested in, but I'm going to be interested in couplings where it's coupling to matter through a To matter through a Jordan frame metric, so that there's not an independent chi-dependence. There's a frame in which the matter is not coupling to the chi, but is coupling to a metric which is built from the Einstein frame metric and chi. And so in this kind of a theory, the two functions you'd have to specify would be A of chi, which is telling you how you couple to matter, and W of chi, which is telling you how the two scalar fields are talking to each other. And that's the interaction that you might expect to be competing with gravity at low energies. Now, this could. Now, this kind of thing where I'm heading, it has a, it smells familiar to people who have been thinking about supersymmetry because it's typically true in supersymmetric theories that the scalars come in pairs. And it's often true that, particularly when you're looking at compactifications, that one of the pairs is an axion and the other one's not. And often the other one is dilettant. And as I say that, half the room says, you know, just shoot me now because why are we talking about supersymmetry? We talked about supersymmetry for decades. We didn't find it. So you're talking about very low energy. Find it. So you're talking about very low energies. Can we please stop talking about supersymmetry? And I want to argue for you why I'm sympathetic to that in particle physics, but for gravity, we've got to be careful about that. And I think that there's a room for supersymmetry to still play a role at very low energies for gravity. And this is one of the places there where I'm now going to use generic things that happen in string vacua to motivate what I'm going to say. So if you think about supersymmetric theories and how particles get split, multiplets get split. Multiplets get split. You know, the fermions, the bosons get split by some amount, delta M squared. And in order of magnitude, the size of the splitting is given by some expectation value, which I'm calling F, which is the thing that breaks supersymmetry, times a coupling, which is the coupling of the field of interest to the supersymmetry breaking order parameter. And that's, and so what typically happens when you look at string evacua is the gravitational sector, the things that are coupling with gravitational strength, they tend to be split the least. And it's because they couple. And it's because they couple more weakly than everybody else. And so it's kind of generically true that you find that the gravity sector gets split by less than other sectors just because that's the sector which tends to be coupling in the weakest way. Now, supposing your cutoff was here, that means it's not actually such a stretch that you could be in a world where you've got a non-supersymmetric particle physics talking to a much more supersymmetric gravity sector, a dark sector that we think is out there. A dark sector that we think is out there could be supersymmetric, and it wouldn't be inconsistent with this. Uh, the fact that we know that supersymmetry has not been found in the particle physics sector. And this was an observation that people I know made in the 80s, but the thing is, the difference now is that we now know systematically how to couple supergravity to non-supersymmetric matter. What you effectively do is you can take any, you know, space you just have one boson or something, there's no fermions at all. You can make that it's supersymmetric by coupling the Goldstone fermion to it to make it. Coupling the goldstone fermion to it to make it, you can make it globally supersymmetric for free by coupling the goldstone fermion appropriately. And then, once it's globally supersymmetric, then you can couple gravity to it, supergravity to it in the way that you always do when you're coupling a globally supersymmetric theory to supergravity. And that technology has been worked out in these papers. And when I talk about specific Lagrangians down the road where I'm coupling supersymmetric scalars to, say, the standard model, this is the formalism I have in the back of my mind. In the back of my mind, and I won't ever talk about it again, but the calculations are being done in this way. Most of the answers we're going to get to, you can understand other ways, but it's uh, what's nice is that you can be very explicit about how these interactions take place. Okay. So in that kind of a framework, if our multiple scalars were in this kind of a world where there's some supersymmetry going on, then the things that we normally are specifying there are things like the Kayler function and the superpotential. And the superpotential. And if they're Goldstone fermion bosons, they're often not in the superpotential. So the Kayler function is the key thing. And the shift symmetries are easy to get. If it just pans only on the real part of the field, then the imaginary part won't be appearing in it. And so I'm going to specifically focus now on the case where the non-axion field is a dilettant, so that there's a scale invariance in the problem. And so what I mean by that is I'm going to ask this e to the minus k over 3. This is e to the minus k over 3 to be a power of that field. So that when I multiply that field by a constant, the Lagrangian gets multiplied by a constant. And it's e to the minus k over 3 that appears just because of the, when you write the Lagrangian in superspace, I'll show you a slide later on. That's the combination that controls how the Lagrangian scales, it turns out. And so if someone tells you what this k is, then you can read off these functions you want to know, the w function and the a function, and they have simple expressions. And they typically, for these power law kind of typically for these power law kind of expressions they give you exponentials in in in chi because they make the kinetic term uh be also a power and so so the this is showing you kind of the explicit expressions but the important one is that the a squared function we're talking about the thing that controls the coupling to matter that also wants to be an exponential and and when you have an exponential coupling to a jordan frame metric that that's a that's a definition of a brand stick That's a definition of a brand sticky theory. That if you did, if you define a grand sticky theory in Einstein frame, which I think people should, rather than the traditional Jordan frameway, this is how you would define it: that's e to the something times the field is what defines the vial rescaling of the metric. And that coupling G can be rewritten in terms of the usual brand sticking parameter. It's for large parameter, g squared is one over omega up to a numerical factor. And so it's a so anyway, in this world where e to the In this world where e to the k over 3 was given by a power and lambda was some parameter, then all of these various couplings are given by lambda. And lambda equals one is a very special choice. People have known that for a long time because the scalar potential that these kind of scalars would have in supergravity has this form. And so if we specialize it to that choice of k that I gave you, when lambda equals one, it's flat. And that's because the choice lambda equals one is a no-scale model. Is a no-scale model. And that, as you'll see in a few slides from now, is that's telling it's something which is you should expect that scale invariance likes to give flat potentials. And the way that supersymmetric theories show you that is scale invariance theories give you these no-scale models where the potential is flat, even though supersymmetry is broken. And so there's a class of vacua that you're led to that scale invariance suggests. Okay. Good. So that's kind of the So that's kind of the story so far has been that if you're motivated at low energies, you should be looking for multiple scalar models. So two is the minimal. The two derivative interactions are the important one, and that's why you had to have two. And a well-motivated class involves the shift symmetry, partly simplicity, partly well-motivated, a case where the target space has got a shift symmetry. So you've got an axion-like thing coupled to a diletton, which is associated with a scale. Is associated with a scaling symmetry, that's something which arises very often. I'm about to make the case as to why that's something you see very often coming from the ultraviolet in string theory. And so those accidental symmetries are playing a role. And part of the reason for focusing on the scale invariance is I want to talk about this mechanism for suppressing potentials that the string theorists found. And the logic of that message is that scale invariance and supersymmetry are better than the sum of their parts. So that the scale invariants are very, very, very The sum of their parts so that the scale invariance with supersymmetry does more for you in the scalar potential than scale invariance alone would have done, or supersymmetry alone would have done. Okay. So what do I mean by the scale invariance? Sorry, there's a question there? So by scale invariance, what I mean is it's actually not really a symmetry. So the metric will scale by a number, a constant. All of the fields in your problem will scale by a constant. That's that same constant to a different power. That's that same constant to a different power. And when you do that, the Lagrangian scales by that same constant to a different power. So the Lagrange is not invariant. So it's not a symmetry of the action. So it's not really a symmetry. But it is a symmetry of the classical equations of motion. And that's kind of why it's powerful when you're analyzing things semi-classically. So the claim is that this kind of a these, every every single string vacuum you've ever seen has at least one of these symmetries, usually more than one. And there's a really simple reason why. In string theory, there's no parameters, so you're always expanding. Parameters. So you're always expanding in fields. So your Lagrangian at low enterprise comes to you as some series over whatever the small fields were that you thought you had. And I've written it in cartoon form here where there's derivatives and things everywhere, but it's basically sums of monomials of these fields that you are expanding in. And of course, it's not at all complicated to see that any one term in the sum has the property that if I scale the fields in some way, that the Lagrangian scales in some very specific way. And in particular, the first term in that series scales in that very way. Scales in that way. And so, what happens is if you go through all the various string vacua, they all have these scaling symmetries. If you're doing in 11 dimensions, you just get one because you have the low energy approximation in that case, but it's a field. And if you have a perturbative string vacuum like in 10 dimensions, there's at least two because you've got the weak coupling expansion and the low energy expansion. And you can just identify what the scaling symmetries are. And if nothing else, they're a good bookkeeping way of keeping track of how big the corrections are to anything. Are to anything. But those are the scaling symmetries that are always there, and it's the Goldstone bosons for them that I want to track. Now, why do you care about the scaling symmetries? What's nice about them is if you're interested in the vacuum energy and how potentials gravitate, as you are if you're trying to find a sitter space, or as you are if you're trying to understand the cosmologic constant problem, what's remarkable about scale symmetries is that they can protect the value of the potential at its minimum even when they're spontaneously broken. Its minimum, even when they're spontaneously broken, unlike supersymmetry, say, or other symmetries. And the reason for that is simple. So, if you have a potential of this form where you scale a field and the potential scales by some other power, then you can derive these two identities from this by differentiating it a couple times with respect to the various variables. The bottom one just says that if you find a place where that's a scale-invariant place where all the fields are zero, so that things are scale-invariant, then that will always be a stationary point of the potential. That's not a big deal. It's typically. The potential, that's not a big deal. It's typically true if you have an asymmetry of your potential. Invariant points are stationary points. The top one is more interesting. It says that if you find a place that's a stationary point, then the potential has to vanish there. And the star here is because there's a caveat that depends on that you can screw it up for one value of W and P here. But it's generically true that if you have a minimum, it has the same value as the scale invariant point. And the reason, so that's not what the Mexican hat does. So that's not what the Mexican hat does for internal symmetries, right? There you'd have a scale, the invariant point is the maximum, and then the bottom of the trough is the minimum. And so, if you go along the bottom, nothing says it's at all related to the maximum. And that's why scale invariance is different. For scale invariance, what's happening is that the thing, you're not multiplying things by phase, you're multiplying it by a modulus. And so, the thing is that if you change the value, if you do a scale transformation on a solution, and if your solution is not And if your solution is not scale-invariant, you're going to get another solution. And so you're going to get a whole line of solutions. But because you're multiplying it by a real factor, if you multiply it by zero, you get the scale-invariant solution. And so they're all in the same line. And so everything's anchored by the scale-invariant solution, which had to be a zero because there's no scales there. And so that's something which is very attractive. It looks like if you could imagine being, if you could spontaneously break scale invariance somehow, you'd have the field have some non-zero value, you could get non-zero masses, but then you'd have a reason. Could get non-zero masses, but then you'd have a reason why the potential could be still anchored as zero. And people made that observation back in the late 80s, tried to build models. The whole issue is: how do you break the symmetries? How do you break the scale invariance? It could be quantum effects. It could be, you know, the thing I showed you was explicit, the Lagrange is not even invariant. There's lots of things that break it. And right after this industry started, Weinberg killed it with his no-go theorem because basically his observation was that it doesn't matter if you can assume scale invariance is an exact same. You can assume scale invariance is an exact symmetry, and it doesn't help you because the quantum corrections in that case could give you phi to the fourth, which is scale-invariant. And what they do is they lift this flat direction, leaving you the unique scale-invariant point as the only minimum. But then you've got the problem that your only minimum is scale-invariant, and so you haven't got non-zero masses as well as a small potential. So the problem is all about how you could protect yourself from the lifting of the potential. And scale invariance in itself isn't going to save you. But that's where supersymmetry can help. And that's kind of why there's a, you get a little bit more bang for your. And that's kind of why there's a you get a little bit more bang for your book in these scale invariant supersymmetric combinations. So let me just kind of just remind you of what scale invariance means in this supersymmetric context. And so this slide is just telling you that, you know, there's a Lagrangian, and I'm mostly just emphasizing that the thing that's appearing, k is appearing as e to the minus k over 3. If I want the Lagrangian to scale the way I've been telling you, then it's e to the minus k over 3 and these other functions have to scale in some specific way. That's what scale invariance means. And there's various formulas here. means and there's various formulas here for what the potential there are and the kinetic terms are and all that than some standard formulas now something special happens if this e to the minus k over 3 if it scales if it's homogeneous degree one in the fields if that's true so if it's if i scale the fields and then it scales with the same power then you can differentiate it a couple times and derive this identity that involves the derivatives of k and the inverse metric of the of the second derivative of k and that's what defines a no And that's what defines a no-scale model, typically. And the reason that people define it that way is that if you have a superpotential that doesn't depend on those fields, the potential has this nice form and it's got this bracket which is vanishing because it's no scale. And what's happening there is that's, you know, I told you that the scale invariance, if you have scale invariance, you're expecting to be able to be flat directions if you spontaneously break the symmetry. Along this flat direction in the supersymmetric case, supersymmetry is breaking. So you do have order parameters that are non-zero that are breaking scale invariants that are breaking supersymmetry. Scale invariants that are breaking supersymmetry. And the no-scale model is the supersymmetry's way of telling you why the flat direction had to be there. And so that's kind of the intuition as to why these no-scale models are there is that they're telling you something that scale invariance told you too, but this is the supersymmetric version of it. And that's actually a very tempting conclusion to have, and it's wrong. It's not wrong, but it's not fully correct. The interesting thing is that scale invariance is sufficient for a no-scale model, but it's not necessary. But it's not necessary. So, an example is this: this expression here. If the first term here, t plus t star, is an example that's homogeneous degree one. If I take that choice, I get a no-scale model. But if I add to it an arbitrary function of two other fields, it doesn't matter what that function is, this is still a no-scale model. So the potential for this theory is exactly flat too, even though this function f needn't be scale invariant. And so that shows you that scale invariance, you could break scale invariance. You could break scale invariance and still be a no-scale model. And so, if you kind of think of it in as Venn diagrams, this area D here is the scale invariant case where things are homogeneous to degree one. But the general no-scale case is bigger than that. And this is an example of something which is in C, but not in D. It turns out there's actually things that are not no-scale that are also flat. Back in the 80s, people analyzed the most general potentials that are flat in supergravity. And there's a criterion that you can enumerate. And there's various categories of things that are each bigger than the other. And so now, The other. And so now, here's how the mechanism is going to work that I'm about to show you in the next slide. So, scale invariance can make your potentials flat. And everybody said, Well, okay, you're going to break scale invariance, so then your potential won't be flat anymore. And that's true. But what can happen is the correction to your scale invariance might still be no scale. And so you might get a lot of scale invariance in your Lagrangian, but you don't have to necessarily lift your potential. And so there are examples where what happens is that the first correction to scale invariance actually doesn't lift. Correction to scale invariance actually doesn't lift your potential, and you have to wait to next order in the small thing, and then you generically start to see the potential get lifted. So, the way that works is, so imagine we have a field tau, which is large, and we're doing a series expansion in one over tau. And so, and we start off with the scale invariant thing, which has got a homogeneous degree one term. So, we start off with something linear in tau. But then there's a subdominant terms, which you know, something which is independent of tau because it's down by one. Which is independent of tau because it's down by one over tau and something going like one over tau squared. And these a's, b's, the b's, and the c's, not necessarily the a's, but the b's and the c's could be functions of all your other fields in your problem. What happens is, so if you imagine expanding in powers of one over tau, the leading order thing you're going to get is going to be scale invariant, and it's going to have a flat potential because it was scale invariant. But now your first correction is not scale invariant because b could be some arbitrary function, but it's still a no-scale model. So your potential still remains flat. It's only at this point that you actually see that the. It's only at this point that you actually see that the potential got lifted. And that mechanism is the mechanism that the string theorists identified back around 2005 when they were just talking about large volume models and they're looking at the large volume corrections to their Lagrangians. And basically, this happens where tau is a volume modulus for the extra dimensions. And people were sure that they were going to kill these models because they found a correction to the Kayler function and then were disappointed when they found the potential didn't get lifted. And it was because this magic was going on behind the board. This is what they call in the string. This is what they call in the string literature. They call it an extended no-scale structure, but it's basically this mechanism for suppressing a potential more than you think it should in a scale-in-grade case. So the models I want to talk about in the rest of the talk are motivated by this. And so I want to basically run with that idea. Let's take tau to be as big as it possibly can be and see what's the biggest suppression we can get in the potential at low energies and see if that helps, understand the smallness of things that we see. Understand the smallness of things that we see at low energies. They're called yoga models. You're going to see that when I write down literally what I just told you there, where I take the coefficients b and c and I have them involve standard model fields, but there's basically a field tau that's being expanded in. We're going to arrive at a place. Oh, I just lost my thought. It was a really good thought, too. I'll come back. I'll come back. And the cosmologic constant is zero because, oh, I lost my thought. So anyway, I'm going to set up a model where it's just basically a standard model coupled to tau and I'm going to build it where tau is as big as it could possibly and just see where it goes. Oh, oh yeah, I remember the thought now. So the thought, you're going to see that the symmetry in itself will not help. I'm going to be led to a place where the I'm going to be led to a place where the size of the vacuum energy you're going to be led to is as size as you think it should be. It should be the weak scale to the fourth or something like that. But the thing is, it'll have a structure which is not generic. It'll be a positive thing. The leading term will be positive for reasons it'll get to. And that allows you to build a relaxation mechanism is because if you have a positive potential, you can try and find the minimum and that's going to want to go towards zero. And so the symmetry in itself is not going to be the whole story, but it allows you to have the structure that you can build the story on. Story on. So these models are called yoga models because they require a relaxation to be natural. So the natural relaxation is why they're called yoga models. So I'm going to literally now do what I told you. I'm going to take a Kayler function, which has this form as a series in 1 over tau. And I'm going to imagine that B and C depend on standard model fields in this way that's where the standard model is not supersymmetric. So supersymmetry is broken in that sector by some large scale. We're looking at the effective theory below that scale. Effective theory below that scale, and the energy associated with that breaking supersymmetry is the benchmark for how big the vacuum energy should be. And I'm just going to tell you what the answer is because we don't have much time. What you find for the tau dependence is kind of the first part is kind of simple. You get a kinetic term, which is kind of like I was talking about. You get powers of tau. It starts off being a no-scale model. So you get the lambda equals one case I talked about before. It's a very flat thing. And because lambda is one, the power here. is one the power here for this this kinetic term is tau is tau squared it would have been a tau to the lambda before i think or tau to the two lambda so that part's generic the coupling to matter is also generic it's coming from e to the k over three and if i've told you what the kinetic term is you know i've told you basically k is minus three log tau then i've also told you what e to the k over three is so i've also told you the tau dependence of the metric and there's no choice there it's the same choice and so now the but the interesting thing is that this tau is coupling to everything through the metric Tau is coupling to everything through the metric. So, what's going to happen in the standard model is you're going to get a tau appearing. All the things that are not scale-invariant will pick up a tau dependence. But the standard model is pretty darn scale-invariant. So, what happens is that the parameter like mu squared or the Higgs squared term starts to pick up a tau dependence. And basically, the Higgs VEV starts to learn about tau. And that's the dominant way everybody learns about tau in the standard model. Now, the interesting numerology is that, so if everybody gets a tau dependence, which goes with the Higgs VEV, it turns out that because the metric is going like one over two. It turns out that because the metric is going like one over tau, the masses go like one over the square root of tau. And so, and the generic scale in the problem here is the Planck mass. And so, what will happen is that the things, all the standard model particles that are getting masses that are linear in the Higgs valve, will get something, a mass going like m Planck over root tau. Neutrinos are interesting because if they get a mass coming from the dimension five term, which involves two Higgs's, then they're going to naturally want to have a one over tau dependence. And the interesting thing is that this numerology actually works, that if there's a tau for which I get the neutrino mass scale right and the standard scale Which I get the neutrino mass scale right and the standard model mass scale right, and that's the tau. If tau is 10 to the 28, so the square root of tau is 10 to the 1214, and this is a this would explain the hierarchies that we see in nature, apart from the particle physics hierarchies. So the goal will be, you know, why is tau that large? And so that's going to come down to what the potential is for tau. If I turn the crank on that Lagrangian I gave you, and I asked what's the potential for tau, it comes as a series of one over tau. It starts with the one over tau squared term. tau it starts with the one over tau squared term it's got a coefficient which is positive because that's basically the expectation value that breaks supersymmetry it's f squared essentially and then there's corrections that go like one over tau and and these these functions remember a and b and w x they all depend on things like standard model fields but they can also depend on logs of tau because they can depend on logarithms of mass scales and mass scales all have taus in them so if you get things involving different numbers of taus in their masses you can get logarithmic dependence on tau in these coefficients On tau in these coefficients. Now, the potential that we got here is not small. So, if you think of 1 over root tau is a weak scale, then a potential that goes like 1 over tau squared is what you would expect if you had an m weak to the fourth term. So, there was no free lunch here, but you're understanding kind of why the answer is scaling like the weak scale to the fourth, but there's nothing which is unusually small in this picture. But it's the fact that this first term is positive that's the interesting thing. It's a square of something. A square of something. So I can imagine adding another field, or a relaxation kind of a field. And as long as that field passes through a point where wx goes through zero, if I only had the first term, it's going to want to find that place because that's its minimum energy. And that'll turn off that term. In general, it'll be more complicated because we have these other terms. But if you imagine, what'll happen is that if I perturb away from the solution that made wx zero, what'll happen is that I get wx will be order one over tau because it'll be dragged away. Order one over tau because it'll be dragged away by the second term, and that's what happens when you do it in details: that that intuition is right. So, that makes this term go like one over tau to the fourth, and it makes this one go like one over tau to the fourth, and it competes with this one. So, they all start to compete with each other at the place where this relaxation field goes to its minimum. And so, the generic way the potential looks is it's one over tau to the fourth times a function which could involve the logarithm of tau. And that's a very attractive form for a function to have. The first thing is the logarithm of tau is actually. The logarithm of tau is actually very interesting because if that log, that function, it's very easy for this. It's an exponential potential in terms of the canonical field, but that function of the logarithm of tau can give you a divot in it and can give you a local minimum or local maximum. And imagine taking u to be a quadratic function, just to be concrete. It's very easy to design that quadratic function to have a minimum. And this plot is showing you kind of how it looks. And you can have it be negative. You can have it be positive. That be negative, you can have it be positive, and what's the reason this is working is that you're chirbing away from a scalar invariant point, which is at zero. You think about why desider space is normally hard to get. People are normally starting at anti-desiter space because they start in a supersymmetric place. And this is not a supersymmetric place. So you're perturbing away from a place at zero. So positive and negative are equally likely to get when you perturb away from that. That's interesting. Second thing that's interesting is a thing that goes like one over tau to the fourth, from the point of view of the standard model, that looks like eight powers of the standard model. That looks like something which is m. Model. That looks like something which is M standard model squared over M Planck to the fourth power. That's actually a very interesting numerology for the vacuum energy because the weak scale squared over M Planck is kind of ballpark of where the vacuum energy wants to be. Now, that's kind of a cheat because that's a very nice dependence on tau, but remember that the thing that we should be comparing to the benchmark is the supersymmetry breaking energy, which there's a floor as to how big that can be because we know that we've integrated it out. So it had to be very heavy. So if you compare that, the So if you compare that, the value of the potential at its minimum to the thing that was breaking supersymmetry, the dangerous thing, this is what it turns out to be. The supersymmetry breaking term can't be smaller than 10 TeV. But the interesting, you know, I told you at the very beginning, this mechanism is going to give you an additional suppression by 1 over tau than more than you thought you were going to get. So there it is. You get an extra one over tau. You also happen to get five powers of one over log tau in this simple model, the first model we write down. And if you put in the values for Put in the values for how as being 10 to the 28, then this gives you out of the box a minimum, which is 10 to the minus 91 in Planck units, which is not the right answer, but it's way better than all the other answers on the market. And the thing I forgot to say is that because the things you're adjusting, the things you put into the parameters and the potential to get that minimum, it's a function of log tau. So no numbers go in that are bigger than 60. And that's giving you log tau is of the order of 60. And so this number like 10 to the 28 is actually coming out as the exponential of a number. Is actually coming out as the exponential of a number in your brand, in your parameter, in your potential. So it's kind of a very suggestive framework. You know, there's lots of things that have to be that you could do better. You might ask, why didn't we try and do better to get a lower vacuum energy? The reason is, is that once the potential is below 10 to the minus 80 in Planck units, then this tau field is light enough. You know, it's generically, it's gravitationally coupled to a small potential. Now it wants to be light. And that way I argued at the very beginning of the talk. Way I argued at the very beginning of the talk. And so it's once you're below 10 to the minus 80, then you've got long-range forces that look like brand sticky fields. And so they look like they should be fatal to you. So I think the most pressing phenomenological issue in these models is how do you understand the long-range forces in these models? And that's the thing you want to nail down before you try and push this down any farther, I think. At least that's the priority that we've had. So that's my long answer. So that's a long-winded motivation for a class of theories. I started off by saying that we're looking for two scalars if we're going to be testing things at low energies. And now I've kind of tried to sell you that the natural choice for those two scalars would be a dilaton and axion. So you have an axiodilaton. Now I want to talk about, there's various phenomenological issues, but I want to, in the time I have available, just talk about cosmology. And in particular, you know, it's kind of hard to resist because the axion could very well be the dark. Axion could very well be the dark matter. The dilaton with this kind of potential is actually a viable model of dark energy. So you needed two things in order to test gravity at low energies. The problem is normally that when you test gravity at low energies, general relativity wins. Except for two cases, dark matter and dark energy, maybe the two things that we need at low energies are the two things that we see. And so I want to explore whether or not you can make a reasonable cosmology. More broadly, I'd like to ask, if you have couplings, which are that story of the cosmologic concept, Which are that story of the cosmologic constant problem I told you, the yoga models, the couplings of the tau field to matter were not small, they were Planck size. So it should have been, it's light, it's a brand sticky scalar with an order gravitational coupling. It should be ruled out. So that means that you're looking for in these kind of models screening mechanisms. Are there ways in which macroscopic objects have weaker charges than the individual atoms they're built from? And I'd like to know whether or not the masses you see in cosmology, are they tied to the masses that you see? Are they tied to the masses that you are measuring in the solar system? And so, as one step towards that, I want to look at the phenomenology of these models in cosmology. And that'll be my last topic. So I could see that I'm within a minute or so of being finished. You can have another 10 minutes or so, Cliff, because we started a bit late. Okay, I set a timer of 50 minutes, so I think I've built in that Slack. And I know I'm between you and dinner. So this is not going to be a problem. I'll describe this. And if there are more slides, I could show. If there are more slides, I could show you, and if there's people ask, I can show you too, but I'll kind of finish this and then see where we are. So, the basic problem I'm trying to address is: in this class of models that I'm trying to sell are very well motivated from the UV and from the kinds of things you're looking for to see deviations from general rotivity at low energies, the problem I'm being led to by thinking of a brand sticky of a diletton is that it's a brand sticky-like particle, and the couplings needn't be small. So, what I want to do is. Needn't be small. So, what I want to do is stand back a little bit and not do the yoga model I told you about. I want to take that class of axiodileton models and treat these couplings as parameters and ask: what are the options? And in particular, one of the options I might allow myself to do was just dial the coupling to matter down to make it agree with the solar system tests. And so, there'll be two things I can present slides for if people are interested. The first one is: let's just do that. Let's dial the couplings to matter down. So, let's not have the axion top to matter at all. Axion talked to matter at all. Well, let's have the dilaton couple by 10 to the minus three strength so that it passes the solar system tests that Brown Sticky theories had to pass. That gives a kind of a very minimal structure. You can ask in that framework, can those two fields be the dark matter and the dark energy? Is that something which it's a constrained framework, but it has some freedom? And you can ask, is this a viable model of dark matter and dark energy? And I want to argue. Dark dark matter and dark energy. And I want to argue that it seems to be. It seems to be that there's lots of things to test, but the very first things you check seem like they're going to work. The other way to go is if I really believe this vacuum energy story is telling in the relaxation story, these couplings should be bigger. And then that means that there has to be a screening mechanism. And there actually have been, but you need a screening mechanism that is going to survive at low energy. So it has to be relying on this derivative couplings and not on the kinds of screening mechanisms you often see in the literature, which are difficult to get from UV. The literature, which are difficult to get from UV completions, and there are proposals for those screening mechanisms, which I won't talk about, but they change how the cosmology works because they involve giving the axion coupling to ordinary matter, and which is a and so there's a there's trade-offs you have to make, which I won't talk much about, but which there's a direction I could talk about. And I want to draw your attention to what I'm not going to do is I'm not going to do any fits. I'm just going to calculate what happens using, I'm going to evolve fluctuations using CAM, but I'm not going to be as sophisticated as. But I'm not going to be as sophisticated as Masha was in her paper. And I got this one coming out soon where she's actually doing parameter estimations, and I won't be doing that. All right. This is a screening slide and we'll talk about, sorry, question? I said also eliminated here. Just okay. Sorry. Yeah, yeah. All right. So here's just an example. So I'm going to show you a couple plots from an example. A couple plots from an example which was aimed to be the dark matter and dark energy, asking what the cosmology of these things look like. So it's so the model is just basically you've got the standard model and you've got these axiodilaton and you've got gravity. And you have those ingredients that I described, the non-minimal kinetic term, and you've got this potential, which I'm going to take to have that form that was suggested by the yoga case. And I'll take two different choices. I'll either take it to be a pure exponential where this is just a constant, the thing of the pre-factor, or I'll take that quotation. the pre-factor, or I'll take that quadratic function of chi, which was the thing that was being motivated by the log dependence of the potential. And I'll take zeta here to be a parameter. And I've chosen this zeta. I didn't take the potential to be an independent parameter as the one that was in the kinetic term, because that's what happened in this yoga case, that they were related to each other. But I'm going to keep them related, but just let lambda, zeta be a dial, just so we can see how things vary as a function of that. And here's a plot of. And here's a plot of the background of the fluid energy densities. And so you red is radiation, baryons and the axion are the blue ones. And so they're just doing the standard one over a cube thing. And the dilaton is just rolling down the potential. What happens is that the potential, it's either got to be very shallow to get a, to give you dark energy so that you just have a slow roll down the exponential, or if you have a, you can, you can be steeper if you have that minimum, because Hubble friction often stops you from going over the edge. So you kind of slide down to it. And then, but you have to start. To slide down to it, and then, but you have to start kind of reasonably close there because at nucleosynthesis, the value of the dilaton is the mass of the particle, and the masses can't have changed by much. So, you can imagine that you start near where we ended up at the minimum at nucleosynthesis, and then you let things go. And typically, the interesting thing is something happens. Even if you start off at rest in the past, the scale invariance makes the fields go into attractor solutions where they actually evolve. And it's very generic for the radiation matter crossover, kicks the field and makes it. Crossover picks the field and makes it do something. And so in the CMB, you like to see different masses than you would see now or nucleosynthesis is the interesting thing. And then so now the question is, are those things observable? This right-hand plot is just showing you the fraction of the total that's in each of these fluids. So here's kind of what the CMB would look like. The left one is the CMB and the right one is the power spectrum. And the various curves are just tracking different values of that zeta parameter. Different values of that zeta parameter I gave you. And they all assume that the coupling to matter was given by 10 to the minus 3. So it's something which is small enough to evade the solar system tests. And what you can kind of see here is that the main thing that you see in the CMB is not surprising that you start changing the mass, you start changing the Sox-Wolf effect for light coming out of the potential wells, because now the fields that they're tracking have masses that are evolving because the scalar fields are evolving in addition to the usual motion of things. In addition to the usual motion of things under gravity. And if these lambdas are too big, then you see that for the small L's and the CMB. But if once lambda, once Zeta is smaller than about 0.1, then all the plots start to look the same as the Lambda CDM plot. So there is a constraint on Zeta, but it's not such a super strong one. Here's an example of structure in the later universe, and mostly it's contrasting on the left an exponential potential to a potential. To a potential, which has got a minimum. And that's just because what happens, the difference between those two things is that when there's a minimum, you oscillate around the bottom of it as you get trapped into it. And you can kind of see that clearer here. This is showing you what the diletton is doing. Here it starts off by assumption at where it is now or at the minimum back at nuclear synthesis. And then you can start it there at rest, although the velocity you start with doesn't really matter because the Hubble friction tends to suck you into a tractor solution very quickly. Very quickly. But what's generic in these models, it's hard. You can't arrange for Chi to do nothing. It always does a thing where it does an excursion, and that's because this attractor you're in does a change. It's trying to follow the dominant energy. And when you go through the radiation matter transition, that's changing the attractor. And there's a transient that goes through the system. And so it does an excursion. And that means that generically, all particle masses are starting to do excursions too. And they tend to go positive in this class of models I'm looking at here. But then there's a thing where they settle down and they oscillate at late times as they go. And they oscillate at late times as they go around them as they as they approach the minimum. That's also true for what I showed you before was the standard model particles. This is showing you what the axion does. This is the decay constant on the left, and this is the mass of the axion. Basically, what's happening is that the decay constant does an excursion because the decay constant is this non-minimal kinetic term. And then the mass changes because the decay constant is changing. That's the bottom line. And it can be bigger in this case just because it's not the same coupling. It's not controlled by the same coupling as the matter coupling to it. By the same coupling as the matter couplings were. And this is an example of this is what the this is shows you what the kinds of equations of state parameters you'd get for the dark energy in these models as a function of A. And you can kind of see that they're not very well captured by linear functions of A, which is not surprising. If the basic observation is that we see a W, there's evidence for W increasing, this can probably be accommodated here, but it's something where this is really where you have to do a better. This is really where you have to do a better job of parameter estimation to see how this would, whether this is a helps you with a daisy description or anything. But it's just that the thing is, these models predict what the W should do, and it's not a simple thing. And so it's something which ultimately, when we can measure the equation state parameter better, that will be a test of these models. And then there's a similar story for cases where the couplings are large enough that you need screening that are coming from the yoga kind of story, and those can be made to work, but it's more delicate. To work, but it's more delicate. The dark matter couplings have to be kind of similar, but not the same as the matter couplings. And so I'll just skip these slides. And let me just conclude. So basically, there's three messages. The first part of it was, you know, we're trying to measure tests of gravity. We're looking for candidates to rule out or rule in. And the power counting. And the power counting of what can compete with gravity and low energies is important for that. And given that we analyze everything classically, we have to stay within the semi-class approximation, which means we have to be in the derivative expansion. So the two derivative terms are the ones we should be looking at. We should have lots of tools for examining two derivative terms. And unfortunately, we don't have those, even though we've been thinking about this for decades, because the simplicity argument of using only one scalar threw away the interaction that has two derivatives. So that's too bad, but I think that's something that that's an opportunity now. But I think that's something that that's an opportunity now. There's a class of very well-motivated things to look at at low energies, which are not very well explored, which is not that common in cosmology. UV physics can be informative, but not in the swampland way where I have to tell you that I think I know what's going on at the UV. I'm just going to use generic symmetries that are approximate symmetries at low energies. And so if you think about in QCD, the difference between the soft pion predictions, which are symmetry predictions of QCD, as opposed to the value of the proton mass, which is a UV. To the value of the proton mass, which is a UV-sensitive prediction of QCD, I'm just making the soft pine kinds of information from the UV. Whereas the essence of the swampland program is telling you that there are things that are UV sensitive, like the proton mass, and that those are the things we should be focusing on. And that's usually a counterproductive argument at low energies. And so that's the difference, I think, between the program I'm describing and the swampland one. And then it's remarkably rich physics. Even this is simple axiodileton has not more complicated. Is not more complicated than the single-field models that people look at. But there's lots of interesting things that go on. And in particular, if the dilettan is really an honest to god dilaton, the fact that masses are changing or predicted to change as a function of time and position opens up a host of ways in which you can start testing and searching for those kind of effects. They were small in the case I looked at because I dialed the coupling down to make the solar system tests work. And then once I've done that, then you're only getting like part per mil changes to. Like part per mil changes to the masses at the CMBs, which are too small to be measured. But if I had had larger couplings as the yoga model would have wanted to have, those mass changes would have been larger. And so then there's a lot more tensions on those models. And whether that will work or not in the long run depends on how you would screen those forces that make the solar system tests viable. So there's lots going on and we're having a wonderful time and wish you were here. And I hope you enjoyed the rest of the time at Banff. The rest of the time at Banff, and thank you for your time. Any questions for Cliff? I think we'd probably do about five minutes of questions because we won't be running into him again. I have a question, Cliff. When you had this actual dilatory model, what were you putting into it? What were you putting in for the potential of the axiom when you're giving it mass? Could it be the QCD axiom that's also this axiom delaton? No, it couldn't be the QCD axiom. Well, there's actually a story about the QCD axion that I did not mention. Because Masha mentioned about how you get things that are kind of smaller mass than normal. This yoga thing that suppresses vacuum energies also does that. But that's something which is a work in progress that it's not really clear how that's going to work out in the end. But the first approximation, the approximation that these are this is not the QCD axion. And so in the in the model I showed you where it was dark that it was playing the role of dark matter, we just put in a potential which was a trigonometric potential, but it was not coupled to the standard model parameter. So it was one I was going to allow myself to dial the size of to get a mass. And the success of the cosmology that I showed you turns out not to depend much on the mass, apart from the assumption that the mass is bigger than the Hubble scale at BBN. Mass is bigger than the Hubble scale at BBN. And so kind of a benchmark you might take is 10 to the minus 15 or 10 to the minus 14 or something like that. But once you're kind of in that regime, none of the things I showed you depend much about the details of the mass and the decay constant, but they would if I had tried to tell you what the production mechanism was. If I had tried to do a relaxation mechanism where I had something which is frozen and started to roll, and I wanted to tie what I saw at late universe to what was going on in the early universe, then I start to have to tell you what the F and I start to have to tell you what the F and the mass are. And we did not do that. The attitude I'm taking is that, particularly if I can make progress on the cosmologic constant problem, I'm happy to do a lot of phenomenology in the early universe and in the solar system, because I think that's a good trade. Because the vacuum energy is normally a hard thing to fix. Why the mass scale of PBI?