Having invited me to give his talk. So it's a great pleasure. Of course, it would have been better to be in Bonf right now, but we understand. So the idea of my talk follows a little bit the last few slides or comments of Dave in his talk and Remy as well yesterday. Uh, yesterday, and somehow we've seen there that strong minimality is a central notion in differentially closed fields and in model theory. And one of the key problem is to understand strongly minimal sets. We don't have full understanding, but this is somehow a problem that's, if you want, internal to model theory or DCF, although it has been. Although it has been applied successfully. So, what I try to do in the talk is to do something a little bit, I guess, more modest. I'll simply try to use a slightly more general notion called irreducibility, which shouldn't be confused with irreducibility of differential varieties. But I'll use this notion to try and explain the relevance. And explain the relevance of strong numbers outside the context of model theory. And I will also then talk about a little bit about the problem of proving that differential equation is strongly minimal. So here you already see that I'm going to use this language. I'm going to say that a differential equation is strongly minimal when it really means that the solution set in a differentially closed field is. Is. Okay, but let's cut to the chase and go and see this notion of irreducibility as defined by Umemura and introduced by Pen Levey. And the idea is that irreducibility means that the solutions, all the solutions of your equations are new. So, what does it mean to be new? And so, Umemura sort of made the ideas of Pendlevet. Peneva clearer, I don't know, or in more modern language, some would say. So, in what follows, I will somehow be talking about Meromorphic function. I won't be mentioning the open set over which it's definite. And so I'm gonna allow myself to move, change that open sets, open subset as free. And so I'm not gonna, I'm gonna identify the function with its restriction. Function with its restriction. And I will have S a set that contains Meromorphic functions on some domain. And this would be my set of known function at the moment. And then I'm going to describe permissible operations that tells you how from this set S do I get more new functions. Okay. Okay, more known functions. So the first three operations can be simply said in a moment, but so if you have a function in S, you can differentiate it. If you have two functions, you can add, multiply, and divide if that makes sense. And you can also take solutions of algebraic different algebraic equations where the coefficients Equations where the coefficients are from the set S. And those roots will be known functions as well. And so all this is to say is that functions that are in the differential field generated by the set that contains known functions are known. But now notice that this idea of the set S is fluid in a sense that now that these are known functions, Unknown functions, I can put it in the set S and build more functions from that. Okay, so if I integrate, oh by the way, I forgot to mention that everywhere for me, the variable would be t. And so I'll be working with d by dt throughout. And if I'm working in a differentially closed field, I fix an element t in that differentially closed field, which when you differentiate gives me. Which, when you differentiate, gives me one. So, this is the idea. And so, yes, so the integral would be known. If I take solutions of linear ODE, where again, I take the coefficients from my set of known functions, then the solutions will be known. And the last one, the next one, is a little bit more involved, and it's about a billion. And it's about abelian functions. So if I take a lattice and in such a way that the quotient with c to the n is an abelian variety, then if I take an abelian function, say monomorphic function on that variety, and I do the right composition, then and where the f1 to fn, that should be an fn here, f1 to fn are known, then and are known, then the function, the composition I obtain is a known function. And finally, Ronnie, may I raise a question from the chat about this one? Could you say briefly what is a billion variety and maybe give the simplest possible example? So a billion varieties. So, abelian varieties would be a projective variety that has a group compatible with group structure on it. And the easiest example would be the elliptic curve. So it's an abelian variety of dimension one. And here the group structure to be abelian, right? So I mean? You want the group structure to be abelian. Right, it follows that it will be abelian, I think. Okay. Yeah. And so here, what we want is that this Here, what we want is that this quotient is indeed a projective variety. Okay, thank you. Is that okay? Okay. All right. And the last one is somehow this is going to depend, and in a moment we're going to see that, but this is going to depend on the differential equation I start with. So for each k, I also have qk, which states that if I have ODE, ODE, where the coefficients of that ODE are from set of known functions, then the solution will be also known. There should be an N here. Okay, so far, any questions about that? And so if I'm going to take a differential equation of the following form, which is degree one in the highest order, for simplicity, there's no Order for simplicity, there's no particular reason for it. It's going to be simpler for me in the next slide. So an f is a rational function in n variable, and n will be bigger than one. So I'm looking at equation of order two or bigger. Then it's, I'm going to say p irreducible, so that if people join later on, they don't. If people join later on, they don't confuse that with the irreducibility of a notion, which for Penlev√©o Memura, if starting from the set of constants, so S is going to be my set of constants, and now I cannot express none of its solution by a finite iteration of the operations. And where, if I start with an equation of order n, I only use up to q and minus one. Okay, and so. Okay. And so if you may also raise a question from the chat and also one from myself. So in the chat, there is a question whether it would make sense to allow to join also solutions of PGs. So here, yes, so that's it. I'm working in the one in ordinary context. So yeah, so my talk is DCF0. So differential fields with a one derivation. And so this is a notion in one derivation, and I don't think it's been Notion in one derivation, and I don't think it's been worked out from a differential equation standpoint. But I think from a model theoretic standpoint that we have this notion of analyzability that fits in that context. But it makes sense, but not for this talk. Okay, thank you. And one more question, just somehow to clarify. Is it true that if I allow Qn, then the definition will become boring, right? Will become boring, right? If I allow Qn, so let's see. In the definition, then sort of the equation which is written is already of order n. Right, it's already of order n. So that's why I go up to order n minus 1. So this is why this is n minus 1 and n would not make much sense. Okay. Right. Okay. Thank you. You're welcome. And so here's the some not bad news, but somehow the annoying thing is that if you start with a differential equation and let's If you start with a differential equation, and let's say it appears in an application that you care, if it's irreducible, then it means that it's highly transcendental in a sense that none of those very classical operations that I described earlier will allow you to get your solution. So, from the perspective of application, it's not a positive outcome to find out. Positive outcome to find out that your equation is reducible. But as we shall see from a multi-theoretic perspective, it's exactly where we study those sets in particular. And so this notion would be useless unless we had a way to verify it. And so Umemura worked out the details of that. And so the equation is said to be easy. Equation is said to be easy, it is p ireducible if it has no solution in CT alge. And the next is a very strong form of saying that you do not satisfy any, no solution satisfy any equation, differential equation of order n minus one or order one, from one to n minus one. So it says that. This one. So it says that if I take any solution, and the hard bit is that in any finitely generated differential field extension, then either I'm going to get that the solution is going to be algebraic over, or it's going to be of transcendence degree n. So it's going to satisfy your equation only or algebraic. Okay? And so Okay, and so I like to somehow always like to give this example if you look at the so if you look at the equation y prime prime is one over t, then whenever you allow this, if you allow log as part of a differential field extension, right, then you Then you have a order one sub variety. But to see that order one sub variety, you added somehow a solution, you added log t. Let's put it this way. And so somehow this generated by field extension is a non-trivial thing. So you have to look for no sort or lower order equation in any differential field extension. Any differential field extension. And so the punchline here is that this condition two is what we mean, we call strong limit mal. Okay, so a definable set is strongly minimal. Remember, it's infinite and any definable subset is finite or co-finite. finite and another way to write it for concrete equation is as you see down this condition two here and so strongly minimality is quite connected to this idea of irreducibility and for from the model theory standpoint strongly minimal sets are good in the sense that there's a precise manner in which we can say that Manner in which we can say that every differential finite-dimensional differential varieties are built using strongly minimal sets. Okay, so any question at this point? So this is the connection with strong minimality and the connection with if you want to solve differential equation and so you're lacking. And so, your lack of ability to do so if you want. And so, now let me talk a little bit about proving strong normality. So, that's going to be the rest. So, now that we know that irreducibility and strong normality can be interchange. I had a little question. Yeah, go for it. Sorry, the Q1 to Qn minus one is about you can't, there's no solution in. There's no solution in what? Can you go back to Q1, Q1, Qn minus 1? So you have to add, so if you remember, you want to do one classical, and then one classical would mean you don't satisfy no solutions where the solutions are. So, but aren't these QNs enough to do everything? Aren't they enough to get everything? The other stuff is about strongly normal extensions. The other stuff is about strongly normal extensions. Do you need the PIs? You don't need the P1, P2 anymore. No, so somehow if you want, it's let me think. Right, right. So you're absolutely correct. But somehow, so when you usually talk about strong numerality, it's hard. Normality, it's hard for people to understand that if you are order bigger than one, you rule out all things that are non-orthogonal to the constants. And that is all this phenomenon of linear differential equation, all the phenomenon of, so that's why I spell it out this way. So, so that people know that when you are strongly minimal, you're actually ruling out. are actually ruling out all these very natural all these natural operations. It's not clear if I just gave a definition of strong linemanity. You have to know maybe the trichotomy to know that. Okay, all right. Sorry, Ronnie. I will mute myself now. Just one small comment in the chat: it seems that P6 didn't appear. It seems that P6 didn't appear, so maybe P6 did P5. Oh, yeah, P5. Right. Thank you. Okay, type. Just, just. Any other questions? All right, so now one, so they are sort of, it's a, as we said, it's a problem we care about in model theory and it's relevant in differential equation. Relevant in differential equation, but it's actually, it can be quite hard to prove that O D's are strongly minimal. And so let me give an example. So if you start with the equation given here, y prime prime 2y cubed plus Ty plus half, well, it's not difficult if you differentiate the expression given here to see that you have an odor one. to see that you have an order one sub variety. So and in some ways it would have been it would have taken you maybe a day to discover that order one sub variety. It's not too hard. But let me just simply change the half to three over two. Ronnie, may I ask just a short question? So to rephrase when you To rephrase, when you s say about one order one sub variety, you mean that if I differentiate the equation of order one, I will get equation of order two. So every solution of equation of order one is a solution of order two. Exactly. But not vice versa. Right. And so somehow you have your original equation will have some solutions that satisfy this equation of order one. And so you don't consider it. And of course, I mean, as James Freytak did, you can. James Freitag did, you can, in this case, you can get rid of that order one sub variety and everything still works, but that's a little technical thing you can do in model theory. But what I want to show here is if you somehow change the half to three over two, well, you would have to discover this order one sub-variety. And it's rather, I think no one ever. I think no one ever differentiated that and checked that you indeed get the equation here. But somehow there's a way you get it. But just to show that somehow it can be highly non-trivial to find this sub-variety. And so what I was hiding here is that this equation is the second pen of the equation with parameters alpha. So it was isolated. Is alpha. So it was isolated by Paul Penleve and as one of the equations of the form given here that has the Penlevet property. So any local analytic solution can be continued as a Meromorphic function on the universal cover of P1. So in this case, less infinity, I guess. Less than infinity, I guess. So, this is Pennovic property, but I won't spend too much time on that. But here, what you see is in this case, you have this nice transformation called the Bacland transformation. So if I get, I start with a solution W of my equation, then I have two transformations given by the differential expression, differential rational expression there, that if I that will That will solve P2 alpha plus 1 and P2 alpha minus 1. Okay, so it's, and this one is not difficult to check. And this, of course, this depends on alpha. So for each alpha, you have an expression. And what this shows you in this case is that you can use that to show that the order one sub-variety grows as n. Grows as n grows. Okay, and so somehow you couldn't have this blanket statement, blanket statement about how there's a bound for you to find sub-varieties. Anyway, so I think time is flying quickly. So if you think about examples of trying to prove strongly more set, the first one you'll come across is the equation. Come across is the equation here. And it was proven that by Poissa and Bruno Poiser both proved that, but I've read the proof by Dave Marker. And somehow they show that this is strongly minimal, but the calculations involved are sort of quite specific to the equation, and it's quite brute force calculation. And so recently we've Recently, with James Freitag and Remy Jowey, we realized that there is a short proof of strong linearity for the equation of Poisson. And somehow, and this proof allows us to generalize, but even then, it's really specific to this form of equation. So let me just say the equation here is y prime prime. The equation here is y prime prime is y prime, and where p q is a rational function that has simple pole at y equals zero. So one over y here is an example. And so I simply want to show the proof. I'm not going to show the full proof, but what the technique is involved. And some of you can perhaps pick up how you would generalize that using, I would use Priso series, but you wouldn't have to do. The series, but you won't have to do so. So if that equation was not strongly minimal, so I'm going to give a proof of the equation of Poisson. If that equation was not strongly minimal, then I would find a solution and a differential field K such that the transcendence degree is one, okay, of a differential field generated by solution. And one way you can rephrase that is that the function f prime That the function f prime is algebraic over kf. And you can quickly check that it can't be in k alge because of the form of the equation. Oops, it's fine. And so then what you can see, because it's in the algebraic closure of Kf, you can simply take a Puissa series expansion and realize that the U itself. The u itself satisfies a first-order equation, if you want. And just by comparing the coefficients of tau, you get a contradiction. It's a straightforward calculation, a straightforward observation. And it was somehow strange to us to see that one could do that so quickly compared to perhaps the proof that we had before. Before. And so, and then this can be generalized using for the other kind of expression. You don't even have to use a pre-set series expansion. And so, here, what I just wanted to show is somehow that we have, even for very simple looking equation, we have it's not easy. And somehow, yes, excuse me, can I ask a question? Because I understand that. Question, because I understand that in your original definition of this irreducible irreducibility, the equation should have no known solutions at all, right? No, say that again. I understood that in your original definition of when this the this irreduci uh the function has to be irreducible, that there should be no known solutions at all of the equation. At all of the equation. No, according to how I defined it, yes. But if you take this equation that we see here, that you circled, any non-zero constant is a solution. Any non-zero constant. Well, if I take y equals one, for instance, then it satisfies the. Yeah, so somehow, yeah, so I'm hiding something here. Something here. So, what really is strongly minimal is this equation with the added condition that y prime is not zero. Yeah, could I just say Jim said something. So, so Yoris, you know, his condition about strong minimality is weaker than irreducibility. Right, exactly. It's not the same as irreducibility. He's not assuming. The same as irreducibility, he's not assuming strong neural is a weaker condition than irreducibility, right? Yoris, I think Yoris was identifying those two things, right? And so, somehow, I'm so from a model frame, even from a model perspective, I'm allowed to talk about the equation and cut out, let's say, y prime equals zero. And what that shows you really is that y prime equals zero is the only order ones sub-variety, but from a point of view of strong. But from a point of view of strong minimality, which is not ignorability, that's okay. That makes sense? Okay, so there are two notions. Thanks. Okay. All right. So and so it turns out that. And so it turns out that two minutes, it turns out that for the Pendove equation, Pendovey claimed that for generic values of parameter, the set defined by the equation would be strongly minimal. And this took some time to prove. But in the end, it was shown that the place where we saw this order one sub-variety was the only place where you The only place where you had a non-strong lemon minimality. And I just want to say somehow that we in model theory are interested in generic values of parameters, but it turns out that even outside model theory, that plays a role. So, for example, it was shown in that paper that even with generic parameters, the second pen of A appears in random. Appears in random metric theory. Not that I'm an expert or I know much about, but they do appear generic parameters. So running out of time, but let me just say quickly, we are able to do much more than just those simple examples. So here, let me just give an example of so-called Schwartzian triangle equation. So here, STY is the Schwartzian derivative. Is the Schwartzian derivative? And we have a rational function of y on the right-hand side, which depends on parameter alpha, beta, gamma, which are constants. And so the solutions are called a conformal mapping of the hyperbolic triangles to the complex upper half plane. And in the special case where you're looking at integers satisfying the condition. At integers satisfying the condition given here, they are so-called Fouxianotomorphic functions. And Penevet again claimed in that case that the equations will be strong on the minimal. And this is exactly what we were able to show and more with the joint work with Geek Asal, James Freitag. And in the case where the parameters are taken to be 2, 3, 3 The parameters are taken to be 2, 3, infinity, that was already proven by Freitag, James Freitag, and Thomas Cannon, that indeed these equations were strongly minimal. And just to say that strongly minimality is quite a strong functional transcendence result. And we were able to use this result to somehow, and much more, to prove what's called the Acklinum and Weierstrass theorem with derivative. And so I've And so I think I'm running out of time. But then so, what I'll end with a slide that I wanted to say, and I'll stop here. So we all extended that result in work with David Blanket, SAS, and still James and Guy to show that a generic equation, when the alpha, beta are algebraically independent over Q, then the equation is also strong. Then the equation is also strongly minimal. And I just leave it here. And the key method in the proof is somehow the power of quantity, one of it is power of quantify elimination in the theory and the study of strong minimal set where somehow you are able to, if you are able to express things using a first formula, you have some power to somehow prove such results. So I'm gonna stop here. Prove such results. So I'm going to stop here because I don't want to go too much over time. Thank you, Ronnie. Questions? May I ask a question? Yeah, sure. So, Ronnie, for someone who is doing modeling, what are the key observations you think they should take out of your presentation? So, somehow that, so there's So there's two things, as I said. So the first one is there are equations out there that would have this property strong normality and somehow which means that the solution are highly transcendental. And so somehow it might appear, so like the Pennova equations or equation that started to appear in May. Equation that started to appear in many physical applications. And there's no technique yet that is available to solve these equations or to get a hand on these equations. And so somehow maybe the relevance is that it might be in some of your models that the equation is strongly minimal, and it would be good to know so that the So, that you are not trying techniques that are due to fail, if you want. I don't know, that could be something. Other questions? Yes, I have another question. So, if you have an equation that is extremely irreducible in the strongest sense, right, do all Do all the solutions somehow look the same? Or can it be, nevertheless, that there are solutions of the equations that are more particular than others? So yes, so it happens. I mean, there are two key examples. So for example, the Fuchsian automorphic function that I describe here. So the J function is one of them. So the J function is a solution to a strongly minimal equation. Solution to a strongly minimal equation, but we have some control on it. Same thing for if you look at Pendove 6, there's so-called, it's called Pendove Picard equation, and it's given in terms of the Weistrass P function. And so there are some that do appear, they do appear using some maybe classical function like the Weistrass B function, but somehow They still consider it irreducible according to the definition. It's not perfect, but I don't know how to explain that particular phenomenon. So I think Gikasal has looked at the Penovi six, this Penovi equation given by, which is irreducible, but given by Weistra's P5. By Weistra's p-function, he's been able to use his theory to detect the difference between this notion every reduced. So I don't know if that helped. Okay, so let's clap Ronnie. Thank you. And we have three minutes, break.