Asked to talk about pragmatic and foreign daisy approaches, something that I talked a little bit about in the 2021 meeting. So, as we just said, I'm a statistician. My experience, I've been to lots of these meetings, but I haven't really worked with particle physicists. I have worked extensively with astrophysicists, and there are, of course, differences, and there's lots of similarities, but there's some differences as well. For example, they don't tend to be quite so concerned about the frequency problem. The frequency properties to 5 sigma, for example, and they tend not to have quite such big data sets. So there's some things that will be different in our approaches. Bayesian statistician, I say not overly so for some of those same reasons I'm interested in the frequency properties of my Bayesian procedures, for example, but again, I'm not so concerned about the frequency properties. I must have floated reasonable. I'm not going to be quite so dogmatic as some people might want to be. Dogmatic as some people might want to be. Okay, so systematics and multistage analysis. Where does this come from? Why am I interested in it? Astronomy, like a physics, has lots of new data resources. I say they're massive new data streams allowing explicit modeling of detailed physical processes. And in practice, this is often modularized. That is to say, there's different people doing different parts of the analysis, different research groups. Analysis, different research groups with different statistical strategies, different astrophysical ideas using different models. And some of them are going to be better or worse at communicating those sorts of things. And we're trying to take the output from one group's analysis and use it as an input in a subsequent analysis. So there's some kind of challenges there. And what we want to do is to think about how we can combine it into an omnibus principle. Combine it into an omnibus principle of analysis and quantify uncertainty properly. So we quite use these terms in this meeting, but I remember talking about the preliminary analysis and the primary analysis in the context of physics. So I'll be using those terms throughout. Quote from Bob Cousins from 2019. When you discover a new dimension or a particle, can you convince the world you understand systematics well? The world you understand systematics well enough to back up your claim. So that's you know, that's what we're trying to do. Three topics: a general framework, and then I'm gonna go through a couple of examples from astrophysics, and then I have some general comments about Bayesian or not being Bayesian. And we'll see if we get to that or not. It's not really my remit for today. So, I'm gonna go through kind of a running example, and just to give you a little bit of an idea of what's involved, this first couple of slides are trying to do that. Couple slides are trying to do that. So, astronomers are interested in what's going on over here in this figure. Basic physics-informed astrophysical models that might turn into the form of parameterized models, computer models, multi-scale models. But over here are parameters that the physicists, the astronomers are interested in that might describe the composition of a source, the temperature of the source, the history of the source, the distance, all these sorts of things. Unfortunately, the source also has to go through instrumentation. Instrumentation, background contamination, blurring of photon locations, blurring of photon energies, and the thing I'm going to be focusing on is the effective area of the instrument. And so the effective area is essentially telling me the sensitivity of the instrument varies with the energy of the photon. And this is zero here. So you can see that the this this curve i it varies quite a lot uh by many factors, uh orders of magnitude I guess. Orders of magnitude, I guess. And so getting that curve right is going to have a pretty big impact on my ability to learn about the spectrum, and the spectrum is where the science occurs. So it's pretty important. Calibration scientists, so a different group of researchers, work on the calibration of the instrument. And they are going to, or have been able to provide us with a sample of possible calibration products, so if possible effective area curves. Effective area curves, which represent their uncertainty. And we like to fold that uncertainty through our analysis. So you can see, not very well here, but this is a kind of a residual version. So you can see there's like the one sigma and two sigma range for these effective area curves, and you can see they squiggle around quite a lot. So there's kind of high correlation, highly structured correlation and uncertainty. So what we would like to do. Uncertainty. So, what we would like to do, we're going to be Bayesian. It's a Bayesian procedure. First thing to say is what the standard or the default Bayesian procedure, or Bayesian or not Bayesian procedure, what an astronomer would typically do is to just take the middle curve, the best curve, and treat that as if it were known. So, one of the things we're going to try to do is to see if that matters or not in our ultimate analysis. So, our Bayesian procedure is going to take that standard model, which conditions. Standard model which conditions on A, the effective area in our current data set and learns about parameters of interest. And we're going to try to average over uncertainty in A, which I'm going to write down as a prior distribution. But it's not a subjective prior distribution. It's a distribution that just summarizes this right here. Oops. Sorry, David, can I just clarify? The calibration scientists. The calibration scientists, do they give you a pariah for those different lines, or they just give you the different lines? They give you the lines. Okay, yeah. So, I mean, I'm not going to go into it, but then so there's a job to do to take those lines and turn them into a function. So, this is the result for kind of a toy version here. And this is the two parameters we're interested in. They're thetas, those are science parameters. The purple dot is the true value. This is the posterior distribution. This is the posterior distribution, a sample from the posterior distribution. What the curve is something like a 95% contour. And you can see it's off. And the reason is I've picked an example where that default effective area was in the distribution. So systems then. It's in the distribution, but it's like one that's kind of off in the light grid. So it's off center. So we got a little unlucky in that initial analysis. And that caused what I'll call bias over here, although it's not to be. What I'll call bias over here, although it's not frequency bias, it's just posterior distributions that go around the place. Systematic errors, here I'm just plotting the best fit for each curve in that sample. So you can see that the systematic errors are a lot bigger, in this case, the statistical errors. So probably I will want to worry about the effective uncertainty and the effective area in this case. And this is the statistical errors for each or for a sample of values here. And because this is a nicely formulated problem, Is a nicely formulated problem. All of those little ovals are about the same size, or are in fact the same size. So, those are the basic output. And what I want to do is think about, in the context of that example, think about a way I can formulate a general way of approaching the problem. So, I want to do this in terms of physics, what you guys, the ways you kind of think about this. And we've talked about multiplying the likelihood. Multiplying the likelihood as one possibility. So we have, again, this is using my notation. I've added y0 just to make clear that this is, you know, it's like a likelihood that I'm learning about the effective area curve from a data set, and that is in fact what the calibration scientists are doing. That's just from my point of view, when I'm fitting this likelihood, this thing looks like a prior issue, because I've never seen the Y0. So, what could you do? You might, you know, you want to do, you know, You might, you know, you want to do inference under this likelihood, which takes the likelihood I'm interested in, multiplies by their likelihood. You might do profiling over the effective area, high-dimension profile in this case. And one thing I want to kind of emphasize here is that in this analysis, my estimate of A is going to depend both on what the calibration scientists did and from my current data set, because my estimate of A is coming from this thing that involves both of those. Is coming from this thing that involves both of those data sets. So, my estimate of the effective area is going to be different than what those calibration scientists told me it ought to be or it might be. Won't go through this Bayesian justification. This essentially looks like, you know, landlines times prior distribution. So from my point of view, it's a pretty easy thing to justify. OPAT, we've talked about one parameter at a time where I have my effect. My effective area curve, and I take, you know, I go one sigma off the mean in one direction and one sigma off the mean in the other direction. I find my best estimate of sigma of theta in both of those cases. I look at the difference, and I say that's an estimate of my effective area. I'm sorry, of my systematic errors. And then my statistical errors are based on just the conditional likelihood, where I condition on the best estimate of A. And notice here that this is something that. And notice here that this is something that's quite different, right? Because this A hat that I'm using is the A hat that the calibration scientists gave me. So my current data does not inform my estimation of the underlying effective area curve. So, questions: What if sigma A is asymmetric or maps non-homonotonically on theta? This kind of analysis seems to me, there's quite a few kind of To me, there's quite a few kind of assumptions that are being made to make this kind of a legitimate thing to do. If A is high-dimensional, actually, in my effective area purposing, it's pretty, it doesn't really make sense, right? Adding sigma, subtracting sigma, it's a high-dimensional thing. A possible, and here's pragmatic Bayesian solution is to instead of just using these two values, sample A from its prior distribution, and for each value of A, sample a new value of theta from the resulting posterior distribution. The resulting posterior distribution. And that turns out to be exactly what I call a pragmatic Bayesian solution. The reason we call it pragmatic Bayesian is because, you know, working in a context where the astronomers are used to using just one value of A that the calibration scientists gave them. And instead of like building this more complicated model where now they need to also estimate the effective area curve, we're going to say, just sample an effective area curve, do what you did before, and repeat. And repeat. Okay, so it's pragmatic, it's really easy, and it brings in uncertainty in that affected area curve. So the general strategies here, pragmatic Bayesian, fully Bayesian. Fully Bayesian is pretty easy to think about. You know, I'm going to base my inference on this thing, which is that the product of the posterior distributions, I've just factored the joint posterior distribution. And the pragmatic has, instead of The pragmatic is instead of averaging over the posterior distribution of the affective area, it's going to average over the prior distribution of the affected area. Okay, so I'm not using my current data to update my estimate of the systematic parameters. So one of the concerns or what you might think about when you look at these two things, from a statistical point of view, the full Bayesian uses all of the data, so it ought to reduce the variance. It's the thing that a statistician. Variance, it's the thing that a statistician would probably do. Maybe they wouldn't be a Bayesian, but they would do something like this, use all the data, something like the product of the likelihood. Cultural, some astronomers have concerns about letting the current data influence the calibration products. The calibration scientists are the experts, right? They know about calibration. Do I really want, in this world, so you have lots of astronomers, they all have their own data sets, they're all doing their own modeling, they have a data set. Model. They have a data set. They make up their model. If they pick the wrong model or the wrong prior, they are affecting their estimate of the effective area. Do we really want my estimate of the effective area to depend on whether or not I include a spectral line or not of my model? So these sorts of concerns. Let the calibration scientists do calibration. Let the astronomers do astronomy. So I kind of mentioned this future bias. If I misspecify these things, I learn about A, and I take that forward into a subsequent. And I take that forward into a subsequent analysis, that can be quite problematic because I just wrote down the wrong spectral model, and now I got the wrong effective area into the future. Current bias, the pragmatic phase, at least in some cases, doesn't require me to set up so many models. There's not as much for me to do. There's fewer things to go wrong. Computational pragmatic phase is easy, as I've mentioned on the previous slide. Practical, if they give me the same answer, one's a lot easier. They gave me the same answer, and one's a lot easier, and I don't have to worry about fussing with calibration. Well, I should probably use the one that's simpler. Well, but we have to kind of see how different are they. And here's the answer. It turns out in some cases, anyway, they can be quite different. So here is my, this is just like the picture we had before. This is the pragmatic phase, which is because the systematics dominate, looks a lot like the picture I had in the last one, but this is just full. Point, but this is full variance. So, this the variance here is a little bit bigger, it has systematic and statistical variance. And the fully base is narrower, right? So, it turns out that the effective areas over here, the effective areas that result in estimates here and here, are inconsistent or less consistent with the data. So, the data is narrowing down to the posterior distribution. These effective areas, curves of the calibration scientists, are not particularly don't seem to be consistent with the data that I'm observing. On the data that I'm observing. So, Nick said this is a question for statisticians. Questions for physicists: Should the primary analysis update the Newsence primary? To me, the real question is, is that a statistical question or a subject matter question? So from my point of view, it kind of depends. If I think I am, as the astronomer, in a position to kind of second guess the calibration scientist, then this is probably the right thing to do. Probably the right thing to do. And if not, maybe not. So it's not clear to me it's a statistical question, but it is certainly something to think about right now. And it's kind of nice that these two the pragmatic phase of the fully control. She's got the answers. The forward propagation or OPAT approximates that words. Had approximate base, or is essentially the same as a pragmatic base if you do it, you know, fly sampling. And the multiplying likelihoods is the same as fully base, except you've gotten the prior institutions. So that's kind of the framework. And I thought it would be nice to, if you look at this picture here, you know, this isn't an indication of bias necessarily, except, well, I know that I'm getting the wrong answer because I have the wrong effect of area curves. Because I have the wrong effect of area curve, so I'm guessing it's probably biased. So, this is a different example, but just to give you an idea of what happens from a frequency point of view: columns here are four different parameters in a model, and I have 30 replicate data sets. This is the default, so I'm using again the wrong effective area curve. Maybe it's not an effective area curve, but some systematic parameter. And I get everything is off systematically. When I do the pragmatic solution, the interval is widened. The intervals widen up and capture the truth, but they're systematically off, so it's still biased. Whereas this one looks really, really nice because the defoiling case actually pulls over and the uncertainty is no bigger than the original. So this is what, you know, in this case, you're like, well, this is what we should do. It's worth thinking about what we mean by bias in this case, too, because you're thinking about this. Again, I'm an astronomer, and my replicate data sets are. And my replicate data sets are new data sets like the one I have. And I'm saying what the systematics have, what's happening with the systematics, is just fixed. If I did the replicates in terms of both of those experiments, then these, the effective area curves would be moving around as well, and the picture would look quite different. So because I'm not really a frequentist, I don't, you know, this is one of the reasons I kind of think it's hard to be a frequentist, because it's not always clear to me what the proper way to think about the replication. The proper way to think about the replicates on it. But from that point of view, that there's these calibration products that I'm going to use. I have some error bars on it, and I'm just thinking about my current data set. That's the experiment I'm in control of. Then we have this kind of bias. Okay, so I wanted to go through a couple of examples. Let's see how I'm doing. And what examples are being plotted in that previous plot? This one. Yeah, yeah. So these are error bars. Yeah, yeah. So these are error bars. This is for one day. Oh, yeah, I haven't given you the context. I just wanted to show you because I don't have the simulation for that toy problem. Okay, so let me go through at least one of these examples. So this is event selection, and I can think about the point is I have events that I need to figure out which events to include in my analysis. Which events to include in my analysis, and which events are not part of my analysis. So it's kind of a classification problem followed by a data analysis. And I can do this either from a pragmatic point of view or from a fully Bayesian point of view. So I'm going to consider three approaches. The default analysis does a classification problem, a classification exercise, and then it assumes that that classification is known in the subsequent analysis. In the subsequent analysis, which is false, but it's something you might imagine somebody doing. The pragmatic analysis is going to try to account for the uncertainty in the classifications. And the fully base is going to try to update those classifications based on additional data. Okay. All of this is easier if I have a probabilistic classification. All of this I'm thinking about, kind of where I can think about uncertainty in the classifications. So this is. So, this is the Orion Nebula and the trapezium at the very center of the nebula. X-ray image of the trapezium. You can see there's lots of point sources that are close together and overlapping. Stellar nursery. Physicists, astrophysicists are interested in learning about what's going on in these different sources, their composition, their temperature, this sort of stuff. So stage one is going to be clustering, a little bit of notation for each photon. Photon Zi, I want to find the probability that it belongs to source J based on its X and Y coordinates. This thing now becomes, this is the parameters that I'm trying to learn about. These are the kind of parameters you don't want to be thinking about asymptotics with, right? Because there's the same, you know, this is, there's as many of these as there are data sets. It's a data-specific parameter. And then stage two, I'm going to fit source-specific. And then stage two, I'm going to fit source-specific models for the spectra. Okay, so what happens? So, and that's stage one, I'm going to use a finite mixture model. The xy coordinates are going to follow a distribution that equals the point spread function centered at the location of the source. That's for photons that come from that source. And I'm also going to model. And I'm also going to model the energies because the spectrum might also be informative for me to help me in my classification. I'm going to use a non-science-based model of just a gamma distribution because these things tend to look like that. And the reason I want to do that is because I don't, you know, we're working on a catalog, and for each photon, I want to give you a probability that it arises from this source, and then that's the catalog that goes out to the astrophysicist who can then use it. Astrophysicists who can then use it in their context to fit various models and think about how they want to use it going forward. That's enough. So I should say, I guess the only thing that's worth saying is that, yeah, we considered whether or not we just want to use the x, y coordinates or also the energy. Turns out using the energy is a useful thing to do. This is the posterior distribution of the number of sources. Distribution of the number of sources with only using the xy coordinates. And if I also use the full model, I get a narrower distribution. The energy is informative as to the number of sources and also affects the classification. And using more information, it's generally. So now let's go ahead and think about what happens in that secondary analysis and how it might differ if I want to use a fully Bayesian versus a pragmatic Bayesian. So I'm looking at the fitting source-specific spectrum. Fitting source-specific spectrum models, data sub J, J indexing the sources. Again, the default analysis just splits the photons based on whichever, based on which point source in the closest to. The fully Bayesian analysis is going to, I have the energy, the x, y coordinates, that's what I condition on. What I want to learn about is the classification, the nuisance parameters, which are things other than the spectral parameters, and the spectra for each of these. And the spectra for each of the individual sources. And here I've just factorized that. So these two things here have gone to the conditioning, and then over here, this is their marginal distribution. Everything everywhere is conditioned by the data. So this is my classification problem. I'm trying to learn about the Zs and things like the source locations and other parameters that describe the classification. So that just goes down exactly. So that just goes down exactly as was for the clustering. And this thing here, now I'm going to do a separate model for each individual source. The sources are independent. If I know the z, I know which photons came from which source. So I'm going to just segregate those photons off for each source. I'm going to fit whatever spectral model I'm interested in and learn about those parameters. Okay? So that's kind of exactly what I'm doing, right? The fully Bayesian. I'm doing right the fully Bayesian Bayesian analysis. I do the clustering, and then based on the clustering, I can do the parameter estimation for the individual sources. The thing that's gone funny here is that the models that are used by these two groups of researchers are different. Here I'm using the simple gamma distribution, and here I'm using a science-based model. So there's actually a technical term for this. The models are simply not congenial. Are they not congenial? They're not friendly. They have a livelihood, but they don't kind of fit together properly. So that's fully Bayes. What is the pragmatic Bayes would have done, would have said, the energy is what I'm using. That's the new information at stage two. I don't use the energy at stage one. So energies are not used in clustering. There's no spectral model here. Spectral model here. Okay, so that's kind of what the difference is. So including energy at stage one classification approximates the fully phase, but with non-congenial spectral models. So what I end up with is a kind of a biased variance trade-off. The pragmatic phase, right, I'm using less information, I expect the variances to grow. The fully base is doing this kind of funny thing by using models that aren't quite the same in different parts of the model. And so that's a bit of misspecification, so I expected. And so that's a bit of misspecification, so I expect a bit of bias to come from that. So, what does it actually look like in practice? Without going into too much detail, there's two of the sources that are overlapping and very strong. So, 35% of the photons came from this source, 7% from that source, and we were 14 sources. A lot of these have probabilities of 1% or so. And I'm going to try to separate them. What does that mean? That means your time is basically up. Basically, they took me at 25 minutes. Yeah, they took me at 25 minutes. Yeah, so this is the. Oh, it's 25 minutes. Okay. Okay. 55 degrees. Well, I'll be done. I'll finish what we're doing. Okay, so what happens here just is that these lines here are the default analysis where you just say, I just segregate the photons. I just learn about them. This distribution is the uncertainty that comes from accounting for the uncertainty in the entire. Accounting for the uncertainty in the classification. So you can see that the uncertainty in the classification, this is like statistical error, right? The uncertainty in the classification is, at least for this parameter, significantly larger than the uncertainty due to statistical uncertainty. So it's worth keeping track of that sort of uncertainty. But maybe I can just do, this is another problem. I won't go through this slide because there's a lot on it. Supernova classification. Supernova classification. I want to classify supernovas. Type 1A supernovas from them, I can learn about cosmology. Non-type 1A supernovas, they can do, I can't learn about cosmology from them. So what I want to do is classify them and then use this. I have a science-based model for this type Ia supernovas that tell me about the parameters of interest, the cosmological parameters of interest. If I try to do something If I try to do something where I analyze, take everything forward, and do a fully Bayesian analysis, well, that means I'm going to get extra information about the classification from the secondary data set. And the way that I do that in a finite mixture model, if I have an observation that's right here, I estimate the probability that it's from this source is this density divided by the sum of those two hits. That's all fine, except if this model is a model that I just had to include because I was forced to. I just had to include because I was forced to, because I'm doing a fully Bayesian analysis, and so it's some ad hoc model, but this is a very carefully orchestrated science-based model. I probably don't want to update my probabilities based on that model. So the pragmatic Bayesian, that's another advantage of the pragmatic Bayesian solution. I don't necessarily have to include these additional models. So let's just leave it at that, and this is my summary slide. Default and naive methods, under uncertainty, and can. Under uncertainty and can't introduce biases, as we described, avoid them unless the nuisance parameters are very well estimated. If you really know what your nuisance parameters are, it's probably fine. Pragmatic base, a simple way to avoid these kinds of problems, but they can overstate the uncertainty and still exhibit a funny kind of bias. But it's always better to overstate your uncertainty than to underestate your uncertainty. So that's kind of the selling point. So you kind of the summing. So, you're kind of the, you know, somebody who wants to do something freaking dirty. So, that's like OP, right? Something freaking dirty that brings in the systematics, but not in the most sophisticated way. Pragmatic, oh, let's say that again, this is supposed to be fully Bayesian methods. Best to use of the data requires coordination of preliminary and primary analyses. If you want to do it properly, you run into these problems where you have one group of researchers that are using one kind of likelihood, another group of researchers are using another likelihood. That introduces its own. Likelihood that introduces its own biases, right? So that bias variance trade-off. And it may require additional models, assumptions, which are raised to at the very end. So I'll stop. Thank you. Thank you, let's have more questions. Yes, so in your second example where you're clustering things, do you have to have Clustering things. Do you have to have the number of sources? You have to specify that in any way. Do you have to have a prior for it? Or the first one, yes, because the first one, there's like their stars, right? This one, it's really like... The first one, the one before this. Yeah. Oh, this one, yes. Yeah. That one. So there is a prior. Where'd it go? I skipped over it. Oh, okay. Why is it Passon? Uh because it's a count. Okay. No, you, of course, want to be a little careful about these. I mean, in this problem, that K, I mean, okay. You know, that K is going to be like, you know, do I include this thing here? Yeah. It's not where the action is for the problem that we're really interested in, which are the two. There's no doubt that those two are the. It's just, you know. There's a question from Zoom which says: this concept seems to be related to the, sorry, this seems to be related to the concept of modular. Related to the concept of modularization and cutting feedback in the hierarchical model literature. Is that right? In the hierarchical modeling literature, I'm not sure. Maybe, Tom, this is from Tom Loreto. Maybe you can unmute and explain it. I can turn it back on. I didn't want to see myself. Like I'm looking in the mirror. Oh, can you hear me? We jang it up. Can you hear me? Hi, David. Hi. You're like God. Something I've been learning about in another context of this corner of the hierarchical modeling literature on a concept that's sometimes called cutting feedback and sometimes called modularization. And it seems to do what you're doing here. It's when you want to kind of break the feedback connection. Kind of break the feedback connection between layers and a hierarchical model. Sometimes for conceptual reasons, like the ones you have here, where you might think there's misspecification at one level that could corrupt inferences at the other level, and sometimes it's done for computational convenience because full days can sometimes just be too hard to do. So it's just a room of art that I only learned about a few years ago, but it's a relatively small literature on it. Small literature on it. So, I'll have to call it modularization and cutting feedback. Both terms are used. There are a few papers on them. I'll try to put some references in Slack to come up and pop up. Great. Thanks, Tom. Okay. Can I pick an issue with your final slide? You may. Yes, I want to quarrel with your it is better to overstate than understate uncertainty. I thought that was what. I thought that was one thing. It is true for engineers, it's probably true for accountants. But for physicists, wrong is wrong in either direction. And I've spent so much time in experimental committees with people who say, well, we take a conservative approach. So we make our systematic errors as large as we like. So when we had this picture, right, 95% coverage is this amplitude picture, right? Where you had the one that the Where you have the one that the coverage did this, right? I'm not going to realize it went down up yet. But I mean, went below 95%. So this is undercovering, and this is overcovering. So the question is, would you be happier having something that stays up here or something that's down here? If I've got something which is minus 5% coverage, I want it. No. You're not comparing light with light. I am. This is exactly what this is, right? This is under. This is going to be. This is right. This is under. This is going to be this is 95% coverage. This is undercovering. This is overcovering. This is underestimating uncertainty. This is overestimating percent uncertainty. But if you're quoting wrong results, even if it doesn't matter which direction it's wrong in, it's still wrong. Okay. Okay, you probably have good reasons for saying that, but I didn't want to let it go. Oh, yes, okay, that's fine. That's fine. Okay, then. I was just going to say, but you never. I was just going to say, but you never know you're wrong. But there are at least five pounds up there. Should we start with the background? Actually, I wanted your question to physicists about whether you should update Neustin' parameters. So, sort of interestingly, I think in a lot of cases, like at the LHC, we have calibration scientists and calibration groups. We generally think the amount of data used in calibration. Think the amount of data used in calibration is so much larger than any primary analysis that, actually, the first thing we do anytime a nuisance parameter is significantly changed by the analysis is go back and check whether the spirit of the model in the first place. So, almost uniformly it's a model problem than it is actually someplace where we want to. Then actually learning, but maybe other people understand. So, I can add to that that there are cases where it was the opposite, and then what happens is that the people who are doing, let's say, the astronomical analysis are. We're doing, let's say, the astronomical analysis are told, can you please go to the calibrators and show exactly what you're doing so that that can be incorporated into the calibration? So that also happens. Sorry, I have one technical remark. I think for the last session, what happened for your session, you know, everything was booked for your talk, you know, not as a discussion session, and that led to a shift of 25, half an hour into the schedule. So they made some. Yeah, so can you declare? That they made some, yeah. So, can we declare this to be the opening of the discussion session? Maybe they notice.