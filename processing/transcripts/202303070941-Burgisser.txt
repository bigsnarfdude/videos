Also, I'm not in banned, I'm here in Zoom call. And yeah, it's my pleasure to introduce the morning's first speaker, Peter Birweser, my local colleague here at Tigo Berlin. He is a professor of algorithmic algebra and he's very well known for his work in complexity theory. He is widely known. His widely known publications include the model graph condition, jointly with Filippo Kuka and published in the Stringer Gundlier or Yellow Series. He also was awarded an ERC Advance Grant for his proposal complexity and condition in algebra numerics in 2019. And he will now also give a tutorial talk on this topic about conditioning. Okay, Peter, just a Peter, just uh okay, thank you, Jurg. Thank you for the nice introduction. I hope you can all hear me. So, let me share the screen. Yeah, where is it here and the full screen? Okay, so you can see it, yes, okay, okay. So, it's a pleasure to give this talk. It's my pleasure to give this talk here. Maybe I should start with a little disclaimer. So, the title of this workshop is Theoretical Computer Science Meets Numerical Analysis. I think I'm more on the theoretical computer science corner. So, but my education is not numerical analysis, but somehow I converge toward it. And I happen to write the book on condition. So, but maybe my view of the things is a little bit different from the one that numerical analysis. The one that numerical analysis have, and of course, I'm happy to learn more about it. Right. So, after this disclaimer, so let's have a look at the oops, that was too fast, an outline. So, the outline of my talk basically have three parts. So, I begin with the basics. What is a condition number? I will explain this general concept mainly for the condition number for matrix inversion, which is also. Number for matrix inversion, which is also called Turing's condition number. Then there's the second part, it's a little bit basically some warnings. One has to be really careful. There are different notions and it can be very confusing. And probably Jim Demmel in his talk will elaborate on these things. I will very briefly mention trial matrices. And then we move to things that I like very much. So the condition numbers can be generalized, can be defined. Generalized, it can be defined in a very large generality, and I like a geometric framework. So, I like geometry, and so I definitely give some definitions basically going back to rice from the 60s. And then the rest of the talk will be explaining how one can implement these ideas for the very basic problem in the linear algebra of computing eigenvalues and eigenvectors. Okay, and then good. So, that's the plan. Good. So that's the plan. And if you have a question, so feel free to interrupt me, or maybe I also have the chat open. I've tried to watch it. Okay, so let's start with the Turing's condition number. As you know, it was introduced by Alan Turing in the 40s. And about the same time, John von Neumann and Goldstein wrote a paper where also this notion appeared. So very general. So what is a condition number? So a condition number. Number. So a condition number is always associated to a computational problem. So I have a function f open defined on an open subset of r to the p to r to the q. And I want to measure the sensitivity of the output depending on the input. So I have some x input and I assume it has a small error. And how much does this affect the output? Okay. But how do we measure errors? There are many ways of doing it. Errors. There are many ways of doing it. You can measure it absolutely, or you can have relative errors. You can do it component-wise and normal-wise, etc. So there are many options. So for this beginning, let's focus on norm-wise relative error. So now I assume that on my input space, in the output space, I have fixed some norm. Okay. And then I have the error delta x. I take the norm of that error. Take the norm of that error and I want to look at the relative error, so I look at this ratio. So, of course, x should not be zero. Once it's the relative error, okay, and then I have the relative error of the output, norm of delta y divided by norm of y. And I want to measure how much it depends on the input error, but only in first order. So, and basically, this condition number, this is not the rigorous definition, but this is the intention. Kappa stands. Kappa stands condition of the function at x is like the smallest number, so that to first order you can upper bound the relative output error as this number condition times relative input error. Okay, and if you want to have a rigorous definition, I mean, I could write the Lim subdefinition, but I don't want to do it. Let's assume the function is a decent one, let's say smooth, differentiable, and then very easy to. And then very easy to see because we are focusing on first order. So, we actually do: we look at the derivative of f, it's a linear map, and let's just take the operator norm, which is well defined. I have defined the norms, it's just, you know, you think of worst case. So, basically, the operator norm of the derivative, it would be the condition when you would be interested in absolute error. But because I said I want to measure relative error, I have to multiply it with no. Error, I have to multiply it with norm of x divided by norm of f of x. So that's exactly that. So I think that's a notion. It's very clean, and you can teach it in any calculus course. Okay, basically it's calculus. Okay. So now, okay, now I have this very little example. It's quite nice. Why not? Let's take, I want to invert a real number, non-zero number, x goes to the x minus one. What is the condition number? You take the derivative, you know, calculus, calculate. You know, calculus, calculate, we get one. Okay, why is it one? It's a bit strange. Well, it has to do because we measure relative error. Otherwise, it wouldn't be one. Okay, now the same thing. Let's do it for matrices. Instead of a number, I have an invertible matrix A. The map is matrix inversion. I'm aware in numerical analysis, some people say one should not invert the matrix and so on. One should rather solve a linear decision, but that chats don't care about it. But that chats don't care about it. Matrix inversion is a very fundamental operation and it's very clean. Okay, so I compute the derivative. One has to be a little bit careful because it's non-commutative. So the derivative at a maps a dot to minus a to the minus one, a dot a to the minus one. That's an easy calculation. And now, okay, let's use the spectral norm with respect to Euclidean norm. Then we upper bound this. Then we upper bound this as the norm of a to the to the minus one squared times the norm of a dot. And it's quite easy to see that this is optimal. So that the operator norm of the derivative is this notion, norm of the inverse of a squared, right? And then if we multiply with these things as before, because we account for relative errors, we get this famous formula for the classical condition number of a matrix, which is denoted. Of a matrix which is denoted kappa, so it's norm of a no times norm of the inverse, and it's we see it's a scale-invariant notion, okay? So, as I said, it was Turing who introduced it, okay. Um, so so this is a definition comes from calculus, right? It's a calculus definition. Now, it is very fascinating that there is a geometric interpretation to that. To that, namely inverse distance to ill-posedness. Okay. So for this problem of matrix inversion, the ill-posed inputs are the singular matrices, the non-invertible one. I denote its sigma. And there is the theorem by Eckhart Jung, is also completely classic. It says that the norm of the inverse of the matrix is one over the distance of A to the sigma. A to the sigma, and you can the distance you can either measure in operator norm or you can do Frobenius norm, it doesn't matter, it gives the same. So, okay, so if you are close to sigma, the norm of the inverse explodes. So, then so if we plug it in into our formula for the condition, we see the condition number of the matrix is the norm of A, spectral norm, divided by this distance. Okay, and this also. Distance okay, and it's also very well known and, of course, super important that this distance of a to sigma is the smallest singular value of a. Okay, so right, we will see that this phenomenon that condition is related to this dwell positness appears in more generality, right? But here I explain it for the matrix condition number, it's the most basic situation, okay. Finite precision, so there are different elements. Finite precision. So, there are different aspects to this condition. So, one is finite precision. Of course, when we compute our digital computers, they have to round. Now, we cannot compute exactly with real numbers. People decided to use floating point numbers. And there is a round-off unit, let's say epsilon machine, like 10 to the minus 12 or whatever. And then, okay, whenever we compute, we know that. Compute, we know that, then actually we always compute an approximation x twiddle of x with a relative error, which is bounded, okay, by this machine unit, right? And okay, there are some IEEE definitions how to do it, but that's not important. So, what one calls basically what one, right? So, the logarithm, let's say to The logarithm, let's say to base 10 of delta divided to the machine precision is called the loss of precision in decimal digits that we have. Now, whenever we compute, we have an algorithm computing in every step we round some error per seat, and so we lose bits of precision. And this can be measured in many cases also by the condition number, but that's not completely clear. So, I think. So I think probably you are those that are numerical analysts, probably you know, but I think one should really one should clearly distinguish condition number of a function from what an algorithm does. So now I assume I have an algorithm A. It's a numerical algorithm. Usually it's written with you assuming you have exact arithmetic, but when it's implemented, you have finite precision and you make errors at every step. Okay? So there is this. Okay, so there is this like fantastic idea, I think, going back to Wilkinson of the backward analysis, okay, in order to quantify what happens with these errors. And he had this idea, suppose we can show that for all inputs X, there exists some E, right, such that what A spits out, so this should be the calligraphic A, so what the algorithm spits out on X is exactly. Is exactly f of x plus this hypothetical error e. Okay, so we, of course, we hope that e will be small, so we call this the backward error, right? So it's not easy to do backward analysis of algorithms, right? But assume we have done it, so then we are only in very good shape because then we can bound what people sometimes call the forward error. So now here on the left-hand side, a of x minus f. the left hand side a of x minus f x norm is actually the error that you know the machine the algorithm produces which is then this f of x plus a minus f of x norm which you bound to first order by the definition of the condition condition times norm of e okay so that's a very general principle in a way very powerful because all of the work relies in the backward analysis so i picked one example of an important algorithm that is the householder householder This is the householder QR factorization algorithm. It's a very important algorithm in numerical analysis. And there is an analysis, a backward analysis. I think it's due to Nick Hayim. And that's what it says. There's a bit a lot of text, but basically he did such a backward analysis on invertible matrix A and B. Um what do we want to compute? Okay, da da da da da da. I'm wondering whether Wondering whether, yes, we come. Actually, we want to solve the linear system. I didn't. Maybe I think there's something missing here on the slide. I think I forgot to write, I want to compute x such that ax equals b. I'm sorry for that. I missed that. And actually, what the algorithm computes in the x twiddle. And then, you know, here is the quantification of the error. And it's a little bit technical. Maybe it's not if you have never. Technical, maybe it's not if you have never seen it, it's not important to understand exactly what it is. But combining this backward analysis with what I said before, then we can say the loss of precision of this algorithm is bounded by the logarithm of the condition number plus 2 log n plus some constant. So, right. Okay, so we see if we have backward analysis, we can. Backward analysis, we can bound loss of precision. Okay, sorry for that little error. Maybe I will fix it before I upload the slide. Okay, but there is another aspect to condition. Condition often also appears as a complexity parameter. So complexity in the sense of how many operations do you have to do to achieve something. So many numerical algorithms are iterative, right? You only compute the result up to a certain precision. Compute the result up to a certain precision epsilon, and you want to bound the number of iterations. Okay, the famous, most famous example, probably method of conjugate gradients, or even more basic gradient descent, but let's do conjugate gradients. So, here this is an example, very famous. You have a positive definite matrix S, you have B, and you want to solve the linear system SX to the B, right? And then you have some pick some start value, and then you compute the sequence of iterates somehow is not on. The sequence of iterates somehow is not important. Now, how you do it, it converges to the solution. And there is a famous analysis of this procedure due to Hesternis and Steevel, okay, from the 50s. And they proved in order to achieve relative error, it suffices to execute that many iterations. And what we see here is the square root of the condition number of the matrix times the logarithm 1 over epsilon. So here is maybe the first example where we see condition number enters as a Condition number enters as a complexity parameter because this has nothing to do with the precision and so it's just number of iterations. Even if you could compute exactly, it would matter. Okay. And there are many, many results in the spirit of sometimes people call it condition-based analysis. I think this name maybe goes back to a paper by Steve Smail, where he kind of said, I have a numerical algorithm. That I have a numerical algorithm, I want to analyze it. And then, first, what I do is I identify the right notion of condition. There are several options. And then I analyze the number of steps in terms of the condition. And maybe in the second step, I study probabilistically what happens with this condition number. So there are okay. So the like we are talking about linear algebra, but you can do this analysis for This analysis for optimization, linear optimization. So, Jim Renecker came up with the definition of condition number, or you can do polynomial equations solving non-linear problems. There is a series of paper by Schubert Smale, and okay, that's basically, let me see, okay, I wanted to say that later, and that's also in this book I wrote on condition we cover all these examples, okay? So, what Okay, so let me continue. Now, if we know precision and complexity depend on the condition of a matrix, so how can we say something meaningful about the quality of an algorithm? Okay. So one idea is to understand what's going on typically, right? So you may say, okay, let's say A is random, just like something typical. Typical. It may also be structured, but for the moment, let's just say it's a random matrix which is Gaussian independent standard Gaussian entrances. And then, right, then you can analyze what is the condition. And actually, there is a random matrix theory. It's very well developed and basically gives you the answer. Like, we know what is the joint probability density of the eigenvalues, of the singular values, and so on. So, what one can do, one can analyze it, and this. Can analyze it, and this formula that which is written in blue here is in this precise form is due to Alan Edelman from his thesis. He proved, among other things, that the expectation of the logarithm of the matrix condition number is equal to log n plus a constant. Okay, so this gives, for instance, this tells us about the average loss of precision for the householder QR factorization. Okay, that's nice. So somehow. It's nice. So, somehow. It's small. If you say, if I see log n, I think of it as a small number. No, I'm this computer science background. People think that's small. So can you hear questions? Yes. So you say that there's an average loss of precision for householder QR. A couple slides back, you said, here's the condition of analysis for householder QR, but it wasn't for that step, it was for solving linear equations with that. Presumably, one could. Presumably, one could, and I don't know if what I mean, what I meant, I was I meant right, so I'm not precise. I meant the householder QR factorization for solving the linear system. That's what I meant. Maybe this is. Could you go, but you could presumably go back a few slides. Householder QR takes its input a matrix, fits its output two matrices, and do a condition number analysis just for that subset of the linear equation solver. It just tells only QR to C or others do that. On the QR mask, others do that. Let me see if I understand. I forgot. So I forgot. So condition number analysis is not for solving linear systems with householder QR, but condition number analysis of householder QR by itself. Does he or others do that? Yeah. Yeah. That's right. You're right. That's right. I mean, that. Yes. Yes. Well of the method. I mean the method which computes I mean you want to compute a to the minus 1B which is X and the method gives you the X twiddle. No a different problem is take as input a matrix spin as output two matrices input is A output is Q and R. Yeah, I'm not talking about that. Does I am or anyone else do that? Do that, yes, probably. Yeah, I'm not sure. Yeah, that's a well, that's a well-known result. The answer is that you know, a minus qr is also machine order machine epsilon times the norm of a, and qq transpose minus the identity is also order epsilon. Okay, thank you, Jim. Sure. Okay. As I said, I'm not a numerical analyst. I don't know everything, but that's of that's very. I don't know everything, but that's of that's very basic, of course. So, good. So, probabilistic analysis: there is another way of looking at it. You may say this, what I showed you before was just an average. Maybe it's not very compelling. There is this notion of the smooth analysis, which was invented by Spielmann and Teng. I will return to that a little later. It's a more refined form of probabilistic analysis, and what you do is the following. You let's say I have a matrix A bar, let's say of normal most one, and then I look at the isotropic Gaussian with mean a bar and variance sigma square. Okay, so now the Gaussian is not centered. The idea is like a bar would be the true value and you add a little bit of noise. So like we had in the talk by yesterday, by Joel Drop, right? So then the condition number, of course, becomes a random variable. Becomes a random variable, and you can analyze it. And there is a result by a probabilist, Mario Schebor. He gave the tail, and okay, he bounded the tail of it, like the probability that the matrix condition number is at most t is bounded by a constant times n over sigma t, and this is optimal up to the constants. Okay, and then so the k is one over t. There is also a geometric reason for that and Geometric reason for that. And then this implies if you go to the logarithm of condition number with the intention of loss of precision and so on, then you see you also get log n plus log one over sigma plus a constant. So this is for the smooth. And you see, of course, when sigma goes to zero, then this becomes bad. But it no, but it grows only slowly. So do you mean the probability the condition number exceeds t? Okay, I have. Okay, I have two statements. The first display statement is the tailbound. The probability that the condition number is less than. Oh, sorry, this is the typo. Yeah, that should be greater than T. Sorry, that's a typo. Oh, my gosh, I have to check. Of course, this should be greater. I will fix it. This should be greater. I'm sorry. The probability condition is greater than t is less than this and that. And then, my, okay, it's almost automatic to arrive from that that. Almost automatic derived from that. Thank you. That's another typo, an obvious one. So, somehow people like to say this in the following way for all a bar and slight random perturbations, A of A bar, it is unlikely that the condition number is large. You may take for A bar an ill conditioned matrix. It doesn't matter. It's still true, right? You perturb a little bit, it becomes much better. Perturb a little bit, it becomes much better. Okay, good. So, this is this topic of smooth analysis of numerical algorithms. So, as I already said, this is a new form of analysis of algorithms that was introduced by Spielmann and Tang, and they got all, you know, all imaginable prizes for that, that you can imagine. And so, for what? Actually, they came up with this idea and they managed to give a smooth analysis of the run. To give a smooth analysis of the running time of the simplex algorithm, right? But this idea, this great idea of smooth analysis, is not restricted to simplex. You can do it for many numerical algorithms. Actually, for many numerical algorithms, a smooth analysis of the running time can be reduced to a smooth analysis of condition number. This is the idea of condition-based analysis. And that's actually in this now. Let me admit the book I wrote. Let me advertise the book. I wrote Philip Cooker with the title condition. That's basically the goal of our book was to explain this, right? In all these cases, not only linear algebra, but also linear programming, polynomial equation solving, etc. Smooth analysis. Okay, so okay. So, but some words of warning. There are many variations of condition now, Muslims really have to. Of condition normalism, they really has to be careful. So let's say maybe, you know, okay, I defined the normalized condition. So here is the definition, but again, a little bit more general when the function is not smooth. So what do we have? Function. Condition number at x, you have the limb for delta to zero of the limb soup of the soup. So you look at this quotient, relative error of f of it. Quotient: relative error of f of x divided by relative error of x when the relative error is less than delta. So, this is basically if f is smooth, it gives what we had before. But however, let's assume now the data is somehow structured. For instance, we have matrices, the matrices, for instance, they may be sparse or I don't know, symmetric or triangular or whatever. But then, to be fair, one should only To be fair, one should only allow structured perturbations in the definition, right? And then we get something different. So, right, so that's what I hear. I focus on matrices. So, this is another type of the L should be an A. I'm sorry for that. Okay. Okay. The condition number F, like I, for instance, I describe a sparsity pattern. I only allow perturbations respecting this pattern. And then the function, the condition that I get would be less. I get would be less than the condition number, and the upper bound by the condition number may be pessimistic. It's not, you see. So, what I want to say, this condition number of a matrix may not be the appropriate, not the right notion when you have structure. Sometimes it is, but not always. And I'm sure Jim knows much more about it than I do. Okay, so here triangular matrices. This is quite a famous example. So, there is a So, there is an interesting result by Wisnav Wattan and Trefethen. So, they looked at the say lower triangular matrices which are Gaussian. All entries that are there, that are non-zero, are independent standard Gaussian. And they proved that the expectation of the logarithm of the condition number is bounded below by a constant times n. So, meaning that the condition number typically is exponential. So, it looks catastrophic. So it looks catastrophic, right? So if you would say, would, I mean, would this be, would the loss of precision in the solution of triangular systems, it's an easy task, you know, solving a triangular system. Would it conform to that bound? You would not be able to accurately find the solutions, but we know that we can. So there is, you know, practitioners know it's not the problem. So why? What's the reason? What's the reason for that? It's puzzling. It's puzzling. Right? And explanation comes. The explanation is, maybe it's not even the only explanation, but one explanation is that let's look at the condition number with respect to the component-wise error. So here again, I put the classical one with the normalized relator, but instead, let's look at component-wise relative error. Okay, so you Error. Okay, so you like we look, we fix a pair ij, like the true value is a ij, the perturbed value is aij twiddle. Okay, and this is another, sorry, this is another type, but should not be absolute, it should not be norm, it should be absolute value. I'm sorry for that. This should be just absolute values. Sorry for that. And then I take the maximum over ij, right? So in this respect, of course, the sparsity pattern, of course, if I would. Of course, if I would only take the maximum over those positions where there are non-zero entries, okay? So then the component-wise condition number otherwise is defined in the same way as before. Okay, so and right, and then one notices two things. First thing is, if you look at backward substitution, it's like the obvious algorithm for solving a triangle in your system. Can you notice you can do Can you notice you can do a backward analysis of that? And the loss of precision is actually bounded in terms of this component-wise condition number. So, like that. Logarithm, component-wise condition number for matrix inversion, L plus log N. It's not hard to prove. It's in our book, that's easy. And then there is analysis by Jung and. And then there is an analysis by Jungen Kuker. He's a former student of Felipe Kuker. The expectation of the logarithm of the component-wise triangular Gaussian matrix is O of log n. So this is now nice, right? So this is an explanation why you can solve triangular system with backward substitution with high accuracy. Okay. And at the same time, it tells us this Turing condition number was not appropriate here. Okay, now I think that if there are questions, it would be a good moment because now I want to move to different topic. Yeah, excuse me, Peter. Yes. Thank you so much for a very interesting talk. So Wilkinson in 1967 or 1964 derived these component-wise error bonds for triangular system solution and already showed there that triangular system solutions is what's That triangular systems, okay. I maybe I right, I think that's more or less it's not obvious, but it's very easy. I did, I do not claim that Philippians saw this was originally. I think that was right, that was known. Yeah, but I don't think that anybody, I mean, this result, the expectation of the logarithm of the component-wise, I think that was not. At least, not. I don't know. I don't think that was in any way analyzed or published. People observed it, probably, that there is no problem, but I don't think it was proved. Okay, so okay, but thank you for the comment. Okay, so now let's move the general geometric framework for condition numbers, and this goes back. Condition numbers and this goes back to a work by Rice in 1966, so it's also very old. So the idea is to think geometrically. So what we have, so we need a little bit of differential geometry, so I put this naive picture. I have a manifold, smooth manifold X of inputs, I think of the line, a manifold Y of outputs, and then the problem is somehow that I want to solve is How that I want to solve is captured by some sub-manifold v. V is a sub-manifold of the Cartesian product x times y. So, in this picture, it's like this curve, right? And I assume x and v have the same dimension n. So, the intention is really x, y, this pair lies in v, means that y is a solution to x. So, you see in that picture, if you have this x, there would be two y's lying above it. Would be two y's lying above it, so the solution may not be unique. Okay, so then in this setting, there is this implicit function theorem is also calculus. You look at the projection, okay, you project down to x. So this is the map from v to x, maps the pair x, y to x. You can locally invert it around the point x, 0, y, 0, if the derivative has full rank. Okay, then you may say. Okay, then you may say if it has full rank, it is well posed, otherwise, you call it ill-posed. So, for instance, these two points, this is a red point with the vertical tangent, this would be ill-posed for the problem here as well. But if you are well-posed at the well-posed point, you can locally invert the map pi one, and this gives the solution map G. It's just this map G goes from maps X to Y locally inverts it. X to y locally inverts it, right? And then you will look at the condition number of this in the way, as I told you before, you take the derivative of capital G. It's now a linear map from the tangent spaces. Let's call it the condition map. So that's the condition map. And then now if we okay, okay, now I assume that both tangent spaces are normed vector spaces. Normed vector spaces. So, very often it's very nice if that you have Riemannian manifolds, then you have inner products, and they give us the norms. But what I'm telling you is, you know, works in much more generality. You don't need Riemannian. So, I have picked norms on the tangent space of x and y. And then I just, as a normalized, okay, as a normized condition number, I would take the operator norm of the derivative of this map G. That's it. map G. That's it. Okay. Now you are in a way, now I put absolute because there is no way. I mean, if x not is maybe not, it's not a vector space, something curved, the sphere, I don't know. I mean, I cannot, you know, quotients are not defined. I cannot directly define relative condition numbers, but it may already be incorporated in the shape of the space. So maybe we'll see an example of that. Okay. So. Okay, so that is very, very general. And now, okay, I want to implement these ideas in an example. Very important problem for numerical analysis is namely condition of eigenpairs of matrices. Eigen pair, I mean, eigenvalue, eigenvector, comes in pairs. So, this slide is a little bit dense, so let's go slowly through it. The problem is, given a major The problem is, given a matrix, a non-symmetric matrix, I want to compute eigenvectors and eigenvalues. So now I have to make a choice about the spaces. I would say my input manifold is just a vector space consisting of n by n matrices. But for the output, it's a little bit delicate because, well, no problem about eigenvalue. It's a complex number, but the eigenvector is only defined up to scaling. So the right way to So, the right way to see it geometrically is to say the eigenvector is an element of complex projective space. So, now you see it's not a vector space anymore, it's a manifold. It's a beautiful manifold. And what is the solution? Okay, this sub-manifold that defines what the problem is. Okay, it would consist of all pairs, or actually it's a triple. You have the input matrix, then lambda, and the vector. Okay, and you want AV equals lambda v. So it's a V equals lambda v. So it's a non-linear condition defining v. Okay. And then, okay, if you want to have this beautiful geometrical situation is just endow x and y with standard Riemannian metrics. So there is, okay, the only discussion is maybe what is the metric on this complex projective space, but geometers say there is a canonical matrix, it's the Fubini-Stubin matrix, and we take that. To be matrix, and we take that. And if you are uneasy about that, think of instead of complex projective space, think of real projective space, real projective space, which is basically a sphere where you identify antipodal points, and then it will be just the usual Riemannium matrix on the sphere. That's something like that. Nothing to be worried about. Okay. And then this triple A lambda V is well posed. One can prove now. Now that's a little lemma. This is well posed if and only if lambda. Well, post if and only if lambda is a simple eigenvalue. That's a little lemma. It makes a lot of sense. Now, let's I give you now I give you formulas for this condition. Now that I have already defined what the condition is. After defining a geometric framework and picking the norms, condition is defined. Okay, now it's just a matter of computing it, which is calculus. Okay, now a little bit technical. So if I have, what do I have? What do I have? I have a non-zero vector V, then this is the orthogonal complement, it's a hyperplane. And then I will restrict, what do I do? I take A minus lambda I, okay, and I restrict it to V per. So, no, because otherwise in the component nothing injuring is happening. And I denote this restriction A lambda V. So this is a linear isomorphism of V perp, and I need it for expressing. And I need it for expressing the condition. So the solution map in this case would have two components: one giving the eigenvector, the other one giving the eigenvalue. Now I give these norms separately because it's nice. So the operator normal here for computing eigenvector will be spectral norm of the inverse of lambda v and the operator norm of the map giving. Map giving eigenvalue would be this funny thing. What is that? u norm of u times norm of e divided by the inner product. So this u is the left eigenvector of A. So one can show if lambda is an eigenvector of A, then lambda bar is an eigenvector of A star. And U would be that. So what you see here, this is basically one over the cosine of the angle of U and V. Now I think that's also well known. If okay, if A is Hermitian, left and right eigenvectors are the same, and this angle is zero, and there is no problem here. This is always one. So, this operator norm for the eigenvalue computation will be one. In a way, no problem at all. However, there is still the thing, the problem here, this condition for the eigenvector computation one can show that would be just the distance of lambda. Of lambda to the closest eigenvector. Makes a lot of sense. Okay, good. So that was quite... So now what do we do? Right. So the idea is, why do I do this? Compute these condition numbers? Because I want to use this for designing an algorithm. Okay. So next step is distance to. step is distance to ill-posedness also arises here. So let's denote sigma prime, the set of ill-posed triples. So ill-posed means that lambda is a multiple eigenvalue of A. And then I can define, actually I had before already these two condition numbers, but actually it's easier to work with this notion. I define scale invariant condition number μ. And what is it? I take Frobenio's norm of A times norm of A times operator norm of dG eigenvector, okay, which is that. And why? Because the other, okay, this condition for computing the eigenvalue is much smaller than the other. So this is kind of a way of simplifying things. So if I can control the mu, I control everything and it becomes scale invariant because I multiply with the norm of a. Okay, so there is a theory. Okay, so there is a theorem, it's in the thesis by Diego Armentano. He proved the condition number theorem in the spirit of Eckhart Jung, and I'm aware that results of that kind have been proven earlier. There has been an early result by Wilkinson, which is also in that spirit. But here, it's in exactly in that setting, this condition number of A lambda V is upper bounded by some constant divided. divided by the distance of the triple 2 but here I didn't put sigma prime it's sigma prime v it's big sigma prime v is the fiber over v okay that's a little detail maybe it's not important for the moment it's the distance of that to sigma in the fiber okay maybe i should say that there's an important paper by jim demo i mean elaborating on this you know relationship between condition and distance to ill posed Condition and distance to ill-posed problem, which, of course, this paper was very inspiring for all these further developments. Okay, so good. Now, moving to algorithms. So let me see, how is my time? Okay, I still have some more time. Stable and efficient algorithms for eigenpairs. So I tell you a little bit of the story. So there has been a series of work. There has been a series of works, influential works, by Schuben Smeil in the 90s, and these papers all had the title Complexity of Besouth, and it went one, two, three, four, five. And the development, well, the goal was to develop like a rigorous geometric framework for designing and analyzing the problem of solving systems of problem equations. There's also the Smale 70th problem in that setting. So you have a number. That setting. So you have a non-linear system, you want to solve numerical non-linear system, and you assume this is polynomials. This is probably the first case to study. And the idea of these algorithms was a homotopy continuation where the step sizes are controlled by condition numbers. I will give more details later on, but that's the idea. Okay, homotopy continuation has been around for a very long time, but the question is, what is Prime, but the question is: what is the step size? Okay, so they designed that framework, and it turns out actually that what they did is extremely general. I mean, they did it for polynomial equation solving, but you can apply it in many cases. It's almost like a template to that, elaborate the details. So, right. And there is okay, now the story, and I think it's related to work by Nikol Srivastava. So, Mike Shoop, so he came with that and said, Well, there is no, okay, there's the problem of computing eigenvalues and eigenvectors of matrices, numerical linear algorithm. There is no, I mean, no, I mean, these algorithms that people are used in practice, they are efficient, but it's not, they are not completely analyzed. I mean, we don't have, we don't actually in a very rigorous Actually, in a very rigorous sense, no, we don't know what's going on. Okay, and he kept asking that, and so, and that was the motivation of Diego Armentano's thesis. And Diego wrote the thesis, and then it was a long procedure. In the end, we happened to write a long paper with Diego Armentano, Carlos Petron, myself, Felipe Kukru, Mike Schoup. And what we did, we just implemented this general framework in this setting for eigenpairs computation. For eigenpairs computation of matrices. And we came up with an algorithm which is provably numerically stable, theoretically efficient in the sense it's polynomial time, but it is not, it cannot compete with the practical algorithms. Okay. So, right. So, okay, and I think I remember I met Nikki Srivastava in the Nobrofoch meeting on complexity, and I told him about that. And I believe that's About that, and I believe that's was one of the reasons why he started his work, right? Okay, okay, so but the thing is, there is this very exciting recent progress by Nikhil and his students, Banks Varkas, where they actually managed to analyze the algorithms that is used in numerical analysis, namely the Hessenberg QR which shifts. And I am aware today is a talk, but I will not. Talk, but I will not attend it because it's after midnight and I'm in Europe. But right, so okay, so let me go on and explain a little bit what is our algorithm doing. Okay, what is our algorithm doing? As I said, it's very, it's a general framework. You can apply it in many situations. Also, it also explains why this is not so superficial because it's really general. General. So let's recall the solution variety V. Okay, it's here. It has a sub-variety sigma prime of ilth post triple. Now the idea is you use homotopy. You start your homotopy with a well-conditioned star triple. Let's assume we have one, it's not so hard to find one. And then, so this is this you is maybe fixed in advance, you may always use the same, and then on in. The same, and then on input the matrix A, you connect A to A zero by a line segment. Okay, okay, here it is. It consists of the matrices A T. Just look at this convex combination. T is like time, it goes from zero to one. Okay, now if A0A doesn't mean the discriminant variety, so meaning that none of the A T's has a multiple eigenvalue, then by general topology, basically, By general topology, basically, you can lift this curve. You have down there, I will have a picture on the next slide. You can lift your segment to a curve, gamma, in V. Okay, so it maps my time t to AT lambda t Vt. And I call it solution curve. So let me here. Here is a okay. I hope I'm not going too fast. I tried to, the picture is not very good. I should have drawn the solution curve. So down. Drawn the solution curve. So down here on the horizontal, I have the input space, the matrices. On the vertical, I have z times projective space is the output, the lambda and the eigenvector. And down, you see, I connect A0 with A1 segment. And the idea is somehow there is this curve up there in the solution variety, which I actually did not draw. I should have drawn it. But the idea is now to follow that curve numerically. What do you do? What do you do? You partition your time interval somehow, right? And then at every time step, you have an approximation. So let's say Ai, let's say lambda i, vi would be the true value. And what you actually have is just approximations. You have mu i, which is close to lambda i, w i close to vi. And then when you move one time step forward, okay, how do you get the new approximation? Do you get the new approximation? The idea is just do Newton iteration. One has to say a little bit things because we are not in the okay, these are curved space, we have a projective space, so we have to define what that means. It's not a problem. That's the idea. It's a simple idea, right? It's a very simple idea. And it's all about, I mean, how to choose the step size. And if you're a practitioner, you may just experiment, right? But I want to have an algorithm. But I want to have an algorithm that I can analyze rigorously. So I have to say how to choose the step sizes. And the idea behind is also a general principle that we should, because we do it in this Newton step, and we know Newton is locally is quadratic iteration. There is like a radius of quadratic attraction, and we want to be within that radius basically. And there's a theorem, it's going back to smell. Theorem, it's going back to Smell that you can bound this radius of quadratic attraction in terms of condition number. So basically, one over the condition number, right? If the condition number is big, then you have to get small. So that's why you can use the condition number for the step size. Of course, there's a lot of it's quite technical to elaborate all the details, but that's the idea. Details, but that's the idea. So somehow I choose the step size as an appropriate function of the current condition number. You may think of one over the condition number square. In the paper, we do something more sophisticated to gain a little bit of speed and so, but that's not important. Okay, so after defining the step size, the algorithm is defined. And then one can prove, now it's about the analysis, we can prove that the number of Newton steps. That the number of Newton steps can be upper bounded by an integral which we call the condition length. And this is what we do: it's the line integral of this condition number along the solution curve. So you have in your solution manifold V, you have this curve, okay, gamma. So you integrate your condition along the curve. We call it the condition length. Okay, the idea is when you get close, when this curve somehow gets close. Get close when this curve somehow gets close to the sigma prime to discriminant thing, the mu will go up and it will be expensive, right? And this condition length will be large. So that's the idea. Okay, and then okay, probabilistic analysis. Okay, I just tell you the results. So I said we fix a well-conditioned star triple. And then, right, so this L now we want to understand what. Want to understand what happens typically. So let's say our input matrix A is standard Gaussian. So the algorithm is deterministic. I mean, if I give away to compute the star triple, which is possible, the algorithm is deterministic, but the running time depends on the input A. And then we can show that the running time is now a random variable because the input A is a random variable. Variable because the input A is a random matrix. And the average number of new iterations is bounded by this. So constant n to the four times the square of the condition number of the star triple. Okay. This is the number of steps. But of course, every step also costs something. Every step also costs about n cubed. So it's not that great, right? But it's polynomial time. But it's polynomial time. We can also do a smooth analysis before, right? We fix like a bar, let's say, of norm one, make just a local Gaussian perturbation with the standard deviation sigma. Then one can prove a similar bound. The smooth average number of mu iterations is n to the four mu squared of the star triple times one over sigma squared. It would be nicer to have log 1 over sigma square square squared. Would be nicer to have log one over sigma, but it's one over sigma square coming from the analysis. Okay, so then you may say, Yeah, then I if I plug in, okay, I plug in what I know about this mu of the initial thing, so I get some bounds. Okay, what do we do we get? I mean, it's really not practical competitive, but we get an average number of Newton iterations O to the N4 for computing one eigenpair, and each iteration cost is O2. And each iteration cost is O to the N cube. So the bounds are polynomial, but they are not great. They are not n cubed. Okay? They are much more. But the algorithm is provably numerically stable. And what we like, we called it strongly accurate in the following sense that, I mean, it produces approximations as good as you want. So actually, it produces approximations in the sense of smell. In the sense of smell. So you can always get from that epsilon forward approximations. And to my best understanding, it was the first algorithm for that problem that was rigorously analyzed at that time. Okay, so I think that's more or less what I wanted to tell you. Time for questions. Thank you. Hi, Peter. Thank you. Yeah, please go ahead. Yeah, thank you again for a very stimulating talk. Did you implement that homotopy algorithm and do numerical experiments with it? Okay, I did not, but a student, a master's student of Felipe Kuker, did implement it and tested it. We also, in our paper, we report on that briefly and actually. that briefly and actually it looked that our from that it looked that our analysis is quite pessimistic so it's i mean these bounds that we prove seem to be pessimistic you know still i don't need that our algorithm can beat the practical algorithms well we used the homotopy algorithm in a collaboration with quantum physicists to compute subspaces and their matrices were not gaussian and was just a headache to make sure that all these linear systems that came up during Newton's method Linear systems that came up during Newton's method are sort of well-conditioned and to determine the efficient step size. So that was not easy. Yep. Okay. Are there any other questions from people in the Zoom call? Yeah, so thank you, Peter, for the talk and for introducing me to the subject at OverwoFak. Indeed, is it true, right? Is it true, right? It was yeah, it's true. I mean, I never heard of this until you told me. No, it's this is an example. Sorry that you can, but I think that's an example. You sit together, you have coffee, you eat a cake, you chat, you transfer something, and that was it. I think after that, you just went on on your own. You were like the right person with the right knowledge for attacking it. So, okay, thank you for that. But the question was, um. But the question was: So, one feature of homotopy continuation algorithms is that the step size depends inversely on the condition number, and so the runtime depends polynomially on the condition number. Are there, and this is different from numerical analysis algorithms where the runtime depends logarithmically. Are there examples where homotopy continuation also has a logarithmic runtime? Yes, yes, for instance. Yes, it's a very good question. So, for instance, when you play these. So, for instance, when you play these games for linear programming, we have it also in our book with Felipe. There you have a logarithm. I mean, of course, it depends on the definition, but it will be logarithm of condition number. Also, there is a theoretical result by Carlos Petrano and Mike Schube that in, I mean, if you in the solution variety, they look at if you have two points and they wonder how close you are. They wonder how close you are. So they prove that there's like a subdivision where the condition length would be much, much less. It would be instead of condition, they have logarithm of condition. But the problem is that nobody knows how to compute that. So we really hope that we think that this we hope that it can be improved, but we don't know how to do it for polynomial equation solving. Equation solving. But for linear programming, it is known. And it's conceivable. Is it conceivable that for the eigenvalue problem, there could be a homotopy where it's logarithmic dependence? I think, I would say yes. I would say yes. Yeah. But you know, our paper, I looked at it when I presented this talk and I didn't look at it for quite some time. And it's kind of a technical thing, even though. Thing, even though the big picture was kind of clear what you want to do, implementing all the details is, I would say, quite difficult, you know. So you had a Gaussian liquid, which is real, right? But the eigenvalues can be complex. So did you implement it in complex arithmetic? Okay, I did not implement at all. So I'm not that was a student who implemented it. So I don't know. I mean, I assume real arithmetic, but I don't know. I don't know. I don't know. I don't know. Okay. Yeah. Let me also thank you for this very broad overview of condition numbers and this talk. And I would like to make a comment before I give the questions to the room locally. And I would like to make a comment in the spirit of the meeting, which also related to open problems. And since Stephen Smale was mentioned so frequently already, he wrote a text. Already, he wrote a paper in Actal Numerica in 1997. It's called Complexity Theory and Numerical Analysis. Yes. And in the paper, I just opened the paper, and there's one paragraph on linear algebra. And he writes something that complexity theory is implicit in the numerical linear algebra literature and so on. And then he says, for more difficult linear algebra problems, such as the matrix eigenvalue problem, where iterative methods Problem where iterative methods are needed, the complexity theory is not fully developed. And I think, I mean, it's from 1997, but I think it's still true. In particular, when I think about the iterative methods of linear algebra, you had in your talk, for example, this bound for the condition with the condition number for the conjugate gradient method. And there's a lot of theory about the bound, and people analyze the bound and so on. But I think. On. But I think that also what Smail is referring, or what is implicit in this quote, there is the gap between this bound and all the analysis of the bound and the actual behavior of the actual algorithm. The actual algorithm of CG, the CG algorithm, does not never behave as this bound. If the algorithm would be so slow as the bound, then nobody would analyze the same phenomenon in linear programming. I mean, what we prove, I talked to Mike Todd, he's a specialist. I talked to Mike Todd, he's a specialist on that. I mean, it's the same. What we prove and what we observe is different. It seems to be much better most of the time, but we don't know. I mean, there's a huge gap between theory and practice. That would be really interesting to study or, I mean, I think that is kind of the. Is kind of the message also of the quote of Snail, maybe. Yeah, but I think this recent work of Nikhil and co-authors goes exactly in that direction because I understand that this is the algorithm that people use, right? Or not? I mean, it's one of the algorithms that is used until the running time on average is n cubed, right? That you. Well, I mean, what we prove is still far from what's because From what's because we have a loss of precision that's log squared n. Okay. And the true loss of precision is log n. Okay. But it's much, much. It's a difficult problem. Well, I think that's a very impressive progress. That's a very impressive progress. And I think it's, I believe, okay, I'm on the theoretical side. I think there should be an awareness that there are open problems here. I mean, this is. Yeah, for sure. A lot of the things is just on good faith. We believe it works, but we don't fully control it theoretically. Okay, honestly, I cannot see the room. Maybe Daniel, are there people with questions in the room? There was one by the last one. Okay, go ahead. Thank you, Peter, for a really interesting talk. Talk. I look this way. Okay. So you said that a lot of the time smooth analysis of algorithms can be boiled down to smooth analysis of a condition number. Yes. Do you know how to do that for simplex? Like, is there a condition number that will tell me if the simplex runs in full note? For simplex, actually, not clear how to do it because, you know, the simplex. big you know the simplex is is a is a combinatorial discrete combinatorial algorithm there's not much smoother smoothness about it so this is the example where where i don't know so for that reason in the book i wrote with filipe we don't talk about simplex because it somehow did not fit that we talk about interior point method interior point method this is you know smooth stuff and so there there it accounts for simplex i just For simplex, I don't see that. So the smooth analysis is really a method for continuous problems with continuous algorithms, I think. Thank you. You're welcome. Okay, other questions from the room? No questions. No questions. Okay, then. Okay, thank you very much, Peter, for the talk. Okay, it was my pleasure. Okay, it was my pleasure. I wish I would be there, but I will go there in about six weeks and so for another event, hopefully. Okay. Okay. Okay, thank you. And yeah, I think, I mean, I don't know.