Here. So graph standards are defined on a weighted graph with a parameter t and it's a subgraph of a graph G that has the property that the graph distance, so the shortest pass distance in this subgraph is at most t times longer than the shortest pass between in the original graph, between any. Original graph between any vertex pair P and Q. And this, so the graph distance is increased by a factor of T, and this factor is called the stretch factor or stretch for short. So in general, in an abstract graph where the edge weights are just unit weights, then we cannot hope for a better. We cannot hope for a better stretch factor than C. So, of course, yeah, a couple of remarks are in order, right? So, the graph itself is always a T stanner with T plus one. So, the goal is usually to have a small spanner with a good spanning ratio. And this is usually not possible in general with a ratio less than three. If you think about the complete bipartite. Think about the complete bipartite graph, then and if we want to have a sparse spanner, then we cannot go below factor of three. But for geometric settings, a picture is slightly different. So even the setup is slightly different. So we think of the graph as a finite metric space where the graph is the complete graph initially and the edgeway. And the edge weights are just the metric distances. And the goal is the same. We would like to have a sparse spanner that distorts the distances by as little as possible. So there are two parameters that have been considered, two key parameters. This is the sparsity and lightness. So the sparsity is just counting the number of edges in a spanner. Edges in a spanner. So both of the sparsien and lightness are comparison to the MSP. So when we count only the number of edges, any tree has the same number of edges, m minus one. And sparsity is just the ratio between the number of edges in the spanner and the number of vertices, basically. Lightness takes into account the weight of the spanner. Of the spanner. So it's the ratio between the weight of the spanner, so sum of edge weights. We're going to use this norm notation for weights because it's shorter compared to the weight of the MST. So what is known about these two parameters? So this is a brief history. So our goal is, so first of all, in Euclidean cases, this This is the stretch vector can go down to one plus epsilon. So for any epsilon, it can go arbitrarily close to one. So this is a key difference to this epsilon graphs. And our goal is to have sparsity or lightness as small as possible, and most importantly, independent of the number of points. So it should only depend on. It should only depend on our parameter epsilon and possibly the dimension. So, the first observation about this goes back to 86 when Chu noticed that Delany triangulations generated by equilateral triangle give a constant stretch factor in the plane. Then Croxel noticed shortly after that. After that, that the stretch factor actually can go to arbitrary close to one. So it could there exist a one plus epsilon spanner, and they didn't care about the stretch factor that much, just it's a constant stretch. And then there are a sequence of results about what is the best possible stretch factor for the Delaney triangulation. If you want non-crossing edges, and there are many different. And there are many different constructions for achieving epsilon to the minus d plus one stretch in d-dimensional space. So one construction is the theta graph that we'll see later, and the other is WSPDs. So there are several construction for this upper band, but it was just a couple of years ago when Lee and Solomon established a matching lower band. Established a metric lower band. So, again, for this space, there's a tight band for the sparsity of Euclidean spinners. So, what about lightness? So, again, the goal is the same, to have lightness as a small constant depending on just the dimension and epsilon, independent of the number of points. So, the first observation. So, the first observation here goes back to 93 when Dust and others show that the greedy one plus epsilon spanner achieves a constant lightness in the plane, and then they later show it in B space as well. So, what is the greedy one plus epsilon spanner? Let me just explain it briefly. So, we are given endpoints in the space, and it is not on the slide. So, it is not on the slide. And we consider the edges in increasing order. And for each edge, we make a decision whether this edge should be part of the spanner or not. And it's decision is made greedily. So, if we consider an edge AB and there's no, the current standard doesn't contain a AB pass of. Contain a EB pass of length, one plus epsilon times the distance, then we add the edge. If there's already a one plus epsilon pass between E and B, then we don't add the edge, right? So it's a greedy decision. The only non-figure thing is to consider the edge as an increasing order. So, VD standard is one of the simplest constructions, and it's always nice to have. And it's always nice to have nice properties as well for this. So it's the first here. And a lot of properties were later proved. It's hard to analyze though, the greedy spanner. So a different construction was considered by Narashiman and Smith. This is a book on geometric spanner networks based on earlier papers that did not. Based on earlier papers that did not contain a complete proof, but in the book they have a proof for epsilon to the minus 2D lightness. And then it was generalized to doubling matrix, where again, the slightness is one over epsilon to some constant depending on the so there's more more results. There's more recent results in this table. So, lightness was further improved by Lee and Solomon in 2019. So, this is the current state of the art for these parameters. So, as I mentioned earlier, there's a tide bound for sparsity in any dimension and almost tide bound for lightness. So, lower bound is absolutely minus d. With a nice construction, and it all matches up to a log one over epsilon factor by not just arbitrary matching by the greedy spanner. So, this is just an introduction. This is the starting point for the question that my talk is about. So, this is about, so far it was about verse K1s for spanners, but like But lightness actually doesn't correspond to the minimum weight. So it's the ratio between the so again, lightness was the ratio between the weight of the spanner and the MST. That's not the same as the minimum weight spanner, right? So for every point set, there is one plus epsilon spanner that has smallest weight. That would be the minimum weight spanner. Smallest weight that would be the minimum wave spanner. So, for both of these parameters, for the lightness and MSP, we have tied bounds, worst test tie bands. So, if we combine these two, we do get a bound for the minimum weight of the spanner. So, let's see what we are getting. So, the weight of this H will be the spanner here, and H over S is the lightness. So, this ratio, we have this upper bound, which is worst case optimal. Upper bound, which is worst case optimal. And for the beta of the MST, so I'm just considering endpoints in a unit cube. And there's a vertical style bound for this as well. So MST is known for a very long time. And for endpoints, this is the bound. So n to the one minus one over d. And these two pictures shows that the extremal configurations, they are very different. So for They are very different. So, for the MST agreed, scale down to the unit cube gives the worst case balance. So, it's an easy calculation that in a tree, every vertex is incident to at least one edge, and the weight is roughly n to the minus one over d. That's the matching lower band for this upper band. Lower band for this upper band. And for the lightness, the matching lower band was again established by Lee and Solomon three years ago. It looks something like this. So it's just a planar construction. Generalizes to higher dimension, but in the plane, it's just n half n-half points on two lines. And the spacing is designed so that we Every one plus epsilon spender would contain a complete bipartite graph. In other words, the spacing between these two points are designed exactly so that if we just go from one point in the bottom to another point in the top, then any detour to a third point would be longer than one plus epsilon times the direct edge. But the point is that the two lower band constructions are really different, so it's unlikely that you'd get a tight bound for just combining the two Verscase bonds. And that's exactly what my result is about: that there's a better bond than this combination here. The exponent of epsilon can be improved. The dependence of n is already optimal, that scales with the unit cube. So again, theorem one is that no matter how many of endpoints in the unit cube, there exists a one plus epsilon spanner of this weight. So if you look at the exponent of epsilon. At the exponent of epsilon, you see that this converges to minus d as d goes to infinity. So, the biggest improvement is in low dimensions. So, in plane, this is an improvement from minus two in the exponent to minus three halves. Yeah, so that's the construction is different. So, it's I can quickly show what is the lower band. Lower band, yeah. So feel free to interrupt if any has questions. Um, so the lower band construction is really just a combination of the two lower bands that we have seen in the previous slide. So we want to place endpoints in a unit cube. I just show the plane. So you can just tile the unit cube with smaller unit cubes and plug in the cubes and plug in the worst case construction for lightness. And in each of these little tiles, the same holds that any one plus epsilon spanner for these points would have to contain the complete bipartite graph. Otherwise, a detour through any other point or any other point out in another tile would be just too long and easy calculation. And easy calculation shows that that gives this lower bound. So, the interesting part was the upper bound. So, but this lower bound construction actually was something fairly unusual, at least to me. So, many of the optimization problems for endpoints in a unit cube are best for a grid. So, we often see that the We often see that the integer grade is the extremal configuration or close to it. So that raised the question: what happens for the integer grid? So if our input point is not just arbitrari points, that's in a grid, either just an n by n section of lattice or to scale to a unit queue just to be comparable to the previous theorem, what is the best thing we can do? Best thing you can do. And surprisingly, there was no previous result about it, and I still don't know the answer. So theorem two gives a lower and upper bound in two dimensions. So there are two formulations of the same result. The first one is phrased for the n by n section of the integer lattice. So the number of points is n squared, and the minimum Is n squared and the minimum distance is just one and this one can scale the same thing down to n points in a in a unit cube. So this scaling only affects the dependence on n. The dependence of epsilon is the same. So looking at the exponents of epsilon, the lower bound is negative, the quarter, upper bound, negative one. One. So I will talk about both upper bound and lower bound later, if you have time. But in any case, it's still an open problem. What is the best one plus epsilon spanner you could have in first section of integer grade? The theorem I have works only in 2D because both upper and lower bound techniques don't seem to generalize. Anyhow, so I say a few words about the lower bound for the grid. So, surprisingly, I have very few tools that I can use. So, the lower bound construction is a bound for must-have edges. So, there are a couple of edges in the grid that must be present in every one plus epsilon spanner. Every one plus epsilon spinner, right? Because meaning that if we don't connect these two vertices directly, then any pass through a third point or other points would be just too long, more than one plus epsilon times longer. And so this is a very big band that only these gives my lower bound. So there are two conditions that can be used. Can be used. One is the empty alias conditions, and the other is the empty slab condition. So let me just explain them. So we are looking at two points A and B. And if you have a pass of lengths one plus epsilon times AB between them, then it's fully contained in this LX of with both side A and B and great axis one per sepsion times AD. One per section times AD. So if there's no other point of the grid in this ellipse, then we must have an edge between them. So, and again, think about epsilon as something very close to zero, where this ellipse really looks like this, that it's very skinny and long. So, ellipses are fairly hard to analyze, even in a grid. So, there's a weaker condition that's easier to work with, and this is the M. Uh, easier to work with, and this is the employee slab condition. So, I just enclose this ellipse in a parallel slab, so bounded by two lines parallel to the segment AB. And the condition is that, of course, AB are grid points. So if you look at the line AB, there will be many other points on this line further down the road. But the condition is that there's no other point in this slide. In this slab, and also no point between A and B. So, apart from other points further down on this line, this slab is empty. And it has the same condition. So, if the slab is empty, the edge must be present. So, easy calculation using experiment and some average. Some averaging argument gives a lower bound. So essentially, we are looking at the end-by-n section of the, well, looking at an integer lattice, the infinite integer lattice, but then look at just one part of it. Then both A and B, both coordinates, A1 and A2, are up to epsilon to the minus one quarter. The minus one quarter, so a small box, and in this box, every pair satisfies the empty slab property by Pig's theorem. And then just by, so it means that the lower left corner has to be adjacent to all other, all pairs that are relatively prime. So all primitive vectors must be present in the spanner. And then just move. And then just moving this star to all other points in the grade, we get our lower bound. Again, it's fairly easy. The upper bound uses more advanced techniques. I'll get back to. So a few words about the upper bounds. I think I have more slides than what I can show, so I'm going to skip through some of them. So it's an upper bound algorithm. Upper band algorithm, we are given endpoints in the plane, and we want to design a one plus epsilon spanner. So there's an algorithm that constructs a spanner, and then we need to analyze it, show that it's actually a one plus epsilon and it has more weight. So this algorithm is a modification of classical Yao graph construction. Yao graph construction, just essentially deleting many edges from the Yao graph. So let me just start with the Yao graph. So here we are given a finite set of points in the plane and each point we and the parameter k. So for each point we partition the plane into cones, k cones of the same angle and for in each And in each cone, we find the closest point to our center. And all these edges are added to the yellow graph. We do this for every point. So it's known that if we choose the angles of the cones small enough, so if the angles of these cones are roughly epsilon, then this gives a one plus epsilon spanner. Proof is by induction. Proof is by induction. And also, this construction generalizes to D space again with the same idea that the central angle of the cones must be, or aperture must be roughly epsilon, but then in higher dimension, the number of cones per point will be higher. Otherwise, the proof is roughly the same as well. So, and the goal is that I'm going to explain is to Explain is to sparsify the yao graph to use fewer edges and still maintain the spanning property but have lower weight. So the key idea for this sparsification is on this slide. So remember that in this yograph we had cones of angle roughly epsilon. So the idea here So the idea here uses a much larger angle, angle roughly square root of epsilon. And we are just looking at a triple of points and design a region here. So this is constructed like this. So you take two columns centered at P and Q. One has angle you one has angle square root epsilon over two the other is square root epsilon and uh and now suppose we have a so we get this intersection of the two cone that I denote by B and suppose that we want to go from P to B now the key observation is that if I already have a one plus epsilon pass from Q to B then we can Then we can combine this pass with a direct pass from P to Q, and the two together will be a one plus epsilon pass from P to B. So again, and this is key for the inductive argument for a one plus epsilon spanner. So if I already have a one plus epsilon and now P is my new point, and I want a one plus epsilon pass. A one plus epsilon pass to everywhere else from t. I don't have to add a direct edge from t to b, it's enough to add just this connector, and this is a good wire point to go anywhere in this purple area. So, this is the key idea that now we can compare it to the yellow graph. So, if the yellow graph had edges in this purple area, then actually we don't. Purple area, then actually we don't need any of these one over square root epsilon edges. It's enough to have just a single edge from P to Q, and then we can just continue to all of these red points on the purple area from Q. Now, this idea can be put into an algorithm. So, just and this is the, well, yeah, so let's show you something stronger. So, not just this observation is true that we can actually enlarge the. So, this is true if we pick some other point A in the neighborhood of B. And if B is not necessarily in this purple area, but in a slightly larger neighborhood of this purple area that I denote here by D hat. So, again, this lemma would say that if we have a Lemma would say that if we have a point in the neighborhood of P and a point in the neighborhood of this larger neighborhood of this purple area, then we can find the one plus epsilon plus from A to B by just using PQ as a viral two viral points. So the algorithm, I'm not going to go over it in detail, is this idea exactly. This idea exactly that instead of, so first we compute these larger cones. And if we already have, if the points in the smaller cones are in this area B hat, then we don't add the edge of the Yao graph. So follow the construction of the Yao graph, but skip some of the edges if they are not needed because of this. They are not needed because of this observation. Now, so this gives a construction. So we get a subgraph, we get a graph. Let's see, my time is soon up. And we need to show two things: that this is a one plus epsilon standard, and then the weight is small. So the So, the proof of this being a spanner is by induction. I'm not going to go over that. And the weight is a charging scheme that charges weight to area. I think I'm not going to go over much of this proof. The key idea that charges weight to length to area is Yenzan's inaccurate disabled. Is Jensen's inaccurate somewhere in the middle? So, just a few words about the grid. So, how do we get an upper bound for the grid? Well, we can use the exact same algorithm, the sparse ya graph, for the grid. The analysis is somewhat different. It uses some number theory. At Ferry sequences. So the grid has some nice structure, and so Ferry sequences are exactly correspond to these slopes that we would need from the origin. So just a reminder, Ferrier set is just the set of ratios A to B, where both A and B are between 0 and N. And we just take the ratios up to 1, so A is less than or equal to B. To one, so A is less than or equal to B. So the Ferry sequence has lots of fascinating properties. And the key property that I need is the average distance of an arbitrary point to the closest point in the Ferry sequence. And for that, there's a theorem, a number theory, that is bounded. And that can be used for the upper bound. Again, I'm afraid I don't have time to go. Don't have to time to go over this. So, let me just finish with a few open problems. I mentioned already one, it's one of them here. So, this is the first open problem that if we only care about the integer n by n section of the integer lattice in the planar higher dimension, what is the best, but the smallest weight one plus epsilon spanner for it? I don't know. They don't know so the exponent dependence of n is clear. The question is the dependence on epsilon. Then another problem about greedy spanner. I showed a new algorithm to construct a spanner for endpoints in D space. Does the greedy spanner achieve the same bound? So, greedy spanners are harder to analyze. So, greedy standards are harder to analyze. Maybe they achieve the same mark as well. I don't know. Third open question is an algorithmic question. Given a set of points in this space, how can we find or approximate the instance optimal, so the minimum bit spanner for that particular point set? So, what I showed here was a So, but I showed here was a worst case. And last open question is: if the allowed tiny points do they have, do we get better ones? I don't know. And I stopped with this. I have a question. So you presented an upper bound and the lower bound for this integer sections of the sections of the integer lattice. Which one do you think is closer to the truth? So I think that the lower bound is very weak because it's. Yeah, I showed it here that it uses only uses only these must-have edges. And I tried other ideas that I couldn't use anything. So I think there could be cases where some edges are necessary, not because they're must-have, but because other points, there's no other way to get from A to B. So I would try to remove the lower bound. Other questions? Let's thank John again for what we talk. Starting again in about three minutes. 