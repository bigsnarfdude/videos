My apologies. I due to other travel adventures this summer, I had to do not appear in person, but it has been a very enlightening and enriching experience for me to listen to all of the talks as it's sort of a non-standard type of workshop for me. Type of workshop for me or a collection of researchers for me to listen to. I come from a probability background and go to some talks that have to do with chemical reaction networks and workshops on, you know, people analyzing them from a deterministic point of view and from a stochastic point of view. But I've never sort of, you know, it's good to hear like a broader picture in other points of view and how. In other points of view, and how this fits into the other types of mathematical modeling that go into systems biology. So I will talk about rare events. And okay, so the motivation for this, just to sort of specify what I mean by stochastic processes and systems biologists, for the most part, what I mean is modeling chemical. What I mean is modeling chemical reaction networks that describe basic, you know, intra- and intercellular processes. So essentially, Markov chains and their relatives. And of course, the stochasticity in these type of systems is key because of the molecular interactions and some environmental noise, though, mostly, you know, this noise I perceive as maybe other. Noise I perceive as maybe other molecular interactions that are not key to the specific reaction network that I'm investigating but affect some of the dynamics, things such as errors that come from cellular division, et cetera. Of course, the stochastic features that make it interesting to do some new mathematics come from the discrete amounts of molecular abundances, right? So the sort of micro-scale modeling versus Microscale modeling versus the standard type of macro scale modeling that involved large amounts of molecular abundances for all of the components and all of the species. And here, these discrete amounts imply that some stochastic features are essential and they bring, they influence long-term dynamics, but in kind of ways that are important to quantum. Important to quantify correctly. And one of the things that I have looked at are rare events in systems biology. So rare events, I will sort of try to describe very intuitively. A lot of you probably know the concept, and then I will move to more mathematical definitions. So, intuitively, the idea is this is departure from typical behavior, where typical behavior means you're somewhere. You're somewhere, you know, the behavior that's close to the mean or plus minus some number of standard deviations. So anything that's away from that is considered, you know, rare behavior in the terminology of probability theory. And of course, why do these things sort of matter in these contexts is because the reactions occur in different Because the reactions occur in different time scales, and the abundances of different species have different orders of magnitude. So, essentially, both of these two contribute to fluctuations, stochastic fluctuations that occur on multiple time scales. So, this brings me to the concept of what's rare can depend on the time horizon that you look at. So, again, quantifying rare events, so probabilistically. Events. So, probabilistically, what this means is that the chance of occurrence of this event, or if you're thinking about a process, so the rate of these rare events, they have to be exponentially low in some scaling parameter of the system, right? So these scaling parameters of the system may be some system size, maybe something else. They're essentially what we call the speed at which you're evaluating the rare events. And this is something that you get to play with, right? With right, um, and uh, so again, what are things that are, you know, what when I think of this, what I think of the differences between slow and rare, because I do analyze lots of processes on sort of these multi-scale with multi-scale features, is things like promoter switching, right? On and off switching of genetic promoters. I think of those as slow, right? Because they sort of happen, but they're not rare. Are not rare while switching attractor sets in a dynamical system is a rare, okay? So, this is just an intuitive picture. Um, the time horizons matter, right? Because on whether, so how we're going to evaluate or quantify these rare events matters whether we're looking at finite time horizons. So, there can be rare events in finite time horizons, which just means they're unlikely. And usually, these are. They're unlikely. And usually, these are events that one considers in finite time horizons, like whether you can have an extreme value, extreme accumulation of some product, etc. And then there are quantities that we consider rare on long time horizons, right? So on long time horizons, usually what one looks at is distributions rather than events because you have. Events because you essentially, if you're lucky and you have some kind of ergodicity in the system, then you may sort of settle in some kind of stationary distributions. So on long time horizons, you would look at things that happen. So these accumulating unusual distributions, so being in unusual probabilistic distributions in a long time horizons. So, you know, extreme times. You know, extreme time spent in some values over a long period of time would be such a rare occurrence on a long time horizon. So essentially, these things are important because transient dynamics on finite time horizons are relevant, but also on infinite time horizons as well. So, by the way, I can, I'm, my vision is not great. So, if somebody's trying to say something. So, if somebody's trying to say something in the room, I will probably not see that. So, just jump in or let the person who can jump in stop me with a question. Okay, so in the context of the cellular systems, we've got the notion of things that can happen for cell. They may be rare events, but if we're considering them on the them on the on the on the scope of a cell lifetime you know that's that can be a long enough time for something that's rare on a on a short time to happen within the cellular lifetime things on sort of more long-term horizons one may think of the fact that then you can perhaps think of the the cellular growth and division as something contributing to accumulation of stuff because you know Stuff because given that you have many trials of something to occur, things may not be rare on the level of the cell population. So why the mathematical? So I look at sort of mathematical quantification of these things and the theory that goes along with it. Why is the analytical aspect important? Because simulating rare events by naive MCMC methods takes an exponentially long time for obvious reasons. Takes an exponentially long time for obvious reasons because very rents are exponentially unlikely, they have exponentially low probabilities. But even efficient methods like important sampling or many other methods that have been developed either use analytic calculations from large deviation theory to sort of bias the sampling, but they still also have strict non-trivial lower bounds on the variability. So the variability of So, the variability of efficient methods can also be a problem, right? Because you may not be able to help how accurate your estimation is. So, this is just to motivate why I'm justifying mathematical results for this. So, this is just a definition of what probabilists think of as large deviation. So, if you have, so now you can live on any kind of metric space. Can live on any kind of metric space, and this will be useful because we can think of not just random variables, but you can, you know, real-valued random variables, we can think of paths, you can think of distributions. Essentially, that if you have some sequence parametrized by some, let's say, n here, then you have a large deviation principle with some rate function i and speed n, if essentially, you know, there's some very use sort of there's technical constructions of these. There's technical constructions of these things that matter because of certain convexity issues, but essentially, what you'd like to say is that the probability that this sequence parametrized by this n is close, is in a neighborhood of the value x of the thing that you're interested, the value that you're interested in is exponentially low with where the With where the rate is given by I of X and the speed, meaning how low exponential is given by this scaling parameter n, right? So you have n, which is your speed, and speed of decay, and then you have I of X as the rate function of these rare events. So now, you know, here are the context, typical context where these things come up. So if you have a sequence of, it does not Of it does not, you know, Markov processes where, you know, you could have some jumps, et cetera. But they do converge in some sense to a deterministic, suppose they converge to a deterministic process, X tilde T, and you let this S, this metric space be the space of paths on a finite time horizon, then you may pick a different, right? Like most of your paths then. Your paths then, or you know, in the mean, your paths will tend to go towards this deterministic value x tilde t, but you may want to know what is the probability that they're actually close to some other path, which I'm denoting here by x of t without the tilde. So the sequence converges to the tilde, so that would be its mean, and some standard deviations around it would be, you know, moderate deviations. But if you go to some Deviations, but if you go to some X D that's quite away from your X tilde T, then you would like to quantify what's the chance that you are actually following a very unlikely path over this period zero to capital T. And then you will have some rate function that will involve both, I guess here I'm no longer using N, but yeah, I am using N. So this rate function will use this new path that you're interested in. That you were interested in, the unlikely path, in order to calculate the rate function. Can I ask a question? Yes, of course. So, when we're dealing with molecular processes where individual events involve a change of one, how do we epsilon is going to zero, but the balls either include a change, a discrete change or not. So, how is that consistent with this approach? Oh, the apps of so here the neighborhood is kind of an easier way to think of it, but this does not need to be phrased in terms of neighborhoods. You can have this as any open set or any closed set. So these probabilities, if you, I've taken a definition that expresses things in terms of neighborhoods of a point, because calculating, usually one calculate rates functions first for points, but then for sets, but you can re-express these. Sets, but you can re-express this definition where you stick here an open set and then here, like a closure of that set. And then here, this rate function would somehow be evaluated as a supremum over all of the points in that set. So let me try asking a different way. Should we be thinking of n as something like the system size parameters so that as you go out in the sequence n, the relative size of a jump gets smaller and smaller? Exactly. Yeah. Smaller, and exactly, yeah, yeah. So, sorry, I did not exactly understand, did not understand your question correctly, but yes, usually we will think of n as some kind of six. So, again, some things may stay jumpy, right? In which case, you will not converge to deterministic process, right? And in that case, you cannot quantify these finite time path evaluations. But if you converge, so if the system size is going to infinity, meaning that your jumps. To infinity, meaning that your jumps the changes in molecular, so you're going to some concentrations that you can describe deterministically in terms of some ODEs, then you can quantify how unlikely you are to be near the solution of the ODE. Okay, thank you. That helps a lot. Okay. So, the other kind of infinite horizon approach would be if you have an ergodic process. So, here that would be relevant for processes that you would model. Processes that you would model, but they are not very close to deterministic process, right? So then you're monitoring its distribution over time. And if you have an ergotic process that will converge to a stationary distribution, then you can quantify things such as the occupation time of various sets. So, how much time do you spend in various sets? And that those times, these occupation times, or depending on what kind of process it is. What kind of process it is for continuous ones, people call them local times, it will converge to the stationary distribution of that set, right? And so then in the context of the large deviations, you would look at the space of probability measures on whatever set this erotic process lived on, let's say it was E, and you would look at all the probability, some, so you would have this as a special probability, a stationary probability. Special probability stationary probability distribution. And then you would look at how likely it is that your occupation time or your occupation measure of your process, of your path is close to some other distribution and not the stationary distribution, right? And you would quantify that here again, I guess, to stay in terms of the n here. Usually, t is used here. So you do one over t times the integral zero to t. So I've just integral zero to t so i've just you know if you rescale things with n just to keep consistent with this uh uh speed n issue but usually what you would use one over t and then the integral zero to t to quantify and then you would say this uh large deviation uh principle holds at speed t and some rate function that you evaluate using you know the features of your process plus this specific probability distribution probability distribution that you that you want to evaluate, how close are the occupation times to those values rather than to the mean value. So the stationary distribution is kind of the mean of the occupation measures for the process. So again, the two different points of view are depending on the first point of view in finite time makes sense if you're close to some deterministic object, right? If you have some law of large numbers that brings you to deterministic object. The second infinite time point. The second infinite time point of view makes sense if your process is not converging to the deterministic thing but it's constantly being in flux, but hopefully over a long period of time settles in some mean distribution pi. Okay, so what kind of stochastic models do I consider for reaction networks? Essentially, one I start from a continuous time mark of chain, and then there's some rescaled versions, right? Some rescaled versions, right? So now the rescaled version, they do not, you know, classically everything would be scaled by a system size and things you know would converge to a deterministic concentrations, but that's not necessarily the case in cellular systems. In fact, one sees these multi-scale properties that will lead to various limiting processes where some things still stay as jumps, right? So your on and off switching of proteins would stay. Things would stay as a jump process. You may have some quantities diffusing around, right? And then you have some quantities being, you know, some aspects being closer to deterministic things, some aspects being somewhat stochastic, let's say, you know, diffusing continuously because they still have, can be expressed in some kind of concentrations, but with a lot of fluctuations, and then some parts that are still jumping. So, again, I'm thinking of this X as a. This X as a vector-valued process, meaning that you're capturing a whole bunch of species, but you could think, you know, it depends how you want to look at it. But essentially, there's a variety of stochastic processes that make sense as good approximation of what's happening in reaction networks. And again, here, what is this? What are these epsilons and deltas that depends on the original multi-scale system that you're given, how big the System that you're given, how big the jumps are, whether it's one or it's something that's, you know, the usual scale, the standard scaling would be that this epsilon is order one over square root of n, this delta is something like one over n. But in the multi-scale settings, these do not have to scale that way with n at all. And in fact, that's where the interesting dynamics happen. Also, because of constraints such as conservation laws, Such as conservation laws, usually there's some kind of reflection of the boundaries, especially the zero boundary, right? Because everything needs to be positive. There's some natural reasons why that happens, because the rates vanish when you don't have the species to engage in a reaction. And so, these usually what makes sense is the appropriate approximation of this process is not to let just general. Process is not to let just general things like general diffusions here, but use reflected processes so that your stochastic process would not go dip below zero, right? So there's a rigorous approximation that say that you should use reflective processes and the reflective processes use this local time on the boundaries to reflect them back in. So essentially, I won't go into that, but you would add to this like a little push at the boundaries due to the reflection parts. Reflection parts. So when you're talking about this multi-scale, is that about time scale? And in that case, to get the large deviation rate function, do you always have to choose the integration time much larger than the longest time scale in the dynamics? Or can you do this at the intermediate level? Well, okay, so multi-scale here can be different. Here can be different stuff. So you can have multi-scale in terms of amounts. So you can have certain things that you look at, certain things that are abundant and you look at them in terms of concentrations. So then they're continuous, right? Whereas certain things like the gene being on or off or the number of our mRNA or something like that, that's still in orders of discrete amounts. So there's the multi-scale aspect that comes from that. Scale aspect that comes from that, which is why you would get, let's say, jumps here with this delta equal to one. So, and then there's multi-scale in terms of time. There's that too. And when I say multi-scale in terms of time, usually I think of multiscale in terms of fluctuations. So, fluctuations can be essentially for different components of X, you can have different sizes of fluctuations of the noise, right? And so, some things can fluctuate much. And so, some things can fluctuate much faster in time than other things. And, of course, if you're interested, again, when you, I actually won't talk about multi-scale things here, other than to say this is why we get interesting sugar presses, but why I'm justifying keeping diffusions and jumps. But it is true, to answer more precisely your question, that on any scale that you're, so if I'm interested in rare events. Interested in rare events for a certain component, then I need to know at what rate its fluctuations happen in order to figure out. Usually the rate of its fluctuations will tell me what time scale, what speed I need to use for the large deviation. So, if you remember in the large deviations, you had that speed. So, usually it's the rate of fluctuations that a parameter that relates to the rate of fluctuations that. That relates to the rate of filtration that tells me what speed I need to take for the large deviations. So, again, if the fluctuations are persisting, then yes, I do need to take, I am measuring things at a speed which is telling me how fast this thing is mixing, you know, which what ergodic, how fast it's converging to some stationarity. Whereas if Stationarity. Whereas if something has fluctuations that are decaying in terms of the size, like when you converge, when the concentrate, when rescaled Markov chains converge to concentrations, then it's more about the size, right? So in these two, this N was more about the size of the jumps here that ended up as a speed rather than, I mean, it is related to the time in some. To the time in some sense, but the time here essentially is fixed. You're looking at a finite time horizon, you're looking at fixed time. Whereas the size of your components, right, that's the thing that's determining this and the speed of large deviations. Whereas here, if you're thinking of ergodic process, so the fluctuations are remaining, then you are thinking of n, which is the size of the flu, the rate of the fluctuations that determines what speed. By what speed you're driving large deviations. So it's not, I'm sorry for a long answer, but it's not a question that has an easy answer to be given. Because what you consider rare depends on what is this parameter that you're using, right? Is the parameter for the size or is the parameter for the time length? Okay, so in the first case, it's kind of a parameter of the size of. It's kind of a parameter of the size of fluctuations, and in the second case, it's the parameter for the rate at which the time mixes the fluctuations over. If that makes sense. Yeah, thank you. You're welcome. Okay, so on a finite time, so this is the example that I was given before. So in a finite time behavior, if you have something that's converted, so these stochastic parts, if, so in the previous model, if so in the previous model if i have this uh going to zero so if my diffusion is going the the the impact of my diffusion if this epsilon n when i take n to infinity this is going to zero and the size of the jumps is going to zero as well in some appropriate sense then i will essentially get a deterministic limit meaning that i'm just keeping you know a dynamics that behaves according to the the average drift right and then you know there i can i can do I can derive, so this is, you would call this a functional law of large numbers, and because you're basically averaging a bunch of small contributions over time, because you're rescaling the size by one over n, right? And then you could also devise functional central limit theorems, which tell you how much you deviate on standardly, right, around this deterministic limit. And then the large deviation principle would tell you, you know, how how how uh unlikely you are to be at some point that's away from from so you're in paths right how far no no no no 10 minutes at it no um 10 minutes um so then here there are ways of calculating this rate function and they typically involve this nonlinear exponential operator which is um can is also sometimes called the logarithmic moment Sometimes called the logarithmic moment generating function, where you look at so this is now the f are functions, continuous functions on time intervals zero to capital T. Then you have this operator on such functions of your path, of your process, and then you have something that looks like a variational principle to figure out your rate function. So, this is just to illustrate that usually you need to calculate something like the log. To calculate something like the log, the limit of a logarithmic moment generating function and then derive the rate function from it. Here's an example where how is this useful in some models for system biology? So imagine you have a Markov chain model where you have some chemical reactions that have a drift, and this drift has two stable and one unstable state. So it's a bistable drift. Stable drift. And then you have some other unbiased subsystem, which is noisy because you have reactions going on, but they're unbiased, such as maybe it's errors due to the splitting of the cell, other aspects as well. And the thing that you care about in the unbiased subsystem is what's the order of the variance? Because in the biased systems, the order. The bias systems, the order of the variance is kind of fixed because it has to relate to the sizing of the drift. Whereas in the unbiased ones, you kind of get to play with it. You could increase it if you want. And here we will, let's say we have a variance that's of order gamma n in terms of n, and it has some variabilities given by sigma squared. So here's an example. This is the sort of An example: This is the sort of the very simplest bistable chemical reaction network, and here's some no-drift chemical reaction subsystem, which basically is just saying, let's just make errors. So, you know, sometimes you convert B to an A in the presence of A, and sometimes you do the opposite, right? And so here, if you plot these two, if you simulate this process with the This process with the appropriate scalings of these chemical rate constants, depending on how fast this gamma is, usually what you'll get, if it's kind of scaled the usual mass action kinetics way, then you will get sample paths that look like this, because the bistable system has equilibria at a quarter and three quarters. And so most of the time it's spending around those equilibria, but on occasion, the noise is taking it away from the attractor. Is taking it away from the attractor of the equilibrium onto the other one, right? And this is the occupation, the right picture is the occupation times. So you're measuring how much time you're spending in the, in the, you know, how much time you're accumulating in the different points, in the different values of the system. So here you can see that essentially this is considered, this will be evaluated by rare events because most of the attractor is pulling you very strongly. tractor is pulling you very strongly to the the drift is pulling you very strongly to the equilibria and it's only the rare fluctuation most of the fluctuations around the equilibrium it's only the rare fluctuations it takes you out of it um so you can quantify this there is a question yeah sorry to interrupt but we're running close to the end of time so i'm wondering how all right so i will go quickly through this to say there's there's ways that you can calculate the rate That you can calculate the rate of these events. And then you can also say: is it just because that n, the system size, was not actually infinite? So you shouldn't have modeled this by diffusion. And you can then calculate the finite system size effect of this, and you can calculate the rate of this, and you can compare these two. And you can say the results, how do these things compare? And when is it more relevant to use? When is it okay to use diffusion approximations? use diffusion approximations and when can you when should you stay with a with a finite system size markup chain and use the the rare event calculations for the markup chain system size and what's interesting is that if you sort of go below go above if you introduce noise that is sort of above met using uh where diffusion approximation makes sense then essentially you will get something like this right so if your no drift noise is overwhelming Is overwhelming, then the diffusion approximation never would have made sense in the first place because jumps are key, because these no-drift reactions are key. And so then essentially, you're not even spending time at equilibrium because all the noise is forcing you into the boundaries of the system. And here, then, it makes more sense to look at long-time behavior. And here, then you would say, okay, I will change my model and yeah. Change my model and I will no longer use. I may use a diffusion, but it will not be with small noise. And I will not consider the jumps to be small because clearly the jumps are relevant in their size. And so here you would look at a long time behavior in this process, which would tend to settle in something. And when I say settle in something here in the system, essentially it will tend to live most of the time. It will spend some of the time in the middles, but then it will spend. The middles, but then it will spend sizable amounts of time on the boundaries, which is not what it was doing before, right? And here, essentially, you would look at things like the additive, you know, instead of just looking at occupation times, you can derive rate functions for other dynamical observables of the process, where you would look at some integrating function, some function integrated over the time of the process. And again, you would use something like the log moment generating function. Something like the log moment generating function of your process, of here in this case, your additive process, what you're accumulating. And if you get a convergence of that, here I'm using t because time is what's scaling here. That's my big parameter. Then, once I get the limit of this object, I again use a variational problem to solve for the rate function. So there's theorems that tell you. Uh, there's theorems that tell you instead of because doing this is hard, um, and so there are theorems for complicated processes of this type, right, which have jumps in the underlying stochastic process that has jumps, diffusions, and all sorts of things. And so instead, you can replace looking for this rate function by solving a certain partial integral differential equation, subject to some boundary conditions, because Subject to some boundary conditions because of the local time aspect. And if you find the so there exists for nice enough processes, ergodic processes, there exist solutions to this partial integral differential equations. And moreover, they will give you the solution for each fixed theta will give you, through a variational problem, will give you your rate function. And moreover, you can also take derivatives in theta. Derivatives in theta of the solutions of these partial differential equations to get the average mean time spent and the average variance of the time spent. And so to show you again what we did on that system that I described before, when it made sense to use a diffusion approximation, you can actually show in agreement to that, even if you look at the long time horizon, which is diffusion approximation. Which is diffusion approximation are only valid at finite time horizons. So the evaluation of rare events or any kind of accumulation of stuff over long time horizons will be different for your diffusion approximation than for the original Markov chain. And in fact, you will show that the local time accumulation near equilibria will have a tighter concentration for the diffusions than for the Markov chain. So it's really, it's showing you that the stationary. It's showing you that the stationary distributions really are different for the two processes, and that, you know, on long time horizons, these approximations, a diffusion approximation, do not necessarily make sense. And moreover, if your noise is overwhelming, so you should not be using a diffusion without jumps to begin with. And you're in that case where I said you kind of bypass the attractors completely because you have so much noise. You can look. Have so much noise, you can look at how much time you spend at the boundaries, and you can actually show that the average time you spend is significantly greater at the boundaries than in the equilibria. And you can actually find the exact value of sort of the stationary distribution at the boundaries. So I'm guessing I'm out of time because I'm not looking at my. So just to end with some connections to the rest of the workshop is that. Of the workshop is that large division principles, they're sort of an important theory within probability theory, but they are highly related. When you look at long-term behavior, they're highly related to information theory because one uses, again, mutual entropy functions to evaluate the sort of relatedness of how rare the station distribution is, how rare some problems. Distribution is how rare some probability distribution would be relative to the stationary distribution. And also, all the theory of large deviations is very tightly connected to the theory of stochastic control. And so, some people are trying to use this to help do some control on some engineered biochemical systems. And of course, just the last bit, because that's what, you know, most of my research is multi-scale versions of any of the results are. Versions of any of the results are particularly challenging because they involve both types, right? So, certain things that happen, certain fluctuations that happen very fast, they may converge to station distribution. Now you need to involve the rare events of you not maybe not converging to it. And on other finite horizons where, let's say, your promoter is switching slowly, you have the finite time LDP. So you would have to combine both of these things. Combine both of these things together. And yeah, I just wanted to say thank you for your attention and apologies for going over time. We have time for one quick question while the next speaker sets up. Mass, a quick clarification question.