Can you hear me? Yes, yes. Okay. All right. So I switched it to full screen view for the slides, and you can see that, okay? Okay. All right. Yeah. So thanks for having me. And I am a postdoc at Missouri University of Science and Technology working under with Marco. Under with Marco Cavaglia and students there. And this is estimating glitch-contaminated gravitational wave signals using artificial neural networks with Netfix. Okay, so first I'll discuss the motivation for this work and then talk about its method and then talk about the results we got and its potential application. And then I'll talk about the conclusion and where we are in the next steps. So, this is motivated by the fact that sky maps are needed to identify electromagnetic observations with gravitational waves. So, with GW170817, we had on the right there, we had the gravitational wave signal and nearby it in time, we had the GRB. And if we look on the left down there, we can see that we have the sky positions, the estimated sky. Sky positions, the estimated sky localizations from the GRB, from Furby GBN, and IPM Fermi Integral. And then we also have the sky localizations from the LIGO data. In this event, Virgo should have detected it given its amplitude, but it didn't. So that restricted it to a smaller subset of the sky. And so then we have the dark green sky localization. And this allowed a follow-up campaign across the electromagnetic. Campaign across the electromagnetic spectrum to get more data and look for electromagnetic counterparts. And for example, there was the detection from the SWOPE telescope in this inset here about 11 hours after the event and comparing to before where there is no where the electromagnetic counterpart is missing beforehand and then it shows up after. So this allowed the identification of the gravitational waves with the Of the gravitational waves with the electromagnetic counterparts. So, this led to a whole host of observations and tests that were done, including testing the speed of gravitational waves, finding out that, or confirming rather, that at least some short gamma-ray bursts were caused by neutron star mergers, and information about the production of heavy elements such as gold. And then, this also. And then this also gave another method to measure the expansion rate of the universe, the Hubble constant. So it's pretty exciting to get multi-messenger observations with gravitational waves. And specific to GW, well, in general, glitches can overlap such gravitational wave signals, and this can impact sky localization and parameter estimation. And this actually happened with GW170817. We could see in the living 0817, we can see in the Livingston data on the right here that there's this glitch that overlaps the in spiral. You can see on the top right there. So in the bottom right, in low latency, the time series was gated with an inverse 2K window to allow a rapid reanalysis of the data for an improved sky localization. And then on a longer timeframe, the glitch was subtracted. Which was subtracted out, it was modeled and subtracted out for parameter estimation. So, this is some simulated data just to illustrate some what can happen, which is we have the, in the simulated data, we have a full time series in gray here, and then a inverse 2K windows applied to the data, giving us the red data there on the left. Data there on the left, and the vertical dashed black line is the geocentric time of the merger in the geocentric frame of Earth. And this is from the data on the left of time series, we get these sky localizations on the right here. And so the full data gives us this gray sky localization that includes the star. And in this case, the star is the injection. The star is the injection, this injection location in the sky. And we can see that in this case, the gate that was applied, if there was a glitch there that needed such a gate, this would actually cause the sky localization to be that red contour, which would no longer include the sky position of the signal, which would not be good for follow-ups. So, this is the general motivation for why we would want to improve on gating and perhaps. To improve on gating and perhaps try to estimate the missing part of the signal, see if we can improve the sky localization. Now, as the detector's sensitivity increases, we expect to have more detectable events, and we expect this to increase with the detector sensitivity. On the right here, we have the events plotted. This is from GWTC3, and this is the TC3 and this is the events for plotted for each of the different observation runs. And we could see that the number of detectable events increases from 01 through 02 to 03. And we expect as the sensitivity improves in the future, we'll have a higher detection rate in 04 and beyond. So as there are more detections, this means it's more likely that a glitch will overlap the signal. So we'll have to deal with this again in the future with more likelihood. With more likelihood. So, this brings us to the objective of Netfix, which is to attempt to mitigate the effects of a glitch contaminating a signal by estimating a part of the signal overlapping the glitch using an artificial neural network. The time series estimated with Netfix can be used to generate a sky map for sky localization and low latency. And this is what our work focused on testing with simulated data. And it could also be used in parameter estimates. And it could also be used in parameter estimation potentially, but this is still yet to be tested. Okay, so the method revolves around using artificial neural networks to estimate the missing portion. And so the idea is that there's a time series containing a glitch and this time series gets gated. So we were working with using a multi-layer perceptron as the neural net, and we could see on the right here. And we can see on the right here, the multilayer perceptron has multiple layers of neurons, which are fully connected to the layers before and after. And the neural net would take as an input on the bottom, you can see a time series that's been gated. So the idea is it takes that as the input, feeds it through the neural network, which ends out, it ends up giving out a prediction at the end, which is the output at the top, which is an estimation of the data in the gated. Data in the gated part of the time series. And so then this could be added back and stitched into the gated portion to give us an estimated time series. So we use an implementation with scikit-learn, and we use the multi-layer Perceptron with one hidden layer and 200 nodes in the hidden layer. Okay, so. Okay, so the setup in general was to assume that there were two detectors observing and that a glitch was overlapping a signal in one of the detectors. So we have two detectors observing and then a potential signal comes through and is detected by the detectors. However, one of the detectors, say H1, has a glitch which then is gated. We were simulating testing with simulated binary With simulated binary black hole waveforms, specifically the IMPhenom D approximate, which has no spin, and we tested with different masses, SNRs, gate durations, and gate times. So for setting up the testing and training sets, the idea, if we look on the right here, the idea is a signal comes through and we can get a rough estimate, initial estimate of Estimate initial estimate of what the mass might be for the signal, and then we would have a neural network that's been trained on masses in the rough neighborhoods. So you can see a little X is the idea of where the masses are estimated to be around. And so then we use a neural net trained on the neighborhood of masses around that. So we tested on three mass ranges, which were a low. Where you're a sort of lower mass range, a medium mass range, and a higher mass range. And you can see on the left there, they range from about 10 to 15 and 8 to 12, all the way up to 28 to 42 and 23 and 35. So we were testing different ranges of masses, and we also varied the network SNR between 11 and 42 on each one of these sets of data. Each waveform is injected into a set of 50 simulated noise times. 50 simulated noise time series, and these time series are colored with the ALIGO design sensitivity curve. Each one is injected with a random sky position and inclination angle, as well as polarization angle and phase. Part of this also gives an uncertainty into the exact merger position in the data that Netfix is going to work on. And since we won't necessarily know the exact time of merger, there's a little bit of uncertainty. Time of merger, there's a little bit of uncertainty, so that also gets trained into the neural net. And then we add additional pure noise time series, which end up making up 10% total of the data. And then this data is split into a 70-30 training and testing set split. So after all of this gets set up, we then gate the data for training and testing. And so the gate we use. So, the gate we used was an inverse 2K window. And going back to the simulated data, you can see on the right, we have the initial data with the injection. And we do this for all the data in the training and testing sets. And we gate the data and we end up getting the red time series, which ends up being the data to train train that gets put in as the input to Netfix. And then it's trained to try and predict the missing part, the part in the game. Missing part, the part in the gate. We tested on different gates. So we have three gate durations of 50, 75, and 130 milliseconds. And then we also tested on four gate end times before the merger time of 15 milliseconds, 35, 90, and 170. So we're working to try a variety of gates with longer and shorter duration. So this gives us a total of 12 gates, and then pairing that with the in combination with the three different With the three different mass ranges, we ended up with 36 different sets of Netfix models of the different masses and the different gates. Okay. So once we have the models with Netfix trained, we actually wanted to test with an additional set of data we called an exploration set. So the idea here was to sort of simulate the Sort of simulate the scenario of where we get that initial signal with its estimate of what its masses are. And then we pick a Netflix, a trained Netfix model in a certain mass range. And the mass range would be in the neighborhood of that signal. And so we, for these exploration sets, were trying to sort of mimic that initial signal. So we had some fixed masses in the middle of each of the neighborhoods. The middle of each of the neighborhoods. So for the low, it was 12 and 10, the medium, it was 20 and 15, and for the higher mass range, it was 35 and 29 solar masses. And then we also had some fixed network SNRs of 11, 28, and 42 so that we could also see how it performed with different SNRs. And then this was injected into 512 noise time series, again, with random time, with random sky positions. With random sky positions, inclination angles, polarization angles, and phases. And so, this is what we used to see how Netfix performed once trained. So the first thing we wanted to look at was the performance of the time series. So to do this, we use the overlap of a full gated and reconstructed time series with the injected waveform. So we called this the match. And you can see there. And we can you can see the equation on the left there of the match being the overlap, and each one of those parentheses components is the inner product, and it's of each respective time series with the injection itself. And then we wanted to characterize the performance of the reconstruction of the reconstructed time series. And to do this, we used what we called the fractional match gain. And so here that's the match of the reconstructed minus negated. Of the reconstructed minus the gated over the match of the full data minus the match of the gated data. So essentially, if the fractional match gain is greater than zero, then the reconstruction is performing better than the gated. It's closer to the, it overlaps better within the injection than the gated data would. And so a reconstruction, we consider it. Reconstruction: We consider it successful if the FMG or the fractional match gain is greater than zero and equal to or less than one. And this data in the figure to the right here is for one of the exploration sets. It's the 20 and 15 masses, and then it's for one of the gates as well and one of the sets of SNR. Then, in this figure, for this particular exploration set, about 95% of the samples are. About 95% of the samples are successfully reconstructed. You can see that the pluses are when FMG is greater than one, and then the X's are when it's less than zero. So basically, it's successful if the point is in the shaded region on the right here, and then FMG itself is the color bar. Okay, so this was one of the exploration sets, and then we wanted to, for each of the exploration sets, get an idea of how. Each of the exploration sets get an idea of how efficient it was overall, essentially. So, for this, we use what we term the efficiency, which is the proportion of successful reconstructions that are in that range of the FMG between zero and one. And so the efficiency was greater than about 50% and up to 95%, as seen in the previous figure, for all but two of the exploration sets that had a network SNR. Sets that had a network SNR of 28 or above. And we could also take a look at the dependence of the efficiency or its response rather to the single interferometer peak SNR. And for the exploration sets, we found that Netflix may successfully reconstruct the data data for the majority of time series with peak single interferometer SNR greater than 20. So if we look at this plot on the right here, this is actually for a few different. Right here. This is actually for a few different exploration sets. There's a single set of mass in SNR. This was done, but then it was: this is the data for each one of the different gate combinations with the color being the end time before merger, and then the different shapes being the different durations of the gates. And we can see that for the data which had a single interferometer peak SNR greater than 15, the efficiency was greater than 60. Was greater than 60 for these cases. And then when we get up to 20, it was greater than about 70% for these cases. So we can kind of see how it changes, the efficiency changes depending upon the single interferometer peak SNR. Okay. So this is a specific example. Again, the one we've been looking at of the time series. And we could see in this case, we also have the reconstruction here. And we could see the reconstruction follows the full data pretty well. Folllows the full data pretty well in this case. And this also leads to having the sky localization on the right, where we've gone from having the gray shaded sky localization, which does include the injection location, to the red gated, no longer includes it. But then once we get the reconstructed data, the estimated data from Netfix factored in, we get the dashed blue line for the skyline. Blue line for the sky localization, and now the injection location is again within the sky localization. So, this is what we want to see. This is an example where the reconstruction was working well. And again, we want to characterize how it's working over the entire data sets. So what we want to use then to characterize the effect on the sky maps is the sky map overlap between two different sky maps. And we follow the paper. Follow the paper linked here to characterize the improvement in sky maps. And the discrete form of the sky map overlap is the equation here, where essentially it's a sum of all the probabilities. It's a sum of the multiplication of each individual's probability meaning each of the respective maps with each other. And that gets summed up where the probability is for the eighth sky map, like if it's reconstructed. Like if it's reconstructed, it would be for that one. If it's for the full, it would be for that one. But it's for the ith pixel in each of the sky maps. And then those are added together and it's normalized by multiplying by the total number of pixels in the sky maps. So what we wanted to do is compare the overlap of the gated and full sky maps, because what we're comparing again to is the original data and the sky map of the full data. Sky map of the full data, and we want to compare the overlap of the gated in the full sky maps with the reconstructed and the full sky maps. And to do this, we use what we call the overlap log ratio. So it's just the log of the overlap of the reconstructed and full sky maps over the gated and full sky maps. So the effect on the sky maps essentially if the overall Essentially, if the overall, and I have the OLR there at the top again to keep in mind during this. Essentially, the overlap log ratio, if it's greater than zero, that indicates that the overlap of the reconstructed in full sky maps is better than the overlap of the gated in full sky maps. So essentially, what we want to see is the OLR is greater than zero. And in this exploration set, the 87% of the samples. The 87% of the samples have an OLR greater than zero. We also have the color in this represents the fractional match gain again, where an improvement of the reconstructed in comparison to the gated is a higher, is closer to one. So the warmer colors are again improvements in the time series. So we could see this is also the same data that was in the previous plots. And we can see again that. Again, that when the time series seems to be performing better, this seems to be happening when that the sky maps also perform better, because you can see that there's lighter colors tend to be on the upper right of the figure here. And we also again have the X's and the pluses representing the fractional match gain greater than one and less than zero. And we can see that it tends to perform poorly. It tends to perform poorly the reconstructed sky maps when the time series performs poorly. For the majority, so you can see the X's tend to be below the dashed line in that case, which is representing when the OLR is at zero. And in this case, 87% are above. And for the majority of cases, in exploration sets with network SNR greater than or equal to the 28.3, we found that the OLR is greater than zero. Is greater than zero. So, by that, similar to this figure, most of the points in each of the exploration sets will, for this network SNR or greater, will be above zero. Okay, so here's a few more examples of SkyMaps and comparing the gated data, the full data, and the reconstructed data. The reconstructed data, and we could see that in these cases, so these are examples of when it's performing well again. And we could see in these cases the gated, the sky localizations from the gated data, the injection locations are outside of the 90% sky localizations. And then in the full data, they are within the localizations. And within the reconstructed data, it's also within the sky localization. So the gated. Within the sky localization. So the gated data misses the sky position, but the reconstruction gets it again in these cases. Which brings us to the next thing we considered, which is the sky localizations are essentially the contours in the sky map. And so it's good to have the sky map perform better with the reconstructions. But as a check, we also wanted to take a look at how the contours were behaving because. How the contours were behaving because the real question is: are we going to be able to follow up and hopefully see the event with electromagnetic observatories? And so what we define at the contour level is, in this case, the cumulative probability of the sum of the pixels in the sky maps up to and including the injection ordered from the highest to lowest probability. So, what this essentially means is that if What this essentially means is that if the contour, we have the example here of the contour of whatever sky map we're considering, if that contour is less than 0.9, this would mean the injection was within the 90% contour. So we can look at this plot over here on the right. And again, the black is the full time series. The blue is the reconstructed, and the red is the gated. And for this exploration set, we can see that going. Exploration set, we could see that going from the gated, of course, the full-time series has the highest line on the cumulative fraction here. And essentially, what this means is that at any particular value here, this is the fraction of our samples in this exploration set that were at or below this contour level. And so, as we go further along and get larger going from 40%. And get larger going from 40%, 50% to 90%, it increases the amount of events that are within that contour. So we could see, for example, here that essentially the gated goes for about 10% of the events are within 90% localization, roughly speaking, when it's in the gated sky maps. And then when we get the reconstructed sky maps, this goes up to about 40%. So that's a nice improvement. And then when we go back to the full time series, Back to the full time series, it's up here around 70 or so percent. So, in this exploration set, the cumulative fraction of samples is higher for the sky maps from the reconstructed series than from time series than for the gated time series. So, the reconstructed sky localization tends to improve compared to the gated in this case. And continuing on in this comparison, Comparison, we also want to know how the contours behave with respect to improving the sky maps themselves. So to do this, we want to compare the contour improvement to the sky map improvement. So we're comparing to, again, that overlap log ratio that was in the previous plots. So what we were characterizing the contour level change was with contour level change was with this uh uh with this very uh calculation of uh well this l here which is essentially the log of one minus the contour to reconstructed over one minus the contour degated so this is set up such that when l is greater than zero when the contour uh is uh well one minus the contour is greater than one contour is greater than one minus the the the one minus the contour of R is greater than one minus the contour of G. So essentially when the numerator is greater than the denominator. So essentially the smaller the contour the better in terms of finding the sky position. So if the reconstructed contour is smaller than the gated contour then L will be greater than zero and the performance to reconstructed contour will be better. Reconstructed contour will be better. So we compared this to the overlap-log ratio. And so we can see that as the overlap-log ratio performs better, that tends that the contours will be more likely to be smaller as well. So you can see the general relationship here in the plot to the right. And we also have, again, the fractional match gain. So looking at the performance of the time series as well. The time series as well. And so we can see when the reconstructed time series tends to when it performs better, there's a little bit more of a probability that the contour will be performing better as well. We could see that for lower values of the FMG tend to be on the left bottom versus the upper right. And so smaller contours are helpful for low latency sky localization. Okay. Okay. So once we have all this, if Netfix is trained well and is giving us improvements in the reconstruction compared to the gated most of the time, that's good. And we could just take that output directly, but we could also do a little bit more work and consider what we have in the real case to perhaps favor using Netflix when we think to reconstruct. Using Netfix when we think the reconstruction will perform better. And then, in those cases, when the gated data actually performs better, we'll keep using the gated data. And so, for this, a little bit of work was some work was done looking at potential ways of doing this. And one of them was this decision tree for a real case application. So, I'll go over to parts of this. So, this is the overview, and I'll come back to this. But basically, the idea is to use the quantities we have in. To use the quantities we have in the real case to try and estimate if we expect there to be an improvement in the sky map, in the reconstructed sky map, because we're not going to have access to the full data in the real case. So far, we've been comparing the gated and the reconstructed data to the full data, but what do we do when we don't have the full data? So the idea is that when a glip overlaps a candidate, the glitch is That's a candidate. The glitch is gated, and then we can estimate the gated data with netfix and calculate sky maps. And we can calculate the sky map overlap and the SNR gain. And I'll explain this on the next slide, but this will be the first decision point. If the SNR gain is greater than zero, we continue with the process. But if it's below, then we recommend a gated sky map. And the next part of the process is taking the overlap of the sky maps we have access. The sky maps we have access to, which are the reconstructed and gated, as well as the gain, and we can use some machine learning clustering and classification to estimate whether the overlap is likely to be better of the full data with either the reconstructed or the gated. And then if the reconstructed sky map is expected to be better, then we can recommend the reconstructed sky map. And if not, then we'd recommend the gated sky map. The gated sky map. Okay, so the first thing to look at is the SNR gain as the initial cutoff, and also to infer to full time series, SNR. And so what we have is on the left here is a plot plotting the gain normalized by the gain over the single interferometer gated SNR, where the gain is the SNR of the reconstruction. Is the SNR of reconstructed minus degated against the loss in the SNR over the full SNR, where the loss is the full minus the reconstructed. So the larger the loss, the less the reconstructed SNR is getting back to the full data. And the larger the gain, though, the more it is over the gated data. It is over the gated data. And when this gets plotted, we can see there's a relation between the two, at least in this set of data. So this would be something to check with different models of the waveform. But when we have this kind of relation, we can use as a cutoff when the gain is at or below zero. So when the S and our gain is The SNR gain is the SNR gain is expected to be greater than zero for good reconstruction. So, if that the gain is less than zero, then we can favor the gated data instead. So, if, but if it, if it's greater than zero, then it passes on to the next part of the decision tree. So, uh, we used SNR as initial cutoff, and uh, if the gain is a and then we can also use the linear relation of the gain. Relation of the gain in SNR to infer how much the sig, how much the row loss is. So, how much of the signal energy is gained relative to the complete essential or the full beta. Okay, so if it passes that part of the decision tree, next, we use the available quantities to essentially infer whether we should use the reconstructed or gated sky. To reconstructed or gated sky maps. And so, what we need first is we need to use some simulated data with some different models to train an algorithm to classify the data that we're going to feed into it. So, first, we take the data that we have in the real case, which is the overlap of the real negated, and then the overlaps of those sky maps with themselves, as well as the SNR gain. Our gain, and we put those in the simulation with simulated against the simulated data, which also includes the full data down here. So the overlaps, the real and the full, the gated and the full and the full of itself. And then we, on this, we use a machine learning clustering algorithm to give us clusters for which we have the data that we have available in the real case that we can identify them with, essentially. Identify them with essentially. And so then we feed this, the overlaps, the real and gated, and the gain, as well as the cluster values into a machine learning classification algorithm. And we train that. Then this ends up being available to us so that we can feed into it the data we have in the real case. So then once all this is trained, we feed in the overlap of the real and negated data as well. Data as well as sky maps, as well as the row gain, and then the sky maps with themselves. We put it into the machine learning classification algorithm, and then that'll give us a cluster that it identifies with. And then from this cluster, we'll have an expected overlap at a real in the full and the gated in the full. And essentially, whichever one of these is better will decide whether or not we should use the reconstructed or the gated. Or the gated data. And so we did some tests of this using agglomerative clustering for the clustering algorithm and random forest as the classification algorithm. And we could see on the left here, we have this plot of the OLR plotted against the gated and full overlap. And we have these different colors are essentially the different clusters for this text. The different clusters for this test case. And so then these stars were cases where this data was fed in to see how the classification algorithm would identify them with the clusters. So the idea to implement this would be we'd use pre-generated injected signals, which would be used to train these machine, train first the clustering, and then train the classification algorithm. The classification algorithm, and then we would classify a time series that was to one of these groups. And from that, we'd estimate the improvement in the sample using the respective group and decide whether or not we should use the reconstructed data or the gated data. So, yeah, so this gets again back to the decision tree. So, we have the The decision tree. So we have the input of the signal, then we use the gate the data, then we calculate the overlap in SNR. And then first, again, it's if the gain in SNR is greater than zero, then we'll continue on and put it into our classification algorithm to estimate whether or not the reconstructed sky map will be better than the gated sky map. And depending upon that, we'll either recommend the gated sky map or we'll recommend the reconstructed sky map. So that's the The reconstructed SkyMap. So that's the overall setup. That's one potential way that it could be used. Okay, so in conclusion, Netfix reconstructs the time series simulated binary black hole waveform successfully for the majority of tested signals for our simulations that we did. Once trained, it takes less than a second on average to calculate the reconstructed time series. So this is nice if we have pre-trained. So, this is nice. If we have pre-trained Netfix models, then we can do this in pretty low latency. And the reconstructed sky maps typically improve compared to the gated sky maps for what we tested. And then further techniques such as machine learning clustering and classification could help decide whether to use reconstructed sky localizations in particular cases. And then finally, improvements in sky localizations increase the probability of identifying electromagnetic counterparts with. electromagnetic counterparts with which would contribute to the knowledge about which contributes to the knowledge about source objects and related physics so that's the motivation for doing this all right so where we are right now is we're currently working to implement netfix as a python package and that that would allow it to be used uh more that would allow it to be used and integrated with uh other things potentially and then uh we're And then we're going to be tuning the hyperparameters of the MLP, the multilayer perceptron, to see how that affects things and if we can improve on what we have. And then we're also going to be testing on, we plan to test on binary neutron star waveforms, templates that include spin and real data. And then another thing to do would be to explore the effect of the reconstructions on parameter estimation. So thank you very much. Thank you very much. All right. Thanks, Ryan. I don't know which question. Okay. Are there any questions on the chat? I don't see any questions. Questions here? All right, there is one question. That was not a good idea. So, my question is: How do you decide the number of clusters for the agglomerative cluster method? Yeah, so that's a good question. Yeah, so that's a good question. I wasn't the person doing the main work on that, but from what I remember, multiple different ones were tested, and it was sort of a balance between more clusters and just seeing the amount of clusters that seemed to give a good output essentially without having too many clusters or a large number of clusters, essentially. Of clusters, essentially. So, yeah, sorry, I can't give you a more involved answer. I wanted to ask another question about the training process. So, if you use this, you gated this amount of data out. Were you doing this over a range of different values of amount of time you're getting? Gating and where you should. So, of course, you did it for BBH, so there's not much room for you to move the central time of the gating. But when you do it for BNS, are you going to explore the times over which you are going to move your gating window? Ah, yes. And we did do this a bit to the amount we were able to with the BBH as well. But yes, yes, moving it in time before the merger, that's part of what we. Part of what we want to do, as well as different gate durations, definitely. So, thanks. So, since you were moving already a bit for the BBH, I was wondering in those cases where you had getting result was actually better than the reconstructed, was it because they were very close to the merger, the getting was being done, or was it something you're exploring still? Yeah, so as I recall, there was essentially, and there's tables in the paper that go into more detail, but as I recall, when there was a lot of signal on both sides, that that was helpful for the reconstruction. So actually, when we got closer, and it was still successful most of the time, but as we got closer to the merger, it became a It became a higher variance essentially in terms of how much it reconstructed. So, as you get even closer, this essentially becomes less data on the other side that has a large signal amplitude to help train the neural net essentially. Does that make sense? Yeah, it definitely makes sense. The fact that when you have more data on both sides, it definitely helps in. Helps in trending the machine. Did you also do other? So you mentioned about doing it for parameter estimation, but in terms of simple reconstruction or a recovery of the parameters, did you also do some analysis on masses, let's say? So let's say you have the data. Now, if you can just see a reconstructed, look at the reconstructed data and pass it through our detection pipeline. Data and pass it through our detection pipeline. Does it improve the masses? Something like that? Ah, I see. I don't. Well, I didn't do that myself. I don't think Kentara did a lot of work on the data analysis as well. I don't think he did either. So I think I'd have to perhaps ask him, but I don't think we actually tried putting it through to see what the mass reconstruction was. What the mass reconstruction was, but I'd have to look back and see if we did that. All right, yeah, sounds good. Thank you. Thank you. Any other question here? All right. If there is no other question, let's thank Ryan once more. All right, so this was, I think there's a coffee break now. So we're going to break for the coffee and then come back for the roundtable discussion session at five. So I think we do you want to take a bit more time because for the coffee, yeah, yeah, for the coffee break, we can take a little bit or something like that. Yeah. 