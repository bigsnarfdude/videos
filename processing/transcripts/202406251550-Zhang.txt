Thanks for the organizers, for the organization, and the invitation. And it's my pleasure to be here to present our work. And today I'll talk about something on the stochastic differential games with random coefficients based on the drug work with Jinyang. And in this work, we study stochastic differential gains with random coefficients. equations. Whose stochastic HgVI equations is a class of fully nonlinear backward stochastic partial differential equations. And we will study the hotness of this kind of solid nonlinear backward SPDs. So our problem is the learned stuff has differential gains. Differential gains. So we consider the following control, the SDEs, the state process, and here the coefficients depend on the time, the X, and also the control. And we consider the payoff for the player 1 and also the cost for player 2 of the recursive chip. That is, this G is defined. This G is defined by the solution of this B backward stochastic differential equations. And the lower value function V and the upper value function U defined as follows. And the main point in our work is that the coefficients B sigma. The coefficients B, sigma, F and also the signal conditions phi depend not only on time space and the controls, but also on omega. So the stochastic differential games has been studied for a very long time. I think so there is really a huge literature on this problem. But due to the time limit, I only To the time limit, I only list summers. So, in the Markovian case, there are two methods that all the youth to study the SDG. One is the PDE method and the other is BSD method. And different from the work of Flamy and Suganidis, and also the Sukanidis and also the work of Bokda and in our work we consider the case that they involve the coefficients at random. So that goes beyond the Mark Kubian case. And in the non-Marukian case, these two papers of Adelt, he used the magical method to study this problem and studied this problem and this paper of Hamadan and he used the backboard, the BSBE method to study the problem. And the PDE method in the non-markman case provides a kind of PDE called the plastic kind of TDE, I think. Yeah. So if the coefficient depends on the time Depends on the time, on the state, on the control, and also on the state process X and the driven brown emotion. And this goes beyond the Markvyn case. But if it works on the path space and the Markviang property will be restored. So the value function will be deterministic and will And will be characterized by a kind of path-dependent PVEs. And the theory of past-dependent PVUs was developed by Jiefeng Zhang and his co-authors, Heng Benji and Dilen. And so in our case, we didn't work on the fast space. We only supposed that the coefficients That the coefficients are measurable with respect to the omega. So, in our case, the PD method will deduce a candidate for fully nonlinear backward stochastic partial differential equations. So, this is the stochastic H GBI equations that the value functions V and U satisfy. And here And here the generator H minus and H plus has the following form. And here the equations are backward SPVs. That is the solution of this equation is a pi V and C. And this kind of backward stochastic back Backward SPDs can be viewed as an infinite-dimensional version of the backward stochastic differential equations. So at the beginning, this kind of equations was introduced as a dual equation for the study of the control problem for SMTBE system. So from that time and there has been a lot of study on this kind of equations in the linear case and the semi-linear case, even if in the quasi-linear case. And the people studied the well-positions of the weak solutions or strong solutions. Meek solutions or strong solutions and with different domain edges, different boundary conditions, etc. But there has been few work on the fully nonlinear case. So this is our aim. Sorry, by the two mirror decomposition theorem. mere decomposition theorem, the stochastic HgVI equation may be written equivalent as the following form. So our aim is to define the stochastic discourse solution to the equation, to the equations and then study the verticalness, including the existence and uniqueness and also the stability result. So from So from non-deem class phase to study the importance of the backward stochastic partial differential equations. Here are some notations that we will use and they are defined in the EuroV, so I will not present one by one. And here B is the banacher space. So S P is the set of all banana space. The set of financial space values and key measurable continuous processes achieved with this kind of norm. And also, we can similarly find the spaces of the processes LP2 and LP, et cetera. And we also can define the space of L local P. Of L local P as the intersection of all the L P. So this HKQ is the KS sublift space and CBK plus 3 half is the holder space. So defined by UV. And here are some, here is the assumption that we pose on the both sessions and it is also Also, very known about the measurable at the measurability and the bonus and also the leap condition. So nothing special. To end the preliminary, I present a regular approximation lemma, and this lemma will play an important role in the proof also. proves also the continuity of the value functions and also in the uniqueness of the solution. So the main idea is that we approximate the non-Markovian case by the piecewise market case so that we need a regular approximation LIMR as this. So here phi n b and sigma n as n And Bn sigma Fn are the diaphragm functions likely enough and they approximate the coefficients phi B sigma F in this sense. And the sequence is uniformly bounded and also uniformly leaks continuous. Then by the Then, by the theory of the BSDEs, we can easily use the properties of the valid functions. The first one is about the boundaries and the continuity of the valid function. And also, if we change the x here to ft measurable value. FT measurable value with random variables and this relation also codes. And in order to prove the dynamic programming principle, we need to introduce the backward sand book. So we define MAPG by the solution to this V. To this BSVE. And by the theory of BSVE, we know that this BSVE has a unique solution, so that this definition is well posed. And also by the uniqueness of the solution to BSDEs, we can prove the same group property of this gene. This G. Then we can prove the continuity of the value function. So under the assumption, if one the value function v u and also the cost function are continuous with respect to t and x. So due to the uniform leaf discontinuity of v in x, it is enough to It is enough to prove the time continuity, and which can be done by the regular approximation. And then we adapted the backward sand group method to our framework, and we can prove this generalized dynamic programming principle that is for two stocking kinds, paw and paw hat. And C is And C is at all measurable random variable, and we have the full DPP. So compared to the control case and in our BIM case, the important point is that there is no convexity. Is no convexity. So, in order to overcome the difficulties caused by the known convexity and also the non-linear dependence, non-linear dependence of the generator on the variables, we need to consider a standard test function space. So, that in order to do this, we need to introduce a class. To introduce a class of sublinear functions, and we introduce the sublinear functions also by the BSD and the theory of BSDEs. So for each case, and we know that this BSDEs need unique solutions, and so that we define IPSO over bar. If so, over bar equals to white over bar and if so lower bar equals to white lower bar. And yes, since the BSD is well posted and this definition is well posted. And due from the theory of BSDEs, Theory of BSDs, we know this kind of if the or by if the lower bias are sublinear functions. And an important result for us is this representation. And this result can be found in this very famous paper about the reflected BSG. And this And this says that the sublinear functions can be represented as the value function of optimal stopping time problem. Then to define the test function, we need to introduce a space of regular enough functions. So we denote by C2. We denote by C3, and we choose the functions in this space regularly enough so that we can use the Ito-Wenzel formula. And such that this U can be written in this evil process form. And since we have this C3, we can define the superjets and also the subjets. And here compared to the classical case and the point will be stopping time and measurable random variable. And I think this is natural, important thing. An important thing here is that how to describe the five states over you or states below you. And we do this thing by the optimal stopping time. So that is we describe the size this overview by optimal stopping time problem. So that here we use the Here we use the sublinear functions. And then since we have the test function space, we can define this costly solution similar to the classic case. And one thing is to explain here that the definition. That the definition of the miscosm solution depends on K0. That is, there exists a K0. And for any K bigger than K0, we can define the viscosity subsolution and viscose state super solution. And in fact, this idea comes from the comes from the path dependent the zero of path dependent so we called the viscosity solution k0 viscosity solution yes indicate that the solution depends on some some constant and here is a remark on the with code resolution if used with a k0 subsolution uh k0 subsolution and for lambda we define u tilde equals uh exponential lambda t times u and then we can check that this u tilde is a k0 subsolution of the following bs d e's and so that we can assume that h minus is decreasing in y Why without loss of junking. And this will make our work through easier. And first, we establish a stability result for these positive solutions to the BSPDs. And the stability result says that if for If we find a sequence of H minus epoch, it converges to H minus in this sense. First, such that this relation set relation seven holds and with Joe epsilon dance to zero. And if U epson is with cos T K zero subsolution, Zero subsolution associated to the non-linear generator H-manners epsilon. And if there exists a U such that U epsilon approximate U in this sense, in this sense, and then we can know that the U must be a K0 subsolution to the BSPDs associated to the non-linear generation. Non-linear generator H manners. Here is a remark on the stability result. In fact, we can construct another approximation and under this kind of approximation, the stability result still holds. That is, we use a Mollefair rho, which is a smooth function on the smooth function on the compact set and to define the g tilde to approximate the coefficients and then we constructed the Hamiltonian functions h plus or h minus if so in the same way as h plus or h minus And all H minus. And then the relation 7 is satisfied with the ρ epsilon equals to L. L is the Leipzig condition. It is the Leipzig constant. And so under this kind of this kind of approximation, the stability result still holds. But we can't use the approximation. Can't use the approximation in the regular approximation language before because the approximation is not uniform in time t. And then we have the existence of the viscosity solution. So under A1 and the value function V is the viscosity L solution to the stochastic HGBI equations. And the And the proof is based on the BSDE techniques and the generalized dynamic programming principle. And then in order to obtain the uniqueness of the solution, so we need to introduce some functional space because as before I said that As before, I said that compared to the control case, we in order to overcome the difficulties caused by the known convexities and the known and non-linearity of the generators, non-linear dependence of the generator on the variables. And we introduce We introduce a standardized function space. And so this makes the existence easier, but makes the uniqueness much more difficult. So in order to obtain the uniqueness, we need to introduce a larger space than the C3. So we define the function space. We define the function space C to lead as this as following. So U is in C to L is it is called that there exists a constant L U as such that U is defined with respect to this L U and although this U should be piecewisely regularly not piecewisely regularly. So this space is larger than the cis weight. Okay, okay. Sorry. So, and then in order to get the uniqueness, we first should prove a weak perpetration theory. And the idea is also inspired by the theory of Inspired by the theory of past-dependent PVs. So this weak comparison theorem says that we can compare the with costly subsolution with the functions fine in the C to leap, not directly compared with costly subsolutions. And by using the weak comparation theorem, and also we need to add assumption A2. It says that the diffusion sigma does not depend on omega X and the controls. And under these two assumptions, we can get with costlier solution is unique. So why A2? Why A2 is marketingly assumed is that because that because of the possible generators and the lack of certain estimates for the second order derivatives of E. So this prevents us from using the perturbation of sigma. So we need to add the A2 to get the uniqueness result. Uniqueness result. And if we assume the superparabolic condition, and we can relax the A2, so one of the following three holes, and we can still get the uniqueness of the solution. And finally, and if we suppose the exact condition holds, and we can get the And we can get the existence of the gain value. I think it is a standard result from the gain sigma school. Okay, so that's all. Thank you very much.