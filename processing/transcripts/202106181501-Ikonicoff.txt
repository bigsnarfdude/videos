A particular way to use these operates to produce what we call divided power algebras. Now, for those of you who have worked on this object before, and if you have worked on Kayla differential, you might have a clue how these connect to the notion of algebraic differentiation. But what I'm going to do today is not completely related to these. Completely related to this version of differentiation. Recently, I was developing a characterization of divided power algebras obtained from distributive law. And as a very easy application, I was computing the characterization of divided power algebras with derivation. And I realized that a very natural example of this was given by divided power polynomials and formal divided power series with the actual Power series with the actual formal differentiation of polynomials and formal power series over a field of positive characteristic, possibly, but I'll show you how it works. And that's also an article that has been showed to me by JS and Robin. So I'll show that later. So I thought that presenting this easy, nice computation would make for a perfect 20-minute talk. And to conclude this conference, and I will try to advertise for the Try to advertise for the pieces inside the notions that have something to do with differential categories. So indeed, I'm going to talk about divided power algebras with derivation, and it's a small part inside an article that I have put on archive recently, which is called Divided Power Algebras and Distributive Laws. And if you search that or just my name, there's no way that you can miss it because I No way that you can miss it because I don't have homonyms. So let me describe what is a classical divided power algebra. Let's say that you have a commutative associative algebra over a field of characteristic zero, and you look at the family of operations for all integer n, which is given by taking an x in your algebra, exponentiating it to the power n, and dividing by the factorial. And dividing by the factorial n. If you want to talk formally about those operations, you can draw a list of relations that will actually define those operations. So there's something a bit weird about my table is that my first law is actually something that doesn't talk about those operations and says, well, there's a commutative multiplication. So I'm putting that there for later. But if you look at the next relations, they are what the Relations, they are what define those operations. So, monomiality tells you that these operations are monomial. Homogeneity tells you that a degree zero polynomial should be the identity, well, should give you back the unit, sorry. Reduction repetition tells you how to multiply the divided power of the same element to different powers. And there's this binomial coefficient that appears. Minomial coefficient that appears. And then the Leibniz rule will tell you how to apply the divided power to a sum. And contrary to a normal monomial where you would have the Newton rule with binomial coefficient, in this case, the binomial coefficient doesn't appear. Unitality just tells you that the first degree divided power should be the identity. And then composition one and two tells you how to compose divided power with the Compose divided power with the product or divided power with other divided powers. So it sounds a bit silly what I'm doing because I'm on an algebra of characteristic zero. So I can do all of this and it's quite obvious. And the reason why I'm doing that is because now, formally, if I have a field of positive, possibly positive characteristic, I can still define the notion of a divided power. The notion of a divided power algebra over this field as being a commutative associative algebra with a family of operation Î³ n satisfying 1 to 6 without talking about the fact that I'm dividing by a factorial n. And I added something saying up to some way to handle the unit, and that's because there's some problem with the units, but I choose to hide it under the rug. What you can do is either It under the rug, what you can do is either say that the gammas are defined only away from the units or a certain augmentation ideal, or you can actually take away all the units, say that your algebra doesn't have a unit, but then you cannot define gamma zero and you have to change your Leibniz rule. But there's many ways to handle the unit. All right. So I'm going to give you a first example. So I'm going to give you a first example of divided power algebra and the canonical example that I can cook up is actually the free divided power algebra over a set of generators. But instead of a set of generators, I'm going to start with vector space. So if you have a vector space V, you can construct its algebra of symmetric tensors, which look like the symmetric algebra, except that here, so what I'm denoting by sigma n here. Sigma n here is the group of permutation over n letters. And instead of quotienting by this action, I'm taking the submodule of fixed points. And this has an algebra structure by taking the shuffle product. And it turns out that this has a structure of a divided power algebra and a divided power algebra, which is free in Which is free in the category of divided power algebra over the vector space V. So, of course, I'm saying a lot of things inside that means that this is a monad, et cetera, but we're going to see that later. Explicitly, if you take a base of your vector space v, then as a vector space, you can see gamma v as being generated by the divided monomials. Divided monomials, so just like your free polynomial algebra, but the difference is that the product is given slightly differently and extended by bilinearity. And I gave the formula for the divided powers here. So I give it on the set of generators for the algebra, and it's extended by monomiality, homogeneity, Leibniz rule, unitality, and composition rule. Unitality and composition rule. And you can think of this x hook n as the divided power. One thing that I should add here, maybe that's the good moment to do it, is that this gamma is indeed a monad and has an algebra structure. So it's an algebra modality. And it turns out that it has something that behaves like a differential combinator, but that's an ongoing work with JS. An ongoing work with JS. And if you ask questions on that, I might answer, or I might just send it to JS if he knows how to answer better than me. The second example that I want to show is the formal divided power series. So what I mean by a ring of formal divided power series over an algebra A is this thing, which would be like Which would be like lists of elements of the type I take an element of a and then I take something which is in the nth part of the divided power algebra generated by an element x. So the best way to think of this h is as sequences a and xn. So that's the formal power series that you're used to, but I'm writing with a hook because But I'm writing with a hook because I have to think of these as the divided powers of x instead of the powers of x. Or you can think of them as just lists of, like a multi-index, like lists of just the coefficients. And this has an associative commutative product, which is inherited from a and gamma x. Pretty much, you want to sum that just like you're used to. Sorry, you want to multiply two sums. Want to multiply two sums like that, like you are used to, and then you will be asked to multiply the element in A and multiplied x bracket n with x bracket m and multiply those two things give you n plus m choose n x bracket n plus m as I said in the previous slide. Now, if you were in characteristic zero, those bright zero, those bracket n represent the divided power x n divided by n factorial. And if you try to differentiate a polynomial like that, so the differential of the nth divided power gives you the n minus one divided power. So we can formally extend this definition of derivation even if the field is of positive characteristic. Of positive characteristic. And here on this set of on this ring of divided power series, well, if I take my divided power series to be just a list of coefficients, I'm just shifting by one. And that's because of this derivation of divided polynomial. And on that, there's also an integration with coefficient zero, which just does the contrary. So I'm shifting in the other sense by adding. In the other sense, by adding a constant term zero. And in this article from 2000 by Keo and Pritchard, that was shown to me by JS and Robin, they were defining the divided powers over the ring of divided power series inductively by putting gamma zero being the unit as one with. unit as one would expect and then gamma n plus one from gamma n by saying that gamma n plus one of f is the integration with coefficient zero of gamma n f times the differentiation of f. It turns out that this is completely coherent with what we would expect on the generators and it satisfies the right structure. All right, so that's my second So that's my second example, and I'm going to use it to ask the following question. If I have a divided power algebra and it's endowed with a derivation in the algebraic sense, which means that d of a times b is d of a times b plus a times d of b. What is the relationship that this derivation should have with the gamma n? With the gamma n, what is the relationship between the derivation and the divided powers? In other words, what's a natural or reasonable definition for divided power algebra with derivations? Now, on the Hurwitz theory, we have the power rule, which says that the derivation of gamma n is gamma n minus one of f times the derivation. And long story short, And long story short, I'm going to explain to you why this is a reasonable definition. It's actually what we would expect on a formal divided power algebra with derivation. So I need a framework in which divided power algebra makes sense and derivation makes sense, and that's when operates come into play. So I'm going to fall into that. So, I'm going to fall into that gap where if you know what an operat is, this is going to be already known for you. And if you don't know what an operat is, then it's very possible that you still don't know after my explanation. But I still have to define something, so I'm going to try. And since I'm amongst category theorists, I chose the category theory definition. So, if you have a symmetric monoidal category, I said with countable products because I was trying. Products because I was trying to see what was the weakest possible setup for operators. Here you can think of your category of base category as being vector space over a field. Then you define symmetric sequences in C as being a list. So a symmetric sequence in C that I denote, for example, M is a list Mn of objects of C such that for all integer N, Mn is endowed with an action of the Is endowed with an action of the permutation group on n letters. Alternatively, you can see that as a functor from the category of finite sets and bijection up to isomorphism into my category C. And I'm defining two monoidal products on it. The first one is the tensor product, and I've added this sigma here to show that it's the product of symmetric groups. So it works just. Symmetric group. So it works just like the graded module product, except that to get the right action of the symmetric group, we need to induce. So this is the induction from the Young subgroup sigma i times sigma j into sigma n of the module mi times the module nj. And I keep saying module because in my head I'm on vector spaces or modules of a ring. And I have a second product which is And I have a second product, which is what we call the composition product, m circ n, which in RT n is given by the sum over k of m of k tensor and tensor with itself k times in n. So I just said the word RET without defining it, so that forces me to define it right now. Mk is the element of m of r a t k. So that's K. So that's RTK element of M. And elements inside this thing are like one element in M and then tensor and elements inside. And with the sum of RATs here, so the sum of RAT Here is N. All right, and an operad is just a monoid in the category of symmetric sequences with this second product, and you can figure out what the unit is from my description. In other words, so that's the definition in terms of categories, but that's not the definition that I like to use. What I like to say is that an opera is, so a symmetric sequence, so it has. So it has RETN operations, which are the module of Pn, and I like to see them as trees with n leaves, because this way, when I'm going to talk about the composition product of an operad, since it's a monoid inside its category, I'm going to be able to graft my trees and obtain this kind of composition. So if I take an operation in P and then operations in P again, I can compose that. Again, I can compose that, and to each tree, like that, I get an element inside p with the right R T, which will be the sum of R T of what's on top. And there's a permutation of inputs that tells me how to shuffle the inputs, so the leaves. And there's a unit because it's a monoid. So since it's a unit for this composition, I can actually just give you the composition of one element. And that has compatibility reaction. In any case, Has compatibility reaction. In any case, that's the definition. Now I want to use it for my divided powers. Normally, with an opera, we define the 3p algebra functor as being this functor which takes a vector space v, sees it as a symmetric sequence in RT zero, and then compose it with P. And that looks a lot like the symmetric algebra of. Symmetric algebra over V. So it turns out that when P is an operad, this S of P is a monad, and you get a category of algebras over P. And that's perfectly fine, but that's not what we're going to do today. We're going to... Two minutes, very good. We're going to take a slightly changed product where we take the invariant submodule instead of dividing by the operation. Dividing by the operation. And modulus on very slight conditions, we're going to get a monad which we denote gamma p. And this is based on the symmetric tensor algebra that I talked about earlier, the motivating example being that for the operator of commutative and associative algebra, these correspond. All right, so let me go towards my results. The first result that I got a few years ago is that Years ago, is that instead of seeing those gamma p algebra, which we defined as divided power algebra over p, as just algebras over ammonad, there is a characterization in terms of polynomial or monomial operation satisfying relations. So that was the first goal. But today I want to talk about divided powers and derivation. So here is the actual result that I want to talk about. That I want to talk about. In the later article that I wrote recently, I saw that when you have two operads and they're made into the composition is made into an operad by a distributive law, then the divided powers over this composition of operad can be seen as a composition of divided power functors with a distributive law. And this is a pretty empty result because it's based on results. Result because it's based on a result by Beck from when he defined distributive law. But to talk about what we are talking right now, there is an opera constructed from com that is constructed with those distributive law that gives commutative associative algebra with distributive law. And the result is that when you want to look at a divided power algebra over this opera, the notion that you're looking at is exactly the natural. That you're looking at is exactly the natural notion of divided power algebra with distributive law. And the characterization that I obtained from this is a divided power algebra with a derivation that satisfies exactly the power rule that we had earlier. And to conclude, what I wanted to say is just that, in fact, what happened is that I did the computation, found this relation, and then I remembered the article back here and pre-shouted when to look. Article back here in Pre-Shot went to look and saw that there was this thing that said exactly the same thing here. So I was pretty happy that everything worked well. All right, that's all for me today. I'd like to thank you for your attention and thank the organizers for this wonderful conference. Thank you, Sasha. All right, so any All right, so any questions?