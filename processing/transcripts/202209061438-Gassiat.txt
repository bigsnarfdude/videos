It's a great place here. Great people. So, um yeah, so what I will talk about is uh perfected SD. So, this is a very standard object in stochastic analysis. And I will consider the questions: can we do what we do in password stochastic analysis to this object? And uh yeah, so that's not so easy, and uh I'm explaining why. Um Right, okay, so what is a reflected SD? So you have your standard type of SD dynamics, you have a driving signal X, your Y, which is driven according to X along some vector field F. And the reflection just means that you have some additional term. And what this does is it constrains uh your assumption to take value with some uh sub sub uh sub domain of this. Subdomain of the case of speaking something like this. So this is D, and you have your solution which moves according to some dynamics. And you have this additional term which is part of the solution. So the solution is the pair Y and this part K. And okay, so you should have this constraint which is basically enforced by this guy. And this guy should have this special force. So and typically what you take Um typically what you take, it's that was the case, but this additional term is a bounded variation term, so this is a bounded variation, and it pushes you your solution, it pushes it inside. And in this talk, I will most I will focus on the case where it pushes you in the normal direction. This is if you are at the boundary, so you have some force, but if your solution wants to go out, then basically it it's actually uh pushed back in in the direction of this The direction of this model. And then you have something like this. So, yeah, so whenever you are inside the domain, you just behave like some classical variance and just you have this additional term which only appears when you are at the moment. And these things are very natural objects when you have some kind of process which satisfies some dynamics, but in addition you have the constraint that it has to be. Has to stay valued some domain. And this, when so, sometimes this constraint is enforced by dynamics, water fields never go outside the domain or something, but when that is not the case, you have some uniform additional mechanisms to keep you so shaped. So basically, the most standard example of a domain is when, for instance, you have something where all the coordinates have to be positive. So, this is very natural in many applications, for instance, in queuing theory. Many applications, for instance, in queuing theory. If you have the size of a queue, this is a positive number. So, yeah, so of course, then you can have many more complicated domains. And this is really a very classical object. So she asked, I write the first solution of this kind of equation. It goes back to Scroll in the 60s. I know there are many papers in the 70s, 80s, 1990s. So there's maybe like hundreds of papers in this. So it's a very well-understood object, very Very like you know sort of results about this and all sort of weak assumptions on the domain and so on. And the very simple question that I want to focus on this talk is, okay, we know how to do this with semi-matting it, but what about trying to do this in the context of rough path theory? So for instance, if we have some dynamics or we want to model this using not a classical plane motion, but for instance a functional plane motion, can we do that with this kind of equation? This kind of equation. And we have this constraint of remaining in a domain in a compatible way with, for instance, an equation beyond value functionality. Okay, so let me just explain quickly why things are easy, if you want, in the classical case of um of a story material. Okay, and uh okay, so let me uh assume to simplify that the So, and okay, so the difficult point here in this context, I will focus on in this talk when you want units for the equation. Okay, so this is just about it. And okay, the point is that even though in principle this equation is not a In principle, this equation is not super standard AC because you have this additional bounded variation term. It has some nice property in the sense that you have this inequality here, which means that you should have a convex domain and you have two points, y equal to y. Let's say okay, let's see. Here is my prime and here is white. Here is y. And basically, you have this normal function, and somehow it's you have this. So, what this scalar product angle is that essentially this normal vector, it only goes in the direction. So, it doesn't, if you push this point in this direction of this vector, it's only bringing it closer to the other. Okay, so some kind of contractivity uh property. And with that, you can see very uh simply just using that and simply just using that and expanding the square here, that for instance, if you have a solution uh with dx equal to dt here, so just a like an OD plus something like this, that in fact uh this second term here basically it disappears in the inequality. You get something negative. Okay, so if you take two different solutions, this reflection, because of this uh somehow this uh contractivity properties, monotonicity, if you want it it's con it it does not um It does not, it only brings the solution closer. So, this is the case for standard bodies, it's very easy to see that. And, of course, also, I'm just making the remark here because in many applications you have analytic noise like this. And also, in that case, there is no problem because, of course, when you take two, if you have two solutions, the difference disappears. And then I'm just making this remark here. And why is this also simple if you have a Bohr motion? Also, simple if you have a brain machine or if you say nothing, that you basically do the same thing, except that now you have to take it. And again, a very simple computation shows you that because of this inequality here, this bulk version, they only bring things closer, at least on average, and you get a unit. And yeah, and so I also want to make this remark that so formally this this Because the equation is not given as a classical OD, okay, you have a system, but you can sort of formally see it as an OD driven by something which is very singular, and this would be like what you would have with the term entity of drift, which is the gradient of this function t. So this would be the gradient of the fun. I mean, formally, of course, this is, you know, you can make this. You can think of it like this. In any case, it's it's a And this in any case, it's something this reflection more or less constrains to something like a gradient flow term where the potential is zero in the domain and plus infinity at okay, which makes sense. It just means that it's from five zero plus three. And the vector functions, this is not an actual approach. But yeah, so in the classical case, this is very easy, and of course, you can also weaken the assumption a bit. And now the question is. Bit. And now the question is: Is this compatible with worth pass type solutions? Or just, I mean, a quick reminder of how you define worth pass solutions is typically, and this is what I write here, that you have this kind of local expansion, then you say that, okay, up to a small enough error, these expansions are exact. So this should be y. So if you show y in your solution, the increment of y is basically given by f of y times the increment of y. By f of y times the equivalent of x, and if your variant signal is better than one-half, this is enough to optify your solution. And when you go a bit below, you need to take an additional term and so on. Okay, so the rougher the logs, the more terms you need. But okay, so this is a difference of our type of argument. So here we want these rough path equations, you have how you define assumptions, how you prove that they are unique. how you define a solution, how you prove that they are unique and so on is based on things which are almost involved, which then you use the so-in-lema to say that it's actually the process. But and this is somehow a different kind of argument than the thing we had before, which is not an equality or an almost equality, but just an inequality, and then sometimes even in expectation. And I would say that it seems like it should work, okay. When you see this, this is so simple that, and you know this thing, okay, the this drift only brings them to small. This drift only brings them to solution closer and looks at seeing. Um so it seems like it should work. And it's kind of a I was I will explain in uh two minutes. It's actually doesn't it doesn't work. It's not really compatible and uh maybe I'll be surprised. Um yeah but before that let me give some uh a few positive results. So now I have this uh so yeah these two positive results. So the first one is that okay like I said I'm going to focus on the Like I said, I'm going to focus on the question of uniqueness for this talk because existence is actually it holds, or at least there's a technical reason to suppose to only prove for alphabetical answer, but it should be taken. Anyway, this was works of Ida already a few years ago. So he considered this equation and he obtained some estimates to show that you have the existence. But there are not too much regular Not too much regularity RD, basically the same assumptions that you need for the classical SD series. So, IDA showed that you always have at least one function. And the uniqueness was not yet known. And later it was shown, in fact, that you can have uniqueness in 1D. So, 1D, not for so for white. Because this means that 1D is there's not so much uh possibility for what kind of geometry you have. So basically this is why you have a Have basically this is why you have a half. Okay, so it's thinking of a half line, it's also works maximum, but uh something like a half-line. So it's just much much simpler than this. It's just you have your assumption, it has to stay positive, and then you can show unit messages. So this was first done by this paper of Sammy and Manco, John. Yeah, and in fact, so the the so the so I I put so there are two other papers also who degree and I at this point is red. Also, holding with this, and I think this one is red because this is a the proof has been really simplified compared to the first one. And this one is simple, and sometimes you use really this monotonicity, okay, and 1D monotonicity is somehow simple because we have only one direction, so if you don't point outside, it will point into direction somehow. And uh so in fact in this paper that I surprised they do even more because they show I mean I think one of the hotels will talk about that later later. Photos will talk about that later later this week, but they show that even with jumps and so on, this works, but okay. So in 1D you can use this monotonicity to really show that you have genomic. Then the question is what happens in the multi-dimensional case? And also I will give several results. So which again, like I said, is maybe a bit surprising. At least for me it was surprising. This sort of very simple object sort of reflected equation. Simple object reflected equation, it doesn't work when you have a rough dragon. And so the result is the following: you have this equation, which is two-dimensional like this. So you have this two-dimensional equation, and the domain is also very simple, because it's just a half space. So the constraint is that x has to be positive. Yeah, uh I I I have this my graph of the solution in in one way, yeah, but um In one way. So you have this sort of simple equation. So the constraints that x has to be positive. And then you have this linear dynamics from x and y, this kind of hyperbolic system. And just to that, you have just a simple drift, minus dt, and the reflection. And then this turns out, it's a very simple equation. It turns out to have infinity minus solutions. If beta is irregular. And in particular, so what I showed was that. And in particular, so what I showed was that, for instance, if you take a fraction of motion, if you take, so for one half, for any index treating as a one. So the rough setting. Yeah, and I also looked a bit more into it. What exact fabularity do you need on beta? And in fact, I showed that you can also take anything which is slightly less than one half order, and which means that you need to have Um which means that you need to have um modulus of continuity with the power of the log as soon as you take anything which has a strictly bigger pro power in the log than the usual one for random motion, then you packify many subjects. Those are two cases. Yeah, it's it's not the same. Uh yeah, these are two two different things. Why? Yeah, so it's it's a oh, okay, so it's not one uh why is not reflective? Yeah, so why is not reflective? not reflected. Yeah, so y is not reflected. So it's a half half space. So y is free and x is reflected. And so this is what the solutions look like. So this one does not really correspond of course to a function of dimension. It's more if you had jump data or the drift of jumps, but it helps to see what's going on. So you see that this this first part, the linear part, is just your solution moves along hyperboles like this. Balls like this, okay? And then the drift actually pushes you back like this. If you see that you have these hyperboles, the drift is somehow going, if you think of the hyperbolic, you see the drift between the here, or the hyperbol is higher. So somehow the drift, even though also this drift is somehow, it's not really pushing you away from the origin, it's still in terms of the circle, it's pushing you to the higher hard purpose. And then the reflection actually ensures that you don't go into this part of the plane because Sure, that you don't go into this part of the plane because if you went into this part, the drift would actually push you somewhere in the bad lower. So, it's very simple, this, and okay, with this, for instance, you can make very specific computations based on this. That what you see was the one-half regularity comes from, is that essentially, if you want the ratio of your path has to move, so if your path moves delta in this direction, then the The delta in this direction, then the actual increment here is more like delta score. So to get something which escapes from zero, yeah, I mean, okay, this is this is why the one half is coming from. This is kind of quadratic relation. What is depicted on the right? So on the okay, so this one is sort of a toy what happens if beta would be a jump, no, no, no, some kind of jump process. So each one of them is a jump process of Of the portions. And this one is actually what happens if beta is a fractional coefficient. Okay, but I forgot to say something, of course, because it was stupid because I have just given the graph of y solution. That of course this means that you have several solutions because the origin, the stationary solution which stays at the origin is a solution. If if y and x are zero, this is zero. This means you you just have a drift which pushes you like this, but since you have a friction you push back and the solution will stay at zero in The solution which stays at zero is in is a solution. What you're depicting is the non-trivial solution. Yeah. So where does that? In fact you can see there's also another one, uh the other part of it. All negative one, because this is the symmetry. Um yeah, so I mean very simple, but yeah, so this is equation. So so even though you know this reflection here again with what I said, it's reflection when you are here, it only it's When you are here, it's only it's not pushing you away from the origin, but it's only pushing you in this direction. Auto-going auto distance, but still it's somehow when you have a rough signal, doesn't mean that you are unique, that you stay at sorry, the signal on the right-hand side was when it's a fractional pronoun emotion. Yeah, and I maybe h equal to 0.2 or something else. I mean this is very easy to simulate, and I I take the initial condition almost zero and Almost zero and well, you see, because he touches several times, right? So if you do not have a reflection, it will move here. Because really, so this when you this moves like this, but just because of the reflection, it stays here. Okay, so this is a negative result. What about positive results? And here, I mean, to formulate this, I won't I won't To formulate this, I want to introduce a notation with what is called the score of the score, sorry, the score of a map. And it's just basically the score map is if you have a path in the full space, it's a map that this one maps the restriction, sorry, not the restriction, but the constraint. So now basically just one way to factorize this, I'm just given one pass W at the pass. One path w at the path z, which stays in the domain and which is reflected in the domain. And this means that with this in hand, you can rewrite your reflected equation as just this fixed point like this. If you look at this, what is the dynamics here, then it has to be... You take this guy, it is restricted to state domain, so it's gamma. And so it's very useful to be able to do manipulations with this guy, and okay, so for instance, the physician. This guy, and okay, so for instance, the f this first paper by Scroott, which he made, was a very simple but very nice observation that, in fact, uh when you dominate it just uh R plus, then this has a very simple form. And of course, if you have if you want to pass to stay positive, it just means that whenever you are below zero, you have to subtract the inf running info. Yeah, and also here a remark is that if you have something which is a product of the main, so okay, so that's So, okay, so not thinking about anything uh very complicated here, but for instance, when you have this half uh half space in 2D, then you are looking at the uh score map when the domain is R plus times R. Then it just means that you don't touch the second coordinate, and for the first one, you do this reaction. Right, and so really the point is that now you can write this equation as a fixed point like this, and you can say, okay, can I analyze this fixed point fixed on tools? Excellent tools, which means what are the properties? Does this map gamma here have nice properties that I can use? And in fact, yes. So it was proved by these Polish authors in 2015 that in fact this core map, at least in this simple case that I described, when you have products of intervals, maybe infinite or not, but product of interval, then in fact this map is Lipschitz in Pivari H. So this core map. So this core map and uh yes first they only did it for the half-line and then you just this is just a question of the relevant subform is a pivotation function of the pivot. Now they came back with a new paper last year where they did this for bounded interval, yeah, but um so so this core map is lifting pivot. And because of that of course this means that you can then in the case in the young case so if you so you remember So you remarked that my counter example was in the rough case, but in the young case you don't need any rough past approaches, you can do everything with just a classical p-variation, and with that, this means that you can basically set up a fixed point equation, fixed point principle, contraction principle for the significance. This thing is loop sheet simplifiation, and if you are in the long case, this thing is also going to be lip sheet implication, so you can set up a fixed point. This is why what they showed, I mean the move. They showed this, and of course, as a more or less immediate correlation, you get uniqueness of solutions for equations driven by a fractional branch. And they also, in fact, do a bit better, that they also can obtain well positive for some mixed equation. So we can do it with classical brain motion using these soy material ideas, and they can basically this mix. You can basically this mixes well with this project. Okay, so so yeah, so it's basically this this idea says, okay, when you are in the young setting, this is going to. I want to talk about some more recent results that I have using my Pejour Student Cast Madrid, which is it's not directly related to this problem of uniqueness, but it's more of a variation of what you can do in this young case. Do in this young case. And this is a result on a regularization by laws of bodies. So it's similar to the things we've seen already in two talks in this concept. Yeah, so you have a dynamic of this form, so you have a drift B of Y T and to that you add a functional migration, and you want to do the reflection for this problem. And what we showed is that for that, this works for even very irregular. Even very irregular functions B, sense that B can be taken C alpha with alpha as soon as alpha is written in this case. And you remark that when this guy goes to zero, this goes to minus infinity. So D can be arbitrarily negative distribution. And somehow this is a variation on the argument. This is a very nice treatment of chemical and group. So we already explained a little bit. So Dieremy and Fabian explained how this works. So the idea and why also this is not very surprising if you know the previous slide that why we did this is that we do reflection, the previous slide shows that reflection works well with pillaration and with a young integration theory and in fact the idea in Catalogue Benini was that to use Young integration To use long integration to solve the equation. So they were doing the full space, but and so I'm going to go quick here because this was already discussed in two talks. But the point is that you look at this average field and the important observation and why you have organization by noise is that this guy has a much better. So each of these guys in X has a bad variability, but when you take the integral, because this guy goes basically everywhere, how oscillates a lot is as much. And for instance, so h and yeah, so the point is that then when you write the equation for uh the solution minus uh ground motion B, you can you use this uh average field that you need. So if you have the the usual uh oh this is the question and so and for for us with this additional reflection element, gradient signature of the galaxy. Right. Yeah, okay. And but you see, okay, so one thing though is that no, okay, I'll just go to the next slide. To continue a bit more explaining, in fact, this is sort of this simple thing, seeing this as a fixed point like this. It only works, it doesn't work if you want to go to this what is expected. We want to go to this, what is expected to be the optimal regularity here. And by the way, this is actually the same one for this statement is just saying, okay, we can do exactly the same as they did, but if we are restricted to sets to stay in a domain, I mean, a domain of this very specific form. Oh, two minutes. Yeah, and okay, so one thing, I'll just mention one thing is that what we needed to obtain this. What we needed to to obtain this uh optimal regularity is to show that uh we we know that the regularity of the turbature for the functional brand motion and we we needed to show the same regularity but for the reflective function of motion. And okay, it's not so surprising that basically you have this thing which is very regular and you add to it something of finite variation and with some procedural work similar idea. Um okay, I'll just go quickly to talk about open questions. Um About open questions. Yeah, so it's not, I think there's still quite a lot to understand here that it's not answered. Okay, and okay, so for instance, there is one thing. Okay, so it's sort of an obvious question in this strong case. Can you do in many applications, it would be natural not to have like a half space or a corner that's like this, but what happened if, for instance, you domain also simple but has a non-right angle. The non-write-handed map. And in that case, it turns out that the analysis of the scroll map is more complicated because you don't have this. So now you have interaction between the different codes. And if you want to do the same thing that FiPox case 2 did, you can ask yourself, okay, what is the property of the score of the map in this low-copy domain? Is it usually simply variation? And I will just note here that the case of P or infinity, which corresponds to supernova, has been studied this paper by Gupio Nishi, and it's actually not Dukyo initially, and it's actually not as easy. Sorry, it's actually a bit subtle. Okay, and I'll just skip directly to the final slide, which I think is the most interesting question that remains here. Is that okay? From my cattle example, we saw that there is no general unitness for the questions, but can we still find a way to find criteria to restore unitness? And for instance, so here I mentioned just three things. Three things. One is that, yeah, if you if you noticed what my results were, is that I gave results for functional notions 3t less than 1 half, and then for functional functions 3t greater than 1 half. And I didn't say, okay, so h equal to 1 half somehow is a classical sense, it's a classical case, so you can do it with usual Martinez theory, but you could ask yourself what happened in actually this case. So with this precise logarithm, So, with this precise regularity, if you have a rough path, you need the password analysis. And because for the counter example, I explained that there are the regularities that you need to have. You really need to be strictly worse than brain motion to have several solutions. And you can ask yourself, so yeah, is this a general fact that in general if you would take a rough path which is almost not enough path, so which is actually the case of um any interesting uh problem. Many interesting well, at least interesting processes like this back order nerve class. So, in that case, what would happen? So, around basically one half. Just something which is just a little bit less than one half order, do you have units? And okay, the more interesting conjecture is, can you find some condition of the vector field that would guarantee units? Because if you remark, again, I mean, these are some ideas coming from considering the contraexopheryle, is that if the contraexable Considering the counter example, is that it's a counter example, you have this boundary and there is just one point where you have a point. So this is the origin. Everywhere else, there is no problem. If you start everywhere else, you will have a unit solution. You can see the one point, if you have a vector field, it's just uh something like this. So well it's uh it's it's zero here, but it's non non-zero in your website. But it's non-zero every remote. Yeah, so it's sort of, you could expect that somehow, as soon as your noise is pushing you to the boundary everywhere, then a situation like what happened with this head robot will not happen. So this is a sort of bit of a loose conjecture that if you have non-degenerate dynamics in the sense that everywhere on the boundary, the dynamics push actually pushing you towards the outside the domain, then it would catch you. And okay, and finally you can also And okay, and finally you can also say: would you have uniqueness not everywhere but somehow, like for almost any initial position? Which would mean for instance if you have like a cloud of particles and you know how they avoid you. Okay, so thanks for the stuff. Okay.