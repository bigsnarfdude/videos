Uh, we can uh get started with the next talk if uh Eddie is ready. Uh, so this is Eddie Shouty from um did I pronounce the last name correctly? Um close enough, Shouten Shout. Okay, uh yeah, and Eddie is going to be talking about uh minimal entanglement for injecting diagnobits. Uh yeah, thanks for being here. Um, I was asked yesterday evening to give a talk, so I had slides ready, but this is like the I had slides ready, but this is like the long version. So I will try to skip through some parts to keep it within 30 minutes, right? Plus questions? Okay, so let's see. All right, so I will talk a bit about how we want to implement gate sets on a fault-tolerant architecture and, in particular, a surface code architecture. So, first, I'll introduce this problem a bit more, talk about how we can. Problem a bit more, talk about how we can compile CNOC gates, and then we'll do some non-cliffer gate compilation stuff. So, you know, the Microsoft group has put out a paper last year, I think, where they propose a certain compilation stack, right? So you specify your algorithm in some high-level language. I mean, maybe it's Q-sharp. Language, I mean, maybe it's Q sharp or something or Clipper. And then this compiles down into what they call an intermediate representation, which could be your Clifford plus T gate set or Toffoy and Hadapart or something like that. And in particular, we'll be focusing on the next level down in the stack where we take this Clifford plus T gate set and then we come up with a circuit that implements it. Circuit that implements it on a surface code architecture, right? So the surface code architecture is perhaps the most widespread quantum error correcting code, you know, for like superhero qubits. Which, you know, and below that is, you know, how do you implement QVC? How does your device control work, et cetera? But we're going to forget about that. And I think everybody at this workshop is fine with that usually. Workshop is fine with that usually. But maybe air correction could be cool to talk about. So, yeah, we're given this logical gate set, so clipper plus t, and we're going to compile it into the microcode is the technical term I think we're going to use for this. So, you know, local, ZZ, and XX measurements on the error correcting code, you know, because we're doing lattice surgery and polyoperations. Poly operations. Okay, so what does an architecture like that look like? So we have our surface code patches and we're just going to tile them in a 2D plane. And this will allow us to do lattice surgery between adjacent patches that implement the CZ or XX measurements. The logical gate set can be visualized as follows. So if in each of these squares, we have one logical qubit. One logical qubit that is air corrected through a surface code. And the gate set consists of poly operations and single qubit measurements in the Z or X basis. But through lattice surgery, we can also do XX or ZZ measurements in the horizontal and the vertical directions. And you know, we have some implementation for Hadamart that you know expands the patch a little bit. So you have this weird, you need like a two by two piece of space on your architecture to implement this hat of art. So, you know, let's translate this weird language into something everybody should be familiar with. Namely, if we want to implement a CNOT gate, we can implement that by doing a ZZ menu. Can implement that by doing a ZZ measurement with an ancillary qubit and then an XX measurement. And then we do local polycorrections. Another example could be a swap gate. I actually didn't explain this, but this is sort of a single qubit teleportation. We call it a move gate. So, if this is an ancilla patch, then you can always teleport a qubit onto an ancilla. And then using those operations, we can implement. And using those operations, we can implement a swap. So we kind of move our qubit to the right and to the left, and then we move it vertically, you know, a second time step. And this is done by measuring the adjacent patches? Yeah, so you really just imagine doing teleportation onto an ancilla. So you kind of entangle A1 with A2 using a CNOT, and then you measure it in some basis, and then with corrections, you do a teleport. And then with corrections, you do a teleportation. Okay, so we love making choices, right, in organizing how we're going to compute things. And in essence, I think choosing an architecture like this is making a choice in how we want to compile. And one method that we frequently use is. One method that we frequently use is called are called magic states, right, to implement non-clifford operations. And what that means is that we're going to produce very special, you know, hard to produce states in specialized magic state factories, which are the red regions on this architecture on the right. And then we're going to use them in our computational space to perform a computation just using. A computation just using Clifford operations, which are relatively easy to do. And Litinsky proposed this architecture on the right. It's from his paper. And a particular scheme that we can use to do a computation is by commuting all our Clifford operations to the end of the circuit. And then, whenever you commute a Clifford operation through, Whenever you commute a Clifford operation through a t-gaze, what you get is some like large non-Clifford rotation, right? It's a poly string with rotation pi over eight or something, which can be implemented by consuming one T magic state. So this is basically implementing one T gate after a bunch of Clifford has been commuted through. And the advantage is that at the end of the circuit, you just need to do one. At the end of the circuit, you just need to do one cliffric circuit to implement all your clipric gates. So, you know, the only thing really that is hard to do in this kind of scheme is that you need to implement these big olive product measurements. All right, so what are the pros? Well, this is very easy architecturally, because the only thing you really need to worry about is how do I implement these measurements. worry about is how do I implement these measurements and we just all need only these magic t states right if it's a clipper plus t gate set and the number of magic state factories that you need is limited so this is sort of small in in in in its surface like in in the width the size of the code that you need however there is one con and that's that we are now sequentially That we are now sequentially executing all our T gates, one after the other, right? So we're kind of trading time for space savings in our computation. So if we say wanted to do two gates simultaneously, then two T gates simultaneously, because maybe we have a lot of magic resources lying around, then we can't because these don't generally commute, right? Yeah. Yeah. But I mean, if the problem, if the cost is primarily coming into the magistrate distillation procedure, if you wanted to do them, why not just make like a bug ton of T-states and then just apply, eject them all at once when you're going through it? Well, so that's the problem because you can't implement P1 and P2 at the same time. You can only inject one T state at every time. State injection is cheap. Yes, that's right. Yes, that's right. So then, what's the big deal? Um, well, I mean, it's still you have a whole logical cycle to inject one state, right? And it scales with the number of T gates you have in your circuit, even if it's cheap. Because implementing this requires you to create a very large, you know, cat state on your code, like a GHZ state. It basically uses the whole computational space to implement one by injection. Implement one, inject one state. Sorry. I still don't understand why this is a clock. There's no parallelization at all, right? Yeah. You have totally independent separate teams happening, and one might just have to wait for the other one to. Yeah, so your T size will become your circuit depth. Sort of. It's roughly like that. That's only if you cannot parallelize, you'll be one of the. Yes, that's right. But in general, that's the case. Yes, that's right. But in general, that's the case. You know, there are cases where you could optimize things, but yeah. I don't understand about the unparalleled ability of P1 and P2 because in active volume, Daniel had this like bridge qubit that allow you to do, like even though, for example, P1 and P2 use the same qubits, but you can still implement them simultaneously. Why is this not the case in this? Since you're also using the game of surface code as you. You're also using the game of surface code as your faceline architecture. Yeah, I mean, it's true, but that technique basically doubles the size, right? Because you're taking the space and you need to teleport it back in time. Well, you already need these two tickets. You already, like, they are already prepared in your ancillary patches. So, you, I thought you want to, because you want to optimize the time that you use, you spend implementing P1 and P2. Okay, maybe I wasn't clear. I mean, I haven't said anything about. Of, I mean, I haven't said anything about what we want to optimize, but we will want to optimize the volume of your computation, right? So the space times the time. And if we're going to use this trick to use the bridge qubits or teleport states back in time, we're going to need to double our space just to do one of those. If we want to do another one, then it's tripling the space, right? So it's not. There are many choices you can make. I'm not saying it's not, you know, not. Not feasible or anything. It just depends on the constraints of your device. So, then, can you articulate for the optimizations that you're looking at what the assumed constraints that you've got are? I guess we don't necessarily constrain our device, but we're just trying to find a method that might have better asymptotic scaling in certain parameters. Yeah, exactly. That's exactly what I'm asking. What are the parameters that are? So, what are the parameters that are of greatest interest you specifically have? I guess the depth, usually. Okay, so you're the opposite of me. You mostly care about the depth rather than the size. Well, you know, in the end, the end-all metric is the volume, right? But we're going to come up with asymptotic scaling that is better in depth and then see numerically whether. Numerically, either the volume is comparable or advantageous. So it is a kind of like you're fixing the space. You imagine fixing the space and then optimizing the depth given that fixed space. You're not thinking about, you're basically just taking a snapshot of whatever depth you use and not thinking about or whatever space you used and not thinking about, you know, kind of adding more space to it. I guess what we're going to do is we're going to forget about the We're going to do is we're going to forget about the magic state factor and take them as a given. So we're going to have plenty of t-states, which is very maybe not realistic in the near term. And we're going to double also the number of ancillas that we're going to use. But then we're going to get better asymptotic scale in the depth. Maybe I'm going to pause on the questions because I want to, you know, this is a long presentation. I don't know how far I'm going to get. I'm going to get so, and we haven't even talked about what we did. So, yeah, you know. And so, maybe it's a great thing for a discussion session later. I'm also learning a lot of things. So, okay, so how do we maintain the parallelism of our circuit? You know, just implement your circuit the old-fashioned way, right? So if you want to implement the CNOT on this architecture, right, now you have to think about how do I actually implement. Have to think about how do I actually implement the CNOT between two qubits that are far apart. And then, you know, secondary, we also have this problem with implementing non-coding gates. So, you know, we can use swaps, but this has a square n-depth lower bound just from the distance on the architecture. Or we can use this technique called a long-range CNOT gate. So we create a very big bell pair to mediate. gate teleportation protocol. And so this is what we call a depth two implementation because bell pair preparation is depth one and the measurement is also depth one. So how can we prepare this? Well we create a bell pair, you know, do our ZZ and XX measurements, and these bell pairs we can create at arbitrary distances. We can create at arbitrary distances in constant depth by just chaining together, you know, the bell break creation. I'm going very fast through this, but I'm happy to discuss afterwards if you have questions. So what does this look on the architecture? Well, we create bell pairs on, you know, odd pairs, I guess, or even pairs, and then we do the measurements to create a bell pair. And this is E and X X measurements. So what this means is we need So, what this means is we need exclusive use of these patches to create the Bell pair. And that means that if you want to implement, say, three CNOV gates on various pairs of qubits, then these paths can be very long, but we know it's constant depth, so we don't really care. But you can sort of see that this is using a lot of this space on your architecture to implement three CNOTs. And we're going to improve that by By allowing edge disjoint paths. Okay, so we're going to allow paths to implement CNOTs that can cross at a vertex, but they need to be disjoint along edges. So none of these paths have an edge in common. And we show how to implement this in depth for. And maybe this is, if you're familiar with some topological quantum computation, then this can be. Computation, then this can be seen as building a bridge in the third dimension over the other paths. But for the purposes of this talk, this is not necessary knowledge. So how do we do this? So let's say we have our CNOTs on the architecture, then we allow these crossings here at vertices. So all of these CNOTs can be implemented in depth four. So it's just It's in depth for so it's just a constant depth. And the intuition is that we're going to use the time dimension to build a bridge over any of these costs. I think, I don't know if I have an actual, in the paper we have an actual circuit. So if you want to know how it works, I will refer you to the paper. And the reason why we do this is because these two This is because these two techniques can be separated asymptotically in particular examples. Because, you know, in this example, if we want to implement C naughts between the qubits on the left and the qubits on the bottom, we can only implement one C naught at a time. However, there are square root n paths, edge district paths that can connect these particular C naughts. So there is an asymptotic separation in some cases between. Some cases between these two methods. So, you know, maybe paying a 2x overhead is worth it if you can implement more than twice as many C naughts. So you're trading a little bit of time for depth in some sense. So I'm going to skip over this. There's various hardness results, which are, you know, maybe of interest because we can use approximation algorithms to find. Approximation algorithms to find these sets of edge disjoint paths. So let's go to non-clipper gates. So we know our Clipper plus T is universal. And one little fact is that we can implement our T gates by consuming a T state. And the circuit looks like this. So we have a T state that somehow appears somewhere, and then we use this Clifford circuit to inject. And then we use this clipper circuit to inject the T gate. And we introduced this gadget where we can implement diagonal gates at a long range, right? So if we want to implement Rz rotation on this qubit, we can instead entangle it with an ancilla and apply the T gate on that encilla and teleport the result into so this is. So, this is kind of a nice construction that allows us to do some things. So, our high-level idea will be to entangle our computational qubits, right, in the blue region, with the magic state factory, where we are able to apply these T gates. Instead of moving the T states into our computational The t-states into our computational space, we're entangling our computational qubits with the magic state factors instead. So let's see, that's fine. And we can generalize this construction to any diagonal gate. So, for example, if you're thinking of CZZ. So, for example, if you're thinking of CZZ gates or something like that, you could have a magic state factory that prepares CZZ states, but by definition, that same region on your computer can also implement the CCC gate. It might need to be structured a bit differently, but let's say you are able to implement the CCC gate in some ancilla space, then you can just entangle your three qubits with the ancilla space and do that thing. I'm sorry, I thought you want to implement D, right? This is the one that you want to implement. Yeah. And then why you're using something that you don't know how to implement to implement something that you don't know how to implement? Like D on the right-hand side is implementing the left-hand side. Yeah, I think that's a good question because maybe I wasn't clear enough in the sense that we have our computational space, which is this blue region, and we're going to assume we have designed our architecture in such a way that we're going to assume. In such a way, we're going to that we're going to assume that in the blue region we're only going to do clifford gates because those are easy, and we're going to have some ancillary region in red where we're going to do those non-clifford gates, right? So they're just magic state factors that are pumping out magic states. And this is a probabilistic process that takes a lot of time. So you have many duplication, much duplication in this. But usually this requires a certain But usually, this requires a certain amount of area that we have conveniently optimized these magic state factors to be super efficient. It's just that you need ancillary qubits to do it. So we assign a particular space on our computer to do that, you know, 100% of the time. And then the problem becomes: how do we communicate between the computational space and the space where we can actually do our non-cliffer gates? Aren't there these grading strategies that you can do in order to be able to do long-distance communication if you have enough ancillas that are left over? Is that not a favorable trade-off? I mean, maybe I'm not familiar enough to answer that, but I guess at the core of our argument is a proof that if you want to inject such magic gates, the non-clifford gates, then some entanglement needs to be created in this process. It in this process. So we prove that there's a lower bound on it. And then, you know, depth guarantee depth bounds follow because creating entanglement takes time. Okay. The back one of the slides. Yeah. Yeah, this one. So on the right-hand side where I've got that D data, are you thinking about that as something that was already Thinking about that as something that was already injected with like a magic state injection at that protocol? I think. So we make a simplifying assumption, right, that is motivated by having this red region where we can create magic states. Instead, we assume that you have a region on your computer where you can do those gates, right? The non-clifford gates. So let's say a T-gate. So if you know, if you have a So, if you know, if you have a place on your computer where you can do a T-gate, then this can be implemented, right, in that region. But I guess, I mean, in some text, there is that the way that I would do that gate is by a magic state projection. Yes, yes, indirectly or it's just that there's a specific assumption here, I guess. Yeah, I'm gonna make sure the data wasn't actually ticked, but some like arbitrary volume. That you want a person as a person next to land, right? So, like, this gadget is one symmetric to sort of initiate the execution of that data rotation and then you can execute the data rotation also at this factory without consuming all the t-states. I see, and then a simple teleportation. Yeah, and then but then of course you just still want similar, right? So, you might be like otherwise you would have to you know do plenty of this state injections with Functions that the injections were basically you have to think about a lot of work happening kind of out in the red zone and then a single telepathy. And another way that it's advantageous is that you kind of decouple because you can commute this poly. As long as you can commute this poly later, you can have that happening on the side, you know, while you're continuing your computation. Yes, there's also some. So I know you said no questions at this point. I'm sorry. But I need to know, like, for the case of this swap network where you want to swap around a bunch of qubits. What is the absolute worst case scenario? Because in the all-to-all connectivity regime, you can do it in constant depth always. What's the worst case scenario for a surface code swap in this kind of architecture? In this kind of like architecture? I mean, we assume a grid or 2D layout, and then it's just the diameter of the graph. Even if you just have one pair at the diameter, and after that, it actually doesn't get worse because you've already attained the worst case. Well, I mean, with this, with this, like these chains of bell pairs, where like you now you can do it in constant depth all the way across the graph. Yeah. Like, what's the worst case scenario, even in that setting? Is it constant depth now, or is it still? In depth now, or is it still scaling? You know, like also the time between, yeah, so it's like I have it, I have all my service code patches laid out, and I just want to basically scramble them up. Like, what's going to be the cost of that kind of operation? It's still going to be of order, at least square root n, because, you know, if you swap two sides on your architecture, this is an entangling operation, and you're creating order n entanglement, right, between the two sides. Right between the two sides, and your cut size is only of square root. So you can create only squared and you know, e-bits per time step. Gotcha. So you need squared and time steps to actually do that. That makes sense. Do the reverse. Cool. So let's see. See, so yeah, another maybe advantage is that if you're, you know, Vadim alluded to it as well, if your gate is on like a higher level in the Clifford hierarchy, then just having one copy of that magic state is not sufficient to implement, right? So if you have a Z theta rotation where theta is some strange angle, you know, like some rational number or something, that is not popular. That is not popular. Then you might need to inject many, many of such states to implement a gate like that. So it might make more sense to kind of delegate a particular region of your computation to implement this diagonal gate D. And Eddie, maybe I know we slow down a lot with all the questions, but maybe you wrap up in a few minutes and then we can take. Up in a few minutes, and then we can take more questions offline. Okay, let me see. So I can skip through this stuff. So we show a relationship between the amount of information, but so we show a relationship between the stabilizer nullity and the The stabilizer nullity and the entanglement that is required to inject our non-clifford gates, in the sense that if you want to, say, implement a CZZ gate, then the nullity of a CZ state is three. So you need to inject at least three qubits into your code to implement the CZZ gate. And similarly, for all other diagonals. And similarly for all other diagonal non-Clifford gates, or all diagonal gates. So, you know, like the zero state has zero nullity, so it doesn't, you don't need to reject anything, obviously. But I'm going to skip the proof. Okay, cool. Cool. All right. So, for compilation purposes, what this means is that if we have our non-cliffer gates, then we can compute the number of E-bits that are required to compile these operations. And then, necessarily, if we take a mean cut that separates the region where we have magic state factories and where we're doing our computation, this provides a depth lower bound. This provides a depth lower bound on how long our computation needs to be, simply from computing the stabilizer nullity of all your gates. And therefore, we conclude that if you have an architecture where you're going to separate your factories from the computational space, then you better have sufficient connectivity between the two so you can keep your computation going because you need to keep making this entanglement between the two regions. And one way to do it is to sort of interleave magic state factories with your computation, which folks are already looking at. And another result is that our S-disjoint path compilation algorithm is optimal for injecting single qubit rotations because it creates the minimum amount of entanglement between the computational space and the magic state matrix. Matrix state matrix. So we have some numerical results for various circuits, but I'm going to skip over that and I'll briefly mention sort of the asymptotic complexity that I alluded to earlier. So we have our edge-de-strength path compilation algorithm, which we propose, and its scaling is better than swap in the Clifford case, and it's better than this Litinsky style compilation when we have. When we have non-clifford rotations, right? So single qubit rotations, in the sense that if you want to do k rotations, then we only need order square root k depth to implement. So thank you for your attention. Thank you for the talk. I wonder when you prepare a lot of questions. I wonder when you prepare a lot of magic states, or like when you have this magic state factory running and you have your computational space, how do you do the scheduling? Because I was worried about what if you have some magic states prepared, but in the computation, you don't need it yet. But by the time we need it, maybe like your state is no longer valid and you do another VRALS. And then this would be a waste of all of your resource or the time that you have done. Yeah, so the magic states that you have, you can store them basically indefinitely. Basically, indefinitely, right? Because you're running on an error-corrected code, and presumably it's of sufficient distance that your state remains coherent for the length of the computation. It is true that now this region where you have that magic state sitting might no longer be useful in the sense that its output is obstructed, right? It can't make another magic state, so it has. Can't make another matrix, so it has to wait. But we kind of don't really look at this in detail because we just say, okay, we have this region where we can do non-click gates and diagonal gates. We don't care how exactly. It doesn't have to be a particular magic state factory all the time. This could be a separate compilation thing, right? Like if you notice that you're filling up your storage with magic state. Filling up your storage with magic states, then maybe you can do something different or reorganize or something like that. We don't know. Does that answer your question somewhat? I would love to follow up with you after the phone. Okay. Sounds good. So would it be right to say that this technique is a way to try to get a configuration which is almost? Which is almost as parallel as the logical circuit that you started with. So I can try to get a circuit which is very parallel, kind of like the Clipper plus P or Clipper plus Bays kind of button or something. And then by the time I compile it, it kind of takes it in. Yeah, yeah. I guess the assumption here is that the circuit that you are given is already fairly optimized in that sense. Otherwise, it doesn't make much sense to apply. Make much sense to apply this technique because if it was already quite sequential, then you might as well just do the polybase because that's sequential too, so you're not losing it. Further questions? Yeah, can I ask another one? So, just now you look at the circuit as polyparotation measurement. You said, oh, well, we can push all the cliffhers all the way to the end of. Push all the clip runs all the way to the end of the circuit, and then, like, then this will involve some update to your like pi over eight rotations. Um, but have you considered like not push them all the way to the end, but only push maybe part of them? Because then your circuit, at least for the power over eight part, will not be so entangled because you don't really do too many cliffer updates. Yeah, yeah, that's an option. You could choose to not push it all the way to the end. Push it all the way to the end, do some clifford gates, and then sort of you know, it's kind of like a reset, right? So, you don't have that huge clifford operation that's getting pushed to the end. You kind of stop where it's becoming too entangling. You actually execute the cliffords. And do you have like spotted any like sweet spot? Like, for example, we don't look at it, so it's not, yeah, the goal of this work isn't. The goal of this work isn't to look at that particular extreme points, right? Once you explore the extreme points of the portion of all it risk computation in one extreme, right? So this agent jump fast another way. But you know, once you face compiling practical algorithms, you don't have to stick with one approach, right? So now you understand. Right, so now you understand pros and cons of pros approaches, and we should come back to them. Right, and you know, so in polar-based computation, there are some tricks also like in second papers where you have this sort of like memory register where you can use it as our space where we activate the configuration on and all post-process out for storage and things like that. And also reduce the model for space. So you now, like, once you face an application and play around with these techniques, you can solve them all the computation by using edge paths. And the point about edge distrolist is that you want to optimize the parallelization of the gate because if they're edge destroying jobs. Destroying jobs use this two CNOT several needs? The edge destroying part is mainly about implementing a CNOT circuit. So if we just have CNOT gates, I guess the goal is to implement as many CNOTs in one order, one time step as we can. So the method we propose takes twice as long, but it can implement more CNALTs in one go. You could try doing both and seeing which one is better. And see which one is better for your particular algebra. All right, well, maybe we should thank Eddie again and take more questions and start offline, so please get started.