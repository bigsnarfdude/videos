I guess we'll have to go back over there just on the screen. Short range condition. Okay, so sorry for the delay. Our next speaker is Lukasia Kosti from Carlsburg, Institute of Technology, right? And she will speak about the method of multipliers in spectroscopy. Please. Thank you all very much for the kind. Thank you very much for the kind introduction. And I want also to thank Gerald, the organizer, Peder, David and Ionel, for the kind invitations. Really amazing to be here part of this event in this enchanting place. So thank you very much. So yeah, as the title of the talk suggests, I will talk about the method of multipliers in spectral theory. So basically, the method of multipliers originally was developed Originally, it was developed to somehow study the dispersive phenomenon. So, from the 70s, Moravets introduced the method to study some quantitative dispersive property of the Flame-Gordon equations. But in the last decades, it has been recognized this method as really useful and now I would like to say also a standard tool in order to get interesting and meaningful results in spectral theory. A meaningful result in spectral theory. So the question we want to answer to is very natural and very easy to understand. So we want to consider the following perturbed operator that is in some sense the sum of two operators, a reference operator that I will denote as H0 and the perturbation V. The perturbation The perturbation is an operator of multiplication by a generating function that is assumed to be complex values, so our setting is not such a job. And the question is, let's suppose that we know about this reference operator, its spectrum, and what one can say about the spectrum of the operator. So, so far, I didn't give any example of the operator of the reference operator we will consider, but let's suppose that. But let's suppose that in any of our examples there will be a standing assumption that the spectrum of the free operator, sorry, the point spectrum of the free operator is empty. And then our goal is to understand under which condition under perturbation this property remains stable also in the perturbed setting. And of course, it is reasonable to believe. It is reasonable to believe that we will get a positive answer to our question under suitable perturbations. So, since bound states usually are trapped states, it is reasonable to believe that introducing some repulsiveness condition on the potential, then we can get absence of bound states also in the perturbed setting. But we can also think that we can somehow control, if we control somehow the Control, if we control somehow the bad behavior, so the attractive behavior of the potential in a way that is suitably small compared to the free Hamiltonian, also in this framework, we can get some stability. And so, at first, I will tell you that the method of multiplayers was developed in a purely PD setting, and I will just recall you the original framework. So, as a toy model, let's consider the Schrodinger equation. Let's consider the Schrodinger equation that is written here. And let's suppose, I will explain a bit more why. Let's suppose that we want to understand the behavior in time of this L2 weighted norm. So the multiplication by x squared. So we want to consider the differentiation, the two-time differentiation in time. So then we can rewrite this L2 norm as the mean value of this multiplication operator by x squared. Multiplication operator by x squared. And then, just using the fact that u is a solution, of course, formally, but using the fact that u is a solution of the linear Schrodinger equation, one can see that every time we differentiate in time this mean value, we obtain the mean value of the commutator with the generator of the dynamic. So, this means that now we have another differentiation in time to do, and now we are. To do, and now we are here the mean value of this operator, and then we differentiate in time, we use the equation, and we get a double commutator. Now, one just compute explicitly the double commutator that is nothing but A times the Laplacian, and then from this identity we obtain the following identity here, just after an iteration by parse. And since the L2 norm of the gradient of U is a Of the gradient of u is a conserved quantity for this model, what we get is that the second derivative in time of this quantity is strictly positive. So this means that this function, so that this integral is a convex function in time. So this means that it tends to plus infinity as the time goes to plus or minus infinity. And this is exactly a quantification of the disparistic phenomenon because in Because in a dispersive equation, the idea is that even if you start with a data at time zero that is extremely concentrated in zero, so let's say that this integral is barely zero, then as the time goes by, the very localized data somehow becomes a superposition of wave trains that are everywhere on the real line. So this makes the integral, this integral. makes the integral, these integrals as the time goes by going to plus infinity. So far there was no multiplier method in this slide. So here we were just using formally that using the equation one could get this useful identity. But actually this identity obtained formally, just using the equation, can be obtained alternatively and in a rigorous way. And in a rigorous way, multiplying the Schrodinger equation by this skew symmetric multiplier, so the commutator of the generator of the dynamic and the x-squared, and then taking the real part of the identity. So now let's see how to use this method for our purpose, so to prove absence of bound states. And we start again in a toy model. In a toy model setting. So we consider as first the self-adjoint Schrodinger operator. So in my first slide, there was a reference operator here that was H0, and now the H0 is replaced by minus Laplacian. And now we consider V as an operator, a real valued function. So the idea is that we want to assume that some bound state exists, so and we want to obtain a contradiction of that. We want to obtain a contradiction of that. So we consider the eigen-value equation. Here, of course, lambda is real because we are in the self-adjoint setting. And then we start somehow developing the method of multiplier. So as before, we multiply by the skewc metric multiplier that we have already seen in the previous slide, and then we take the real parts. So now, looking at So now, looking at the right-hand side, so the real parameter lambda does not see the real part, so it just goes out. And then here we have that this quantity is a purely imaginary quantity because it's the mean value of G-Symmetric operator, so it disappears at the right-hand side. But what is important is not just that we don't have any more right-hand side, but that it disappears at the presence of the gim value. The presence of the eigenvalue. So, and this is important because we want to prove the total absence of the eigenvalue. So, we don't want to obtain somehow estimates on the location of the spectrum, but we want something that is somehow not depending on the spectral parameter at all. So we are happy that the spectral parameter does not appear anymore here. And then, just using some algebra, we have that this left-hand side instead is the mean body. Is the mean value of this double commutator. And now, using what we have done already before, so we are computing this double commutator, or at least the part related to the free operator, and then we obtain then the L2 norm of the gradient of U, and then, of course, a term depending on the potential. But this term that depends on the potential, and better depends on the radial derivative. It depends on the radial derivative of the potential, depends on that in a nice way because it is the sign of the radial derivative who gives the sign on this integral. V is the real part of V here, right? Sorry? You don't need the complex part of the imaginary part of V here. No, no, no, here, no. It's just the real part of it. Yeah, yeah. It's we are that's the self-adjoint. It's we are that's the self-adjoint case, so here we are. Yeah, I will show you in the next yeah this is just the toy model to understand how this method works, but then in the next slide I will show you what to do with the no-set adjoint case. So just to say that with this method we realized that there are simply easily easy conditions to give about the potential. Give about the potential in order to get the contradiction that we want. Because if we assume that the radial derivative of the potential is negative, then what we get from this inequality is that the L2 norm has to be less than or equal to zero. But of course, since we are assuming some decay of our eigenfunction, then this implies that Q has to be trivial. And so this implies that the point spectrum of the perturbed operator is this point. Of course, This boy. Of course, okay, this is a somehow an easy request, but as I was telling you before, actually we could we understood that the good sign of this object is the negative part of this. But then if we assume that somehow the positive part is more in a suitable sense compared to the free part, to the kinetic part, then also in this case, if the smallness condition is sufficiently small indeed, then we can get Sufficiently small indeed, then we can get the same. So, for those of you who are somehow familiar with the Moore theory, so the commutator theory a la Moore, then somehow you could have recognized in what I was telling you before a similar approach. So, basically, the Moore theory says that let's suppose to consider the Schrodinger operator, and in particular, let's consider the self-adjoint Schrodinger operator. The Moore theory simply says that if simply says that if the Hamiltonian here is symmetric, then this mean value of the commutator of the Hamiltonian with an operator A is equal to zero. And for Schr√∂dinger it turned out to be a useful object to consider, to set as operator A the generator of the dilation. And indeed, if one considers, if one assumes that U is a solution of this eigenvalue equation and one consider The eigenvalue equation and one consider A as the dilation operator, then explicitly writing the commutator here, one gets that is nothing but a multiple of the Laplacian and again there is a radial derivative of the potential appearing. And this somehow this has immediately some condition to give to the potential in order to get a contradiction also in this framework. So simply assuming the negativity of the rate. Simply assuming the negativity of the radial part of the radial derivative of V, then we get absence of eigenvalues also with this method. But how does the Moore theory meet the method of multipliers? So in the method of multiplier, what we had to do is to study a double commutator. In the Moore theory, the the crucial point is to study and to give a sign to a commutator. sign to a commutator. But then one like gives a closer look to the generator of the dilation and then one sees that actually, so here we have to study the sign of this commutator here, but actually A is nothing but then the commutator with the Laplacian Nx square that was exactly the operator that was appearing in the slide of the method of multiplier. So studying this commutator is the same This commutator is the same as studying the W commutator for the method of multiplier. And indeed, we get exactly the same condition on B that we got before. But the problem of the Moore theory is that it does not fit well with the non-self-atrolled framework. So this identity holds only if the Hamiltonian is symmetric. But instead, what Fanelli, David, and Luis Vega in 2018 proved was that the method of multiplier instead would give some. Instead, it would give some interesting results also in the non-self-adjoint case. So, let's just try to use the same strategy that we were using in the self-adjoint framework. So, of course, the spectrum in this case, since we are in a non-self-adjoint setting, is no more necessarily real, so we emphasize that introducing the real part and the imaginary part of the spectral parameter. And we focus just. Parameter, and we focus just on excluding eigenvalues that are in a sector containing the positive real line. So we are basically considering the worst case. So the other case it's easier. And then we do the same. So we multiply by the same multiplier and we take the real part. But this time does appear a term which depends on the eigenvalue, actually, on the imaginary. Value, actually on the imaginary part, and this term unfortunately does not have a sign. So we understand that one identity, so just this identity that was working pretty well in the self-adjoint case does not work in the non-self-adjoint case. But then we use just some basic knowledge. So let's suppose to have some term that has, for instance, a bad sign for us. So we want something positive, so a bad sign is being negative. Then we know that just. Negative, then we know that just adding a square and b square makes these three terms together having the sign that we want. So basically, we understand that, okay, one identity was not enough for us, so we need to add more identities to obtain some sign on the right-hand side that could help us to get the same results, so the absence of the in-values. So, a good algebra and suitable choices of multipliers give Give this identity here. And it seems that we are not getting any better somehow, but actually, we take advantage of some old works by Eyus and Kevin Seitel, and they were studying limiting absorption principle for electromagnetic Helmholtz equation. And basically, what they do, what they did, was to introduce some sort of, in their analysis, was to introduce. In their analysis, it was to introduce a sort of change of gauge. So, u is our function, and we multiply by this phase factor. And just computing the gradient of this u minus, we simply realize that what appears here, so in the first line, is nothing but the L2 norm of the gradient of mu minus, and here it appears a term again involving the gradient of mu minus. Again, involving the gradient of mu minus. So, this term was the bad term because it was the term that was depending on the spectral parameter, but now this term is positive. So, paying the price of putting minus or equal than zero here, we can get rid of this term. So, again, we are in a setting in which there is no presence of a spectral parameter. And then, as done before, we want to introduce some notion of repulsiveness, of repulsivity, and Of repulsivity and a smallness condition on the potential in order to get again the absence of eigenvalues as before. So we, together with David, some time ago, we tried and we tested the the robustness of the method also. So so far we were working on the whole Euclidean space on the whole R D. And we tested the robustness of the method also Robustness of the method also in some special case, so in a special domain for special domains. So, in particular, we have a result in the L space. So, you can think to this problem as considering the free Laplacian and perturb the free Laplacian with a potential that somehow is supported on the boundary. So, in this case, on zero plus infinity. And now, the role of the potential is played by this. Is played by this function alpha here that appears in our Roban boundary condition. So somehow the self-adjointness, so this function is complex value, so somehow the self-adjointness or non-self-adjointness of the problem is depending on the self-adjointness or not of the boundary condition. And one can do exactly the same analysis, and basically, what one obtains is that now the condition that one has to give. Condition that one has to give to obtain an absence of bound state are conditions that are somehow on the boundary of the domain and no more on the domain itself. So for instance, we can assume some repulsivity condition and get rid of this term, just assuming positivity of the real part, and then we understand that to treat this term, so what one This term. So, what one has to do is: okay, we cannot assume some RD type smallness condition as done in the previous case, because here now we are working on the boundary and instead we want some object that is on the old domain, omega. But somehow we partially integrate by parts, so in a way that we can get this term bounded by the h one half of homogeneous norm of u minus, and then just using a trace argument. Using a trace argument, we can get as before that if the constant appearing here is sufficiently small, then we get some power of the same absence of eigenvalues we obtain in the Wull of Vidian case. And now, just for you, for concluding, so this method actually was tested also for Was tested also for other models. So we were interested in considering the electromagnetic Schrodinger equation, so where the Laplacian is replaced by the magnetic Laplacian. And in the algebra, what happens is that, of course, appears a new term, a new term that does not depend on the vector potential A, but depends on the physical object. Object, so the magnetic, the magnetic field V, and is this term right here. And then, also, in this case, if one assumes some smallness of the following type, so some hardy type smallness condition for the magnetic field, then one can conclude absence of A values also in this framework. And just to compare, there are other works that try to disprove the presence of eigenvalues in this electromagnetic setting. Electromagnetic setting, but in a way, so for instance, just to cite one, there is this work by Koch and Tataru of 2006 in which they gave results based on Carleman estimates for obtaining absence of eigenvalues, but with giving conditions which depended not on the magnetic field here, but of the magnetic potential. So giving somehow gauge depending conditions. Gauge depending conditions. And now just B is regular log. And then we need to assume a B. Okay, we can also, we can also, under different conditions, we can also treat like if we have just one singularity, so also R node bonding is included, but with a bit of different, so we have to justify also. bit of different so we have to justify all the all the these formal uh uh steps but uh with Arunov one also works so it was our example exactly that that case and just in if I have just one minute more so what I did in my so already some time ago in my PhD thesis was to adapt this method to treat these lame operators of elasticity that I don't I Elasticity that I don't, I will not go into details, but the fact is that this operator is a matrix-valued operator. And then, also, after having some sort of experience in treating matrix-valued operators, we worked jointly with Luca Fanelli and David in order to treat matrix-valued electromagnetic Schrodinger, so operator of these four. And what we did was so optimal. So, obtaining some sort of very general theorem in this situation. But our purpose for treating this matrix-validation was because we wanted to go beyond just the non-relativistic setting, and we want somehow also to introduce and to study Hamiltonians, which somehow take into account. somehow take into account also an inner very important in a structure of the electrons in the electromagnetic case that is the spin uh the spin uh the spin so we wanted also to treat operators like poly operator and Dirac operator for the poly operator it's easy to see that the method can actually work in the same way because what is the difference between the poly operators and the magnetic shredding are just this Magnetic shredding is just this new term, so where there is a term depending on the magnetic field multiplied by these polymatrices. So basically the method works exactly as in the case. So we can treat V and B at the same level. But what is even what is actually more surprising is that we were able to get something for the DR operator. That has a completely solid. All the operators I was showing you before, all the examples were second-order operators. Where a second order operator bounded from below, and then we claim that we can get something for the DRC operator, that is an operator of first order that is not bounded below. And the reason why, I will not enter into details, but the reason why is that, okay, we could consider the D-R operator, the magnetic DRC operator, but we had to put V equal to zero, so with no potential, because we wanted to use the supersymmetry property of the Diracophone. Property of the DR cooperator that tells you just that squaring out the DR cooperator gives a diagonal matrix where on the diagonal we have a shifted poly operator. So now with this supersymmetry property, it's more reasonable to believe, and actually it's easy to prove that absence of eigenvalues can be obtained also for the DR cooperator, assuming that the potential B is equal to zero. And I think that's. Worked in zero. And I think that I had my time. Thank you very much for the attention. Thank you for the talk. Other questions, remarks, comments? Please? So I don't remember the assumptions that you have on uh on the potential uh G. So when you apply it to the the magnetic case, what is it what are the assumptions? What are the subjects? Yeah, I didn't state the theorem, that's an additional slide. So basically, okay, we can treat potential in this form, V1 plus V2. So V1, we assume that is suitably small, so let's say in the sense of Hardy, so we assume some Hardy smallness condition for V1. And here we need just to have L one log. So we want that somehow the overhead makes sense in the sense of so. Make sense in the sense of so we assume some relatively boundedness in the sense of form condition for the V1. For V2, V2 is that we want to assume repulsive condition and for doing that we cannot treat the general matrices but we can treat just say diagonal matrices so with T that has to stay in this space. So it's a differential This space. So it's differentiable and it has to have this integrability condition. So the integrability condition for A and for B are the following one. And actually, the only reason why we need these conditions are because we needed to perform a regularization process. So if one does all the computation formally, one does not see the appearance of this condition, but somehow we have to regularize and make the And make the steps meaningful, and we need to assume this additional condition. But for instance, so okay, 1 over x squared, that is the hardy potential, would not work because if we, so it does not is not in, so 1 over x square is not in L T half. But again, if we have just one singularity, we can perform a slightly different Slightly different argument that allows us also in that case to include this kind of interesting examples. So is P a constant okay? No, we have to have some decay condition for B actually. Yeah. Just a comment. Some sample F condition of the coefficient is one of the not just Is one of the not just technical sources of confident data and some of the testing that we're running others some software that you run. Okay, I see. I see. Okay. Thanks. Let's just go home. Does the multiplier method work for non-local equations? Uh okay. Actually, mm I I haven't tried, but uh uh actually I I had in mind. Actually, I had in mind somehow to try them. I really don't know if there can be probably some easy situation, yes. In general, I don't know, but I mean the power of the method of multipliers is that is just you can really see what you want from the beginning. So you understand if it's going to work or not from the very beginning. So just try. It can be Try is it can be an option, but I cannot say more actually. Any further questions? Any online participants? Doesn't seem to be the case. So let's find the speaker again.