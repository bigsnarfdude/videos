Thanks, Paul, for the introduction. So, yeah, so that's an application of the product structure theorem that I really like. So, I'm happy to have the opportunity to talk about it here. So, thanks to the organizers. And this is a joint work with Vida Brumovich, Cyril Gerald, Piot Micek, and Pat Morin. And it's about building universal graphs. Building universal graphs for planar graphs. So, what is a universal graph? What is the problem that we are looking at here? So, imagine that you have some set of graphs that you care about. So, we are going to care about end-load-explanatory graphs, but this is ready for any set of graphs. And a universal graph for your set of graphs is a single graph that contains every member of your set as a subgraph. Subgraph right so a universal graph for end-dot explainer graphs will be a graph that contains all the end-dot explaner graphs as subgraph. Your universal graph does not have to belong to the class of graphs that you care about, right? So for instance, for planar graphs, the universal graphs that we are going to build, they are definitely not planar. But we want to contain all the anvotex planar graphs or anvotex trees. Pick your favorite graph of class, third class of graphs. Of class, third class of graphs as subgraphs. Okay, so that's the question that we are going to look at in this talk. How can we build good universal graphs for n-vertex planographs? So how do we measure quality here? We are going to count how many edges we have in our universal graph. Obviously, you could take a complete graph on n-vertices. It's a definite universal for all graphs on n-vertices. Not very interesting, it has quadratic mini edges. Quadratically mini edges, right? So, we instead would like to be as close as possible to a linear bound in the terms of number of edges. Okay, so that's the question we're going to address. What's the minimum number of edges in a universal graph for end-of-explano graphs? But instead of jumping right into that problem, let me try to build up some intuition with you by starting by looking at trees, how to build universal grass for an vertex trees. Uh, universal grass for anvotex trees. This is not difficult, and this will be a good warm-up to what we are going to do next, right? So, if you were new to this area and you had to build yourself inversal graphs for trees or maybe also for some other classes of graphs with small separators, maybe your first reflex, your first idea would be to use small separators. Right? So, for me, a separator will be a vertex subset so that when you remove it, Subset so that when you remove it, there is a way to arrange the components in two sets, each of size at most two total cent. That's the definition I'm going to use in this talk. And if we are looking, say, at trees, as you all know, there is always a vertex of the tree, which is a separator, right? You can always orient the edges of your tree towards the bigger half. There is a sink. Remove that sink. Every component has at most another two vertices. And by the usual argument, The usual argument, you can arrange these components in two sets of size at most. So, trees have a very small separator. They have a single vertex separator. So, maybe this is the first thing you would try. If you were to build a universal graph for trees, you would say, Okay, if I want to embed my n-vertex tree as a subgraph of the universal graph I'm building, I'm going to put I'm going to put the separator, so this single vertex, which is a separator, on a universal vertex, this vertex V on top. I make that vertex universal to my construction, and then I recurse. So how many vertices do I have on each side? Well, I have two thousand vertices on each side at most, but one of the two sides will have at most n of the two. So on one side, I can put a construction for two thousand vertices because. Put those n vertices because it will. And on the other side, I can put a construction for n of the two vertices. But this will work. Obviously, if you look at the one side, it's not really a tree, it would be a forest, but this would be contained in a tree, so it's enough to imagine that we are handling trees and thousand bodies here. But so this is already a good construction in the sense that the number of edges would be significantly less than. Would be significantly less than quadratic. But we are not reaching a linear bound or near linear bound with such a construction. If you solve the recursion, which I'm not going to do, the number of edges will be about n to the 1.3. And intuitively, what's going wrong here is that we are creating too many vertices. Right? So here, in one step of the recursion, we have n of the two there. That's nice, but we have two dozen here. And this is blowing up. Blowing up. So once you see this, then maybe your next idea would be: okay, it would be really nice if instead of having a separator where we would have two totals n on each side at most, if we knew that we could have at most another two on each side. That's the next natural idea. And of course, this is possible. Well, it's not possible to find a single vertex of your tree that you can remove so that you have another two on each side, but you can find. To only side, but you can find log and vertices that will do the job by a standard argument. So, let me review quickly the standard argument, but this is very natural. I'm going to call that a perfectly balanced separator. And for me, perfectly balanced will be that you can arrange the components in two sets that have exactly the same size. So, not only of size at most number two, but like exactly the same size. So, this is the best way to separate. To separate your graph. So that's what a perfectly balanced separator is in this talk. And by standard argument, trees on n-vertices they have a perfectly balanced separator of size order of login. There are many ways of seeing this. This is really tree-deft in a sense. Let me quickly review how we get this because we are going to use this actually. We are not going to use this on trees, but we are going to look at bounded tree with graphs because they appear in the product structure. Because they appear in the product structure theorem, and the argument will be the same. So, let me quickly review how we get them. Well, we simply are going to, in the case of tree, we are simply going to rip off our usual separator iteratively. So we get some recursion tree, right? So, this is on top, this is the first attack ripped off, the first separator, and then left and right, you rip off again, a separator, etc. And now, if you look at And now, if you look at the depth of your recursion tree, it could be at most login base 3 over 2 of n, right? Because at each step, you have at most, like at the first step, you have n vertices, and then you go to sets with at most total n, right? So you have, I mean, we don't care about constant factors here, so you have the height log n, but what you can observe also is that, so this is just the recursion tree, but But if you think of edges in your graph, they will always be between a vertex and an ancestor in that tree by definition of ratios. They can never connect to vertices that are incomparable in the tree order. And what we can do is we can take any leaves in that recursion tree and we can take the leaf to root path. Path. We are picking up log and vertices in this way. And this will be some sort of separator. It will separate the left from the right. So once you have a drawing in the plane of your recursion tree, there is a clear notion of left and right. And no vertex on the left and vertex on the right are compatible with respect to the ancestor relation. So this orange set separates left from right. Separates left from right. Okay, and now what you can do is you can start at the leftmost leaf and look at the corresponding leaf to root path, and you could look at all these sets where you go always to the next leaf, right? So you just scan from left, the leftmost leaf to the rightmost leaf, you look at the corresponding login vertices. And each one, each time you separate left from right, but there will be a time where you separate. But there will be a time where you separate, where left and right will have roughly another two vertices. Because when you move to a leaf to the next, well, in this case, you would add one vertex and lose one. If you move again, you would add like login vertices and lose login vertices. So in each step, local changes you make, it's like at most login vertices. So you will find a choice where you have up to log n vertices almost the same on left and right. And then once you have this. Right, and then once you have this choice, then by removing a few extra vertices, you have your separator that is a perfectly balanced separator. Right, that's a quick sketch of how to get it. And now, how do we use that? Well, we are going to do the obvious thing, right? So, once you have your tree, you're going to take a perfectly balanced separator and you're going to make a click out of that. Our perfectly balanced separator will be embedded on that click on top, and you're going to make that universal add to the rest of the graph. And then you recurse on each side, but now you know exactly how many vertices you know on each side, right? It's n minus the side. It's n minus the size of this click over 2. And how many edges do we create in this way? Well, in one step of the recursion, we have this click of size order of log n, and we have about n vertices here. So in one step of the recursion, we create n log n edges. Next step of the recursion, where we will have n over two vertices here, n over two vertices here. So we are going to create n over two times log n edges here, another two times login. Edges here, another two times log n edges here, roughly. So this will be n log n again. And there are at most log n steps. So in total, this graph has n log squared n edges because. And this is universal for trees. And so this is a near linear bound. And up to a one log n factor, this is, I mean, this is almost optimal. It turns out that with using a more complicated construction, you can shave off. Complicated construction: you can shave off one log n factor, so you can go down to n log n, that's the theorem of Chung and Brahan. But for the purpose of this talk, we are actually being fine with paying some polylog factors. So, this easy construction will be good enough for us, and that's what we will have to keep in mind. Okay, so that's for trees. It turns out that for trees, n log n, this is the best you can hope for. There is a matching lower bound, simply because if you have a Simply because if you have a universal graph for n vertex trees, well, you need to contain the star on n vertices as a subgraph. So you need to have a vertex with degree roughly m, so n minus one. But you also need to contain the graph, which is like two stars on n over two vertices. So you need to have two vertices of degree at least n over two, n over two minus one. You also need to contain this. You need to have at least three vertices with degree rough. To have at least three vertices with degree roughly and over three, right? So, if you look at the degree sequence of your universal graph sorted in non-increasing order, it has to dominate this, roughly n, and over two, and over three, and over four, up to the minus ones. And so you will have at least n log n edges. So n log n is tied for trees, and that's the end of the story for trees. Okay, of course, what we did so far, we didn't use much the file. We didn't use much the fact that we are looking at trees. The only thing we painted is the fact that trees have smooth separators. They have a single vertex, which is a separator. And from that, we got a log and size subset, which is a perfectly balanced separator. That's the only thing we use. So as soon as you have a class of graphs that have small separators, you can do exactly the same construction. So if you have a class of graphs where the n-vertex Where the n-vertex members have separate of size at most s of n. So it could depend on n. For instance, for penographs, this would be put n. Then from these usual separators, by paying an extra log factor, you can get perfectly balanced separators with exactly the same argument. And then you can do exactly the same construction discussed. And then you have again an extra log n factor from the recursion steps. And then you get either side graph for that, for the end of the. For that, for the n-vertex graph in your class, where the number of edges is n log squared n times size of the separator. So, if you have, if you are looking at trees, this is one. If you are looking at graphs of bounded tree weight, this is a constant. So, whenever you have small separators, you have a corresponding construction using these separators. Obviously, if you're looking at classes of graphs where the size of the Of graphs where the size of the separator is small, like strongly sublinear in n, but polynomial in n, so like n to the alpha where alpha is strictly between zero and one, then by standard analysis, these extra login factors that disappear, right? Because you have a square because you insert a click at the separator. So you mean here? Yeah. Oh no, that's the plus. Yeah, sorry, sorry. That's okay. Okay, yes, it's okay. Yes, it's a plus, it's not a times. But thanks, that's a good check. Okay, so yes, indeed, if you look at classes like a planar graphs where the size of the separator is strongly sublinear, but it's polynomial in n, like root n, then these expand factors they disappear because of geometric series. So actually, you don't have Series. So actually, you don't have the extra log squared n factor by user counting, which I'm not going to do. But then in that case, you really get bound on the number of edges, which is size of the separator as a function of n times n. So for planar graphs, this is root n times n. So this is n to the three half. And for planar graphs, that's essentially all what was known. This is exactly what Babai, Chunger Dusch, Brahan, and Spencer did. Schumer Dosh, Brahan, and Spencer did in 1982. They showed that for planned graphs, you can do n to the three-half edges, and that was the best known up to now. But of course, this is not restricted to planar graphs. It works for any class with small separators. So, what I'm going to tell you today is how to use the product structure to get from n to the three-half edges to a near-linear bound, n to the one plus. Nearly bound, n to the one plus leader of one. But before doing that, let me mention some generalizations of this to some other classes of graphs that have strongly sublinar separators and that are that are related to planar graphs. Just to give you some overview, I'm not, of course, going to give a complete overview. I'm just going to mention three examples to have in mind. The first example. The first example does not have a product structure, so what we are going to do does not handle this example. So, if you look at touching balls in R D, so intersection graphs of touching balls in R D, as we know, they have small separators, separators of size at most n to the one minus one over D. So, if these two, you have a back to Kennedy graphs and we have routine separators, but like for larger D, you still have universal graphs with subquadratically many edges. Subquadratically, many edges, but we have this bound, but we don't know how to improve this bound. That's one thing I wanted to mention when these at least three. Still using separators, another generalization of penalty is looking at graphs on surfaces or graphs for being a fixed minor. You have root and separators each time. There is you hide the dependency on your surface or on your minor in the big O. So more precisely, if you have a graph. So more precisely, if you have a graph for your genus G, you have separators of size root of G times N. If you formulate a graph H as minor, you have separators of size at most H to the three half times root n. So when you fix these things, you have separators of size root n. And this translates to inverse graphs with n to the three half n times some dependency on the minor euphoric. So this Know you follow it. So, this bound here, we are going to improve it to a near-linear bound because there is a product structure there. This bound here, we don't know how to improve it because we don't have a product structure. This would be one of the open problems. And as one last generalization of planarity, you have the notion of k-planarity, right? So, every it's a drawing where each edge crosses at most k-order edges. We also have for fixed k, we also have root and separators. Separators depends on k so k, and this translates again to the other side graphs with about n to the three half edges. And there is a product structure, so this will this will be improved as well. Okay, so that's for the context. Now let's look at the product structure. So, as I mentioned, we get a near linear bound, n to the one plus linear one. And this is for invertext planar graphs, but more This is for endotex planned graphs, but more generally whenever you have a product structure where your horizontal graph edge has bounded through it. So, this is this we did with Louis and Pat, but it builds heavily on the previous paper with a superset of photos with Lida, Louis, Cyril, Piot and Pat, which is for the related problem of adjacency labeling schemes or equivalently induced inversal graphs. I'm going to say a few words about that at the end of the talk. Okay, so we are going to use the product structure. In the product structure of penographs, say you have a graph H that has tribute at most eight or at most six, depending on which version you use. And what we are going to use, we are going to use trivia in the sense that it implies that you have a small separator, right? So if you have trivial k, you have a separator of size at most k plus one. And that's how we are going to use trivia in this talk. So I don't have to recall. So, I don't have to recall what the product structure is. We have it in mind. So, let me. Okay, I don't know what's happening. It seems not working anymore. Okay, so let me be a bit more precise about the theorem we prove and the bounds we get. So, it's a theorem for So, it's a theorem for graphs that admit a product structure. So, more precisely, we are looking at the n-vertex graphs for which you can find some subgraph, some graph H of 3B d at most T and some graph P so that your graph is a subgraph of H times P. So, once more, we look at all the invertex graphs that are subgraphs of some H times P. So, H is not fixed, and H has three terms. And we for those for these uh for this class of graphs, we build and we build a universal graph that has a near linear number of edges and the dependency on the tribute is t squared. Typically, we think of the tribute as being a constant. This is a constant times a near linear part. It works again. Great. Okay, so that's the problem, and now. And now, let me say a few words about how we are going to approach the problem. So, there we go. First, let's speed up the problem a bit. So, what we are looking at is n-vertex subgraph of h times p. h is a bounded tree graph, kaffir tree, for instance, and p is a path. Now, if you are looking at the end vertex of graph of h times p, you might as well. times P, you might as well assume that the number of rows, so the number of vertices in P, is at most n, right? Otherwise, there is a row that you don't use and email, you may as well remove that row. So you actually can imagine that P has exactly n vertices, just to simplify a bit the picture. Similarly, when you think of your boundary tribute graph H, you might assume that it has at most n vertices. If it has more, there is a column in the product that you are not using, you might as well. Product that you're not using, you might as well remove it. So, you can actually imagine that H has exactly n-vertices, P has exactly n-vertices, and you're going, and you are looking at a strong product of these two, and you want to realize the n-vertex subgraphs of that product. Okay, so that's the picture we should have in mind. Now, there is a subtle difficulty here, is that H is not fixed, right? So, if, for instance, H is a tree, and Since H is a tree, and tree with one, it's not a fixed tree. It can be any tree on n vertices, and you have to prepare for every tree. That's a bit annoying. It would be nicer if we knew in advance what is the age we should be looking at. How can we replace a set of graphs on n vertices, for instance, all the n-vertex trees or all the n-vertex graphs of tribute eight, by a single graph, by using universal graphs, right? So instead of like preparing for all possibilities. Instead of like preparing for all possibilities for H, we are just going to replace H by a universal graph for graphs of trivia. So that's the first cleanup that we are going to do. So let's do it now. And let me a bit, let me describe the universal ground for Turbity. The universal graph for 2BT slightly differently than what we did just before. So you have in mind this picture for how to build this universal graph for turbidity, right? By ripping off iteratively these perfectly balanced separators that you make universal. It turns out that the following construction is almost the same. There is a slight difference, and it does that as well. And this will be easier. As well, and this will be easier to think about in our construction. So, let me describe this construction, and you will see that it's almost exactly the same in the subgraph, but this will be slightly easier to play with. So, what is this construction? So, first, I'm going to look at complete binary tree of height log n. And by the way, all the logs are in these two from the on, so log n is really log in these two of n. Complete binary of height log n plus all the edges implied by transitive. Plus, all the edges implied by transitivity in a tree order. That's the graph I'm looking at. And now, in that graph, you blow up each vertex by a click of size what you would expect for your first perfectly balanced separator. So, free p of size or free t log n. I'm going to use the letter omega for that. So, I'm going to blow up every vertex by omega vertices, a click on omega vertices, and omega is. vertices and omega is like t log n right um so this graph if you think about it it's almost the same as what we built for for tribute t uh and that's so it's universal for triple t and that's the one we are going to use one way to describe this graph so it's really this uh closure of complete binary tree where you blow up each vertex by blowing each vertex by a click we can describe that as taking the strong product with a click on omega vertex and we Gabriel. And we are going to see in a moment why it's actually a good way to think about it in this way. So what do we want to do? We have this graph on top right, this slide, which is what? It's strong product of C log n with k omega. But that's just a fancy way of saying our universal graph. Of saying our universal graph for 3T. And we take the strong product with this path on n vertices. So this is the graph we are looking at, and we want to realize all the n-vertex subgraphs of that graph. If we realize all the in-vertex subgraphs of that graph, we in particular realize all the in-vertex subgraphs we cared about from before. So we are doing a bit more, but this will be enough. Okay, so that's what we want to do. That's what we want to do. And now that the main technical theorem that we are going to prove is the following: we are going to drop the strong product with the click on T log n vertices, on omega vertices. We are going to drop that and we are going to just look at the strong product of or the closure of our complete binary tree with the path. And we are going to realize the end-vertext subgraph of that with a near linear number of edges in the inverse subgraph that we are building. Graph that we are building. I'm going to call that graph GN, and I claim that if you can do that, which is really the heart of the proof, then we are done. And the reason is that if you can do that, say that you have a universal subgraph for the n-vertex subgraph of product of these two graphs, then you can actually solve the initial problem. And why is that? Well, if g n is universal for the invertex of graphs of this product, then you can take You can take Gn and blow up each vertex by your click on T log n vertices. And this will be obviously universal for the n-vector subgraphs of this graph there where you blow up each vertex by a click on omega vertices. You are doing exactly the same operation on these subgraphs. But this graph, I mean, you can rearrange the factors, it's exactly the graph we cared about. So it's enough. So, it's enough in terms of universality, it's enough to solve this problem. And what about the number of edges? What's happening when you blow up vertices by a click of size omega? Well, each edge gets replaced by a complete bipotet graph with omega squared edges. This is what will dominate. So, in terms of counting down the number of edges, we had this many edges before. So, n times some n to the value of one. To the beginning of one, and now we have an extra omega square factor. In our case, omega was order of t log n, right? That's the size of our perfectly balanced separator in the graph of boundary with. And so, this omega squared, this is really t squared log squared n. We have a t squared, and the log squared n I'm just going to hide in this n to the leader of one term. So, in terms of number of ages, we are good as well. Of number of edges, we are good as well. So it's enough to solve this problem. And this is really how we clean up the problem. And now I'm going to tell you a bit about how we use the product structure to build inverse subgraphs for the n-vertex subgraphs of closure of multi-binary tree of right log n and a path from n-vertices. So this might seem like a technical problem, but this is really the Problem, but this is really the heart of the problem. So, again, you have to picture in mind: you have this path on n vertices, so you have n rows. In each row, you have a copy of the same graph, complete binary tree of height log n, plus edges implied by transitivity, right? So, you have to have this picture in mind. It has n squared vertices, and you want to realize the n-vertex subgraphs of that product. Of course, if you look at a single n-vertex subgraph, well, the way it uses the rows, it could be like really Be like really, really, really uneven, you don't really know, and somehow you have to anticipate all possibilities. So, what I'm going to do now is I'm going to tell you what are the vertices of the universal graph that we are building. But I'm not going to tell you what are the edges yet. So, I'm just going to tell you what are the vertices. And then I'm going to switch to what is the embedding strategy to embed like a given endotextal graph of a product inside our universal graph. Our universal graph. And from this embedding strategy, you will have a glimpse of what are the edges that we actually need to put in the universal graph. But I'm not going to define the edges explicitly because it's a bit secondary. So what are the vertices here? Well, the vertices are easy to describe. They are triples XYZ and XYZ are big strings. And they sum up to roughly log N. So one times the login base of n. One times the login base two of n bits. Now, precisely, z is not very interesting, it will be of size log log n bits. I'm not going to, it will store some extra information. I'm not going to go into that. The really main part is x and y. And they will handle the two coordinates of our product. So, y will somehow encode in which row we are for a given vertex. For a given vertex, and x will encode somehow where we are in this row for a given vertex when we embed our end vertex subgraph or product inside or in the subgraph. That's the idea. Now, these x and y, in terms of number of bits, they will sum up to roughly log n. Log n plus a little of log n. And z is pretty small-size log log n. And that describes the vertices, right? It's all the triples where the bit strings. The triples where the big strings are not too big in this sense. That's all the vertices. And now I'm going to give some interpretation to these vertices so that you get some idea of how we use the product structure. So let's look first at what's the job of the y coordinate. The job of the y coordinate will be to somehow encode in which row we are from the perspective of a vertex and we are going to use binary search. vertex and we are going to use binary search trees for that. So let me remind you of the definition of a binary search tree. So that's a rooted binary tree and each node has a key or value. And the key property of a BST is that in the left subtree, all the nodes have a value less than your node. And in the right sub-tree, all the nodes have bigger value. So there is no tie in the situation that we are considering here. And the first And the first thing we do, we do something which is quite natural, is that we are going to build a BST, a binary search tree, on the rows. So equivalently on the vertices of your vertical path. So you have n rows, but when you look at an n-vertex subgraph of your product, you don't really know which rows you are going to use. Maybe some rows are not going to be used at all, and maybe you are going to use a lot of vertices on some rows. So you have a notion of weights for the rows. Weights for the rows, and we want our BST to depend on the weights of this row. So, to take one extreme case, if you use a single vertex in, like on this picture, the weights are in red here, you have rows up from one up to 15, so one up to n in general, then what you're going to build for your BST on the rows is a perfectly balanced BST on these rows, like on this picture. But of course, in general, it won't be like evenly. Evenly distributed, you are going to use some rows and some rows you are not going to use. So, maybe you have lots of rows with weight zero. In this example, you're maybe only using rows six, seven, eight, nine, ten, and maybe you have like big weights in rows six and ten, you have a weight of six, and maybe a weight of one on the three rows in between. So, that's like a more realistic situation. And in that case, our BST on the rows will only store the rows with. Store the rows with non-zero weight, but we want the BST to be biased with respect to the weights, to the row weights. So, more precisely, we want to that if rho i has some weight ri, then the corresponding node in that BST, the node corresponding to rho i, has depth at most log n minus log of g sweight. And that by completely standard construction, you can build that. So, the intuition you have to keep in mind. That so, the intuition you have to keep in mind is that the rows with big weights will be close to the root in your BST. Okay, so so far, this is like completely standard and very natural. Like you have maybe uneven distribution on the rows with respect to the weights, and you build a BST to handle that. And now, if you look at the y-coordinate in the In the definition of the vertices of the universal graph, the job of Y will be to encode the position of the row in that VST. So if you look at the VST, how do you encode the position? What's happening? You simply write left, right, left. You simply encode how you go to that from the root, how you go to that vertex in the PST. Right, so that's for the vertical binary. Right, so that's for the vertical binary search tree, the binary search tree on the rows. And so far, there is nothing special happening, I would say. But now the real work comes with handling the rows themselves. And what we are going to do is that for each row, there will be a corresponding binary search tree. So we will have n binary search trees, n horizontal binary search trees, one for each row. So if you look at row i, there will be a corresponding I, there will be a corresponding BST, and the job of this BST will be to store the vertices of rho i that are actually used, you know, and the text subgraph. Right. So there is a question. Yes, just a quick question. You know, you said that your tree is going to be biased with the heavy nodes closer to the root and the lighter nodes below. Doesn't that affect the balance of your tree? Yeah. So is it going to make it like... So, is it going to make it like some O of log n or something? So, it won't be more than log n. So, you're talking about the vertical binary search tree, right? Yeah, that one. So, the thing is that the sum of the weights is n, because we are looking at an n vertex of graph. So, we are weighting the rows, but the sum of the weights will be n. So, we will still have that the height will be log n at most. Most, but what we really have an extra property is that if you have a node, so a row with big weight, then it will be close to the root, like but the path from the root to that node will be shorter. That's the extra property we get. But we still get an upper bound of one log n on the height. I hope that answers the question. Okay, so now if we look at the horizontal DST. So, the horizontal BSTs, so the ones we create for each row. As I said, the job here of these BSTs is to store the vertices of that row that we actually use in our end-vertext subgraph. So in an extreme case, if we use all the vertices in that row, so what is this row actually? This row is a copy of C, right? It's a copy of this graph on top: complete binary of hypogen plus transitive closure. Plus transitive closure. And we need to talk about the vertices of that graph. So let's number them. And we are going to number them as if the underlying tree was like a perfectly balanced BST. So we are going to use this numbering on top. So if we are in an extreme situation where we use all the vertices of a given row, so all the weight is on a single row, then corresponding VST we are going to build naturally would be simply this VST. Simply this VST, right? It's simply store all the vertices in a perfectly balanced BST. But in general, you're only going to use a subset of the vertices of a given row. So I don't know, maybe you are going to use only vertices that are numbered five, six, and seven in this picture. And now your BST has to store only those vertices. And now the question is, how do you build your BST? And that's really the problem that we need to solve. We need to solve. And if we were stopping here, then maybe you would think: okay, let's just build a perfectly balanced BST from scratch that only stores these values. So in this case, it would be this. And that's nice. It's especially nice if you think in terms of bits, because that at least will satisfy our upper bound on the bits requirement. Because if you think of a vertex, Because if you think of a vertex of your n-vertex subgraph of your product, you are going to spend some number of bits to encode in which row it is. So if it's in row i and it has some width r sub i, you're going to spend at most log n minus log r i bits to encode in which row it is. And once you encoded that row, you still have log of the weight of the row bits left that you can spend. Of the row bits left that you can spend, and then you are going to use them to encode the position in the row. And it turns out that the corresponding row BST has exactly R sub i vertices. So if you have a perfectly balanced BST there, then you can encode the position in that BST using log of R i bits. So in terms of number of bits, this is perfect. Like you are going to satisfy this condition here. This condition here. But of course, this would be too easy, right? And this is not good. And what is not good intuitively is that here I'm just talking about one specific n-vertext subgraph of your product. But we have to handle all possible n-vertext subgraphs. And if we do this, there is no relation between a BST in rho i and a bst in rho i plus one. So intuitively, in the universal graph, when we put the edges, we somehow When we put the edges, we somehow have to anticipate all possible connections between rho i and rho i plus one. And it can go, if you don't know anything about these two BSTs, can go all over the place. And you are going to put lots of edges and you're going to have at least quadratically mini edges. So that's like, I would say up to here, this is somehow natural, but we are faced with this problem that if we just use perfectly balanced BSTs, it doesn't do the job. You are going to put too many edges. Going to put too many edges. So let me tell you what we do instead. And this is the part that I'm not going to describe in this, but the idea is that for each row, we are not going to build the BSTs independently. What we are going to do, given an n-vertext subgraph of our product, we are going to start in row one with a perfectly balanced VST containing. Balanced BST containing the vertices of row one that we use. Then, when we move on to the next row, we are going just to update that BST a bit. And so the BST for the next row will be based on the previous BST up to some modifications. So if you think of the copy of C log n in row two compared to the copy of C log n in row one, there are some vertices that you keep in the corresponding copy. There are some vertices that appear. There are some vertices that appear in row two that were not in row one, and there are some vertices that disappear that were used in row one and are no longer used in row two. So, in terms of operations on the BST, you have some insertions to do in your BST, and you also have some deletions to do in your BST. So, we are going to do these insertions and deletions. And we are going to go in this way up to row M. Right, so then the BST in row I plus one will be based. The BST in row i plus one will be based on BST in row i, but you do the necessary insertions and deletions. But if you only do that, then you lose a control on the height of your BST. And then in terms of number of bits, this will be way too much. And we are not going to fit into the setup of our universal graph. So we need to do some rebalancing in each step. So we are going to do insertions, deletions, and rebalancing. And at this step, well, you know. And at this step, well, you know, this is like a classical setup from data structures, right? Operations on DSTs where you do insertions, deletions, and rebalancing. Lots of data structures that do that. But it turned out that none of the existing data structures fit the bill. Like none of the existing ones could do what we really needed in this proof. And then at this step, Pats came up with a fantastic new data structure that. A fantastic new data structure that he called a bulb tree sequence. And that does exactly what we need. So at each step, the height will be almost optimal. So the BST will be almost perfectly balanced. It will handle insertions, deletions. And when we do the rebalancing, every node in a BST that survives can only move to a bounded, a very small number of places. And the fact that it can only move to a few... And the fact that it can only move to a few places after you rebalance means that when you put the edges in the universal graph, you only have to anticipate a few number of moves. And this will translate to a few number of edges in between two consecutive moves. Okay, I'm being very vague, but that's how somehow the idea of how we get a near linear boundary for edges. It's really by using this new data structure. New data structure that we use here. Okay, so let me not say more about this part. But that's really the idea of how we use the product structure. So this works for any classes of graphs that has a product structure. So for penal graphs, for graphs on a fixed surface, drawn on a fixed surface, you have a linear bound. For key penal graphs, you have a product structure. This should be the topic. You have a product structure. This will be the topic of one of the talks in this week. So you get a near-linear bond here as well when k is a constant. Yeah, and that's essentially it for universal graphs. Now with the three, four minutes that I have left, let me say a few words about a related problem, the problem of induced, of building induced universal graphs. Of building induced universal graphs. So, there we want to realize the set of graphs that we care about not as subgraphs but as induced subgraphs of the graph that we are building. And there the problem is no longer to minimize the number of edges, but the number of vertices. For planar graphs, that's a problem that was studied a lot. Building universal induced universal graphs with few vertices, especially in theoretical. In theoretical computer science, there have been a number of bounds over the years, and for a while it was talked at a quadratic bound. So there was a construction of a Universal graph with roughly n-squared vertices. And that was using the fact that in a planar graph, you can partition the edges into two bounded tribute. So by the way, this problem is also known as adjacent labeling scheme. Adjacency labeling scheme, this is the same problem. The only difference is that in adjacency labeling scheme, you actually count the number of bits you use in the label. But so you are going to take a lock, right? So a quadratic bound translates to a two login bound on the number of bits, but it's the same problem. And then recently, Bonami, Gaboal, and Mihau Pilipschu, they use the product structure theorem to get a summary. To get a sub-quadratic bound for planar graphs, for end-dotex planar graphs, they got an n to the four toes in the product structure theorem. And what we did with Vida, Luis, Finland, Piott, and Pat, we got a near linear bound. And again, so the construction is different from the one I tried to sketch just before, but the main engine of the proof, this new data structure is the same. This new data structure is the same. So these bulk tree sequences are used in a very similar way in that construction. It's just that the way we define the vertices and the edges of the universal graph is a bit different. So this works for any product structure. And so it works whenever you have a class of graphs with a product structure. And so you could have some. So you could have, okay, so you have these two problems, right? The first problem I described where you want sub-graph universality and you want to minimize the number of edges. The second one I quickly mentioned where you want induced universality and you want to minimize the number of vertices. And then you could wonder, well, okay, these two problems are different, but can't you just solve both of them at the same time? And the problem with the construction that I just mentioned here is I just mentioned here is that this construction has few multices and nearly no bound, but it has a lot of edges. It has quadratically many edges. So it doesn't do the job for the first problem. And the first problem only realize your n-vertext tenor graphs as subgraphs, not as induced subgraphs. So it doesn't do the job for the second problem. But it turns out that there is a way to combine the ideas of both constructions into one construction, which is much more complicated, but you can have actually But you can have actually induced universal growth with a minimum number of vertices and nearly minimum number of edges whenever you have a strong product. So there is actually one construction that solves both of them, but this construction is more complicated. Instead of ones bigger, but it exists. Okay, so let me conclude now with some open questions. Some of these questions were already mentioned during the program. During the problem session yesterday. So, as I mentioned at the beginning of this talk, if you forbid the graph as a minor, fixed graph as a minor, you don't necessarily have a product structure, but you do have square root n separators if you fix your minor. So, the best bound we know on the number of edges for subgraph universality is n to the three half. Most likely there is a near linear bound, but we don't know how to prove it. But we don't know how to prove it. And in particular, if you try to use the Robertson-Seymour structure theorem, Roth structure theorem, we don't know how to handle fixums. That's really annoying. For planar graphs, well, we have a nearly upper bound, but from below, we only have an n-log n lower bound coming from trees. For all we know, this could be the real truth. So it would be nice to know what's the exact asymptotic. For induced silos and graphs, we have similar open problems. So if you for me, the fixed graph. Thank you. For me, the flick graph H as a nine or the best bound on the number of vertices in our induced unbelievable graph is quadratic. We don't know how to get better than quadratic, and again, sums is a difficulty. And there is an entry on quotor discussing that right now. And for planar graphs, well, we have a near linear upper bound, but for the lower bound, we don't even have an n-log n lower bound. So it could even be that the truth is bigger of n. And actually, for trees, And actually, for trees, so that's different from the first form. For trees, this is the truth. There is a big of n construction for induced inversal graphs for n-vertex trees. So that's another direction for research. All right, thank you a lot for your attention.