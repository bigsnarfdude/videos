Okay, so thank you all for coming, guys. It's a pleasure for me to introduce Emina. Emina is speaking about multiple concurrent local data access with codes. Emina, thank you very much. Whenever you want to start. Thank you. And thank you for inviting me. I am very happy to be here and I want a lot. And the format is really nice. And the format is really nice with the review talks and tutorials. And this talk, actually, since it's a fairly new material, it also has this kind of a review or a tutorial component. And the figure you see here is meant to say something about the talk, and that is you've all heard about locally recoverable codes or codes for storage. So this year, though, So this year doors are doors to places which contain some data, let's say, but not all users can get into there simultaneously. So a few of them can get at the same time, maybe five or so, but the rest of them have to queue. And if you don't design your system properly, like with widen up door, then these queues can get out. Then the skews can get out of hand, can become very long. So, this is sort of the connection with the talk. And I've been working on these problems sporadically for a few years now and have many collaborators, and I'll mention them as I give a talk. But people who are the recent collaborators are also here: Janeira, and Altan and Alberto. And if you have any questions, And if you have any questions and they happen to be together with you in the Getter Town, then you can ask them. There is also a paper. It has been published actually, but there is an archival lecture. All right, so let me see if I can advance. So the codes here are systematic and these audiences tend to be large. From what I scanned, I don't probably need this slide, but Probably need this slide, but here it is. For us, codes are systematic and they're going to be defined by a generator matrix. And the matrix actually plays a special role. And one of the running examples that we are going to have throughout this talk is the generator matrix for the simplex code. And these are all strings of line 3. So this is a 7.3 code. And I wrote Code and I wrote the standard basis first, but it includes all strings. And so it encodes data into ABC, into ABC, and then A plus B, B plus C, A plus C, and A plus B plus C, which is all possible X source. Now, recovery sets, again, something you've heard about before, are defined for a basis vector in this. A basis vector in this talk because this is our object that we want to recover. And a minimal set is a recovery set for A is the one in which span A belongs. And if you remove any other vector from R, then A is not in the span. So we need this minimality. Minimality. And we are going to use the standard notation for the size of R. So here they are for our simplex code. We have this isiomatic code and we can also recover A from these three groups. There are more groups. There are more ways to recover A, but these are disjoint and they're the smallest. And actually, we don't even need the larger ones for what we want to do in this particular case only. In this particular case, only so locally repairable codes with availability are defined as codes which contain TTIS, they have parameters R and T. They have TTIS joint repair groups for each data symbol, and each group has at most R symbols. So our 7.3 code is 2.3 availability code. So 2, each group has at most 2. Advanced two symbols, and three is how many repair groups you have beyond the systematic. And this is a healthy research field. We already heard some talks about it, three, I believe. And there is some penalty to paying the minimum distance. And so that's one of the parameters you may want to optimize. Optimize. And there are some other desirable things or some other parameters that you would like to optimize. So various classes of these codes have been constructed by using different techniques. The problem I'm going to talk about is not a generalization of these codes, at least it's not how it started, but at some point we realized that it can be looked at that way. And it may be easier for the community if they are presented that way. So that's why I'm talking about this. Way. So that's why I'm talking about this. Another group of codes, which is related to what I'm going to talk about, are batch codes, and it's a large class, but what we call primitive multiset batch codes are those where any size L multiset of data symbols for any such multiset, there are L corresponding disjoint recovery sets. So you can recover a multiset. Recover a multi-set simultaneously. So here my multi-set is A, B, B, B. So this is multiset of size 4. And I can recover it from this group, A from A, B from its systematic node, and then from these two other recovery groups. And I don't need to touch A plus B. And one can show that the simplex code is a batch code of size. Of size where the amount is this parameter L is for. Now, different letters are used regionally for parameters of these codes, but in order not to confuse them with usual coding theoretic parameters, I will use L. L is not prime here or anything like that. Now, there are various generalizations of these batch codes, which are restoring multiples in a per server, allowing limited recovery set overlaps, etc. Recovery set overlaps, etc. And the interesting thing, and they are connected, as you can see with the locally recoverable codes, but they were actually defined for different, they were motivated by different applications and defined by different groups of people. LRCs were defined for repair, and that's why they have even this repair in their name for recovery from erasures. Recovery from erasures. And batch codes are motivated by load balancing. And the original paper may even have load balancing in its title, or if not, then it's mentioned a lot throughout the paper. And here, what I'm going to talk about is yet another application which started as something different, different application, but then we again found a connection with these two. And people who know about LRCs may be able to. Is may be able to help us out here because I and my collaborators don't know as much. So, what is the system that we are looking into is a system where simultaneous download of multiple symbols from non-necessarily disjoint recovery sets is what we are looking for. So, we have Nodes providing service to multiple. Nodes providing service to multiple concurrent users. For example, it can be cloud edge nodes providing streaming, download, computing. And we distinguish, and that is what is different between this work and the work on coding only, between two functional components at each node. One is for data storage and the other is for service request processing. So for storage model is So for storage model is exactly what I said. There are k equal size data objects. I'm just now talking about it more formally. Are stored on n nodes. Data objects are represented as elements of some field and coded objects are linear combinations of the data objects and the matrix G specifies these combinations and it's important for us. And each server stores only a single object for this talk. Single object for this talk. And data objects can be recovered from multiple sets of coded objects. And nothing new here, it's exactly, let's say, an LRC code, except that we will consider other codes as well. So that's storage. But now remember those doors and people trying to enter at the same time. So servers in use don't Are not designed to serve only one user. They serve multiple users. And even if they serve only one user at a time, users can queue. And as long as these queues are not infinite, we are in business. So we don't have these recover from an erasure type of a thing. We have dynamics that is this. That is decided by the server capacity. And the server capacity can be measured in bandwidth, so I can pack new users within some bandwidth W. Or it can be measured by the service rate. If I have a queuing system where I serve one user at a time, they can queue, but if my service rate is not sufficient, my queues are going to get very long and therefore I cannot serve rates at a high. Of rates at arrivals that is higher than this mu. So on the left-hand side, I cannot serve simultaneously more than mu users. On the right-hand side, I cannot serve more than mu rate of arrival and hope that my system stays stable. So theorists would call this stability region. Mathematically, they are identical, as we will see. And so in And so in queuing model, requests arrive at rate lambda i, and in bandwidth, the number of requests for object i is lambda i. And how many requests there are depends on other things rather than on our of the capacity we have to serve. And therefore, we want to see how many of such requests we can serve simultaneously. And so with these, So, with this bandwidth and ability to serve multiple users at a time, let's see how these recovery sets are different, how these codes that are locally recoverable codes or LRC codes or LRC with availability behave in service. So, you can ask yourself, what are the simultaneous recovery sets in this code, this MDS code? And that's our second running example. That's our second running example. And there are two. So, if you want to recover A, you can get it from A and then any two out of these three. And I have drawn here B and A plus B, but I can pick any two out of the remaining three. So that is what an LRC would say approach about this particular MDS code. Now, if I look at the service, right, ability to serve Right, ability to serve simultaneous users, then I have four simultaneous recovery sets. Actually, any subsets of the generator matrix that would describe this, of the columns of the matrix, in which span A lies. And that would be A, B and A plus B, B and A minus B and A plus B, A minus B. And I can actually, if I have here, I can put six users per. Can put six users per node. So I can put six into A and then split the available slots between different recovery groups for the rest of the nodes. And this is actually the best I can do. If I put together this service and storage, it looks something like this. Now, very often, people, at least in this community, will probably see. At least in this community, we're probably easier to relate to bandwidth than to queues, but queues are here easier to draw. So if I have a request rate, a Lambda or say Lambda A users arriving to my system and asking for A, I can allocate these requests so that I can split arrivals or I can split users so that some of them go to the A node, some of them to B and A plus B. These are L. And A plus B, these are L A2 users. This is the second group, and then there is third and the fourth group. And this vector, lambda A, lambda A2, Lambda A3, Lambda A4, I call the request allocation for lambda A. And now I can formulate the problem is actually asking which request vectors lambda A, lambda B, lambda C can be served by this system. Or formally, and for a general K, which set of service rate region represents a set of vectors that can be served by the system. And lambda i is the request rate for object i. Then we have this allocation lambda ij, I will send this to the recovery set j, there are possibility IH sets. I age sets. And we know that we can serve the request vector lambda one to lambda k if there is a location. This is the second condition that gives me when I sum over all recovery sets, the Lambda I users that I want to serve. And this first is just says you cannot send anything to the servers that exceeds their capacity. And this requires. Um, and this request allocation is what we would like to find. Um, we don't always have to find uh to say something about the service rate region. And actually, different allocations may give me the same points, may serve the same vector. And then, if we require this lambda ij to be either zero or mu, or we will later just use zero and one, then we have something that we call integral. Something that we call integral service rates. And when we work with that, then we can make comparisons with the patch codes, not necessarily with LRC always. So in our example, ABA plus B and A minus B, the region of positive lambda A's and B's that are below the red curve is what I consider. If I had four nodes and I just replicated AA and BB, I would be. A and B B, I would be able to serve what is in this square. So I've given up this when both have high demands in order to handle some SKUs. So in that sense, coding is better than replication. Of course, not always, we'll talk about that more. And if each of these is mu is equal to six is the node service capacity, then Then I can serve here 12 A users, for example. This is this point here: 12 A users and 6B users, or I can serve 15 A users and 0B. And how I do that is given by this allocation. So, again, a slide of comparison with LRC. Slide of comparison with the LRC codes is that if you treated this as an LRC but still asked the service question, then your region would be below this innermost triangle line, I mean, and we call that LRC simplex, which generalizes for any K. The one inside here we call material. One inside here we call maximum achievable simplex, and then this one we called maximal symmetric simplex. It doesn't have to be, it doesn't, not all points in it are achievable, but it represents a bound on the sum of the rates. So it basically tells us how many users can use the simultaneously. And for some codes, these bouts are closer to each other. Closer to each other, and for simplex codes, they all coincide. So, here is a recent bound on the service rate region, which is actually sufficient to specify the entire region for simplex codes and for some MDS codes. And I'll tell you which ones a little bit later. So, this is our So this is our this is again this code here. This is its generator matrix and this is how the bound is is done and this is the joint work with Janira and Alberto and is actually okay I'll talk about that later so it's interesting here because it uses some parameters of the code whereas previously we had some of these results but Had some of these results, but we did not use much of a coding theory, just general kind of principles of optimization. So, this is in two dimensions when case two. The bound is general, but I just drew this. In general, we are going to be dealing with polytops. And some that we found, it seems, even have names, although some kind of scary names which look like the problem. Look like the problem is hard. But I mean, it's not that the name is tough, it's more that such names appear, then we have problems. But here is something super simple, and that is if I have three, if I want to store three objects, A, B, C, and if I add one more node, what can I do? If I store C on it, it does not. If I store C on it, it does not do anything for A and B, but in the C direction, I get more capacity. If I put B plus C, it does nothing for A, A stays the same, but it helps B and C. So it's good for the situations where B and C are kind of both can get popular, but not simultaneously. And then this is treating equally all three. So there are different shapes, and these shapes depend on codes. And these shapes depend on codes. So there is this geometry that is associated with this that we would like to understand better. And so there are many kind of questions that are of interest, and they range from algebraic, geometric, combinatorial, and even in probability, because actually they started as a problem in queuing theory. And we can also address them through different techniques. So I'm going to tell you the first one. So, I'm going to tell you the first one, which I am kind of the most comfortable with. And each one of us that work together has his favorite. So, here is a combinatorics. And I'm going to define for an LRC code something I call the recovery graph. And you've seen graphs for LRCs, but not this one. So, I'm going to talk about the example. And here at the top of this slide are formal definitions. Formal definition. So let me just first go over the example. So if I start with my matrix G, then to each colon, I am going to associate a node. So there is a node in this graph for each column. And if this is a binary one, then this is node one. If this is a binary two, this is node two. If this is a binary four, this is node four. And in this simplex code, I have all seven. I have all seven numbers, right? That are representable by three bits. And I'm going to connect two nodes if when I XOR the corresponding columns, I get some base vector. And for one and two, one and two and three, it's A, it's the first one. So two and three give me the first one. And so. The first one, and so on. So, this is why I call it a recovery graph. So, the nodes again are columns of G, and the edges are between two nodes, which when X are together, give me one of the systematic symbols or data objects. Now, you also see some special nodes that are given by a zero, and that's actually counted for in the Actually, counted for in the definition, an additional node for each systematic column. And they don't correspond to anything in the matrix. They just signify that I can recover B by reading only from node two. So that is how this graph is defined. And some kind of combinatorial optimization problems on these graphs. Optimization problems on these graphs will give me some of the answers I'm looking for in the service question. And next piece, I have drawn the final plane, which is the final geometry determined by these columns, right, these points here, vectors. And the hyperplane, this one in the red, the line, is drawn in red. Drawn in red because it's actually special if you look, these particular three points are special if you look at this graph, and they're special in the sense that they correspond to an independent set of this graph, an independent set paranoids between them. And that will come up again. But I'd like to already point that there will be some interplay between combinatorics of these graphs and the geometry. Of these graphs and the geometry. Okay, so we want to use some notions in graph theory. And fractional matching of a graph, and we are interested in this recovery graph, it assigns non-negative weights to its edges so that at each node the sum of weights does not exceed one. And if you take these weights to be either zero or one, that is something called integral matching. It's actually Something called integral matching, it's actually just called matching. Because when you remove those edges with a zero, you have certain properties, right? So how does it matter? Well, if I define, if I look at some matching on this graph, and then for each, let me just look at this graph, look at the matching of this graph. So I have assigned base to this. Assigned weights to these edges, and then I look at everything, all weights that on all edges that are labeled by A. I will call that lambda A X. And the collection of these for all X is something that I claim, so that the vector of these. Of these lambdas in any matching is actually something that I can serve when my capacity mu is one. Because every node in this graph, all weights have to sum to one, and that's the capacity of the node. So that's how I treat the capacity. Okay, so now how is this claim, how is this equivalence between the matching on this graph? Between the matching on this graph and the service rate region, helpful. So, I'm going to tell you shortly, but first, let's look at some examples so that you understand what I just said. So, here is a recovery graph for a simplex. This is, it's bipartite. It's the same thing as this graph, right? The same thing as here, just written a little bit differently. So, all I've written on this side corresponds to weights, odd weights of the Odd weights of the vectors in G. And then I added these zeros, and these are these, this is this also circle in the final plane on the other side. So the only way that I can recover something is when I add something of different parity together, right? I cannot add two things, X or two vectors with the same parity and get a basis vector. So the edges only go from here. So, the edges only go from here to here, from left to right. They're not directed, but connect left and right. And so, a fractional matching, which is given here, so at each node I have a sum one, will actually give me service rate vector one, three, and zero. See, there is no C in this vector. When I add all that's on B's, I get three. When I add all that's on B, All that's on A's, all red ones, I get one. So this is the vector. But this is also a batch code because I can serve one A and three B's with an integral matching. So this actually gives me a new matching problem where I can emphasize this biperty, because for biperty graphs, we can tell a lot about integral versus fractional matching, but not in this case. But not in this case. So there is a new matching problem which says the following. If I have now this graph or any recovery graph, but even just this simplex graph, if lambda A is some on A edges, lambda B is some on B edges and lambda C on C edges, it's a weight. And if this is smaller than four, if lambda A, Lambda B, and Lambda C are integers, is there always an integral matching? Integral matching that can achieve that. In other words, are these integral points in the service rate region something that corresponds to batch codes? So these are examples. Now, what can we say? If we consider a system using an NK code with a generator matrix G and gamma G is its And gamma g is its recovery graph. Then the sum of rates in any request, lambda 1 to lambda k that can be served by the system, cannot exceed the number of vertices in a vertex cover of gamma g. And a vertex cover of g is set of some subset of vertices of gamma g, so that each edge is incident to at least one of these vertices in. In the cover. And that follows straight from a combinatorial optimization graph, which says that a maximum, first our result, it says that maximum of this lambda i is the functional matching number of g. A matching number is just the sum. A maximum is the, yeah. And does the, does it smaller than the cardinality of the vertex coverage? So that's theorem. The vertical scover. So that's theorem in combinatorics. And that was particularly useful in characterizing capacity of the binary simplex codes, because we can say a lot about their graphs, of the structure of the graphs. So, and that's also, you know, final geometry you are familiar with. So these are all strings of length k. These are all strings of length k and gamma k is bipartite again because the only edges exist when you XOR on these what's on the nodes of an edge you have to get basis vector. So you can only connect edges that have different parity. Those that say the same parity are not connected and therefore it's bipartite. And then you can say something about And then you can say something about the degree because you have now all possible strings of length k. So any one of them can be used to recover something and therefore each edge, each node has a degree k. And there are total k minus one vertices of gamma k that correspond to the output columns, and that's actually the minimum vertex cover. And you can use that to also show that you don't need That to also show that you don't need larger recovery groups, that this minima of two and one are sufficient. And it's convenient here that recovery sets are of size two, but if we had higher recovery sets, as we do, of course, in some codes, generalization of these results to hypergraphs is straightforward. So, with this structure, with this lemma, it's With this lemma, it's easy to prove that the region of a simplex code is actually simplex, but in Rk, because this lambdas are real numbers, and they have to sum to the k minus 1. So the polytop is a simplex. And achievability is just, we will just slice, we will just assign a fractional matching. A fractional matching if we want to, if we want to pack in, if we want to serve lambda one to lambda k that Hussam is smaller than k minus one, we can always do that by assigning the weight lambda i over 2 to the k minus 1 to each edge this labeled by i. This is like slicing the capacity of each node and saying to object, you will serve i people with this much. I people with this much of your capacity. And so that's achievability, and the converse is from the vertex cover. And this result actually for integral service region, it took a paper to show on by Yugal Casuto and collaborators. And collaborators on switch codes. So, asking these questions whether it's good to whether integral points in this region are also achievable through integral allocations would help us to, in an easier way, Derive some results that are combinatorially hard. There is another thing that is interesting here in connection with this kind of fractional and versus integral matching, and that is connected with something called asynchronous batch codes. And it came from Vitaly Skacek and his collaborators. I heard it from Vitaly at Oberwalfach. Vitaly at Oberwalfkach. It was one of our last coding in-person meetings of this type in 2019. When he was saying, okay, you are serving these users, but can one of them leave and if one of them leaves, can someone else take its place? And for simplex code, for which you know that you can use servani multi-set of four, if you want to have this property in the paper by this guy. Uh, in the paper by these guys, they showed that uh no, uh, you will have to start to be happy with serving only two at a time if you want to have these dynamics that with one leave, anyone else can come. However, that's not the case if you allow this fractional service, which is not fractional service, it's just the finite bandwidth, bandwidth of a server bigger than the bandwidth of a user or. Bigger than the bandwidth of a user or server as allowing queues, right? Then you can do that, right? So you can also ask what is the asynchronous service rate region? And I suspect for that, if you want to do this approach, then it might be hard. You would probably have to know the matching polytop, etc. But it's worth looking into for practical and for academic reasons. So, right. So, here for this asynchronous, the main question is: if some users leave the system, can others use the free resources without you having to rewire everyone, you know, disconnect and reconnect and send them to other places, etc. Because there is a cost with that. So, that was combinatorics about finding service rate region. And now, let's look a little bit at geometry. So, for geometry, For geometry, we are going again to start with our matrix, but now these columns are going to be points are going to be points in some finite geometry, right? And for this particular example, we have the final plane. And this, I actually never mentioned that I don't have to have All different or columns, I can also repeat some of them. So, this set is of points that correspond to these vectors, to the columns, is a multi-set, and we are going to call it a ground set on purpose, right? To indicate there may be some connection with metrics. Okay, so this is a this. So, this is a geometry here. And I just want you to take a look at this line, this hyperplane actually. It does not contain any standard basis vectors and it's a unique line among these seven. And so, why am I looking into that? Because there is a bound that says that the sum of Bound that says that the sum of the rates that I can serve by the system is equal to the cardinality of the set, the ground set minus the points in planes which don't contain any standard based vectors. So it's here I have a graph. So here I have seven points. If I remove this three, I get a bound of four, which is exactly, which is also achievable for the simple. Also achievable, this Vorta Simplex code. And kind of easy way to see it, or since I'm not proving this here, is that for any point in this hyperplane, you're going to need some other points. So, in order to make up a recovery group. Up a recovery group. So the points in this hyperplane by themselves cannot repair anything. So they have to have at least one friend over there to join for recovery of anything. And so, remember, we had this type of a bound that the sum of lambdas is smaller than something before as bound. Is bound on the maximum of the matching number through the vertex cover, but this turns out to be actually the same bound because those points, as I said, they cannot repair anything by themselves, therefore they're not connected. And therefore, they wouldn't be connected in this graph. And since they're not connected, they form an independent set. And that means that their complement in the ground set is the vertex cover. Is the vertex cover, which is exactly what we had in the combinatorial approach. Except that we had, you know, I was looking at the combinatorial, and one of my students was looking more into geometric, and it took us some time to realize it's the same thing. So how far does the similarity go, you may ask? Is there an encompassing view maybe based on metrics? And here are some other results. Here are some other results which are in this paper to just show you that we only scratched the surface. So we only found, there are some explanations in some other papers, but it's mentioned here. We only found service capacity for simplex codes and then some special cases of MDS and read more. And this one is actually something that we were doing. These are techniques, combinatorial geometric. Techniques, combinatorial geometric, which you're doing by water filling, the information theorist will know what I'm talking about. It's kind of a greedy algorithm, but it can be actually much in a much nicer way shown by this dual coding bound that Janira and Alberto derived for our ICIT paper. Okay, so I told you so far just I have a code. What can I start? But what about code? Can I serve? But what about co-design? It's actually what we like usually more. And there we really have very little. And it's completely open. I'll just tell you a little bit what we have. So suppose that you want to, someone gives you the region. This is what I want to search. This is my situation, right? Users are arriving with rate lambda A, A people and B people with rate lambda B. And I know that lambda A never exceeds or it's very unlikely to exceeds. Is very unlikely to exceed alpha. Lambda B is very unlikely to exceed beta. What about, and their sum is not going to be higher than gamma because there are only that many users in this city, right? Or at this rush hour, if it's edge nodes or something like that. And so it's a kind of a natural constraint, this kind of a trapezoid or whatever looking polytop. Polytop. And so you may want to ask how many nodes I need to cover this region. Minimum number. That's why it's minimal storage. But I may also want to say I don't want to do anything complex. That's what actually cooperating also with systems people on this. There is a group of Kali Adgara detectmion. Kaliadkara, the technion. And they ask, I only want to extort things. I don't want to do anything, only two at a time. So you may ask something like this. You can only use one, zero, zero, one, and one, one as points. And you can ask how many of these, how many of these, and how many. So how many A's, how many B's, and how many XORs. And it turns out that for that, that we know how to find. And And let's see, I don't know if I stated the result here. It seems I don't have that slide, but anyway, we can express this minimum number in terms of alpha, beta, and gamma. So I think I'm missing a slide, and that's something that we did with, I don't know if this particular example, but a little bit more general with Alex. With Alex Sprinson, he might be here in the audience, and his student, Nadia Kazemi, and also Sasha Kortz. So, okay, so it doesn't seem I have that slide, but this is how it looks when I have alpha and beta always four and gamma changing. So, if they're all four, then I have this kind of a simplex. I need A. kind of a simplex I need a a b b a plus b a plus b and and if a gamma is actually alpha is changing but the sum stays the same and beta stays the same if alpha draw drops from four to three I can remove one of the coding nodes which is interesting that's the best thing to do because I already said Because I already said that the coding is good for covering these SKUs, these kind of points that are on one side or the other, and so on. So this is, I want to find the minimum number of nodes, and also at some you will notice that, for example, here there are five nodes and at the bottom there are five nodes, but at the bottom I don't need coding and that's a better option for a system. System. So now, what about minimizing someone gives you the number of servers and tells you what can you do with this? How much can you cover? I really like this picture. It was done by Sarah Anderson and Anne Johnston and Gretchen Matthews and Carolyn Meyer at ISERM a few years ago. And before they did this, we had thought that according to Had thought that coding can only improve in these corners in the SKUs. But that's not the case. So if you have just replication, four A's and four B's, you have here, four A's and four B's is this square. And now let's call something dramatic and let's put this here, a rich alumni, this kind of points on the projected line here. What you get, since you for anything to recover, you need to access two, your service rate drops. So you lose. Rate drops. So you lose, you still have the same number of nodes, but you lose all of that. And then you can say to yourself, let's keep the same code, right? It's the same with reliability, but different generator matrix. It's systematic now. And it's a little bit better. And it may be all you need. Pass, it buys you something, something of the space that replication couldn't. But the reason I really But the reason I really like this picture is this last example is that this region not only increases, increases, shows that coding, but combined with replication, can give you a better performance in this kind of skewed regions, but overall region is less. Or, the region is larger than what you can get with a square. So, that's the point that sometimes replication together with coding is the best thing to do. And another, that if you look at the two middle ones, then this service region depends on the generator matrix, not on the code, which is important because you may want to keep the code for reliability purposes. There is another area which is performance analysis. It's probably not very interesting for this group, and it uses different techniques. But you can ask the following. Now, in a few slides ago, I had this kind of a region with sharp edges. And I asked covered this. But usually, these edges are not sharp. These arrival rates are random variables. And this here is a truncated Gaussian lambda A for the blue points. Lambda A for the blue points, I took A to B 44 and Lambda B 88. It's some kind of trying to mimic some kind of Zips law that B is twice as popular as A. And since it's Poisson rivals, it also has spices large variance. But it's just the back of the envelope calculations I did. And I took two coding schemes. One is Sorry, two systems: one with three disks and one with four. The one with three disks, mu is eight for each service bandwidth is eight. And you have ABB, three possible codes, AB and A plus B. And the system with four nodes has service capacity of each is six, so that the total service capacity of two is identical. And the codes are replication and the MDS code. And the MTS code. And when you look into the expected coverage, or what is the fraction of the demands, because these are probabilistic things, what is the probability that the demand will be covered, if you will. It's 0.73, let's say 0.74 for this AB, and then much better for AB and A plus B. Plus B. Because they kind of do have this real demands, this kind of a shape. For the one with the 4CF4, with the identical total service capacity, both replication and MDS code beat the system. In fact, MDS code is covering point 94, which is really good. The only problem is that you Problem is that you do this at the expense of downloading more data, right? And so, again, in this systems and performance analysis, that's one question that you want to ask. What is the cost of these strikes? So, now if I overwhelmed you with, well, it wasn't an overwhelming mathematics, but it's the fourth date of the conference, then let's just see what I would like you to remember. I would like you to remember. So, suppose you have, it's a problem of a city with two movies and three cinemas. So, there are two movies that are A and B movies and three cinemas and each one has 100 seats. But assume that city have 200 people each evening who want to see a movie. And that's and that's is that Is that sufficient, right? To make these to make everyone see what they want to see. And obviously, it is if you can just change your movies based on the tickets that you sell, right? So if there are 150 A's, you put A in two and B in one because there will be 50 B's. Will be 50 bits. But what if you don't know really how who wants to see what? You may make some guesses based on this popularity, but that popularity can be different next evening, and maybe it's not easy to transfer these movies. It's easy to transfer movies, of course, but some big content is not. So that's why I'm talking about this. So let's say movie A is Aladdin and movie B is Beauty and the Beast. So what do you put here? And the B. So, what do you put here? Well, maybe some kind of XR or A and B, but then you would have to maybe pay two tickets, right? Because to see A and B, you somehow can clone yourself and go to two cinemas and your two clones, your two proxies are somehow XORing this in your brain. I had to make an example with movies. But in any case, it costs twice as much. And then you can ask other questions. Questions. Can lambda A people CA and Lambda B people C B as long as Lambda A plus lambda B is smaller than 200? And if that is not the case, maybe how about 300? Or how does this service region looks like? And so I'm going to close with stating the problem again and telling you what the questions are, what the objectives are. So, K data. So, K data objects are stored redundantly across n nodes. Data objects are represented as elements of some finite field. Each server stores a linear combination of data objects, so recoded object of that same field. Requests for object I arrive to the system at the rate of lambda i in the queuing model, or there arrive lambda a people wanting object A. And each node. day and each node uh at each node the requests can be served at rate mu is equal one these are this normalized rate the mu that's you can see it as a bandwidth as well and some objectives are determine the set of rates lambda one to lambda k that can be supported by the system implementing some common redundancy scheme. Scheme. Question 2, Objective 2 is designed under the schemes in order to maximize or to shape the region that supported arrival rates under some limited resources. And I showed you, I've given you a specific number of notes, or I can say I want to give you, I'm asking you to minimize the number of notes. Nodes. And then you can also ask how to evaluate the performance, which is finding the stability region of this system for some given stochastic model of this lambdas. And that's all I have to say. Thank you. Thank you very much, Amina. Please, let's thank Amina. And we have time for one or two quick questions. In Oaxaca, if there are questions. Okay, so if the