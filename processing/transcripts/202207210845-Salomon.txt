Thank you, Sebastian. So hi everyone, my name is Ludovic for people who don't know me. And in this talk, I will present new ways of handling constraint in multiple T by bug automation. So this is a joint talk with Jean-Mark Sebastian Diabelle, who is present here, and Professor Georges Bijon from France. And I just want to thank, of course, the sponsor who gave me fellowship, Yvalo, particularly, for this nice work. The problem that we consider is the following. We want to minimize an objective function f composed of several components over a feasible set, which can be divided into two parts. First part, the set of inadexable constraints, which are constrained but cannot be evaluating during the optimization process. Typically, bound constraints imposed by the physical context belong to this type of categories. Second part, which is the set of flexible constraints, which are constraints that could be rating really. Are confirmed that could be written during the optimization process but must be satisfied when the algorithm stops. I will come back later on why I make this distinction. The relaxable constraints are delimited by the CG function, which, as for the objective functions, are supposed to be black boxes. So, as for every day, I will just define what is a black box in my context. So, a black box is just any process such that when providing an input, it returns one or several outputs, and we are working. Several outputs and the networking of a process are not analytically available. I learned in my earlf from the book of Charlotte. So, just black box is just a simulation software which can take a long time to run from sometimes several minutes to many hours. Well, in our case, we can suppose that it can fail. So, it gets sometimes while the software is not implemented to deal with certain combinations of inputs, and so it can just crash. Of course, you cannot make any assumption of the structure of problem. Function of the structure of the problem. So, you will know it is smooth, non-smooth, and most of the time it's noisy and non-convex. And the most important, you do not have access to derivatives and you cannot approximate them via finite differences. So, it is impossible in our context to use classical Rayson-based tech. As an example, as an illustration, consider the following example: the demolition of a solar problem, but the same problem that Sebastian Plantida raised today, but I need to talk a bit about that. Talk a bit about that. So, as a civil engineer, well, you do not want to build a solar panel solar. So, most of the time, you are an engineer, so you write physical regression, you write your model, and your model is parameterized by a lot of parameters. For example, the number of solar panels, which we call two sun rays, the dimensions of shutterware, which will just take all the sun rays, while the different commands of the multi-sol system, which will take the sun rays, convert it into it. Converts it into it. And finally, the different components of your laser system, which will tailor it, convert it to vapor from vapor to electricity. So all the ASIS system is quite complicated, 100 pages in the test of Matthew. All this system is just packaged into a huge simulation software. And the goal, what I want to do, just, okay, you give me a simulation software, and I want to find the optimal parameters which will first maximize. Which will first maximize the simulated production of energy by the solar pump and at the same time minimize the cost. And after that, I can give it to the engineer this type of optimized parameter and he can use them to build the solar plant system. That's the idea. Another difficulty with majority automation is that you need to compare solutions. As some people have presented before, I will not just inside take too much. Take too much. I will just not too much insist on the slide. So you have the two most important correlations of a dominant oscillation, and the one when they are not dominated, they are incomparable. It is also simpler to visualize this type relation in the obligatory space. So I just, as I will use this type of graph in figure in during all the talk, please do not hesitate to interrupt me if you do not understand it. Okay, so we are in the vibratory space. We want to minimize both of the chief. So we are looking for solutions. We are at Are looking for solutions we are on the left button, and I represent four different solutions in the feasible RT space, which is this kind of platform. And if we consider X1, we can divide the RT space into three different zones. First one, the dominant zone, which is great because we are looking for solutions which have better obligatory values than X1. And if you take a look, you can see that X4 dominates X1. Then the dominated zone, which is not really great because in this zone which is not really great because in this zone allocating allocated solution with worse values of f1 and worse value of f2 so in this case you can see that x1 dominates x2 and finally volatile zone which is very indifferent zone where you are looking for solutions which are indifferent according to x1 if we take a look at x3 we can see that x3 has a smaller f1 value which is great but unfortunately a higher f2 value than x1 and so both solutions And so both solutions, according to the definitions, are incomparable. Due to this incomparability relation, well, the set of optimal solutions of a given mutual automation problem is not a singleton, but most of it is not often a singleton, sorry, but most of the time it's composed of several solutions, what we call the parito set. And the image of a paratole set by the objective function is called the parato font. The goal when we design a mutuality backdoor automation problem is to find the Optimization problem is to find the best discrete representation of your parameter. Okay, so what we proposed in a previous work was the D Multimath algorithm, which has its name, which has its name indicates strongly inspired by the DMS and BMAS algorithms. So, sequentially to BMAD, it can handle more than two abilities, and add it is a specific dashboard, well, more constrained dashboard than DMS, and so it belongs to the DMS a lot. We can prove that. To the DMS model, we can prove that it converges to a set, it generates a sequence of set of points which converge to a set of locally paradox optimal points. Our experiment experiments are also shown that it is complicative according to other state-of-the-art results. So, as I mentioned before, it shares a lot of similarities with MS. First, it does not aggregate any other objective functions, so it works directly on the initial maturity automation problem. It is also a direct search method, so it is built around the problem search. And as for DMS, it adopts. And as for DMS, it adopts the concept of an iterate list, which are just the set of best feasible non-linear situations found at the beginning until the beginning of iteration care. At each iteration, the pull center is chosen among the elements of L tier. A slight difference with DMS is that we directly impose a restriction on the choice of a pull center, which according to the restraint by Lou, and we change a bit the success. So we say that there is. Abid the success, so we set the value success if we find a new feasible candidate which dominates the current incubator. So, problem when we design this algorithm, we say, okay, if we want to deal with constraint, we just reject all infeasible points, such as DMS. The problem with this approach is that sometimes you could view it will be interesting to view values constraint and just such that you can speed up a bit the method. Speed up a bit the method. Second problem, which is well, which in our process was a bit embarrassing, is that we need a feasible starting point, and sometimes some real engineering application problem will not have one. So we need a way to deal with that. If we take a look at the literature for the deterministic mutual automation community precise, there exists in mutual automation two types of methods. First one, scalarization approach. So you take your initial mutual Approach. So you take your initial multi-obility automation problem, you transform it into a succession of single objective formulations, and after that, all single obliterative formulations are solved by a dedicated single objective constraint solver, which are located on either right. Second type of approach, which was proposed, is the Pelletty, the Pelletty based line search approach, which was proposed by UZ and Hall, which are in this room, and which I think if you And which I think, if I do not make a mistake, it's our just generation of PLT-based approaches for single-operative automation. Okay, so we saw a gap, and so we wanted just to focus on filter-based and two-phase approach. So we just wanted to press this type of approach. For this reason, the new algorithm that we proposed was called the demulti-maths-Pebb√© algorithm for Pebb for progressive bio. So, as this name indicates, it is an extension of the MATS-PEBE algorithm for single objective automation to multi-role. For single retail automation to multi-reti automation, and we can also prove under mid assumption that, as for the FMO, we can prove that it converges to a set of locally pi two clapped optimal points, which is great. Okay, the mixed math PBA relies on two main ingredients. First one, as for the talk that Joseph presented on Tuesday, is the use of a constraint relation function, which is just a way of quantifying the infeasibility of a given solution and how it works. You just take all your XML constraints, put Just take all your axiom function, put it into a function which is equal to zero if your point is feasible, otherwise, it is strictly positive. Second main agent, the extension of the dominance ratio for cost optimization, which is directly taken from the one proposed by Charl in 2009. If both points are feasible, if we compare both two feasible solutions, in this case, it is equivalent to classical pi-to-domier spatial. Otherwise, it is just equivalent. Otherwise, it is just equivalent to you take your consideration function as an additional relative, put it into your initial mutual relative vector, and after that, you using this augmented objective vector, you just apply this the ply to the main operation, as you can see on this figure. Now that we have the main ingredient, I can detect a bit more the main characteristics of the D multi-math Pebby algorithms. So it is built around a problem search, such as Search such as for DMS with extended buyer approach. But we define two sets and not only one. First set, the set of feasible incubant solutions, which is equivalent to the iterate list. So the set of best feasible points found at the beginning of iteration K. Second set, the set of infeasible incubant solutions, which is a bit more technical, but are just the set of points with the best objective values, which are infeasible and which are below certain thresholds. Below certain threshold. The idea is that by exploring around this type of point, we could hope to find better feasible solutions which could really improve our algorithms with future potential iteration. Ask increases, the barrier threshold is reduced, which means that we just remove solution that do not give a quick improving of one of our two sets. And we say that there is success if we find conditions, we dominate one of the two framing figures. One of the two framing fluids. If I want to just give an expression of how it works, I will start by the feasible case. We start from the feasible solution, it's cap. On your right, you can see the BWC page, so same stuff. We want to see solutions that are in this corner. Then here is the frame and the match associated to this feasible solution. Okay, each iteration is divided into two steps. First one, the search, which is optional, and considered just in evaluation. Optional and consist just in evaluating a finite number of points on the mesh. As you can see, as one does the dominate this case, we continue. Then we move to a pool. The pool is just a local expression around the current incubator. And this pull cell, this pull point must belong to a subset of a mesh that we call the frame. Okay, so we start by P1, P1 is directly projected because we are in a stream by our context. Then P2, P2 does nominate each case to recontinue. P3, P3 is dominated by ECS. P3 P3 is dominated by EK2.2 and finally P4 P4 that dominates EK. So that's great. Our iteration is a success. At the end of the iteration, as for DMS, DMLTMAS collects all new feasible points and affects them a frame and a meshes parameter, which are superior to the frame and the meshes parameter of our current implement. Note that if our point still belongs to the ETR at least, in this case, we reduce the mesh and the frame associated and in potential future. And in potential future exploration iteration, we could hope to just explore more finally the decision space. So now for the invisible case. We start from an invisible solution. Here is the durity space with an additional objective, the constraint direction function. Then here is the frame, still the frame and the mesh associated to this invisible solution. We move directly to the pull step, and we are going to evaluate one by one. And we are going to evaluate it one by one. We start by this point, project it because it is above the threshold. Then, this point doesn't dominate if the current incubance will continue. This point also does not dominate if the current incubance will continue. And finally, the last point which dominates the current incubant in terms of hash evaluity. It is a success. So, at the annotation, the bio threshold decrease. We just regenerate the set of infeasible non-dominity solutions, and we will pick one of them as the next. We will pick one of them as the next current incumbent. We start for this new solution, we generate a set of points, we evaluate them, and note that we just find two new feasible solutions and two new infeasible solutions. At the next iteration, one of these two new feasible solutions will be chosen as a feasible film center. And we still keep a way to explore around an infeasible pool center. And as previously, Percentile and as previously, the bio threshold just decreases to radiator ratio, but not monotonically. For the one more interesting, here is the formula for the update of the hash gamma threshold. Seems a bit complicated, but the idea is simple. So if we do not, if we just do not find, if our iteration is not a success, but we still have a point which improves, well, which is the least influx, if we have still a point which is the least. If we have still a point which is the least infeasible possible, we just decrease the bio threshold. Otherwise, we decrease it by slowly. And we just need to just stop at the value of the infeasible film factor. Okay, I just need to give a quick summary of the main results of the conjugate analysis of the multimad. So we need to have main assumptions. First one is basic because, well, that's how we need, but makes Need that makes it possible for the algorithm to work. Second one, more technical, but at least make it possible to just extract a set, a sequence, a frame, and meshes parameter, which matches the. We need this also, we need to characterize what is a locally pipe optimal solution in a mutually relative non-smooth context. For that, we use Mutant of PyTo-Clark optimal solution, which is just the following. You take your locally optimal solution, and if you take a direction which belongs to the high-pattern gene cone, you cannot find Transform cone cannot find any direction which is a distant direction for all objective vectors. So now the main result: if we just consider feasible frame center, which positionally could not be, which in this case are generality by the algorithm, we can extract a sequence of points which converge to a localic type of current optimal points, which is great. Now for the infeasible case, if we just take a look at the sequence of infeasible frame center, we can describe a sub-sequence of points which converts to Of points which converts to optimal solution, but optimal solution according to the constraint relation function locally. Okay, and so that's the two main reasons. Okay, so now with experiments. We implemented this algorithm in Julia, best long-ride ever. To be sure that it is quite efficient, we use all kinds of tricks, but we just make it the most efficient possible. So, speculative search, the top one in term of Top one in tap in terms of mesh, the top one, in terms of full time, the most efficient, just to be sure that's working. Note that we just use also the opportunistic strategy, which means that as soon as we find as soon as we detect a success, we just stop the iteration, move to a breakfast. And this one is a bit more technical, but if you have a question, I will be glad to answer to it. Okay, we consider competitors: BIMAS, Paris and Bayer Probe, DFMU, Perxi-Bay approach, and NL2, which is And an L2, which is an infrastructure-based algorithm, but we need one. We consider other variants of the algorithm to be sure that it's not our implementation that is just better than the other one. So we consider the multimath TOB, meaning a two-phase approach with XMAYR, which is quite simple. If we do not have a finisable starting point, we just move to the first phase. So we try to decrease the concentration function. If we find a feasible solution, we stop the first phase, move to the second phase. Phase, move to the second phase, which is just the following weight. We take the feasible solution for another starting point and apply the demultimats with the extended R. Second one, the multimaths penalty, suggested by the author, by DFMO. So we just use the same, exactly the same penalty parameters. The idea is the following. You just take your rule acceptable, put them into probabilities, and you have a nice one-concrete problem, and you solve it using a demolitimage. You solve it using a demolition extend by approach. Okay, so we need to use, we start by data profile, so we need to use a certain set of points and we use the hyperbola. Now, if we start by comparing just a bit the three different variants of demultimats, we can see that curiously, to the best of our profile, it's not demultimats with positive variants, which is better, but demultimats with profile approach. So a bit better, but not too but not too much. And but But not too much. And these two algorithms, the multimaticity of A and D multimatially, are quite equivalent. If we increase a bit the tolerance collusion, which means that we just relax a bit the condition on which we consider that a problem is solved, you can see that this time the multimath speech is a bit better when for large budget evaluation, but not too much. But still, the three meters are still really, really close. Okay, so now we've compared just Okay, so now if compare, just to I know by the same behavior for the MIT mass TOB and I should reject for the MIT mass PLT, but normally should be the same. So if we compare all bearitive soldiers, we can see that this time the mitimate PB is the clear winner, following by DFMO, and Analogia2, which is evolutionary based method, is last one, which is quite nice. Okay, same thing when we increase the bibliotelar solution, the same. The same behavior can just appear. Okay, so we use a set of analytical problems. What we want to do, we want to see if it behaves well on real world. Yes, sorry, yes, I forgot this one. Multi-received solver. So when we consider the world set, this time the multi-mod is still better. And same when we increase a bit with the lower schedules. Okay, so we consider a real world problem, so solar eight and solar nine, which were which were. 8 and solar 9, which were planted by Sebastian, so I do not insist a bit more, a bit too much on it. Just know that they are extremely costly, so I cannot use data profiles, so I need to use something to see if they work well. So I use convergence profiles. Okay, convergence profiles for mutability optimation are the following. They just consider the evolution of the normalized hypervolume indicator according to the number function evolution. Just to keep it simpler, just the higher volume. To keep it simpler, just the higher the better, and it's bound in above by one. So, what you can see here is that the multimativity is the clear winner in this case on the solar eight problem, following by the multi-matsub, the multi mats per dimension, and all the other algorithms. If we take a look at the parental form approximation generated, we can see why. We can see that the multi-matri-b capture a part of the paratoff which is not captured by the other one. So, this part on the So this part on the on the left uh on the left uh on the top left, which explains why it is a bit better than the other alboisms. Now we test it on solar nile and this time, just to show you an example that doesn't work, this time um the scalars and magic metals are better. Note that in this case pilatibase uh approach to petri phase and um the multimads um the multi the multimads pre base still The multimatural remains the second one. Also, last thing that I want to point out: okay, in average, energy looks nice, but as you can see, there is a huge variability, so I should not recommend it as to solve this type of problem. If we take a look at the Pareto form generality, which is here, you can see that it's extremely flat. And so, when you have a scalar sense-based method, it will just go directly to this and just after that try into external. So, that's why they are Trying to external. So that's why they are better than other algorithms. For Penalty-based approach, well, I will say that I was not really fair. I just used the default parameters. So they were not really tuned for this type of problem. And that's why they are not really well working. So that's explained why the PILT-based approach fails. If we zoom a bit, so we can see it's still really flat, but it's just well. So you can see. Just one. So you can see that this time the MAD just captured a larger part of the Python font, which, in our context, for our type of funking, we consider that they are better. Finally, the last one, Steve production of chemical process, a free objective problem, it's quite cheap, but the fact is that it's failed really often. So that just is a really nice problem to see if our algorithms are quite robust or not. So if So, as you can see, this time Dimitsimas TB remains the clear winner, following by Dimitsimastio B and DFMO for the last one. Note also that this time energy is completely failed, and so that proves that dynamistic algorithms in state are really great algorithms, which is nice. As you can see, the Parato Fund general, we can see that Dimitri Mass Pay Bay, the Parato Font of Dimitri Mass Pay is a bit larger than the other one, which explains why, according to our critique, it is better than the other. Fritier, it is better than the other. Okay, as a conclusion, we propose two new extensions of the multimads algorithm: the multimads with profile approach and the multi-math with the plundy barrier approach. Okay, we generalize single or t approaches. Our experiments show that it seems that our algorithms are performing well according to other state-of-the-art algorithms. Another thing that was quite surprising for us is that at this time, a simple two-phase approach in This time, a simple two-phase approach in the mutual relative context is quite good and is equally extremely obvious. So, if you do not have time, you can just implement that normally to give great results. I thank you for your attention. Do you have any question?