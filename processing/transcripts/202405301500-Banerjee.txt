Thanks a lot, Jeremy. And yeah, it's a pleasure to be here and to meet all of you wonderful folks. So today I again feel free to interrupt me at any point of time. So my plan is to kind of tell you a little bit about my sort of ongoing research in sort of dynamic rank. Sort of ongoing research in sort of dynamic random networks and the role of centrality, especially this is kind of the key word I want you to focus on. And all of this is so most of the talk is going to be joint work with my colleagues Shankar Bhamidi and Zoe Huang. And there'll be another part of the talk where I'll talk about my joint work with Mariana. And all of them are from my colleagues at UNC Chapel Hill. Something is good start. Can create some click music of perfect. So, let's begin with a general kind of vague question. So, how do you model a dynamic network? So, a network that sort of evolves in time under the combined effect of age and popularity of the word disease, right? So, if you think about any sort of social network or citation network, so all of these networks are changing over time, but changing in a very inhomogeneous way, right? So, people who are more popular tend to gather friends at a faster rate. Tend to gather friends at a faster rate. And people who have been around for a longer time tend to become more popular because they have just longer periods of time to evolve. So if you look at this, this is an example of a citation network. And yeah, I can't tell the sort of words here, but this is kind of the rough geometry of a citation network, which has evolved over time, say for 20 years. And you see that in this network, so the color coding is for subjects. Color coding is for subjects or papers that are closely related to each other. So you can think of these as sort of communities, but you also see some sort of inhomogeneity in the geometry, right? So you can think of these as the hubs. So the bigger blobs are the more highly cited papers. And you see that those parts of the network are denser than the others. So in one snapshot, you see sort of regions of density and regions of sparsity. So that's one big difference. So, that's one big difference between sort of dynamic networks and static networks like the Erdogani configuration models, et cetera. So, in static networks, there is a lot of exchangeability between the vertices and a sort of sparsity is sort of a uniform sparsity over the whole graph. For dynamic networks, things are sort of varying in one single snapshot. So, the question is: how do you model such networks? Well, I mean, there are lots of ways to model them. Ways to model them. And before we even start to model them, we need to understand what we mean by popularity. So, how do you quantify popularity? So, if you had some centrality measure or some notion of popularity, which would quantify how popular or central the vertex is, and suppose that's a function from the vertex set to the non-negative reals, then you could sort of build the network by this mechanism. Network by this mechanism. So the mechanism is the network is growing in time. So at each time step, suppose at time n, the network is this g n. So how do you construct g n plus 1? Well, a new vertex comes in, v n plus 1. It attaches to an existing vertex v with probability proportional to the centrality score of v in the current network g n. And with different notions of popularity, you get different scores psi. Scores psi, and those will lead to different types of network evolution. So, what's the easiest notion of popularity? The number of friends, right? So, if you look at a social network, your number of friends, that kind of gives you a first-hand notion of how popular you are. So, if you take psi to be degree, you get the well-known preferential attachment model, where the probability of attachment is proportional to your current degree. And this has, again, this is. And this has, again, this is also called the Barabashi-Albert model. It has been explicit, very popular in the last decade or two. And the reason behind that is it can be rigorously analyzed and it exhibits the power law phenomenon and the small world behavior that are commonly observed in sort of more real-world networks. So the degree distribution is like a Pareto, and the sort of small world phenomenon means like if you take these two typical vertices, the distance between Vertices, the distance between them is sort of logarithmic in the network size. But if you think about this for a minute, there is no reason why degree should be the most natural notion of popularity. There could be other notions, right? So think about, suppose you want to write a paper and you want that paper to be influential, right, or popular. Well, you could write the paper and wait for 30 years and wait like for it to gain traction. Or what you could do. Or, what you could do is you could look at a very influential paper, look at an open problem in that paper, and try to solve it, right? Now, if you can manage to solve it, you will get popular by association, right? Because you are associating your work to something more popular, right? So popularity can be enhanced either by having more friends, but also by connecting to more popular people. So, it's sort of a recursive notion of popularity. And this is Notion of popularity. And this is sort of the basic intuition behind something called Google's page rank. So, Google's page rank is sort of what made Google what it is today. It was sort of an algorithm developed by Bryn and Pate, which gives you a notion of centrality that is used to rank web pages and refine your search every time you sort of search for the same thing. So, and this is a non-local measure. So, degree is a local measure, it just depends on your. Is a local measure, it just depends on your one-step neighborhood. Page rank, as we will see, is a more global centrality measure. So it depends on the whole network, but the effect of faraway vertices sort of diminishes in a certain sense. So let me just give you a little bit more description of what page rank is. So, page rank, so this is the simplest definition of Google's page rank. So, you look at a direct So you look at a directed graph, G is V, E, and you select a dampening factor, C. So what page rank is, is the stationary distribution of a mark of chain on the graph. What's that mark of chain? Well, at each step, you flip a coin, with chance C, you crawl. That is, you select an outgoing edge at random, uniformly at random, and jump to your neighboring vertex. Or with probability one minus C, you jump. Line is C, you jump. So you restart. You select a vertex uniformly at random from the whole network, and you just teleport there. So one can actually show that this process mixes really quickly on the graph. It's exponentially fast. And the stationary distribution is what is called the page rank. So it's a system of scores that satisfies this kind of equation. So the page rank of a vertex V is there's a constant plus C times. There's a constant plus C times, so the sum of the page ranks of its in neighbors with appropriate weights. So, this is just a rephrasing of the equation for the stationary distribution. This is like the sort of the sort of the whatever the for a harmonic function you have this equation. It's like similar. Now, you can actually look at this and see that if your graph is very large, suppose it has n vertices. n vertices the stationary distribution will be of order one over n at each vertex right so just to kind of make things scale free one looks at something called graph normalized page rank so you look at the stationary distribution and you blow up the scores by the graph size so this will give you a set of scores for each vertex which will not decay as the graph grows and this will also satisfy some equations so if you go back to that sort of harmonic equation Sort of harmonic equation and sort of unfold it, you can keep on like you can actually get a more explicit equation for the page rank. So, this is a weighted sum of the statistics of the graph around the vertex V. So, the page rank of a vertex V is the sum where L K of V is the number of vertices which lead to V in k steps. So, for example, L1 of V is the indegree of V. Is the indegree of V. L2 of V is the two-step indegree and so on. And for each LK, you're weighing that down by C to the power K. So as K grows, this thing decays exponentially. And this is what you get as a score. So you can all, yeah. When C is equal to one, so let's go back. So you never jump, you only crawl. Never jump, you only crawl. Well, there are some pathologies because if there are some dangling nodes, you just get stuck there. So it's not even clear that the strain is erodic under sort of more general, general graphs. But if things are sort of strongly connected, et cetera, you do converge to a stationary distribution. And that's actually, I mean, for undirected graphs, that's equal to the proportional to the degree of each vertex. For directed graphs, it's actually not a closed-form expression. So it can be something more complicated. Something more complicated. But it's good that you asked the question. So for undirected graphs and for C equal to 1, your stationary distribution of this walk is just equal to the normalized degree. Now, when C is not equal to 1, and for undirected or directed graphs, you get this page rank. So all of these, you can, so all these centrality scores, you can think of as the stationary distributions of some Markov chain on this graph. So any questions up to this point? So this is just when C is equal to 1, well, this formula makes sense for any finite graph. It will be, I mean, it will be what it is. You can just, so for, so, so, so this one, you can just, you can, okay, so this one will be zero. But you can look at sort of a normalized page bank by dividing by one minus c, and that will give you something meaningful. So, yeah, when C equals one, things get a little tricky, but again, for undirected graphs, we're good. That just gives you the degree. All right, so now if you think about the degree and the page rank, and if you think about sort of what's common between these two scores, you can think of them. So, what's the stationary distribution of a mark of chain? Well, you run the mark of chain, you look at the average number of times a state is visited, right, on the long time horizon. That's the stationary measure. The long time horizon. That's the stationary measure of that point. So, if you think about, say, a network, say for now, let's assume it's a tree network. Suppose this is your network, and suppose you focus on one vertex, V. So, suppose this is your vertex V. Then, what's the centrality of this vertex V? Well, you run a mark of change, suppose it starts from here. Suppose it starts from here. You look at how many times it's visiting V, right? You look at the average number of times it visits V, and if that average number of times is higher, centrality score of V is higher. So that's what's going on behind the scenes in both these centrality measures. So there is a hidden concept of reachability. So the Markov chain is sort of an exploration scheme on the graph, a randomized exploration scheme, and the centrality measure. And the centrality measure is a measure of reachability via the exploration scheme. So that's what's going on in both of these centrality measures. So that leads us to sort of this general sort of philosophy that popularity and reachability are sort of connected to each other. So you, a new vertex explores the network around the uniformly chosen vertex. So you pick a vertex uniformly at random and I prescribe. At random, and I prescribe an exploration mechanism. And you see how many times this exploration withits a given vertex, and that's a measure of its centrality. So, this motivates us to define a class of growing random networks which evolve via exploration. So, that's what this led us to define a new class of network model. And again, this is. Model and again, this is a very simplistic model from an applications perspective, but this is just to prove some theoretical results and try to see how we can extend it later. So, what's this model of exploration? So, the parameter of this model is a PMF, the probability mass function. So, what you do is you sort of simulate IID copies of Z from this PMF and assume they have finite expectations. So, how do you grow the network? Well, you start. How do you grow the network? Well, you start with two vertices and one edge from V1 to V0 directed from V1 to V1. Now, how do you grow the network? Well, suppose you have constructed the network Tn. To get to Tn plus 1, a new vertex enters the system at time n plus 1. It selects a vertex uniformly at random from Vn. And from there, note that things are directed now, right? That things are directed now, right? So if you think about this graph here, suppose this is your root, so call this the root phi. And suppose the new vertex selects this vertex here. So there is a unique path to the root, right? It's a tree, it's a directed tree, so there is a unique path leading to the root. So what you do is you explore along this path. So you traverse this path for a random amount of time, and that random time and that random number of steps is given by Zn plus one sample from the PMF so again so the the idea is you're trying to get to the most popular vertex the root but you for every sort of additional sort of like hop you make there is some cost involved so you don't want to go all the way to the root but you're kind of taking that path and going a random number of steps and attaching to the terminal vertices So that's the mechanism. So you select the vertex uniformly at random, you traverse towards the root for a random length of time, sample from P. And if this length of time is greater than the distance to the root, you just stop at the root, you attach to the root. So that's your network model. Exactly, exactly. But again, like you think about Z, so all we're assuming is Z has a power law. I mean, it could be, it has finite expectation, right? It could have heavy tails. So you could have, once in a while, these really large values of Z. And note that these networks are sort of logarithmic in diameter, right? So it's not clear that you will stop visiting the root after some point of time. In fact, it's not true. So you will keep. Time. In fact, it's not true. So you will keep visiting the route pretty frequently, but how many times depends on the PMF? Does that make sense? Sorry? Exactly. Very good question. So I'm not claiming that this is like, so this is the first step in the analysis, but this gives you some tools. Analysis, but this gives you some tools that you can actually use to study non-tree graphs. So, this was our first step in towards that direction. So, yeah, for all of this talk, I will assume that everything is a tree. Jeremy, you had a question? Everything is always exact for the tree. Exactly, exactly. So, in a way, this exploration is very simplistic, but you will see that even in this simplistic exploration, you see lots of phase transitions. So, even in this very simple, almost trivial model, you see. Simple, almost trivial model, you see some rich behavior. So once you get to known trees, the hope is you will see even more non-trivial behavior. And very good question. So these are connected. So I started with the technology sort of measure attachment. I'm giving you something different. Attachment, I'm giving you something different, but these are connected. So I'll reveal that in a couple of slides. So, yeah, so these actually lead you to sort of specific choices of the PMF, lead you to different centrality measures. And I will give you a few examples. So before I get there, just a pictorial description. So this is the T5, V6 enters the system, the samples are vertex uniformly at random. Suppose it's V4. Suppose V6 is 2, it goes up two steps, attaches to V1. So that's how this sort of So that's how this sort of this trend tree graph grows. And to answer Blaze's question, so what's the most trivial PMF you can think of? Well, there is no exploration. So P0 is one, right? In that case, you just get the random recursive tree, which is you pick a vertex at random attach. So there is nothing going on. What's the next simplest PMF? It's a Bernoulli. So P0 and P1 are positive. Everything else is zero. Are positive, everything else is equal. In that case, a sort of one-line calculation will tell you that if you rephrase the model, like it's exactly giving you preferential attachment model. So let's think about why that's true. Well, so let's see how can you attach to this vertex here, right? You either select here and don't explore, or you select one of these. You select one of these and go one step out. Right? So the probability of attachment to this vertex is the in degree plus some constant. So it gives you the professional detachment model. So these are sort of two very basic choices of the PMF. If you take the PMF to be a geometric with 1 minus C as a parameter, you get page 1-driven attachment. So, in fact, you can So, in fact, you can convince yourself that when a new vertex comes in, does this exploration, the probability of attachment to a given vertex is proportional to the current page rank of that vertex. So, you see that, like, in this exploration scheme, you can encode lots of different models by making proper choices of the PMF. So, that's kind of, and this model has a name. So, it's actually appeared multiple times in the CS literature. It's called the random surface. In the CS literature, it's called the random surfer model. So it's just like modeling sort of surfers on the web. And there is a SODA paper by Tebolu and Melsted who obtained sort of partial results about the expectation of the page rank and degree of fixed vertices in this network. Exactly, exactly. You can think of them as sort of a generalized version of page rank, where at each step, when you are flipping the coin, the coin can like the probability of success can change with the number of steps. So yeah, you can think of the general model as sort of a generalized page bank-driven model. So, again, what's our goal? Our goal is to rigorously analyze this model and try to model the model. This model and try to produce some theorems. And with proper choices of p, you can get results for each of these models by just plugging and playing in those theorems. Any other questions up to this point? I mean, is the model clear? What's the original model? So these are easier, but again, the goal is to kind of The goal is to kind of not just get confined in these models, like have more sort of a more non-parametric class of models, right? So, you want more sort of freedom in those parameters. So, that's why we decided to attend the general PMF case and see what we can get. So, yeah, you're right. So, for specific choices of the PMF, you might get more refined results. But the goal is to kind of give more general results based on that PMF. All right, so that's the sort of the construct. So that's the sort of the construction phase, and now we will try to understand what happens as a network grows. And again, as I mentioned in my first slide, so these networks are highly inhomogeneous, right? So there are regions of density, regions of sparsity. So you could ask two kinds of questions. So what if I pick a vertex from one of these large networks uniformly at random? So what will the neighborhood of that vertex look like? Of that vertex look like so typical neighborhood. So that could be one kind of question. The other one could be: how does the network appear around the older vertices? And how does that differ? So there are sort of different questions you can ask, and you can explore the regions of density and sparsity by posing these two questions. Now, the first question, so the way to analyze the first question is through something called a directed local weekly. Something called a directed local weak limit. So local weak limits for random graphs is a very powerful tool. And by now, it's reasonably classical. So it was started off by Alderson Steele and popularized by Benjamin Ishwan. And the directed version is by Garavalia, Van der Hofstadt and Litbach for 2020. So I will give you a very informal description of the local weekly event, so like sort of hiding away technicalities. Technicalities. So look at a large graph GN indexed by this n. And for any vertex V, this is kind of weird. So for any vertex V and a fixed K, you look at the incomponent of V in the graph. So incomponent observed up till K steps. So for any V, you get a subgraph. That's the incomponent. And you look at the empirical measure. So you can think of this as a random measure. So, you can think of this as a random measure on the space of finite directed rooted trees. And you can also allow for some marks, which I don't want to get into for this now. So just assume that this is just an empirical measure on the space of finite graphs. And you want to understand whether this random measure has a weak limit. So, what is this saying? Well, this is, you can think of this as the sort of. As the sort of geometry of a k-neighborhood of a uniformly chosen vertex, right? Does that weakly converge to the geometry around the root in some limiting random graph G? So that's what this convergence is trying to capture. And note that here there is some technicality. So this is a random measure. So it's a weak convergence of random measure, but this weak convergence could happen in one of these three notions. So like So, therefore, you have sort of local weak convergence in distribution, in probability, or almost surely, based on what you can show. So, I will try to kind of tell you the local weak limit for our model. It's a very natural description and try to exploit that and use some stochastic analysis on that limiting object to understand the degree and page bank distribution of these random graphs. So, let's try to understand the local weak limit. And this is one trick that has paid off quite a bit in the last few years for me. So, we have an initial discrete class of models, right? So, discrete time model. Vertices coming in in discrete time attaching, right? Now, the local weak limit can be described in terms of a continuous time model. So, what you do is look at the exact same process, but Exact same process, but now in continuous time. So here T star of T is a growing tree process. It's a Markov chain in continuous time. Started from a single vertex. Each vertex reproduces at rate one. And whenever there is a reproduction, you sample a Z from the PMF and you go towards V naught, Z steps, right? Only difference between the original model and this model. Original model in this model is that there is sensory. So if z is greater than the distance to the root, you don't attach. So you can think of sort of the dynamics as, suppose I want to understand sort of the in component of this vertex, they call this V, right? So all of these are directed towards V. So whenever a new So, whenever a new vertex comes in and selects something here, nothing happens. When the new vertex queries, say, this vertex and moves up, it goes z many steps. If z is less than the distance to v, you attach. If z is greater than the distance to v, you attach to an ancestor. So, you don't see that affecting the sub-tree attached to v. So, that's what this is doing here. And so, the only difference is this is. And so, the only difference is this is in discrete time. We are sort of stating the same model in continuous time. And the reason for that is the local weak limit then becomes this continuous time tree process stopped at an independent exponential one time. So, you get a finite random graph, and that's your local weak limit. And this is actually nice. And this is actually nice. So, one might ask: so, what's the advantage? You could have approached the low local weak limit in lots of different ways. And that would have led to lots of different descriptions of the same object, right? So, why this description? The reason is this T is in, this exponential time is independent. And this is a continuous time mark of chain. So, you have lots of techniques that you can do generators, you can do lots of sort of Ito calculus on these things. And then you can just plug in the exponential and thereby get its mass into. In the exponential, and thereby get its mass influence. So that's the reason for kind of like getting this description. So the independence is something that you obtain by this continuous time reformulation, independence of this time with the pre-process. So any questions about the yeah. In this computer time model, are the speeds moving at times before? At no at times before the reproduction happens, or are they fixed and then a reproduction happens? So what do you mean moving? Well, like, are they establishing the total length of their edge in terms of relative course before they re-group? Exactly. So, so, for example, you start from, say, so, so what's the local weak limit? You start from V naught, right? At some point, exponential one time, it will, it will. point exponential one time, it will lead to sort of a child V1. Now both of these have their independent Poisson clocks, right? So one of them will reproduce. So for suppose this one reproduces, it queries, so suppose the corresponding z is to zero, you get some v2, and so on. So you're creating a tree process in continuous time with the sensoring. So when you overshoot, you don't attach. But otherwise, it's very similar to the original process. So, this is the first theorem. So, the first theorem is the local weak limit of our sort of random graph model is exactly t star that I described in the previous slide. So, in particular, if you want to say understand the empirical degree distribution on this random network, it converges to the degree of the root in the limiting graph T star. So, that's just about. Star. So that's just a byproduct of local weak convergence. So this is the first part of this theorem. And so again, like you can just look at degree or you could look at any sort of statistic of your sub-tree. So for any vertex, if you look at any statistic of a local neighborhood, you can approach that by local weak limit. So now the second part tells you sort of the first sort of interesting phenomenon. Interesting phenomenon. So you see a weird dichotomy in these models. So if your expected value of z is less than or equal to one, so what does it mean? So z is the exploration length, right? So easy less than or equal to one means you are not exploring too far. If that happens, what you see is that the expected degree of the root in t star is equal to one. Star is equal to one, and the expected size of this random tree is infinite. And typically, this is something that you observe in almost all the local weak limits of all the random graphs available in the literature. So, this is some sort of a uniform integrability condition for the empirical degree distribution. So, whenever the degree distributions are uniformly integrable, you have these two things happening. So, these are sort of very general phenomena. So, these are sort of very general phenomena. Now, when E of C is greater than one, that's when weird things happen. So, the expected degree becomes strictly less than one, and the expected size of the tree becomes finite. So, in some sense, like if you're just switching your expectation slightly to cross one, again, the exploration length slightly increased, and that's enough to cause this qualitative difference in the local weakness. Weak them. So the tree size becomes finite in expectation, and there is some sort of leakage of mass, right? So more mass is traversing towards the root, and that's resulting in sort of the lack of uniform integrability of this distribution. Very good question. So if you think about so. Very good question. So, if you think about so, so this is a prelimit model, right? So, what's the expected in? So, B is your in-degree because there is a plus one here. So, what's the in-degree of the total in degree of this model? Well, for each edge, you counted exactly once, right? So, you're adding up the in-degrees of all of these vertices, and thereby you're just adding up all the edges, right? So, how many are there? It's a three, right? So, n minus one edges. So, if you look at the expression So, if you look at the expected in degree, so let's call that dn of the prelimit. So, dn is the empirical degree distribution of tn, then this is equal to n minus 1 divided by n. So, so, and by Fatu's lemma, you can show that the limit has to be less than or equal to 1. And equal to 1, so this will converge to 1, right? And when this is equal to the expected value of d. To the expected value of d, you can actually conclude uniform integrability of these dn's. When this is strictly less, it's lack of uniform integrability. So that's what's going on here. Any other questions? Let me. All right, so there is, so again, this regime is very well known because, again. Very well known because again, you're don't remind me. I'm in a sort of metastable state at this point, so don't shift my equilibrium. So this regime is, so again, so all this in a 1991 paper actually talked about a class of trees which satisfies these two conditions, and he called it fringe trees, fringe distribution. So that's why. Distribution. So that's why going with that analog, like that nomenclature, we will call this the fringe regime and this the non-fringe regime. So that's kind of the idea of the local weak limit. And now the question is, what can we do with it? So how can we derive the degree distribution just using the explicit description of T star? Now, to do that, I will give you a sort of a That I will give you a sort of a very heuristic computation, a bunch of computations, and you will kind of see what to guess. So remember, we want to analyze t star of t, right? So that's the continuous time-tree process. And we want to understand the evolution of that and then stop it at an exponential time. So now the key objects that we will work with are these specific. We will work with these specific pit. So, p i t is the number of descendants at distance i from the root in this growing tree process. So, if you think about this as your sort of tree process tau star t, so suppose this is my tau star t, then p1 of t is one, p2 of t is two, because there is one. T is 2 because there is one vertex at distance 1 from V naught and two vertices at distance 2 from V naught. So I can describe the number of vertices at each level from the root by these PIT, right? And they again form a continuous time sort of infinite dimensional Markov chain. And the sort of generator is given by this. So if you want to understand what's the rate of growth of PIFT, right? So when can. PIFT, right? So when can the number of vertices at distance i grow? Well, one of the vertices at distance L could reproduce for L greater than i minus 1. And then the new vertex could traverse up L minus I plus 1 steps. So you get in sort of a rough sort of rate equation for Pi of T. And you could write this more compactly as an expression like this. As an expression like this, it's roughly an OD with some noise. So you get an exponential of this thing. So A is an infinite matrix. So this thing is already ill-defined at this point. But suppose you could define it, then you get e to the power 80 times a martingale, positive martingale. So this is a way of writing down the infinite dimensional vector of these sort of vertex counts at different distances from the root. At different distances from the root. And again, this is not well defined because, in fact, this A matrix is not well behaved. So, one can show that it's not a compact operator. Even to make sense of this, you need some sort of rates of convergence of certain power series, which you don't have. And so, to avoid all of those, we would like, so the first trick I want to tell you is giving a probabilistic meaning to this experience. probabilistic meaning to this exponential matrix, e to the power 80. And this goes back to sort of like if you have the generator, you exponentiate, you get the sort of transition kernel, so on, right? So I will associate a different Markov process to describe the right-hand side. So for that, I will just consider a simple random walk with increments zi minus 1. So it gives you a random walk. So, it gives you a random walk. And consider the hitting times. So, this is the t bar k is the hitting time of zero of the random walk started from k. So, what you can show is that the exponential of a times t takes this exact form. So, it is like an exponential Taylor series with these probabilities. And so, these probabilities are sort of points. And so these probabilities are sort of quantifying the hitting times. So how much time it takes to hit zero, starting from k. And note that to describe, so if I want to understand the degree D, it is just P1 of tau. All of you agree? So number of children at distance one at that exponential time. So I need to understand P1 of T and P1 of t and then sort of like play this, like work this tau into this picture, right? So I need to understand the rate of growth of p1 in time. So if I want p1 here, I will have t1 here. So what is the decay of these probabilities? I start the random walk at one. What's the chance of it hitting zero after i many steps? And I need pretty refined bounds on these because you see that this is an exponential. An exponential this whole thing, so I need large deviations of these hitting times. So that's why sort of the degree distribution of these networks connects to large deviations of hitting times of this random wall. And luckily, this is more classical. So there has been a work, a couple of papers on this by Daly and Pigs in the 60s and 70s. So the large deviation behavior of these hitting times is well understood. These hitting times is well understood by now. So, again, the details are not important, but you kind of describe it by this recipe. So, you look at the probability generating function of this PMF, and you solve some functional equation. And then you kind of sort of, again, like the details are not important, but you have this crucial thing R that comes out of this sort of kind of black box type argument, right? So, you have you solve this equation, get an S naught. You solve this equation, get an s naught, you take a limit of s to s naught of this ratio s over fs. So, again, forget about how we got here, but look at this r. So, this r is going to play the crucial role. So, this r describes the large deviations of this hitting time. So, the result tells you that the probability of a random walk started from one to hit zero after time n, but eventually, so you eventually hit zero, but after time n. You eventually hit zero, but after time n. So this probability decays like one divided by r to the power n, where r is something kind of implicit, but you can solve it for specific choices of PMF. So now let's see. So if you believe me that, like, so this will roughly behave like r to the power negative i, if you just plug this in, you get roughly e to the power t divided by r. So all of these are very approximate heuristic computations, but Approximate heuristic computations, but at least they will lead to the right answer. That's why I'm showing this. And now you just plug in the exponential tau. So out of all these calculations, like the rough thing I want you to kind of take out of this is the degree distribution will have the same tail behavior as this random variable. So tau is exponential, so this is the power law. And the index of the power law is given by R. Our law is given by R. So you see that this continuous time Markov chain description of the local weak limit was very useful in even getting the degree distribution. So the result is, so in the fringe regime, you get exact logarithmic large deviation. So this is what you get. So again, just to summarize, the empirical degree distribution on this random network converges to some limit. Network converges to some limit, and the limiting random variable satisfies this large deviation. So, you can think of this as a power law with like k to the power negative r as a decay. Now, when in the non-fringe regime, the heuristics that I mentioned, there are some gaps we could not fill. So, we could only come up with upper and lower bounds. And again, like the exact numbers are not important, but there are these numbers. Not important, but there are these numbers. And somewhat funnily, like these two numbers actually agree for a lot of PMFs. Okay, so it's not like these are, so in the non-princh regime, there are certain cases where you can actually get the exact large deviations, but there are examples where these numbers don't agree. So that's kind of the result on the degree distribution. So maybe I'll just kind of like take one minute here to kind of. Of, like, take one minute here to kind of answer any questions. What? I'm sorry. But yeah, I mean, again, like, I know this is like, again, like, I didn't want to kind of like give you all the computations, but I just want to take you, take out, like, for you to take. I just want to take out this result and just think about this as there is a network model. You can define a local limit and use sort of these continuous time mark of chains and large deviations for these random walks to get information about the network itself, the degree distribution. Yes. Yes. So one way could be first of all like you can like so one way could be sort of a like that you look at the dynamics and and see like how the network is evolving but maybe a cheaper way to take You need to know that, but another way is to kind of before you go on investigating the sort of like the more intrinsic dynamics, one way could be you just plot the empirical degree distribution, do a log-log plot, and try to kind of estimate the exponent in the power log, so the Hill estimator, right? And then the thing is, if that estimator matches with the perfect attachment model, you just say, okay, I'm going to model it by this. Say, okay, I'm going to model it by this. If it doesn't, you see whether you can kind of like fine-tune the PMF to make it close to that exponent, right? And then you start investigating whether that model suits your purpose. So that could be one way, but again, like. All right, so with this out of the way, let me tell you. So this kind of gives you the typical behavior. So typical neighborhoods around vertices and the degree distribution. Now, let's talk about the old. Now, let's talk about the older vertices, for example, the root, right? So, what happens to the root degree? Now, when you are in the fringe regime, so the expected value of this expiration is less than or equal to 1, the root does not get too many vertices, right? Because things don't really make it to the root. So, when E of Z is greater than 1, so in this regime, you would expect that more vertices attached to the root. So, the root degree will tend to be higher. So, the root degree will tend to be higher in this regime than this one. So, that's clear, right? Because you're kind of going towards the root. This means that you are kind of going farther, making it more closer to the root, and here you're not. So, what's more surprising is that there is another phase transition here. So, in the non-print regime, you actually get condensation. So, the root degree actually grows exactly. Actually, it grows exactly like the whole network size. So, a lot of the vertices attached to the root, so the root degree is the same growth rate as the network size, and you can actually get a law of large numbers for that. So, again, the constant here is not important. It comes out of a branching cost extinction probability. When E of Z is less than or equal to one, the root degree grows sublinearly and it's roughly like n to. And it's roughly like n to the power 1 over r. r is greater than 1. So, again, you see that in the root degree, you see again these two different regimes based on just the expected value of z. So, in the non-fringe regime, you have condensation, in the fringe regime, you don't. Yeah. Yeah, so this is typically the behavior. So, like for the preferential attachment model, you can actually show that the probability that the degree is greater than or equal to some x is roughly like x to the power negative 2. Now, if you look at the degree of the root in the network, it is roughly It is roughly like square root of n. So you always see sort of the whatever exponent you see here, the rate of growth of the root becomes n to the power 1 over that exponent. And there is a heuristic to show that, but it will take me some more time. But it's usually the case that you flip the exponent. All right, so the last thing I want to talk about in the About in 12 minutes I have is the page rank. So we are trying to compare different types of centrality measures. So this is the degree. So now let's think about what happens to the page rank. So if you remember page rank, so by the way, so this like for different choices of the PMF, you get different exponents. And for the preferential attachment, you recover the classical results. For the page rank-driven attachment, For the page rank-driven attachment, you actually get a completely new result. So it gives you the exact exponent of the degree distribution when you're attaching proportional to page rank. So this constant already appeared in Kevolu and Mels' paper in the expected degrees. What we show is this also appears in the tail behavior of the degree distribution. So, what about page ranks? So, what about page rank? So, we want to understand how the empirical degree distribution compare with the empirical page rank distribution. So, philosophically, what we want to do is we want to compare different centrality measures. So, what do they tell you about the network? So, how do the different notions of popularity compare? So, you, I mean, I already told you like the page rank is given in this form. And again, form and again note that Lk of V is just the number of vertices at distance k from V, right? That tells you why I was analyzing those PKTs. So if you have control over those, you have control over this random variable. So before I get to the result, I want to talk about something called the power law hypothesis. So this has been around for roughly 20 years and it tells you roughly the following. Okay, so again, Following. Okay, so again, you look at a general random network and you want to understand how the notions of centrality compare, right? So there is degree, which is the most basic. There is page rank, which is more refined. So clearly, page rank will tell you, give you a more fine-grained comparison between the centralities of the different vertices, right? But the question is, how do they compare at the extremal level? So suppose you have a network of a size million. So, suppose you have a network of a size million and you want to understand the top 100 most influential nodes. So, what you could do is you sort out the degrees, you look at the top 100 highest degree nodes, right? You could do that. Or you could sort out them according to their page rank and look at the top 100 page rank nodes. So, the question is: how do these two lists compare with each other? If there is a lot of overlap between these two, well, Overlap between these two. Well, you say that, okay, page rank is more refined than degree, but at least at the extremal level, just going to single out the most popular vertices, they perform comparably. And mathematically, you can kind of rephrase this by something called the power law hypothesis, which says that for real-world networks, whatever that means, the power law, so the in-degree distribution and the page rank distribution have a power law behavior. Have a power law behavior with the same exponent. So, if you look at the empirical page bank distribution and the degree distribution, they are both heavy-tailed, they both have power law distributions, and they both have the same exponent. That's the conjecture. And again, this is an empirical conjecture based on sort of like evidence from real network data. And this has been shown to be true for a variety of models. For a variety of models, the Eda 20, the configuration model, and a lot of static network models. So, where you have a fixed number of vertices and you're just throwing in edges according to some mechanics. Yeah. Is there some normalization that I'm missing here? Yeah, so you remember, like, so what I'm doing is. You remember, like, so what I'm doing is I'm multiplying the page rank scores by the network size, right? Oh, so in the limit, this would be unbounded. But yeah, that's a good question. So this has been shown to be true for various static network models where there is no dynamics, where there is no evolution. So, papers by sort of Mariana and her collaborators over the last decade, they have resolved a lot of these sort of power law conjectures for static network models, like the models where. Static network models, like the models where you don't evolve in time. So, the natural question is: dynamic: what about networks that evolve in time? So, a few years ago during the pandemic, I was bored and I started thinking about these problems. And that's what was how I started thinking about page ranks. And the question is, let's talk about the simple preferential attachment model where you evolve according to degree. How does the page rank behave? We know how the degree. Rank behave. We know how the degree behaves. How does the page rank behave? So it turns out again, so the mechanism is: so now in this result, we look at non-trees. So every vertex comes in with cages and you connect one by one according to degree plus some offset constant beta. And it turns out that for this model, the degree tail has this precise exponent and the page rank tail has another exponent. The page rank tail has another exponent. Again, the exact constant is not important. What's important is these are different. So, for networks that evolve in time, page rank and degree behave differently, even at the extremal or large deviations level. So, if you give me the list of the top 10 or top 100 page rank and top 100 degree vertices, there will be differences as captured by sort of these different exponents. Uh these different exponents. So even at the level of large vol okay, so that's again, I did not jump to it because that's not true because that doesn't like it follow from here. You're right. But this gives you evidence towards that. It tells you that the extremal behavior is different. So now the question, so this gives you an evidence towards why these two centrality measures actually behave differently. Ontology measures actually behave differently on these two models. So, you will actually need to get an estimate of the pre-factor to actually make conclusions like that. But this gives you an evidence towards that, that even at the extremal level, page rank and degree behave differently. So, in particular, maybe to avoid any debate, like so what we showed here is that the power law hypothesis is false for the prevention adjustment model. So, now the question is: we have two sort of pictures, right? One is Two sort of pictures, right? One is for static graphs, Paula hypothesis holds. For dynamic graphs like this, it does not hold. And the reason for this not holding intuitively are the correlations. So if you look at two children of the root, right? So root has been around for longer. It is a high degree. The children of the root will typically be older. So two children of the root will have similar age and therefore tend to have similar Age and therefore tend to have similar degrees. So the degrees correlate to their age. So that's why, yeah. Yeah, so that's really helpful. Looking at the formulas for the exponents there, it kind of looks like this is not like a perturbative difference in the exponent. Like there's no, like I'm assuming M, for example, is usually much bigger than J. And if that's the case, then it's kind of like a one over, a one plus c denominator. So it's kind of off by a constant factor. So it's it's basically like a constant factor away in the air. Is that a good heuristic or do I have to scale up? So it's a good heuristic for certain choice of parameters. But again, like c could be close to 0, close to 1, m could be very close to 1, close to infinity, whatever. So for differing choices, you actually have any sort of multiple you like. And it's more extreme when you look at the random recursive tea. When it's uniform attachment, degrees of exponential teaching. Attachment, degrees of exponential tails, and page ranks, you can show they're parallel tails. So it's very, very excuse. Yeah. So, so, so, okay. So, the, so now, like, the last question that I want to ask is, like, is there a model where you can see this transition? So, from static to dynamic, like the page rank TL behavior changes. Can you interpolate the two? And it turns out that the model that I described catches that interpolation. So, the last result I'll present is a Result: I'll present is the large deviations for the page rank, the limiting page rank of our network model. So it turns out that in the fringe regime, when your damping factor is close to zero, so S naught is a constant that comes out of some equation. So when it's close to zero, the degree, so if you just go back to this equation here, right? So when C is close to zero, So, when C is close to zero, you're putting more weight on L1 than on L2, and the weights are decaying really fast. When C is closer to one, the weights are decaying slower. So, when C is close to zero, you get the exact large deviation as a degree. So, the page rank and degree have the same tail. When C crosses some quantifiable threshold, you suddenly see a different tail behavior. So, but just by sliding the damping factor, Just by sliding the damping factor from 0 to 1, you can see a regime where Paulo hypothesis holds and 1 where it does not hold. So you see this transition in a sort of smooth window. And again, in the non-fringe regime, we don't have complete results. We have upper and lower bounds. And I think, so how much time do I have? Is it a minute? Okay. So maybe I'll just conclude. I don't want to. At least the extremal, like the tail behavior. So, in other words, like if you look at, say, okay, so another way to think about this is if you look at the order of the page rank of the largest page rank vertex, it undergoes this transition. So, again, like just a conclusion. So, this is again a very simple. So, this is again a very simplistic model, but even here you see some rich phenomenon happening. So, this is just a starting point. So, extension to the non-presetting would be the next immediate goal. And moreover, other types of exploration schemes. So, this is so there is no randomness in the exploration, right? You just they are this be careful what you wish for. But yeah, so yeah, during the next pandemic, I promise to think about these questions. So, what about other exploration schemes? So, like for non-trees, you have different types of random processes you can use to explore. And the final thing that I'm really interested in, as this goes back to your talk, is like, so there are opinion dynamics, all sorts of epidemic models, right? All sorts of things on these networks. So, for a fixed network, you can give a dynamics, okay. Now, the question is: can you make them interplay with each other? So, there is a dynamic going on on the graph, and that leads to the graph itself changing, which affects the dynamic, the co-evolving network. So, this would be the final thing that we would like to understand, but I think this is a few years away. All right, thank you. So, that was a good clarify. So, you talked about the exponential time to get the explicit power level. That is that making some assumption about the distribution of how something is behaving, or is that something that pops out of bridge books? You mean the the reason why this is the exponential? So actually that's not a big surprise. So the big surprise is the independence. So the continuous time embedding helps you decouple the tree process from the swapping time. And the reason why this is not a big surprise is, so you're picking up vertex uniformly at random, right? So the vertex index of that chosen vertex, like n times u. Chosen word is like n times u, where u is a uniform 0, 1. Now you can show that like the network is evolving in discrete time, but the continuous time model evolves into logarithmic time. So essentially, you are looking at sort of the log of this minus log of n. So this is sort of the sort of the distance. So the age of the vertex you're picking. And this is like log u, which is like an exponential. Which is like an exponential. So that's how it sort of. So the reason it's exponential is because the continuous time dynamics sort of make gives you a time change. And under the time change, uniform becomes exponential. Yeah. In the perfect attachment, right. Likelihood very effective actually, no, yeah. So by ordering, you mean like the So by ordering you mean like kind of flipping the roles of the children will not change things. Is that what you mean? I only have one stack dynamic of it. Exactly. And that's that breaks down actually for this model. Yeah, yeah, yeah. This model. Yeah, yeah, and then it's not just like for the for like this model. So, in fact, like, so one sort of other model that I've studied for a while is like, instead of, so what's special about degree, right? So, if the probability attachment is proportional to degree to the power some alpha, right? So, when alpha is one, you get perfect attachment, when alpha is zero, you get the random recursive free. But this whole spectrum between zero and one gives you this non-linear dynamics, right? So, the evolution of Dynamics, right? So the evolution of the tree depends non-linearly on the degree. Even for here, things break down. So, in fact, you can show one thing that when, so, suppose, like, I'll just tell you, like, maybe one thing. So, suppose I have a snapshot of the network, right? How do I estimate the root? So, where it all started. So, one way to do this is look at the highest degree vertices, right? So, it turns out then when alpha is between half and one, just looking at the top highest degree vertices gives you a Highest degree vertices gives you a confidence set for the root. When alpha is less than half, that's not true. Yeah, for directed, yeah. So I'm saying that you give me a snapshot, remove all the labels and all the directions in that case. So it's so the analysis is not actually very tied to trees because so okay, so I'll make two points here. So there are a class, for example, if you look at the preferential reduction model where each vertex comes in with say five out edges, right? So it's connecting all these edges one by one according to some dynamic, right? So clearly. To some dynamic, right? So, clearly, it's not a tree model. There are loops, right? But you can actually get a lift of these processes, which are trees. So, you can get a tree network process, and by collapsing certain nodes, you get the projected network. So, there are ways to kind of get these models, the non-tree versions, by collapsing some trees. But that's not always true. In cases where it's true, there is hope. You can just extend the analysis. In cases where it's not true, you can't extend. Where it's not true, you can't extend this analysis directly. But all the continuous time dynamics and the local weak limits. So, one thing I want you to take out from here is: even if the network model itself is not a tree, if it's locally tree-like, which is most random network, you can still make this work because all you need to do is to show that the local limit is a tree. And then you're all set. But yeah, so there are some, like, of course, gaps, like things which are very dense. This won't work. Things which have... This won't work. Things which have like directed loops, it won't work. So there are things like that. Right? 