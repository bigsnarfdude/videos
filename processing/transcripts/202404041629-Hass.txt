I just time, not just a minute. Oh, you know, okay. We'll tell you what to do. If I can't see you much for these 10 minutes, including questions. So, welcome back. Welcome back. So we have five ten minutes talks now and after dinner at nine thirty at seven thirty nine thirty we have four or five more short talks and then we can party. So yeah, so let's start with you. Thank you. Thank you. Thank you. Hey, I'm back. Second was the talk. So, three outlines. Outline. What is the role plans? We got your favorite thought of. Uh we said that by a smooth thickening up as if you have tied it with a rope, right? Suppose you're tied assuming the rope has a unit radius, then you look at the menus of the certain dot, and that would be called the rope menus of the dot. So, I mean, I made a few slides to make the definition more accurate, more precise, but roughly speaking. The tie with a load with unity circuits. You do that, you know, the minimum amount you need to tie a particular knot, that's the road. Okay, so I can buy passwords. Remember, that's what it means. Okay, so there is this long standing conjecture for maybe 40 years. So the conjecture was about the role length of outlining mix. Outlining needs. So the conjecture is that the rope lensing need for those outlining guys is at least proportional to their cost numbers. So maybe more precisely means that there must be a universal positive constant, right? So the rope lengths you need is bound below by the quote number of link times that constant. Concept. You need to be careful here. We are talking about the minimum, the lower bound. You can draw your favorite lot, and then you think you are very smart, you made it very short, you measure that length, or I give you the upper bound. It doesn't give you the lower bound. This the idea here is that if you have anything lower than that, you cannot do it. So, I mean, if you make something, it just means you can do it with that, right? So, what? You can do it with that, but what if I give you less? You don't know, right? So that's the difference between the questions. So, come up with a particular example, a smart way to make it really short, it's good. But it's not as hard because you have a concrete way to construct it. Here, there's no such a thing. In that notch space, there's no way you can there's very little you can do actually. So, unless you can associate with this role-playing thing. Associated with this roleplay thing with some node invariant. Because that is something you know it doesn't change, right, as you change your node configuration. So well, it turns out in the case of outlined not, if the NIC has only one component, the conjecture is true, which was proven last year. So it's very recent. And in fact, in this case, And in fact, in this case, there is an estimate about the constant K0. And that is not a very good estimate. I know it can be improved. You see, if you ask me how much I can improve it, I don't know how much. Maybe by 10 times, who knows? I think it's possible for this to make you this like a quarter or something, but it's possible. Okay, but so, but on the So, but on the cubic lattice, this thing probably looks better. So, if you realize you're not on the cubic lattice, so the lens on the cubic lattice is like the discrete version of the local lens problem. So, what is the minimum length you need to realize you think on the 2D lines? So, for ultimately not this is what is the minimum lens you need. So, let me give you a few pieces of where. So let me give you a few pieces where it leads to the proof of that. This I already mentioned when I give that first talk, the number of cipher circles in background give you the upper part for the bridge index. And that I already showed you. Uh so this second thing is uh old result, which kind of connects the discrete case the latest ones. Case the largest ones with the smooth ones. So essentially, up to some constant, those two robberies are equivalent. Okay, that's basically nothing. And this is what I also did in my talk. So if you realize your KC, right, it's a narcissist realization, and then And then you can actually deform this guy so that the resulting knot will give you a diagram so that the lamp of the cyber circles there is bounded by this. When I was giving my talk, I was, remember I was giving you, there was something that says you got this one, this is the number of steps that immediately, if you just count the X and the Y steps, forget the Z steps, right? That was the bottom. Steps right that was the bundle for the number of cyber circles. But remember, I was choosing the xy plane fairly arbitrarily, right? In your lattice knot, right? The total length is added by counting the x and y and z steps, right? Together, right? They give you the total length, right? And one of them is at least one-third of the whole length, right? So assume it's the z direction, right? Then these two. Then these two guys would be at most two-thirds of the total width. If that's the case, then three-half of this times that will give you this, right? So the cipher circle number is bounded above by your length of interaction. And that and that number is an upper bound for your bridge in the uh the breed index. In the breed index, because that's the number of the cycle surfaces. So that's one of the key ingredients. So the result follows from there because the breed index is by that. This is not just for outing, this is for any link. Because this is universal, because that construction does not depend on outening lots. So, and I use the cop to letter B because when you have a link, you have different ways to assign orientation to the components, right? So, you may have different bridge indexes because you change that. That means that you can choose the largest. Okay, and then finally, when you have a not, it's not a mean, I have only one component, right? So, the way I do it is that I double it. I make a parallel copy. I make a parallel copy. So you have your favorite knot rather than outlying knot. I make a parallel copy of it, but then I assign them opposite orientations. And that's what I call this guy. So when you do that, those two guys may actually link each other, so there's a linky number associated. But for that guy, we can cover the breathing, that particular guy, and it can be precisely determined depending on what that definitely. Precisely determined depending on what that area is. But long story short, all of those guys here are positive numbers, so it can be bigger, but at least this, this is a mean number. So when you do the double, the crossing, the breeding dex of the double is bound below by the crossing number when k is outmini. And that basically will combine this with that, that will give you the result. You can see, because when you take your When you take your minimum configuration on the lattice, you double your lattice, right? Now you can figure in the core of the parallel code in the double lattice. The total length now becomes what? Once you double it, the length here gets double. You fit another parallel copy together at four times, right? So you get four times this guy, which is Which is bounded below by this. Therefore, your error of Kc is degree equal to a quarter of this. That's the rel. Then you use the bridge connected to the smooth case, and you get the readout. 40 seconds for questions. Is there any way to improve it by looking at different models? Probably all for that is. You probably just want to deal with use case directing, I think. That's probably the policy phase of the quick length. When you double it, the length is generally more than double straight. Length generally more than doubles, right? No, no, it precisely doubles. Because of the width. And because you make every step becomes two steps, right? Because you double the lattice, right? Which is the length of the lattice. Yeah.  Okay, so I want to talk about some resultant brain indices of pretzelings. And this is joint work with people down there at the bottom. So most of you have heard this before, but I just want to sort of recall some of this. So we already have seen what is a braid. If I close up a braid, then I get basically a link in break form, and there's a theorem which says every form and there's a theorem which says every knot or link can be represented in break form and the braid index is the minimal number of strands we need in order to represent a link in break form. This is one of the many integer invariants we can associate with a knot, and the difficulty is with many of those things they're very difficult to compute. And I want to just throw the following thing in here that Here, that in order to have this breakform, we think that all these strands are either clockwise or counterclockwise. So, in some sense, you have to think of this as an oriented link where you could reverse the orientation of all components, but not of individual components. What is a pretzel link? Well, a pretzel link is essentially the thing where you have vertical columns of twists and you sort of just string them together like this. String them together like this. And there are three different types of these guys. And so I want to just explain what they are. So this first one, all columns are anti-parallel oriented, which means if you look at this first column, one strand goes up, the other strand goes down. Same here, they're all anti-parallel. This guy has parallel and anti-parallel. So for example, you can see that this column, this one goes down, this one goes up, this is anti-parallel. This one goes up. This is anti-parallel, but for example, here, both of these guys go down, so that's very odd. For type 1, all the crossings here are, in each column, have an odd number of crossings. Type 2, all of these have an even number of crossings. And here in this last one, there are a couple of restrictions. The anti-parallel ones, they all have to have an even number of crossings. So this one has four, and this one has four. So, this one has four and this one has four. The parallel columns can have even or an odd number of crossings, but the number of parallel crossings has to be even. This may not be entirely obvious, but if you think about it, these things fall into these three types. The tools which we use is the Holmflat polynomial. I don't want to say very much to this, but this has been mentioned before. The grade index is found below by the highest power, minus. The highest power minus the smallest power in A divided by two plus one. So that gives you a lower bound, and the upper bound you obtain by creating a diagram which has the right number of cipher spins. And basically, if you get those things to match, then that's the Braden mass. In a paper two years ago, we were able to carry this out for all alternating Montesino smooths. So we have a closed formula for the brain index for that. Index for that. Now I was then looking at, you know, like not ATLAS, looking at non-alternating Montesinos knots and compared them with the alternating Montocinos knots. And I noticed that, well, the Bay index is either the same or it's sort of like one less. So we're thinking, well, how hard can this be? And, well, that was sort of a mistake. So we sort of said, okay, let's study. Sort of said, okay, let's try this for the simplest kind of non-alternating things we can think of, and those are these retaliates. And here's sort of the easiest case, and that is the type 2. So let me remind what they are. All columns are anti-parallel, and there's always an even number of clusters. And so I don't really want you to look at the details. I want you to look at, this is our notation. So these are the positive guys, these are the negative guys. Guys. Now, as far as the home flat polynomial is concerned, you can sort of mix these up in any way you want. The home flat polynomial doesn't change, so that bound is independent of this. Now, the ciphered circle drawing, there you have to be careful that it works for any order of these columns. But this formula for six, that's the alternating case. So either all of these are zero or all of these are zero. And that was sort of, we knew that already. There's also work. That already. There's also work by Morosuki and Krzinski, which did some of these breads and mods. The most generic case is if you have at least two positive columns, two negative columns, and then the break index is just one less than the alternating case. So that's kind of nice. And so then this is sort of an interesting case. What does this mean? And so I want to illustrate this with an example. And so first, consider this guy. Consider this guy. And this has a grade index of 14. The standard diagram has 24 Seifert circles. And so, how do you reduce them? And so, it turns out that if you have a column of anti-parallel things, this is the Seifert circle decomposition, you can sort of make a local move, and that reduces the number of Seifert circles. And so, that is almost enough to take a diagram like this and reduce it. Like this, and reduce it to the minimum number of sci-fi circles. There's one other move needed, which I haven't drawn. But basically, here we get everything to match. This is the non-alternating case, and it has a rate index of 12. And so you see this is a difference of 2, but we can crank up these examples to make this difference as large as we want. Okay? And so, what this first picture. And so, what this first picture is trying to show you is, and again the details, this is truly formidable, but you need to make some moves in order to generate a diagram which has a minimum number of siphon circles. And so you make these moves first, and then you see these bold things, and there you can make more moves, and they are sort of similar like this. And you can ultimately match the number of cipher circles you need in order to claim that's the great index. This is the type 2. This is the type 2. All I want you to see is more complicated. This is type 3, and this is only a little bit of type 3. So if... So first about the notation. You have parallel columns which are positive, parallel columns which are negative, anti-parallel columns positive, anti-parallel columns negative. And here's an example. So when you now start looking at this, then you see this crossing is positive. See, this crossing is positive, it sort of goes going down, this is parallel. And then this is also parallel, it's negative, so this is this negative 4. And then you have three anti-parallel columns, this one, this one, and this one, and these give you those. In this formula, this delta plus is the number of ones which have positive sign. And if you see a delta minus, this is the number of ones which have a negative sign. Is the number ones which have a negative sign. And should have gone back. What I sort of did not show you is in this picture here, you actually can see, this is clearly a Brett's blink, but you can see that this guy here has an over-over and it can be simplified. Now, if you look at a minimal diagram of this, it has one viewer crossing, but it's no longer in Bretzen-Link form. It is a Montesino snot. But, well, and so. Well, and so this is a positive, yeah, now this is a negative one, and I think this is a negative column. And so basically, they create this non-alternating thing, and there are some simplifications possible. And see where I am. That's where I am. And this sort of explains some of these funny terms in here. You can take these ones and sort of. There, you can take these ones and sort of do some simplifications. Now, does it matter the order of the tangles? For the home-flat molecula, it never does because it's just the mutation of these columns, and the home-flat moment doesn't change. Now, when you do the diagrams in flukation, it does matter. Okay, so you have to be very careful there. And this is a continuation of type 3, and this is. 3 and this is a decontinuation of type 3. So it's very formal. The thing I want to point out to you is this. There is a particular class for which this strategy actually failed. We couldn't determine this. And how, the home-fly bound gives you this, and the diagram, we can only do this. So we know it's one of the two, but we can't decide which one. And I want to show you the simplest example of this. They're all links. Example of this. They're all links, so I didn't find any of those when I looked at the NOT database. And so this guy in the link info database is this. This is the Rawlson notation. And all these things have in common that these difficult ones, that you have one positive column, one negative column, and in parallel, and the crossing number difference is just one. Okay? And so the And so the inequality from the whole flat polynomial gives you three. If you look at link info, it actually tells you this is four. And how can this be done? Well, you can do the double. So here's a picture of the double. And that should double the brain index. And basically, direct computation shows this has a brain index of seven. And so it couldn't have been three, because then this would be six. So we know this is four. For that. And I won't say much to this. The last slide, I know there's a conjecture. So the last slide is sort of attempts to simplify these things, and it becomes really, really difficult to do this. So this shows you just the beginning, and then here and here and here, there are further moves we made, but I will not go into this. Thank you. And then call L. You can draw the wine or Apple C for copy and then you can on my copy of the desktop. Yeah, so can you draw it before you can track mine? Yeah. Why is it that? That's not a good form at all. I think the code is small or something. And now you switch it. I burned yesterday what I tried to do isn't double, yeah. No, it's common. The command is in F. Okay, I'm ready, yeah. Okay, let me go. Okay, so thanks for the opportunity to talk here. I'm not very performant with this much. Okay, so all this is your work with Mikael Cocheva from Kerlon Ferran. And well, the subject doesn't really fit in the talk, in the conference, so there's more computing, but you see that I'm not very much computing. So the idea is the following thing. I will work with the variety of representations. I guess you are familiar with it. And I'm interested in the algebraic structure because somehow to compute, I need to compute polynomial. So this object I can embed it into, well, if I have a final representation. To well, if I have a finite representative group with n generators, so I embed it in any copies of SL2C, which is an algebraic subset of C4. We call it often the variety of representations, but it's not a variety. It's an affine scheme. So you should be a scare of the word scheme, but not a finite scheme. Because for me, an affine scheme is just a subset of a finite space defined by polynomials. The only issue is that. Defined by polynomials. The only issue is that I may have multiple polymers. Okay? When I work, if I talk about varieties, I don't have multiple points. Because if you think of the idea, you take the radical and you don't have x squared, you have x. But for me, as a scheme, x squared and x are different. Okay? So I may have double points and triple points. So in fact, let me make a picture. So imagine that I I am the complex plane. That I'm in the complex frame, which is like this, as everybody knows. So I have x equals 0, and I may have x squared equals 0. So it's the same variety, but it's a different skill. So the formal way to think of that is if to think of ideas. So this is an ideal and that's a different idea, okay in the ring of colouring. The ring of coordinates. So there is no reason why I get a variety, okay? Because this algebraic structure may have points with multiplicity. So I need to look at that. Or I'd like to look at that. In the last 15 minutes, I will show you an example to motivate this. Okay, so the second step is that we want to look at We want to look at representations up to conjugation, okay? Because conjugate representations are equivalent for whatever purpose we want to look at it. The problem is that the topological quotient of the ribbon computation usually is not household. So we look at some kind of houseification, so we take a larger quotient. This larger quotient uses characters. So what's a character? A character is a set map from the group to see. The group to see that match every element to the test of rho. That's the character of rho, okay, of rho of gamma. And the lemma is that two orbits, the closure of two orbits, intersect if and only if they have the same character. So the right object, a priori, is the variety of characters. And this is also Gebraca that's a theorem of processing from the 80s or 70s, I don't know, that says that the set of our characters. That says that the set of all characters has an algebraic structure, it's the natural algebraic posture. And this is going to be a skin tool. So, in the next slide, I will explain the algebraic structure. Okay? So, what's the algebraic structure of the set of characters? So, I don't call it the variety of characters anymore, I will call it a scheme of characters. So, we use stress functions on the variety of representations, which is, it looks like. Which is, it looks like the character, but it's the different point of view. So, every representation you make the trace. And what processes proof is that the variety of characters it embeds in CN with coordinates samples functions and it has an affine scheme, so an alternate subset of CN. And this is called the scheme of parameters. And I had some. And I had uh some explanation for that. I I will skip that because I don't really have time. Let me better show an example. If I can. So start with a free group, and there is a very known, a very classical example, which is the free group on two generators. And this goes back to free Ken-Krain. So we have a free group generated by A and B. So there is an isomorphism of the variety of characters with C3 and the trace. C3 and the trace, the coordinates are the trace function of the two generators A and B and the product. Okay? What does it mean algebraically? Algebraically means, well, in terms of polynomials, means that the function algebra is just the algebra of polynomials, or more effectively, means that if I have an element of the group, then the trace function of this element is a unit polynomial on these three guys: T of A, T of B. Guys, T of A, T of B, and the trace of the product. And this tells me that the variety of characters is still three. Once I have the proof, the proof is very nice because it has compatibility. It uses some trace identity. So you have two matrices from SL to C. So the trace is symmetric, the trace of the inverse is the same trace because that's it for SL to C. And I have this other identity. at this other identity. Trace of AB plus trace of AB minus 1 is trace of A Z times Trace of B. And the result is some identities for test formulas. And this one is very important because this relates these identities with the scale algebra, which I will not talk about, but it's used of the time. Okay, for instance, if I want to compute the trace of a square, so I apply this formula here. I apply this formula here, okay, with gamma mu equals to A squared. So I have P A times V A plus P of A. I'm confusing, A times A, A times A minus one equals to T A squared. And from this I get Ta squared, Ta squared minus one. And this is an algorithm that you can use to. Is an algorithm that you can use to prove this. So, what happens if you have more, a free group of Hagger Ram? It's not so simple, but it's also known. And this is an affine scheme, which is irreducible, it's like a variety. It's well behaved. So, what's my purpose to compute? My purpose to compute is to start with a final presentation of a group. And, well, if I take a few roots, I know how to compute it. A few groups, I know how to compute it. If it's not free, I have to take care of the relations. And that's the result I won't introduce. I will introduce. So, well, this was inspired by a previous result of Gonzalez Acunia and Montesinos 30 years ago. So, I have a finite presentation. If I want to compute the variety, computing the variety means just the subject, and I take the radical idea. Radical ideal, so you have x squared, I take x. Okay, so I need to compute the trace of the relations. I put the trace of relations is equals to the trace of the identity, which is true, and each relation times an element, a generator, equals the trace of the generator. So, this is a super adding of the variety of characters of the food group, and I need to add these equations, okay? So, if I'm interested as a skill. So, if I'm interested as a scheme, well, what they do, and then they take the radical because they're interested in varieties. So, every time they have a power, they just take the generator, okay? And as a scheme, I need to eat what we prove with Mikael is that we need more, one more, some more relations. And of course, we don't take the radical. Okay, so in this case, we are sure of what is a multiple point, what is not a multiple point, and all that. And all that. And the idea of the proof is not complicated. So as a scheme, this is given by some equations, T gamma equals T mu every time that two elements of the field group project to the same element. And this is using the second algebra, which I will not talk about. And we use trace relations as. We use stress relations, as in the previous examples, like this, to reduce the circumstance. So it's an elementary proof. The bad news is that this is very ineffective. Very inefficient. Because if I have a group with two generators that works, three generators is more complicated, but we didn't succeed putting a single example with four generators in SageMath. That that that that that worked. That that that that word is really complicated and just an example, quick example. Why should we look at characters? Well, there is an example which is you take the following org before, take the fig grave knot. Well, I cannot draw the fig grave knot in three seconds or two seconds. But that's a presentation of the I'll put an orbifa structure on it, okay? Uh I finish that somehow. I finished that sample. So that's the representation of the flu rate node, and you add this relation that h equals one. So you compute the characters and blah blah blah blah, and you get a double point. And why do you get a double point? Because this only flow is included. This is related to the geometry. So somehow these double points, triple points, and so on may be interesting. And I finish here.   Okay, so uh I am going to tell you about a project from a summer student at UVIC. His name's Sean Lee. So, this is just a summer project. And in short, I suppose it's maybe best. In short, I suppose it's maybe best described as a visualization of the Cassin invariant or the type II the Cilium invariant of knots. It kind of barely technically fits in with the theme of the company. It has to do with knots and the algorithm that he uses, that he implements a tiny little bit of randomness in it, but it's not significant. It could be randomness could be. But yeah, so let me tell you a little bit about this visualization. A little bit about this visualization. So take the configuration space of five points on the knot. So that means like five tuples of points on the knot, but then you remove the ones with repeated coordinates. So if the first coordinate is equal to the second coordinate, that's not allowed. So this is an open subset of this product. Product. So, what we're going to do is, we look at five tuples of points on the knot that satisfy some geometric properties. So, to get a little bit closer, look at the configuration. So, our knot is going to be sitting in R3, say. Then we look at the configuration space at five points, and inside of that, there's the subspace where the five tuples sit on a round circle. A round circle. And the important thing to notice about this subspace of the configuration space of five points is that if you take three points in Euclidean space, say, they sit on a unique circle or line, so the other two points, those are each codimension two conditions to be on the circle or line. So this is a Line. So this is a codimension for subspace of that configuration space. So, you know, if you were to generically sort of intersect this with the circle subspace, you would get a one-dimensional sub-manifold of this configuration space. And this, sorry. Good. And Sazia, you're going to have to remember you're next. But yeah, so this configuration space of five points on the knot, that's, as a space that looks like there's the cyclic orderings, there's four factorial of them, and then there's wherever the first point is, well, that's the point coming off. And then the remainder, it looks like the interior of a fourth simplex, right? Because it's just sort of. The remainder are just points in an open interval with an order fixed, right? So it looks like that. So, okay. Now, one more notion I want to define is that, so when you take this intersection, five points in the knot with the circle subspace, that's a one-dimensional sub-manifold, generically, but it may not be compact. And so, what we do is we look at is we look at, we have this notion. So say here's a circle and then here's the knot. And if you have point one, point two, point three, point four, point five, so here's here in the in the circle ordering, so they're given in the natural ordering. And then we, then those five points, they also have an ordering along the knob. Ordering along the knot. So, you know, point one and two are consecutive along the circle, but then we can demand that they're not consecutive on the knot. So this subspace, we could talk about the subspace where points that are consecutive along the circle are not consecutive in the not ordering. So those are called pentagrams. So this is So this is C5 of the not intersect the circle subspace, but where if you're consecutive on K, then you're not on the circle. Right? Because in that, it's a one, two, one, one, two, three, four, five. They have to have four five they have to have this sort of ordering if that's the if that's the order if I'm numbering along the ordering of the knot that's what they would have to look like on the circle so these are pentagrams circular pentagrams so yeah so now the the theorem is that these so these are five tuples so now this is a So now this is a compact-oriented. You have to look at the normal bundle, but it's naturally oriented, one-dimensional manifold. And so you can just map down to the knot by forgetting all the points except for one. They said P1 through P5 to P1. And the theorem is that the degree of this map is the Cassin or type 2 invariant. Or type 2 invariant. And yeah, so this space here, so you just pick a component, right? And so this configuration space, it looks sort of like a five-dimensional fattening up of the knot in a sense. And so you get this manifold, if your knot has this orientation, this manifold might have the opposite orientation from the point of view of this projection. Of this projection. Yeah, so that's the result. And so Sean, he created a computer algorithm to visualize this. And the key idea is that if I was better at Euclidean geometry, I'd remember this formula, but I had to get my notes in. So there's this thing called the Polemy inequality. So I'll phrase it as a function. So a function of, say, four points in R3, and you just take the gap between P1 and P2, the length, P3 and P4, the gap between, I think, what is it going to be? P2 and P3 times P4 and P1. And then you subtract P1. T1, T3. This is the sort of the X-Court diagram factor. So that's the Tolmy function. So these points are, say, an R3. And so the theorem is that this is always greater than or equal to zero. And it's only equal to zero when P1, P2, P3, P4 are on a circle or a line in this cyclic ordering. Cyclic ordering. So, what Sean did is you take this function, g, from C5 of the not to the real numbers, and you send P1 through P5 to this only function of, where we demand. We demand a cyclic ordering of the points and add to that, so that's the first four points, but then you also need the other, you also need to include t5 with the right cyclic ordering. So I think it winds up being this, I believe. And so this function is greater than or equal to zero and equal to zero on the on the integrates. So then what So then, what he did is, so when you enter a not in a computer program, typically you create a PL not. You have a certain number of sticks and segments. And this function, it is very nice if you choose, say, the five-point from disjoint segments. It looks roughly like a quadratic polynomial. And you can kind of guarantee that either there's no solution or the solution is just a nice. There's no solution, or the solution is just a nice, essentially straight line through that product of intervals. So, a gradient descent method, gradient descent methods are very effective. Tiny bit of randomness to get everything you want. But yeah, so the idea is you just, so if you have, you know, if you have a PL0 with like n line segments, then you just take n to the five possible initial conditions. End of the five possible initial conditions, a point in every line segment, and you run the gradient descent algorithm. And this guarantees you find all the components of this manifold. And you actually get a guarantee of density of the points. You can even write down a C1 uniform approximation to the solution curve. And anyway, so then you have that, and then you can. You can. So, this is a trefoil. So, a trefoil is a fiber in a ciphert fiber ring of the three-sphere. So, this is an embedding of the trefoil, which is almost one of the cipher fibrings. And so, these are all, these circles are just being pushed around by isometries of the three-sphere, essentially, up to approximation. And then, you know, the figure eight-naught, its casino variant is the opposite. Whoops, there we go. Okay, so it's you know, it's uh. Uh okay, so it's it's you know, it's uh so what that what I'm showing you here is that's a little fast, is pre-computed stuff. Uh if you if your computer does have uh uh a GPU and you your web browser is comfortable with web GPU, you can enter any knot you want and it'll it'll farm it out to your GPU. If you have you know thousands of cores, it'll be very fast. And let's see, and then you know you can do some more. You could do some more complicated notes. This one's probably a little ridiculous. Let me slow that down. So we're still polishing up the app a little bit. It's part of one of these Ober Volta imaginary projects, these exhibitions. And it still goes a little too fast. I hope this summer we'll polish it up a little bit. This summer we'll polish it up a little bit and make the interface a little bit more pleasant to use. But yeah, that's the project. And this is on the web. That address I can give it to you if you're interested. So we can get back here. I was just looking for a single object to cache. There's something less than auto, I understand. Thank you. I wanted to talk about this because Nick couldn't make it. This joint work was Nicholas Hobert. It was deeply rooted in his ideas. He came to work as postdoc with us to Japan. So my motivation comes from the study of three manifolds, right? So I want to study geometry and topology of three manifolds with finite simplicial, you might say. Simplicial volume, I say, you know, simplicial volume is just Gromov norm multiplied by volume of regular ideal tetrahedron. It's equal to hyperbolic volume with many flows as hyperbolic. And of course, these manifolds can be traced back to link complement centrisphere when closed due to the Gauch wallets and they just, when they are custom, they just already have this nice boundary of Tauri, which is a link. But just sensibly talk about geometry. Sensibly talk about geometry topology of three manifold. We hope for a model that produces enough hyperbolic links in three-spheres. And who knows what enough means, but at least you know, when crossing number is low, you want to generate many of them, right? Because we know that when crossing number is low, we generate a lot of hyperbolic links, just by diagrams and tables, etc. And we also want nice link diagrams because we often try to trace back the geometry and topology to properties of linked diagrams. Topology to properties of these diagrams. So, you know, we need something to use with nice properties. And so, this is a new model called random meander model. What we do, we take this arc, and many people studied meanders, but in different contexts, and we put just these half circles on top and bottom, and we match them. And this corresponds to matching pairs of parentheses above and matching pairs of parentheses below. Mentioned pairs of parentheses below. So a string of pairs of parentheses. Then you can make a link out of it. So you basically choose crossing information at random. And those proved that every node has a Neanderthal. And then combining that with what Heim-Joel and Liniel and Novik proved, you get that every link has an R-strand Neanderthal. So if you take multiple strands here, Multiple strands here. And these are kind of slightly redrawn, really, but they are potholder diagrams. That's how it was with Heinz and Joyles and Linux and Novik Beaker. And what happens here is that these are very well studied. If you have a string of mentioned pairs of parentheses, then the number of such valid strings is something called Catalan number. Catalan number exists. And periods since the 19th century, you know, for example, it becomes partition, something else, something else. And of course, the first, as Moshe said, sanity check. What you want to check is that you don't generate the same link over and over and over and over. So you want to check, make sure that you really generate different links by doing this. And for this, many people previously used various fragments. This is something Jason was talking about, like he used true foil fragments. Use two foil fragments. So, the fragment we use for this is something we call pierce circle. So, circle like this. If you choose crossings correctly, you cannot get a good link. And something we prove is that if the number of crossings and number of strands tend to infinity, then random link is non-trivial with probability one. And basically, what we do, we look at this number of graphs with these pure circles, and then we get hypergeometric series and some kind of. And some kind of old results, like classical results of Pancorea and the Zilberg's algorithm, allow us to prove that this is autotically approaches zero. And then there are coordinates. So for example, which is rather straightforward, you know, if you have a given link, then probability to generate such the same link kind of isotopic turn to tends to zero is R goes to infinity. So you do generate all links, but not like So, you do generate all links, but not like you generate the same link over and over. Another corollary says how many distinct meanderable nodes you have. And you can find similar proof also in Heimes and Jaws and Linear-Lenovic paper, where you use result of Welsh and you use something else. So, here we use bound on the crossing number. By the way, so what happens if you have, for example, a figure A diagram, this is also a figure A. For example, figurade diagram. This is also a figure A diagram, but if you rate it in this drawing in this meander form, you have more crossings. So, the question is: how is the number of crossings related? And we do have NIC proof that for notes, we don't know what is at full links. We have that for links, we could see how many prime links we have, perhaps. And what else we wanted to do is to count the number of eigens and number of twists. Why? Because this leads us to hyperbolic volume. A volume. And eigens in the link diagram correspond to just consecutive matrix parentheses with nothing in between them. And it turns out that people also studied such strings of parentheses a lot. So the number of valid strings of n parentheses with exactly key substrings, like this, is something called Narayana number. Also, have existed in competitor for a very long time. So someone already counted it for us, which is really nice. And as a result, you can get As a result, you can get a number of eigens and then number of twists in a random Meander diagram. And here, R is the parameter of number of crossings. And actually, S is the parameter of the number of crossings. R is how many parallel strands you have. So you have two parameters. And you have the exact number of trees in RS diagram. And then you can apply volume bounds. And I could say this is in the I could say this is in the spirit of a beating, which I think was Nathan's student, right? So he also applied volume bounds to another random model. But you get to get what is the expected volume of these random links. So the volume bounds belong to initially that can be then, they were improved by Gothursten. Upper bound, we extended it to simplicial volume with Dasbach. So here you have. With Dasbach. So here you have to save for alternate random meanders. Here you can see for all kinds of random meanders, upper bound holes, lower bound holes. And there are some corollaries. Of course, if you take, for example, one strand, you get a very simple bound, but even with multiple strands, it's not a difficult bound. And I feel that maybe this is very much like a start. So, you know, the volume is kind of. So, you know, the polymer is valid, it brings some interesting results. We still don't know the distribution of hyperpoly links, for example. And there are so many things we do not know. Well, stop here. We have some time for questions. Why are the pictures in the middle of the middle? This, you know, from the proof, if you ever looked at this proof by Lucknow, proof by Golden Firsten, that's how they prove their upper bound for volume. It's actually a very nice proof. They pass on to circumference and circumcision of tetrahedrons, and they're able to say that for every crossing, they have that many tetrahedrons. Okay, so let's uh 7:30, and if you signed up for a 10-minute talk, then you're not going to be able to do it. Oh, I still like free.