All right, thank you very much. It's my great pleasure to present my recent work here. And thank you for the organizers and then the participants for coming and for inviting me and for coming. Okay, so today I'm going to talk about some recent research development on the low-rank tensor approach simulating the non-linear high dimensional velocity. The nonlinear high dimensional velocity systems. The property we are looking into here: one is that we try to represent the high dimensional function, the kinetic solution by the low-rank tensor format to reduce the computational complexity, mitigating the curves of dimensionality. Secondly, is that the highlight of our work is that we want The highlight of our work is that we want to preserve the macroscopic conservation laws in the local and global fashion, and we term it locally macroscopic conservative property, which it is short for low-mac property. And this is the joint work with Weigo from the Texas Tech University. All right, so I'm going to start from introducing the kinetic equation. From introducing the kinetic equation, of course, all of the audience know about the equations. So I'm going to be brief here. And I'm going to highlight the computational challenge here is the curse of dimensionality. At least this is one of the computational challenge. And our approach is a so-called approach, to sorry, the low-rank approach to represent the high-dimensional kinetic solutions. So it starts from So it starts from our work maybe two years ago about this low-rank representation. And then recently we built in this low-mack property to preserve the macroscopic conservation laws. I'm going to explain the idea in a very simple 1V setting, but that idea could be extended to high-dimensional problems by the so-called hierarchical Tucker tensor representation. Along the way, I'm going to present the numerics and then finally I'm going to conclude with a summary and future work. And this is the system we're considering the Velassov equation. And in the general, there's a Velassov Maxiwell equation, where the F is the probability density function for the charged particles for the species S. And so, as we know, it's a 60 plus tonproprop. It's a 6D plus ton problem with 3D in X and 3D in V. And this Velassov part describes that the charged particle they move with the velocity V, and their velocity are meaning accelerated or decelerated by the electromagnetic field, which are determined from the Maxwell equations. So there's a nonlinear coupling between the velocity of the Maxwell part. And the curves of dimension. And the curse of dimensionality is the fact that if you have a 6D problem and each of the dimensions, if you place n number of grid points for a mesh-based method, then in the antigen computational complexity is n to the power of d. So the dimension d is on the power of n, and that is the well-known curves of dimensionality. curse of dimensionality. So it's well known that the particle method is a great method to overcome the curse of dimensionality, the particle in cell. Yet it suffers from the initial sampling, the statistical noise. There is also the sparse grid method, which has significantly reduced the computational complexity, yet it is still quite expensive for. Still, quite expensive for high-dimensional simulations. And what we are touching on today is the low-rank tensor approximation for the velocity of solution. And there has been many efforts before us in exploring the low-rank structure, either for the velocity of dynamics or for in general, the kinetic solutions. So, for example, there is the dynamic low-rank approach for the velocity of similar. Low-rank approach for the Velasov simulation from NCAMER and Lubik back in 2018. And after that, there has been a few efforts in preserving the massive momentum, for example, in this 2021 work and also by Jing Wei Hu and her collaborators on applying the low-rank approach, the dynamic low-rank approach to. The dynamical rank approach to multi-scale collisional kinetic systems. And what we want to say here is that the approach I'm going to present you is a so-called low-rank tensor approach. It's a parallel and independent development from the dynamic low-rank tensor approach. And what we are presenting here is for the velocity of dynamics. And a unique feature here is that for the high-dimensional problems, High-dimensional problems, we use a hierarchical dimension tree to further reduce the computational complexity. All right, so what is the idea? So this slide probably is the most important slice in understanding the approach. I'm going to present the idea for a very simple 1D, 1V velocity Poisson system. Okay, so for a Velasso-Poisson system or 1D1V solution, we can imagine our solution function f is a function of x and v. And if we assume that we use endpoints in the x direction with the index i from 1 to n x, and then we use another n grid points in the v direction with the index j. In the V direction with the index J running from 1 to N V, then our solution F at this grid point could be viewed as a matrix Aij. And for each of this matrix, it made a singular value decomposition. And this part, we call it U1 in the singular value decomposition. Each of these columns, it represents It represents a discrete approximation to the solutions in the x direction, the basis in the x direction. And each of the rows on this u2, it represents approximations to the basis in the v direction. And then the singular values here, they are the coefficients. And imagine that in the extreme case, let's say, Extreme case, let's say we have only rank one singular value decomposition, that means that our solution could be represented by a column vector and tensor product with a row vector. And if you have rank R, so it's a summation of them. When the rank R here is much less than N, so this is the scenario where it is a, there exists a low rank. There exists a low-rank approximation to the solution in this discrete format. Again, the columns here represent the orthogonal global basis for the x-direction here, and then the row vectors, they approximate or represent orthogonal and global basis for the v direction. It has a corresponding It has a corresponding decomposition, so-called the smich decomposition at the continuous level. It means that the function f as a function of x and v, it could be written as a linear combination of separable functions, u1 of x multiplied by u2 of v, and then taking their linear combination. When r here, the When R here, the rank of the problem is much less than n, the resolution in each of your directions, then it represents a significant saving in a computational complexity. And this is becoming more and more significant if we consider a higher dimensional problem, say one 3D, 3V problem. So we can see a very significant saving there. All right, so this is the important assumption. The important assumption in devising our algorithm. With this assumption, then at each of the time level n, we will write our solution into this low-rank format. And the basis in the x and v direction, as well as the coefficient, they're all time-dependent. So it's all depending on n, the time level here. So, for example, for 1D. So, for example, for 1D1V velocity Poisson system, the equation looks like this. And we assume that the initial condition admits a low-rank format, which it is true for many of our test problems, then the F0 of X and V, we could write it as a linear combination of separable functions. This is in a continuous format. Now, imagine that if we only use a simple forward Euler discretization to this Velasso-Poisson system, then our updated solution, which is Fn plus one, it will be Fn, the Fn plus one will be equal to Fn, which has this low rank representation minus delta T V F. V F sub X, where we can bring the V, this multiplication operator to the basis in the V direction, where we can take the X derivative to the basis in the X direction. In that way, the discretization of this V F sub X, it also admits a low rank format. The same thing applies for the other term. applies for the other term e of x and f sub v, where we can let the e multiply by the basis in the x direction, where we can take the derivative of the v basis. In this way, in this forward Euler discretization, the rank of our solution will increase from rank R to rank 3R because of these two extra terms. Two extra terms. So, this is what we call the add basis step, and we can do the spatial discretization, dx and dv by the Wieno method or by the discontinuous Galurkin method. So, that this that we could do all these high-order discretizations on those basis, but the important thing is that they are only performed in the one-dimensional. In the one-dimensional basis, that leads to the saving in the computational complexity. So, if we only have the add basis step, then you will imagine that the rank will increase every time threefold. And then very quickly, we lose the low rank structure. So, the second step is very important. The second step is that after you add a basis, we will do a singular value. A singular value truncation to keep the rank of your solution low. So there is the SVD type truncation to remove the redundancy in bases. Oh, sorry, I used to have a very nice figure to show how it works. So if you have some extra, so in each of the step, you originally have rank R. Originally, have rank R. In the add basis step, you will have rank 3R. And then you can perform the SVD type truncation to remove the redundancy of the basis. So, for example, for the bump on tail instability problem, if we set our truncation thresholds to be 10 to negative 4, and the rank of the initial condition, in fact, I think it starts from rank 2 or rank. From rank two or rank, it's very low rank. And as you see, with the time evolve, the rank of the solution will increase gradually. And this is with such a resolution, 64 multiplied by 128. So, for this test problem, you can see that our method could capture the dynamic of the rank with the With the solution, and we can also accurately capture the solution very well. Jimei, just a question. Are you doing their dimensional splitting? No, we didn't do any dimensional splitting. So if you see this, we add in this forward order step, we add these two all together. This is a shorter presentation that I prepare, but in a longer version, I will show that our actual time discretization is a second-order multi-step method. But we do not do any dimensional splitting. Thank you. Yeah, thanks for the question. I wish I have the other slides to show the reduction. slides to show the reduction on my rank. Okay, so just to summarize, our method is low rank and it's rank adaptive, meaning that if your solution stays low rank, our algorithm will be able to capture such a low rank structure. For example, if it is a weak land out damping example, you will see that the rank of the solution will stay low all the time, probably throughout. Probably throughout the simulation, all the way to t equals 60, the rank of the solution will remain maybe three or five, very low rank. It mitigates the curse of dimensionality. So in the 1D1V test, you will see that if we increase, if we double our mesh resolution, our CPU term will only increase slightly, will only doubled, but not 2 to the D plus 1. 2 to the D plus 1. It's high order accurate in both spatial and temporal accuracy. However, our S V D truncation step does destroy the conservation laws because we didn't do anything special. And there is the conservation law. As we all know, when we take the moments of our kinetic solution, we will see the macroscopic moment equations. And we will see that the macroscopic mass, moment, and energy, it should be considered. Momentum and energy, it should be conserved. And so, we know that there is an intrinsic local conservation loss there. However, the mass momentum energy conservation is lost in the SVD truncation step. So, that's our follow-up work where we propose a conservative singular value truncation. So, what is the idea? So, what is the idea? The idea is that every time when we add the basis, we just directly remove the redundancy by SVD truncation. But now we want to be a little bit more careful. And what we did is that after we add a basis, we will do a projection step, a projection to a subspace that is spanned by one v and v squared. V and V square, and that subspace it represents the principle to preserve the mass momentum and kinetic energy. So what we are doing, what we are going to do is we are going to project, we are going to perform an orthogonal projection onto that subspace first and obtain F1. And then the remainder term we call it F2. And that remainder term F2, we can perform. term F2, we can perform the singular value decomposition. We can perform the truncation based on the singular value decomposition there to remove the redundancy. So in that way, we could preserve the mass moment and energy from the pre-pre compressed solution. However, in the updated, in the add-based step, the original kinetic solver is mass and momentum consistent. Is mass and momentum conserving, but it's not energy conserving. So that's one comment. So, in order to do the projection, we introduce a proper inner product space with the weighter function that is a maximum value just to ensure the proper decay in the velocity direction. And in that way, through the computation, the F1, the projection step, it actually admitted a very simple structure, a low-ranking structure. Structure, a low-ranker structure that is the F1, it's a maxillum, which is the weight of function multiplied by a ranker 3 tensor, which consists of this C1, which represents the conservation of the mass. So you see that the coefficient is related to the macroscopic mass density. The C2, the coefficient, is related. coefficient is related to the macro the conservation of momentum or the charge or the current density J and then the C3 is related to the conservation of the energy and this F1 it could be explicitly expressed in this simple rank III form and it preserves the mass and momentum and energy the F2 part actually it has a zero macroscopic Has a zero macroscopic density, mass density, current density, and kinetic density. And we will perform a weighted SVD truncation on that. So we will see that the result that the bump on tail instability problem with the truncation, with the conservative SVD truncation, we were able to conserve the total mass. Conserve the total mass and total momentum at the level of 10 to a negative 12, around that level. And that level is not the machine precision, basically because of the boundary. However, the energy is still not preserved. So that comes to our third development, which is the locally macroscopic conservation scheme, which we simultaneously. Which we simultaneously evolve the conservation laws, the macroscopic conservation laws with the kinetic equation. And in particular, we evolve our F solution by our low-rank approach. And meanwhile, we use our F solution to compute the flux terms in the macroscopic conservation laws in a flux difference manner. In that way, our macroscopic. In that way, our macroscopic row J and E will be locally conservative and globally conservative. Once we have the row J and E updated from the macroscopic system, we will use it to feedback into the F1 part and then to ensure that our F1 is locally and globally conservative for all this macroscopic conservable. Macroscopic conservables. So, with that projection, we will be able to see that for the same bound point instability problem, we able to preserve the momentum and energy at the level of the machine precision. It's beautiful conservation, although the singular value decomposition truncation thresholds are made to tend to negative four. I see that I'm running off the time, but this is a very brief. But this is a very brief remark that we extended those approaches we talked about in the 1D1V setting to the 2D2V setting by the tensor approach, that leads to the computational complexity that is linear with respect to the dimension. So, for example, in the add basis step, we will have this hierarchical dimension tree to in the add basis step. In the add basis step, and then we will perform the corresponding high-order singular value decomposition for high-order tensors. And in the end, the computational cost is linear with respect to the dimension of the problem and is polynomial with respect to the rank of the problem. So it's r to the fourth. And we also incorporated the local mass and momentum energy conservation into this tensor approach. Into this tensor approach. And let me present you our solution for the weaker land out damping case for the 2D2V. And as you can see on the left, I present you how the rank increase with respect to the time. And then the highest rank we observe in this 4D problem is about 13. And we capture the exponential decay in this. The exponential decay in this 2D2V problem that we can land out damping. And we also want to say that every time we double our mesh resolution, so 16 multiply 16 by 32, every time we double our mesh resolution, our CPU term only increased less than doubled. So that is very, very significant. And that represents that our computational Our computational complexity only increases linearly with respect to the dimension. And the previous computation, this is without the conservation projection. If it is with the energy conservation scheme, the computational complexity is much larger. But still, you can observe. But still, you can observe that every time you double your mesh resolution, your CPU time only doubled or even less than doubled. So this is the computational complexity that has this D in the front. And we also observe that the total mass, moment, and energy they are conserved, globally conserved and locally conserved at the level. Conserved and locally conserved at the level of machine precision. In our original paper, we also have the simulations for the strong land out damping for the 2D2V simulations. So if you're interested, you're welcome to read about our paper, which is available in the archive now. And we also have the low-MAC, low-rank tensor approach with the DG discretization. We are currently working on We are currently working on the multi-scale low-rank approach for the Fokker Planck collisional operators. And it is our current and future direction to consider the implicit solver in this low-rank approach. Also, coupled with the dynamic low-rank approach with the asymptotic preserving properties and environment and to preserve certain. and to preserve certain physics laws to building a structure preservation in this low-rank approach. So with that, I will stop and I'm sorry for such a rush presentation, especially towards the third part. Thank you, Dime. Questions? Comments? Hello, thanks for your talk. I have a couple of questions. First, I'm wondering why do you use a Dagger format and don't use something like Tensor Train decompositions or other sort of Tensor format? Yeah, Tensor Trend, that's a good question. So because we kind of feel that for this 3D, 3V, there's a very natural decomposition between the X and V direction. Transition between the X and V direction. And if you were using the tensor trend, there is this kind of all the dimensions are the same, right? You have this structure. So the short answer is that that's a great suggestion and it's a good direction to try. But in our initial effort, we adopted such a dimension tree structure. Okay. And the other question is: I'm wondering, do you have any Do you have any intuition on what are the features in your program that would make it suitable for a low-rank structure? I'm thinking, for instance, I know that for other PDs, the fact of having no locality will mess with the composition. Right, right. That's a very good point. So, in fact, one comment I missed to make is that this Is that this Velassov operator has a very tensor-friendly structure that makes the low-rank approximation, and that it's a very good tool for this Velassov part. And if you on the right-hand side, if you have some other collisional terms or some other non-local terms, so then new considerations have to take into account. Thank you. Thank you. Thank you. There are more questions. Hi, my name is Hanji. Thanks for the very nice talk. I also have a question about the rank. So your algorithm considers like adaptive rank, right? If I understand correctly. So if, let's say, in your evolution, you actually have increased rank, and then for some later time, the rank decreases. The rank decreases, would you consider removing some of the bases, or do you always keep the amount of bases that you add? No, the bases will be removed. So if your problem, so the idea of this approach is that it will automatically capture the rank increase and decrease in the SVD truncation step. That SVD truncation, it tells you: okay, in this time step, what is the optimal data sparsity? Optimal data sparsity. Okay. And that's a good contraction into the other approach, with the other approach, the dynamic low-rank approach. The initial development has the ranker fixed, but of course, now they also have the new development of adding the rank and so on. I see. Thank you. You may, I have a question too. How do you compare with because of the market? You compared with because of the land that you were, most of the samples you did, they were not coupled really, no, with Poisson or of course not Maswell. But how you compare with kind of spectral methods and say, I mean, that we are they are supposed to be super accurate. So, I mean, just curiosity. Yeah, okay, that's a very good question. And we did try. That's a very good question, and we did try. So, first of all, it is coupled with the Poisson. Yeah, just that I didn't mention it. And the way and his student also do the philosophy of Mexico. And you will see that our original, we did try the with it. So this low-ranker framework, it's very general. So I put a dx and dv here. DV here, and so basically, you could do any DX DV that is your favorite. And for example, one of our recent paper is DXDV using the DG method. Well, we claim that we can have some like the flexibility with respect to the grid. And the original paper DX and DV is a winner method. And special method we did try. It try and so the spectral method will work well, I think, except that if you have if you have kind of if your resolution is not enough, then you will have oscillations and it's hard to filter it out. Yeah, but but if your problem you think it's a good problem for a spectral method, then yes. Then, yes. Okay, thank you. So, any other question or comment? Well, if not, let's thank Jima.