So what I'm going to talk about, I'm going to talk about today's learning and ranking research topics in statistics. So this is in collaboration with Peng Shengxi at the University of Georgia and Tracy Ko, who is one of the organizers of this conference, and also Wang Shan Li. There are many problems we can talk about, study about on the statistical publications. On the statistical publications. For example, what are the representative research topics in statistics? So people may say, okay, there's base, there's experiment design, this variable selection, and so on and so forth. But how to identify them? And how many of them? The secondable, how does the logic and ideas disseminate across topics? Like, for example, from base to variable selection and then variable selection to experiment design and so on and so forth, and how to rank this. Supports and how to rank these topics by their impact. We can study this by the MATSTAT data set our group recently collected and cleaned. MATSTATA stands for multi-attribute data set on statisticians. So compared with existing data sets, there's several differences. First of all, many existing data sets like in the machine learning literature, they are kind of just one attribute. They are kind of just one attribute. For example, there are some data sets on the citation only, and there are also other data sets on the text document only, but our data set is like we have like the text, we have citation, we have for co-authorship and all kinds of information. And the second one is about the paper level attributes. We really download the information of each paper. Okay. And so this data set consists of 83,000 papers, about 47,000 authors in 36 journals from 1975 to 2015. And basically for each of these paper in this range, we download everything except the main content. The main content of the paper is very long, but everything else we download. Like from the first line is title, the second line is author and affiliate. The secondized author and affiliation to abstract keywords and MSC subject classification and references. We download all these. So these are the big text information. But aside from that, we also download the citation relationship, like which paper cite which paper. This data set takes a really long time to collect and to clean, especially to clean. It takes really, really long time. But the good news is it's now freely available to everybody. Freely available to everybody who is interested to use it. You can either go to the Traces website or the journal website. Okay, so these are two main papers we published based on the data sets. There are many things you can do. For example, in different talk, I may talk about the statistic triangle. I may talk about the like mixed membership late work, so on and so forth, and the causeship trees, on and so forth. Trees on so forth. But for today, we are going to talk about a topic we have not discussed a lot in the past. Okay, so this is about the journal ranking. Okay, we started with the journal rankings, then we are going to extend it to more broader context for copyranking. So for journal rankings, one of the most popular methods, the so-called stigler's model approach, actually, this is not only due to if the model is also called The model is also called the Bradley and Terror model. And so basically, for the model, it works as follows. For each journal, we have an export score. This is a scalar. So if M journal, in our case, M capital M is 36. So each of the 36 journal, each of them has a export score. Other score is Audio score is regarded as more influential or rank a rank top more on the top. Now, when a paper I in journal K, for example, K is Annals, and another paper J in journal M, let's say JASA, okay, when they interact with each other, means, okay, so one side other interacting means I side J or JSA. Given that the chan, there's two possibilities, GSA or I side. Possibility J sat I or I sat J. So this is a kind of a logic model. It's like the probability of J sat I given them interact is given by this probability. Okay, for example, in this case, J is, okay, so J I is anos. J is JASA. So mu k mic mu m. If an old mu k is bigger than JASA, then this is the positive and the probability bigger than one half. Otherwise, it's smaller than one half. one half otherwise it's smaller than one half so therefore this model says if the general if anodes is is uh have a bigger is poor score then every time when i and j or i from anode and j from journal when they interact the chance that j sits i is larger than okay is larger than i sat j okay so this is a stigma's model okay now here's the results okay on the x-axis we have applied two methods one Applied two methods. One is the Stigler's method. We just use this model and feed and use all this citation count data to feed this mu n and use the mu n to rank all these journals. So this is the x-axis. The y-axis actually is the ranking provided by the layer page, page rank, which layer pages, which is famous ranking method used by Google. It's very successful. Okay. So you can see here, for example, So you can see here for example annos here. So both methods rank it as number one. JISA, okay, so stickers method ranked as number one and the page rank ranked as number three and so on and so forth. This is analysis, JIASA, GRSV, Biometrica, Journal of Merchant Learning Research, Biometrics, Statistical Science, Biostat, Bernoulli, and so on and so forth. Okay, so the main interest today is try to My interest today is try to extend journal ranking to topic ranking. So, topic ranking is very little studied. We're actually not aware of any literature before us. But in order to rank different research topics, there's three things are all unclear. First of all, it model. To study topic ranking, only using the citation data is not enough. We must also use the abstract data. Also, use the abstract data, but so far, we do not have a model that can jointly model the citation data and abstract data. Abstract is a text document here. Okay, so we do not have a model. And also, the concepts is also lacking. We do not have the reviewed concepts. The reason is when paper I in annals and size paper G in JISA, we do know which journal sets which. But when this are paper I, When this is a paper I sign paper GA. Paper I has a whole bunch of topics. It may be talk about Beijing, it may talk about the variables selection, it may talk about experiment design, and GA is the same. We do not know when I set GA, how much experiment design is citing variable selection. So therefore, the concept is also unclear and also the method is also unclear. So our approach is as follows. Our approach is as follows. First of all, we propose a new model called Hoffman-Stigler's model as a new model jointly modeled abstract which takes documents and the citation data. And especially, we introduce a new idea to define what do we mean on topic, topic, citation, one topic cites another. And then we introduce a method called topic ranking, which motivated a recent topic score debated by Kuenwang. So the main things, the main idea. So, the main things, the main ideas here. So, this is about Hoffman's model, it's very popular for text document analysis. Sticker's model is very famous, popular for ranking. But this idea is going to join these two things together. So, we can really combine two data resources and study the ranking, the rankings by topics and topic citations. Topic citations. Okay, in detail, we have three slides to introduce the model. Okay, so the first slide is we're going to introduce the text side, the text document side. Suppose we have M paper abstract, each of them, the words are from a size P dictionary. Okay, so in total, there might be like a little bit over 2,000 words we use in all these abstracts. So dictionary size is about 2,000. And the citation counts, we have n papers. Okay, so the size of the text document or the length of the document is n sub 1, n sub 2, up to n sub capital N. Okay, so this is length of different text documents. For the ICE document, word J. Okay, so this is the index, this is index for the text document, this is the index for word. This is an index for word. So dij is the empirical frequency word j in text document i. We are using a multilomial model, say ni multiply di is p-dimensional vector, okay, because p-dimensional, because p is a size of a dictionary, is a multilomial with this ni and with this vector of probability. So this is a p-dimensional probability vector. So if every entry is long-negative and there's some point. Every entry is long negative and there's something one. This vector is defined as follows. Okay, first of all, since the parameter k is a number of research topics. So later for our head, we believe k is 11. Okay, we're going to explain that later. And wi is for each text document, we introduce a k-dimensional. You can think of 11-dimensional weight poppy. So you give them paper. So you give them paper, so it may have like 20% on base, it may have 30% on variable selection, 10% on experiment design. Okay, so therefore, this double I, you can think about 20%, 30%, 10%, and so on and so forth, 11 dimension. Okay, now the keys introduce capital K different vectors. Each of them is p-dimensional, a1, a2, up to a capital K, A sub capital K. Each of these A Capital K. Each of these AK is a PMF on probability mass function. It is actually the text document. When the text document is a pure document on topic K, then this is a multilomal parameter vector for that pure document. So here's the concept pure document means this document is pure, means it only discuss one topic. It does not depend on discuss any other topic. Any other topic, only discuss variable selection, for example. Then, corresponding to variable selection, let's say we have A sub 3. So, A sub 3 is P dimensional vector, and which is the PMF for this multilomial when this document I is a pure document. But of course, most of the documents are not pure. So, therefore, we are going to take a weighted average. For example, this is A1 is a pure document, very slightly. A1 is pure document variable selection. A2 is a pure document in base. And this document, they have 20% in base and 30% in variable selection. You basically just weighted of them. And then this becomes still a p-dimensional vector. And it's also PMF. In matrix form, you can always write this. So D1, D2, DN as a P by K matrix times. As a p by k matrix times a weight matrix. So we call these p by k matrix a topic matrix. These are the topical weight matrix. We are both interested in. Okay, so p is a dictionary size, capital N is the number of documents, and the K is the number of topics. The second part, the key part is recall Wi is a topic weight vector. For example, Wik is the weight paper I put on topic K. For example, you have a paper. So Wik costs 20%. WIK equals 20% if this document has 20% weights on variable selection. Okay. Now, when paper I is cited by paper G, we say topic okay is cited by topic M. Okay, topic okay, so I has topic one, two, three, up to 11. J also has topics one, two, three, up to 11. Now we pick topic okay, this is the variable selection, and M as an experiment design. So when paper I size When paper I size paper J just one count, this is one integer, one times of citation. But we say that the topic K in this case is cited by topic M with the topic weight in the site T multiplied the topic weight in the citer. For example, in this case, I is cited by G. Okay, so I being cited. So I the cited and J is a citer. Okay, for example, this may be one third, this one maybe one. Maybe one third, this one may be one quarter, so multiply to get one twelve. Okay, so when I set it here for one times, we only count the topical case side of the topic of main by one over 12 times. Okay, so this is the main idea. With this idea, we can just talk to modeling, Hoffmann's cost modeling with Spick's model. So this model now is very, very similar to Stickler's model, except, okay, so this is the same as before. So, this is the same as before. But now, the new notion is the paper I has a weight vector. We use this weight vector to compute a new export score. So this is overall export score of this paper I. Now, this formula is very similar as before, but before we have mu sub k minus mu sub m here. When paper i is journal m, the journal gain, journal k and the paper j is for journal n. Now, but here we Now, but here we replace them by a weight, weight vector times mu and a weight vector times mu. Okay, you can compare these with these. Okay, so it's very, very similar, okay, except there's no w here, okay. There's no w here, okay. Now, if you combine this together, we do have a new model, okay. Now, the remaining things is how to fit them, okay. So, the topic ranking, uh, the idea is as follows: so we have As follows. So we have two steps. We have four steps actually. The first step input all these word frequency vectors. So this is for paper one, paper two after the last paper. And the citation, a GSS matrix, this is the binary matrix. If you have a thousand papers, then this is thousand by thousand. If I cite J, then Cij is one and otherwise zero. The first step, we need to determine the number of topics K. number of topics k once the topic k is determined you can just use the topic score algorithm the next space estimate the topic matrix a once a is obtained you can just estimate the weight for paper i by the region regression okay so the region regression okay so now we have all this wi we can just go back and plug in here you can plug in here so then you can just use the citation cons to feed for this mu okay To feed for this mu. Okay. How to do that? We are going to talk this a little more later. Okay, now we plug in this W, we use the citation data to feed for this mu hat. Then we just rank all these topics by the fitted values, mu1 hat, mu2 hat, and mu k hat. For example, in mu1 hat is one, mu2 hat is 0.9. So mu1 hat is bigger with a better rank than mu2 hat in this case. Okay. Now the topic. Okay, now the topic score is a method for topic learning proposed recently by Tracy Ko and Minjou Wang. Okay, so the basic idea is goes as follows. I do not have time to go into the details of spectral algorithm and it's very fast and it's also recently proved by Ko and Jimmy Wang to be rate optimal. Okay, so this is the main idea. Okay, so to use this To use all these algorithms, the first step, of course, is to determine the number of topics k. For our data, we argue that k equals 11. We are going to explain why. But before, let's first present our result for k equals 11. And then a little while later, we are going to explain why we think k equals 11 is the most appropriate choice. The first result we're going to present is about the so-called anchor words. so-called anchor words. To determine the K and to label all these topics, we need to use many, many approaches. And anchor words is one of the several approaches we use. One is anchor word. A word is anchor word for topic K if it appears only when we discuss topic K and is unlikely or never or at least unlikely to appear when we discuss other topics. For example, you can think about For example, you can think about La Soul is an anchor word for variable selection because whenever we discuss, okay, whenever we discuss La Soul, it almost only appears when the topic is paraprosletian. It rarely appears if you discuss other topics. Similarly, you can think about the prior is anchor word for Beijing, so on and so forth. Now, remember, this matrix is This matrix is p by k. P is the number of words, so each row is a word, and k is the number of topics. Now we fix a word j. We let this be a row of a hat. We normalize it. Okay, we normalize this row so that it has a unit L1 norm. Then, for example, if A had JK, it's very big, it's very close to one. It's very big, it's very close to one because the L1 norm is one, so therefore, all these rows of this vector sums to one and it's also non-negative. So, if one of these entry, one of the entry of this row, of this vector is very large, close to one, then we would say word J is possibly anchor word for topic K. Okay, for example, if a K is very selection J is lasso, then you would expect this number to be very large, but A. Number is very large, but AJ hat on other entries is nearly zero. Okay. For example, A hat G M, if M is Bayesian, this is probably very nearly zero. Okay. Okay. Anyway, so now for 11 topics, we are going to report in the next slide, we are going to report the 20 words that have the largest AGA to high K. Okay, for these 20 words, okay, they are. These 20 words, okay, they are this vector, the corresponding vector of AJ had highly concentrated on one entry. And that entry, we think, is a means that word J is an anchor word for that topic. Okay, that entry is a topic and J is a word. Okay, now let's see what happens here. Okay, so we have 11 topic. It takes a long time, a really a lot of effort to label them and how to label them. To label them and how to label them, we are going to discuss a slides later. Okay, so here we have 11 topics. We can label them with the debates, biomedical, clinical trial, experiment design, fabsis testing, inference, latent variable, machine learning, mathematics, statistics, regression, and time series. Okay, for example, base. You can see what are the anchor words, anchor words we identify. Parameter, loosence, conjugate. Lewis conjugate improper prior, two parameter, reparametation. For example, for regression, we have regress, regressor, regression, single index, back fitting, cook distance, coefficients, slide. For example, for time series, you have time, series, failure, and onset, weight, repair. And for machine learning, you have metropolitan. This machine learning actually refers more. More like statistical machine learning and is heavily overlap with the Monte Carlo, Markov T-Monte Carlo algorithm. So you can see a lot of words here. Okay, so this and uncle words. Okay. So why we think k equals 11? Actually, from the script plot, we cannot deduce that. This is a script plot of the singular values. We can only say maybe k equals 4 or something. Okay, k equals 4. Okay, 4. equals to 4 okay 4. But we then try for k equals 4 to 16 and for each of them we are going to make this plot. We are going to make this plot. For example, if we for k equals 16 we have 16 panel of this for each of them we print all these top 20 anchor words then we try to label based on the anchor words and our inside information as a statistician about the community As a statistician about the community, we try to interpret what this topic is. So we go back and forth for many, many rounds. It takes many, many days. And we finally decide K equals 11 is a reasonable number of number of topics. And also, these topics can be labeled as this. So this is the way how we determine K and how we label these different topics. Okay. Okay, so the next result. Okay, so the next result I want to show you is that our algorithm not only presents all these anchor words, but it also gives you an estimation of these topic weights. So for every paper, you have 11 dimensional vector wi. Okay, that's your weight in different topics. For example, wi can be 20% Bayesian, 30% invariance lecture and so on and so forth. And environmental selection and so on and so forth. Now, an author A, small A, an author A, they may have many, many papers in this data range. So for each paper, this author, for example, Jian Jingfan has 100 papers in this range. So for each of these paper, he has 11 dimensional vector. That's the topic weight vector. We take the average. So this becomes Jenga Fan's weight vector over average over. Average over all these over 11 topics. Now, for convenient, we are going to standardize each of these WA hat by the overall mean of all those papers in 87,000 papers. Okay, so therefore, the sum of these vectors one and it's low negative. The sum of this vector, the different entries, sum of different entries, this vector now is not one, it's zero. Okay, it's zero. So sum of the Is zero. So some of the entries is positive entries is negative. The positive entry means this author, Jianqinfan, has more weight than an average author. So he has more focus on that topic. If an entry is negative, it means Jianqinfan has less than average focus on that topic. Okay. So here is Jen Qingfan's vector Z sub A. Okay. Z sub A. Okay, here's David Donahoe's G sub A. This is the Michael Jordan just being used. So you should look at, we should look at the positive ones. Positive ones is their focus. For example, Jianqing is very focused on regression. Mike Jordan is very focused on machine learning. Bing Yu is very focused on machine learning and also verse selection. Okay. Variable selection, okay. This variable selection regression is a little bit overlap, so this is like more kind of for this variable selection is more kind of for classical variable selection, like the large and small p regime. Okay, so the modern regression is basically here, the modern regression is basically here, okay. Okay, and Donahoe is more spread out, okay. So this is the research image, okay. So I only have four minutes left, okay. I only have four minutes left. Okay, so let me finally talk about how to do the topic ranking. Okay, so recall set the two paper I and GA. So this is our model. This is the Hoffman's and Stigler's model. It's an extension of Stigler's model by incorporating Hoffman's top weights. Now to SN Mu, we first use the citation matrix. We first, okay, so to SMU, we use a C. Okay, we first use the text document. We first use the text document to do a text learning to find out the topic weight for different papers. Then we plug it in. Now, using this C, we can refit for this mu1, mu2, muk, okay, in detail in the next slides. And then we rank all these topics according to the mu1 hat, mu2 hat, mu k hat. So the details here is a little bit tedious. Okay, we use a quasi-likelihood. So I'm going to skip these slides. Okay, so here's a Skip these slides. Okay, so here's the results. So here's the result. This is 11 topics. Okay, you can see that the export score of mathematical statistics actually is very large. Okay, it's compared to other methods actually very large. Because you know, this mathematics studies is about like a series in high-dimensional data analysis about MLE likelihood ratio and fundamental testing procedures and so on and so forth. Procedures and so on and so forth, they do have a lasting impact. The second one is regression, and this one is multicolored, Markov chain, or machine learning, and inference. Experiment design zero is not actually zero because for our method, we have to estimate one degree of freedom. So we choose the topic in between to set it as zero. Okay, so this is okay, set a zero. So clinical trial and biomedical research. So, clinical trial and biomedical research in this export score is lower compared to mathematical statistics because our journal is primarily on statistics, not about the clinic trial, not about a biomedical study. So, you can imagine that the idea is more like flow from mathematical studies and regression to the more applied areas like a clinical trial and biomedical. Okay, so this explains why, okay, the expert score and ranking. Okay, so ranking. Score and ranking okay. So, rank is one to three up to 11. Okay, of course, our model including the original Stigler's model as a special case. So, therefore, we can really just using our model for the journal ranking. We are going to produce the same result as before. But for journal ranking, we do not use the text data. So, this reduces back to the stigma's model. So, last, we are going to present a figure to you is about a cross-topic citation graph. So, immersion. Topic citation graph. So, in machine learning literature, the citation graph, or so-called low-lid graph, describes how the lowlid flows from one area to the other. So, it's a visualization tool. To calculate this graph, we are going to construct this kind of directed aid from topic K to topic L by this. And NKN is the attribute of citation from topic K to topic M. So, to So, to calculate this number, we have two ways. One is just use the topic weights. We estimate it using text document and the citation counts. But this one turns out the give figure is less interpretable and more noisy. So, we eventually choose a winner takes all strategy. For example, if a paper, this is a paper, I, it has 11-dimensional weight vector. Weight vector. We pick the entry, the maximum entry as the topic. So, for example, if the paper is 30%, 20%, 20%, 10%, so the 30% is Bayes, we think this paper is Bayes. So after that, we just assign each paper as one index, one index in 1 to 11. Then, according to the winner's tax all, we counted and Takes all. We calculate NKM, then we calculate PKL, and this is the figure. This is a direct graph from between these 11 topics. Experiment design is isolated because the age goes in and 8 goes out. The weights are both pretty small. So it's non-zero, but it's smaller than 0.09. So we remove the 8. So it's not displayed, but it's actually the 8, it's not zero. Okay. So this kind of log. Okay, so this kind of knowledge graph is very informative. For example, you present the graph to someone at the eight widths. Okay, the wider the eight means the wider eight means more impact. The narrower is a smaller impact. The direction means inference. Okay, inference goes to regression means inference side regression. So the regression so regression is export, inference in this case, it's import. Okay. So therefore, the So, therefore, the big circle in between is more influenced. The smaller circle is less influenced. This is even smaller. Okay, so you can see the regression and the mathematical stat is a lot of arrows goes in and is big. But this is actually not exactly the ranking. Okay, you can visually think regression is the biggest one, but actually, according to our model, mass stat actually is bigger. So, this is this is. Bigger. So, this is a good reason for that because here we only count the citations. But the Stigler's model argued that only ranks by counting the number of citations not good enough because sometimes you being cited by a top journal weighs more than being cited for a lower ranked journal. Okay, so therefore, this figure does not have to be consistent with this. To be consistent with this one. Okay. It's highly correlated, but it does not have to be exact the same. Okay. Okay. Anyway, I think I'm around of time. So I'm going to stop here. So I have, we, our group has collected and cleaned the large-scale high-quality data set and the publications of statisticians. It's free. Everybody interested, you're welcome to use it. And we also have code we would like to share for free. Okay. It's also the data and code also on the GitHub. Also, the data and code also on GitHub. Okay, we propose a Hoffman-Stigger model and the TR-scored joint model and analyze text data and citation data. We identify 11 topics in statistics built across topic logic graph and rank the topic in journals. So the result helps understand the research behavior patterns, impact of statistics, and help the DIN and the grant fund agency for decision making. And if you would like to And if you would like to read the paper more, so the detail is in this paper, and here are more also related paper. Thank you for attention.