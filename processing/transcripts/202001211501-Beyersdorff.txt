And this is joint work with Joshua Blinkor and Mina Mahajan, who is also here. So let me start by saying a few words on QBF, quantified Boolean formulas. So far we've mainly looked at propositional proof complexity, and of course the thing that we have here additionally is quantification, but just over 0 and 1, so weak quantification. And why would you be interested? And why would you be interested in QBF proof complexity? So, the first relation which has very much driven the field in the last couple of years is the relation to QBF solving. There's quite a bit happening in that area at the moment. And what I also find interesting is that you see different effects from propositional proof complexity. So it's just very interesting to see if things from propositional world just lift. Propositional world just lift and carry over, or if we see new phenomena, and that is also what this talk will be about. And then there are quite strong connections to circuit complexity, also to bounded arithmetic, and in particular this relation to circuit complexity will be what I'll be focusing in this talk. So maybe just another slide on QBF solving. So you all know that SAC solvers are doing a tremendous job. Doing a tremendous job. They are really very successful. People have talked about the SAT revolution. And it's fair to say that SAT, the main innovations, have taken place about 20 years ago. So SAT by now was a quite mature technology, works very well. And of course, it's a very interesting question how far can we push this progress? So can we also lift it to even more computational challenging settings like QBF or even to next time? Even to next time complete problems. And you see that in QBF we are actually at the stage where things are happening now. So it's reaching this, it's behind sight, of course, but it's reaching a stage of industrial applicability. And there's very much movement and new ideas floating around in the solving community and interaction to the proof complexity community. And that's what I really find quite interesting. So also these theoreticians can make an impact on what's happening in solving. On what's happening in solving because it's happening right now. Right, so I won't talk about solving anymore, but we will look at proof complexity. And of course, we need some proof systems. And we will be mainly looking at resolution here, the QBF version of resolution. And how do you get such a system? So you take propositional resolution and you add one rule that works on the quantifiers. So resolution is as before. So, the solution is as before, and then you have one new rule which is called universal reduction. And in this rule, you have a clause C which contains a universal literal, and you can adopt this literal provided that nothing in C depends on U. So, in other words, C does not contain variables which are right of U in the quantifier prefix. So, I should have said that in QBF resolution we are working with formulas which are unstable. We are working with formulas which are in C and F and are in prenex normal form. So we have formulas of this type. We have a prefix and then we have a matrix consisting of clauses. And just a very simple example here, you could resolve on x a resolution step, then you have the universal variable u and you can reduce it to the empty clause. But you couldn't have done the reduction on this clause, for instance, because here it's blocked on x. So the u, So the U, so the X depends on U, so you cannot draw U in this setting. Okay, and that's a sound and complete proof system for QBFs. It's actually also the first QBF system designed in the 90s. And you can do this in a much more general setting. So this idea of using a propositional proof system and adding this universal reduction rule and getting a complete QBF proof system. And getting a complete QBF proof system works quite generally. So, again, you fix a prenex QBF, and then if you have a line in your system, which for instance in Fregel can be just a propositional line, again you have a universal variable on which nothing else in the formula depends, then you can substitute u for 0 or for 1. So that's exactly generalizing this reduction rule that we had for resolution. And then what you can just do is you take any proof system. Can just do is you take any proof system P, a propositional proof system, and you get Q P by adding this one rule which is sound and concrete. And if you plug in for P resolution, then you exactly get the resolution system that you can get from the previous slide. So this gives a hierarchy of QBF resolution systems, which I would argue are also quite meaningful, and in particular, this distribution. Quite meaningful, and in particular, this distribution system is quite interesting because it relates to what's happening in solving. And now, if we want to study proof complexity in this setting, there's one observation which actually Paul mentioned already in his survey, that if you have a formula which is propositionally hard, say for the proof system P, then if you just quantify everything existentially, this will be hard for the system QP. This will be hard for the system QP. Also, that's inevitable because in this system QP, if you don't have, if you only have existential quantifiers, you can only use the rules for P and nothing else, so you carry over this hardness. So that's not really what we are interested in. So we are interested in reasons for hardness that come from the quantifier alternation. Or we could also ask differently what additional reasons for hardness do we find in QBF. It's clear that we find this type of hardness, It's clear that we find this type of hardness, but what else is happening? Now, what you can do is: okay, you could say maybe you just count the number of for all reduction steps, but you can actually find a neater and clearer model by allowing NP oracles in QBF pros. And let me just show you how this works. So I will call the system QP with an NP original. Again, P is a propositional base system, so you've got the rules of that. You have for all Rules of that. You have for all reduction as before, and now you have one additional rule where from any number of lines which you have previously derived, you can derive any semantic inference. So this is just a propositional inference. So that means you can collapse arbitrary propositional derivations into just one step. So it's even stronger than this idea of semantic resolution, for instance, because here you have arbitrary values. Because here you have arbitrarily many clauses. So, for instance, you would refute pitch and hole in just one step. Okay, so the motivation why we look at this is that this NP oracles allows us then to get rid of this propositional hardness. And it's actually also motivated by what's happening in QBF solving, because people also use SAT as oracles in that setting. So it's actually quite a natural setting. And now, what we want to understand is what are the reasons for hardness in this system. So, if you use these NP origles in QBF proof systems, as I've said before, you eliminate all propositional hardness. So, the question is, and that's the main question for this talk, what sources of hardness exist in these QBF systems? And these are really the sources of hardness that come because of quantifier alternation. Alternation. And the answer that we will give here is that these sources for hardness actually come in a very clear sense from circuit complexity. So quite a few of you might know this proof complexity theme song, which at gatherings like this is actually also regularly performed. And it starts with resolution, of course, and then there is a line which says. Course, and then there is a line which says no bounds for circuits play a role, where you notice connection isn't well defined. And this is kind of the theme of my talk here. So there are of course connections like this. So proof complexity versus circuit complexity. I mean, this figured already in previous talks. And there is a general belief in the community, I would say, that. I would say that there is a connection between lower bounds for proof systems that work on C circuits, so where lines are C. There should be a connection to lower bounds for the circuit class C. Now this is a general belief which I would say I mean has not really been made formal yet. Of course there are various settings where things like this work. For instance in feasible interpolation you import lower bounds for monotons. Lower bounds for monotone circuits, but it's not so clear what the monotone circuits have to do with the lines in the proof system. This works in a sense in algebraic proof systems. Ido also mentioned that in this talk this morning. But I would say that perhaps the clearest such connection happens in the QBF context. So there is a result with Jung where we have shown that if you look at Q Fregel, If you look at Q-Frege, so Frege systems plus this one new for all reduction rule, we can precisely characterize hardness by this dichotomy. So we can say that there exist hard formulas in Q-Frege if and only if one of these two possibilities hold. You have lower bounds, you have hardness for propositional Frege, or you have circuit hardness in the precise sense that you have lower bounds for non-uniform NC. Have lower bounds for non-uniform NC1. So exactly the formulas that the system works with. The precise condition is here that P-space should not be contained in non-uniform NC1. And you can recast this result by looking at this NP-Oragle model that I introduced on the previous slide and say that you've got super polynomial lower bounds for this Q freak with an NP oracle if and only if you have these solid lower bounds. If you have these socket lower bounds. Because here the first case is exactly killed by the NP origin. And this works also for other settings. So if you go to extended Friege, again we have hardness for QBF extended Friege under this n-pyroicle if and only if we have this hardness result for P4. Okay, so that's quite nice. But it doesn't tell us anything about resolution. So that's the problem that was left open by this earlier work. And the question, of course, is can we characterize QBF resolution hardness in a similar way? And this is perhaps the most interesting case, really, because as I mentioned before, QBF resolution corresponds to ideas in QBF solving quite similarly as propositional resolution corresponds to such. Corresponds to such solving. Okay, and what I want to show you today is that we can do this, we can achieve such a characterization by a circuit model, a decision list model, I will explain that. Using this, we can actually show a very neat size-width relation, which was previously not known. And this gives rise to a lower-bound method, which is really very easy to apply and elegantly reproves lower bounds that Lower bounds that were obtained otherwise before. Okay, so first of all, what's our circuit model? So it's a natural generalization of the classical model of decision lists that goes back to the 80s. So decision lists typically compute Boolean functions with one bit outputs, and we just generalize this to might be outputs. So let's say we've got input variables. So let's say we've got input variables x1 to xn and output variables u1 to um. Then a decision list is simply a bunch of if-then statements. So you've got a bunch of terms here, t1, t2, tk. These are terms in the x variables, so in the input variables. And you evaluate these terms. If they are two, then you set the u lock, the u variables, the output variables, according to the d's. According to the Ds, and these are total assignments to the humes. So it's a very simple model. You just go through the list, and one of the lines will trigger. The last one doesn't have a condition, so you also get an output. It's a very easy circuit model, which is actually well studied since the 80s. So we call this model unified decision lists. I'll explain in a moment why we call it unified. I explain in a moment why we call it Unify, but it's some version of multi-output decision list. And I would argue that these UDLs, as I will abbreviate them, they naturally compute counter models for false QBFs. So if we look at the solution, it's a refutational proof system. We want to refute false QBFs. So the QBFs are always fully quantified. And then what we want to do is Then, what we want to do is we want to compute a counter model for such a false QDF. So, let's say phi is our formula that has both existential variables x and universal variables u and let t be a UDL with inputs x and outputs u. Then we say that t is the UDL for phi if for each assignment alpha to the existential variables, we compute an assignment t alpha to the universal variables. To the universal variables, such that this phi defies the matrix of phi. That's the precise definition of a counter model. But of course, we also need to respect the quantifier dependency. So for instance, if you've got a prefix like this, then the value of u1 should only depend on the value of x1, not on x2. So you need to respect these dependency conditions in the UDL. Okay, and now And now, once we have this definition, we can actually state the result. So, let phi be a false QBF of bounded quantifier complexity. So, we have a bound on the number of quantifier alternations. And the size of the smallest QURS NP refutation of phi, so it's a QBF refutation under an NP oracle, is polynomially related to the size of the smallest QDL for phi. So, of the smallest. So, of the smallest decision list that computes a counterpoint. Or you can also express it equivalently, if you don't like this n-per-origgle, when you can say a sequence phi n of bounded quantification is hard for QBF resolution, if and only if one of these two cases happens, the phi n's require large UDLs. The X, or you have certain propositional hardness in the formulas. And actually, in our proof, we can precisely pinpoint what this propositional hardness is. So we can precisely identify steps or parts of the proof or parts of the formula which are propositionally hard. So the bound of the quantifier complexity, does it come into the exponent of the polynomial? What's the the bound of the quantifier complexity? That's right, yeah, that's right, yeah. Right, yeah, that's right, yeah. Okay, so let me just compare this to this previous result on QBF Frege. So in QBF Frege, we had, we characterized the hardness of Frege, where we worked with lines from C, from the circuit class C, precisely by hardness for C circuits, yeah? So N C one Frege was precisely characterized by lower bounds for N C one, P Poli, exactly by Pipoli Frege. Exactly by P4. This is a bit different here because in the solution we obviously work with CNF, so you can say maybe depth 2. And it's known by a result of Causen on decision lists that the complexity of these lists is strictly intermediate between depths 2 and depths 3. So that means our circuit characterization is slightly stronger than the model we work with. So in that way it's a bit different from the circuit characterization we had for this Characterization we had for this Frege hierarchy. Okay. So maybe let me say a few words on the proof. So you need to show two simulations. The first one is from a proof you need to go to a circuit. So from a QBF refutation you can extract the winning strategy for the universal player. A player efficiently, and you can do that in a UDL. And I mean, if you see, that might sound familiar to you because strategy extraction is a paradigm that has been studied in QBF quite a lot. It's also interesting for practitioners, because not only does it give an answer, but it also verifies the answer. It computes a counter model. And this has been done by single output decision lists for this solution before, but what we do here is we combine these into one. is we combine these into one UDL. And this combination actually depends on the quantifier complexity. So the list grows in that construction. And it's interesting to see that if you look at these single output decision lists, so this classical model, it's probably too strong to characterize QBF resolution hardness. Because there are actually QBFs which are hard for QRS, but with easy lists. Lists. So this model doesn't capture it, but these UDLs exactly have the right stance. And then for the other direction, you need to start form a UDL and construct a proof. And this makes use of some entailment sequence, kind of normal form proof of the resolution, where the intuition somehow is that we prove the correctness of the UDL in. The correctness of the UDL in resolution. This is quite a bit technical, so there are some details to it, but intuitively you can think that we kind of prove in resolution that the strategy extraction algorithm is correct. And as far as I know, this is the first time that such an idea was actually considered, that you go from a strategy to a proof. The other direction was kind of well known, but But yeah, and this entailment sequence that we define here actually also allows us to pinpoint exactly the propositional resolution hardness. Okay, so this actually also works for a system called QURES, which is even more prominent in QBF solving. What's interesting here to remark is that previously, I mean, it's well known in the community that QURES is exponentially stronger than QURES. Exponentially stronger than QRES. So in QRES, you only have resolution pivots which are existential. And to some surprise, actually to us as well, we show that these systems are equivalent on bounded quantifier complexity. So hence you can transfer our characterization there. So the systems are different, but on bounded quantifier complexity they simulate each other. And another surprise, I have to say also for us, is that we get a us is that we get a size-width relation by this characterization. Well, I believe you all know this well-known result of Benson-Som and Wigdessen for propositional resolution, where you show lower bounds for size via lower bounds for widths. So it's perhaps the most widely used technique today. And actually in previous work we've ruled out this technique for QBF. So we had, I mean, I give quite a few talks where I was saying this doesn't work in QBF. Few talks when I was saying this doesn't work in QBF at all. And well, I mean, we had explicit counter-examples, and there's no mistake in the paper, but kind of we draw, we learned the wrong lesson there. Because our counter-examples actually use unbounded quantifier alternations. And we actually also showed that the proof of Benzel-Son-Wiggleson doesn't go through in QBF. But using our characterization here, we can show Characterization here, we can show a size-witz relation for QBF resolution, and it looks slightly different than Benzer's from Victor's in Swiss light. But again, we have a lower bound for size via a lower bound for widths. So the widths is here actually existential widths. So you count the existential literals in clauses. But ignoring axioms, you see you also have the quantity. You see, you also have the quantifier complexity of the formula entering the picture. You have the squaring here, which you had in Benzelson-Wittison as well, but you've got another factor of log n here. And what's perhaps also quite intriguing is that you don't have any dependence on initial widths. So if you want to prove lower bounds, for instance, there's no need to do a Zeit transformation. You can prove lower bounds for formulas which have deep initial widths. And well, we obtain this characterization by using our hardness characterization via UDLs. So basically, what we do is we start from a proof, from a QB resolution proof, we transform it into a UDL. Then there is a result for decision lists by Pschauti, who show a size-width result for single-output decision lists, which you can see also generalizes to UDLs. And then we try UDLs, and then we transform it back to Q resolution. So we use our two steps of our transformation, and if you plug it together, you get exactly this relation. Let me try to illustrate this by an example. Some of you might have seen these formulas before, Pallity formulas, so it's quite easy p uh QBFs that exist, that that that that uh show a contradiction based on pallity. Show a contradiction based on parity. So you have a bunch of input variables, the x's, and then you say that the parity of the x's is different from u. So how you do that is you take some auxiliary variables that encode the prefix sum. So x1 is equal t1, and then ti minus 1 plus xi is ti, and then in the end you say that u is different to tn and then you see immediately that the only winning strategy is to compute. That the only winning strategy is to compute u equals the parity. And it's also easy to see that for each UDL of parity, you really need existential with n. Because the very first line in the UDL is an if-then statement, if some condition on the x-variables, then you output the parity. And you need, I mean, that computation needs, in the first line, needs to depend on all variables. Variables. So this immediately heads that lower bound, and previously we needed to actually import circuit complexity, substantial circuit complexity results. And this also works for another formula called the equality formulas. Maybe I skipped the details there. It's an easy formula where you can see that the only winning strategies is to copy u equal x. equal x. And again, if you do this computation, you see very easily that for the first line you require all existential variables in there. And this was shown before by a technique called size cost capacity, which was using some semantic lower bound argument. And again, it falls very easily under our new paradigm. So I'm arguing here that this actually unifies and greatly simplifies previous lower bounds. Lower bounds. And this brings me to the conclusion. So, what I tried to show you is this type characterization of QVF resolution hardness by circuit complexity, which involved finding this UDL model, which I would say is a quite natural computational model in the QBF context because it computes these counter models. So it yields the size-width relation, but it looks different than what we are used to from the propositional. We are used to from the propositional domain. And you can quite easily prove lower bounds via this machinery. As an open problem, I might just mention that this only works in the bounded case, and it's not clear to us as yet what would be the right circuit model in general. Thank you very much. So what does it mean? What does it mean? The number of alternations? The number of alternations, yeah, exactly. You can actually show that UDL is not the right model there. So you have formulas which have unbounded quantifier alternation, which have short proofs and Q resolution, but which need large UDLs. Just a curiosity right at the beginning when you were given the recipe for constructing the quantified systems by adding Constructing the quantified systems by adding universal reduction. Just curiously, how does that compare to, when you take Frager as the propositional system, how does that compare to the usual sort of QBF Frager where you have a sort of comprehension on the quantifier? Are they equivalent? I mean the sequence systems that you can use. Yeah, okay, right. So these are much stronger because the sequence systems, you can manipulate the quantifier prefix. So these systems that we work with, they always work on prenex, QB. Work on prenex QBFs and you don't touch the prefix at all. So the prefix remains constant throughout the proof. Even if you allowed that form, you could also imagine the for all x phi, you could substitute any formula into the x instead of just the booleans. Yeah. And would that be stronger? No, that would be equivalent, yeah. That would be equivalent. Yeah, okay. Yeah. So really the strength is coming from the button. You have to not manipulate the prenex. Exactly, exactly. Yeah. Have you talked about an analog of the? Have you thought about it whether it's an analog of the tree resolution size for trade-off? No, we haven't really thought about this, but since it really uses this UDL thing, I mean the construction there when we go from the UDL to the proof and back, the proof is inherently dark-like that we construct there. So it doesn't, since this is the proof idea that we use via the UDL transformation, this transformation cannot be made realized. Transformation cannot be made tree-like at all. But it's, I mean, it doesn't rule out that you can show a tree-like relation otherwise, of course. Can you put the statement of the size with three dot? There's a log n there? Yeah. That log n is the same that you have later in 2 to the n over log n. Exactly, yes. And what's the origin of this log n? Oh, this comes actually from this result of Schaudy here. So he shows this site-switch result. He shows the site Switzer result for decision lists, and we import that generalized multi-output format, and that's exactly something we inherit from his framework. I don't think it is known whether it's tight, but looking at the proof, it's not obvious at all how you could improve that. What's the complexity evaluation? Well, that's pretty simple. So, evaluation part of the problem. I mean, not as you can easily transform that into bounded depth circles. Oh, really? Okay, sorry. Because, I mean, you just specify the input variables here, and then you just need to go through the conditions, and one of them will trigger, and that's your output. So, it's a really very easy computational model. Okay, sorry, I missed something. Okay. Let's think again.