Alright, let's start with the second part of this morning session. We have Ayush Khalif from the University of Robot Burkham, who is going to tell us about teamwork shopping and reflecting BSDEs under Abit Valenum. Thank you very much for the introduction. Thank you very much for this invitation. So I will talk about two related problems, option scoping and RBSDs. But when we run the road, then it's completely arbitrary new. So first of all, I will define the model for you, the motivation. Then I will give you the goals, the literature, and the challenge. The literature and the challenges. Then I will define, give you the result that we found around optimal stopping in this setting. Then we're going to move to the linear RBSDs, then in general RBSD is graph time. Okay, so let's start. So here what I call the initial model, so a probability filter probability space. The filtration is because of the evolution that all agents get through time. Everybody gets. Then, on top of that, we have random time. We have random time. The random time for Pitris is the default time of the film. For Elif Insurance, it is the death time of an agent. So, this random time is arbitrarily random variable non-negative. So, here, just for technicality that doesn't have conceptually any new things, we assume that tau is strictly called still finite. So, then we look at this process. We look at this process and we increase the frigation because tau usually is a random time. So, a random time you can't see it before it's happening. Anyone cannot see it before it happened. So, that means when you increase the flow of information, that means this tau should be what? It should be a stopping time. You can't put it as initial enlargement of defiltration. Because nobody sees it before it happened. That's the reason why we go to progressive enlargement, filtration. We don't go to initial enlargement. Okay? So, this is the reason why. Okay? So this is the reason why you take tau. G is the proper symbolize metal expression with of f with with with tau. Then, so the guy who see f, who receives this information, can see this tau through these two processes, what you call the asymmetric supermartino. Okay? The survival probability. Okay? So, and for us, mathematically speaking, this power is parametrized in F through these two. Parameterized in F through these two processes. Equivalently, we can say it is parametrized by this dual projection of D and the Martin La pair. So these two pairs is equivalent. You can go from this parameter to be one to one. Okay? So this is the setting. Okay? So now, for that setting, you take any your process X that start in the F. Start in the F. And you look at when your asset stops at tau. You look at for the resonance from 0 to tau. So for that set, and we are looking many problems. We are moving many directions. Evaluation, hedging, we doing many things. So many things, including this one, they are very much advanced. Okay? The point all of them to one. All of them to one type of BZ, which is this one. R BZ. All of them converge to this BZ that. So what's new here? Well, first new here we have now arbitrarily. Lot of stopping time is complete the arbitrary running time. That's the the the red one is the most difficult part. Okay? The second new one is we have this The second new one is we have this driver here, U, is another process right continuous, non-decreasing. So most of the DSDs, they don't have that one. But we know. I'm not a specialist of BSDs, so don't ask me much. I just, we were forced with this problem into that one. So we find this new, so we dig on the electronic, we didn't find this one. We find one poor sky, he doesn't have either zero heel, he has Either Z or H, we have this one and kind of this G depends on Z or what does it. So for this one, in the simplest case, this one, we found this form with Y and Z. And U is completely, you have no control of U, U can be singular to the Lebesgue measure. So that's that. So now. U is part of the solution, the solution? Or U is given? No, it is given. So here is the, that means the parameter is F G. is the parameter is F G U that's it and S so this is the main target okay so what we want to do here well we want first we want to see what are the minimal conditions on the data F G W F G U so U for example Xi the minimum condition we can guarantee existence or That we can guarantee the existence of an unit of solution for this BCDE in LP, for any P. What will be the condition for that? Okay? So, the second, we are interested to see, because if you go, for example, creator's literature, so to do computational things, they move to F, because they don't see tau. So, they move with parameters using the parameters, even in the simplest case with tau, they move to F. Okay? So, we need to find a connection between. So we need to find connection between dot G and F B. How to move one to one? You need to find the BC in F that connects both solutions and you can move what you travel back and forth, whatever you like. So that's the interesting problem here. Then we need to see what are the norms that we need to define for the solution and the norm for the data. Data. So many problems. Why these problems? I will explain to you. So first of all, here, you can see why I mostly well, first of all, audience topic and RBSD we know everybody knows, probably they are connected to each other. But more importantly, why aren't you auto-stop content? Because we couldn't solve this problem without going through optimoscoping problem. We couldn't solve this question without going solving the optimoscopy problem and the random horizon. stop a problem and the random horizon. We could. Plus, we have other reasons, financial problems that need that resource. So we have two strong motivations, so we move to the optimal problem to look at it, how it behaves with arbitrary tau. We don't see anything on tau. I take take your initial model as simple as electrical, but keep tau arbitrary. Why? Because there are many literature specialists in the insurance empirical research. In the insurance, empirical insurance, empirical letter to it reject the idea of lit in tau to be independent or weakly independent with the initial model F. The empirical results reject that one, define the puzzles. So we shall have explained that one. From my point of view, is what that correlation. When they put that independence or weakly independence between f, that means the initial mode and tau, there are many risks are negligible. Are negligible, neglected, and that caused the puzzle that he found in correct work. Okay, so this is just quick motivation more. So, why am I interested to see that why this you can ask why this norm, there is a problem of norm here, because of this one. So, these are the challenges. So, the challenge is that this tau is not asked from Arthurian norm. When you stop tau with W with tau is not a local multiple anymore. So that why Paul credit risk what they do? Tau this support immersion. Then they don't have any problem, then they should use the machine that only developing BCD and they get results. No, we are not accepting that. So then one way say, okay, let's compensate to this one. Then you ended up with a driver that is not licensed. And this, if you Unless, if you assume something from beta. If you assume something from beta, that means you assume something from tau, we don't want that. Because we don't know, even if you assume something on, even on the density of beta, whether that tau exists. Why that tau should exist. Give me an example. On top of it. So we don't want to assume anything on tau to keep it up to line. So no matter what your model of tau, it comes from insurance, from from clear risk, from anything else. It should work. Anything else, it should work for us. So then another reason is the Martingal inequality. You see BSDs, if you look at the literature, you sit down and look at all the papers on the BSDs, the main thing used there is what? Martingale inequalities. Those Martingales qualities fail when you have the arbitrary. Basically fail. And you have been for a while working in that direction. It failed completely. Okay? So then you So then you're going to have many problems. First of all, that classical analysis that done in BCE, you will not apply here. And secondhand, if you move to the direction of where this inner party needs like stability, you will not be able to do anything there. And that question, can we move to this direction? I try to move in the direction that we try to see what uh you did and try to come up with something. Then try to come up with something, it's a big mess. So we move to a different version of big mess to this. Very good. And then, which is in the future, maybe I go back to that big sample. Okay, never mind. So the other reason is that what I'm interested later is this one. So I keep capital T infinity for example. Infinity, for example. Okay? Then I have in bounded horizon. That was in bounded. So if I solve bounded, then I can easily find, we're going to find the terminal condition that corresponds in F that corresponds to the terminal condition in G. You can imagine T should be H capital T. But when you let tau, you let capital T go infinity, that means you have inverted present. That means you have in boundary horizon, there's many problems coming. Many challenges arise. Okay? And one of them is that because your H is completely arbitrary, you don't control it. So this may not have a limit, then many things, many questions comes in. Okay? Then, so if you compare it with the literature, so the one in green here is illustrated as a special. Here, it understood as a spain more general because we have a DU here. Okay? Okay? And this person, we didn't look for them. I'm not a special of the disease at all. I just comes in. I was forced to do that because I have no way other than shifting PC stuff. I tried directly at, it didn't work. It doesn't give me this as the BC solution. The solution, description of solution something. So I was forced on, I have no reason, not because of math, no, because I have other reasons. Okay? And you compare the letter to all the shows that you have immersion, that this thumb is nice, everything is fine, you can take the missionary off all the developed on BSD is the applied, you can do this for the old, then what? Then the only contribution is what? It's just take here, apply here, and get. Just take here, play here, and get. Take from here, cook here, and send. That's it. So I'm not happy with that one. Plus, as I told you, there's numerical reasons for that one. They reject this assumption. The other one, as I said, the version is too strong because it is equivalent to some independence between f and tau. Okay, let's move on. So, as I explained to you, the optimal stopper. So as I explained to you, the optimal stopping problem, we have two reasons for that one. One reason is because we need to answer one of the questions about the VSE, RBCE that solves another functional problem. And one reason we have other facial problems that need active doctrines to pen undercut. So for that one, we look at this Dr. Scoper problem, right? This is in G. Okay? So for this G, and we have the reward, okay? This is X. Reword, okay? This is XSG is the reward, and this is the snare envelope or the value for process, right? Okay, then so the first question we need to find the counterpart F of this process, of this principle problem. That means what we need to find a reward in F such that we can connect the reward and the value process in F to the reward in G and the value process in G. So what's the connection between that? Connection to it. And that's one of the big questions here. Then from that, we can also say, talk about existing in G connected to the excision F. So if you start with even a simplest case in G, in F, what you can say about in G, so that will give you the uh condition on the parameter of tau and F that guaranteed existing in G. So what those conditions? Okay. Conditions. Okay? So then we need to move on. So I'm not all suspicious of authors of problem, but I was forced to do that. So I need to find, so then we dig to the literature with huge sensor. I know one of Edgecar research in 1972, the textbook. Then we need to maximal stopping, maximum and minimal stopping in G, how you can connect it to F and visors. Okay. So now this. So now this is the result. So to do that, what you need to parametrize. So you need to parametrize xg connected by something in F. You parameterize G, anything in G using F. Okay? Because F is given. So how we do? That's the parameter. So we take the rewired. You suppose we are going to do all the up top. The rewire. Are going to be only of tau. The reward doesn't move after tau, then we can prove the existence and uniqueness of two processes: one optional enough, one progressive enough, and this is the connection too. This is the integral with respect to that one. It's simply, so D, you can write in the H tau just to single channel. Okay? So that one, that's the given sum. Then we connect them even with. Then we connect it, even with fine direct in XG can transfer it into F, to S down. And the regular interval, the structure of C Martingale can be transferred to F. And the connection when you stop this way, cannot even this way. So that way. Then we can even talk about the integrality because sometimes we need the L P how the L P transferred into the integral of both parameter. parameter parameter pair of in F and sometimes we need class D, if you see X in class D in G, what will be what implies that this one is antengable with respect to this measure, D is the single chunk, so we have measure respective time as a label, and X, this product, is of class 0. Okay? So once we fix now this problem, that means we parameterize you This problem, that means we parameterize uniquely this one, we can move on. Then we need more, so we say, okay, now you have xg parameterized by xf and k progressive. But we can more, because you need to go more in details, because we know from our previous result that when you add Previous result: that when you add out the model, it adds three types of big risk. One is what we call it: pure mortality risk, number one, pure mortality, number two, and the correlation risk. And the correlation risk, if you dig, there are many types we succeed to disintegrate things. So that why from that one, this gets a spar from that one, we divide this one, the equivalent to x, f doesn't change, but this one we can place it by. This one we can place it by a projection k optional, which is the projection optional with some measure, and the difference between them, which is tf, which is the difference between this one. So this is the equivalent. If you know this one, you know this is triple and vice versa. So this should be not boring. And that point I'm saying here. Okay? Now, once this one is parameters, we can move on. The conditional projection with respect to this measure. Like, you can think if as expectation with respect to mu. With respect to this one, because this is optional sigma sigma d. So M is same as X. You can take that one usually because I kept that one following the probability letter. Property letters. I keep that. So I'm not be far. Yeah. So we usually, so that one, usually that means this one I projected with respect to this measure, but on the optional sigma. Okay? So then we have. Now we can answer questions. So the XG, so this is G. So this is the server of G can be written this way. Completely disintegrated. It is connected to the optimal stopper problem of F with this reworld process. So we can move back and forth. That's that. This is the standard volume G, is a slam volume in F, evaluate G, together, and you get. Together, and you get another three-type material here, example. Okay, and that means the auto-super problem F is given by the reward of this process. This is the reward. This is XX and G. G is the survival party, and this projection integrated with the parsion of D. Now Now we need some in the in the this is under P this is under P now we in G we can change the probability that what we will do in the in the RBC to solve one of the the tools important tools is to change property to choose an adequate change of property that property will change. So the actually the envelope snail in G and the Qt will that can connect it to the distance envelope of F. It's an overvalue of F and the P, but the reward process changes. And the connections change drastically because our part disappear. So this is a... Now we are done. We can move to existent universe. So we can prove that the optimal optimal problem enter G has a solution if and only if this one has a solution. One. This one has a solution, one-to-one. It's enough to look at this problem in F, and then you can prove this one, and the solution you can connect them through by the previous theory. Now, if one of them exists, that means it has a solution, that means the minimal exists, minimal optimal time exists, and we can connect them this one, and both of them exist, and this one. That means the minimal of f, to calculate the minimal of t, you just take the minimum without, and that's it. You're done. The maximum. The maximum you need to do like uh in uh in Kines papers, you have to do differently. So if the maximum exists for that one, then it exists for F and they are connected this way. So we are solving problem completely. Okay, so that was top in optimal stop a problem. Now we can move to RBSDs. So RBSDs, this is the this is the so we're gonna ignore that point of view because I need to just Because I need to just show you the important really the innovation, where is the key problem, key new things here. So let's look at that one. We're going to go even simpler because the idea is when you increase, they increase the difficulty, of course, but let's see the key idea first. So we take that one first, the new zero, for example. Okay? So this is the definition of BSD. So, this is the definition of this D. So, I think I will skip because most all of you probably know about it more than me. So, then, so this one is the definition of DI if we want the paper. Then we look at this is of class D, that means this one of uniform integral plus this integral T. Then it is in L P, then this space are noun, this is the L P space, this is a sub this one, this one is noun, okay. This one is noun, okay? The martingale noun, this is integral. So now we're going to start with this one, just linearly, and see what's the problem. Just linear. F is completely constant in u and z. So what happened? And h is optional, okay? And we have that. So here what we need? We need two things. We need a change of probability, then we can assume nothing on top. You added by change of clothing, and that one will absorb, we will make w tau is a marking value with the zero assumption. And I will use the standard result that I did before. And then I doubt the key, two keys, go together, this one. So first of all, we discover I knew with another work in another direction that this guy, when and the G is positive, so all the electric technically the risk, all this will G positive. Oh, this is G positive. So assume. It's not strong. It's not strong. But even though I'm not happy with it, but it's not strong. So then, for that condition, we have this GU can decomposition into two processes. This one is a military decomposition of supermarket, but it's not unique. It's different. And because each, this guy did play a key role. So, and then we figure out this guy, when you invert this guy. This guy, when you invert this, this one is it where they stop it, is all equal Martin, and that the big surprise. And then that means when you take your investment for an capital T is finite, then you get a nice probability that changes everything for you. And that's the first predictor. That's it. That means there's a probability any multi-general F start any multi angle in F. You look at multi-generation F. Local multiple in F. This is a local multiple in G and the computer and that edge. Now I should handle things and if I will follow the what? The classical literature of RBCs. But I should care about Latin because you have a different expectation and they have to move the G under the problem. Okay? Then I'm done with this one. This is the trick. With this one, okay? This is the trick. Then now I is very clear. So assume this one I'm not happy with, but this is the lowest of the lowest assumption that increases the risk of insurance. Assume that this is the assumption that you assume, for example, on the data, should be altogether in order to get a solution. That's it. Then I have, I get inequalities. I control the solution using the data in this way. See? So maybe I love what some of you. So maybe a little bit, so if you look at, especially if we look at the paper of the last paper of Bouchard 2015 in SPR, so this one he put it with capital T, so we make sure that C doesn't depend only on E at all. Nothing else. Why? Because we need to go to the limit. Then I have petrol and everything. So there we find these inequalities. That means and the queue well done. So and the queue, I have a solution, everything is fine. Okay? Okay? And then Okay, and then I go to differential solution because I need to go to the limit sometime the approach things. Okay, I need these ones. So, following the papers of RBSD. So, I find everything here and the Q2 will die and G. Then I can now look for the relationship between what is the F base D. What is the FBC? So that one, so first of all, I found that BC in G has existent unit, okay? And it's connected to the optimal stop and on, as normal. And from optimal stop and on, I will get the VC in F. And the VC of F, I will find the driver, I will find the barrier, I'll find the terminal condition, and I find the VCD this way. Then I'm done. them done. They will find and they will tell you that the BCD they are connected. Here is the connection between them, the solution, all type of streets. And this one, this NG is one of the martini we defined in one of the paper where we really did some real job because any marking energy with the composite and that rely on this martingale was to be called pure mortality martingale type 1. Okay? So now So now we have clear, clear answer for linear one. Okay? Now if you move, if you t put capture t equal to infinity, the many problems arise. One of them, this one is not a martingale in general. Because this one is not uniformly integral in general. And this if you assume something for that. And we don't want that at all. One time at all. Okay? So we are against that. So then the second condition. So we need what are the conditions on data? Because this Q2 now is not valid. You can't use QA Telta for this. You can't. Because it's not a probability or the failure. However, what we did before, it doesn't go to the waste. It is very much important step. But we need to build what? Another technology. Another technology that will next step you can combine. So that will be good things here. So now a mini question comes here because when you remove t caps to infinity, everything all what you did before, you can use it. You can apply directly and say, oh, look, it doesn't work that way. Then this is our approach. So we're going to use those inequalities we find, which is this one. Right? So the first was step one, we can initialize So the first was that one we can try to do habra caden habra, or some magic things, to move to P. And that's the big piece. We need to move here without zero assumption on top. Okay? Zero. We don't move no assumption. So how to move this one to here? Then second, we're not going to care about the second part. That one is less, is less less. Less complicated than the first one. Okay? So we can move then, we're going to get what? We're going to get this one less than this one, that's it. We find that we can use the approximation, we can use this unique, we can move on as clasp. And that's the big problem. So, because this, the idea behind this, for example, see? So, beyond this inequality is the BDG. But you can use. But you can use B D G with Tau, because everything fails. You can use B D G and P with Tau, because everything fails. So here we have this different, we find different, different, different inequalities. And the key behind it is this crucial memory. So as I read in one of the paper or the books of Negros and Meyer, simple, some of the good ideas they are very simple remarks. It's not simple. So simple, you take x as optional, you find connection between. So here, you can start from here with x non-negative, you find connection between, you move it to f this way. You start see to move it this way. You look at the second one, it's more easy. Then, under some condition on the x and tau subcondition here, we can prove this one has a limit and it converts to some some norms. So norms with p and d t. So nodes with P and D T, and that's the key, that's the really key for the nodes. Okay? Then, if we think a little bit better and take x is the right continuation of statement, but it's increasing. That means final variation even, but increasing, starting increasing. Then, first of all, you can move this way. And the important thing is the norm of this guy and the L P you can control it, is controlled by the norm and the Q12 guy. And this is the step one. This step one, the hardest. So we moved from Q to P, that means this one is already, so this one is smaller, so it's very nice. And the constant doesn't depend what? On anything, except R and G zero. G0 usually if we put we put that our strictly positive is one. If the filtration F zero is uh uh that means broad motion, then G zero is a constant. The G0 is a constant single problem. And the constant. So that's the key things here. And then we can go smoothly. So what we're going to do first is that the first step. We're going to move, see, we move from Q to P, from Q to P with different norms. And this norm is like you discount the process. This W epsilon 12 is a discount, we call it discounted process. Discount process. All processes are discounted. Then we find the norm and P is controlled by the normal P is controlled by the norm of data and the Q. The first step for this one. Then we move on for the same difference because we need the level to take the stability and to approach the general things. We need to do the same thing for that one. Then this gives us an idea. What will be the normal data? What will the norm on the solution? So that one here. So that one here gives us the normal data. And then this one gives us the normal solution, the idea. So the normal solution will be like how you discount the process. You will be discounted. And this is not surprising. First of all, in financial mathematics, discount is very common. The amazing thing is through the paper of Bouchard and Domas in 2015, I found in general, I think what they do or In general, I think what you do, or rather, maybe I don't remember, so you do discount it to get the general E minus alpha T to control the norms. So discount is like an ignore. But here we enforce things. Things come naturally. I didn't. So this is the only way to do it. Then we can get the existential uniqueness for the embodiment case. So embarrassed, this is the law, this is the data. Yes, this is the norm, this is the data, this is the normal data. F is the integral of f. H and finite. Then that basically has a unique solution. And we can control the normal of that one here. There is no Q at all. At all. Then we do the same thing for the difference. How do we get the difference? And we get F. Then, now we need to find the connection with the F. Still a problem there, but here we have extra condition, that the things that we are forced to add more condition here on the parameter than G. So G need only this one, but to have this one, then the VCD is the same form. That means the driver, you dispand the driver, dispand the the The triangle, this comes the barrier, then this is the BCD. So find in the letter to some BCD, this one that means the limit is going to zero infinity when T of the infinity. The limit is zero. And one thing here you can tell you, the BCD, this one is when you find one, I think policy, you add this one, use the EBC, this is extra. But there's no Y or Z the head at all. But this is X. at all. But this is extra. That means uh we have that one, we call it B C E uh U g F D V here or D U D U yeah that means this one. Extra terms in the gyro. So then the solution they are connected to each other this way. So the solution we already find the linear one bounded risk bounded resin doesn't change we can prove that one okay okay and Okay, and so for BCD here we are following the idea that many papers, especially I read the mini papers of NISA, 2Z. So well the BCD can get to the BZ from RBZ by putting S minus MBT, you ignore K and that's it. You get it. So but still we write it down. Okay, I will move faster. Now, the general case. The general case, you don't have this narrow ball. Don't have this now. Then you have the problem. Where the problem will come? If you forbid it, you will not be able to see clearly what will be the ABSDNF that will be, you put things together one-to-one. And that's the main challenge there. As I'm saying here, there is no snow envelope solution. So for the linear, you can move to the snow envelope. Snell envelope, it was nice to study and to get in F, but that one sounds good. You have a snow envelope, but it's the solution. Have a snow envelope, but the solution is connected to each other with FT driver there. See? But so it doesn't give you an idea. And that's the challenge there. So, to find this guy. Plus, the norm inequality, there are many things. But the linear case is a big step to move forward. And of course, here, the same as in the BC literature, there's the non-space change. Later, there's the norm space change. That means you have to discount e minus alpha or something to get nice estimation. So, for that one, we have, so we follow the literature, so that means there is a we discount by alpha and this, and we find this inequality. So, we follow both the literature and And the literature and the Liar K, we succeed to get these inequalities. Suppose you have bounded horizon. So by Q2, change in the model, we get the same. Here I look much, much complicated than the linear case. But we succeed to get them fully. And then we get the same thing for the And then we get the same thing for the difference of solutions, the estimation of law, but still under Kit Velta. Then we move on to the existence solution and F. And that's the big error, the big problem to find the F. That one, so this is a structure you can write up, and that this is the VCDNF. The VSDNF. So, and that one. The BZNF. So, and that one to get it, you have to you have to do it by approximation and to use the linear case, and that you exactly you find that the driver has this problem. There is a multiplication by, there is a graph factor, there's a graph factor in y and z, but you discount it outside. When it is linear, when it is linear, that this doesn't band this one, you get the same as before. That's the thing here. That the things in here. So if this one doesn't change, you discount the value, you discount the terminal condition. Doesn't change much. Cool. But this is the new thing here. And then the solution, how they are connected, is the same, doesn't change at all. The format, the same form, the same map that map, the solution G map solution is F. G immune to HF. And this is the general one, that means tau, the same problem. So this is where we apply what we did before, same challenge as a linear case. So we find the normal space for the data and the normal space for the solutions, same as before, as the linear case. And yeah. So this is busy enough. In F, if unit is infinity here, the same as that one, but F has the same driver that you find before, dividend. And I think that, yeah, so this is how to find this. This is the relationship. The relationship stays the same, doesn't change much. And that's, yeah, I think I'm on time, right? Yeah, I will. So with that, thank you very much. 