And so how I started to work on this project is I found this paper, this different paper from Cozar, where they showed that most of the plastic in open ocean were fragments. And he measured the distribution of size of the fragment and shows that the PDF seems independent of the location. And from a physicist, it means that there should be a generic mechanism that can explain. Generic mechanism that can explain probably this observation. Two steps are needed to understand this behavior. First, an embrittlement of plastics, meaning that, as you know, salt, UV light and so on can damage the plastics, and then you have a process of fragmentation. And in their paper, Koza and collaborators propose a power law to explain the PDF and say that for small sizes, That for small sizes, there is a big difference between small plastics and their prediction. And so they say that there should be a new mechanism for fragmentation that occur at small scale. However, their model was based on a paper published in Physical Regulators, where they study the fragmentation of plastic ball who are who And so this mechanism is very unlikely in the ocean. And we were wondering what happens if the fragmentation was due to extreme deformation during storm events that lead to extreme deformation and so fragmentation. However, in turbulence flows, there is not a lot of work on deformation nor fragmentation of plastic or brittle material. So that's why we start to study. Uh, that's why we study we start to study this problem. So, first, I will present what we did on particle deformation and how this work can help to understand the fragmentation of plastic in the ocean. Okay, so the first part, two questions can be addressed. The first one is when does a particle deform in a turbulent flow? So, typically, what is the minimal size for fibers to be bent? And the second is when it is bent. And the second is when it is bent, how this particle can deform in the flow. What are the statistics of the curvature typically? So, if you are looking at this question, this is classical stuff doing influence interaction. Just one second, I have this. Yeah. So, this is classical stuff in field structure interaction, where you say that you have a force that is applied on the object by the On the object by the flow, and you balance the hydrogen impulse stress with the bending force. So if you have high turbulence, you would say that the pressure force due to the mean flow will balance the bending force. And if you have a laminar flow, you would say that the viscous force will balance the bending force. And with this kind of argument, you will define the minimal length over which the object can be defined. However, here this. However, here this approach is not well, it's not the good one because the force are also responsible of the addiction of the particle. And so the total force of the particle will bend the particle. And also, if you are looking at particles in the initial range, you will have several length scales that matter. So the question is, what is the good length scale that matters for the velocity? As we know, also, there is a lot of shapes in the ocean. We discussed a lot. Is a lot of shapes in the ocean. We discuss a lot about this during this workshop. And as a physicist, we go to the simplest object, which is which are fibers. And we work mainly on fibers, and now we are extending our results on disks, so to this object. So if you consider fibers, the equations that direct the deformation are the Causer equation, which is the balance between the inertia, so the mass times the axis. Inertia, so the mass times the acceleration. Then you have the tension force that ensures the stretching, the response of the stretching of the fibers. You have the banded force, and then you have the forcing, which here I will consider is as viscous forces, as it is classical to do for slender bodies. So now you can have three different deformations that can be the first one is bending, which evolves with a typical time scale, which is given by balancing the bending force. Balancing the bending force with the viscous force, and which scale with the viscosity the length of the fiber to the power of four divided by the bending modulus, which is a young modulus and the moment of the area, moment of inertia. The second deformation that you can think about is stretching. And here you balance typically the tension force with, once again, the viscous force, and you end with a stretching term that scales more or less the same way, except that here you have L2. Way except that here you have L to the four L sorry the aspect ratio to the four whereas here it is the aspect ratio to the power two and finally the last one is the twisting and in fact you can show by dimensional analysis that the twisting time scale and the stretching time scale scale the same way and they are for fibers as I spectrum show are long meaning that the length is much bigger is much bigger than the diameter you will add the banning time You will have the bending time scale that is much longer than the stretching time scale or the twisting time scale. So it means that you can consider a fiber as inextensible. That's why we said in the numerical simulation, we did the tangent vector to be the norm of the tangent vector to be equal to one and unprestable. Okay, now you have another question: is what is the typical length scale of the fiber compared to? Length scale of the fiber compared to turbulence length scale. So we are dealing with homogeneous and isotopic turbulence to have a simple framework. And so we'd say that we have two length scales that matter, the integral length scale. And for length scales that are much bigger than this one, the flow will be uncorrelated. You are here in the inertial range between the integral length scale and the Koluga of length, while you have the classical correlation due to the structure function of turbulence. And while you are in the viscous And while you are in the viscous flow, you will have a laminar random flow that evolves. And in each of this regime, you will change the correlation of the spatial and temporal correlation of the forcing, which is Cu here, which is related to the field velocity. Okay, so first, are distorted particles smaller than the Kolmogorov line? So at the scale of the fiber, the flow is smooth, meaning that you just have a linear gradient. And so And so you cannot bend easily the fibers. And in fact, you can show that there is some preferential alignment for fibers with the gradient of velocity. And so you just have two ways to have deformation. You have stretching fibers when the particle is aligned with the largest eigenvalue of the coagent tensor. And also the banning mode, where you have a compression. Sorry, where you have a compression due to the flow. And in fact, you can show that for particle smallers and the congraph length, you will have mainly this configuration that appears. And so now if you look at the evolution of the end-to-end distance, which is R here, most of the time you are at the same, so this is numerical simulation done. Sorry, I forgot to tell that by a colleague at Nice, Jeremy Beck, and his student, Sofia Allende. And most of the time, Day and most of the time the fiber is stretched, so the end-to-end distance is equal to the fiber length. And from time to time, you have the fiber that is strongly aligned with the compressional direction, and so you have a strong buckling event that appears, and while you have this kind of deformation. And the flexibility or the amplitude of the deformation is controlled by what they call the flexibility parameter, which is a balance of the viscous force and the bending force. And so, as you see, the signal is totally intermittent because of the preferential alignment, and you should have some misalignment of the particle with the most extensional direction of the gradient velocity gradient tensor. Now, if you consider particles that are much larger than the integral length, the coefficient depends on the large K flow. So, as I said, we were dealing with a much larger line. We are dealing with homogeneous and isotropic turbulence to have simple stuff. And so the correlations are delta-correlated in space and time in this approach. And so you can expect to have deformations that are very close to what has been seen in polymer sciences, where you have a random world basically and the deformation that is related to uncorrelated nodes. Now if you go to the most interesting part is when you are particular in the inertial range. Particle in the inertial range. Here, it is more complicated because you don't have clear preferential alignment within the flow, and also there are several length scale and time scales that matter. So, the question is, in that case, what is the minimal length before deformation? So, to do that, we did some experiments in a fun common flow. So, a font command flow is a tank where two impellers are rotating in opposite direction, creating a big shear layer at the center, which Shear layer at the center which destabilizes at high windows number, and so you have a big turbulence in this kind of thing. And you can see here two set of images at low frequency, where you don't have a lot of energy in the turbulence, and at high frequency, where you can see that at high frequency, the fiber are distorted, whereas at low frequency, at least at the beginning of the movie, sorry, the fiber are undistorted. Fiber are undistorted. So, how can we explain this feature? So, to do it simple, we look at the evolution of the fiber of the end-to-end vector as proposed by Jeremy Beck or as I did, by Jeremy Beck and Sophia Allende, or as it is done in polymer sciences. What happens when you keep the frequency constant, so the intensity of turbulence constant, and you increase the length? Constant and you increase the length. And you can see at the beginning that you follow the dashed line, which corresponds to a straight fibers, not without any distortion. And then you go away from this distortion when you look at the end-to-end vector. And this RG is a radius of duration that you can compute from the formation of the fibers where you follow the same kind of behavior. So here you see a fit, a plain black line, and it comes from polymer models. And it comes from polymer models. So in polymers, there is three different typical classical models. The first one, the one you learn when you are small at school or at the younger age, you have an ideal chain, meaning that you have a random walk without any constraint for the position. When you increase the length of the polymer, you will have a self-avoiding random walk because the probability to have to go at a position where there is already a Go at a position where there is already a monomer is important, and so you cannot go there. And so, you have a change in the evolution of the end-to-end vector, the norm of the end-to-end vector as a function of the fiber length. However, these two regimes are derived for very long polymer when you have a lot of flexibility. In our case, we are dealing with close to the transition when you have stiff polymer to flexible polymers. And this kind of polymer are called in their community worm-like chain. Warm-like chain, and they are characterized by what they call the persistent length, meaning that the correlation of the orientation of the tangent vector decorates on this length scale. From this relation, you can define, you can compute the evolution of the end-to-end vector, the norm of the end-to-end vector as a function of the fiber length and the persistence length. And you have this solution. And in our case, we fitted our exploital point with this formula, and you see that you have. point with this formula and you see that you have a very nice agreement. However, here you put all the physics into this parameter LP and you expect that this parameter depends on the turbulence intensity. It may also depend on the fluid and the mechanical properties of the fluid and of the fibers. So we vary both the frequency here as you can see. We vary the bending modulus through the U modulus or the diameter of the fibers and we also Of the fibers. And we also change the fluid viscosity because you can see here that for the same fibers, the viscosity plays an important role. And this can be expected because it is related to the forces. Okay, so how can we interpret now the persistent length to do some physics? So in polymer theory, what is done in general to interpret this length is you say that the binding energy that is stored into the polymer is equal to kT the Polymer is equal to KT, the typical energy of the forcing. If you do this analogy in turbulence and you say that the KT is the energy of the ADs, which have similar sizes than the fiber length, you end with this relation. And you see that this relation is independent of the viscosity, and so it should not work. Why polymers and turbulence cases are different is because in turbulence you have an out-of-equilibrium stationary process. An out-of-equilibrium stationary process, meaning that you cannot do a balance of energy, but you know that for the system which is constituted of fibers, the total energy cannot vary in a stationary process. And so you have to balance the injected power and the dissipated power. So the injected power, it's easy. It is related to the turbulence that you inject into your system, the turbulent energy that you inject in the system. And the dissipated power is Power is typically the energy that is stored into the fibers and divided by the typical time scale of evolution of the fibers. As I told you at the beginning of the talk, for bending, you can define this time scale by balancing the bending force and the viscous force, and you end with this relation for this expression of the balance for the evolution of the bending coverage of the deformation. Then you can define the balance by the balancing this two. By the balancing these two terms, now you can define a typical length scale L E, which is equal to EI divided by so the value modulus to the power minus sorry to the power one quarter divided by the fluid density times the fluid viscosity times epsilon to the power one over eight. So now if you plot the persistence length as a function of this elastic length which characterizes the transition. The position, sorry, you can see a very nice collapse of this experimental data with our prediction. So, what does it mean? It means that a fiber that is much shorter than this length scale cannot be bound by a turbulence. However, for fibers that are longer than this length scale, you can be deformed. And so, you can, if you think about the PDF I showed you about the fragment size distribution, you can see a clear. You can see a clear difference if the fibers are or the fragment are longer than this length scale or smaller. So, now if we think, look at the characterization of the deformation for fibers that are much longer than this length scale. So, to do that, we did also numerical simulation where we solved this equation in undimensionalized form. As you can see, you have some parameter which is gamma is coded the Is gamma is coded the rigidity of the fibers, and the stocks number is coded the importance of inertia. We didn't play with this with the stocks number, we fixed it to be the same as one of the experiments. And the flow to have a less expensive numerical simulation, we choose kinematic simulation, where you have the same spectrum of the turbulence, but you don't resolve the world largest. Don't resolve the whole Lieutenant stocks equation, so it's much less expensive. But you don't have all the intermittency that is all the intermittency that is present in the turbulence. However, with these tools, what is nice is we can look both with the same codes at the turbulent cases, so what we call the turbulent cases, so the inertial range, and also polymer, when we say that the stiffness is very important. And so at the end, the typical length scale of deformation is much better. The typical length scale of deformation is much bigger than the integral length. And so we can clearly compare what is the difference between the turbulence regime and the polymer. So to look at the influence of the flow correlation. So, sorry, if now I look at the mean curvature as a function of the fiber length normalized by the elastic length, you can see that at the beginning, for both polymer regime and tubulant regime, or the intermediate regime, which is a mix in between. Intermediate regime, which is a mix in between the two, you have an increase from zero curature to a value, then this value saturates in the polymer regime as it has been observed in polymer sciences. However, in the experiments and in the numerical simulation in the turbulent region, you can see that you have an increase of the curvature, you reach a maximum value, and then you decrease. It means that long fibers are harder to bend than short fibers. That was quite unexpected. That is, that was quite unexpected, and to understand that, we need to look at the evolution of the curvature as a function of the position of the fiber to have a local approach of what happens. So, in the polymer regime, here, I plot the evolution of the mean curvature as a function of the collinear coordinates. So, you are normalized by the fiber lines, meaning that here you are at one extremity, here at the other, and here you are in the middle. For short fibers in light blue, For short fibers in light blue, you have small curvature, then you increase, and then you reach a plateau which doesn't change with the fiber length. When you do the same thing in the turbulent regime, you can see that for short fibers, you increase the curvature until you reach a plateau which corresponds to the maximum curvature that we get in the previous plot where you have the mean value of this curvature, if you want. And then, when you still, if you continue to increase, When you still if you continue to increase the fiber length, you can see that you have a decrease of the curvature at the center, which is also quite unexpected because this, when you want to bet the fiber at the position where you have the main deformation, you should do it by hand. So how can we understand this profile? So to do that, we need to look at what happens when you have an ED that wants to bind very long fibers. Bent of very long fibers. So when it rise, it creates a curvature. However, as I said at the beginning, the fiber is inextensible. It means that when you bend the fiber locally, you need to rearrange the whole conformation of the fiber to pull the fiber towards the deformation. And this motion is related to a new dissipation term, which is the viscous dissipation along the fiber lines. And so And so you can write it this way, where you have the new additional dissipation term, which is the integral of the wall dissipation along the fibers. And with scaling arguments, you can show that at the end, you expect that the curvature should scale with a curvilinear coordinate L zero to power minus two over nine, with some scaling factors, which is which depend on the fluid density, banding modulus and the turbulent kinetic energy. And the turbulent kinetic energy. And if you do that, you can find a field which is here's a dashed line with only one parameter, which is the amplitude of the curvature here. And you see that you have a very nice agreement with our numerical simulation. And this also works with our experiments, which are more noisy. That's why I don't present it here. Okay, so to conclude on the deformation, we can see that fiber longer than the elastic line. Longer than the elastic length can be bent, and we have a straightening of the longest fiber due to the flow. So, now that we know that, how can we model the fragmentation and what is the fragmentation mechanism or distribution of the fragment that we will have with this mechanism? So, to do that, we would use the simplest approach where we're not considering the first mechanism that occurs in the ocean, which is the aging of the particles. The aging of the particles. So there is no chemical, nor chemical damaging the fibers. We will consider that we have a brittle object, meaning that it breaks if the strain is more important than the maximum value. Otherwise, there is no deformation of the fiber, so there is no plasticity if you want. And the strain is related to the deformation. You can say that the maximal deformation is related to maximal curvature. Deformation is related to a maximal curvature that you can show. And so, numerically, what we did is when we compute the deformation, and when you have high curvature, you say that you break at one point and you let evolve the system. And as we don't have inertia, we show that the breaking events are independent. You don't have a cascade of fragmentation, for instance, as it can occur if you want to break one spaghetti in air, for instance. Now we have two parameters to. Parameters to understand the evolution of the size distribution of fragments is what is the maximal curvature before breaking and the duration of the experiments. So if we vary this in experiment and numerical simulation, so these are the fragments that we collect after our experiments in a turbulent van-Kamen flow. You can see that at small scale, for short time, you have large fragments and You have a large fragment, and for the same fragility or for some whittleness, when you increase the time, you decrease the size of the fragment that you can expect because you have the probability to have fibers that break is more and more important. Now, if you consider the same amount of time and you look at what happens when you increase the fragility of the fibers, so you go from the top to the bottom, you see that as expected, when the fiber is tough, meaning that the maximal curvature is important, the fragments are big. The fragments are big, whereas when the maximal curvature is small, you create smaller and smaller fragments. And to tune the free viscosity, to tune the parameter, we play once again with the free viscosity to modify the elastic lens. And experimentally, to change the brittleness of the fiber, it was quite complicated. So we work with glass fibers because you don't have any plasticity, but you have some effect with density that. Effect with density that might occur, but we think that they are negligible to understand our observation. And so, if you use raw fibers without any equipment, you have one whittleness. And if you eat the fiber above 600 degrees for a certain amount of time, you can change the whittleness of fiber. They become more and more fragile. Okay, so what happens when you look at the film? Okay, so what happens when you look at the evolution with time? So here is for the same with different experiment the size distribution after different time. So for short time you can see that you don't have a lot of small fragments, but when you increase the time you reach smaller and smaller fragments, but it seems that the size distribution saturates at the at one at this value, which is the elastic length. And you have the small And you have the same picture in numerical simulation, where initially you have a flat distribution because, as we will see later, the location of the fragmentation is randomly distributed in this case, and then you create shorter and shorter fragment to collapse the PDF towards the smaller elastic length. And if you look now, what happens if you change the brittle mass, as expected, once again, if you have a tough fiber that cannot be broken easily. That cannot be broken easily, you have larger fragments, and when you decrease the brittleness, you will have smaller and smaller fragments, both in experiments and in numerous. So, to explain our results and relate this observation to what we did on the deformation, we propose a simple model based on a population equation where we say that the evolution of the number of fragments of size L is given by a Is given by the fragments that are produced during a breaking of events of fiber that is bigger than the length L. And this number decreases when a fiber of size L is broken. And so you have two parameters that you need to define from the observation of deformation is the probability of breaking per unit time for fiber of length L, and then the location of fragmentation. And then the location of fragmentation. So, first, we will focus on the probability of working per unit time. And this is related to the distribution of the curvature. So, here, imagine that you have a maximum curvature that is, so I put it the distribution of the square of the curvature. So, it's the elastic energy, local elastic energy that is stored in the fiber. So, if you have a maximal curvature that is very big, much bigger than Big, much bigger than what you can wish, the fiber cannot be broken. In the opposite case, extreme case, if you have a maximum bending curvature that is very low, any fluctuation can broke the fibers and you will have very small fragments. What is interesting and what we get in our experiments is where we are in between these two regimes. So, to be broken, you need to, the probability to be broken is the probability to have a curvature. The probability to have a curvature that is bigger than the minimum value. So, this is given by the integral of this curve between the maximum curvature to infinity. And then for barylong fibers, you need to have this is a local approach, sorry. And so to the simplest model that we can make is to say that barylong fibers are constituted of n fragments of size L E. So you have n which is equal to the fiber length normalized by L E. Is equal to the fiber length normalized by LE. And the probability that the fiber break during this iteration is given by the one minus P L K B over L divided by L E, which is a classical Bernoulli probability equation step. Okay, and now we can plot P of L as function of kappa V, the maximal curvature, from what we get in our deformation. In our deformation model. Now, the second question is: where does the fiber break? And to do that, we need to look at the evolution of the mean curvature as a function of the position. And we make an assumption is that if I go back here, the curvature, the local curvature is the same than the mean curvature of the system, which is a first order, but this is. A first order, but this is the agreement between our model and the experiment seems to validate our measure, this assumption. And then, as you can expect, is that for a long, when the mean curator is higher, you have more probability to break. And so, for very long fibers, you can break independently anywhere in the middle of the fiber, but not on the boundary because of the boundary condition, which imposes that the curvature is equal to. Which imposes that the curvature is equal to zero at the extremity. And when you decrease the fiber length at the end, the probability is maximal to be broken at the center. So Christophe did the whole computation to have an expression of gamma L of L prime, which is the probability to be broken at a given position. And this is exactly what I said, meaning that close to the boundary, the probability to be broken is very small. But at the same time, for short fibers, the probability is very broken. For short fibers, the probability to be broken at the center is maximal. And for very large fibers, you have more or less a plateau to be broken. Okay, now we need to tune the time scale of this equation because gamma and p doesn't fix the time scale, and we do that by looking at the evolution of the mean size of the fragment that we measure. So, in the recurring simulation, we get one parameter for the time scale. We get one parameter for the time scale, which are this one. So the plain line are the observation from the direct numerical simulation, results from the numerical simulation. And the plane line, the dashed line, sorry, are the results from this model, where you have just one parameter which is related to the time scale of this equation. And if you do that, you can then look at the evolution of the PDF, which are the plane line from the numerical simulation. The numerical simulation and our modeling in dashed line, which are collate, which are reproducing very well our data, especially for large size. And the discrepancy at small size is related to the way we fitted the smallest fibers, but it's in very nice agreement. And if you look both at the evolution of time and if you look at the evolution of the stiffness of the fiber, the toughness of the fibers. Stiffness of the fiber, the toughness of the fiber. So it's the maximum evolution of the maximal curvature. We can also do the same for the experiment where you can define one time scale for each curvature and you can also reproduce the distribution that you observe, the size distribution you observe. Note that here in experiments, you cannot give one value for the maximum curvature. You have a distribution because of the distribution of defect that you can have into the. Distribution a defect that you can have into the fibers, and so you need to consider this distribution that we measure to have a nice agreement. Otherwise, the model cannot reproduce our observation. Okay, now if I go back to small fibers to because we know that it also exists fibers that are much smaller than the commodities in the ocean. And so Jamie Beck and Sophia Allende look at what happens when you have fibers that can be broken. That can be broken that are smaller than the common growth lines. As I told you at the beginning, you have only two possibilities for the deformation: either stretching or compression due to buckling. And they look at both scenarios. And so, as the tension is maximal when you are stretched, when you are stretched, the tension is maximal at the center. In this scenario, you only break the the fiber into two pieces, two equal fragments. Fragment. However, if you look at the buckling scenario, the probability to be broken depends on, and the mode that is selected depends on the intensity of the gradients that the fiber experience. And like that, you can produce small fibers. And here, as there is some time correlation for the forcing, contrary to our case, you can have some cascade scenario where you break first a fibers and can be broken then in several. And can be broken then in several pieces and so on, because the fiber is the different fragments are still aligned with the compression direction of the velocity coagent tensor. Okay, so to conclude on the fragmentation, we have shown that no new fragmentation mechanism at small scale are needed to explain the observation. And we hope that this scenario can be tested maybe in the ocean and in the model. Maybe in the ocean and in the model, and can help the modeling. And that the maximum of the PDF is given by the elastic length of fibers. So if we now look at the order of magnitude that we can have, so I note an oceanography. So I pick the value, the typical value for plastic, so one giga Pascal is typically the value that you can have for an island, for instance. The epsilon that I will choose is the one that we found for storm events. We don't know if they are represent or not. Or not reconstructive or not for in general cases. But with this value, we can have elastic lengths that are between two and five millimeters, so not that far from what is observed for the smallest, the maximum of probability for the size distribution of fragment. So, what we are doing now to try to extend our work is to look at more complex shapes because, as we said, shape matters in Side shape matters in microplastic. So we are doing experiments in a new tank. It's just that I got some funding so I can build a tank that is more is best to is better to look at Lagrangian turbulence. And we are looking at the moment at flexible dis and the first result we get is to to determine one flexible disshape can be bent and we show that there is a strong analogy with five That there is a strong analogy with fibers, except that for this, inertia cannot be neglected. And this change the time scale of evolution of the deformation. And so the expression of the minimal length that can be for this to be deformed. And here I plot just the equivalent of the end-to-end vector for fiber. So it's the ratio of the moment of the eigenvalue of the moment of inertia as a function of the turbulence intensity. And you can see that if we know. Turbulence intensity, and you can see that if we normalize with a balance of power relative based on the inertial time scale, let's say, you have a nice agreement. And you can see that the most flexible disk goes away from this, the deformation are weaker. And in fact, we can say that this is the same phenomenon that we observe for long flexible fibers. Tension becomes important, and so you are stretching that matters now. And so the dissipation. Now and so the dissipation, the viscous dissipation due to deformation are important. And if you look at this at the values that you found from this equation for the same material and the same value of epsilon, you get typical lengths that are once again in the good order of magnitude to what is observed for the maximum of probability for the fragment size distribution. The other question that we have is related to the dynamic. We have is related to the dynamics of fragmentation that is very important if you want to understand the fate and the time scale of evolution of plastic in the ocean. And I skip it, I pass on it rapidly before, because if you look at the time scale here, you can see that in the experiment, you need to wait for a very long time before observing any breaking event. This is very different in chematic simulation, where you don't have any intermittency, whereas the fragmentation is very fast. And we think that the difference is relatively... Fast, and we think that the difference is related to the probabilities that the fibers burn into the area of the region of the flow where the turbulent kinetic energy is important. And so, for this aspect, the density can change because you can have some expulsion of high verticity region, for instance, as the density of the glass is much higher than the one of the fluid. And finally, we want to look at the influence of the deformation. At the influence of the deformation on the dynamics of the particles that can change the diffusivity, for instance, of the plastic in the ocean. And so, here it's a recent result that Eric Hibara that is doing a postdoc at ERFE with me on the evolution of a flexible disk that is struck into a vortices and where flexibility is clearly important because if you do the same experiment with a disk with the same size, this same density, but This sand density, but Steve, you don't observe this phenomenon. Thank you for your time. And if you have any question, I will be pleased to answer. Thanks for the talk. We have time for maybe one or two questions. Nimish. Nemesh? Hi, Gauti. Really nice talk. Thank you. I just want to make sure I understand something correctly, so it might be a stupid question. So the elastic length, you find that scaling based on a balance of power, and then the dissipation there is the dissipation due to the increased curvature of the fibers. Is that right? So, but basically, if you think about the system, you inject the system is the fibers, okay? You don't care about the fluid. Fibers, okay? You don't care about the field. Here, the field is just due to the forcing. So, the energy you inject in the system is related to turbulence. So, this is a rho L cube epsilon that you can write easily from turbulent plot. Now, the dissipation that you want to, the dissipation that you can have is related to the energy that you stored into the fibers, and you need to divide this energy by a typical time scale. And so, for fibers, this time scale is given by Time scale is given by the relaxation of fibers with viscosity. Whereas for disk, the evolution of this time scale, which is related to inertia, so a bending mode, if you want, bending weight. Right, right. Yeah, yeah. This dissipation is related to when you have the particles that move into the field, you will have an additional dissipation due to the viscosity. Right, right. So I think I got that correctly then. So then the question is: should that not also depend? The question is: Should that not also depend on the number density, the number of fibers per unit volume, or the volume occupied by the fibers divided by the total volume? So here it depends. If you think about collective effect, we are in very dilute situation where you don't have any interaction between fibers inside the flow. So you don't have increase of dissipation due to particle particle interaction via fluid or solid interaction. Free or solid interaction. If you think about, then if you think about the whole system, in fact, you can sum the fibers if you want to have the what you want to do is the mean dissipated energy and the mean injected energy. And at the end, the number of fibers will cancel out when you do the balance between the two. So, not a problem if the number density is low, I guess is what you're saying. No, yeah, yeah. If you have very high concentration flows. High concentration flows, there you will have some trouble because you will have some dissipation that are responsible to the interaction between fibers. Okay, thanks for the discussion. The great talk, Gautier. Maybe we.