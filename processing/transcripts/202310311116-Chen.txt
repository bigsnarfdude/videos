Hi everyone, I'm Huan Cheng. I'm a CETA postdoc fellow at U of T and my main research area is costing rhythmization. And today I'd like to tell you something about how we can measure the realization history using the quasar spectrum. And this project is done in collaboration with Josh and Kiel Rogers at YOUTI. So first of all, what is realization and why do we even care about it? So realization is this important episode. Is this important epoch of time in the early universe when the majority of the gas underwent a major transition? So, our universe starts with a big band roughly 30.7 billion years ago, and the gas starts off very hot and ionized. As the universe expands, the electron moves slower and it will combine with the protons to form the neutral hydrogen gas. So, in the next 100 million years, our universe is. 100 million years, our universe is pretty dark. There are nothing particularly exciting going on, but gravity is still doing its work. It pulls matter together. So the denser region gets denser and denser. And finally, the first generation star born out of it. And once these first sources are born, all kinds of exciting events happen in, like stellar wind and they explode, they collapse to form compact objects. To form compact objects, and then those supermassive black holes rose and shine and feed back to the galaxy. So, on the largest scale, the high energy photons emitted by those sources in galaxies impact the gas at large. So, they will knock out the electron bonded in the hydrogen atoms and the universe, the gas. And the universe, the gas in the universe, become ionized again. And thus, this is the terminology where ionization comes from. It's the second period of time that our universe is in an ionized state. So this epoch is full of mysteries sometimes because it's so distant from us. Sometimes it's called the last frontier in astronomy. And that's why NASA spent billions of dollars to send JWST to try to find some and observe these first also. And observe these first sources. So, we really want to understand when, where, and how these first sources formed and when it started to impact the universe as a whole. So, theoretically, we know that this realization process is very complex, it's non-uniform. Usually, it starts with some over-dense region where there are more ionizing sources, and they form up. Ionizing sources and they form bubbles, and those ionized bubbles grow bigger and bigger, and finally, all the gas in the universe got balanced. However, from an observational point of view, the constraint on this realization is still not that strong. So it's still a very open question where realization starts and ends. Historically, people have been using the CMB to put a constraint on the midpoint of realization. On the midpoint of ionization. And that is because after the universe got ionized, there are a lot of free electrons which can interact with CMV photons through Thomson's gathering. And by analyzing the CMV power spectra, we can put a constraint on the midpoint of randomization like the gray band shown here. However, due to its integrated effect, it's pretty challenging using CMB alone to Using CMB alone to differentiate if the realization is start early but gradually or later and sharply. So this is a challenge using PonySDMB. But there is another way which gets more and more attention in these years, and that is by finding the signal of neutral gas in the universe from sources directly living in the Epoch Morean. Living in the e-popular organization. And the particle signal I've been talking about is the Lyman alpha damping wind. And this leads to the constraints here shown by the different colored dots. And the sources I'm most excited about are quasars because they are the brightest sources, meaning that we can observe them even in very high ratios. And these two. And these two violin constraints are from the quasars, like this kind of quasar spectra. We can get high quality spectra for quasars even at ratio 7 or 8. So, as a series, I would like to understand how accurately we can put a constraint using the spectra like this, and imagine if we Like this. And imagine if we could get the constraint at every restrict, then we can map out the detailed time evolution of randomization. So first thing first, what is the lambdalpha damping wing? So here I'm using my simulation to give you a visual example. So here is a simulation, radiative transfer cosmetical simulation, and this box at this epoch is half ionized. This epoch is half ionized. So 50% of the intergalactic median is ionized. So the yellow represents neutral gas, while blue represents ionized gas. And all these red dots represent the massive galaxies. So imagine there is a quasar living these massive galaxies and we observe it along this way. You will inevitably encounter many little patches in front of it. Patches in front of it. So here I'm showing the neutral fraction of gas as a function of distance from this quasar. So whenever the photons propagate and encounter the first neutral patch, they will create a Lyman alpha absorption line. And a note for people not working in astronomy, so a nice thing about extragalactic astronomy is that due to the Hubble law, every spatial distance is correct. Distances correspond to some velocity and thus due to the upload wavelengths. So you will probably see me using the length in distance and the velocity kind of interchangeably. So when it encounters the next patches, it will add on some absorption. And if you convolve all the neutral patches along this sign line, this is the final. Sign line, this is the final damping weight that I'm interested in. And a very interesting fact about the reionization is that although it's a very patchy process, it's still very structured because all these bubbles are due to the cluster of the gases. And if you go to check the simulation, you will find that the scatter of this damping wind is not that big. So here I'm showing the 68%. Here I'm showing the 68% of damning win shape at universe of different global neutral fraction. And you can find that, especially in the first half of realization, this scatter is small enough that allows you to differentiate cases with global fraction difference larger than 0.1 inch. So this is kind of promising, which means that this tells Which means that this tells you that if we can measure precisely even one damping wind, we could probably constrain the realization as precisely as point one. However, the real life is always more complicated than that because this damping wave is not really directly observable, it's only one component of the real spectra. Of the real spectra. So here I'm showing a more realistic simulated quasar spectra. The damping wing I talked about is this kind of orange envelope. I'll put it into a more intuitive spatial picture. It's a rise from a neutral gas outside this quasar impact region called the quasar proximidisome. Inside this quasar proximidism, Inside this polyzaposamini though, there are still a lot of absorption due to the residual neutral gas of neutral fraction 10 to the minus 5 inch. And this makes this inference of this damping wing quite challenging. But the good things about this quasar approximate zone is that the radiation profile inside is pretty predictable. It's almost So yeah here I'm showing the ionization rate of this as a function of distance inside this proximity zone. We can see that this is entirely transparent to ionizing photons. As this profile is very predictable, it's almost perfect law as r to the minus 2, that geometric dot ocean. The structure The structure, the structure, which was we usually call the lemma before it, by the way, is also very straightforward to model. So imagine we live in a universe without any neutral patches. This is the lineup of a forest in the quasar cosmetic zone. And all these strong absorption lines correspond to the denser gas in the cosmic filament. You are showing the corresponding density fluctuation. Density fluctuation. So, all this absorption is due to the density fluctuation in the large-scale structure. So, our goal is very clear. In this type of spectra, we try to infer this using this envelope to infer the global neutral fraction as well as the size of the quasar-approximated zone. And the challenge here I had is that. The challenge here I had is that how to describe the likelihood function of all these correlated pixels. And I struggled with that for a bit. And then I consult an expert in statistics, like Josh. And then I realized, well, in machine learning, people have already been working on this exact problem of intropractical light paper for a long time, and there are many tools. A long time, and there are many tools developed. So I started to play around with this like info-free inference with conditional normalizing flow. And the specific package I'm using is the SBI made by NACALAB. So what I need to do is train a neural density estimator. And the training data I use is kind of composite spectra database. Database. I first sampled the landmark of a forest in the quasar possibility zones in six of my simulation boxes. And then I also sampled the damping wind from my simulation with different neutral fractions. And then I put them on top of each other to form this synthetic spectra. And I made another separate set for testing. And And here I'm showing one of the results. So here is one example. This is testing data. By the way, this blue line is the beam spectra which actually goes into the training machine because this is roughly the quality of data we have now. And here I'm training this. And here I'm training this density estimator user mask autoprogressive flow with five hidden features and the five transformers. And this is the posterior weak dot. The red dot is the bound choose and we can find that SBI reproduce this quite accurately, which is also very exciting. So how does it compare with the So how does it compare with the more traditional result method used in previous work? So previously people have been proposing some pseudo-likelihood, assuming that if you beg the pixel this way and more or less you just treat it as independent and the final likelihood you just times the likelihood of each pixels. And this likelihood is estimated by some histogram. By some histogram. And if you apply this pseudo-likelihood method, this case will result in this kind of posterior, which shows a clear degenerate trend. Because if you ignore this correlation, you can have this kind of spectra, which give you a higher likelihood here, or this steeper function that gives you a light slightly higher likelihood here. So, I did this. I did some standard simulation-based calibration using my testing set for both this SDI and the previous pseudo-backrium method. This is just a side-by-side comparison for this one single case. And for this entire test set, I performed some calculated the rank distribution of this true value. And here I'm showing the result. Showing the result, the distribution of the SBI method and the pseudo-likelihood method. And the SBI shows that its distribution is consistent with the uniform distribution, meaning that the inference is unbiased, while the pseudo-likelihood methods result in this U-shaped distribution are telling you that this constraint, the uncertainty is underestimated. And here, Estimated. And here it's also showing that SBI has a smaller bias in general. So again here, I'm also showing the scatter of this inferred global neutral fraction. And the scatter is around 0.1, which is very encouraging and exciting because this is almost an optimal. Almost an optimal inference you can get because remember the cosmic variance of this damping wind is also tells you using one single spectra, you probably just can get a constraint about this accuracy. I also have done some tests with multiple spectra. You just stick this spectra together and put it into this SBI. It into this SBI, and we find that if you increase the number of quasars by five, and then it's scatter reduced by half by roughly what you would expect. So here, let me just summarize my talk. I hope that I showed you, despite the patchy nature of realization, the damping wind has a small scatter. And using simulation-based inference, we could achieve. Based inference, we could achieve an unbiased inference of the neutral fraction to around 0.1 for a single noise spectra. So in the future, we also like to add more realistic noise of different kinds and to really do some end-to-end testing for how, in the real world, how this method works. Any questions? I don't know if it's premature for this, but have you gone back and re-examined some of the literature constraints on visual fraction from backing wing measurements to see if you might be biased? Sorry, what? Have you like read, you know, there's all these literature plots of You know, plots of amplifier wind constraints on the ionization discrete. Have you tried to apply your code? Yeah, this is what I'm currently working on on a separate project more on an observational side. But I would say the arrow bars that show all this is only part of this error bar. It didn't consider a lot of system methods. So yeah. I have quite a question. If what's the computational cost of running all these simulations? Is it quite heavy or is it perfect? Yeah, so if you want to so I do this training data set in a conversated way list because my s my simulation code will like it's more costly to It's more costly to post-process the sign lines in a more neutral universe. But you can speed it up, or you can just split it into different part, which I believe is, I'm also testing it. But there are also a lot of nuances in the heating history, but yeah, the computational heavy problem is that run a bound sign with higher results. Now we're signing with higher resolution. Quick question while John gets second. Okay, let's thank Runching.