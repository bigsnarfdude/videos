Okay. I'd like to thank the organizers for that talk. I'm going to kind of talk about a couple of tricks today, which I've spoken a lot about in previous talks. So none of this should come as much of a surprise. And your tricks are a way of converting some topics. Way of converting some topological problems into lattice embedding problems. And then the other trick is how to solve those problems by comparing the lattices that come up. And I wanted to highlight a couple of places where I think these tricks need more development, and I'd like to see progress. So I'll begin with some motivating topological questions. Some motivating topological questions, but just a pair to keep running throughout the talk. And these are problems that many of us have looked into as an aspect of. We start with a rational homology sphere, and one very natural question we look at is we ask whether why is rational neural board fits the boundary of a rational homology ball. I think that's a middle bed board. Nothing before is a smooth rational. Everything I'll do in the top will be in a smooth category. So that's one question you can ask. And another natural one is whether y is a Dane surgery along an odd. Increase it here. This would be my notation for Dane surgery along an odd. So K is odd in S3, and P denotes And P denotes some positive integer for this talk. So I'm thinking about when I say is y a not surgery, I mean positive integer, tank surgery, a lot of non-exercise. For the most part, I don't know. Okay. So I wanted to mention a couple of obstructions that are very well known, get used to address these problems and relatives of enough. And those are. And those are coming from Donaldson's theorem and coming from the invariance in Higgard for homology. First trick is going to be to combine those two to get interesting lattice constructions. Okay, so I'll just remind you, Thompson's theorem. This is the theorem characterizing intersection forms of smooth closed definite four manifolds. So the hypothesis is that four is going to denote. The Z4 is going to denote what I just said: a closed, smooth, definite point hold. And the implication is that the intersection pairing on Z, this is my notation for this, this lattice attached, which is the second homology group of Z of torsion. equipped with this metric unimodule in bilinear form. This is diagonalizable. The notation I will use for that is IM, some lattice notation. That's just the lattice of rank M that has just an orthonormal basis with an L. Or you could write Z M copy. Or you could write Zn, and think of that like the identity matrix. Okay. So this is a useful obstruction for these kinds of questions if you know a little bit more about the three-manifold way. So to apply it, we often want to look at a class of three-manifolds which arise, which have definite fillings. So I'm going to suppose that y is the boundary of x-core, where x4. The boundary of x4, where x4 is definite. And I'll want to make sure I'm looking at a, you know, that that's a rich class of examples. Some examples of this include, say, Wi-Fi could be a lens space, or more generally, it could be a separate hybrid space. Or more generally, but in a different direction, it could be the branch double cover, branch double cover along some alternating length and these here. These are all examples which definite fillings. I'll say a little bit more about those in a little bit. Well, then we get some nice obstructions. Get some nice obstructions. So, with regards to the first problem, if my manifold happens to be not a rational, it's going to be the same, well, this isn't the trick yet, but the idea is the same in both cases. I'm going to take my filling four-manifold, and I'm going to glue it to my putative rational homological. There's something a little bit funny there with orientations. Maybe I should reverse orientation on this. Reverse orientation on this, and I should assume perhaps that this one is a negative definite. Again, I guess the statement Donaldson's theorem I had in mind, that's a positive definite holds with either sign. So if my rational sphere is the boundary of a rational ball, then I can glue these two together. And what I end up learning is that the intersection The intersection form right like this. So this is going to be now a positive definite mass. This is going to embed into the with full rank into the standard diagonal IS have this full ranking value. And that's for interest. I think it's quite That's for interest, I mean it's quite a restriction. So, you know, it was noticed 40 years ago, you know, if you took widely, say, the branch cover of the minus 3, 5 cell pretzel, it fails to bound a rational model because it has this nice unimodular definite filling, which is not isometric to standard lattice. That's a that gives the proof that minus three pi seven parents was not smoothly slice. Seven principles not, it's move resize. Okay. Okay, so that's one lattice restriction. In the second setting, we can play a similar trick, except instead of putting on the rational wall, what I'm going to do is I'm going to take the trace of surgery, trace of p3 and vein surgery, well, okay, and attach it. Okay, and adapt it. Trace of surgery. And the implication in this case is that this lattice, once more it embeds into the standard diagonal lattice, but now it has, I guess we'd say, code rate one because this piece has embedding number B2 equals to one. If I label my embedding, If I label my embedding feed, then the orthogonal complement, then I'm just saying, is spanned by a vector called the notepi sigma. And the only thing I know about this vector sigma is it's self-pairing. Self-pairing is P. Write it out in integer coordinates, and the sum of the squares of those coordinates is. So, those are some useful applications of Donaldson's theorem. You can get some IELTS out of those. So that's the Donaldson's theorem obstruction. Now, there are obstructions coming from the B invariant as well. So, in the context of bounding a rational ball, Bounding of a rational ball. What the D invariants give in this setting is you can look at Spincy structures on the filling rational ball. You can restrict those to Spincy structures on Y. And the wonderful fact is that any Spincy structure you choose on Y, which is the restriction of one product, has advantage of being there. for any spin C structure you choose, which is the restriction of something from the four manifold. And there are lots of these, relatively speaking. So the image of R is a, I wish I could say subgroup, but it's a subcourse or of frequency structures on Y. And the order is equal to the The square root of the order of, well, first homology, the number of spinsy structures on that. So you have a lot of vanishing d invariants. That's useful. In the context of the second problem, if you know a little bit more about manifolds, like all these, many of the examples I've mentioned have this feature, and then branch shift codes are alternating in. Feature and then branchable because of the alternating notes, are examples of all spaces. Then there are some nice formulas. So there are these efficiency formulas. So I can label expensive structures on y. So I'm assuming that my y is, you know, doing, I'm doing an L space search. I'm doing it. Surge will wrong or not to get an L space. Surgery along a knot to get an L space. I'm doing P-frame surgery along my knot. There's a way of labeling Spincy structures by integers between minus PO and 2. And the statement in this case is that I'm using annotation, the difference of the correction terms for y from just doing p-search view of the unnaught, these are governed by the torsion coefficients of the. Of. But the knot you're doing dang surgery along. And for an L space knot, these coefficients are especially nice. So they form a non-increasing sequence that's going to go to zero, and each drop could be by at most one. Not many people use these by. Not going to be able to use these fabs, but it goes down by one or zero each time. Yeah, so if you were trying to rule out a particular L-space from being surgery along a knot in the three-sphere, you would know your piece should be its order of worst homology. And then you just try to match up spincy structures with those on piece surgery on. Goes on a p-surgery on your own knot and see whether you could produce a sequence of integers that happens properly. Do it, and that tells you that. You're down too with the D invariants work quite well. It plays very well with lattices. But I want to organize at this point. And my motivating problem is bounding a rational ball being not circuit. Useful circumstance is when you can calculate the invariance from a filling form manifold. So this is the definition. So if I'm in the setting where I'm now assuming y is Now, assuming y is the boundary of a positive definite poor manifold, x score is set to be sharp if the d invariant. So in general, you have some inequalities with the invariants and some alphabetic topology information from your format, which take the form that the divariant is bound. The D invariant is bounded above by this expression, which looks like it comes from some kind of index formula. So I've chosen the L Spincy structure of X, which restricts the one automatic. So we have these inequalities in general. Four manifolds called chart of, in fact, Is called Shark of the fact that the D invariant in each Fincy structure on three manifolds is actually the minimum of these funny values. This is true for every Spincy structure. And we have the same examples as before. So lens spaces, cipher pygrid spaces. Hybrid spaces, provided you're allowed a choice of orientation, and branched double covers of alternating links, whole bound shock forms. So standard examples for a lens space LPQ. You found this linear plumbing along spheres, something like this, where these coefficients are governed by the continued fraction expansion. Continue fraction expansion Q. So this kind of a filling is a definite filling of a lens space. For cipher fibric spaces, we have star-shaped pictures which generalize this linear picture, these linear lattices. And my favorite example, branched double covers of alternating leaves, have these nice Gordon Lutherland. These nice Gordon Legal buildings. I'll do one example, because that's a nice to look at. So if I took it from Start from an alternating projection, I can give it a well, on paper it would be a checkerboard, a chessboard color, huh? On a blackboard it would be checkerboard coloring. These more Christmassy AAs. You get this spanning surface, this checkerboard surface, where the red one. For the red one, I'm going to put a vertex into each region and drawing the take graph in this way. This is the take graph instruction. So from my alternating diagram D, produce this take graph G. And this graph G has a lattice attached to it, a lattice that flows on the graph. So these are, it's just the cycle space of the graph. The cycle space of the graph, but it remembers an inner product. So, in this example, you see the cycle space of this graph is generated by two facial cycles, labeling A and B. So, my flow lattice in this example is freely generated by these classes A and B. And I just need to tell you how they pair together, pair with themselves. I get that by the Compared with themselves, I get that by looking at the picture and seeing how many oriented edges they have in common. A is a four-cycle, so it has an apparent four. Their product oriented cells. B is a five-cycle. A and B have two edges in common, but with these orientations, those edges are opposite to one another. So these varying s minus two. That completely describes a lot. So, what I'm telling you is that the branch double cover of an alternating link has a sharp fill in, and the intersection pairing on that sharp filling is given by the lattice of photos on the tape graph. So this plays well with this abstraction. You can really just calculate the data variance right on the nose from this filling sharp form. Filling shirt for I go until 15. Alright, so ready for the first trick. So first trick is to combine these two abstractions, Donaldson theorem obstruction and the invariant obstruction. Tip number one. Tip number one. David Darlinson theorem, construction, and construction, D and D. So here is the pair of theorems that you get. By the way, this is supposed to be a menu of lattices. Linear lattices, star-shaped lattices, lattices. These lattices come from menu A. Where does this come from? Then you may. Just wanted to put that there if that was mentioned in the abstract. About to get to know UK. So here it is. So here are a fair theorems. So theorem one. This is a theorem that I did jointly with Slavin Yavaka. It was the first time to run this trick. So the setup says, before so, y is a rational homology sphere, the boundary of a sharp form manifold. And we assume as well that y is the boundary of some rational homology bulb. Again, everything is smooth. Then, right, the thing that was here. Right, the thing that was here previously was the statement that the intersection of lattice on X should embed the full rank into the standard Euclidean lattice, I n. So this implies that lambda X embeds the full ring into the diagonal lattice. But we gain more by knowing that these corrective terms vanish. Terms vanish. So, what's true is that, moreover, every unit cube that you pick with vertices centered at vertices at points in this lattice, so what I'm trying to say is that any time I choose a vector, I n, and I look at the cube that has that, say, as its bottom left vertex, this cube. This Q This Q intersects with my embedded subtle address optically. So that's a theorem. I'll give a quick example of it. Turns out this is an example. Of it. Turns out this is an example where the branch-double cover bounds a rational ball. This should have an embedding of this kind into the lattice I2. Okay, so I'm trying to embed this lattice described here in terms of generators and pairings in just the standard integer lattice in R2. So I need to find a place to throw. So I need to find a place to throw the vector A. I have to throw it onto something that has self-pairing 4. A good choice would be, for example, the vector 2,0, medium of A. Then I need something that has self-pairing 5. So you're thinking of something with coordinates 2 and 1 in some order with some sign. But it also has to have pairing minus 2, the one that I already wrote down. And we'll find what this is. Down. And you'll find that this is a good choice for B. And those populate a sublattice. I'm just going to draw on one of the other forms of that sublattice that I got. There they are. And you see immediately in this picture, anytime I pick a square that has vertices of lattice points of the I2 lattice, it contains a point of I embedded in some. Point of my embeddedness of lattice. In particular, that tightly constrains what the discriminant of this lattice could be. It has to hit every unit cube. So in particular, this is saying that its index at IN is no more than the number of points in the Q this as the consequence and that the discriminant of this lattice. And that the discriminant of this lattice cannot be too big. The discriminant is going to be the square. So this condition we gave a funny name to. Because it's ubiquitous from the point of q, so we call it cubiquitous. A bit of ahistorical. Okay, so in a paper with Brendan Owens, we call it cupoquitus. We call it ignootis. It wasn't in the original paper. Where did I use theorem? It is, yeah, so I mean, Donaldson's theorem is giving us this abutting. Ah, sharp is, so I also know that my d invariant is going to vanish on a lot of spaces as really equivalence classes of some. Classes of some elements of this lattice. So, what's going to happen is to values that I'm taking are really identified with characteristic elements of this lattice IM. And in order to get this value equal to zero, this element has to be a plus or minus one factor. So, saying that these d-invariants are vanishing is going to be saying that every, basically it's going to say. Basically, it's going to say that in every coset of my embedded lattice, I'm going to pick up a plus-minus one vector. And I'll have that all at once to say that I have this cubic condition. Alright, well, you c you can do it with some kind of converse. You conjecture some kind of Congress. Right, yeah, we do conjecture Congress. I was going to mention that. Yep. So I could mention that now. So conjecture really, so this is a conjecture a friend and I have made. Maybe I'll get time to talk about some evidence for it. Is that if you specialized in the case of the branch. If you specialize to the case of the branch double cover of an alternating link, conjecture that this manifold you get bounds of rational homology follow if and only if this condition. So if I take the last of those on the tape graph, Forward direction is that theorem, or implied by that theorem. The reverse direction is what we would conjecture that. Somehow having a buttiquitous embedding of your lattice is supposed to guide the construction of some kind of rational wall going here. Ranch double cover. It can do in some cases. I think there are a lot of The theorem along these lines is assuming that y is searched along a naught. It's also an L space. And I should have said also that, as before, y is the boundary of a sharp format field. And here I want it actually. Um and here I want it actually to be negative delta. So something a little bit on board about. But then like mentioned before, you get this embedding from Donaldson's theorem, which has a covariant one. You know that the orthogonal We know that the orthogonal complement spanned by a single vector self-guaranteed. But furthermore, this vector has an interesting combinatorial property. It's what we call a changemaker vector. So that could have been highlighted in that. Highlighted in red. So you're looking for a co-rank one embedding of your lattice, but it has to be orthogonal to a vector with a particularly contrasting form. And the way you think about them is they're vectors, you put the numbers in increasing order, and they're going to give something away. And you ask, is it the case that every number on my list is less than or equal to the sum of previous ones? And I think that's the case. Vector? So a non-example of this theorem would be the length space L101. So So I would be attempting to embed, so I have in mind that I'm getting some signs off, but I'm just imagining that I have a rank 1 lattice generated by a single element that's subranked 10. And I'm asking, can it embed in the lattice y 2? And that's the same as saying, can I write 10 as a sum of two integers? Yeah, so I can. Yes, I can embed it in this way as the vector 3, 1, even negative 1. The orthogonal complement to that, though, is this vector 1, 3. So, you know, it passes kind of naive earlier version of the Donaldson test. It does have this co-ranked one embedding, but the orthogonal complement is not a change maker vector. 3 is not less than or equal to the 0. vector. Free is not less than or equal to 7 plus 1. 3 is not less than what? Yes. Well, 3 is not less than or equal to the sum of the previous values plus 1. What's the sum of the previous values plus 1? Is any of the 12? Yes. And 3 is not less than or equal to the sum. Oh, not less. Yeah. Equivalently, if you had. Equivalently, if you had a $1 bill and a $3 bill and somebody asked you for $2, then you'd have to use it. That clear things out. Okay. So away goes menu A by accident. But okay. So I told you a bunch of lattices which come attached to some standard examples. So some standard examples. Linear lattices, R-shaped lattices, graph lattices. And now we have some new funny kinds of lattices. NUB. And so we get down to comparing lattices and we ask which lattices on N and A appear on N. Here on line B. Because you're interested in maybe some specific instances of some of these problems I've mentioned. So some specific problems, one of which I already gave a conjectured answer to. You could take, for example, branch double covers of alternating links. So which branch double covers of alternating links? Branch double covers called negative links found rational balls. And you're led to ask the question, which lattices of flows on planar graphs, which flow lattices on planar graphs are going to go from A. This is on B. So anyway. So we have criteria. Um another would be well just so I handle it, but I could ask um well okay. I could ask which one spaces are not surgery in the way that I mean I mean In the way that I mean, I mean integer, positive integer, ding circular. And this is asking for which linear lattices are Hangemaker lattices. And the remarkable thing is that when you can solve these problems, when we're not done solving that problem, we have a conjecture. When we're not done solving that problem, we have a conjectured answer. But it's just empirically true that whenever you find flow lattice or planar graph, which is ubiquitous, or you find a linear lattice, which is a change maker, then that corresponding branch double cover of an alternating length does bound a rational fall off the corresponding bone's base is gained surgical on. So, yeah, doing a very complicated combinatorial analysis, you can Complicated combinatorial analysis, you can solve that problem completely in the corresponding topological one. In this one, we just have some partial work, partial check mark. We have partial progress. Yeah. Okay, what exactly does this? What exactly does it make for the linear lattice we change? So like the vectors generated? Yeah, I mean that you can take your linear lattice and embed it with corrupt 1 so that the complement is a changemaker factor. So really which linear lattices are without no complements too. Do you have any other thing that's Okay. Yes. Some plot the alternative, but probably, but not all. Okay. I did want to mention that. Yeah. I mean, we want to expand menu A and menu B. And I don't know other conditions besides these two that go on menu B. So if you have some nice dein variant obstruction for some problem you're studying, see if you can combine it with Donaldson's theorem and generate more things from menu B. That's one problem. That's one problem I wanted to put out. But are there other manifolds which bound sharp or manifolds? Maybe you would want to throw those onto Venue A. The answer is yes. In fact, at one point I'd ask, so if you take the branch double cover of an alternating link, you found a sharp formidable orientation. Does the mirror of an alternating link get an alternating link? The answer to that is no. The answer to that is no. So there are some examples to do for Ballinger. The Ballinger showed that there's this class of graphs called planar graphs, you've heard about them. Those are the ones that you you see when you get when you do take graphs of alternating productions, for example. For example, there's a class of graphs called apex planar graphs, which is just where you take a vertex and you join it to every vertex of a planar graph. Like K5. K5 is an example of an apex graph. They're often just called apex graphs. And, you know, there's graphs in your literature on them. They have link list embeddings and space. So Balancer gave a really nice class of examples. Balancer gave a really nice class of examples. He showed that for every apex graph, there's a mild generalization on a planar graph, there exists an L space y such that y bounds a sharp Fourier manifold x plus minus y bounds a sharp Fourier anift x minus, so these are both sharp. So these are the start. And the intersection lattice on X is isomorphic to the flow zone the graph G. And the lattice on the other four manifold part is dual to that. It's multiple in some sense. It's the cuts on. So this would be an interesting. So this would be an interesting founding of examples to study more. Might even be able to produce strong L-spaces amongst them. Take the L-space corresponding to K5. Ask, is that a strong strong? If you don't know what that is, then. Josh, what what did you say? Lambda x minus is the lattice of cuts on this graph. Lattice of cuts on an histogram, which is a lattice I didn't really tell you about. Yes. Do you think that you can generalize to a large company of graphs? Yeah, that's, I mean, it's tantalizing. I don't know. You might ask if you could build an example like this for any finite crap whatsoever. So accurate. If you have a manifold which bounds sharp fillings with both orientations, there is a strong restriction on what the lattices attached to those are. And the restriction is that they're, I would have a hard time remembering what everything I'm about to say means, but it's the lattice of flows on a regular atrophy. And lattice is a flow zone of graphs, I populate. Flows on the graphs and populate kind of a pretty dense family of flows on regular measurements. You should be looking for examples which have intersection lattices which are like flows on a graph or something mildly general. Five minutes gives me just enough time to talk as much as I want. Just enough time to talk as much as I want about trick number two. How to compare. You don't know if these all spaces aren't branchable covers. I don't know if these are branched double covers. Yeah, it's not clear. They're just given by some Kirby diagrams. I mean, they have these, you know, they're they're like these chain mail links. People recovered this. Ago recovered this L space result. So, yeah, so Ballinger's examples are a subset of some of the examples that I and Akle wrote down this chain help. So, okay. Well, I just wanted to mention how, you know, if you if you wind up with one of these kinds of problems where you're comparing um a lattice or menu A and the A lattice for menu A and a lattice from menu B, you know, how in the world are you going to solve it? How are you going to compare two different lattices? And that trick is to study the way into these lattices empirically seems to be to study so-called irreducible, also known as the literature sometimes indecomposable. Also known as sometimes like the Lee Theory Literature, lead simple elements of my essence. This is a useful way for comparing them. Because if I'm just given a pair of lattices, like say I'm given a basis for each one, how are you going to test all the possible change of basis matrices taking each other? Nice if you knew something a little bit more about the bases you're looking at. You can get them if your bases consist of simple elements. So, quick definition. So, lambda is going to denote some definite integral lattice, probably just a brief lattice. V is an element of the lattice, and I'm going to say it's reducible. If it's possible to write the lattice as a sum of elements, both are non-zero, and where the inner product of these is greater than or equal to zero. So I can write it as a sum of vectors that make a right angle or a QR look one another. And it's irreducible otherwise. For example, in Im the irreducible elements are just like unit vectors. The irreducible elements of The irreducible elements of EA, which has yet to come up in this talk, these are its roots. But more pertinent to our examples, if you look at irreducible elements in the linear lattice, say I'll label these generators x1, x2, x, xm. So these label the generators a hundred. Label the generators. I'm not talking about their self-apparents in this picture. Irreducible elements here are just what I get by taking some path. So I just take some xi plus xi plus 1 plus i plus j at the expense of putting the sign. So any combination like that, these are the irreducible elements of this status. And this status. And this fact nicely generalizes. It's not obvious that this is a generalization, but it is. If I look at the irreducible elements of flows on the graph, these can be identified with simple cycles in the graph, oriented cycles in the graph. So like graph theoretic cycles. Not like cycles. And that's hands up. Well, I'll take two minutes there. So so change makers have very nice change maker lattices have very nice bases of Very nice bases. So changemaker lattices have nice bases. And when you write them down, they have what I call the standard bases. And all these standard bases that there's already usable. All irreducible elements. So, you know, if I wanted to So, you know, if I wanted to, if I had a linear lattice on my hands and I wanted to know as a changemaker vector, I have this standard basis for my changemaker lattice given. And I'm asking, could it somehow match up with some subpaths of my linear lattice? And just taking that point of view, thinking about how different irreducible elements compare together, what. What motivate what's the engine behind comparing change maker lattices and linear lattices? Really comparing your useful elements and these lattices that enables that classification to go. That's one of my two minutes I've taken. The last thing I'll say is, so you know, I've alluded to, and I'm not going to put it up on the board, this partial result that Brendan and I gave in support of our conjecture. Our conjecture. That was a case in which we weren't just looking at ubiquitous lattices, but we were looking at very sparse cubiquitous lattices where you have a... You actually give rise to a cube tiling, a Euclidean space. For these cube tilings, there are very nice bases attached to them. They have irreducible elements. Then you can compare it to flows on the graph. But what's missing is some nice description in general. Description in general of nice bases for ubiquitous lattices. So, for the very lattice-friendly, I'm going to put this as kind of a question which has impeded progress on our conjecture, which is, is there a nice way, so is there some kind of nice or preferred basis of irreducible elements where you run up a mill? Ubiquitous lattices, which you could then hope to use. In order to figure out which rare lattice is that's a problem which frustrates me. And I asked for more lattice vetting restrictions coming from being variants and stuff. I mentioned balancers, examples, and so I'm happy. So I'm done. Alright, just like Jack. Alright. Can you say where the phrases change, Mafia? Well, it's because if you, these vectors have the property that if you think of the, so they're like non-negative integers, positive integers, you pretend that they're values of coins, and so they have some total amount at the moment. So, if they have some total amount, add them all up. And then, Bustin you would ask of a collection of coins is: can you make exact change from any value from one up to the total amount using coins? If so, then it's called a change maker, if not a change maker. The smallest amount should be one penny. I want to know what that should be one is the definition means. Very good. What would the next coordinate have to be? One or two. One or two. Okay, well thank you again. 