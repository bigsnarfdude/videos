So, in general, we can have a Z D lattice, although in the future, later on, we'll talk about the Z1 for the XY chain. But in general, you have a Z D lattice. And then for any point on the lattice, there is a local Kilbert space. You can call it HM, but you're Usually this HM are just a finite dimensional space, for example, Cn and here if n is equal to 2, so if it's C2, then it corresponds to the spin one-half system because you have two states of the electrons spin up and spin down, right? You need two-dimensional vector. And if you have CN, that corresponds to a spin n minus one over. n minus one over two system okay so at each point there is a local Hilbert space and then for some set of Z D for example we call it J then there is a composite Hilbert space we call it It should be called H capital J. In that case, it's just a tensor product. Oh, the local ones. So M is in J. So this is a tensor product space. And let me introduce what are the observables. And these are the operators. The observables are the bounded operators. A we say this in this capital AJ space that is the tensor product of all the bounded operator on each local Hilbert space. And there are some many examples of such being system, for example, there are Heisenberg. Heisenberg model, which is about a Sabine Mahal system, where you have C2 for each local hilar space, and there are also some so-called AKLT model which about the spin one system. So you have C3 for each local hybrid space. Okay, so now let me get to the model I'm going to talk about. Model I'm going to talk about today that is called XY chain. So now we return to the Z1. Let me add another page. So we consider a piece of Z. Let's call it 1 to N. So it's a lattice, it's one-dimensional. dimensional one two three that are capital n and here we consider spark system so that at each space each side you have a c2 vector and the hilbert space is a tensor product of them okay so the dimension of this hilbert space because it has a product so you multiply the Because it's tensor product, so you multiply the dimension, so if dimension is huge, dimension of the Qber space is 2 to the n, not 2n, as it's not direct sum, it's a direct product. And the homotonium we are going to talk about, which is called unazotropic. Of course, we want to also talk about azotropic, right? XY chain. Right xy chain is we call it capital Hn that is the sum of n minus 1 mu j mu is a Kabbalian constant and 1 plus lambda j. Lambda j is another Kaplan constant. I will tell you what are the meanings for that and 1 minus lambda j. So now Minus lambda j. So now you see it's anisotropic in this sense because there are two, you have one plus lambda and one minus lambda. So these are the xy terms and there is a diagonal term which is comma j sigma z j j from one to n. Okay, so first Okay, so first I have to tell you what is what are these sigma sigma x sigma y sigma z. So they are the poly matrices and let me just maybe let me just write it down it is 0 1 1 0 sigma x sigma y is 0 i negative i 0 sigma z is 0 is 0 sorry 1 0 0 negative 1 so these are the polymatrices and what are this sigma x with the j with a sub index j that means this is sigma x on j you can understand it this sigma it acts on j so it kind of acts on the j's component of the hilar space and it's time service identity operation Tensor with identity operator on the remaining part. So it's a local. It acts only on the J set. So there's a local. And these sigmas, sorry, this mu j and lambda j, lambda j is usually between zero and one. 0 and 1 and they are complete constant. In particular, this lambda j characterizes the brands of the anisotropic interaction. Between the nearest neighbors, right? Here is sigma x jj plus 1 and sigma y jj plus 1. And also, this mu j is a gamma j is just some potential, right? So that is the definition of the xy chain. So what is the object we will try to study for this for this harmonian for this on this tensor product space? On this tensor product space. So, the same we are going to study the so-called Lieber-Robinson bond, but before that, I have to introduce what is Heisenberg dynamics. So, it's a volume, so we take observable A, which is, we know, is just operator. And then you evaluate it in time, right? Define this tau t A is time evolution of this operator under the Hamiltonian that we have. That is e to the i T H N A e to the negative I T H N. This is the total T. This is the time evolution. Of the observable A. To see why this is a time evolution for this observable, the reason is very simple. Because if you take an initial state Poseidon in the Hilbert space, and then you And then you evolve it in time. You know, Possibi T will be e to the I negative I time T H N Possi. This is the state when you evolve in time at time t. This is passive t. And then you try to make an observation by taking your observable and just take the quadratic form. And this is you plug in the state at the time t and you move this to the other side and this is exactly the total TOA. So it's a different idea from the From the it's a little bit different from that you look at the time evolution of the state. Here, you look at the time evolution of the observable, which are the operators. So, this is Heisenberg. This thought here is called the Heisenberg dynamics. Heisenberg dynamics. And let's just not call it it. So, then what is Lieb Robinson Baum about? So, for now, let's return to the most general setting because that was what was proved in Dieb and Robinson's paper. Very general. So, if you consider a Z D letters and you take two sets, J and K, in the subset of the letters, and you assume they originally don't intersect, they don't overlap. And now we take some local observables A that is in AJ and B that is in AK. So they are local in a sense that A X on the J sets, B acts on the K sets, and they are disjoint. So they are local. So you can immediately know that the commutator. Immediately know that the commutator is equal to zero. So the Lieber-Robinson bond is a bond of the following form that is bound in the not bounding the commutator of AB, but bound in the commutator of tau t of A and B. So the time is the commutator of the time evolution of A and B. This is Lieb-Robinson bond. That is a bound of the folding form, so bound by normal A, that's very natural normal B. But what's an important thing is you have E to the negative, maybe here you need to put a constant C, but it doesn't really matter. But E to the negative eta. And distance, djk is the distance between the k and j sets minus vt. So where eta is positive. Eta is positive, and djk is just a distance between the two sets j and k. And v I will say the best possible v is called the Lieber-Robinson velocity, but let's call v the velocity. Okay, t is time, and I will show you why it is called the velocity in a second. Lost it in a second. Okay. And so this is the Lieber-Robinson bond. So Lieber-Robinson proved for a large class of operators, spin systems. So that was proved in 1972. For a large class of subinsula. Uh so being says comes Let me tell you why why do why do people care about such kind of comment it's about the commentator because because when I first learned it it was not very clear to me why why do people Clear to me why do people want to ban the second or commentator in the first place? So, this is why this is the reason why we have a Z D letters. So, let me for simplicity let's just draw a Z2 letters. And the J and K, they are two subsets of J2, Z2. J say two say two that but that's let me just take them to be two points so some j and k they just consider single points okay and let's say there is a person called Alice that is standing at a j set and there is a person called Bob that is at a case set Alice has a homo Alice has a observable A and Belb has observable B, right? And let's assume A is unitary. I want to show you why do people care about this kind of bond? And hopefully I can convince you why it's related to localization. Some is related to localization. Okay. So here is what Alice will do. So you have an initial state. An initial state per psi. What Alice does is at the time t equals zero, so Alice applies the operator A to Passet. Okay, so it changed, she changed the operator into Passet. Let's call it Positive. This happens at time t equals zero. And then And then as time evolves, at time t this date has become pass t tube is our old friend either negative A th times pass initial state now at times t at time equal to t Bob Tea. Bob wants to make an observation. So she wants to tell if Alice did anything to the state, applied anything to the state. Bob makes observation. By this is already at time t, by applying his Hamiltonian to the state at time t and take this inner product. Product. Now, we already know that the per satitude of T is e to the negative th per satitude, which is really A per side B. Okay, so this is what Bob observed. Again, you can move this term to the left-hand side. What one get in the middle is exactly tau T O B. So the Heisenberg dynamics of B, observable B. Now it becomes clear why do we care about the computator of Tau T O B? About the commutator of tau t of b and a. So suppose, say tau t of b and a they commute, then you can switch them. This is under the condition that suppose they commute, then you can commute them. And we assume that u a is unitary, so this part just goes away. And this is what Abob observes. And he couldn't actually, at this point, you can unfold this total T of B and move it back, becomes Poseidi T of B Posei T. Okay. So what does it tell us? If the commentator is zero, then Bob tries to make an observation, right? Make observation, right? And what he gets is the same as as if Alice did nothing, right? This is the same observation as Alice didn't do anything to the state, didn't apply the operator to the state. So this is the same as that is did nothing. To the state, right? At time t equals zero. Okay. So that is clear why this commentator appears, right? Because it really tells you the propagation of what Alice does to the set where Bob stands. This commentator really tells you if the comatatatatatatatatatat This commentator really tells if the commentator is very small, then Bob feels almost nothing by what Alice does at m t equals zero, right? So, and and what the Lieber-Robinson bound tells us, if we go back to the Lieber-Robinson bound, it tells us this combinator can be bounded by such kind of upper bound. What it tells us is the foreign, so at, for example, at J center. For example, at j centered at j, you draw a disc, and with the radius, what is the radius of disk? Is vt. t is the time, v is the velocity in the Lieber-Robinson bound. So, V is here. So, you drop a disk with radius vt. And basically, the Lieber dropping the button tells you outside this disk, it's actually outside this disk. Disk the commutator is naturally small, so it has very minimal effect on the observations outside, right? And this disk is called a light cone, right? And clearly, this velocity V characterize how fast this light cone propagates. It's going to prop if V is non-zero, then it's going to propagate to infinity. But V actually tells you how fast this Actually, it tells you how fast this net cone propagates. Okay, so V is tell us the speed of the propagation propagation of the latcone. So, in this sense, if V is equal to zero, so if you have V equal to zero, zero. So if you have v equals zero, then that means this lead cone doesn't propagate at all. So this can be understood as a characterization of localization in the many body system. So this notion of dynamical localization was actually introduced by so they introduced a notion of dynamical localization. Very cool. As far as I know, it's unclear what dynamical localization really means in the many body system, but this is one notion of it. This was introduced by Amza Sims and the Gunter Snows. Sorry, I spoke. those sorry i spell the first name they introduce the the the spin system is they call the spin system is dynamical localized if the velocity mic i show the velocity is the is equal to zero in the leab robinson bar Is equal to zero in the Lieb-Robinson bond. So I hope I have convinced you by this notion of localization because it really tells you whatever Alex does at a set J, it doesn't really affect Bob's observation at all if Bob is standing far away, sufficiently away. And they actually, in their paper, they actually proved it for the azotropic Anderson case. And they actually prove it for the azotropic case. So now let me introduce some literature on the XY chain. Let's return to the XY chain, the specific model. XY chain the specific model at bits are they okay but before we before I talk about the literature maybe it's best to give you a preview of the proof first because that will make sense what I why I introduce some of the literature in a second so for the XY chain the proof usually is as follows the benefit of The benefit of XPAC, the advantage of XFAC chain is there is a so-called Jordan Wickener transformation. Oops, I don't want to use this color. Remember, this Hn was two to the n dimensional. So, this transform you can easily find in any of the literature that I list. It actually transforms Hn to another operator, H, which let's call it Mn. That is no longer 2 to the N dimension, that is 2 to the N dimension operator. And in particular, And in particular, this Mn in the isotropic case, when I say isotropic, remember there was one plus lambda j sigma xx sorry, plus one minus lambda j sigma y. So when I say the isotropic, I mean the lambda j are equal to zeros. The lambda j are equal to zeros. So that this is the coefficient in front of xx is the same as the by y coefficient. In this case, this mn is actually reduced to the standard shredding operator or Jacobi matrix. I would say shredding error, but it's you can really So that's the esotropic case. In the unisotropic case, where this lambda j is non-zero, for example, is equal to a constant that is non-zero, then this m is actually becomes a two by two block as a freedom operators. Yeah, as a freedom operator. Okay. Then, so this is all done through the Jordan-Wigner transform. And the statue of the spin chain can be really through the Jordan-Wigner transform is reduced to the study of this Mn. This MN. No, no, I should really talk about the literature. So as I mentioned, there is, so I'll talk about the random case first, and I'll talk about deterministic case key. Let's take, so there was was Hamza Sims those so this not the case where it's isotropic it means lambda j identically equal to zero and mu j is a constant and so let me quickly So let me quickly, sorry, I had to remind everyone. There is a sigma y by term and there is the potential that is comma j sigma z. Okay, so where this potential is ID random variable and what they prove. And what they proved is this V is zero. So the Lieber-Robinson bond holds with velocity equals zero. So that means dynamical localization holds. And then, of course, there is a question about this isotropic. Then Chapman's dose returned to this problem in 2015. Problem in 2015, they work out the they were able to prove it for the anisotropic case. Also, V is zero. Okay, so Lieb-Robinson bound with V is zero for the n-isotropic case. And there is also one result. There is also one result, which is not really exactly about the spinning system, but it's about the block trading operators. That is clearly relevant to the anotropic case by Algert, Chamise, and Sodin. So their result is for the random. block trading operator we wish as i said which is clearly it can be applied to the xy chain isotropic because it's a special block matrix so let's for the random case for the deterministic case For the deterministic case, and there is a work by Domanik Marius Lam, Miluki Lukic, and Yesen in 2014, where they studied the azotropic azotropic case where the potential the potential is gamma j is Fibonacci potential. Okay, so that's a Fibonacci case. In this case, they proved a very interesting phenomenon that's called the anomalous. I always have trouble spelling it anomalous. Lieber-Robinson bound, which is a Lieber-Robinson bound with, remember it was negative V times T, but here is V times T to the alpha. So here is a fractional power of T. And they identify this alpha as the upper transport exponent of the Fibonacci homotonium, the standard Fibonacci homotonium. It matches homotonic on Z. And also, the three of the authors, they also studied Demonic, Lukic, and Yesen. They also studied in 2015. They also studied, no, it's in the anisotropic case. case with periodic potential gamma j and what they proved is the Liby-Robinson bond holds with V times T with a lower bound on the velocity. So it's different So it's different from the random case where they showed the velocity is zero here. For the periodic case, they showed it has a positive lower bound. And there is also Ilya Kovsky. And he showed that he considered the isotopic case. And with some assumption on the reducibility, so under some reducibility assumption assumption this assumption actually is not very strong actually, it holds for any, for example, the reducibility assumption holds for any. Assumption holds for any analytic of V with potential V with small enough coupling constant if I understand it correctly. So, this assumption holds for V analytic and lambda if you put a coupling constant small enough. So, whenever you are in a reducibility region, then Ilya also showed there is a There is a lower bound on the velocity, positive lower bound. So just by looking at these results, I think there is an intuition that for the Fominati case, there is a singular continuous spectrum, right? And where the And where the deliberate is you have t to the alpha, a fractional power. So the intuition is after the reduction, after the Jordan-Wigner transform, the Hamiltonian weakness you get, if the light Hamiltonian is ballistic, has ballistic transport, then you should have a positive Lieber-Robinson velocity like this. So if the Hamiltonian is ballistic, So if the Hamiltonian has ballistic transport, then you then one would expect or try to prove a positive velocity. On the other hand, if the Hamiltonian like the Anderson model is localized, then one would try to prove it for the zero velocity, the Robinson bound. And if the Hamiltonian has singular Is a singular continuous spectrum fractal dimension spectrum, then you would expect it has an anomalous Lieber-Robinson bound. I mean, this is just an intuition. This is by no means this is such a general result as known. So this is just intuition. So one, what to expect. Okay. And since I also, again, since I mentioned the isotropic case, it's clearly related to Case is clearly related to the block trading operators. For the deterministic case, there are also results of Bergen and Tridemer's guy in 2000, I think, where they studied the tradier band model of quasi-periodic trading operators. Of quasi-periodic shading operators, and where they proved the localization for analytic potential analysis large. This lambda is not the same as lambda j that we have. Here, I mean, gamma is equal to lambda v. And there is also a result more recently by Sylvia Sklein. And that is on block Trainer or Jacobi operators. I mean, these results are not about the XY chain, but as I said, they clearly can be applied to the XY chain. But I have to mention that these are results for the localization. are for the localization localization and these are the for almost every frequency all right so the the the model that i'm looking at this is working progress is i look at this xy chain model in the anisotropic case With a specific potential, not analytical potential, but with potential lambda times cosine, so almost massive potential. But in the end, as a shopping case, so eventually you have a block matrix. So this model, so after the drawdown weakener. The Jordan-Ligner transform. So, let me tell you what the operator is a Hamiltonian look like. You have Mn and it is a block matrix, two by two block. Here you have comma one, the potential times J. Here you have negative S. S negative s okay, the negative s here you have negative s transpose, here you have gamma 2j da da da. You have gamma n j here, you have negative s and negative s transpose transpose. So this Transpose. So, this is the operator that one gets after the Jordan Wigner. In the anisotropic case, this S is one minus, okay, now I shouldn't have used lambda before, but let me probably minus B. Let me just use B B one B minus B. Where B is? Where b is b is actually our lambda j. So I apologize for the notation. I shouldn't have used lambda here. And I think I have used lambda. Let me call it B. So this is S. What is J? J is a 2 by 2 block. That's very simple. It's 0 1 0 0 1 diagonal. Okay. And this command is Kamaj is whichever potential that you prefer to work with. Okay, so that's the operator. And what Hamza Sims and those they proved that there's a following. So if this operator Mn has dynamical localization. M n has dynamical localization, exponential dynamical localization, then you have Lieb Robinson one with zero velocity. So they showed that if this operator satisfies some of the operations. Satisfies some exponential dynamic localization. Actually, they have to take an expectation in a random variable. For the Mn that actually implies the Lieber-Robinson bond with zero velocity. Zero velocity, right? So, this is what they proved. So, then everything is reduced to prove it. V is equal to zero is reduced to the study of this block matrix. So, reduced to study establishing the exponential dynamic localization there. And what I proved is a it's it's a folding so for this special almost massive potential and the lambda is large enough is greater than a constant c so c is a c is absolute constant and i do plan to sit down and just compute it what it is so What it is. So C is C is absolutely whenever lambda is large enough and alpha is del Penteco. Then for almost, then this guy, and actually the infinite volume guy. Exponential dynamic localization. Here we need to integrate about this about this theta to get exponential dynamic localization is less or equal to. And this is what I And this is what I have wrote. Well, where does this Lambda large come from? Because usually a natural question is, is there any way to push this lambda to be greater than two, for example? And the answer now is. No, it's I don't think so because so because in order to prove this localization, so even for the analyst localization, so you want to show the green function decay exponentially. And this is a one-dimensional case, so you can do the so the green function is a mu, but it's not a tri-diagonal. So because now this mn. So now this Mn, this M is seven diagonal matrix. It's no longer a tri-diagonal matrix. So when you do the green function expansion, you cannot just control the numerator by the Lyapuno exponent. And let so we need a lambda is large enough to control the numerator of the grain function. numerator of the grain function expansion but to control the numerator actually there is a tech technique developed in borgen chitomersgaya's paper for the for the long range case not the seven diagonal but just the long range case there is a technique developed by borgen chitomers guya should i written and also And also a very large guy in the almost almost paper. So we need a lambda large mainly to control the numerator because it's not as simple as the trading race where you have a determinant on the top and then you control it by the transform matrix and you control it by the Delphine exponent, which is log lambda. But here there is a Is a there, but in order to control the denominator for the grain function, you also have to control the lower bound of the denominator. So, here actually, the denominator, lower bound is, I want to add a page where it's not adding. So, the lower bound for the denominator, the way we control it is developed from G Lumerus Gaius. proof for the almost massive operator, the non-perturbative localization for the almost massive operator. And which in particular involves a polynomial argument. And it's lucky that we can do it here in the block case. So that's how we control the lower bound. Bond and we need to use some symmetry of the blocks in order to have the lower bound. All right, I think I will stop here and take questions. Thank you for your attention. Thank you very much. So can you hear me? Yes, I can hear you. So can you replace cosine by arbitrary knowledge function by extra restrictions on frequency? Yeah, of course. Yeah, you can replace cosine with analytic function, but yeah, but you need to, the result of them is for almost every alpha. And as I mentioned, these log matrices were already started before by Borgen, Giudemaskaya and Before by Bogan, Genomeskaya, and Kline. So, where they already have a result for Anderson localization. It's just a question to see if dynamical localization holds, but I think that should be true. Yeah, I think it's in the band paper. They also have dynamical localization. Oh, where? In the Burgundian band model, the last section. Oh, okay. Sorry. So they already have. Okay, I realize Henry. They have okay. I realize I realize okay. So they but it is not a strong dynamical localization statement, it's not averaged in thes. Yeah, but so modification is still needed. But so do I understand correctly that going back to the almost metal, Ilya's result on zero velocity applies up to lambda less than one? Yes, I think so, yes. And your result for lambda bigger than? For lambda bigger than some constant. So, what happens in between? What do you think? No, no, no. I mean, if you go to, if you talk about the isotropic case, I think you just have localization for lambda greater than two. It's a sharp. Okay. Here, because here is a block, so that's why I need to assume lambda is large. I see. So, okay, I'm confused. And so, for small lambdas and For small lambdas, then does Elias result apply or not? I think Ilias' result applies to the isotropic case. Only isotropic. Oh, so for anisotropic, there is no result linking reducibility and nothing I'm aware of, but not even for periodic periodic, yes. Again, this result by Damanik. Again, this result by Damanik Lokic, Jason. Oh, this is for anisotropic. And Delias is only an isotropic. Okay. All right. Thanks. Okay. Can I ask a question? So for the zero velocity for the spinning system requires dynamic localization for the Schodier from the Schoder side. What if dynamic localization? Okay, so there's no weaker. I mean, what if the it's only spectral localized but without dynamic localization or only on the not fully localized but only on the age. There's no result or partially anything we can say about the system. But whenever one can prove spectral localization, one can probably improve. No. Dynamical? No, there are like there are two cases. Just first, there can be a random system with fully localized. I mean, all the viewpoint with exponential decay, but with a positive transport. Say, like one half, like a polynomial or dimer model. So that's one case. The other case is for higher dimensional lattice, you have the dimensional lattice you have the you only have the age localization right like in higher dimension if you have mobility age you only have the age uh localization okay you don't have the full i'm not very sure because okay so the for the isotropic case damanek lamb and lukish yesen they show they had they kind of identified this alpha as upper transport exponent so here this alpha So here, this alpha here. So Lieb-Robinson bound not with Vt but with T to the alpha. And this alpha, they identify it with the upper transport exponent. So I assume that there are some localized system with positive upper transport exponent, then I'm not sure what to expect. What to explain? And this one is for determined. So is the result Fibonacci dependent or is it a result that whenever you have an upper transport exponent of this? It's minimal in the audience. I'm not sure. I'm not sure. David also, right? Also, right, yeah, who also supposedly in the audience. So, so the timer model I mentioned is very simple. Just you have like a shonier and the diagonal is not ID, but all the even, I mean, you have one, one, I mean, every even outside are coupled. Then this system has a viewpoint fully localized, but it's diffusive, like the transport exponent is one half. Like the transport exponent is one half. Helps use a bit more than just the transport exponent. They all use some of the estimates that are under the foot. And the things happen here, if I understand that was the results are not black boxes. If you have an upper transport component, then you automatically get. Component, then you automatically get problems found. They they use a bit more about the they use a bit more of the estimates that are under this load. That's how I see. I see. Yeah, that is a very interesting question to see what happens for the dimer model. Yeah, it's very interesting. Yeah. Are there other questions? Yeah, I have a Yeah, I have a naive question. At the very end of your talk, you mentioned some lower bound, deriving some lower bound and taking into well, making use of some symmetries. And my question is, standard methods for proving lower bounds that have to do with subharmonicity are not applicable? It is applicable. It is applicable. Then, if you use subharmonicity, then if you use that kind of general results, then you probably would have to delete, if you just follow Bergen-Cohstein's strategy, you probably have to delete some omega, zero measure set. What I use here is from From Lana's proof for the almost massive operator, where we actually use the p is not only any arbitrary analytic function, it's a polynomial. And that's actually you get polynomial you get from the symmetry, so you have to play with the matrix, yeah, and yeah. And yeah. And this gives you sharp results. This gives you all the things and actually sometimes give you sharp results. Basically, it is an arithmetic result and like what we can get from the previous work. But you need but for this you need the cosine and not the any trick polynomial, for example, right? Polynomial, for example, right? Yeah, I can't do it for tenant, but it's yeah, it's for what tenant also, but as similar to the map. Thanks. Thank you, thank you, thank you for your attention. Through the sweet minutes coffee break. Pretty sweet minute coffee break, and then when we're coming back, we can go in purple. So, are you in a good spot? Yeah, it's already there. Thank you for having me. 