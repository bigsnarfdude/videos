There are three parts here. The first one is the warming map. For those of you who haven't seen our previous work on the 1D burgers synchronization of triad phases, this would be a first. But if you know, if the majority of you here have seen that work, I can skip it. The second part is introducing. The second part is introducing the complications about characterizing synchronization of triad phases in three-dimensional network stokes. You may wonder why we are skipping the 2D case. It's just a matter of circumstances. So, you know, we should do the 2D case as well, but we embarked on the 3D. Embarked on the 3D problem, and it was super difficult. After three or four years, finally, we have something. And the third part is the new results that after showing you in the second part that nothing was working fine. Third part is good hopeful kind of results. Okay, so the part one is based on the paper. One is based on the paper with my former PhD student, Brendan Moray. It's published in JFM. The second part is based on Moray's PhD thesis and work in progress with Bartek and a former postdoc of his, D. Kang. And the third part is based on, at least, you know, in terms of the setup, it's based on the Is based on the amazing work there by Bartek and his two postdocs on finding an extreme solution, right? So remember last talk before lunch where I think you explained the situation in 3D Euler, which is very different. Which is very difficult compared to the 3DNA Stokes case because of some technicalities. So, thanks to that, I can skip most of the technical parts. I just go directly to the initial condition. Hopefully, I will have time at this point to finish that. Okay, so part well, so with part one, okay? I'm just gonna change to my second file here. Here and okay, so the first results are concerning the one de Burger's equation, which probably all of you know it's an integrable equation. So, what's what are we doing here, right? Still, it's interesting because it shows if you change a little bit the forcing to make it not integrable, say you put up some random forcing, or if you change the dissipation term, suddenly a lot of questions are. Suddenly, a lot of questions arise, and Bartek has done papers on that as well. The fractional terms in the dissipation term. But so the nonlinear term doesn't change, and that's what matters to me, the non-linear term, because that's how you can see how energy is flowing across the scales. So, in this simple model, if you start with a sinusoidal initiative condition, this will gradually evolve into some shock, right? And this shock in this spatial point of view, in the physical point of view, it's obviously some jump of the function. In this case, the profile is that you can think of it as a density of fluid particles. Usually this is a model for gas dynamics. Gas dynamics and um so, but you know, in Fourier space, it's very interesting because in Fourier space, what you expect to see is accumulation of energy at high wave numbers. And this process of energy going from small wave numbers to high wave numbers is only due to the nonlinearity in the equations of motion, and somehow the nonlinearity encodes in its component. Encodes in its complexity of coefficients and so on, encodes this direction of energy, the forward cascade, as we call it, right? But then when you look at the behavior, it's very interesting because the snapshot here shown for the profile, you know, near the end of the simulation, when it's very when the choke has already. When it's very when the chock has already formed, when you take the Free transform and calculate the energy spectrum, so the modulus square of the Fourier coefficients, you find this nice power law and then the decay at high wave numbers corresponding to dissipation situation, right? However, you know, the Fourier spectrum has a phase. These are These are complex numbers. We are plotting the modulus squared, but what if we look at the phases of these variables? And it turns out that the phases are doing something even more interesting than this energy spectrum. The phases are synchronizing to take preferred values. And the way to demonstrate that very quickly is take this energy spectrum, but then change the phases of your solution. Of your solution to a random choice of phases. So each phase of each component you had of k is random over a uniform distribution. And then calculate the physical space, and you're going to get this plot here in red. So by randomizing the faces, you completely destroy the shocks. Okay? And this is, when you start looking at it, it is trivial, right? It is trivial, right? Because it says, well, for yeah, for in order to have a very nice localized physical space feature, you need the phases to be very precisely defined. It is easy to see when you do free transform. But why do phases do that? Okay? And in 1D burgers, you can provide a lot of information on that, like predict this. Information that like predicts this behavior. And you know, that's what we did in the 2018 paper with Muray. And I'm not going to talk about that type of model and so on, but at least just to set the stage for the next part, right? So what do we do? We expand a field in four components. In this case, the brawling is one-dimensional in space, so there's only a real variable. Well, in this case, an input. An integer, one integer for each wave vector. So it's a one-dimensional wave vector. And we assume periodic boundary conditions here, of course, with you know periodicity to pi. And when you plug these answers, if you want, into the equation of motion, into the PDE, you obtain this set of ODEs for the For the uh for your components, and as you can see, the non-linearity here is what drives the transfer of energy towards smaller scales, but it could be well to large scales. It depends on how lonelierity looks like. And in this case, for one divergence, it happens to go to small scales. And to understand that much better, we do the amplitude phase representation. So we take our Representation. So we take our ODE system for the free amplitudes and we decompose free amplitudes in the modulus and phase. And in so doing, the equations get more ugly, particularly for numerical simulations, completely out of the question. I wouldn't recommend anybody to try this because you're divided by some quantity that could be close to zero, so it's really bad. But from Really bad, but from an analysis point of view, it's very nice because it shows, first of all, which ones are the real degrees of freedom in this picture. It's not the individual phases. It's this combination of three phases. It's a linear combination of the sum of phases associated with the triad condition. So this K1 plus K2 plus K3 is the usual momentum condition, the triad condition. Condition or thread condition coming from uniqueness of the Fourier expansion, and in the in the in the evolution equation, the the coefficients right of this ODE system pick up only these values of phases. And so for example, if you look at the original problem, the original PDE, it is clearly translation invariant. You can Invariant. You can look at the system from a different perspective. You can change the x variable to x plus epsilon for any constant epsilon, and that doesn't change the dynamics. It shouldn't. That translation invariance does not affect the tried phases because it affects the individual phases by changing each individual phases to plus epsilon times k. And when you do that transformation, And when you do the transformation here, due to this condition, the extra term vanishes. So these triad phases are invariant under those type of transformations, which is great, particularly, for example, if people are looking for extreme events for what was the problem. Much simpler than what Barton. much cheaper than than what what uh bartek is is is doing but uh for for a low dimensional system people look for um periodic orbits for example if you try to look for periodic orbits these variables are much better because they simplify the search quite a bit okay so how come this is important in terms of the fluxes when you look at the energy in a given shell in this case it's just a subset of wave numbers right Subset of wave numbers, right? From 1 to k. You look at the energy of, well, in this case, it's the energy of the wave numbers larger than k, so it's the other side. You want to see how energy goes to that set. So you look at the time derivative of this energy, and this is a result that comes back to Kraken: that the energy change, rate of change has a non-linear contribution, right? A nonlinear contribution, right? From the non-linear terms that depends only on interactions between triads, but these triads contain one mode below K and one mode above K. And the third mode can be below or above K. So those are two types of triads you can have. But you cannot have the three modes below K or the three modes above K because then the terms cancel out in the sum. And so this is what you're going to. And so this is what you're left with. You're left with a flux, a flux, so-called flux formula. So this pi of k tells you how much energy is flowing, in this case, towards large wave numbers. And as you can see, this term contains mostly positive terms. This wave number, these amplitudes are by definition positive because they're the modulus of the Fourier spectrum. And so this. And so this term here determines whether this quantity is positive or not. If the phases are equal to pi over 2 or around pi over 2, this sign is going to be positive. And then you're going to have positive flux. So what is happening in this case is that the phases are preferably going to pi over 2. Otherwise, you wouldn't see any forward flux. It so happens that for Wendy Burgers, not only is it preferable, it's actually overwhelmingly preferable. The value pi over 2 for the triad phases, this is a PDF calculated over 160,000 triads and also over time. So it's a long, that's why it looks so smooth. And notice we're putting the logarithm of the PDF versus the phase. Of the PDF versus the phase. So you can see this really is almost all the triads going here at value pi over 2. This is a dynamical situation, right? They go there because in the ODE, there is a kind of forcing, right? But look at these faces. You don't see them in real life because they have no energy. By definition, they are the complementary variable to the energy, right? Variable to the energy, right? They're like the conjugate variable in quantum mechanics to the energy, you know. They're more related to time. In fact, that's what they do. I mean, the phase is when do you decide to push? Are you going to wait a little bit or are you going to push now? That's the phases. So, yeah, complicated. But they are definitely doing something dynamically very interesting. And if you If you try to quantify this quantity, right? So, yeah, you got a PDF, but yeah, it's peaked. So, can we measure this like with just one number? And we define the so-called Kuramoto parameter, borrowed from Kuramoto's work on synchronization of phases for other systems, but still can be used here. It's the average of these exponentials, right? So, if all the phases are kind of randomly Uniformly distributed between 0 and 2Ï€, then this average is going to be zero, right? Over a long time and over a large set of modes. But it so happens because there's a preference. Basically, this is the full transform of this PDF, you're going to get a very high signal. And, you know, we did. And you know, we did a lot of experiments, and it turns out this, just look at the lower quantity here. This is the Guramoto parameter. So, when it gets one, it means we have synchronization. So, you can see this is a forced with some stochastic forcing. So, you get strong events of synchronization, then nothing because of the forcing, stochastic forcing takes the system out of that synchronization, but then it goes back again, and so on. Back again and so on. It's intermittent in time. So it has all the usual signals of turbulence. So great system to study. I hope I've convinced you of this. The only thing if you are interested, if you are more interested, there is this physical picture. You get synchronization when two shocks collide, which is nice, right? But we didn't know that. We did all the study in the Fourier space and then we tried to explain because We tried to explain because of some colleagues were saying, Yeah, but what is the physical situation? Okay, and we tried and found that in fact it has to do with this collision of shocks. Okay, so I'm gonna skip this part just to show you this long statistical calculation where we show effectively that strong dissipative events, which is in the vertical axis. Vertical axis. So high numbers, high values are correspond to strong dissipation. And the x-axis here corresponds to high values of the current model parameter. And they are correlated. That's the good thing. You can see the peak there. It shows its correlation, right, over time. Okay, so hope I have convinced you that this triad thing is not just an imagination. Thing is not just an imagination of mine, it's true. Something that's happening at least in the 1D case. Does it happen in 3D case? That's the next question, right? Well, the next question should have been, does it happen in 2D? But you know. So we went to 3D right away, and we found a lot of difficulties. First of all, there's not just one scalar field. Velocity field has three components. What do we do? Answer is do the helical triad composition. Try decomposition, but that's already making the problem more difficult because it creates all kinds of triad types, not just one type of triad, you get at least four types of triads because you end up with effectively two scalar fields interacting. That's what three-dimensional Navier Stokes is: incompressible. Incompressibility allows to eliminate one of the components, so you have two. Of the components, so you have two degrees of freedom, but these two degrees of freedom are independent. So you end up with the possibility to construct triads out of these two degrees of freedom. So simple combinatorics would give you two times two times two, eight possible triad types. But fortunately, in most of the simulations, they have zero helicity. So we can simplify to four. To four. Sorry for the pseudo helicity press. But it's still interesting. Pseudo helicity still means something regarding helicity. It's an eigenvector of the helicity operator. So, and also the problem is that we don't see a lot of synchronization. Well, I'm telling the story, you know, I'm telling you the story of the second part. A lot of difficulties. Then you will see in the third part. Then you will see in the third part, light comes at the end of the tunnel. So, any questions so far? Let's go. So, second part is on this first attempt we had the child faces in 3D. And you see, I have to say, you know, Maurice was an excellent student. Excellent students. And that's why it worked well what we did, right? It wasn't like from the point of view of what I expected to see. I was too naive at the time. I thought I was going to see, you know, all the three-dimensional triads doing the same as in 1D case. I was completely wrong. But you still see something. So that's the good part, right? Okay, so in 3D, we have this. Equations of motion. With my student Muri for his thesis, we put some forcing in the system at large scales, as usual when you're looking for turbulence. You put forcing at large scales and try to see how energy is flowing to smaller scales. And yeah, and it's incompressible. So we start with Fourier decomposition as usual. As usual, but now you see you have a vector field here. So, the three components are not only complex, but there are vectors in 3D, R3, with components which are complex. All right. So, C3D. But, okay, so some details on simulation, just to show you that this was serious work. It was serious work. Number of degrees of freedom 512 cube. That's the resolution you used on each direction, pseudospectral method with the usual problems of pseudospectral methods. But this was a dissipated case, so everything was fine. The problem here was to find something that was stationary statistically. And you know, this means you have to wait very, very long. You have to wait very, very long to see results. So, these are typical results, for example, the energy spectrum. You're not going to find Kolmogorov spectrum here because of the type of forcing we were using, but still you see some cascade of energy. That's what matters. And it's here in these so-called classical flux plots. I'm not sure how many of you have dealt with turbulence problems or have read anything on turbulence, but one of the things they calculate. Turbles, but one of the things they calculate is this flux that I showed you in 1D. But instead of considering a subset of modes in 1D, it would be, you know, from 1 to K. Here we consider a sphere of wave numbers because supposedly turbulence in 3D is isotropic. So it goes in all directions. So we look at the sphere of wave number K, of radius K, and we want to know how much energy goes out. Energy goes out of that sphere. And that's what this flux gives you. So, this is classical regulation. And usually, if you had perfect turbulence for a very long range of scales, the flux should be flat here because it would mean that energy is flowing out of the sphere, but then out of the other sphere that got it, then another sphere got it, and so on. So, it keeps on flowing with the same rate. On flowing with the same rate, okay. But when you have dissipation and load resolution, your flux usually starts decaying very early. But still, you can say this is acceptable type of turbulence. Okay, what matters for us is, and sorry for the heavy mathematics here in terms of formulas, just to show you that there is a way to decompose the velocity field in a meaningful way. In a meaningful way. So you have the free components originally calculated, but you decompose them in terms of these basis vectors HK plus and minus. And the reason of this HK plus and minus is to automatically solve the incompressibility condition. So this K, these H vectors are automatically Automatically perpendicular to wave number, as you can see here from this formula. And they have, in a way, the same vorticity as they have velocity. So they are kind of helical. That's why it's called helical. They have this helical feature incorporated. And for us, it's very simple. Just we take it as a tool. We take it as a tool to simply decompose the velocity field into two types of scalars. One type is called U, it's still complex, but it's now scalar, and U minus. So two types of scalars interacting. Now, how do they interact? This was originally, well, I'm not sure if Olefe was the first one, but you know, it was shown in his paper in some detail. This is the type of evolution equations. This is the type of evolution equations you will obtain. Okay, so time derivative minus the dissipation term of a given helical amplitude is star because it's simpler to put the star on the left-hand side. Star means complex conjugate. It's equal to this sum of quadratic interactions, right? So these are looking like it in our 1D burgers, but they are more complicated because you have. More complicated because you have some over wave numbers and some over the type of mode. All right. And here I introduce the universe U, which is the set of all wave numbers minus the origin, because that's what the wave numbers of interest are. And notice in this sum, you have the triad condition incorporated, of course. And this is. And this is all very simple. It comes from the uniqueness of Fourier decomposition. So, maybe we should add a large screen here. So, if you look at the thing carefully, there are four types of helical triads. Notice in the previous slide, it is telling us that there are triad interactions, but that could be But that could be, say, for example, if you're interested in knowing how U is evolving, you want to then sum over the different mode types, so plus or minus. So you're going to have plus or minus here, plus or minus here, and plus here. So you have four types of interactions right away. And these are the four types. And they are nicely ordered. Nicely ordered in this sense. So you're thinking in terms of scales. You have a small wave number here, so large spatial scales, intermediate wave number here, and large wave number here, so small spatial scales. So you're, of course, interested in knowing whether the interaction goes forward or backwards in terms of the scale direction. And the class one type of triad, when you analyze the When you analyze the coefficients, it turns out to have a kind of a mixed type of formulation. Some part of it goes backwards, some part of it goes forward. And the class two has also similar, but more forward than backwards. And the class three, interestingly, has only forward type of cascade. And this is all calculated from instability of a trial. So very simple. You look at the triad. So, very simple. You look at the triad equations, you look at the coefficients, and so it is not a very sophisticated calculation to get these arrows. And class 4 also has this forward type of cascade. And so, because the first wave number is less incise than the second wave number, less in size than the third wave number, we came up with a new notation. Came up with a new notation which is instead of class one, class two, class three, which is called the first sign, the sign of the first mode, sine of the second mode, sign of the third mode. For example, in this case, it would be plus plus plus trial. This one would be plus minus minus trial or simply PMM, just to simplify notation, PMM type of trial. Here, the third class is PMP plus minus plus. Plus, minus plus. This one turns out to be, by experiments, the most important one for the forward cascade, which is amazing because you know this calculation of Balefek has nothing to do with dynamics of a full set of triads. It's only just looking at one triad and so on. Okay, so we look at the energy in a given set of wave numbers, but in this case, because of reality of the velocity field. Of the velocity field, we need to allow for modes with plus or minus wave number. It's a technicality, but still important. So we have a subset of wave vectors such that minus c is c and we define the energy there. We look at the time derivative of it. As usual, you're going to get a term coming from the forcing, the input energy, a term coming from the dissipation. This is basically the antrophy time. The astrophyte times the viscosity, and this pi c is the non-linear flux, non-linear flux of energy. This is the term coming from the non-linear tried interactions that I showed you first. Okay, this term here. Let me just go back, have a look. It will be this term, okay? In all its complexity, and we're going to try to understand this term, all right? Okay, so this is an example of such a set. Sample of such a set C that we were initially trying to understand, but just recording that this was prepared by my former PhD student. Now we're not going to use this really with Bartek, but this was nice kind of beginnings of type of thing. We were trying to choose the most energetic modes over shells. So you take a lot of shells, and on each shell, you choose the most energetic modes. The most energetic modes, and then you form this set. Of course, this changes as a function of time, but it gives a nice idea of the possible interacting modes. Okay, so there's a lot of calculations to be done because this is just the beginning. The flux is given by this formula here. So you can see here clearly the tried interactions, product of three amplitudes. Amplitudes, but then you know, to understand whether the directions are positive or negative, we do the same game as before. We do this amplitude phase representation for each of these complex scalar values. And this is going to create a lot of different thread types again, as you know, but at the least it's going to allow us to simplify what happens in terms of the Happens in terms of the refactor here. At this level, it's not yet finished. We need to do one extra calculation. So we take into account the fact that the prefactor is also complex. So we need to also take the phase of that prefactor. In the end, you end up with this formula where you have a prefactor that is completely, by definition, positive or zero. Definition positive or zero in the generic cases. So you have something that you know has zero phase. So all the phases are in this combination here. And the study now is going to be what are these phases. And do we expect to see a strong synchronization over all possible triads as we saw in the one decays towards a positive value of this. Towards a positive value of this. Notice there's a cosine here, not a sign. So, in this case, the question is: are the triads, the triad phases, going to zero? Do they prefer going to zero or not? And here where the fructations start, but notice first here, usually this set C, you can think of it as a sphere, a sphere of radius K. So in the first In the first term, only one mode is in the sphere, and the other modes are outside the sphere. So, this type of term we call it non-local because it requires two high-wave numbers and one small wave number. And the second type of term is called local because you have two modes inside the sphere, and the third mode has to be outside, but it's only the sum of the other two. Be outside, but it's only the sum of the other two, so it has to be kind of in the vicinity of the sphere. All right, these are more or less ideas to understand this logality of interactions. So in the previous work, we found the synchronization of the faces. The plots don't show very clearly here, but maybe you can see a little bit in this in the one on the left. Do you see those rings? Do you see those rings? So, when you plot the faces, you see some rings distributed in different places, and those rings represent that the faces take particular values, coherent values, not random values. So, that's good news. But then, you know, what do you do with them? Like that's in terms of calculation, you know. So, we try to study the Kuramoto parameters. Model parameters on a given set. These are time snapshots of the sets. And we did the study, right? And the results, well, we plotted it in a way that looked fantastic. But when you start looking at the values of the PDF of the triad phases, you notice the variation is very small from 0.15 to 0.17. So it's almost a flat distribution, but it has a preference, a slight preference to take values. To take values at the points of synchronization where supposedly there is a strong transfer of energy to smaller scales. So there is evidence, and of course, this has to be like this. There must be a slight preference to take values for a forward cascade because we observe a forward cascade. So it has to be. But it's frustrating. But it's frustrating that it's so small, the signal is so tiny. And what was happening is that we were taking too many triads. Of course, we were taking too many triads. What else could we do? How could we decide which triad to take? We had to take all the triads in a given set, which are a lot of triads. We're talking about tens of millions of triads or more. So, yeah, I think that's for. Yeah, I think that's that's that's for now. Uh, I already split what local and non-local is. So now I'm just gonna go to the next uh part. I hope uh you're still with me. Now we're gonna go for the nice action. Um so part three is about this new approach. After the dissolution of not finding a lot of order in these triads, the really almost random, this tiny signal, which is required, otherwise you wouldn't see forward cascade. But apart from that, it was not very spectacular. So with Bartek, who had done this work on the stream flows. Who had done this work on the extreme flows? It was a new idea. I mean, the flows that Bartek has presented are optimized, obviously, right? So you have small allocation of resources, low-dimensional models, numerically speaking, but they give you the most interesting behavior you can imagine because you ask for it, right? You want to. Because you ask for it, right? You want to see at the late times a very high dissipation of energy, for example, in 3D case. Okay. And accompanied with that comes a lot of different activities in the fluid. For example, this reconnection events, this collision of vortex rings that has been observed. So Maybe the faces are doing something also very interesting. That was the idea, right? So, why don't we try to understand that? Okay, so we went, let me just quickly give you an overview of Protex results, but this slide was from 2021, so maybe there are even more results and the question marks. The question marks are not there anymore. Martik? Yes. Yeah. So this one here. Yeah. So, but you know, you see in all these problems, there is a quantity in this case, it was the anstrophy. The E here, the P is the palenstrophy, it's the next order of the next. Next order of the next moment of the of the issue of norm. And here's the case for 3D in aerospock. So the question was: Can we make this estimate sharp for a finite time? For a finite time, and of course, this was investigated in the paper by Bartek. So, Kang, Juan, and Rodas, 2020, JFM. Okay. Okay, so one of the snapshots of the initial condition, very close to what you showed. Very close to what you showed. This is in the X just showing the X vorticity profile. As you can see, the X direction happens to be across the towards the screen. So this looks like two vortex tubes. And if you look at the Y vorticity, you're going to see also two vortex tubes. And the Z vorticity, also two vortices. So this looks more like the dispelled Skida Pel's initial condition. Initial condition. But this was found from the optimization problem, not as a nice guess, right? So at late times, these are the result of a pretty high resolution simulation that they had made, not the one we started, like because for purposes of having quick reaction time and so on, we started with a small one, 128. Small one 128 or 256 at max resolution. This one was done for 512. Yeah. So, but you know, more or less, the flows should look similar if you change the resolution. So, in the paper, Bartek and collaborators found this result. Of course, this is the behavior of the on the top left, the behavior of the anstrophy as a function. The anstrophy as a function of time. And by construction, the flow is such that the final time entropy is maximal given the initial entropy. The Fourier spectrum looks like this. This is the 1D spectrum, so this is the average or the shells. It has an initial kind of slingshot effect. So initially, kind of slingshot effect so initially it goes to some uh flatten it flattens out and then it expands to make it look more turbulent right with a kind of power law that's it attempts to get to a power law and there's something happening here in the middle of the of the simulation that they identified as a reconnection event so the vorticity The vorticity develops some sudden change, but it's not particularly dissipating this situation. It's a recognition event, but without too much dissipation. So for me, it's more like an ordering or reordering. And when you look at this, it looks like these are vertex rings, maybe like the vertex lines that reconnect, they actually form a ring. So maybe. Form a ring, so maybe yeah, but um, that's the story. Now, when we take this model and we study the so-called weighted PDFs, which are the PDF of the phases, but when you include the flux contribution coming from each phase, you find these plots. In the vertical direction, there's time, right? So the initial condition. Right, so the initial condition. Let's look at the triad that we know, the triad type that we know is the strongest contributor to the flux already. This is already telling you the story, but it turns out this triad PMP plus minus plus is the most flux carrying triad type. Okay, so initially it has some preferred values. Preferred values, but kind of flat. But as time evolves, particularly in the middle, something happens here, right? There is a strong concentration of the values near phase equals zero, which corresponds to strong synchronization and strong flux forward and cascade, you know, to smaller scales. So, there's very interesting things happening here until this moment. Happening here until this moment here, which is supposed to be the regonation time, and then this PDF starts dissipating and it starts getting again flat. Okay, so we found this very consistently, you know, all the type of trials, even the ones that don't produce a lot of flux, they always have some strong kind of values, but some of them are off, like anything beyond minus pi or two. Beyond minus pi over 2 to the left and to the right of pi over 2 correspond to negative fluxes. So, yeah, question, what's happening? And okay, here's the answer, hopefully. So okay, just give you the question. Okay, just to give you the context. On the left, you have snapshots of the energy spectrum. As you can see, only for the small wave numbers, say two, three, four, five, you get something that looks like turbulence at the time of maximum entropy values, right? So this is really good. I mean, when the system has reached high dissipation, it looks like a durban flow. It looks like a turbulent flow, but here we're not forcing it, it's you know the usual decaying initial condition. I mean, initial condition, then decay evolution. And here, I'm not sure if you can see this straight line, it corresponds to the predicted Kolmogorov spectrum. So, with the constant CK 1.6, whatever that is, you know, predicted from experiments. So, it looks like our Our system is behaving like a turbulent flow, at least near those times. For comparison, we show the Taylor-Green initial condition just to show that we really find very high up energy spectrum thanks to the optimization. And here for the plots in time of the entropy, the same. In black is the extreme initial condition, and then in Then, in blue, below the same initial condition, but with the initial phases scrambled, the behavior is very similar. And here is for the tailor green, very, very down below. So, we did a careful energy flux analysis from a classical point of view. We found, for example, these typical snapshots, remember the ones I showed you from my student, they look very much like this. So, the flux starts going kind of. It starts going kind of this is the kind of initial time, nothing really is happening. But then, when you get to the time of maximum entropy or maximum dissipation, you get this kind of flattening of the flux, which is perfect for a turbulent guy. You know, like if you're doing turbulence, this is what you want to see. And the fact that this bulges up for the extreme case instead, then going immediately decaying. Immediately decaying, as for the Taylor Green case, is a good indication that the extreme flows are trying to produce this strong flux over several scales. So now we do the study triad type by triad type. So we did the four cases and also some intermediate cases. I don't have time to explain that, just to show you that the plus, minus, plus type of triad is the one that has the best. That has the best flux contribution. But there are other two or three types of triad that also have some contribution. But let's focus on the one, the triad type that has strongest contributions. As you can see, when you want to see how much flux goes out of the sphere with k equals 2, you find this strong flux at a value 12. But this is the final time, right? So the calculation of Bartek was done so that the Don't so that the maximum dissipation happens at this final time, but somehow the flux away from cables two occurs earlier, right? Why? Because it's energy that has flown away, but then has to continue flowing away until it gets to the high wave numbers and they get dissipated. So it makes sense. In fact, this is easily shown here. If you start looking at these plots for cables three, the maximum goes a little bit further. A little bit further to the late times, he goes four even further, he equals five even further. So it's really showing that, yes, the cascade phenomenon is happening here in real time. But there are too many triads. If you count the number of triads, you're going to find 10 to the 8 to 10 to the 9 triads. How to find just those triads responsible for the flux? There must be only a few because of locality. Because of locality, you know that just looking at the energy spectrum, only the low wave numbers have some energy, then nothing. So there must be something related to locality. So we do this crazy loop. We look over all possible triads. We look at the largest contributions from the pre-factor, not the phase, just the pre-factor term. And we order them according. So we find the maximum first. We do a loop, find the maximum, then do. Find the maximum, then do another loop and create a PDF over this new variable, the amplitude value. You do, say, 100 bins from zero amplitude to the maximum amplitude to see how the distribution of triads behaves. And this is what you find. For example, for the PMP triads, you find that this was for K equals two, so energy going through flowing away from K2. Going away from K equals 2. We did 10,000 bins just to show how it happens. So modes at this 10,000 value have the maximum amplitude, and then amplitude decreases linearly down to zero. And you can see that the first amplitude modes, this is the initial condition, have, you know, they're very isolated. These jumps show that. But then you start seeing. But then you start seeing less jumpy behavior. In fact, it turns out that the first 10 bins here, the first 10 bins out of 10,000 contain 99.99% of all triads. So a huge amount of triads here are contributed with zero flux. So why don't we just take out those triads and just consider the high-contributing triads? Contributing triads. That's the key idea. And this is the same, but the snapshot for the late times. So we do that, we take out this 99.99% of triads, and we get this new flux plot as a function of time. The red one is the new one. Almost unnoticeable. The same flux is only carried by a tiny fraction of the gryads. By a tiny fraction of the gyads. So let's see if I can. So I'm going to show you this animation. This is the PMP type of triads. And here is the behavior in time. I hope this works. So to understand how the phases, sorry, how the flux Phases, sorry, how the fluxes, sorry, the triads contribute to fluxes through k equals 2 in this case. You have to look at this kind of PDF, but it's just a few points. So each of these points is a triad that you can identify. So there's only a few of these triads in the system. So I shouldn't, I shouldn't. So if I here I have a slider that allows me to reduce the number of triads involved. So here for example I am taking only 500 triads out of 11,000 triads. Already the ones I took were small, 11,000 Were small, 11,000 triads out of 10 to the 9, but now even less triads, and they still have a strong signal. If I just take one triad, then nothing happens, but you know, I start adding just a few of them, and then I get the nice behavior. So it's only the high flux triads that are contributing. And notice that some of them have behavior here near zero, so phases near zero corresponding to positive flux, and some of them have negative. Flux and some of them have negative flux. So it's a mixture of them. I need them all because otherwise I cannot construct the whole distribution. So you see, this process is basically binning, allowing for me to bin using the pre-factor as a reference, but I don't know the phase. But what happens is, of course, that there is a preference to have phases near zero. And that's very consistent. You can do it for all. You can do it for all tribe types and for flow past, for example, cables 5, which is where many more triads are there, but still the reference is kind of clear. And I want to quickly, I don't know how long I have, maybe so we introduce this. We introduce this Kuramoto parameter again and we do it in a more clever way. So instead of summing all the exponential of i times phase and divided by number of triads, we just look at this sum and see how it behaves as a function of n. It turns out that as long as it grows with n, we are happy, right? We can say we have some synchronization because it means that the signal Because it means that the signal tries to produce asynchronization, as you saw in the figure. Most of the triads, or a majority of the triads, want to be near phase equals zero. So this quantity allows us to establish that. And I'm going to maybe, yeah, I'm going to show that right now. Okay, so this is the result. You start from the corner there on the top left and start adding up these exponentials, right? So if all the faces were completely randomized in a uniform way, you should get a random walk, but with the zero mean, right? But because there is a slight preference to have positive contribution to the flux, you start seeing this. You start seeing this kind of drunken worker, but on a slope, right? It starts moving to one direction. And it's amazing. As time evolves, remember this is done as I change the number of triads involved. So, for example, if I reduce the number of triads, I just have a shorter path. But as time evolves, when the system starts becoming more ordered because of this interesting reconnection. This interesting reconnection event that happens in the middle, you can see that this path becomes as long as possible, right? And you can then test how it evolves when you add more terms. So it's clearly consistently adding more terms. But you know, it has some waiting times. So it is a kind of random work process with an extra with some preference. That's why we don't see perfect synchronization. We don't see perfect synchronization when you divide by n, but if you divide by n to some power less than one, you're gonna see a nice synchronization. That was basically the mystery of this problem. We were divided by the wrong number. Finally, for those of you who were asking, what are these triads doing physically? Here's the answer. Here's the answer. The problem usually is how to plot a trial is three-way vectors. Each wave vector has three components. But the condition k1 plus k2 plus k3 means there's only two independent wave vectors. So you have six independent variables. How do you plot the phase as a function of six variables? It's not possible. So we came up with this idea of plotting this normal vector, which is very nice because it It contains the information that ride in a way where whichever two modes you choose, the normal vector has the same direction. It's a ray. It's the same, it can change sense, but it's the same ray. So we can use this vector to define a triad and ask the question whether these vectors have, you know, because remember now we have the list of all high flux triads, so we can start plotting these vectors. So, we can start plotting these vectors and see how these vectors distribute in a space. So, we do that. Oh, this works maybe smaller. Okay. So Here we're plotting on the box of wave numbers in blue the actual wave numbers associated to this triad, like belonging to these triads. So if you consider all the triads, it's going to be a large plot like that. And if you consider only a fraction of them, you're going to see only a few of the wave numbers. Let's say for this fraction here, where we know we're going to find a nice. Where we know we're going to find a nice behavior representative of the whole set. Now, let's study this behavior in time, right? So, how actually the number of modes decreases. So, it's less modes, but more energy flowing out. And you can see here is the plots of those normal vectors. So, this is showing that there's two preferred directions for the flux across k equals two. But for the flux across k equals five, Equals five, you get this very, very interesting behavior. This will be the last type of thing I show, right? So you start getting a clustering in a different direction near the time of supposed reconnection. And look at what happens to the wave numbers. They form this kind of elongated structure, and these arrows. And these arrows here correspond to the normal vectors, and they seem to be in a flattened distribution. So you can see here in 3D, if I point towards the diagonal, you can see that this distribution is a flat, kind of a flat 2D distribution in this diagonal, 111, which is In this diagonal 111, which is the diagonal of the vertex rings that you found, that vertex found. So, and you know, in the vertex rings, all directions are possible, but only rotated in the plane. So, that's why we are seeing all these arrows, these normal vectors pointing on a plane, because I think it corresponds to a vertex string. At least a vortex string will give you this behavior. So, in this way, with this analysis, we found. Analysis: We found the vortex ring without looking at the actual physical pictures, right? All right, so yeah, I think my time is up already, some time ago. I'm going to skip the conclusions and I'm going to thank you very much for your attention.