I mean every thought is the same thing. If you thought back, one thing is that you have a lot of team bubble views. Yeah, but I don't know if you're like the last one.   We will start right away with the first talk that is by Sandra Suturama to talk about a typ typical behaviour of agri-particle in existence. Okay, well uh thank you uh for uh inviting me uh For inviting me, it's wonderful to be here at a conference devoted to themes of Timo's research. Maybe I could just say a few more words. When I arrived in Ames in 98, Timo is probably and actually found a place within walking distance of his house. Any memories and uh Any memories? And I've heard a lot from you, path-wise and otherwise. Thank you. Let me talk about some work with Varthan. It's about a tight particle in ASEP, which is a model I think familiar to all of us. But let me just fix some of the notation. So we have particles on the line and of course jumps to occupied locations are restricted and we're considering nearest neighbor processes. Jumps left is P of minus one or Is P of minus one or Q, we'll call it Q. And the jumps to the right are a P. And so this is, of course, canonical process. So the problem we're interested in is we just tagged one of them or distinguished one of the particles and we want to follow its motion. It's not in general a Markov process. It's not in general a Markov process with respect to its own history. So we need to understand what the other guys are doing. And if there's a lot of particles, of course, the dominant flow will force the tag particle to do something, but there are occasions when it's alone and then it has its own plot. Okay, so Okay, so um so um uh this is of course a uh it's a Markov process and uh it has a generator which I've uh put plus minuses to just keep it on the line and yeah, feel free to to interrupt if there are any questions okay I think I can. Um okay, I think okay. Okay. Okay, so uh uh as is custom, TASEP is uh when you're only allowed to move to the right. And uh ASEP, I'll take the convention that the right probability is more than the left one. And of course you have symmetric simple exclusion and from mass conservation we know there's a family of invariant measures and measures and and uh you know this is uh this remotely product measure is is uh stationary uh stationary measures for these buses okay so so so our question is there's been a lot of work on tag particles so our question is if the tag particle is going to go further than it than it should go Than it should go, let's say starting from one of these stationary states where we distribute particles according to density œÅ, then how does it get there? How does the system organize itself so that that deviation is achieved optimally? Standard question of large deviations. So, what is the typical behavior? Where is it supposed to be? Behavior, where is it supposed to be? So, the typical behavior starting from stationary state, so here I've just conditioned that the origin is occupied, so that's where the attack particle is initially. Okay, so it's well known, you know, going back to Elen Sara and Fredun, that the tag particle is The tag particle is slowed down if it were just by itself. If it were just by itself, it's moving according to velocity p minus q, which we're calling gamma. But it's slowed down by this factor 1 minus rho. So this is well known. And so this is the typical location if we introduce a scaling factor. If we introduce a scaling factor, so we're thinking of the process speeded up by time n, so at time microscopic time nt. And we're going to also coarse grain space so that the grid size is 1 over n. So this quantity at macroscopic time t should be roughly the slope. So So for TESA, there's a very nice formula going back to perhaps Keston. I read it in a paper of Kibnis a long time ago, where you can understand the tag particle as a current in a certain zero-range process, where so if you look at the space. So, if you look at the spaces between particles and then follow the spaces between particles, that'll be a certain zero-range process. And so, this location is the current in a certain zero-range process across the origin. And in TASA, you can assume that there's no particles behind the tag particle, it doesn't really matter. And so, then if you look at the zero-range current, The zero range current and do a time reversal, then you'll see that from a generator calculation that the XT is distributed according to a departure process, which is the arrival process, the POSOP process. Burke's theorem in queuing. In ASAP, you don't have an exact formula like that, but you have this very nice approximation. You have this very nice approximation by Pablo and Luis Roberto Fontes, where it's almost a Poisson process with this rate. This is the thing that we saw from the Law Bush numbers. And you're perturbing it by an error which has a very good moment property. So, from this congregation, you can already see what the large deviation rate function should be for the type particle in TASEP, and from ASEP, you might be able to guess something. So, rephrasing the question in this notation, so this is typically where it should be. So, if we're not there, if A is the macroscopic location we're trying to get to, which is atypical. To, which is atypical, how does the system organize so that you get there? So in this talk, we're starting from this random stationary initial, which is important actually for us. So as I mentioned from the Burke's theorem computation, you know exactly what's going on in TASAP. Exactly, what's going on in TASEP in terms of cost? The large deviation rate function is just the rate function for Poisson processes. And the Ferrari-Fontest relation gives you large deviation upper bound estimates. This quantity is not independent of this one, so it's not, so you don't get it exactly. Exactly. Okay, but you get a bound. Okay, so what's our goal in this talk, in this work, is so what we're going to discuss are change of measures, strategies under which we can achieve lower bounds to get these exact costs, let's say in TASEP, and hopefully what we feel should be. What we feel should be the cost in ASIP. And then we're going to try to match it by minimizing over strategies and then showing some upper bounds. And in the upper tail, upper tail means you're deviating beyond the mean. In that regime, then we can map. Okay, and so. And so I can give away the punchline. So near the zero, the Ferrari-Fontest approximation gives the right answer. But if you're far away, then there's a change. Okay, so we're going to do fixed time, so one time, one macroscopic time, so we're not. Macroscopic time, so we're not looking at the process in time, just a fixed time here. And so we might as well just take t equals to one. So previous work, this problem was studied in symmetric simple exclusion. And there the scaling is different. So in the ASEP, we're expecting orthodox. We're expecting Euler scale, and here you're having diffusive scale. And so you can write down a rate function, which is contraction from the large deviations for the empirical measure. Okay, so this goes back to Derdog, Dershenfeld, and more recently an explicit formula was given in this work of Imumura, Malik, and Susan. Since I already mentioned that tight particle is related to current, it's also related to current. It's also related to currents in the exclusion process itself. It's a different problem, but it may be nice to mention some of Timo Semonel's work, Markov processes as related fields paper. And more recently, the problem in TSEP has been studied by Lee Shan and Stefano. And in ASAP, starting from some initial conditions, there's also been some nice work. And both of these work start from deterministic initial conditions. So as I'll try to indicate, it's a little bit different flavor from what we're going to do. Okay, so coming back. Okay, so coming back. So, what I'd like to do is I'd like to discuss the result in ASEP, but it's more concrete to discuss TASEP. And the methods are the same. So, we cut it down around this gamma parameter. We don't have to keep it around too much. I'll indicate where it appears. So, it's just maybe easier to, I thought it would. To, I thought it would be better to be concrete with the taste of first. So it turns out that there's three regimes of interest. So in t sub gamma is one, so this is the typical macroscopic velocity of the tank particle. So this is where it should be at time one. And so if you're if you're If your velocity is bigger than one, that'll be a regime where the structure of the lower bound and upper bound are different than if A were between 1 minus rho and 1. And also, there's a third regime where it's in the lower tail where it's less than 1. So in each of these regimes, you will have different behaviors. Have different behaviors. So let me just, you know, I don't think I'll have time to do all three, so what I'll do is I'll discuss a little bit about A bigger than one and a little bit about A in the lower tail. And then if I have time, I'll mention what's going on in the middle. So when A is bigger than 1, So, when a is bigger than 1, so remember that the time particle has a clock with exponential parameter 1, and so if your velocity is going to be bigger than 1, then you have to change the type particles. There's no way that it can get there without any change, even if there's no other particles in the system. So, you certainly have to, you know, if A is bigger than 1, If A is bigger than 1, so if you're trying to get over here, then you really have to change the tech particle. But of course, it's nearest neighbor, it can't jump over other things. So we have to do something about the other particles. And so this is where the difference with the initial condition comes in into play. If we're having deterministic initial conditions, Not, if we're having a deterministic initial condition, then in this picture, you know, there's going to be order n particles here, and the target particles starting here. All of these guys have to speed up and get beyond this location. So each one has order n cost, and so the order n squared cost. Okay, that's very large. Okay, and on the other hand, since we start from random initial condition, we have the Addition, we have the opportunity to actually just make these cars disappear. We just remove the offending cars. And the entropy cost of that on a macroscopic interval of size 1 is order n, which is much smaller. Okay, so to put those comments together, let's Those comments together, we have to understand how much, where to remove particles and how many of them to remove. So that's connected to the bulk flow. So the hydrodynamics of TASEP or ASEP is very well known. We're talking about the empirical measure of particles here. And if we start from If we start from local equilibrium measure, where we have some initial profile and we sample it at x over n and then put a particle there with probability that number and not with the complement probability, then independently, then that's the local equilibrium measure. If we start from something like that, if rho naught is constant, then this is, of course, the invariant measure. So if rho naught is slowly varying, then we Then we can, it's well known, hydronomics is well known, and you're converging to this hydrodynamic density, which satisfies this type of trophic or burgers. Okay, so I put back the gamma here. Gamma is one taste of. Okay, and you know, there's a whole theory. And there's a whole theory about all this. Going back to Roost and Fregun's work, and Timo's work also shows this in a different way. And so there's generally non-uniqueness in the system, and so you have to select the entropy section. Okay, so coming back to the Zach particles, so this Particles, so this so this is the event we're interested in. So if we this is the velocity being bigger than A, or the scale position being bigger than A. This is in TESEP, this means that all the particles between zero and this location at time t, there should be nothing because, so in case of I can just So, in taste step, I can just assume that there's no particles behind the tag particle. So, let me just remove all of those, right? So, if the tag particle is going to be beyond an, that means before an, the tag particle has swept all the other guys out. So, this is a kind of a current relation with respect to exclusion. And so, if we divide by 1 over n, then this is approximately. By 1 over n, then this is approximately equal to this quantity when x is equal to a. And so this condition here is roughly the same thing in the continuum as this. Okay, so this height function, if you like, satisfies, if you integrate Berger's equation, you get this equation. And so I've set gamma equal to 1 here. I've set gamma equal to one here. Okay, and so the entropy solution of this is satisfying the Hop-Lauptz formula, and here it is after some questions. Okay, so one more ingredient. On the other hand, this quantity, which is the average number of particles between zero and a n at A n at macroscopic time one is, you know, it can't be smaller than this deterministic quantity which solves the previous Huff-Lax formula, the entropy height at A, without incurring super-exponential costs. So, specifically, this limit. This is a statement exactly. This is a statement exactly that if you reinterpret this, you can say that the number of particles beyond at macroscopic time one can't be more than n times this quantity. So to be more, you'd have to speed up an order in particles, and we discussed that's that's very costly. That's basically what this is saying. So putting So, putting those together, we can deduce where to remove particles. So, we're trying to move to this location. And this is the quantity from the super, this is the inequality from the super exponential bound that we had. So, this is the deterministic number, and this is the thing from the scaling the The mass into the system. And if the tag particle is going to be here, then this has to be equal to zero. That all the mass has gone beyond it. So now use the formula that we had before, this one, and put it back into here, and you have some inequalities. And you have some inequalities. We had a variational formula, right? Where is it? Here. So it's super verb Z. This, I guess, should be Z. Sorry about that. Okay, again, this should be Z. Sorry. So we have some inequalities. And so if you, you know, it's not, you can't actually do it, right? If you think that this inequality. If you think that this inequality is okay if you differentiate both sides, it's not, you can't do that, but you have this kind of thing. And so that suggests what the picture should be. So this quantity would be, this is zero unless Z is within one of A. And so that's what we get. So we get that from zero to this location, there should be. From zero to this location, there should be no particles. And also, the formula suggests that we can allow some particles from A minus 1 to A, according to the blue macroscopic profile. And so the intuition here is that the type particle is over here. The particles here are going to move in tropically, naturally. And so you can put some particles here, they have time. Of particles here, they have time one to get beyond A. And so just this blue curve will come into the yellow one. And the tag particle, now we're going to change its rate. So there's a cost of this initial profile. You remove all the particles here, you change the Bernoulli road to this slanted profile, and it's And it's an integral you calculate, so this is what you get. And now you have room for the tech particle. You have to change its rate. We change its rate so that in time one it gets to A, so we change it from time one, rate one to rate A. Okay, and so that has this cost. If you add these two costs together, you get back the things that we had in the beginning from the exact one. That's kind of cute. Cute. Yeah. Okay, so so uh uh so a comment in ASEP is that uh the only thing that changes here is that is that we once we remove particles. I mean some of the locations, this picture will change slightly with you'll have to put It'll change slightly with, you'll have to put some gammas into this picture. Okay, but there will be some empty space. The tag particle now is not a Poisson process, it's the birth-to-death process moving left and right, possibly. So you have to change the birth-to-death process. So this factor, this term would be different in ASAP, but you still add it onto the piece that you got from removing the particles, and then that should be the rate of it. And then that should be a great point. Also, the removing is different, right? The removing is different only in terms of some constants. It's a different profile. It sort of looks the same, but these numbers are changing. There's some gammas in these numbers. Basically, A will go to A divided by gamma. And then I think this two rho, so this will be A divided by gamma. This is two rho times gamma. This is two-row times gamma or something like this. There's some, I forget exactly the thing. We'll come back to it at the end. I'll give the statement. So that's one, so it doesn't say that this is the only way lower bound that you can achieve, but it's morally maybe the only thing. Okay, so let's turn to the case when in the lower tail. So suppose A is zero. So that means that up to time one, the tag particle didn't move macroscopically. Okay, so one way, of course, is that you just simply hold the clock. That you just simply hold the clock so that it doesn't ring. Okay, and so this has some cost, but it's larger than what we know the answer is. So the other way, I think we're all thinking about it because we've sat in traffic, you're blocked, right? So you're blocked by other particles and so even if you want to move, you can't move. So the question is how how l how long should the block blockade be? Long should the block locate be? And so to save time, let me just say that entropically you'd have to go to size 1 because at location 1, because then the shock will come in with rate 1. But that's too large, also. So we block. So we block actually only up to row, and that gives the right answer, but why? It only gives the right answer if we also change the process. So normally what's going on here is that you'll have a rarefaction made. But we're not going to hold the shock, and so it comes. So it comes back as a shock. That is still a solution of the Berger's equation, the non-entropic solution. And so in that solution, the blockade comes back to zero at time one. And so it's suitable for us. We have to calculate its cost. And this is known from Known from work of Luke Jensen. And so this is a profile, a non-entropic profile in which costs have been computed. And it looks a little bit like this, where L is L is zero, R is one. L is 0, R is 1, R is rho. And anyway, so if you put all that in, you get this at the cost of changing the measure. And so we had to actually change the initial profile, which was all row, to one and then coming back down to row. And so that has this additional cost. If you have these two guys together, you get what we had from the exact formula. So you don't slow down the first model, the tech model. We don't slow down the first part, the tech particle. We don't touch it. We could slow down the tech particle, but that would just increase the cost. It would not be optimal. Yeah, you could optimize over those, and then you see that this is the one that you get. You could do that and then have a store thing. You can optimize over that, and this is the best one that you get. Okay, so just maybe a couple of minutes on upper bounds. So yeah, by the way, there's an open problem here. So this Jensen formula is only for TASEP. So we don't have a formula like this actually at the moment in ASEP. It's something that The others could be. Okay, upper bounds. So we've given now some change of measures to achieve cost, but how you know in KSEP, we know that actually that's the right answer, but maybe there's for ASEP in particular, we want to minimize overall strategies and To minimize overall strategies and try to match upper and lower costs. So we can do this when A is bigger than the B. And that'll identify the rate function. So just a sketch, it boils down to understanding this formula, this logarithm here. So if you remember, If you remember, X of n over n being bigger than A is the same as this event happening. And so you can go ahead and put in the superexponential cost bound and then you can drop Drop, you know, get an upper bound by just dropping this, you know, having this less than or equal to zero. And so in the end, what we can afford to minimize is perhaps just the initial change of measure, which is this, subject to this being equal to zero. So it's only So, it's only changing the initial measure. And so there is the part where you can change the process, but for the upper tail, it turns out we don't need it. Is there plus missing in between? Sorry? Is there plus missing in between? Maybe, yeah, definitely there's a plus missing right here. Sorry. Okay. So this is a calculus of variation problems. A calculus of variation problems, and so this can be solved. It's not so easy, but it can be solved. And so we can match upper and lower bounds. In ASEAP, there's another category. You can go left. And so here's the rate function. So in the middle region, middle upper tail region, this is the cost you get. It's actually the one corresponding to the It's actually the one corresponding to the Ferrari functions of approximation. And then in the upper tail, when A is bigger than gamma, you pick up that birth-death composition. And so this is just the end of the talk. Next talk. Questions? I already saw that non-entropy solutions are absolutely zero through this stuff. Is this general that if we take quicker conditioning, you can allow this entropy behavior? Yeah, that was a sort of surprise to us. You know, we thought it would be just by blocking with enough particles and just moving entropically, but it turns out that uh in a lower tail, the non entropic solution is Onotropic installation of the soul. But the upper tail it doesn't. I don't I haven't seen it, although I should be corrected if anybody knows. So this certainly may be one of the first instances. Did you argue about that's the best tragedy here? The um uh best tragic in uh Strategy in the optimization problem so we can maybe let me interpret your question. Are you so we don't by minimizing the upper bound, we can achieve the exact formula? Is that what you're asking? And so, therefore, we can give another argument for the rate function. For the ring function in the upper tail for tesel? We're not using verts. For the lower tail, yeah, that's a great question. Yeah, for the lower tail, we haven't figured it out because it's this big problem of optimizing overall solutions of Berger's equation. You have to minimize Jensen variant formula. On the other hand, On the other hand, looking at the profiles, they're not that bad. So there could be a reduction where you only have to consider NICE profiles. In which case, there may be some NICE profiles only with three or four discount units. So there may be some chance, but I don't know that. But for Arbiter, when you figure out the terminal shape, from 0 to 1, basically thing that is valuable. Basically, think is by evolving the thing quite a bit. Yeah, is there? I mean, this happens a lot. Is there an explanation why that sex goes to the case? Well, it was the first time I saw it, so you know, I don't have a more physical explanation. Good question. Yeah, it was fine. 