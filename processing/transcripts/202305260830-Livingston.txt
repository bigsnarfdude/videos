Good morning everyone. Welcome to the last day of the Burke's workshop on formalization of colomology theories. And today I'm going to finish with two talks back to back. So first of all, Aminia Linster is going to talk about group colomology in me. And then hopefully we'll have a virtual talk at the end of my population. So take it away, Aminia. Thank you. Hello. Thank you very much to the organizers for the invite. Much to the organizers for the invite to speak and for organizing everything. It's been a great week. I'm going to tell you three definitions of group chromology. I'm going to explain the formalization of two of them, which is in MATLAB, and the proof that they agree. Then I'll talk about what I've used the definitions to do so far, but which isn't in MATLAB. And then I'll give a long list of things that need to be done. I'll talk about sort of what you need to use to do them. What you need to use to do them, and so forth. So, first of all, we use group cohomology to study groups by looking at other objects that the groups act on. So, the objects that we care about are G modules. These are abevian groups, which we denote additively with a multiplicative G-action that distributes over addition. And given a G module, we define our first definition of group cohomology to be the cohomology of. To be the cohomology of this complex here, called the complex of inhomogeneous co-chains. And so you can see the objects in the complex are quite simple. It's just functions from g to the n to m. But then on the other hand, you've got this really ugly differential. So it might be okay for computation in low degree, but then you might have a bit of trouble saying things in arbitrary degree. So, in low degree, this is what the differentials look like. You notice that the first map, the kernel of that map, is going to be the elements of m that are fixed by everything in G. So H0 is going to be the G invariance of M. We also have that group cohomology is functorial in the second argument. So, a G module morphism induces maps on cohomology for all n. And, like all good cohomology theories, we can use this to show that. Theories, we can use this to show that a short exact sequence of G modules induces a long exact sequence in cohomology. So here's a less close to the ground definition. The invariance functor is left exact, so it has some right-derived functors. Now, how do we calculate right-derived functors? We're supposed to take an injective resolution of our G module and then apply the invariance functor and then take homology. But injective objects are massive and Injective objects are massive and like hard to use. So, how did we get the first concrete definition? It must have not come from an injective resolution because the objects in it were quite friendly. So, this is because the category of G modules is, first of all, equivalent to the category of modules over the group ring Zg. And we also have that the invariants of M are isomorphic to the Z G linear horms from Z, where we give it the trivial G action. The trivial reaction. So, group chromology is actually the right-drive functor of some hom functor. But these have a name, they're called x-groups. And the thing about x-groups, the thing about x is that it's a bifunctor. So we can calculate it either by taking a projective resolution of the first argument or an injective resolution of the second argument. So this is where our first definition came from. It came from a nice projective resolution of z. So, yeah, in massive, So, yeah, in Mathlib, X is only defined in the nice way. So, you can only compute it by taking a projective resolution of the first argument. And if we were to prove, if we were to define, make the other definition and then prove balancing of X, which says that they agree with each other, we'd be able to view it as a right-derived functor too. But as it stands, we only have the friendlier definition. And so, yeah, in MATLAB, we've got the concrete definition. We've got the concrete definition and the sort of left or right definition and a proof that they agree. So, how is that proof going to go? Well, to compute group cohomology by taking a projective resolution of Z, there's a standard resolution to take of Z, and it's called the standard resolution. And the objects in it are slightly sort of bigger than the ones you could sort of see in the inhomogeneous code chains because. In the inhomogeneous co-chains, because now the nth object is z of d to the n plus 1. But the differential is much dicer. So, you know, it's not immediately obvious that the differentials here are going to turn into the ugly differentials from before. But we can work out what's going on with the objects. So we take home of the standard resolution, and then we do this long chain of isomorphisms. So the first one is going to be because To be because you know, this isn't the isomorphism between zg to the n plus 1 and z g tensor z g to the n that we're going to use isn't the obvious one that you get from the diagonal action of g acting on everything, because the action on z g to the n is going to be trivial. So we're going to end up with some quite weird maps in this isomorphism that we're going to define later. And then the next one is going to come from some kind of tensor homojunction that's also going to be sort of non-trivial to formalize. And then the last two are going to be. To formalize, and then the last two are easy. So, like, you know, our linear homs from R are just the left and the right-hand side, and then Zg to the n is a free Z module. So, yeah. And then once we've done that, we just have to check that the isomorphisms commute with differentials. So, we have this in Letlib now, but there's a couple of notes to make in the way that it's stated. First of all, we can replace Z. First of all, we can replace Z with any commutative ring K, so we do. And secondly, we're going to have to talk about objects with a K action and a compatible G action. And there's a few different ways you can do this. And deciding which way to use was a question that all the people who developed the representation theory library had to answer. So I'll talk a bit about the solution that they chose. It agrees with the X definition. With the X definition, you know, if it's like object-wise or object-wise, yeah, yeah. Okay, yeah, um, so yeah, the first option we have for dealing with things with a K-action and a G-action is to just talk about KG modules. Now, the natural instances you needed to make to use this formulation seem to cause some diamonds. So, suppose you have like a K module M and it has a G-action. A K module M and it has a G action, and you want to turn it into a K G module, then the natural instance that you make when G has an action on K and when M is the group ring, the group ring K G, then the action that you get from the natural instance we need for our representations doesn't agree with the action of A1 itself by multiplication. So you don't really want to have it. So, you don't really want to have it as an instance. That's the main example I thought of, but you know, people who were developing representation theory I think ran into other diamonds as well. Similarly, if you use just like these theoretical diamonds that are never going to happen. Yeah, but I mean, it's like the assumptions on these variables aren't even like wildly general. Like, we've got a comring k and an ad com group, you know, a k mod. An adcom group, you know, a K module M, G is a group rather than a monoid, but you still get diamonds. The other option is to work with objects with a K action and a G action separately, but I think that caused problems as well. And ultimately, people decided that the best definition, oh no, here's another thing we could do. We could work in the capital M category of modules over Kg. So like outside the category theory library, a module is like a top. A module is like a type with a module instance on it. Inside the category 3 library, it's all bundled. So a term, a type, module R is like, has three structure fields. It's like a type, an add-com group instance, and a module instance. And so the module structures built into the type is unambiguous. You're not going to get diamonds. But there's a natural K module instance on the term of type module Kg. And so if you start with a K module with the G action, you turn it. K module with the G action, you turn it into a term of type module kg, and then you look at the k module instance on it. It's not definition equal to the one you started with. And so it's kind of really annoying to work with. So here's the solution. We bundle the G-action. We give up on using type class inference to express the g-action. So these are definitions due to Scott. The first one is the category of The category of V objects with a G action. So V is any large category, we have an object V and V, and then we have a like a morphism rho from G to the endomorphisms of V. And when V is k modules, this is the representations. And so, yeah, we can't express the G action with a nice scalar multiplication notation, but this doesn't really even make things more verbose because the Because, like, the representation morphism has built into its type G and K and the object we're doing the representation on. So things are still pretty concise. And I used this, and it worked really nice. So our first job is to define the standard resolution. The objects are easy to define as representations induced by the diagonal action of g. And then the differentials, the k-linear maps, underlying. Differentials, the k-linear maps underlying the differentials are easy to define, but then we need to show that they square to zero. And there's a sense in which this is already in MATLAB. So if we can express our resolution in a more abstract way, then we can sort of link up different areas of the library and we can avoid some code duplication. So that's what we did, and we followed a strategy suggested by Joel Ryu. So thank you, Joal. So this is So, this is going to come from the fact that there's a connection between topological cohomology and group cohomology. So, if we take the classifying space of G, then the cohomology of that agrees with the group cohomology of G. And we construct BG as the quotient of universal covering space EG by an action of G. Now, EG is this massive thing, like for every element of G to the n plus 1, we have an n simplex. And we're not going to construct it as a topological. And we're not going to construct it as a topological space. We're just going to work in, you know, we're going to ignore topology. You can go from topology to simplicial objects to chain complexes, and we're just going to work on this side. So we're going to define EG as a simplicial G set and call it EG. And yeah, so this is the geometric realization of this thing is going to be the actual topological space EG. So as a simplistical G set, it's an So, as a simplicial G set, it sends n to g to the n plus 1 with the diagonal action, and it has the natural action of the morphisms. And then, because a simplicial object is a functor, we can compose it with the linearization functor from G sets to representations, and we get a simplicial representation. So, this functor is just induced by the free k module functor. And then we can take the alternating face map complex, because now we're in an abelian category, and we end up with. And we end up with a chain complex of representations, and it's the one that we want. So the objects are definitionally isomorphic to kg to the n plus 1, and then simp shows that the differentials agree with that nice definition from before. So we've got nice definitional properties. D squared is zero is in the API. Yeah, yeah, yeah, yeah. So you get that for free. But that's not all we can get from um from this uh E G interpretation. From this EG interpretation, we can also get the fact that we're going to need our complex to be exact, except at the right where the co-kernel is isomorphic to k with the trivial representation. And this is going to come, you know, in the chain complex land, this is a quasi-isomorphism of two of resolution and a complex support in degree zero. In the simplicial land, this is going to come from a simplicial object with an extra degeneracy. And in the topological land, this corresponds to EG being contractible. To EG being contractible. So, how are we going to show this? Well, first of all, we're going to show that EG is the check nerve of the G-set morphism from G to the terminal object. So, for example, it's been shown that G to the N plus 1 with diagonal action is the n plus 1 fold fiber product of G over the terminal object with the sub. So that sounds trivial, but it takes several definitions, but it's not like, you don't run into any annoying problems. And then, thanks to Jojoel, we know that. And then thanks to Joel, we know that the augmented check nerve of a split epimorphism has an extra degeneracy. And also thanks to Joel, we know that when we take the alternating face mark complex of a simplicial object with an extra degeneracy, we get a complex that's homotopy equivalent to a complex contributing degree zero by the thing you've augmented for. But there's one problem, as a map of G sets. One problem as a map of G sets, unless G is trivial, the morphism G to the terminal object is not split. So, first of all, it is split as a map of sets. So, we're going to show that augmented EG, when we compose with the forgetful functor to set, this has an extra degeneracy because it's still a check nerve. So, it's the check nerve of a split epi. And then, when we compose with the free k module functor, we're now in, you know, yeah. Now, in, you know, yeah, we're no longer a check nerve, so this is why we had to start without the k-action, but the proof strategy. But any functor preserves extra degeneracies, so we still have one of them. And then now we're in an abelian category, so we can take the alternating face-mark complex, and we get homotopy equivalents of our resolution as a complex of k modules and the complex concentrated in degree zero by k. And this will be enough for us. So first So, first of all, the only non-trivial map in homotopy equivalence is in degree zero. It's rather than being from Kg to K, it's from K, you know, fin 1 to G, but anyway. And we check that this comes from a MAC of representations rather than just being a K linear map. And we can't upgrade this homotopy equivalence to a homotopy equivalence of complexes of representations, but we don't need that. We just need a quasi isomorphism between the resolution and the very simple complex. And the very simple complex. And that's fine because the forgetful functor from representations to k modules is exact, analyst, and faithful, and so we can prove that such a functor reflects quaso-isomorphisms. So we have everything we need to show, to define the resolution and to show that it's quaso-isomorphic to what it should be. So the next thing to do, the final thing to do, is show that the objects in the resolution are projective. We're instead going to show that. We're instead going to show they're free, and we're going to pass to a module category to do this because it's got a nice free objects API. And we're going to do this by constructing the isomorphism that we saw in our long string of isomorphisms between the tensor product where kg acts on itself by left multiplication and the kg n representation is trivial and then we put the diagonal action on the right hand side. And so obviously the left-hand side is free. And so obviously the left-hand side is free because kg to the n is a free k module, and so if we tensify kg, we get a free kg module. Transport this across the isomorphism, and we know that the objects and the resolution are free. So I built this isomorphism twice, once right at the beginning of the project and once right at the end. So I'll sort of compare them a little bit. So if you want to define the isomorphism directly, you have to define these slightly ugly. Define these slightly ugly maps. And it's easy to define them as k-linear maps, but then first of all, you have to upgrade them to morphisms of representations. And we're using quite simple objects, but when you try and make a term of morphisms of representations, you have like a k-linear map field and then a proof that is compatible with G actions. And you try and do this short proof. And you can't use DSIMP and you can't use symp because they're timeout. And so it's kind of surprising. And this is kind of surprising. So you have to prove the lemmas separately. And the resulting maps were really slow. One of them takes 27 seconds. Well. You're in the category of modules, by the way. No, no, no, not yet. I've not even been using category theory. Well, you're using category because morphisms of representations, like you don't have, you have a category of representations, and then morphisms of representations are only defined in that category. Like we don't have a sort of concrete definition of morphism. Of concrete definition of morphisms of representations, because you'd need to take the representations as an argument, and it would be, yeah. So you're using a tiny bit of the category theory library. And yeah, you want to show that you want to prove how the maps act on simple elements. Proving this about the k-linear maps is fine. And then you try and prove this about the representation morphisms by just writing the By just writing the proof for k-linear maps, it's just one line, and it takes like a minute to compile if you do it in IUP. If you write by apply to help the elaborator with unification, then it's a lot quicker. But there's something Lean doesn't like about this definition, I don't know. So the second time I did it, I did it after I'd used the category theory library a lot more and I knew some tricks. And also, I just wanted to sort of factor out the process into some more abstract steps. So I made an Steps. So I made an isomorphism of G sets and then I used the fact that the linearization functor is monoidal. And so this time around, we don't have to show that it's an isomorphism. We don't have to show that it's morphisms of representations. But we do have to prove that the resulting maps agree with these ugly maps from before. And so this is what the proof looks like. It's a massive sim block where most of these things are definitional. I'll talk a little bit more about why that is in a bit. But if you have some tricks, then you can make the screw fine and it's not that. What except is that auto-generated? I can't remember. I think some of it was. Was it interesting by hand? I think so. It used to be a lot longer and then I just, you know, I'll talk about this a bit, but like the golfy sorts of briefs, I just like take away one number, so use for compiles, take away the number. So if it compiles, take a bit of a minute since zip Z. Just a very low-level question. Why is it CIP A instead of CIP? Because I think the last, you get it to a state where the two sides are not syntactically equal, but they are definitionally equal. That tries exactly, so it fits no music tries to raffle. Yeah. So what was I going to say? Yeah, so this formulation is using the category theory library more, but it's a lot faster than the first definition. So, yeah. And then the last thing to do is transport, you know, go to the module category and transport the basis from one side to the other. But we're punished for being in the module category because on this left-hand side, this is the module we want. But when we take our representation isomorphism. Take our representation isomorphism and parse across the equivalents. The module we get on the left-hand side is not definitionally isomorphic to the one on the screen. And that's the one, the one on the screen is the one we want to use the results about bases that we need. So we have to, in the bottom line here, we have to write, this is the isomorphism of representations. We use it to define the functions in the isomorphism, and then by hand, we In the isomorphism, and then by hand we prove that this can reach with scalar multiplication. So that's a bit annoying, but it's fine. So then we have everything we need. I'm skipping a load of random homological API that wasn't very interesting, but there's the projective resolution. And we can immediately sort of make one stupid definition of group homology, which is that it's X groups, and here's projective resolution you can compute them from. I include this code because you can't. Code because you can't just write the definition. You have to write by let definition exact this, which is like, I've often found that when I make a definition with X'd in it, you get weird things like a deflem issue, or you have to write by apply, whatever. So that's a bit, it's not always the case. I've got another fine use of X'd, but it's a little bit unstable sometimes. Sorry? It's not ideal. Stable something. Sorry? It's not ideal. Yeah, it's not ideal. There's vitals with proof, right? Yeah, yeah. Yeah, we're going to get a new one. Yeah, don't do anything with X because we're going to get a new one, as we heard the other day. But still. So the definition we really want is the inhomogeneous co-chains and the fact that they agree with the X groups. So let's look at the isomorphism again from before. The last two are fine. No, the last, I'm missing an isomorphism sign. The last two are fine. Missing an isomorphism sign. The last two are fine. The first one we've just sort of done. The middle one is going to come from some kind of tensor homer junction, but you know, the statement of like maps out of the tensor product corresponds to bilinear maps for modules over a commutative ring, this isn't that. Like kg is in general non-commutative. So we're going to need something slightly different. The first thing I tried was go to the module category, build a slightly more general definition of like content products. More general definition of like contents product.curry. And I was punished for this again. So it's best to just stay in the category of representations and use some more abstract category theory stuff. So we want, we're going to use the fact that the category of representations is monoidal closed, because what that means is exactly what we want. It means that tensoring on the left has a right adjoint called internal hom because it's going to look like some kind of hom set. Look like some kind of hom set, but not exactly, you know, homes that are also an object of the category. So, yes. So, we've already got a monoidal instance on representations, and it's defined by transporting across an equivalence. So, this is the category of functors from G as a category with one object to k modules. So, like you send a single object to the k module you're representing on. To the k module you're representing on. And then the morphisms are the elements of g, so you send them to endomorphisms of your k module. And there's also like a concretely defined monoidal closed instance on the functs category, given, yeah, on that one, yeah. And we can transport this across the equivalence too. But then we need to show that the internal homes we get are what they're supposed to be. So they're supposed to be. They're supposed to be given by k linear maps of the two representations, and the representation on these k linear maps is given by sort of conjugating by the representations that we're homing. And we also want that the homset bijection is what it's supposed to be, which is the underlying k-linear maps are given by tensor product.curry and tensor product.uncurry. And there were various reasons that this was kind of hard. So the definition of clothes. The definition of closed is a class with one structure field that says tension on the left is is left adjoint. And then the definition of is left adjoint is a class with some structure fields. And for some reason, I don't really fully understand this, but it's kind of if you've got a concretely defined right adjoint, the internal homs, it's kind of hard to unfold IHOM to find out how it's defined underneath. So in the functor category, I did this by deltering enough times, but I tried to do the same thing. Enough times. I tried to do the same thing when unfolding the IHOM that we get by passing over the equivalents, and I can't do it. Like I delted everything in the goal state, and we end up with this, and then you delta any of those things, and they don't unfold. Maybe there's a trick, I don't know. But alternatively, you could work out what this IHOM is supposed to be. It's that. And you write show. Yeah, yeah, yeah. Yeah, yeah, yeah. So, like, you show the statement of that lemma and it times out. So, you have to make it as a separate lemma and then rewrite it, which is kind of annoying. You know, like the right-hand side is a lot more previous than the left-hand side. So, does it turn out to be definitionally equal to XL? Yeah, yeah. So, we proved that it's, you know, this second line, this is what it's supposed to be: the representation on k-linear maps. And it takes, I think the only thing. And it takes I think the only thing that's not definitional you do X and then uh and then the the the important lemma is the single object in vasINV which is something about you know you've got a category with one object and something about inverses and if it's a great point yeah I would have expected to like construct the functor that you want and prove that it's a right adjoint and then use the uniqueness of right adjoints for some sort of this works This works. Yeah, I mean, I kind of wanted. I like the fact that you can sort of define a memoidal cost in systems in one line by just transporting across the equipments, but yeah, I also don't like this lemma, so maybe we could refactor it. Here's another lemma that you cannot read. That's about transporting noidal plates instance over in a couple of sync. And I needed that for similar reasons. For similar reasons. Again, I'm sure there's a trick to all this for people who know the character theory library better, but it's a trick you have to learn. I've learned some other tricks, and if there's one for this, I don't know it. Now we've proved that the homestep right action agrees with tense product.amcurry. This is not the proof that it's the same math lib, the proof that the symmet lib is much shorter. Is much shorter. But in the past, when working with category theory, because I was naive, I thought, you know, everything's really slow, but that's just life. I won't do anything about it. I won't try and change my ways. And when I was trying to do this stuff, I could no longer proceed with that attitude. And so you have to, there's a lot of situations where desync times out, or you can't, you know, if you try and, if you get the goal state into something that's definitionally equal but not syntactically equal, with two Basically equal with too many layers of structure, then REFL is really slow. Basically, you have to stop relying on definition of qualities and instead work out what DSIMP would do if it didn't time out, and then state those REFL emmers separately and then put them in a massive sim block. Oh, so no DSIMP at all? Yeah, yeah. I mean, if you did DSIMP only with the definitional ones, it would be fine. But you can't just do DSIMP. And yeah, if squeeze DSIMP worked, Yeah, if squeeze decent worked, that would be really cool, but I guess it's harder to make that work than squeeze simp. Oh, does it? Cool. Okay. So I think that was my first proof. And it was sort of, I think simp definitely timed out here. Like you just had to, and the sim set wasn't like confluence, so you have to do two different blocks. And all of this, you know, most of these are definitional. There's like one or two that aren't, but you need to do all of this to reply the ones that aren't definitional. And then somebody. And then somebody can't remember who, and I can't remember what change they made, but somebody changed the definition of tensor product on Curry to give it slightly better definition of qualities. And this means you can reduce the proof to like three lines. So yeah, it depends a lot on trophy completely. There's this other slightly annoying thing that, like, because I don't know if this would be a sort of clean thing to change. Be a sort of clean thing to change, but because monoidal closed is defined as an adjoint to tensoring on the left, the resulting homset bijection is this sort of opposite way around from what you get from tensor product.uncurry. So we have to do f.hom.flip. And that's sort of, you know, maybe the proof could be even shorter if that wasn't the case. I'm not really sure. But it's sort of weird. So I think if you defined it as tension on the right, then you wouldn't have to do the flip. Did you ex ever experiment much with changing these giant blocks into rewrites? And I know sometimes it fails just because rewrite can't do a step, because it's a camp. I think there are sufficiently many places where you were doing something twice. Yeah, it's a good question. What would be the advantage? I mean, often it's faster, and so when you have giant sim blocks timing out. I mean, these giant sim blocks, like the code is fair. These giant symptom blocks, like the code is fairly fast, but it's just finding what should be in the sync block that's difficult. And then, yeah, removing it. Yeah, I guess if you did it with rewrite, you wouldn't end up with any superfluous lemmas because many of these you can probably take them out and it would still compile. So yeah. Then there's also the in-between tactic which is simply writes. Oh yeah, yeah, yeah, yeah. Maybe we need extra tools to help people take logic and blocks and convert them into simply writes and Convert them into CPU rights and screen that produces a simply write. So, yeah, sometimes getting an object that's deeply within the category theory library to agree with an object that's outside it is tricky, but if you learn some tricks, you know, I'm a lot less, I'm happy to do this now, whereas I wasn't just like at that point in the project. And now the proof is much shorter. And there's the isomorphism we needed. That's all we needed. Isomorphism we needed, that's all we needed. It's just like the homestead bijection, except we need it to be k-linear. And then we get the isomorphism of objects that we want it. So now we can finally define the inhomogeneous codains. We define the differential in the simplest possible way. But then because it's really ugly, proving that it squares to zero is a pain to do directly. And so really we want to just get this for free from all the work we've just done. From all the work we've just done. So if dash is the differential in the standard resolution, then when we precompose by dash and then sort of conjugate by the isomorphisms we've made, we just want to show that this agrees with the differential in the inhomogeneous coaching complex. And this was still, you know, it wasn't three lines, but it's a lot easier than proving that it squares to zero directly. Yeah, and then we get d squared equals zero for three. And there's the definition. Cohomology of the in-home genus code. And there's the fact that it agrees with X. This isn't particularly native code, but it's the last result that I'll show from Mathlib, because there isn't anything else in Mathlib yet. So that's what's in Mathlib so far. I've got a bunch of stuff on some branches that I will PR. I will PR soon. And the first one is the fact that, as the definition stands, the first few objects in the complex are like functions from Vin0 to G to A, VIN1 to G to A, which is not ideal. And there's loads of also nicer expressions you can give for things in H0, H1, and HU. So I have a big file making life easier for those low degree cohomology groups. I've been sitting on it for a while because building HBI is hard. Building HBI is hard, and the best way to find out what needs to be in there is to use it to do stuff. So I've been sort of using it to do things. So, does your PR, for example, prove that H2 classifies extensions? Not yet. But that's on the next slide. It's at least 300 lines. So this is going to need to be one individual VR. It involves giving a better expression for. So homology is defined as the co-kernel of a map from an image shown. Of a map from an image sub-object to a kernel sub-object. And we have kernel sub-object and kernel as a limit, and it's quite annoying. Whereas if you step outside the category theory library, then you can define homology as a co-kernel of some linear map that's a bit simpler. And so we want to use this nicer expression. So we have to prove that they agree. And it's a composition of a bunch of different isomorphisms. Of different isomorphisms, and whatever order you do them in, as far as I tried, it would time out. So instead, we do it by showing that this quotient of modules satisfies the universal property of homology. And then it's all fine. So yeah, that's just to say people have been discussing whether we should have like has homology or a more beefed up version of that. And I'm very much in favour because it's quicker and easier. Any easier. So, yeah, I'll talk a bit about what else I've done. Everything is about low degree, not all about actually, and uses the inhomogeneous co-change definition. So, the first thing to find is this nice sort of more general functoriality property. If we've got a G module A and an H module B, and a morphism of groups, and then that should say k-linear map, not additive group, a map from. Additive group, a map from B back to A that's just k linear. Then if phi and F satisfy this compatibility property, then we get a map on the cohomology that varies in both arguments. So this is really useful. We can use it to find the long exact sequence, which I was putting off for ages because I thought it would be hard to like get everything out of LTE and make it compile and then use it. But it was fine. I'm just going to stick. So thank you to this conference. Thank you to this conference. So, basically, they've got like: if you've got a short exact sequence of complexes, then they have like a six-term exact sequence in colomology. And so, all we needed to do was like define, use this to define the short exact sequence of inhomogeneous co-chains. You can also use it to define the restriction functors and the inflation functors. So, the first one is if H is a subgroup of G, then a G. Subgroup of G, then a G module M is also an H module, and you get a Mapon cohomology. And then if H is also normal, you get an action of G mod H on the invariance, the H invariance of M. I haven't made them functors yet, but it should be easy. And they're just, you know, I've got the action on maps and the action on objects, and I just need to put it in, like, package it together. And then using that, I've defined the information restriction exact sequence, and that was just nice. You know, everything's You know, everything's nice and fast because you're using the concrete definition and not appealing to anything abstract. So, the inflation restriction of that sequence you had for time being is without the H2? Yeah, yeah, yeah, yeah. So, yeah, you can get a bit more. But doesn't that need like the spectral sequence? No, there is a, of course, it's a consequence of growth from the oxidative spectral sequence, but there is a downward proof of the following proof. There's this map called the transgression. There's this map called the transgression map. Yeah, and these we can define by hand. I think it would be certainly extremely useful for us. I've tried to sort all this stuff in, like, what you can do in a down-to-earth way, what you can do by changing projector resolution, and what you can do when we have the other definition of X. And sometimes, like, you could do something in multiple ways, but it's much more natural with a more abstract way. But I think with this, like, you're working. But I think with this, you're working down to earth, and therefore you don't want to have to be using high-powered, you know, you want the code to be fast. So, yeah, okay. I'll try and do it by hand. You know, with genus caching, you should be able to make the reason in classes for each. There's this paper by Atien Wall, where they do it explicitly. Okay, I'll put that on the to-do list. Or, like, yeah, we're about to, after the stuff I've done, I'll have a list of like project suggestions. So, if anybody wants to do that, consider it on the list. This last map at the bottom lands in the G invariance of that H1. Oh, ah yeah yeah. That's useful only if you want to go further. I don't care. Were you able to get that as well? I haven't done it, but it should be okay. Yeah, like making this was quite nice. It was nothing was sorry. Yeah, so we've also done Hilbert's theorem ninety. Theorem 90. So if L over K is finite in Galois, then this H1 group is trivial, where the Galois group acts by automorphisms. And maybe it doesn't look like much on its own, but we can extend it to pro-finite groups data. And also, if we've got it in a long-exact sequencing cohomology, it tells you about the groups around it. Likewise, I've done about half of the bijection between H2 and equivalence classes of extensions of G by M. So is this injection or is it injection for a kind of? So I think I've taken like a two co-cycle and a G module and made the extension and shown that like and then if they differ by a co-boundary then they're isomorphic to this extension. It's like there's nothing alive about it, I just haven't finished it yet. There is one annoying thing about it in that, and this also applies to the first point. applies to the first point. We've been talking about G modules as additive things and we've been talking about G as well as vicative. And in Math Libra you have to, you know, it's hard to move between these things. So if you have an extension of groups you want them to all have the same operation. And also when you're showing that the trivial class corresponds to the semi-direct product, you want both parts of the semi-direct product to have the same operation. I don't really know how to make this. I don't really know how to make this into the neatest way to deal with this. But the first example doesn't even time check, right? Yeah, yeah, yeah, yeah. It's not. It's not that in massive. I just gave a natural statement. Additive appliances or something. Yeah, we've also got like if the G action is trivial, then H1 is homomorphisms. And again, you need to make things multiplicative. So yeah, like. So, yeah, like I'm just doing the math at the moment, and then I will maybe ask on Zulip how we can make this less ugly. The other thing is that because we're working with representations, and this stuff is about when k equals z, we're dealing with like rep zg, which is sort of superfluous information. Um I think because this is fairly close to the ground, it would be safe to uh leave the category of representations and just use type class inference again. And just use type class inference again. So use an abelian group with a distributable action. Because, yeah, I don't think you'll run into diamonds because what we're doing with it is sufficiently simple. And that would make it a bit neater. But then you have to make an extra category equivalence. And also, like, duplicate a load of code because we've got these nice expressions of two co-cycles that you want for general k, but then you also want them to do this. And so you have to transpose it across the equivalents. It's just, you know, that might take a while to be hard for these. That might take a while to be harsh for these annoying reasons. Then, a natural thing to do with this is that we can also interpret h1 in terms of extensions, and I haven't done that yet. So, that's most of what I've done. The rest of the talk is suggestions of things that it would be good to do. First of all, this is something that uses just the inhomogeneous code change definition, so you could do it like immediately, not above group chromology. So, this is So, this is when G module is not necessarily abelian. And it doesn't really have as nice a theory as the abelian case. There is like some kind of abstract interpretation that I saw in NLAV, but I didn't understand it. So, I think the best thing to do, first of all, is just to build it concretely. So, we can't really define higher commodity groups. We can define a pointed set, H1, and get a medium exact sequence attached to a short exact sequence. Let me just comment. You can extend it also one further if you want to. Okay. By hand again, yeah. By hand. If A is continued in the center. Okay. Some applications of non-abelian groupy. This is important when we have two objects that are isomorphic over a bigger field, and we want to know if they're isomorphic over a smaller field. So this is quite vague because you can define it in quite a big generality, but if you've got x, A big generality, but if you've got x, which is an object over L, then the objects over k that are isomorphic to x when you are over L are called the k forms of x. And then the k forms of x biject with an h1 group, which is this automorphism group of x, which I haven't exactly defined, is in general non-abelian. So one application of this is central simple algebras over k that split over L. So when you tensor with L, they're isomorphic to tensor with L, they're isomorphic to n by n matrices over L. This bijects with a non-abelian, I think I said group, non-abelian H1 set. And yeah, we need this to, there are two definitions of Brauer groups, one in terms of central symbol algebras and one in terms of H2. And so you need this point to prove that the definitions are equivalent and that's useful. Oh, there you need Adams' math. You want to go? Oh yeah, yeah, yeah. You want to go? Oh, yeah, yeah, yeah. Precisely, that's. Yeah. Okay, so this is stuff that you can do currently as well because it uses the current definition of X. But don't do it, wait for Joel. So these are all fairly. Easy only wait for Joel to do it, to refactor X. Yeah, yeah, yeah. Or like, yeah, I mean, do what you want. I'll probably do some of them. That's a mistake. Okay, so we have some results about the size of G when G is finite, annihilating cohomology groups. We have... So how do you prove it using the S definition? Because the proof I knew was cos restriction correlation. Yeah, yeah. I think you can, because I've seen a proof like using like embedding an injective module, but you can do it. You can do it. Right. The first one you can do by refactoring. By refactoring my proof of equivalence a bit, to like you get this homotopy equivalence of k modules between the resolution and the complex constraint in degree zero. And when g is finite, you can sort of average over the homotopy equivalence and use that to show that multiplication by the size of g is homotopy equivalent to zero. So yeah, that's a proof. And yeah, similar for the next Um and yeah, similar for the next one. And then uh this, yeah, there's these ones as well. So the last one is um best proved by like picking a nicer projective resolution of nerh stayed them all, but picking some different projective resolutions that are simpler than the standard one. Um here's some theory you can build using MathLibExt. Um how much time do I have? Ten minutes. Ten minutes. Okay. 10 minutes. Ten minutes. Okay. So, yeah, given a subgroup H and an H module A, we can produce the G module called the co-induced G module by taking Z H linear. I think some of this should be replaced by K, but Z H linear maps from ZGU to A. And this is a really useful module because when H is trivial, current use modules are acyclic for group commodities. Are acyclic for group homology. And so some proofs that might need the right drive functor interpretation, we can just do with Current Digit models. That's a neat trick, like if you, yeah. It means you can start. Theorem was that you'd have to wait for the other definition of export. You can do now if you want. And then similarly, we can find the induced module by tensoring, and these given a junction. So when H is trivial, this is just the modal closed instance that's we defined before, but obviously this. We defined before, but obviously this will have to be defined separately. And then, because a projective resolution of Z as a G module is also a projective resolution of Z as an H module, we have the following isomorphism, which gives us Shapiro's number. So that would be fun. It shouldn't be too hard, and it's a nice theory, and you could do it using what's currently in Math Lib. And here's some things you could do with Shabira's lemma. You could find co-restriction, and then Co-restriction and then so yeah, again, none of that should be too hard. Here's some maybe meteor goals. Again, you don't need too much more theory, but then you do have to just do a bunch of work of constructing some extra-productive resolutions. And that allows you to define the cut product and then prove some properties. You can also prove. You can also prove a property about like current res interacting with the cut product, which might be slightly harder, but so I should put those ones. We can also, I haven't talked about group homology at all, but it's defined group homology as X groups, group homology as Tor groups. Because we have the standard resolution and we also have Tor, you can define group homology in like one line and then another line saying here's one way to compute it. Computer. So that would be easy, but then you have to use that and use the cut product you defined on the last slide and put it all together and to find take homology, and then you can do class field theory. So that would be a bit of maybe a sizable project. But again, you can do it basically with what's in method. So here's another category of things you can do. First of all, define the right derived X groups, approved planting of X. X groups, proof bounding of X, and then show that group homology is actually a derived functor. So whilst we can give these isomorphism on objects with the current definition of X, with right-derived X, we could actually give a much more structure because X is a derived functor, so it's a universal delta functor. So to prove that a morphism, to define isomorphism. To define the isomorphism between X and another delta functor, we just have to check that they agree in degree zero. And because we've constructed the long exact sequence in concrete group homology, it's not too hard to show that it's a delta functor. I haven't done that yet, but it should be fine. Because there's delta functions in LCU. And once you have things, you can also reconstruct tape homology without homology. There's a definition of tape homology using entire resolution that spans on the right and on the left. Resolution but spans on the right and on the left, and they even apply this right-the right functor. I've seen like the sort of complete resolution, but then doing sort of projective things with it. Yeah, I didn't know that. Cool. So I haven't done much work towards defining text, but we do now know that in one file of my branch, that like yeah, hierarchical groups of an injective object are trivial. Are trivial. And then this is what Joel's going to do, right? Yeah. Joel's going to even try Joel Jacket. Yeah. So again, you know, wait if you want to. And then, yeah, one thing that this gives us, because we then have an isomorphism with more structure, because it's an isomorphism of delta functors, we can then show that Greek quality is right functor and define the Linden-Hosswall-Sair spectral sequence. So this is an extension of inflation restriction and Restriction and because the proof of it is sort of by specializing the Grothendieck spectral sequence associated to a composition of derived functors, we need the derived functor interpretation. So here's something else you can do with right derived x. We can do Galois chromology. So lots of useful group comology results assume that g is finite. The Galois group of a Galois extension is proto-finite, so it's an inverse limit of its finite quotient groups corresponding to finite sub-extensions. For finite sub-extensions, and we want to be able to extend results that assume finiteness to pro-finite groups, so we can do number three. So, how do we do this? If G is a topological group, a discrete G module M is a G module such that the action of G is continuous, should say continuous, when we give M the discrete topology. And here's another definition. So, not in Math Lib, but already done. But already done, if you've got a discrete G model M, we can define a similar complex to the inhomogeneous co-chains where we assume that this time the functions are also continuous. And taking the cohomology of that gives us something called continuous cohomology. Now, because M is discrete, you can define this if M had a different topology, but you have only when M is discrete do we get this correspondence between normal cohomology. So, first of all, So, first of all, using the continuous cohomology, it's not hard to show that continuous cohomology is a direct limit of normal group cohomology over finite groups. And I was working on this. I can't remember how far I got in the isomorphism, but one thing you really need is that a pro-finite group is an inverse summit of finite groups and not just a finite status. And this boils down to some like sort of fairly long group theory proof. So I've done that by having. Proof. So I've done that, but I haven't PR'd it. And then, given that, on the other side, we can make continuous coalogy a delta functor. And then, if we know that normal group coal g is also a universal delta functor, we can show that they agree by checking degree zero. And then we know that we can compute group cohomology of a pro-finite group and a discrete G-module by checking a direct limit. And therefore, we can extend results about. And therefore, we can extend results about finite groups to profinite groups. A good thing to analyze with profinite group comology is cohomological dimension, because it's not very interesting for finite groups, but it is for profinite groups. So that would be a fun thing to do. But you'd need sort of all this, I guess. Yeah, that's the end. Thank you very much.