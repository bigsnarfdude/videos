The idea is that we have the physics of the model that we implement into a nice sheet model, and then we have observations that we use to initialize the ice sheet model, but also to try to when, and they always do, disagree with model output, we can try to optimize unknown or poorly resolved or constrained input parameters such as forcings, well, initial conditions, boundary conditions, things like that. Boundary conditions, things like that. Okay, so I have three points. I don't know if I'll have time to go through all three, so we'll see. I wanted to go really quickly through how we do inversions in glaciology. And I want to talk, this is something that we talked about with HMR a few months ago, and I thought it would be interesting to share that with you, the difference between the discrete and continuous gradient, and what the differences are, and then talk a bit about BETMachine because it's also using that data assimilation process. All right. So, well, you all know this, I'm sure. Well, you all know this, I'm sure, but the idea of data assimilation is you have your input parameters. That's alpha here. Alpha could be C, could be anything. You have your forward model, and that gives you a model output. And in an inverse problem, you have the output, and you want to know what the input of the function is. And f minus 1 is not explicit, we don't have an explicit formulation for f minus 1. So we need to solve a PD constraint optimization, where we have a cost function that measures the best fit to observations. That measures the misfit to observations. We can divide that by the error squared or variance or whatever, and some regularization that Marvel talked about. And the constraint is that our velocity here, the model velocity, has to satisfy the model equations. Okay, so one, the way we solve it typically is either using automatic differentiation or we have to write down the adjoint state. So we introduce a Lagrangian, which is typically the missing. Which is typically the misfit, and then the integral of the model equations multiplied by lambda, which is a Lagrange multiplier or a joint state. It has different names, it's always the same thing. And then you can integrate by part so that the boundary conditions of the model are in the Lagrangian. Okay, and then the trick is the Lagrangian is just a tool to get the gradient of the cost function with respect to our parameter, because that's what we want. And then we want to follow some kind of gradient descent. So you can already see that. So you can already see that the derivative of the Lagrangian with respect to geodoint states will recover our model equations. So the derivative of the Lagrangian with respect to geodoints is zero if v is the solution of our model equations. And then we can define the adjoint state as being such that the derivative of the Lagrangian with respect to the model state, so to v, is zero. That gives us an adjoint state, lambda bar. And then if we use these two, then we have... Use these two, then we have an explicit formulation for the derivative of the cost function with respect to alpha. So it's a directional derivative. It depends on how you want to perturb alpha. And it has that explicit formulation. So if we solve the forward model, we get d bar. If you solve the adjoint states, which comes from this, we get lambda bar. And this integral gives us the directional derivative of the cost function with respect to alpha. So I went a bit quickly, but that's. So I went a bit quickly, but that's that's how things are solved. So that's an example. We get our initial Bayesian condition, model velocity, and target velocity here. And so we get our first gradients, we optimize, that's what we get. And after 10 iterations, we get a fairly good fit. So obviously we would do more than 10. But we get a fairly good fit for the data, and we infer basal conditions that are not known. And this can be done at the scale of Ventorica. Mauro showed a few things. Mauro showed a few things. So I said, it's not the only model that can do that, of course. There is UA, Mali, and all of these models. Okay, so that's all great, and it's working pretty well. The problem we're having now is that we have a lot of data sets from different sensors at different times. And so we kind of don't necessarily know how to deal with that amount of data. So I don't want to go through this laundry list, but You know, that's this laundry list, but we have laser altimetry, radar altimetry, ground-penetrating radar. They give us data about even internal layers and age. So we have gravity data that's all airborne. We also have space-borne instruments that give us also the altimetry at different scales, of course, with a different level of uncertainty. Synthetic aperture radar, so that's surface motion, that's what we use for surface observations, but also that also gives us grounding night position. That also gives us grounding line position, surface elevation, and also gravity, low resolution DHDT such as GRACE, all GRACE hold on. And finally, we also have in-situ data. So these are typically point measurements that we don't necessarily use right now, but we have GPS stations, ground penetrating radars that are fixed, seismic station, boreholes, that can give us temperature proposals. So, in an ideal world, we would like to have a cost function that looks more like this, where we want to have a misfit to surface observations. So, I should have divided by something so that everything is consistent. But you get the idea. We want to match the surface speed, surface elevation, temperatures, and everything we have. And that changes with time. That also has, it's also for different times. The T V here, the times for which we have surface data, may not be the same as Ts and T. Be the same as Ts and T temperature, and we may have gaps sometimes. So it makes our life a bit complicated. So it's virtually impossible in that case to derive by hand, just like I did in the previous slide, the joint state and the gradient of the cost function. We have moving bounding lines, we have potentially caving fronts that retreat. All of that is potentially not differentiable if you look at the You look at the if you want to do it by hand. But we can use automatic differentiation. That's something that is more and more popular in this field. But the problem is it requires to rewrite almost entirely a model. Just the way it's done, either by, there are two ways, source-to-source transformation. You need to have a nicely coded Fortran code with, you're not allowed to use things. Patrick and she may talk about it. And then the program will. And then the program will spit for you the adjoint program that basically gives you the gradient of your cost function with respect to your inputs. So it's great, but again, it requires a bit of work. So this is the idea with autonomic differentiation. Instead of giving a field, a functional alpha, you have your, now you discretize input. Your alpha is one per vertex, per grid point, per grid, whatever you have. Grid, whatever you have, and your forward model computes J. The joint model will basically give you, you have to solve the forward model, and then you can go in reverse, and it's going to give you the gradient of your cost function with respect to each of your components of your input parameters. And here is just alpha, but you could have alpha, you could have the stiffness, damage, july connects, anything you want, presumably. Okay, so. Okay, so now I want to talk a bit about the difference between discrete and continuous gradient. So that's what we saw. We have the directional derivative of our cost function with respect to alpha that has this form. So it's an inner product, and you see that if we want to maximize the descent, we need to perturb alpha. So the delta alpha should be collinear to the rest. Collinear to the rest. So we should choose a gradient that's 2 alpha v dot lambda and scale it in some way, and then we'll say that alpha nu is alpha alt minus mu, that's to be determined, a scalar, times that gradient. And that way we follow a steepest descent. You could use BFGS, but it all comes down to what gradient we're taking. So that's the continuous gradient. Now, if you use automatic differentiation or if you Differentiation, or if you don't optimize for alpha as a field, but alpha as it's in its discretized form, where it's the sum of individual alpha i for each model grid in this case, multiplied by these nodal functions that are one on each of the vertices and zero on other vertices. So this is typical in infinite elements and in other types of analyses. So now instead of again trying to derive the gradient of alpha, we wanted The gradient of alpha, we want to derive the gradient of each alpha i's, and that's going to give us a vector. So, our discrete gradient is going to be a vector with the derivative of j for each of the alphas that we have. And we can show by using the same equations that it has this shape. Now, the problem that we have is that obviously the discrete gradient, which is dj d alpha i, is not the same as the continuous gradient taken at that location. Taken at that location. These are completely different beasts. What we can actually show is that the discrete gradient at alpha i, so how sensitive the cost function is when you change the value on your node i, is you can take the, it's the inner product of the gradient by that nodal function phi, because we're changing the direction where we're perturbing alpha is in this direction, the direction of phi. So we can actually. Of phi i. So we can actually, we see that it involves the continuous gradient in some way. So the reason why this is problematic is that it shows when we use unstructured gradients. Was that integral on the last slide a boundary global or it's the whole omega model domain? So this is our target velocity. This is our model velocity and this is the friction coefficient that we're trying to infer. This is for a structured grid. This is for a structured grid, this is unstructured. And here we're using the discrete gradient. And you see that with an unstructured grid, the pattern that we get for the same, about the same fit towards the end, the pattern that we get for alpha is extremely noisy. And that's because our nodal functions have different footprints. In the case of a structured grid, the footprint of our individual nodal functions are the same. So we're not the way that each That each notable value the alpha has on the gradient is the same. In the case of an unstructured grid, you see that when you change a basal friction here, it will affect all of this area in red, and right next to it, just this area in green. So what this means is when you change a basal friction here, you're affecting the model much more than when you change it there, because it's affecting a bigger surface area. And that's only due to the unstructuredness of the mesh. So the So, the noise that we see here is just artificial. It's just because we're using that discrete gradient that depends on the footprint of each individual null function. So, Matthew? Yeah. I think this is just because the gradient is not unique and the gradient you compute depends on an inner product. And you get an inner product. But if you use a one that is weighted with a mass matrix, this thing goes to the microphone. So I'm going to talk about concern. So we can use regularization. It's not great. You can weigh the gradient using non-function input. You can weigh the gradient using non-function footprints or use mass matrix scaling. And so the idea is we basically do an L2 projection of the continuous gradient. And as you say, if you do this and put this into the equation, you see that you have the mass matrix that arises. And then you can take your discrete gradient that comes from automatic differentiation or come from something that you manually computed. And then with the mass matrix, you recover. With the mass matrix, you recover a smoother gradient that's consistent with the linear gradient that you wouldn't go. But the reason why I mentioned this is I don't think a lot of people know about this, and the noise is just an artifact in that case. Okay, I have seven minutes to talk about bed machine. I think I should do it. So, Morrow mentioned this when you take, you initialize your eyeshadow funnel with an eye stiffness that looks like this. That's from Kriging. That's from Kringing. That was the data set in February 2013, I believe. And in star velocities, and that's what you use to initialize your model, then the flux divergence is going to look something like this. So plus or minus 100 meters per year, and it's saturated. So as Maro said, it can be much more than that. So the problem is you may be great. The model may be awesome in terms of capturing present-day data. If you're running forward, that's your DHG team. So you're going to have mountains, and the model is going to go off-rails just because of that. You know, go off-rail just because of that inconsistency between these data sets. So, one possibility is to try to use that same equation, but since we have a, it's not great, but we have an idea of what dh dt should be, we can basically try to solve for h such that it's consistent with the conservation of mass. So, for that, we do have constraints from radar data. So, this is a typical radar from OIB, from accords. From my cords. That's what we observe. So we have the air, the ice thickness, and bed topography and ocean here. And one of the problems is that we only have radar data along these font lines. And so we have many gaps. In between flat lines, we have no idea how deep the bed is. So that's what the mass conservation approach can do. It can try to fill the gaps between the radar data. So the idea is that now we solve for this event. We solve for this infection problem where we have the flux average infection should be equal to this, where this is assumed to be observed. And we, because it's a hyperbolic equation, we can only constrain the ice thickness once perfect line. And so typically what we do is we constrain the ice thickness on the infill boundary. So it's inland, that's going where we have better data. But we need to have one line that goes fully through, that closes the model domain. So that's what we get if we don't do anything else. So, what I've done here, I've imposed the ice thickness on the infill boundary, put in my velocity data from INSAR, accumulation from RANMO, and so in that sector, we're starting to see features that we know exist and were missing in the previous data set. And on top, the lines that you see are measurements of bed. So, what you see is it's doing an okay job, but there are many places where it's not. But there are many places where it's not great. And again, that's because I only constrained the flow lines once. I've only imposed the observed thickness on the info boundary. So the idea is to formulate, again, an optimization problem where we want our cost function to be such that the model eye thickness that's consistent with the conservation of mass is as close as possible to the measured ice thickness from radar data. And there's the constraint that the model ice thickness has to be consistent with the conservation of mass. Constrivation of mass. And the knots that we allow to turn are our input data sets. So in the equation, it's CPP bar at the depth average velocity, not the surface velocity from insar. So allow the velocity to be changed back up to 5% less, and then there is also some noise and flexibility. So I put plus or minus 50 meters per year. And then the apparent mass balance, the HGT may not be right. There are some places where the surface mass balance is more than a meter per year off. So all of these are fields that Of these are fields that we can optimize. So I wouldn't trust too much what we get out of what the model says for these two, but the thickness does match the observations. So I'm running out of time. This is exactly the same thing. Lagrangian is the cost function plus the integral of the Lagrange multiplier times the model equations. We can derive the adjoint states and the gradients. They have to be slightly approximated. There is one small issue, but it's very minor. And so that's before we constrain. And so that's before we constrain, after we constrain, and now we have the three troughs of upper dynamic that are consistent with observations. So that's what we had before operationalized bridge, after operationalized bridge, and Kraiging, you see that the bed would go back up in between flow lines because it's isotropic in this case. With mass conservation, we fit the data as well as Kraiging, but we do have these continuous features. And I think that's the end. I forgot what? I think I might have forgotten. No, we did. He did, okay, so I don't think the bell's running yet. Yeah, the bell hasn't run yet, does it say how much time you have left?