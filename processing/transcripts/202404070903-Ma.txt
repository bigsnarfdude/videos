With a former postdoc of mine, Jing Weijang, and a current postdoc, Callum. Callum is here in the audience right now, so you can direct all the tough questions to him. And I'd like to thank the organizers for having us here and having this fantastic set of talks. All right, so the title of the talk is Online Contention Resolution Schemes for Network Revenue Management and Commodorial Auctions. I'll explain what all these words mean. What all these words mean. I'll start with a very broad scope. So, this is an online allocation problem. I think a lot of us have worked on these problems. I don't think there's been an explicit talk on this topic yet. Broadly speaking, it captures secretary, optimal stopping problems, where I'm just trying to stop on the biggest number in a sequence that arrives online. There's dynamic fulfillment applications in e-commerce where you've got to decide where to fulfill from. Fulfill from personalized source and recommendations under limited inventory. Finally, dynamic pricing of a flight. Alright, so narrowing scope a bit, so the key trade-off in all these problems is kind of like reward now, that might consume more resources, versus reward later, you save resources. I'm going to now fly towards networking management. I'm going to focus on this application. So, here are the challenges that I have. So here are the challenges that I have this complicated combinatorial network where if I sell an itinerary from Boston to St. Louis to SF, I'm consuming a unit of resource on this flight and a unit of resource on this flight. All right, so network revenue management, further narrowing the scope, I'm going to focus on the one stochastic extreme. For this talk, I'm going to assume all demand distributions are known, perfectly correct distributions, and independent over. Distributions and independent overtime. I think it's fair to say this is the standard setting for the network revenue management classically in operations research. It has been a lot of different approaches. Broadly speaking, a lot of them are based on a deterministic linear program. You might have heard the words like big price control, where you take the dual or you can do the primal with booking limits. There's a lot of papers about resolving this deterministic linear program. This nickel in your program. Long history in the field of rhythmic management and OR. There's also approximate dynamic programming approaches, where generally the challenge is the state space is exponential in the number of flights, and so I can approximate the value function in a way that doesn't may or may not use the deterministic linear problem. Okay, so I'm going to present an approach here for this problem today based on randomized bounding of the deterministic linear program. Of the deterministic linear program, but that is different than sort of this typical approaches for this problem. All right, so the outline of my talk is: I'm going to try to explain the approach specifically for network revenue management, state our results specifically for network revenue management, and then I'll sort of broaden out a bit and give some background on randomized rounding and how this specific problem for revenue management compares with online contention resolution schemes. Resolutions fees. And then, time-permitting, I'll try to get into some technical details. Alright, so let me explain to you exactly what's the difference when you're thinking about the randomized rounding approach to NRM network revenue management. So, I'm going to do a formal model now. There's some simplifying assumptions. The ones in green are all not crucial. So, none of these are basically crucial. I'm going to have resources. These are my flight legs. I'm going to assume every flight only has one. Flight legs. I'm going to assume every flight only has once. It just makes everything easier to illustrate. I'm going to have products. These are my flight itineraries. Each product, J has a fixed price and requires a subset of these sources AJ. Over T time steps, each time step there's going to be a request for a particular itinerary j drawn from a probability vector lambda tj. It could be just changing over time. The sum is of OST1. The sum is of OST1. If the sum is less than 1, there's some chance there's no request not here. Alright, so here I'm assuming the accept-reject model. If you want, you can extend this to pricing and assortment. Those are not crucial. And also to make illustration easier, I'm going to just create duplicates of itineraries so that the set of possible itineraries being requested at a time t, which I denote using nt, they're a disjoint union of all products. Okay, so what's a deterministic linear program? Okay, so what's a deterministic linear program? So I don't think we've seen this yet here today, so let me quickly go through it. Basically, I'm trying to capture an offline solution where I replace every random variable with its expectation. So you should think of xj as the probability of selling product J. So accepting a request for product J that's in for time t and t. This has to be at most lambda tj. And then this is basically just saying in expectation, no Just saying in expectation, no resource can be consumed more than once, or I'm summing over the products J in the set that such that they use the resource time. And then the objective is just I'm trying to maximize the expected revenue. Okay, good. So what I'm going to try to do that's different than all the previous approaches is I'm going to try to give a uniform guarantee where for every product j appearing at any time t, I'm going to try to sell it. I'm going to try to sell it with probability at least alpha times xj for some alpha as large as possible. So basically, you know, if I can do alpha equals one half, then I'm earning a half of whatever the deterministic click of variable. But I'm going to try to provide the stronger uniform guarantee. All right, so let me now just state the results that we're able to obtain through this approach. So first now let me further limit the scope a bit. Let me further limit the scope a bit. So, I'm going to focus on non-asymptotic ratio guarantees. I'm not going to try to see how things improve if I have large inventories. But they're going to hold for any amount of inventory. It's going to be parameterized by L, the maximum number of resources required in any flight machine, right? And I'm going to get guarantees relative to opt-LP, which I'm going to use. Opt LP, which I'm going to use to denote the optimal objective value of the DLP. This is going to be an upper bound on any optimal offline or optimal dynamic program that you might want to compare against. And no better results are known even if you're going to compare against these featured benchmarks. So for this talk, I'm just going to focus on comparing the OctLP. And then some of our results will hold in two special cases of interest, two different cases. One is the case of Poisson demand. The case of Poisson demands. Basically, what this means is I'm imagining each time step as infinitesimally small, so the chances that there's a customer at all in that time step is small. I can still offer an assortment and have substitution, but the point is, I'll explain why this is important. The second special piece of interest is what I call L hypergraphs. So it's a specific structure of the products. Here, maybe you don't think of airlines, think about Here, maybe don't think of airlines. Think about like a restaurant selling a combo that's like a main plus a side plus a drink. If I can divide all of the resources into all different groups, main courses, side dishes, and drinks, and every product consumes at most one item from each group, then I'm going to call this an L-partite hypergraph. That's like matching an L-partite hypergraph. One special case of this that has One special case of this that has been studied by Mika and co-authors is booking hotel intervals where the length is the most. Just to make sure, is it partition matrix? Yeah, exactly, exactly. It's equivalent to partition matrix. Yes, perfect, yeah. So this will come up. No, we didn't need to come up with the names. Partition matrix before. Okay, yeah, yeah, yeah. This is also equivalent to constraints under the intersection of L partition matrix X. Okay, I'm good. So let me now state our results based on randomized rounds. So first, we have a simple way of getting a randomized where we have a simple way of getting a randomized rounding guarantee of alpha equals one over one plus L for in the general case. So this was already known in a nice paper by Mika and co-authors. They already show how to get 1 over 1 plus L relative to on the LP. But I would say here there's a different conceptual proof of why 1 over 1 plus L is the right answer. It's quite simple. I'll try to show you if possible. And here we're getting a uniform data. Whereas when you do this Uniform guarantee. Whereas when you do this approximate dynamic programming approach, you're not going to get the uniform guarantee for every detail. Okay, secondly, we actually show that this guarantee that Mika developed is tight as long as L is the power of a prime number. I'll tell you why we need this later. So, you know, it's tight for general L, but we can't unfortunately prove it for every single L. If L equals 6, who knows? Few notes. Okay, and then in those two special cases of interest, we're going to do strictly better than this benchmark. So we show it's not the right answer. In either the special case of independent Poisson demands, sorry, just Poisson demands independent, where at any time step the chances of any sale is small, or in the case of L-partite hypergraphs. So, okay, so I would argue that you could. So I would argue that you could view 1 over 1 plus L, even though it's parametrized by L. You can view L as fixed. And I would say this is a benchmark that has also appeared in other papers. So in some follow-up papers with Mikas, in a paper I have with Jackie, where we extend it to reusable resources. Julian Topological extended to flexible products. This analysis comes up. Sorry, this guarantee comes up. Using a very different type of analysis, online combinatorial options. Analysis, online combinatorial options. I'm not going to define this problem for this talk, but there's a very similar type of setting where it's an online problem where each person's valuation function, they want the most items. Through a different item pricing analysis, this one over one plus L also shows up. It's also showed up in some single sample profit inequality settings. So all I'm arguing is: okay, this benchmark appears a lot, and we show how to do strictly better than it in one of these two special cases. In one of these two special cases. And coming to Brad's point about L-partition neutroids, so in particular, profit inequality on the intersection of L-partition metroids is mentioned as an open problem in this paper, and we show that 1 over 1 plus L is not the right answer, or it's strictly better. Okay, so I'm done stating our results. So now I'm going to give a bit more background on randomized rounding and our approach and how it compares. And our approach, and how it compares with standard online contention resolution schemes. Okay, so randomized rounding in general, we saw this during David's talk. Broadly speaking, you have a feasible family that describes all subsets of itineraries that are feasible. So, like in the most simple case, I might just have two possible itineraries and I have one seat on a flight. Both itineraries require that seat. I can accept at most one of them. I can accept at most one of them. So basically, so I'm going to let x1 and x2 be the incidence vectors of whether I accept that itinerary. So basically, I can accept just the first itinerary, just the second itinerary, or neither itinerary. There's going to be some polytopal relaxation. That's the convex combination of these points, or it could be bigger, but it has to contain at least the convex. At least the convex domination of the incidence vector integer points, it has to be a relaxation. Okay, so what are the different ways in which you can study what is rounding? Rounding, the goal is given any x in this polytope, your goal is to randomly construct a feasible subset that gives exactly this uniform guarantee. You need to promise that every single xj is selected with probability at least alpha, and you want this guarantee. Alpha, and you want this guarantee, alpha, to be as large as possible. So you're assuming dependence actors coordinates, right? Each element is active in property. Okay, so I'll get to this. So in the most basic form, there is no independence. There's no rules. You can select whatever things you want. So alpha will be one if your polytope is actually the convex hull of your points. In the problem I'm studying, this is actually not true. Even there's a gap, there's an integrality gap, even in the offline case, because the polytope real. The offline case because the polytope will actually change. Okay, so that's the most basic form of randomized routing. It's offline. You can just do it. This is the form David presented. There's no rules on what you can do. Now, so, okay, so the simplest case of online or where there's some rules on what you can select, so I'm going to call this offline contention resolution. This is kind of the definition of contention resolution. I can't just arbitrarily pick whatever flight, whatever I'm. Whatever flight, whenever I want, I need the customer to actually request it, right? And then so basically the model is each itinerary gets requested independently with some known probability, xj, where xj is just this polydual point. And then it's the same rules. It has to be feasible, but I can only pick active products. And this already makes it harder. Even in this simple example, the guarantee decreases from one to three quarters. Okay, online is where I don't get to see whether things are active right away. And this is basically our case. I sequentially see whether each product, there's a request for it, whether I even have the option of taking it. And then if I do have the option, this is colour that's being active, and it's feasible. If it's not feasible, I can't take it. I have to immediately decide whether or not to accept it. All right. All right, and then so finally, in the case we're studying, there's this notion of time. So there's not only itineraries, but there's also time, and for each time, you have at most one itinerary of writing that's drawn according to some probability vector x. Just to clarify, so earlier I had this constraint that lambda tj was the chances of there being a request for itinerary j. Request for itinerary j at type t, v sum to at most one. xj is the optimal solution of an LP. Since xj is less than this and d sum to less than one, the sum of the x's are less than. So you just have to subsample. So basically, when itinerary j arrives at time t, that'll happen with probability lambda tj, and then you subsample with probability xj over lambda tj. But okay, essentially the problem just reduces to one where you have these probability vectors xj for each time, and at most For each time, and at most one active element from them will be requested. Alright, so generally the things get harder when you go down. The only non-obvious one is three and four. I'll explain in what way it gets harder because there's more and more rules. And so the standard online contention resolution scheme is this one. There's no notion of time in the notion that at most one product in a set can arrive at a time. What I'm going to call this, and this is What I'm going to call this, and this is the case we care about, I'm going to call this random element OCRS. So it's not just like elements sequentially appear and they're independently either on or off. Here there's some like negative correlation, where each of these sets, there's at most one element being taken. All right, so now I'm going to compare the two notions. So let me just recap this again. So what is the rules of the game of random element OCRS? You have these times that's t. Have these times next t. Sequentially, you see some active element in t, if any, there might be none, drawn from a vector xj that sums you at most one, and then you immediately decide, etc. So this captures standard OCRS if each of these batches, nt, has size one, and then every batch it's either it just survives or it doesn't. Okay, so this is quite simple to show: a random element. Example, we show a random element OCRS can give you a guarantee alpha for very general problems. And then a standard OCRS, it can only give you a guarantee of alpha when the demands are Poisson. Or I'm not going to define this, but online combinatorial auctions with single-minded buyers would also satisfy this. And let me just explain the intuition for why these productions work. It's this notion of negative correlation. So in standard OCRS, So, in standard OCRS, there's the element that arrives, it either arrives or it doesn't. Here, it's like I have these three different itineraries that could arrive at a particular time, and at most one of them will arrive. So there's this negative correlation. This has been studied in several works about OCRS before, and generally their negative correlation can only help. And, you know, that's sort of intuitive. It's kind of saying, like, if exactly one of my two things are active, then it's like great value. Of my two things are active, then it's like great. I can always either select one or two. But here we're going to define the selectability to be the worst case, so the optimal alpha that's possible under a worst case instance, where I let an adversary choose the batching. So this can only be worse, and that's what I mean than standard OCRS, because the adversary can always just make all the batches have size one and capture whatever is the hardest instance in standard OCRS. But here, they can also do whatever. But here, they can also do whatever adversarial batching and create this negative correlation of the selectability generally is defined as the worst case over all possible feasibility families in some family. So I'll give some examples next. And also all potential points X in the column code. Okay, so I'm gonna now just also So I'm going to now just also give some background on some other results and the difference between standard OCRS and fixed element OCRS and why it doesn't seem to have come up. The difference, so basically, you know, before this work, my sentiment was always like, you know, whatever you can do in standard, you can do in the rest. And this has always been the case. So let me show you now. The easiest case of contention resolution is where I just can pick a most K items. So, you know, all the itineraries use the same flight. All the itineraries use the same flight. There are different price points for the same flight. I have cases. Clearly, here, all the elements are symmetric. So if you're just telling me there's some active element that is set, if there's negative correlation, it doesn't matter. The set of resources requested is always going to be symmetric. So by definition, there's no difference. For a general matroid, there's also no difference. And so I have this paper with Jackie where we extend kind of this proof for the standard matroid. This proof for the standard mutroid to this case. You know, admittedly, I don't think this was super hard. You kind of just take the proof and you show that when you add t, it works. But importantly, there was no black box reduction. And I was always wondering, okay, why do we have to write the proof again? And then, you know, I was like, okay, if it works here, it should always work here. But this is not so, you know, it's something specific about Matroids and the proof that actually allows it to extend. Because we're going to see for network-driven management through NATO. All right, for Knapsack, this is another case I've worked on previously with. Case I've worked on previously with Jesuit Zhang and Jawei Zhang. We did this where each item has a deterministic size, and then items having a random size is kind of like a random element out of a possible different sizes arriving. And kind of we also felt a bit, you know, you can say stupid, where we just take this proof, we kind of just write it again over here, and we had no way of saying why we can't just do a reduction. But so now for graphs, For graphs, so I should say for graphs, the tight, okay, so sorry, so for network event management, when L equals 2, the special case of this is matching on graphs. You can think of each edge as an itinerary consisting of those two vertices that are the flights, and each vertex can be used the most once. Here, the tight result is not known. I have some work with Canal in this area. But so importantly now, But so importantly now, here there is a difference. So basically, in the selectability and standard OCRS, the lower bound is strictly higher than a third. It's 0.344. And what we show here is that if you allow this negative correlation on graphs, it can actually hurt you. You can't do better than the third. And in general, this is at l at most 1 over L plus 1 if L is a prime power. 1 over L plus 1 if L is a prime power. And then, you know, we show how to beat 1 over L plus 1 in these two special cases. And this also establishes, to my knowledge, the first separation between where an adversarially chosen batching negative correlation can actually occur. Good question. So maybe it's a naive question, but one way you can you can think of Aloha's algorithm, these kind of like a 3D coverage in the state of the least, right? And then one day it works, you can get half of our submission. We can get half of our solution is that if I basically cover half in all the path steps, then in every time there is half of the entire space yet, so I can get all the way to half. Now in your problem, why can't I just say if I'm targeting 1 over L plus 1, there are L paths from the path, so somehow L over L plus 1 is left, so I can always do 1 over L plus 1. Okay, so for... Yeah, yes, that's true. That's exactly how the 1 over L plus 1 works. So sorry, so for random element, it's Works. So, sorry, so for random element, you can still get one over L plus one, but you're capped by this. You can't beat this. That's true. No, no. Those are, I think, but just like the first answer maybe, to just get one over L plus one for the random element of CRS. Yeah, the argument basically. Yeah, yeah, yeah. The argument is what you said, yeah, yeah. But I'm saying we can do strictly better than this one in these successor pieces. And generally, that argument is actually yeah. So, okay, so using, I guess, the remaining time, uh, actually, so okay, so I should say also here, I mentioned that. So here I mentioned that the polytope relaxation is not tight. So there's also known results about the integrality gap. So this was kind of the easiest setting where there were no rules. I didn't have to like flip a coin to see whether I'm even allowed to accept each element. It's just there's no rules. I can freely select any elements. There's this result from 2012 showing the integrality gaps. So they're also strictly good. So you can, yes, you can carry this. We're not able to achieve that, but that's kind of the best you could possibly. Achieve that, but that's kind of the best you could possibly hope for, which still decreases in L as time. For the one over one plus L, you don't need the negative correlation. Yeah, yeah, yeah, exactly. So sorry, like we can handle negative correlation. For the one over L plus line, we can do it for random element OCRs using quite a simple argument that is similar to what you're saying. So the random element OCRS doesn't have a single negative correlation. No, no, sorry, it does. Random element is where it can have. Sorry, let me, yeah, yeah, good. Random element. Yeah, yeah, good. Random element is where it's negative correlation. I could just call it negative correlation those things. Random element is where I have these batches empty and at most one thing is. Can that part be adversary? Yes, yeah, yeah, yeah. So an adversary, for random element, it means an adversary chooses. So it's only hurtful. So you can easily mess at a negative correlation helps somehow? So generally, it all, you know, the intuition of why negative correlation helps is it's like, you know, if you're trying to select Is it's like you know, if you're trying to select either you or Jackie, and I tell you either you'll want to be selected or Jackie. But I'm saying, so I'm going to now try to show you the example of why in graphs negative correlation work. Yeah, yeah, yeah. But yeah, the 101 plus L still works if you can have negative correlation, but we can do better than that if you don't have negative correlation in general. But if we have negative correlation, we can't do better than that unless we make some assumption like L part. Okay, good. So any other questions? Good. So, any other questions before I get into like I try to do some technical stuff? Okay, so let me just try to show you the example of my negative correlation curves. The construction for L equals 2 is actually very simple. It's this graph over here. Basically, batch 1 is this perfect matching here, and each has probability essentially a half. Batch two is: I'll either choose this edge or this edge, and batch three is the middle edge, which is going to be the bottom, I think. Be the bottom, I think. And so basically, you can argue formally like this. I'm going to let mu denote the event that u is already matched when E arrives, and V be the event that V is already matched when E arrives. In order to accept the last element with probability, at least, sorry, this should be C times XE, I have to make sure that I keep both of these. To make sure that I keep both of these vertices free with probability at least gamma because e will only be active with probability x. So, okay, good. And essentially, so you can do some massaging to rewrite this term like this. It's kind of like I have these bad events. Either U is blocked or a V is blocked. But generally, in the classical case, the way you beat one-third is you show that there's some chances that both bad events happen at once. So you're actually blocked. But here, basically, negative. But here, basically, negative correlation just means exactly one better that can happen. Because you can't possibly have u and v both matched. Because in batch one, either this edge or this edge comes. If you took any of them, you can't take any of the edges and matched. Okay, and this is just a formal argument to show this must be zero, so therefore you can show that gamma has to be a positive. Um s yeah. So negative correlation is not in availability, but actually in the structure of both. In the structure of the so it has to do with the combinatorial structural allocation. Yes. Yeah. Yeah, yeah. Negative correlation in the batch. Yeah, negative correlation in the batch. So basically, in the standard setting, the reason you can beat one-third is this and this are independent. So there's some chance you can have both of the bad events happen. But here you can't. Okay, so let me just quickly go through why we need the primality assumption. So the construction is based on finite affine planes, which exist if L is a prime power. Is a prime power. So basically, here L is three. I have nine points. I have four sets of three parallel lines. And basically, the key property we need is two lines from different classes intersect exactly once. The construction is similar to before. It's just an extension of what was before. Basically, the first L classes, you have, so each class corresponds to a time step. Each time step, you have like a uniformly chosen random. Uniformly chosen random line chosen from that class arrive. You can't possibly select two different lines from two different concepts because they intersect exactly once. So basically, it's the same thing once you get to the last L, all the possible bad events, at most one of them could have happened because all the lines that you could have taken in parallel were all in the same class and at most negative negative correlation, the most unaccording. All right, so basically. Alright, so basically, finite affine planes exist when L is a prime power. It does not exist if L is 6 or 10, which is found through brute force computer search. This is an open area in combinatorics. A great question. You can talk about the function. Yeah, I think it's basically exactly. So I actually don't think something weaker than this will work. But maybe. But I haven't thought about it. But I haven't thought about it too much, but essentially we use, yeah, we, this is kind of the structure. Quick question. Yeah, but those X's don't actually come from the LP, right? I don't know. Like those X's in the bad example, they're not the optimal LP solution. Oh, great, great question. Sorry, sorry, okay, good. Here, I only showed that you can't beat one of our own plus all with an OCRS. In the paper, we actually show that we can make an example where if you solve the optimal dynamic programming using In programming using backwards induction, you still can't do better than once for a problem constantly. The dual of the factory when we are here against the example relaxation is OSL. So you can't do better than one for a bad problem. Yeah, yeah. So here, just for illustration, I showed it for this uniform guarantee. But even if you just want to guarantee relative to opt-out E, yeah. Yeah, no, great Christian. Thanks for bringing that up. I should have mentioned that, yeah. So it's not just because I'm trying to provide this uniform randomized rounding guarantee that I'm limiting myself. You can't do it as long as you're limiting yourself. Do it as long as you're limiting yourself when compared to the algorithm vaccination. Okay, good. So I'm going to skip this. How we actually beat it in the cases, it reduces the optimization problem. So let me wrap up. All right, so what are the key takeaways? I hope you remember. One is randomized rounding as an approach to network revenue management. Two is beating this benchmark that I argue is a benchmark. It's arrived and it's appeared in a bunch of papers. Three is this separation. Negative correlation can actually. Negative correlation can actually hurt you because if L is one of these numbers, then you can't do better than 1 of correlation plus L. Whereas you can if you don't have negative correlation. And there's an open problem. Can we beat 1 seventh when L equals 6? All right. Thank you very much.