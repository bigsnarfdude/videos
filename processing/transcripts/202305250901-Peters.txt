I'm going to talk about joint work with Dar de Boer, Piotr Bauis, and Chris Grecht. Chris Grecht is a colleague of mine at the University of Amsterdam. He works on combinatorics, some computational complexity problems. And David and Pyotr are joint PhD students. Well, Pyotr already graduated this year, and David will graduate next year. So this is a one project with This is one project with the four of us together. And it will be similar in spirit to what Roland talked about, somewhat, but all the details will be different. So if you didn't pay attention to Roland, you should be fine. So let me introduce. So I'm not going to talk about the easing model. I'm going to talk about the independence polynomial, which is the partition function of the hardcore model. Let me introduce that. So we have a finite simple. That. So we have a finite simple graph, no loops, and a subset is called independent if no two vertices are adjacent. So and the independent polynomial is the sum over some parameter lambda to the power the size of the independent subset, and we sum over all possible independent subsets. So it's not a difficult definition, but it's difficult. Definition, but it's difficult to get intuition for. So let me give you, I will have actually a very large number of examples in my slides. So here is a famous example in combinatorics, the Peterson graph. I've been told it's the counterexample to all conjectures that are false in graph theory. So the Peterson graph has a partition function, an independence polynomial. It starts with one because there's one empty set. And then apparently, here you can see five lambda to the fourth. Apparently, there are five different independent subsets with four vertices. So I can see one here, this particle, this one, this one, and this one, particle vertices, sites. I use all these words to mean the same thing. Nodes, that's one, and then you can use the symmetry to get five of them. And then, well, the 30 independent. The 30 independent subsets of two points or three points you can. The next slide I put in for Slava. So SL of 2Z, this is a freely generated group generated by believing these matrices. These matrices and their inverses. But it's an so it's it's it gives you the four regular tree, infinite tree. So we want to define, we want to work on finite graphs, perhaps finite graphs converging to an infinite graph. So we take it modulo 3Z, and then we obtain a finite group. A finite group generated by these four elements. So we, oh, wrong direction. We obtain this graph, and it's an independent polynomial. And I'm not going to check that there are 33 independent subsets with A points. And then we can let 3 go to infinity, so we can get SL2 of Z modulo 13Z, for example, and you get a rather large graph. And I have no idea how to compute the independence polynomial. How to compute the independence polynomial. It would be nice to be able to say something about the limit behavior here, but I have no idea, so I'll throw it out to you. Say something. Can you relate this group to the smaller group in such a way that you can say something about independence polynomials? That would be nice to know. What is the motivation for this definition of polynomial? It has different motivations, so coming from graph theory. So, coming from graph theory, people are interested in, for example, the number of independent subsets or the maximal size of an independent subset. So, the number you can get by plugging in one, the maximal size is the largest. So, it's a generating function of the independent subsets. From physics, I think the original motivation comes from physics. The hardcore model studies, for example, gases. So, the easing model is intended to study magnets. Tended to study magnets. Hardcom model studies gases, where each atom has some hard core. Where if an atom is here, another atom has no interaction energy. They're too far apart, but it can't be on the same place. It cannot overlap the cores. And if there are no overlap, then they're allowed and there's no interaction energy. So that's, and I'll give another one with a picture later. So that's one motivation from physics. And in some sense, the hardcore model and the easing model are the two possible two-state models that you can have. So let me compare the independence polynomial with the easing model that Roland discussed. So in some sense, this is easier because I have only one parameter, only what Roland called Gacity. I think you I think you used z. I will use lambda. However, it's also more difficult because in Roland's talk, the zeros in the lambda plane, they all lie on the unit circle, that was the Li-Yang theorem, and that doesn't hold in this set. So they can be all over the complex plane. Although not on the positive real axis, which are the physical coordinates. Coordinates. And well, I'll get back to that in a second. And there was something Roland said that threw me off. He said that when the free energy per site converges on R plus, then the density of the zeros converges. And that was unexpected to me. And I believe it's false here. And well, I believe it because I think I can prove it. And so I asked Roland about that afterwards. He said, well, the proof of that really uses the fact. That really uses the fact that the zeros lie on the unit circle. So perhaps it's not surprising that it fails in this thing. And this difference will play an important role in this presentation. And I will focus on graphs that in some sense, and I'll be slightly more precise about this later, graphs that converge to all of z squared. So here's an example. You can take a point in z squared and take a finite neighborhood. And take a finite neighborhood. All points that in the taxi driver metric are, for example, of distance at most six to the central point here. And then you get some partition function, some independence polynomial. Or you can take a square. It's a different independence polynomial. I won't check the numbers, but you can see it's a 64 vertices. You can take even. Vertices, you can take even either the even or the odd vertices. This gives you your maximal independent subsets. So you have two of them of size 32. So I can understand the largest degree term. If you take a cylinder, what's a cylinder? You take the square and you add edges from above to below. So it goes round. And then you have the same two maximal subsets. But because I'm working on an even cylinder. I'm working on an even cylinder, it wouldn't be true on an odd cylinder, but for an even one, if you add these edges, your independent subsets still survive. But since you introduce more edges, some numbers actually go down. For example, 68 here below 64. So some independent subsets are no longer independent when you introduce more edges. We can introduce even more edges to get a torus, so now we also introduce edges. So now we also introduce edges from left to right. And again, some numbers will go down because of the introduction of these new edges. And the torus is what I will focus on. In fact, the even tori is what I will focus on. So what are the typical independent subsets of a torus? So what does that mean? So we fix lambda, and I'm going to work with probability measures. So I want lambda to be positive, otherwise, it doesn't make sense. And I say that. Makes sense. And I say that the probability of a given independent subset is lambda to the power i, that's the weight, but then I have to divide by the total weight, so the sum of, but that's exactly the independent polynomial. So what are typical properties in large tori? So really let n go to infinity and I want to write up some properties that have measure one in the limit. Have measure one in the limit. For small lambda, for large lambda, and somewhere in between. Well, for small lambda, so then the weight, the fewer particles you have, the larger the weight, if lambda is very small. So you should expect an almost empty independent subset. Not entirely empty, because there's only one of them, so the probability of that one will go to zero, but you should have some. Go to zero, but you should have some small spots of particles here and there, and for the rest empty. So that's easy to imagine. So, what about very large lambda? So, I'll show you a picture. Can you see this? So, what you should expect is something that's very close to a maximal independent subset. So, here the blue ones are, let's say, the odd particles. So, those are all filled, except again, Except, again, there are only two of them, so the probability of exactly maximal will go to zero. So there are some small deviations from that maximal pattern. Excuse me, could you remind what the parameter lambda stands for? Yes, so the weight of an independent subset is lambda to the power the number of particles. Well, what it stands for? Yeah. It's fugacity. So it's e to the power. So it's e to the power, the temperature, and then there's a Boltzmann constant. Okay, so that's to do with that. And on the graph, it's just the way that you associate one independent set. Yes, so for every particle on a vertex, I get one vector of lambda. So the more, if lambda is small, close to zero, then the more the larger i is, the smaller. The larger I is, the smaller my width. And if lambda is large, then the larger I is, the larger the width. So for large, I was looking at large lambda here, so that we want to have as many particles as we can, so maximal is either odd or even, but since there are many more independent subsets which deviate slightly from that pattern, you would still expect something like this. You would still expect something like this. And this is a computer-generated picture. As Roland remarked, the number of independent subsets or the number of spin configurations is way too large. It's like two to the power of the number of vertices. So that's not how it's done. Some dynamical process to generate this picture. So you have like a Markov painted scene. Similar. It's called Glauber dynamics. You start with some state, and then at each step, you take a At each step, you take a particle and you look. Can we fill that particle? We take a side, can we put a particle there? If so, we do that with some problem with it. Or we remove it with some problem. And then I think for this one, it's a bit, yeah. And this is like 100 million iterates of that process. Whether that's enough is unclear because it converges not so fast. So it's difficult to get. So it's it's difficult to s to get computer pictures of typical behavior. But still I think this is it's what I would expect. It corresponds to the computer picture. So I'm happy. I mean I guess I've seen problems where they regularly want like a markup chain. Yes. Yes. But it doesn't, but this process doesn't occur directly. Yeah. Let me follow up on that question, Jessica. I'm not sure what it would mean for that process to a microphone. For that process to a marker, because you should have many, many kind of representatives of this kind of probability. Yeah, that was what I was wondering. Does this long enough for it to be uniform on that? So let's go to a bit smaller lambda, so still bigger than one. Then these deviations become larger. Then these deviations become larger, and you will expect some deviations that go all the way from one side of the torus to another. And this becomes difficult here. I hope you can see this is a bit blue here, but here it's red, and here it's blue again. Of course, this is the same component as this, because it's a torus. And this deviation here could not exist without that deviation. Because you cannot have blue and red here that continues until you get here. That continues until you get here. There must be green stuff in between. So, these green deviations I will call contours, connected components of that, they will play a role in the proofs. And maybe I will get to that. So, what about odd tori? This is a little trickier. What do you think is a typical state for very large lambda? Very large lambda for an odd torus, 2n plus 1 by 2n plus 1 torus. So you can't have the even pattern or the odd pattern on an odd torus. So you must somehow separate that. I see you seeing something with your hand. Can you describe that? Yeah, so you might think, well, you have to separate the two. But on a torus, you can't do it. It's not separated by something that's only vertical, because then it's. Something that's only vertical because then it's still connected in the other direction. So you could do a cross, right? But a cross is not the minimal way to do it. So the computer-generated picture shows that actually some kind of diagonal would, it's bigger than this, but it's a lot smaller than the cross. So that sh would be your typical deviation for an autorus. I'm not going to discuss autori because it's more complicated. More complicated. So let's talk about phase transitions. And there are many different definitions of phase transitions. I'll use the same one that Roland discussed on Monday. So this is called the Yang-Li theorem, not to be confused with the Li-Yang theorem, which also suggests they were not friends, even though they wrote two very influential papers in the same year, 1952. So the Yang-Li theorem states that if we That if we normalize the independence polynomial properly, so we take the logarithm and divide by the number of vertices, then the limit exists and is continuous if you take a sequence of graphs converging to the integer letters. And I still haven't said what converging means, but all the examples I gave satisfy this. Moreover, if Um moreover, if if you have a parameter and uh complex zeros avoid this parameter so uh of uh avoid the neighborhood of a positive real parameter, then your limit function will be analytic there. So a phase transition is a parameter where you're not analytic. And you can detect this using the complex zeros on the positive real so we have a Because on the positive real, so we have a polynomial with positive real coefficients, it will never be zero on the positive real axis, but it can be zero nearby. And so we need the complex plane to understand the behavior on the physical polymers. Can you learn what is Z of G large? That's the independence polynomial. Ah, okay. Yeah. So this is a normal normalized independence polynomial. Independence polymer. And this is called the free energy. And then going back already to the 70s, people observed that if you study partitioned functions, such as the independence polynomial, on graphs that are in some sense recursively defined, then you can often describe that using iterates of rational functions or maps in high dimensions. And by studying these dynamical systems, you can help to describe phase transitions. So let me give you. Describe phrase transitions. So let me give you some examples. So the first example was: this is not from the 70s, this is from a paper of Roland and Lecher and Michel Jubic. Oh, this one goes also back to the 70s? This is the first paragraph. Yes, but the paper from the 70s, I think I'm thinking about they already had it on this on the regular tree. They observed that there was some like A. N. Berker study. A and Berker studying such things. Yeah, do you know the name, a year? I can tell you I've been already. Yeah, so okay, so this is also old. And the papers I know best, well, I learned about it in 2010, I think, published later. And we heard that you can describe phase transitions using dynamics of this rather complicated map in the these are not. In the, these are not the most pleasant coordinates. But that's an example. This one is easier. If you look now in the independence polynomial, here, this one was the easing model, the independence polynomial on D-arey trees, then Sly and Sun prove that there is a unique phase transition. And recently, Juan Ivira Letrier and Martin Sombra have talked several times. Talked several times about the proof that this phase transition is actually of infinite order, meaning it's not analytic at that parameter, but it is C infinity. And you can describe it, what they do is you can describe it by this very simple one-dimensional rational function. This is for the tree. This is for the tree, yes. Yes. And this tree. And this is the activity locus you get for that function. So the zeros accumulate on the white set here, which is, I drew it by computing the spherical derivative. So compute the spherical derivative and you plot the points in white where the spherical derivative is very large. So spherical derivative of some large iterative f. Why should the spherical derivative being large mean that you have zeros? Being large, mean that you'll have zeros. Because if you're the zeros accumulate where your family of integers is not normal. And not normal, we heard already several definitions of this, but from P1 to P1 it just corresponds to the spherical derivative going to infinity. So that's why I drew it in this way. Thanks. Another example is Fibonacci tree. So you started with a point. Nudgy trees. So you started with a point and an edge, and the next one you get by hanging the two previous trees under the root. So this one is obtained by you take the root vertex and then below it you hang these two grep these two jewels. And these trees also converge to the same DRA tree. You can do this for any degree, but you know. So you get the same limit. So you get the same limit uh tree as for this one. Naively, I haven't said what the topology is. But their union is the same tree. However, four computer scientists proved that the zeros of these independent polynomials all lie on the negative real axis. So they don't accumulate anywhere on the positive real axis. So there's no phase transition. So apparently you have a different So, apparently, you have a different free energy for this sequence than for the other sequence. So, Roland defined the lattice by saying a lattice that's a sequence of graphs. And apparently, that's right. We shouldn't just say this is the independence, the polynomial of the infinite tree. No, it's the independence polynomial, or the limit of that, for a sequence of graphs. And the union of these sequences is the same, but the Of these sequences is the same, but the free energy is precise, it's different. Is the critical the phase transition? Is this singularity? The phase transition is where it's not analytic. A physical parameter where the free energy per site is not analytic. It's it's one definition of phase transition. You would also like i to have one phase on one side and another phase on the other. Face on the other. So you can make that more precise. One state on one side and another state on the other, like from liquid to gas. But let's go with just one definition. Okay, so why do computer scientists care? Most of these work in the computer science department in Oxford, but they just prove theorems. So I'm not sure they're computer scientists. Scientists. But here's a paraphrase theorem: that exact computation of partition functions, and it holds for the Ising model, Kotz model, for the independence polynomial, is hard. You can make more precise statements. Often sharp p hard. It's a counting version of n p hard. So for almost all parameters, not at zero, then it's one, but at all other parameters it's hard. So you can't compute it exactly for large graphs. It exactly for large graphs. However, absence of zeros, so if you have some domain, let's say a domain around zero, around the parameter zero, where you know that your partition function is never zero for some suitable class of graphs, then there exist efficient algorithms that compute the independence polynomial up to some multiplicative error in polynomial time. So, this is why people in computer So this is why people in computer science departments are interested in proving theorems about this. So what do we see? Also, the complex zeros play a role here, even if you're only interested in the physical parameters. So I heard this quote recently. You may not care about complex numbers, but complex numbers care about you. Thank you, Frank. I thought I'd steal that. It's useful. Go ahead. Yeah, but attribute it. Oh, oh god. So to you? Is it your original? To you? Is it your original? Ah, okay. Next time. I wasn't sure about that. So, what about God or other people for other people? The one about God is for other people, from other people. I won't use it to mind. About complexity, this is use science. I got this. Use science one time. It was screaming at an algebraic geometry. You may not care about complexity, but complexity cares about you. Ah, okay. That was the original. Okay, so it's complexity. Okay. So I'll make sure to attribute it next time I get it. Sure, to attribute it next time I'll talk about it. So, the main motivation for this work is to see if we can say something about, for example, phase transitions, or at least free energy per site, in a setting like what I talked about, converging to z squared, where you don't necessarily have a recursion. It's not clear how to relate the partition functions of bigger squares in terms of smaller squares. Bigger squares in terms of smaller squares. So here's another physical motivation. Suppose you have a layer of graphene, which is a hexagonal carbon lattice. Then there are holes in there, and if there's some gas like helium here, then some of these helium atoms can be absorbed in the holes in this graphene. This has been experimentally studied. But if there's a helium atom here, then the neighboring There's a helium atom here, then the neighboring sites, which are the holes of this, so it's a triangular lattice, the neighboring sites cannot be occupied. Somehow the helium atoms, even though they're light, they're still too large. So you get an independent subset of the dual lattice. And sides that are not adjacent, the interaction energy is almost zero. So you get the independence polynomial. Or the independence polynomial is a good model for this. So, can we? This is something you would like to really would like to understand in physics, but it's hard because you can't use dynamics, at least not literally. So, here were three examples, the torus, the cycle, and the square, and these all converge in the appropriate sense to z squared. Their limits agree, and this holds also if we don't have to make them squares. We don't have to make them squares, we can make them rectangles. So the sizes don't have to be the same as long as the minimal size goes to infinity. However, if you look at tori of very uneven sizes or cylinders, the distribution of the zeros is not the same. They don't converge to the same. So that's the difference with the easy one. Easy one. If you keep the top side, the vertical size fixed and you let the horizontal size go to infinity, the torus in this cylinder behave differently. So what can we say about the location of the zeros? So inspired by the dynamics, I drew a picture of the spherical derivative for the twenty three neighborhood of zero, and I get something that looks very much like the picture from the paper of From the paper of for the Dary tree. And it reminds me of a monopoly set. It looks like there are infinitely many components, and you get something that's bounded, it looks like the components are simply connected, and for none of these statements I have a proof. Well, I can prove it's bounded. So, how about squares, cylinders, and tori? So, here are some. So here are some plots of zeros. So maybe this is the most insightful one to look at. This is the 8 by 128 torus. And you see some curves going up to infinity here. So if you let the horizontal length go to infinity, zeros do converge to infinity, it seems. So here's a theorem really due to Helmut Perkins and my co-author Chusschrecht. So if you look at So, if you look at subgraphs in Z2, induced subgraphs, for which the boundary consists either of only even points or only odd points, then the zero sets are uniformly bounded. And it relies on techniques from Borges and Ingrid. So, for example, if you take that n neighborhood of a point that satisfies this condition, then zeros are bound. So, how about these other graphs? So these are the new results with David, Gyoto, and Chus. If you look at tori that are somehow balanced, so the long side is at most exponential in the short side, and you let j go to infinity, then the zeros are uniformly bounded. But if you But if you look at highly unbalanced tori, so now I want the longer side to be larger than the exponential of j to the power third, then the zeros are unbounded. So this, to me, I'm happy, this is fairly close, but there is a gap here, and we don't know whether either of these two is sharp. I suspect this one is sharp and this one is not, but that's not something I can That's not something I can prove. So that would be interesting. So, what's the idea of the proof? Well, the easier proof is for the unbalanced tori. So, then you, for tori, you can express the partition function in terms of a matrix. So, the independence polynomial is the trace of some matrix. It's called the transfer matrix to the power n. So, that's equal to the sum of the eigenvalues to the power n. The sum of the eigenvalues to the power n. Now, something that Sobol already observed is that if you have one eigenvalue that's of maximal norm, that's strictly larger than all the others, then for large n, this won't be zero. So zeros can only accumulate on parameters where you have more eigenvalues that are of the same maximal norm. So what are the parameters? What are the parameters? Then you have to investigate this matrix. What are the parameters for which you have more eigenvalues of the same norm, of the same maximal norm? Well, near infinity, there are actually algebraic curves where the two maximal eigenvalues have the same norm. So the zeros will accumulate on those algebraic real algebraic curves. That's for fixed j, but so for fixed j. Fixed j, but so for fixed j, they're unbounded. So if you let j go to infinity slowly and let n go sufficiently fast, then they're still unbounded. But that doesn't give you estimates, so for estimates you have to work a little harder. So estimates, you need use some complex analysis. But this is not this is not a deal. Not that the other direction uses what's called contour models that really go back to Borgson Imbry and even earlier work. So let me recall, a contour is a connected subset of vertices for which the independent subset locally does not correspond to either the even or the odd pattern. So those were the green deviations from. So, those were the green deviations from the maximal independent subsets. So, and to the subset U, I also add the data on that subset. That even a contour has a type, which is the parity on its boundary. The boundary must have a pair, must be either even or odd. So, each contour has a type, and then there is a one-to-one correspondence between independent subsets. Between independent subsets and compatible collections of contours. So, this is the picture I showed earlier. It's an independent subset, but we can recover the independent subset by only remembering the green sets and the states on the green sets. Because here, the boundary on this green set is blue, so we know this must be blue. And here it's red, so this must be red. So, if you know the green stuff, you know the independent subset. So, it's a one-to-one correspondence. Now, the problem is that compatible, compatible is a different notion, difficult notion, because suppose you have something here, here is a contour, and here is a contour, but this has odd type, and this, the interior of this, has even type. Are these compatible? Well, they can occur if there's another contour in between. In between. So this, compatible is not a pairwise notion. It depends on the whole set of contents. Klan, can you say again what you mean by like even type of a continuum? It means that the boundary here is even. Well, the type is the exterior boundary. What that means on the torus is unclear. But you look at the length of the boundary. Have the length of the boundary? Is it even noted? What about a two? On this boundary, you see that only the red points are in your independent subset, and the blue are not. So a contour not only remembered the points, but also the data on the points. And from the data on the points, you can see that the right-hand side here must be even and the left-hand side must be odd. So for a small context, So, for a small contour like this one, there is a clear notion of exterior. And the type of the contour is the parity of the exterior. So, what I meant to say here is that to be compatible is a difficult notion. But Borgson Himbry found the solution to this. So, you can change the definition, it's quite technical, but an actual But after this change, you only have to consider even contours, contours of even type. And then the compatible just becomes non-overlapping, and that's a pairwise condition. And then on the torus, you have these large contours, and as I said, this one can't even exist without that one. And also, its type is not well defined. So, how do we do? So, how do we deal with that? Well, one solution is to consider all these large contours that really notice the topology of the torus, consider them all together as one contour. And as a consequence, we can say that the independence polynomial of a graph equals the independence polynomial of a much bigger graph whose vertices are all possible contours. Vertices are all possible contours, and there is an edge between two vertices if the two contours are incompatible. Okay, so that's, I think, a tricky notion. But for this, the idea is then to prove zero freeness for this much larger graph. And the large contours are still a problem. The large contours are still a problem, so we need to prove that the contribution to this log in the limit is zero for the large contours. And that we do with some simple complex analysis. So imagine you have two sequences of functions, fj and gj, but fj starts at one, because it contains also the empty independent subset, for example. And gj starts at some very high large power, at least. At least cj plus plus i already plus irritables. So they're sequences of holomorphic functions, and z is like 1 over lambda, so z is small. And you suppose that the sequences, the log of fj over some suitable integers, and the log of fj plus gj over some suitable integers, same suitable integers, they converge to the same limit on a a small ball around zero. On a small ball around zero, or some aj that grow at most exponentially. Then we can shrink the ball a little bit to conclude that gj is much smaller than fj. Not a difficult lemma to prove, but uh I had not seen it before, I was always happy to have some complex analysis in this proof. Complex analysis in this proof. And also, this condition on the exponential sharp. So, for this lemma, in order to deduce that the contribution of these large contours is negligible in the limit, we use the lemma for which this condition is sharp. So, that is an indication that maybe the theorem really requires such an estimate. I believe that's what I wanted to say. I believe that's what I wanted to uh say. Okay, so thank you very much. So I was going to ask about the remark that you made about dependence of the uh limiting behaviour on the approximations. The example that you gave was on the tree, the area tree. So, probably the dependence on the approximations comes from the fact that the limit is non-amenable. Whereas, in the case when the limit is amenable, then at least qualitatively, there should be some independence of the approximation. No, no, no, no, no. Oh, on R plus, yes, yes, that may well be true. Yes. Yeah. And I have a second question, if I may. And I have a second question, if I may. Have people looked at the Slabinski triangle? Well, I gave a talk in March and somebody asked the same question. But the Sierpinski triangle is claw-free. It means that you cannot find a subgraph with one vertex and three neighbors that are not. That are not adjacent to each other. There's no claw in a Sippinsky graph. So there's a theorem that says that if you have a claw-free graph, then the zeros of the independence polynomial all line on the negative real axis. So for the Sippinsky triangle, all zeros lie on the negative real axis, so there's no phase. On a negative field axis, so there's no phase transition. Broader, you could ask: what can you say about the independence polynomial on cell similar groups, on iterated monotonic groups? And that is something I'm studying with Ishanchanka. There seems to be something interesting that you can say. This is a very start of the part. Small triangle by that's also a remark which I made. And then I don't know what the answer is. So I decided to say something about what I did know. Yeah, we're thinking about this. What's the reason that I'm especially glad to be here? You have so the first zero and the real line, I mean the first zero from the right, you have Do you have some kind of regularity of this formula at this point? So the first real positive real parameters where zero accumulate? Is that what you're asking? For example, for this graph. So there's work of Schlossman and Dubai, already from the 90s, I think, who studied that parameter. So it's not known whether the phase transition is unique. The phase transition is unique, but they prove that there is a phase transition at that first parameter. So it's not analytic. The order is, and where it lies in the order is not known. So they have like eight different characterizations of phase transition, and they prove they're all equivalent. Their work might be uh an answer to your question. And they have the density of And they have the density of the balls that is much more. Yes, yes, they prove something. Is there any theory like if you have instead of graphs saying sequences of complexes and yeah, also those transitions? I mean if you like instead of graphs, if you have like higher dimensional complexes some sort like Or is there something like language or squares or like cubes? I have no idea. The motivation comes from physics, and it's very likely that probably our world doesn't just consist of grass, it's more likely consistent. There's a large literature on this topic and it seems likely that it has been studied. It seems likely that it has been studied, but I'm not aware of the results. Thanks. Thanks a lot, and thanks to using the other letters. 