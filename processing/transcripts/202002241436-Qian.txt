From all previous talks today, I'm not talking about the available device or implementable devices. I'm going to talk about the mobile health uh health applications. And also, I received AshPaz's email about the one slice for challenging, and my understanding was I only need to prepare one slice for the 15 minutes talk. That's awesome. And then after Susan's explanation, I expand this to like five slides. Next slide. Okay, so today I'm going to talk about something about policy learning based on mobile health applications, not just high-dimensional actions because of these five slides. Okay, and my focus is going to be focused on the introduction of the mobile health applications. And this is a joint work with my colleague Ken Chung. He's also, he's here and he will give a talk on this IntelliCape app. So if you are not, if Mike is not clear, you can ask him. If Michael is not clear, you can ask him later on Thursday. Okay, so this Intellite suite of apps is a suite of apps for treating depression and anxiety. And it includes like 12 individual apps. The understanding is when you use those kind of mobile health applications, it's better to just use one app for one specific target instead of using one app to treat all possible depression and anxiety symptoms. And anxiety symptoms. That's why we have 12 acts here, each one taxed for one symptom or one problem. The first row, four acts, are kind of tangle your thinking challenges. For example, you might have some negative thoughts, and then you might put the negative thoughts in the thought challenger one, this one, to see if this thought is really worth to worry about. Then there's a lot of good strategies to cope with these thoughts. And then these two, purple chew and Pooh chew and slumber times that way to teach you how to calm down, like how to relax and how to have a good sleep. This one is a relax, good sleep. And these two are for checklist. Basically, if you want, you tell the act what's your value and if you want to leave your value, you should do to leave your value. So you make a list like an action list and then you just check down whether you did those kind of actions every day. You did those kind of actions every day. And for these two, it's easy from the name. Basically, it just teaches you to move or to take some activities or exercises. And then for the other two, they're kind of different functions, like the worry noise tells you how to untangle your worries. You have some kind of things you worry about, and the social force is how to socialize people. Now, so each app is designed by some technical. Each app is designed by some clinical psychologist and is optimized within the app. We don't have control for that part. Everybody, I mean, they have optimized each app. And the key point here is the hub app. Because we have 12 apps here, then we need something to manage these 12 apps. Like, which app should the user use, right? And how to coordinate those apps. So our focus here is the IntentHub app. And the the hub app has two functions. The first one is m the hub app needs to make a recommendation of individual apps. So the recommendation is set to be like weekly recommendation. Of course, this is actually open deployment apps. You can find this in your cell phone app store. So some people may have app installed on their cell phone. Have half installed on their cell phone, then some people may not have hub installed on their cell phone. And then the primary analysis, actually tending the primary analysis, so this shows that for those hub users, they have a higher loyalty and higher regularity as compared to the non-hub users. That means the hub app is really useful, right? Now, within the hub users, now our question is how do we Now our question is how do we recommend those apps so as to enhance the overall hub usage? Because we already showed it's useful but we still want to optimize it so make it more useful. And then possibly because our long-term goal is to treat patients with anxiety and depression so possibly how those kind of app usage translates into clinical benefits. So and they have a restriction here. There are 12 apps, but you shouldn't really recommend Apps, but you shouldn't really recommend all apps every week, right? So there's a restriction. Although there are 12 apps, the restriction is no more than two app recommendations per week. Kind of realistic goal here. So the first goal is hub app recommendation. The second goal is to manage all kinds of messages and notifications from other clinical apps. For example, here we only requ so with the We only rec so with the app, we only know the app usage, but we still want to know for the depression and anxiety patients, we want to know their symptoms, right? So, one function for this hub app is to prompt some message, ask the patient to fill out a PHQ for questionnaire. The first two, the four items, questionnaire, the first two are for depression, next two are for anxiety. And if you have this information, it will be very useful. If we have this information, it will be very useful, like as clinical outcome. We can use to tailor treatments, tailor F recommendation in the future time points. And the thing is, so this, okay, so this prompt push notification is also weekly notification. And it's sent as like on the first day after you download the hub app, the hub app is going to prompt a notification. And then if you rep and then every seven days, the hub is gonna prompt another push. The hub is gonna prompt another push notification asking you to fill out this PHQ4 questionnaire. But what's the exact time to send out the notification? It was not set. So basically they randomly prompted the notification within the 24 hours. So here another question we want to answer is what's the best time to send out the push notifications to maximize the response rate? So those are the kind of decision-making problems. Problems. Now, in general, our setting is like we have three elements setting. We want to do decision making. Now, each individual will track like multiple time points. In our case, each time point is like a week. And then at each time point, we know the user's past usage pattern and whether it's a weekday or weekend, or other information like the weather or whatever, right? Right, and then this is our, we call this state, and then there's an action. So it depends on what's our goal. In the first app recommendation, the action will be which apps to recommend. Or for the prompt push notification, the action will be what's the best time to send out the push notification so that the user gonna answer this push notification. And the outcome you are interested in. And the outcome you are interested in will be all kinds of different possible outcomes. In the push notification case, the outcome is whether the patient responds to your notification. And then for the app recommendation case, the outcome will be whether the users use the recommended app or not. Weekly or in the next week or in general in the long term. And there's a long term goal is whether there's Is whether there's improvement in their clinical symptoms, like clinical outcomes. And then in the data, each individual will be observed like multiple time points. We just empty the time points. So the goal here is to find a policy. The policy is going to be just based on user information, like usage pattern of all past information. And then take those information as input, output, and Input, output, and action so as to optimize the outcome of interest. So, this is like a potential outcome framework. If you use this policy to make your decision, what would be the exact outcome you are going to see in the future? So, that's a general framework. Now, this is the page of uh challenges. So, I think this is kind uh this this is um open deployness um Open deployed apps, mobile health applications, and the data are mostly observational. So there are lots of interesting questions we can work with, but because of the observational data, we have no control of the individuals. There are lots of challenges here. For example, when we want to make an app application from statistical point of view, we have to have a high dimensional action space, right? We have 12 app individual apps, but your recommendation will be like no more than two apps per week. Like no more than two apps per week. However, in the observed data, the observation is very sparse. Actually, half the patients may not even get any recommendation. And then there are some combination of actors recommended in the same week, but not all of, you don't observe all possible combinations. Actually, you only observe a small um possible set of combinations. So how do we make app recommendation in this case with high-dimensional action space with some constraints? Action space with some constraints. And another thing is there's a high heterogeneity across users. Usually, when we make decision making, we say we use individuals' past history to make a decision. But the problem is if we can either pool over all individuals, in that case, you borrow strength from other people and you make a decision. But here, even for different users, may have completely different habits, they have different skills. Habit, they have different schedule, right? So, even they have the same usage pattern, you don't know what will be the best strategy. Maybe the strategy based on the state could be different across individuals. But also, we cannot just use each individual's own data to make policy learning because there are actually very high drop-offs. We have very limited amount of information for each user. So, limited data might have like six weeks or six weeks. Might have like six weeks or sixteen, eight weeks or sixteen weeks, and then they might drop out later. And actually, the response, the job out rate kind of high, we will see a narrow out rate. So the response rate is actually declined quickly, either when the response to the push notification declined quickly, or the app usage declined quickly. And another challenge is whether we should care more about the immediate rewards or long-term rewards. Rewards or long-term rewards. So, in rewards millennia, we most often care about the long-term rewards, especially if you want to treat patients. Your goal is to ultimately cure the patients in the future. So, that's the long-term rewards we care about. But when you do mobile health applications, it's kind of different because we actually the patient, the individuals may drop out the app very quickly, and you have no personal interaction with the individual. So, you want to So you want to engage them as quickly as possible. So in that sense, we want to care more about immediate rewards. Another reason we care more about immediate rewards is like in our case, the response to the push notification actually gives you some kind of clinical measures of individual symptoms. And these individual clinical measures may be useful for the help to make recommendations in the future. So in that case, we have to care about current when the individual Current when the individual responds to the push notification or not. And another thing is, although we care about long-term rewards, but we need to be realistic. Maybe the indicator is going to drop out quickly. So we should talk about immediate, more realistic goal first. That's the immediate rewards. But then how do we connect the transit, the immediate rewards to the long-term rewards? So that's all the challenges I have. And this is my last slide. Um this is my last slice. How big was reminders how many users Sean had in the data set? A large number, right? Very large number of data we have. Now we have two waves, each with about three uh two thousand something. Two thousand about four thousand. How are you all thinking about the long-term reward? How are you all thinking about the long-term rewards? Long-term rewards, that's actually a little bit challenging. First, we thought about long-term means of accumulative app usage. That's one long-term rewards we can deal with. Another one is we actually have a small, small study, small like trial study in those small subset of patients, like 100 patients, we actually collect their clinical outcome after several weeks. But that's a very small subset, like 100. Oh, that's a very small subset, like one hundred patients. Yeah. Yes? Okay, so you said they usually use the app for like no more, like six to eight weeks. Is that right? Is that what you said? Everybody is different. Some people just download this and stop using this after two days. But usually they eight decision networks. Yes, eight weeks, something. So 12 choose 2 is like 66, and since you're not really like getting that much longitudinal data, maybe it would make more sense to think of this as just a straight-up optimization problem where you're trying to, if you, I'm assuming you have like a model for what you think the probability of success for whatever the clinical outcome is, right? So you could even enumerate the 66 options across the eight periods and fruit. And brute force it potentially, right? Yeah, then we need to pull over all individuals, right? I think we have to, otherwise. Yeah, yeah, right. That's what I'm assuming, right? Like you could use like machine learning or something to come up with like a model to do this. We try to do that. One problem is I think also high noise data. We still still trying to figure out pick out some information. So far we haven't found any interesting. Find any interesting information. Basically, what we find is recommendation is always better than no recommendation. That's what we find. So, no personalized part in this. I think we need to wait. So, have you thought about, you know, there's all that work on off-policy learning. It's quite hot right now. Well, I don't know. I think it's still pretty hot in the CS world. Have y'all start? And there you pool over your body. So, is that You know, you so I is that what you're thinking about doing, like off-policy learning? So you have a data that was collected under some policy, you don't know it, which it was collected under some policy, and now you're going to learn a new policy. I guess this is what you're doing, right? So she is pooling over people. Like offline learning is what you're doing. Yeah, offline. That's what I was talking about. Yeah, that's what I thought you were talking about, but I wasn't 100% sure. Yeah, that's right, right. Yeah, that's right. Yeah. Where you use like importance for. Where you use like importance weights and stuff like that? You know how they do that, or other people, or there's all this work by Emma Brunskill. No, no, we have to just use try to do Q-learning thing. And then we, the thing is, actually, it's not a stationary process. That's something I worry about. So right now, we try to build time in the model to make it still functionally stationary. So it's in the process. The problem is the data is really high. The data is really high noise data, so it's hard to find some signal, as you say, some interesting results. And also there are many different apps. Should we tap for outcome, should we say if I use app usage as outcome, should we just tackle for each type of app and for this particular uh the usage of this particular type of app or we should put out put out all usage of all apps together? I mean, there's there are many different choices. Many different choices. You said you were not doing personalization, right? So, what are you doing here? Why not like margin structure models? No, we do personalization. We do personalization. Yes. We try to match the state to the action. So, this is this David Moore's group? This is David Moore's data. So, does he have any ideas about what might be, what might cause confounding? Because it isn't observational. Does he have any, it seems like it might be possible to get a lot more information from him on this data. He's actually a pretty nice guy. You know him, don't you, Ken? The confounding issue is qualified. The compounding issue is well it's not as as much a compounding, it's more like a reverse causality. So one of the criticisms in the paper is that we establish how it's associated with high usage of the conditional of air, but then who would like to use air or so that's just a way you could use um uh authority. So that that's what except the So that's what, except the small number of patients, actually we're 400, not 100. So in randomized rounds, so we have technical large follow-up. So that would be the gold standard that we're going to have. Yeah, that's looking forward to have that. So just a lot of data cleaning. So everything presented the nice development field, like the data is nice, but we spend a lot of time on just make sure data that is involved as a pattern. But that's a great question. But that's a great question on how to do it on family. That actually could be one of the questions that we did provide. So we did a trial several years ago with a similar type of toolbox. It's now available on reachout.com tools and app section. And what we found, it was a standard RCT. One group got the toolbox, another group was the control group. The signal was very weak. The signal was very weak recommending apps. It was a small signal, but it was really weak. So I'm just wondering: given the effect of apps is so weak, the optimization, it may be because the interventions are not sound, and your methods are sound, but it's probably not able to find that effect because the intervention effect is not measurable. I think they found that by each individual inter app is F is kind of a useful device, kind of positively associated with the clinical outcome. That's what they found. So it's supposed to be useful. My slide. They didn't consider cognition, they didn't consider the personalized effect. Yeah, but the study setting is very different. So when you're studying the effect of each app versus person using different apps, people don't compartmentalize that way. Like, when I'm feeling this, I'll use this app or that app. It's not. If they're stressed or if they're in if they're experiencing one other risk factor, they're not necessarily thinking in a rational way. Like they'll all rationally choose the app. So it's, yeah, I guess what I'm trying to say is it's probably not straightforward to transfer the learning from individual app evidence to composite toolbox evidence. Yeah, I think yeah, step in loss of patient, but I think um yeah The individual won't be able to choose that's why we want to design a way so that the hub can choose appropriate apps for the individual That's what we want to do because if you ask the individual to choose which app I think they may have no idea I think they may have no idea the magnet. Yeah, so I think I don't even think that I just look at app usage that you will have a strong signal to your so-called outcome. But I think we have anything else. I think there's plastic effort to think the at least for those who enrolled in the chemical trial. And go to the clinical chart, then it will make you have a record so that we have a user in the job. But I think this is just one piece of a bigger, so this is a cube one that we want all the time. So we will do something special.