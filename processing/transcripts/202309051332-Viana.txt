From the Altitude, and I'm happy to share some of the work we've been doing on data representation for ourself by Alpha. Let me start by giving you some information about the institute I don't know if everyone here is familiar with. We are a non-profit research institute located in Seattle. We are about seventy people working on multidisciplinary teams. And our values are team science, open science. And in the last years, we've been And in the last years we've been sharing with the community tools that range from gene editing to imaging to data analysis and data visualization. Our scientific mission is to understand how cells organize themselves and how they change. And we believe that to achieve this goal, it's important to understand these concepts, cell organization, cell behavior, and how they interplay in time. Very much related to what Felix mentioned yesterday. Felix mentioned yesterday, shape this function, and this is what we think. And our working hypothesis is that if we have a good understanding of this, we should be able to look at the cell and say what the cell is doing, what it did, and what it's going to do in future. My talk today is going to be mostly focused on cell organization, how we define and how we measure it, and it's going to be divided into two parts. The second part I'm going to try to talk a little bit more about recently. Talk a little bit more about recent works we've been doing, and I would appreciate feedback on that. Okay, so let me start by unpacking this term intracellular organization in measurable, well-defined terms. Starting with cell and nucleus. I think, like many of you here, we understand cell and nucleus as landmarks in the cell where things organize themselves around. And we use some concepts from the literature, some that we see new. Some that we can see here in this workshop too, to create shape space. And using that shape space to find cells that are similarly shaped. The next concept that we are interested in is the average location of organelles inside the cell. But because cells have very different shapes, it's hard to tell if an organelle is in the same place in different cells. So people have tried to overcome this problem in the literature by growing cells in micropatterns. So all the cells have the same. Patterns so all the cells have the exact same shape. Unfortunately, that doesn't work for the type of cells we work with, but we have a shape space, so we can navigate that shape space and find cells that have similar shape. And for those cells, we can look at a particular ergonelle and see how much variation we see in the location of that ergonelle. Next, as important as the average location, is the variation around mean. So we look at the same structure across. At the same structure across different cells, then we ask the question whether they occur in the same place or in different places. So we came up with this measurement that we call stereotypy to answer that type of question. And we also have another measurement that we call concordance that looks at two different structures and how they co-localize in mind cells. Unfortunately, today I'm not going to have time to talk about this to you, but I encourage everyone interested to please look up this paper that First, please look up this paper that came out earlier this year. Now, I had two slides to talk a little bit about the myology that we use to apply this framework to. So, we use CRISPR-IGIN Editing to edit human-induced food buttons themselves. These are the cells that we work with. And we develop reproducible and scalable live cell imaging to image those cells, and then we create. And then we create segmentation workflows to segment with high accuracy and extract single cell data sets for this stem cells. These cells, they grow in diphthideo-like colonies like this one. They are very high impact, and we use DNA dye and membrane dye to mark the cell membrane and the nucleus. And each cell line that we produce. And each cell line that we produce carries one GFP that labels one organelle. And we have 25 different cell lines, each one of them tagging one major organelle cell that goes from mitochondria to ER, Go G. Okay, so now let's go back to our framework. So we start with 3D segmentations of cell in nucleus, and the first thing that we do, we align all the cells. Do we align all the cells along the longest axis so that the longest axis is parallel to the x-axis, and we apply the same rotation to the nucleus. And then, because our cells are not very complicated in terms of shape, we simply do a spherical harmonic parametrization, and we now represent these meshes as a set of numbers. We can use these numbers to reconstruct back the shape with high accuracy. And then we simply And then we simply use PCA to reduce dimensionality from all these coefficients delta to eight dimensions. And this eight-dimensional space is what we are calling here a shape space. Every point in this shape space can be converted back into the square common x coefficients and from that back to my shape. And here I'm reconstructing the origin of our shape space and we call the corresponding shape the mean cell shape. The mean cell shape of this shape space. To investigate what each dimension of this shape space corresponds to, we simply do latent walks on this eight-dimensional space. This is a 3D reconstruction of this corresponding shapes, and here are 2D projections from side view or top view for each one of them. We found that the second shape mode is related to size, so mostly related to cell cycle progression. Cell cycle progression. The first one is related to cell height, which is related to the density of the colony and the local density that each cell experience. And the other shape modes are more different ways the shape can vary that are probably related to physical interactions between cells. So now that we have our shape space, we can talk a little bit about the average location of a deviant structure. Average location of a given structure. So let's start with our shape space. I can select one cell in the shape space, and let's say this cell has GoG tag. Because this cell and Newfoundland are parametrized with Sperco harmonics, we can simply interpolate the SPERCA harmonics coefficients to create these intermediate shells. And I guess based on the last talk, this is one thing that we probably can improve using other techniques. But now for each one of the points. But now, for each one of the points on these intermediate meshes, we can go back to our segmented image and ask whether at that location we have a presence or absence of Goji. And we report that in a binary matrix. Now we can do the same in a local area of the shape space for all the cells that have Goji tag. And we average the, we call this representation parametrized intracellular location representation for pillar for short. Now we can average together Short. Now we can average together all the pillars for all the Gauchi cells. So this encodes the average location of Gauchi in those cells that are shaped like that, in that area. Now to visualize this average pillar in 3D, we have to have a template shape. So in this case, I'm just using the V shape of the shape space. Can go through the same interpolation process. I can morph this builder into that shape and get the three. And we have the 3D visualization of Goji. And when we look from the side, we see Goji seems to be at the top of the set. Yeah, so now we can do the same for all the cells from all the 25 different structures. And this is the basic result that we get. Again, I'm showing a top view and a side view for each one of them. And because all this, we call it marked cells, they have all the same shape, we can visualize them in. The same shape, we can visualize them in an integrated way, like this. And we can also use the average pillars to compute correlation between average location of organelles. And we can display the result as a correlational matrix like this, that then we can use as input for hierarchical clustering. And basically, the result that we get is the classic textbook cell compartmentalization. All the nuclear structures, nuclear periphery, cytoplasm, all the cell compartmentalization. Class and all the self-worth structures. One possible application of this is now to compare these heat maps across between different conditions where you have, for instance, a drug that perturbates the localization of mitochondria or the co-localization of mitochondria and neuron, for instance. The one application I want to discuss a little bit is comparing cells that are at the edge of the colony with cells that are at the center of the colony. At the center of the colon. The cells at the edge they are known to have a different expression profile. So we asked whether we could also see difference using this framework. So the first thing we did was to find, look in our shape space for all the cells that are at the edge of the colony, and we changed the alignment for these cells so that now the outside of the colony is always on the right side of the cell. Now, going back to our mean shape for the full data set, this is what it looks like. And this is the mean cell for the edge cells data set. And we see they have different shapes, so we cannot directly compare the intracellular organization. But the one trick that we can do is use our shape space and then project the edge cells of that space. And now, for each edge cell, we find the nearest non-edge cell. And now we have. Cell. And now we have this matched data set that we can treat as its own shape space where all the cells are under the same shape distribution. This is the corresponding mean shape for that space. When we project the average pillar of mitochondria, for instance, in that shape, we see that in edge cells, there seems to be a higher concentration of mitochondria on the right side, which is the outside of the column. So to further test this hypothesis, This hypothesis, we use the different flavor of conditionality, reduce the space. Instead of applying PCA to the coefficients that describe shape, we applied PCA to the pillars. And then we found the linear axis that most discriminate these two populations. And then this axis, we can count how many cells we see in each population. In each population, and the higher the difference between these two histograms, basically the more significant the phenotype is. We can also animate this, and we can clearly see polarization of mitochondria going from the left to the right, meaning when you go from non-edge cells to edge cells, we can also access the higher concentration of mitochondria towards the outside of the colony for edge cells. We did the same for all other structures we have. We found similar polarization for other organelles, lysosomes, cogene. And one counterexample that we found was the adrenal junctions that actually polarize towards the left, which makes sense because the edge cells don't have neighbors on the right side. So these junctions polarize to the left side of the cell. Okay, so far I showed you how we define organic. Showed you how we define organization and the framework that we are using to quantify it using pillar and dispersal harmonics. The pillar is great, but it's a very generic approach because it's trying to do the same type of trying to create the same representation for all characters at once. It's definitely not compact. It's the same order of the original image in terms of number of pixels. The reconstructions are not as great for functane structures. And as I said, it's morphology agnostic. And we believe that to answer very specific questions about other organelles, we must develop more appropriate representations for different morphologies. So the rest of my talk, I'm gonna focus a little bit on two different structures, PCNA and nucleoli, and how we're developing representations for them. Developing representations for them. Now, I have one slide to convince you that these are two important structures to look at. And this is all you need to know for the rest of the talk. PCNA is tagging the active sites of the replication, DNA replication, and it has a very stereotypical pattern across cell cycle. So if you look at here, I'm showing examples of cells in different cell stages from G1. In different cell stages from G1 all the way to mitosis. And you see, the spatial patterning of pCNA is such that you can look at an image and say in which cell cycle that cell is. Nucleoli is a liquid light condensate. It has three different phases, separate compartments, which is shown in this image here with the three different colors, a gentle, green, and yellow, I believe. And yellow, I believe. And it's very important for genome organization in the nucleus and ribosomal production. And I hope I'm going to talk a little bit more about this, but what is in common about these two structures is very different from cell and nucleus, which is a single piece. These are highly dynamic, multi-piece, and functive-type structures. So just to recap a little bit, what I just said, cell and nucleus, they're simple in a way, single. Simple in a way, single piece, they're in our case star-like shaped, so we can do a fine job just using spheroharmonics. We get interpretable coefficients, it's very compact, good reconstruction, and they're generative in a way that we can go back and forth between representation and chain. That is another story when we go to these other structures. They are multi-piece, they can go from zero to three hundred per cell, and each piece can be arbitrarily complex in terms of shape. Complex in terms of shape. So it's not very clear that we can even talk about parametrization in the analytical sense, like sperm harmonics for cell and nucleus. So instead, the approach we are taking is use machine learning to learn representations for the instructor setting. Here we are using point clouds for PCNA and sine distance function for nucleon. I'm going to go into details now. So PCNA, it's a very PCNA, it's a very difficult structure to segment because the brightness changed so drastically across cell cycle. So we don't want to we yeah, we didn't want to rely on any segmentation. So our approach is basically take the raw data and interpret that as an intensity, as a probability distribution. Then we are sampling points from that distribution. And we use the x, y, and z coordinates from these points from many cells to train. From many cells to train an auto encoder, a variational auto encoder, that is implemented in using vector neurons to make the learning process rotational behavior variant. So this learning process generates latent variables that we want to use for analysis. We test the quality of this model by looking at the original data versus the reconstruction. I have two examples here. I hope you can appreciate studying a fine. I hope you can appreciate it. It's doing a fine job. We can do latent blocks to investigate what each dimension of this set of latent variables is representing. And you see, like the first one is capturing sort of aggregation from sparse to condensate. But the one problem that we found is that when we apply this to other related variables, most of the time what is being captured is actually the global nuclear shock. Capture is actually the global nuclear shape and not the spatial pattern that we are interested in. So now we are trying to use conditional encoders to decouple the nuclear information from the learning process. Another thing is there is no reason to believe that these latent variables are fully independent, so it doesn't quite make sense to analyze each one of them individually. So in a way what we want to know is whether as a whole this set of latent variables encode biological information. Variables encode biological information. Luckily for us, PCNA is so closely related to cell cycle that we can investigate some of that. So, here what I'm doing is projecting all the latent variables we have into the using pattern map. It's just one flavor of the missionality reduction technique. So, each point corresponds to one cell, and each cell is color-coded according to the cell cycle stage. And we see like this nice transition from G1 to medium. From G1 to mid-S and G2. So that is suggesting that these latent variables have some biological information in it. Another thing that we tried to do was to classify the cell cycle stage from the embeddings. And in this case, we use a simple linear classifier. We get 75% accuracy. Just to give you a baseline, if we use nuclear volume, because the cell is growing over time, so you can imagine it's able to predict cell cycle. It's able to predict cell cycle, we only get 28%. And if we use the x, y, and z coordinates that we used to train the model in the first place, we only get 34%. We can also compare this result with a more fancy type of image-based classifier that looks at the image and tries to predict the class. And with this, we only get about nine, I mean, we get 90% accuracy, and this is pretty much what a U1 scorer would get. Score would get. I want to distinguish these two approaches. This is fully supervised, so the model was trained to perform that one task. And in this learning process, the model doesn't know anything about the cell cycle stage. He's just trying to reconstruct the point clause. Another thing we can do, we can select all the cells that belong to the same cell cycle, for instance meat S, and average together representation for all those cells and reconstruct. Those cells and reconstruct what is the average distribution of bCNA at that cell cycle stage. We can now do this for all stages and compare with the pattern that is known for pCNA. And just to remind you, this is the known pattern for pCNA. The first row is all the cells are under the same contrast settings, and this row has been adjusted for cell cycle stage. So G1 is much. So, G1 is much dimmer than late S. And now, this, I don't know if you guys can see, but this is the reconstructions we are getting. So, especially for a mid-S, late S, and late Sg2, we can reconstruct very well the spatial patterning, especially the ring around the nucleus and this condensates. We're still having problems for G1 and G2, and we think this is because of the sampling problem. And we think this is because of the sampling process, the signal SOTM for these stages. We have some ideas and we work on improving it. Okay, so now moving on to nucleoli. Nucleoli is also multi-piece, but here we want to preserve information about the shape of each piece. So we decided to use the sine distance function. So we start with the segmentation of nucleophile, we compute the sine distance function in three D. The sine distance function in 3D. And we use the same framework, but now instead of x, y, and z coordinates, we are feeding in the sine distance function images. And the job of this network is basically to reconstruct the images as you compress and get latent variables out of this grammar process. We tried to do this also in the rotationally coherent way. It didn't work for us. Yeah, I mean, we can talk more about this, but we are not. More about this, but we are not able to do rotationally equivariant on the edges for some reason. Anyways, again, so the results I'm going to show are not rotationally equivariant. And if I'm not mistaken, all the images have been aligned also in the same way I talked before about the cells. We can evaluate the quality of the model by looking at reconstructions. And yeah, you can see. And yeah, you can see how the very tiny pieces of nuclei are well preserved in the reconstruction. Again, we can do latent walks to inspect these latent variables that are learned. In this case, the first one seems to be some sort of labbing, which is actually one of the things we see when we look at this movie of nucleoli. In this case, we don't have direct information about cell cycle. Information about cell cycle associated to nucleoli. So instead, we project these latent variables into T and we color code this projection based on features that we measured from the segmented images of nuclei. And we found this first axis to be related to the X and Y aspect ratio of nuclei. And the second axis is related to how many pieces you have in your segmentation. You have in your segmentation, which is an indicator of cell cycle. There is some debate, but it seems to be that early on in cell cycle stage, you tend to have more pieces. Yeah, so I think the next thing we're going to do here is try to solve this rotational equivalent problem. We are moving away from image-based our encoder and try to do point cloud plus implicit decoder. We can talk more offline about this. We can talk more offline about this. Yeah, so I showed you how we generate these representations for nucleoli and pCNA. They seem to be good representations, they provide good reconstruction, they seem to capture biological variability, and they are generalizable in the sense that there is nothing really specific about BCNA and nuclei. The next thing we want to do is tackle the dynamics. Is tackle the dynamics problem. How the cells move in this latent space. And I have two slides to share some of the ideas we have and hopefully get feedback on it. So we are interpreting these latent variables as the axis of this high-dimensional cellular organizational space. And for the sake of simplicity, I'm going to reduce this down to two dimensions. Reduce this down to two dimensions. I'm using some arbitrary data to illustrate the idea. If we look at this data, if this data is coming from time-lapse data, for instance, we know how this cells transverse that space. And then we can start asking questions about solar behavior. Why do cells have different behavior when they're navigating? Why are they occupied? Navigating where they occupy different areas of the space. And I have one slide to show you our attempt of using proper togonal decomposition to tackle this problem. I don't know if everyone here is familiar with, but proper toggle decomposition is a way to decouple spatial temporal data in spatial modes and corresponding dynamics. I'm going to illustrate this with I'm gonna illustrate this with this toy data set. So, we created a data set of tracks where we interpolated three numbered shapes: the cube of Tahedron and a cone. This one example is one of these tracks, and we also added some noise to the surface to make the tracks distinguishable. So now we can go ahead and apply POD to this. These are the two spatial modes that we get. That we get with the corresponding dynamics. So, the first thing we can do is go back and see how well we can reconstruct the data with this. It's doing a probably good job. It's getting rid of the noise that we added. The one problem is when we try to interpret this, I mean, it's pretty hard. We don't actually know what they mean. But the one thing that we notice is we can look at these dynamics and we see like this inflection points. And now we can target the reconstruction. And now we can target the reconstruction on those points, and what we get is exactly the interpolation or the building blocks that we use to create the data in the first place. And this is the type of high-level description that we are after for PCNA nucleoli. This could be, for instance, in the case of nucleoli, could be nucleoli undergo a process of splitting in two shapes or merging backs and splitting three shapes, something like that. Something like that. Of course, this is for one track. Now you have to apply this for all the tracks in your data set. They are not aligning in time, so you have to think about clustering. So just to conclude, I showed you how we are working on these four different structures, how we are developing different representations for each one of them. How we want to use this concept of latent space to investigate. Latent space to investigate dynamics. And hopefully, when we have all this data available in the same cell, we can do this analysis in a more integrated way and ask questions about interactions between different instructors. Yeah, with that, I would like to say thanks to everyone from the Institute and glad to answer any questions. So, for your nuclear line, when you have this separation, you know what happens when the cell cycle actually has its air gets separated and dissolved? Yeah, it does dissolve. So I think there's three compartments. I think the outermost is Nucleoplasmin and then Formillarin and UVF. And I think the outermost goes. I think the outermost goes up, go disassemble first and then triple R. I mean, I don't know what happened with UVF. But yeah, I know that the first two, they disappear and then they reassemble after. And is that what you are meeting up again? Because it's for all the different. We are only talking about the interface. We don't go into mitosis just because they disappear. Yeah. You mentioned using vector neurons to have rotational invariance. To have rotational invariance. So it wasn't clear to me if your input is to the image and if the invariance is how they're going through the space. But the input that is happening, then the input are 3D coordinates of the points that we sample. How do these vector neurons work at a high level? I'm not a writing person to ask. Do you know the next? Yeah. But something was already used in vector. Yeah, I know the Spectre Neuron's being out. I know the specter neurons have been out for a while, we just using the their their code. But the idea, I I think high level speaking, it's the idea is that you pass a neuron together with your with your coordinates, and I think you apply a group invariance and you make sure that the vector isn't changed after that operation. Yeah. So, I think for the neutral research, so uh this Also, but these different pieces, right? Do you have any evidence of the shape is correlated or are they independent? I think that you could. It's a good question. One work that I know is that because it's three phases separated, you can predict some if you have two, you can predict the third one. But if there is a patterning in time, Patterning in time, I think that is it at all. This is some of the things that we are looking at. I was interested in your part analysis, which is very much in favor of your harmonic PP position. I was wondering how, since you already have the packet map and you have the side character space, how are you integrating that with the pod or about separate analysis? Yeah, so the pod is applied. So the pod is applied to in the toy data set I forgot to say we parametrized this vertical analytics. So we just apply pod to this work analytics for that toy data set. But in theory, I mean what we really want to do for the CNA is learn those bigger variables and apply P of D to that. And then math dash. And that map variables. And we have some results that seem to be working, but we are still struggling to interpret the results. All right, thank you very much.