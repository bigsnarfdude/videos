Ah, so people have been asking me where Lethbridge is. So this is us here. This is Calgary. This is Lethbridge. That's the Alberta-Montana border there. So yeah, not too far away. If you ever get a chance to swing by, we have a brand new science building that we're very, very proud of. So this is going to be a little different than a lot of the talks we've had because I'm going to take you back to deterministic systems. Systems. So the theme was networks, and I started thinking, what do I do that's networky? And this is it. Some of the results are old, but we're starting to get interested in this again. So the basic problem is this, that biochemists often draw networks that they claim have certain behaviors. Or they're trying to explain, developmental biologists, they're trying to explain something on a molecular level, and they draw a diagram of A diagram of interactions, this gene induces that one, and so on and so forth. And the question that you'd like to answer, at least kind of the first question you'd like to answer, is whether the diagram is consistent with the behavior that's claimed. Most of the time we don't have, and many people have commented on this in this meeting, most of the time we don't have parameters. So we'd like to be able to do some qualitative theory to at least, again, determine whether something is consistent or not with a given behavior that's Consistent or not with a given behavior that's claimed for the network. So that's what this stuff is about. This is about doing some qualitative analysis on graphs. The particular class of systems that we can do this for, there's a larger class of systems, but the class of systems that I like because I'm a chemist are mass action systems. So I'm going to talk about the theory for mass action systems. There are some ways in which you can extend this to non-mass action systems. So I want to. Mass action systems. So, I want to start by acknowledging the people who have done a lot of this work. Maya Mincheva really developed all of the mathematics. She proved the theorem. She was a postdoc with me many years ago. She's now a faculty member at Northern Illinois University. Ruhula Min was a master's student. He worked on an application that I'll talk about at the back end of the talk. Catherine Roussell has done some much more recent work, again, on an application, but one where we used to test out some ideas. To test out some ideas. So let's start with a stupid simple example, the Brusselator. You can analyze this completely analytically using classical techniques, right? You find the steady state, there's only one. You analyze its stability, you find it can have a hop bifurcation. But I want to point out kind of the connection between the kind of what we, the, the pieces, the things we've got in here. The things we've got in here, and then the equation we get. So you can write the characteristic polynomial in this funny way, which Bruce Clark was the first one to do. So normally what you would do is evaluate these derivatives, put it in a Jacobian matrix, put in the equilibrium point or the steady state point, and go from there. But in fact, you can convince yourself after a little while that the terms that go into these all, if you'd smash. All, if it's mass action, all look like some coefficients times some rates divided by some variables. And that's because of the very simple rule for differentiating monomials effectively. The question, so this one's very, very simple, right? So I think we probably all know if you've got a second-order polynomial, if you want solutions with positive real parts, so an instability. Real parts or an instability, then at least, well, this coefficient here has to be, well, at least one of the coefficients has to have a negative sign. And in particular, the only one that could have a negative sign, because this thing here is positive, is this one because of this term over here. So it turns out that this observation that terms with negative signs are special generalizes in a way that I'll explain in a few minutes. So let's start. So let's start with a general characteristic polynomial written this way. So I've got lambda to the n, a1, lambda to the n minus 1, all the way down to a n. So my coefficients are a k's. n is the stoichiometric dimension of the system. So I have to have taken out any mass conservation relations before I do this. And there's a, again, really super well-known theorem goes back a long, long way. Way, it's lost in the mists of time, so to speak, that at a saddle node bifurcation, this coefficient in particular has to pass through zero. Well, automatically, that gives you kind of an easy result, which is that if this thing is going to pass through zero, then at least one of the terms that makes up this thing, because again, in a mass action system, that'll be a complicated sum of terms. At least one of them has to be negative, or else it'll never be negative. It'll never pass through zero. So if you want to saddle node bifurcation, So, if you want to saddle node bifurcation, this coefficient over here has to pass through zero. That's an easy one. And therefore, it has to contain a negative term. Okay, what about Handrunov-Hopf bifurcations? Well, it turns out something similar is true for mass action systems, and I don't want to try to extend it outside of that, because I'm really not sure if it's true a little more generally than that, because it's more complicated for an Andronaut off once you get out of dimension two. But certainly, if it's a mass action system, then System, then, and again, these are necessary, not sufficient conditions because there's a bunch of things that can mess you up. But one of these terms here, not this one, because that's saddle note, but one of these coefficients here has to contain a negative term. Okay, so the theory I'm going to present here is actually originally due to Ivanova, who wrote these funny little papers that contain no proofs whatsoever. Papers that contained no proofs whatsoever. It made what seemed like very bold claims. And then what Maya did when she came to my group, she said, you know, we have to provide proofs for this. And so that's where she started. But essentially what we do is we work with a different representation, a graphical representation of our chemical reaction mechanism called a bipartite graph. And in these particular, so bipartite just means a graph with two types of nodes. In these particular bipartite graphs, we have species nodes and we have Species nodes and we have reaction nodes. And we essentially, you can read off the reactions from these things once you get used to it. So, for example, reaction two here, we take an x and we convert it to a y through reaction two. Reaction three, we take two x's, so any stoichiometric coefficients that aren't one, we put them on the edges. We take two x's and a y, and we turn that into three x's. Okay, so you can, there's a simple one-to-one mapping from a reaction metric. Simple one-to-one mapping from a reaction mechanism to one of these bipartite graphs. Okay, so what? Well, now we have, now it gets kind of definition-heavy. So, you know, I mean, depending on your level of tolerance for these things, you can go to sleep now and wake you up when you get to something interesting, or you can try to follow along. So, you have to break up this thing into pieces because the pieces turn out to be connected to the bits in the characteristic polynomial. Characteristic polynomial. So, one of the important types of pieces are edges, and they always go from, so these aren't edges in the full sense of a graph theory or almost anything. It's an edge. These are very specifically edges from a reactant to a reaction. And from a reactant, not a product. So, always with the arrow going this way. And we just denote them this way. Then we have paths, and there's two types of those. There's positive paths, where you go from a reactant through a reactant. You go from a reactant through a reaction to a product, and again we denote those just Xi, VK, XJ. But there's also negative paths. And negative paths, you go from a reactant to a reaction and then to another reactant. So you'll note that all of these things always start going from a reactant to a reaction. So that's one of the things when you start to draw these things out, you have to kind of remind yourself. Out. You have to kind of remind yourself of that all the time. Anyway, these negative paths, we just put a bar over them to remind ourselves they're negative. And then we build cycles out of paths. So a cycle is a sequence of paths that begins and ends at the same species. And I have something missed. Well, it's actually it'll come a little later. But the only things that we're interested in are cycles that only pass through each species once. So you can't kind of revisit So, you can't kind of revisit a species knowing. We have positive cycles, they have an even number of negative paths, and we have negative cycles which have an odd number of negative paths. And a funny thing that sometimes makes it hard to pick out all of the, we'll have subgraphs in a couple of minutes, but it makes it hard to pick out all the subgraphs, is every negative path is also a positive cycle. Why? Because you can start at xi, go through. You can start at xi, go through the reaction, go to xj, and now you can take the reverse negative path, which is considered distinct because it starts at a different node than the first one, and go from xj back to xi. And so you have two negative paths that gives you a positive cycle. So that's when I always forget to look for those. All right, so we've got now edges, we've got, oh, I've We've got now edges. We've got. Oh, I'm sorry. Sorry, it's coming to your side. So if it's going from the species to the reaction, does that always mean that the species is a reactant in that reaction? Yeah. Okay. Sorry. All right. So we've got edges, we've got paths that we make into cycles. So now we're going to have subgraphs. So a subgraph, what you do is it's a union of edges and cycles where each species is at the origin of only one edge or path. Edge or path. Okay, so this makes the things kind of, how should I put it? So the cycles and edges end up being disjoint because of the way this is constructed. So, right, yeah. So, yeah, I'll just say that. So, here's some examples of a couple of subgraphs, although they actually have other subgraphs hidden in them. But we'll just do the obvious ones. So, here's a So here's a subgraph that has a cycle, so just a simple little cycle going from x through the reaction back to x, and then an edge from y to this reaction. And this is what we call these edge subgraphs. It just consists of two edges, x to the reaction, y to the reaction. What does this mean, this reaction? What chemical reaction does it correspond to? So this particular reaction... on the right. Yeah, so so these actually all come for these actually come from the same reaction. These actually come from the same reaction. They're subgraphs from the same reaction. They're subgraphs from this one. And it's this reaction over here. 2x plus y makes 3x. And what we're doing is we're picking out a couple of subgraphs that in this case share the same species vertices and a reaction vertex, as it turns out. As it turns out. But on the left side, the product is 3x, right? Yeah. What is the product on the right side? So the subgraphs are not reactions. The subgraphs are just these formal things where we have a union of cycles and edges. So this is a subgraph that's a union of a cycle and an edge. This is a subgraph that's a union of two edges. Okay? So it's a formal thing, so they don't map back directly. They don't map back directly to chemical reactions. And I picked some very simple ones here that go through the same reaction, but oftentimes subgraphs, so for example, there would be a subgraph that would be x with coefficient 2 goes to v3, and I can't remember all the reactions, but let's say y goes to v4. That would be another subgraph that would be a perfectly okay subgraph. Okay? So the only restriction is that. So the only restriction is that each species can only be used can only appear yeah can only appear at the origin of one edge or path. So a subgraph need not be fully connected? Need not be connected at all. Okay? Alright. Alright, so then the subgraphs, the reason I showed you two subgraphs that use the same vertices is because then we actually group the subgraphs into what are called fragments. Into what are called fragments. And a fragment is the union of all the subgraphs that share a set of vertices. Okay, so in fact, so in the order of a fragment is the number of species vertices. The number of reaction vertices can be less than the number of species vertices. It can never be more, but it can be less. So for example, these two subgraphs I showed you a couple minutes ago are members of the same fragment. It's a fragment of order two because it's got two chemical species in it. Two chemical species in it. And if you wanted to do, so these are only two, though, there are actually two more, which I'll tell you about in a couple minutes. There are actually four subgraphs associated with this fragment. The fragment, when we draw the fragment, we just draw all the vertices and all the edges that you have to choose from in order to make the subgraphs. Alright, so there's a notation for fragments. There's a notation for fragments. So, what we do is we list all the species and we list all the reactions. The order doesn't actually matter. It's turned out. So, for example, this fragment here, you can call that, so this is the order of the fragment here. We can call that an S2 fragment. There could be several of them. There usually are, in fact. But this one is XY and then V3 twice, or you can write it just once. It depends on kind of your taste in these things. Generally, it's a good idea. Your case on these things, generally it's a good idea to write it as, to write, you know, if you pass through it twice, it's generally a good idea to write it twice because then it's easier to do the next thing, which I'm going to show you. So we've got subgraphs, which are made of cycles and edges. We've got fragments, which are unions of subgraphs that share vertices. Okay? Questions? Yeah, actually. Yes. So, I'm sorry, I don't understand. In what sense do you pass through V3 twice? Oh, so yeah, so you can see here that, for example, there's a cycle and then there's an edge and these two things. Almost no matter what you do with this fragment, if you start drawing subgraphs for this thing, every subgraph is going to pass through V3 twice. So you're going to reuse V3 twice every time you draw a fragment for this thing. Okay. Okay. Other questions? All right. So we started out talking about characteristic points. So, we started out to talk about characteristic polynomials. What's the connection? So, here's a characteristic polynomial. Again, this is just to show you the notation. We used the labeled the coefficients that way. Well, it turns out that the coefficients, a general AK in here, you can write as a sum over fragments of order k. So you find all the fragments of order k and of terms that look like this. So a coefficient that I'll tell you how to calculate in a minute. That I'll tell you how to calculate the minute associated with the fragment. And then you take all your rates and you divide by all your concentrations. Again, this comes from the funny way, this comes from the funny algebra of taking derivatives of monomials, basically. Can you explain again what this characteristic polynomial describes? So it's the characteristic polynomial that you get from doing the stability analysis of the equilibrium point. Okay? And what we're looking for. Okay, and what we're looking for is conditions under which this polynomial might have eigenvalues whose real parts pass through zero because that'll be associated with tidal nodes, with bibrications, and some other things that I won't talk about today, but you can also make out from this. Okay? Alright. Okay, so a corollary to what I've told you so far is that a necessary condition for a saddle node bifurcation is that Bifurcation is that there's at least one fragment of order n, right? So again, that's associated with this bear coefficient over here, whose coefficient, so the coefficient of the fragment is negative. You have to have at least one of those or you'll never, if all of these guys are positive, then this thing is just automatically positive all the time. It'll never have a saddle-barbled agitation. And what is that? Okay. I'll tell you how to count. I'll tell you how to calculate in a couple minutes. Okay. Okay? So, but it's a characteristic of each fragment. So each fragment has a k. Okay? And we're now in pop bifurcations. It's going to be the same thing, but it's one of these coefficients instead of this one. There has to be a fragment with a negative k somewhere of order little k. So if I want to make So if I want to find Endernov hop bifurcations associated with A1, I need to find, you never find those, but you need to find a fragment of order 1 that's negative, but those never happen. They're usually in here somewhere. Okay, now if it's a fragment with a negative coefficient, we call those critical fragments. Okay, so that just means it's got a negative k. Okay, so how do you calculate those things? Calculate those things. So the k for a fragment is the sum of some k's for each of the subgraphs in the fragment. So if we write a reaction this way with the stoichiometric coefficients of the reactants being alphas and for the products betas, these Kgs are a set of products. So you take all the edges in the subgraph and you square Graph, and you square the stoichiometric coefficient corresponding to that edge, and you multiply those together. And then, again, there's another set of coefficients. Now, for the cycles, you've got to calculate a k for a cycle, and you multiply the k's for all the cycles in the fragment, in the, sorry, in the subgraph. Okay? Because now we're calculating a k for a subgraph. And the k's for the cycles, they're kind of interesting. So they have a negative sign. If you're looking at a Add a negative path, then it's minus the product of the stoichiometric coefficients of the two reactants, because if it's a negative path, you've got two reactants going into a reaction node. And if it's a positive path, you multiply the stoichiometric coefficients of the reactant and product because those represent going from a reactant through a reaction to a product. Now, the fun here, if you want this. The fun here, if you want this thing to be negative, then you need at least one of these to be negative, probably several of them, but at minimum you need one of these to be negative. This part will never be negative. The only way you can pick up negative signs is from the cycles. If you have an odd cycle, then so sorry, if you have a negative cycle, Have a negative cycle which has an odd number of negative paths, then you have an odd number of these terms. Overall, this sign is negative, but there's another negative sign here that makes the thing positive. So in fact, you have to have at least one positive cycle in order to get this to be negative, which is the only way you can make this negative, and you need at least one of these to be negative for that thing to be negative overall. So there it is. So a critical fraction. So there it is. So a critical fragment has to contain at least one subgraph with an odd number of positive cycles. And again, all these things are necessary, not sufficient. Just frankly, I'd love to get sufficiency because conditions I don't have them yet. Okay, so lots of little fussy details that you have to work your way through. Here, real quick example. So this fragment here that I've been using as an example is a Using as an example is a fun one to work your way through. So there's an edge subgraph that's just this edge and that edge. You always get edge subgraphs. It's got a kg of 4 because you square this coefficient, you square this coefficient, which is 1, multiply them together, that's 4, you're done. This one here, so this is this little cycle, and then this edge. The edge doesn't do anything interesting, you just get a 1 squared, but the little cycle here. Get a 1 squared, but the little cycle here, you have a negative sign, it's a positive cycle, right? There's only one path, really, so there's a positive path. So you go 2 times 3, so you get minus 6 overall for the cycle. So then for the subgraph, you go 1 squared times the minus 6 gives you minus 6. So you can work through all of these things. Where are the other two? So these are the two subgraphs I told you about before. Where are the other two? You really have to think about this. So this one over here, you go from y to x through this edge, so that's a positive, that's a positive path, and then you take this negative path back. The last one here, this is the one I was warning you about, but I always miss when I'm looking for these things, is basically you go like this and then back this way. So it's the negative path, which is also a positive sign. The negative path, which is also a positive cycle thing. So you work out all this stuff, and it turns out your coefficient here is zero. And in fact, if you look in the characteristic polynomial, there is not a term that looks like v3 squared over xy times anything. So this was for illustration purposes more than anything, just to kind of show you, because the Brusselator doesn't have a lot of pieces to play with, so it's kind of started that one. Now, the critical fragment in the Brusselator is basically this one here. So it's actually a fragment of order one. It's actually a fragment of order one. I said that you don't usually, I mean, in really simple models, yeah, you find these things. But it's a fragment of order one, one chemical species. You always have an edge graph, so there it is. But you also have this cycle, which has a value of negative six. So overall, you get a coefficient of minus two. And if you remember what I said when we started out, these ksk's are the coefficients of these terms in the characteristic polynomial. So you pick up a v. So you pick up a V3 over X times this coefficient of minus 2. And again, that's the instability generating term in the presolator. I should say one of the reasons that this thing, you'll notice here I'm supposed to substitute in the values of the equilibrium or steady state point, right? One of the reasons that these conditions are not sufficient is that sometimes when you substitute this in, some of the negative term will cancel, it needs something else. It doesn't for the resulator, but it's not uncomfortable. For the Brussel later, but it's not uncommon that that happens. So there's always a bit of hunting around to do even after you've done this analysis. So that's the basic theory applied to a super simple mechanism. How are we doing so far? Anybody got questions? Okay, now, of course, as you can imagine, we don't really want to do this for the Brussels later. I could have done this much more easily. Oh, yeah, I love this part. There's a bonus theorem that you get out of this, which we prove in a different paper, which is that if you've Paper, which is that if you can figure out how to do all this critical fragment analysis, it turns out that if you have a critical fragment, you also have the possibility of Turing bifurcations. So, critical fragment of any order, if you can find one, your system might have a Turing bifurcation, again, necessarily not sufficient. Okay, but we want to do these crazy kinds of things. So this is the nodal lefty system. I don't know how many of you there are some developmental biologists here who probably know more about it than I do. Probably know more about it than I do. So, this is a real interesting system. So, during development, you have to specify a left and a right side. This happens in all vertebrates, but even there's versions of this kind of all the way down to the simplest bilaterians. And it's essentially the left side is specified by a protein called nodal. And what nodal does when it binds to its cell surface receptor is that that receptor. Receptor is that that receptor becomes a kinase and it phosphorylates SMAD2. This part here is a little bit speculative, but our analysis shows it's probably right, which is that you have to take, then two SMAD2s get together and they bind to SMAD4. We don't really know in what order, but it turns out that doesn't matter much either, dynamically. This thing and some other proteins, so there's some details I'm leaving out, they translocate to the nucleus. Leaving out, they translocate to the nucleus and then they activate a bunch of genes, but in particular they activate the gene for nodal and they activate the gene for another molecule called lefty. Why do I mention lefty? Lefty, it turns out is an antagonist of nodal. So what it does, it comes in here and it gums up that receptor. Lefty is called that because originally they thought lefty was the protein that depends. The protein that determined the left side, but it turned out it's nodal, but the name stuck. And the reason they thought that is because when you look at expression patterns, well, first of all, nodal does a whole lot more than just a term on the left side. It does a whole bunch of things. But they noticed that lefty was expressed on the left side of the embryo, and they thought, aha, lefty, you know, must be the left side marker, but it's not. Turns out it's nodal, which does a whole bunch, again, a whole bunch of other things. Bunch, again, a whole bunch of other things. So we looked at the system, and well, maybe I should tell you a little, a tiny bit of history. So there's a hypothesis that goes back really before these guys, but they're the first ones who really took it seriously, that it's a Turing instability that is happening in this system. So, and it's really nice because if that's true, nodal, of course, we said is the determinant of the left side, it activates. Left side, it activates transcription of genes that determine the left side. So it's the activator, not just in the genetic sense, but also kind of in the Turing sense as well. And Lefty, of course, is an inhibitor of nodal of the whole nodal signaling pathway. And as it turns out, Lefty diffuses a lot faster than nodal through tissues. And so it's just perfect from the Turing perspective, right? It's got that. The Turing perspective, right? It's got that activator that diffuses slowly and inhibitor that diffuses fast. They didn't really, they did some, how should I put it? They did some simulations that weren't actually based on any actual biochemistry, so it was less than satisfying that way, which is funny because these guys know the biochemistry. They're a lab that's expert in it. But a few years later, an English group came along and suggested. Came along and suggested that maybe it's not a Turing bifurcation, maybe it's kind of a spreading wave of leftness, in other words, nodal, that spreads to the left, essentially. Interesting paper, a little hard to... I had trouble with the paper because I couldn't kind of, I couldn't understand the geometry. The geometry they were talking about in their paper had no obvious relationship to the geometry of the embryo, so it was a little hard to figure out what they were offering. So it was a little hard to figure out what they were on. But if you were going to have wave propagation, the simplest way to have that, of course, is to just have bistability in the kinetics, right? Your classic bistable type of waves. So a couple questions arise from that. So does the mechanism, as it's currently understood, allow for one or both of these behaviors? And or, conversely, does it rule one of them out? So there were some more interesting literature that Some more interesting literature that we tapped into. One of them was, you know, we were kind of working on this stuff, and this paper came out, and we thought, oh, that's interesting, because that really helped us kind of focus in on things. Turns out lefty may not be strictly required for patterning. So for a long time, people thought that inhibition is absolutely critical to getting the pattern, to actually just getting the nodal mostly on the left. And you can so, or more specifically, Kind of having lefty delivered according to a careful program and the diffusion control and the whole thing that you have in a Turing pattern, that doesn't seem to be required. Because what you can do is you can knock out lefty and then just basically bathe the embryo in lefty. And you still get, it's not quite as robust, but you still get a left side determined. It appears that what lefty does is kind of titrate levels of nodal. Levels of nodal. So maybe, as a result of that, maybe we thought, you know, while we were working on this on the fly, maybe we should look at just a model of just nodal. Just leave Lefty out of it. So we did that, and I won't show you the whole mechanism. It's more or less the picture you saw with a few kind of details added in just to get it right. So the nodal-only system has seven independent variables, and there is an Variables and there is in fact an n equals 7 critical fragment and it's the smallest critical fragment, there are no smaller ones. And so that would be consistent in nodal, in a nodal only system with bi-stability. Therefore, potentially, well, so there's the problem, right? So therefore, potentially with wave spreading, because that gives you bi-stability in the system without diffusion, but it's also consistent with Turing. So a critical fragment of any. So a critical fragment of any size is good enough for Turing. But nevertheless, there it is. Just taking a real quick look at it. So essentially, it's pretty much what you would expect. In fact, here's Nodal. And what it does, it activates the receptor as an enzyme. This is receptor SMAD2 complex. You get phospho-SMAD2. They dimerize. There's a reaction. So again, this is just a fragment. So again, this is just a fragment, so it doesn't show all the chemical species in the mechanism. But this reaction here is the phospho-SMAD-2 dimers assembling onto SMAD-4 to give you a transcription factor. And this I know the real transcription factor has other stuff in it, but we left those out. And then that transcription factor goes and activates the gene, which makes Mornodal. So it's pretty much what you'd expect. There is this coefficient of 2 here, which you might think, Of 2 here, which you might think, you know, maybe that's important. Turns out it is. If you take this coefficient and make it a 1 instead of a 2, this fragment is still critical, but if you know your bifurcation theory, that last coefficient passing through 0 doesn't only give you saddle nodes, it also gives you transcritical bifurcations. And what happens if you reduce this coefficient to 1 is you get a transcritical instead of a saddle node, and that is not going to give you any kind of patterning. That I know of. If somebody knows different, let me know. Alright, so there's a critical fragment for this system. So if you don't have lefty, both bistability and Turing instabilities are possible. So it rules nothing out, but it says at least, it tells you the wiring diagram is at least capable of patterning. So you may ask, how did we find such a large critical fragment? We didn't just stare at it, we used software. Maya and her Maya and her colleagues wrote a piece of software called Pratelpy a few years ago, and it is an invaluable aid to doing these analyses. You can do them by hand. If you get good at it, I had a student, so one of the students who did the stuff I'll talk about later, who did a link, he got really good at finding critical fragments by hand before this software existed, but it's really quite difficult. The software has a few idiosyncrasies you have to learn to work around, but it's actually really helpful. Okay, so. Very helpful. Okay, so I took out lefty. Now, what happens if I put lefty back? So this speaks to one of the questions we often have, which is to what extent can I study kind of sub-mechanisms and modules and hope to learn anything about the bigger mechanism? So if you have a critical fragment in a sub-model that you then embed in a bigger model, there's a tendency, and you know, depending on how things connect up to it after that, but there's a tendency. Connect up to it after that. But there's a tendency for the critical fragment to remain critical, but the value of n, the number of independent concentrations, has increased. So now it's a critical fragment for a k less than n. So this means now that you could have Andrenau-Hop bifurcations in the bigger model, and in fact we found them in this model. Adding edges, so another thing is if you take something that is a critical. Take something that is a critical fragment and you just add edges that aren't actually connected to it because you're allowed to do that to make bigger fragments. Of course, those edges just multiply the value of the stuff you've already got by the square of the stoichiometric coefficients, so that doesn't change the sign. And so if you can do that again without kind of forcing you to change the structure of the fragment, then a critical fragment of order k less than n. Critical fragment of order k less than n in sufficiently complex models tends to be the root of a family of critical fragments for, if you will, k prime from k up to n. And so, in fact, by stability remains a possibility for a bigger model. Maybe not a big surprise, right? But still, it's nice to know that the math says the same thing. I should say that these models, like, you know, the smaller model is just nodal. The the smaller model is just nodal. There was that one critical fragment. But this bigger model here, there's literally hundreds of critical fragments in it. Without the software, this would have been a nightmare. So as a result of that, so we still have the possibility of Turing instabilities because we have critical fragments still, and so we still haven't ruled anything out. But we know that both the possibilities. But we know that both are possibilities, so now we've got to start investigating the reaction diffusion system, which is what we're starting to do. So I have five minutes left, so I'm going to go, I don't want to say really quickly through this last bit, but there's a couple things I want to touch on, so I'll just touch on them, and if any people are interested, they can talk to me later. So one of the things that occurred to me and that I kind of embedded into this left-nodal paper, which was supposed to be an applied paper, is the idea that, in fact, you can use this for model simplification. You can use this for model simplification, and just to kind of, again, to kind of romp through it quickly, I have a chain here of things with stoichiometric coefficients of 1. If I basically eliminate all of those and just draw, you know, basically, I'll call this V9 prime because it's not quite the same reaction anymore, but basically just connect from a reaction that comes out of phosphosmat2 all the way to here, keeping this coefficient of 2. I haven't changed the coefficient of 2. The coefficient associated with this fragment, so it's still critical. And so I could have a simplified model where I get rid of all this stuff at red. Of course, I'm losing now kind of biological realism, but I'm gaining in terms of simplicity. So I might be able to do more analytically. There's just, you know, simpler models generally are helpful. So this would be consistent with doing something like, you know, replacing, so the reaction that was here before. So, the reaction that was here before was dimerization, right? So, I'm replacing this dimerization with jumping all the way to an activated gene somehow. There's a couple different ways you can imagine doing that. The other thing is, so this bit here is just Michael's menton, but if I basically just replace that by bimolecular reaction, I still have, I had a positive cycle here, I still have a positive cycle, it's just much simpler. And so, again, that doesn't mess up. And so again, that doesn't mess with the value of the coefficient. So that fragment is still critical. This is pretty radical, right? Because this mess with the ability of the system to saturate. That might change things quantitatively. You have to be a little more careful about that. But anyway, these are things you can do. Okay, so this part I'm going to go super quick through because I know I'm running out of time. Turns out there's theory, we developed some theory for There's theory, we developed some theory for delayed differential equations as well, which you might be interested in if you're gene expression systems, right? So, and about, so this kind of, so when Maya came to my group, I pointed out something I'd done like a long time ago, which is develop these delayed mass action systems where the reactants come together at time t, but the products only appear later. And it turns out that for these systems, these delayed mass action systems, Systems, these delayed mass action systems, there's a counterpart to the theory. In fact, you use the same bipartite graph, and the only difference is this sign stays, but this sign goes away in the calculation for delay systems. And so it changes the types of cycles that are important changes. Well, in fact, all cycles are equally good, I guess, whether positive or negative. So here's the theorem. So a delay-critical fragment is a necessary condition for delay-induced. Is a necessary condition for delay and induced instability, and they're the ones with these negative coefficients, which again are calculated almost exactly the same way. I'll skip all this stuff about odd and even cycles. So here's the example here. This is a fairly cheesy model of photosynthesis, but it was designed to test the hypothesis a colleague of mine had. And it's got two delayed terms. Effectively, one of them is the photosynthesis starts off with a reaction catalyzed by this. Well, we can debate exactly where. By this, well, we can debate about exactly where it starts, but you know, kind of one of the key reactions catalyzed by Rubisco, and you get oxygen. After a bunch of other things happen, you get oxygen, so there's a delayed appearance of oxygen, and then there's transfer of P-glycolate to the mitochondria, where it gets converted to CO2. And this delay here is kind of intended to model transport delays mostly. So if you don't have any delays, this model. If you don't have any delays, this model doesn't have any critical fragments. So it's not capable of doing anything interesting all by itself. But if you put in the delays, it has one of these delay-critical fragments, and gratifyingly this transport delay shows up in this fragment. And so you can prove things about delay systems. So really quick. So all these graphical stability analyses give you necessary conditions, not so bad, for a whole bunch of interesting A whole bunch of interesting instabilities. Endernav, hop, saddle node, and transcritical, Turing, delay-induced instabilities. There's lots of areas for further development here. So this one bothers me because I always say necessary, not sufficient, because that's what the theorems say. The vast majority of time, when you find a critical fragment, you get the instability you're looking for. And so the next Uh so the necessary conditions must be really close to sufficient conditions, but I don't know what those are. So one of these days I'll figure it out or so one of you may if you're smarter than me, which is likely. The software, the software is kind of critical. I'd like to spend some time working on it, but it's not really my software, so you know. And it would be nice to put the model reduction stuff on a really solid footing of some theorems, because right now it's more like just looking at fragments and take up the bits. Fragments and take up the bits that you don't like that don't seem to do much. So, my funding comes from NCERIC. This is a bunch of references that I can get later. In fact, I have actual physical reprints for some of these. They were the last ones I ever got. So, this looks a lot like the SR graph that Christian Feinberg familiar. So, do you get injectivity? Yeah. So, do you get injectivity from this? Can you use the same conditions? So, so, yeah, so their method is older, better developers, and they're able to prove a few things we can't prove. And nobody has yet figured out what is anything the relationship is between our two maths. I guess the question really is: can do I need both or can I just use one of these analysis? Yeah, well and in fact there's a there's a really cool website. It doesn't do our methods, but it does a there's actually a whole family of methods based on graph theoretical analyses. There's a real cool website. I can give you a link later if you want. Yeah, and it runs through a whole bunch of these methods and they don't all give exactly the same results, right? We've never done a head-to-head comparison with some of these other methods. It would be interesting to do that. So so remarkably mark, um the is so the theory really depends on the uh on having the polynomial form of the uh of the relationship. You mentioned something about the saturation with the Nicholas Mac. Did I miss something? Yeah, so so what I what I meant there was that if you start to, you can reduce the mechanism, the the graphs in ways that maintain criticality. Criticality. But some of those transformations shift the steady states, for example, and fairly, all of these transformations would change the steady states somewhat, but some of them could have more dramatic effects than others. So for example, if you replace Michaeli's mental kinetics by a bimolecular reaction, well the bimolecular reaction will never saturate, right? No, but I thought you said that that that that that what you developed That that what you developed only works for mass action. There are versions that we talked about in our first paper that are more general, but they're also, how should I put it? They're slightly, the results are slightly less powerful, so unless you happen to hit an example where they work really well, sometimes they're tricky. Some of the CRN stuff from Fine Birds Group has been extended by George Cranzin, I guess. By George Crassian, I guess, to non-mass action stuff. Our stuff, like, we kind of know what extensions would look like, but we haven't really worked them out in detail. I was just wondering whether there's another way in sort of sort of, like, say you have some arbitrary functional relationship, and within some neighborhood of that mapping, you would be able to do like a linear transformation. Like, you could always take, take, take. Like you could always take take take a take a saturation curve, right, and then you just expand it and convert it into like a mass action like approximation. Well exactly. That's what I normally do. So if somebody gives me a model that's not mass action, I figure out what mass action kinetics would give me that functional form if I apply the steady state approximation. And then I work on the mass action system. But it expands the size of the system, which is sometimes. But then you can go back and reduce it. If I find that that interaction is not critical. Find that that interaction is not critical to the