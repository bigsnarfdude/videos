Okay, so now we're going to move on to Alban Bashi, who will be talking about online model error correction for neural networks from Ethereum to ECMWF forecasting system. Thank you. Good morning, everybody. So, I'm a researcher at Ã‰cole des Prompt in Paris, in Marco Kesburg. And today, what I will present to you is It is the result of a collaboration that we have with ECMWF on the topic of model error correction with neural networks. So what I will show in detail is how we can actually train neural networks for that specific task using data simulation and in particular the Fordiva-like construction. So I will start. So I will start this presentation by saying a few words about weak constraint for Devar. So we already had a lot of presentation about that, but just the key ideas. So in WeConstraint4Devar what we are trying to do is to relax the perfect model function and the price to pay for this is that we hugely increase the the problem dimensionality. Dimensionality. But fortunately, this increase in dimensionality can be a bit mitigated if we make some additional assumptions. And for example, we can make the assumption that the model error, so what I write W here, is constant over the data susmension window in such a way that our dynamical models can be written like this. So you have the physical model plus W C constant model. So now So now the cost function depends on two terms. You have the initial state and the model error, the constant model error. And you have three terms. You have the background error term, the model error term, which now depends on the model error covariance matrix. And you have finally the observation error term, which depends on this model, which I call the reconstrain model. So this we constraint. So this weak constraint formulation is called forcing formulation of weak constraint for devar, and this is the weak constraint for devar that is currently implemented at ECMWF. So now moving a bit away from this forcing formulation, I would like to make the assumption that we have a model which is parametrized by a set of parameters, and we assume that these parameters are And we assume that these parameters are still constant across the data estimation. So now we can derive a new cost function which depends on both model parameters and initial state. And you have again three terms, the same background error term, the same observation error term, but it now depends on the parametrized model instead of the reconstructed model. And you have replaced the model error term by the parameter error term. By the parameter error term, which now depends on the parameter error of an vertex. Okay, nothing fancy here, but now if we imagine that our parametrized model has a neural network, then we can define P as the set of weights and biases of this neural network, and therefore we can now estimate Can now estimate these parameters as part of the data assimilation process. So, this approach can be seen as a neural network formulation of reconstrained for divar. Okay, now if we want to merge the two approaches, so we have on one side forcing formulation, on the other side neuroanatomic formulation. So, what we can do actually is we can come back to the assumption that we have. Uh come back to the assumption that we have a constant model error throughout the window, and we can now assume that this constant model error is estimated using a neural network. So in a way, the parametrized model is the sum of the physical model plus the constant model error, which is estimated here using our neural network F. So, in effect, you can rewrite your parametrized model using a Parametrized model using the composition of the weak constraint model and the neural network. And this is actually very important because it means that we will be able to build this simplified neural network formulation on top of what is already existing, and in particular on top of the already implemented weak constraint for Devar in the incremental assimilation framework of ECMWF. So, in this incremental assimilation framework, one of the most important elements is to be able to compute the gradient of the incremental construction. So, let's see how it goes. Okay, so this is a pseudocode that we use in order to compute the gradient of the incremental cost function. So, I won't go too much into details, but what I would like to say is. But what I would like to say is that everything which is in black here is what is already implemented for reconstruction for debar. In particular, you have first the tangent linear loop and then the adjoint loop. And now, if we want to implement our simplified neural network for Debar, we just have these red lines to implement. So we have first the tangent linear of the neural network. Of the neural network, and in the end, the adjoint of the neural network. So, let's make a quick summary. If we want to implement this new, fancy, simplified neural network for Livar, we can actually reuse most of what is already in place for WeConstrain for Livar. And we just have a few building blocks that we need to implement. To implement. So we need, of course, to provide the forward operator of the neural network. We need that in order to compute the non-linear trajectory at the start of each outer iteration. And then we need, for the gradient of the cost function, we need the tangent linear and the adjoint operators of the neural network with respect both to the neural network input and neural network parameters. And this is where it gets a bit tricky because these operators, all of these, they have to be computed in the model core, so where all the components of the state vector are available, and in Woops, the the object-oriented prediction system developed at ECMWF. This model core is implemented in for TAL. So we need a a neural network library Need a neural network library in Fortran with all these operators. And actually, we couldn't find one, which is why, in order to implement our methods, we have chosen to implement our own neural network library in Vortran. So, you can have a look at it. It's open access on our GitHub page, and we provide these functions for feedback. For feed-forward neural networks with fully connected layers, so which are really the most basic neural networks you can come up with. So now, interestingly, we have included this neural network library inside OOPS and we have provided an interface between OOPS and this Fortran neural network library in such a way that, okay. In such a way that, okay, now it's possible we can estimate some neural network parameters in hoops with our neural network for devar method. Okay, so very good. We have this new fancy method. But before we actually use it for operational data estimation, we want to actually illustrate how it performs using. How it performs using low-order models. So, in order to do that, we will rely on what is already existing. So, in particular, we will use the QGI model, which is implemented in groups. So, this is a two-linear, two-dimensional quasi-geostrophic model. In terms of data assimilation, in the control vector, we included all. Uh we included all the values of the stream function psi for both levels, so top level, bottom level. So and we have a discretization of 40 grid points in longitude and 20 grid points in latitude in such a way that we have in our model a total of 1,600 variables. So, what we do is we will do some is we will do some twin experiments. So we will define a reference situation of our QGI model in which we already know the model parameters. And so this will be our true model. And on top of this true model we will define a perturbed setup in which we will actually pertube the model parameters. So in this case we have chosen to perturb the layer depths and we have also chosen to change the And we have also chosen to change the integration time step. So, these modifications result in a model error which is actually non-trivial. And this gives us our, let's say, physical model that we will want to correct with our neural network. So, to illustrate the model, I've provided it here some snapshots. So, the top two So, the top two rows they show the model state. So, you have the string function for the bottom layer, for the top layer. So, longitude, latitude. What we see here is basically that the model dynamics is characterized by a a huge wave which is slowly mo moving towards the west, and you have actually periodic boundary conditions. Actually, periodic boundary condition in the x direction, and the wave is then coming back. And in order to illustrate the effect of our perchop setup, so this is the true model, and the bottom two lines they show the model error. So, this is the instantaneous model error. When you start with this model state, you compute the force. States, you compute the forecast, so in this case, a one-day forecast. You compute the one-day forecast with the true model, the one-day forecast with the perturbed model, and this is showing the difference between the two. And what you see is that there are some patterns which are definitely related to the model states, but they are probably not that obvious. Okay, so we have Okay, so we have our true model, we have our model error, so now we can think of what kind of model error correction we want. By construction, our new method is very similar to parameter estimation in data assimilation. And actually, we know that parameter estimation is really difficult when we have a high number of parameters. When we have a high number of parameters. So that's why we want to use a neural network correction which is as expressive as possible while using as few parameters as possible. So we need a smart architecture. So usually smart architectures mean that we need to inject some prior information to design this architecture. There are a lot There are a lot of examples in the literature, but we have selected a very simple architecture which has been designed a few years ago precisely for model error correction by Massimo and Patrick. And so this is a vertical architecture. By vertical, we mean that what we will feed to the neural network is a vertical column of A vertical column of model variables. So, in our case, so we have two layers, so we will give to the neural network the stream function for the top layer and for the bottom layer. So, two numbers at a given latitude and longitude. We provide additionally latitude and longitude as additional predictors. So, this gives us a total of four input predictors, and we expect the neural network to return Work to return the model error correction for top layer and bottom layer at this specific location, so at this specific latitude and longitude. And now, if we want to recover the full model error correction field, we just have to loop over all possible latitude and longitudes, which is actually very simple with neural network formulation. Um so we have four input uh predictors, two output predictants, and uh we use uh uh uh a very shallow architecture with only two hidden layers and each layer has 16 neurons which gives us a total of 386 parameters. And if you compare this to the total number of variables in the system, so 1600 is we we are we are relatively We are relatively smaller than the number of variables, so we estimate that this could be a performable situation. Sorry. So before we jump directly Before we jump directly into online learning, we would like to first do offline learning. So offline learning here will provide us a baseline that hopefully we will be able to beat. So in our online learning configuration, we will use sparse and noisy observations of the system. So therefore in offline learning we will In offline learning, we want to do the same. We use sparse and noisy observation. We don't have access to the true state. And in order to handle this problem, we combine data assimilation and machine learning, as we have been doing in the past few years. So this is a method which has been designed by Julier Rajard, which has been illustrated later on low-order models and higher-order models. So, effectively, in this So effectively in this method, what we do is we use data assimilation to estimate the state of the system from the sparse and noise observations. And then, once we have computed the analysis, we are able to use machine learning to estimate the neural network parameters from this analysis. So, this is what we represented. We have data assimilation from the observation. From the observation, we estimate the state, and with machine learning, from the state, we estimate the neural network parameters. And we can actually iterate this process in order to increase the accuracy of the analysis and of the neural network estimation. But it turns out that for model error correction, when the neural network is designed to do a model error, Is designed to do a model error correction, not a full model emulation. One loop here in this scheme is already pretty good. So that's a good start. So therefore, in our experiment, we will only stop after one loop in this case. So now, one last thing is that in practice, if you do modeler reproduction, you train the neural analysis. The neural network to target the analysis increments. And in this scheme, the analysis increments are proxy for modeler. Okay, so we are able to do offline learning, and what we will do to evaluate the accuracy of our neural network is we will take the corrective model and we will use it in data assimilation experiments. And we will measure the accuracy of. The accuracy of both the analysis, the first guess, and some long-range errors. So, technically speaking, when we do offline learning, we target the analysis increments, and the analysis increments are actually a proxy for the model error of one window. And in our scheme, what we want to do is we want to correct the model error from what for The model error from one time step. So we need to rescale the error from one window to one time step. And this is actually making the assumption that model error grows linearly over time. So we need to rescale this correction, and once we have done the rescaling, we can use it as a constant for things throughout the window, as we would do with constraint file. With constraint value. So these in this table I report the data assimilation results. So you have the first line is strong constraint for devar with no model error correction. The second line is our AT strong constraint for devar but with the neural network trend offline as model error correction. And for comparison you have weak constraint for devar. And in this table what we see is that We see is that the neural network correction is indeed effective and is able to reduce both the analysis errors and the first guess error compared to strong constraint for error. In particular, you reduce the reduction is most impressive on the first guess error. And now if we look at the long range error, so what we do here is after each analysis cycle, we Analysis cycle, we compute a thirty-two days uh forecast and we measure the accuracy as the forecast footman square error compared to the use. And in blue, you have a same strong constraint for Devar without model error correction. So this is basically the accuracy of our non-corrective model. And then we have in red weak constraint for Devar, which improves especially in the first. Especially in the first few days. And then we have our neural network correction offline in green. And what we see here is that it is really effective because it reduces the focus error up to 10 to 15 days and then the effectiveness starts to detra. Okay, so now we are ready. We have our baseline. We have our baseline and we would like to compare it to online learning using our new neural network for DevAp. So, what we will do is we will start from the set of parameters that we have obtained with offline learning. So, effectively, this means that we use offline learning as a pre-training step for online learning. And remember, we need to provide for the algorithm a background error correction. A background error covariance matrix for the model parameters. So we have actually no idea of what we could do. So we started with a diagonal matrix and we choose a coefficient. We actually tried several coefficients and picked the one that gave the best results. But what I would like to say is that this coefficient is actually very important. Is actually very important because it measures how much information we will transfer about the model parameters from one data estimation window to the next. And in our experiments, we will run a large number of windows, and for each window, we will measure once again first guess, analysis errors, and long-range forecast errors. So there we go with analysis and first-guess errors. So the same colour scheme is applied as previously. So we have in blue strong constraint forever without model error correction. In red weak constraint. In green the neural network trend offline. And now the new neural network variant is in Till. Hopefully it Hopefully it's uh it's well it's good to see. So at the start of the experiment we are actually very close from offline learning. And this is expected because remember we started with the set of parameters that we have obtained via offline learning. Okay, but as new observations become available, so as time evolves, online learning starts to kick in. Learning starts to kick in and start to steadily improve the accuracy of the model, which results in better first guess and analysis errors. So at the end, we have come up with a significant improvement in both analysis and first guess compared to offline training, which is very positive. And now, what we will do in order to measure the accuracy of the forecast is we The accuracy of the forecast is we will take the last 32 days of experiment and we will average the forecast order. And this is what we get here. So the blue, red, and green curves are exactly the same as previously. And now we have added on top of that our new neural network for NIVAR. And what we see is very positive because until day 2. Because until day 12, our model trained online is even more accurate than the model trained offline. So now just a few words about this error increase. So after 12 days, the forecast error increase accelerates a bit and we actually think that this is this is related to the fact that we have a very small neural network. That we have a very small neural network, and our neural network is not able to predict at the same time short-range errors and long-range errors. And actually, if we were to have a more expressive neural network, so this would be more difficult to train, but potentially we would be able to get more accurate both short-range and long-range errors. Okay, so we arrive to the conclusion. So we have developed a new variant of Fordivar, of reconstructed Fordivar, in which we are able to perform a joint online estimation of model state and neural network parameters. So this new method has been built on top of the existing WIC constraint for DIVAR in the incremental estimation framework, and it has been implemented in OOPS. Been implemented in OOPS using a newly developed neural network library in Fortran. We have tested the new method with the QG model. We have seen that it results in more accurate neural network corrections than offline learning. And finally, I would like to say that this method, since it is implemented in Woods, is absolutely compatible with future applications to more realistic products, in particular, the Products, in particular the IFS. And that's what we are doing at the moment. So we have written the interface between the neural network and the IFS, and we are starting to experiment a bit on how this can improve the forecast accuracies. Thank you for your attention. Questions? Thank you, Mimas. It's very interesting. I was wondering, so if what you can do is expand the analysis like via small effort going on at this time? So, yes, it's possible to extend to other systems. Like, I mean, there's Like, I mean, the extension to, for example, the IFS, it's in terms of coding, it's done. We just need to experiment to see how well it performs. And then you mentioned other. Another thing is that you mentioned that you want to improve the forecast. So yes, the goal is to improve the accuracy of the forecast. So we hope that the the neural network is able to predict To predict, let's say the one hour or one day model error. And by correcting this one hour or one day model error, we hope that we are able to make more accurate forecasts. Yeah, I could. I didn't try in this set of experiments. That's absolutely not. That's absolutely human, I guess. So, maybe this question was for both of you, but I'm wondering: okay, so in our kind of atmospheric trace species problems, we might want to estimate the state, and then it's clear to me we have a lot of data about the state, so it's clear to me how something like this would help. But for the fluxes, we have no direct observations. And so, we, you know, it's not clear to me how machine learning techniques, when we have no direct observations, Techniques when you have no direct observational constraints on something, something that's not convolved with transport, in other words. But here we have no direct observations of the model parameters. We don't know what kind of model parameters, what kind of neural network parameters could be good or not. And still, we are able to derive, to come up with some parameters that, in a way, improve the accuracy. Improve the accuracy of the model. So we can say these models, these parameters are the estimation is good. Can we? I don't know. I think this is all very intriguing and I'm looking for something I can use and might have problems. But maybe we can talk about it in the discussion. Yes, sure. Oh, then I have a question from online. Okay, go ahead and quickly. Yeah. Great. I'll have a really nice. Great. Alvin, a really nice presentation. It's great to see. And I have a question about the adjoint and tangent linear of your neural network. I know we've worked a little bit with you all at Isa and Video on this and also similarly created adjoints and TLMs of the neural network for a different part of a CTM. And that worked fine. TLM and adjoint sensitivities match each other, numerical precision. But then when we compare the sensitivities to our Compare listen to these to our actual adjoint of the physics and chemistry component that we were trying to describe, there was basically no correlation. And so I'm curious if you check the sensitivities that you get out of your neural network and if you have any kind of similar issues in terms of these just being sort of numerical derivatives that are hard to sort of explain in a physical way. Physical way. It reminds me a little bit of when we were sort of deriving adjuncts of numerical invection schemes. And you could derive the precise adjunct, but as Adrian's group showed, it would lead to sort of physically meaningless activities that would cause problems with our 45 systems. So do I understand well that what you are trying to do is use a neural network to build an emulator of your system in such a way that you can use the Your system in such a way that you get the adjoint for free? Am I correct? That's potentially a goal, yeah. And so just, yeah, you know, having built a neural network, having taken the adjunct of that or a component for which we actually already have the adjunct, but just as a point of comparison, trying to understand the adjunct of a neural network, what is that? Adjunct of a neural network, what do those sensitivities mean? And can we just swap out those listening views for the adjunct of the physics-based model or an architect, the chemistry-based model? To do that, just seems like it's going to take some more research, some ideas, but I'm curious what your ideas would be about this. Yeah, so here I would say the approach is different because we do not use the neural network. We do not use the neural network as an emulator of the full model, but rather an emulator of part of the model. And the adjoint of the neural network is used precisely to train it, to be able to derive good parameters, parameters that will be able to make the model predict the model error. And so, of course, the whole method is built on the assumption that we already have an adjoint for the physical model. We are not trying to replace this adjoint. But yeah, perhaps in the future trying to emulate the Emulate to make a full Shoregate model and use this zero gate model to have the objoint. Perhaps it would be also possible. I don't know. Does that answer your question? I guess or maybe just rephrases the question. Yeah, I mean, perhaps open area research to what extent we To what extent we can use the derivative bits of the neural network. Apparently it's working for you and this application, so anyway, thanks. Hey, yeah, one quick question. It's actually a really quick one. On your slide 13, I noticed that the confusion neurons is the steep huggers. And I was wondering if anybody if that would make sense to walk back or something like that. Or something like that? Yeah, so actually, in previous experiments with the Lorentz system, what we have done is we have progressively decreased this P, because this P essentially tells you how accurate your model parameters are. So at the start of the experiment, you expect your model parameters to be not very accurate. So you would like a large P, and then when you have run a sufficient number of windows, you are Of Windows, you are more confident about your other parameters, so you would like to decrease the value of the peak. So that makes perfect sense, but also I don't know exactly what your parameters are, but does it make sense to use them? It could make sense, but how would you decide about these different parameters? Well, I also wanna and just see that article makes sense to estimate directly from what you want to propagate. So what you want to propagate and analyze in your location or you could both get the info. But l l so each parameter corresponds to here in a row in this in this graph. Oh I see, I see. I wouldn't know how to weight, for example, this parameter compared to this one. You know what I mean? I understand what you say. I'm just wondering if that's something you could gain inside the low-loop. Possibly. Okay, all right, thank you. I have two very good questions. One, um, how many outer loops did you run? Um, so for this model, uh, it's three outer loops. Three outer loops. And did you change the resolution in those outer loops or did they start? No, no, no. It's, you know, it's uh just a QG model, uh, very low resolution already, so uh I didn't uh need to to change the resolution. And yeah, that stability that they vote for and some it goes. You don't reduce the error, but you have like an equally. So the the in this regime, right? Yeah, yeah, but I need to explain what happens here to explain. In this regime, you are in a good regime because you decrease the error, and since you decrease the error, you are better and better and better. But the thing is that when you arrive here, you start to have. Here, you start to have, let's say, an RMS of three. So, you are pretty far away from the actual true state. So, your model error estimation assumes that you are somewhere closer on the attractor. So, the model error estimate is clearly wrong. And in this case, it's making things worse. So, if you wanted to derive an optimal correction, Derive an optimal correction. So you should here you should switch off the correction. Yes. All right. So just have a quick announcement. Today we finish at 11.30 so people can catch the bus on a reasonable amount of time. And tomorrow Amount of time and tomorrow, uh, before uh coffee break, then we'll read the machine learning discussion.