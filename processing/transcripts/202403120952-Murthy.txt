Seminar. Okay, so this is the sales pitch for Massive Random Access. I think this has been repeated several times, so I'll just skip this slide. But the only one small point I want to say is that unlike what Bay said in his talk, in this talk I'll focus on grant-free random access and not worry about scheduled access-related issues. And of course, the challenges include detecting which users. Include detecting which users are active, estimating the channels. And unfortunately, Wade stole my punchline already. That among these two, one of the points I wanted to make in this talk was that the user activity detection is actually a simpler problem. And the real challenge is estimating the challenge from the active users, which is actually required for detecting or decoding the data correctly. The other thing is that because you have Is that because you have a massive number of users, you cannot assign orthogonal pilot sequences to every user, so you have to use non-orthogonal pilots, which leads to the pilot contamination problem. And then there are several special cases that one can consider. For example, reusing a small set of orthogonal pilots among the users, or using quasi-orthogonal pilots, well-designed pilots that have low cross-correlation properties, or a simpler thing to do is to just randomly choose. Simpler thing to do is to just randomly choose pilex from some cost function. There is a multi-user interference, and then one has all these other practical aspects that one has to deal with in these kinds of problems. Okay, so the protocol that I'll focus on in this presentation is Irregular Repetitions Lot at Aloha. And it's a very well-studied protocol, and some of the people who've written some of the Some of the people who've written some of the seminal papers on this topic are here in the audience today. But for the purposes of setting the stage for this presentation, let me just say how this protocol works very briefly. It works very much like the slotted Aloha protocol, except that users, let me see if this works. Yes. So users, when they have data to transmit, instead of transmitting their packet in one slot, randomly. Their packet in one slot, randomly chosen slot, they will transmit multiple copies of their packets in several randomly chosen slots. Also, the number of replicas they choose to transmit can be random. And so, they choose a random number of repetitions, and then they choose a set of slots uniformly at random among the available slots. And then they transmit replicas of their packet. So, in this cartoon example, there are four users and three slots in the frame, and user one has chosen to. And user 1 has chosen to transmit in slots 1 and 2, user 2 in slots 1 and 3, and so on. And this at the base station, you have to decode via successive interference cancellation. So for instance, in slot 3, only this user is transmitted, so you can decode this user's data. And if there are various ways to do it, for example, if the header of the packet tells you which other slots this user has transmitted the packet in, you can go. Transmitted bracket in, you can go and remove interference from that slot from this transmission. Or if these users are choosing their random slots from a particular seed and that seed is known at the base station, then the base station does know which slots the users would attempt packets in. And so it would know that this is the slot where it has to cancel interference. And after canceling interference, it can go back and look and see if you can decode additional users in a slot. Additional users in a slot. And further, if let's say user three happens to be much closer to the base station than user one, then in a slot two, for example, you could end up capturing this user's packet even though there's a collision. And then you can perform successive interference cancellation to remove interference from slot 2 itself, then decode user 1, then remove interference, and eventually decode user 4. So, in this cartoon example, 4 users got decoded in three slots. But overall, the primary motivation for considering a protocol like this is from this paper here, which shows that, at least asymptotically, as the number of users and slots go to infinity, if you use a soliton distribution to draw the number of repetitions and choose slots uniformly at random, then this IRSA protocol can achieve a throughput of one packet per slot, which is the same as the throughput. Slot, which is the same as the throughput you would get if you could perfectly coordinate the transmissions from the users. In fact, when you have multiple antennas at the base station, you can do much better than one packet per slot, and we'll see that. Okay, so this is the model. So you have M users and when we talk about user activity detection, only a small subset of this M users are going to be active. And there are T resource. And there are T resource blocks. It's a slightly general way of saying that there are T slots, but if you like in your mind, you can think of it as capital T slots per frame. And the base station is equipped with N antennas. And so the users transmit a tau-length pilot followed by its data. And the user's activities can be represented or captured by an axis pattern matrix G, which is of size T by M, and T is again the number of. m and t is again the number of slots and m is the number of users. So if the ijth entry of this matrix is 1, it means that the jth user has chosen to transmit in the ith slot. So if you write out what the received pilot signal is, then it has this form where you have the activity coefficient and then you have the access coefficient, you have the channel and you have the pilot from the user. And these pilots are very And these pilots are vectors of length Ï„. And followed by this, there will be a data transmission phase where the data signal can be written like this. And the channel itself is composed of the path loss part and the fading part. So, if you look at a single slot, then the user activity detection, as Wei mentioned in the slot, is going to be in a Mentioned in the slot is going to be in his talk, is going to be a sparse recovery problem with the additional structure of row sparsity. What is the observations? These are the pilot observations. It is the size tau, which is the length of the pilot, by n, which is the number of receive antennas. And so, if a user is active, then you will receive transmissions on all the receive antennas from that user, and these are the channel coefficients of that user. These are the channel coefficients of that user across the entities. And so this is a joint sparse recovery problem. And there are many algorithms in the compressed sensing literature which solve this problem, which are very powerful in terms of being able to solve this problem. In particular, for this talk, I'll focus on a particular algorithm which is Which is called sparse Bayesian learning. In general, I would say the sparse Bayesian learning algorithm in terms of performance is similar to the ML approach that Way talked about as well as an AMP-based approach. But from our point of view, certain analysis can be done using the sparse Bayesian learning approach, which sort of makes it a little more attractive. But otherwise the performance is similar. Okay, so now the question or the question which is which I have one question I want to consider is how do you choose the pilot length. So the pilot length again affects the number of rows of this observations that you get here and the number of columns depend on the number of antimons. So in fact you can't really change So, in fact, you can't really choose the pilot length independently of the number of antennas. If you have more antennas, you can imagine that you can potentially make do with a shorter pilot length. And so, again, the model is you have an observation y, which is of size tau by n, and you have a pilot matrix, which is of size tau by m. m is the total number of users, and x is a matrix which contains the channel coefficients of the users. The channel coefficients of the users. Unfortunately, these tau, n, m, etc., are different from the letters that we used in his talk, so you'll have to follow my notation people. Okay, now one sufficient condition from this paper here is that tau just needs to be of the order k log m over k and this can give you vanishing support recovery error as m, the number of users, goes to infinity, as long as n is much bigger than log m divided by log log m. Than log m divided by log log m. So practically, this translates to choosing tau to be of the order k log m over k. So the pilot length should be of the order of the number of users, number of active users. So another result which we showed in this paper here is that there are actually a continuum, there are a variety of possibilities because you have two degrees of freedom here: the pilot length as well as the number of. Here, the pilot length as well as the number of antennas. And so, at one extreme, if you have tau to be of the order of the number of active users, then you need n, the number of antennas, to be of this order here. And notice that it scales as m log m over k. And if you have, you can also make do with tau of the order square root of k log m. So, this is the same scaling as what We was referring to in his talk. As what Wei was referring to in his talk. But you need a much larger number of antennas, which is the square root of k factor extra number of antennas required for successful geter. So unlike other results, we have a characterization of not only the pilot length needed, but also the number of antennas you need to achieve a small probability of error in support recovery. Now, in the context of IRSA, the structure of this matrix X is slightly different. What happens is that users are selecting a small number of slots to transmit their replicas and only a small number of users are active. And because of that, there is a sort of double sparsity structure in this activity pattern matrix G. And in terms of the matrix X, it translates. Matrix X, it translates to a sparsity structure that looks like this, where user 1 has only chosen to transmit, has chosen to transmit on this, this, and this slot. And so those coefficients are active. Whereas in the slots where the user has not chosen to transmit, the entries of x are 0. So it's not that the whole row is active versus the whole row is inactive, but rather the row is active. The row is active, but not all columns in the row are non-zero, and which columns are non-zero depends on which are the slots in which the user has chosen to transmit. And so one can actually extend this sparse Bayesian learning framework to handle this kind of a structure in your matrix that you're trying to recover and then recover the activity coefficients. I'm not presenting details here in the interest of time, but the extension is actually pretty simple. Extension is actually pretty simple. And the interesting thing is, you see the cost function here, which is exactly in line with the cost function you saw in the previous two talks, which is the cost function to be this is the log of the likelihood. So you want to maximize this cost function. This optimization problem does not admit a closed form solution. So you can use the EM algorithm to iteratively find the map estimate. Find the map as heat. And our modification to the multiple measurement vectors pass Bayesian learning is basically an algorithm that is specifically tuned to perform user activity detection when IRSA protocol is used for transmissions. One question. So in your model, uh you assume uh the log fielding coefficient to be the same across the the copies or uh it's going to be dependent on the copies? So, yeah, it's independent across the copies. They're all different. So, that's why we think of it as resource blocks so that they could even be at other frequencies, etc. The copies could be transmitted in other sets of sub-carriers. And there are much faster versions of these algorithms, including these algorithms. These algorithms, as well as the competing algorithms like ML or AMP, and those can also be used for the same extension can be applied to those versions also. Okay, so just some simple numerical results to show how the false positive and false negative rate vary for some typical settings. So, here consider a frame which Consider a frame which consists of 50 slots with 1500 users and 1% of the users being active. And the base station is equipped with 4 antennas. And what you see here is that if you have, let's say, pilots of length 15, then you can have near perfect user activity detection. And this 15, you should compare it with, so there are 1500 active, say 1500. 1500 active, say 1500 users. So, if you wanted to assign orthogonal pilots to all the 1500 users, you would have to use 1500 length pilots. Obviously, that's way too much. And if you consider that 1% of the users are active, then on average, 150 users are active in a frame. And if you wanted to if you could magically figure out that these are the one hundred fifty users who will be active and design orthogonal pilots to them, you would still need a pilot of length one hundred fifty. Need a pilot of length 150. Whereas here, we see that even with just 115-length pilot, you can achieve very good user activity detection performance. The other thing I'll say is that these other algorithms that are compared against are actually not algorithms that have been designed for IRSA as a protocol. And so they just do slot-by-slot detection. And if a user is detected as being active in any slot, then you declare the user as being active. And you declare the user as being active. So these are really very suboptimal algorithms for this problem, and so the performance is, of course, poor. Now, so what this slide shows is that there are effects like what happens as you increase the load. So the load here is the ratio of the number of users to the number of slots. Actually, the number of active users. Actually, the number of active users to the number of slots. So, if you have 50 slots, then at a load of 3, there would be 150 active users transmitting. And this is with 16 antennas at the base station. And what you see is basically that as the load increases, you will need to use a longer pilot length to achieve a certain desired false negative rate performance. And similarly, here, And similarly, here this is showing the result as a function of the number of antennas. And so, as the load increases, if you increase the number of antennas, then at a very high load, you cannot really lower the false negative rate unless you go to extremely high number of antennas. Whereas, so at least in the in practice, I would say increasing pilot length. I would say increasing pilot length is perhaps easier to achieve low false negative rates compared to increasing the number of atoms. And overall, you don't need very long pilot lengths. So for these kinds of settings, if you use a conventional compressed sensing algorithm, then if you have k active users, so again in this context, you have 150 active users, and if you compute k log 1500 divided by 150, that will come to about Divided by 150, that will come to about 350. So a conventional compressed sensing algorithm would require pilots of length 350 for low false alarm rate or false negative rate performance. Whereas with these modifications to the SPL, you can make do with pilot lens of the order of maybe 20 years. And then there's a question of how does the choice of pilot sequence? How does the choice of pilot sequences affect the performance? And we've experimented with different choices of pilot sequences. The ZOFCU, the DFTs, the Hadamard, these are orthogonal pilot reuse type of sequences. So they're pilot sequences of a certain length and users just pick one of those sequences at random. And the takeaway from this is that different Takeaway from this is that different pilot sequences actually give the same or similar user activity detection performance. However, if you look at the throughput, the Hadamard pilots as well as the DFT pilots actually offer poorer throughput than the ZOF-2 pilots or the BPSK random pilots, Gaussian pilots, etc. And also notice that we are now in the regime where the load is. We are now in the regime where the load is two or more, and so the throughput is also more than two. So you are achieving more than one packet per slot, is the throughput is 2, 2 or 2.2 packets per slot. And this kind of ties in back with Vay's point about between user activity detection and channel estimation, it's the channel estimation that really limits the performance. Because when you use orthogonal pilots, Orthogonal pilots, then if two users select the same pilot sequence, then there is kind of 100% pilot contamination. And so that leads to larger channel estimation errors and therefore poorer throughput. Whereas if you were to use random pilots, then you can actually achieve much better throughput for the same pilot length. Okay, so then uh the the other thing is that uh And the other thing is that for the specific case of IRSA, if you want to look at how the pilot lens scales, as I mentioned, there's actually a double sparsity structure here. First of all, out of the M users, only MA users are active. And second of all, when a user is active, they're not transmitting in all slots. They're choosing a subset of slots and transmitting in those. And so if you pick a particular slot, only L times D. only L times d bar users collide on average, where d bar is the average repetition factor of a given user. And so if you take that into account, what we find is that under some typical settings, your pilot length of order 30 is sufficient and that agrees with the simulation results that we obtain. So I wasn't sure how long it would take, so I'm a little bit ahead of time. But so, this is my last slide. And so, there are what I've shown to you is basically a user activity detection algorithm and its performance, and some of the key trade-offs involved, such as the number of antennas, the load, that is, how many users are active, how many users are present, the activity. Users are present, the activity factor, etc. There are many interesting directions such as accounting for the short packet communications or handling time and frequency synchronization errors when these users are transmitting to the base station. They're not going to be perfectly time and frequency synchronized. One may be interested in throughput in other metrics such as energy efficiency or latency or age of information besides. Information besides the throughput itself. So we have some work in these directions also. And power control at the users and how that can be used to improve the performance. And of course you could have multiple antennas at the user's side also. And in that case, one can use that to further improve the performance. And finally, about support recovery-related issues, there is another talk from my former student who's currently a postdoc in Cindy's group. Postdoc in Cindy's group. She will talk at four o'clock at two o'clock today. So you'll hear more about that in that. Okay, thank you very much.