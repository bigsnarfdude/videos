All right, so let's get started. So, welcome back to the hybrid thematic program on modeling and theory and population biology. And this is a program of the Banff International Research Station. And over the next five months, we'll be bringing you a variety of online events in the area of modeling and theory and population biology. Population biology. And today's event is staffed by Jake Pasaki from Banford International Research Station. And please send him a note in case of any technical problems. A couple of quick reminders on the slide of our mailing list, upcoming website, events for up in the website for upcoming events. And I just wanted to And I just wanted to draw everyone's attention to our next event, which will be in two weeks on the 30th, where we'll have a career panel to discuss strategies and challenges involving job searches and careers in math, statistics, and physics departments. And coming up a bit later in our five-month program, we'll have a similar panel focused on biology departments. So, about today's talk, with Today's talk. Within our five-month program, we're planning to include a series of talks focused around the theme of applications of mathematical population biology, where mathematical models and theory have been important on societal problems, and particularly where members of our community have worked on these problems together with people outside the immediate scientific community. We heard a bit. We heard a bit last week from Tanya Stadler about her work on COVID modeling and some of her efforts involving the government of Switzerland. Of course, epidemic models are only one of many areas where there's an intersection of population models and society. And that brings me to today's area, which is forensic population genetics. Of course, another really significant Course, another really significant area where a background from mathematical models of populations has a major role to play in a significant societal problem. So today's speaker, Bruce Weir, has had a distinguished career in population genetics and statistics, but he's also been involved with the intersection of population genetics and forensic. And forensic genetics, really, since the very beginning of forensic genetics as a field, you know, first emerging in the 1980s and getting to be more commonly used and standardized during the 1990s. And Bruce has served on many different advisory panels for forensic genetics, both thinking about problems involving unidentified human remains as well as forensic genetics in the criminal justice. As forensic genetics in the criminal justice setting. And he's been recognized for this work both within the population genetics and statistics communities as well as within the forensic science community. And he's, for example, been elected as a fellow of the American Academy of Forensic Sciences. So today, Bruce is going to tell us about his work in forensic population genetics. So, welcome, Bruce. So welcome, Bruce. Thank you, Nah. Okay, so you need to share my screen. And there it goes, I think. No, excuse me. Wrong slide. How do I get out of this? Stop sharing. Share it again. And I need to view it. It looks good. Yep. No, it doesn't look good. All right, so thank you, Noah, and um apologies in advance for not having enough time to cover your own recent work of very nice stuff on linking forensic and non forensic databases. And non-forensic databases. So, this is meant to be a personal romp through the interesting world of law and science. And I hope I do better today than I did in Los Angeles three years ago. The LA Times was not particularly kind to me describing my talk on that occasion. So, here's another report in the public domain. Maybe not dry sand, President. And President Clinton left some DNA on a dress, which got him into some trouble. And there were some numbers attached to the statement, and those numbers are certainly difficult to believe. And we're going to explore where numbers come from. So not as dry as sand, maybe, but I'm not sure this particular segment was digested. So here's a recent case that I was involved in from Arizona. From Arizona, it was a homicide involving a death by gunshot. The DNA profile from a stun a swab taken from a trigger of a gun is a mixture. And one of the components of that mixture matched the DNA profile of a person of interest who turned out to be the defendant in a trial. And along with that statement came a numerical statement. The approximate incidence of this profile is one in a trillion Caucasians. One in a trillion Caucasians and so forth. And where do those numbers come from, and do they even make any sense? They sort of belong our normal way of thinking. So let's dive into that. This profile issue was a nine locus microsatellite or short tandem repeat profile taken from the trigger and person of interest. Each of the loci has two alleles. These numbers are just designations. Basically, Adjust designations, basically the number of repeat units for the Macro satellite with occasional notational indications of some of the repeat units being incomplete. So that's the data. What do we know about that profile? So these are the data. This is the database used by the forensic agency in that case, where they had profiles, a few hundred profiles from different self-identified groups with somewhat unfortunate labels. Groups with somewhat unfortunate labels, so they would agree. I don't think I like any of these headings: Caucasian, African, American, Southwest, Hispanic, Navajo, and Apache. So I'm not sure what they mean. Anyway, here they are, sets of people, and amongst those people, the frequency of the alleles in that profile hovered around 10-20%, something like that. And if you simply multiplied together a column of A column of 20 numbers of that order, you're going to get a small number. So that's not complicated. Problems with that, the first one being certainly the alleles can't be independent as they're not. What about that a single locus? That's to make the problem easier. So, this is an old problem. We call it the Hardy-Wander theory. And Eric Landon looked at this in one of the first cases to challenge the NA evidence. Cases to challenge the NA evidence, the case-story case in New York. And Eric said to justify applying our classic formulas, the Hispanic population in that case must be in Hardy-Weimberg equilibrium. And he conducted a test and said one finds spectacular deviations from Hardy-Weinberg. That's a very strong statement. It's somewhat surprising. It goes against what we typically find in samples of humans. We don't find many. Of humans, we don't find many spectacular deviations. So, this was interesting. Turned out, of course, that it may be the fact that in that particular typing system, heterozygotes are best classified as homozygous. Now, coming forward a few years, I was giving testimony in a homicide in Denver, and the prosecutor asked me about how they equilibrium. I did as best I could, and he said, Well, what did you do about it? Could and he said, Well, what did you do about it? And the data you used. I said, Well, I used Fischer's exact test for Hardy-White equilibrium. Immediate objection from the defense. They said that was essay. And if the prosecution wants to talk about Fisher's test, they need to bring Mr. Fisher to the stand. It became very clear to me that I was wasting my time discussing how do you want to get equality or indeed anything in a courtroom. So I put my excursion into the law on hold. Excursion onto the law on hold for a few years. So still got large numbers or very small numbers, and there's been several reports of the effects of increasing the number of loci in a profile. The FBI started using 13 and that's increased. Typically, it's 20 now, but there are more, of course, many more microsatellite markers they could have used. And these people just give a little table showing the consequences. The consequences by their methods of increasing the number of loci. And these are what they call the expected match probability. These are just numbers obtained by multiplying together 26 or 30 or 40 alleles. And they do indeed get smaller. The implication of these authors is that more is better, the more loci will give stronger evidence, making a coincidental match. A coincidental match less likely. And these numbers are indeed getting quite beyond their user experience. Their paper and that observation doesn't quite match with what Peter Darnelly reminded us a long time ago. After observing matches of some loci, it's relatively more likely that the individuals involved are related. See, they share DNA profiles, in which case, match is observed at. In which case, matches observed at subsequent noci will be less surprising. That is, knowing with knowledge of matches of some loci will increase the chances at subsequent noci in contrast to the independence assumption. So that's an obvious statement. We know it. We've done a lot of theoretical work bolstering that loci are not independent, even if they're in linkage equilibrium and unlinked. That does not guarantee independence of Independence of genotype frequencies. We've published that many times to no avail. So we're resorting now to do numerical demonstrations. And here's a paper. We've shown this plot actually in other meetings, but it's a paper currently under review in the field. And on the x-axis, we've just simply reported the proportion of pairs of profiles that match, meaning. Match, meaning all the alleles of the profile match. And this is just for the two loci on the y-axis. We've taken the product of the single locus proportions. And they lie pretty much on the straight line, which is, of course, the reason why tests for linkage dissectilibrium fail to find any. Three locus matches still pretty close to the straight line, but then by the time we get to four, and certainly by five, Get to four, and certainly by five, we're seeing the observed and expected proportions beginning to depart. These points lie mainly below the line of equality, meaning that the actual or the observed matching proportions are bigger than we would predict by multiplying single locus proportions. So that's an uncomfortable observation, completely expected, completely ignored at the moment, I think, by the forensic community. But it's a Forensic humanity, but it's a fact we have to look. So, what can we do better? Can population genetics help us, as we would certainly hope? And some work going back a long way now, David Bolding and Richard Nichols published a nice paper, and they borrowed the language appropriately of forensic science at that time, saying that if you're going to address a problem of evidence, you should have competing hypotheses. Competing hypotheses, just as there are competing stories in a courtroom. One of them, that the person of interest is the source, for example, of the DNA and the crime scene. The defense hypothesis would be the opposite. The POI is not the source. And then there's some evidence, typically the profiles from the crime scene and from the person of interest. And it's standard practice to take a ratio of the two evidence probability. The two evidence probabilities. And providing the testing, the typing technology is good and some other slightly weak assumptions, we can replace this likelihood ratio by the reciprocal of the conditional probability. What's the chance that unknown person, person who actually committed the crime under H2, given that we're seeing that these person of interest has their profile? So we would call this the matching probability. Matching probability, and that's our term. Now, at the time of the Simpson case, 1994, US forensic agencies were using only the random man, not excluded, for mixtures. And they said this, they do that because it was easy to understand, and a jury would be able to understand. And they, as the court, they cited, they cited a report when they They cited a report from the National Research Council of the US National Academy of Sciences saying that if a suspect pattern is found within a mixture, it's appropriate to assign a match frequency as the sum of the frequencies of all the genotypes that are contained within the mixture. So that sounds easy. It's completely worthless. It says nothing about those hypotheses, about the reason people are in court. It doesn't take into account the It doesn't take into account the complete set of profiles. It certainly does not address mixtures. So I was asked to help the prosecution in the Simpson case by saying, in fact, there is an alternative to using the RMNE. And that was a novel thought at that time in the US. And there had to be a hearing, an admissibility hearing, to see if the Here he could see if the prosecution was allowed to present something better. So, one of the defense attorneys, William Thompson from UC Irvine, said a couple of months earlier, before the trial, in a chapter in the volume that I edited, as it turned out, he said, let's beginning of his paper, he said, let's consider competing hypotheses for a DNA case. And for his paper, he said, let's consider our belief and how these hypotheses. Our belief and how these hypotheses are affected by the evidence. So that's my stuff. He must have forgotten he had written that because during the admissibility hearing, he objected to my testimony saying Dr. Ware has a tendency to slip into the language of likely diggers, and we certainly object to any such testimony. At that time, I was relying on work from my colleague Ian Evatt. My colleague Ian Abbott, a United Kingdom forensic scientist, who had published a paper detailing exactly how to approach mixed DNA profiles using setting up likelihood ratios. And it was a nice look, 1991, four years before the trial. At the end of the hearing, the judge said he allowed the prosecution to present likelihood ratios. Likelihood ratios. Looking back at the testimony of myself and the defence expert Dr. Shields, I find the analysis offered by Dr. We is more accurate and closest to what the evidence truly presents. So under those restrictions, I'll allow testimony at trial. So the prosecution won that battle. Of course, they didn't win the war. So in a way, it was sort of a perfect victory. So moving forward to the trial where I was on the stand. Trial where I was on the stand to talk about likelihood relationships and mixes. And one of the defense attorneys, Peter Newfield, got a bit agitated. He said, the question, sir, I would like you to calculate the percentage of the population that cannot be excluded as contributing to this mixture. Okay? That's a very different question than the question you answered to the jury. That's a question I would like you to answer. Of course, he would, because those numbers. Course, he would because those numbers were quite different from the prosecution's numbers. They were helpful to the defence, and the defense was not allowed to present any numbers in that trial. So they wanted the prosecution to give their case. I said I'm very uncomfortable doing that because I don't think it's really a naughty statement and probably not very helpful. Anyway, there was some backwards and forwards, and in the end, I answered the question. And in the end, I answered the question. Peter Newfield was sanctioned by the judge for raising his voice. Random man, not excluded numbers were given in the trial, and in fact they're still used today. Although luckily, they are gradually being replaced not by any effort from statisticians such as myself, but by increasing use of some software based on something called probabilistic genotype. On to something called probabilistic genotyping, which in fact has likelihood ratios at its heart. So maybe with the tide is turning. So back to the David Balding work, having described likelihood ratios and so forth, went a bit further and assumed that allele frequencies in a population, if he assumed that they follow the beta distribution with parameters. Distribution with parameters depending on the allele probability, and a parameter I'm writing as theta, and he called it FST at that time, then these match probabilities could be formulated. Just simple moment calculations for the beta distribution. Not complicated, but it has a very nice effect that the conditional probability of the genotype homozygous or heterozygote is bigger than the unconditional probability. The unconditional probability. So the more you see, the more likely you are to see it in the future. And you can build up quite nice equations to handle complex situations. So these thetas, it's convenient to think about them as IBD probabilities for random pairs of alleles. Of course, behind the beta distribution, going back to Silwritz work, there are some assumptions, typically drift mutation equilibrium and random mating. And random mating. But it was a very nice result, and it turned out to be very useful. We've looked at the consequences of applying that in the multi-locus situation. We don't have sensible 20-locus versions of FST. So what is done in practice, which is helpful, is to use the Boolean-Nichols equations, the so-called theta correction for each locus, and then multiplying. Each locus, and then multiplying those single locus probabilities. So that's not correct, of course, and it's very conservative. So, here on the bottom line, the x-axis, we've got observed proportions of matching at five loci. And on the x-axis, we've got the products of these theta-corrected single-locus values. And as the colour changes, so does the value of theta. So, certainly for the Of theta. So certainly for theta zero, we've got a lot of points. In fact, the theta is zero. Forgetting this correction, the line of equality pretty much splits the observed and expected values equally. But as theta increases, the expected values become conservatively smaller than the observed proportions. And it would be certainly conservative, helpful to a defence to use of values the Use of value establishment. So that's what's done. I don't think we've finished thinking about that, and certainly we could use help with other people thinking about the issue. I think if there's much debate going on at the moment, it's on why chromosome data, why chromosome is used on occasion, it's sort of an adjunct evidence, particularly for sexual assault. Interesting, in California, a Y-profile match has to be shown. Profile match has to be shown before courts will allow familial searching, search of a database for a relative of the person who left the DNA evidence. Anyway, so why chromosome data is used on occasion? So here's a case from Alaska that I was giving some advice on. It was a DNA profile, and this sample was a mixture. And the lab thought they could separate minor and minor contributors to the mixture. To the mixer, and they said the minor profile matched the profile from the person who was defendant in the case. And there's the number, as is required by courts, the DNA matches about 4,000 times more likely if the defendant or relative, male relative is the contributor than if a random man is. So that's obviously not a trillion, much weaker evidence, but certainly that statement as it stands is fine. As it stands, it is fine. There was another case, another sample of evidence in the same case with the same conclusion. This was another, another, it was a single locus item of evidence, and the same matching was found, the same profile, and also matching the profile of the defendant. So, what are those two profiles? The two items of evidence: 22, Y Prime Zone, microsatellites, here's the person of interest. Here's the person of interest. He matches where he can, as is always almost always the case. Actual evidence profiles are not complete. There's all kinds of things can go wrong. Degradation, for example, and alleles, some alleles were not tight. So there was indeed a pretty good match where possible. Interestingly enough, the prosecutor had access to a native Alaskan database. A native Alaskan database, and there was a profile in that database which almost matched the person of interest, except for one local, probably relatively recent male relative. So what's the big difference? What's the problem? Autosomal profiles have been interpreted as though the alleles were independent, which they're not. White chromosome profiles assume the alleles are deep. But I was assuming here there was a dependent which there might be that mutation we think does act independently. So it's sort of odd because we've got no recombination. We've won rudible evidence for linkages to sequilibrium between pairs of Y permission. Anyway, so we have a matching required, the prosecution is required to give a number. So the simplest way The simplest way, the naive way, is to say, Well, how often does that type occur? Will we look for it? So, let's take a sample of men, type them, and see how many of those men match the evidence. The answer is almost always zero. I was with you like this why chromosome match is not a very common event. So, one way, one simple way is just to say, well, I saw zero, how big could the frequency be in the population? The frequency B in the population, and I got as I giggled as zero. And for confidence, it's about three over the sample size. Nothing to do with genetics, of course, in this number, nothing to do with the number of loci, really. So it's not satisfactory, but it's the preferred way currently for attacking addressing why data. Ignoring population genetics. Nor in population genetics. So the US used to maintain its own database, the USYSDR database, no longer, there's no longer funding for that. So the US depends on the European database, YHRD, a very large database maintained by some German scientists who do a very nice job of assuring quality of profiles that they accept into the database. And there's a little description you can find. And there's a little description you can find about it in Wikipedia. It has 350,000 profiles and 100,000 of the most commonly used commercial typing kit. They claim to be open access. Of course, they're not. You can certainly go to their website and type in a profile and get an answer, but you can't get the data. And that's a result of European privacy laws. So I typed in the profile in that Alaska case. Here are the 22 loci, here are the alleles. And using 100,000 or 93,000 profiles in the database, there was no matches. And they gave a confidence limit. So if they don't occur in the whole database, they certainly won't occur in a subset of the database, which includes US profiles, and they certainly don't occur within any. Certainly, don't occur in any subset of US data which have these unfortunate quotes labels on them. So the profile doesn't exist in the data set. So what can we do, going back to the Baldy Nichols idea of bringing in an IBD probability, we know what those values would look like roughly for random aging populations and the drift in mutation. And the drift in mutation. For stepwise mutation, Ozera and Kamura gave a formula a long time ago. It has the same flavors as our typical one over one plus four NU, but N is the number, in this case, of Y chromosomes, and U is the haplotype mutation rate. The point is that as we get more loci in the profile, there's a more opportunity for mutation, so the mutation rate goes up. The mutation rate goes up, so theta will go down. So the probability of a match will go down with more loci, as we would expect. Formalizing that, this is a very standard equation. What's the chance of two profiles being the same type? They depend on the probability pi of one of them being of that type, and then this parameter, which we can think about as being an IBD probability or. I B D probability or it could be a correlation going back to Silver Rhine's work. And if you just divide by pi, you get the match probability, which is theta plus some other term. This is, of course, bigger than the chance of seeing it a second time is bigger than the chance of seeing it the first time. But maybe more interestingly, this probability, this match is bigger than theta. So maybe theta gives in itself, even for pi gets very, very small. Even the pi gets very, very small, thesis giving us some guidance on what's the chance of a coincidental match. And so there's two problems with that equation. It's two parameters that we know network of them. So we don't know the probability of a profile being of the type. And these are our profile user probabilities. And in particular, we don't have a good way of estimating price. Have a good way of estimating pi squared. We can estimate pi by taking a sample, but to estimate pi squared, we need an estimation of variance. We don't know pi and we don't know theta. We can get some guidance, so we've been resting on some of the recent work with Jaron Goudet, where we have revisited the problem of estimating FST, and we work with what we've called a little sharing or. Sharing or a little matching, sort of borrowing from the forensic needs, what's the chance that two profiles have the same type? Well, they depend on the theta value for the population containing those profiles, and they depend on this unknown sum of squared probabilities. That's within the population, and you're going back to civil rights ideas in the 1920s. 1920s, you can't really address probabilities in isolation. And Elizabeth Thompson's made that very clear. We need to some reference point, and the reference point we've adopted is the sharing or the matching between pairs of populations. So there's a theta for each population, and there's an analogous quantity for pairs of populations. So instead of estimating the target parameter theta, which we do, Target parameter theta, which we don't believe is estimable in general, we estimate this compound parameter, which is the matching within versus the matching between. And it's interesting, this is a very simple idea, seems to work pretty well. We rely on some nice work by John Story showing that this ratio converges almost shortly to the parameter value. Here's the number of dose ion quotes. About them as the number of loci increases. So the fact that it's a ratio is not a problem. And it's interesting for if we had equal sample sizes, this is just the same equation as the Were in Cockham estimated some 40 years ago. So we've estimated theta and in the process of getting that published. We don't have the YHID data, which is by far the biggest data set. There are several published sets of around 20%. Several published it to around 20,000 profiles, not really enough to do much with. What IHID did do, luckily, is give citations to their data sources where they were published. So we've looked at the data, the publications, and harvested the profiles and constructed our own database. And that's about 70,000 profiles. So still not enormous, but certainly we had 50,000 or so useful 22 logist profiles. 22 largest profiles. 22 was the number in one of the big mainly used commercial typing kits. And these are from several different populations falling into six broad ancestral groups. So we have done that partly in plea to a statement from Sweden, which is the FBI's working group on DNA now suspects. Suspects. Till we find estimates which are broadly consistent with the SWIGDEM guidelines in 2014, the current guidelines do not show estimates because the sweepdown considers the issue to unsettle, to publish theta. Anyway, here are the estimates we've found: all times 10 to the power of 5, and with these raw. These raw continental grouping labels using thousands of genomes, notation, etc. And they get the estimates get smaller as we get more both site, but the rate of decrease changes. And just plotting that the matching proportion on a log scale goes down as the number of loci increases for a while and then it increases, looks like it's increasing. Increases, looks like it's increasing quite steadily. And then we run out of data because even with 50,000 or so pro, and it didn't make much difference whether we had African, European or Asian samples, we get this pattern. But we ran out of data. We don't have many matches, more than 17 or so loci. We've done some simulations up to 50 loci, which what we thought was a sensible model, and we get the same, we get an initial dip in the. Thing we get an initial dip and the log matching and then a steady increase but at a decreasing rate until we ran out of data. So that's about where we're at with the warranty chromosome data. I mean the issue is forced on us in a way by needing to demonstrate that we're capturing the strength of a multi locus profile. Strength of a multi-locus profile. And we are in the situation where legally prosecutors are required to attach numerical strength. I mean, it'd be a lot easier if they simply say, here it is, here's the match, and we think this is the person, which is what hand washing experts are allowed to do. That's not satisfactory either, so probably it's good to try and attach numbers where possible. There are other ways of thinking about allelographic. There are other ways of thinking about allelic association, the null concept of entropy. Just to remind you, the entropy is the sum, if you've got a calorie with types U, the entropy is the sum of the type proportions times their log. So if there's only one type in the sample, one of the p's is one, with the log of zero, so there's zero entropy. As they get more and more types and go equally frequent in the sample. Frequent in the sample, then the entropy reaches its maximum value of one over the number of times. So, this is a useful concept, and particularly because it has this simple additivity problem issue with property when there's independence. So, here's the entropy for a two system, maybe two locus profiles, all the types for the two loci. Alleles of the two loci, the log of their sample proportion, and if they were independent, if the sample proportions were products of the allele proportions, so we just got the sum of the logs, and the joint entropy is the sum of the two single locus entropies. So that's that's the issue, the fact that we can exploit. So entropies are additive when there's independence, and that gives rise to the concept of commercial entropy, the entropy of. Conditional entropy, the entropy of B given A is the joint entropy minus the entropy of B. So we looked at data and started with a series of Y chromosomes and started out choosing the locus which gave the highest single locus entropy and then chose the locus with the highest conditional entropy and proceeded. So here these are these are HL data, 20 or so wide chromosome markers, the single White chromosome markers, the single locus entropies, and the conditional ones, the way we order them, go down steadily. But after a while, the conditional entropy decreases. And after a while, the overall measure of diversity is not changing substantially. So it'll continue to change, of course, if we have more deathful places. Places, but it looks like, as a practical matter, in this case, it doesn't make much sense to get more than a dozen or so low cycles. You're not going to change the overall measure of information. So, just to wrap it up, what have I said in this little personal tour? Population genetics can be useful and guide the interpretation of DNA profiles. The strength of the evidence stone. Strength of the evidence depends on the probability of the evidence and the alternative hypotheses. And this statement is a paraphrase of what I and Air called the first principle of evidence interpretation. And these probabilities are shaped by evolutionary forces about which we know something or we can make statements. And most certainly um simp simple to think about and easy to demonstrate that progress is decrease, but at a decreasing rate as we get Decreasing rate as we get more closer. So that's simple, but we're scientists and we need to be careful as I found. So the very goals of science are more different. Science is fetched for the truth and seeks to increase knowledge by formulating and testing theories, and I would say by looking for generalities and patterns and data. Law seeks justice by resolving individual conflicts. Resolving individual conflicts, although this search often coincides with the truth. Rules of decisions that are not tailored to individual cases, such as those that turn off statistical reasoning, are often viewed as suspect, as indeed they are. So that's the caution, the lesson that I have learned, which makes life very interesting. So thank you all for paying attention, and I look forward to further discussion. Okay, thank you so much, Bruce. So I guess for anyone who has a question, you can raise your hand and then, you know, call on you and can unmute and speak in this forum. And while people are thinking of People are thinking of questions. Maybe, can I ask you a little bit, Bruce, about you? Mentioned a California law that involved a Y chromosome profile being needed in order to pursue familial searching. I'm curious about that and about scenario where the relative might not be on the male line. Yeah, no, good question. Good question. So so the use of familial searching is not widespread. It's where it has been used, it's been found to be useful. So this is when an evidence profile is obtained and searched against the database. So the CODIS database is 20 million profiles and it's quite large. But even then, it doesn't have everybody. So it's very often the case that the Devons profile does not have a match in the database. But there may be profile. But there may be profiles in the database which match at most of the local, maybe a few alleles differ, strongly suggesting that the database profile was from a relative of the evidence donor. So one way of just simply doing it is to do one of these so-called familial searches looking for profiles like that. The problem with that in practice is that it can turn up a large number of close matches. Close matches. And that's in a practical matter. It's a lot of work for investigators. More importantly, it brings into the attention of the authorities, people who are completely unrelated to the crime and the person. So there needs to be, it was thought as different states have wrestled, but there's a lot of states just simply prohibit the procedure. California allows familial searching, but only for sexual assault. Only for sexual assault cases where a Y profile match has already been found. So they know, and not found in the database, in their database. So they know that this I've got this right. They've got evidence that the, I'm going to get into trouble now. They've got evidence that the provost's not in the database. I forget, I'm missing. Maybe that's your question. I'm forgetting the logic. But then the prosecutor has to show that before they're allowed to proceed for an autosome or familial search. Can you help me there? I just think I'm forgetting about it. Yeah, I mean, that sounds okay. And maybe, so maybe you could regard it as a seem to reduce the burden of an. Reduce the burden of investigation, but it does require a wide profile. Yeah, yeah, I guess there's sort of been the different approaches that different states have taken to the familial search, you know, where I guess in some it's not allowed, in some it is allowed, and then California kind of taking this somewhat intermediate position. Yeah, yeah, that's wrong. Great. So, John Wakely has a question. So, John Wakely has a question. Hi, Bruce. Thanks for an interesting talk. I really take to heart your point at the end about the different goals of the courtroom versus science. And I wonder if you could say a little bit about that. It strikes me that for me, there's something a little bit uncomfortable about putting a lot of fancy statistics with numbers to what ends up being a binary decision in a forum that is really unlike. That is really unlike what we do in science. And I'm not sure what to do about that. And if we're a really good statistician, for example, you know, we might end up wanting to calculate a number in the end and then flipping a coin and letting the person go with some small probability or something like that. And so a lot of different ways one could make these decisions. And I don't know that we do it in the best way overall. No, I think I should go concern. Your concerns, so you know, and I didn't go into all the discussion around likelihood ratios, it's only a likelihood ratio, it's only the ratio of probabilities of evidence. It is not what the court wants. The court wants to know if this person committed the crime or not. And rules of evidence and rules of procedure suggest they should adopt a decision that gives the most likely thing to meet the Gives the most likely being meant the correct one. So decisions are made by judges or juries, and that's their business. We are not allowed and shouldn't tell them how to vote on conviction. So this is an attempt to guide their decision making. The decision is theirs. It doesn't matter what the likelihood ratio is. They can decide to convict or acquit depending on their individual beliefs, and that's our system, and I think it's a good one. And that's our system, and I think it's a good one. So, that we're not telling the court how to behave, we're providing them with the evidence. And it's not helpful to say there's a matching profile and this is a very rare event. Of course, it's rare. 20 locus profiles are not common. So don't tell me it's rare. That doesn't help me at all. But tell me, well, I see a match and the chance of seeing it again. That's rare. Again, that's rare. And then this is what I try and explain what rare is. And if I have to do it, I talk about lotteries and having the best one I ever heard was a slot machine with 20 wheels. And if you pull the leave and get 20 deals, don't have the right fruit. That's a rare event. And you get the payoff. So trying to put some sense, and I really don't like these large numbers. I don't, I think they are misleading. Think they are misleading. I don't know what they mean. So, the locus' assumption of independence does bother me. One way around that is to adopt Jim Crow's table. Why don't you just say, what's the chance that a brother or a sister of the defender will have the same time or of the perpetrator will have the same time? So, try and give some context and don't go beyond that. Context and don't go beyond that. You know, I used to advocate for not giving numbers at all. I think I've backed away from that. So in the UK, they say once the number reaches this threshold, which could be 10 million, the FBI tried to do that and their calculations were a bit dodgy. They tried that and the prosecutors did not like it at all. You know, they don't want to get up to falling off the cliff effect. They don't want to say, Well, up to this point, I've got to give a number beyond that. I can say it's the person. And that's why that Clinton quote had this meaningless phrase be a reasonable degree of scientific certainty. That doesn't help. Well, this is part of the problem is that there's this language about reasonable doubt, which it seems like we should have something to say about because we're dealing with chances. We're dealing with chances, but we really shouldn't. In a way, we know we know a lot about reasonable doubt. Surveys have shown that it's completely useless. Reasonable doubt means different things to different people. So there is no numerical standard. I mean, I can't disagree with anything you'll say. Thanks. But I've been wrestling with it. Thanks. Yeah, and so should I. Thanks. Yeah, and so I should also mention for anybody who has a question and would rather just write it in the chat, you can do that as well. And just this discussion is very much in the spirit of what we're thinking for this line of talks on applications and trying to square different cultures within our field as well as outside of it. So thank you. Outside of it. So, thank you for all those comments. No, maybe I have to do a little plug, a little plug for this problem measure. So, it used to be that we would, the forensic agency would do a typing and say these alleles match or they don't match, and do not match was an exclusion, and that was the end of the story. Probably some genotyping, and behind that, of course, was some decisions made by the analyst about. Made by the analyst about whether there was enough DNA in the sample to give a reliable signal. So there were hidden thresholds above which they would declare, they could declare a match or not, or simply ignore that locus, which is not good either. So problematic genotyping says let's model the typing system and admit the fact that we see something in the typing technology. Something in the typing technology, and most typing is an electroferogram, it's a trace, that's a series of peak heights, representing the amount of DNA on the sample. Let's model the process leading to those traces and not declare a match or an exclusion at all, but to attach probabilities to what we see. So it's model-dependent, but we end up. Dependent, but we end up, they end up with a probability statement, which they can then use for likelihood ratios. But there is no absolute statement made anymore. So I think that's quite nice. So there's no such thing as an exclusion. Anybody theoretically could match any profile if enough things happened during the typing, enough problems with amplification and misinterpretation and so forth. Interpretation, so forth, or stutter or mutations. Anybody could match any profile, but you can attach probabilities to what you see in the data. So I think that's a big advance. It's very nice work, very hard to explain to a jury. So in a way, things have gotten worse. Now it's very much a black box. But I think that's a step in the right direction. Direction. Great, thanks. So there's a comment in the chat from Jane McDonald that there's a book called Math on Trial, How Numbers Get Used and Abused in the Courtroom. And maybe that leads me to another question, which is, I mean, you mentioned handwriting as kind of another area of forensic. Area of forensic evidence with different standards. And, you know, I want to have kind of any remarks on, you know, forensic genetic evidence is supposed to be the gold standard for scientific evidence presented in courtrooms and kind of the burden that that places on the field and kind of the challenges that come from forensic genetics having this. Genetics, you know, having this somewhat elevated status, you know, kind of curious about your own. Yeah, that's nice. So, of course, we're lucky with these DNA profiles that they are genetic and we know quite a bit about genetics. And there is a random process underlying them. Handwriting, I'll tell you some examples, not maybe not quite as clear, although there have been experiments done to see how often handwriting from different Handwriting for different people matches. It's interesting that Goldwin's book on fingerprints, the conventional fingerprint, in 1892 reported his experiments. So he did a lot of experiments. He made fingerprints and cut them out and shuffled them and did all kinds of heritability studies and so forth. So he attached numbers to fingerprints. They were mind-bogglingly small, as the DNA profiles are. But he did that. But he did that, and that was a brave attempt. There's been some discussion about doing that for DNA fingerprints in the US. Probably, conventional fingerprints probably won't proceed. Like all type, I mean, there's other things that can go wrong apart from the numbers. I mean, certainly we've seen instances where the wrong person's been declared to match. So, if you ask a fingerprinting expert on what he bases his judgment, he says, On what he basis' judgment, he says, Well, I've been trained, and that means I went to a course and I did a test at the end, I was given 100 profiles, so I had to match them and I passed. End of story. I see Reginald had a question. Yes, yeah, Reggie, yeah, go ahead, Reggie. All right, can you see me now? Yeah. Okay, hi, Dr. Weir. I have a quick question from the slide you showed in the beginning about From the slide you showed in the beginning about the supposed one-minute trillion chance and then the conditional entropy on the later slide, I was wondering if the people out there in the field generally realize that once you get beyond a certain number of microsatellite loci, especially since they have so many alleles, that you're getting more possible matches than people have ever existed or ever will exist, probably. And so, like, I could throw out 50 loci with maybe 10 alleles of each locus and say, oh, there's only one quintillion chance that this is wrong, but does that really mean anything? Does that really mean anything since the set of actual people is a lot smaller that you were comparing against? Yeah, I try and counter that by saying these are probabilities, they're not proportions. So the size of the Earth's population, current or previous, has, I say, nothing to do with it. So we're not estimating the proportion of actual people with the profile. And that's a hard, and it's very hard to, I think, it's not an easy concept. Easy concept. And I don't know how to address to make that distinction. I do talk about tossing a coin and giving it, say, that there's a chance of one and two that I'll see ahead. Even if I don't toss the coin two times, the chance is still one and two. The chance of one in a trillion has nothing to do with the size of the population. It's a probability. And that's the issue, of course. What does that mean? It's not a proportion. It's not a proportion. I mean, I'm agreeing with you, but I'm just saying it's, I'm not worried about the size of the population. Oh, yeah, I'm sure you're. When people throw numbers out there, sometimes I don't know if they think about how they're stating things. Yeah, it is probably understanding the probability aspect of it. But that is, I mean, that's one problem we have. So try and explain what's good to Yeah, and I guess you were alluding to that sort of right at the end there, Bruce, about the probabilistic genotyping. And, you know, I guess as the techniques get more sophisticated and whether, you know, kind of how the field thinks about the statistical justification of the method on one hand versus the On one hand, versus the challenge of communicating that method in a court setting, on the other hand, and maybe experiencing this also now with genotype imputation, you know, being another method that's kind of in that same space as probabilistic genotyping. Same sort of challenge. Yes. Yeah. And you know, it's been adopted more widely. The only reason. Widely, the only reason it's been adopted is that they can get a result from problematic cases, they can get a result where conventional interpretation methods were failing. So it's sort of not a good justification. So maybe just one more question about the, you mentioned the 70,000 Y chromosome. You mentioned the 70,000 Y chromosome profiles and how kind of challenging it was to assemble all of those from a very large studies. That's huge. Yeah. And so, you know, maybe just curious about your thoughts on databases of forensic profiles and what's missing and what's needed. know what's what's needed and kind of the the challenge of you know a setting where there's you know protections of privacy uh on profiles that are used in actual cases but uh you know some need to have profiles in order to look at the calculations and do those better yeah well i think i would really love to see publicly accessible databases you know You know, this twinching and hidden profiles and the code is set as a target completely protected, but neither you nor I are ever going to be able to see those data. And maybe with good reason. It's very hard to, I mean, even 70,000, 100,000, or a million profiles is never going to give us reliable estimates of one in a trillion anyway. So maybe it's hopeless. It's interesting though. It's interesting though. So, we read two or three hundred papers and downloaded their spreadsheets, and about half of them were clearly wrong. I mean, simple things that we could test, like making sure that proportions added up to 100%, or making sure that the allele designations were recognised labels, or any number of things. And we wrote the authors, I say we, it's John Buckleton's work, wrote the authors. John Buckleton's work wrote the authors, and some of the time they responded saying, Oh, yeah, thanks for pointing that out. So the errors are the published data are full of errors that we know about. Then we found instances of high degrees of matching, lots of profiles. In this one particular study, the authors said they took care to some of underrepresented men. We found In we found multiple instances of the same profile, strongly suggesting a paternal, common paternal lineage. And you certainly want some relatives, but you don't want the sample to be in risk for relatives. So it's very difficult in practice. Did the big genetic studies help us? Does the UK biobank data? The UK biobank data helps us. Maybe we can certainly translate from SNP profiles, SDR profiles, as you know. We could construct databases that way. Would that help? Or would people want us to use the data that way? I'm not sure. So we're in a bind. We say we, if I'm helping the community, I try to help both defense and prosecution. Defence and prosecution. If we ask for help, we need to help them meet their goals of giving numbers or argue against doing that. So we do the best we can and that we are helped by having more data. I think if we can, you know, we've already demonstrated, I think, convincingly that five locus matches are not the product of five single locus matches, although if we put in these population structure corrections, we over correct, so we're not doing harm. So, we're not doing harm. But that's a data demonstration, which I think is useful. Will there be more data? Probably not, I would think. Reality. Okay. Well, thanks so much. So, we've reached the end of the hour here. So, right on time. I'd like to remind everyone that we'll see you again in two weeks for. We'll see you again in two weeks for a career panel on academic jobs in math, statistics, and physics departments. And thank you again to Bruce for really a terrific tour to your work on forensic genetics and a personal perspective on the field. So look forward to seeing everyone again in two weeks. Thank you. Thank you. 