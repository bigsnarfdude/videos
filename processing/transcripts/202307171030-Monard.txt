I want to talk about the Euclidean and hyperbody X-ray transforms. Have these transforms been beaten to death so far? Yes. Can we beat them a little harder? Yes, also. So that's the story I'm hoping to tell today. It's a nice follow-up to Andrash in the sense that the way we beat them a little harder recently is. We beat them a little harder recently to look at what's going on at the boundary, try to fit normal operators in some special calculi and see how that helps us invert the X-ray transform. Not on homogeneous bases, but then with more general context, we might not have constant curvature in the interior, but you have some special boundary at infinity, special geometry at infinity. So I want to discuss joint work. So I want to discuss joint works with Roy Timishra, a former postdoc, and Joey, who also spent a year in Santa Cruz, and then recently worked with Joey and Nicolai Nikitakis, who's currently at Hanover. So I'll talk about X-rays on the Euclidean disks, and then some family of special operators, and then what we can say about more recently the hyperbolic X-rays. But more recently, the hyperbolic X-ray transfer. It's a very fresh slide, some names might be missing, so I apologize in the fans. So these are the two main players I want to discuss. I can take a function on the disk, I can integrate it over fans of Euclidean geodesic, this will be the X-ray transformer, Euclidean X-ray transformer F. This family of curves gives rise to the family of data points here, and this is the Euclidean X-ray transformation. I use an X-ray transform of F. And then the same F here can be integrated over, we tell as a function on the point-carry disk. I can integrate it over hyperbolic geodesics, which I can parametrize in this so-called horocyclic parametrization, one boundary point plus a horocycle parameter. And I can also look at this as a column of data on the X-ray transform side. And so the questions, so these transforms have been. Questions? So, these transforms have been inverting for a long time. Inverted, you can get F out of the X-ray transform of F. What I've been interested in lately is to find a, so you can even get like L2H one-half stability estimate, this operation of one-half smoothing. But then, you know, to get back to the question I mentioned, more generally, you know, you More generally, you want to compose the operator with some adjoint of it and then ask yourself in what calculus it is. Is there a nice sobolex scale on which I can formulate a tame mapping estimate to capture the smoothing degree and the smoothing, the non-smooting anti-smoothing degree of the inverse, that kind of question. And this was also born out of work with Gabriel Paternain and Richard Nico, where you Richard Nico, where UQ question might require you to have a handle on an explicit inverse or an explicit functional setting where to formulate an inverse for the normal operator. And initially on surfaces with on Riemannian surfaces, we say incomplete flow and convex boundary. And so you really have to deal with boundary effects. And then, you know, it's one half smoothing, but it's. You know, it's one half smoothing, but in some cases you fit it into a functional calculus of a Laplacian that has a continuous spectrum, and so that normal operator is not written in some compact form and compact as a compact operator. If it's in the functional calculus of something with essential spectrum, you won't have discrete spectrum. And so recently, just as an observation, if you put something, if you tweak Some single, some if you tweak a little bit this normal operator by putting singular weights between the X-ray transform and the adjoints or the back projection operator, you can make normal operators which in spirit of still reflect the X-ray transform, it's just the X-ray transform, which has changed boundary behavior. But as an operator, it has much better properties. Okay? So to give you data points of what I just said, you know, on Euclidean R2 X-ray transform composed with this adjoint is negative squared to La Flash and that's Is negative squared to La Flacian as free multipliers. So you thought it was compact, but this functional relation tells you you don't get something compact, at least not in this one. On the hyperbolic disk, you can also do something. The normal operator of the hyperbolic X-ray transform is a function of the hyperbolic Laplacian, who also has a central spectrum. So you think, well, okay, maybe I can fit this in. Okay, maybe I can fit this in the calculus of the zero calculus, the calculus of uniformly degenerate operators, but also this is maybe not a great framework to make this operator compact. Yes, question. What is the gamma? The gamma function. So, this is the kind of formula you get with representation theory tricks. Okay, so that's the motivation. And if the motivation is to get refined functional mapping properties, maybe the best starting point is to start in context where you know the singular value decomposition of the operator. Because in some sense, the starting point might be if I know the S V T, I pretty much know everything I need to know about the actual transform. So let's start with the Euclidean disk and see what we know. The Euclidean disk and see what we know. So I take the Euclidean disk, I put this boundary defining function on it, and then I model geodesics infinity coordinates. So a boundary point EI beta, and then an inward-pointing vector alpha. Making an angle alpha would be inward-pointing normal. And I can define the X-ray transformer out of that. And then I've defined the back projection. And then I've defined the back projection operator. It's the adjunct of the X-ray transform for some topologies, but you can also think of it as a way to bring a function defined on geodesic space back to a function defined on the disk. And what you do is you use the footpoint map. Foot point map is a take a point in the direction in the interior and map it to the unique oriented geodesic passing through it. So if I have a function in geodesic space, I can turn it back into a function. I can turn it back into a function on the manifold by taking the averages over direction at a given point over all geodesics passing through that point. Okay, so what do we know about this? So I'll use the space of geodesic is 1 cross minus pi. is s1 cross minus pi over 2 pi over 2. Cosine alpha is a boundary defining function. So this is a manifold with boundary, so it has a boundary defining function. And I don't just know the S V D of one X-ray transform, I know the X V D of infinitely many value, infinitely many weighted versions of the X-ray transform, again weight with respect to UT measure time to D to the gamma for gamma greater than minus one, valued in some approximate Valued in some appropriately weighted space, I can get this as a bounded operator with this adjoint. If I stare at the right basis on data space, so these are beta, alpha, or my Fending coordinates, and if I write them in the right way using orthogonal polynomials in this variable, I can actually extract the kernel of the adjoint algorithm. So that tells me, you know, first of all, the X-ray transform. All these X-ray transforms, weighted or unweighted, have infinite-dimensional co-currents. And then the functions that don't get back projected to zero define a family of orthogonal polynomials on the disk. And then they happen to be orthogonal in the right delta space. And there you have it, you have the singular value decomposition of the X-Co transform. Of the X-Co transform. The singular values look like this. P now is the beta function, but it does look like a double ratio of gamma functions. It has n to the minus one-half asymptotics, but you have two spectral parameters, and so that actually might get modified a little bit also. So the you know the one-half smoothing once you throw in boundary behavior actually gets a little um gets a little tricky. It gets a little tricky. And so, yeah, these polynomials are also called the generized disk circuit polynomials. Okay. So this is spectral. So all of this in picture. So data space can be thought of as this spectral picture, so this half lattice, where each of these functions is represented by points, and then these two are. Point, and then these two are thought of as two spectral parameters of like a distinguished differential operator in geodesic space. And what this says is that the range of I0 is this colony here. It's W infinite on the upper half. All these functions get back projected to zero, so that's the codomain, the co-kernel. And then these one by back projection gives you the zero-market polynomials, which some of you might be familiar with in the shortened optics and things. Optics and things like that. And you can be sure that they make a basis because the top-degree term is spanning all possible values of C in C block, all monomial. Okay. Okay, so now you have the SVD, and then you can say, well, okay, if I map L2, then I can characterize this exactly. And then this is the best range. And then this is the best range characterization I can hold for it. Now I'd like to tie it in with some Sobolev scales. Are there Sobolev scales that capture this? And so first of all, what's a Sobolev scale? So is it the domain space of a distinguished differential operator maybe? That is a good definition, perhaps? That was my idea. In the case gamma equals zero, you can come up with a solution. You can come up with a Sobolev scale that captures the right decay in the spectral direction. And it's based on thinking of a Dirichlet domain space of this distinguished spectrum, which is T beta minus T alpha. So that captures the spectral decay, doesn't capture the co-kernel. And then the co-kernel, that's a different story, but you can find a special boundary operator, some of which introduced by Christoph Umman. That actually captures exactly which functions get triggered or not by the range of I0 and turned out to be equivalent with Helga's and Nudby condition, etc. So you have the range characterization on L2. Maybe you want to go higher subolf spaces. And so to get higher, what's a natural subolf scale that would capture the smoothing properties of the X. The smoothing properties of the X-ray transform. Well, you have the SVG, so you might want to say, why don't I define a space that just encodes faster decay in the thermodynamic decomposition of the function defined on the t. So that's kind of ad hoc at first sight. But these functions turned out to be eigenfunctions of a special operator. So that operator is elliptic in the interior of the disk, and then it's elliptic. Of the disk, and then it's ellipticity that generates normally at the border. And so that space, you can actually think of it as a domain space or a distinguished self-agenialization of this operator, which perhaps brings some hope of generalizability to non-symmetric spaces. So then what can we prove about these spaces? Okay, they intersect with C infinity, they're domain spaces. Their domain spaces of the graph closure of L gamma when you equip it with domain C infinity of the closure of the disk. And then there, the normal operator maps Hs gamma to Hs plus some offset and then the inverse maps into S plus some other offset. And so the normal operator might be smoothing by slightly more or less than one degree, and then the inverse might be. And then the inverse might be unsmoothing by slightly more less than one degree. So there's some wiggle room that cannot be sharpened. It's due to what's happening. Somehow it's the only... It's a subodet scale where you can get tail mapping estimates in the sense that the exponent of continuity and stability are not moving wherever you are looking on the scale, which is a tameness property. Property. But what you lose is you lose some marbles. You lose the fact that the exponents are not quite one-half, or plus one and minus one. But what you gain is that if you get this funny version of the normal operator, you get the same isomorphism of C infinity. So it's it's genuinely invertible on C infinity of the closure of the disk. And then recently we can actually say more. And then recently we can actually say more. You can tell that some spaces like those, if you look at H2K, it's got k well-defined traces, and they're essentially the first k terms of the Taylor expansion outside of the bottom. But you gotta go up to 2k to extract the first k terms. That's kind of the fun fact. Okay, so out of that, well, okay, so you have these spaces, you got marks. So, you have these spaces, you got more than one way to look at them, and then you have some sub mapping relations. So, now I know that the actual transform applied to these spaces maps me to those spaces. And that's the description of them. There's more fun facts. There's well I guess if you look at the the shape of the s b the values of the the singular values, The singular values, you could stay long enough to produce operators that quantize the spectral numbers I told you, n and k, and then you can find a functional relation between normal operator and the county, you know, this funny degenerative operator and then angular differentiation. Okay. And then, well, unless gamma equals zero, it's kind of not very pretty and kind of harder to write into some more intrinsic. To write into some more intrinsic, you know, sublime scale to find out of a differential operator. But in case gamma equals zero, this simplifies into this. So we think of like X-ray transform of HS, Twiddle, being HS plus one-half with respect to some directional differentiation, and then the kernel C minus kills the co-kernel. And what's interesting here is that the And what's interesting here is that the normal operator is in the function of tapinus. This is an exact negative square root of this degenerative operator. Interesting connection. Okay, so that deserves some words about this family of operators. I mean, at that point, these operators need change of smooth structure if you want to fit. Change of smooth structure if you want to feed them in the well-known microcore calculi. But Joey, as a side quest, we wanted to study them in their own right. So this is what we did. So I want to say a few words about this. They've been present in the literature for a while. They show up as so-called Keodish operators. If we extended this operator past the unit disk, it will become hyperbolic. They have application fluid flow, space-time on. Flow, space-time, Andraš used them to factor the hyperbolic Laplacian and help construct meteromorphic continuation in a different way using that. They're also called Kimura diffusion operators, although defined on manifolds at the corner here, it's just a disk. And somehow they're related to the zero counts, if you massage them in the right way. So, what we did is we asked ourselves We asked ourselves, well, is this, you know, what are all possible self-agile realizations of these outputs? And so the way you do this is by first staring at the minimal operator, which is the graph closure of the same operator defined on functions that vanish to infinite order at the boundary, define its adjoint, call it the maximum operator, and then our self-adjoint realization. All self-actual realizations would be sort of operator with domain in between those two domains. Or domain of actual domain. And they realized as relations on the boundary values that kill this pairing. So one can derive an approximate green identity on a slightly smaller disk. So you can integrate by parts with respect to the right L2 pairing. And then you collect some boundary. And then you connect some boundary uh some boundary term at the at the radius r and you ask yourself in what sense can I can I send r to one? What does that extract? Or what kind of traces can I extend? That's the question. And so I mostly present the main results here. So the point is that there's some kind of maximo polyhomogeneous. Of maximal polyhomogeneous space that's table by L gamma. So gamma not zero is infinity plus t minus gamma is infinity. If gamma is zero, it's infinity plus log d is infinity. If modulus gamma is greater than one, you find that the minimal operator is self-adjoint. End of the story. There is no other self-adnormalization. And then if gamma is between minus one and one, you can construct traces. They correspond to extracting the leading order term of each of these. Order term of each of these functions here, each of these summons. And so I call them Deutschland or nomen trace. And then they're defined on some appropriate subdef space, surjective, and then their boundary regularity is well understood. For gamma not zero, you might have some classical sub norm on the circle, and then for gamma equal zero, you get some Rach Sober F norm. And so, for all f and g here, you can get this Green's function, this Green's formula. And once you have a proper functional framework, then you have the theory of boundary triples that helps you characterize all self-agent realization as arising from a boundary relation. So what do we learn out of this? Well, you know, one of the questions you might ask is are other self-agent realizations of L gamma related to the X-ray transport, for example? It's the X-ray transform, for example. Or which one is the X-ray transformation? And so, for example, for gamma greater than zero, realize, okay, it's a Dirichlet realization. And for gamma between minus one and zero, it's a My Minor realization. For every self-agent realization, I'd cook up a family of sub-ed spaces that might or might not help me describe mapping properties. Okay? Okay, so this is what we know about this operator. And there is also a DN map from the DN map lovers up there. So then I want to finish with ongoing work with Joey and Vico on how to use everything I just mentioned to the hyperbolic X-ray transformer. The hyperbolic X-ray transformer might take a point. The hyperbolic capture transform, I take the point-carry disk. I choose a slightly different boundary-defining function, we'll see why in a minute. And I showed you the horse-60 parametrization pictures, what it looks like. Basically, all oriented geodesics can be parametrized by a boundary point and then a whole cycle parameter in R. And then I still have a foot point map. So I take a point in the unit circle bundle of the point-carry disk. Carry disk associated has a unique geodesic oriented geodesic passing through it. And I can play the same game, I can define the X-ray transform in the back projection operator. So there's been older work on hyperbolic X-ray and more recent on asymptotically hyperbolic manifolds. Particular stability estimate by Nicodemus that by new code that show that in some sense you can fit the normal operator, hyperbolic operator, in the zero calculus and formulates WBT estimates on zero subolex spaces. What I showed you in the first slide is that connecting the normal operator with the hyperbolic Laplacian might not give you compact. So so what we'll use So, what we'll use is this magical fact, which is that if you find this map from the unit disk to the unit disk, if you push forward the Poincaré metric, you get the Beltramic line model, whose geodesics are exactly reparametrizations of geodesics of the ETD indices. So stare at this picture, distorted by E, and then your geodesics become straight line. And then your geodesics become straight lines. The axis get distorted, but you care about geodesics, not axis. That's okay. And what's nice about it is, of course, it's a very, it's well-known fact for very long. Probably mask Gabriel for how old is this? 300 years? What's useful about it is that we're Useful about it is that we're connecting a case, a geometry where the boundary is convex and the flow is incomplete, with asymptotically hyperbolic case, case. And with an asymptotically hyperbody case. So in terms of fitting normals as operators in appropriate calculi, et cetera, et cetera, we can move everything from one context to the other. At least everything we know about Euclidean disk, we can tell a story in the hyperbolic case. Store in the hyperbolic case. And so this is what we do. As a result of projective equivalence, Euclidean X-ray transform of a given function is the hyperbolic X-ray transform of some distorted version of that function up to distortion and up to a weight. And then similar story goes for a back projection operator. And out of that, all the theorems in the first part that I wrote can have a counterpart in the hyperbolic disk. Part in the hyperbolic disk. So you can construct weighted impersonations of the attenuated hyperbolic X-ray transform. There are, you know, context where they're bounded, full description of the kernel of the adjoint operator, full description of the singular value decomposition. The eigenfunctions are deformed versions of the encoupling room. You can define subf mapping properly. You can define subref mapping properties and then find a context where you have some kind of smooth space of smooth functions for which the normal hyperbole operator is isomorphic. Functions have to have a Taylor expansion of the boundary because the projective equivalence has this magic property to turn the first boundary the second boundary defining function into the square of the first. Function to the square root of the first. So this is already the square root type change of variable at the boundary. But these are essentially everything you know about the Euclidean disk can be moved according to the hyperpotic disk where you get normal versions of the hyperpotic X-ray transform that are compact, fully known singular value decomposition, a class of singular spaces that encapsulate the mapping properties. And then finally, you can look at how to move the cap. Look at how to move the Cardish operator to put it back by this change of variable. And it's not quite a zero operator, it's a wedge operator. So in the sense that x squared times that operator is a zero operator. And then there's a, you know, these operators are studied in their own right. And so currently we're at the moment where we're trying to see how the results we have match with where you're. uh match with uh work that Kaina and Mendoza have been doing on like more general context for wedge operators. Okay, so uh let's keep the conclusion. Thank you. All right, time for a quick question. Yes, John. Yes. Um can you say could you compare the rate of decay of the singular values for the two transforms? For the two transforms? It's the absolute same. So the senior values are the same for those that are right. Because you take one picture, you deform it, the operators are just a little bit more. Yes, they're the same. Thank you. Yeah, control. So, I mean, so related. I guess the similar values is the reason that you care about the compactness. But yeah, so why compactness? I mean, in the applied side of things, you have a million ways to do regularized inversion. Ways to do regularized inversion, you can be truncated SVD, you have, I mean, it's nice to have eigenfunction expansion. And so, all the inversion approaches can, there's a million ways to approach this. Even learning a compact operator, more recently in the work where people are looking at machine learning questions, operator learning, and things of that nature, having a compact operator is just much nicer. You're the Keldish-type operator in the region where it's hyperbolic. Do you know what the structure of the nullby characteristics are or how sort of? So we confined ourselves to just looking at the elliptic region, so the disk is the elliptic region, we did not look at them. Last slide. Well, so far, so what we can achieve is not metric pervasion, but you can throw in Pertation, but you can throw in an attenuation that's compactly supported away from the boundary and fit the attenuated X-ray transform, the normal operator of the attenuated X-ray transform, in the same scale of spaces. So that scale of spaces is capturing the mapping properties, tameness properties, isomorphisms, symphony isomorphism properties, things like that. So that's, yeah, maybe that was something I wanted to mention. The goal is to, I guess, these are very like. I guess these are very like Fourier analysis cases, but the good is to provide reference cases for perturbative content. Alright, if anyone has any more questions, feel free to look down from