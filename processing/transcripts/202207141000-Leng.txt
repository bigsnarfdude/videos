Cool. Yeah, thanks for the invitation and it's thank you for coming to my talk. So this is Yen. I'm an assistant professor in the business school at UT Austin. So because I'm from the business school, a lot of the questions that I care about are related to how individuals or how organizations make decisions and how to integrate the knowledge on the dependencies of their decisions into a machine learning model. So the type of network sort of I'll talk about is social network. Sort of about talk about is social network, but it will be slightly different from what I think many prior talks have mentioned of social network as well. Is that when we talk about social network, we really care about a causal flavor in the sense that how one individual would affect the decision of another instead of merely network connections. The reason that we care about this causal influence structure is that so the That, so the ultimate objective for our research would be to help policymakers or help firms to better make decisions. So, we need to design interventions. Then, a good intervention should be able to change the decision making of another individual. So, our problem is not to make better prediction, but to better design this sort of network intervention to increase the behavioral change. I will give you an example of what's the difference between the intervention, the cause. Between the intervention, the causal flavor versus a prediction. So, think about if Samsung wants to launch a new phone and it wants to design an advertisement and send it to like, let's say, 100,000 individuals who should send some target. The one way of targeting is that they will just send to individuals who are likely to adopt the phone. The other one, adopt as in buy. The other one would be these individuals will adopt the phone only if they. Will adopt the phone only if they receive the advertisement. So, this the second one is a causal flavor in that they will adopt the phone only if they receive the advertisement. So, the second one is what we are more interested in in designing interventions. So, I just want to give a short description of the difference between our network, this sort of with influence structure, comparing with the connectivity. Okay, did I just use this? Okay, cool. So a little bit of background in terms of the connectivity of social networks. You might have heard about this sixth degree of separation, which was experiment done by a sociologist in 1960, where he asked an individual in Nebraska to send a letter to a random individual that he doesn't really. To a random individual that he doesn't really know in a small town outside of Boston, and he found that on average it would take six degrees of separation, a six-degree personal acquaintances to accomplish the task. And Facebook did a follow-up study, and they found that this connectivity was reduced to about 4.5 degree of separation about five years ago. So, this is only related to connectivity. Talk about how people connect to one another. And the future studies are more interested in studying. Are more interested in studying how one would influence the decision-making of one another. Chris Dougies and James Holand did a series of very influential studies in early 2000, and they found that habits such leads to obesity or smoking or even happiness could, quote, in their study, they talk about could lead to three degrees of separation in terms of influence, but there has been a lot of criticism after their study. After their study to criticize their causal identification. So I label this as behavioral assortativity. You can think about it as homopholy as well. And I have another empirical study where we observe that social influence can spread up to three degrees of separation through phone calls with some econometrics and statistic tools. So this basically talks about how individuals are connected and also different types. And also different types of connections and relationships. In practice, we need this underlying influence network to design network interventions, which can be useful to accelerate behavioral change or improve the organizational performance. So these are really useful if we want to design some political campaign, for example, get out to vote, or a marketing campaign or healthcare campaign for people to adopt some health. For people to adopt some healthy behavior with the network information and understand who could affect the decision-making of one another, could help us better design the intervention strategy under certain budget constraints. The problem that we face is actually a lot of time this underlying influence network is not observable for a bunch of reasons. The first one is that it seems that Facebook Is that it seems that Facebook and Twitter have a lot of available data. However, we argue that if you think about the decision that you make, you have a lot of Facebook friends, but very few of them will affect your decision making on particular behavior. And depending on the behavior of interest, maybe different friends will influence your different type of behavior. So this is talk about the importance of identifying the relevant network instead of merely. The network instead of merely who connects with whom. And in some developing economy, the way that they get this data, for example, a poverty lab at MIT, they did experiment in India. In order to get this data, they would go out and ask people, who do you hang out with? Who do you borrow money from? Who do you seek advice from? And things like that. So it's very costly to collect this information for a developing economy. And third is that the debt. And third is that the network data that we collected are static, which means that the accuracy will decay over time because of the dynamics in the network. So new edges are being built and old edges are destroyed. Last one is relevant to this behavior and dependent reasoning. So depending on different types of behavior, we are talking about different types of your neighbors may be more relevant. And some of your neighbors may affect your decisions negatively, which Our decisions negatively, which from a network intervention perspective, we don't want to reach those neighbors. So, that motivates our study is that we want to infer this influence structure from the observed actions, so solely from the observed actions. I want to start from our previous work, which was published two years ago in ICML. That gave us a better motivation and also would help to understand this type of. Help to understand this type of network game better. So, I want to start from what's the intuition of why we can infer the influence structure from individuals' decisions. So, from the beginning, I motivate that, and also from some empirical studies in social science, we know that individuals would influence the decision-making of one another. Now, you can think about these two types of broadly encompassing relationship. So, the first one, we call it complement. First, one we call it compliment, but an example of that. So, think about high school kids decide how much time they want to spend on Snapchat. The more time their friend spends on Snapchat, the more utility they will gain by engaging on the, spending time on the platform to engage with their friends. So, what as an outcome, what you will see that if some ne some individuals spend more time on the social app, their neighbors will spend more time on the social app as well. Spend more time on the social app as well. And the other type of relationship is the substitutive relationship. So think about your decision on buying a book. You get more utility by reading the book, but you need to pay the price for buying the book. So if your friend purchased a book, if you know that your friend will purchase a book, you can borrow the book from your friend without buying the book yourself. So this, we would see, we call it a substitutive relationship. Relationship. And as an outcome, you'll see negative decision makings of individuals. So this will behave like a hydrophobic network. So what we try to do in our previous study is that from the observed actions, so a bunch of decisions people make, we want to infer the interaction network. And also, we want to infer some game-specific marginal benefit. And I'll be more clear what that means. So I'll talk about some of the literature. So, I'll talk about some of the literature that could help to solve a similar problem. Well, the same, yeah, similar problem to infer the network. The first group is this statistical modeling. So we could use the graph to capture the data distribution and we maximize the data likelihood to get the precision matrix. There are also some physics studies that would use some physical process, for example, some diffusion cascade to inform. Example, some diffusion cascade to infer the underlying relationship. And the third group are signal processing. So, depending, usually they would assume that graph could infer some signal properties such as smoothness and use that to infer the network. So, the difference between our study and these literature are we want to add in some strategic decision-making of individuals such that we can make network interventions based on the network. Network interventions based on the network and also utility function that we learn. There is one paper by Barak and Onariel in 2019 that they solve a similar problem as well. I'll show more carefully what's the difference between our study and their study. So I'll first start giving a very short overview of this game on networks. So basically, we would have a set of players that they are connected by some interaction network. Some interaction network, and they make decisions to maximize their utility or a payoff function. And we assume that these individuals are rational agent, meaning that their objective is to maximize their utility function. And then we can use a Nash equilibrium to predict their decisions. So basically, we assume that they, because they're a rational agent, they want to maximize their utility, they wouldn't deviate from the Nash equilibrium because otherwise they're a utility. Otherwise, their utility will be lower. So, again, there are these two types of relationships that I just talked about. So, basically, the difference between this complement versus substitutive relationship is that whether a given player's relative payoff in taking an action is increasing or decreasing in the level of their neighbor's action. So, as an outcome, you would either see a more sort of homophilous graph in terms of action or a more heterostoly graph in terms of. More heterosily graph in terms of action. So I'll first very quickly talk about the game designed by Barak and Onario and then go into our utility function. And our new study wants to sort of build a generalization framework to summarize these methods. That's why I want to build up a little bit and talk about their game structure. Structure. So Barak and on Ariel designed a graphical game look like this. We name it an action-conforming game. So basically, individual's action will decrease if their individual's utility will decrease if their action deviate from those of their neighbors. And so this, depending on their utility function, we could write their equilibrium action, which is actually very, can be explained by the first eigenvector. Now, the problem with Now, the problem with this, well, not really the problem, well, one disadvantage of this study is that they don't capture the substitutive relationship as we talked about just now. So if individuals' behavior are different from their neighbors in this heterophilic graph, this is not something that this game can capture. And also, you see that this game would predict the same behavior for all the games. There is no game-dependent parameter. There is no game-dependent parameter, which makes it not that realistic in practice. So, we use a linear quadratic game, which is a very widely used game in economics and management to model a wide range of behavior, like peer effects, consumption, externality, and so on. So, the game structure looks like this. So, there are mainly two components. One component are related to One component are related to individual behavior, not related to their neighbors. So, in this individual component, this AI is their action, and then BI is the marginal benefit. So it's game-specific. You can think about it as like for each action that I perform, how much benefit that I gain. The second term is the cost associated with the action. There's a scalar to it for this point. A point five scalar that doesn't really matter because it's sort of like a normalization factor. And the second component is the network effect, which is really fairly important in our setting. So there is a network factor beta that can help us to model these two types of relationship complement and substitute. So if beta is positive, you'll see that if AJ, AJ. You see that if AJ, AJ is the behavior of neighbors. So if AJ is higher, that would motivate the central individual I to perform higher action as well. So that UI will increase, but that is constrained by the cost term. So that can help us to capture the complement relationship. Similarly, when beta is negative, you will see that when AJ is higher, if the focal individual eye also performs higher action, utility will decrease. So this will. Will decrease. So, this would capture the substitutive relationship leading to negative behavior of these individuals. So, I'll give you another two examples just to contextualize this game. The first one, think about a group of still high school students that the action is the time spent on coursework and their utility is their payoff. And we can consider a network as a fully connected network for all individuals. Network for all individuals in the classroom. So, if some students work really hard, so if some students' action A is higher, that would motivate everyone to work hard to get a higher grade. So, that is a complement relationship. Another example, let's think about teamwork or maybe papers with large set of authors. The action is time spent on a joint project, and the payoff is the performance. So, if someone on the team works, The in the team on the team work really hard that actually may motivate others to shirk the responsibility and work less hard, which is not good, but that you might have experience with that. So, this is an example of a substitutive relationship. You may observe like negative decisions. Okay, so after we have this utility function, we can get a natural equilibrium. You can think about it as a steady state where no one wants to deviate because if they deviate, One wants to deviate because if they deviate, they will get lower utility. So, if they are rational agent, they wouldn't want to deviate from this pure strategy Nash equilibrium. And we use this to predict individuals' behavior. So, in order to get the pure strategy Nash equilibrium, we take first order derivative, and then we can get a closed form relationship between the action A with the graph structure G and the marginal benefit B. And this is game-specific. Now, we make a technical Now, we make a technical assumption that the spectral radius of beta g is smaller than one so that the solution is well defined. We can also write down or expand the action with the geometric series. So you can see that this shows that the payoff dependency can actually indirectly spread through the network, which actually is in line with some of the empirical study that I Empirical study that I motivated in the beginning. So I'll very quickly talk about the method in our previous paper in 2020, and then I'll go into the new paper. So we can rewrite the Nash equilibrium, reorganize the equation in the following way. And then what we observe is that we observe a bunch of games. So let's say K games, for you can think about each game as each position. So think about your ratings on like biz. Think about your ratings on like this, on a restaurant, your ratings on spa, ratings on gym, things like that. And then given that the marginal benefit is different, the action is different as well. So what we observe is only the action and what we want to infer is the marginal benefit as well as the network structure. So we propose a optimization framework that kind of like a joint learning of the marginal benefit and also the Benefit and also the graph structure by imposing some sparsity constraint on the graph and also some prior on the marginal benefit. So we have a fidelity term that we want to make sure that the predicted action is as close as the observed action as much as possible. And then we have some sparsity constraint on the graph structure. And also some like it should be symmetric, diagonal is zero, et cetera. And the last one is our And the last one is our assumption on the marginal benefit. So, here in this setup, we assume that marginal benefits are independently distributed, meaning that neighbors' marginal benefit are not dependent on one another. We also have a setup there. We assume that this marginal benefit is homophilously distributed as well, meaning that neighbors' marginal benefit are similar to one another. So, in this setting, we can replace the third term with Setting, we can replace the third term with the graph Laplacian. So that's, I'll not go into the detail, but that, so this study, our study plus the Barack study will actually motivate what I want to present is that these two papers require some assumption on the network game. And a natural criticism is that in reality, the network game that we assume may not model the actual behavior of individuals. And there are different types of And there are different types of networking, and we don't know which one is actually the behavior, actually, model our behavior. So, the question that we ask is: then, can we learn a mapping from the action to the network structure without explicit knowledge of the utility function? So, I'll talk about generalization, but before that, I want to introduce another network game, but it hasn't been studied in the network inference literature. Studied in the network inference literature yet, but it's it we incorporate in our framework as well. Um, so this is a linear influence game, which was motivated by the threshold model in sociology, which basically says that individuals will adopt certain decision if a percentage or a number of their neighbors adopt the decision. And we did some tweak to the game to make it continuous. Um, so you see that um the utility function um is a combination. Is a combination of a focal individual and the action of the neighbors. Subtract a cost term related to, or we call it a tolerance term related to focal individual's action. And then the equilibrium action has the form that is the inverse of the adjacency matrix and a game-specific marginal, game-specific individual characteristics. So, and then we want to use these different games. Use these different games to help us motivate the structure that we study. So we write down the utility, the equilibrium action of these three games. So ranging from linear quadratic linear influence to BH is the, we short BH for the barric on our real game. So you will see that it can be summarized as a function of the adjacency matrix and a function of the idiosyncratic characteristics. Idiosyncratic characteristics. And they would have different functional forms. So for a linear quadratic, it's the inverse of the identity matrix subtract beta multiply adjacency matrix. And for linear influence, it's the inverse of adjacency matrix. And for barric, it's the largest eigenvector. And then for HB, the linear quadratic and linear influence have this idiosyncratic term, while Barrick. Cratic term, while Barrick on REO doesn't have this term because it is not game-specific. We just did some quick analysis of how of this equilibrium action is based on the distribution of the marginal benefit term, which is only relevant for a linear quadratic and a linear influence game. So we assume that the marginal benefit term would be distributed as a multivariate Gaussian distribution. A multivariate Gaussian distribution, and the covariance matrix is a combination of the identity matrix and the Laplacian matrix. So, with this, we can use it to model the level of smoothness in marginal benefit. So, for example, if A goes to zero, sorry, alpha goes to zero, that means that this is the independent game. You see that, well, that means that the marginal benefit here is independent because it is not affected by the network. Because it is not affected by the network structure as well. You can also go to the other stream that alpha goes to one. In this case, it is purely smooth on the graph. And then because of the distribution of marginal benefit, we could plug it into the equilibrium action, and then we can get the distribution of our observed action with multivariate, we can model it with multivariate Gaussian distribution. And the covariance nature. And the covariance matrix can be interpreted as a graph filter with frequency response in this following way. And recall that alpha is this smoothness, this term capture the smoothness in the idosyncratic characteristic, and beta in linear quadratic capture the strength of the strategic dependency in the individual's behavior. So, overall, the bulk part pattern for a linear quadratic is that, let's say, if beta goes to one. Is that let's say if beta goes to one and alpha goes to one, the action will tend to behave like the leading eigenvector of the graph. So, meaning that the action will be fairly smooth and it will be easier to infer the graph from the action. For the linear influence game, it's a little more complicated. So overall, when alpha goes to one, we tend to get smoother actions, but the exact behavior is heavily affected by the magnitude of eigengen. The magnitude of eigenvalue values that are close to zero. So we did just a simple illustration on this. So this is the Ardo-Stranding graph with only 20 nodes. We choose relatively large alpha and beta to be 0.8. So for linear quadratic game, which is shown in the blue curve, the y-axis is the log filter response, x-axis is the eigenvalued index. You see that it is dominated by the leading eigenvector. By the leading eigenvectors. So you see that we tend to get a smooth action. And for the linear influence game, it is dominated by the mid-spectrum eigenvectors, which are not necessarily sparse, meaning that this linear influence game is harder to infer the graph structure. Okay, so now we'll what so with that, that's sort of having a background of what motivated our study. So our goal is to Our study. So, our goal is to learn this mapping directly from decisions to network structure on a small population, and then we can use the data on a completely unobserved network with actions observed. So, the assumption that we have here is that the utility function is the same in the individuals in our training set and individuals in our test set. So, this is different from inductive link prediction that Michael presented, because in the test set that we have, in the test set that we have we don't observe any any any data any of the network connection so in terms of the setup we would have some action graph pairs coming from games with the same utility function and then for each of the if each of the action graph pair the model would take in both the action and the adjacency matrix and then the action will be for for for for the the action will be for each individual Action will be for each individual. We have K number of independent games. So we can think about we have K number of actions and we take in this matrix and then we output the adjacency matrix. So then there are some others literature that I want to review a little bit here. So there are some other, because right now we sort of observe some of the adjacency matrix already. So it's no longer this unsupervised. So, it's no longer this unsupervised learning setup in the first paper that I present. So, there are some similar studies. The first one is the stream of study that would infer the directed axelic graph. And their underlying assumption is that individuals would behave according to structural equation modeling. I personally like those type of work. And so, their method cannot be used in our. Their method cannot be used in our method because the underlying assumption on how individuals behave differs. And also, they assume that cycles don't exist, which in our setting is very likely that cycles would exist on social networks. Second stream of work, I think many people talk about it in this workshop. It has been mentioned multiple times about this neural relational inference. So it was trained on a downstream task that Stream task that they use to predict future state of the system. So, we actually tried this method in our setting. It doesn't work that well even compared to a random model. We think the reason is that the intuition could be that think about a star network. So, all the periphery node will be very similar to one another, and then you would predict that all periphery nodes are connected. But in fact, they're only connected to the central node. So, this is. To the central node. So, this is completely wrong. This intuition of this, the most predictive network connection may not be the network connection that actually affects the decision making. Last one is the deep graph, which infers the undirected graphical model. So, this work is not permutation equivariant and is also not scalable to large graphs. So, for our problem, for our method, the method um the the the the framework needs to have two important properties first is that it needs to be permutation equivariant over the set of nodes since we need to um apply this method to completely unseen nodes and second is that is it needs to be permutation invariant meaning that a game k in one of the graphs doesn't correspond to game k in uh and there's basically no correspondence between the games in different um graphs um so we designed this quite So, we designed this quite simple graph now game transformer. So, we have this auto encoder and decoder framework. So, the input again is a matrix with number of users and then their actions for number of games. And we would output this game-specific latent representation. The reason we do this is motivated by our setting that we see that this idiosyncratic characteristics are really. Idiosyncratic characteristics are really game-dependent, so we want to learn this game-specific characteristic. And then the output from our decoder is the adjacency matrix. So our encoder is transformer-like. It just have three steps. So we first would expand the individual's action into a vector of features. And then we use a typical attention network to learn the attention. To learn the attention weights. And then we would refine this expanded action representation of y via function that would possess, that would take in the aggregated representation from neighbors. So that would be the output from the encoder, which is the tensor. The dimension will be for each user game, we have I've dimensional feature. And then, in terms of our decoder, we have a dot product decoder. So it's relatively simple as well. We have this dot product so that it can ensure permutation equivariant. And then we aggregate all the games with these permutation invariant operators. So in our case, we choose some over the number of games so that our method is invariant to the game. Invariant to the game modeling. So then I'm going to show some results. We start with some synthetic data and then I'll go to the real world data. The nice thing with synthetic data is that we assume that the underlying data Hello, okay, good. Okay, and then we have three set of random graphs. We have a Roshrani, Westro Gatz, and Barabasi-Albert. So, WoodstroGatz is just a K-regular graph. Each individual have K nodes, and then we would rewire some of the nodes. And Barabasi-Albert is, it would have. And Barabasi Albert is it would have a core periphery structure. So typically we would think core Barabasi Albert is more closer to social network than the other two. And then we would generate equilibrium actions according to the game of interest. So I will show results for each of the game. In our setup, we have 850 games in the training, 50 in the validation, and 100 for the test set. And we evaluate with AUC, just the typical method. There's the typical metric that we choose. In terms of the baselines, we have just simple correlation and regularized graphical lasso and this deep graph. And also these two optimization-based methods, R-method and also Barakand on REO. So this is the result for a linear quadratic game. So here on the top row, these are results for independent marginal benefit, meaning that the Marginal benefit, meaning that the marginal benefit has no information about the graph structure. And for the second row, that's the result for the smooth marginal benefit, meaning that the marginal benefit itself encode information about the graph. And from left to right, we see a left to right column. We see Woodstow Guess, Erdo Schranny, and Barabasi Albert. Sorry, that is very small. And then the x-axis is the spectral radius. So the middle, we do, we test. We do we test the spectral radius from point uh from minus 0.8 to 0.8. So the middle point will be zero, where meaning that there's no strategic dependency. So for the independent marginal benefit, you overall, so it's very clear that the performance is better, much better when structural dependency increases. And we overall, we would see that our method would perform on par or superior to all other methods and with the dip graph being the runner-up. Deep graph being the runner-up. And what is interesting here is that this performance is even better than our previous paper, where we know the actual network, we know the actual game theory record function. The reason is there's a slightly cheating part here for these deep learning-based method because for this optimization-based method, we don't observe any of the networks. So it's purely unsupervised. Well, with our new method, Well, with our new method and also with deep graph, they need to take in, like in our setting, about 850 networks as training. So that helps to better learn the utility function. And the second set of results are related to the linear influence game. Again, from left to right are Wats Rogatz, Erdo Shrani to Barabasi Albert, and then the ELF, sorry, the X axis. Alpha, oh, sorry, the x-axis is the alpha, and from zero to one, as the analysis that we did before, going rightward, we would expect the smoothness to increase, and the action will encode more information about the graph, making it easier to infer the graph structure. So, overall, we see that the performance for Westrogas and Erdoshrani are lower than Barabasi-Elbert. So, we think the reason is that the smallest absolute eigenvalues of these two graphs. Eigenvalues of these two graphs are much smaller than Erdo-Shrani, sorry, than Barbasi-Albert, and then the actions will behave very similar to the mid-spectrum eigenvectors, so which are not smooth at all. This is result for this Barrick on our real game. So in all of the graphs from Westrogatz to Barabas, to Albert, we see that we perform the best. That we performed the best with DipGraph being the runner-up for Ward Strogatz and with the regional method being the runner-up for Erdo Schranny and Barabasi-Aubert. So that's a set of results on simulated data. And this is some results on real-world data. So we have two set of real-world data. The first one is data collected by this poverty lab. data collected by this poverty lab in at MIT that they go and ask people to name who are your friends who who who do you who do you who are you affected by and things like that so the agents in these network are different households and the actions are facilities that adopted by these households and the relationship we think will be a complement relationship so because of social influence because of peer pressure they tend to perform similar to one another in terms of the number of graduates In terms of the number of graphs, we have about 75 villages, and we split this data into train test split. And then the ground truth data that we treat here is the self-reported network. This could be more accurate than other data that we collected on digital platforms. So, in this data, we see that we perform the best, which is the bottom one, and the runner-up are actually correlation and graphical lasso. Graphical lasso, which could mean that in this example, people don't really behave that similar to either a linear quadratic game or the barrack on RO game. In the second example in Yelp, we have Yelp users and then being the agent and for the actions, those are the average rating for different business categories. So we could reduce the number of actions that we observe also because the data is quite sparse, so we aggregate for a different business category. Aggregate for a different business category. Similarly, this we think is the complement relationship. So we would observe similar behavior for neighbors. So this one, the input to our data is that we have 5,000 subgraphs. We can think about it as communities. And then the ground truth here is the online social network. Now, one caveat here is that in this setting, because the data is not self-reported, this ground truth may not be the actual ground truth because this only means who followed who. Because this only means who followed who. It doesn't really mean that they will actually be affected by one another. But this is the best data we could find. So, in terms of the performance, our method still performs the better with our prior paper with linear quadratic game being the runner-up. So, this could be because on this digital platform, people do behave similar to a linear quadratic game. So, with that, I want to conclude on the contribution. On the contribution. So, we use the unified parameterization to combine three types of network games. So, that helps us to understand better the nature of different games and also help us to motivate our framework. And our framework basically would infer the underlying network structure based on the actions. And more importantly, we do not assume any explicit knowledge about the utility function. Explicit knowledge about the utility function. And lastly, we contribute to this field of data-driven structural inference with a method that would adopt this permutation invariant transformer. So in terms of limitation and future work, the first one is that our game is static. So individuals only perform one-shot decision for each game. So in reality, it could be possible that individuals would make decisions repeatedly. Perform would make decisions repeatedly and using some repeated game to model individual behavior may be more realistic in our setting. Second is that we might, I think in this workshop, we have many amazing talks about dynamics networks, and I think it'll be interesting to extend to infer the dynamic networks. Lastly, is that in our second paper, we still observe some of the network, which can Observe some of the network, which can be a fairly strong assumption. And in practice, application that would be relatively costly as well, because we still need to go and get the data. So I think it will be very interesting to develop a method that we don't observe any network connection as well. So with that, I want to thank for your attention. That's concluded.