Yeah, so thank you very much, Francois, and to all the organizers. It's been a very interesting and informative conference. I feel like, to use a phrase my colleague likes to say, I'm drinking from the fire hose a little bit, but I'm learning a tremendous amount. So if I can get these slides to move. So I want to talk to you about a set of PDE inverse problems. Set of PDE inverse problems motivated by fluid measurement. We'll have one problem which will be in the focus and come up several times through the talk, which is the recovery of a divergence-free vector field from the observation of a passive scalar. But I want to just sort of mention several other fluid measurement problems motivating sort of current and future work that I'll just briefly mention. I was going to talk. Mention. I was going to talk a little bit about the Bayesian statistical inversion framework, but I think this has been discussed so much at this conference and in a more sophisticated way, maybe than I will have done. So I'll try to go quickly through that. And we'll focus on sort of two lines of work. Firstly, the sort of design analysis and rigorous convergence results for a class of Convergence results for a class of infinite-dimensional Markov chain Monte Carlo algorithms that have been of great interest to us. And then I want to say a little bit about consistency in terms of this first problem that maybe will be some interesting counterpoint to the wider program of Richard Nicol and others discussed on Monday. So, first, I want to acknowledge my collaborators. My collaborators, wonderful folks, Justin Kermitis, my former PhD student, and Cecilia Mondayini, who was postdoc here at Tulane and is now at Drexel, and Jeff Beauregard. So I owe much to them. And so, all right, so this first problem you can think of very simply as you have a divergence-free vector field for simplicity and visualization purposes and many other reasons. Uh, purposes and many other reasons. We're going to work in 2D and have it be time-independent. And it's as if you drop a dye in a glass of water, it's being advected by this unknown velocity field and it's diffusing, and you want to recover as much information or get an estimate from sparse noisy measurements about this underlying velocity field. So, I'll just briefly mention a So, I'll just briefly mention a couple of other problems that are on our upcoming agenda that I think illustrate that this Bayesian framework of interest in this workshop comes in happily in terms of fluid measurement problems. So one problem we're starting to think of is you have a Stokes flow, it's maybe excited from an outer boundary rotation, and you're trying to estimate the shape of the inner. The shape of the inner boundary on an annular domain. Okay, and for a fixed domain but unknown boundary conditions, there are very relevant problems here in fluids. And one that we have particularly in mind is Rayleigh-Bernard convection, where the stirring comes from a bottom heating profile in the fluid. And we want to, from observations in the bulk, make estimates on the In the bulk, make estimates on the bottom boundary condition, the bottom heating profile. So, in all these problems, we have an infinite-dimensional unknown parameter, naturally infinite-dimensional. And our forward map is a composition of a non-linear parameter to PDE solution map observation operator. And as various folks at this conference have formulated, you can You want to, in effect, invert G, but that's practically and theoretically impossible here. But considering this Bayesian framework gives us a reasonable way of quantifying uncertainty in this unknown parameter. And it fits nicely within this regularization framework, as many have observed here, that you want to minimize some loss function between your observed data. Your observed data and your forward map of your unknown, subject to some regularization term, which, of course, corresponds to the map point appropriately for the Bayesian inverse problem. And this can be made sense of well in an infinite-dimensional setting as observed here. So, of course, in a Of course, in a just very simplistic way, to take observables from this posterior measure, you have, so to speak, the integration problem from hell, where in high or infinite dimensions, and each sort of grid point, each evaluation point costs you, in our situation, a PDE solve. And so, but this Markov chain Monte Carlo framework is Is actually maybe our only hope in many situations, or is an important framework to resolve information about observables of these type of target measures that we're interested in. And so, in fact, what originally drew me to the subject was the fact that we have here an infinite dimensional problem where Where studying Markov chains on infinite dimensional spaces could be used as a computational tool. And the question mixing, which I had been looking at in the SPDE context, might be addressed using sort of recent developments from Markov chain theory. Okay, so I'll just briefly go very briefly here. Go very briefly here. I think Richard Nicoll said much, much more and much better than I could in general about consistency. But from this fluids perspective, I think it's also useful to think about this as experimental design, that as we have, say, a fixed number of measurements, how would we place our sensors so that we have for a given prior that we can calibrate? That we can calibrate based on lots of physical understanding a minimal amount of variance. And of course, the concentration problem as the number of measurements goes to infinity is consistency. So let me turn to, did I see a question? No. Okay. So let me turn to describe. So let me turn to describe the Markov chain Monte Carlo approach. Well, this has been overviewed by many in this conference. So again, we have a proposal kernel, and in order to get an unbiased sampling of a target measure, we sample from the proposal kernel and form, excuse me, a particular acceptance. A particular acceptance ratio. And by accepting the proposal with this given probability, we either move to the proposed point or we stay where we are. When you have a symmetric kernel, you see clearly, you get some nice intuition that if you go to a point of higher probability, you simply accept. And if it's lower probability, you accept with. it's lower probability you accept with the um with a probability uh you know relative probability between your proposed point and your your current point this is going all the way back to the 1950s um so the 64 000 question here really is how do we come up with good uh proposal kernels and uh three uh popular approaches are sort of the cheap and cheerful sort of random walk And cheerful, sort of random walk approach where we simply make something like a Gaussian proposal around our current state and let the metropolization resolve the shape of our target measure. But using insights from dynamical systems, and I think starting in the late 80s, 90s, The late 80s, 90s, you can develop all sorts of more sophisticated approaches around Langevin dynamics and Hamiltonian systems. And so we came into this subject fascinated by and excited by this sort of work around Andrew Stewart's group, where versions of, I'd say, all three approaches were developed for Were developed for target measures that have sort of absolutely continuous with respect to trace class Gaussian base measures on Hilbert space. The idea here is that you can somehow with a combination of skillful preconditioning the dynamics around the covariance operator of the Gaussian measure and stable numerical schemes. And stable numerical schemes that you can derive algorithms that make sense directly on the infinite dimensional setting. And then hopefully you have something that in some sense partially beats the curse of dimensionality in the sense that when you ultimately truncate these methods to finite dimensions, the rates of mixing should be independent of the Of the dimension of the truncation. Okay. So let me zoom in on two of these algorithms to begin with. The PCN algorithm has already been mentioned. This is based on a preconditioned Crank-Nicholson discretization of Orenstein-Ullenbeck dynamics. And so with this discretization, you have a chain or A chain or a proposal kernel which is absolutely continuous, which actually holds the Gaussian prior measure as invariant. And so you can formulate with some nice general state space Metropolis-Hastings work of Tierney, a simple accept-reject mechanism here. Now the Now, a second approach around Langevin dynamics, again, preconditioned with the linear piece of this resulting dynamic, taking a Crank-Nicholson discretization explicit in the gradient terms, you have an algorithm. And here we sort of see the local shape of the target measure, but of course you pay for this by comparing. this by computing gradients of your, what for us is the log, is the log likelihood function. And so this is probably blaringly obvious to many of the PDE optimization experts, but when you look at the gradient of this function, Gradient of this function a priori, each direction you want to compute the gradient costs you another PDE solve. So you have to develop an adjoint method, which is in essence integrating by parts, that you see that by considering this adjoint equation and sort of plugging in that this guy is the left-hand side of this directional derivative equation and integrating by parts, you can reduce. And integrating by parts, you can reduce sort of functionally infinitely many PDE solves to just two. So this is what sort of makes these sort of things possible, these sort of higher order methods. So maybe the method that most caught our imagination and attention and really connects with a lot of beautiful ideas in Hamiltonian systems, which is maybe. In Hamiltonian systems, which has maybe been discussed a little less in this conference, is the so-called HMC approach. And here, now I've written target measures in this sort of finite dimensional form. You observe that the Gibbs measure, e to the minus Hamiltonian, is an invariant measure under the Hamiltonian dynamic. And so if you consider a Hamiltonian whose potential is the same as the Hamilton Whose potential energy piece corresponds to this potential in your target measure, and you take a natural quadratic kinetic energy piece, then the momentum marginal of your Gibbs measure is a Gaussian measure, which you can sample from. And so you sample from the Gaussian measure and from your current point, which is you think of as a position, you run forward, your hand. Position, you run forward your Hamiltonian dynamics, you marginalize again onto the new position, and that gives you a chain. But of course, we have to implement this in practice, we need to consider a numerical discretization of this dynamics. And it matters very, very much how you, even in the finite dimensional setting, it's a very delicate matter to properly discretize. Properly discretize the system. So, you want to use a geometric integration scheme, typically classically a leapfrog scheme, which is symplectic and preserves reversibility properties of your dynamic. And so you can see then that you get a metropolization step, which depends on your current position and drawn momentum, and then the drawn momentum and then the outcome of your of your of your uh numerical uh run and you'll notice that this is a little bit different structure than the um original setting of metropolis and hastings because it depends not just on your um current point and your proposed point but also these axillary uh momenta okay so Okay, so the algorithm that we've been working with is this a beautiful generalization due to Beskos et al. to the Hilbert space setting, where they again sort of precondition the Hamiltonian dynamic. So in effect, look at the position velocity formulation. And they use a particular splitting of the particular splitting. Particular splitting in developing a numerical discretization. So we've been implementing this in practice, as I'll show you in a slide or two. But as we tried to understand better what was happening here, we wanted to get a sense. Their proof is a finite dimensionalization argument, and there's a sort of seemingly magical cancellation of infinities here. So we wanted to better. So, we wanted to better understand their metropolization mechanism. And naive as we were, we had this idea that because these gradient evaluations are so expensive and also arduous to implement that we could maybe replace these gradient terms with some kind of approximation. kind of approximation. So what we realized is called in the field a surrogate trajectory method. And in sort of trying to understand how this sort of the scope of how this term could be replaced with various lower order approximations ended up on, sort of stumbled upon and gradually ended up with the development of a sort of grand unified theory. Development of a sort of grand unified theory of these metropolis-Hastings algorithms on general state spaces. So we end up with a formulation that shows that all three of these methods and many other methods can be encapsulated under one algorithmic setup in such a way that we have a good framework for developing what you would call surrogate trajectory methods. So let me walk you through this general theorem. General theorem that we have. So I have two just measurable state spaces: one, X, which I'll think of as my position space, and Y, which I'll think of as my momentum space, and a target measure, mu, on my position space. And there's two sort of elements to having a very general metropolis Hastings type algorithm. We have a proposal momentum kernel. Momentum kernel, the Markov kernel from X across the measurable sets of Y, and we have an involution. And so your algorithm is simply you sample from your given position from this momentum kernel, push both elements through under an involution map, and you assume this isn't actually a necessary assumption. This isn't actually a necessary assumption, but if you don't have this, you probably have a kernel that's a Markov kernel that's of no particular interest. But you want to assume that S, the push forward under this involution map of the compound measure M, which you can think of as a generalized Gibbs measure, is absolutely continuous with respect to M. And so having drawn Having drawn V from Q, pushing forward into this map, and then marginalizing onto S of Q, and computing this radon-nicodyme derivative, you get a kernel which is reversible with respect to your target measure. Okay, so this general framework recovers. This general framework recovers random walk, Monte Carlo, MALA, HMC, and we've checked some, sort of shown how this also applies to sort of a little bit more exotic methods like the geometric approaches of, say, Girolami Collarhead. And it encompasses all of the infinite dimensional samplers that I've discussed. Samplers that I've described above. And we sort of, under this general theorem, recover a sort of algorithm where essentially under particular parameter choices, you receive all of these different MCMC samplers. I should say that our colleague Andrew Holbrook is sort Our colleague Andrew Holbrook is sort of a shadow fourth author on this paper. He introduced us to all sorts of computational statistics literature, and there was much more of a prehistory on this than we realized as we developed this abstract theorem. So what pops out of this in the finite dimensional case where you have a Lebesgue measure based on continuous random variables is the Metropolis-Hastings-Green algorithm. Is the Metropolis-Hastings Green algorithm, which is actually surprising, but maybe not from the history of this area of computational statistics that they didn't see that this was immediately connected to Hamiltonian Monte Carlo. And this earlier work of Tierney, which formulates the accept-reject mechanism in the accept-reject mechanism in terms of radon-nicodyne derivatives, falls out as a Nicodyne derivatives falls out as a special case of our theorem. And you can conversely use Tierney sort of twice as a proof of our general framing. Okay, so here's this sort of generalized algorithm that encompasses HMC, Infinity, HMC, MALA, and PCN. And you see actually that the reasoning. The reason it works is that each one of the steps of our of the of the of the of the algorithm sort of is preserves is an absolutely continuous transformation, that's what I want to say, with respect to the this sort of class of Gaussian base measures. So, and you can think of this f that appears in this algorithm as base. that appears in this algorithm as basically anything that has decent regularity from at least from the point of view of from the point of view of algorithm from the point of view of maintaining reversibility so will will will will work okay in terms of as as an algorithm so this is a this is a basis of of a sort of surrogate trajectory Of a sort of surrogate trajectory method, if you like, general basis for that. I'll say just a few words about the proof. And this is one of these things that if you see the right framing of the problem, you get a very simple sort of several page proof. And so when we want to sort of obtain this reversibility condition, we see that in this kernel, the accept piece is. Except piece is the only piece that you want to actually need to check. And so, using the fact that S is an involution and that the just basic properties of push forwards, you see that, and with simple sorts of identities, you can develop, you can sort of develop a whole calculus of push forwards. You obtain this balance condition. Very, very cleanly. All right. So let me turn and describe some extensive numerical experiments we worked on with this model, this recovery of a divergence-free vector field from a passive scalar. And we wanted to see, like, you know, for this problem, could we, in fact, In fact, could we, in fact, resolve this posterior, this Bayesian posterior that we would obtain? So just developing examples here is a sort of full-time job for an incredible PhD student. And our idea to sort of see if we could resolve complex correlation structures and Complex correlation structures and so on would be to take data in such a way that we'd have certain symmetries in our problem that in this case, a true vector field V and its and reversing the orientation of the vector field would give the same data at some specific points in space and time. And there are lots of natural within this galaxy. Lots of natural within this Gaussian framework, I should say, there are lots of nice priors that you can bring to bear, sort of inspired by turbulence in fluids. So just a couple words about the scale of these experiments. You know, we're talking tens of millions of samples. Each sample is costing you a PDE solve at a A PDE solve at high dimensions. And I can give some specifics, but you get an idea here about the sort of relationship in terms of cost and sort of practical terms between PCN and HMC for particular parameter choices of our integration time. Francois, how long do I have? I'm just. I'm going to say 13 minutes. To say 13 minutes. 13 minutes? Okay. So I'll just briefly say that our first observation is you can resolve incredibly rich structure using these methods. And by the way, I should say the results on the Metropolis Hastings that I just presented to you came later. So we hope to use this as a basis for further. Basis for furthering our numerical experimentations. But using both HMC and PCN, we're able to resolve incredibly complex correlation structures. This is the projections onto Fourier modes of our posterior. And here's two-point correlation structures for vorticity fields and for one and two-point statistics. One and two point statistics for the different components of our velocity field. And on a per sample basis, of course, HMC is much, much more effective. And you see this in terms of the looking at trace plots of the likelihood function, of the individual Fourier modes here, of our autocorrelation function. And when we And when we look at this sort of grid that I just showed you at 150,000 samples, you can see that HMC is resolving much of the structure where PCN is sort of is sort of just getting at little wisps of it. But in the end, on a sort of wall clock time basis and taking into account that I think it's You know, there, I think it's something on the order, if I'm remembering correctly, of something like 32 PDE solves versus one for PCN on a sort of wall clock time basis and all the different ways we measure this, it's sort of a wash. And I think there's a lot more on a kind of a practical experimentation basis to sort of compare these different methods and how effective they are in practice. But in our experiment, But in our experimentation so far, it's sort of a tie. Okay, so one question coming out of this was to actually, and I think this is directly relevant to some remarks of Richard yesterday. We'd like some guarantees on these algorithms, but we're studying. But we're studying something that's infinite dimensional and in infinite dimensions, measures tend to be mutually singular. So one would like to consider alternatives to Washerstein distance. There's a beautiful theory that's developed in recent years on sort of weak Harris theorems around Washerstein metrics of weak convergence that sort of avoids this problem. And it can be if one. If one obtains such contraction estimates, one can get, you know, sort of law of large numbers and central limit theorem type results on the basis of these contraction estimates. So we started out with a, or we're starting out with a sort of an idealization of this method due to Beskos and collaborators, this Hilbert space-based HMC, and our ideal. HMC, and our idealization is that we consider that we can exactly resolve the dynamic, where they show in 11 by a kind of spectral approximation argument reminiscent of the Hamiltonian PDE literature around the work of Organ, that indeed the resulting Gibbs measure is invariant with respect to this dynamic. This dynamic. So we're able to actually approve a mixing result in a certain weighted Washerstein norm, as I display below here, or I should say pseudometric, I shouldn't say norm at all, pseudo-distance. But this pseudo-distance encapsulates sort of small scales and large scale contraction in the dynamics. Large-scale contraction in the dynamic. And we have that up to an integration time, which is dictated by the Hessian, a uniform bound on the Hessian of what's effectively for us a likelihood function and the top eigenvalue of the Bayesian prior, we can get an exponential rate of convergence to equilibrium. And this sort of And this sort of contraction estimate. And one of the things about a result, by the way, is that we're actually able to study these global bounds in the context of this model problem for us, which is this advection diffusion equation. But it ends up involving some fairly sophisticated PDE analysis. Analysis, and maybe somebody smarter than us will be able to go farther, but we're able to get this sort of point measurement case only in a time-stationary regime and the general global bound on the Hessian in terms of spatially averaged observations. So it's on our sort of agenda to address the metropolized version of this, but you do get central limit theorem and law of large numbers. Theorem and law of large numbers results out of this. And I should really emphasize that I think one can go deeper, although maybe more at the level of toy models in understanding better integration times and so on. But this weak Harris theorem provides an excellent framework for the study here of these problems. And I think a lot more needs to be. These problems. And I think a lot more needs to be understood, even at the finite dimensional level, about the mixing properties of Hamiltonian and Monte Carlo. So here's just a few words about the weak Harris theorem. These mixing results sort of classically correspond to creating an explicit coupling between two, you know, the two-point. You know, the two-point Markov process starting from two different points and seeing that the coupling induces a contraction. And one expects this from Lyapunov structure at large scale, certain irreducibility and local smoothing at intermediate and small scales, and sort of the genius of this work around error and Mattingly is to sort of show. Is to sort of show that you can construct an appropriate sort of pseudometric, pseudo-pseudometric that you can achieve this contraction sort of all at once and avoid these explicit constructions, which are quite Byzantine in the previous literature. So, but So, but how do you see this Lyapunov structure and how do you see this irreducibility in this Hamiltonian dynamic? I think you get some insight in how this connects to Hamiltonian systems. And even though Hamiltonian dynamics is, so to say, energy preserving, the reset step inherent in the HMC algorithm is a sort of energy. Is a sort of energy removal mechanism. So, if you're at high kinetic energy, you expect that some of that is converted into kinetic energy, and then it's just reset away as you run this chain. The irreducibility properties lead, the irreducibility and small scale properties lead to very interesting control problems from a Hamiltonian dynamics point of view that if I have Dynamics point of view that if I have two initial positions and a momentum, can I choose a perturbation of the momentum in the second process so that we get some kind of contraction after enough steps. And so you can kind of view this appropriately as a control problem and cost of control problem that you can avoid explicit coupling. Can avoid explicit coupling techniques here. So, maybe I'll just spend the last couple of minutes describing some things about what we were proving about consistency here. And from a kind of simple-minded point of view, you know, our obstructions are one, for a particular observation procedure, can we sort of fully resolve at the level of the posterior message? Posterior measures, the solution theta. But there are sort of some fundamental symmetries in the U to theta map, which show that that map is not invertible in general. So if I have a stratified and say, I guess I'm doing X, and my velocity field is pointing all in the Y direction, then solutions you're going to obtain. Solutions you're going to obtain of this PDE are going to be of the one-dimensional heat equation. And therefore, you have to be careful about you don't even have invertibility because all of these different y directed velocity fields are going to give you the same solution, theta. And, you know, we come to see the prior as our friend. our friend we we we we we we use it to sort of rule out increasingly wild uh solutions uh wild uh choices of you to sort of match the data as you get more and more uh data and these sort of infinite dimensional problems so um uh in the end and and i you know i see this as kind of a a a um uh uh a first step but in the end we're we're we're choosing an observation End, we're choosing an observation procedure that's similar to those discussed by Richard Nickel and others. But with regard to this lack of invertibility, we do find that if we choose our initial solute concentration so that we maintain a sort of that they that they that they're not that the gradients of the solute concentration are non-parallel off of Are non-parallel off of a set of measures zero, we indeed can get a certain invertibility. And so, if we think of running two controlled experiments, in effect, where we have two different initial conditions that satisfy this initial solute concentration condition, we can indeed obtain in all Sobolev spaces of sort of lower order than our Lower order than our true velocity field, weak concentration and limit as n goes to infinity. And the role of the prior here is to sort of main, to sort of control a tail condition. And one of the things that I think we want to keep thinking about, this condition, I can prove. This condition, I can provably show applies in the case where our prior is, you know, has bounded support. The Gaussian case, I think, remains open, although I think there are similar sorts of difficulty in other work that was presented for this condition I'm listing here. Here. So, in any case, we get a concentration. I'll again emphasize that we see this as sort of experimental design in a certain way. And to put this in a certain perspective, maybe there's work I'm not aware of with many experts in this room, but I think one of the features, we don't have rates of convergence, but one of the features of our But one of the features of our approach is that our forward map, we only need that it's invertible. So I don't know that we can obtain, or it's maybe possible, but we have not been able to obtain Lipschitz bounds on the inverse map, even locally Lipschitz bounds on the inverse map. And so I think we have a framework that, and given how hard some of these problems are, that we can still obtain sort of consistent. That we can still obtain sort of consistency, even if we don't have this Lipschitzianity on the inverse map. So, maybe I can say just a few quick words about the proof, depending on time. The first step is indeed to observe that your observation procedure is sort of resolving something that places a penalty on differences in the Penalty on differences in the theta and some in some norms, so sort of identifying large divisors. And so compactness plays a very crucial role in these type of results, I think. And so the relish compactness theorem is what allows us to sort of develop a uniform law of large numbers so that we're able to indeed sort of recover the true scalar field on sets. On sets of large measure, like so. And as I said, and as we emphasized from the beginning, the continuity of the inverse map is not true unless you consider it as this sort of compound map from two different controlled experiments in our problem, maintaining this sort of initial concentration condition. Concentration condition, and then using again compactness in this elementary observation from analysis that was pointed out, I think, one of the talks, which is that every continuous injective function on a compact set has a continuous inverse. So that's all we're using for this problem. And then simply making use of Portmantau's theorem to theorem to to to obtain um to obtain weak convergence uh from from there all right well so um maybe i'll i'll wrap up i think you know the bayesian approach is is a compelling methodology for these pd uh inverse problems from from a uh sort of fluid measurement uh perspective we've been looking at this um this uh this this this particular problem of This particular problem of recovering the velocity field from a solute. But I think there's a number of other PD fluid measurement problems that are really quite compelling within this Bayesian framework. I think this we Carris theorem is a powerful approach to get rigorous rates of convergence on various infinite dimensional. Various infinite-dimensional MCMC algorithms that have been developed. And having a sort of grand unified picture of this metropolis-Hastings algorithm, I hope in future to have a lot more to say to you about using this as a sort of basis for developing surrogate trajectory methods. But I think it's useful to have this sort of grand unified picture about how all these algorithms fit together. All these algorithms fit together. And so, and this consistency is really very interesting and compelling problem that I think requires a lot more work in this context. So, I thank everybody for their attention.