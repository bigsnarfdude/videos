For future research related to a meromorphic version of many of the constructions that I'll spell out in more detail today. Okay, let me give you some context for this talk. This fits into the broader theme of constructing good function spaces of iterated integrals. Today, this is specifically about compact Riemann surfaces sigma of arbitrary genus H. So unless specified other ones, So, unless specified otherwise, you can assume the genus throughout the talk to be arbitrary. Choose your favorite one. And also, concerning moduli space, I'm not tied to being on the hyperelliptic locus. So, replace the word higher genus Riemann surfaces by saying either hyperelliptic or maybe not. Okay, so this is the broader research agenda into which these results embed. And I guess this is also the research program. And I guess this is also the research program of many people in the room. So I really hope that this talk will be a useful conversation starter. Now, to get slightly more specific, a midterm goal that hopefully becomes more accessible with these results is to get a handle on the differential equations of iterated integrals on Riemann surfaces. So, most obviously, we look at differential equations in the marked points, but usually by construction, polylogarithms solve. Construction polylogarithms solve nice differential equations in the mark points. But I also hope that in the next year or two, we get to the differential equations in the moduli, which in the genus I case is differential with respect to the modular parameter tau of the torus. So many of the current research is motivated by the goal to maybe next year spell out differential equations for the moduli of higher genus surfaces. The moduli of higher genus surfaces, say in period matrix entries. And yeah, such differential equations that go all the way to the moduli have numerous advantages. So for instance, this could be the ticket to develop a symbol calculus on higher genus or efficient expansion methods. I mean, you know it quite well from Genus One, where many expressions you simply expand around the cost, where the A cycle of Potorus pinches, and at higher genus you have some more degenerations to look at. Some more degenerations to look at. And differential equations in the moduli will be good for you to get efficient expansions starting from some corner of moduli space. And it's probably good to have control over many such corners. Yeah, so this is about the dreaming ahead. And what will happen concretely today is a crucial stepping stone towards the goals above. Namely, I will bring some relations among the Bring some relations among the integration kernels of higher genus surfaces, which generalize the partial fraction relations from genus zero, and the Fe identities that practitioners of elliptic polylogs know, Fay identities satisfied by the Kronecker-Eisenstein kernels used in various constructions of elliptic polylogs. Yeah, so this is the context. Is there any question on that? Question on that before I go into more specific things? Okay, so as I said, most of the talk is taking place on a Riemann surface of arbitrary genus. So it is depicted like that here. So we usually start characterizing a higher genus Riemann surfaces, a Riemann surface by its homology basis. So here is a concrete choice. So here is a concrete choice of a homology basis. You pick a couple of cycles, some of them drawn in blue we call A cycles, and others drawn in red we call B cycles. And that splitting an A and B cycle is just there to define a canonical intersection pairing. So here we are picking a homology basis, formally written like that, such that the The intersection matrix is block off-diagonal in the sense that the A cycles don't intersect among themselves, the B cycles don't intersect among themselves, only if A meets B cycle, there is an intersection plus minus one, namely when you are setting their indices to be equal. Equal. Okay, so this is the basis for homology I always have in the back of my head. And then we should next talk about co-homology. And I won't give you a full 2H-dimensional basis for that, but you can always pick little h of these cohomology basis elements to be holomorphic. So there are holomorphic. H holomorphic or abelian differentials to be denoted by omega subscript I of x. So at genus one, this is simply the dz differential. It's just a single holomorphic differential at genus one. And then starting from genus two, there will be several of them. And yeah, a word about the indices. A word about the indices. So, whenever you see capital letters ij somewhere in the middle of the alphabet, then say, sorry? It's just I'm a bit confused with the yes. Oh, should I should I swap? Yeah, if those are cycles, then the one should be down, and if downstairs are different, then the one should be up. Oh, okay, okay. Differential forms have the one upstairs, cycles have the one. Have the one upstairs, cycles have the one downstairs. My apologies, thanks a lot. Good, yeah. So, indices, i, j, and so on run from one all the way to h, the genus. And I will use Einstein summation conventions. Whenever you see a repeated index, then you can assume it is summed over. Okay, and now let me state some condition that specifies the basis choice among the abelian differentials. We normalize that. We normalize them on the A cycles in the sense that this pairing here should become chroneca. I can always enforce that by making a neat basis choice among the abelian differentials, omega. And with this choice, I no longer have control over the B periods. So if I now integrate these omega j's around the B cycle, I get what I get. And this is the period matrix. And this is the period matrix often denoted by omega. It is symmetric by Riemann relations, not so difficult to prove. And you can view them as a parametrization of the complex structure moduli, sometimes an overparametrization, starting from genus 4, but this won't be an issue today. Okay, so this. Okay, so this is the period matrix. And most of the objects I will manipulate today will be functions of the period matrices, but I'll be lazy and don't spell it out all the time that this is f of omega. But I will spell out the dependence on marked points on of various objects you will see in the rest of the talk. Yeah, then I should state. I should state some conventions on the index management. So these indices ij and so on that run from one to h will appear both upstairs and downstairs. I will try to be more careful with the positioning than I was with the one of the h ones. And I will raise and lower indices with the imaginary part of the period matrix. So the conventions for index management. The conventions for index management are such that here with this imaginary part of omega, which is still symmetric since omega is, and with the upstairs version referring to the inverse, I will sometimes raise and lower indices. So, most prominently, I will refer to complex conjugates of the abelian. Complex conjugates of the abelian differential, which are here with an upstairs index, which tells you that there is an inverse period matrix baked in. This has some advantages for the modular transformation, that under modular transformations, you only see the meromorphic omega ij and not their complex conjugates. Maybe some of you have done such tricks at genus one, and that extends smoothly to arbitrary genes. Smoothly to arbitrary regime. Okay, and the last thing I want to say among the basics is Riemann bilinear. So, for instance, if you are working with these raised indices and implicit inverse y's, then there's a very simple formula for integrating a generic volume form. So, at genus 1, the volume form will just be a multiple. Volume form will just be a multiple of d square x. But now at higher genus, there are h square options to pair an abelian differential with its complex conjugate, both bringing their own indices and they can be chosen independently. And this h square worth of volume forms integrates to Chronicle. Okay, so these will just be some Lego. So, these will just be some Lego bricks that you will see in the subsequent constructions. Now, let's get more serious. My first goal is to introduce some integration kernels that, as I will claim, generalize the Kronecker-Eisenstein series, the genus one. And for that, we need to introduce some more tricky functions on the surface. Tricky functions on the surface, which are not holomorphic, but instead have some simple posts or logarithms. And we start building them from what many people call the string Greens function. Maybe I'm biased by my background, but let me explain what kind of Greens function I have in mind. We proceed in two steps to build a Greens function. Step one is let's One is, let's build something Meromorphic that vanishes linearly with x minus one at the origin, which at genus one is simply the theta one, the unique odd Jacobi theta function. But at higher genus, you need to be more careful about what is theta one. So it is still true that theta functions make the music, but you need to be a little bit more careful which theta functions. Bit more careful which data function you use. So don't worry if this is not your daily bread and butter. I'm just giving this as a conversation starter that you can read up more on this. So this is maybe more on those who have already seen a higher genus data function in their life. So pick an odd spin structure or characteristics new. So a genus 2, for instance, there are 2, for instance, there are six choices of odd characteristics which make this an odd function of that argument. So, all of these six choices at genus 2 are equally good to have a linear vanishing as x and y go together. But which of the six should I pick? And to be independent on that choice, there are some funny denominator objects here. These are half differential, admittedly slightly unauthored. Admittedly, slightly unorthodox objects, and the best way of defining them is by telling you what their square is. So these h nu's downstairs are square roots of the following object. Contract the abelian differential with a theta derivative. Sorry, a derivative of a theta function with respect to the first argument. And then evaluate that at Then evaluate that at zeta equals zero. So at genus one, this is simply the derivative of theta one at the origin, which you need to normalize the prime form to make sure that it vanishes with one times x minus y and not a funny... Sorry? Oh, yeah. Yeah, so the entire integral is its argument. So typically, this theta function takes a vector with h Takes a vector with H components as an argument. And this H component vector is having components. Well, take one of the abelian differential and integrate like here. Okay, so at various points, I'm referring to the odd spin structure. And great news, this combination is independent on new. So the denominators are doing exactly what they should to compensate. They should to compensate the dependence of the numerator on μ. And this is something quite serious because the numerator would have extra zeros, vanishes at places where you don't want it to vanish. And the denominators cure that. Okay, so the prime form is a really standard object which you can read up on in Tata Lectures on Theta or in the Book of Bay and other references. I just wanted to make sure it is briefly getting reviewed. And yeah, the prime form is a key structure in building the string Green's function. Or from a conformal field theory point of view, it's a two-point function of a free boson on a higher genus Riemann surface. And more pragmatically, it's a version of the logarithm, a version of the logarithm which is more or less tailored to the periodicities. Tailored to the periodicities that you expect for all of these homology cycles. Okay, I'm promising a logarithm. Here I'm writing a logarithm. Since the prime form vanishes linearly as x goes to y, this has the correct singularity structure. And the periodicity properties, well, I was a bit lazy and didn't spell out how the prime form transforms as the mark points go around the cycles, but let me just say. But let me just say, here is a kind of compensating term to eliminate the worst monodromies. So, what is happening here? Here are again some abelian integrals, h component vectors of omega i integrated between the points. And we take a bilinear in these imaginary parts and contract them in the inverse period matrix. The friends of the Taurus may recognize. The friends of the torus may recognize it as the non-harmonic term in z squared divided by in tau in the Green's function on the torus. And this is an uplift to arbitrary genus. Okay, so it is these objects that will enter as the seeds to the higher genus integration kernels, which in turn we claim are a good way of generating polylogs. Oh, yeah, and I think that's. Oh, yeah, and I think there's just enough space to make a key comment on the poles. So the integration kernels to be used here have poles at most of order one. I mean, this is not automatic. There are also very nice approaches to user connection with higher order poles. So I just want to be clear that in this talk, we have at most simple poles. Most simple poles, and they are realized through the prime form and the Green's function. So, more precisely, you get this simple pole from both the logarithmic derivative of the prime form and likewise from the derivative of the Green's function. Yeah, so view these objects as a kind of completion of the simple pole to have good periodicity properties tailored to the surface. Properties tailored to the surface. Okay, so these are the atoms of the construction. Let's now come to the molecules. Let's now so a counter example would be the Weierstrass function at genus one. function at genus one. This is a beautiful way of completing the Denam cohomology. Or at higher genus I can use the double derivative, not only partial x, but additionally partial y of log e. And also this you find in various places of the literature. So the attitude in this talk is if you find yourself needing to integrate a double pole, use integration by path until you're landing on the integration. You are landing on the integration kernels with simple poles that I'm about to introduce. Yeah, I would say it is. It is, yes. Or, okay, partially the limits of the failure entities in later parts of the talk will help you do this in more general situations. But there are definitely pros and cons to either approach. So the Weierstrass function with a double With a double poles is really good if you want to work on the polynomial description of the torus through the elliptic curve, y square equals degree three or four polynomial in x. So there can be many, many reasons to prefer such a higher pole construction. Okay, so here is now a lightning review. So here is now a lightning review of the polylogs that we constructed in the paper from last year, June, with Eric Doker and Martine Hitting. And step one is to review the integration kernels, which will make essential use of the rings function from over there. Yeah, so since I keep on pointing out that simple pole here, what is happening is that we embed this simple pole into an H times H matrix of integration kernels, which require two indices to be specified. And spoiler alert, this will be the higher genus version of the Kronecker Eisenstein F1, which the elliptic positive. One, which the elliptic polylog experts know is the only Kronecker Eisenstein kernel with a simple pole. And indeed, we have the simple pole from the Green's function on the diagonal. So up to here, it looks a little bit weird that I'm introducing these indices and try to sell you more than just one higher genus version of F1. But there is an issue about the Spring Greens function. About the string Greens function, that it's not conformally invariant. You may prefer to switch to a different Green's function, and it's particularly nice if you make the construction such that everybody can use his or her favorite Green's function. So to attain independence on the choice of Green's function, we put in this convolution integral. So here the indices go on the Here, the indices go on the abelian differentials. More precisely, these two indices characterize a volume form against which I'm integrating the derivative of the green space. And I don't think you see that at genus 1 typically, because if there's only a single volume form like at genus 1, that is just a trivial constant that you subtract everywhere. No need to talk about this at genus 1. But since, starting from genus 2, we have multiple volumes. from genus 2 we have multiple volume forms for choice it is really important to know where in this h by h matrix indexed by i and j we are so this is one way of motivating why i want to have h times h such integration kernels that generalize f an alternative motivation is to look at the laplace equations or the anti-holomorphic derivatives maybe we can discuss this in private if you want to hear more about it You want to hear more about it. The anti-holomorphic derivatives of this object have some drawbacks, but that term is largely embellishing the anti-holomorphic derivatives. This is a second motivation, why to add this convolution here. But okay, I think I've already broken the ice. There is a first convolution integral here, and we can repeat that. We can construct higher. Repeat that. We can construct higher rank integration kernels by convoluting further against derivatives of Green's functions. Yes, please. Oh, yeah, the the second you mean here? It looks the same. I can just switch to the Ara-Kalov Greens function. This is how we present the construction in our papers. Yeah, I actually took this talk as an opportunity to tell the story slightly different as how we write it in the paper. So in the paper, we go to the Archilov Greens function on line number one. And here I want to. Line number one. And here I want to point out: you don't have to do it. It's nice if you do it, because then the integral is really well defined on the surface and not a fundamental domain. But if you want to stay closer to the prime form, you can do everything with a string green function. It really depends on you. But I would not recommend to alter the expression here. Namely, if you do, then you are in trouble getting a flat connection at the end of this. Getting a flat connection at the end of the day. So the flat connection to be written in five minutes will suffer if you remove that term or do other things. Okay, so here is the higher rank integration kernels. So there's once more the anti-holomorphic abelian differentials, which have some index. And now I'm convoluting. Convoluting stringreens function with the integration variable in the second point against a lower rank F tensor. Okay, so this is a recursion relation that you can use starting from R equal to 2. So take this as a base case and then stick it into that. So we are appending more and more indices to these F tensors. Says to these F tensors, which are tracking in which order we were doing the convolutions against the different abelian differentials. And the order matters a lot. So this won't have any symmetries in permuting the upstairs indices. Please keep track of your convolution order. Oh, yeah, the things to be built from that will be special cases of chance iterated integrals. I guess chance theory is super general. So I think what you are asking for will be answered in three minutes when I write down a generating function of polylogs using that. Please remind me if I don't answer the question in a few minutes. I would say it's a it's a feature that your family of integration kernels has many many members that already at transcendental weight one I have h by h members and this is important to make the polylogs close undertaking primitives and if you don't put enough members into that function space maybe you're running short of primitives Space, maybe you're running short of primitives. And I will try to argue, based on the failure identities at the end of the talk, that it's pretty necessary to have all these components out there to guarantee that the polylogs constructed from these kernels will always allow you to find a primitive with respectful mark point. It will pay off at the end of the day. Please. Oh, well spotted. Thank you so much, Andre. Absolutely. Thank you. Okay. Yeah, so all of them are by construction one forms in X and scalars in Y. And yeah, I wanted to make more contact with the Taurus. So on in the specialization. In the specialization to h equal one, if we go back to the torus, then you get on the nose the chronecker kernels, namely the number of upstairs indices equals the superscript of your Kronecker Eisenstein kernels. So the number R of upper indices. Number R of upper indices simply becomes that superscript, which is traditionally put in parentheses. And on the torus, we have translation invariant, which is no longer there at higher genus. So at genus one, these kernels happen to only depend on the difference x minus y. But it's important at higher genus to preserve the comma. I mean, at higher genus, there is really a separate dependence on x and y. It doesn't simply On X and Y, it doesn't simplify to say the difference, not even after Abelman. Okay, so this is why these integration kernels here make smooth contact with genus one polylogs, most specifically with the Brown-Levin approach to generate elliptic polylogs from iterated integrals of these F kernels. Curves. Yeah, and I advertised the string Green's function or Arakelov Green's function for its periodicity properties. These kernels are all single-valued on a pair of surfaces, so both X and Y. No monodromy as they go around the A cycles or the B cycles. And in meromorphic descriptions with simple poles, this is usually not the case. I will comment on a connection. I will comment on a connection introduced by Enriquez, which is meromorphic with simple poles, but has monodromies on the B cycles. Okay, so let's now do the polylogs coming from these integration kernels. So there's admittedly some non-meromorphicity in bits and pieces. The string rooms function is very non-meromorphic. And also, after the Meromorphic and also after the derivative in x, it stays non-meromorphic. So clearly, this is not a meromorphic function in x and y. But integration over x and y, well, you better want to be homotopy invariant. You don't want integrals to depend on the path. And with non-meromorphic ingredients, this is quite tricky. So you need to work hard that integrals of f's don't depend on the path. F's don't depend on the path. And this will be ensured by building a flat connection. And this is literally the philosophy used by Brown and Levin to construct elliptic polylogs. The main difference is that various variables and building blocks acquire indices now. So, fans of the Brown-Levin paper know that there will be a Lie algebra with one generator per homology cycle. A homology cycle in which the flat connection takes values. And now that we have HA cycles and HB cycles, we need more non-commutative variables than in Brown-Levin. So here, this is a freely generated Lie algebra in two H generators. And this is where the connection takes values. Okay, now let me write down the connection. It is a combination of dx. Combination of dx bar terms and dx terms. It's a mixed form of one, zero type and zero, one type in x. And okay, for the dx bar part, I will be pretty modest and just write down a single term. Nabelian differential contracted in sum of the generator's mean. And most of the complexity is sitting in the x part, the one comma. X part, the one, zero form part, where, not surprisingly, we have the abelian differentials. And now, for those who remember the genus one construction, I have to put in an F1, I have to put in an F2, I have to put in an F3. There is now an infinite tower of these F kernels. So this infinite tower structure is exactly the same at higher genus. And we once more decorate them with the B generators, more precisely with adjoint actions of the B generators. So here, in case of the two index F, which has a simple pole, it's a adjoint action right here. And then the next F will have a pair of adjoint actions. And clearly, these adjoint actions don't commute. So you have to be very careful. So, you have to be very careful in which order you write them. And this ties in with my earlier warning that also here, be careful about the ordering of indices. Yeah, and this will be used as a generating function of polylogs. And the key expectation on iterated integrals is homotopy invariance. Is homotopy invariant. I only want to depend on the endpoints of an integration path in a given homotopy class. So I want to present these polylogs as a function of x and y, and not as a function of the detailed description of the path in between. And the reason this works, the reason why this flat, this connection here. This flat this connection here produces homotopy invariant iterated integrals is that it's flat. So the differential with respect to the point x gives you dj equals j, which j. It solves the Maura-Cartan equations, and that's why iterated integrals of J are homotopy invariant. Yeah, and this is one of the Yeah, and this is one of the motivations that I mentioned before why the construction is done in the way it is. So, for instance, you would have trouble obeying the flatness condition if it wasn't for this extra convolution term over there. Okay, so this, as I say, is a generating series in polylogs. And how is the component excavation done? So, this will be a huge power series. Be a huge power series in the non-commutative variables, the little a's and the little b's. It won't be in the Lie algebra anymore, but in the universal enveloping algebra, which you probably can guess from the X symbol here. At any rate, I can expand it in words. So here, w denote words in all of these letters. And now the coefficient of each word is Of each word is defined to be a polylog. So we define hyogeneous polylog by the instruction: take that path-ordered exponential, expand it out in the A's and B's, and then read off the coefficients of different words in A's and B's. And since the entire PxP is homotopy invariant, so will be all the coefficients. Homotopy invariance holds word by word in the Holes word by word in the X's and Y's. And again, all of this is strongly guided by the Brown-Levin construction at genus one. So if you specialize this to genus one, then it's the Brown-Levin polylogs. Maybe I should finally give an archive number after mumbling the names so many times. Here. Here it is. So, specifically, this connection up here, restricted to genus one, gives you the Brown-Levin construction connection. And if you want to have all the details of the dictionary, the non-commutative A variable in Brown-Levin is almost the above A. There is a little shift. Above A, there is a little shift by pi over m tau times b. But okay, this is pretty normal if you compare different flat connections. It's almost the standard case that you need to apply some variable transformations. Okay, so this concludes the presentation of the higher genus polylogs. So don't worry if you haven't Sorry if you haven't 100% memorized all the details of that. The only thing I want to discuss further about is that there exist integration kernels. We have handle on them through integral representations and they are single valued in both points x and y on the surface. Their iterated integrals will generate higher genus polylogs. Generate higher genus polylogs. Okay, and now I would start discussing the functional identities among these Fs, or essentially the Fe identities. Hyogenous generalizations of the Fe identities among the Kronika Eisenstein FK kernels. Any question before we start with Fay? So here I'm getting into the work in progress part, specifically a paper that Eric and I plan to. Eric and I plan to put out by the end of the month. But yeah, before doing the higher genus version of that, let me try to motivate you with examples from the sphere and the torus why something like Fey identity is necessary and interesting. Please. Let's say the homotopy, yeah. So the obstruction to homotopy invariance is measured by dj minus j which j. Or putting it differently, you look at the differential equation of that thing. So maybe let's give it a name for ease of writing down that differential equation. So this option. So this object double line gamma has by construction this differential equation. And now the question is, is that integrable or not? Hit it with another D operator and then to assess whether it's integrable or not, you will need to check if this Mauger-Cartan equation is satisfied or not. So if the differential equation is not integrable, this is a symptom. Integrable, this is a symptom of having integrals that depend on the path. Okay, I was about to start into a genus zero incarnation of phase type identities. At genus zero, this is just about partial fraction. And why do I even dare to bore you with partial fraction relations? What I want to What I want to point out here is that partial fractions are essential for genus zero polylogs to close undertaking primitives. So here, these are the good old Gonshavov polylogs. I hope everybody has the definition at their fingertips, iterated integrals of D-log forms. But suppose you want to integrate it against a quadratic denominator, not only a single D-log form. Not only a single delug form, but a product of two of them. Then, in the first place, you can't just apply the definition of Koncharov polylogs. Instead, you first have to rewrite the integrand a little bit such that the denominator is linear in x. We can't do the quadratic one, but we can do the linear one. So, what I'm doing from left to right is To write is I apply a partial fraction relation. Rewriting this fraction here as that one plus or minus its image with y and z interchanged. So we do a partial fraction inside the integrand. And now we are in the out of the comfort zone of the Gonsharov polylogs. We can just do these integrals in the Do these integrals on the right-hand side using the definition. So here, this integral against the dx over x minus y just means that we pre-pend the letter y next door to all the other letters vector a. Okay, so this is in practical terms how partial fraction implies the closure of genus zero poly. The closure of genus zero polylogs under integration. I guess it was firstly pinpointed in this way in a Brown reference from 2006. They close under integration over Z. Okay, so this is a genus zero motivation and quite Genus zero motivation, and quite similarly at genus one, when you deal with elliptic polylogs, either in the Brown-Levin formulation or some meromorphic variants thereof. You may be in similar situations where you can't just apply the definition of elliptic polylogs, but perhaps you're facing a product of integration. Facing a product of integration kernels that you need to simplify before proceeding. Okay, so let's take a look. How could such a J identity look like? And well, partial fraction is about simple poles, and we have a unique Kronecker-Eisenstein kernel which carries that simple pole. So a very naive prescription could be try uplifting these D-log kernels. These D-log kernels into F1s. So the most naive question could be whether we can simplify this by copy-pasting the partial fraction relation. So this naive copy-pasting would lead you to these terms. If term by term you replace the If term by term you replace the F1 by its simple pole, then this would be on the nose partial fraction over there. However, this cannot work because the difference is not meromorphic. Suppose you compute x-bar derivative on both sides, you find that this doesn't work. So you need to find a meromorphic completion of the right-hand side. And this is one way to motivate the results. Motivate the raison d'être of the higher rank or higher weight Chronicle Eisenstein chronic. So F2 is there to repair certain incompletenesses of F1. So F2 is, so to say, the tail of higher functions that is generated in an attempt to mimic partial fraction. So more generally, you need More generally, you need a meromorphic completion by F's of various ranks, typically two and higher. So this is, so to say, the new ingredient of the genus 1 Fe identities in which way they go beyond the naive partial fraction from genus 0. Okay, and yeah, similar to the genus 0. And yeah, similar to the genus zero story, Bay identities are a necessary condition for the elliptic polylogs to close under integration. So, informally speaking, you need to be able to eliminate a repeated appearance of x. If you're facing an integrand, which is bilinear in Kronecker Eisenstein kernel, you can't just run the definition, but there will always be a phase identity to save you. Be a phase identity to save you, to eliminate repeated appearances of the integration variable. So, suppose your mission is to integrate over x, then you will be offended by seeing a product like that because it has too many x's. Yeah, and this can always be resolved for any pair of integers r and s. Of integers r and s. And the explicit way of resolving the misery is here. Oops. Many of you have seen this formula, have worked with the formula. This is how repeated appearance of X can always be bypassed. So the right-hand side, I don't want to walk you in all detail through it, but the only thing you need to know about the right-hand side is that the integration variable. That the integration variable x appears once and not twice. So, this is, in practical terms, the reason why elliptic polylogs close under integration. You would be in trouble without Fay. So, to write a statement analogous to the genus zero story on the other blackboard, this Fay identity is your silver bullet. A identity is your silver bullet to guarantee that such an integral of elliptic polylog times two such Kronecker Eisenstein kernels is still contained in a function space. Maybe I was a bit sloppy in saying what exactly closes under integration. What exactly closes is products of polylogs times the F kernels. Kernels. And there can also be functions of tau, like one over m tau is all over the place. But at any rate, when we need the primitive of this object in our physics calculation, we definitely need to sooner or later go to that failure entity. Okay, this was genus one motivation. Oh, no, no. All genera will force you to go through all ranks. This comes from the closure, no, sorry, from the flatness condition on the connection. I didn't stress that properly, that flat connection already at genus one, has an infinite number of terms. And that's right, that's right. If you don't want that, you can. If you don't want that, you can work with a connection involving Weierstbas. And I think this has found less physics applications so far in comparison to the elliptic polylogs with the infinite selection of kernels. Absolutely. So a given Feynman integral may, for instance, decide to not involve anything beyond F green, for instance. And in string theory calculations, we use them for low. We use them for low energy expansion with respect to alpha prime, the inverse string tension. And to oversimplify a little bit, the order in alpha prime is the bound on the weight above. So in each physical situation I know of, you're usually cut off to only look at a finite number of kernels. Yes, yes. And I even have a counter. And I even have a counter example of my fingertips. For string amplitudes, it's often advantageous to look at generating functions of would-be string amplitudes to make them close under tau derivatives and other things. So there are situations where it's rewarding to tolerate the presence of infinitely many more. But whenever you ask about a specific order in Dimrek epsilon, specific order in alpha prime, I'm not aware of a counterexample as to. Example as to only finitely many F kernels contribute. At any rate, the Fay identity here at Genus1 works for arbitrary ranks R and S. For sure, the number of terms on the right-hand side will grow a bit, but it's definitely available for arbitrary pairs. For arbitrary pairs, RNS ranks. Time is flying. I think the chair persons have to stop me at some point. Okay, I think I'm getting to the final and main results that I wanted to deliver. Generalizations to fair identities at arbitrary genus. And what are the new qualities of genus two and higher? Well, the F kernels, as you saw, became tensors. There were indices ij running from one all the way to H. So starting from genus two, you can no longer close your eyes towards the tensorial nature of the kernels. And that will literally propagate to the Fe identities. To the Fay identities. So, Fay identities, again involving several marked points X, Y, Z on the surface, they will become tensor-valued. And there's something else which can be ignored at genus 1, at least in many applications, you can ignore it. We need to specify. We need to specify which leg enters through a scalar or a one-form. I don't think I have been too careful when to put the d-axis, but remember that the higher genus F kernels are one-forms in the first point and scalars in the second point. So here is the form degree. And accordingly, kidentities at higher genus will be one forms in two. Will be one forms in two out of the three points on the surface, without loss of generality in the first two. Okay, now I can write down the first instance of a higher genus phase identity, and to illustrate how closely related they are to genus one, I will just start rewriting this identity here. So now I more or less preserve the pairs of arguments. Y and X, X and Z. And instead of just writing F1, I need to write two tensors. And actually, the indices are frequently contracted. So there is a non-trivial index structure. We have three indices I and K. We have contracted indices J. And here is the higher genus uplift of the Fe identity from G. Of the Fe identity from genus one. Yep, so far, so good. Now, concerning the F2s, the F2s will have three indices. And I also need to be careful. There is a hidden F0 here, one. But the F0 will uplift to the abelian differential. So at genus one, I would just see a dx here. I would just see a dx here, or sometimes people don't write the dx and write one instead. But I need to be more careful with that at the higher genus. So that takes care of the first F2, and the next F2 is taken care of by this, yx. And finally, my last term, which looks like omega j of y. J of y and contracted like such. Okay, so I hope I erased all the minus signs. Remember, we no longer have translation invariants at higher genus. So they really depend intrinsically on two points independently, these F tensors. Okay, so this is once more showing you: if you don't like repeated appearance of X, you can apply. Of x, you can apply such a phase identity. Now it's a tensor-valued one. And this is h square components to this equation. And you really need h square components to eliminate possible scenarios of getting stuck with a repeated appearance of x. So this is exactly as many equations as you need to deal with repeated appearances of a given point. Yeah, this is not only. Yeah, this not only works at the rank shown here, but the combinatorics is worked out for an arbitrary number of indices. So now the room is getting too small. Oh, yeah, thank you so much for your help. Oh, fantastic. The room has exactly the right size. Okay, so this is a teaser to one of the results in the upcoming paper with Eric. The results in the upcoming paper with Eric, where the Fay identity here is just given a few more indices. So here I'm using multi-index notation. The vector arrow means as many I's as you wish, and here as many P's as you wish. And if you're worried about the contracted index, this is not so bad because the second marked point only appears in the trace with respect to the last two legs. The last two legs. So there's some representation theoretic yummy that guarantees that you have enough equations, even if there is a contraction inside your Fay identity. So this, we claim, is the complete family, infinite family of Fay identities that save you from getting stuck with a repeated appearance of X. And I dare to say this is an essential ingredient for the closure of the hyogenous polylogs under integration. Under integration. Okay, I plan to say something about the coincident limit when two of the three points are moved together, but maybe we leave this for private discussions. But if you want to know how holomorphic Eisenstein series generalize to higher genus, then ask me in a coffee break about the coincident limit when, for instance, Z goes to X. But what I really want to say. But what I really want to say is there will be meromorphic variants of higher genus Fe identities. By meromorphic, I mean they refer to integration kernels, which have the same index structure of the Fs, but are meromorphic in both the mark points and the market. In both the mark points and the moduli. Yeah, such meromorphic integration kernels were introduced by Enriquez already quite some while ago. And admittedly, there's not an explicit formula, but this is more a characterization through their functional properties. So Enrique's implicitly introduced a family of integration kernels. Of integration kernels, which from the index structure looks exactly the way like the Fs are looking. Single downstairs index and otherwise an arbitrary number R of upstairs indices for all ranks like that. So Enriquez shows that they are unique once you specify their poles and monodromy. Nodrumi. And he furthermore discusses, also in joint work with Federico Sabini, how they are useful to generate iterated integrals on higher genus surfaces, where everything is term by term meromorph. The price to pay is that single-valuedness gets lost. As you know from genus one, having simple poles and meromorphicity forces you into non-trivial monodromies. And Enricus defines these. And Enriquez defines these omegas through the B-cycle monogramies. Okay, and these omegas, even though explicit formula are not yet written down, are very close in spirit to the F's. I'm sorry that this is a rather fluffy statement for now, but in the same way as there are monodromies here. Way as there are monodromies here for x and y going around the b cycles, they are anti-meromorphic derivatives there. But x-bar derivative and y-bar derivative is non-trivial. And from a Plumbus point of view, you can transport the information from antimeromorphic derivatives here into the monogramies there. So these connections between antimeromorphic derivatives Between antimeromorphic derivatives and monodromies, are strong enough to uplift the Fe identities to literally carry over Fe identities among Fs that they become on the nose Fe identities among omegas. This is a conjecture, and Eric and I are highly. And Eric and I are highly grateful to all the discussions with Federico and Benjamin about this subject. We plan to write joint papers about the proof of that. For the moment, it's a conjecture. And the conjecture is pretty easy to state. Take a Fay identity among Fs and replace every F you C by an omega. Then we claim that this is a Fay identity for the Enriquez kernel, even not knowing an explicit formula for that. Explicit formula for them. So, roughly speaking, the sketch of the proof goes as follows. You look at right-hand side minus left-hand side and contemplate whether it's zero or not. And if it's zero, it should definitely be single-valued. No monodromies, please. And it's pretty non-trivial to manipulate objects with these many, many indices in a way that all monodromies cancel in X, Y, and Z. And besides being single-valued, it also needs to integrate to zero in a certain sense, which is maybe the hardest part of the proof. But yeah, if you are using these omega kernels in one way or another, there was, for instance, a paper today by Federico and the ETH group. And yeah, whenever you feel like using a Fe identity, just grab them from this formula here: relabeling any F you see. Enabling any F you see to be a Henrique's kernel omega. Okay, so I hope we are all comfortable with the shuffle symbol here. And just ask me if you would like to have a computer implementation. Good. Yeah, so the moral of that story is you can spend You can spend 80% of the project working with these F's and enjoy their single-valuedness. I mean, one of the practical virtues of single-valuedness is that you can discard total derivatives. So many of these Fay identities were built from discarding total derivatives recursively again and again. So it's really useful to have a function space where every member is single valued. And once you are done building your phase identities, then you can examine if they Then you can examine if they export to neighboring function spaces, like here. So, like these omegas, since they have monogamies, you have to be careful when it comes to discarding total derivatives or not. But it's at least good to get a candidate for phi identities from the f's and using their single-valued. I mean, proving a candidate relation is usually easier than deriving a relation that you don't know yet. Know yet. And I hope that in the future we can extend this kind of mindset to differential equations in the moduli. We are thinking about how to do this with the Fs and to maybe then export the results on differential equations of F's to the omegas. This is one of the follow-up directions. But now I went enough over time. Thanks a lot for everybody's patience. Thanks, Olivur. No worries about the time because it was 45 minutes plus 15 minutes discussion, but we already had a lot of discussions. So if there are some questions that we would not like to take to the coffee break, please please. And I don't know if people are there on Zoom. No, but there's no question also. Oh, okay. To be honest, I haven't even found a string theory understanding of the genus 1 situation with the 2 RI. Yeah, there would be. Yeah, there will be a talk by Andrei on the kite integral with two elliptic curves. Maybe one goal for this week is to find a bridge to string theoretic techniques and the coexistence of two elliptic curves in one Feynman integral. I don't have anything useful to say on this. Yeah, one question which we also um it matters for us a lot about is about the numerical evaluations of these ideal integrals. Of these hydrogen integrals. I mean, I understand these identities restrict the number of kernels that you can have, but for these hyogenous surfaces, do you also know how these non-meromorphic kernels for this polylog implementation would actually be easier to solve at some numerical evaluation at a certain point. I don't know. How do you do the numerical evaluation of these turn these uh integrals? The integrals? Okay, a practical implementation is still several sleepless nights away. The first step will be to expand around corners of moduli space. The F's at genus H degenerate to F's at genus H minus 1. And then you need a differential equation in period matrix entries to take you from the degeneration to the actual point where you want to have them. So this can easily take months to develop that. Take months to develop that in full glory. But the reason why I'm super optimistic is all the F's boil down to Agarkalov-Green's functions and convolutions thereof. And there is very concrete literature on degenerations of the Agarchlov Green's function. So it's just a matter of uplifting the known properties of Agarchlov-Green's function to the F's. That's the plan for the near future. Are you planning? I'll definitely be one. I'll get active on that. Yes. Action on that, yes. Uh, there more questions. If not, let's thank Oliver again and we resume in half an hour.