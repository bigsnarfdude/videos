Plus five minutes questions. You don't mind that your talk is going to be recorded? Is that okay with you? Any chance I can still escape? No, no, no problem. No, no. I mean, if you wish, you can. It's okay. Okay, it's fine. Thank you. Thank you. So, yeah, it's also for me. I'm sorry not to be with you. Must be nice over there. But in any case, it's nice that I can attend virtually. So I want to talk about some recent works I've been doing with Alain Korn and others, where we try to investigate what you can do with non-committed geometry or spectral geometry in general when you only have like parts of the spectrum available or when you have some kind of finite. Some kind of finite resolution at the spatial level, which is sort of dual in a sense. So the usual setup is, I will describe it quickly only, and I will actually not use too much of the technical details of that, but this should be kind of the general framework that we're working in and should be familiar to most of you. So the idea is that you combine an algebra, like coordinate functions on some. On some manifold, together with a self-joint operator, which is like a Dirac operator on a Riemannian spin manifold, which has certain properties, and they sort of meet by their action on a Hilbert space. The C-structure will be bounded operators, and the self-joint operator will typically be unbounded. And indeed, the example to keep in mind is smooth functions on the Riemannian manifolds. H would be the. Thoughts H would be this L2 spinners and D will be a Dirac operator. Now, the idea is that you can actually reconstruct from that the geometric structure. And a key formula for that is the following. So you, for instance, the distance, like the Riemannian distance between two points, they can be captured by this formula, which is actually a formula that is completely formulated in terms of. Completely formulated in terms of this analytical data. So it's about states, positive linear functionals on this His algebra. And pure states will be the extreme points of that convex set and this state space, where these will be evaluation at points in the case of cumulative C-s2 algebras like continuous functions on a manifold or smooth functions. Now the distance functions on the function on the state space is then given by a On this state space is then given by a supremum over the evaluations of these states at point A, but have to control these elements in the algebra A to lie in some kind of leap ball. So this means that this commutator with D, so the derivative essentially of A, is bounded by one in norm. And then I can actually reconstruct in the case of a Riemannian spin manifold the distance, the actual distance between points, but also between measures in a more general Measures in a more general kind of control sense. But that's the idea, and this is just to kind of get the setup right and to understand what we're talking about. So these things are the usual notion of spectral triples and gives rise to the spectral approach to geometry. And now what you need to know actually is quite a lot if you want to work with this. So this is somehow what I want to argue, is that you have to do, for instance, some kind of Have to do, for instance, some kind of solutions to differential equations. You have to do a lot of global analysis to understand this spectral geometry. And in terms of physics, you actually want to kind of restrict to some part of that. So you would only have a part of that data available by, for instance, measuring only within a certain energy range or with a certain resolution. So what I want to argue is: so, how can we actually How can we actually, or actually the question I want to raise is how can you actually approach spectral geometry when you only have like a part of the spectrum or a finite resolution available? And previous works in this direction were already around. D'Andrea Lizzi Martinetti, they worked on these kind of truncations that I will be considering as well. So they already studied this, and we developed the sort of the general framework for that. General framework for that. And so Glass and Stern tried to implement spectrogeometry on a computer. And that's also there is inevitable that you have to sort of confine to some kind of finite dimensional description or subsystem or truncation of the full spectral geometry. So there you are led to the same kind of considerations and wonder whether that actually approximates in some sense the original geometric space. So, these are two papers that I wrote in the last few years with Alain Kohn. And so, they develop this notion of operator system that I will now kind of motivate. So, if you have this, if you kind of agree on this spectral approach to geometry, so you have this triple A, H, and D, and you may wonder what happens if I restrict my spectrum to only part of it. So, like I take a spectral projection. It so, like, I take a spectral projection p, let's take it to be finite range, and then I look at the projection to the closed Hilbert subspace P of H. Well, there I can actually restrict my operator D as well, because it's a spectral projection for D. Only part of the spectrum is taken into account. So that's still acting as a self-adjoint operator. That's all fine. But the algebra A actually does not respect this, typically does not respect this closed subspace. So it does not. This closed subspace. So it does not act there. So, what I can do is I can compress this algebra with p on the left and the right and look at that part. This kind of this is just a set of operators, a vector space of operators, but it's not an algebra in general. Now, what is it? It's an operator system, which for me just means it's closed under the star. And it may also be closed under the norm, in the norm. But for now, the most important thing is that. But for now, the most important thing is that it's closed in the star under the adjoint. So that's one kind of natural appearance of an operator system. That's a vector space closed under the star, the vector space of operators closed under the star. Now, another approach is to consider metric spaces where you take a finite resolution into account. So you say that two points, x and y, they're like related if their distance is smaller than epsilon. And now that's not an equivalence relation because epsilon is fixed, but it is a so-called tolerance relation. So it's symmetric, reflexive, but not transitive. So you have to kind of deal with that. And so you may wonder, so what kind of operator algebra can I associate to that? Where I usually would take integral operators. When I take the support condition into account, so that the support lies on this relation, then I find that I cannot take product. Find that I cannot take products of these integral operators because this convolution product of the kernels would actually increase support from epsilon to two epsilon, etc. So I have to fix it. I cannot take a product, but I still have this symmetry and this notion of reflexivity. So I have a reflexive and transitive relation. Sorry, a reflexive and symmetric relation, not transitive. So I have this set of operators which This set of operators which are closed under the adjoint again. So let's talk a little bit about operator systems. And this is, say, an earlier part of functional analysis. So she's studying with Arveson. Where an operator system, as I said, is a star-closed vector space E of bounded operators. It could also be closed in the norm, but let's leave that. But let's leave that out for the moment. It's unit or if it contains the identity operator. Now, it really kind of started with Choin Evros, who kind of developed this theory and also kind of indicated what is the structure that is crucial in this otherwise rather, say, meager structure, because I just have a star-closed vector space of bounded operators. Well, actually, the difference or the kind of the deeper structure. The deeper structure that lies in the maps that you consider between them. And the maps are supposed to respect a certain structure on this operator system, which is an ordering. And that ordering comes from indicating what I call positive. So I have a cone of positive operators, E plus, and it sits inside E. And I even have matrix cones. So that's cones M and E plus inside M and E. M and E plus inside M and E, where I amplify my operators to matrices with values in this operator system E. Now it's this structure that one wants to respect. So maps between operator systems are completely positive maps in the sense that if I extend it from E to M and E by just acting in each entry of this matrix where the entries are in E, that should be positive. So it should respect these cones. These cones. And then isomorphisms are complete order isomorphisms. And it's this kind of map that, if you would kind of go back and look at C-star algebras, coincide with what is usually a star isomorphism between C-star algebra. So it's kind of generalizing that to this setup of operator systems. All right, so let's look a little bit at the structure of these. Sort of the structure of these operator systems, and let's first do that for unital operator systems. Then you may wonder how you can associate maybe a C-star algebra to it. And that's actually a question raised by Arvison, was wondering if there is a smallest C-star algebra that is kind of generated by an operator system. And kind of surprisingly, it's possible to kind of generate different Caesar algebra. Different C-stra algebras by realizing the same operator system as different bounded operators on some Hilbert space. So, what I mean is that I kind of take an order isomorphism, so realize it as a different system of a different operator system acting in a different Hilbert space. And then the Caesar algebra it generates by just taking products and sums and so on will be different. So, I look at the smallest one. And so, more precisely, a Caesar extension. More precisely, a Caesar extension would be what you get when you take some realization of E inside A, in a Caesar algebra A, and that A is generated by the image of this E. So you just take products, and that's what you get. And the Caesar envelope is the smallest among those C-Star extensions, so that there is some kind of universal property that you can always subject onto this A, which is in that sense the smallest. So you take out some quotient, you take out some ideal. Some quotient, you take up some ideal taking quotients because this row is just a C-star algebra map, and that's giving you this C-star envelope. And a nice example of this is actually what you get if you take an operator system of continuous functions on a closed disk, which are harmonic. But then what you actually realize is that, of course, I mean, this sits inside the continuous functions on the closed disk. But actually, you can, because these functions are hard. Because these functions are harmonic, the restriction to the boundary is actually sufficient to know the function by just solving the Laplace equation using some Poisson kernel. So actually, you do not lose any information by restricting to the boundary. So that kind of realization of the same operator system by quotienting out, say, C0 of the open disk will actually give rise to the C-0 envelope, which is. Rise to the C-Stra envelope, which is continuous functions on the circle, so that's much smaller in a sense than the continuous functions on the closed disk. So, you actually can get rid of a lot by respecting the order structure on the operator system. Okay, so let's see what we can actually use these for, in particular, how we can do geometry with them. So, then we have to go back to these state spaces to reconstruct geometric structures. To reconstruct geometric structures and metrics. And in fact, the fact that the structure of this cone of positive elements allows one to introduce states, positive linear functions of norm one. So that actually works in exactly the same way as for C-stra algebras. And most of the things you do for C-struct algebras, you can actually do for operator systems. And in the finite dimensional case, it's quite useful to talk about the dual. So, of course, infinite dimensional, then you have to think about the binary space dual so some. Think about the Baron space dual, so some more topology is needed. But the idea of the dual is that you have this order structure just induced by saying some functional is positive if it maps positive elements to positive numbers. And what we have is that if we would understand the dual and if we would, for instance, understand the extreme rays in the cone of positive elements in the dual, then we know exactly what the pure states are on E, because that's what they correspond to. On E, because that's what they correspond to. So, if you have a good understanding of the dual, it gives you information about the states, the state space on E. And that's for the finite-dimensional case, it's actually quite nice. So, that's actually what I will first kind of illustrate by means of an example. So, these examples are very simple. So, a circle S1, you take a spectral truncation of the Dirac operator on S1, but that's just truncating to finite Fourier. Truncating to finite Fourier modes, so that's an orthogonal projection in this Hilbert space onto the span of the first n e to the ik t for k from 1 to n. And then you kind of compress your sister algebra C of S1 by this projection. And that's an operator system. It's actually quite nice because what you find is that they're given concretely by Tupli's matrices. So finite size, so n by n. Size so n by n, and the n is fixed matrices which have constants along the diagonal. So that's what I will consider. And indeed, this is closed under the star because it will respect this structure if you take the star. And what one can also show that the C-stra envelope, for instance, is the matrices. And that's actually the smallest C-stra algebra it generates precisely because there's no, well, M and C does not have non-trivial ideals. Have non-trivial ideals. So you cannot really take anything out to get a smaller Caesar algebra. So that's a kind of a fortunate situation. So M and C is the Caesar envelope. So this you generate. But we have to, of course, M and C is not so interesting to consider. It's much more interesting to consider this operating system of Tiplis matrices. Their structure is very rich. Now, to understand the state space, we introduce this dual Fegier-Ries operator. The dual Fezier-Ries operator system. So, first, let me explain what it is and then talk about duality. So, these are like truncations in Fourier. So, it looks similar, but now what I do is I take functions on S1, but I introduce a support condition in Fourier, where I say that I only have these kind of these finite Fourier coefficients that gives me this function. So they're like polynomials of a certain fixed. Polynomials of a certain fixed type, of a certain fixed degree. And an element is positive if it's a positive function on S1. Now, the C-stra envelope of this, actually, then it's clear because you can take products and the support will grow because the product will correspond to the convolution product in Fourier. So the support will be twice, etc. So that eventually you get the C-star of Z, that's the C-star envelope. But there's nothing smaller that could be generated. That could be generated. Now you can analyze the extreme rays and the pure states on this. So, first of all, the extreme rays on this are given by elements. And that's a very nice argument. One can show that if you look at the Laurent series, then all the zeros would lie on S1. So, of course, that means that I have to know these zeros with multiplicity, maybe. And that gives me precisely the Laurent series. So there's a one-to-one correspondence by giving these zeros and these extreme. By giving these zeros and these extreme ways. The pure states, and that's another kind of thing one can use now: is that, of course, I have an operator system that is contained in C star of Z. So any pure state can be extended to a pure state of C star of Z. But these are just points on S1, because C star of Z is C of S1. And actually, you get all of those points. And so that means that even though I have a finite number only in Fourier, so it's a finite number. Are only in Fourier, so it's a finite-dimensional system. The pure state space is all the points of S1. So, even though I truncated, I have a lot of geometric structure at this level. Okay, the duality that I promised is actually the following. So I have a pairing between this CS1N, that's my notation for this tuplet system, and C stars at N with the support condition in Fourier. And the pairing is just given by the natural theory. Pairing is just given by the natural thing to do with the coefficients kind of paired. And this is actually the fact that this is respecting the order structure, which of course is what we need. So that I can specify that something is positive if the functional that you get via this pairing is positive. That's a result which is based on the Fegeries lemma. And so you see, so here on the left, you see Feger standing, HÃ©rie on the right. On the right, and sitting here is Cara Teodori, who's also kind of these. So, these results are very old, but it's very nice that we can kind of re-formulate or rephrase them in terms of these operator systems. But essentially, they're based on this lemma that they proved. And so, the duality that I state here was proven by Alan Konner myself for the order structure, but Douglas Ferenek. Order structure, but Douglas Ferenek mentioned that actually, well, for the matrix order, of course, you have to work a little bit more. So he provided the proof of that basing himself on the operator-valued Fegier-Ries lemma. It's like extending it to matrix-valued functions and so on, where it also applies. And then it means that I can kind of harvest now, use the duality by just putting the thing that I had on the previous slide in reverse. So the extreme race on this triple C. Extreme rates on this triplet system would correspond to the pure states that I had before and the other way around. So that means that, for instance, the pure states on this triplet system will be given by these endpoints, these zeros that I have to choose on the circle. And that gives rise to this TN modulo Sn. So this is the end torus up to permutation. And the extreme rays in this tuplet system, they actually are, they could be kind of They could be kind of recognized in the result of Karateodori. That's why I also put this picture, which was known at that time, but now it's kind of rephrased in this language. Okay, so that's the structure of these state spaces. Well, then one may wonder actually how, let me actually, before doing this, let me keep this in mind. So I have these endpoints on the circle. So the pure state space of this truncated system. This truncated system would give me some points on the circle. Now, the question arises: can I actually approximate the whole circle in some sense? Does it converge to the circle when I take n large enough? So this I address by using some notion of Gromov-Hauser convergence. And what I find is that I have this definition where I want to kind of approximate. kind of approximate uh e so this e h d that's a spectral triple even though it's based on an operator system that's essentially the same definition and look at the sequence of operator system spectral triples so again spectral triples but based on an operator system and i may wonder whether these state spaces somehow converge when i equip them with the distance function that i introduced in the first slide and so for that i i have the following definition so there's a c The following definition: so there's a C1 approximate order isomorphism, which just means that I can go from E to En and back with Sn such that they're sort of each other's inverse. And that's the way to relate states. But of course, I'm not one-to-one. They're not really inverse, but they're like I have some control over how they are each other's inverse. So approximate inverses only. So for that, I mean that I have, well, there should be positive, units of contractive, and Leipzig contractive. So also with. And leap sheets contractive. So, also with respect to the leap sheets norm, which is this commutator with D. So that's guaranteeing that I have some kind of way to pull back states from one to the other. And that's essentially how I will relate these state spaces. And then the controlling of how they are each other's inverses is done by these sequences that go to zero, gamma n and gamma n prime, times the leap norm that I showed you here. Under this condition, so having such a C1 approximate order. Having such a C1 approximate order isomorphism, I can show that the state spaces S E n, so for each of these, converge to S of E in Gromov-Hauser distance. So that's kind of controlling some notion of convergence for metric spaces using the usual notion how to compare metric spaces, which is chromo-faus of distance. And I think that in Lada Moliera's talk this week, more information will follow on this notion. More information will follow on this notion of distance between metric spaces. And so, what happens is that if you look at the case that I was showing you, so the C of S1, so the compression, let's call that Rn, so the restriction to a turpless matrix. It allows me to pull back states from this system, this matrix operator system, to the circle. So it gives me some kind of state there. Actually, you can show that there's an. Actually, you can show that there's an inverse which is related to the again this Vegere kernel comes in. So that's the convolution with the Veger kernel Fn and the other one will be a Scho product. Actually, what we can show is that they indeed are controlled. So they do satisfy this property of the C1 approximate order inverse. And so what happens is that what I showed is that the state spaces will actually converge to the state space. Converge to the state space of C of S1, so probability measures on the circle. And what Hackelman showed a year later was that actually this even applies to pure states on these operator systems. They also converge to the probability measures on the circle. So there's some kind of smearing involved. So you cannot really be very sharp, but you get all the states eventually in the limit. And actually, there's many more examples which can be kind of reformulated. Formulated Fasi spheres of Riffel, quantum spheres that were considered more recently, Fourier truncations that were considered by Riffa. And actually, the circle can be generalized to D-dimensional tori, which is done by my PhD student, Marta Leimbach. So that's about the limit and how one approximates the circle by taking these spectral truncations into account. So even though it seems natural, this the question is completely open whether this works in general. Completely open whether this works in general. So, if you take a spectral triple, you do a spectral truncation. Can you actually prove that if you take the spectral truncation large enough, does it converge to the original state space with the metric, well, the topology, the We start topology, which is metrized by the distance function. So, that's an open question still, which we're kind of slowly moving from circles to tori, et cetera, and understanding more and more. And understanding more and more about this. All right, so let me move to the non-unital case, which is preparation for these spaces at finite resolution. I think I have about 15 minutes. And I will say something about the structure when you do not have a unit. That's, of course, much more complicated because Course, much more complicated because the state spaces do not behave so nicely. That's already true for C-serv algebras. So, what you consider is an operator space. So, that's again a space of operators. In other words, there's some kind of norm, even a matrix norm. And there's also a matrix ordering, like the one I discussed before. But I don't impose a unit. Now, one can look at the state space and even non-cumulative state space. So, these are functionals in the dual of E. In the dual of E or M n of E of norm one and they're positive. Now, that's not always convex, and it's not weakly star compact either in general. So, the convexity that you usually do for states actually evaluates it at one. And then you say, well, if I take a convex combination of two of these, then of course that will also evaluate to one. And so that positivity is, of course, fine, so that you do get this kind of result for the non-communication. Do you get this kind of result for the non-cumulative state space? So, one then resorts to the quasi-state space, but then this is okay, it's complex and weakly star-compact, so that's fine by usual kind of arguments in functional analysis that this is just a closed ball in the joule and so on. So, that's completely standard. But the problem may be that zero is always around, so sort of you have to avoid the extreme point zero. The extreme point zero in this quasi-state space because that will lie in this dual and it will be extreme. So, what you can show is actually, well, there is a sort of a restriction where you can use this quasi-state space to identify the matrix norm. So, that's a general definition of Werner, which is what he called a non-unital operator system. Operator system, and that's given by a matrix order operator space, as I did before, for which you can realize the norm by looking at the states or the quasi-states, as I did in this formula for what I called modified numerical radius. Now, so maybe it's not so relevant to have this in full generality because I want to kind of specify to a much more restrictive setup. And that's where I look at operator systems, not with the units. Operator systems not with the units, but with an approximate unit. And it's not so much a multiplicative unit because I don't have a multiplication, but it's an approximate order unit. So it's like essentially these E lambdas, so that's a net. And what I can do is I can take any element x, emission element x, I can sort of kind of have an upper and a lower bound minus t e lambda and t e lambda, so a lower and an upper bound. And the existence is what I call an approximate order unit. So having that possibility for each element x, Hammersian element x, this gives me the notion of an approximate order unit. And this is like having a unit, because in a C-sharge reference, it would always be possible to kind of take an emission element x and have it smaller or equal to the norm of x times the identity. And it's also larger or equal to minus. And it's also a larger or equal to minus the norm of x times the identity, right? So that's that's sort of the motivation behind this. But what we kind of argue is that it could be that this approximate audio unit is matrix is norm defining in the sense that if I take the smallest such t, that gives me actually the norm of x. And that's just what I said in this example. So it's like you want to kind of sandwich x between the norm. Sandwich x between the norm of x and minus the norm of x times the identity, and you want that to be the smallest possibility for which that holds. So, like with Caesar algebras, and here I say, well, let me kind of loosen that identity and allow this whole family E lambda to appear. That is a result that that's actually then a non-unital operator system. So, we're in this general context of Venner, but the advantage is that we have a control, not so much of a unit, but an approximate audience. So much of a unit, but an approximate order unit. And so, if I want to, for instance, take convex combination of states, I may not kind of take its evaluation at the unit, but I may evaluate it at E lambda and then take a limit. So then I have still a control of this convexity. Actually, what one can show then is that the state space, SNE, in the presence of this approximate order unit is still convex. That's because the limit of the evaluation. The limit of evaluation at these E laminas will actually be respected by convex combinations. Now, if you furthermore have that you have a norm defining approximate order unit for a Ceter algebra A, which is actually contained in an operator system E, then you can also extend pure states or states, pure states in particular, to a pure state on A. So that's very useful because typically for Caesar algebras, we have a lot of information. For C-star algebras, we have a lot of information available, but for operator systems, this is much more complicated. Now, there's two more things that one may actually show: is that there's a Jordan decomposition, but maybe the most important is that the dual of E, so E star, is actually related to a quotient construction, and that's respecting the order structure. So I can actually maybe find the state space of E if I know something about the state space of A. Okay. Okay, so yeah, there's an argument that extends this to dense subspaces, but that's just because I take joules, so that's not too surprising. So let's see what happens if I take this example in mind again. So I take a metric space and let's apply this to the relation R epsilon, where I take two points X and Y to be in the relation if their distance is smaller than a fixed epsilon. So it's like a band. So it's like a band inside the pair group point, but inside the product of x with itself. And I say that this band is sort of the relation that I want to consider, but it's not an equivalence relation because my epsilon is fixed. But it's symmetric and it's reflexive. Then I, so let's assume it's a measure space, so I can define the Caesar algebra that is associated to say x cross x. Cross x and I introduce a support constraint for integral operators to lie on this r epsilon. And then I find that I have an operator system, which is this closure inside the compact operators on L2 of x. Now, actually, there's a nice relation with the row algebra. If you're familiar with that, this has to do with finite propagation, which actually is very closely related to what I just explained in our epsilon. Or in R epsilon. So they will actually lie inside of their C star X of epsilon. But let me move to, also in view of time, to how one actually can construct an approximate order unit in this case, so I can apply these general results on the state space. So what I will do is I sort of break my space X in finite pieces. So I take partitions of X in terms of X. Of X in terms of measurable sets of small enough size, so the diameter is smaller than epsilon. So u i's, there will be this partition. It could be, so it's epsilon partition, that means the diameter is smaller than epsilon, it's finite, so I take finitely many in there, and it's partial, so it's not necessarily covering all of x. So I just have these pieces of measurable sets that sort of are supposed to eventually, when I refine and refine, are supposed to kind of. We find are supposed to kind of describe the structure of x. And the finite dimensional algebra I can associate to such a partition is actually what just taking the indicators one on u for this u being in this partition. And then these I can multiply because there will be just the characteristic functions on these sets. And then I can just realize this as a finite dimensional matrix algebra. So these are the compact operators on L2 of P. So these are the compact operators on L2 of P, but since this is finite, these are just matrices with a fixed size and also with a unit E P. So that's just the identity in the matrix algebra. Now, since I have my diameter small enough, I can realize that actually u cross u, when u is in this partition, will lie in my relation. So this means that even if I restrict my tolerance relation to these partitions. Tolerance relation to these partitions, to these final partitions, the diagonal will always be there. And that means that my EP, my unit, is actually contained in the operator system E that I defined by those matrices with the support restricted to this tolerance relation. So the support of these matrices will actually lie on the tolerance relation and outside it will be zero. So it's like a band around. Like a band around the diagonal that I allow, and otherwise it's zero, but the identity will always be there. So then I have my refinement, p is more than equal to p prime, so it's direction of these partitions that allows me to kind of include these operator systems. And this actually is in agreement with the inclusion of the finite-dimensional algebras, so the matrix algebras. Algebras. And so, if I would then take my E P's, the units in each of these algebras, it will actually be an approximate order unit of the direct limits, so that's the algebraic direct limits of these APs, which actually will be contained in the direct limit of my operator systems with that support condition, because the diagonal will always be there. And that's exactly what I need to allow to understand states and so on on these operators. And so on on this operator system, because this is my approximate order unit for my operator system. And indeed, what happens is that if you take this algebraic limit of these matrix algebras of a certain support, there will be a dense subspace in the operator system that I, as you said, to the relation R epsilon on the metric space. The same applies actually to the algebra. So there will be a dense star sub-algebra of the C-Ster algebra of compact operators now. That will be the C-Stra algebra as a The C-served algebra associated to x cross x, to all the integral operators. And the fact that you have these approximate order units, which are in fact norm-defining for each of these elements, allows me to conclude that I have this norm-defining approximate order unit that is contained in the operator system. So then, as a result, one can show that, for instance, the C-star envelope that will be the compact operators just because there's no ideal that they can take out in the compact operators. They can take out in the compact operators because it's simple. But more interestingly, it allows me to understand the pure states on this system. So I know now that the pure state on my operator system, so in view of the fact that I have this approximate order unit, it can be extended to a pure state on the compact operators, but they will just be vector states, because I know very well what the pure states are for the compact operators. So they will be vector states. The only thing I have to figure out is which ones they are. Figure out is which ones they are. I look at this quotient that I described before, so the annihilator of this system E R epsilon. And I realize that the vector states are given by some vector psi in my Hilbert space, L2 of X, they will be such that the support should be kind of, well, not too far apart. So there shouldn't be pieces in the support which are more than an epsilon apart. Because then if I would restrict it to operate. Would restrict it to operators with that support condition, it would kind of fall apart into two states. So, actually, that's the restriction that I need on my vector states. So, what I call epsilon connected for the support of psi. And then I have a good control now of how to kind of see what are the analogs of points on my operator system E R epsilon when I introduce this relation where I kind of have some kind of finite resolution of size. Resolution of size epsilon. Okay, so I thank you for your attention. Thanks, Valter. Any questions from the room here? And then we move if there are any questions from Zoom. Well, let me see if there is any question from Zoom. Is any question from Zoom? Yes, I mean, I can I ask a question, yeah, yeah, yeah, just go ahead. Yeah, so, uh, Walter, thanks for the talk, first of all. Yeah, so imagine you wanted to define some invariants for operator systems, for example, k-theory or other non-commuting invariants. So I suppose you would take sister envelope and define your k-theory as k-theory of the sister envelope. Sister envelope, perhaps? Yeah, no, I don't think so. But of course, this is a very good question. So, K theory in particular. Because I think about these operator systems of the tablets, so these tiblitz algebras or tiblitz operator system. Yes. Then the Caesar envelope would be the matrices, M of C. So it doesn't seem to consider. And it's also not what is related to C of S1. Yeah. We also know that there are. Yeah, we also know that there is some content, so you're probably familiar with this work on the spectral localizer. I'm sure you are. So that actually is something that you do on these truncations. And it gives you information about an index pairing, which actually takes place in the full ultra, not in MNFC. But the computation is done there. Some structure that one has to kind of understand better, which may. better which may have to do with so of course the first challenge would be how to define modules and and but that's the even the probably even the wrong question because there's no product structure so then there's a candidate which is much more related to uh hermitian structures so which may exist actually for operator systems because positivity is actually around so that's more the line that we're thinking of it looks like it might involve something like k-theory of exactly Something like K-theory of exact categories and stuff like that. So one has to take a kind of categorical, more general perspective. Yeah. Yeah, sure. It's probably like this. So it's one candidate would be what... So there's this notion of like L-theory or the WIT group. Yes, yes. Much more defined along these lines. And there you could actually see the role of Hermitian structures much more prominent. The role of Hermitian structures much more prominently than the module structure, so that could be an opening. But I'm not so sure, I mean, it should all fit with the spectral localizer, which is surprisingly just a matrix, which at some point, some truncation, some size will actually reproduce the index. And so, and that's kind of natural if you think about spectral flow, for instance. I mean, you will see that that will only happen around zero. Happen around zero, so you could actually forget about most of the details, say, of the spectrum. Yes, yes, indeed. Yeah, but okay, it's a very good question. So that's something to think about, anyhow. Thank you. Is there any Fidel? If you take this seriously, from a physical point of view, I'm sure you take it seriously. Point of view, I'm sure you take it seriously from the mathematical one, but and you really think that this is the somehow the space of quantum gravity, something of this kind. Can you try to do some field theory which would be free from divergences or something? You would need a scale, which is probably the scale of the highest eigenvalue out of which you built this projection. But have you thought about this? Have you thought about this? Yeah, so it's actually the origin of this whole approach is actually that. So, but then, of course, there's the problem of never returning to the original motivation. Because what we were having in mind was that you should somehow take into account quantum effects. And if you think about that in terms of a Dirac operator, you would have to kind of take into account like logarithms of D squared, for instance. D squared, for instance, rather than d. So you take like what you may call a dressed Dirac operator. So it's like the propagat, which you get from like a self-energy computation that you have to invert, and then it would give rise to a sort of addressed Dirac operator. And that's what we were looking at. But then we realized that the usual theory doesn't work. So you have to sort of allow a scale where these effects will be. A scale where these effects will be taken into account so that as the scale gets higher and higher, these effects will actually come into account into play. And so, this is the original motivation, but then, okay, we still have to get back to that. But in principle, the fact that we do have a finite dimensional truncation allows me to introduce these effects now. So, at least theoretically, it's possible. And if you would do And if you would do that, for instance, on a computer, that would be quite useful because everything is indeed finite-dimensional. But whether it's really going to work, that's still open. So, Walter, if I can ask something which is related to what Fidel said, if I wanted to write down the action on what will be different with respect to the spectral action principle that we know from the original approach? Well, actually, that's. Well, actually, that is typically something like an approximation where you take only sort of finite elements into account. Then the question is, how much do you need of that to, for instance, reproduce something which is geometrical? And of course, you know that whenever you do something which is finite size, the spectra action will not give you what you usually get, like these asymptotics, they will not work. Like these asymptotics, they will not work. So, what actually Abo Stern did, so the project with Glasser and Stern I mentioned, is that there's a formula that allows me to sort of approximate these like these singular traces that you would find in the, for instance, in the spectral action, like zeta residues of zeta functions. Of course, they will not be there if you have just a finite dimensional system, but you can actually relate them to an approximation like Relate them to an approximation like what think of the example of the Dix matrix. That's actually something which is singular. So it will, in a finite-dimensional context, it will not give you anything. But the formula itself is a finite dimensional approximation. It's like a limit of one over log n, for instance. And then you take these n eigenvalues into account. So it is very much like that in principle. And then you can actually do that to the lower residues as well, kind of the sublet. Use as well. Kind of the sub-leading behavior of a heat kernel can actually be written like that as well. So you have some approximation results for the spectral action that you can use, and they will indeed give you in the limit the curvature terms that you usually write. I'm not sure if that answers the question. Okay, yeah, thank you. Thank you. Any other question? Yes, Martin has a question. Yeah, also about physics. Is there Yeah, also about physics. Is there a physical motivation for using non-unital algebras? Yeah, so essentially it's just coming to you. So if you take these relations on a metric space and you say that you take integral operators which are supported. Operators which are supported on that kind of neighborhood of the diagonal, then the unit would be something like delta functions on the diagonal. So they're not really there in the system. So you can only approximate those units. It's like you're forced to work with the compact operators. And then that's what you have to do. And the compact operators would be corresponding to, well, essentially having all points related. So then your epsilon is. So, then your epsilon is kind of as large as possible. And so, that would say that there's only one point essentially. So, all the points are identified, which amounts to considering the compact operators being read equivalent to a point or to C. So, I would say that the relation itself gives rise to these non-neutral operator systems, and then one has to deal with it. So, it's more like I don't see a like. A serious kind of physical interpretation for that, but it's just the fact that you're led to consider that when that relation is given. Okay, thanks. Okay, if there are no more questions, let us thank again Walter. Thank you. And we move to the next talk. Thanks. So, Ludwig.