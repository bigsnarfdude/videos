Separation and so let me raise the screen Nobody from the file. Why is it under file? File? No? So I think it wasn't still on the website, so we think we should probably just copy it on the desktop then. Ah, right, so just copy it on the desktop. Okay, I'll get it. But I'm looking forward to score. View. View. No, just view. Because it's on the website, it's not on the website. It's not on the website. That's okay. It's good enough. Okay, so I'd like to thank our nicos, Paviano, Rihanna, Filip, and Jean-Proslav for this invitation. And thank you, Jules. It's actually my first time at Bath with snow, so it's a new one for me. For me, but it's always beautiful here. Okay, so let's see. After all these, I think I have up to 10, 2, I suppose. So, this is what I'm going to talk about. It's work with several people. Why is this doing this for you? It's because it's in the we need to basically look at the microphone. Okay, okay, good, good, good. Okay, yeah, so, um, right, so, so, this is an overview of what I would like to talk. It's probably too optimistic, but anyway, so this is going to be a problem where you're going to have two scales, an epsilon and a delta. And as usual, there are three possible regimes. Either they go in tandem or delta goes faster than epsilon to zero, there's the converse. And then, of course, these all kinds of other questions you All kinds of other questions you may ask. I have to say that we started this relatively recently, 2019, so there's a ton of stuff that we would like to know. But basically, I'm going to tell everything I know as of today. And so I will start with a very brief introduction to the phase transition model that most of you are very familiar, so I'm going to move fast on that. So that's a typical picture, right? You have a double output. Typical feature, right? You have a double out of terror here. Whoops, something happened. Oh my god. Go there and put the full screen. I think it probably just. Sorry, one of these buttons it has two, right? So be careful with this thing because okay. So anyway, so um So anyway, so um you have uh basically two two in this case, two fluids uh that um they like to live at the bottom of the wells of this of this energy W. This is a prototype, one minus two square square. Actually, most of what I'm going to say, if not everything, it actually happens also for vector values. So the the wells could be leading in R D, so it's not necessarily a spectrum value. Not necessarily square value. But as usual, you want to minimize this energy. Of course, if I just leave it like that, you have infinitely many possibilities. Or maybe it's the container where the two coexist. Usually you will fix some total mass so that you force that you're not always in one phase or the other. And you want to minimize, and of course, anything that looks like Anything that looks like this U sub E will do, which is A in the set E, B in the complement, provided you satisfy the right mass constraint. And then, and so of course then you ask, okay, but I would like to have a selection criteria. This goes back to Vander Walls, which is well, okay, add some surface energy, which is basically what this turbine is doing here, right? So you would go from A to B on a layer. On a layer of epsilon, so this would be basically of order epsilon total. And so that's you modify your energy like so. And Goethe conjecture that if you take minimizers for i epsilon, that they converge in some sense to preferred minimizers on the original problem, in that the In that the U, as I wrote before, oops, this U C B would now be a particular E, which is one that minimizes surface energy inside the container, right? So we all know that this is the story. Okay, then this was rigorously proved by Modeka and Martola, first Modeka and Modek and Martolai in the 70s. Monica and Monkey Mortali in the seventies via gamma convergence. And indeed, they prove that if you scale, well, if you don't scale, you don't see anything, but because of order epsilon. But if you scale by epsilon, then that's of order one, and if gamma converges to indeed a perimeter of their wavelength is equal to X, which is the same as I'm waiting to be. And essentially, this is like it's. It's like a surface energy with an isotropic surface energy density, CW does not equal the normal. CW in this case is computed explicitly like so. And of course, in terms of minimizers, you're not messing up anything because they have the same minimizers, f epsilon alpha epsilon. And then we know that, of course, that's the essence of chemical convergence, then minimizing. The essence of gamma converges, then minimizes of f epsilon will converge to minimizes of f. So that gives the selection quite. I don't think I need to spend time with this audience of what is gamma convergence, but just to make sure that again I come back to that. We all remember that two, essentially two inequalities, right? One is what you call the gamma limit if, which is this, and then the gamma limit two, which is the construction of a recovery sequence. Sequence and so that's basically what we have to deal with as we move forward. And again, I mean, in terms of the selection criterion, you get what you want. Okay, and then of course this was rigorously proved by many different people in many different ways. And I have here a list of many contributions. In particular, Guy here, he worked with couple. He worked with coupled perturbations, so it was written in this way: scatter values. So he was using, correct me if I'm wrong, the sensational duality, convex duality, to prove this. I'll come back to this. And I come back to this because he actually had moving wells. And most of what I'm going to talk about will have moving wells. Okay, and the list goes on. I mean, you could have, like, with one more degree of rigidity, you could have, depending on the brain. You could have, depending on the gradients, if you think in terms of elasticity and then criterize with Haitian, of course, in this case, you know that you're going to get laminates and so on and so forth. And if your name is not there, your name is on the dots. So the point here is that as we are investigating the applications of this kind of models, you realize. Of these kinds of models, you realize that actually there are many circumstances in which each one of the mediums should actually not be homogeneous, well, true, could be ideal. And you could have some kind of an homogenization process occurring as you're moving to dimension reduction, as you're going from volume to surface, right? As you have this phase transformation. And so, bottom line, the fruit of wells would actually depend on the position, just as Deep has assumed before. In particular, we will look at this example of lipid rats, so that's within your skin, and in this case, there is a phase separation, and it's actually shown. I'm going to come back to this, that this. Come back to this. That this is in their model, which is pretty much kind of healthy with a marginalization. And they show, this was in nature, that at the macroscopic level, instead of getting what we are used to, which is like interfacial energy with some surface energy density, actually their first order gamma convergence is actually blocked. And it's only as they go. And it's only as they go to the second order gamma convergence that they start seeing phase separation, not come back to this. Okay, so here is a typical cartoon for an emotionalization process, which comes from the same paper. And so you say, well, okay, fine. So we are going to do that. So we are going to take an energy that is going to be zero. To be zero, it could depend on the position x. There's going to be a fast variable here, so you're going to have a homogenization occurring there. Everything could be vector valued, it's okay. It's going to be periodic in this Q is just the unit normal cube in our M oriented according to the automatic. So it's Q periodic. I'll come back to quasi-periodic and stochastic. Periodic and stochastic mortalization later on. And of course, this goes to the without. The example that we have in mind, actually at some point I even have multiple analyses that don't have to be two B. But the point is that the example that we have, that I have in mind, is that when you look at the cell of predicting Q, you divide it into, say, a blob E, and then the complement. A blob E and then the complement, and so in E W should look like a W1, outside should look like a W2. But the moral of the story is that as depending on X, you would like it to not be more than 10 at the door. It could jump. So continuity in X is probably not a good idea. Okay, well, let's see where this comes from. So I'm going to start first without homogenization, but well, depending on But, well, depending on position. And again, as far as I know, this goes back to Guy in the Scalar case. Then Christofe and Gravina at CMU, they in 2021, they did that vectorial case, no marginalization, but just moving wells. But the behavior that they assumed, so at the bottom of each well, it had to be exactly quadratic. To be exactly quadratic. So it's basically C2, and you look at telexpression to be exactly quadratic because they needed that to control the behavior of genes. And they're going to remind you that later on. So that's, as far as I know, that's what we had before we started putting amortization. And we are now going to put amortization in the picture. But let's first make our life a lot Our life a lot somehow easier. So, homogenization and fixed transition, but let's do it with fixed ones. So, not depend on transition. Okay? So, that goes back to 2019, 2020. That was in interface at free boundaries with my postdocs by the students. And so, this is the case where you go in tandem. We proved that the gamma limit. Proved that the gamma limit is not to expect. So it's a surface energy. Oh, that's funny. But with, so it's the integral over the boundary of un is equal to y. With density depending on the normal, what sigma is, all of us here could have guessed, right, is the usual self formula, so there's nothing particularly profound about it. Profound about it. So you have Qν is a Q with two faces perpendicular to double nu. Going back to Stefan Mueller, we know that in a vector problem, we need to have cells bigger and bigger. So we have T. Th should look like surface energy. So you divide by T to the M minus one. And the U's are the usual things. But I come back to that. What I think is interesting here. What I think is interesting here, though, is that it turns out that this is truly anisotropic. So the signal really depends on the normal in a non-trivial way, unless you basically don't have a marginalization. And to me, this was a surprise because we have worked on these Kahn-Hilliard phase transition problems in all kinds of, like instead of grad U squared into the F of grad U or whatever. F of grad U or whatever. And my intuition was always that the only way you get anisotropy is from what you put here in the surface energy. If it's anisotropic, right? It's a gradient square, it's an F of gradient. This is the Rieszman interval. It's gradient squared. And still, this is completely anisotropic, it's a theorem. Okay, similar to again, there's also the Zephyr later on, but at this point. Later on, but at this point, there was work by the senior Bradis Catopiat in 2003. But instead of having the marginalization in the W, they have a marginalization here. It's a completely different phenomenon because if you have it both here, you have the fight. Because W wants to look, W is periodic with respect to the orthonormal basis, yes. So is the theorem meaning that you have a specific. Meaning that you have an explicit simple example in which you misotorm. Yes. And so I will say that, right, so in our case, why is the phenomena different? Because when these oscillates, on one hand, W wants to orient itself according to the automobile basis, right? Because X-vary has a poricity. While these is going to try to look Is going to try to look on the interface with the normal, and that normal may have nothing to do with or to normal pens. And then you have to fight. That's basically what it means. Okay, the cell problem again, that's what you expect. The U's that you take here are the usual ones, right? So this is your norm, this is your cube. You would like Q to look like B on top, A on the bottom. It's not H1. So what you do, you take that, you modify it a little bit with a row. Modify it a little bit with a row, and basically, it's going to look like the little bit away from the interface, like here. That's your preferred modifying. It's independent of the way you modify it. You can also prove that. But basically, the U's are nice and smooth, but tend to look like P and then like the type. So, the source of an isotropy is exactly what I said. So, this would be if you were so liking, say, that. If you were so lucky, say, that you are zooming in a point of your interface between A and B, okay, you flatten the interface and say the normal is EN. So what you do is locally, you just tile your interface with copies of your cell phone, and then you add them up. It gives you what you want. But if it's skewed, then it's not true. And adding up will not give you the right result. That's basically. That's basically hand waving, it's the reason why. The roadmap is what you expect, right? You start with compactness, which I'm not going to bother you with that, it's trivial. Bond and energy converge to PV functions. The gamma limit if, right, remember, then there is the gamma limit too, which is recovery sequence. Most of the time, again, my experience is that the gamma limit inf is what makes you think, right? So, am I going too low? And once you kind of have an idea of the And once you kind of have an idea of the gamma limit if, then you basically blow it up, you scale, and you get your recovery sequence, right? In our case, it was exactly here that we had the problem. The gamma limit if we cannot figure it, but what else can it be? It's the cell formula. But it was to find recovery sequences that we had to suffer a little bit. Okay, so this is going to be my only proof, I think. And even then, I'm going to go. Think. And even then, I'm going to go like that. But I just want to tell you why is that, say, FNU was EN. So if you're lucky, why is that going to be so easy? Because, okay, so you go back to your definition, right? That was the sigma of the end. That was the cell phone. You do the usual thing, you kind of press it around the interface, so so you just respan it appropriately, it goes to use, it's a it's an admissible sequence. It's an admissible sequence. You plug it, you do a blow-up, you plug it in the energy, blow-up, you keep going, doesn't matter. I want to stop here. And at some point, you end with something that looks like this. The point is that epsilon goes to zero first. And if you look at W, and if you look at how the oscillations on the optimum profile are, they go exactly together, right? They go in epsilon. Right? They go in epsilon, they go exactly together. So we know you just use Riemann-Lebregg lemma here, and you get rid of that variable. This is what you get: bingo, you go back to the first T-sequence. But that's the point, is that they're oscillating in tandem. They go together. The oscillations to fit the normal to the interface with the oscillations that make the double comfortable in terms of free situation. Okay, what if we have other directions? Well, okay, so then the first observation. Well, okay, so then the first observation is that you know what? Actually, there are many more orientations with respect to which W is periodic. And if you have a normal mu that has rational entries, then if you take a very, very, very large lambda, basically the common denominator of all the denominators, now you have a cube which is like this, right? Like this, right? With a normal view that way. And now you can tile your space with this, and now you have quality, but now you go in a skewed way. And then there are all kinds of interesting linear algebra stuff. For example, I give you one of those normals, and you can complement with n minus one normals in the same space with rational components, which is still an autonomous base. That's not your typical graph, of course. Typical graduates, of course, because they have to be more space with respect, which you have predicting. And for example, if you start with a rotation that maps n into mu, I can find a new rotation that does the same. But not only that, but all other EIs are in that good space, and the Euclidean norm is very small. So there are all kinds of that interesting algebra that comes in. And then you prove that signal. But then you prove that Sidney is well-defined is finite. It does not depend on the choice of the modifier or the small formula. It's upper-semi-continuous. Actually, at the end of the day, you're going to prove that you have a gamma limit. So sigma has to be convex, right? Because it has to be normal continuous. And so it's actually continuous. But you don't know that yet. So you have to prove by hand that it's a person continuous, which you do. And then, okay, so then if you now have one. Then, okay, so then if you now have one of those normals, now again you can target these huge tiles and use the blog method. And basically, you can do, you can recover, you can produce recovery sequences for polyhedral sets that have these good normals. And then you wrap up visual way, right? You take an arbitrary U, you can approximate in V V strong by UN, and again, by density. And again, by density, where their corresponding phases are polyhedral with good normals. By Heschechniak, you have, and Sigmi is upersmith continuous, you have this upper semicontinuity. But for each one of these, you would know how to find recovery sequences and you'd analyze. There's nothing profound about that. Okay. Now life starts becoming interesting, yes? But the anisotropy came from W, not from the U-Rash. We came from W, not from the irrationality of the normal structure. No, it goes because you have the homogenization here with the time. So if W has a symmetry, it's also true for the real sigma. Sorry? So if W has a symmetry, that symmetry is also true for the surface energy? Well, yeah, if it passes through the cell formula, I guess. Right? That's true independent of the orientation. Yes. No, I don't understand. I think there are these subscribers from the fact that you have pretty. And it also comes from the fact that you have period discs, so the period disity somehow gives you two direction, goal and direction, which are special, which are the direction of the period disc. So it's nothing very, it's not related with the values of the wells or something, but just the fact that the W is periodic in the direction that you look at is a problem for all, which is not one of the coordinates. But okay, if you're patient, eventually I'm going to come back to that. Okay, but that's that's fair too. But that's that's going to. I'm not sure exactly what that theorem tells me. Okay, that's that case, by the way. Disclaimer: that's the case where delta and epsilon are very tandem. We only did a case where the wells are fixed. So we didn't do moving wells in that case. And it's actually something with Ricardo Liki Stafferi and Liki Panetti, we are looking to that. So okay, so now it's the case where Epson. Okay, so now it's a case where epsilon goes, where delta goes to zero faster. Delta is homogenization, right? So that means that you basically homogenize first and then you have the phase transition, right? In our minds. Now, I should say that my student Hagerty and then before the City Bradis Candle Piat, they looked at that case, but actually. At that pace, but actually on the F, not on the W, and that there was a gap. It had to be much faster. Now we close the gap. It's just we only need this. There is not this gap as we had it before. Okay, you know that somehow WRM is going to show up, right? And again, I remind you what WRM is, just basically you covexify with respect to and you And you y becomes the microscopic variable here, the protonic variable. Again, so that's your Fm. And again, W is only carated. Periodic, I'm sorry, it should be very wrong. It's periodic usually about the activities. Okay, let's start again with fixed wells. I'm going to assume that it's basically quadratic at UV. There is nothing. There is nothing mischievous about Kudrat. Could be well, P bigger than what. P is equal to one, it's a different ball game. I don't know. But P, okay, growth like P at Infinity. But I'm not assuming anything at the wells, exactly at the wells. I'm just saying active infinity looks good. This can be from multiple wells, and in the end, you remove the quadratic behavior in the wells, and you get. And you get what you expect, right? Probably first you're marginalized, and then you have typical kind of hill here, but with a double long instead of a double movie, right? And that's your C, right? That's the usual C that you get from there. And so we pretty much do it to get there. The question is how you get there. Okay, so what we did was we used the unfolding operator, but we Unfolding our prayer, but we unfold it only in W. So the fast variable is unfolded, right? Into an upper white variable, which is a microscopic variable. And just very briefly, I don't want to spend much time on that, but that's what enfolding operator does, right? It transforms the fast variable into basically macroscopic variable. So then you get rid of that scope, but of course the price to place that you have double intervals. Integrals and we are going to use the notion of two square convergence. But the good news is that the unfolding behaves very well with respect to two square convergence. And you have a way of writing an integral with the unfolding. There's a little bit of an error because of what happens here. You cannot completely cover. Cover so that there's this error of the red zone here. That's what I call this omega-epson hat. But okay, but there are all kinds of very good properties of the photograph, which I should say goes back to, I don't know if I gave them credit, to Izur, Damon, uh oh gee, help me here. Uh Help me here. Uh well, you know, and Visitine separately, uh, Doyna, Seranesco, and okay. So it's it's beyond. Okay, so for, I'll come back to how you use this and folding right there. But the game Olimitsoup is very easy. Why? Because I'm going to write, I'm going to basically, it's very easy, well. The devil is in the defense, right? So I can, okay, that's just dragon inequality, right? I'm adding and subtracting W1. For this one, I know how to construct. That goes back to my work with Tartar, in the vector case. We know how to construct a recovery sequence for that. Where is the difficulty to prove that actually this business goes to zero, right? That's a killer. So that's where the analysis is. So, do I want to spend a lot of time here? Probably not. No, I can't. Okay. Okay. So, okay. This essentially is going to tell you how you can kill that term. And there are all kinds of very fine quantitative properties between the unfolding operator and the original operator. And you see that a miracle happens at some point when you use the usual. When you use the usual Modica Mortular trick, right? That you bounce from below these, but basically you use quality. And you're going to get an estimate of this exact like that of x, and which goes to zero. So that's absolutely sharp. Okay, so I don't want to spend time on. Okay, so I don't want to spend time on this. Okay, as I said, you're going to go back to the usual gamma limits. You have to truncate double in a funny way, but we know how to do that because this is exactly, we know how to construct these sequences, and then you have to prove that you're going the right way. A huge part of this analysis relies on ideas of Peter Stenberg and Zunika. Peter Stenberg and Zunica for geodesics of the general performal metrics. And we use that in a fundamental way in all our estimates. If I have time, I come back to this, but I may not have. So now let's look at the other case. Epson much smaller than delta. So now you have phase transition first, right? And then somehow you have a motionization happening on this surface, right? That's based on this. Again, you take. Again, you take finitely many values, only calculatory, depending on the bias, right? That's the regime, that's your energy. And you see that at this point I'm not scaling, I'm not dividing by epsilon yet. I will, but not here, right? So I'm basically looking at the zero gamma limit. Not scaling. Okay, so I'm gonna have moving wells. I'm going to have moving wells. The behavior near the wells, it's not, I don't have to have them exactly quadratic. I expect to have kind of quadratic because it's the expansion. The wells need not be separated. You can have AIs and BI's coexisting. So you could have these pools of zeros. And again, at infinity, you have some kind of a quadratic model because. So, again, this goes to Brightis and I think that this is the work they did, which by the way, so it includes, that should be okay there, what they've done, but it was very specific to their problem. And again, let's look at the zero-order term. You get what you expect. You're going to get W all, right? Because, okay, you go back. Okay, go back. If I'm not scaling, some this is going to disappear, right? And then you just there's nothing profound about that. And you prove that minimizers look like so. So they are like convex combinations, but the two scales of AZ. So this was first done, as far as we know, by Gilles and Stéphane with gradients. Gradients, right? Again, zero of order of term. Our proof is very different. We use two-scale methods as compared to that one. Then you want to look at the next order. So you do a back-off the envelope calculation, right? You have a little cartoon. So, okay, so I'm going to go from A to B across an error. I'm going to have a buffer here that's going to be the size of my cell, gamma. And you plug that into the energy, right? You see what you get. It's just a beautiful. See what you get. It's just a usual scaling. And then you stare at that for a moment and say, ah, wait a second. If I divide by epsilon over delta, this is what I get. This is innocuous because epsilon over delta goes to zero. And then you look here, and that's exactly Carnegie Hill, right? That's a scale of its inverse. Scale of its inverse. That's exactly Carnegie Hill. So then, with that scale. So now you know what you should do. You divide by that, and this is what you get. That and this is what you get again. You're going to unfold, but now I'm going to unfold in both terms: both in the graded and in the W. Again, here I'm giving credit to Sierra Nez Guardan de Presor and independently Byzantine. Again, we use that. And then we're going to define the geasic distance between. So if I'm sitting on position Y. On position Y on my cell, and I want to connect the point P to point Q, and P is, say, on phase I and Q is on phase J, then this is going to be my geasic distance, right? I start at P, I add at Q, and across phases I to J. Okay, and then you prove that at first order, now it's at first order, and remember that I told you that. And remember that I told you that in this regime, we be drafts, it's a peggy nature, that they saw, oh, what we get is bulk. We don't get surface energy. What you get is bulk. The first gamma limit is an integral of omega dx. That's volume. So it's not an interfacial energy. Where the phase transition is in here, in that V is going to be a B V function, and you're going to go across the jump. And you're going to go across the jump of E with the geodesic distance, what I just did. Okay? And so you see the phase separation by respecting what the energy density looks like. But at the negative eye, this is bulk. Okay? So, again, as I said, at first order, you don't see a microscopic phase separation, you see it next. And then, Next, and then you say, okay, so now I know that I should eventually get to a surface energy, so it has to be the second order. But to get to second order, you need to what? You need to find out what is the minimum of F1, subtract and stand, right? And then you go to the second order. That's a lot involved. And usually we are so lucky that Are so lucky that we subtract zero because you know that the minimum is zero, you just have to scale and then go further, right? That's the point: is that actually the minimum of F1 can be non-zero. And you prove that it's zero if and only if the A's and the B's are continuous. Or the periodic extensions, but we don't like that, right? We want them to be measurable. So, okay, so, but anyway, there's more to that which I should be able to tell, which is basically we should be posting it to archive hopefully by the end of this week. There's a draft, but it's not a good draft, so don't read it. But the real thing should be this week. So, anyway, so. Anyway, so what are the challenges? Is that you have two scales? Is that the wells are discontinuous, they may be even overlapping. That again, in the case of Christoffei and Gravini, without the marginalization, they had exactly looking like the square at the wells. We don't have that anymore. The wells, again, they don't have to be well separated, but still it's okay. So now Okay, so now again, what are we studying now? I hope this is going to come out soon. It's Nextcloud, right? And we are doing that now for fixed wells. And what we do here, okay, first we had to find out what is this minimum of F one. And what we use in our analysis is the so-called plate-like minimizers, going back to Caffanier de Lalafrie. Cafa de Lalafi and then also Chabol, his collaborators, Tier Guccia, and Rofana and others. And we can actually finish up the grammar image, which I'm not going to show you now because, again, I hope it's okay, but we are still going through the proof. But if you are right, what is interesting is actually, although it's coupled, Although it's coupled, right, with epsilon going to be much faster than delta, if you would have done delta going first and then epsilon, it would be exactly the same. Except you cannot prove. I mean, it's the same if I do this proof and I do that proof in the end they are the same, but I cannot prove that when they go in tandem, this is the right thing to do. That's the problem. Okay, open problems, and I think I'm Problems, and I think I'm pretty much on schedule again. Let me remind you that epsilon is the transition layer, delta is the scale of the publicity. Oops, not yet. So what we don't know. When delta adaps from going tennis, which was the first place I showed you, we don't know yet with moving loss. We are studying that. When you have a modernization must. When you have a modernization much faster, then absolutely we also don't know how it does. There is now more recently quite a bit of work now putting together modernization, and also it also brought you Tatariali kind of framework. And also here. And then, of course, you ask, oh, what about the gradient flow? Right? So now let me evolve by surface diffusion. You have kind of like an aluminum. You have kind of like an Alan Pan now, but we have marginalization, right? And again, there's a ton to be done there. We only did that in the critical regime with Russell Shaksi, Jessica Lean, and my former postdoc Radaf. Independently, Peter Morphy. Also, we this is work independently, Peter Morphy and LS. Peter Morphy is a student of Suvenidis. And by the way, we publish in the same year in the same journal. And the results are the same. The techniques are completely different. And we kind of find halfway through our work that we both do the same stuff, but it was so different that it was fine. But again, in terms of gradient flow, there is so much to design. I mean, for example, I have to tell you, in our case, just one minute, in our case, In our case, we have a very, very particular W in that it's exactly, say, it's decoupled like that. So in our work, it is like that. And by the way, what we did is not without loss of generality, because you really need it to look like this. We had to, there were quantitative properties. There were quantitative properties on like hyperbolic tensions of these traveling waves and all that, where we used specific form of W. Peter Morphe had more general cohesions than you, but he had completely different techniques. And again, I owe something to Ian because I was saying that it I had it here and I don't. So the non-periodic surgery. The anisotropy. No, no. No, okay, so what I'm not talking about simply, I'm talking about an isotropy of the sigma. And you can prove that unless you have basically what is it? So if this, for example, if you have an example like this, if A is not continuous, if you don't want A to be continuous, then you can. What the protein is, then you can prove, it's an example, quite simply, it's a 2D example, where you prove that sigma actually depends on the problem. That's a result by Ricardo Dystoffey, where of course you cook it up, but you have a measurable function which is periodic and kind of like stair-based kind of thing, and you prove that it's. So just to clarify, you're saying that you have an example of an A. Saying that you have an example of an A which is discontinuous, for which you get a sigma which is truly an isotropic. But in general, can you, is there a way to link the symmetries in A into the anisotropy? No, but I never thought about it. So the short answer is I don't know. But I suppose that the way to do it is to look at the cell formula, try to study cell formula, right? So in this case uh you the the wells are the same. Just as well. Yeah these are fixed wells. Same. These are fixed wells. Fixed wells, but it's completely decoupled this from that. Although, of course, in the end, you know, this is going to look like A and B and this is going to not orient according to whatever publicity has. And this is it. We have time for a couple of questions and thing I don't understand. If you take the terminal covers the case where the dependence uh respect to the status variable. Yeah. So and you you say but there is no need work like a machine. Did I say that? So if I take the W, not depending on the white, we have two. Yeah, which is just a usual W. Yeah. So you have the second term, W1 should contain the usual interface energy. Yes. Yeah. Yeah. But it in theory. Okay. In in Germany. Okay. Are you talking about the case when I say that that's the case? No, no, that's the case. That is the case where, let me go back, where you had go back here. We spent five times, right? Five times, right? Is that