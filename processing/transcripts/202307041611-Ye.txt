I'm a postdoctoral from Fort Hutchinson Kansas Center, but I will soon hopefully join the faculty team. So I'll continue the discussion about data integration. And instead, I want to introduce a little new modality that we haven't covered too much in our discussion. So it's about cell surface protein. So the technology that we use is called Sci-C data. So Sci-C is a technology that cannot only give you the genes. That cannot only give you the gene expression, basically that's a single cell RNA data, it can also tell you the cell surface protein measurement. It is profiled by the antibody direct tag. So I'm going to use ADT count to represent the cell surface protein enrichment. Okay, so why do we want to measure one more modality besides the gene expression? So, especially for the immune-related study, for those immune systems, some of those like System, some of those like immunologic cells have already been differentiated. So, some of those cells have specific genes do not need to express anymore. So, that's why you can see on the young map, if we only use single cell RNC, the helper T cell and the cytotoxic T cell kind of like form a cluster because their gene expression profile are very similar with each other. However, for those immune cells, because they need to fulfill some specific cells, have specific functions. Cells have specific functions. There are those functional proteins on their cell surface. Those proteins are the product of RNA that has already been deployed and on the cell surface. So those are the cell type specific information we can leverage to separate out those specific cell types. So that's why on the right-hand side, using the cell surface protein measurement data, you can see a very clear separation between CD14 cell and CD18 cell. So that's why when we're in the So that's why when we integrate two modalities all together, we can achieve much refined step-cell type identification. So basically, size-C data give us two big matrix. The RNAC count matrix gives us the gene expression, rows are genes, columns are cells. And again, it also gives us the cell surface protein environment data, which is this ADP count matrix. ADP count matrix. So again, rows are proteins, columns are cells. And because this technology measures two modalities simultaneously within a cell, so the column have this one-to-one matching relationship, showing that those are the gene expression, those are the cell surface protein arrangement within that exact cell. And also, based on the experimental design, currently we can measure 10 to up to like 300 cell surface. Up to like 300 cell surface proteins simultaneously within the cell. Alright, so now it comes to our open. So we want to do quality check, we want to see if there are any amounted technical noise in the data before we carry on any downstream analysis. We did this for single-cell RN-STIC, so it makes sense to do it for this new modality as well. So single-cell RN-STIC has known for its bar. Single CRSD, it has no info sparsity, which means there can be a lot of zero on the count matrix. But for the protein part, it's not that sparse, actually. And zero can be a background signal for the single-sign RN-seq data, meaning that either this gene has no expression or this gene's expression activity is just so low it cannot be captured by the technology. So there is a background for single sign-seq data, but zero is not background for the cell surface protein anymore. The cell surface protein anymore. And instead, the cell surface protein has this background called nectar P. And I'm going to show you now. So, for example, if we take one protein across different cells, for example, and generate its corresponding density distribution. So, on the right-hand side, you can see that x-axis is an ADT count, y-axis is a density, and each row is a sample, one color represents a batch. So, you can see like So you can see like there's not many cells that have zero protein. This particular protein has zero count. Instead, it has this bi-model pattern. So the first peak is called a nective peak. And this nective peak captures a background signal. And it still have a count simply due to the unspecific binding ability of those antibodies. So for example, this yellow antibody, it should bind to yellow protein. It should bind to yellow protein on the cell surface, right? But this yellow antibody also has this very low lactical fluid, but still this specific binding ability to randomly bind to all the other protein, just randomly. So that's why it form this NAC2P, it means like for all those cells that have those number of yellow protein count measurement, those cells do not actually have yellow protein on the cell surface. Protein on the cell surface. It still has a readout because the yellow antibody randomly binds to other antibody and give you a readout. And the second peak is called positive peak. It means like those cells really have a yellow protein on the cell surface. That's our signal part. So you can see like for batch 1, 2, 3, the negative peak and positive pea have a very clear separation. But for batch 4, well, the negative peak and positive peak have certainly Active P and positive P have a certain level of overlap, showing that the background signal and real positive signal is not that distinguishable compared to batch 123. So we suspect like maybe there is a so-called batch effect in this data. And we confirm it on the UMAP. So you can see like batch 4, the batch effect dominates over the biological information and forms its own cluster. And this kind of batch effect is quite, is kind of like gradually to be quite common, especially for, especially because we are generating more and more data. And for large cohort study, for example, this COVID data that is generated in 2021 and it covers like 130 patients. So it's like a huge task. No lab or one center can fulfill this task completely. Fulfill this task completely. So, like, this project is kind of split into three centers and they follow the same experimental design. But you can see like different centers have their own setup, have their own technician, have their own requirement. So, for center one, you can see the nexus peak and positive peak very nicely separate with each other. Well, it is not the same thing for center two. So, you can see like the So, you can see like the so-called positive signal, it becomes like a heavy tail, like a shoulder peak. And center 3 is good, but not as separable as center 1. So, 3 center gives you three different level of quality data and how to analyze them together. That's why we need some data integration tools and normalization model for the cell surface protein. And before we propose new normalization, New normalization method, there are definitely some straightforward ones that is in practice. For example, the center-log ratio is proposed in the very first ICE paper. That's why it becomes so widely adopted in the field. So centered log ratio take a geometric mean across different proteins for one cell, and they try to use this geometric mean to kind of like estimate the sequencing depth and get rid of it. But you can see, like, first, like, whether we should. Like first, whether we should get rid of sequence cells can be an issue, especially for the cell surface protein data, because we will only measure 10 proteins within that cell. The 10 protein can represent the cell's different function. If this cell wants to fulfill this function, it definitely needs a lot of certain protein on the cell surface. It does not mean like there is a sequence bias for the cell. It's simply because this cell needs this cell surface protein to fulfill such function. Protein to fulfill such function. And also, besides ZikasenDAP, there can be a lot of other variation sources that can lead to batch effect. For example, different labs may use different IgG antibody to capture the cell-sex protein epitope, and also they may use different concentrations of those IgG. So you can imagine different concentration levels can give you a very different separation between negative E and positive E. And also there are same qualities. And also, there are quality issues, all kinds of other technical issues. We cannot exhaust all those variation sources. So, that's why I just use this simple center log ratio. You can see batch 4 still have quite distinct density distribution compared to batch 1, 2, 3. And again, it confirmed there is still batch effect in the data. Okay, so what I've shown you are four batches within one study. Four batches within one study. But what if we want to do the data integration across different studies? Because, like, right now, there are more and more size data that are generated, and we want to merge them to see, like, can we study the real cell type in a better way, and can we associate it with different clinical outcome in a more comprehensive way? So, to integrate the data, you can see, for example, showing here, one row represents a study. It can be a data set or can be like a study that. Like a study that generates different labs or design for different study. So the variation can be even more dramatic. So for example, some of the negative peak showing here can be even higher than some of the positive peak, you know, another study. So such dramatic variation definitely cannot be fully handled using center lock ratio. So on the zoom map, you can see like one color represents a study. So for after center lock ratio, So after center log ratio, like one study still forms its own small cluster. So still the data is not fully integrated. So that's why we're thinking like instead of propose a very complicated model that can exhaust all the potential variation sources and model them explicitly, can we just identify all the negative population and identify all the positive population and then push all those? And then push all those negative peaks to align with each other, push all the positive peaks to align with each other, and then we can get rid of the batch effect to achieve data integration. That's why we propose this method called ADT-NOM. It's like the normalization for ADT count. Okay, so ADT-NOM starts with a very routine data quality check and filtering. And first step is to identify the negative P and positive P, and we use curve registration. And we use curvature registration. And then we use local minimum cannot identify a valley between 2p. So this value can work out like a very rough ratio to separate out the background signal and the positive signal. And finally, our target is to align the negative peak, align the valley, and then align the policy peak. So it fits very nicely into this functional data analysis framework. And to put it more mathematically, so we use kernel. So we use kernel density to describe each sample's protein count. And then the peak and valley are considered landmark as those are our target and targeted to align them. And to align the landmark, including peak and valleys, definitely we need a transformation function. And this transformation function should achieve like same starting, same ending location, and all those landmark should be. And all those landmarks should be aligned. So, to get this transformation, and also the most important thing is that this transformation function has to be a smoothing and strictly monotone function because we don't want to mess up the protein expression order across different cells. And to do that, so basically, this is our objective function. We add a small penalty here to ensure like so this will be this transformation function will be a smoothing and like strictly Will be a smoothing and like strictly monotone function. Some of the results. First, because our target is to do peak alignment, so you can see like negative peak alignment, positive peak alignment. And our harmony here is that ATD NOM can take in your prior information. So for example, this data set only contains T cell. So in my case, I work on CAR T cell immunotherapy, so all my CIS C data only contains T cell. only contains T cell. So I have this prime information like I know there's only T cell in my data set. So if you observe, you can tell ADV norm set prime information like if ADT norm you identify a peak, just align it to positive peak to show like there are so many times out there. So we set up a parameter to allow the prime formation. And also like we definitely can't handle missing value because when we do data integration, not all the studies We do data integration, not all the study can matter CD27 or some lineage protein marker. So ADNOM just learns whatever is available. So after the peak alignment, you can see like ATNOM can merge cells from different data sets into one cluster and they all come from the same major cell type. So you can see like previously for the orange one that's mono-size, they're split into like different Splitted into like different clusters, now they are merged with each other. Definitely, we did some benchmark analysis, compared with other models, and use ARI to evaluate the batch effect lock from the data and the cell type separation. So, basically, a good message should be located around this corner and that source message. And I will skip over the rest bonus function and show you some about the software. Show you some about the software. So, we provide the R package and we're also developing a Python tool so that we can cover users from both worlds. And after, I designed like around 20 parameter to tune the peak identification and alignment because we use the kernel density, so it's very sensitive to the bandwidth. And I designed around 20 parameter, and I think it's just so inhuman to tune 20 parameter. So, why not just develop a shiny app? So, if like somehow if Somehow, if you found some peak identification, for example, this one here is not that accurate, you can just manually go to that data set first and manually set the value and will be adjusted. So instead of tuning the parameter, if you found tuning the parameter is hopeless and the scope is shiny. And with the help of ChatGB and all those AI systems, now it's super easy to develop those kind of interactive tools. To develop those kind of interactive tools. And I will stop here and thanks our grant. So, thanks for the great talk, and I think this is going to be really useful for, like, I work in IMC and cytology cytology and everything. Right. I guess the question I have is: is there a reason why you don't use the RC? Is there a reason why you don't use the RNA data? At least distinguish peaks. Why data wall? Because some information is very unique only to the protein data. And we kind of finalize those two modalities. When I analyze the data, those two modalities kind of have different features. It's better to analyze them separately and then merge, integrate later on. Later on. Just curious about the curve registration. So that works, of course, really well when you have a bimodality, you have two clear peaks. But what happens when you have like a rare population? It's only positive in a very small subset of cells. Yeah, so in that case, you may not only just have two peaks, in that case, you may have three peaks, even four peaks. So basically, So basically we can either add the piece for you. 