And I'm not going to lose myself in all these sad things because we're going to have a closing remark at the end by Carlos. So I'm just going to jump in directly to the first speaker. So I'm very pleased to introduce you today to the first speaker, Professor Smita Krishna Swami. I hope I pronounced it correctly. And so a little bit about her. She did her undergrad at the University of Michigan and her education. And her education culminated in a PhD in computer science and engineering at the same university. And she's now an associate professor in genetics and computer science. Her lab works mostly on machine learning techniques for high-dimensional data and works mostly on technique, non-linear technology, non-linear dimensionality reduction and visualization, learning data from learning data geometry. And uh and data denoising, imputation, and inference on feature networks. Some examples of data that she's working on include single-cell RNA synchronic data, mass cytometry, with a particular focus on immunology and immunotherapy among other specializations. So today she's gonna talk about her work in deep geometric and topological representation. Ecological representation with some interpretability on biomedical data. And yes, thank you again, and the floor is yours. Sorry, just trying to unmute myself. You can see the screen, right? Yes. Okay. Thank you for the introduction and hope you've had a pleasant stay there. I wish wish I could have been there in person, but I think I'm going to a different advanced conference that's Going to a different advanced conference that's in person in July, so I'm looking forward to seeing the sites. So basically, a lot of the problems in my lab are motivated by the idea that we have biophysical and biochemical systems that are very, very complex. And we finally have kind of the data that you can learn about these underlying systems from, but the data is sort of generated on MOS. Generated on MOS in terms of millions of cells, thousands of molecules, many, many patients on which you have data. But these have to be organized in a way that you can understand what the features are that can be responsible, for example, the conditions that we were just talking about, like immunological conditions, or even understand what the causal interactions and the mechanisms driving things. And the mechanisms driving things like self-fate are. So, fundamental challenges in this kind of data, which might not be as prevalent in non-scientific data, is the fact that there is a lot of noise, so that can occlude any kind of insights that you're going to gain from it. They're very, very high-dimensional, and the structure is often not known a priori. So, it's very important to understand the structures of your data and what you're actually seeing. There's many sort of modalities or measurements. Modalities or measurement types that can occur on the same entity that can be like looking at different views. For example, you know, the blind people feeling one side of the elephant, see the tail and the ear. It's very much like this. And also, another thing is that really to get interpretable, actionable insights from this, we need to consider the idea that these are actually dynamic systems and that you're actually seeing snapshots of those. So these are some of the challenges that my lab has looked. Challenges that my lab has looked towards handling, the first couple of which I'll talk about more so than the others today. So, some of the keys to gaining these kinds of insights from any kind of machine learning model is not simply that in biomedical data, you can just predict the result and be happy with it because then nobody will trust it. No one has any understanding of the causality or how the mechanism works. And really, what we're looking for is more understanding. So, this is why. Understanding. So, this is why my lab really focuses on learning representations of the data that are actually highly interpretable visually and in other ways. So, the basic framework we use is manifold learning, and if you want to be more specific about it, it's graph-based manifold learning a lot of times. But we augment the graph with diffusion processes that allow us to treat features on these data graphs as signals. So, we employ a lot of techniques. So, we employ a lot of techniques from graph signal processing and also topological data analysis in order to basically learn features from the data. Now, after learning these kinds of features, it can be much easier, much more interpretable to apply machine learning techniques to perform prediction or associations from it. But of course, you don't have to sort of do it in order. You could also regularize something like a neural network so that it. Something like a neural network so that it immediately learns interpretable features from your system, so that once you have some kind of predictive result, it's immediately attributable to some specific characteristics of your data. So just to give you a framework for the idea of manifold learning D, this is the assumption that your data that you've collected lies in some regular spaces. And what I mean by regular spaces are these. And what I mean by regular spaces are these kind of smoothly varying, locally connected patches. And it doesn't have to be one patch like this. It could be several. And what you're seeing here, though, is that this date space is highly restricted compared to something where the features are not so well coordinated with each other. So what you typically see in the biomedical and life sciences are the features that you're measuring, like the genes, proteins, epigenetics, they're all really highly coordinated and working together. Coordinated and working together to form a lower-dimensional state space, and characterizing this state space is what gives us a lot of the interpretable features. So, for example, what characterizes this progression right here. So, an underlying framework we use, either alone or together with other more traditional machine learning frameworks like classifiers and neural networks, is what we call a data geometry framework. You may have Framework. You may have heard of an earlier work that came into play here called diffusion maps. But we often don't use just the diffusion maps. We treat the diffusion data and diffusing over data as a process as an underlying framework. And it has a lot of different connections to these different methods that I told you before. So at the heart of this is the sort of game. At the heart of this is the sort of the idea that if you have your data, you can turn your data into a graph. So a typical method for turning data into a graph is to go from absolute locations of data in some kind of measurement space to relationships between points. So here, a relationship between points is the distances. Then you can actually invert the distances into affinities, which gives you stronger relationships, or emphasis on the stronger relationships. Or emphasis on the stronger relationships in the data. And from here, you can figure out the manifold. You're already starting to see the shape of it. But imagine you put a signal at one of these vertices and you let that signal diffuse. As you're letting this signal diffuse, you're figuring out pathways in your data. And that's really what diffusion allows you to do. It allows you to have signals on your graph or use signals as features on your graph and have them diffuse to, for example, figure them diffuse to, for example, figure out the major pathways or eigen directions of this. So just to hone in on what exactly that operator is, so if you have any graph, you can turn it into a diffusion operator, which describes the diffusion process on the graph. You just take the adjacency matrix and you can row normalize the adjacency matrix and you get these diffusion probabilities, which will tell you how, for example, signals will spread on your graph. Will spread on your graph. The earlier diffusion maps construct is an eigen decomposition of this type of a diffusion operator, and it gives you these diffusion components, which are the eigenvectors weighted by the eigenvalues. And what we find here is that these eigenvectors are actually very nicely arranged from high values to low values that, like PCA, explain the importance, but they also contain very interesting information because they actually form harmonics on your data graph. So this allows On your data graph. So, this allows us to bring in signal processing, and this is why I'm calling this framework very comprehensive because it immediately allows us to go from learning the graph and the graph features to trying to do pretty advanced signal processing transforms on it. So, the second eigenvector of this is a slow-moving signal on the graph. The tenth, for example, is a very fast-moving signal. And this can allow you to, for example, denoise features on your graph immediately. Immediately. Other things that it allows you to do, which I might have less time to talk about, is to think about how different features are spread on a graph. And this is the idea of optimal transport. And it turns out that differences between multi-scale diffusions actually form an optimal transport distance of signals on your graph. And finally, we're often not looking at these data graphs at one level of granularity. These data graphs at one level of granularity, we find that looking at them at many different levels of resolutions allows us to pick out features of entire data sets that can characterize the entities that you're trying to characterize. So I'll first start with how we use this diffusion framework to organize data hierarchically into subgroups whose proportions, for example, can give you features from which you Features from which you can, we've shown that we can detect biomarkers or prognostic markers from disease conditions. So, the main idea is to use the diffusion process to naturally allow groupings of data to appear at all different levels of granularity. There's a number of works where we've used this, including IEEE Big Data, where we originally presented something about it. It was subsequently published also in NATO. Published also in Nature, and we have actually submitted a more mathematical version of this to Simons. The motivation behind this is that biological entities have multiple levels of organization, and there could be meaningful features at any level of organization that can help you explain some kind of output or predict the output. And what we want to do is look at features that. Is look at features that emerge at all different levels and sort of quantify which levels might be meaningful for us. And to do that, we go into algebraic topology. And algebraic topology is used often in computational topology. And the idea basically is to quantify abstract shapes of features. For example, these Betty numbers. The Betty zero quantifies the number of connected components. Number of connected components, Betty 1, the number of cycles, Betty 2, the number of cavities or voids, and so on. So, in computational homology, which is actually a data geometric method, you start with data and you start thinking about the relationships between data points by filtering over an epsilon parameter. So once you filter over this epsilon parameter, whenever these balls overlap, you destroy the individual components and come up with a unified one. But you'll notice that this actually One. But you'll notice that this actually coarse grains the data into these larger components. And so essentially, topological data analysis is looking at features that emerge at different levels of coarse graining. And the idea is we want to look at all scales, and we want to see interesting features that appear at all scales. And you see at this scale, a cycle emerges, and this is why there's a blue dot here. And the cycle is almost immediately destroyed because when you increase the size of these dots, there's actually a different cycle that occurs. And especially interesting, maybe. And especially interesting, maybe persistent features that stay for a long time. So, while that process is interesting, we noticed that it often wasn't giving us very meaningful results on biomedical data. And we reason that it's because it's reasoning in the ambient dimensions of the data space and not in the manifold dimensions. So, in order to have this operate in the manifold dimensions, we defined a different filtration called a diffusion filtration. Filtration called a diffusion filtration. And the idea is just that you come up with a diffusion operator of your data by going from your data features to distances, affinities, and the Markov normalized operator. And you reapply it, but you recompute the distances afterwards. And what this gives is a way of course-graining the data slowly, such that different levels of granularity naturally emerge. It must be mentioned that this is different than hierarchical clusters. Mentioned that this is different than hierarchical clustering because hierarchical clustering forces emerge at each iteration. But here you see some iteration, nothing happens. Some iterations, a lot of things happen. So the time at which something happens is actually very careful and meaningful here. And so what that's actually doing, if you want to look at it in the spectral domain, is you can think of the features of your data points as signals on a graph. Signals on a graph, and if you look at it in the spectral domain or the Graph Fourier domain, then that's akin to loading these features onto the eigenvectors of the diffusion operator or a related graph Laplacian. And once you do that, what you're seeing is this filter is actually, this filtration actually also creates a signal processing filter, which slowly kills high-frequency. Slowly kills high-frequency noise. Earlier, we just used one iteration of this in our method Magic and we discovered that it denoises data. For example, this is data that didn't have dropout. We added it and then we imputed it. But now we want to see what we can get from continuously running this kind of condensation filtration over and over again. And one of the interesting results we got is when we tried it on this data set, which is the neurons of a C. elegan swarm. Now the C. eleganum C. elegans worm. Now the C. elegans worm only has 200 to 300 points in the sense that it only has 200 to 300 neurons. And what we had were cross-sectional images, kind of like a salami slice of the worm. And based on how often neurons are found together, we created an affinity between the neurons. And then we used this affinity matrix and ran this process to its conclusion where everything is one point, which I'll show you about in a second. I'll tell you, show you about in a second. And when we did that, what we got is a complete organization of how the neurons in this worm form. So you have individual levels of neurons and you have groups of neurons which form neural circuitry. But these individual neural circuits have to communicate together to form the entire nervous system. And so this was validated by our collaborators led by Mark Moyle from the Danielle Cologne-Ramos lab, and this. Colon Ramos lab, and this was published in Nature last year. So I said something when I was saying this. I said this is actually giving a complete organization because everything at the end of the process converged to one point. At that time, we weren't actually completely sure that this happens. We weren't sure that there is no case where this can get stuck and this actually completely sweeps data to find groupings and features at all different levels. But since then, we've come up with two different ways of proving that. With two different ways of proving this convergence. The first way of proving this convergence is to look at the convex hull of the data. So if you look at the convex hull and you apply the diffusion operator, the diffusion operator always replaces features with a convex combination of its neighbor's features. So what that is doing is putting things, everything, into the convex hull of the data. So if you move everything into the convex hull, that means your convex hull shrinks. And what is their rate at? And what is the rate at which it shrinks? The rate at which it shrinks is determined by the smallest component of the convex combination. So, if your smallest value in your affinity kernel is delta, then it shrinks at a rate proportional to delta, and you can prove that these convex holes are nested, and they'll go to one point. There's a different, and so what this proof actually tells you in practice is how you need your affinities to be defined. Infinities to be defined. We found a different convergence based on the spectrum of the diffusion operator. So, as I said, both the form of the diffusion operator and its frequency spectrum or eigenspectrum give very interesting information, which is what makes this framework so rich. The idea is that when you apply the diffusion operator to a function, the resultant value is bound by Is bound by the so-called Fiedler value or the second largest eigenvalue that you have. The first largest one is always one, but it's the second largest one. And you can actually bound the second largest value away from one by selecting the bandwidth of the diffusion kernel appropriately. And we even adjust the bandwidth so that you get consistent convergence in a fast way. So that's a little bit about this kind of process that picks out multi-scale features in the data. The data. Recently, we've also used this together with an earlier method we had called FATE to come up with multi-scale fate. And I will explain that in a second, but that gives you a visual way of looking at data at multiple levels of granularity and where you can zoom in to specific areas of the data and you can see it more clearly. But before I explain that, I'll talk to you a little bit about what it means to find. Little bit about what it means to find features in point clouds. So you might be used to thinking of each observation as a vector of measurements. So you can think of, this works well if you had bulk RNA sequencing, for example. In single-cell RNA sequencing, typically people think of each cell as an observation. But it seems that that's really no longer the case. The unit of observation these days is actually a clock. These days is actually a cloud of points. So, on patients at Yale, New Hampshire, for example, there was a whole cloud of points or a whole single-cell data set collected on the whole patient. Now, you have to come up with features from the single-cell data set or point cloud. So, you're basically lifting all the analysis that you're doing by looking at heterogeneity between points to looking at heterogeneity between point clouds. And to facilitate: Clouds. And to facilitate this setting, one of our first forays was a comparison method called MELD, which was published last year at Nature Biotechnology. So, what MELD does is it allows you to compare two clouds of points. So, one cloud coming from a control condition and one coming from a treatment condition. And if you just looked at them, there's a great deal of overlap and it's not clear how they're different. But if you really want to hone in on the differences between them, then one thing we can do is we can estimate the density. Can do is we can estimate the density of these two samples in the manifold and look at the differences in density and look to see what features are really key in areas of difference. So conceptually speaking, what you're doing is you're thinking of each sample as forming a density on the cellular state space when you're looking at the differences in density. And you're looking to see what cell types are enriched in these differences. So this is actually a little bit of a different way of thinking about finding these features than normal. About finding these features than normal. Usually, people just perform clustering and then they say, How are your cluster proportions different? But if you think about it, the clusters that you a priori divide your data into or partition your data into may have nothing to do with the response or the actual difference between the data sets. And you might find things that are completely obtuse or uninformative features. So, instead, what we do is we go. So instead, what we do is we go ahead and compare the two-point clause first, and then when we see the areas of differences, then we look to clustering the areas of differences to find more informative features. And in order to break these features down discreetly is where we use the multi-scale topological analysis that I just showed you. So the way we actually do this is again using a filtering framework on a graph. Framework on a graph. So we have a graph here, and one of the data clouds we're looking at is indicated by a 1 here, and the other one is indicated by a 0. And you can actually use a graph filter that mimics heat diffusion, which in turn has shown to be a density estimate on the graph. And I'll skip over these, but basically you can find an analytical solution based on a heat kernel, which is well studied in kernel density estimation. Kernel density estimation. You can reformulate it as a reconstruction error combined with a smoothness error, and you can find a unique solution which gives you a way of filtering your data that's similar to diffusion, but slightly different, and it's more stable. So, when we apply that, we can find areas of the cellular manifold that are enriched, and therefore we can find cellular subtypes that are predictive of outcome. Outcome. And another useful way of doing that is to invert those densities into a likelihood using an uninformative prior. And now you can color each cell by the likelihood it comes from the control or treatment condition. And now you can see areas of this space that are enriched in one or the other. And here's an example of it: control versus stimulated T cells. And here you have the And here you have the likelihood signal, and based on the likelihood signal, you can pick out areas that are highly enriched for the treatment. And now, when you look at their gene signatures, they tend to be very sharp, and they'll tell you what processes are going on. So, that's a toy example. We want to do this on other examples where we don't already know this a priori. So, one of the data sets that we've tried combining MELD with our multi-scale diffusion. Our multi-scale diffusion topology is in AMD and also in other neurodegenerative diseases. So, recently, we had a collaboration that gave us a total of about 17 different retinas that were single cell or single nucleus sequenced. And when we looked at it, we found several different cell types that are well recognized as the most persistent cells. The most persistent cells. So we no longer wanted to look sort of at the most persistent cells, but at the cell types that were most enriched in the disease. So when we look at those at a coarse grain level, we point to the microglia and astrocytes, which are both immune cell types in the retina and actually in any neuronal tissue. But when we look for this kind of enrichment based on MELD, we see subclusters that are actually enriched that actually occurred earlier in the diffusion process. In the diffusion process. So, at some iteration of the condensation I showed you, we had a separation out into three subclusters of the microglia. One of the subclusters is enriched in control, and two are enriched in different stages of the disease early in life. And when we look at these signatures, they seem to be very robust. And one of the ways we can see that they're robust is they actually occur in other neurodegenerative diseases, like Alzheimer's and multiple sclerosis. Alzheimer's and multiple sclerosis. So, when you look at these signatures, these can actually suggest targets for therapy or biomarkers for early detection of these kind of conditions. And you can validate these in a variety of ways. I'll show you, our collaborator actually did multiple validations by injecting inhibitors for some of the parts of the signature and things like that. But this is a very visual way, which is RNA scope. And here you can see that components of the signature are more high. That components of the signature are more highly enriched in wet or dry AMD or in these other conditions. So, we were also able to use it in another disease together with our FAIT methodology, which is COVID or COVID-19. And actually, this is going to be the cover of Nature Biotechnology in May. I was hoping that the May edition would already come out since it's May 6th, but it hasn't come out yet. I just checked. But here's a sneak preview into the cover. Into the cover, and the idea is that this is a multi-scale embedding algorithm for data exploration. This comes from our earlier method called FAITE, and the idea of FAITE was to actually preserve diffusion geometry of data in low dimensions so that you can actually look at it. And the way this differs from other dimensionality reduction methods is that it's very specific to trying to preserve diffusion affinities in a denoised fashion as opposed to neighbor embeddings or methods that project. Or methods that project things to directions of variation. So you'll notice it's able to denoise and preserve diffusion geometry. So the way it does it is it computes the diffusion operator using a specific kernel called an alpha decay kernel. And then it forms a distance between data points based on the diffusion probabilities, which is an information theoretic divergence that it embeds into low dimensions. But one of the drawbacks. But one of the drawbacks of FAIT way is that it's only looking, and probably most of these methods, is that they're only looking at one granularity of the data, whereas we just showed you that different granularities of the data can contain information about different diseases or stages of diseases. So if you want to get into that level of granularity, you can't just like stare at the whole picture. And what we really wanted is a way of looking at the data at this level, you know. The data at this level, you know, and getting clusters out at this level, but then being able to zoom and look at subclusters and substructure. So, this part here, if you zoom in into it, you'll see a lot more substructure, and now you're seeing subclusters. So, multi-scale fate gives you this very clustered form that you can zoom into and look further and further at. And also, the fact that we're using simplified coarse graying the representations of the data points makes it so that it's very highly scalable. So that it's very highly scalable. So we applied this to longitudinal patient cellular response from 219, now more actually, patients who were admitted to Yale New Himmon Hospital. So again, each of these patients had multiple data clouds collected on them based on these different panels of flow cytometry that were measured on them, resulting in a really huge number of cells, 80 million cells. And now we wanted to featurize or learn features. To featurize or learn features from these cellular subpopulations. So, again, we use MELD together with the multi-scale fate methodology. And what basically the multiscale fate methodology is, is it's applying the condensation to the fate operator, which is this diffusion potential operator that you have here, where you take the log-normalized diffusion probabilities. So, for example, when you combine For example, when you combine all of these patients and now, color by the cell of origin using our MELD signal, you see some area of the manifold highly enriched in patients who die from COVID or have mortality. So we're calling this the mortality enhanced signal. And you look to see which sort of cell types have them, and you see, again, weak signal. But when you go into subcellular types, then you'll see a stronger signal. For example, this. A stronger signal. For example, this means that eosinophils and CD16 monocytes, when we zoomed into this cluster, have enrichment in mortality, but these CD16 negative ones don't. So if you took off these CD16 negative ones, then you'll have a more predicted populations here, which you can use to predict mortality with. You can see the same thing in, for example, the T cell panel. There's some part of the T cell panel that's highly enriched, and this enrichment is a Enrichment is a IL-17 plus interferon gamma plus grain ZIMB plus population. That if this population occurs, then you can predict mortality. But the funny thing is the total number of T cells is protective. So generally speaking, people with more T cells do better. But if you look at this next level of granularity, people who have this particular kind of T cell do a lot worse. So in that way, we're able to mine all four of the panels that we had on these panels. All four of the panels that we had on these patients and all of the cells. And we're able to come up with specific cellular subtypes, and these are not canonical cellular subtypes. So they're very specific things like CD14 minus, CD16 plus monocytes. So they have a lot of modifiers from the canonical subtypes you have. And now we can apply machine learning on top of this. When you apply machine learning on top of this, here we just reused a random forest. Now we can get attribution of these features to see which are Of these features to see which are most predictive of the mortality. And you see that monocytes, surprisingly, are the most predictive of mortality. And so suddenly you have, because you've engineered these features using these diffusion coarse graining process, now you can tell which of these features actually can drive the disease. So now I'm going to switch gears just a little bit in the last few minutes and show how you can do this with neural networks. So our first four range. So, our first foray into doing something like this with neural networks was SACE. And the idea of SACE was to let the neural network find emergent patterns in the data. So SACE does a lot of this by using regularizations in the data. And lately, we've been using SACE to do something like multi-scale fate by tuning the granularity of the embedding that you're looking at. So, specifically, Saucy features several. Specifically, Saucy features several regularizations, and this is the message that I want to get home to you: is that if you want to use this kind of feature engineering in neural networks, then you have to think up very clever regularizations. So one of the regularizations that SASI uses is a clustering regularization. And actually, the magnitude of this clustering regularization will control the granularity of the clustering. Another regularization that SASI uses is this maximal mean discrepancy regularization. Maximal mean discrepancy regularization, which corrects for batch effect. So then you have embeddings that you can interpret by cell type rather than batch and other things that you can do or you can bottleneck it so that you can have visualizable dimensions. So for example, the representation of clustering that you can use as a coarse-graining knob here is the idea that you want discrete codes. So for example, this cluster could have a specific code, this cluster has a Specific code, this cluster has another one, and you want good spacing and binarizable activations. So, here we actually used an activation entropy penalty on the activations of the neural network so we can get these binarizable codes. And the higher you hike this up, the different level of granularity you get. In fact, you can add layers to this neural network to get multiple layers of granularity in the same network, which we're checking for now. We're checking for now. So, as you hike up this network, you start getting these bistable behaviors that you can use to correct between patients. You can use to featurize patients based on the codes that you're getting. And an example of doing this, I'll skip over this, is this idea that you have different kinds of patients. Here, this was an infectious disease, and you have different kinds of patients with different of these cluster proportions enriched between them. Between them. And this again will tell you what cellular subpopulations and signals are leading towards this disease. In a totally different application, we directly use diffusion within graph neural network frameworks in order to predict and even generate molecules. So the idea here is that we want representations of molecules, which are themselves graphs, that are very, very Graphs that are very, very interpretable in terms of structure, so smoothness and faithfulness to the structure. So, where this is really strongly tells you structure, but also some kind of property. So, you have some kind of property here that you're trying to optimize. So, you can actually go into this latent space and just traverse through the latent space. And you can tell exactly what's happening. You're moving through the space with information about structure and function. Structure and function. So, as we saw before, molecules can also be encoded as graphs, and we saw that graph representations were very useful, particularly when you combine them with graph diffusion and graph signal processing. So, I think most of you have heard by now that graph neural networks tend to lose a lot of information about signals on graphs, mostly because they can only do feature aggregation that tends to lose information as you increase the number of levels. The number of levels. So the idea here is that if you have two different graphs, as molecules, these could be very different. This has some kind of 3D fold here, and this doesn't have it. But if you're looking at signal aggregation locally, they could be very similar. But on the other hand, if you use graph diffusion, you can see that places this signal could diffuse in two steps is very different than where it could diffuse in three steps. And now you can distinguish between these graphs. And so we went with this. So we went with this kind of insight, and again, you can create a diffusion operator from a graph, and we created graph wavelets, which are differences between scales of diffusion. And so what we do is we take our graph signals and look at differences between scales of diffusion. And you can even use this to characterize the entire graph, even in the absence of features, by just putting a Dirac feature on each part of the graph. And actually, Um, and actually, we last year we introduced a graph neural network that has built-in modules for doing these multi-scale diffusions, which is called a diffusion wavelet, and a series of diffusion wavelets, which is called a scattering transform. And you learn the scales, laziness, and many other parameters as you would in a neural network. So, how do we use this neural network? So, our neural network basically learns specific kind of features from the graph. It learns Of features from the graph. It learns diffusion features at multiple scales. So once you learn these features, we put these features through an autoencoder, and the auto-encoder is penalized to predict some kind of property. So now you have your latent space highly organized because of the features you basically told it to learn here and what it's trying to predict. So if you look at this, it suddenly gives you a very interpretable visualization. Interpretable visualization of the graphs that you are using in your network. So initially, we're using these non-coding RNA molecules, and this molecule is C3, which is known to be bistable. And you see most other graph neural network or even graph embeddings are not telling you that this is bistable. They're not properly organizing it. So you see that the graph scattering, regularized by energy, is actually. Regularized by energy is actually clearly breaking this down into two components. And similarly, with a toy trajectory graph here. And more recently, what we've been sort of looking to do is actually generate molecules right off the latent space in a very controlled way because now we can interpret this representation really well. So we've done this not only for graphs, but also sequences. We've paid attention to creating a highly structured light. Into creating a highly structured latent space. The reason you might want to do this for sequences is if you want to design proteins or antibodies, then you have combinatorial explosion in the sequence space, and you can't really well model epostasis. And a lot of the attempts are looking at one mutation at a time or reinforcement learning on one mutation at a time. So these typically tend to operate at the sequence level where it's very hard to traverse all the sequence space. Sequence space. And another one is to operate on the level of sort of a distribution of sequences, and now you have an exponential number of sequences to actually try out. So instead, what we tried here is a transformer model from NLP. So we use a transformer encoder with a bottleneck. And this bottleneck is very much like an autoencoder bottleneck, which has a decoder and a regressor, similar to how I showed you in the graph scanner. Similar to how I showed you in the graph scattering network. And we structure the latent space in additional ways to render it pseudoconvex. So you have negative sampling here so that you're actually reaching a fitness optima right in the middle. And now what we can see is that you can actually start somewhere and optimize your molecule by ascending the gradient. So basically, in order to get this kind of a very highly structured A very highly structured light and space, we actually needed several penalties. Reconstruction, so this is actually just the reconstruction penalty you see in autoencoders, but in this case, we used a transformer encoder. Regression to a property, negative sampling of things that are far away from high fitness levels, as well as interpolation to make this space smooth. And so, what that gives you is a latent space where you. gives you is a latent space where you can just climb to generate more optimized molecules. And we can see that in our representations that in many different data sets the joint training representation tells you which way to go in the sequence space and the higher degree of organization tells you how to climb that space. So as a result what you can do is you can use gradient ascent on the space to get better molecules. So, these, this is actually comparing on this embedding with the other kind of approaches that are prevalent or doing. So, directed evolution can, you know, goes one mutation at a time, but it can kind of flip around and change between tracks. MCMC is kind of exploring this in a haphazard fashion, whereas gradient ascent is going more directly to high fitness sequences and finding more of them. And what you can do from there is. And what you can do from there is to look to see, because these are structurally coherent also, what structures give you the high fitness. And one of the ways you can do it is using attention maps from the transformer to see which structural patterns or which kind of combinations of molecules are doing this. So we're using this same framework both with sequences and with the scattering transform. So this can be looking at how Looking at how the same kind of latent space, either you encode a sequence with a transformer or you encode structure with our scattering transform framework. And in either case, it's really the structuring of the latent space using the mini-regularizations that can really give you the ability to generate optimized molecules from this latent space. If you want to go a little bit into how we do the same kind of Into how we do the same kind of thing, structure the latent space with a graph scattering network that I talked about before. You have the scattering network here, we have a latent space here, a regression network here, and actually an adversarial generator here. And this whole path is penalized by both a reconstruction and a regression, as well as a generative model. And it's really the central piece of this is the latent space that's so highly regulated. Is the latent space that's so highly regularized to be able to traverse it? And we've currently been doing both public and privately available data sets, and we're routinely finding that our model finds a lot more valid and novel sequences. Although sometimes it's finding less unique sequences because it's going directly towards a specific area in the fitness manifold, which you can actually fix by reinitialization. Fixed by reinitialization. So, just in terms of future work, I just actually want to emphasize the importance of interpretability in these kinds of biomedical spaces, whether you're looking at cells or molecules. I think the ultimate goal for all of us is to actually not be able to use AI as a black box, but really be able to use it to understand things about the underlying systems. And the ideal would be if you can come up with a model that sort of even simulates the underlying systems. That sort of even simulates the underlying system, albeit it does it in a way that's computationally efficient. So there is a tension between sort of black box models and interpretable models, but in the sciences, I think it's very important, as these are often sort of inverse problems. With that, I'm going to stop there. So we have a lot of other types of networks and things like that that we create from these frameworks of diffusion geometry. Of diffusion geometry, topology, and deep neural networks. And if you want to check out any of our resources, please visit our lab's webpage or GitHub. And hopefully, I have a couple of minutes for questions. Thank you very much, Samita, for this very interesting talk. Are there questions from the audience? Yeah, Ben? Yeah. Oh, Ben. Yeah, Adi Smita. Thank you for the amazing talk. I guess I have a couple questions based on my own inspiration from these sorts of things. So I'm on the road and we have a lot of data about a lot of different diseases, but each individual disease might... Sorry, what's your name again? I'm sorry, I just couldn't hear your name. Can you hear me talk? Yeah. Okay, I didn't say my name. My name is Jen. Okay. Go ahead. Okay, go ahead. Yeah. So I'm at the road, and we have a lot of data about different diseases, but each disease might be constrained a little bit. But there are some shared patterns underlying all these circuitry. So are there ways that we can, how would you think about applying these sorts of methods like MELT or others to look at distributions that have shared aspects between many different outcomes? Between many different outcomes? Yeah, so I think I actually showed that a little bit when I was looking at the neurodegenerative diseases. One of the ways that we've been looking at related but different diseases, or even patients who have related but different manifestations of COVID, is actually to use this multi-granular feature learning. So when we learn these features at these various different levels of granularity, and we tend to look at which seems We tend to look at which seem most implicated in the disease, that gives you a much sharper signature. And you can actually analyze each disease even alone like that and then try to find similar subpopulations in other diseases. And there may not be the exact same subpopulation, but there could be a very similar subpopulation. And in that way, I think you can curate a common pattern. But it could also be possible that you actually, in the beginning, combined all of these. And we did that with our COVID patients, right? We combined all the patients and we put them here. Combined all the patients and we put them here, and we found a whole region of the manifold that was enriched. And each of these sub-regions could be in different types of patients. So, I think you could do it either way, depending on how much compute power you have. You either have the power to combine all the data at once and search for features that can allow you to characterize the diseases, or you can search for features initially and to see if they're related features in the other diseases. One question actually related to this slide. Well, first of all, thank you for the great presentation. It was really, really nice. So here you are putting together all the patients, right? Okay, and but you know, because each patient will have it a different profile, especially in the cell types that are much more or less populated in each individual. In each individual. So, my question is actually about how robust is this analysis when you have missing information, like the type of, for instance, cellular clusters, subgroups of clusters that you can find using MEL, would be there if you do not have some cells, for instance, in the data sets? So, I'm not totally sure of your question. Totally sure of your question. Are you asking me if you don't have the markers to identify the cell types, or are you asking me if some cell types don't exist in some patients? And actually, I think that it's okay. So the kind of model that we have when we're thinking about MELD is as this kind of model. And we've seen that this kind of model empirically works. The idea is that people don't fundamentally have a totally altered cellular state space, but rather you You have different densities on the same cellular state space. Now, if you only had one or two patients, and some of these patients may not have cells in some region of this manifold, then you'll lose out the manifold. But that's where the more patients you have, the more likely you are to learn the entire state space. Now you can see patients as distributions on the state space. Okay, okay. But do you think that you would be able to find any ways, subgroups of Ways subgroups of cells? Yeah, we do find subgroups of cells that are sort of enriched across patients. Okay, thank you. And that's, you know, subgrouping was kind of the point of the course training we were doing is to find different levels of granularity. Hello, wonderful talk. This is Jusmita. I was just wondering that. Wondering that when you say that now the units are not cells but the unit is cloud. So what does that cloud has? It's a data set of cells. Like it's a bunch of single cells that are measured in some modality. So instead of being a data point, it's a whole data set. Oh, so the units you are combining everything to the to one unit for one patient, which has these cells, everything. So the idea is each patient is described by a cloud of cells. And now what you really want to know is how the patients relate to each other. So here each point is a patient. But underneath this, each patient actually has a cloud of cells that look something like this. Something like this. So, how can you relate the patients to each other on the basis of the fact that you've measured entire cells on them? And there are several ways we, even in our lab, have done it. But one way is to featurize these patients by interesting and unique subpopulations of cells and how often they occur in these patients. And that's one way that we've found to be successful. And actually, another way that I didn't get to do it is to directly measure Earth Movers distances between these clouds of patients. These clouds of patience. And we did that in a different paper that I didn't have time to go over to. The idea of measuring the Earth mover's distance is very much related to MELD, for example, because MELD measures densities at one level of granularity, and we basically used an extension of this kind of density that was multi-scale to come up with an earthquake move or distance. Redistance. And that's really what I meant by. Oops. That's really what I meant by the idea that you now have to compare whole point clouds. So you can either divide the point cloud out into subgroups that you can identify across patients, or you don't have to do that. You can take the whole point cloud and somehow take its distance from another person's whole point cloud and you see which One more question about so one big limitation of topological data analysis is computational resources. So I mean tho those are you know processes that are very heavy from a computational point of view. Having from a computational point of view, I was curious to ask you if you are like applying some kind of strategies in order to run fast. I'm referring to the TDAs specifically. Yeah, we do. I mean, so for instance, the kinds of filtration we're doing, a lot of those filtrations are based on operations on a diffusion operator. Things like powering and multiplication by a diffusion operator. And we've actually shown in several papers how to speed those up. Shown in several papers how to speed those up using landmarks and reduced versions of the diffusion operators. And also, just kind of like the features that you measure, it often turns out that just a couple of dimensions of the features, 0 and 1, are usually enough. So you don't necessarily have to present very high orders of features. So those are some of the tricks that we use. Okay, thank you. So we can offer really meaningful levels of granularity just by measuring topological activities of H0 and H1 features. Hi, I'm Dario. So I currently work with biological data, and I was wondering if your fission clustering method, which kind of does a theoretical clustering, as you said, would be useful for me on other domains. So have you considered or have you tested which is the Have you tested which is the variant of the clusters that it generates with regards to other clustering methodologies? Yeah, we have tested it against clustering methods mainly in the sense that we're looking to sweep the levels of granularity so it's really more of a coarse graining method. And we're looking to see if the clusters, once you reduce the data into the clusters, you still have kind of preservation of the data geometry and in those ways we Data geometry, and in those ways, we've compared it to things like Louvain, Leiden, K-means, and these types of things. But the variance of the cluster sort of changes through the different levels. So that's what we're looking to see if we're doing it kind of systematically. Are there any other questions? Maybe on the other hand. Sure, I have one more. Okay. Okay. Thanks, Ben. Ben again. You do a lot of analysis of things of data that are implicitly on graphs. How do you think about analyzing these data as signals on the graph or translating them into the spectral domain? It seems like you've done both here. I'm wondering how you think about trade-offs with the data. Well, first off, a lot of the data is not inherently on a graph. A lot of times I've put them on a graph, which is pretty easy to do. Is pretty easy to do. So you're asking me about vertex domain versus frequency domain analysis. So you can actually, there's like advantages of doing kind of both. In the vertex domain, you can define these things like these diffusion wavelets and stuff that are localized on certain vertices and in the frequency, and frequency-wise, if you looked at. And frequency-wise, if you looked at their frequency. So they're localized with a trade-off somehow in the vertex domain and the frequency domain. In the beer frequency domain, it's easy to tell if you're taking off certain frequencies of signal. Like you might want to just low-pass filter your data or high-pass filter your data to take out some kind of batch effect. So I think it helps to kind of think about both the vertex and frequency domain. And actually, lately, we've also been trying to load these to Trying to load these to dictionaries of atoms and also the atoms. It helps to vary the atoms and the frequency and the space. So I don't know. I think you should think about both of them. Just like they do in signal pressing. All right. So if there are no other questions, I think online we don't have any. So let's thank Professor Smith Krishna to one. Oh, Professor Meet that question. That's the one I get. Thank you, thank you so much. Bye-bye.