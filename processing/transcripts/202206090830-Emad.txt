Thank you very much. I'm going to share my screen. Okay. Good morning, everyone. Today, I'm going to talk about some of the research projects in my lab focused on deep learning in cancer precision medicine, following the very nice talk by Valentino. So, as we all know, cancer is a major health concern around the world, and precision medicine aims to improve. Aims to improve the outcome of patients by adapting and finding the best course of treatment based on the molecular and clinical characteristics of the tumors. Related to this, there are two major problems that in my lab we are quite interested in. The first one is better understanding the molecular mechanisms that are involved in response of different patients to treatments, single drugs or drug combinations. For example, finding proteins, genes. Example, finding proteins, genes, signaling pathways, or gene regulatory mechanisms. And in the second problem that is the topic of today's talk, we are interested in developing predictive model that can tell us whether cancer cells respond or do not respond to one drug or drug combinations. Now, focusing on only single drugs, what do we mean by drug response? Do we mean by drug response? Well, it's depending on what type of cancer models we are talking about, this kind of quantitative measure will be different. If you're talking about tumors, for example, one way would be to see if the size of the tumor changes after the administration of the drug. That's one way. There are other ways, of course. If you're talking about cancer cell lines, usually we can form those response curves and quantify that. One way being, for example, asking what dosage of the drug kills half. Dosage of the drug kills half of the cancer cells after a certain amount of time. Now, the first problem we are interested in is developing a model that can predict response to single drugs. Now, from the machine learning perspective, there are different ways we can formulate the problem. We can formulate this as single model per drug, where basically if you have M different drugs, you train M different models, one per drug. One per drug. Of course, there are some shortcomings with this approach, meaning that you can't really share information across drugs and you can't take advantage of the similarity that may exist across different drugs. The other two formulations allow you to implicitly take advantage of the similarity that exists between drugs. The one in the middle is a multitask learning framework where you train one model, but then you have M different drives. Have different drugs that you allow your model to predict them by sharing information across them, especially at the earlier layers of your neural network. The third type of formulation is a paired prediction model, where instead of having a multitask formulation, you provide as input some representation of the drug that allows you to then have a pair of cell lines and drugs given as input to your model. To your model. And this is the model that we are quite interested in because it gives us more flexibility to capture different types of similarity in our latent embedding space. So speaking of similarity, what do we mean by similarity? And this is something that machine learning models need to take advantage of in order to perform and make predictions. Well, if you're talking about cancer cell lines, the idea of similarity is that if you have two Is that if you have two similar cancer cell lines, however, you want to define it, if you give them the same drug, you expect to relatively see similar responses. At the same time, same thing for the drugs. If you have drugs that are similar, however you define it, if they are given to the same cell line, you expect to see similar responses. And this is something that we want to be, our model to be able to capture. And there are, of course, different ways you can capture capture. Ways you can capture cancer cell line similarity or represent cancer cell lines. There are many different studies, and they have actually found that gene expression profile is a good one, particularly in the context of prediction of drug response. When it comes to drugs, there are different ways to represent them, molecular structure, properties, and targets. But what we found is that there's a lot of improvements still possible in better representing the drugs. And in fact, one of the talks, Jin Tang. In fact, one of the talks Jin Chang gave a couple of days ago, one of the problems he brought up was how can we best represent drugs? And this is definitely also was consistent with our observation that this needs to improve. So with that motivation in mind, we argued that another type of similarity we can capture is the similarity based on the pattern of sensitivity that these drugs induce in different cancer cell lines. What do I mean by that? Imagine that we have two groups. Imagine that we have two groups of cancer cell lines, group X and group Y. And what we observe is that there is a group B of the drugs, that this group Y of cell lines are quite sensitive to them, and this group X are quite resistant to them. So this already tells us that there is some degree of similarity between drugs and group B. And what we ideally want to happen in our embedding space of our neural network is that the embeddings are placed close to each other in the Placed close to each other in the latent space. But then, if you have another group that has an opposite pattern, we expect them that their embeddings be placed separate and far from the embeddings of group B. And this is the kind of similarity that we want to be able to capture, of course, in addition to the other type of similarity at the cell line level and at the drug level, for example, using molecular structure that we talked about. So, how can we do this? Well, Do this? Well, as various very interesting talks on graph neural networks discussed it, graph neural networks are good tools for us to be able to capture this kind of graph patterns in our data. So as input to a model that we have developed called Big DRP, we have the gene expression profile of cancer cell lines. We also use drug descriptors, molecular descriptors of drugs. Molecular descriptors of drugs, which is a representation of their structure. But also, to form that bipartite graph that I showed you, we are going to use the cell line by drug matrix of drug responses. And we can turn that into a bipartite graph by basically looking at each of our drugs, so one column of this matrix, and then identify the cell lines, the top. Identify the cell lines, the top K cell lines or top K percent that are most resistant to it, and also the K percent cell lines that are most sensitive to it, and turn that into a ternary adjacency matrix that then we can use to form our bipartite graph. So what do we have at this point? We have yellow nodes corresponding to different drugs. We have purple nodes corresponding to different cell lines, and then we have two type of edges that connect. Have two types of edges that connect the drugs to cell lines, whether they are sensitive or resistant. But additionally, we also have node attributes, drug descriptors for our drugs, and gene expression profiles for our cell lines. Now, this is going to go into a heterogeneous graph convolutional network, a two-layered one, which the aim of which is to improve the embeddings and representations of our drugs. Of our drugs, which was very well motivated by the previous talks, which allows us to perform message passing and information sharing through this bipartite graph, and through that information sharing, improve the representations of our drugs. In parallel, we also send the features corresponding to cell lines to a separate encoder as well, and we get embeddings for our cell lines as well, which then Lines as well, which then we concatenate and send it to a predictor neural network for drug response prediction. So, this is the basic idea behind the architecture of Big DRP. But just as a reminder of why this kind of graph convolutional network works and allows us to share information, the way it works is that we have an attribute vector for each of our nodes. We also have a trainable weight. A trainable weight matrix W that when we end-to-end train our model, we can learn the weights. And by multiplying these two together, we form a message for each of our nodes. So here, node D. Similarly, we form messages for node A, B, and C. And then these nodes share their messages to their neighboring nodes. And similarly, node D receives the messages. And the hope is and the goal is to aggregate these different. Is to aggregate these different messages that are received from the neighbors with the original attribute vector plus some learnable bias, and this is sent to some non-linear activation function. Here we are using leaky reloop, and that allows us to have a new attribute vector representing this node. And this is the case if you have only one layer of a GCN, if you have more than that, then this new embeddings can be sent. This new embeddings can be sent, and this kind of message passing can repeat as many times as you need. Now, when we talk about the bipartite graph that we are interested in, of course, it's not a homogeneous graph anymore. We have two type of edges, so we can't simply have one trainable weight matrix. Instead, we have two different weight matrices, a sensitive weight matrix that is responsible to forming the messages for our sensitive edges. Our sensitive edges and a separately parametrized resistant weight matrix that allows us to update the messages for our resistant edges. And then they can again aggregate through this formula, which is a generalization of the formula we saw before, where we also have a normalization factor to make sure that high-degree nodes are not going to bias our updates. So, this is the basic idea of how this message passing allows us to aggregate information. us to aggregate information from different nodes and capture this kind of pattern of similarity that we were interested in. But another thing that we observed was that if we look at the predictor and what it sees itself, it sees the embeddings that come from the cell lines and also the drugs. But the problem is that given that we are training end-to-end and we are using a GCN to update the drug embeddings, change in the embeddings. Change in the embedding of one of these drugs will also change the embedding of another drug, right? And from the perspective of this predictor, it keeps seeing changes in the embedding of the drugs. It's a moving target problem. So the task becomes quite difficult for the predictor to train. So instead, additional to what we had done after the big DRP is trained, what we did was that we froze the waste, we froze the embedding. Froze the waste, we froze the embeddings. Sorry, not the waste, the embeddings. And then, for only one extra epoch and with a lower learning rate, and with the frozen embeddings, we trained our predictor to improve the performance. And what we observe is that even though overall the improvement is small, it's consistent across every single drug. So the performance of every drug improves slightly. So, to see how well we are doing, we focused on GDSC data. We focused on GDSC data set where we had 944 cell lines, 237 compounds, and we used five-fold cross-validation with two type of data splitting strategy. The simpler problem where you have just random pairs of drugs and cell lines being held out in your fold, and the more challenging one where cell lines are completely held out, and during the training, you have never seen the cell lines. Cell lines. So we call this leaf cell line out. And for those of us who like to see these kinds of performance tables, not the best visualization, but it's quick to see how we are performing. We basically saw that Big DRP Plus performs better compared to many different architectures and many different models, both deep learning-based and also traditional based methods. Now, this is another visualization that may be a little bit more. Another visualization that may be a little bit more informative, where we are looking at the Spearman correlation coefficient as a measure of performance. Y-axis shows the performance for Big DRP plus, X-axis shows for different baselines, and each circle in the scatter plot corresponds to a different drug. So if you have more points above the diagonal line, it means that Big DRP plus is doing better, which is consistently the case for these different comparisons that we have done. Okay, so we were having. Okay, so we were happy with this performance, but then we asked: okay, so what does this bipartite graph, what does it do? What does it do to the drugs? Does it put drugs that are relatively similar together? What can we understand from that? So we clustered this graph and identified five robust clusters of drugs, C1 to C5. And we also had a baseline MLP model with the same architecture as our. The same architecture as our big DRP, except that it didn't use the HGCN. And we measured how much benefit each of these drug clusters gain from this bipartite graph. And we saw that C3 seems to really benefit from it. And then when we looked a little bit deeper into the 20 drugs in there, we saw that the majority of them are protein kinase inhibitors. And many of them actually share a similar mechanism of action, which was an encouraging observation, just because that's what we expect. Just because that's what we expect to see in the bipartite graph. And then after that, we asked: okay, can this model help us to understand how the mutation of actual tumors would influence the response to drugs? So we, among many things, we used Big DRP to predict the response to 485 thyroid carcinoma in TCGA. And we also looked at We also looked at the mutation profile of these tumors, and we observed that BRAF was mutated in 57% of the tumors. And in fact, this mutation is one of the most common one, and it's an activating mutation where it activates the MAPK-ERC pathway. And as a result of that, we have sustained cell proliferation and adverse outcome. So, given that this is an activating mutation, what we expect to see What we expect to see is that drugs that target this pathway, in particular, for example, BRAF inhibitors, and try to inhibit the pathway would work better for tumors that harbor this mutation. And that was exactly what we observed. So we looked at the family of drugs that inhibit the MAPK-ERC pathway, and we observed that tumors that harbor the mutation. Tumors that harbor the mutation respond better compared to tumors that do not have this mutation. You can also see that based on the scatter plot, where we have the majority of points below this diagonal line reflecting that observation. So if you're interested in this, the paper just came out in bioinformatics a couple of days ago. Please take a look. But we also were interested to see if this model allows us to do new discoveries. Now, what we were Now, what we were interested in was to identify selective synergistic drug combinations for ovarian cancer cells that have a SMARCO4 loss of function mutation. And then we were wondering, okay, so how can a model that predicts drug response to a single drug can be helpful to predict synergistic effect of drug combinations? So what we ended up doing was that we found a set. Was that we found a set of cell lines of ovarian cancer that were deficient and they had this loss of function mutation that were also treated by a drug that we were interested in. And at the same time, we also found cancer cell lines of ovarian cancer, again, treated with the drug that did not have that mutation. And we used those and we used Big DRP plus to predict the response to the 237 compounds that. To the 237 compounds that we had, and then we could look at the cases where we had a very sensitive response for this group of cancer cell lines, and we could observe a lot of resistance in the second group of the cell lines. And we can rank basically drug combinations based on this. And we identified candidates, and our collaborator, Dr. Huang at McGill, also performed. At Mikhail, also performed experiments, and we found that our hits actually correspond to two novel drug combinations that confirm exactly the selective pattern that we expected. So, this is a very interesting direction that currently we're working to better understand what are the mechanistically, what happens between these drugs that allow us to have this kind of selective synergistic behavior. Now, talking about drug combination. Talking about drug combinations, of course, we are interested in them because they allow us to target different proteins at the same time, different pathways, and can have potential for improved outcome, less single drug resistance, and lower toxicity. But we can't always find this kind of treated gene expression profile of cancer cells with some drug to use a single drug. With some drug to use a single drug predictor. And our question was: can we use the untreated gene expression profile of cancer cell lines and develop a model that can predict the synergistic and antagonistic effect of drug combinations? Now, again, the question is, how do we measure synergistic or antagonistic effects? Well, there are different measures, two of them, for example, ZIP and S-Mean. But overall, what they try to do is to try. Do is to try to capture how much more effective the combination of drugs are that we can observe experimentally compared to some reference where it captures the expected effectiveness of the drugs under the assumption that they do not interact. And if we see better synergistic through this comparison, we call the drugs to be synergistic. And if it's low. To be synergistic. And if it's lower, we call them antagonistic. And if it's close, they may not be interacting much. Now, as for any other deep learning method development, we need a lot of data. And there are fortunately very nice databases such as DrugCom that have captured different type of synergy scores for many different cell lines and many different drugs. However, the bad news is that when we actually look deeper into these databases, they're quite sparse. Into these databases, they're quite sparse, and understandably so, because these drug screening experiments are expensive and the search space is really huge, given that we have three variables that are changing. So, for example, this is just a snapshot of one slice of this three-dimensional tensor for one cell line. And even though technically we have measurements for more than 4,000 drugs, in reality, really at this triangle, like 300 drugs, we have measurements that these drug combinations have been tested. These drug combinations have been tested against each other. So, it is very helpful if we can have a computational model that can basically impute these unknown values in guiding drug screening experiments. Now, there are, of course, other pre-processing and data cleaning that needs to be done to make sure that the data is ready for method development. And after all of those are done, we ended up with only 75 unique cancer cell lines. Cancer cell lines, 2,500 unique drug pairs, but overall, 43,000 triples of drug one, drug two cancer cell line that we could use for prediction of drug synergy scores. Now, you may ask, okay, so given that this idea of bipartite graph and getting better representations worked for single drugs, why can't we use a similar idea for drug synergy score? The challenge is that we have only 75 cancer cell lines. We have only 75 cancer cell lines. And the whole premise of this bipartite graph and the pattern we were capturing was forming a bipartite graph where we connect drugs to most sensitive and most resistant cell lines. And we had approximately a thousand cell lines there. So there was quite a bit of information sharing that we could take advantage of. But when we only have 75 cell lines, this idea is not going to work much because there's not much information to be shared. So instead, we focus on other ways of improving the embeddings. Of improving the embeddings of our samples. In particular, we added auxiliary tasks to basically regularize the model and give us better generalizable embeddings. So instead of just predicting the synergy score, we also at the same time predict single drug responses. And also, we used different parallel encoders that allow us to capture different views of the input features and capture different types of. And capture different types of relationships between the inputs. So we developed a method called Marcy. If you're interested, it will also be described by Reda, who developed it in ISMB 2022. But before giving you the idea behind the architecture, I should just tell you what the input looks like. So, for cell lines, we again use the transcriptomic profile of them corresponding to highly variable genes. For the drugs, however, we found that this We found that the signature, the drug signature coming from the LINCS database corresponding to 978 landmark genes, where we are looking at before and after treatment by a drug, that actually is quite more informative for this task. We focused on these kinds of differential expression changes for two cell lines because that gave us more representation for a larger number of drugs because we need a lot of samples for training. Training and this kind of triple basically goes into this architecture. So, as I mentioned, we have two parallel encoders. The one on the right is a pair encoder, which tries to, independent of the cell line, capture the interplay between the two drugs. The one on the left is a triple encoder that tries to capture the interplay of all these three components. And if you notice, there is a bottleneck layer that basically performs dimension. That basically performs dimensionality reduction, followed by an expansion that allows us to increase the capacity of the model and improve its expressiveness. Then, after we get the embeddings, these are concatenated and sent to a multi-task predictor that, as I mentioned, perform those three tasks together. Now, we used the five-fold class validation. We compared Marcy to different models, both based on deep learning and non-deep learning based on. And non-deep learning based on different measures of synergy and also different metrics for a regression problem. And we saw that it definitely improves the performance in a consistent way. And we can also look at this from a classification problem. So we can binarize, for example, here the zip scores and say that if, and we can set a threshold. If the zip score is above some threshold, we can call these synergistic. If they're below some negative. If they're below some negative of the threshold, we call them antagonistic. And we can discard the values in the middle as low confidence. And we can change this T all the way from 0 to 20 to see basically as we are making the problem easier for these different models, how would the performance change? And again, we see that Marcy works better, but towards the end, as the problem becomes very easy, some of the other models start catching up. Another thing that I wanted to mention about this, which is more just a comment for trainees in the audience, is that it is useful a lot of times to look at the embedding space and the latent space to see whether what you want to capture, what your model want to capture, is actually being captured at that space instead of just relying on the final metric of the performance. So, for example, here I'm showing you in a PCA space. Showing you in a PCA space, the top two principal components, the embeddings that are learned by the two different encoders that we have. And what I like to see, especially as T increases, is a good separation between the synergistic drugs pairs and the antagonistic drug pairs, which is exactly what we can see here. For example, for T equal to 20, there's a good separation even in this linear space. Now, the pair encoder also allows. Encoder also allows us to have this kind of separation, but at a different degree. But then the question becomes: is it really necessary to have both of these encoders at the same time? Do they capture the same thing or complementary? So that's when ablation study becomes quite important. So we did a very thorough ablation study with many different type of encoders, and we saw that indeed, having these two different kinds of encoders are helpful. We can add extra encoders, the performance improves a little bit, but we Improves a little bit, but we argue that it's not worth the extra complexity that it will add. So, this was some of the studies that we were interested in, just focused on the cancer cell line. But at the end of the day, what we care about is what happens in a real patient and a real tumor. So, from completely computational and machine learning perspective, when we want to make prediction on real tumors or set a test. On real tumors or set a test set that corresponds to tumors, ideally, we want to train our model on a representative set as well. Ideally, tumors may be of the same type. The problem, however, is that if we do that, we are going to be quite limited by the amount of data that is available. Maybe we can look at three or four very old drugs corresponding to chemotherapy, but it doesn't allow us to really look at this across a wide variety of the drugs. Wide variety of the drugs. So, what we are interested in is that can we train a model on cancer cell lines and then use that to predict response in actual tumors? Now, this is a challenging task. Many different reasons. Some of them are technical and it relates to some of the points that was actually brought up in the discussion. The moment you have different data sets generated by different labs at different time points using potentially Different time points using potentially different biological protocols or data processing protocols, you will have shift in their distribution statistically. But even a more important arguably point is that cancer cell lines are not necessarily the best representation of the real tumors. For example, Valentino very nicely described the intra-tumor heterogeneity that exists in real tumors that cannot be captured through cancer cell lines. So there are definitely major challenges. There are definitely major challenges and hurdles that need to be addressed. So, the first project we worked on, which came out in 2020, we focused on really looking at many different strategies that had been proposed to see how well the model that works really well on cancer cell lines, how well they generalize to real tumors. And it turned out that this is surprisingly, extremely hard, surprisingly, because. Extremely hard, surprisingly, because when you throw a lot of models at something, eventually, even by random, you expect something to work, but it didn't. So, and that was really surprising in the sense that at the best that these models could do, we could distinguish between sensitive and resistant tumors for 50% or less than 50% of the drugs. The only thing that seemed to work well was a method that we developed called tissue-guided lasso, which, in a non-trivial way, incorporates A non-trivial way incorporates the cancer type and tissue type in training of ELASO model. And a lot of other ways of including this kind of information, like for example, treating them as confounders, did not work or did not change anything really. So this was a good starting point, but as you can tell, there is a lot of point for improvement. After that, we moved to more advanced deep learning models. We developed a method called Models. We developed a method called Tindle that is currently in revision. You can take a look at the paper on bioarchive. And this model, again, we found out that using tissue information and cancer type information, which is not surprising, is actually quite useful. And here we could improve the performance for now 75% of the drugs. But again, this is something that can be improved. Can be improved. And we're working on looking at single-cell RNA-seq to really capture that intra-tumor heterogeneity of the tumors to have better models that can go from cell lines to tumors while capturing those effects. Now, one thing I wanted to mention about Tyndall, which relates to some of the interpretable AI talks that very nice talks we had, is that it also has a component where we are using a neural network explainer. Using a neural network explainer, followed by a systematic way of ranking genes coming out of that, using transcriptomic data to identify a small set of genes whose expression significantly contributes to the prediction. And to test this, we focused on tamoxipen, a drug that is used widely for breast cancer treatment. And we also were performing very well on it. And we identified 10 genes, and our collaborators. And our collaborators at Mayo Clinic, Dr. Wang and Dr. Cairns, performed gene knockdown experiments on two cancer cell lines. And consistently, we saw that the knockdown of seven out of these 10 genes significantly changed the response to tamoxifen. And several of these genes were for the first time, we were finding the association of them with a response to tamoxifen. So this was actually quite interesting with regards to finding genes that are To finding genes that are relevant in our prediction. Now, how much time do I have? Five minutes. Okay. So one thing I again wanted to mention related to some of this idea of integrating different data sets that is quite important is that, again, we can look at the latent space and see whether what we expect actually happens. What we expect actually happens. So, for example, here again, I'm looking at the PCA space, looking at, for example, Tyndall and what happens in the latent space of it. And what I like to see ideally is that TCGA samples and GDSC samples are kind of put together, they're merged. And this kind of domain discrepancy, that the domain shift that I was talking about is kind of resolved. And here we see that that seems to work well. Combat, which is a method for batch effect removal, works decently. Works decently. But one thing that was a little bit disappointing for us was that methods that are in the deep learning domain are particularly developed for domain adaptation, they did not work as well as we expected. And we suspect that this is because they have been developed for image data that have a very different type of properties. And as you can see, for example, here, ADA completely puts the TCGA and GDSC samples separate from each other. Examples separate from each other. So, we can already tell for debugging that this is not going to work well given the problem that we have. So, the final remark that I wanted to make is that, again, we should really think about this kind of domain discrepancy going from one data set to another. And these are many different reasons behind it: different labs measured by different technologies or processed differently, or even different models. And what ends up happening is that a lot of And what ends up happening is that a lot of times, methods that are developed in the deep learning domain, we cannot just bring them, plug it in our model, and expect them to work. So, a lot of times, we need to, as a community, develop methods that work for the omics data that we work with. Now, also just a comment to the trainees in the audience. It's a very good practice to think about the deep learning method development as a representation learning problem, where you really think about what you Where you really think about what you expect to see in the latent space and try to see what strategies you can use in order to capture those kinds of properties. You can use data integration, auxiliary tasks to regularize your embeddings, and also using different views of the input features. So I just finally wanted to thank my collaborators at McGill and Mayo Clinic, as well as trainees that were on these projects, as well as various funders. Thank you, and I hope it helps. Thank you, and I hope that we have some time for questions.