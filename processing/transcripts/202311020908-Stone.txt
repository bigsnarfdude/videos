Then, yeah, thanks for having me. My name is Connor Stone. I'm a postdoctoral fellow at the University of Montreal, specifically at the Ciela Institute, which is an astrostatistics institute at UDM. It's really closely tied as well with the Mila Machine Learning Institute. And I would love to have been in person to talk with all of you, but as I said in the flash, As I said in the flash talks, my wife is within one sigma of giving birth. So I definitely can't travel right now. But I'm still going to talk to you about Astrophote fitting everything everywhere all at once in astronomical images. And to get started, I think I should show you an astronomical image. So here we have a very pretty picture from the Very pretty picture from the James Webb telescope. And I think it's very indicative of the sort of new era of astronomy that we're entering into with all these incredible new telescopes coming online. And there's a lot of really interesting elements of this new era of astronomy that we're entering into. You can see, of course, that there's a lot of galaxies and stars here. Of galaxies and stars here. And what's really exciting about this is that it's such a deep image that can show us very low surface brightness things in the sky. You'll also notice that it's a colored image. There's multiple wavelengths that we're looking at here. And obviously, in some of the other programs like Euclid or the LSST, we're going to be painting the whole sky with incredibly deep and detailed imaging. And detailed imaging. But something that I like to point out about images like this is that, as beautiful as it is, this image is almost useless. What it is in the computer is really just a gigantic matrix of brightness numbers. The information in an individual pixel is not very much. So, what we have to do in order to do any astronomy with an image like this is to sort of bring models. is to sort of bring models to the image. We have to sort of pick out an object in the image and say we're interested in a galaxy like this. Well, we need to define some properties of it. We need to learn, say, what the brightness of the galaxy is or the size or the color of the galaxy. We need to start extracting information from this image in order to Image in order to do some science. And so one of the ways that's most straightforward to do this is forward modeling. So we pick some analytic model for our object, in this case, a galaxy, and I'm going to say this is like an elliptical model where the brightness as a function of radius is a Circec profile, which is a generalization of a Gaussian. But the telescopes don't see perfect analytic models, they see pixels. Models, they see pixels. So we have to take this analytic model and integrate it into some set of pixels. And as well as that, the instrument itself has some response, like a point spread function, which we convolve in order to blur the image and get a sense of what this pure analytic model would look like inside our telescope. We can compare that with the data, we get residuals, and we can do something like optimize chi-squared by assuming. chi-squared by assuming every pixel is an independent Gaussian. When we optimize this chi-squared, what we're doing is finding the analytic model parameters which best match into our data. And once we've got those parameters, then we know something potentially intrinsic about this galaxy, like its luminosity or its size or something like that. This is really like a core problem for a lot of astronomy that gets done after the fact, processing and understanding images. Processing and understanding images is one of the main ways that astronomers work. And so, as you can imagine, there are many codes out there that solve this problem. This is just a small subset of them. Some of these are very general and they solve a lot of astronomical image processing problems. Some of them are more specialized, but all of these sort of at a high level solve the same problem of extracting meaningful information from. Meaningful information from giant matrices of pixel values. Now, given how many codes there are out there already, you might imagine we don't need another one, but I'm going to argue that we do in fact need a new one. And that's because there's some new stuff coming out of the machine learning world, like this code PyTorch, which gives you access to two sort of killer apps. One of these being GPU acceleration, when you write your When you write your Python code using PyTorch, it's very similar to working with NumPy, but in the back end, it can actually all be run on GPUs, which makes it like order of magnitude faster, which is really awesome. And it also gives you access to the other killer app, which is the computational graph. While you're doing all the calculations involved with the forward model, it keeps track of these calculations. And when you get to some end point, like the chi-squared, you can then go back. You can then go backwards using the chain rule through each of those calculations and get back to your original analytic model parameters, and you get derivatives on those parameters very quickly and very accurately. It's essentially an analytic derivative, which means you get your derivatives accurate to machine precision instead of using finite differences. So this necessitated sort of rebuilding a 2D. Building a 2D photometry code from the ground up. And that's what I've done. It's called Astrophote, and it's written 100% in Python, which makes it very flexible and easy to extend and work with. So like I've added in multi-E-band and multi-epoch image analysis. You can get very principled statistical uncertainties from the code. Like there's a lot of photometry-related stuff and astrometry stuff that you can do. And astrometry stuff that you can do with Astrophote. In fact, you can, in principle, create any optimization problem that you want in the code. And you can access it just with pip install Astrophote. So I'm going to tell you a bit about like what we mean, what I mean by fitting everything everywhere all at once. So first up, the GPU acceleration. In practice, this comes out to about a factor of 10 speed up. Factor of 10 speed up. You can see that I just took a thousand by thousand pixel image, I put some CIRSIC models in there, and I let Galfit and Astrophote try and optimize the parameters. And if you just have CPU, then Astrophote and Galfit probably come out to a very similar time scale. Whereas with the GPU, you get about a factor of 10 order of magnitude speed up, which is really nice. Speed up, which is really nice. And you can do really powerful statistics with this. So here I'm fitting everything, which is here the a galaxy, a little star, a sky model, and a PSF, which involves this. And I'm fitting the parameters for all of these simultaneously. We've got the galaxy parameters here, PSF parameters, star parameters, and sky parameters. Star parameters and sky parameters. And by fitting it all at the same time, that means that we have access to covariances between all of these parameters. And that's what you see in the covariance matrix here. And there's also different ways that you can fit. So like with the Levenberg-Markford fit, it's super fast. It takes like five seconds in this case to optimize all the parameters. And you get access to the dark contours that you see, which are the Contours that you see, which are these little Gaussians. If you care a lot about the precise and non-linear behavior of your uncertainties, you can run a no-U-turn sample, which is a MCMC algorithm that uses gradients in order to accelerate the, or in order to reduce the autocorrelation time. That one takes a little longer, but you get access to some subtle non-linearities. I don't know if it's showing up on the screen, but you Showing up on the screen, but you can see that there's a few areas where the errors kind of poke out and curve a little bit. This turns out to be very important to some people. For example, if you look at the covariance between the PSF parameters and the galaxy shape parameters, like the axis ratio, this would be very interesting to people like weak lensing analysis, where they care very, very precisely at the part in 10,000 level what. Thousand level, what the PSF is and the galaxy shape parameters are. So having access to the covariance between these things is really quite important. Now by everywhere, I mentioned that you can fit multi-band data. So here I have an example where I have a galaxy and some stars around it, and I have this object imaged in multiple bands. So here is the UV. So, here is the UV, the visible, and then the infrared wavelengths. And we're fitting a model across all of these wavelengths all at once. So, certain parameters like the position of each star is actually using data from all of the images collectively to try and constrain that parameter. So, you can actually fit a model which spans across these multi-band images. And we can fit. And we can fit everything everywhere all at once, which is what's happening here. We're fitting galaxy, star, PSF across multiple images. Here at the bottom, we recover a PSF image for each of these individual bands. And so we're trying to solve this like gigantic simultaneous optimization problem. In total, there's like almost a million pixels here and then 500 percent. Here and then 500 parameters trying to all like settle it into one optimal point, which is quite challenging to do, but pretty exciting that we're starting to get these results. And of course, we get, because it's simultaneous, we get the covariance between all of these things. It's not restricted to just multi-band data. You can also do time series data. So, for supernovae, this is really interesting because Interesting because they have time series data, multiple images of the same object over time as the supernova gets brighter and dimmer, and also multi-band data for this. So this is multiple time, multiple band, and doing a simultaneous fit in this really giant data space is a huge bookkeeping headache, but really cool to work on. So I don't have results to show you on this yet, but it's something very To show you on this yet, but it's something very exciting that I'm working with some people on to try and do this modeling at a really large scale. So the room here is filled with astrostats people. So I figured I'd put up a list of things that are like interesting challenges that have come up along the way as I'm working on all of these problems. So of course, sampling. Sampling, if we care about the errors at a detailed level, we need to do sampling really well. I'm currently using nuts, but if you know something better, let me know. I have, of course, a very large, non-linear, non-convex optimization problem, and I'm using Levenberg-Marquardt for this. But again, if you know something better, please let me know. So, often these problems become too large to fit all of it in memory at once. So, we're fitting like subsets of parameters at a time. Parameters at a time, and so if you know something about piecewise optimization, let me know. Convergence testing, getting good parameter initializations is, of course, very important. The closer you can get to the optimal point, the faster everything runs. Higher order likelihood modeling, like I get the covariance matrix from the Lindenberg-Marquardt, but as I showed, there are further like non-Gaussian errors there. And so, understanding that in some way that doesn't take In some way that doesn't take two hours would be really cool. And yeah, there's lots of problems that are sort of coming up as I'm trying to fit everything everywhere all at once. So I mean, I'd appreciate anyone who thinks they know stuff about this that I don't, which is probably almost all of you. Then please reach out and let me know. Before I end, I'd like to highlight some work that's being done by a PhD. Some work that's being done by a PhD student at the Siella Institute, which is this really cool diffusion model deconvolution. It's really quite incredible that he's approaching the deconvolution problem at a pixel level in a fully Bayesian framework. So he's taken a bunch of redshift zero galaxies, trained a neural network to understand all of these redshift zero galaxies as a prior for what galaxies look like. And then we can go. Like, and then we can go up to images like this from HST, where we're pushing the limits of what the telescope can do. We're looking at these blurry, noisy galaxies, and we can actually in a like churn through this Bayesian process and draw out posterior samples from a, again, a Bayesian analysis where these samples represent potential images of what the galaxy could have. Images of what the galaxy could have looked like at a higher resolution. And although these are really nice, and at the bottom here, this was our best performing example. These look really spectacular, but of course, this was the only input that it had to work with. So how do you trust it? Well, we went to some JWST data and found that we actually were able to recover these structures really well. Recover these structures really well. So, we're actually matching what's in the real data. So, we were really happy that it's able to solve this problem at a really, really accurate level. So, with that, I'd like to thank all the people that have been helping make Astrophote happen and some really cool research. And I'd like to thank all of you for listening. 