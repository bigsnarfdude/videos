This is a report on a topic that has been ongoing for maybe seven years now. I remember hearing about it in 2014, but I think some of you guys have heard about it before. And this is a new proof and a new result, I guess, that might be, I don't know, it has certainly changed my impression on the topic. This is all. On the topic. This is all a joint work with Tomorabi. We did almost all of it this summer in July, August. So is this how I move? Oh, but then I have to actually press on the slides. Okay. So your prerequisites are different. I assume all of you know what a post-it is. So all I want to say is that we're using the To say is that we're using this notation covered and covers in a post-it. This thing cuts off my last line. This isn't good. Is there a way to fix it? Can I move this family to the right? I'm afraid I can't. Okay. For now, for now, there's there's gonna be yeah. Be yeah, okay. So basically, this symbol means that U is under V, but barely under V, so there is nothing between them. And this is just the opposite relation. Okay, how do I clear? Erase all. So we are going to use for every post at P, we are going to use a variant of it called P hat, which is just the s the the original post at P. The original posit P. Can I have colour? Yep, I can have color. Plus an extra highest element one at the very top and an extra lowest element zero at the very bottom. We are calling this p-hat. We need to say delete. Ah, okay. So a linear extension of a positive P is. A linear extension of a posted P is a list of its elements in an order that doesn't contradict the posted order, basically. So if an element is under another element, then it appears to its left in the linear extension, like here alpha appears in front of gamma. Okay, so now the actual birational stuff begins. Birational stuff begins. We fix a ring, and in this talk, it will not necessarily be a commutative ring. A k labeling of a posted p is a function from p hat to k and its values will be called the labels. So we draw a k labeling by just drawing the posit p along with the two extra elements zero and one and just drawing each each of each of the values of the labeling. Of the values of the labeling at the respective point of the posit. So, yes, we are labeling the zero and the one as well. Now, we are going to define some maps that act on the scale labelings. Namely, for any element V in the posted P, we define the so-called birational V toggle. To be the partial map that changes each k-labeling as follows. If you apply this V toggle to a labeling F, its values at all elements not equal to V just do not change. Whereas its value at V undergoes the strange transformation. So, first of all, M bar, whenever you see a bar over something, that means inverse. If you would be writing M to If you would be writing m to the minus one, those expressions would just become very unwieldy pretty quickly. So I'm using m bar. Now, so what happens to the value, to the label at V? First of all, it gets inverted. Secondly, it gets multiplied on the left with the sum of all values under V and then on the right it gets multiplied with the so called harmonic sum of the labels above. Some of the labels above V. And when I say under and above, I mean immediately under and immediately above. So for example, if my post-it locally looks like this, here is V, here are the three elements above V, and here are the two elements below V. Then F of V becomes. So f of v gets inverted. As for the values above, you do their harmonic sum, which means that you take the sum of the reciprocals and then you reciprocate this. So this double bar. And on the left, you just have the sum of the things below. It's a strange little transformation. You can tell why it's called toggle because this. Can tell why it's called toggle because this F value gets inverted. And if the ring is commutative, this is actually an involution. If the ring is not commutative, it's not, which is why its inverse has been also introduced and called the Elk God by Mike Joseph. So I'm not going to study the inverse. I'm just mentioning that it exists. Okay, so this is a partial map. There is no way to make this definite. There is no way to make this defined everywhere because f of v can fail to be invertible. Even over a field, it could be zero. F of u can fail to be invertible, and the sum can also fail to be invertible. So there is no guarantee that it actually does, this map is defined. Well, if it's not defined, we just leave it undefined. That's what partial maps are good for. Yes, and as I said, this is a local change. Only the value at V changes. All the others stay the same. The other stay the same. Okay, as I said, if the thing is commuted, if this is an evolution, then it's defined. Now we are going to compose these maps to make a big map called R. The strategy is very familiar to most of you. We just go over the entire postet and we compose all the toggles. How do we go over the postet? Well, we pick a linear extension. Well, we pick a linear extension and we go from highest, so from the last to the first entry in the linear extension. So, first we toggle at the very top of the post-it, then at the next highest element, and so on. And what if there are spedilinear extensions? Doesn't matter because all of them give the same composition. In fact, this is again a standard argument known from Stryker-Williams, for example. If two toggles, if Toggles if two elements of the post that are incomparable, or even if they just don't cover each other, the corresponding toggles commute. So, and you can transform linear extensions in such a way that you're only swapping those two. So, here is an example. Here is a poset. So, the poset is the so-called two by two rectangle, which looks like this. Here is the post that again, but with the here, this is the post-set we had. So I've added a one and a zero to it. And here is the labeling. I'm just labeling the six elements with some elements of my ring. Okay, so how do we apply this map capital R to it, this birational row motion? Birational row motion? Well, we have to toggle starting from the topmost vertex and then going along a linear extension. So after the topmost vertex, we have two choices. Either we go here or we go here. But as I just said, it doesn't matter. So in some order, we do them and then we do the bottom one. So actually doing it first, we toggle the z we get x plus y, which is the sum below a z bar. Sum below, a Z bar, which is the inverse of Z, and then B, which is the harmonic sum of the things above. This is toggling the topmost vertex. Next, we toggle the vertex on the left, and we get this expression. Next, we toggle the vertex on the right, and we get this expression. I mean, there is an obvious symmetry here from left to right. So, this is in a way obvious once you have the first one, and finally, we talk. And finally, we toggle the bottom vertex. So, this gets complicated because we have to take the harmonic sums of the things at the top, and those things are already toggled. So, you get this ugly triple fraction, I guess, because it's a bar over a bar over a bar at some points. Fortunately, this actually simplifies, which suggests to us that these toggles aren't completely random, that there are some patterns here. There are some patterns here. Okay, note that we do not toggle the one and the zero because there is here there is nothing above and here there is nothing below. So we would get zero if you try to toggle them. This is the reason why we added the one with the zero. We need them as buffer space basically to avoid empty sums. So why is this called birational remotion? Well if you know Well, if you don't know classical row motion, I guess you should treat this as like a new map. If you know classical row motion, you can view this as a generalization of it. In fact, let's consider the tropical summary of the integers. This is the set where you take the integers, you add minus infinity, you turn the maximum operation into addition, and the addition into multiplication. This is strange, but you have rules like maximum of A plus C, B plus C equals maximum AB plus C. If you sprint enough at this rule, you will realize that it's distributivity law. So it's like a secret ring structure on the set of the integers, except that there is no zero, because there is no number, there is no zero station, maximum of zero. 0 stash to the maximum of 0 over a is a for all a. So this is why we need minus infinity. Once we introduce minus infinity, some reason sometimes this thing erases instead of writing. I don't know how to trigger that. I would like to trigger that now. But anyway, maximum of minus infinity, A is A. So by introducing minus infinity, we not only get the distributivity law, but we also Only get a distributivity law, but we also get a zero, and so this becomes what is known as a summering. Basically, a ring without subtraction. Okay, so what do we do with the summaring? To every order ideal of the poset, to every S in the order ideal set, we assign a labeling by the tropical separate where the label at each element of the poset is one if the element is not in the ideal set. If the element is not in the order ATL, and zero if the element is of the order ATL. And also we count zero to the order ATL and we don't count one to the order ATL. So if our post-op looks like this and our order ATL looks like this, then you'll have one, sorry, no, you will have zero, zero, zero, zero, here, and one, one. Here and one, one, one, one, one, one, one here. Basically, this is the indicator function of the company. And you add a zero here and a one here. This is how an order ideal becomes a labeling. Now, if you remember the definition of the order ideal V toggle, you will easily see that this order ideal toggle is the restriction of the birational toggle in the tropical centering. In the tropical semaring. And therefore, the order ideal raw motion is just the birational raw motion applied to the tropical semmaring. And if you don't like semi-rings, because we've been talking about rings, why suddenly semi rings? Well, first of all, there is nothing wrong about semi-rings. Secondly, you can use the rational numbers and apply a certain limit. This is a fairly known strategy. I think Jim has originally introduced it, but Introduced it, but it also appears in the work of the Japanese. So a labeling or a labeling is always the map from EPF because you label uh the zero and the one as well. Yeah, even if you don't care about the labels at zero and one, you need them in the row motion. And one, you need them in zero motion. So, yeah. So, this is a typical question you will ask in this subject because the things more or less a technical role, but generally you use them as some kind of lower and upper bound. Okay, so what about birational romotion? What can we prove about it? Well, a bunch of results are known. Results are known. I'm biased towards my own paper with Tomorrow for all those reasons. So, what can be shown? If suppose of P is the right angle, so something alike that looks like then a birational remotion to the people of skewed power is the identity. What else? If P is the right half of a square, okay, so a square. Of a square. Okay, so a square is a rectangle with two sides. And its right half would just be when we focus only, for example, on this part. So we ditch all the vertices on the left and we look only at the right half. Again, there is a finite order, which is 2p. If it is the If it is the top half or the bottom half of the square, we also report it here. And even better, if you take row motion to the peace power, we get reflection across the vertical axis, which is weird because you wouldn't expect this to happen. Some kind of spooky action at a distance. You do this local transformation and suddenly your labeling reassembles, but flipped. There are more cases. Suichi Okada has shown that. Okada has shown that most of these are actually particular cases of something that thoughts for every minuscule posit corresponding to the algebra. And the order of R is the Coxeter number of corresponding R algebra. And finally, there is also a class of forest-like posets. So basically, you look at a forest, you order it from a root, and so it looks something like this. As long as the As long as the leaves are all at the same level, the order again is finite, and again you can find the exact value, but there is an upper bound in this LCM. Now, this might suggest that any finite poset will have a finite order of R. This is not true. These two pretty simple posets, including this fence, have infinite order of R. What else can happen is that once you start That once you start looking at non-commutative k, things get even more complicated. For example, this simple: if k is commutative, r to the six is identity. If k is not commutative, nothing like this is true. So at this point, one might give up the whole question. Maybe non-commutative brings suggestions. There is no combinatorial motivation to consider non-commutative. Motivation to consider non-commutative rings known to me for now. This is something I would like to see. However, seeing commutative polynomial things being generalized to non-commutative in combinatorics is not exactly new. I have seen this happen with cluster algebras, with something called the Konsevich map. There are many examples. So, at some point back in 2015, Tom and I have. 2015 moment, I have tried and taken a look at the rectangle. Turns out that not only is lost. So let me define the rectangle once again in detail. We fix two positive integers field q, we fix it in k, and we let p be the p by q rectangle. So what is precisely? This is the Cartesian product of a chain of length p with a chain of length q, whereby. Chain of lengths q where by lengths I mean number of elements. So here is how it looks like for p by 4. Pre-change in times for shape. Now fix any labeling of this by an arbitrary ring and let A and B be the labels at the very bottom and the very top. They all serve a special role as we see. So So, what it turns out is that there is a periodicity theorem which says more or less that romotion is finite order. Except you do romotion a few times, you don't get the original labeling back as in the commutative case, but rather all the values get twisted. But specifically, each value gets multiplied with a bigger on the left, and oh, I discovered on the left. Oh, I discovered how to zoom. How do I unzoom? 100%. So you multiply them with A, B inverse on the left and with A inverse B on the right. Last time I presented this conjecture, I said conjugated. Well, this is not actually a conjugation. This is something that tries to pretend that it's a conjugation. Yeah, so this is in a way at least not very. At least not periodicity. You can imagine it was previously going up a spiral. More is true, not a surprise to anybody who knows our previous work, there is also a reciprocity relation which connects the values at two antipodal elements at the square. So this will take a while to I I do have to explain this because this is a debate group project. For each point, there is a counterpoint, antipode, which is basically the same direction that you go from the bottom to this point. You go now from the top and backwards. So if you have to go one step to the left, sorry, one step northwest, you will now have to go one step south. You will now have to go one step southeast. If your point was ij, the stancy point will be p plus one minus i, q plus i minus j. And the claim is that the labels are related. Specifically, the label of at ij after L row motions will be related to the label at the antipode after L minus i minus j plus one row motions. And note that we have to assume that these things are well defined. We can no longer We can no longer pretend that they're almost always well defined because we're just having an arbitrary ring. We don't know how many of its elements are invertible. Maybe the ring is nice like Q and almost everything is invertible. Maybe the ring is something stupid like, I don't know, what is a good example of a bad ring? There is many, there's like Z mod 2 to the n, which has very few invertible elements. So we have So we have to just assume that things are well defined. But of course, you get enough examples. You can take like a matrix ring and then... Come on. Not okay, Google. No, this isn't Google either. So sometimes you can do, for example, matrix strings over Q. Over Q, this is the rings I've been using to verify a lot of these facts on Sage. Of course, you cannot prove anything this way, but if you want to quickly disprove such a statement, you just use a matrix ring and you plug random matrices. So this is how you get lots of labelings. And if the matrices are random, those things are usually well-defined because you rarely hit a non-invertible matrix by accident. Okay, so. Okay, so I'll have to be quick with this example. So instead of doing it, one doing a single row motion in detail, I now do several row motions. So here is the result of doing one row motion. Now let's do another, a third one. I'm not, this is a dot dot dot because to because I said there is a symmetry. So you can just take this value and you replace what do you replace, X and Y. What do you replace x and y? You swap them. So you get this value. So I don't need to stretch the screen. And here is what you get after four row motion. But wait, shouldn't it have periodicity more or less? Isn't this too complicated? Shouldn't this be what should it be? It should be AB bar Y A bar B. Well, turns out it does simplify to AB bar Y A B. It does simplify to AB bar y A bar B. Annoyingly, with non-commutative elements, there are no good methods to simplify them. I mean, there are some algorithms in the literature. I'm not sure if anybody has even ever implemented them on a computer. How do you simplify a non-commutative rational expression? You cannot like bring things to a common denominator. You cannot do many of the other things that would work in the commutative case. It's a lot it's it's a much deeper subject. It's a much deeper subject. So, yes, on the two by two rectangle, we have seen that this periodicity is true. Now, how do we prove it in general? Well, first we looked at the commutative case. We proved it in 2014, and since then, a bunch of other proofs have come out. So, our original proof. So, our original proof was inspired by Volkov's proof of the thermological periodicity. First, we assume that we have a field. We show that almost all labelings are in the image of a certain map from the matrix space. Specifically, if you have a matrix A, a P by P plus Q matrix, you can define a certain labeling whose labels are quotients of minors of this matrix. So this break. So, this bracket notation tells you to pick only a bunch of columns of A to get a square matrix. So, this is a maximum minor of A, and this is also a maximum minor of A. And if you divide them, you get some kind of projective coordinates. So, this is all very closely connected to Pluto coordinates on the Grassmann. And in fact, if you don't want to look at the matrix A as the matrix, you can look at it as an element of the Grassmannian. This is the formulation. Element of the Grassmanian. This is a bit more natural. Okay, and the nice thing is if your labeling is the image of a matrix under this grasp, then remoting this labeling is more or less basically just shifting the matrix. So what I mean by shifting is you move the last column to the end. And for good measure, you also multiply this column by a power of minus one. But you can pretend that you're only moving it. You can pretend that you're only moving it. In either case, if you do this people a few times, you have moved all the columns back, and so you get the original metric. So this way, to make this more rigorous, you've got this commutative diagram. And what it gives us, it tells us that raw motion is of order P plus Q on all labelings that can be obtained as Labelings that can be obtained as images under this GRASP zero. And fortunately, more or less all labelings can be obtained as such images, modulus and technicalities. So you get the order. And you can get the reciprocity using similar arguments, again using these labelings. Yeah, so there were a lot of technical details involved. We have tried to generalize this to an arbitrary in K. This is to an arbitrary, and we had some success with it because you can generalize this grasp map. Again, if you have a non-commutative matrix, there is something called a quasi-determinant, which replaces not a determinant, but a ratio of sub-determinants. But this is perfect. This is exactly what we need. We don't need determinants. We need the ratios. And this is annotation by Gilfand and Rietach, who have who I think have done the most work on these quasi-determinants. Work on this quasi-determinants. If you do this, you get again a family of labelings that again has this property that when you draw about the labeling, it's as good as shifting the matrix. Unfortunately, while the algebra works out so nicely, the technicalities do not. First of all, what do I mean by almost all labelings? What does almost all even mean? For a field, I have the risky topology. Nothing. I think maybe there is some default work here, but I've never seen any definition of the risky topology for non-commutative rings. We cannot even assume that K is a skew field. Unlike in the commutative case, in the non-commutative case, you have examples where something holds for all skew fields, but does not hold for all rings. Not hold for rings. Again, it has to do with the fact that you can have denominators that you cannot move out. You have those fractions that are somehow stuck in the middle of products and you cannot move them away. So the same problem that you have with localizing a category. So everybody's doing it directly at a category to localize this problem. So by now we think that this approach is a dead end. By now, we think that this approach is a dead end. Somehow all the algebra works, but the technology is there. There was a new proof of the commutative case by Muziker and Robi, which has kind of inspired us, but again, it doesn't quite work out. It is a non-commutative case because it relies on explicit formulas that include expressions like this. In general, these expressions are sums over. And sums over systems of non-intersecting lattice paths. Now, okay, you still have systems of non-intersecting lattice paths, but how do you take a product? Now you have to care about the order of the factors. Things are not commutative. What order do you choose? I don't know. Maybe there is a way to make it work, but there is no obvious way to take it work. Okay, so back to square one. So, back to square one. We don't have any theory available. We can just play around with the formulas. So, let's do it. First, some notations. We fix P, we fix the rectangle, we fix our laser. We assume that all the necessary row most are well defined. So we assume that the denominators are invertible. We call the top and bottom A and B, and we introduce this quick notation XL. Notation XL means the value at X after L iterations of row motion. And I realize I should have said here, but it doesn't matter much. We're not going to talk much about 0 and 1. 0 and 1 are boring because the values at 0 and 1 don't change. We just keep reading them off, but we never keep overwriting them. So 0 LSA and 1 LSB, whatever L is. By the way, is somebody looking at questions in the chat? Are there any? Oh yeah, please make the sites available. I'm not I'm not ashamed of anything in them. Or at least not uh not nothing I found the first, yeah. Nothing I found so far. Yeah. Okay, so we can rewrite the definition of R as this expression because by the time we are romanting V, the things, the labels above V have already been raw moded, and the labels below V and the V are still developed. So you've got this perfect e-definition of promoting, which, by the way, makes it clear that it doesn't depend on the choice of linear extension. And this is the same formula. And this is the same formula restated using our new notations. Because what is V1? V1 is the value of F after one row motion, or FP, and the zeros are the values before row motion. Okay, this is this formula repeated. Of course, by the same logic, the same formula is No, no, it is working. I was just pressing the wrong thing. Sorry. I have to, like, I'm pressing this thing just so that I have the next page into screen. I don't know if that's the right thing to do. So basically, instead of you looking at 0 and 1, I looked at L and L plus 1. One, I look at L and L plus one, it's the same logic because the L plus one labels are just the L labels remote at once. I suggest you think of this thing as time. So this is time L. And the whole thing you can think of as a dynamical system. You're probably already not much to suggest. Here are our claims that we must prove, restated using these new notations. Oh my, I realize I haven't recommended. Oh my, I realize I haven't recompiled this. So at some point I decided to rename this y as x prime. If x prime is the antipode of x, then x l is a times the inverse of x minus 1, x prime, l minus i plus j, l j plus 1 times this is this process. And periodicity in the sense of x p plus q is x 0 twisted by these things. How much time do I have left? Because can I? Left. Can I trust this clock? Oh, five minutes. Okay, then I cannot trust this clock, actually, I think, because according to that clock, I've already started on time. Okay, thank you. So I have like 10 minutes afterwards. Okay. Now, so the first thing that I'm pretty sure everybody in the subject noticed, I think Greg and Tom were explicit about this in their paper, is that reciprocity is... Is that reciprocity is all we need? Once you have reciprocity, you can apply it twice and you get periodicity. And of course, if you take the antipode of an antipode, you're back at the old point. So this should surprise no one. This is just the reasoning. Okay, so one last thing to prove, not necessarily the hard one, but okay, now we only need to prove the circulation. Moreover, Moreover, proving reciprocity, you only need to prove it when L equals I plus J minus one. Because what happens if you increase L here? This is just moving forward in time. So this is just starting at a later time, basically, like this talk. So if you to be more formal, this is applying the same statement to RF instead of F. For to RF instead of F. So if you can prove it for the minimum possible time where it makes sense, you can prove it for all L. So now come again some tricks that we have not introduced ourselves. I think Mike Joseph has been very explicit about them in his paper. I don't think he has invented them. I think Jim Propp did invent them. He spoke of the transfer maps. I'm going to speak of Samsung or Pass. If you look at the things closely, it's the same. If you look at the things closely, it's the same thing. So, a pass is a sequence of elements of the poset, including 0 and 1, they're allowed, where each next one is covered by the previous one. So, for example, on this rectangle, you can have something like this, this, this. So, basically, at each step, you go either one step north, either one step south. North, either one step southeast or one step southwest. And we call it, of course, the path from here to here. So our paths always go down. Next, for each V in P and each L, we define the following two expressions, delta V L and nabla V L. Delta V L is the value at V at time L divided by Divided by the sum of the values just below v at time l. And by divided by, of course, I have to specify: is it on the left, is it on the right? Well, I do it this way, of course. There is other choices, but this is the one that works. And nabla is similar. I take the inverse of the value at V and I multiply it by the harmonic sum, so again the recipro reciprocal sum of the reciprocals of the values just above V. Of the values just above P. And we also extend this to zero and one, where we just set it to be one. For any pass P, I define delta P and nabla P by just multiplying the deltas and nablas along this pass. And I multiply them in order from top to bottom. And finally, if U and V are two elements of my poset, I define delta U arrow V and nabla U ROV. A nabla U arrow V to be the sum of the deltas of all paths from U to V. So you see a sum over latest paths. This is a bit like Music Randrobi, but it's simpler because we're only looking at single paths. We're summing over all ways to get from some element u to some element v. So we get this usual binomial coefficient many paths, and we're summing over all of them. But we're summing over. Over all of them, but we're summing over single paths, not over tuples of paths. Now, this is pretty well known. You have this formulas for a labeling in terms of this deltas and nablas. So, basically, you can reconstruct the labels from the deltas and nablas. And this is easy to prove by induction. I'm not going to do the details. Induction. I'm not going to do the details. What is also nice about the deltas and Nablas is that this simple equation now encodes the definition of row motion. Why? Well, here is the transition equation again. This is a consequence of how promotion is defined. And if you just bring something, bring this thing on the left-hand side, thing on the left hand side and rewrite you get this. So everything here is completely formal. Okay and so basically you can replace every nabla by a delta if you move the time backwards by one. So the nabla at a given time, let's say time six, is the delta at time five. And of course, if because it's true for each element, it's true for each pass, and therefore it's also true for the sums of. And therefore, it's also true for the sums of pairs. The nice thing is this already gives you a proof of reciprocity for the bottommost element of the Polset. So this is reciprocity at this element, one one, connecting it to the value at PQ. This is because you write the value at one one using the delta pass formula, the Double pass formula. formula the Nabla pass formula you replace the nabla by a delta using this formula and then you rewrite it back using the delta pass formula okay so this was easy but how about the general case okay now I now I have to be now I have to get very quick so there is a simplification which basically makes use of a certain symmetry of the rectangle the symmetry is saying I mean the Symmetry is saying, I mean, the values aren't completely arbitrary. You have this connection between neighboring values at neighboring times, even by raw motion. And this allows you to argue that if reciprocity holds at M, at S, at T, and at U, then it also holds at V, whenever you have this vertex M, which is like stuck between four vertices, S T, U, and V. And the proof is. And the proof is a rather annoying computation and cancellation argument. You just have enough formulas there that almost all of the add-ons determine the remaining add-ons. But what this helps you, how this helps you is that, okay, now the most important thing is hidden behind the screen. Yeah, okay. What it tells you is that you only need to prove this. You is that you only need to prove reciprocity for j equals one, so you only need to prove it for those points on the bottom left edge. If you have done that, it's true for all points. And you've already done it at this bottommost point. So you only need to do it here. So the next case to try is the point 2,1, of course, the next highest point. And here we can And here we can again apply the pass formulas, but this doesn't immediately lead us to the goal. Instead, it leads us to the following strange identity. It tells us that the sum of the delta products over all paths from PQ to 21 equals the sum of the nabla products over all paths from P minus 1Q to 1, 1. This is interesting because note that this formula does not involve romance. That this formula does not involve remotion in any way. The time is one here, and it's one here as well. So we are not remoting anything, we're just having a single labeling. So we can actually drop the scop strips. And we can generalize this somewhat. Namely, we fix two points u and u prime that are adjacent on the top right border and two points d and d prime that are adjacent at the bottom on the bottom left. On the bottom left order. And the claim is that at each given time L, the sum of the delta products over all lattice paths from U to D equals the sum of the nabla products over all latest paths from U prime to D prime. And when I say latest path, I just mean path. By the way, this is not just generalizing what the previous formula. This is more or less equivalent to it. Because if you're trying to prove this, Because if you're trying to prove this, you'll quickly realize that the thing above u doesn't matter, and the thing below z prime doesn't matter either. So you don't lose anything by pretending that your rectangle starts here and ends here. And then z equals to one, and this equals p minus one q. So this is actually, we are not losing anything. We are just rewriting our goal. But notice that we have restated our goal with no. Stated our goal with no raw motion involved. Well, at least for 2-1. This is kind of progress. Moreover, this lemma is really crucial. If you can prove it, you can get the claim of reciprocity, not just for 2-1, but for anything on this left border. And as we have said, this is enough. I'm admitting the I'm omitting the argument for why this is enough, but this is a pretty straightforward computation. Okay, now I think there is really something missing. Yes, we don't have enough slides here. Okay, yes. So basically, the lemma is probably the hardest part of the argument, but it is doable. We have a combinatorial proof and we have a more matrix. Combinatorial proof, and we have a more matrix-style proof. Oh, thank you. Thank you. Okay. I don't have time for details, but can you scroll to the second to last page with the questions? Is this all part one? Yeah, so on the one hand, we now have a simpler proof than what we had in 2015. However, we However, we do not consider it optimal in many ways. Most importantly, we are using subtraction to prove a statement that does not involve subtraction. Raw motion is all about adding, multiplying, and dividing. By using subtraction in one of our arguments, we have forsaken the possibility of making it work over semi-rains. Making it work over semrings. So, and there are examples where something called true over rings does not hold over semrings. David Spark gives such a thing on this overflow. So, can you scroll further? So, it is an actual question, and I'm not even sure that the answer is yes. Whether the periodicity and reciprocity theorem still holds over steadings. For commutative standards, we know that by the standard argument, it is only non-notic theorem. But for non-commutative siblings, this is an actual question. And furthermore, of course, we have all the other families of post-As that are unexplored. We believe that triangles again work. We don't exactly know how to prove it, but we haven't proved it yet. Okay, can you go to the next slide? Further? All right. So thanks to a bunch of you. Now you skipped a bit too far. Now you skipped a bit too far. Thanks to a bunch of you for helping out. Thanks for keeping the flame burning. We have been out of the subject for a while. Now we're back. Thanks for everyone who organized this conference. Thanks for the Institute of Omarova for the hospitality when this project was made. Thank you for your patience. And there is a bunch of references to prior work. We haven't written up the new proof yet, but you can see most of Years, but you can see most of it in the slides actually. All right. Okay, let's thank Dorian. In the interest of time, maybe just one quick question. Mike had a question in the chat asking whether it's possible to do the AN case for the non-commutative setting by using the same kind of trick we used in the commutative setting. So, probably not to the full extent because it relied on, yeah, it relied on almost all, it relied on the extra something, I believe. At least it relied on two being invertible. Also, maybe you can think around it. Honestly, my hope is that we might not even need such a key because maybe this is kind of argument can be a bit difficult. I don't know. It would probably be too much to ask. It would probably be too much to ask, but it's a green field, you can't really lose it. Other questions?