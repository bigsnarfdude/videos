So it's a challenge for stress method. That's why maybe I just borderline inside this workshop. So this is a joint work with two researchers and the team Makutu, L'Oréon Fouché and Halfam, two young researchers, with who I used to work on HDG approximation, but I have also a contribution with Sebastian for other equations. For other equations. So, Makutu is a joint team between Total Energy, which is a company that maybe you know who is working on energy, as its name is indicating, in RIA, and we are hosted by the University of Po and Pi-Ladour. And when I say this is a joint team with an industrial partner, it means that we have people from the industry in the team who are hosted by the university as well. So, it means that we have a lot of topics which A lot of topics which are very challenging, and for us, it is very important to be able to handle the heterogeneities of the computational domain because, when dealing with elastic waves, what we want to do is to image the subsurface. So, if we consider that the Earth is homogeneous, it doesn't make any sense. Okay, here you can see I want to mention this project. So, this is a national project that has this land. Project that has been launched by the French Research Agency to enhance the exa cell computing since we will have maybe, I hope, in the beginning of 2025 a European machine which is called Julwern and that we will share with Germany, Italy, and we will use this machine to perform some exacial computing. So it means that during my talk, So it means that during my talk I will be interested in HDG approximation just because it is a method that is very conducive for parallel computing. And for us, parallel computing is mandatory. If we do not use it, you will see the size of the computational domain. If we don't use it, we cannot perform what we want to perform. Okay, so here is the heartline of my talk. So a brief introduction just to show you in a nutshell what you You in a nutshell what we mean by imaging the subsurface. Then I will present the HDG formulation that we use for solving the elastic wave equation. I will illustrate the interest of using it by some numerical experiments. And then I wanted to finish my talk by some one result of inversion, because imaging the subsurface meant for us solving inverse problem. Solving inverse problems. So, this is an ongoing work, but we begin to have nice results. So, I wanted to show you at least one. Okay, so let's go. So, here is a very simple presentation of the idea of using wave measurements to understand what's going on in the subsurface. So, we do it with the Earth, but in the team, we also do it with the Sun. So, the picture should be different because we can The picture should be different because we cannot generate source on the Sun, we use passive source. But here for the Earth, what we do is we generate seismic sources, then they propagate into the subsurface and we put a line of receivers. So this is the line, the red, oh, what did I do? So this is the red line that you can see here. And these receivers are able to record all the reflections that. All the reflections that open into the subsurface and created by the discontinuities, the heterogeneities that we have to take into account in our simulation, since this is what we want to recover when solving the inverse problem. So, what is the inverse problem? It will be consider what you have recorded at the receivers and then try to retrieve the physical properties of the domain in which. Properties of the domain in which the waves have been propagated. For that purpose, from a numerical point of view, what we need is first an accurate solver for the forward problem. I mean, what happens between the source and the receiver. And then we need an efficient process of inversion. I mean, what happens between the receivers and the physical parameters. For the inversion, we are not. For the inversion, we are not people proposing a new method of inversion. We are doing the full waveform inversion, except that recently we have proposed a new cost function, which seems to be very interesting to reduce the computational cost, but I will not deal with this today. So, now what I would like to do. Okay, so now let me continue with the solution of the forward problem, which is based upon the HDG formulation. So we deal with this type of equation. So this is the elastic wave equation, which is formulated in the frequency domain. So there is always question why in the frequency domain since the data that we have are in the time dependent domain. So we prefer to work with the frequency domain for mainly two reasons. For mainly two reasons. The first one is the fact that when you consider the frequency-dependent equation, you can include physical parameters that depend on the frequency very easily. For instance, the attenuation. Considering the hearse, this is very important, at least to have the attenuation. If you go back to the time domain, you will have something which is aurible, a fully integral operator. So regarding numerical schemes, this is a nice problem. A nice problem, but very difficult to solve. Another very important issue, or feature for us, is the fact that when solving a frequency-dependent problem, you can use a direct solver, which allows you to have multiple right-hand side. And once you want to solve an inverse problem, you will need multiple right-hand side because if you want to image a Because if you want to image a piece of earth, you need multiple sources, and in the frequency domain, it can be done with a direct solver at the price of one single factorization. So, there is a question of computational. We are always looking for method that allows us to reduce the computational. This is always the same story, but we want to keep the accuracy. Okay, but everything is not dream in the life. Everything is not green in the life, and you can see something which is here in red, which is the I don't use this, I don't know how to do it. So here you have the equation of memory cost, and this is really an issue when dealing with frequency problem and in fact the matrix factorization, and in particular in our case, because we have huge systems, this is the limitation, and that's why we And that's why we really enjoy using HDG formulation. Why? Because for us, DG is very, very efficient. It is very efficient because we can adapt the size of the cells and the order of approximation to the physical properties of the domain. And we can do it very easily with DG. But DG is very expensive if we compare it with continuous finite. It with continuous finite elements. This is a very naive picture that you have here. You compare, you count the numbers of degrees of freedom here, you are with continuous. You go to discontinuous, you see that you are increasing. And I just told you that our main problem is the memory cost. So it means that using DG, we increase the problem of memory. But luckily, people propose to People propose to use HDG, which consists in, in fact, removing all the inner degrees of freedom of the method on the boundary, so that here, so here it is not very convincing because I put a picture with low order approximation, just because if you increase the order, the picture, you cannot read it anymore. But if you increase the order of approximation, then this option will be very complicated. This option will be very competitive even with this one. Well, I hope that I, yes. So, now, what is the HDG formulation? The HD formulation, you come, it's a DG method in which we have applied a static condensation. So, this is something that people know from a while, in particular, people dealing with mixed finite element method. This is what they were doing. We're doing. So it's just this. You cannot do this with all DG methods, but you can do this for some DG method, which are called the HDG method. As I mentioned, it appears, and I think that all the community agrees with that point, it's not even mine, which is WAVE, the community of waves. HDG is very efficient once you increase your other. Once you increase the order of approximation. And what we observe for our application is that as soon as you are bigger than four, it is really, really efficient. But now there is another problem. If you use high-order approximation, you don't want to use a mesh with small cells. So, how do we deal with the variation of? I forget to mention what it is, C in the equation, maybe I. C in the equation. Maybe I was too fast. Maybe I can go back. Yes, here, if you look at the equation, so I didn't mention that u is the displacement, sigma is the stress tensor, and c is the tensor in which you have all the characteristic of the domain. And this tensor can have variable coefficients in the case where you have a heterogeneous. So, how to handle the variation of C in particular if the cells are C in particular if the cells are big because what we used to do in the past is to say, okay, I will consider a domain in which all the physical parameters are constant per element. But if the element becomes large, you have a lot of chance to have variation inside the cell. So we had to handle with this. So let's go into the formulation, the HDG formulation, how we do it. So we begin with a variational formulation. With a variational formulation at the element level. This is something which is very classy. So here you have both equations with state functions, and here in red, you have what handle the heterogeneity of the domain. So if I want to make appear the HDG unknown, which will be for me the numerical trace of U, I will explain U after how I introduce it. I necessarily have to I necessarily have to perform an integration by part here to make the trace of u appear. Okay? And if I do it, if c is a variable, I will introduce the derivative of c and from a theoristical point of view, we can do it, but numerically we don't like to introduce the derivative of such objects. So it is not very difficult to take into account this problem because To take into account this problem, because you can change the equation. You change the equation and you say, okay, I will introduce what we call the completion tensor, which is nothing but the inverse of the stiffness tensor. And by this way, you see it's a very simple idea that people do, geophysicists do, you have all the heterogeneity here, and by using a quadrature formula, it's okay. Using a quadrature formula, it's okay, you can unknown it, and there is no problem to do here a net bypass so that you introduce the trace of U, which will become our global unknown for the HDG formulation. Okay. Okay, so here I apologize. This slide is horrible, but I don't have time to detail the HDG method. And this is not the purpose of the workshop, so I will not do it. But I wanted to put on a single slide the principle of the method. So here we are at the Here we are at the discrete level. So the discrete anodes xh corresponds to the approximation of u and sigma. And here you have the numerical trace. So why do we have a numerical trace? It's just because we are working with this continuous space. So as far as I perform an integration by part, I cannot speak about trace. I just can speak about numerical trace. Can speak about numerical trace. We could use a generalization of the trace. This is exactly what we do with the numerical trace. So then you could say, okay, but I don't understand the first equation, which is the first one, AE, blah, blah, blah, because I only consider the numerical trace of U. And if you perform the integration by part, you will also have the numerical trace. Will also have the numerical trace of sigma. Because if you remember the equation, you have the first equation in which you have the divergence of sigma. So, performing the numerical, the integration by part, you will have, in fact, the trace of the normal trace of, oh, I am saying nothing, the numerical trace of sigma point L. Okay. So I will explain after I how we can only uh consider the numerical trace of u. The numerical phase of U. And then here you have a revelation that you end up with by summing over all the elements, because the first one that you see, it is local, it is at the level of the element, and then you sum over all the elements and taking into account the jump between elements, you end up with this kind of relation, which relates the unknown, the volume unknown, with the numeral count. Volume unknown with the numerical count. So please admit this formulation, it is okay. And then you assume that the matrix at the level of the element AE is invertible. It allows you to remove XH and then you end up with a global system which only involves this quantity, which is set on the skeleton of the mesh. Of the mesh, which corresponds to the picture that I show you about HDG. So, in fact, we are not far from Fresh methods since we are only considering the skeleton of the mesh for the global system. So, what do we have to do from an algorithm point of view? We have to create local matrices. We can do it in parallel. We can change the order in all the matrices if we want, if needed. We have to assemble the global matrix A, which is defined here. Okay. Then we have to solve a large system. For us, it is very large, I will show you. For that, we work with the people of MEMS because, in fact, they like very much HGG matrices because they have very nice property to put forward their solver. So they use us as an ambassador. Ambassador. Okay, and then once you have solved this problem, you get the numerical trace and you have to recompose the volume solution. And the price to pay, it's nothing because you have to solve local small linear system. You can do it in parallel and it represents less than 2% of the rental. Okay, so I try to. Okay, so now let me explain. Okay, so now let me explain why. In the first equation and thus in the second one, I only have the numerical trace of u, because if I insist, if I perform the integration path of the two equations, I will have the two trace. So in fact, I use this relation. And what is very important is this, tau. Oh, this tau. This is the stabilization matrix. And this quantity is the one that will make my method efficient or not. So the first attempt that we found in the literature was to use the identity. Okay, so maybe I should explain why we only have u hat. So when you perform the first, the integration by part of the first equation, you will have Of the first equation, you will have this constitution. So I replace it by this expression, which is the relation between both. And then what I do is to remove this quantity by performing another integration by part, so that I remove this term. And then I end up with a s system which only involves this quantity. This is a very simple. It's just a question of integration by part. Of integration by part. Okay, so here now I am in position to show you a new result that we have obtained, which is a new term for stabilization of this equation and thus of the global system. Yes. So, what we have done is something which is very technical. So, I So, I cannot present it, but you can find it in this paper on archive. It is online. And we also have a research report that you can find on our website, which is very detailed. You have all the computation. You also have the difficulty that we have to cope with. It is, I think, 80 page long. You will find a lot of things because I want always to have. I want always to have all on the table to discuss with people. So, how do we develop this parameter, which is quite complicated? First, this parameter is valid for dealing with anisotropy, because it was one of our interest, because the earth is anisotropic. So, we perform a kind of we solve. We perform a kind of, we solve a Riemann problem, in fact. So we go back to the time-dependent regime and we solve a Riemann problem at the interface between two elements. And we had to assume that we had three distinct velocities in the domain. So the P velocity, which is the standard, and two third uh s velocity, which is something which is uh the the from a physical point of view really uh From a physical point of view, really it's okay. It's not a fantasy of mathematicians that need to make the computation okay. So here I didn't want to define this quantity. It only depends, it is very important to notice it, it only depends on the characteristic of the waves, of the domain. It's not something which depends on the numerical scheme and so on. It's a parameter which only takes into account the variation of... only takes into account the variation of the domain. If you are interested in the method to get this quantity, you can look at the paper and I should mention another work that we did with Sebastian and Nathan. We did exactly the same and in fact this development was inspired by what we did with Sébastien and Nathan on the convected Elmos equation and we were able to improve the result of HDDG of Paul. Of HDDG for this kind of equation by in the same way solving a Riemann problem at the interface between two elements to find, in fact, the optimal stabilization parameter. So, obviously, maybe we can do it in some specific configuration, but it turns out when performing simulation that it works even in a general domain. Okay, so let me now show you some numerical. So let me now show you some numerical experiments to show you the gain. So here, this is a standard example that we use. So it is a 3D domain, which is huge. This is a typical size that you have in geophysics. They use this. So you have first things important. You have topography. You can see on the top. So for the bottom topography. So, for the topography to take it into account, we used to have a small order polynomials so that we can use small cells to fit with the topography. And then, what we use to do is regarding the value of the physical parameter, we change the order inside the mesh, which is one interesting feature of DG method. And here you have a picture, and the color that you can see here. And the color that you can see here corresponds to the different order of approximation that we have to perform the simulation. So we go from three to seven, sometimes we go from two to ten, it depends on the value of the velocity. So here you can see on the I I repeat, on the top you have very small cell, in the bottom you have big cell, okay, and uh by this way we really optimize By this way, we really optimize the use of this method. I am very sorry. You should count how many times you did it. It's just to have you as a collaborator. Yes, maybe what I should say, I forget. Say, I have forgotten to mention is the fact that inside the cell we use Lagrange basis to approximate the physical parameters. In fact, no, we can do it depends. If we perform a forward, if we solve a forward problem, we fix them at the beginning. We fix them at the beginning. But what we do is if we are in a loop of inversion, then we authorize ourselves to change the order of our perceivation during the computation. Yeah, because each time we have to update the velocity, because we work a lot with this velocity model, I mean we represent the domain of propagation. Ah, propagation. My God. The domain of propagation with the value of the velocity inside the domain, but you could choose something else. You could choose the permeability. For instance, you could choose the density. You have many, many different ways to represent the domain. In the inversion, we authorize ourselves to change the order. We can do it. Based on the grade of the grade? Yeah, it is based. Yeah, it we it is based both on the gradient and if we observe when updating that there is a suddenly a change an important change in the physical parameter. Yes, because it is very important to understand that we adapt the order of approximation not only to the regularity of the solution obviously but to the value of the physical parameter. It's very important. And it is even important more important in the time domain. Okay, so on the bottom here, you have a very standard example, which is the Marmusi model. This is the model that each geophysicist used to benchmark his numerical method. So we always start with this, in fact, to be sure that we are not doing bullshit. What is the difference between the two? It's the same here, the two pictures. It's just here. This is what I get if. Here, this is what I get if I consider that the physical parameters are constant per element. So you can observe it's not very nice. You have a lot of like the image add noise. And here it is moose. And regarding the simulation, it is very important because the wave will see that, for instance, this the wave will see that. The wave will see that as a reflector. So you will generate noise, numerical noise, just because you don't represent correctly the computational domain. So here are the results. So if you look this histogram, can you say it in English? Yes. In this colour, that should be red. Red. This is what we have with DG, the computational cost with DG, and here this is with HDG. So you can turn on that. You understand why we are so happy in using this numerical method. Here you have some important information, the size of the matrix. So it is 10 to the power 7. It is not that big. We can have more than 10 to the power 8. Have more than 10 to the power 8, and I think maybe you will show an example with your summary, no, yeah, or not. Yeah, yeah, yeah. No, just to say that we have application with a really huge number of degrees of freedom. So here you can observe this is not one minute for the second, it's it's okay. Uh and I think I can move on because maybe I I talk too much. Maybe I talk too much. We are late. Ah, yes, this is an example. This is a poisy. Because what we decided to do is to take a solar model in which we put elastic waves. We know that it doesn't make any sense, but it was very interesting to us because we were able to include anisotropy and we were able to include a density which is collapsing. Collapsing on the boundary. So, this is more or less a stiff problem to us, and just to see if our method is able to work. So, you have the information here, the different information. But please don't say outside that in Makutu they think that there are elastic waves in the sun. It's just to challenge our method. Okay? Okay, so here you have the result. Okay, so here you have the results. I cannot still explain them because we performed the session from today. Just we were able to validate them with another method for which we obtained exactly the same result. So you can tell me, but maybe the method that you used to benchmark doesn't work. I think it works because we use it for a while for other problems and so on. Yeah, yeah. So we have to analyze the results, but it seems that our method is able to handle, how to say it, strong changing in the physical parameters. We are very happy. And actually, we are using it when we deal with the sun, but with other equations and other parameters. So now let me move on to the inverse problems just to show you a real. Problem just to show you a result of inversion, and I would like just to mention one point which is important to us because this is something very classical. So, in the team, we are using the full waveform inversion. So, in a nutshell, what is the full waveform inversion? You have observation here that you get from geophysicists, astrophysicists. It depends on who you are working with. And we have an immediate software. Software. And what we are doing, we introduce a cost function which will compare the observation and the numerical observation that we are creating by the simulation. And we hope that once both the cost function will converge to zero, I mean the numerical observation will converge to the observation. So here you have what's going on when we perform the algorithm. perform the algorithm we we have an initial domain an initial um how to say it an initial uh propagation uh propagation we initialize the process with a model which has nothing to do with the the model we are probably we want to retrieve uh and what is important here in the in the in the loop so we perform simulation we solve the forward problem for a lot of source Problem for a lot of source because we have to image something which is big. And then we compute the functional function, the cost function. We have the cost function, we apply the optimization process. And what is important here in our method is the adjoint state, because it is based on the method of adjunct state. And when you are in this situation, what is very important is the fact that Is the fact that you would like not to increase the computational cost by having the solution of the agile state problem? And this is an important equation because you cannot say that each time, whatever the discretization is, the adjoint of the discrete problem is the discrete of the adjoint problem. This is a very old question that was mentioned by science. By science, I remember well, and Sia, and we are very lucky because with HDG, it works. And in the past, we had a very bad experience because we were using a weight-adjusted discontinuous Galaken approximation. This is something that were developed by Warburton and Jesse Chan, if I remember well. And in that case, the discrete of the adjoint. The discrete of the adjoint is not the adjoint of the discrete. So we had to increase the computational cost by doing something for the adjoint state. And this kind of the wage allows you to handle the variation of the coefficient inside the elements. So at that time, for the time-dependent problem, we would like to have collaborators to find the solution because we are stuck. So this is what I wanted to show. So this is what I wanted to show you on that slide, what is important. Okay, so this is blah blah blah. I always say it. So here a numerical experiment to conclude. So we consider a two-dimensional case. In fact, I will tell you that 3D simulations are ongoing. In fact, we have results, but I didn't have the time to include them into the talk because my talk wasn't scheduled. Talk because my talk wasn't scheduled at the beginning. But if you have the opportunity to attend a WAVES conference, or you will see some. So here you have the Marmousy model for the different values. So since it is elastic, we have P waves and S waves. The density, we do not inverse the density. We keep it as it is. But we will have to do it. And here, To do it, and here those are the initial domain, the models that we are using for the initialization of the inverse procedure. And this is what we obtain. So it's not that bad. We say, oh, not exactly that. We never recover exactly the domain that we use because this is a domain that we have, it is a synthetic. Domain that we have, it is a synthetic domain, so we have some imperfection, obviously. Here, what is important in the process, you can see that we are using 13 frequencies because, as you know, the inverse problem that we are solving is hill pose. So, we tend to be stuck into local minimum. So, to escape from the local minimum, we change the frequency. We have The frequency we have regularly, and this is the way to avoid this problem. Okay, and I think that so here, just to see the difference and the interest in using HDG and the way we use to have a variable coefficient, here we only use 20,000 cells, and with the ODG standard method, we need this number of cells for a result which is not. For a result which is not as good as this one. If you compare it, if you look at the Euro. Okay. So maybe I let you read the conclusion because I am out of time and I apologize. Take you. Appose. Minimally, one question. Does anybody have a question? Just very quick. I'm curious about this non-robustness when you choose a unit because I have used HDG for scalar problems, even non-linear. And one of the things that I like is just put the stabilization parameter to one very. So can you say a few words about how is it not robust for elasticity? In fact, I cannot say it's not robust. In fact, maybe we should perform more experiments, but Perform more experiments, but we have compared the stabilization that we get with the Kelvin's Christoffel stabilization term, which is more used than identity. And in fact, we have more observed that we have more accuracy than robustness if we compare our parameter with Kelvin-Christofer parameter, which is just a Kelvin-Christofer identity. I don't need I'm not sure that I but we can discuss after. I am thank you. There is a question online because you can you cannot yes, I'd like to ask a question: How do these HDG methods behave in terms of numerical methods? Of numerical dissipation and numerical dispersion for the wave propagation problems? So we didn't perform the analysis for the elastic waves, but for the acoustic waves, it is very robust. In fact, we made computation by increasing the size of the domain in terms of the number of wavelengths that we are propagating. And what we have observed, this is it is And what we have observed, this is it is very, very robust. But it's just an observation. We didn't perform any dispersion analysis for the time being. But I think it's quite difficult because we try to do it with Sebastian with finite elements. And even in 2D, this is something which is very technical with DG. Okay, so not worse than not worse, but maybe better. I First, maybe better, I can. As I mentioned, we are considering very, very huge domain. And our experience is that the dispersion tends to be dramatic when we increase the size of the domain, because we are always using high-order polynomials. So, this is our observation that I agree. But I agree that we should perform, we should finish the dispersion analysis that we have done, but with HDGE we never did it. It is just observation. Okay, thank you. Can I have a. Yes, yes, please. Can I? Yeah, the Mark Ainsworth in 2004 wrote a paper about the dispersion and dissipation. Dispersion and dissipation analysis of DG methods for wave propagation. So he found that if you use polynomials degree K, the order of dissipation is, I believe it's 2K plus 3 and the order of dispersion is 2k plus 2, something like that. So it has a really It has a really, really small amount of dispersion. And when you increase the polynomial degree, you should have even less. Yes. So my guess, as you said, to prove this in 2D and for the wave equation is difficult, but my sense is that you are going to find the same result. Okay. Okay, but if confirmed. Okay. Okay, but it confirms what we have observed with numerics. So it's it's a good news. Thank you. Thank you very much.