Okay, thank you so much for the very nice introduction. Thanks also for the invitation. I'm very sorry that I cannot be there with you. I would love to be, but yeah, as it is, it is. And so I'm happy that I can still give this talk. So now, I think we live in exciting times. I mean, AI is all around us. AI is all around us, infuse our life in various ways. But there are still, I mean, problems and there are also fundamental boundaries. And so, this talk is a bit about what limitations we face concerning AI and also how we can actually overcome them. Because to my mind, limitations is something which is often overlooked and which is not enough discussed. And so, in this talk, I would like to raise also a bit awareness of that. Sorry. Sorry. Yeah, so I think, I mean, we are at the beginning of the fourth industrial revolution. We see AI in various aspects of public life, self-driving cars, robotics, telecommunication, also in more sensitive areas like, for instance, the whole legal system. And also, I mean, the job market. And then, I mean, there's no area of sciences which is not impacted one way or the other by AI, ranging from medicine over astronomy up to, I mean, areas also. Astronomy up to areas also like the humanities. And so I think it's fair to say that I mean, we are really seeing and we will see in the next five, 10 years, a radical change of our society in its Fulbright. Now, I mean, I said there are many successes, but there are also downsides. And let's look at the downsides. I mean, for instance, there are problems with robustness, as we know. I mean, we have adversarial examples. There are problems with fairness. Problems with fairness, the training data is not chosen in an appropriate manner. I mean, it's amplified by the neural network, and see we see fairness problems, inference, decisions like classification. Most of the decisions are still like a black box decision, so explainability is a major issue. In particular, since I'm from Europe, I mean, there's this right to explanation or right to explain in the EUAI Act. So, this is a major concern right now. Also, we need a massive amount of data and typical neural networks. Amount of data, and typically neural networks are trained for one specific task, and so on, and so on. So, many each use, I mean, one observes, and let's maybe summarize them from a more high-level viewpoint. I mean, I think the major categories I see that we are problems with safety and safety, for instance, we see accidents with robots, and after all, a self-driving car is nothing else than a robot. We see problems with security, so we can have malicious attacks. So, where can have malicious attacks to those systems? So, for instance, taking over control of self-driving cars. Then, one major problem is the data problem. So, there could be privacy issues, privacy violations in particular in areas where data is scarce, like in the health sector. And then problems with responsibility. So, often we don't know how decisions are taken, and also decisions can be biased. So, in that sense, I think it's fair to say that reliability is one major problem worldwide. Is one major problem worldwide. And there's another problem which I think is also often a bit swept on the rug, which is the problem of the enormous energy consumption. And I think this is something which maybe is not highlighted enough because, in fact, it is a much more serious problem than one can imagine. So, here you see the sources, the decadal plan of the Semiconductor Research Corporation for the Biden administration in 2021. And what you see here is the world energy production. Here is the world energy production, and what you see here is if we continue using CPUs and GPUs, and this is the energy you just need for communication, then I mean, in 10, 15, 20 years, with that amount of energy which we require for communication, we will reach the world energy production. And you can imagine what that means. Yeah, so in that sense, this is a key problem. We cannot continue with any. We cannot continue with AI the way we do. We have to seriously think about how we do that and what we can maybe do to improve it and to reduce this danger. So the question is, I mean, also, are there fundamental limitations that constrain us? How can we overcome them? And in the end, I will also talk about the relation to next generation computing. Okay, so that sets the stage for my talk. And one. And one key focus of the talk will be: I mean, the current hardware which we use, to which extent, I mean, Gita, we cannot hear you. Oh, can you hear me? Yes. You got disconnected for maybe 30 seconds. Maybe 30 seconds. I see. Okay, am I back now? Yes. Okay. Yeah, maybe tell me because I don't know. I mean, it says the internet connection is instable. So I hope. Okay. Yeah. So let's see. Hopefully it won't happen again. But then, yeah. So tell me, and then maybe I switch and use a different network. Okay. So, I mean, yeah, so we worked a lot on theory on expressivity, conversions of training algorithms. Conversions of training algorithm generation abilities. However, I mean, I think what is not that sufficiently considered is actually the limitations of the hardware which we use, the computability, for instance. So there is a theory to practice gap, the nice theory which we develop. I mean, if we now bring it on the hardware, it could be that there are fundamental limitations which constrain us. And so this, I think, is not sufficiently explored today. So examine the boundaries imposed by... So, examine the boundaries imposed by digital commutations. So, the question is: I mean, algorithmic solvability, what does it mean? So, let's come to a general definition in that respect. So, the question is: I mean, we have a problem, I know, an inverse problem, for instance, whatever you can think of. We want to solve a PDE. Resolve computable. Is the problem computable? Can we construct an algorithm that solves P? So, what does it mean from a higher level viewpoint? So, we have this problem P, which is described by. Which is described by a function with an input-output relation. And the question, and then on a higher-level root point, is: can we find an algorithm so that for a feasible input, whatever that means for now, this algorithm gives me exactly the correct output which I require. Ah, so I mean, there are a lot of problems which can occur. I mean, the solution for P could be maybe not unique. I mean, then the algorithm will just output one of those solutions, but maybe more importantly, But maybe more importantly, I mean, feasibility will be described to a certain extent, so feasible algorithmic operations by also the hardware which we require or which we use at that point, properties of the computing device and its hardware. So the existence of the algorithm will depend on the computing device, and that I mean very sensitively and very closely. So this brings the computing device also in the game. The computing device also in the game when we talk about algorithmic solvability. And right now, I mean, most of the time, if you use GPUs, CPUs, we use a Turing machine, and it's commonly believed that everything you can compute on a Turing machine, you can compute on your laptop, let's say, and also vice versa. And so, I mean, not going into details, what a Turing machine is. So, basically, it's a strip, zeros and ones with a head, and then it computes and manipulates the. It computes and manipulates the points, the bits on the strip. And so, in that sense, you see already the key problem here. Typically, problems are of a continuous nature. You bring it down on your laptop, on a Turing machine, and so this can cause certain issues from a computability viewpoint. Computability theory, I mean, it's a very beautiful theory, and I don't have time to look at it here in detail, but let me just show you the basics. I mean, what this Show you the basics. I mean, what this is basically about. So there is the notion of a computable real number, which is, I mean, a real number is computable if there is a Turing machine which has the property, if we have n, so an accuracy on the tape, then the Turing machine will terminate with a rational number which approximates this r up to 2, 2 minus n. So that's the notion of computable real number. We can compute it for any. Computable real number, we can compute it for any given accuracy. And there are a lot of examples of computable numbers. The set is countable and dense. And there are also irrational numbers which are computable. Also, I mean, most, let's say, natural numbers are computable. And then we can extend this to functions. One can say a function is computable if we have an algorithm and the algorithm is here in a mere Turing machine, which if we have computable Turing machine, which, if we have computable inputs, then for all n, so these are the accuracies again, we obtain an approximation to f of x up to 2, 2 minus f. So, I mean, it's again in the spirit of a computable real number. So, the notion of a computable function is not that surprising. We can approximate that up to arbitrary accuracy with algorithms, so meaning with Turing machines. With Turing machines. But there are examples of non-computable functions. So, for instance, if you have a constant function which is equal to a non-computable number, it's certainly not computable. I think that's not surprising. And also discontinuous functions. Yeah, so I mean, if you now work on your laptop, on your GPU, on your CPU, there are certain inadmissible algorithmic operations. So certainly you shouldn't process any non-computable numbers or even. And non-computable numbers, or even something like deciding whether two computable numbers are equal is not computable. So, in that sense, I mean, the problem is always in the details. So, if you work with kind of continuous quantities. And so, what could happen, you see here in this image, I mean, it could be that your solution or what is output is far off, but you wouldn't realize it because it's not computable. So it could be. Not computable. So it could be far off the computed value and far off from the true signal. And so, I mean, it's now come to the definition of algorithmic solvability. So a problem is algorithmic solvable on a Turing machine if the function describing the problem is computable on a Turing machine. And so this is what one certainly aims for and what one hopes for for all problems and also in AI, I mean for all, let's say, optimization problems, that this is the case. Problems that this is the case. So let's look at one large scenario or one large group of problems which are inverse problems. So I mean, I think you're all aware what inverse problems are. You have observations, you want to recover the original data. So for instance, for MRI, this is very standard. You have here, I mean, your sampling operator, which is typically, I mean, underdetermined. You have your measurements, and then you would. Have your measurements, and then you would like to recover X. Yeah, and we all know, I mean, there are a lot of successful approaches, sparse regularization techniques. Now, people use deep learning to get better performance and so on. And we also know it's a near-approach problem. So, when you solve it, you need regularization. And so, one classical method is, for instance, I mean, going to sparse regularization. You see this here. So, here you have, I mean, you're So here you have, I mean, you optimize over the L1 norm, and then you have here this constraint. So now, I mean, the question I now, and so let's bring it to the next slide. So these are now the solution set of this optimization problem, which then hopefully solves this inverse problem under sparsity constraints. And so what one can show is that, in fact, I mean, the problem described by this function, which you see here, this function capital Psi for a fixed parameter. capital psi for a fixed parameter epsilon for an n and for m less than n is not algorithmic solvable algorithmically solvable on on a turing machine so this is a bit disappointing yeah so that means also if you use a neural network to solve it this will not work yeah so this is this is a fundamental constraint um which is not something related to the inverse problem but it is closely linked to the hardware It is closely linked to the hardware you actually require here. Yeah, so that means we don't find an algorithm, so a general algorithm, a general procedure on digital hardware, which yields neural networks, which approximates this for any given accuracy and all, on all reasonable AI, I should say. Now, one can extend this result. Even I said this is a result for Turing compatibility. Turing computability, there is a weaker version for computability, which would make this result stronger, which is called Banach-Mazur computability. Which basically, I mean, a function is Banach-Masur computable if it maps computable sequences onto computable sequences. So here, remember, RC are the computable numbers. So what one can show is that if a function is not Banach-Mazua computer, function is not Banach-Masur computable, then it is not computable with respect to any other notion of computability. That means that is the weakest form and what we can show is that this the result even holds for this very weak form for computability. So in that sense this shows that no matter which computability notion you have, it will not hold. Okay, so then you can say, okay, I mean I have the machine accuracy. I mean, I have the machine accuracy. I mean, certainly I don't want or I cannot expect that it holds for any given accuracy. So the question is then: I mean, when does and where does algorithmic solvability breaks down, which approximation accuracy can be reached? So if you want to go to machine accuracy or be a bit looser, I mean, then maybe an approximation, you can get away with an approximation. And so that raises then the question: I mean, Is then the question. I mean, does there exist a computable function that gives you the result? Remember this function psi. So if I go back, just to remind you, so this was the function psi. It depends on a matrix and on my y, which are the measurements. And it's this optimization problem depending also on epsilon so that it approximates this up to two to minus n. Up to 2, 2 minus 10. Okay, so that would be still acceptable. Certainly, I mean, approximation is always. So that's something which one maybe could live with. But what we could show there is that if we have meta epsilon and we have a capital N and some M less than M. And so here, I mean, you see the M is, you know, so it's the size of. So, it's the size of the measurement vector. Then one can show there does not exist a Banamoso computable function ψ hat, so something to approximate it, so that this accuracy is less than one fourth. So, there could be a systematic error of one fourth. That doesn't need to be, but I mean, there is the possibility. Yeah, so this is a bit, I mean, more or less disappointing. So, even if you loosen it and if you don't require precise. Don't require precise, um, let's say, precise recovery or precise, um, a precise notion. If you loosen it to approximate, there's still still a problem which you face. Now, yeah, so this doesn't, I should also say, yeah, so this doesn't depend on the unboundedness of the input dimension, which one might imagine, but also if the input space is compact, it still holds. So now this. So now, this result, I mean, how do you prove it? Let me just give you some insight. I mean, this is an existence result. I mean, it doesn't give you, let's say, precise knowledge about scenarios which go wrong, which is maybe not that nice, but it is as it is. So the key here is, I mean, to show that this map is not computable. So this is a lemma. And then if we Lemma, and then if we prove this lemma, we can use it. So, so this lemma, let's just look at this lemma. So, it proves for a map, and this map is exactly on the spaces if I go back, which we require. Yeah, and so this is a lemma which gives hypothesis or conditions under which this map is not computable. And so, the conditions are as follows: I have two computable sequences, and if I can construct them in such a way that they them in such a way that they satisfy these conditions, then this map is not computable. So what are these conditions? So these conditions are, first of all, I find two sets so that this map maps my one sequence into the one set and the other sequence into the other set. So that these maps are strictly disjoint. There's a positive distance between them. But in addition, the Addition, the sequences have a common limit point. So, if this is satisfied and I construct this, then this mapped side tilde is not computable. And then I can go as follows. So I can, yeah, well, I mean, first we do prove the lemma, then I construct input sequences to meet the conditions, and then I will can analyze these input sequences to obtain the degree of approximatic, of algorithmic non- Algorithmic non-approximability. Because then, I mean, I can show how far these are apart. So, this lemma is the key. But as you see, again, I mean, this is a non-constructive, I mean, it is constructive, but it will not construct the problems which occur. Okay, so, I mean, let's look at two extensions. I mean, one observation is, I mean, that this result does not rely on the properties of the considered optimization. So, even if one uses other optimizations, this still holds. This still holds, for instance, for the Lasou. This still holds. One can prove a similar result. And also, I mean, it doesn't rely on the properties of inverse problems. I mean, you can show similar results also for certain classification problems. So it's something more fundamental in that respect. So the question is, I mean, how to deal with that? Because that's certainly not what we want. In particular, if we think about reliability for AI, I mean, this is a concern which should. I mean, this is a concern which should be erased before we really go to true reliability. And so the question is: I mean, to which extent are the limitations connected to properties of Turing machines? So that now raises the question, I mean, can we actually get an idea on how powerful the hardware needs to be to enable algorithmic solvability of inverse problems? So, how far do we need to extend it or, let's say, make it improve it? They make it improve it. And so the main limitation of Turing machines are, I said, approximation of computable real numbers by rational numbers. And so the idea then is that certainly if we could go to analog computing models, this could solve the problem. It is unclear today if such a computing device can be realized and it might not be suitable for implementation. And it might not be suitable for implementation on digital art. But, I mean, there are certainly very exciting directions you might have heard of. I mean, there is this direction of neuromorphic computing where already neuromorphic chips exist. So there are companies like Spinacher and so on, which design neuromorphic chips. These are more closely modeled to the human brain. So, what they do is they incorporate true analog elements by currents and voltages. Elements by currents and voltages. And also, this is one additional, let's say, benefit. They are much more energy efficient. So, this would solve then also the energy problem, which, I mean, as I said, and as I hopefully discussed enough is one huge problem for the future. Then there's quantum computing, which is also, I mean, if you do quantum computing without qubits, so if you use optical devices, like for instance, here in Munich, we have Iman. Like, for instance, here in Munich, we have Immanuel Bloch. He has these optical devices and has, let's say, quantum computing using this. Then, also, this could be a way, although this will not solve the energy problem. Then there's bio computing, which is at a very preliminary stage. You can compute in cells. Then there are hardware based on memory technology, which will also, to a certain extent, mimic, let's say, analog computing and also much more energy. It's also much more energy efficient. So, there are very exciting directions in that respect. Yeah, and so, I mean, the key question is: then, does the non-computability result also hold for different computing models, such as we are somehow analog computers, whatever that means for now? And also, maybe we can give complexity classes or something in this direction. Okay, so let's consider extensions of the Turing model. So, the goal is certainly to have, let's say, a mathematical model which computes with real numbers. For now, it is not clear how close we can get to that with real hardware. But in fact, there are interesting developments. Modic Main Wisto technology looks like that it might even be able to mimic this Bloomtrop Smail machine. So, there is this beautiful framework, the Bloomtrop Smail machine. I mean, I'm sure you have heard of Smail. Sure, you've heard of Sneyer, the mathematician, and maybe the others too. So, this is a mathematical model of analog computing. I mean, you compute here over arbitrary rings, you use arithmetic operations, and you use comparisons on elements of the rings. So, I mean, this is just very informal. It's a very complex framework, which I don't want to go too much into the details here. I mean, the characteristics, the basic characteristics of this BSS model is an extension of tree. S model is an extension of Turing machines over arbitrary rings, and there you can actually compute with real numbers in a certain sense. Okay, so what is now a computable function over such a Bloometh-Smale model? A computable function over R is now an input-output map. Let's call it phi B of a Bloom Troop-Smale machine over R. That means on input X, this machine terminates. x, this machine terminates and outputs phi b of x. So now, I mean, we have a notion of a computable function over r modeled by this Bloomberg-Smail model. And so let's now also maybe remind you what semi-algebraic sets are because we will use them in a moment. These are finite unions of sets of this form. So you have here polynomials, the p's and the q's, and the set capital q is a set of real polynomials. Of real polynomials. And so this is what we require for a semi-algebraic set. And there is a beautiful theory by again Bloopet Smile machine by Bluetrop Smale, which shows that every semi-algebraic set is BSS decidable. So there exists a calling machine so that for all X we have that this Phi B S gives me the characteristic function on S. So semi-algebraic sets are closely linked. Are closely linked to Bloomschup's mail machines in the sense of decidability. Okay, so let's go back to our problem: inverse problems. So this is the solution set. We already saw that many times. Remember, this is the sparse minimization problem, which we want to solve. And this is the solution set, the capital Psi. So now, I mean, this is an optimization problem. It's now the question: I mean, what is optimization on these? I mean, what is optimization on these machines? So, here, I mean, for an optimization algorithm on a real loop-smeil machine, I mean, the input is a finite set of real polynomials describing a semi-algebraic set, and the polynomial and the output is the inf of f and a minimizer. So, this is an optimization algorithm, but the question is whether we can now solve this optimization problem in this sense. Problem in this sense. Now, so this is what can be realized on a Bloomschubs mail machine. But the question is now: can we put this, what we want to solve, in this framework? So that requires, do we have here semi-algebraic sets? Okay, so what we see is that this, in fact, is a semi-algebraic set. Now, the L1 norm is not a polynomial, but you can split it into the positive and You can split it into the positive and the negative part, then it actually becomes a point or yeah, so maybe let's go back because it might have been a bit quick. So what you need for an optimization algorithm is you need a finite set of real polynomials and a polynomial. And so then, I mean, the output is the inf of f on this semi-algebraic set and the minimum. And the minimum. Okay. And so you basically optimize over the semi-algebraic set. And so now what we saw on the next slide is that this is indeed a semi-algebraic set. And you can phrase this part here to be a polynomial. Now, so that now fits in this framework of Bloomschup's mail. So in fact, with this machine, you can solve this optimization problem. This optimization problem so that the puzzle pieces fit. So you have your semi-algebraic set ends. Okay, so and what we can then show is that real inverse problems described by psi are algorithmically solvable in the Bloomschroms mail. So this is the positive result. The key question then is certainly, I mean, do we have hardware approximating this model? But as said, I mean, there are interesting directions which could lead, in fact, to Which could lead, in fact, to that, that we can, let's say, build this BSS model in hardware. So, let me also mention at this problem at this point that, as I already mentioned before, not only inverse problems are, let's say, an issue which one needs to tackle, but in fact, I mean, there are also classification problems which can be shown to a certain extent to be not computable, the pseudo-inverse. Then, for partial. Then, for partial differential equations, there's something like a complexity blow-up. So, if you have your input to a PDE, then the output will be exponentially larger if you realize it on digital hardware and also certain optimization problems. And so, I mean, the goal, I mean, also, I mean, for me, is to get really, truly mathematically reliable and also energy-efficient AI by embracing these. By embracing these novel computing devices, in particular, augmenting digital hardware by analog hardware to tackle those problems. Yeah, and so let me mention at this point that we also founded a company, Ecologic Computing, which actually goes in this direction and where now the goal is to develop for specific problem settings optimal hardware combinations and software wrappers so that everything is reliable and at least 100 times more energy. And at least 100 times more energy efficient. Okay, so I mean, so until now, I mean, we talked about problems concerning computing and how you can actually tackle those maybe by going to novel hardware. Now, the problem is, and I mean, certainly this all is true also for neural networks. So, if you solve your inverse problem, you do it by a neural network, you run into all those problems. If you solve your If you solve your classification problem by a neural network and this satisfies certain conditions, then you will run into those problems. So, now, I mean, for next generation computing like neuromorphic chips and so on. So, the question is, do we use the same neural networks or do we now need to adapt the neural networks? So, let's go back now to the architectures and what I talked about now. I mean, so this is a Turing machine, a Verne architecture, which we are all For Neumann architecture, which we are all extremely familiar with, I have binary input and binary output. Now, if we now consider neuromorphic hardware, which to my mind is the most interesting right now, I mean, as I said, quantum computing is nice, but it will not solve the energy problem and biocomputing and so on is at a very preliminary stage. So, the neuromorphic hardware, we have spike input and a spike output. That is, in fact, much closer to the human brain. In fact, much closer to the human brain, and it is also significantly more energy efficient. The execution speed is much higher, and hopefully, I mean, right now, not, but I mean, hopefully in the future, and that is the promise, it will be more robust. Yeah, and so the question is now, I mean, here for Neumann architecture, we have normal neural networks. What are neural networks now for this neuromorphic architecture? Because now we don't have bits to handle, but we have. We don't have bits to handle, but we have these spike inputs. So the neural networks need to now deal with other types of input data. And the question is, how do we adapt those? And again, I mean, let me remind you the development of neural networks based on the key ingredient, namely artificial neurons. The first generation were perceptron models, which were maybe the very first stage, and then certainly the artificial neurons, which we deal with. Neurons, which we deal with and use right now. They are biologically inspired, but they are very crude. I think we all agree that this is nothing which we have in our brain. Still, I mean, they are very powerful, they are universal approximators. But now, I mean, we need to be more smarter than that. Because I said, I mean, first of all, we need to be more energy efficient and we also need to deal with these spike inputs. With these spike inputs. And so this brings me to spiking neurons. So spiking neurons are much more biologically realistic than first and second generation, what I showed you on the previous slide. They have at inputs electrical pulses, so something analog in that sense. And so these spike or action potentials are the elementary units. And so here, I mean, you already see this figure. Yeah, so let's say this is my. Yeah, so let's say this is my neuron, and so I have here different inputs coming in, different spikes. And you see here what happens in the neuron. So if you measure it here, you see here the action potential come in and they build up as they come in over time. And they all will not come at the same time. So time is a key component here. Yeah, so they will build up. And at some point, I mean, they will go over the threshold and then the neuron. And then the neuron will fire, and so then the potential again goes down. So, this is what happens in a spiking neuron. So, this is then a spiking neural network. We have as input spikes, and it's still a big problem how you actually transfer in an optimal manner data. Data to spikes. What you can always certainly do is you can encode this image as ones and zeros and then build the spike train depending on this bit sequence. So that's the easiest you can do. But maybe there are more optimal, better ways. In any case, so then I mean, you have your spike inputs, you push it through the spiking neural network. So every neuron, something like this will happen. So the spikes, the So, the spikes, the action potential will build up at some point in time. It will reach the threshold, and then the neuron will fire and continue to the next neuron. So, here, I mean, the key component is that we have an asynchronous transmission of information via spikes in contrast to a feed-forward neural network where everything is synchronized. So, the information is, in fact, encoded also in the timing. In fact, encoded also in the timing of the spikes. And let me also mention at this point: I mean, there are very complicated models for spiking neurons in spiking neural networks, also based on stochastic PDEs. One of those, which is a bit more, let's say, on the easier side and I mean, still difficult to analyze because you always have these timing components and it's actually highly challenging. One of those is a spike response model, which I would like to introduce. Spike response model, which I would like to introduce now. But let me also say that time is, in fact, I mean, one crucial factor in this model and in any model which you consider. Okay, so let's look at the spike response model. So a spiking neural network then is a directed graph, which consists of, well, I mean, as usual, a finite set of spiking neurons. We have a dedicated subset of input neurons. subset of input neurons and then a set of synapses. Every synapse, so XU V in E is associated a weight. So that's kind of like the neurons, the normal artificial neurons which we worked with before, but also a delay, a synaptic delay and a response function. So the neurons themselves, which themselves which the synapses connect yeah so every neuron which is not in the input dedicated input set is associated with a firing threshold that's related to also to the bias which we have for let's say the classical artificial neural network and a membrane potential so the membrane potential um you see here uh in the spike response model uh so you have here the time component um Then you have here a delay, the TUF. So, what are the TUFs? There are in FU, which are the set of firing times of the neuron U. So, it fires at certain times. So, this, I mean, depends on the previous neurons. So, when they reach their threshold, that makes also the analysis so complicated. So, here you have the firing times of the neurons it is connected to and from which it gets its signals. Then the response function is applied to this and the weight. And then you sum over all these firing times and over all synapses which approach this one neuron. And that gives the membrane potential. And so when the membrane potential then finally reaches the firing threshold, then this will fire. Yeah, but the time, I said, I mean, the time component is essential here that makes things well. Makes things well, I mean, more biologically realistic, but also from a mathematical standpoint, much more challenging. And so, here is a depiction of that. So, here you have, it's a very tiny example, you have input neurons, and here you have the output neuron. And here you basically see what happens for the potential of this neuron. So, the PV of T, this is the time component. And so now, I mean, you see, depending on when. On when signals come in. So let's say you get here your first signal. So this is here the U2 spikes. And maybe this, sorry, is the potential which comes in. Then the next, you get the input from U3. Yeah, and so this draws it now again. So, this draws it now again, I mean, down. Then you get the next input, and so on, and so on. Yeah, so slowly, I mean, the potential is building up. At some point, it will reach this threshold, and then it will go down and fire. Yeah, but I mean, you see here, I think, very nicely the time component. Okay, so now let's assume, make things a bit more easy, that a neuron spikes only once. So then, I mean, you can get rid of one of the Of one of the sums. And basically, for each u, so the neurons which are connected to v, you have only one spike. So you have this tu, the unique point when this neuron spikes. And that makes things a little easier. So yeah, so to use the firing time of the presynaptic neuron u. Yeah, and so now let's assume also that the response function is linear and satisfies a condition like that. So let's recall. That so let's uh let's recall this d UV. So these are the synaptic delays. So this response function has this synaptic delay if my t is in this interval and otherwise it's always zero. And this delta is the length of the linear segment of this response function, which is intrinsically linked to the respond function. So then, I mean, if you have this additional assumption, so Have this additional assumption so that this is linear, then one simplifies to this term. Well, I mean, you can easily compute that. And now, if we assume that the delta is large or even infinite, so if I go back, you see this is the delta, the length of the linear segment. Then, I mean, through some computations, you get the TV, which is the time the neuron V fires. The neuron V fires look like this. So then, I mean, the output firing time is a piecewise linear function of the input firing time, and under some ill condition, it's even continuous. So, this makes things nicer and it's, yeah, I mean, one, let's say, mathematical observation which one can take. Okay, so now, I mean, the key question in all this is: we have spiking neural networks, we have classical neural networks. Neural networks. So, how do they relate to each other? Can one express the other and vice versa? Is one more complex and in that sense, maybe more efficient? And so on. So let's compare those two. The one result which one can show is that if I have a classical real neural network, so the classical artificial neural networks, which we work with something constantly, then I can. Then I can find a spiking neural network with that many neurons and this number of layers that realizes this classical neural network. So, what you observe here, I mean, not looking at all the technicalities, is that this looks kind of, it looks depends linearly on psi. So, if I have a classical neural network and I want to represent it by a spiking neural network, the spiking neural network has, yeah, I mean, it has the same. It has the same complexity in certain sense. It seems to be not difficult to approximate. And so, I mean, one key ingredient of the proof is to look at the RELU activation function and represent this by spiking neural networks. One should also mention here one result that one does not find a one-layer spiking neural network that realizes the RELU. It has to be a two-layer spiking. Okay, so. Okay, so in that sense, spiking neural networks from the complexity, yeah, or let's say, yeah, let's say it this way: if I represent a classical neural network by spiking neural networks, I don't increase the complexity. Okay, so now, I mean, let's look at the other way. So now I have a spiking neural network with only one output neuron. And then I look at how this response. I look at how this response time, this Tφ, can be realized by a classical neural network. So that's the other way around. And here, what you already observe is that here, I mean, you get something exponential. Yeah, so that seems like that, I mean, if you want to do something via, let's say, classical neural networks, I mean, it seems to be exponentially more complicated than with spiking neural networks. And so, this is or could be an indication why spiking neural networks, neuromorphic computing, is. Spiking neural networks, neuromorphic computing is actually much more energy efficient. And so, the ingredient of the proof, I mean, this is, I'm sure you're aware in classical neural networks of all these proofs, which look at different patterns, different activation regions. And this is, I mean, a similar idea. So, here for spiking neural networks, you can show results of a maximal number of linear regions under the condition that's a synaptic way. Under the condition that the synaptic weights are positive. Yeah, and so then I mean, you can show that this Tφ is continuous piecewise linear with 2 to D minus 1 linear regions, and then we can use classical results from neural network theory. Yeah, and so here, I mean, it's just a very, very, very toy example where you see activation regions of the spiking neural network. Here, there are three regions, but Regions, but what you saw on the previous slide is that the spiking neural network decomposes the input space into much more regions with fewer neurons than if you use classical neural networks. Again, an indication that they are more powerful. Okay, yeah, so I mean, the previous results are nice, but what you really want, I mean, is a result. You want, I mean, it's a result if you go back. Yeah, so that you cannot do better than this. Yeah, so that this is that you need a lower bound for that. And so for certain classes, we can do that, but the main overall result is still missing. So for instance, I mean, you can find many, many functions where you can compute how many neurons you need. And then with classical neural networks, you strictly need more than for, let's say, a spiking neural network. And then, for let's say, a spiking neural network, and also for the minimum function, there you can prove a more general result, which shows you that for a classical real neural network, Eurospective of the depths, I mean, you need at least D neurons, but here for a classical neural network of depth three, this is necessary. So, I mean, here for sparse. For spiking neural networks, for the minimum function, you can also show in more general terms that there you need strictly more, let's say, neurons and layers for real neural networks. Yeah, but I mean, the main goal is to really show that, yeah, and so this I pause here, also open question, I think very exciting research directions is when and to which extent are spiking neural networks more expressive than classical neural networks, and I mean strictly more expressive. And I mean, strictly more expressive, so having lower bounds. Also, the training procedure for those networks is not, there are ideas, but not clear. There's no classical training procedure like we have for normal neural networks. What about generalization? There's a nice result by two colleagues from the University of Vienna, Neumann and Petersen, who proved first generalization results. What about energy consumption? So, what is actually suitable? So, what is actually a suitable model and measure for energy consumption? Can we then prove that? So, in that sense, I mean, from my viewpoint, this direction will be even more important. I mean, in the future, right now, I mean, mathematics of spiking neural networks is a wide open field. And also what I showed you is only for the spike response model. If you look in the literature, also in Europe, there were, I mean, many submissions now for spiking neural networks, but all of those are. But all of those are typically without any theoretical content. So I think from that viewpoint, I mean, mathematics of spiking neural networks is a wide open field. And from my viewpoint, I mean, very exciting. So let me finish with some final thoughts. I think we live in exciting times, at least concerning AI. We see impressive performance, but mathematics. Gita. Hello. Hello, Gita. Yes. You were gone for a little bit. Maybe you want to restart the conclusions. Oh, I see. Thank you. Okay. So what I said is I think we live in exciting times concerning AI. There was impressive performance for real-world applications, but a mathematical foundation is, I mean, a comprehensive. Foundation is, I mean, a comprehensive one, still missing. And so we have still a way ahead of us. Now, we focused here on limitations, in particular from a computability viewpoint. And we discussed that there are certain problems with digital hardware, which might be overcome with more, let's say, innovative hardware, in the sense also an analog hardware, the Bloomtop Smail model. And from the neural network perspective, I mean, certainly these computability results are. I mean, certainly these computability results all hold for that. But if you now go to next generation AI computing, in particular concerning neuromorphic chips, then the classical neural network is not the correct model anymore. You need to go to spiking neural networks because now you have spikes as input. And the exciting thing is that it seems that they are actually much more powerful normal neural networks. And hopefully, one can also show that, in fact, they are much more energy efficient. So, from my viewpoint, Efficient. So, from my viewpoint, as a vision, I think next generation AI computing is of essence to consider also from a mathematical viewpoint. So, as I said here, mathematics to my mind is crucial for next generation AI computing. And with this, I'd like to conclude, and thanks for your attention. Are there any questions for Guita? Thanks, Guita. That was a fascinating talk. I have a philosophical question, which might be extremely naive, but I would like to get your opinion on it. You're very, I mean, could you speak a bit louder? Sorry. Oh, sorry. Yeah, okay. Can you hear me better now? Yes, yes, perfect. Thank you. Yeah, so I have what might be a very naive. So, I have what might be a very naive philosophical question, but I would like to get your opinion on it. So, we distinguish between human minds and machines in at least two ways. One of them is ethical. We don't want to use human beings as mere means to an end. We want to see them as ends in themselves. Another is physical, which is machines are normally distinguished from human minds in that their instantiation in hardware is different. In hardware is different. And a big thrust of your talk seemed to be that the only way to solve the problems we're facing now in terms of energy consumption and so on is to bring the hardware underlying machines closer to the hardware that we see in the human mind. And I was just wondering if you had any thoughts on this. Yeah, that's a very, very interesting point. But yeah, I think your conclusion is exactly right. Is exactly right. So, I mean, if you think about it, the human brain needs, I think, 20. I don't know the English expression for that for computing. Whereas, I mean, as we know, for the GPU cluster, I mean, it's astronomical. So, in that sense, I think it's a very natural way to try to mimic the human brain closer. Also, this might solve problems with the huge number of training data which we need. I mean, a kid. We need. I mean, a kid needs certainly, I mean, not a million, needs to be not shown a million cats and dogs to distinguish that. So I think there's something in the human brain which we don't understand yet. And so the hope is that now, I mean, with this, we get a bit closer, whether we capture the right component of the human brain that way is not clear. But yeah, so that's the hope. And the neuromorphic chips might be one way, and it seems that they are. One way, and it seems that they are more energy efficient. So, maybe at least that component can be captured. Yeah, so I mean, you can also argue and say, well, maybe we need to be smarter on the software side. But I think, I mean, the hardware is one, I mean, key limiting factors. So, I think you can be as smart as you want. I mean, if these computability limitations are so severe that it needs That it needs to be, let's go in hand and hand in hand in hand, I mean, to improve the hardware, but then also the software accordingly. Thank you. I think we have a question online, maybe from Kyle. Yes, hello. Can you hear me? Yes, perfectly. So, I wanted to ask: another big part of your talk was regarding the computability. Regarding the computability of all of these inverse problems that arise in optimization, and you know, clearly we do so much optimization these days, it's a very important point. However, I wonder if there is something of a domain mismatch problem for some of these inverse problems, which is that in general, when we try to solve LASSO or Lasso or basis pursuit or any of these problems that involve sparse signal recovery, we assume that the input signal itself was, or at least approximately was itself sparse. So in the codomain, like these measurements that we aim to feed into these inverse problems are not generic. Like we are considering in general a very small subset. A very small subset of the space of possible output signals that we wish to subject to these inverse problems. And so I wonder whether the results on computability change if you were to, for example, consider only the subset of the codomain for which this solution to this optimization problem exists and is unique. Yeah, so I mean, thank you for the question. Also, great question. I mean, thank you for the question. Also, great question. So, yeah, so on the one slide, I said that, I mean, this, let's say, infinite input domain is not a problem. In fact, I mean, you can prove the same results for, let's say, compact domains. One should say that these results are results also of a universal type, in that sense that, I mean, if you want to have a universal algorithm which holds for many matrices and different accuracies, if you And then different accuracies. If you now have, let's say, a very specific measurement matrix and let's say a very specific accuracy you want to reach, I mean, then you can design an algorithm specifically for that setting. So these computability results are if you think, I mean, you have the chance to have a more, let's say, universal approach to that. And then you run into these problems. Yes, I see your point. However, I think in most of these problems that you shared, we are assuming a net. You shared, we are assuming a known measurement matrix, right? So we can at least assume that these problems are parametrized by the particular compressive operator that we consider, as well as some information about the structure of the signal class. So, you know, this is this is still universal for the signal class itself, given a choice of the itself given a choice of the um of the compressive operator um so i i guess like i i still wonder whether you know like asking that we can compute a uh an output for any any y is is reasonable i'm still not quite sure i i fully um like i at least like in my mind like if we consider this measure zero subset of the of the codeman rather than the whole Of the codeman rather than the whole space, it seems likely that we would do much better as far as these computability results are concerned. Yeah, so that could be, as I said, I mean, for specific settings, when you are more specific, I mean, then in many cases, I mean, you have a chance to overcome these computability results. That's absolutely right. Yes. Thank you. So I have one question regarding this gap between compatibility. Gap between compatibility of the PSS model and the Turing model. So, how much of this gap is due to the existence of ill-posed, let's say, instances for many of these problems? Because in Turing model, like the size that you need to write the inputs matter, while in the VSS model, kind of the size of writing a real number is put under the rack in the model. Like all the real numbers are written in the same, even if the number may be. The same, even if the number maybe it's say 10 to the minus 27, very sparse, it will be the same as writing the number 123. So, how much of this gap is due to maybe inputs in which you will need extra effort in the Turing model to write the solution down, while in the BSS model is just uniformly written down? Well, yeah, it depends on. I mean, so I mean. Yeah, it depends on. I mean, so I mean, the connection was not that great. So, I hope I captured your question correctly. Um, so the question, if I understood correctly, is about let's say the different input formats for Turing machines and for BSS machines, whether this makes an impact. How to say, but I mean, so if you have, let's say, so the problem occurs. So, the problem occurs if you have, let's say, continuous eye problems, you have continuous data, so real data. There, certainly for the Turing model, you have different representations. But in fact, I mean, these results hold for any representation you can choose and you can take. So, it depends not on that. Whereas for the BSS machine, I mean, there's no question, at least for these idealized. At least for these idealized analog models of how to represent it. Certainly, I mean, in the end, I mean, this ESS machine is also idealized. So, if you then, I mean, go to, let's say, real hardware, you will have, I mean, to find good representations for your data. And so, this is a different ballgame. And then one has to see, I mean, how far this deviates then from the result which we obtain and whether you can have again computability. Again, gain computability. But right now, I mean, this is the situation in that direction. I think there were Malacho with some soup and independently. So, sorry, could you say again? I mean, there were always breaks in the I don't hear anything now. With finite precision, and then they have like an ocean. And then they have like an ocean of all that. It will be interesting to see if you could extend the computability results for general BSS machines to BSS machines with the, let's say, precision restriction. Yeah, yeah, yeah, yeah, sure. That's true. Yeah. That would be interesting, yes. I have one last question, Ita. So you advocated how, for example, Advocated how, for example, the complexity measures for the spiking networks were better and more energy efficient. But the numbers for the complexity were something like 2 to the D cube or something like that. So could you comment on why that would be more efficient? Like what is the baseline and how does that number connect to energy efficiency more precisely? That's an excellent question. Question and um, so as I said, I mean, I what we are still looking for is a very good model or measure for energy efficiency. So, right now, we look at, let's say, the number of neurons, but whether this is and the number of neurons which are activated, whether this is a good model, we don't know yet. So, what we what we do right now, we set up a testbed for neuromorphic chips and want to also check, I mean, go down to the hardware and then see what mathematically a good. See what mathematically a good model for energy efficiency is, and then incorporate this. So, right now, I mean, what I just said, so maybe I phrased it a bit too strongly. So, what I just said is that, I mean, if you emulate a neural network by spiking a neural network and vice versa, then you need, I mean, let's say, layers and neurons when you emulate a spiking neural networks by. Emulate a spiking neural networks by classical neural networks, then vice versa. So, this shows to a certain extent, I mean, that spiking neural networks are, well, I mean, more powerful. To which extent this relates to energy efficiency, then you certainly have less neurons which are activated if you compute the same function. So, this is one argument to say that this is more energy efficient, but I mean, I I would like to go there much deeper, but this is still a work in progress. All right. Well, thanks, Gita. Okay, one last question, I guess. So I think I have a better way of formulating the question I tried to ask before, which is, it seems like we're pushing to create these machines to be even closer to human beings than they already are. Look at something like ChatGPT, there are many people who would say this passes the Turing test. Many people who would say this passes the Turing test. And then, if we're implementing these things in hardware, which is indistinguishable from the hardware that human beings run on, I wonder to what extent we're going to have ethical obligations towards these things. Oh, I see. Do you think this is a problem that we might run up against in the future? And if not, I wonder why not. I see. Yeah, so that's a very interesting question. I mean, I. I mean, I don't worry in ethics, but let me say from my human experience what I would think. I mean, in fact, I think it might be that we run into ethical problems. I mean, if we mimic humans more and more, I mean, I think right now it is that, I mean, there are so realistic, I don't know, robot dogs and so on, that people also are already afraid of turning them off. Yeah, so and then, I mean, if you have something which is very close to the student. Have something which is very close to the human brain and it seems very natural that, say, the speech is very natural. I mean, it could be that, yeah, that people feel very attached to it and are afraid to actually turn it off. And the question is, I mean, so I was just at the AI for Good Global Summit last week, and so there were also some people interviewed, like Sam Aldman. Like Sam Altman. And it seems that people believe that, I mean, at some point in, I don't know, 10, 15 years, AI might also get a conscience to a certain extent or a self-awareness. Now, if in addition, I mean, the hardware mimics the human brain even more, I mean, then it becomes a very serious ethical problem. So, from that perspective, yes, I think there will be concerns of that in the future. In the future, yes. Thank you. All right. Thank you, Gita. Sure. Okay, bye-bye. All right, so I think now we have the group photo to be taken. So I guess I don't know where we're going to go, but we'll probably be all.