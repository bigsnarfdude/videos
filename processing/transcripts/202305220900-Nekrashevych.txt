Especially since there are some obvious candidates on the about this related to this. And also one of the aims of the talk is to give a setting to other talks in this so let me start from the definition. What is this? A similar group, so similar action. So a faithful action Uh so a faithful action of a group uh T on the set of finite words over some alphabet on the freemanoid generated by the set is said to be so similar If for every G and every letter X, there exists an element of the group between the note G, kind of restricted to X, which has the property that if G acts on a word starting with letter X, then it acts on that letter. On that letter accordingly, but on the tail that this new element acts. In other words, the action on the tails of words is also an element of the root. So typically we'll represent X star as a tree. So empty word is the root, one letter sub words, one letter words are first level, two letter words are second level. Second level, and in general, word V is connected to words of the frame VX. And this condition means that actually you can iterate, so this will be true not only for one-letter words, but for any letter, any words. So you will have that for every V action on the words starting with V is action on the prefix, and then some other element. And then some other element acts on the table, and this other element is denoted the same way. So you have our tree, and this is our element letter V. G will move it to a word of the same length, so on the same level, somewhere. And then if you just look what happens down in this sub-tree, ignoring everything else, you will see action of that other element, G. So action, local action on the subtrees is the same, it also belongs to the group. So it's easy to define such groups just declaring their action and using this type of equalities as definitions. So for example, you can say, let's take alphabet consisting of 0 and 1 and take one element which is given by the condition that Which is given by the condition that if you start with zero, you get one, change one, and then don't change anything. So, meaning the identity element acts on it. When this one is changes to zero, and then let A act on the rest. So, this will define A in a unique way, and then the group generated by A will be the action of this group, which is by the Morph P C, will be so similar. Will be so similar, will act so similarly. So, this is the so-called adding machine, the odometer, and this is how you add one to a binary number. If it is zero, well, you write it here in the opposite direction. If it is zero, you change it to one. If it is one, you change it to zero and carry. But you can write something random, almost random. For example, you can say, let's take two elements, A and B. I say A0W S1W, A1W. A1W is 0BW V0W is 0W. V1W is 1AW. Again, this will define two elements, two optomorphisms of this rooted T using these recurrent relations, and this will Define some groups. So, if I condition that the action is faithful, you just take the group generated by these automorphisms of the tree. So, you will get some group. And it will be actually very difficult. Well, in this case, it's a well-known group, so we know many things about them, but if you write something really random, there'll be no chance to understand what that group is. What are the other non-conditions? Like if you say if you define it random when it's like infinite and when it's at least some properties of this group, like in a very general setting? Well, you can check. Well, no, almost any of these questions are not known to be solvable. We don't know how to solve these questions. We cannot if you just write it at random. We don't know how to check if it will be infinite. We cannot check if other things. Other things. We can check if an element is trivial or not. And even that. So if you take a generator and in your recursion, as I did, these are all generators, then you can check if some element is trivial or not. But you can write this as a word in generators, and then that will be significant. Anyway, I will explain why they're important a little bit later. So that's one way of defining these groups, just writing these recursions. Another way is to write them more compactly, namely noting that we have a permutation on the first or any level. So we can record the permutation and then we record these elements. So for example, here we can say that A corresponds to Corresponds to, so you have permutation 0 and 1 are switched. And then at 0, for 0, section is identity. And for 1, this is called section is taken. We can write something like this. In this case, we have A does permutation 0 and 1 is switched. Then at 0, the action is on the tails. The action is on the tails is identity. At one, the action on the tails is B. B is identical permutation. And then at B, it's identity. At 0 is identity. At 1, it's equal. Well, usually we denote 0, 1 by sigma, something like that. And we replace this by equalities. So you write assumption. A is sigma 1B, B is E is so what we write on this side is the reef product or the semi-direct product of the symmetric group and square of the group. For this meeting, it makes more sense to use instead of using elements of the symmetric group to write permutational matrices. And then it's natural to write these elements. And then it's natural to write these elements of these sections as entries instead of ones in these permutational matrices. So in this case, this will be written that A is 1, 0, A, 0. Here, that A is 0, 1, D 0 and B is 1, 0, 0, A. So, this is a for some people, this seems to be a better way of writing these pronotations more intuitive. So, why this is natural and how we can introduce some algebras in this setting. There are different ways of approaching this. So, for example, we can take, so we have this action on the rooted tree, we can look at the boundary. We can look at the boundary of the action, the Canter set, or in other words, space of infinite sequences. And then think for a second. I don't understand one thing. At the very top, on the right, you say A goes to the permutation because it's transition 0, 1 and comma A. Is that supposed to be A? Yeah, this is A. Okay, I don't understand. What is this? This. Oh, for that one. Okay, the second attempt. Oh, for that one. Okay. The second example. Okay. So down at the bottom example is the second floor. Yes. Oh, yeah. So sorry. And the equality means military equivalent. Yeah, that's what I will define. That's what I will explain. So another approach to this is that you look at the boundary of the tree and okay, unitary equivalence appeared, so let's use space. My original idea was to use the space of continuous function. Idea was to use the space of continuous functions, but maybe Hibbot's choice is better for this reference. So there is a natural measure on this boundary, the Bernoulli measure. Take the uniform distribution on the alphabet and take the Bernoulli measure. So anyway, this is the unique invariant measure for the action of the automorphism of the tree. And we can take therefore L2 of X omega of the. Of x omega of the boundary. And then there are natural isometries. So because if you take a letter x and look at this tree, it's isomorphic tree to the whole tree. And the isomorphism maps xw to w. So we have a natural homomorphism of this part of the boundary with the whole boundary. boundary just the shift and uh or other way around you have isomorphism induced by kind of creation operator which takes the whole space and pushes down functions to here. And this is a part of the tree boundary so this is so we get an isomorphism let's call it S and isometry from we get an We get natural isometry from the space of all functions on the boundary to the subspace of functions which are supported on this subtree. So I don't know how to denote it, but let's call it xh and we get hx support. Page X supported on X X omega, so on the space of the set of functions that are only on the that live only in this point. This map is not measure-preserving, it multiplies measure by a constant, so you have to take that into account when you write down the unit. Into account when you write down the isometry. But you'll get an isometry. As you scale the functions. Yes, just scale the functions. So the whole space is isometric to the subspace, but also the whole space is equal to the direct sum of these subspaces. So you get a self-similarity of the whole subspace with its direct sums. So you have these isometries, SX. S X and those. Now these isometries. So those are X at the same level or is it at all? Yeah, the same level. We fix level 1. Yes, okay. We're just trying to understand your notation. You take letters, the first level, and we get that the whole space is isomorphic to the direct sum. And yes, finite direct sum. Yes, finite x, huh? And these operators, now the group acts on this boundary, so we get a natural representation. I don't know how to note it. Unitary representation. And those recurrent relations that I wrote down, they are just some equalities between operators. Namely, the fact that Az. Namely, the fact that A0W is 1W is written as, I will omit the operator, the representation, letter, it just says that A as 0 is S1. So what is B of H? Bounded operators on the Hilbert space. So this becomes this equality of operators. This operator appends 0. A acts on the word. That's the same as just append 0. Word, that's the same as just a pending one. So A of 0W is 1W, so that's what it says. And A1W is 0AW. That says that AS1 is S0A. So these equalities become just equalities between operators. Now, but if we But if we now decompose the Hilbert space into this direct sum and look how A acts on the direct sum, then we'll precisely get those matrices. So when we identify, in other words, we have decomposition of x into the direct sum, and then we have identification of each of xx by that isomic. xx by that isometry SX with H. So you do these two things. First you decompose, then you identify these subspaces with H and then this becomes natural after those identifications. So this is an implication of why these metrics notation is natural. Of course there are interesting questions. Of course, there are interesting questions, like this was written for summer unity representation. We took the Hubert space. But what we just look at this abstractly, so we get a map from the group ring to the algebra of matrices, or that group ring. What are sister norms which agree with this map? Agree with this map. So, for which these norms on this ring this is continuous. And one can show that there is a maximal one, a unique maximal norm for which this is true, and there is a unique minimal norm for which this is true. This is sometimes one of those, but not always. And then one can try to understand spectra. You know, they're not the same. Sorry? You know the maximum of all them. Sorry? You know the maximum of all the length here? Not always the same, yeah. But in many cases, they are the same. For C is the same. And I think for this, it's the same. And then we can try to understand spectra of elements of this range and use this map to understand. map to understand the spectra, assuming that the norm that the map is continuous. So that will be a topic of some of the talks in this conference. Okay, now I want to talk about something called contracting loops. And for that, with every fin suppose now that f is finitely generated. Generated and fixed P positive number and consider the following procedure. Pick N, consider the vector of all those sections on the level N. So we look how the group acts on the level N and take the lengths of these group elements. The length with respect to the generating set. So we have some fine generating sets, so these elements are written as products, and we take the shortest decompositions. So we get some vector of lengths, some vector of natural numbers. Take the L P norm of this vector. So take some of these lengths. These lengths to the power t, mean xn, and then take, well, I am well aware that when p is present 1, this is not a norm, but I insist. Let's take this. Then, let's compare this with the length of g itself and then take Lim soup as length of G goes. As length of g goes to infinity, and then stake lim sup actually will be lim when n goes to infinity, and of course we can renormalize tea and renormalize teak n throughout of this. So we take the rate by which the LP norm decays when we go down the levels. Well, it might not decay, might be, this number might be greater than one, but like. Be greater than one, but like the rate, the exponential rate of behavior. And call it eta p. So the fact is that eta p is continuous and non-increasing. So this will be some continuous function on p for a fixed g. This will not depend on the generating set. This will depend only on the group action. And you get a continuous function. And we see that the group is contracting. That the group is contracting, well, together with the action. If, again, I can do the same for p equal to infinity, so then they take maximum here. If theta infinity is less than 1. Otherwise, theta is a finite number, always why can the numerator I don't know to explode? Oh, it's oh, data is a finite number. Yeah, it's not much, it's not much. Basically, if you do it for Basically, if you do it for to make it depending on G, it will be somewhat duplicative with respect to the group multiplication. So if it is fine for generators, it's bounded by maximum of this thing for the generators. So it will be okay, so if you have a contracting group, you have a continuous non-increasing function. By the way, I don't know if this is strictly decreasing or not, which is an interesting question. Reason or not, which is an interesting question. But in any case, there will be infimum of p for which it is less than one. We know that at infinity, at infinity is less than one when it is contracting. There will be infremum of those for which it is less than one. And we call it critical S1, not PC. This is an interesting invariant. It can be less than one. For example, for the famous Grigor Chu group. For example, for the famous Vigor Chu group, it is less than one, and it is exactly the number that appears in the uh in the growth estimate. Uh so if this number is less than one, then the group has sub-exponential growth. It's intermediate growth. Okay, so that's one interesting object which we don't really understand very well. So there are many examples of groups which you don't know what it is. There are some examples which you know. There are some examples of which we know what it is, but it's sort of new. Excuse me. Yeah. So if you say the word critical exponent, does it mean that there is a transfer operator in this definition? That's my question. Yeah. So, first question now, does this number, rather, I don't think that this number has exact meaning for those metrics? For those matrix recursions, but question like proposal for investigation, define a similar number for matrix recursions. So what I did here, it was purely in terms of length of group elements. So there must be a similar notion of LP contraction for those matrix recursions, which must manifest itself in the spectrum. So understanding something. Understanding something. So, in all those computational spectra where you have a renormalization and this map on the pencil of operators, there must be some number which is related to this critical exponent, and there must be an inequality. So, this either less always or greater than always that the number which is related to spectrum. But I have no idea what it would be. So, should we just consider the generators of the group instead of all the generators? Of the group instead of all the G elements? No. You have to use all the group elements. We just consider the generators. No, here. Well, maybe I was wrong about the month of activity, but I don't think you can. Well, maybe you can, but it doesn't really help much. No, no, I No, no, I was. I probably was. Yeah, the point is it is similar to the veritable. But this is the most important part. So the numbers that you get for the generators will be bad. You have to take long products to reach this limit. So yeah. What is index for eta on the bottom line? Infinity? Infinity, yes. But indefinite. Infinity, yes. But in definition, it's L within its peak. Yeah, P can be infinity. Definition is contract in this level. If L infinity is one, then it's contract. P can be infinity. I take T equal to infinity here, so that that will be maximum now, but not P equals infinity. Okay, now here is another number. Maybe even more interesting, but again, maybe the most interesting one will be related to spectra, but that's something that we don't know yet. So another number. So if you have a contracting group now, and there is a hyperbolic graph, namely, so remember on the tree where The tree where the group acted, V was connected to VX. Now, what we do, we connect V to X V. So we'll get a different tree. And then on every level, we connect W to S of W, where S runs through the generators. So on every level, we draw how the generators act on that level and reconnect the words. And reconnect the words using this rule. So, for example, for that binary odometer, so for adding one, this graph will look like this. And so on. So So you see that now this is not action on the virtomorphisms on this tree, because the action on the virtomorphism was for this tree. Here we'll get some different tree, but it would be nicer. In fact, it would play Gromov hyperbolic. And there would be boundary of this gromo-hyperbolic graph. And that geometry of that boundary is what I'm interested in. But I want to define something called control. So, I want to define something called conformal dimension of the boundary, and I will do it using a characterization by Bourdon and Kleiner. So, let's take a gromo-hyperbolic graph. So, in this case, the boundary is the circle, for example. And so we take this set of vertices and consider, again, we fix some p, this time greater than or equal. Some p, this time greater than or equal to 1, greater than 1. And consider the following algebra. A p, we take all functions on the boundary of this graph, so on the hyperbolic boundary, which can be continuously extended onto the graph. So functions f on the boundary of this graph, called gamma, such that there exists Such that there exists a continuous extension to x star, so to the set of vertices. And let's denote this extension by f tilde, such that the gradient of this extension is L T summable. Gradient meaning you take the differences between values of the edges, and that's your And that's your function on the edges, and this function on the edges must be a P sum. So, sum over all generators and all sum of all generators of difference between f and values at f and s of f to power p plus sum over all letters f tilde w and f tilde x. And f tilde xw, the power t must be finite. This is the algebra, the sub-algebra of the algebra of continuous function functions. And when you increase p, the algebra increases. So you'll get an increasing sequence with p, you get an increasing sequence of algebras, and there will be a moment when these algebras Be a moment when these algebras are dense in the space of all algebras. So the note consider the infimum of those p for which a p is dense in the algebra of all continuous functions. In other words, with the normal with yeah, with the uh with the max norm. In other words, you take the P, those P which distinguish points. So for which any two points can be distinguished by function. So this infinum is, by Bordanis and Kleiner's result, is the conformal dimension. So correct I force regular conformal dimension of this function. Of this part. You can use this as a definition. Maybe it's kind of making one more natural. And we will denote this then of this group. Not of the group, but of the action, of course. It depends on the action. So first theorem P C is less than or equal to C. So that critical contraction. Critical contraction exponent is less than a conformal limit. It's an interesting question to understand when this is equality and when this is shock. There are examples of both. So those two examples that I mentioned in the beginning, for them both numbers are equal to one. So that's the case of equality. For the Grigor 2 group, this is 1. This is less than 1. So there is this situation of Is this a situation of drop of dimension? Okay, there are some people in conformal dynamics here, so I will mention something related to Soson's theorem. And so we can, there is a way of estimating this number from below using something called, well, some map, some linear maps appear in the famous Thurson's theorem. In the famous Thurson's theorem. Namely, take an element of G of infinite order and take conjugacy classes, set of conjugacy classes of such elements. And let's take linear, form a linear span of those conjugacy classes. And then there is the following map. So if you take an element G, it will act in some way. It will act in some way on the first level. Take the cycles of the action. For example, here length is 3. Take then G cube, this is for example X, and take section of G cube at X and take this congestive class. Or in other words, take the section in all these three letters and then multiply them. So this will be the same, you'll get the same So, this will be the same, you'll get the same contributor class whether you do it for this, for this, or for this. And same, you can do the same here, just square section at one. And then for the value p, you do the following map. You map g to, in this case, I hope I remember correctly, one-third to power t minus one times the result. times the result plus one half to t minus one times the result so each time you take the degree the length of the cycle raised to power one minus p times the the conjugacy class of this section and add them through all through these through these and we call it the first and map for p so this is a map on the linear span of these Map on the linear span of these conjugacy classes. Take some finite-dimensional invariant subspace, and the theorem is that, well, not the theorem, just observation, that if eta t is less than 1, then the spectral radius of TP on every single radius of the radius of dp on every invariant finite dimensional subspace is less than enough. That's easy. But the observation is that you can use something which you can call therson substructions to bound CPC from below by exhibiting some invariant subspaces and computing the spectral radius. In the spectral radius. And this bounds below this number, and hence also this number. That's something known in holomorphic dynamics that you can bound to control what they mentioned within third-sense obstructions. You're saying P C is bounded below by the spectral radius of the T P? Yes. But spectral radius on every on all five-dimensional subspaces. Sorry, no. Sorry, no, not for spectral radius. P C is bounded below by that P for which all spectral radii are less than 1. We are varying P, and P is nonlinear variable. It appears as a power in the matrix of this linear. So once you find that P, you're going to follow. Yes. Yes. A little bit more complex. Okay, now I. Okay, now I haven't started talking about the words in the title of my talk. So I think. How much time do I have? Five more minutes. Five more minutes. We'll leave a few minutes for questions. Okay, then I can at least formulate the theorem. So, what is the relation between random walks and this business? So, here, There's business. So here, AT is about LP gradient. And when you study random walks on graphs and want to know what is probability that after you are in this place you visit for the first time another place without returning to your original place, that's related to something called capacity. Related to something called capacity, and that capacity is infimum of this type of expressions in the case of t equal to 2. So now you shouldn't be surprised that 2 in relation to control dimension is important for random books. So what is that? So suppose we have a group G, and let's take mu a measure Measure on G, a probability measure. And let's assume that it's symmetric, so G is discrete. So meaning that measure of element is equal to the measure of its ingress. And then we have the random walk. So meaning that we sample, we take g1, g2, g3, and so on, gn, that each gi is independent random variable. Random variable distributed according to new. So we take a product, that's a new random variable, and with add, get this random variable. So that's the random walk. And okay, so So, don't want to define person boundary. So, I define luvi. Anyway, so I will define like n wavy way. So, you have this random random walk. So, maybe it was unfortunate you wanted to. So, S1, S2, S3, Sn, and SDN you this end me this element. So you have this sequence g1, g2, g3, and so on. So you have this infinite sample path. Now let's identify two sample paths if they agree except for some beginning. So starting from some place they are the same. So this identification is not well behaved with respect to the sigma algebra of events. Events, let's take the smallest sigma algebra which does this identification. So we get some probability space, and that's called the Poisson bar. So you have to use different notations for increments and for sample paths. Yeah, that's nice. Those on the next slide. So this is the sample one. This is the sample one. The sample. So, in other words, so we're interested in the case when Poisson's boundary is trivial, meaning that there are no events which take no measurable events at infinity. So, informal. Another definition is that there are no bounded harmonic functions, they are non-constant. So, a function f on g is called harmonic if If a value at an element is equal to the average at according to mu and not having events at infinity, non-trivial events at infinity is equivalent to the condition that every bounded harmonic function is constant. Okay, and being Louville under some conditions of the measure implies that the group is amenable. And that's a question which interests many people. So let me now formulate the main theorem. Fullodia being viewed as the property of the random wall? Yes, of radio. It's a property of random. But it has con consequences for the group. Consequences for the group. So let G be a contracting self-similar group such that the conformal dimension, yeah, this is the joint result with Jenny Jeng and Nicolas Markov. Subject conformal dimensions stick to less than two. And as I said, this is important because this has interesting consequences for the random walks on the graphs because it's related to capacity according to that Buddha-Kreiner result. But it's easier than that, Buddha-Kreiner result. Let mu be a symmetric measure. On G such that so-called peace moment, so you take a measure of elements raised to power t is finite for some t greater than t critical that you define. In particular, yeah, then the random Then the random walk generated by mu is unit. In particular, if you take finitely supported measures, so for example uniform measure in the generating set, then this is automatically true, then that random walk will be lube. And that implies that such groups are amenable. In particular, it implies, I didn't have time to define what it is, but many of you know it. If the Julia set of a post-critically finite rational function Finite rational function is not the whole sphere, then the equated Modamic group is amino. More than that, not just amino group, but sluvable for any measure of uh say that has finite second moment. Okay, that's all for Okay, that's all. Thank you. Any questions you could have? Very nice number. I enjoy it. The condition you put on the spectral reuse less than one was TP with very subspace is finite dimension. We find this proof of a theory by Jacob Rota in 1960 saying that people. 60 saying that keeper space, any contraction that has spectacular less than one, is similar to the construction of the pensal space of the unilateral shift, the adjoint of unilateral shift tensor one, so either part of this t. So this is model theory. Every contraction with expected rate less than one can be modeled as a restriction on that operating term in the state. What have any connections? How many connections we have? Is the way you were describing this and the way you're... Yeah, that's the shift is important here, so it might be. Yes, I'm correct. Any other questions? Just to remind us, sir, Miuville meant the Poisson boundary was empty? Trivial. By one point. Trivial. Yeah, yeah. So har space of harmonic functions space of harmonic functions is the space of what? Bounded functions on the with L infinity on the on the Poisson boundary. So having no non-concept means that it's just one point. Hardest part of this to show some contracting group is amenable. Showing that the That the conformal dimension is less than two. Sometimes it's easy, like in this case, not very easy. It's a theorem of McMullen that in this case the conformal dimension of the Council dimension of the GV set is less than two. Not very hard, but it's not really observed by Mahala. But in any particular case, you can prove that Hausa dimension is less than two just by estimating. Just by estimating some derivative derivatives, it's not in particular cases. Yeah, that's another definition with the definition of conformal dimension. That there is some class of metrics, natural class of metrics on the limit space, conformal metrics, and conformal dimensions, the infinomal house of dimensions of house metrics. And say usual metric on the dual set, usual spherical metric. Usual spherical metric is a representative in that class. So that gives you an evidence that it's less than two. But it's not equal. Let's say for all polynomials, the conformal dimension is equal to one. So the household dimension can be speed one at one. 