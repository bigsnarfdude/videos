Okay, thanks a lot. Thanks for the invite. Too bad I can't be there in person. Hope to see you soon in person. So the work I want to talk about today, it's joint work with my postdoc, Tommaso Rossati, who is also here at Imperial. It's sort of work in progress. So some of what I'm going to do, well, I'm going to sort of make clear which bits are Clear which bits are actual theorems where we have a proof from A to Z, and which bits we strongly believe that we can prove it, but haven't worked out all the details yet. The motivation is, well, I mean, some of you were probably at the previous workshop that was organized about a year ago by the same group. By the same group, and at the time, in that previous workshop, I talked about the joint work with Michele Cottizilate. And the motivation for both of them is the same, but then the toy models we look at go in some sense into orthogonal directions in a way. So the motivation is the following, right? So that's the motivation. So is you take something like 2D stochastic Navier-Stokes on the Taurus. Stochastic Navier-Stokes on a torus. So you take 2D stochastic Navier-Stokes on a two-dimensional torus. And now you imagine that you actually force it with a forcing that's periodic, but that's periodic with half the period. So that's your forcing, forcing which is periodic, say, half the period. And then you ask yourself: does that process have a unique invariant measure? So we have that old result with Jonathan, where we show that if we restrict ourselves to functions that are periodic with the same period as the forcing, then we know that we have a unique invariant measure. But right, so then the question is uniqueness. Uniqueness of invariant measure and right, so we restrict if we start with an initial condition that also has a period, you know, has this half the period kind of period, then that remains the case for all times. And we know that we have a unique invariant measure in that space. But of course, then the question is: what is that invariant measure stable? Right? So if you start with. Stable, right? So, if you start with a generic initial condition, which might have some component here that has really the large period and not the smaller period, then does that component die out over time or does it actually remain of sort of order one? And you might imagine that you have sort of a second invariant measure. And the conjecture here, right, is that so the conjecture. So the conjecture would be that the uniqueness at say large viscosity. So that's actually a theorem from a long time ago. I guess that's a theorem by Jonathan from the late 90s. So one has uniqueness at large viscosity, but then the conjecture of it is that one has not. Conjecture of it is that one has non-uniqueness at small viscosity, or if you want large Reynolds number. And so that's the interesting case. So the interesting case here is this bit is to show that if you take such a system and you make the viscosity small or the Reynolds number large. Small or the Reynolds number large, then you actually have like a phase transition, right? So you actually go from uniqueness to non-uniqueness of the invariant measure. If you want, there's a sort of bifurcation where at high viscosity, you have a uniqueness, you have a unique invariant measure which is stable in a way, and then it becomes unstable at small viscosity. And there's additional invariant measures that kind of branch out. And so in that work with So, in that work with Michele, which I talked about last time, we used sort of a low-dimensional toy model. So, we basically took the Lorentz, the model of the Lorentz, the regular sort of Lorentz attractor, and we put noise in one of the components. And that had retained certain features of this system here, right? So, in particular, the feature of having a quadratic nonlinearity and having a one-dimensional. And having a one-dimensional linear subspace which is stable under dynamic, on which you have an invariant measure. And for that system, we were able to prove precisely that conjecture. So we were able to prove that in that particular case, one-dimensional sort of invariant subspace on which you always have a unique invariant measure, then that invariant measure is the unique invariant measure for the full system for some values of the parameters. For some values of the parameters, and you have an additional invariant measure for other values of the parameters. And the main ingredient, if you want, in our analysis at the time was a sort of quantitative control on the sort of Lyapunov exponent of the linearized dynamic around the Dynamic around the invariant subspace. And so, what we want to do here in this work with Tomazzo is we wanted to study that in the infinite dimensional case. So, the work with Michele was a finite dimensional sort of toy model. And so now the work with Tommaso that I'm talking about. Tomaso, that I'm talking about, is going to be an infinite-dimensional toy model of a linear dynamic, which one should think of as sort of like the linearization of this one around the subspace of functions that are periodic with half the period. So that's the sort of thing we have in mind. But then our time model, in some sense, we look at a somewhat arbitrary linear dynamic of that. Dynamic of that type. I mean, not arbitrary. I mean, yeah, I mean, like we fix one. So it's not like we have a general result, but the one that we fix is not the Navier-Stokes dynamic, but it has somewhat similar features. In particular, we remove some of the features that one doesn't see in the Navier-Stokes dynamic. Dynamic. And so then the question is: if you have a sort of linear stochastic dynamic and you project yourself onto the space of norm one element, right? So if you have a linear dynamic, then very often what would happen is you wouldn't really have an invariant measure because what happens is that things either go to zero or the norm somehow blows up. And so if you want to actually have You want to actually have something like an invariant measure, you want to actually project onto the sphere and then look at the dynamic on the sphere. So the toy model that we are looking at for this linearized dynamic is that we look at dtu equal to minus minus Laplacian AU. function A U plus U D W or U D W D T if you want where now this is on the torus on the d-dimensional torus so u goes from so time is positive times d-dimensional torus say to R and this noise here is Here is white in time, time smooth in space, and it is stationary in space. So basically, think of just forcing Fourier modes independently and we assume that That it's non-degenerate on the Fourier modes with, say, wave number less or equal to three. That's sort of a technical thing, but we need a little bit some non-degeneracy of the forcing. But it's not a sort of hyperelliptic type result. Okay, and so then the question is: you take a model. is you take a model of this type. So the reason why we look at here not just Laplacian but Laplacian to the power a and we actually take a here bigger than one, we can do equal to one, doesn't really matter. So a larger is more interest is interesting in the sense that you don't have a maximum principle, right? So there are existing results of the type of what I'm going to talk about if you have a maximum principle and they use very, very Maximum principle, and they use very, very strongly monotonicity and the maximum principle. And that, of course, you wouldn't have it for Navier-Stokes, right? So in the case of Navier-Stokes, you would have the Laplacian here, but it would be vector-valued and you would have a Stokes operator. And so you wouldn't have the maximum principle either. So that's the reason why we put this A here. It's really just to destroy the maximum principle to make the point that we don't exploit the maximum principle at all. So, this is obviously linear, this dynamic, right? So, if I multiply u by some real number, then that's still going to be a solution to the equation. And so, the interesting bit is to look at pi t, which I define as being u t divided by the L2 norm of ut. Okay, so if you want to project onto the Project you onto the unit sphere in your L2 space. And then the question is: do you have some kind of quantitative erodicity for IT? Okay, so in particular, do you have like the spectrum? So, in particular, do you have like the spectra gap, for example? And the claim is that you do. We don't have a full, so that's the bit where this is work in progress. We don't have a complete proof that you have a spectral gap. We strongly believe it. And we have a proof of a statement that is about, you know, two-thirds of the way down. Okay, so what is the right, and so let me just mention, right? So there is a Just mention right, so there is a recent result by Davakrishnevison and co-authors where they do actually have a somewhat quantitative algorithmistic result for process of that type, but with A equal one, and they strongly exploit monotonicity and the maximum principle. Okay, and so here we go in terms of the way we approach the problem is going to be completely different from what they did at the time. From what they did at the time. So the problem here, of course, is that, so the difficult, one difficulty, if you want to difficulty, is that the deterministic dynamic has infinitely many. Many fixed points, right? Because every eigenvector of the linear operator is a fixed point of the linear dynamic. So if you don't have the noise here, then the eigenvectors of the linear operator just remain, they just get multiplied by something, but then that something just gets projected out. And so all the eigenvectors. And so, all the eigenvectors for the linear operator here are fixed points of the deterministic dynamic. Okay, so you have lots of fixed points that you need to show sort of destroyed if you want under the addition of noise. So, in that sense, it's very different, even though it looks, it is a parabolic equation, right? But the behavior is very different from what we're used to if you look at sort of say. If you look at sort of semi-linear parabolic problems, where typically the deterministic dynamic has a sort of finite-dimensional attractor or something. Right here, you don't have a finite dimensional attractor because you have infinitely many fixed points. And they are all sort of at distance one of each other because you have an orthonormal basis of eigenfunctions, and every point in that orthonormal basis is a fixed point. Okay. Okay, and so how do we control the dynamic then? Okay, so what we want to do is we essentially want to build, we want to have some sort of control, we want exponential ergodicity, so the main ingredient is to have some kind of Lyapunov function. And so the question is here, what would be the right sort of Lyapunov function? So normally the kind of Lyapunov function. So, normally the kind of Yapunov function you look at is maybe some kind of power of a Sovolef norm or something like that, or maybe exponential of a Sovolef norm or that sort of thing, which behaves kind of nicely under the deterministic dynamic. But as we said here, if you take any sort of Sovolev norm or something under the deterministic dynamic, it doesn't necessarily get improved, right? Because, again, because of every eigenvector. Because every eigenvector is a fixed point. So, what we do is the following. So, let me sort of draw a picture. So, that's now in Fourier space. Okay, so let's say we're in two dimensions. So, you have k1, k2. And the eigenvectors are sort of indexed by elements of this integer grid. This integer grid. And so now what we do is given you, so you have a certain amount of energy that sits on each of these modes. And so what you do now is you find like d value of n, right? So you write, say, m of u to be the To be the smallest M such that if I project U onto the eigenvalues with value bigger than M, this projection is less than in L2 to projection onto the eigenmodes with value less than m, with k less than m. Less than m with k less than m. Okay, so here, if you want that circle here, that would be k equal to m, right? And you should think of here to have sort of like pi m minus is the projection onto all of the modes that are here and pi m plus. Pi m plus is the projection onto all of the modes that are here. And if I put m, right? So if I make m very large, then at some point, most of the mass is going to be, you know, at some point the pi m minus u is going to be bigger in L2 than the pi m plus. And so you look at the first time where this happens. And so you call this m of u. And so the m of u is basically. The M of U is basically such that about half of the L2 norm is here, and half of the L2 norm sort of sits in lower modes, and about half of the L2 norm sits in the higher modes. And now what we want to show is that basically this M, M of U, you want some sort of tightness result for M of U, right? M of U T. You want to show that under the dynamic, You want to show that under the dynamic, if you look at the dynamic of this m of u, if u solves that equation, right? So m of u, of course, depends only on the projection of u onto the sphere, because this obviously is sort of homogeneous. So under the projected dynamic, you want to show that m of u actually has a tendency of decreasing up to a point, and then you have some kind of tightness. And then you have some kind of titans, which is obviously, it has to exploit the noise somewhere, because that would not be true if you didn't have the noise on your dynamic. And then another bit that's going to be also useful is I'm going to define a norm u say ms square is the sum of k. Of k minus m plus 2s u k squared. So this is basically Sobolev norm. It's essentially the Hs norm, except that instead of having a k to the 2s, you look at only, you know, it's like k minus n to the 2s. You essentially, so it's a semi-norm, right? So you essentially ignore these guys. So the plus here means that you make it zero if that quantity is negative. So it's like a So it's like a Sovolef norm, but these guys are norm zero, and in some sense, your weight here only starts taking effect from this level M onwards. And then what we believe is that if you look at the exponential of m plus u square, and that u square where the m here is Square, where the m here is really the m of u, not a fixed value of m. So this is rather non-linear sort of functional. Then we believe that this is actually a Lyapunov function for this system. But what we can turn into a theorem so far is some form of tightness. So the theorem is that there exists a There exists an increasing sequence of stopping times Ti such that if I look at the expectation of the exponential of m of u t i plus 1 conditioned on f t i then this is smaller than constant. Then this is smaller than constant e to the m u of t i. Well, indicator function m t i, if you want, is bigger than k, plus some big value indicator function of the opposite, sort of m less than k. And this constant here, we can make it as small as we want. So this constant is less than one, that's the point, in order to get something like a Lyapunov function. Like a Lyapunov function, but we can actually make it as small as we want by fiddling around with things a little bit. And plus, we also have good control over the sort of interval between successive stopping times. So you have this sequence. So these are not deterministic times, they are stopping times. But we have a pretty good control in the sense that we know that the time it takes for one of these. The time it takes from one of these stopping times to the next is, if you want, not too big and not too small. So you have exponential tails from above, but you also have sort of exponential tails from below in the sense that like you have bounds on the moments of the exponential of the difference between the stopping times, but you also have bounds on the moments of like exponential to some negative power of these stopping times. Okay, so you have pretty good control that they don't get too big and they don't get too. They don't get too big and they don't get too small. And so, you know, so that allows you, in principle, to turn this into the more usual kind of tightness statements. Okay, so that's, so why is this a reasonable thing to look at, right? Because showing that these guys are tight, right? So showing that this quantity tends to decrease, right? So on average, it decreases by this constant less than once. So it tells you that actually, on average, the mass of your solution does sort of tend to concentrate into the lower modes as you would expect. But again, this is not true if you don't have the noise, right? Because we're looking at the projective dynamics. Okay, so for the projective dynamics, it's not true that if you just look at this equation here, That if you just look at this equation here, things concentrate into the low modes because if everything is concentrated in one mode, it just stays there. But if you have the noise, then we claim that this is true and actually the noise helps. So I think I've got five minutes left, so I'm just going to tell you what's the main idea in the proof. And so the main idea, right? So the thing is, you have to battle against. The thing is, you have to battle against the deterministic part. So, some of the deterministic part helps because you know that if, right, if at some time the value of m is something, something like here, and then say, so that tells you that about half the mass is here and about half the mass is here, right? But then you also know that the eigenvalues of the linear part of the operator are much bigger here. Of the operator, they are much bigger here than they are here. In this region, the eigenvalues are big, and in this region, the eigenvalues are sort of smallish. And what we're going to do is we're going to take some sort of a buffer zone. So we take actually like an order one region here as some sort of buffer zone. And say, if you knew that, say, there's, for example, no mass at all in the buffer zone, right? Then you essentially know that the energy. The energy that's here actually decreases quite a lot, whereas the energy that's here doesn't decrease as fast. And therefore, you would expect that after a later time, there's much more energy in that bit than in that bit. And therefore, you would think that the M, right, the M is sort of the point that separates the energy such that there's about half of it, which is above and about half of it below. About half of it below, you'll think that the m sort of decreases, right? But you have to make that qualitative because it might be that sort of like all the energy that sits below is sort of concentrated very close to this M and so even if you know the energy here sort of decreases and the energy here increases, then maybe after a while sort of all the energy is here, but that still hasn't actually made. Is here, but that still hasn't actually made the end move very much. So you have to sort of battle, if you want, the concentration of energy in sort of two narrow energy shells. Okay, so if the energy is concentrated in sort of narrow shells, then this is a problem because the deterministic dynamic would just leave it there. And so And so this quantity n wouldn't actually move, right? And so, what we do is we introduce a notion, right? So we define, so we say, say, say, U is concentrated if so, say now. So, say now I have like three regions, okay, because we introduced this buffer zone. So, say from now on, pi m plus is actually the projections onto the mode that are above the upper region of the buffer zone. Pi M minus is the one above. And in the buffer zone, I call it, say, pi m zero. Okay, so now I have three regions. And you say that u is concentrated if If the energy that's in the buffer zone is bigger than, say, a quarter of pi minus, and it's diluted otherwise. Okay. And it's diluted. And so, then, what we want to do is we want to. What we want to do is we want to essentially treat the concentrated case and the diluted case differently. And so, in the diluted case, in some sense, it's not that difficult to convince yourself that something along these lines should be true. And that's basically because, well, it depends on how exactly you define the M and so on. But essentially, in the diluted case, you guarantee that because of this effect. Because of this effect, that the energy that's in here tends to go down, and the energy that's in here tends to go up. In the diluted case, that's sufficient to sort of guarantee that that value of m moves down a little bit. And the problem is the concentrated case. And so, in the concentrated case, we really need to exploit the noisy part of the dynamic. Of the noisy part of the dynamic. So, in the concentrated case, we actually what we need to exploit is that with high probability, even if all the energy is, say, concentrated in this little buffer zone, then with high probability, because of the presence of noise, some of the energy is actually going to leak out both into sort of this minus region and into this plus region. Region. And then, once enough of energy has kind of leaked out, then we can exploit the fact again that there is a sort of gap in the spectrum between this region and this region, which sort of has this effect that if you want the energy that's here is actually going to grow exponentially fast relative to the energy that's here, then again, that's sufficient to some extent. That's sufficient to some extent sort of you know get the value of n slightly down. Um, and the uh, yeah, so I think I mean that's somehow in like a super nutshell. Um, that's the mechanism that we exploit. Okay. And from a technical point of view, the main problem is to actually, well, the main problem is to actually figure out of how what Find a way of how to actually exploit that mechanism. And also, sort of, as you, in order to exploit it, what you really need is sort of good control on these type of quantities. And so, you know, from a technical point of view, there's quite a lot of work that goes into controlling these type of quantities. But I think I stop here since my time is. Stop here since my time is up and let's go to questions. Thanks for your attention.