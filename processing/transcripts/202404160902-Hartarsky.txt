So today we'll be about lower bounds. I should start by saying, pointing out that in general when you listen to a talk on booster population quite frequently it's a bit misleading. And this was visible from yesterday. So we had four talks. Three of them did not say anything about lower bounds. And the fourth one, Rekas, was saying things about the lower bounds. Was saying things about the lower bounds because the upper bound was completely proving that if you are not in rotor, you have PC equals zero, it's basically immediate. So that's why she was talking about lower bounds. But in general, we tend to focus on the upper bound when we give talks because it's just much more intuitive. That's where the intuition is, but the difficult part is the lower bound. So as a result, So, as a result, today we will work more and prove less. So, let's do that. Let me remind you: we are working with Provoze Footstrap Recreation, which was at four rules: this one, this one, this one, and And this one. And we were interested in the infection time of the origin under the product Vernouli measure, the commander. So lower bounds means we want to prove things like We want to prove things like the probability that this is larger than something goes to 1 as p goes to 0. Right, so this is what we will do and we'll go there slowly. So we'll start with some things which are priority are just analyzing how the process behaves. And then we will eventually have enough background on the process. Enough background on the process to do this kind of thing. So, a very important thing about booster population is what we call the rectangle process. So, the rectangle process, I first needed a little definition of what the clue. Of what the closure is. It's almost self-explanatory, but given a set A of you interpret this as initial infections, the closure, which I denote by square brackets A is the set The set of all sides which become equations textbooks. Okay, so this is the closure. It's pretty clear why it's useful. Now, having stated the closure, I can state the rectangles process lemma. So it tells us how we can find the closure in a more useful way. Uh in a more useful way. So, given uh fix A we can find a closure as follows by the following process. So, we define a collection of rectangles. So, start with singleton rectangles for each point. Okay, I will also make a picture just after it. And at each step, so these steps don't have much to do with the time of the process. Theratively, we place two rectangles in the collections. In the collections, in the collection by the smallest distance at most one by the smallest Rectangle containing both. I'll leave a little bit of space, but here's an example of this stuff, but Nice. Good. So, okay, that was true. So, how does this rectangle process proceed? We start with these little rectangles. Say one by one today. One by one today, and we keep merging. So, importantly, the order and choices that we make don't matter. So, in the sense, now I need to pick two rectangles that are at distance at most one. I have lots of them. I can pick these two, for example. So, I replace them with this rectangle. Then maybe I do it here. Then maybe I take this now slightly bigger rectangle than this one. So, now this gives me this bigger. This bigger one, maybe I do it here. Bigger rectangle, maybe this one comes like this. This is fine. So now I have even rectangles that distance zero. One is included in the other, so I basically just remove this one. And so on and so forth. So let me finish it quickly. This, this, this guy, okay, then I merge with this one big thing. And in the end, I get just everything. Okay? So this way of finding the closure is extremely useful, specific to some models. But this one is one of them. So, okay, proof. Okay, proof. I did a proof by picture. You can do a proof by induction. So by induction, you prove that the collection of rectangles, indeed, the union of the collection of rectangles does get infected. So this is in the initial state, it's obvious by definition. And then if you take two rectangles that Take two rectangles that are a distance one, so either they intersect or like this. You need to check that they do infect this entire thing. Okay, and then the last thing that you need to check, so this will tell you that the final collection of rectangles gets infected. You need to check that nothing else does. And indeed, if you have a collection of rectangles that are at distance at least. But are a distance at least two apart, well, nothing else happens. For this model, even if they touch diagonally, nothing happens. Yes, so this is what you mentioned. This is distance two, and nothing happens. So this guy will not get infected, it will not yet. Alright, so this is our rectangle. Alright, so this is our rectangles process. Next, I need a. Is this clear, right? So, next definition. Internal filling. So, this is also quite a natural notion. A rectangle Uh a rectangle R is internally filled uh if this will occur several times. That's like so if the infections inside of it uh give the rectangle itself. Okay, so uh this is Okay, so uh this is quite a crucial property to have and uh this will become immediately relevant before I state the lemma. Let me also say uh R1 and R2 are disjointly internally filled if um There exists A1 and A2 included in A, disjoint such that A1 is good enough to internally fill R1 and the same for A2. For day two. So, if you know what this joint occurrence of events means, this is just an instance of that. If you don't, think this is a different. So, you've sort of subtly changed what A is between these two things. Here it was just a general set, sort of, but now you're thinking of it as the initially. Thank you for that. Also, I forgot here to mention the order and blah blah don't matter if A is finite. Okay, so here A was an arbitrary set. Here we're thinking that and you can't think of it as an arbitrary set, but we are thinking of it But we are thinking of it better as the random P, mixed P random initial collection. Okay, so why is this of any relevance? At any given time, any stage of the rectangles process. The rectangles process all rectangles are disjointly internally felt. Okay, so proof. Uh by induction. Not hard, so let's take a look quickly. What am I doing at each step? Okay, I assume by induction that it's true at some point. In the initial condition, in the initial stage, it's true. I'm merging to. I'm merging two rectangles which are disjointly internally filled. This is by the hypothesis. We just discussed that this will indeed make this rectangle internally filled only using the corresponding A1 and A2 here and here. That's enough because it produces the two rectangles, and the two rectangles produce the big thing. So this tells us that indeed things will be internally. Tells us that indeed things will be internally filled. And the disjointly internally filled is also clear because I just take for A the set. Let me call this R3. The result of merging, this one is R2. This one is R1. So for A3, you just take A1 union A2, which is Gate, which is sufficient to produce the big one, and it's destroyed from the others or other rectangles like these ones. So it's an easy mess. Let me not spend more time on that. So, so far, so good. So, this is uh the this uh rectangles process is extremely useful uh and it will allow us to prove uh a very important lemma. A very important lemma, which is known as the Eisenman-Lebowitz lemma. Actually, they did prove it, so for once it's named after the right people, I think. You can see the statement, but I think that's a good idea. Okay, so they promote the following thing. Let K be an integer, let's say, R rectangle if the semi-pyrameter of R, which I will denote like this. Semi-parameter input K then and R is internally filled then there exists There exists R prime contained in R rectangle such that so firstly R prime is internally filled and the semi-perimeter of R prime is between K and 2K. So just for history for a question, did they actually look at Frober's process or did you understand that process and its process? What happens on the rectangle structure like this? That is correct. What happens on the rectangle structures like this in the armo cho? So, in the normal to neighborhood population, okay, let's see what changes. This does not change here. But those are the things we're going to feel now, right? Those that are touched just in the diagonal. Yes, yes. So, no, sir. Here, the only thing that changes is this one becomes a two. Okay. I mean, this two doesn't help. I mean, it's I mean, if a distance that could be like this, there are two things, and they don't. I changed today. Okay, so this let's say it's just instant. Oh, okay. Okay, so for two neighbor you just replace this by this plus one And also for the Eisen-Liebrewitz lemma you don't need the second lemma, right? I mean that's it that was just follows I'll use it a bit later. Yes, so but back to Naver, this part, this definition is still the same. This part, sorry, this is the definition. Sorry, this is the definition. This is the same, the proof is the same, this lemma is the same, and this proof is the same. Are two factors one or something? They are the models. We want to see actual proof of that. Right. So let's actually prove so the proof is So the proof is follows a rectangular process and it uses just this one observation to make that in this picture this is R3 that is obtained by merging R1 and R2 claim phi of Phi of R3 is upper bounded by phi of R1 plus Phi of R2. Okay, so this claim is for rectangles really not hard to check, but it has a very nice proof that I don't know where it's called. You can ask him about it. But anyway, I won't explain why it's true because we really don't care about the constant 2 here. About the constant two here. And if I allow you a constant five, I'm sure that you are convinced. Okay, so then this two will become a ten or whatever, but it will be fine for our purpose. But this is true even without the five. Okay, so this disability is nice, but we don't really need it very strictly. So, how do So, how does this help you? It tells you that at each step in the rectangles process, you want to follow the largest semi-perimeter of a rectangle. What can it do? Well, it will increase, and it can increase at most twice or ten times at each step. So, it will not jump from below k to above 2k or 10k. That's uh that factor. Alright, so this was not hard to prove, but it's extremely useful. Why is it useful? What does this tell us, basically? It tells us that if we have, if something happens, there is some internally field rectangle, then we can extract another rectangle of the desired size. This parameter k is completely free. We choose. Free, we choose so it just needs to be smaller than to start with. But apart from that, it's anything we like, and we get exactly the size we want up to this factor two. It will not bother us much. Okay, so this is all the preparation I needed. Any questions of myself? Okay, so with this, we can prove a course threshold. So, this is what Eisenman and Leibowitz did. So, this is the other part of the result. So, there exists an example that we can make explicit in the end such that the probability that the infection time is larger than or equal to. Infection time is larger than or equal to exponential sine over P goes to 1 as P goes to this. Okay, so proof the okay, so assume zero Zero gets uh let me call this T, but I don't rewrite it. Assume that this happens. So then by the rectangles process, this tells us how we can identify the closure. And it's a certain union of rectangles. So if the origin gets infected, So if the origin gets infected before time t, this is clearly not helped by anything that is further away than t. The process is local. So I'll draw a picture. Here I will have the box minus t. Here's the origin, square box. Then the origin should belong to the closure of the set random set of invections. Random set of invections intersected with this minus tt squared. Okay, this is this is clear if this happens we have one of two things. We start thinking: how could it be that the origin gets infected? Option one, I'll actually go a bit faster, but option one, the origin is just initial. Think of, um I'll go a bit faster, okay. Uh option one, there is an infection supercosin. Uh Superclosure. Distance between set A and the origin is less than A. So in this proof I'll put a number of strange numbers. This is just to point out that we really don't care about. There's just one thing that will work and I'll point it out. The rest is very, very pricey. Okay, so this will handle very easily. Or There exists a rectangle containing the origin. The rectangle is contained in minus tt squared. It's internally filled. Yes, yes, yes, yes. Maybe I should okay. A is the Is this internally filled? Yes, but A is the P P random reserve functions. Yes, so this is internally filled and if there's no infection around the origin, then this R should at least be a little bit big. So this is just a teeny tiny box around the origin. We have protected infection, so we should go out of that. Okay. Probability of case one. One is clearly at most one thousand D. 1000 E, which goes to zero S P goes. So this is the easier part. Assume I, sorry, 2. Then we consider two cases. Case 1, which I'll start with the important case, then there's the unimportant case. Then there's the unimportant case. So assume that the center terminal of this rectangle R, the origin is in some determinative field rectangle R. My question is, how big is it? Option one is pretty big. Let's say other than p to minus three. This whole proof will be for p small enough. This is a big number. Is a big number and this three is not important. Okay, so then what can we do? Then we use our Eisenman-Lebowitz level. We got our big rectangle. We can extract any size we want up to this one. And now we need to make a crucial choice by the Eisenhower month. There exists R prime, let's say, contained in, for how far, sorry, contained in R, and I'll even say that it's contained in minus Tt squared, such that it's internally filled. And its semi-perimeter is between so this 2 and this 4 will not be important, but the 1 over p is. We need to, this you can figure out. You just do the reasoning and then optimize. These are not the optimal constants, they just make it very simple. But crucially, we choose this. But crucially, we choose this so-called critical size one over you will see why it's wrong Okay, so R5 is even a subset of R, right? Yes, okay, so now we want to bound the probability of such an R prime or such R prime we have We have the probability R prime is internally filled is at most something. So here I will use what I will call later the traversability bound, which is a very simple observation. So in order for some rectangle to be internally filled, there should not be a column without any infection. Without any infection. It's very easy to see because otherwise you would at most get the rectangle on the left and the rectangle on the right that are far away from it. So this cannot happen. Okay, what is the probability of that? Well, let's see. So this rectangle R prime has a long side and a short side. And okay, we know the semi-perimeter, so the long side needs to be. Needs to be at least half of the semi-perimeter, which is at least two over, so it's at least one over. The short side is at most half the semi-perimeter, which is at most four over p, so it's at most two over. Of course, the short side can't be longer than the long side, but we'll do it long. It's perfectly. So, this is at most one. So this is at most 1 minus p to the power short side. So it's for us to choose, but we choose the advantageous way to do it. So we look for an infection along every short side. So 2, 2 over p, and all of this is to power 1 over p at least. Okay, this thing, p small, is approximately 1 minus minus 2 to the power 1 over p. Okay, so here we start seeing appearing something exponentially small in 1 over p. We're almost there. So in the end, we do a union bound on R prime. How many choices? How many choices of R prime are there? Well, at most, something like 2t squared, you always cute my plus 1, times, okay, so this is the position of r prime, and then I need to choose exactly the size of r prime, the length and the width, which Width, which are well, at most, I think it's 4 over e squared, like that. And now I've multiplied this by the bound that I got, 1 minus e to the minus 2 to the 1 over. Okay, and this, if I choose epsilon, so that this. Epsilon, so the t was this t. So if I choose 2 epsilon smaller than log 1 minus e minus 2, which is hopefully a positive number, we are, so this is go to zero. Thank you. Okay, so this is the important So, this is the important case. The other case is treated in the same way, but it's just not important. Let me do it a bit quicker, and then we're done. Case two. Well, the remaining one, so this phi of R is between twenty and And by 2 to the minus 3. Okay, so by Eisenman Leibowitz, extract a rectangle R prime that is included in minus P to the minus 3, P to the minus 3, something like this. R prime is internally filled. And I need to choose my I need to choose my semi-perimeter. So here I don't need to be very smart. I can just take 20 to 40, which is what I can guarantee in any case. Then by this thing that I will again call the traversability bound, then the median bound, as before, probability of. Probability of k is at most 1 minus 1 minus e to the power. This one was bigger, okay, 20, right? 10. So this thing is approximately 20. And this I need to multiply by the number of choices, which is something like p to the minus 6 times 1,000, which nicely goes to 0 as p equals right. Do you need to be a little bit more careful with the problem? Because it's definitely minus 66. Yeah, but it's the minus 5. Yeah, but it's to the power. Ah. That that was the point. Uh um yes. Okay. So it's really the same thing, but this is not the important case. As you see, I can do whatever I like. This here is the only important thing. The scale 1 over p. Okay, so this tells us that the whole problem, so this reasoning is basically always like that. Is basically always like that. The tricky part is getting a hand on an upper bound on the probability of a rectangle of critical size, something like this, being internally filled. So as long as you have that, you get what. Okay. Any questions here? Keep enough zeros. So, in the remaining time, I will make a desperate effort to explain the sharp threshold namely a theorem by Ander. by under which says that what we proved yesterday is indeed the right constant so exponential square over 6p and minus p This thing goes to one SP goes to zero. And I forgot it. Okay. So we'll try to, I won't do the whole group. I will explain it, however. So from what we saw, proposition okay, for any epsilon. Okay, for any epsilon we can choose fix epsilon positive then fix C large enough depending on epsilon and then P small enough we have that the probability We have that the probability of R being internally killed. I'll tell you what R is, I can guess for now, is at most exponential phi squared over 3p to the minus plus 7 for any rectangle r with with the sense derivative R between C over P and 2 C over P. Okay, so we are again on this critical scale, but we need to go a little bit further, a large construct. And so the claim is that if we prove this, we have proved this, the proof is there. There's nothing to be changed. How do we go about proving that? So, for its idea, I think that the most important, so okay, I should say, I don't know why, but people find this paper intimidating. I think this should not be the case. So, I will try to give you all the arguments. I will not write formulas. I will not write formulas or stuff like that much, but the proof is very clear. So there are just a few ideas that get together in a very logical way. And hopefully by the end of the talk, you will understand how it could happen. Then you just fill the details and it works. But you shouldn't be afraid of this proof, and I hope that Jericho will be your friends. So hierarchies. Uh so the idea of hierarchies is starts with follow the rectangles process but follow the rectangles process back it starts like this and then get a little bit It starts like this and then it will get a little bit more complicated, but what does this mean? Okay, so I somehow managed to internally fill a big rectangle. How? Through me it came from somewhere, from two rectangles merging. Okay. Uh where did those come from? Probably came from two rectangles merging. Probably this one as well. Uh And probably this one as well. That's all. So let me give them names. One, two, three, four, five. Okay, so then I can draw something that represents this in a natural way. It's a binary tree. It's one, two, three, four, five. And then there's And then there's say this is six, seven, okay, so this is six and seven. The eight of this is eight, nine is eight. Okay, so this is just a way to represent the rectangle. So far we haven't done anything more than the rectangles. So far we haven't done anything more than the rectangles process. Now the the key idea is to do to follow the rectangles process backwards uh and then coarse. Okay, what do I mean by that? Erase a little bit. Well, the idea is to not keep track of all of that because that's a lot of mergings. And we just And we just want a vague idea of where things came from. So, what do I mean by that? I mean, okay, I have this rectangle and I follow back. Maybe just merge with this one infection here. And before it was one smaller, and before that, it was one less wide, and before that, there was a little two by two that merged with it. That merged with it. Then the rectangle was actually this. And I do a few steps like this. And then I just forget about this stuff. It's not so important. I will just keep track of the fact that I got the big one from the slightly smaller one, and I don't really remember. And I don't really remember exactly how I did that. Okay, so I just keep this part of the picture. This is one thing that would happen. The other thing that would happen is, well, our rectangle just splits into two huge pieces, and then I probably want to keep track of both, right? Because otherwise, I'm losing a big part of this. So then this picture will become. This picture will become something like this. There will be two types of events. Either, so it will be a unary binary tree, something like this. Something like that. So, okay, so far I haven't told you exactly how I choose this. This is an extremely tunable technique. This is an extremely tunable technique. So you decide when you stop this, you decide how big things you decide to not see in your error case. You can tune this as you like. So let me tell you how you produce it and depending from how you produce it, it will tell you how you should define it. So, okay, basically, to do Basically, to do one step, you do it you construct it from top to bottom. So you s imagine you know your rectangle, you ask where did it come from? You follow your rectangles process backwards. Time of backwards rectangles process. And here you look at the process. Uh and here you look at the maximum semi-correl, more or less. Uh okay, you start with your initial rectangle and you fix a certain amount t by which you want to decrease. Okay, you want to decrease the central error by something, then you stop and you record what you have, and then you give it okay, but of course you can't hope to get it. Okay, but of course, you can't hope to get exactly that, so you also allow for some error, which could be something, but let's just keep it simple and allow the same error that so I'm trying to hit this strip here. Okay, so what can happen? The central parameter will decrease, will increase, will decrease, and eventually one of two things will happen. Either I will be a bit lucky, Either, I will be a bit lucky and it will just nicely follow in my script. In this case, it's simple. We are in this picture. We just draw something like this. We record this rectangle here. This rectangle is the one we started from. And then we start over, and this is our new rectangle. So I have just constructed this part of the area. What will happen? Of the air. What will happen? Then I will have decreased the size by something between t and 2t. Right? This is the nice case. There is also the somewhat bad case that it does exactly before hitting this. It's very nasty and it decides to jump over this frame. It goes directly here. This could happen. How does it happen? This means. How does it happen? This means I was decreasing, decreasing little by little, and then suddenly this happened. And moreover, this happened, and both of these rectangles are big. Why? Because I jumped over the strip. So the second one needed to be at least E. Right? So it needs to be somewhat big. So in this case, I will record four things. I will record four things. I record the initial one, because I want. I will record the last one before splitting, the first one after splitting, and the one that is not on the picture, which is the one that I used to go from here. Okay? This is these two. This one and this one, then the side maybe splitting. So this will give me exactly a picture like this. This will give me exactly a picture like this. This guy I started from, I did a little bit of decreasing, and then I split. Okay, so then this edge, I will not know exactly that it's between T and 2T, but it's at most this one. It's all dependent on the order of the rectangle process. We said before that there was no order, order does not matter, but now order matters. Now order matters. How do you decide it's the matter? Anyway, I bet. Uh it doesn't matter. But okay, it matters. Okay, we we got the okay, so that's good. I think I need maybe five-ish more months. Okay, so this is how we construct our hierarchy. It's based on this. Then we need to decide when to stop. So when this gets kind of small, we say, okay, that'll. Small, you say okay, that's enough. I don't want to see things that are smaller than T or maybe it's a bit bigger. Sorry, yes. I mean, I can whatever. So, this we have constructed. This is what we call the year. And by the construction, if it If the big rectangle is internally filled, then I can, for example, say that this guy, this guy, this guy, and this guy are all internally filled, and they are internally filled disjoint. To convince yourself, but follow the rectangles process, and you can merge things in such an order that these are at some point exactly the Some point exactly the collection of rectangles that you have in the rectangles process, so they are occurring distros. They are internally filled distros. Okay, so actually you can also convince yourself that here there will be events on the edges, like this, and on the leaves of your tree. So these will need to be internal, though. Need to be internal. And on each edge, like this, what kind of event do you want? You want this kind of event. So you go from the smaller rectangle to the slightly larger rectangle using some stuff that's here. Right? This event has to happen. Okay, so this is the event that we want for this hierarchy to occur. Now we need bounds on these. Bounce on these events. So we have three types of things here, and two things we know already how to control. So we're in a good position. So probability of a leaf, we have our traversability pass, which is what? 1 minus 1 minus p to the phi over 2 to the phi over, where phi is the semi-perimeter of the retirement. And if the semi-parameter is small constant over P, then, by the way, this T we will take to be small constant over P. So if this is small constant over P, this is approximately phi times P over 2. So it's a small number to this power. So this tells you that small rectangles cost a lot compared to their Compared to their size. We are aiming for exponential in 1 over p, and this is a large constant to the power of something, or 1 over p. So these things are very costly. This should just be remembered. Now, another thing we know is how to deal with things like this. So, here two options for you. Either you know the random. For you, either you know the vandenberg-Kestan inequality, decay inequality. Option two, you look it up afterwards. So probability of one times probability of two. Okay, so this we just decompose. The last thing we need to deal with is these edges. Okay, so probability of doing this. The probability of doing this, so this corresponds to this picture. So this corresponds to this picture. Let me call this A, B, C, D. So, okay, to grow from this one to this one, one thing has to happen, just by traversibility, I need to have at least one infection on each of these columns, and here as well. Right? It has to be different. So I can certainly say 1 minus 1 minus p. 1 minus 1 minus b to the power, what is this? D to the power c minus a. And okay, I can also do the same thing in the other direction for the rows. Get to those of you who are scared to go in a second. But this is C D minus B. Okay, so Okay, so this is not quite the case because the two things are not independent. There's these corner regions that are bothering us, but they are small. We did everything so that they are small. So we can just get rid of them. Say it's very unlikely that there's lots of things there, just by Chernov. So forget those things. And if we get rid of their corners, then this. Corners than this more or less. Alright, so and here we start recognizing our differential form over TQO of this gamma ABBC gamma. Okay, so this starts looking good. Now there is one type of hierarchy that we have already dealt with, which is the simplest one. Which is the simplest one, but the most important. This thing we lied about. So, the probability of a hierarchy like this, we are done with. You just use this bound for each edge, you put it together, it gives you exponential minus the differential form along the path that concatenates well, and this. And this and then you need to prove that any path that starts at something small and ends at something big is more or less this one. So there is, this is the optimization of the path. So this is an analysis. Optimization of the path. So, this is an analysis exercise which uses convexity of the function f from yesterday. So, this thing is more or less what we want. So, it's the integral of f from almost 0 to almost infinity. So, if we get this, we're up here. But this is the important part. Now, unfortunately, and that's the tricky part of lower bounds, and that's what we did all these hierarchies for, we need to These hierarchies for, we need to deal with the others, the other areas. So notice that we, at each, at least at each second step, we decrease the size by quite a bit. So there won't be too many steps. It's boundedly many steps. So there's not many here. So we just need to find the worst one and then do a union. Okay, so once we're there, we need one last observation. Need one last observation, which is the fact that this kind of hierarchy is better than this kind of hierarchy. Here this is, this is the same as this, this is the same as this, and this is the same as sizes. Okay, why is this true? This is true just by This is true just by, so these things have the same probability. How about this one? Is it better than this one? Yes, because the function f was decreased. So if you do, if you grow when you are big, it's easier than if you grow when you are small. That's all that this is saying. First merge, then grow. Not first grow, then merge. Okay, so if you believe Okay, so if you believe this, you will believe me that the hierarchies we need to deal with are going to look like this. Okay, when we have a hierarchy like this, we do the following. We say, this stuff I will call the pod for reasons that I will not explain. And so. And so we have two cases: either the pod is big or the pod is small. The last reasoning. If the pod is big, we use this bound. There are lots of leaves, they are kind of big, and they are very costly. They have a good bound on them, so they just deal with everything. We forget about everything else in the earth, you just keep the leaves, that's it. The other option is that the pod is. The other option is that the pod is small. Because the pod is small, let's just forget the error, the pod forget everything here.