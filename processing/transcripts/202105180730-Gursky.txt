Okay, so it's my pleasure to introduce Matt Gursky, who's talking about the extremal eigenvalues of the Conformo Laplacian. Thank you, Paul, for the introduction, and thank you to the organizers for the invitation. And thank you to everyone who's listening in. So it's, as I indicated, it's 6:30 in the morning for me. So I hope that. In the morning for me, so I hope the talk doesn't reflect that too much. So, I'm going to discuss joint work that I did with one of my finishing PhD students, Samuel Perez Aea. And so, as I'll explain, what we attempted to do is study some well-known problems, phenomena for surfaces, and try to see to what extent they work in higher dimensions. So, the alignment of the talks following Azahara is really good for me because there's gonna be some overlap in. Because there's gonna be some overlap in the formulas. Okay, so let's begin with the classical case of the surfaces. So, really, just to set up some notation. So, take a closed surface and choose a Riemannian metric, and then we have the Laplace-Beltrami operator. So, my operator is going to be a negative operator, so I'll actually be looking at the eigenvalues of minus the Laplacian, and then order them. So, from lambda one is going to be the first non-trivial one, and I'm going to be considering the behavior of the eigenvalues, and in particular, just the first non-trivial eigenvalue. In particular, just the first non-trivial eigenvalue within a conformal class. So let's introduce the usual notation that the brackets around a metric denote its conformal class. And then let's define the first conformal eigenvalue to be the supremum of the first eigenvalue. Now, of course, for reasons of scaling, that has to be normalized. So in two dimensions, what we want to do is multiply by the area determined by the metric. And of course, the definition immediately raises. Course, the definition immediately raises a couple of questions. So, first of all, is the soup even finite? Is this well defined? And the second question is: why soup and not the inf? So, it turns out the inf is not interesting. And we'll see in a minute here that the soup is actually finite. So, this is the correct quantity variationally, if you want to study. Okay, so a little some another definition here. So, we're going to say that a metric is maximal, really, maximal. Is maximal, really maximal in its formal class would be more precise, if this normalized first eigenvalue for that metric attains the supremum. So the word extremal shows up in my title, and here I'm introducing maximal. Not every author uses these terms in the same way, so I want to be a little bit careful to explain how I'm going to be using them. So maximal means attains the soup. Okay, so are there examples? And the answer is yes. So I'm going to give The answer is yes. So I'm going to give it, by the way, a very cursory sketch of what's known for surfaces. A lot more is known than what I'm going to explain. I'm trying to draw a bead from the surface case to the higher dimensional case and just hit some things that are relevant to what we did. So the first and this very well-known example is this result of Hirsch. It says, well, okay, what if you look in the conformal class of the round sphere? Well, then the supremum you can calculate, it's equal to 8 pi. You can calculate it's equal to 8π. That's the value for the round metric. And in fact, you can prove that a metric is maximal if and only if it is a constant curvature metric. And then much more generally, and this now explains why the soup is well defined, why the soup is finite, is this very well-known result of Yang and Yao, which gives an upper bound for the first conformal eigenvalue that simply depends upon the genus of the surface. So it has nothing to do with the conformal structure. nothing to do with the conformal structure. So now we see by this result that it's in fact always finite. I should also mention by the way so I defined the first conformal eigenvalue. You can define obviously the kth conformal eigenvalue and people simply absolutely do study that. Again I just I want to stick with the first eigenvalue just to make the story a little simpler. Now there's some other work that's been done on other surfaces. So let me just touch on a couple of things. On a couple of things. So, for example, Li and Yao studied the case of projective space and computed the supremum there, showed that the maximal metrics also have constant curvature. And then there's been different works, worked by different people for flat tori. You can do calculations to estimate the supremum, has to do with the lattice you're considering. There's a bound explicitly given in terms of some invariance determined by the lattice, et cetera, et cetera. So, anyway. etc etc. So anyway it's it's been it's been studied quite a bit. Okay so now let me so maximal again means it attains the supremum. Now let me introduce the term extremal. So the one of the challenges we're going to study this variational problem of trying to maximize an eigenvalue subject to some volume or area constraint. So as a variational problem it's different than the kind of thing you might be used to, certainly different from the kind of thing I've worked on before because the I've worked on before because the functional we're looking at is going to be continuous, but it may not be differentiable everywhere. So, this is where this notion of extremality is going to come in. On the other hand, and this is going to be crucial, is that if you have deformation, so again, we're restricting to a fixed conformal class. So, if you have a conformal deformation of metrics and you assume for technical reasons that it's analytic in the deformation parameter t. Parameter t, then it turns out that the one-sided derivatives at a given metric exist. All right, so it may not be differentiable, but you can calculate the derivative from the right, derivative from the left. They exist. And moreover, there's more or less a kind of formula that I don't want to reproduce because it's a bit complicated. It would take a while to explain, but it's hiding in the background of a lot of the things I'm going to talk about later when we come up with characterizations of extreme metrics. Metrics. Okay, so this, by the way, this is a whole result due to Perget, this existence of the one-sided derivatives. Okay, so we're going to say extremal means of the following. So sometimes this is referred to as C extremal to emphasize the fact that you're only looking at deformations of the metric in a fixed conformal class. But suppose we have an analytic family of conformal metrics. And so, again, we now know based on Béger's early work that. Based on Berget's early work, that the one-sided derivatives exist. So, we're going to say that a metric is extremal if, well, the derivative from the right is non-positive and the derivative from the left is non-negative. So, in particular, if it's maximal, if it hits the soup, it's going to be extremal, but you could have an extremal metric which is not maximal. So, this is going to basically replace the notion of critical point since we lack differentiability. Although I admit, extremal is a little bit confusing since that typically means you're maximizing or minimizing something. But in any case, I'm trying to stick with what's typically used in the literature. Okay, so what I guess, you know, a big motivation for studying this problem, other than the obvious intrinsic interest in spectral geometry, is this sort of remarkable connection between extrude. To between extreme extremal metrics and harmonic maps. So, I guess this goes back to this is an observation really not a rash vili. And this is a slice of something that's a little bit bigger picture, but let me just explain it in this conformal setting. So, suppose you have an extremal metric, then there's a collection of first eigenfunctions, call them phi i, so that the sum of the squares of those eigenfunctions is a constant. And of course, you can just normalize that constant. And of course, you can just normalize that constant to be one, as I've done here. And then, in particular, once you know that, what you can do is use the fact that there are eigenfunctions. You can just, and you can define a map. So if I have k of these eigenfunctions satisfying this property, then that defines, that k tuple defines a map from my surface into a sphere dimension k minus one. And it turns out you can just calculate using the fact that they're eigenfunction that this defines a harmonic map, in fact. finds a harmonic map in fact and moreover it just falls out of just doing the calculations the energy density is constant and it's given by that the extrumal eigenvalue so you know if you obviously the condition should look familiar right this is if you take the round metric on on the sphere the you know the the coordinate functions are eigenfunctions right and the sum of the squares are constant so point the point here is that that's a particular example of a more general phenomena of being extremal Remote. So now, yeah, just a remark. You'll notice that if you're maximal, then this collection of eigenfunctions has to, the number k, the number of eigenfunctions in this condition, has to be strictly greater than one, right? Because the first eigenfunction changes sign. So you can't have the square of an eigenfunction, first eigenfunction equaling one. So you have to have at least two, right? So in particular, So, in particular, what that means is the dimension of the first eigenspace is at least two. So, your eigenvalue, lambda one, is not simple. So, I point that out, well, pointing that out because we're going to see something like this later on. But also, just to point out the somewhat surprising fact is that the generic, generically, eigenfirst eigenvalue is simple, but for extreme metrics, they're not. Or it is not the first eigenvalue. Or it is not the first egg. Okay, so I defined this notion of extremality and maximality, illustrated with some examples, what more generally is known. So this was worked out by Petrides and on joint work of Nadarashvili and Seer. Now, I should say that the publication dates there are kind of misleading. Well, I mean, the publication dates are correct, but they give you sort of the misleading impression of the priority here. Misleading impression of the priority here. So Petrides specifically cites the work of Nadarashvili Seir. Just his work happened to appear in the journal first. But in any case, what they both proved is that given any surface, any formal class, a maximal metric always exists. Okay, what about regularity? So it turns out that your maximal metric is smooth, except possibly at finally many conical singular points. Many conical singular points. So, just a couple of remarks here. So, parts of Petriti's proof I just want to point out relies on work of Kokarev. And I also want to point that out because later on, and I can't remember if I actually put this in my slide or not, but some of the calculations that we do when we begin looking at these things in higher dimensions, we really go back to some of these calculations of Kokorev. So, and Petritis did as well. So, he's done some important work and sort of. Well, so he's done some important work and certainly deserves to be cited here. The regularity statement, by the way, follows from this observation that the maximal metric defines a harmonic map. So this is what you really end up doing after you get to the existence of this maximal metric is that you then realize, okay, it defines a harmonic map. What do I know about the regularity theory for harmonic maps from surfaces? And that's how the statement about only finitely many singularities and they're conical. Conical. And then, of course, I mean, I haven't said this explicitly, but it should, you know, you can probably imagine that although their proofs are quite different, the key property that's obviously used in both is the fact that if you're on a surface and you're looking at conformal changes of metric, then of course the Laplacian has a very simple formula for how it changes. So the conformal invariance of the Laplacian is a crucial aspect. Is a crucial aspect of this existence theory. Okay, so that's all I want to say about surfaces. Let me now move on to what we try to do in higher dimensions. So let's first of all agree that we should try to retain this conformally invariant property of our operator so we can try to exploit some of the ideas that were maybe used in the case of surfaces. Now, there's a lot of operators from which one could choose. So we're going to take maybe the arguably one of the simplest. Arguably, the one of the simplest examples that's sort of a generalization of the Laplacian. So, we'll do the conformal Laplacian. So, this I'm sure is well known, and it was in Azahar's talk as well. So, this is just minus the Laplacian, at least in my convention, plus some, plus a potential, which is just a dimensional constant times the scalar curvature. And then, okay, this is conformally invariant, but with a different weighting than for this Laplacian on surfaces, and that's actually going. Laplacian on surfaces, and that's actually going to play a role in why the statement of results in higher dimensions is going to look different than the statement of results in the surface case. So it turns out, I mean, if you look at them with a correct pair of glasses, they're kind of saying the same thing, but they look fairly different. And it's just because of the different conformal weighting that's hiding in the background. So the weighting itself actually will, in fact, play a role in some of the other formulas. We'll get to that in a minute. To that in a minute. Okay, so let's label the eigenvalues. So lambda 1, less than lambda 2, et cetera, et cetera. Now, there's a couple of conformal invariants you can associate to the spectrum of the conformal Laplacian. The first one is just the sign of the first eigenvalue. So, in contrast to the case of surfaces, where the spectrum, the non-trivial part of the spectrum begins above zero, for the conformal Laplacian For the conformal Laplacian, as everyone I'm sure here knows, you can have negative eigenvalues. So the spectrum can begin and get, you know, for some conformal classes, it can begin negative, and then, of course, it eventually has to become, go off to positive infinity. And anyway, so the sine of the first eigenvalue is a conformal invariant, and the sine of that invariant agrees with the Amabi invariant. Okay, so that's one conformal invariant associated. The second is, and this is obvious from the conformal invariants. From the conformal invariance of the operators, that the kernel is a conformal invariant. So if you have a zero eigenvalue, right, that's a conformally invariant property. And in fact, in the negative case, when you have negative eigenvalues, it's very easy to just write down a product example or something. We have lots of negative eigenvalues. It's pretty simple to do that. But it turns out that the number of negative eigenvalues is also a conformal invariant. So it's a little less obvious. You have to do sort of a mini-maximum characterization. A characterization of the eigenvalues, but this is also the case. Okay, so now suppose we want to try to do what we did, what's been done in services. All right, let's look at the first eigenvalue. Let's try to extremize it in some way and see what happens. Okay, so you might guess, let's try to do something completely analogous. Let's look at the supremum of the first eigenvalue, and then, of course, you want to normalize it again just to get rid of scaling issues. So you multiply by. So you multiply by higher dimensions, turns out this particular power, the volume, takes care of the scaling. However, this is not going to work. And so this is not obvious, by the way. This is work of Baron de Man and Jamis back in like 2008, I have it here. So it turns out the soup is always infinite. Now it's a little bit surprised. I said it's not obvious because this well-who-work of Corivar shows that if you're looking at the law, When the work of Corvar shows that if you're looking at the Laplacian and you normalize in the correct way, that is finite. So, somehow for the conformal Laplacian, you lose that. So, what, you know, of course, they're different operators. You have the potential term in there. So, the influence of the potential term this is showing is pretty profound. So, what they showed, it's quite interesting, in fact, again, I can't really get into this, but they showed it that what's going on here is the order of the operator. Here is the order of the operator plays a role. So, roughly speaking, that if you have a conformally variant operator, and if the order is less than the dimension, then the soup will be finite, basically. Okay, so the problem, assuming the soup will be infinite, sorry. So what's going on here is once we go to higher dimensions, we're looking at still a second-order operator in the conformal Laplacian. So, the soup by their result is going to be infinite. So, you can't do the soup. Okay, so what about the inf? Okay, so what about the n? All right, if soup fails, let's give this a shot. Okay, so it turns out this is a really interesting problem, but we're a few decades too late. So this is just equivalent to the Amapi problem. Okay, so I want to, it turns out this is just Holder's inequality, but I actually want to go through this because you're going to see how the conformal weighting of the conformal Placian pops up in studying these extremal eigenvalue problems. Extremal eigenvalue problems. So let's just write down the usual Rayleigh quotient, the variational characterization of the first eigenvalue. So we have a metric G tilde in a fixed conformal class. And let's choose a background metric. So we've got a conformal class determined by some metric G. We're going to look at all conformal metrics G tilde. And because we're in higher dimensions, we'll write them in the usual way. And now I just want to keep track of how this Rayleigh quotient depends upon the conformal factor. Conformal factor. That's the goal here. But of course, along the way, we'll see why if you minimize the first eigenvalue, you're really just looking at the AMADI problem. So what you do is you use the conformal invariance of the conformal Laplacian. So if you take the inf over all test functions of this sort of Dirichlet form of this Rayleigh quotient, it's the same as taking the inf of the kernel factor times the test function phi. times the test function phi. So all I'm doing here is rewriting the volume form in terms of the power of u. It's the usual kind of thing. So the point here is this last, comparing the last line on this slide down here. You can see the arrow or my little hand hopefully in the first one. So the point is this Rayleigh quotient. You can write it in terms of this control metric G tilde, or you can write it in terms of this Dirichlet form for this background metric. And the denominator Background metric. And the denominator here now has this weight depending upon your conformal factor. All right. So if you vary the conformal metric, you don't really have to think about varying the operator here. You can stick with the conformal Laplacian of your background metric. All you have to do is compensate by putting a weight depending upon the conformal factor in the denominator. So, in the case of surfaces, actually, everything cancels out, but that's. But then there's some other issue that comes up. So, again, the weighting is a little bit different in different dimensions. Okay, so anyway, so now you realize that the first eigenvalue is just the infemum of this Rayleigh quotient. Then it's just holders inequality. So since it's going to show up again, this weighted sort of Rayleigh quotient, I'm just going to give it a name, R for Rayleigh, and then U for the control factor. And then you just do, we're assuming everything were in the positive case. We're assuming everything we're in the positive case. So, all the quantities are positive. You just run Holder's inequality. And if you do that in the denominator, what you end up getting is that the normalized first eigenvalue is bounded below by the Yamabi invariant. So, if you have equality just by equality and Holder's inequality, you see that you must be talking about a Yamabi metric. All right. All right. So, if in higher dimensions, if you're looking at the conformal plausion, you don't want to take the soup. If you take the imp, you're just looking at the Yamabi problem. So, very interesting, but obviously. Very interesting, but obviously, you know, no sense in studying that anymore. So, at least in this context. So, what Aman and Umbert did is they said, okay, let's look at the next eigenvalue. These other eigenvalues have interesting variational properties as well. So, they define what they call the second Yamabi invariant, which is you take the infimum of, because again, the soup will be infinite, obviously, because the second eigenvalue lies above the first eigenvalue. So, you take the infimum of the second eigenvalue. So, you take the infimum of the second eigenvalue again, again, normalized. All right, so what happens here? Well, so what they showed is that, in fact, if you try to solve this problem, it's never going to be attained by a smooth metric. So, even in nice settings, you won't get a smooth solution. So, this, let me try to explain a little bit what's going on here. So, the first thing they recognize is that you need to broaden your definition. Is that you need to broaden your definition of a control metric? So you'll remember when I wrote down that Rayleigh quotient characterizing the first eigenvalue, there's a similar one you write down obviously for the second eigenvalue. And again, the dependence on the conformal factor really just ends up in the denominator as a kind of weight. So it turns out you can study these Rayleigh quotients and your weight doesn't have to be regular in that case. It just has to be in some LP. Case. It just has to be in some LP class. So, what they defined are generalized control metrics. So, this is, it's not a bona fide Romani metric, but sort of formally, you look at functions u, which are integrable to the correct power so that the volume is well defined. And you assume that they're non-negative almost everywhere. Okay, so this is the class in which you're going to take the in them of the second eigenvalue. Themum of the second eigenvalue. And then, okay, what do you mean by a second eigenvalue if you're now considering these non-smooth type metrics? Well, you can write down that Rayleigh quotient that, again, it just involves that the conformal factor is some sort of weight. And then what you do is you just copy the classical minimax characterization of the second eigenvalue. And that's how you define the second eigenvalue of a generalized conformal metric. So now everything makes perfect sense. So now everything makes perfect sense. Now you have to be careful. So I'm telling a bit of a, this is kind of inaccurate. So you can do the minimax characterization, but you have to be careful. You can't, typically for the second eigenvalue, what are you going to do? You're going to do a mini max over all two-dimensional subspaces in your test function space. That doesn't quite work here because you could have your, this conformal factor could vanish on an open set or something, and it would be very easy to make this, you know, in FEMUM. Make this, you know, in FEMUM not well-defined. So you have to restrict it, but it's just a technical thing. You have to, I don't want to get into it, but you can still make it work. All right, that's the key point. Okay, so suppose you have one of these generalized eigenfunctions, and suppose you have a, say you fix a generalized, excuse me, let me say this more carefully. You have a generalized conformal metric. You write down this mini-max characteristic. You write down this minimax characterization of the associated second eigenvalue. All right, suppose you have a function that attains the minimax, so this should be like your idea of a second eigenfunction, right? What does the minimax characterization tell you about that function? Well, it satisfies this eigenvalue equation. So it's a weighted eigenvalue equation, right? So you have the conformal Laplacian with respect to your background metric. And then the right-hand side, it looks like the eigenvalue equation for the second eigenvalue, but you have For the second argument, but you have this weight. So, this is what allows you to work in a very weak sort of notion of conformal metrics: the fact that the conformal invariance of the operator allows you to write down an eigenfunction equation where the conformal metric appears in a sort of a reasonable way, just a zeroth order, right? So, all you need is some integrability to make some sense out of the second eigenfunction. Okay, now just a quick remark. So, this corresponds to what you would see in the smooth case. Corresponds to what you would see in the smooth case. So, suppose you have a smooth conformal metric, and you write down the eigenfunction equation for that smooth metric. Then just using conformal invariance, it agrees with this generalized notion. So this is just extending everything to a non-smooth setting, but it's the same equation. Okay, with that understood, let me now explain what they did. Okay, so in Amana Umbert, they looked at. So in Aman and Umbert, they looked at the second Amabi variance. So they want to minimize the second eigenvalue over all these generalized conformal factors. And what they showed is that, well, you can find a generalized conformal factor which attains the infimum. Provided you make some, it's basically, it's like, it's like, just like in the Amabi problem, given the parallels, it's not too surprising. They have to run some sort of concentration compactness argument. So they need to show that you should think about this as. You know, this you should think about this as being like the if the amavian variant is strictly less than the sphere kind of condition, all right. They get compactness that they can build into their problem, they can capture a you know minimizing subsequence that converges in some weak sense to a minimizer, and you get in the limit a generalized control metric. Um, and okay, what is so, and what do you get? All right, so it it attains the infimum of the second eigenvalue generalized in this in this in this setting. Generalized in this setting, what does it mean geometrically? Well, not so surprising. We'll see. It ends up giving you a solution to the Amabe problem, but because we're looking at the second eigenfunction, it can change signs. What's going to give you a nodal solution of the Amabe problem is what happens. So let me state it this way, all right, because I want to draw the parallel, because initially it doesn't look like there's any parallel with the case of surfaces, but here I want to draw the parallel with the case of surfaces. So what they should So, what they show is that there's a second generalized eigenfunction that's related to the conformal factor in this way. So, they wrote it as the absolute value of the second eigenfunction is equal to the generalized conformal factor. And you take that condition and you stick it into the second eigenfunction equation. And now the second eigenfunction equation looks like this. So, the conformal factor just gets replaced with the power of the second eigenfunction. Power of the second eigenfunction. And so you're just looking at this is a changing sign solution of the Amabe problem. So if you minimize the first eigenvalue, you get a solution of the Amabe problem. If you minimize the second eigenvalue, you'll get a nodal solution of the Amabe problem. That's the summary of what they discovered. Okay. Now, I want to, for a moment, I want to zoom in on this condition. So they said that the characterization of characterization of being of minimizing attaining this uh second Yamabi invariant is that the square of the eigenfunction is equal to the square of the conformal factor. Now you might say well gee in surfaces it was kind of it was really nice if you had say a metric for which the first eigenvalue was maximized then you had this beautiful condition that the sum of the squares of the eigenfunctions were constant right and that and that therefore defined a harmonic map. So what happened to this condition Happened to this condition that the sum of the squares of the eigenfunction was constant? Well, it turns out this is kind of what's going on with this equation. So, what's happening here is that in the case of the conformal Laplacian, you get a different conformal weighting. So, for surfaces, instead of all the eigenvalue squares of the eigenfunctions adding up to a constant, in higher dimensions, they add up to, because of the conformal weighting, the conformal factor squared times. The conformal factor squared times a constant is what's going on. So it's the conformal weighting that's sticking this power of the conformal factor there rather than one as in the case of surfaces. Now, another contrast is that in the case of surfaces, you always have a multiplicity result. There's always more than one eigenfunction for a maximal metric. Here, they showed it's always simple. So you just have one eigenfunction. Okay, so you got simple in the higher. So, you got simple in the higher dimensions versus always this kind of multiplicity thing going on in the case of surfaces. And okay, I just already explained this, that this is really a general, the condition that they came up with is just the generalization of the case of surfaces. So we have just one eigenfunction and the equation just sort of builting in, baking in the conformal weights. Okay, so let's. Let's uh, but now it seems like this connection to harmonic maps completely disappears, right? So, you know, the I sort of try to explain that well, the condition in surfaces that the sum of the squares of the eigenfunctions is a constant gets replaced by this sort of less satisfying, but nevertheless, you know, parallel type condition. But what happened to the harmonic map characterization? All right, so to try to see if we could. To try to see if we could get back to some kind of connection. Sorry? What happens when μ2 is equal to the constant? When μ2 is equal to which constant? You call it K2. Oh, wait. Sorry, I don't think I understand. So μ2 is the eigenvalue. You need a condition that mu2 is strictly less than some number. Oh, what if it's equal? Oh, yeah. Oh, I'm sorry. I'm sorry. I see. Yeah, and they can practice. I see, yeah, in the compactness. I don't know the answer to that. Yeah, it's I'm sure it's not easy to answer, right? Because it's like in the Amavi problem, right? If you call trying to characterize what happens in the case of equality, I suppose is not so easy. I've never really thought about that. Okay, cool, cool. Okay, so what now I'm getting to the work I did with Samuel. And so we wanted to look in a setting where we might have a chance to still see a connection to harmonic. See a connection to harmonic maps. And so, what we're going to do is look at not the positive case. So, the first eigenvalue, again, its sign is determined by the Yamabi invariant. So, we're going to look at conformal classes with negative Yamabi invariant. And to remind you, the number of negative eigenvalues is a conformal invariant. So, if you move within that conformal class, you're always going to have the first eigenvalue be negative. And it's easy to see. So, in the positive case, So, in the positive case, so that if you try to minimize the first eigenvalue, you're just recasting the Amabi problem. Excuse me. Same thing is true for the negative conformal classes. So, here, if you maximize the first eigenvalue in a negative conformal class, that's equivalent to solving the Amavi problem. So, the first eigenvalue is interesting in the context of studying scalar curvature, but it's our, you know, especially in negative case, it's obviously well understood. Case, it's obviously well understood. Okay, so if what about what they did? Find the first eigenvalue has a nice characterization. Let's go to the second eigenvalue. What if you try to do what they did and minimize the second eigenvalue? Well, the situation is that they studied positive control classes, so zero is kind of like a floor for them. So they can study the infemum. They can study the infimum, but in negative conformal classes, it's easy to see that if you look at the second eigenvalues, you can always make the infimum of the second eigenvalue negative infinity. So you don't want to study the inf of the second eigenvalue. Instead, you want to study the soup. All right. So just because of the sine flip, you just have to, you know, instead of minimizing something, you have to maximize something. All right. Okay. So. Okay, so what we're going to do is take a conformal class. We're going to make sure that there's at least two negative eigenvalues so that the second eigenvalue is now negative. All right. And we're going to take this supremum. Now, if you get the exact same thing they got, it's probably going to be a fairly limited interest, but I credit, so this is an observation of my student, Samuel. So when he started digging in and doing some calculations, he realized that something different was going to happen. Something different was going to happen. So, when you maximize this eigenvalue versus minimizing this eigenvalue in the negative context, you should see something different pop out of the extremality condition. And so that was sort of the beginning of why we got interested in this. So let me tell you what we found out. So again, we're just going to assume there's at least two negative eigenvalues, so that lambda two is negative as well. And we have to make this technical assumption that zero is not in the spectrum. That zero is not in the spectrum. Basically, when you start running these arguments and doing limiting arguments, you don't want eigenvalues accumulating at zero. So that just eliminates that possibility. And then, so what's the conclusion? So you can always find a conformal metric that maximizes the second eigenvalue of the conformal Laplacian. Now, for the regularity, we know a little bit more. So it's globally limited. More so it's globally lip shifts and it's smooth away from the zero set. Okay, so it still could be singular as a metric because you could have a zero set. You can make some more precise statements about the size of the zero set. I won't do that here, but something, but these are general, just quoting general PDE results, basically. All right, and then what is it, what geometric properties does it have? So, well, it turns out, so now we're going to see the parallel again more. Going to see the parallel again more surfaces. So there's a collection of eigenfunctions from phi i bar, such that the sum of the squares of those eigenfunctions is equal to the square of your conformal factor. We call it u bar. All right. All right. So on the one hand, it looks a lot like Amman and Umbert in the sense that, okay, they said that you have one eigenfunction and the square of it is equal to the square of the control factor. Here we're Equal to the square of the conformal factor. Here we're saying, well, there could be more than one eigenfunction. All right, so, but on the other hand, how do you know it's there's not that's not the case? I mean, maybe there's always just one eigenfunction, so the eigenvalue is simple, and you just get this connection to nodal solutions. Maybe this is actually the same exact situation, but it turns out it's not. There's really a dichotomy here, depending upon how many eigenfunctions you have in this condition. So, let me, exact same result. Let me exact same result. I just want to state it in a different way to emphasize this point. So, either you just have one eigenfunction, and then it's just like their result. So, that eigenfunction is related to the control factor just by taking absolute values. The control factor is just the absolute value of the eigenfunction. If you take the eigenvalue, eigenfunction equation, plug that condition in, what you've come up with is a nodal solution to the Ababi problem. That could happen, and we know by example it can happen. But you can have, you could have. But you can have, you could have examples where you have k is bigger than one, so you'll have a sum of the squares of multiple eigenfunctions is equal to a square of the conformal factor. And then just imitate the argument in surfaces, got to do a calculation. But it turns out that this will, if you take, because of the conformal weighting, your eigenfunctions and divide by the conformal factor u bar, you can define a map into a k minus one-dimensional sphere and you can Minus one dimensional sphere, and you can verify that it's a harmonic map. So we get back to the situation where there's a connection between extremal metrics or maximal metrics and harmonic maps. Okay, but you're still left with this nagging doubt. I mean, maybe case two actually never happens, but it turns out it does. All right, so both possibilities can occur. So I'm running a little bit behind time, so let me not worry about the first case. It's easy to come up with conformal classes where the first case happens. The first case happens. Just don't take my word for it. You thought about it for three minutes and understood the notation, you could easily come up with examples. But let me talk about the second case because that actually took some work. But it turns out there's lots of examples as well. So what you need to do is take a compact manifold with negative scalar curvature, and you got to normalize it some way, but you can always attain this. So what we did is we just took something, we took a compact hyperbolic manifold. We took a compact hyperbolic metric, but you don't need to just because it's easier to calculate certain things. But anyway, if you just look at the product metric with a sphere, then it turns out that you can verify if you normalize everything correctly that the product metric is actually maximal in its conformal class. So this is, you have to do some sort of, do some hard work to show that given any other conformal factor, the generalized second eigen or the second eigenvalue associated with that is Eigenvalue associated with that is always going to be less than or equal to the product metric, so some work involved. But you can do that, and then particularly, you can see here you see concretely this harmonic map, right? So it's just that the eigenfunctions of the sphere end up defining being the eigenfunct for the product metric, right? And then they define a map into a sphere. So here it's very explicit, the connection with a harmonic map. So anyway, you get lots of examples where you Lots of examples where you see this dichotomy. So, it really is the case that there are some conformal classes where you're just going to capture a nodal solution, and there are other conformal classes where you'll absolutely capture a harmonic map. Okay, so let me just couple remarks. So, in this example, we constructed using this product metric. So, there you get, you can have fairly high multiplicity. We can have any multiplicity I want. We can have any multiplicity I want in this construction. That's a contrast with Aman and Umbert's work, where their maximal metric is always simple. And also, in contrast to their work, in this product example, the maximum metric is actually smooth, right? I mean, the product metric is a smooth metric. So in their case, it was always going to be one of these generalized metrics. The maximizer was never smooth. Was never smooth. And then here's something else that's kind of strange and just doesn't has no parallel in the case of surfaces. So after we do our normalizations and we look at this product metric, that product metric is actually a Yamabi metric. So the product metric is Yamabi metric, so it maximizes the first eigenvalue. And our work shows that it all simultaneously maximizes the second eigenvalue. So on surfaces, then this is a On surfaces, and this is a work of El Soufi, you can never have a metric that maximizes both eigenvalues, two consecutive eigenvalues simultaneously. All right, it's cannot, he can rule out that possibility. Higher dimensions, this can happen. All right, so let me just, well, okay, let me just mention one thing. I'm going to wrap up here. So, all right, so what, what, what do, how do we pull this off? Uh, so you want to. So, you want to, as always in these, almost always in these variational problems, you want to regularize the problem. And we regularize it in a way that we tried regularizing a lot of different sort of sophisticated ways. And then we realized that because of the structure of the problem, you could do something fairly simple-minded and get away with it. I mean, you had to do some work to realize that, but what we do is we look at this, just like Aman and Umberg, we look at the space of generalized component factors that we just, but we look at for any parameter, any value. any parameter any any value of epsilon positive we look at this subset for which uh some small net for which the conformal factor raised to some small negative power is integrable all right and restrict to restrict to this subset so in general if you try to do this you're going to run into all kinds of problems when you look at the variational properties if you can capture something in this restricted class but it ends up working in in this setting because of the way the calculations play out but in any case the the Play out. But in any case, the key for adding this negative, this integrability condition is that it gives you automatic control on the first eigenvalue. So, again, something that happens in higher dimensions that you don't see in first dimension in surfaces is that if you're trying to control the second eigenfunction or second eigenvalue, excuse me, you can lose control of the first eigenfunction. So, in our setting, at least in a negative setting. So, the first one lies below the second one. So, you could get good control in the second eigenvalue. And in principle, the first eigenvector. Second eigenvalue, and in principle, the first eigenvalue could be crashing down to minus infinity. So, you got to do something to take care of that possibility. So, this is a method to do that. And then, so we just regularize our functional in this way. All right. And so, then, anyway, I won't tell you the rest of the story, but then you can always do this. And so you end up getting very good integrability conditions on your control factor. And you could take limits this way. And I'll end there. Thank you very much. I think you have 10 more minutes. Oh, I thought the schedule said I had till 20 after, so I wanted to finish five minutes early. Okay. All right. Of course, you're the chair. I don't want to argue with the chair. Okay, let's ask for questions. Are there questions? Yeah, I have one. Hi, Matt. I have one. Hi, Matt. Hi, Andrea. In dimension two, so you mentioned this result by Nadir Shvili and Seer. Yeah. So solutions are smooth up to conical points. Is there any constraint on those conical angles? So, I guess, as I mentioned, that's a harmonic map question, really. But so I don't see why there would be. Would be uh, I don't see why you would get that from the uh extremality condition, but I never thought about that before. So, would you get any constraint? I mean, I'm sorry, I've never thought about that before. That's a it's an interesting question. I uh yeah, like I said, it sort of pops out in the proofs, but I've never really thought about whether you can dig a little deeper and see a connection between, okay, well, wait a second. So Second. So, because the energy energy density is constant and it's equal to the first eigenvalue. So, if I know the energy density, can I easily figure out the conical angle? Could you repeat the question? Yeah, so in two dimensions, there's this characterization that if you have a maximal metric, then you have a collection of eigenfunctions that define a harmonic map. Of eigenfunctions that define a harmonic map from your surface. And it's smooth up to possible conical singularities. So now you have these conical points, right? And Andrea is asking, can you say anything about the cone angle for those points? So all I know off the top of my head is that you know that the energy density is constant. If that is enough, then I have another question. So in your theorem, you have existence, but do you have explicit example? Oh, well, there's this product example that. Product example that is that what you mean? Right. So, this is an explicit example that you can write down, that is, you can prove by hand, as it were, that this product metric maximizes the second eigenvalue in its conformal class. And yeah, and you observe it's smooth, and you can see the map being defined. I mean, much more. I mean, much more explicit. Like, if you, if H is a hyperbolic surface, do you get something interesting? Well, I mean, what do you mean by it's interesting? You can take an explicit hyperbolic surface where you know the eigenfunctions, the maybe a Maybe. Oh, right. Sorry. Yeah, but okay, I see. Right. But okay, let me. Yeah, it's hard to, yeah, I mean, unless you dig into the calculations. What's going on here is that you're taking a product with something with negative scalar curvature just to give you negative eigenvalues. So you're in the correct kind of conformal class. But the eigenfunctions for the second eigenvalue are actually the spherical harmonics on the sphere factor. On the sear factor, I see, I see. Yeah, so sorry, I should have emphasized that. So, you don't even see if you set the guy. So, I said, you know, very mysteriously that you have to normalize it the correct way. Well, you normalize it in such a way that you don't even see the eigenfunctions of the H here. Okay. I see. So, because we really want to use the fact that we have these spherical harmonics in the other factor. I see. I see. Okay. Thank you. Yeah. Okay, thank you. Yeah. I have a question. Hi, Matthew. In dimension greater than two, you went with the conformal Laplacian. Did you consider also the GJMS operators, like the Panitz operators, would be a natural thing to do? Yeah, this is something my student has started working on. As you can imagine, lots of things come into play that don't happen here. So I don't think he has a lot to report right now. What I originally asked him to look at. What I originally asked him to look at, not surprisingly, is the penance operator, right, in four dimensions to try to see if he could run, because that would seem like it would be much stronger parallel with the case of surfaces. But it's very difficult because as well, Luca, you know why it's very difficult, right? So there's a lot of things that happen that you can't quite, you know, draw a line between four dimensions and two dimensions and work out how to resolve them. So yeah, he's thinking about. Them. So, yeah, he's thinking about it, but there's a lot of, you know, certainly a lot of the setup is already there, right? But a lot of technical things we don't understand. Right, but since it's a higher order operator, new difficulties might arise. Exactly. For sure they will. Are there more questions? Yes, Matt, just one curiosity: what is a welfare? Just one curiosity, where is Samuel from? I'm sorry? What is Samuel from? Where does he come from? Puerto Rico. Okay. Thank you. By the way, he will be at Princeton starting this September. Hello, Matt. Hi, Monica. Hi. I was talking before to you, but I realized that you were. You but I realized that you were not listening to me because my microphone was off. Sorry, sorry. Beautiful talk. So do you know anything about the nodal region of your eigenfunction? And do you see, no, because for it would be nice to classify all Nodal solution for the Yamabe problem. Do you think you can say, yeah, for sure, you can say something? Yeah, okay. So, okay, so very good question. I'm going to give you a very incomplete answer. So, the only place we thought about this carefully, so if you look at nodal solutions for the Amabi problem, there could be many such solutions, right? So, it's very hard. I don't know. It's very hard. I wouldn't even know how to start to characterize those nodal sets. I mean, probably, and I'm sure people have thought about this on some level. We thought about the other case. In other words, there's this dichotomy. Either you have a nodal solution or you have this collection of eigenfunctions that define a harmonic map. It's the second case where you can still, in principle, have a singular set where your conformal factor hits zero. It doesn't give you a nodal solution to the Yamabi problem, but there we really. The Amabi problem, but there we really wanted to try to understand what the nodal set what the zero set of our conformal factor looks like. The only results we have come from just quoting sort of classical results about the zero locus of solutions to elliptic PDEs. So they don't really use the geometry of the setting at all. But so I've never thought carefully about, we always thought about the nodal case as being sort of, I mean, that's sort of, I shouldn't say well understood. That sort of was, I shouldn't say well understood, but the connection to nodal solutions was preceded our work. So we were more concentrating on: gee, can we see what's going with the connection with harmonic maps? So I haven't thought really, it's a great question, but we haven't really thought about it in any level of detail. Okay, thanks. All right, if there are no more questions, let's thank Matt for a beautiful talk. Thank you. Thank you.