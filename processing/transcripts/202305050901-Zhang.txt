Okay. Anyway, if something goes wrong, but I leave it, okay. Not my fault. But I I want I want to say a few words about Sizu Kawausa. I never met him. Since I guess most of you never heard about him. So let me say a few words about him. So we work with Niza and Tunye and a few other co-authors. We worked on the path-dependent PDEs a lot during those years. Yes. I never met him. I got to see him paper in 2020. But at that, I learned, so as I stopped talking, I learned that he started to work on the blog about the same time. So it took him nine years to finish his Afro-Maper. And it took him another three years to get the paper accepted. Okay, it's amazing. So I never met him, but naturally we propose a problem to him. So has dependent. And mainly what I'm going to talk is. Mainly, what I'm going to talk about is piece of work. We propose a problem. It's very complex idea. Unfortunately, it's technical, but I'll see how much I can explain the idea. Let's see. So, for the passive dependence, because maybe I already give an excellent introduction on the mean field control problem, so I will not motivate it anymore, but I want to say motivated the passive dependence. Okay, why are we interested in it? Of course, I mean for five. In it. Of course, I mean, for finance people, mass finance people, I mean, lots of things are test dependent, so actually, we are fine. So, in the beginning, we'll just talk about all these. So, it's natural, it's test dependent. But some people just say, okay, these are exogenous. What if I don't care? But in the past years, I have some I call it intrinsic capacity dependence. So, the problem setting is completely state-dependent, but the solution is capacity-dependent. Okay, so from state-dependent, Okay, so flung state dependent is a setting. But as a solution, we have to use the path dependence. So one is quite popular, the rough volatility models right now. So it's like the volatility is a fraction of blind emotion, or more generally, the voter status of equations. So it looks like it's a state-dependent in the equation, but actually it's non-Markovian. So it's like a delay. So the state of process is non-Markovian. That even if we take a conditional expectation g of x capital T, state-dependent. X capital T stay dependent, but the condition expectation is passed dependent. So it's very natural. And another one is quite interesting. So we worked on the gains. So for gains, you know, the natural equilibrium typically is not unique. For control problems, of course, optimal control may also not be unique. But the value is unique. And when the problem is state-dependent, the value is state-dependent. That's fine. But for gains, you have multiple equilibria, and the corresponding values can also. And the corresponding values can also be multiple, not necessarily equal. So we propose to study the set value of the gain, which means I consider the set of values over all equilibrium. And luckily this set, of course, it's unique, yes? Luckily, this set is set by dynamic programming. Okay? But for that dynamic programming, you have to use pass-dependent stuff. If we restrict to state-dependent controls, equilibrium, DPP fails. DPP fails. But if we use a pass-independent equilibrium, it can choose. Then we can recover the DPP for that set. So it's intrinsic, okay, following the non-integiness. And I want to give another example here to see why its path dependence comes out for this problem. And interestingly, this is also a mean field type. So let's see. So very standard control block. Okay? Very standard control block. But on purpose, I put this back order. But on purpose, I put this backward SD. It's not linear here, okay? If it's linear without a YI phara, ZI phara, that's just a conditional expectation. Yes? So nothing to say that you have a standard HGB equation for the value and the optimal control, or at least you have one optimal control, which is feedback type. But of course, feedback type, it's random. Okay? It's random. These process is random. So now I say, what if we restrict to deterministic? What if we restrict to deterministic controls? And this, I think, I have a good motivation why we talk about determinant controls. So I was thinking: so, typically, you have a control, I by T. You say you can depend on all the information you observe, yes? So let's say you observe X. So that's the natural setting, yes? But so that's the information you observe up to time t. But we need to have some time to process the information, at least, yes? So in practice, In practice, you need to have some time. Let's say you need a time data to process the information, to decide your strategy such. So that your control should be F minus delta measure. And if delta is large or if capital T is small, that's deterministic. So that's my motivation. Okay, I call it an information information delay. Anyway, so let's think of the deterministic controls. Of the deterministic controls. If we talk about deterministic controls, you define the value dynamically, you can still define u of tx to start from tx, yes? The problem will be tiny consistent. Okay, the problem will be tiny consistent. Then you don't have a PDE. Then what do we do if it's tiny consistent? So my observation is this. For the standard one, we allow it to be random, so i plus star, it will still react to the Still react to the state process, yes? So it depends on this, but unfortunately, it's ready. Now I want to be deterministic. Water will be deterministic. The law will be deterministic. So it will be a natural guess. So probably my optimal control will take a new form. Hopefully. And indeed, it's true. So in the linear case, if it's linear, I can introduce the V of T law of XT basically. This guy will be this function will be time consistent. Okay? So it will satisfy HJP equation on the Wasa science basis we are talking about. We will talk about. And follow the Hamiltonian. Flow the Hamiltonian, we can find this. Indeed, it's this. It's true. Okay, but that's the linear case. If it's non-linear, if indeed depend on y or even z, so it fails. This guy is time inconsistent again. This guy is time inconsistent again. But if I change it to time, if I change it to test handle, that will recover the time consistency. Time consistency. So, this guy, this guy will set it by a pass-dependent HJB on what's a sign space. And the optimal control will take the right form again. But I'm using P here instead of L, about that. Okay, so that's one good motivation for the path-dependent equations and also SAGV otherwise. So, mainly to solve the tiny consistency issue. So, once we reach the dimension, So once we reach the dimension, instead of considering state, I consider the law of the state or law of the process of the state. So state of process. We recover the time consistently so we can talk about PDE intersection. Okay. Now we move to the mean field, passive dependent mean field control problem. So give the setting. So this will be standard. This is also standard and in the literature we always assume F0 is rich enough to support all the probability matches. Enough to support all the probability measures. So my processes will be continuous, so I denote this as a continuous path. This is a determinant, sorry, deterministic, okay? And the processes, so these are processes. Peace moment, so this is known, that's the uniform norm. So that's the measures or the laws. And this is my notation. So if I fix t, so law of xt I denote as a mu t, if mu is this. And it will also. This and it will always be adapted in terms of time. So, this notation will be important. So, that's the process up to time t. I'm using this notation here. I'm using this notation, but yeah, in the slide, I'm using this, but I know. So, this is not the flow of the module. That's the law of the process. And so, throughout the talk, all the functions will be adapted in this sense. So, whenever you see this. Okay, so whenever you see these guys, if I don't put a specific T here, they are processors. It depends on the path. Okay, but it's always adapted. But there will be one crucial function later. I'll mention it's not it's still adapted. Okay, never mind. Yes, it's still adapted. Anyway, so our space, state of space is time and time and this is a process, not the law. We can also introduce the overbar here. But later on, unfortunately, for the reason I'll explain it. For the reason I'll explain later. So, our definition of weak solution is not intrinsic in the sense that we are not working on this space. We are working on this space. So, lift to the processes rather than on the what? On the loss. So, now here is the standard problem. So, because it's now can see the process. Okay, can see the process. Because it's a path-dependent, so I need to specify. Pass-dependent, so I need to specify this as well. If it's not a pass-dependent, you just start from KCT, that's fine. But pass-dependent, we need to. This, so it's a standard, okay? So we so this can be pass-dependent, but as a control of the law, it's a state-dependent. Okay, for the control, we just say state-dependent. Yes? That's the question I'm asking. Yes, I don't know. We'll see, we'll see. Yeah, because otherwise, it'll be. Because otherwise it'll be either we don't need expectation anymore, just a journal of this. We are thinking, yes. Okay, so it's quite a standard to prove that the V is a state is adapted and also low invariant. So that if we want, we can write in this. Yes? Okay. DPP is trivial because it's deterministic, Meta also mentioned. So we don't need all those trouble because there's no manual value danger. Because there's no manual value, it's a deterministic. It's deterministic. Okay, it's free. Even these will have regularity, but as a proof of DDP, we don't need a measurable regularity. In some sense, even we don't need a measurability to prove this. It's deterministic. Yes, sir. Right now, actually, actually, I'm using open loop attaches. Yes, sir. I'm not emphasizing that yeah, it's it's open loop right now. I I will say I'll put it into the framework of the the processes. Okay. So our assumptions. The coefficients are progressively measurable, of course. They need to be adapted. And the bonded with C0, that's not needed. But in the talk, for simplicity, some arguments can be easier. And then also, some steps in the talk are not rigorously correct. But in the paper, we remove this so that we need to modify that. Okay? But here, anyway, let's assume it's fun. But here, anyway, let's assume it's bonding. Uniform Lipschitz continuous in X and μ, yeah, X mu with a Lipschitz constant and a continuous CMT. Okay? So that's it. That's our conditions. So some features, of course, the first day is the path dependence. Second is we allow for volatility control. And also, I think for this solution theory, the main feature is it could work for degenerates equations. Degenerative equations. So we allow sigma to be degenerate. But it's not free, there's some price behind, so you can criticize later. But right now, everything looks perfect. Okay, here is the main result. So I want to present the result first before I even tell you what the discourse solution is. So this part is more impressive. The definition part is less. The definition part is less. It's a little ugly. We'll see. Okay. Anyway, so we'll define this quote. Oh, yeah, I even didn't introduce the HGB equation yet. But is that you saw in Matt's talk more or less? Okay. So we have a, so first we have a regular, that's straightforward. That's quite a standard, yes. So the value function is the data visible solution, and we prove the component principle, basically. We prove the compiler basically. Basically, that's the language. Okay. C is the path. What? C is the path. C is a path. Yeah, always a path. It's adapted, so actually we should write it as a where to T, yes. So V is dependent on the whole process, it's not on the path of the process. So when I write this, it's uh it's uh it's not a V of T of C omega. V application or makeup. It depends on the whole process. So actually, you can think of it's low. Just later on when I construct the test functions, the test function will not be low-invalent. Basically, that's the issue. Yeah. So it's globally dependent on the whole process, not a not a test. Okay. What's the norm you use out to say? What's the norm you use on to say? Which set here the unit? Yes. So that's the uniform norm. There's a norm here that we have S. Yeah, yeah, these becomes random variables processes. Yes, these are all stars. But actually in the paper, I tried to distinguish to see. I put the omega here when we refer to the task. Well, it's a two argument, yes. So if you get confused, just kind of find it. When we see Where we see expectation, inside it's better. Okay, so again, as I mentioned, so these up to here actually we can talk about in increased definition, increase the discourse function itself, it can be in these space, okay? But the tester functions will be i in in the process space, not as a say the tester functions are not allowed invalid. That's that's the message. That's the message. Of course, I'll cheat again because otherwise the construction is too complicated. So I'll just keep the main turn. So let's say F was less important, B less important. I'll just keep this. And this, I also drop the low part, but it depends on the law. Okay? Depends on the law. Otherwise, in any case, there will be low here. Okay? Just to simplify the notation slightly. So the So, the main charge of course is the basic solution. There is a comparison principle. Yes? So, to my understanding, I mean starting from the standard physical solution in the PDE literature, there are mainly two types of approaches. So, if I understand correctly, Leon's in the beginning, earlier papers used this approach. Yes, approximate the value function by smooth functions. And then try to prove. So, this cause the sub-solution, you compare. Because the sub-solution you compare with the value function. And the value function somehow you can make it a smooth, a block symbol by smooth functions. So we are using this and we have this paper, you are also using this, yes? So try to consider the V approximate, okay? But this kind of approximation, most case, typically we need a sigma to be indegreen, because otherwise it's hard. It's hard, okay? It's hard, okay? That's my understanding. But the other approach in PDE-lateral Java code becomes much more popular is a WM variable argument using Ishi's lemma, etc. So in this, I saw in your matrix paper, Valuance Pylon. So then we were asking the questions. Actually, in the beginning, we are not thinking of the best dependence, but we are just after we saw this, we were asking, can we also do the doubling valuable arguments? But again, later, of course, it turns out the best. But again, later, of course, it turns out the pest dependency is also okay. Okay. Of course, there are more talks. I mean, there are more works. Hiang has several other works. It is such a several other people in the audience also have related works. So I'll just focus on the idea for the compelling principles. I refer to Mattis. So we will use a double-valued argument. And now let's see what data is. What time is it? Okay. I think basically, more or less, I'll skip this part. So, classical solution, mainly we say what the smoothness means, yes? But later for the discourse solution, actually, these smooth functions will serve as tester functions. So, actually, instead of test solution, I'm introducing the test functions. Okay? What does smoothness mean? So, very quickly, we are working on the process space, not as a loss space. So, in the loss space, we have the Leom's delivery. In the law space, we have the Leom's derivative, it is our linear functional derivative, it is such that's more or less standard. And in the past-dependent case, in the past-dependent case, so here I also worked on it, we have the follow-up and DuPier's work. Similar idea, introduce the passive derivatives. It is such an easy formula will hold two. So now in this space, I'll define the derivatives directly by the so-called intellectual formula. Okay, I mean, this will become. Just formula. I mean, this will become my definition of the solution of the derivatives. Okay? So eto formula is not a result, but the definition. But we can easily prove if it's smooth, they are unique. So that's the good side. And actually, we don't care that much because later on in the test function, we don't apply to general U. We will only apply it to this guy, very special. We only apply the definition to this. So actually, I even don't have to introduce the definition. Okay? It's just for the tech. Okay, if just for the test function purpose. So that's a straightforward we can compute it. It's a simple process. Okay, so here is the equation. 2 refers to this? No, no, kappa. 2 is a square in q. That's a square in the global. That's a square in the global. Square. Yes. Yes. Why do you have a bottom top? Bar means time and the space. Time and the space. Yes. Okay. Let's escape other derivatives. So now that we apply the e to also the definition of the derivatives into the DPP, that's very straightforward. So in the end, the equation looks like this. Again, this is the whole process, not the path. Process not the path. So, when you see expectations that you will see these could be passed, okay, let's forget about those stuffs. Yes, something, it's something. Okay, sometimes it's the process, sometimes if you go to pass, then you need an expectation here. Okay? So here, here, under my assumption, B is zero, F0, so that actually that's it. But in general, you have the B part and F part. Okay? Info I pi I pi in the process. For iPhone is a process. Right now, here is a kind of a control. So that's quite a. And this proof is easy. If the value function turns out to be sniff, then it's a unique classical search. But unfortunately, we are not that lucky. This remark, technically, it's not important, but it's very inspiring, I mean, for the idea, for our approach. For the idea for our approach. So, first, when it's past state-dependent, we can rewrite it. I'm sorry, no invaluant, we can rewrite it, that's fine. But it's this, we saw it in Meta's paper. So, actually, in this case, if we can view the partial mu v, now it's the Linux derivative, as a function of x, as a function of x. Rather than instead we write it as Instead of writing as this, instead of writing as this, I'll say this is a function of x. Okay? As this is a function of x. By the way, the passive derivative, you may feel that should be a pass. Actually, the Leon's derivative. Sorry, not a Leon's derivative. I mean the DuPier's pass derivative. This is not not a pass, okay, it's indeed R. Okay, it's not a type of. But anyway, Okay, it's not a typo. But anyway, so you can write as this. So it's a first-order equation, not a second-order equation. So in terms of partial mu, we don't have a partial mu mu. Okay? It's a first-order equation. That's why we can avoid the issue lemma in the proof. But as this guy is viewed as a C1, as a function of X, that is the H D B here, it involves a delective. So it's inf first order but it's infinite dimensional and It's infinite dimensional and it's an unbounded operator as a function of so that of course we want to borrow ideas from the literature of PDE and infinite dimension system. Yes? Okay. So what do we do? Well the main trouble is of course the comparison principle. But we have the freedom to define basical solutions yes. To define my school solution, yes? All our papers and definitions are different, yes? Okay. We have different definitions. So the circle of the definition basically is the choice of tested functions. The choice of tested functions. So we have some flexibility on the choice. In principle, if you put more tested functions into it, then you need to check the viscosity more. Yes, you need to check it for more functions. For more functions. So that the existing part will become harder. But then it will help for the uniqueness part, for comparing it will be easier to construct the test functions. Okay? So the standard way, of course, we consider this, but we couldn't prove the comparison principle. And now I want to help for the comparison principle. So I want to add more functions in it. I want to enlarge the space. Okay? So that motivated for the PDE literature. There's a PDE literature. We'll add a guide here. So, this guy obviously is not in C12 anymore. But I'll add a component. My test function will look like this. That's exactly what they did. Okay, we'll add this guy. And I put a six here. Now this guy, our function of the process with six moments, that's not a typo. Okay, I'll explain later what's the reason. But I know. But the main thing is this guy. Main thing is this guy. Main thing is this guy. What's the new guy? It's not a C12. Okay, a little ugly. And there's a fork here. So that's an interesting fact. I guess everybody knows. Okay. Okay. The my minus two. My minus two is because uh my test function is the phi the phi later I'll construct it will be in the sixth moment. Construct it will be in the sixth moment. So I will take a derivative, it will go to the first moment. I need to control the first moment. And the z di will help to control the fourth moment. So I wanted it to be fourth moment. That's the reason. Okay, second director. So P is, you say C wall two. C one two C wall two is in the path space, but when you differentiate, you're also differentiating with respect to the on source zero. No, no, not a not at the No, no, not a not a derivatives. The derivative over here is what I missed it out, I guess. So that's the part I skipped. Yeah, I had moved. So derivatives are. So it's this. So this is a whole process. So that's deterministic. Okay, that's deterministic. This is easy to understand. You freeze this. Why I put a T here. I'm sorry, there should be no T, okay, it's a pass dependent. You freeze this part and let this move. So now here is the minor. Move. So now here is my notation is this is still the whole process, not the path. But this guy is a random variable. This guy is able to random valuable. That's less than that's less important. But you have the first derivative immediately because of that. But the second derivative XX is also considered by this also. Yeah. So that's by a choice that would differentiate under Sikha market because this should be true for all the sicker markets. And it's equivalent to that to PSD reactor. Of the Dupier's directive. When I should say Dupier H should be the combination of Dupier and Lyon's directive. Yes, when in this case. In this case. Okay, these are ugly stuff. So I motivated the four, but I didn't motivate six yet. Okay, I'll explain later. Why six? So these are the test function, the given t. The test function, the given t0, the test function start from t0 to t, we will take the following for it, has these parameters. First, there's a constant here, okay, and info i phi. That's important, of course. So we have a parameter t1, kc0, kasi1, zeta 0. Okay, they are all processors. So that t0, kasi0, zeta0, that's a fixed t casi. Here it's a t1, kasi1. Okay, later on. T1, Ka C1. Later on, actually, it's doubling valuable. So this will be T, Ka C, this will be T prime, Ka C prime. We will double invaluable, yes? Later on, okay? And then this takes a special form here. This takes a special form here. Okay? Given these parameters, T0, K0, etc. So T. Uh there are some perspectives on the choice of this. So right now we are using this, it works. Now we are using this, it works. But we may have some other choices. So we are still debating what's the value. So here is a part if we want to criticize, I really appreciate it because maybe we can improve it. What is sigma? That's the coefficient, yes. Of the yeah. Of the equation. Or if different equations have a different So that's part that we ourselves are criticizing. So right now then the definition will be model specific. So if we change the coefficient, the definition will be different in some sense. Yes? So one possibility is we allow for more parameters. We can say that put this sigma as sigma t order, which is also a. Sigma T order, which is also a choice. But then we are adding more. But not as you fix the sigma. I consider all sigma with the desired regularity. That also works. That also works. So if people keep criticize and say it's too model specific, most of all I think it will change it, yes. But it's it's too model specific. Definitely sure you have different definition content. But that that that also works. These these are slightly easier, right? Works. This is slightly easier, right? So the presentation. But thank you. Okay, so these are kind of ugly guys. So, yeah, again, unfortunately, it depends on this specific one. But the good thing is, well, here in notation, I didn't write the PI files, but in general, it depends on PI files. Yes, the log. If we the PI files is still needed not involved. Is still needed not involved. So, so this guy, this guy, we can compute a semi-expressed through some forward-backward equations. That's why we want to write now we keep the same sigma. So then this calculation will be kind of straightforward. If we consider all possible sigma, then it's more. But anyway, okay. In more special cases, like the linear projective cases, we can actually solve this explicitly. So I because we added this guy, I don't want to add too many. So if you add a fewer, it sounds better, yes. Ideally, it added nothing, just zero, that's ideal. It couldn't work. So I want to add as few as possible. That's why we didn't consider all possible systems. But I know. Okay, another good news is for this, and that's crucial. If I plug as any manager, If I plug the assignment multi-variant to it, and then this is absolutely contained as a function t. Again, this is a deterministic function, okay. So, probably I need to make it slightly more. So, so these guys are two T's. I didn't write it. There's another T here. Usually, in this stochastic model, these guys, the past directory is you freeze this, you just shift this, okay? You just shifted this. Okay? Because this guy involves the Berlinian motion, the stochastic part. Usually we don't expect relationships anymore. But remember, here we have the expectation here. So the Berlinian motion part, actually, after the expectation, it's gone. So this guy is still absolutely continuous. So here I'm moving both simultaneously. So that's because this is a deterministic function. We are taking the expectation here. So it's absolutely continuous. Okay, so it's absolutely continuous now. We can talk about the derivative. We can talk about derivative. That's the standard time derivative. It's a determinist function of t. Okay, standard derivative. So it exists omnipresent for t. But unfortunately, this is typical, it's not continuous. Because it's not continuous, so let me move. Yeah, because it's not continuous, so later on in the definition, I cannot just say put it at the time t. At time t, cancel this. I cannot do that. Discontinuous. Okay. So in the definition, it will. So in the definition, it will look like this. Anyway, so once after we introduce that, I think this definition will be kind of straightforward, quite standard and all. So I'll consider phi plus plus C to be my test function. Phi is smooth, but I'll require to, I'll apply it only on, you can say it's a C12 chi2, it's okay, but I put a 6A here just to emphasize later on I'll consider only processes. The only processes with six moments. Okay? So we have these test functions. So if we test the function, if test function, if it touches at this point, it's greater than equal to zero. Subsolution, greater than equal to zero. Again, again, if this guy is continuous, then you don't need to write this, just add the T, everything added T, that's it, yes? But here it's just continuous, so that's the way. And a sub solution, similarly and a solution, of course, of if both sub and a soup. So that's standard. So that's standard. Okay, so that's our definition. And again, so here, oh sorry, here, because this construction involves the others, they are all processes, so it's not low-invalid in terms of this. That's the lesson. Okay, it's not low-invalid. Because it depends on this case 0, theta 0, because it's such a. Okay, so that's the issue. We are not able to. We are not able to work in the in the in the measure space a few a few remark right I I raise it to six then in the in the proof in the proof all the contradictions will be on six only but it says that the solution itself will be required to be continuous in chi 2 so that if we So then, if we prove the uniqueness in chi 6, we obtain uniqueness in chi 2. Yes? Okay, so it's a it's a it's a so it's without a loss of generality. You just need to prove the comparison on the on the Cassie which has six moments. It's fine. It's enough. Okay, also roughly speaking from here, because my Pasi is kind of a special. So if once I fix Pasi, so that it looks like the phi, which is smooth, is a standard type. smooth is a standard tester function for u minus c. So just a quick remark. Okay, and to the existence is quite straightforward and not too much to say. Comparison principle. The first main difficulty is not locally compact. This is not, this is even more. So in our previous works we made a serious effort to try to make it compact. And Meta's work also And the method work also locally, I mean also try to make the space locally compact. Yes. But then there's these so-called Boeing Price valuation of principle. Here he is quite familiar with it, so he's using it very much as well. Okay, it's it's amazing. Actually, the proof is very easy. It's a valuation of the of the acclass valuation of principle. Okay, so very briefly. So very briefly, so we say the option, it's a it's a so let's say it's a complete matching space, so it's uh x and y null, or x1, x2 now, okay. It's called a gauge type. If if it's yeah, diagonally it's zero, okay, and also it's kind of the inverse is continuous. Usually we say continuous is if the distance is small than this. Is small than this is small. Yes? That's continuous. But the gauge type is kind of inverse is true. Okay, inverse is, of course, it's not an inverse function, but in this time. If the optional is small, then is close, then the two points are close. Okay? So actually, D it itself automatically certifies this. So you can just use D. But later on, we'll use this guy to construct a test function, and D is not smooth. Because the test function has to be smooth. To be smooth. Okay, so that's the thing. Okay, so there is this important lemma here as the validation of principle. Say for any function, if optional is a gamma, optional is a gauge type, so you don't need to read all these, oh, actually I forgot to get rid of the oh yeah yeah, that's correct. Anyway, you don't need to read all the details. The point is this. You have W here. You have a W here. You want to maximize it, let's say. You want to find that x star. But the space is not compact, so we are not able to do it. Okay, we are not able to do it. We don't know how to do it. This requires a compactness. The point here is I can introduce another function, which is very close to this. And this function will have an optimal control. Optimal argument. That's the idea. So these two are close and these two are also close. And these two are also close. That's basically that's the idea. So without the compactness, we don't have, we cannot have the optimal argument. But I can modify the function slightly. And that modified one will have an argument. So this is a modified one, which is close. Okay? You have all these, they are, they are, yeah, they are close, it's small, and later on when we actually apply the derivatives are also small, so this and this will be very close. This and this will be very close. In other sense, we need. Okay? And this guy is optimal argument exists. This guy is optimal argument exists. This will be flashy. This will be smooth. Yes. Okay. Now I said we need this guy to be smooth. Yes, apply to our situation. Oh. Oops, that's the ugly part. So you look at these pathways. If it's a state-dependent, if it's a state-dependent, actually, it's easy. We can just do this. Okay? Actually, if it's indeed a state-dependent, we just need a four. Okay, we don't need a six. But as a main trick, that's the Jinjin's trick when he worked on the path-dependent PD. So he in the path-dependent case, he somehow he made it uh smooth, just like depending on the path. Depending on the path. Okay, of course, we don't check here. Now I can explain the six. So first, these guys have to be even, yes, otherwise you cannot differentiate. And the six is the lowest one. If we change this to four, if you change this to four, I'm sorry, I think this should be twelve. If we change it to four, then the second derivative will be discontinued. The second derivative will be discontinued. So six is a small story. So, six is a small story. Okay, of course, if you go higher, that's fine. Okay. So, this guy will be smooth. So, you fix this, it will be smooth. Fix this, this will be smooth. In our previous sense, the pattern escaped as a function, and it was that kind of sense. And with all the desired estimates, it will behave just like this. Okay, I will cheat again. Actually, I'm already running out of time. So, when I So, when I construct the W below, I'll pretend it's compact, so I will not get to this bunch. I'll just use this, and I'll assume this guy will have optimal arguments. Okay? Pretend. But anyway, after this guy, we add all these stuff, so we can estimate the derivatives as well. It behaves very nice. It does not add trouble. Okay. So, okay, now very quickly. Can I pull a few minutes? Thank you. A few minutes. So, very quickly, I think this is kind of a standard. So, that's very standard. Here I want to control the moments. That's not a big deal. And these are also standard since I'm talking about a six. And this is the tricky part. Why I put a four here, why I put a five or six here. So I put a four here because later on my test function. Four here is because later on, my test function will use this. Then the derivatives will be first moment, second derivative of first moment. Yes? I want the derivatives to converge. The first moment converges. I want to get this. I want to get this convergence. Okay? So these four come from the second derivative of this. So I want this to be convergence. In order to get this, I need to add this part. I need to add this part. Okay? And these five six, it's very carefully calculated. It's very carefully calculated. It should be between 4/5 and 1, so 5-6. Okay, so this is the amount to get this. So that's just here is we keep it the same time. Keep it the same time because we cannot construct a test functions. We need to differentiate the T and S as well, T T prime as well. So that's the next one. So I injected my differenti design. So my differential design. So the the first part is kind of standard. So these are fixed. That's the one half of the one I got previously. So this one is fixed. Now I have K C T here, Casi prime, T prime. I'm sorry. T prime here. So that's uh kind of a standard. So n here, I put a two to the sixth minus one because I'll use this term to control this turn. To control this plan. To control this term. To control this term. Okay? So I'm simply using this factor. A simple factor, say 2 to the 6th minus 1. So that's K C minus zeta 6 plus K C prime minus zeta 6 greater than equal to K C minus K C prime to the 6. That's the simple fact. Okay? So I use Okay? So I I use this to control one part. So this part. Then similarly we want to control this part, yes? Then naturally you may say why don't we say force, so two to the four minus one, cassett minus zeta t, that kind of thing. Can we do that? And the answer is no. The reason is this. So imagine I replace this ugly part. Imagine I replace this ugly part with this. With this with this, say, casi t minus zeta t n epsilon to the fourth. Imagine I replace this guy by this. Okay? But then I'll construct a task function, yes? Then the task function will consist of this part. Then you need to take a derivative of this part. Then you need the convergence here. Then you need a convergence here to the two. Agree? If my test function consists of something like this, so the second derivative will be square. So I need this. Then here I need to add another term square. It doesn't work, yes? So here the trick is, the trick is here, this guy, this add this, the 2 to the 4 minus 1, this sun, also greater than equal to this. So that sun will go less than equal to. Sun will equal to the force here. This guy. This guy. So this turn, this term will take care of this. And that's why we, because this will go to the test function now, but that's my new P C term, yes? That's the whole trick. That's why we introduced that per C, the X-ray term. This does not go to C1, 2 derivative table anymore. We'll consider D over T. Anymore. We'll consider D over DT directly. Okay, so that's the idea. So anyway, so then we can get the desired estimates and finally we have the compiling method. Okay, thank you. Sorry for the time. Any more big question? What do you think? A big question. If I were to restrict myself to the case for Restrict myself to the case version.