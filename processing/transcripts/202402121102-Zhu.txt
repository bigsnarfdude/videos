You know, I thanks the gene and also Shoto and also Helen for the invitation. And actually I put my L into a very awkward position because I didn't really read the emails. I just agreed and just send the abstract. I don't know whether the topic I'm presenting is connecting with the theme of the workshop. I hope so. And also, this is the first time I give this talk. This talk, and because this, you know, is something did many by my collaborators, my former students, my and many thanks to my collaborators for all the works we did. And actually the motivations. It's my first time to give this talk. Bear me with anything I say something wrong and the basic what No, you see the other basic I I didn't do it. But it doesn't matter because I'm gonna But it doesn't matter because I'm the last keyboard is moving. Okay, there's this by just stuff on it. Don't let you glow out it. Okay. Yeah. Yeah, and one thing is, I think since 2018, I worked at DD for three years. Chinese Uber is a ride-sharing company. And actually, one thing I have been working during that time is basically trying to analyze the data from the Deep. And actually, the other channel is some. Actually, the other experience is so valuable to myself in the sense of, and I personally understand the data science much better than before, because I did a much more project than I can imagine in my life. And that's the one thing I learned. And the second thing is basically I learned better about two-sided markets and all these kinds of e-commerce stuff. And basically, how do we dig into the business schools and work with all these e-comm people? And the problem is very hard, and in general, because there's a lot of challenges behind it. And actually, after several years, and at the beginning, I don't know what should I do, how much I can contribute to the company. And actually, after several years, we eventually, and my collaborators and my friends, we come up with this kind of general goals. We try to develop this. Goals, we try to develop these marked other zeros in two-sided markings. And we use a lot of such a knowledge and also the knowledge for operational research and machine learning and cover inference. And actually, our general goal is to evaluate and improve the operational efficiency of the rally sharing paradigms. That's in general our goals. And actually, the tools, in terms of the five major modules that we try to develop, modules we try to develop events the supply demand diagnosis and also supply demand forecasting and also life value analysis for customers and policy evaluation and policy optimization. And actually after I come back to from the DD actually I spend more time to write the papers these days because when I go to DD I don't have any time to do any of this kind of research. That's too many meetings every day and I just do all kinds of projects. Do all kinds of projects. But now I have more time to write all the ideas out. And actually, this is one of the topics, the five topics, one of them, basically, is policy evaluations. You're going to see a lot of papers come up from my group. It's basically we do A-B tests. It's very straightforward, right? Everybody is doing A-B test in pharmacy and other kinds of areas. We basically compare the new old policies in spatial tempo system. The difference is we have this. The difference is we have this kind of strongly special temporal systems. The system is very complicated in the sense of we have a strong interference inside, and all the existing methods doesn't really handle the strong interference very well from both theoretical and practical perspectives. And actually, the goal is basically we'll try to improve the service qualities from the three different sites. One is the drivers, another one is the riders, another one is the platforms. Another one is platforms. Each state holder has its own kinds of interest. We have to balance all of them. That's basically something we are working on these days. Technically, it's not straightforward at all, and also it's very challenging. And this is the basic slides I generated yesterday night when I prepared the slides. I didn't prepare the full slides, but this is why I use the Chat DVD to help me answer the question. DVD to help me answer the question: What's the connection with the topic that I'm presenting today and also the translator working the genotype? But I think the answer is quite close to what I'm thinking. And first of all, it's enhanced the robustness. That's why I'm not a quantile person, you know, but I get interested in quantile regression. That's one of the key reasons. That's one of the key reasons we have basically enhanced robustness. The second one is improving interoperability. That's also important for business aspects. And the number three is promoting fairness. This is also important. And the last one is quantifying uncertainty. All these are the four topics are quite important. That's one of the key motivation for us, the developer, to focus on to develop the method of related quantile regressions. I'm not a quantile person, you know, the ball is, but I think that's the important topic I should. The important topic I should focus on. That's one of the reasons that I asked some of my colleagues to work on this topic. That's the reason you see a series of work on this. And this is just to give an illustration. It's basically the traditional average treatment effect is very sensitive to allies. And you can get pretty bad results sometimes. And the medicine itself, okay, one thing I did yesterday. Okay, one thing I did yesterday basically just to review the whole literature is basically about quantum regression. I wanted to look out of ten different papers. I read through all the papers. And actually, I remember most of the things I read them before. And basically, you want to do the quantile relation. Everybody, I think here are pretty familiar. You want to, I found the quantile functions y given x. And basically, you're trying to solve these kinds of minimum. these kinds of minimization problem minimization problems and using checklist athletes class of the class neural network or other functions okay you could use the parametric functions or non-parametric functions here here I use the neural network because in practice usually the number of X the features we we considered usually more than one hundred at least the most problem we have. Because we have our thousands, millions of the subjects. Millions of the subjects, sometimes even more. That's the reason, and then we use the neural network. And actually, though, we basically object functions of distribution learning, basically we try to minimize these object functions. Even in this expectation, we can use the average data to average to approximate this. Okay. And this is the basic a general formulation. I think al almost everyone here knows these formulations. I ch yesterday not yesterday I I just heard it remember myself. I just remember myself. And actually, one issue in the field is causing quantile problems. And actually, in particularly, we know that even x is one dimension, and you plug into the models and that you do optimization. If you don't put the constraint inside, basically, the learned quantite curves does not really sort of centrify basically this monotone kind of relationship. Relationship and this is the code causing the problems. Okay, there's a different way to handle these problems. And basically, I just show you one example, simple examples. Basically, from the left to the quantile estimators with crossing, and the right one is quantile estimators with no crossing. And you may see these some of them might be here and all this here. And there's no crossing and risk crossings. With crossings. But in practice, I tell you the fact. These low quantiles, high quantiles are most important cases in many business settings. And in the business, even though the middle part is important, but for the business aspect, the tail part is more important. Because we want to prevent some bad cases to happen. And that's very important in practice. And this is a small problems, you know. This is a small problem, you know, it seems like. And basically, one thing is when we started to work on the project, the first one, could we come up with new narrative models to solve these things? One thing we can just follow the literatures, basically put all kinds of nonlinear constraints on it. And actually, but if you work on the neural network and use different architectures, that probably are issues because it's not very straightforward. And actually, what we did is And actually what we did is, one of my former interns, now in the Beta Dance, and what he did is basically we designed these architectures. And this is the input features, this output. And actually we decompose these kind of things into two layers. One is the data layers and one is the random layers. And we call this kind of non-crossing basically quantile. a non-crossing basically quantile architecture is basically the kinds of operation. It's kind of plus together of the V and the D. That's the two different lengths. And the key ideas is you can build our papers. That's the exact formulas over there. And I just show you how to do it. And suppose you have this kind of at the beginning, this is an outer base e-learning. Of base deeper learning neural networks. You could have positive or lactative, right? You have no control by that. Okay, but it doesn't matter. And then you apply the activation functions to create a kind of non-active output. We project it. And then we basically, this is a monotonic model, right? Whether it's a minus. And basically we take these kinds of cosine of the functions we generate along crossing quantiles. And for this one, And for this one, and also we centralize it. And actually, the centralized is the V part. And the D part is basically kind of one of the problems. And then basically, after you do these operations, only two things you need to do is you have this non-crossing quantile neural network. Basically, they have the V and the D. These arbitrary quantiles you can put inside in certain degree. And then you basically, this is basically. Basically, this is basically the neural network we can see. And this is the preserve of these kinds of monotonic properties. And actually, this is some type of insight, but it doesn't matter. This is the general non-crossing quantile neural network we propose to address the issues. And actually, LIX is basically a simple linear operations, Wi-X plus BI. Class BI and the sigma just remove functions, active functions. And this is the class of the NQ networks for certifying the problems. This is the basic function class we can see. NQ network. And also you have depth, you have the width, and also you have the size, and also you have the number of neurons. This is basically, we give a simple approach. Basically, we give a simple approach. There's a few papers to talk about these issues in the literature, but this one we developed here is pretty easy to use and it can address the problems. And then also the formulation is very simple. And you can read our paper in KDE last year, and this is a pretty interesting thing. And the next thing is basically I have a collaboration with Jiao Hua and also some of these trainees. And actually, one And actually, one project we did is I threw the model to the Guohou and Daisy. I think it just proved the theory. That's what he did. And actually, he basically proved this kind of low-asymptic upper bounds. This is very complicated. It involves a lot of parameters. And he tried to convince me this is simple, very, you know, unknown thing. I know how to prove it, but I just. I know how to prove it, but just the text of the middle. But in general, you have the stochastic errors and increased the basic increasing narrow size, but decreasing the sample size. The second one, approximation errors, is bias, basically decreasing in narrow size and the smoothness of the target point out functions. This is the first theory we proved in the paper. And this is basically the numerical. basically the numerical are the graph graphical basically presentation of the bias and the various trade-offs and this is the typical as a standard calculation in the statistical learning measure choose and this is the basically is the learning guarantees if on the specific case the path the the the the length and also the depth of the neural network and actually Neural network, and actually, you can achieve this kind of rate. This is almost an optimal rate. And for that, okay. And this is another extension of the theoretical results. Basically, we made another assumption because in the previous one, the input to the features dimension is the D. And here we assume that basically the D has the low dimensional magnitude. has the low dimensional manifold structures. That's the basic assumption that basically the D0 is the manifold dimension low dimension structure of the input X. And actually this is basically typical like a rolling twist row and this is a peak database. And actually the bound can be improved because if you have these kinds of Have these kinds of structures inside, and actually, this is a they see that the D can change the D zero stars because of that. And actually, we just basically, this is a, for this kind of project, we are not driven by writing a paper for KPE. We are really driven by doing all kinds of different projects. And actually, this is why ideas can be useful for other purposes. Use it for other purposes. And the one is basically related to basically we can use this one to do the causal inference. And also, we can also use the same ideas to do the policy optimization. And this is basically we can use this one for conditional average treatment effect. This is typically basically the UI designs for the seven app like TikTok or other meta. And basically, how to personalize. And basically, how to personalize the UI for each user based on their preference. These kind of questions are mainly driven our development. And actually, this one thing is to show you how we apply this one to the condition of average attribute effects. And you see that this is the general knowledge about this definition and also assumptions. And this is the key things we improve. And actually, this is the basic. And actually, this is the basically one pretty popular basically, the two deep learning model structure architectures for the tilet or the dragonet. Both basically, they have these kinds of input features, then it's the best net. And basically, you're doing these kinds of transformations, then go to the T tower and the R towers. And you are not familiar with this architecture, the next slide tells you more. The next slide tells you more clear ideas. The best way to basically learn a shared representation for all the treatments because you have multiple treatments. And the R is associated with each individual treatment. But the key differences here is basically for us, we plug in our non-crossing kinds of quantile based neural networks here instead of compared with the currency. In that case, we can calculate this quantile basic treatment effect. Training effect. And also, we can use this one also to calculate the average training effect. That's the key difference between our method and compared with this, another previous little method. And this would basically tell you numerically how do we, mathematically how to do all these kinds of optimization. For k tau, for r towers, basically we consider the quantity of the Huber laws. And the k is the number of the quantum. In practice, we can. Number of the quantiles. In practice, we can select even one quantile or 1,000 quantiles. In practice, it depends on the business, the specific problems we're working on. And actually, also this is the T-towers. And actually, in practice, this basically is to try to estimate the score estimators. And actually, we can combine this. The final loss of the D-NATH is basically combine axis of. Is basically combine X is the features, T is the treatment, Y is the reward. And then basically combine all the things together to do automation for that. And this is basically, we have proved the theory behind it. This is the third theory we proved. Basically, we have three component one is the best net, the second one is RNAT, the third one is the T-Net, and actually, this is the basic assumptions we impose on it, and actually, this is the theoretical. And actually, this is the theoretic result. It's too ugly to me. Why don't you make it more simpler? But it's okay. I think basically it's pretty interesting theoretical results. Some people like it. That's the reason we need to submit it to some statistics journals. That's the update basically another coronary is known guarantees for some specific cases. And actually this is uh tell you if you how to really use the the the tools, the architecture that we developed basically for conditional treatment. Actually, you can use all for other purposes. Well, there's two applications we consider. One is basically for some of these kinds of the target functions, you have monotone constraints. For instance, basically for some of these Instance, basically, for some of these kinds of businesses, if you give them more kinds of incentive, basically your response function either wants to increase or they will decrease. You can use the ideas to do it. And another one is basically zero inflation basically with a DNA. Basically, for many cases, you will see a lot of responses contain a lot of zeros. Okay, only a small amount basically have a non-zero response. How to deal with it, and also you can use. To deal with it, and also you can use our idea to join to handle it. That's the basically, and I hope that people can use our method for that purposes. That's a different application because all these motivations come from our real applications. Because we have to do this type of data in order to really apply this method. And actually, we use the two semi-synthetic data sets. One is IHDP, another one is ACIC. There's two data sets. A CIC, there's a two data set that you roughly know the ground truth. And actually, we can, because this one we know ground truth, we can calculate precision in estimation of heterogeneous effects. And actually, we compare with the steroids method. This basically, these are two data sets. And this is the in samples. And another one is basically a testing set. You see that our method is dramatically improved, compared with the existing method. Method. And this is the real data set. And actually, these are the two kinds of important data set. There's a lot of subjects inside for this two data. So we ran this experiment for two days, two weeks for the two basically two different experiments. One is advertise, another is search. Okay? And advertise is mainly related to the different kinds of companies, basically. They have a specific. Basically, they have specific kinds of budget constraints. And actually, this is basically they pop up this kind of information and people click these kinds of buttons. And this one is a search, search count. You see that for this data set, majority of basic data is basically zeros. And this is basically the two kinds of challenges, real problems. We're working on basically, we try all the existing methods, and this is the use of the DNA. This is the use of the DNA. Basically, you see that we still improve a little bit, at least for some cases. And actually, we show you that basically if we impose this monotone constraints inside, actually, we will have again much more improvement than that. And because the reason is because in some tail cases, and actually if we don't impose this kind of constraint, the result is pretty bumpy, the tails. The result is pretty bumpy, the details. And actually, that's created a lot of the problems in practice. And actually, this is another basically the and also this is another second data set for the search because there are a lot of zeros in our data set. And actually, you see that if we impose using this ZI DNA, you'll see that we'll also improve a lot. Compare with this method. Compare our method because all the other methods. Compare our method because all the other method doesn't apply to heat. We didn't compare with the other method because all these other methods doesn't work. And this is basically the two key things. And also we did aberration studies. Basically, this we choose the number of the quantiles and for different cases. And this is some cases we do two hundred. And basically this is the for the simulation studies. And also we this is also the second simulation studies. Also, the second simulation studies, there's also relative differences or various tasks. Because while the data set, there are about 1,000 tasks. And we show that among all these 1,000 tasks, our method works better than the existing method, and it needs for more than 900 of the tasks. And this is generally basically in the reverse add examples. The optimal policy based on DNAT. The optimal policy based on TNAT, I text the about 2.8 significant increase in values to advertisers. 2.8 is pretty impressive numbers. And in the search examples, ZIDNET able to improve the number of such accounts about more than 13%. It's also increased a lot. Because in the e-commerce, 1% or 2% is a lot of money. Maybe you think about that basically. It's not about who have small samples. And also, additional DNA has been adopted by, we really use this in the company to improve the user experience. And this is basically an increase about 0.1% increase in the user activities. That's how the chipboard works. And actually, I tried to wrap up. Basically, this is the Basically, this is the one thing we do the treatment, the policy evaluation and optimizations. This is another basic thing we are working on, basically, application to distributed reinforced learnings. And this is the basically, we try to, this is the basic general formulations basically related to the distribution of reinforced learnings. And this is the basic algorithms basically using our Algorithms basically using our one-crossing the quantile basically method. And I just show you the theoretical results and also show you a pictures. This is basically tell you that this is one method, these blue lines, is basically the traditional quantum regression. Basically, the distributional kind of reinforced learning is our method for that. And then you see. And then you see that the conversion multiplies the traditional ones. And the conclusion is we have this kind of general method. Because at the beginning, the reason we do this quanta is because we think this is important for trustworthy in a certain degree. And that's the four key motivation for that. And then we basically try to develop a method for these purposes. Purposes. And this is basically. I share some of the key references if you're interested, and you can take a look at some of the papers on this topic. And finally, this is a JASA has a theory and method that has special issues on the artificial intelligence statistics in artificial intelligence. And I hope the people can submit some best paper to the issue. And also, happy Chinese New Year. Chinese new year. Great timing, and because we interrupt your talk twice, we still have some time for some questions. I'll start. So you use this human sound to enforce montonicity, right? Yeah. But one possible downside is that you think about it, you're adding all the lower tails together, right? Is that going to introduce some voice? Oh, let me ask. Let me ask another one. Why is it good? It's easy to include it, but why is it included if I think about the performance? That's a good impression. Because we automatically, if you look at our models, we automatically have all these, because the formulation we impose, we wrote them over there, guarantee that. That model tools, because you're implicitly to In basically to basically impose that one without solving the complex optimization problems. I think that's the one key advantage because the implementation is much stable. If you just impose some monotone constraint inside basically for particularly when input features high, I'm not sure the solutions you'll get is stable or not. But the lower cow is most difficult for compound representing, right? Compile referencing, right? I agree, I agree, I agree. But you're adding it all up to you know, every compile. No, we just make sure that basically ensure that basically this is the terabyte still sensitive without problems we have. But because we do the cumulative sum, basically we impose that one or the media handle that case. But I still agree with you because the post-tutorials have less data, but that's what we are issues. There's a different way in terms. Issues. There's a different way interpolating the data, you know. But I think the computation is straightforward using our method. That's the one key advantages. So I guess you could just start from the lowest compile. You could start from some compile where you can have more required estimation. Oh, I think you see that the reasons we did that, actually we did do that. Because we centralize it. The V is the center. The V is the center. Then the one we're using individual basic estimator. Then everything else is basic monotone. Yeah, because the V is captured the center, the medians. And everything else is basically going up. That's a monotone part. That's an elegant part because we impose the middle part has to be very stable. I think it's a different control. I think it's a different one. I think it's probably good that you start from the middle. Because your way is you just end up. Your way is you just add up. Let's say after activation, let's say lower tail is positive. You're going to add that number to everyone. You introduce the noises. If that lower tail is really bad, you add it to everyone, right? You go back to your example. If the lower tail is positive after activation, then you can add it, right? To every compile? Maybe. But so far, for all the cases that were considered, it seems like this formula. Considered, it seems like this formulation is the most straightforward approach to solve these problems. And if you can, you can take other approach, but this is the most straightforward we take because of that. I think the key thing is the last step here. We will estimate that the V, V is essentially this central part. And everything here is imposed a lot of tones because we naturally impose that, but because of the formulation, the B, the B. Nation, the B, the B, B, the V. If you read our papers in KDD, you will see that why, how could we impose that? That's the basic functions. This part is straightforward because we just choose the middle. It's very stable. And this part is basically just the impulse monotones. Then the problems I I agree that there could be the issues, but we need to invest them more because and so far we we're doing pretty good. So far, we're doing pretty good. We compare with the other quantile regressions method for deep learning, quantile deep learning, new level method. Well, the method is much. At least it's not worse than any of these things. We did all the simulation to compare. Because our approach is more straightforward. I'm not saying it's the best one. Maybe you can find something better than it. I take it. I take it. I have questions coming. Okay, so I see some of your real data applications, you show those competency tools. So how do you construct competency tools? I think in some of your data have confidence value. Plus, minus something. I forgot to call it the keyword they have. Some A and so how do we calculate this competence? I think we randomly submit the data. Like 80% is for testing, another one is for 80% for training, another one is for testing. We basically randomly submit. Repeated MyGo 100 or 1,000 times, I don't remember exactly. Because this one has one choice. You can use the data set. You are also a fairly large sub-size, although the task is small spread at the moment. But how did this have 1,000 tasks? You see that for our final results, there's the 1,000 replications. Actually, our method will work only better than the traditional method. It's about 900-something. This is also another set of the methods we don't beat it. I don't know the reason, but we're having another tensor is just interesting to work with. Okay, if no further questions, let's both speaker again. Thank you. I finished my job, my friend. In the afternoon, one third one forty here for photos. No, no, no. Well, we would say if I want. So my demand is like forecasting. And you're still going to be a scientist.    I think there's I don't know if you're public lawyers who can't do it.    But it's okay, I think it's it's really fast at least.