who is going to talk about the association, cock assets and artificially. Thank you very much to the organizers for making this workshop happen. It's great to be at Ben. Thank you for the opportunity to speak. I'm going to talk today about some joint work with Pong Wang on the decay conjecture. Many of you are Conjecture. Many of you are familiar with the Kakeia conjecture, but I'll briefly recall it nonetheless. So the Kakeia conjecture concerns objects called Kakeia sets, or Bezokovich sets. So a Kakeia set is a compact set in Rn that contains a unit line segment pointing in every direction. Segment pointing in every direction. And Bezenkovich constructed examples of such sets that have Lebesgue measure zero. That's a bit surprising. And the KK conjecture asserts that such sets have to have full dimension. Full dimension. So we'll take a Kakia conjecture every Kakaia set in Rn as dimension n. Now, this is not quite a well-formed conjecture. Quite a well-formed conjecture because, as we've seen even today, there's many different notions of dimension, and these different notions could lead to different versions of the Kakeia conjecture. The most commonly stated version of the Kakeia conjecture asserts that every Kakea set in Rn has, let's say, Hausdorff dimension in N. You could also ask this question for Minkowski dimension or we've looked at Fourier dimension, really for any version. This is an interesting question. And this question has been answered, at least in the case of how. Been answered, at least in the case of Hausdorff and thus Kofsky, dimension, when n equals 2. So this is Davies from 1971. So I'll just say n equals 2 until we have a satisfactory understanding of that situation. In dimension 3 and higher, the problem is open. And Boe's partial progress in this direction has consisted of fixing a dimension, maybe dimension 3 or dimension 4, and considering decay assets, let's say, dimension 3, and okay, we'd love to progress. Let's say in dimension 3, and okay, we'd love to prove they have the Kofsky dimension 3, Hausgoro dimension 3, but have you? We don't know how to do that. Let's try to prove some lower bound on the dimension of the KSS, let's say in R3. So there's been partial progress in that direction, or in R4, and so on and so forth. The result I want to talk about today is a result of Hong Lang and myself, which says that if we consider an easier type of dimension, so a type of dimension that likes to be large, called a squad dimension, then we can prove that decay sets in R3. Then we can prove that decay sets in R3 have full a SWAT range. So I will state that as a theorem. So we finished this result at the start of 2024. I guess the notation is 2024 plus. So every data set R3 has a SWOT dimension 3. And our three has a slot dimension three. Okay, so the definition of this logic convention is not particularly technical, but I think in 30 minutes this may not be the best use of our time. So instead of telling you what that is, I want to give you some sense of what it means to really get your hands dirty and show that I think KSS actually has, well, That actually has, well, either a small dimension 3 or what it would mean to have Minkowski or Health Groove dimension 3. Let's stick to R3. Just to get some sense of what this really means. And then time permitting, I'll give you some idea of what are some of the ingredients in the proof, what the enemies look like and how they're circumvented. Okay, so let's try to actually dive in. So, generally, the first step when studying the IKEA problem is we try to discretize it. So, we pick a small scale, which we often call diagnosis. Scale, which we often call delta, and we might replace a ket by its delta neighborhood. So when you do that, a k set contains, let's restrict attention to R3, a line in every direction. When you take its delta neighborhood, then you have the delta neighborhood of a line in every direction. So I'll say discretization. So delta is a small parameter, but really we're interested in the asymptotics as delta goes to zero. In the asymptotics, as delta goes to zero. So we should think of delta as being very small. Whenever we write any sort of constant, those constants have to be independent of delta. And so what does the delta neighborhood of a line segment look like? Well, I'll call it a tube. So it has width, delta in this direction, and roughly one in this direction. And I'll use blackboard volt to denote a set of delta tubes. So if I begin with a Kakia set in R3, that I take its delta thickening. 3, and I take its delta thickening, then okay, there's a delta tube whose coaxial line points in every possible direction. But if I infinitesimally perturb the direction, presumably the corresponding line in the cassette might not have changed all that much. So with the resolution of delta tubes, you might not see the difference between them. So really what's meaningful is to talk about delta tubes whose coaxial lines make angle at least as big as delta. Only then can you really distinguish the difference between them at resolution delta. Between them at resolution delta. So these will be delta 2's and they're going to point in delta-separated directions. So the direction of a tube is just the direction of its quaxial line. And how many tubes am I going to consider? Well, there's interesting problems for different numbers of tubes. But generally speaking, if I start with a Kakia set that had a line in every direction, then I can expect to consider a collection of Delta tubes where there's Collection of delta tubes where there's a tube in every delta-separated collection. So if we're in R3, the cardinality of such a collection is going to be on the order delta to the minus 2. And now the way that we actually get our hands dirty with the Kaka problem is we consider the union of these tubes, and we'd like to show that that union has fairly large volume. So, because Betzenkovich constructed a measure zero Kakia set, as delta goes to zero, if I discretize such a Kaka set, the volume of the union of Set, the volume of the union of those tubes can go to zero as delta goes to zero, and we're interested in the asymptotics of that. And for example, we can talk about different notions of dimension and what that's telling us about the volumes of these UVs and cubes. So I'll give some sense of what that might look like. Let's maybe begin with a lower Mukovsky dimension. Let's start with that, maybe roughly here. So, what, in order to show that the lower Minkowski dimension of a Kaka set is large, what that actually means in practice is we can say for, say, every positive epsilon and all sufficiently small delta. What does sufficiently small mean? I mean, it's smaller than some threshold depending on delta. Well, when you take t, which is a collection of Of delta tubes pointing in delta separating directions whose cardinality is on the order of delta to the minus 2. And we need to show that the volume of the union of these tubes is at least as big as delta to the epsilon. So the order of quantifiers is important here. For every positive epsilon, in all sufficiently small delta, our enemy, so in some sense you can think of our enemy gets to choose a delta, which is the scale. gets to choose a delta, which is the scale at which the Kaka set is being discretized, and they also choose the Kakia set in some adversarial way. They give us this collection of delta tubes. We have to analyze their union and show that no matter how they're arranged, the volume is still pretty big. It could go to zero as delta goes to zero. It's lower than any polynomial control. This is what lower Minkowski dimension means. Okay, upper Minkowski dimension, I'll write this here. That's a bit easier. So it's easier to show a set has large upper Minkowski dimensions than lower Minkowski dimensions. Than lower the cost of the dimension. So again, it's for all positive epsilon, all sufficiently small delta, we have this collection t. But now we get to choose the scale at which we are analyzing this K set. So we get to choose some positive scale, rho, which is at least as big as delta. And it has to be much smaller than 1. So there's a few additional quantifiers I'm brushing under the rug here. But instead of considering this union of tubes at scale of delta, we get. This union of tubes at scale delta, we get to consider it at scale rho. I'm going to write n sub rho to be the rho neighborhood of the union of these tubes. That's more or less the same as taking each one of these delta tubes and fattening it up to a rho tube. And we'd like to show that this union has large volume. Now the global host has moved a bit. The volume needs to be rho to the epsilon. So we could add in some quantifiers. I'm not sure if that's a useful thing to do. Maybe I'll just say it out loud. So if this makes sense, if we want to. This makes sense. We want to show that there exists a row. So for every positive epsilon, our enemy chooses a Kaka set, discretizes it at scale delta, which they get to choose. They give it to us. We look at that Kaka set and say, ah, it might look small at scale delta, but at scale rho, it actually looks quite big. We get to choose rho. Now, if we choose rho equals one, then yeah, it looks like the unit ball. So that's clearly not the purpose of what we're doing. So, what do we need to do? We're doing. So, what do we need to say? Well, for every epsilon, there is some positive eta, so that you give me a KS set at scale delta. I can find a scale rho, which is at least as big as delta and substantially smaller than 1. So maybe less than, let's say, delta to the eta. So eta could be a very small number, but as delta goes to 0, it's still going to 0. And I get this huge range of scales. Any scale between delta and delta to the eta, eta is tiny. I get to pick any row that I want in there. I get to pick any row that I want in there, and I need to show my decays that's bigger than that scale. So it's much easier to have large upducosity dimension, but we get to choose the scale that we analyze the problem. You can make life even harder. You can look at Hausdorff dimension, which I'm not going to have any results to discuss, but we can look at the Hausdorff dimension of K. And it's the same sort of thing where your enemy chooses a scale, analyze the k-set at, and gives you this collection of tubes at scale delta. Of tubes at scale delta, but they make your life even worse because instead of looking at the volume of the union of tubes, your enemy also chooses a subset of each tube in some adversarial way. So maybe I'll call that y of d. And we need to show that this is bigger than delta d epsilon. Now, of course, if they picked the empty set, that would, this clearly can't happen. This inequality clearly can't be true. So what's going on here, y of t is chosen by your enemy, it's adversarily chosen. It's a subset of t. We call it shading. A subset of t, we call it shading, but it's a reasonably large shading. One example would be the volume of y of t needs to be bigger than the volume of t times something which goes to zero, but fairly slowly as delta goes to zero. So maybe, so log of one over delta blows up as delta goes to zero, but fairly slowly, so it's a p inverse effect. So your enemy chooses a shading on these tubes, and even if they manage to throw away some fraction of them, the volume's too big. So this is moving upwards. So, this is moving upwards is harder to prove. Downwards is easier to prove. The very bottom thing, which I think I'll need a new board for, is a slot dimension, which is even easier to prove. And it's of a similar flavor to this statement, where you give me a collection of tubes. I get to pick a scale row, where my set looks big. But my life is even easier. Instead of saying, so this is a subset of roughly the unit ball, because KS sets are compact, might as well be inside the unit ball. But I get to zoom in to some. But I get to zoom in to some smaller region. I'm going to pick some value of r, which is bigger than rho, but less than or equal to 1. And I'm only going to look at what's happening inside of some particular r ball, where the k set looks even more dense. And if I can find such an r ball, then you've got biggest one dimension. So I'll. Maybe I'll actually write down a precise quantified statement at this point. So here is the, or A theorem that Hong and I proved, which implies full as. That Hong and I prove, which implies full as well definition. And I think it will be helpful to actually write the order of quantifiers down properly. So let's say the following. So for every positive epsilon I said out loud there exists some eta. So I'll say there exists eta such that the following is true. For all delta sufficiently small. Sufficiently small depends on epsilon. Okay. So what is the statement? Well, so let T be a set of delta tubes pointing in different directions. Now, for those playing along at home, if you are taking a Playing along at home. If you are taking notes, leave room because I'm going to cross this out and put in a different condition later. Pointing in different directions. Maybe I should say delta separate directions, rather. And how many are there? Well, let's say, as before, roughly delta to the minus 2. You can lose a constant, that's fine. You can even lose delta to the eta. That doesn't really matter. So then, Really better. So then there exist two scales. So here we said there exists some rho between delta and one, so that's still true. But I'm going to say there exists scales rho and r, where rho is at least delta, rho is less than r, r is at most 1, but they're fairly well separated. So rho is less than or equal to delta to be eta times r. So what's going on here is r is just 1, and then that's saying. Just one. And then that's saying rho is less than delta to the 8. But now we have these two scales we get to choose. And there exists an r ball. So this is a ball of radius r such that, so instead of asking that the row neighborhood of the tubes be big inside of the ball of radius 1, it only has to be big inside, relatively speaking, inside the ball of radius 1. So the union t of t take its row neighborhood. Take its row neighborhood. Y'all add some rats just in case there's any ambiguity about what's going on there. Intersected with the ball of radius r. What is its volume? Well, it's at least the volume of that ball times what? Rho over r to the epsilon? Okay, so I think you'll quickly convince yourself that this is an easier statement to prove than the up of being. Than the up of Binkovsky statement here, because this just corresponds to r equals one and you take the unit law. So each one of these is getting easier to prove. So we've proved, sorry, each one of these is getting harder to prove. This way it's easier. So we've proved the easiest statement of a somewhat respectable definition of dimension problem. Okay, so I'll pause for a moment. So this is as much as I'm going to say from the point of view of explaining the statement of what we proved. So I'll pause to see if there's any questions about that. If the statement makes sense. I like people are on board. Great. In fact, we can prove something a little bit stronger. You can replace this with a shading. It's sort of in the flavor of Hausdorff convention, but it's nowhere near as difficult of a statement to improve as Hausdorff convention. But that gives you certain advantages. Essentially, what it then tells you is whenever there's a PKS set, there's going to be two different scales, rho and R, where the rho neighborhood is almost as big as the R neighborhood. That's an interesting consequence of using the shading. Is this a genuine inequality, or is there supposed to be a constant in front? Ah, so if you wanted to put a constant depending on epsilon, then this statement would be true for all delta. Instead, I'm saying all delta is sufficiently small, I'm picking it small enough to meet that constant. Which is sometimes a useful way of looking at it. Okay, so I want to spend the remainder of my time, maybe eight or so, maybe nine minutes, giving some sense of how you might prove a statement. Giving some sense of how you might prove a statement like this, what can go wrong, how you get around it. So, one of the advantages of a statement like this is you are allowed to zoom in to some location and consider what's going on at some scale. And we get to choose both. So if this statement were to be false, what that would mean is for every ball and for every scale, the reverse of the ball is true. And this is telling you that your set. These true. And this is telling you that your set is very porous, that every scale and every location in your set is very porous. We can try to understand what that might look like. In particular, these sorts of KSets, after you apply various types of rescalings, you get, well, maybe not the KSets anymore, but collections of tubes which might satisfy some of the hypotheses of this original problem, and that kind of rescaling could be valuable for us. One problem, if you take a tube, there's all sorts of scalings that send it to a tube. But the property of pointing in delta-separated directions isn't very stable under all these. Directions isn't very stable under all these kinds of free scalings. So it's helpful to replace that with a different hypothesis. So we're going to get a superficially stronger statement, but one which is more stable under the kinds of operations we need to perform. So I'll give you a definition. So as always, T is a collection of tubes, so we say T satisfies the convex-Wolf axioms. So convex is in convex set, Wolf is in PonWolf, who made many contributions to the Kekia problem, including introducing some precursors to this definition. If for all, this makes sense in any. This makes sense in any dimension, but let's just restrict attention to R3. So, for every convex set in R3, we can ask how many tubes from our collection are contained in this convex set. In general, our convex set is going to be roughly in the unit ball, let's say. So, if W is roughly the unit ball, it's all of them. But if W is a smaller convex set, I want a smaller fraction to be there. Fraction of the effect. So I wanted most of the volume of w times the number of tubes, and I'm allowed to lose a constant. So really, I should say you satisfy the convex wolf axioms with error c, where c is the constant here, but I'll scope with that deeply. Great. Why is this a useful definition? First of all, if your tubes, well, if you satisfy this property, well, a tube itself is a convex set. I can allow W to be a tube from my collection. So this left-hand side is at least one, so there's one tube yet itself. So there's one tube in itself. What is the right-hand side? The volume of a tube, that's delta squared. Gets ignored this constant, times the number of tubes. So the moment you satisfy the convex wolf axioms, there's roughly the correct, there's at least the correct number of tubes, delta to the minus 2. Which, let's say you have delta to the minus 2, they point in delta separated directions. Not too hard to convince yourself they satisfy the convex wolf axioms. What's a convex set in R3? It's essentially a rectangular prism. It has to have length at least one in one direction, though it's not containing any tubes. And then for a two-year-old, And then, for a tube to be contained inside of it, the angle of that tube is constrained by the dimensions of that convex section. You can pretty quickly convince yourself this property is satisfied by tubes pointing in different directions, delta-separated directions. So, instead of asking pointing in delta-separated directions, we can say satisfying convex hit axes. And this becomes a slightly stronger theorem. The goal is not to prove the stronger theorem, but it's The goal is not to prove this Romler theorem, but this is somehow a more stable theorem to actually prove. Okay, so that's step one. Figure out the correct question to ask. Now we have five minutes to try to think about what's actually going on. So in some sense, you can think of this as a proof by contradiction. We can imagine the theorem were false. That means there's a counterexample. We can try to quantify what does it mean to take the worst possible counterexample, study the structure of that, and eventually discover that this object. And eventually, discover that this object is so well behaved that it violates an existing theorem previously due to Hong and myself, saying that such nicely behaved UK sets actually have full Hausdorff dimension, and thus definitely can't be a counterexample of the asquat dimensions. So let's try to actually do that. So there's a lot of quantifiers from two. Imagine this was false, we have to start negating them in the correct order. So what does it mean? Okay, suppose false. Sort of want to keep this. Let's erase this, unfortunately. Yes, what story is this important? Of course, the inherent proof will not fit in this margin. So suppose false. So the statement begins for every positive epsilon. This is true. So if this is false, there exists an epsilon for which this fails. I want to take the biggest, later on, I'm going to take the biggest possible epsilon, but there exists. The biggest possible epsilon, but there exists some positive epsilon so that for all, no matter how small eta is, this statement is not true. So, what does this mean? It means I can find a sequence of deltas point to zero so that no matter what scale row I choose and what r ball I choose, this inequality is reversed for that concrete value of epsilon bounded away from the zero. So, my counterexample is porous at every location here. Maybe I won't work. Okay, maybe I won't write that, we'll just say it. But what is the biggest epsilon I can take, which is my counterexample. So maybe I'll just say, there exists, we'll do red as the negation. There exists some epsilon naught bigger than zero, so that for all eta bigger than zero, blah, blah, blah, blah, blah, this inequality is now run first. This is for all balls. Reverse all the quantifiers. I won't do it all for you. But this inequality, right, I just reversed it for some concrete epsilon naught. Great. What do I want to do? So I'm picking epsilon naught to be the biggest epsilon naught, the biggest counterexample. Great. And now I want to do a second level of the worst possible counterexample. So I told you, I no longer need this here, right? I wanted delta to the minus 2 tubes in order to ensure that there. Tubes in order to ensure that their volume added roughly to one. As tubes pointing in delta separated directions, well, the empty set points in delta separated directions. We need lots of separated tubes. The moment I ask that you satisfy the convex wolf axioms, I immediately have at least delta minus two tubes. So we didn't need that restriction. In fact, I could have a bigger collection of tubes that satisfies the convex wolf axioms. Roughly, how many distinct delta tubes are there in the unit ball in R3? Well, the set of lines in R3, that's a four-dimensional parameter space, so there's roughly delta tubes. Dimensional parameter space, so there's roughly delta to the minus four delta tubes in R3. And if I take all of them, that also satisfies the convex coordinates. So you can have more tubes, that's still fine. And actually, the more tubes you have, the easier it should be for their unique to be big. So I want to find the worst possible counterexample. I've already found the worst possible epsilon naught. And now I'm going to find the biggest possible collection of delta tubes, which still makes this inequality go in the wrong direction. And how many is it? Well, let's say it's delta carnal du t is like delta t. Now, you have t is like delta to the minus alpha, some alpha, the worst possible alpha, biggest possible coefficient. Okay, why is this good? Well, let's consider, so what I would now want to show you is that this collection of tubes actually has to have a lot of sort of coarse self-similarity properties. In the parameter space of tubes, it more or less has to look alpha-regular. Why is this? Well, let's consider what happens when you take each tube and you thicken it by row or some bigger value of row. Well, now I have a collection. Grow? Well, now I have a collection of rotooths. After I do a bit of pruning, they still satisfy the Cloudbex wolf axioms. Great. Maybe the cardinality of this was much bigger, potentially, than rho to the minus alpha. I can certainly give you an example where that happens. But if that were to be the case, well, okay, I shouldn't have used rho. Let's call it tau. Well, if that were the case, then I now have at this latter scale a collection of tubes which has. Scale, a collection of tubes which has bigger cardinality than what was supposed to be the worst, the biggest possible collection of tubes, which witnessed this counterexample. So that, there has to be some row and some ball so that this is bigger than epsilon naught. But this whole thing is invariant under rescaling and under thickening. So that's already a contradiction. What I thought was this worst possible counterexample, no, I just wasn't looking at the right spec. So what did we conclude? In fact, this has to be true for every possible Has to be true for every possible tau. Whenever you thicken it, the cardinality can't increase quite. But we also have a reverse equation. Just take another more bunch of. So we also know that this is, up to constants, bigger than tau to the minus alpha. Why is that? Well, imagine not. Then I could find some popular tau tube inside of which there were a lot of delta tubes, right? More than delta over tau to the minus alpha, just by pigeon coin. But that's good, because this whole thing is solved. That's good because this whole thing is also this inequality. The whole point of it is it's invariant under taking a batter tube and rescaling it or looking inside of it. So that would say, oh no, there's actually a much denser collection of tubes I should have looked there. Again, this inequality couldn't have been there. So we've already convinced ourselves, hopefully, that the cardinality of this set at every thickening needs to be roughly calculated by minus model. Now, that wasn't the only hypothesis. We also needed them to satisfy the convex wolf axioms at scale tau, and also when you look inside of it, you've got. How, and also, when you look inside a recruitment, has to satisfy the reason of the recruitment, has to satisfy the context group. That requires work, and I won't talk about that at all, but that's a key step. But once you've established that, we're now in a situation where we have this collection of nelta tubes. Whenever you thicken it, it still satisfies the convex wolf axioms. Whenever you look inside a thickened tube and rescale, it satisfies convex wolf. So, this is called satisfying the convex wolf axioms that every scale. And this is exactly the situation where the KSE is very closely related to being sticky. Are very closely related to being sticky. And so Hong and I proved something called the sticky decay theorem for that, which essentially says if your decay set satisfies this kind of Alphorus regularity at every scale, then its Hausdorff convention is full. And so we're now, we're so self-similar that we know this is not a formula. Okay, so that's an overview of the proof. I'll stop there. Thank you very much. Questions, comments? You said that you can make this slightly stronger with shadings, but that you're not there. Is version with shadings necessary for the full proof of observed dimensions being so the question? So in order, this statement without shadings formally implies this one-dimension statement. However, the way we structure our proof, we cannot prove this, the easiest path we have to prove this. The easiest path we have to prove this statement actually goes via shadings. And the version with shadings has some nice consequences, which I mentioned are valuable in London. Which do you think is more likely to fall first? Minkowski dimension in R3 or Asma's dimension on R4? Well, okay, the short answer is I have no idea. But one challenge in R4 is that. In R4, is that we know the convex Wolf axioms are not sufficient. And there's a very simple counterexample, which is consider the variety, let's say, ABCD, or SYZW if you will, in R4, such that AB minus BC equals 1. Sometimes this is called, well, you could call this SL2 if you wanted. And so this is a perfectly nice variety in R4. It contains. Variety in R4, it contains a three-dimensional set of lines, and so when you thicken it, its delta neighborhood contains a three-dimensional set of delta tubes. They satisfy the convex Wolf axioms, but clearly their union is not everything. So this already suggests that we don't even know the right way to do anything in R4, so that seems kind of scary. There is the polynomial work axioms, which forbid this type of thing, but they're harder to work with. So I'd say R4 looks hard. I don't know if anything else is easier. I don't know if anything else is easier, but that's definitely. The convex wolf axioms seem to be enough. There's no. Let me put it this way. You could replace the condition that tubes point in different directions with the condition that they satisfy the convex wolf axioms. And we don't have any counterexample to the statement that maybe that's not okay. In R4, this is a counterexample to that statement. So we don't even know what to do. And let's stay in the speaker again. thing to speak again.