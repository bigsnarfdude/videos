For the workshop, and thanks everyone for sticking around the last talk of the day. So, I'm going to be speaking on tensor representation of finite dimensional hop algebra. I think almost everyone in this room already knows the terminology in the title, but I'm just going to go ahead and still, like candid, give you a friendly reminder of some of the terminology. So, hub algebra is, again, a vector space that has this algebra structure, multiplication. There's algebraic structures with multiplication map M, the unit map U, and also co-algebra structures. We have this co-multiplication delta, which I'm going to use throughout this talk, and co-unit epsilon. As well as, so the algebra and co-algebra are going to make it what's called a bi-algebra with some compatibility conditions, and then the existence of the antipope map and mapping H2 itself is going to make it a half-algebra. So, we've seen an example of Hopalgebra throughout. So we've seen an example of hub algebra throughout this talk for the last couple days. Group algebra, what else? Polynomial rings, tab algebra, universal enveloping algebra, Lie algebra, also some of the basic examples. So throughout I'm going to use this notation for my co-multiplication map. And so I'm interested in the question, or in fact, a nice representation theory of the Happashbar in the following sense: that if you have any two module over H, any two module over h, then I can tensor them together and it's still again a module over h and exactly this multiplication co-multiplication delta here is that make it happens. So here I can sort of break h apart using this delta, right? And so I have h1 now acting on the first component v and then h2 acting on the second component w. So that's giving me a nice module structure. So you can also ask the same thing if I can take v and then tensor itself If I can take V and then tensor itself K time, it's still going to give me a module over H. So, this is what I'm calling tensor representation. So, the overall goal for this talk is to think about the structure of when you take two modules of tensor together and the structure when you take the same module of the tensor over itself, k times, but k can be any positive integer. So, this talk, I'm going to walk through sort of two directions or two topics. Or two topics in this tensor representation direction. And this is a joint work with Georgia Bedkart, Rekker Biswall, Ellen Kirkman, and Jiro Zhu. And it started from the Women in Non-Communicative Algebra Representation Theory Workshop, the second one in 2016 that JSE have co-organized as well. So the first topic is going to be looking at Macaulay matrices, so using linear algebra, right? And in our And in a way, you can think of the climatey as a way for you to encode quantum symmetry, sort of the way half algebra acts and the way tensor representation decompose. And the second topic is going to look at the way when you take V tensor itself K time and look at the endomorphism of V tensor K as an H module. And so we call this one as a centralized algebra. So what does this algebra look like as an algebra? In algebra. So, I'm trying not to go into the technical detail of each of these individual paper. You can look up in the archive, or is they all published on, at least online right now. So, at least I'm trying to use this talk as an opportunity to invite you to work in this direction. And along the way, I'm going to introduce some of the open questions in this topic. So, if you're interested, I'm happy to talk afterwards as well. So, the first So, the first topic, the colon literacy. So, the motivation for this work is coming from the work of Mackay in the 1980s that he introduced what we now so call the Mackay correspondence. So, we're saying the following, that if you have a Mackay quaver described over this uh subgroup G of the SU two, then all these Macai quaver are going to be in one to one corresponding with the R find linking diagram of types A D E. Linking diagram of types ADE. So the Mackay corresponding has been an inspiration to a lot of the areas of study in singularity, invariant theory, representation theory of group algebra, representation theory of Lie algebra, and so on. And a few years later, Stanford sort of looked at that kind of correspondent and then looked at the group algebra in particular, and this is going to be over characteristic zero. Going to be over characteristic zero. And he has established the correspondence in the sense that the columns of the character table in your group are going to actually yield exactly the right eigenvectors for this Paki matrix. And the contribution class representative is actually going to give you the eigenvalues. So there's a very nice corresponding between character theory for group algebra for group and then the Mackay eigenvector. And then the Mackay eigenvector and eigenvalues for Mackay matrix. And the story in characteristic P is not going to study until much later on. So this is a very recent work in 2020. In characteristic P, you have also a similar phenomenon, but then you have to look at the Bower character table instead. And the conjugacy class now, because we're in characteristic P, so we have to look at those of all the P prime, that relatively prime to P prime. That relatively prime to people. Right? So, some of the motivation in terms of like, okay, why are people interested in studying Makari matrices? So, the work of Benkart economists Liebeck and Tip in also recent years look at the Makov chain. In fact, for example, for the UQSO2, they say that they look at the Mackay matrix for UQSO2 and realize that there is a Jordan block in these Mackay matrices, and they actually determine. And they actually kind of determine some interesting markup change that arise in this work. And overall, With a Swoon in 1999, then look at the semi-simple almost co-communative half-algebra and sort of attempt or give a description for what it means to be a character table for this very particular case. And she showed that the character table also have some sort of relation with the Macau matrix as well. With the Machiave matrix as well. So, our overall goal in this project A is to study Machiave matrices, but of course, as you already see what I'm hinting at, it's for any finite dimensional half-algebra, not just for the group algebra, not just for the semi-simple or multiple community. What about Machiave matrices in the general sense? And then our sort of more ambitious goal is to see if this Machiavelli matrices has any relation to the pair. Has any relation to the character table, or even what does it mean? So that's why I put in the quote notation. What does it mean to even describe a character table for half algebra in general? So that's our go ahead. Let's look at what is the Mackay matrix. So here I'm going to describe this in a more general sense for half algebra instead of what Mackay has studied originally. So H is going to be a finite dimensional half-algebra over my field, and just for simplicity, I'm going to let it be actually. Simplicity, I'm going to let it be algebraically closed. Tensor product is going to be over K unless otherwise. B is finite-dimensional module, but I'm going to call it dimension D. You're going to see it short later. SI is a set of symbol module, and a PI is just a projected curve of the SI. And so, Mackay matrix is defined as following. So, if we take SI, the symbol module, tensor would my V, this is again an H module. This is again an H module. We talked about that on page one, right? And so we can decompose this, but the problem in this general setting is that it's not necessarily simizable. So not everything is going to be completely reusable. But however, you can still record the multiplicity of the symbol SJ that occur in the SI tensor V. So we're going to record that and call that Mij. So the Machi matrix. So the McCai matrix that associates to tensoring with V is going to be the Mij. And so since you have M symbol module, this is going to be an N by N matrix. And then you can think of the Machiave matrix as an adjacency matrix for what we call the Machiai quiver. So graph, so it's just a graph with vertices and arrows, right? And the vertices, the nodes, in this case, are the symbol modules. And the number of arrows. Models and the number of arrows that go from the node i to node j is given by this multiplicity. So, we also along this work defined what we call the projective Mackay matrix, which is similarly, but however, in the story here, originally Mackay matrix was looking at when you tensor symbol and you decompose as symbols. Here, we're going to take this projective, tensor projective V and decompose as projective. B and decompose as projective. And record this multiplicity as Qij. So we have two notions, of two matrices, the Mv and the Qv. And let me introduce a little bit of the terminology here. So for any element X in the Hub algebra, I can have two vectors. So here, this is trend posed, so this just means this is going to be a column vector, and this is just going to be a row vector. A row vector that is recording the trace, the trace of the symbols and the trace of the projected margins. You're going to see that those show up in a little bit. So just to give a brief overview of the result that we have done in this work. So for generality, for any half-algebra, we are able to establish this relation right here. It's basically coming from the core multiplication structure, actually. You can see here this x1, x2 right here is coming from the delta map. X tube right here is coming from the delta map, right? And in fact, this first identity gives us the notion of right eigenvectors. So in the sense that you let x to be the group-like element, so that's meaning delta x is, sorry, delta g is g tensor g. So the x1, x2, you replace it g and g right here. And you can see that the Mackay matrix has the right eigenvector is given by this trace vector that we have in on the previous page, and that's going to give This page, and that's going to give you this eigenvalues given by the trace of B. All right. And then, on the other hand, when we look at the projective Montpai matrix, we also establish this identity right here, which is going to give us the left eigenvector sort of description. By just, again, if you let x be group-like and then plug into this formula here, you're going to have a description of a left eigenvector of this QV, this projector. This QV, this projected Paca matrix transpose. So you're going to ask, okay, what are the relations between those two? So, in fact, using this sort of like tensor duality description right here for relating the PYJ and the MHA, we also can show that the projective Mackay matrix is basically the tremose of the Mackay matrix over this V tensor, so it's V star. So this V star here is a K dual of V. Dual of V. And if you let x to be 1, going back to relation 1 and relation 2 right here, we can actually recover the Jinper, Plang, and Ragnar result, which is basically saying that the right eigenvector for the Machiave matrix MB with exactly this eigenvalues D, and remember D is a dimension of my V, original that I used to say with, is exactly this vector S that recording the dimension. Vector S that recording the dimension of my symbols. And similarly, the left eigenvector is going to be recorded with the dimension of the projected smart jobs here. Again, just plot 1 into for x right here, and trace of 1 is exactly d. Yes, the dimension of V. Alright, now when we also look at the, okay, what about a case when H is semi-assembled, and we know that the Mackay matrix is going to be exactly the projective Mackay matrix of MV equal to QV. If V is self-develop, If V is self-dual in addition to that, so that means that V is isomorphic to V star, then if you plug N V to here, like M V equals to Q V, so that's mean M V equal to M V M transpose V star, and V is self-doubt, so it's going to be M transpose V. So I hope by the end of the semester, Millennium Algebra students will recognize that this means that M V is symmetric, and hence that means that the Mackay metric is orthogonal. That the Mackay matrix is orthogonally diagonalizable. So that's a very nice result for semi-symbol, but on the other hand, for non-semi-symbol Hoffman, you're not going to have that nice behavior. So we look at this example for the Drimfield double dn of the tat algebra. And in fact, we give a complete description of the characteristic polynomial, eigenvalues, eigenvectors, everything in terms of dn but then we are able to describe But then we are able to describe it sort of combinatorily and also a very nice description in terms of Chebyshev polynomial of variant types. And to give a precaution why the maximumized symbol doesn't work very nicely is because of the existence of this generalized eigenvectors here. So the story is that when we're looking at this example, we don't have enough eigenvectors. So we can't not really diagonalize. So that's not going to. So that's not gonna prevent us from generalizing the nice relation that we see in the group algebra or the semi-simple algebra in general. So a couple of questions or several questions in this direction that we can ask ourselves in general for any half algebra and for any V module. And for simplicity, you can restrict them to be finite-dimensional. But again, like Jim said, again, one new question. GM said IV1, a new question just removed the recognition, right? So, when this is Mackay matrix symmetrix, and when is it diagnosable? So, we've seen in the case of the UQSL2 or in general of the case of the truthful level of a tap algebra, that this is not true. The macaroni is not diagonalizable. And what about the significance of the eigenvectors? We see in the group algebra case that it's going to give a really nice relation. That is going to give a really nice relation with a character table. But here we don't really have a nice description of that. And actually, that in fact turned out to, you know, similar to this next question is, can we recover some sort of or define some sort of notion of what it means for a character theory for half-algebra? And this is still remaining a question for us after we study for the dream prudential of Taf algebra. And then at the end of our project A, we sort of So Project A, we sort of also looked at the fusions relation and fusion matrix that was defined in the sense of Pohan and Westrid in their paper and see if there's any relation between micromatic matrix and the fusion matrix. And at least for UQSS2 and also for the tripod of a tap example, we see that these two matrices share the same eigenvalues. But the eigenvector might have a different story. Different story. So, is that going to give us any indication in terms of the categorical sense in general between this several things? So, those are some of the open questions that I'd like to propose and see if you can interest it or have any questions on that before I move on to the next topic. Alright, second one. So, this is to the study of the centralizer algebra. Again, this is when we take the V and chant. This is when we take the V and standard at K time and look at the endomorphism over a V over as an H module. So here I'm going to sort of restrict the discussion to quasi-triangular Hub algebra and V to it to be simple module. But of course we can remove that restriction and see if you can have the general description in general. But the reason I would like to look at quasi-triangular in general, because it's a very big class of algebra that arises in Big class of algebra that arise in the study of NOx theory, invariant theory, tensor category, overfalls, and so on. So it's very, very nice. And the reason is with the quasi-triangular Hubalgebra, you have what is called a distinguished element, what is called R matrix. That is an element in H tends to H. So I'm going to call it, has a component xi and xj. And it satisfies some condition, but one of the conditions Condition, but one of the conditions is a Yang-Baxter relation. So I'm saying that I can use this R matrix to construct an element in this centralized algebra that I'm interested in. So the way the construction goes as follows. So by abuse of notation, I'm still can think of R as an element in this intermorphism. Basically, R gives me an action of H on the V tensor V. Again, Xi acts on the first component and Yi act on the second component. Component. And then I'm going to swap them. So I'm going to apply R first and then swap the component XIXJ and define the new element called the RI checked. And this is going to be an element in the endamorphism V tensor KK time. And this one, the first, the rest, the one right here, just identity matrix, identity map on V, and the R checks now acting on the I and I plus one cancel slot. I plus one cancel slot. So R first and then slap them on those two slots. And this RI check here, you can see that it's actually certified as this Young-Baxy relation or the Brayding relation. So I'm going to talk a little bit about that later on. So the tensor module VK is going to emit this action of the Bray group. And sometimes it's going to act in factor through the Evil Harry-Hecker algebra. And Ladoop and Brand actually gave a very nice recipe for the action. Gave a very nice recipe for the action of such a module. An own study by Jimbo pointed out that when V is actually dimensioned 2, you can actually use factor through an action or the temple leap algebra that arises in a question that Tercy asked Milan at the beginning earlier this morning. So Goodman Wenzel and Independent Way Martin in 1993 have this sort of isomorphism map right here. It's an endomorphism, but actually the dimension is actually map. Actually, the dimension is actually natural. This is going to say that the Taylor Lead algebra factor through and acting on the two-dimensional modules and centralized algebra over this two-dimensional module. And this action is faithful with exactly the right information that you're looking for. So what are the ray group, Evo-Hurry, and Tableau? I'm going to just describe them in a bit. So here we're going to have P is a primitive end-room. P is a primitive end unity, and I have an algebra that defined on this generator S1 through SK minus 1 that's subject to this relation. And if it satisfies the first two relations R1 and R2, then that gives you the description of the group algebra of the break group on K minus 1 strain. And you can see this relation saying that if your strain are far enough, then Si just can be with SJ. But if they're next to each other, then you start deprating. Start with a grading, right? Because RT is a grading. And then if you have the relation R1 through R3, then we have the Ivohiri-Haka algebra of type A. So this is a quotient of the grade group, group algebra. And the tangible lead algebra is the quotient of the Ivohiri-Haka algebra with this four-relation here, using this new presentation using the TI instead of the SI. And here I've restricted my parameter to be for this particular case, just for the story. To be for this particular case, just for the study for this topic. But in general, in definition, the Tambola leaf algebra can be defined using any parameter. And so we also know from the, very well known, that the temporal leaf has this dimension given by the peckland number. And so I'm going to skip a little bit since I'm running out of time, but we're looking at this geometry of a tap algebra that is non-semi-simple, quasi-triangular. Non-semi-simple, quasi-triangular, and so this fit very well with that. What we're interested in. So, we also, using the result by Kauffman and Bradford, that this element, this DN, is actually a ribbon half-algebra. If anomaly, n is odd. So, along our work, we also describe this ribbon element explicitly as well. So, going back to our study for the centralized algebra, we mainly use the result by Chin and his co-author. This is a series of papers that spread over 10 years. That spread over 10 years that studied explicitly the representation of this three-field double overtatled bra. So he described a simple module, the projective module, and give very nice action as well as a tensor product in depth. So our first result in this direction is we were able to establish an action, in fact, an algebra isomorphism between the temporal leaf and the centralizer of the algebra. And it's described explicitly here. In other words, you can think of it as the temporal leaf is actually. Of it as the temporal leaf is acting on V tensor K, and in fact, we are able to show that this action has actually turned out to be fatal. And so, you're going to ask, okay, so when is it isomorphism? So, it's injected when it's just pi's isomorphism. So, that is the next question that we're going to look at. But in order to answer that question, we actually have to look at, we use a technique of comparing the Protelli diagram between the tensor range over the tri-fu-double algorithm. Over the trifled algebra, and also the Protelli diagram over the UQSR2. So, the below here is the Brotelli diagram for UQSR2, which can be represented by partitions of K, here K is a rho, the V times of K, with at most two part, whereas this is the fertility diagram for middle V times of K. So, for example, in this diagram, maybe it's too small to see, but I'll start with level one is V20, one of the symbol models. 2, 0, one of the simple modules, and V tensor V at the level 2 is decomposed to the module V30 plus the module V11, with some multiplicity that I don't put it in there. And you can see already the similarity between the two Verteli diagram. So using this, we are able to give a description of the dimension or exactly the formula for the dimensions of this centralized algebra over this two dimensional simple modules. What these two-dimensional symbol modules mean. And I'm going to skip through the description of what these letters mean. It's basically just record the multiplicity that the symbols and the projective module occur in the V tensor K decompositions. And in fact, for the computer purposes, you can see that they actually give a number of paths of length K, very nice computer way. But using this formula, we now can go back to our original question and actually give a And actually give a description when math is an isomorphism. But in fact, the assumption is that it's only isomorphic up until this values of k. So we recognize that when k is greater than 2n minus 2, the endomorphism right here has a much bigger dimension than the temporally, and the dimension grows very quickly. So just to finish up with some of the open questions in this reaction, so of course In this direction. So, of course, the lingering question is: what is the full description of the centralized algebra beyond the isomorphism that we described? So, this is the ongoing work that Ellen and I, hopefully to finishing up so that we finish what Georgia was set out to do. And then along our earlier version of our archive, we actually described this using some of the diagrammatics argument. So, can we actually now think of this algebra as a diagram? Now, think of this algebra as a diagram algebra using string, cups, cap relation, and so on. And generally, for any dimension, so here we're only restricted to two-dimensional. What about in general dimension? Can you describe this centralized algebra in general? And we've already seen some of the obstruction when we try to look at the dimension greater than O3. And what about when we extend this beyond this DM? What about just any triangulated? Any triangulated triangle, quasi-triangular half-algebra in general. So, what is the description for that centralized algebra? Alright, so that's all I have today, and thank you for listening. And I'm sorry, I'm going out of time. None, let's thank Ben again and head to dinner at 5:30. Just a small announcement. I had a tape.