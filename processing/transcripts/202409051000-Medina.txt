Friends on this type of problems, genetic trees and graphs. So it's probably a bit disconnected from the previous two talks, but hopefully there'll be something for everyone. Just to say this is joint work with Richard Everett and Xavier Didelov from the University of Warwick. And the paper, it took some time to get it out there, but it's finally there, so you can see it as from last. As from last year. So, I'm going to talk about population genetics, just a brief intro, just to motivate this type of problem. We'll talk about vase and Monte Carlo on trees, why this is related to bacteria and recombination, and then finally, how to use these super clever MCMCs for actually dealing with this problem. Yeah, so I'm going to go. Yeah, so I'm going to go quickly on this, but essentially, when we have a bunch of DNA data, we'll have a bunch of sequences, a bunch of letters. So here we have like three or so samples from DNA data, which is, bless you, that is basically a sample of DNA, not a sample of data as we are used to. And we essentially have this sequence of letters that are mostly the same. Are mostly the same all the time, except for sometimes we have this shift, right? Like from T to an A or from T to C, etc. And in population genetics, what we want to study is the variation between within and between population. So one of the basic elements in population genetics is to understand how individuals reproduce. Individuals reproduce, and also how the DNA mutates as we see. And for this, equalescent theory is the theory that helps describe it. So just to be clear with a simple picture, we have a bunch of individuals at the present, and we may be interested in reconstructing the past of how they reproduce. This is originally introduced by Originally introduced by Kingman, who proved this is a limiting ancestral process, and there's lots of interesting theory behind that. And just to be super clear about it, we have a tree, a coalescent tree is going to be defined using a topology, which I denote by tau. So the topology tells us how these individuals are going to coalesce. So for example, here we have that three and four coalesced first, and then we have one and two. And then we have one and two, and then those two branches coalesce at the third time. But also, we have these times, this set of times that are continuous. So, in a sense, the coalescent process is a stochastic process, but contains continuous and discrete features at the same time. And why do we care about this? Well, for starters during the pandemic, there was this interesting, I think you can still see it, but it's not that interesting. but it's not that interesting anymore. But you can see this, how the COVID was, how the SARS-CoV-219 was spreading and maybe doing some inference also on who was spreading it where. So without taking data into account, we can think of the coalescent We can think of the coalescent as, as I said, as a stochastic process. But we have an idea of how this evolves. And our colleagues from theoretical probability can say more about it. But essentially, we're allowing people to coalesce with the same probability. Like you can choose two random individuals and they can coalesce. And also the times are shown to be exponential. Be exponential. So the times between coalescent times are exponential. So then the sum of these times is going to be gamma. So I'm not going to go into the details of this, but essentially we have one of the simplest models we can think of for mutation is that letters can swap from A's to T's or C's to G's or whatever. And these times also are related to the exponential. But there are more. Exponential. But there are more complicated models that are probably more realistic. Right, so with that in mind, we can also compute the likelihood. So given, for example, given two DNA sequences, just imagine we have these two, we can compute the likelihood for a single site. So a site is just going to be one of the letters. So the DNA sequence. One of the letters. So the DNA sequence is composed by many sites. So essentially, we need to account for these latent variables. Because, for example, if we're doing this G, you know, this T with this G, then we need to take into account what happened in the past. So maybe it was a T and then at some point there was this mutation happening here, which is exactly what it's happening. Here, which is exactly what it's there. Or maybe it was a G and then the mutation happened on the other side. Or maybe there was something different and then there were two mutations happening. So for that, we need to take this large sum to take into account all these latent variables involved. So that's only for two DNA sequences. And then for a single site, if we have n sites and then m data. And then M data sequences, then this is going to be a crazy product, right? However, there are efficient ways of computing this. One of these is the pruning algorithm from FERSTIN, which is basically looking at the leaves, what happens on the leaf, and then just go upwards. Because once you compute what happened in each of the nodes, then it's like a recurrent problem, right? So you can just. Problem, right? So you can just go up. And assuming there are L sites, for example, and they evolve independently, then the likelihood becomes this product of lots of sums and recurrent calculations. So if we were frequentists, then basically we're done, right? We can compute the likelihood and then we'll try to find maybe the maximum likelihood. But we like to. But we like to deviate from that, especially because we want to establish a path, right? And why being Bayesian in this problem? Basically, it's easier to interpret results because we have lots of noises, lots of noise in these processes. And an easy way to get rid of unwanted parameters may be. Of unwanted parameters, maybe, especially for practitioners, they'll be probably interested in mutation, but not in other features of the qualescent. So it's easy just with Monte Carlo, you just integrate them out and you forget about them. And additionally, we have already a candidate for the prior, right? So, our colleagues from probability theory, they tell us how. They tell us how this stochastic process behaves in the absence of data. So, this is really like the basic step for establishing a prior. So, at least for the three, we can use the same equation as before. And I'm not going to bore you logs with Monte Carlo. Maybe you already heard much of it. But essentially, we want to estimate some features. Want to estimate some features of the posterior, maybe the posterior expectation or the posterior variance, et cetera. And for that, we can do either Monte Carlo. I cannot see that. Oh, I'm spoiling. Yeah, so we can use Monte Carlo using a proposal queue. Or maybe we can use an MCMC, maybe a Metropolis Hastings chain, but essentially we. But essentially, we can use these pseudo-samples or pseudo-draws from the posterior to actually compute or approximate some features of the posterior. And yes, for example, in trees, we can use MCMC. And I think in the community that deal with these problems, they are already aware of MCMC MOOC. And they have some clever moves. Clever, clever moves for doing this on a tree. So, for example, we have the exchange step where just a part of the tree is gonna be attached to some other part, and then you have to check whether to accept or not. A sub-tree slide, which is basically just taking a piece of a leaf and then put it somewhere, or the Wilson bolding, which is just swapping completely. Slapping completely between two branches. However, the problem is for even with these clever steps, it takes like forever to actually get an answer. So one of the drawbacks of doing MCMC for this is that even if we have all our data, probably there will be more data coming through. For example, think of the pandemic. For example, think of the pandemic, right? Like every day there was new data coming. And then what we needed to do or what people needed to do was to stop their MCMC and take into account this new data. So one idea is to actually do more of a sequential Monte Carlo approach, because essentially we will expect that if we have enough data, say for example, and data DNA sequences. Data DNA sequences, maybe getting another one is not going to change much the posture, right? So, with that principle in mind, that will be why sequential Monte Carlo would be a good idea. We have a paper about that that worked quite well. And if you are not that related to sequential Monte Carlo, it's just basically this idea of incorporating more data as it becomes available. More data as it becomes available, but doing it in a clever way so you don't have to recompute posteriors completely. And essentially, it's just that, right? Like you have a bunch of particles, you weight them according to the posterior, and then you just keep the ones that are good. But then you need to perturb them because otherwise there's this degeneracy that if you just live here and then continue the process, essentially you're just gonna be. Essentially, you're just going to be replicating one of the particles. And that's not going to give you a good answer, right? So the perturbation is important. Right, so how can we now combine these ideas and apply them to the specific problem? I'm going to talk about bacteria, why this is important. I fail my biology exams all the time. I fail my biology exams all the time, so probably I'm not the best to convince you about this. But so bacteria reproduce clonally, so usually they are clones of each other. But once in a while, they decide to share some of the DNA they have, which is sort of like the sexual reproduction for them, but they don't have sexual organs or anything. So it's just these. It's just these odd events where they decide to share information and this is called recombination. And why are our colleagues interested in modeling recombination? Well, to understand first bacterial evolution, but also understanding the rate between recombination and mutation, how recombination varies across genome, across time. Genome across time, understanding the transmission of pathogens. And one thing that is, I guess, quite crucial is this resistance to antibiotics, right? Because if one bacteria becomes resistant and decides to share this information to other bacteria, then potentially we can have this massive problem. The problem with recombination is The problem with recombination is we talked about this tree, and with time, if we're going back in time, these trees were gonna coalesce essentially to one point. But with recombination, what happens is now that the tree might bifurcate. So it starts becoming smaller, but then with recombination events, there's a new branch appearing. So that makes things more. So, that makes things more complicated. And this essentially is not a tree anymore. It's called an ancestral recombination graph for almost obvious reasons. But the crucial thing here is that it's going to bifurcate as you go into the past, but also it's trying to coalesce at the same time. So, essentially, using args is the Is the right thing to do to model this process, but you but doing inference on this is quite complicated. So essentially, we have to resort to approximation, so we need to sacrifice some sort of exactness to actually get a better result. So just to be clear on this, we have think of this as the tree that describes the bacteria reproduction clonally. Reproduction clonally. So, if they were to reproduce clonally, that would be the process describing them. But with recombination, it might happen that at this point in time, bacteria decided to share some information with this individual. Or over here, at this point in time, there was some shared information between them. And it's just, it's not just going to be depending on times, it also depends on the fragment of DNA that is shared. So, think of these two different possible universes. So, this is what the clonal origin is trying to model. The clonal origin is this model from Xavier around 2010, maybe, which is trying to. Which is trying to do this inference on recombination for bacteria, but it's an approximation to the actual recombination graph, in a sense that we first infer the tree and then later on we append these recombination events just to try to make sense of the basic. So in that paper, Xavier and co-authors were doing a standard Bayesian A standard Bayesian inference thing. And it was taking forever for them to actually run. So they have some simple examples where it actually works, but it was an open problem for them, how to speed things. And the problem with this essentially was that they had, there are lots of parameters to infer. So, first of all, we have the mutation rate, which is here theta. But also, I guess more importantly, is the number of recombination events because you were basically, they were basically thinking on how many of these color lines were going to attach to the tree. And for each of those events, you have a time of departure, say that point over there, a time of arrival. Of arrival, but also you have a site on the DNA of arrival and a site, an initial site, and an ending site for the actual DNA that was shared. So for each recombination event, we'll have four parameters. But also a priori, we don't know how many recombination events we have. That's modeled by a parameter rho. So in essentially, essentially, So, essentially, we have this inference on a non-fixed dimensional posterior, which is sounding very crazy at the moment. We can talk about priors, but maybe not today. So in essence, what they did was to fix some of the parameters, the global parameters, and they were just trying to make They were just trying to make inference on the number of recombinations and the four extra parameters per recombination. So this type of inference, what you have to do is basically resort to MCMC and not just MCMC, it's going to be the reversible jump, MCMC. That in theory works really well or should work really well, but in practice is terrible, right? This is terrible, right? Because you're trying to explore a posterior of different dimensions that is not a fixed dimension. And then you basically need to propose going up or down in dimension. And within dimension, you have to explore all the parameters that you are considering. So as I said, the jumps are going to correspond to going up into one or Up into one or going down in terms of recombination events that you have. So, even if we fix the global parameters, we'll have this set of parameters to make inference. So, as I said, typically the reversible jump suffers from bad mixing. And I'm not just saying bad mixing, like terrible mixing. Mixing like terrible mixing, and a huge number of iterations might be needed, especially for this type of problem, these complex problems. But recent developments have shown that essentially the ratio we will use in an ideal MCMC, so the ideal MCMC will be if we knew how to compute the marginal for the number of recombinations. Marginal for the number of recombinations because if we knew that, we could essentially speed up thing. So we cannot compute that because it would mean integrating over thing. But basically, what they showed, Christoph, Andrew, and colleagues, is that this ratio can be seen as an expected value of the ratio you use in the reversible jump. In the reversible jump. So, in other words, the ratio you use in the reversible jump is just an unbiased estimator of the ideal ratio you would use in an ideal MCMC. So the question here is like, if we already have an unbiased estimator for the ideal scenario, would improving this estimator make a faster adequate? Um, faster algorithm, uh, and the answer is yes, but with some restrictions. Uh, two different forms of doing this would be to use annealing. Um, annealing is just like this bridge between different distributions related to tempering, what we saw just in the previous talk. But also, we could improve this by just adding more importance points, right? Importance points, right? It's just like an average. A Monte Carlo, how do you improve a Monte Carlo? Just take more points, right? So these two approaches can be used to tackle this problem. Essentially, what's happening is think of this small problem where you have the tree that's going to be fixed, and then you propose a new recombination from these times and maybe on this chunk of. And maybe on this chunk of the DNA. So, essentially, with annealing, what we're trying is to perturb this proposal and maybe find a better place for it so we can actually improve the chances of being accepted. And we can do that just for one, or maybe, as I said, like for multiple importance points. So, in a sense, we can take capital N of these. Can take capital N of these proposals. And the idea is just this refined MCMC is to not trying to do one big step. Otherwise, it's just like almost impossible that you're going to climb that mountain from the very slopey side. So instead, what we're trying to do is to find Do is to find a route where climbing the mountain is not that difficult. So it's computationally more expensive in one step, but overall should be easier to explore the posterior. So I don't have time for showing you exactly the algorithm, but essentially is we compute many of these ratios that I said is the unbiased estimator for the reversible jump. And then we just retain the one that has a better chance of being selected. Right, I'm going to skip this right to the example. So we have real examples with E. coli, but maybe this typical example, a simulated example, is more illustrative. So assume we have 50 sequences of length 50,000. We will assume that the tree remains fixed and we also fix the global parameters. So, we're going to compare how the modified reversible jump is doing in comparison to the original one. So, in blue, you see the reversible jump. And here we're just seeing how we're reaching to places with high High likelihood and also with measuring time, right? So, as you can see, the blue one is doing terribly. I guess initially, at the end, he kind of catches up. And I guess it's clearer when you see it versus time. If you see it versus iterations, it seems that these four different settings for the modified. Different settings for the modified reversible jump, they are doing exactly as good. But in terms of time, this configuration actually matters. If we look at the effective sample size, as I said, we have, I mean, after the burn-in and everything, we have a really, really small effective sample size for the reversible jump. Size for the reversible jump in comparison to these other three. And when we measure time, essentially doing the parallel version, it's the best thing to do, which kind of makes sense, right? Like instead of spending your time trying to come up with this clever path for doing the jump, you just use more importance points, and that this can be done in parallel. So over here. So, over here, we have some comparison of the sites that are recombining, but probably the most interesting part is when we plot the mean recombination frequencies, so this is the DNA sequence, and the height of this graph tells you how often is this recombining on average. So, essentially, when we compare the two, the best we get and the bad one. We get on the bad one, you will say, probably these are these two are the same, no, or look pretty much the same. But when we actually zoom in, we see this pattern sometimes. This is the truth, and the reversible jump is not actually, it's not capturing this part, whereas the modified version seems to do a much better job. So, our colleagues were quite pleased to see this because actually the algorithm was not just a waste of computational research, right? Right, so with that in mind, I'm just going to conclude. So in population genetics, there's been an increasing attention because we have lots of data now that is cheaper and faster to get. But also the problems we kind of get are quite complex and difficult. Quite complex and difficult. One of these is the ancestral recombination graph, which is quite challenging, even if we resort to these approximate versions. Recall that this was an approximate version of an ARG because we fixed the tree at the beginning. The model computational methods may prove useful, but unluckily they are not that well known outside the stats community. So it was probably... So, it was probably impossible to think that our colleagues, that our geneticists, are going to implement this properly. So that's why we try to make this link between the two communities. And in an essence, if they have already existing code, so modifying this reversible jump was not, I mean, it took some years, but it's not that complicated. If you already have the That's complicated. If you already have the massive chunk of code that needs to deal with global parameters, etc., modifying this was actually simple. I guess it was understanding the original code that was difficult. And of course, there's still lots of room for improvement. We can think of maybe not doing so naive annealing. There are adaptive schemes that could be implemented in terms of improving the MCMC. The MCMC and the list goes on, right? So we have probably projects for another life. With that in mind, I want to thank you again for the invitation and thank you for listening. I have lots of references here if they are of any help. And I'm happy to take any questions. Thank you. Thank you, Tomita. Thank you, Felipe. So, how I mean, you compare it with the original album, but how does he do against like Sequential Monte Carlo? So, Sequential Monte Carlo is kind of hidden here because Sequential Monte Carlo was. Because the question Monte Carlo was used to improve this estimate. So, this estimator can be seen as just one importance point overall. So, one importance point doing important sampling is terrible. So, what we did was improve this ratio using an SMC estimate, and on the other side, was just using multiple importance points. Multiple importance points. So, in an essence, here we are not accounting into like the data as the data becomes available. So, here you have your end sequences and that's it. But on the other paper, I just mentioned that it's somewhere here from Richard and I. We actually did the inference on the tree using SMC. So now your particles are going to be trees. Trees. And that was pretty good compared to MCMC because at some point your MCMC struggles with a lot of data. So having a sort of an approximation at time n, it makes it possible to do the jump to n plus one easily. So yeah, just to summarize, it worked well. It's just like how you define your starting points, I guess. Any more comments? Please. Maybe I'm right. Actually, related to these slides, this comment that you're making that you can use MCMC as more data concentration. But somehow here, you are changing the target posterior, no, because as you're adding more sample, is a posterior on different space of different size. Of different size. How does this work? So I'm sorry that I didn't put that picture here, but essentially you start with a tree, like the ones I just pictured somewhere here. Say this is a tree. And there's more data coming. So if you have another sequence, there has to be another leaf. So with SMC, what we did was what we did was uh you start with your you start with your tree your original tree or the posterior time n and then you just propose to add a new leaf somewhere but possibly the proposal you're going to make is terrible so what you have to do is to actually perturb it a little so actually it represents this pool of samples this pool of points or trees are going to represent the posterior time Represent the posterior time m plus one. So the standard SMC will be if you are on Rn, say, as more data becomes available, Rn still be the support of your posterior. But here, the posterior actually changes dimension. So, what you do is you propose to add a point or to add a dimension in one of these existing branches, but then you need The branches, but then you need to perturb them for actually obtaining a pool of trees that represent the true posterior. But it can be done, and especially if you use the existing moves they have from MCMC, these moves you can use them in SMC without problem. Thank you. Let's thank Felipe again. Thank you. Thank you. A little bit shorter break, just so we see on time with lunch and everything. So we see on time with lunch and everything. Let's meet again at like at 11 a.m. Yeah? Peter, there was a question from Florian. Oh, sorry. Go ahead. Can you read it out, Arden? Yeah, thank you. Thank you. Just a quick question, Philippe. Great talk. So I was just wondering when you're doing like the sort of smart reversible jump idea, this is probably. Idea. This is probably as well very costful because you need to do these reverse moves and you need to do a lot of stuff. And in that perspective, have you considered doing just sort of replacing the unbiased, the usual unbiased estimator for the reversible jump by just more weight without the correction that Christophe and co-authors have come up with. And co-authors have come up with because I think it's a for those big models, like it's like the convergence is so hard to assess than having something that's technically invariant and reversible and all that. I mean, what is the trade-off here? And have you explored the idea of non-correcting the fact of using more like draws than just one? Okay, yeah, thanks for the question. So we have So we do have the correction they use. I don't know if that's exactly what you were asking, but yeah, when I didn't talk about the algorithm per se, but this is for going up in dimension, but for going down, essentially we could do the same thing here, like just compute an unbiased estimator that has reduced variance in a sense. But yeah, as But yeah, as Christophe and co-authors point out, that will be a noisy version of the MCMC. So for going down in dimension, you have to do this kind of clever way to keep everything and everything targeting the right posterior. Otherwise, you end up with a noisy Monte Carlo that, you know, it can still be done, but it's extra complicated. Extra complicated, an extra complication, right? Because now you have to assess how good is that noise approximation. You have an approximation on top of another approximation, right? So we do use the trick they present in the paper, just for guaranteeing these invariance of the chain. Yeah, I guess my question was: have you done any experiments without the correction? And if yes, like, what can you say? If yes, like what can you say? No, we haven't because, yeah, exactly, because we had this approximation on top of another. We wanted to just get rid of that. Okay, but that could be a way to cut it off. You're getting bitchy about the coffee break. Thank you very much. Let's meet again like five past today. That's 55 minutes better. Thank you, Philippe. Thank you, Piraha. 