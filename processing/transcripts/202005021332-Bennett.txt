Let's see. I hope you can all see that. So, again, well, thanks for the invitation. It's always much appreciated, and I'm glad this is an honor of Richard. Let's see. I should mention this is all I'm going to be talking about today is going to be joint work with Samir Siksek at Warwick. And let's head on from there. Also, the usual disclaimer. Also, the usual disclaimer that I will be hiding as much technical machinery as humanly possible under the rug. So, if you want more details, you can ask me later. Anyway, I'll start off. There's a picture of Richard at some point past the age of 90 hiking with Mount Assiniboine in the background, which again was pretty much his favorite mountain, his and Louise's. And so he always liked heading up there. So what I'm going to talk about today. What I'm going to talk about today are really some sort of classical Diophantine problems, but I'll start with looking at the sequence of perfect powers. Might as well, we'll make them positive, though there's no real restriction in going the other way too. And just notice that this sequence is essentially dominated by the squares. And so we know basically how many elements there are in it up to size x. It's a lot less than x. And so it's reasonable. Than x, and so it's reasonable to expect that the gaps in this sequence ought to grow as a sort of general probabilistic kind of thing. So, currently, well, just to show that the gaps after eight and nine have length at least two, there's an old conjecture due to Eugene Catalin from the 18th century. Can I interrupt you for a second? We don't see the slides, we only see your title slide. So, we just sent some chats, it's still on the title slide, it's on. It's still on the title slide. It's also not full screen. I don't know if you have to make it full screen or what the story is. Nor did we see Richard. Really? I don't even, I just see your title slide. Okay. Well, I don't know if Brendan has this. Okay. I saw Richard, okay. But now I see the title sliding in. There's Richard. Richard. Richard, Richard, and there's the slides. Okay, there's a slide. Is that everybody seeing that? I'm going to try to go full screen again for me. Is it full screen? No. Is this some bug with Adobe? Okay, let me let me. Also, the screen is flickering a lot for me at least. Okay, let me kill that. Let me try to open this with preview. So I used Adobe Acrobat and that worked fine. I was used, that was Adobe Acrobat. Yeah, so I'm not, I don't think it's Adobe. Okay. I used it with Windows. I don't know if you have a different operating system. Or are you just sharing the Windows? I'm sharing preview. I think you should share the whole screen, like the desktop, instead of just the application. Okay. Okay, the fun continues. Um, okay, let's go back to this. What is going on here? Uh, cancel, do not want to leave meeting. What is going on here? Stop share. Okay, so share screen, all desktop. Yeah. Okay. Let's try this then. View full screen. Full screen. Oh no, what's it doing? Okay. Okay. How is that? That's working better? Yes. Okay. So back to our gaps in perfect powers. So Catalan's conjecture was that the only consecutive perfect powers are eight and nine positive perfect powers, and that was proved by Mihalescu in. That was proved by Mihalescu in, well, it was published in 2004, proved a little earlier, though Breda's definition of proof is different than yours and mine. But nonetheless, beautiful results from 2004. And you could ask reasonably if after 27, all the gaps in this sequence have length at least three. So in other words, what happens if we replace the right-hand side on the equation in Catalan's conjecture from a one to a two? One to a two. And this actually is an older problem. This dates back to the 1930s, and S.S. Pillai conjectured that, in fact, if you fixed a positive integer c, there are at most finitely many perfect powers whose difference was c. And another way of writing that is that the gaps in the sequence tend to infinity. It doesn't have anything about how quickly they tend to infinity or anything more than that, but that's a conjecture. More than that, but that's a conjecture pilli. And this conjecture is proved only in the case when c equals one, only for Catalan's conjecture. So it's wide open. There was a claim of a proof due to Gregory Chudnovsky in the 70s, but no paper has ever appeared. Not really waiting on that one too much. And of course, this is the sort of thing that if you play around with this business, you'll see immediately as a consequence of the ABC conjecture. Of the ABC conjecture of Master and Austerley, you know, you can decide for yourself or not whether you accept that that's been proven. So let's step back to something much easier we might be able to prove. And it's a curious thing to do, but let's look at a particular exponentially growing sequence. The sequence of integers of the form 2 to the n minus 7. And I've written down the first 19 terms in that sequence, starting from any. In that sequence, starting from any exponent n equals three, then that first 19 positive terms. And in boldface, what you've got are 1, 9, 25, 121, which are pretty obviously squares, and 32,761, which is arguably less obviously a square, but it is actually 181 squared. And so another way of discussing that is that if we have this particular, it's an example of a polynomial exponential Diophantine equation. Diophantine equation, I've written it in a very weird way. This would normally be written as x squared plus 7 equals 2 to the n, perhaps, but I've tried to write it so it sort of fits into the framework we were talking about before. As if you basically, instead of taking all the perfect powers, you just take the squares, which is most of them, and then you add in the powers of two, which is of course very few of them, and you ask when do you have gaps of length seven in that sequence. And so the suggestion is basically it's these five examples, and that's it. It's these five examples, and that's it. Now, notice that if you start looking at gaps in sub-sequences of all the perfect powers, they don't necessarily really correspond to gaps in the sequence itself, because of course between 121 and 128, which you've got here, there's actually a perfect power 125. So this is an old question. It goes back more than 100 years to Ramanujan, and he posed as a question, not really conjecture, in the Journal of the Indian Mathematical Society in 1913. In 1913. And it was proved in a paper by three distinguished mathematicians, Chaola, Lewis, and Skolem in the Proceedings of the American Math Society in 1959. But in fact, it was actually proved by Shapiro and Slotnik in IBM Journal of Research Developments related to coding theory a year earlier. And actually, Schinsel pointed out that, in fact, he'd proved it with Braukin somewhat earlier in Acta. Somewhat earlier in Acta Arithmetica. And in fact, it's in an undergrad textbook as a problem for undergrads some years before that, in a textbook by Nigel, which you can still buy. It's a Chelsea book, a little red hardcover. And in fact, it was solved some years before this by Nigel in a Norwegian journal. And I've mentioned this sort of sequence of events to people before and pointed out that it would be a little unfair to expect Chaola, Lewis, and Skolem. Chaola, Lewis, and Skolem to actually have followed the obscure writings in Norwegian in an obscure Norwegian journal. But if you actually research this, you'll find that Skolem, well, was Norwegian and in fact was the editor of that journal. So it's possible that in any case, this was missed. So if we generalize this and we look at the sequence of squares and other powers, then you can sort of extend this to this. You can sort of extend this to this type of equation. This is a conjecture of Jungren and J. E. Che. Cohen that, in fact, all the solutions, if you replace the 2 to the n by something more general, y to the n, actually still correspond to y equals 2. And this was actually solved somewhat recently. So this is more recently solved than Catalan's conjecture, because it's actually kind of hard. And the techniques involved are sort of similar to what we're doing. To what we're doing, we're uh, Samir and I are using techniques like this, but a bit a bit more difficult in what we're going to be talking about later. So, in general, it's one of these things that if we want to know about gaps between perfect powers, we know almost nothing. We can't prove that they grow at all. But if you look at the slightly easier problem, it turns out to be much easier, gaps between perfect powers, if you fix one of them to be a square. If you fix one of them to be a square. Now, again, that's the great majority of perfect powers in some sense. Here, we can do a lot more. We don't just show that the gaps grow, we can actually show that the greatest prime divisor of the gaps has to grow. So it grows, if you like, in both Archimedean and non-Archimedean terms. Okay, so we have explicit things here. And these results all follow from bounds and linear forms and logarithms. And so I want to give you an idea of how those proofs go. And when you see Proofs go. And when you see that, you have an idea of why it doesn't work if you replace the x squared with a different power. Okay, so what we're going to do then, we're going to focus on equations like this, like this x squared plus 7 equals y to the n, in one of two situations. So d will either be fixed, like 7, or we'll just fix the prime divisors of d. And so the results I mentioned in the previous page, so these they're called Lebesgue-Nagel. So, these are called Lebesgue-Nigel equations. The reason they get that name is that Lebesgue actually solved the case d equals one back in the 19th century. And Nigel wrote a number of papers on this. The case d equals minus one looks like it should be easiest case other than say t equals zero. But in fact, the d equals minus one case was open until the 1970s. So, rather surprisingly. And as I mentioned before, if you just look at that. As I mentioned before, if you just look at that difference, d is giving me at least an absolute value, the difference between x squared and y to the end. We know that the greatest prime divisor of that has to go to infinity. And so, and effectively here, that actually gives us an algorithm, actually effective algorithm, if you like, to solve such equations in either situation one or two. So, we actually will get a bound upon x, y, and n that just depends upon s in the second case or on d in the first. So, let me just So, let me just sketch how these sort of things are proved. So, suppose you want to solve this equation. Let's suppose that we can find integers a, b, and x, say, satisfying the second displayed equation. So I've got lots of displayed equations that are blue and white, blue on white, and I apologize for those of you with blue-white colorblindness. This one, it's the second one, the black and white one. And if we had that equation satisfied, If we have that equation satisfied for integers x, a, and b, then we just conjugate both sides, multiply the conjugates together, and you get a solution to the equation in blue. So this is then, this is a sufficient condition to find us a solution to x squared plus d equals y to the n. And you might ask, well, when is it a necessary condition? When can we go in the other direction? And it would be necessary if, well, we ruled out d is 3 mod 4, because we're sort of assuming that we've got a quadratic field where the That we've got a quadratic field where the ring of integers is just z of root minus d. If we forgot about units, obviously here, if d is negative, so that root minus d is a real number, then we've actually got, at least if d is not one, minus one rather, we've actually got infinitely many units. We're playing around here, class number one. So, those of you who've played around, sort of elementary number theory, you've tried. Played around sort of elementary number theory. You could try to solve these equations by factoring. You basically have, I've got a product of two things being nth power. Gosh, I'd like to conclude they're both nth powers. Well, when can't you? Basically, when this stuff happens. So if you don't have, if you have class number, that can get in the way. If D is not square free, that can get in the way. And we're sort of assuming that we've got a product of two terms being an nth power. If they're not relatively prime, we can't really reach the conclusion that they're nth powers. So, but if magic So, but if magically we had all that, so if we are in this situation here, the first equation at the top, I guess I can move my cursor to it, then what we have is an algebraic number in this quadratic field, alpha, with the property that the nth power of alpha over alpha conjugate is extremely close to one. And so if we assume, say, here, that d is positive, then we've got to be. Positive, then we've got the nth power of a complex number, genuinely not a real number, that's close to one. And that tells me that the logarithm of that number, well, that tells me that the number itself is close to a rouse unity. Okay? And so we end up getting a relation like this, I've marked down here, that n times the logarithm of this thing is very, very close to k pi i for a suitable choice of k. A suitable choice of k. K here you can bound an absolute value by, say, n or n over 2 or something like that. And so, noticing from Euler that pi i is log of minus 1, we have a linear form in logarithms of algebraic numbers with integer coefficients. So, this is the sort of situation that you can apply machinery from transcendental number theory to get a bound upon n. Okay, so we've got just this quantity is far smaller than it ought to be, and for large n, that's a contradiction. To be, and for large n, that's a contradiction. So, if we go back to the equations that we're interested in, and we don't assume all of this stuff, it turns out that we can still reach pretty similar conclusions. And I'm going to hide the details under the rug, but effectively you can do the same thing. You can still use bounds for linear forms and logarithms. Now, you might need more than two logarithms, or you will typically. And if we're in that situation, too, where it's that. If we're in that situation too, where instead of fixing, say, D equals seven, we take D to be just an integer that comes whose prime divisors all lie in some finite set S, then we're going to need to use linear forms in p-adic logarithms for each prime in the set S. But we can basically do this, and if you crank the handle and are careful, you end up getting an explicit upper bound upon n that, well, I'm not making explicit, you get an upper bound upon n that you could. Making explicit. You get an upper bound upon n that you can make explicit just in terms of the primes in s. Okay. And so that basically says n is bounded above. And so you're left with a finite collection of smaller n to deal with. This is our exponents in our equation from 3 on up. And for each such n, this reduces to a finite number of degree n, 2a or 2a mahler equations. Now a 2a equation is an equation of the shape is an equation of the shape binary form F equals a constant. And a two-a-Mahler equation is an equation of the shape binary form F equals a product of powers of primes coming from a fixed set S. And if you look at this, I say just as one has for this, if you look at this equation here, I've written at the bottom of this page, if you simply expand the right-hand side and collect the coefficients of root minus d, you root minus d, you get a binary form of degree n. Call that f of ab. And that, if you match up coefficients, has to equal one. That's a two-way equation. So this thing here implies, this last equation implies a two-way equation of the shape f of ab equals one. And these are things which you can solve effectively through, again, machinery from transcendental number theory, together with reduction techniques from Diophantine approximation. So let me just look at what one would call the very easy cases. Make sure I'm not racing along too quickly. All right. So let's assume, I'm not going to assume all the super easy stuff, but I'll assume a lot of it. So let's assume that D is positive. That means that the situation about units is pretty easy. D being positive, then means we're looking at an imaginary quadratic field. And so the units are very easy to understand. Are very easy to understand. In particular, there's finitely many of them. Let's assume that y is odd and x and d are co-prime. That means that when you factor the left-hand side, the terms are co-prime. Okay, so that's sort of, I'm setting up my life to be easy. And let's assume that n is co-prime. Probably I need that n is odd here, and it'll say at least three, but n is going to be co-prime to the class number. And so that again, this is all set up so things work easily. I'm basically cheating, but these are the easy cases. But these are the easy cases. So, in these cases, you just do the usual thing, and you really do get that each of the terms you factor is kind of an nth power. We can hide the units. And if you, it's an nth power of something, call that something alpha, then if you just look at the thing you get by taking the nth power of alpha minus its conjugate, divide by alpha minus its conjugate, you can work out that this is actually what's called a Lucas sequence. These things show up in lots of cool places. But in particular, this is a sequence of integers, and this thing actually. This is a sequence of integers, and this thing actually divides d1. And now, remember, in our situation, we're assuming that all the primes dividing d are from some fixed set s. So that gives you, if you like, if you want to do the decomposition of d naught d1 squared, you get a finite collection of possible d0s, right? There's going to be two to the cardinality of s of them, or something like that. Those are the square-free possibilities. And then the rest, all the prime factors are in s. All the prime factors are in s. And so, what we get here is a Luca sequence where the nth term has all of its prime factors essentially fixed. And there's a beautiful pile of machinery that the culmination of it is a theorem of Bilou, Arrow, and Vucci that says that, well, hold on, these Lukas sequences get primitive divisors. They get divisors as you go out the sequence, as n gets larger, they get divisors that never showed up before, new prime divisors. And so, if you fix the set of prime divisors, And so, if you fix the set of prime divisors, that's going to get you a really good bound upon n from this result of Bilo, Amero, and Vuce, which is often called the primitive divisor theorem. So, this basically says that you can just solve these if you're in this situation where you can guarantee that sort of nice things happen, then you can solve these really easily. So, d equals five, for instance. D equals five, why can't be even? Why can't it be even? Because you just look at the left-hand side, mod eight. Okay, and so you avoid these nasty situations. Also, a situation in the second one, if you take D to be powers and two, powers of three powers of 11, again, that can't ever be 7 mod 8. And so you avoid the possibility in this type of thing that y is even. When y is even, this all breaks down. When y is even, the two terms you get by factoring x squared plus d are not co-prime. And so you do not get a Lukas sequence. And so, you do not get a Lukas sequence. So, these are the easy cases, and this is what essentially the entire literature is on. There are dozens of papers solving these equations, always assuming that life is incredibly easy, which seems like cheating to me. But I mean, there's literally 30 such papers. And in every single one, they make assumptions that guarantee that they're in this case. Okay, so well, what's a harder case? Now, this is the frustrating thing. I've already said. Thing. I've already said that we can't prove there's even finitely many perfect powers that differ by two. We can't even prove that the only perfect powers that differ by two are 25 and 27. Pardon me, we can't even prove that the only perfect powers where one of them is a square whose difference is two are 25 and 27. Well, that's not really true because you also have minus one and one. But in any case, we don't know how to solve. We actually can solve the equation x squared plus two equals y to the n, but we can't. y to the n, but we can't solve this one. x squared minus 2 equals y to the n. So this is one just to give you an idea that everything works just fine. In fact, you get probably the very best upper bound you can get from linear forms of logs in this example. We get an upper bound that's really small. It's 4,111. But and for each smaller one, you actually get very nice looking two-way equations. So we've a binary form in this case equals plus or minus one for each degree n. For each degree n, you only get one of these. And if you go from below, you can just solve the two equations for degree n, where I'll assume n is prime, up to and including 37. So you're left with these. The last thing I put in there, n is not one or seven mod eight, that comes from a piece of machinery using the modular method. So fry curves and things I'll be talking about in a little bit. So the frustrating thing is we're left to solve these, and you think, well, that doesn't look like it should be that hard. Like it should be that hard. But as we saw in a talk earlier today, this actually is hard. Well, we didn't really see that described that way. But how do you solve a two-way equation of, say, degree 101? Well, the first thing you need to do is go to a corresponding number field corresponding to the form of degree 101. So it's a number field of degree 101. And you need to find, at the very least, a collection of independent units, a full rank. So that's at least 50. So that's at least 50. So you've got to actually do, and we saw a nice description earlier of algorithms for finding fundamental units. Well, we've got to do it in a situation where we've got at least 50 of them independent. And we've got to find them. And right now, unless you're extraordinarily lucky, this ain't happening. And that's for degree 101. Don't talk about degree 4000. So ultimately here, it's a frustrating situation that we know the only solution to this equation. That we know the only solution to this equation have x equals plus or minus one. We know that, but we can't prove it. Okay, so what I want to do is focus, and this is what my work with Samira does, is on these situations where we're in either D is fixed or we've got a finite set of prime divisors. But I also want to focus on the situation where this primitive divisor stuff doesn't work. I said almost all the papers actually make life easy. I want to make Make life easy, I want to make life harder. And if you focus on the situation where either D is negative, so it's a real quadratic field, or D is positive and 7 mod 8 and Y is even, in which case, again, the factors you get by factoring the left-hand side are not co-prime, then the primitive advisory technology fails. And there's exactly two results in these situations. So, one is the paper I mentioned earlier of Bujot, Mignot, and Sixec, which handles, for instance, examples like the case. For instance, examples like the case D equals seven. So D equals seven and Y even, that's in this last case. And there is a thesis, an unpublished thesis by a PhD student of Samir's from about 10 years ago by Carlos Barros, who handles a number of cases where D is negative. Okay. So the techniques I'm going to describe actually work pretty generally, but I'm going to focus just to make life a little less unpleasant on the cases where A little less unpleasant on the cases where d is plus or minus a prime power. So I'm really, we're really going to focus on case two because Barash has got some ideas for case one. We want to do the case that nobody's looked at. So, and we'll do a, I'll make my set S have a single element. So I'm kind of cheating in that sense, but nonetheless. So in other words, we're going to look at these, at these kind of equations. And really, we really, the hard bit is in the second equation here, is if Q is. The second equation here is if q is seven mod eight and y is even. So let me take a look. Uh I start 12:30. Let me just comment on some earlier work. So there's a number of papers on these kind of things. And in particular, here, the linear forms and log stuff has been worked out somewhat carefully. In general, there's no real general statement for x squared plus d equals y to the n because it's very unpleasant. The dependence upon the prime divisors of d is quite, quite hard. So, but Buuge, at least. So, but Buuge, at least in the simple case where y is odd, in the simple case where y is odd, you get one fewer logarithm, essentially. So, this situation, x squared minus q to the a equals y to the n, you basically get this, you get a linear form in two complex logarithms and a linear form in two piadic logarithms. And in some sense, that's about as good as you're ever going to get. And so you get these fairly clean-looking results as bounds upon the exponent n. So, again, roughly 4.5 million q squared log. Half million q squared log q, but that still leaves you with rather too many 2a equations, in this case, 2a mahler equations to solve. It's just not going to happen. So just to point out, the bounds in the remaining cases are worse. They're bigger than this. This is, in the business of linear forms of logs, this would be considered a very small and elegant bound. Okay, so in a different direction, one can use techniques like Use techniques like those used by Wiles to solve Fermat's last theorem to attack certain types of ternary equations. And one of the sort of families you can look at are things where you have a ternary equation like I've got down here in blue, x to the n plus q to the a y to the n equals z squared. So your exponents are sort of n, n, and 2, if you like. Yes, there's an exponent a, but that's not so important. So you could do this, you can handle these kind of equations with coefficients. There are Fry curves that are associated to these. Fry curves that are associated with these. And if you work out the details, so the details in general are worked out in an old paper of mine with Chris Skinner. But for this specific case, there's a paper of Evora and Krauss that basically say, well, look, this ternary equation is not something that linear forms and logs can touch. You add in the extra y to the n, linear forms and logs won't tell you anything. In the case where y is plus or minus one, that corresponds to the two equations we were looking at before. Linear forms and logs always hand. Linear forms and logs always handles it. And so, in this more general situation, this machinery from Fry curves, if you like, will bound n unless q is a prime of particular shape. It has to be, it won't work for q being t squared plus or minus particular power of 2. And you have to stare at that a little bit to see, but that's actually almost no primes. The number of primes of that, of all those shapes up to x, is Shapes up to x is little o of pi of x. It's actually big o of root x. I think if I get the logs counted right. So basically, this says that most of the time, this machinery will do what linear, if we if we think we then go and take y equals plus or minus one, most of the time, this gives you an alternative proof of the stuff you get from linear firms and logs. It fails for some zero. For some zero percentage set of the primes, most of the time it works and it gives you a more general state. So, in practice, if we look down at that bound, that bound, lower bound upon n, we saw earlier the bound upon n was like q squared, log squared q, and this bound is like q to the q, which is a lot worse. But in practice, this is sort of a worst-case scenario. If you really work it out, so here's some example. If we want to say, well, what are the primes that actually Want to say, well, what are the primes that actually this is applicable to, up to say 100? Well, here they are. There's quite a few of them. And again, the set, the percentage of this goes to 100 as you go out further and further. But for these primes, you can actually, with a little bit of work, reduce that crazy looking Q to the Q bound down to 7. So the takeaway is that when the Fry curve kind of stuff works, it actually works a lot better than linear forms and logarithms. Works a lot better than linear forms and logarithms. That's the general takeaway. And that's something that's generally true. So we can make a statement, which can be made sort of more precise, that in general, if you look at an equation like x squared plus d equals y to the n, the Fry curve stuff will work 100% of the time, and it'll always give you something better than linear forms and logs. On the other hand, it fails for most of the examples you try a lot, because 100% doesn't mean always in this business. So, okay, I've got some conclusions. So, okay, I've got some conclusions. So, the good news then is that this method of attaching Fry curves to these things, to these equations, allows you to really handle these funny particular equations without using linear forms and logs for most primes. The bad news is it really fails and it fails hard for some primes. When a prime is within one of a square, then this equation has a solution with y equals plus or minus one. equals plus or minus one and every odd value of n. So for instance, that's the example take a to be one and q to be two. Then we've always got a solution by taking x equals one and y equals minus one if n is on. And so the fact that this always has a solution for every single value of n, this kind of trivial solution, basically is a real obstacle to applying these sort of Freiker methods. It just makes it not work. So we've So, we've talked about the good and we've talked about the bad, and that kind of leaves the ugly. So, the good are the ones where the method just works, and the bad are the ones where the method really isn't going to work. And the ugly are the ones where there's an obstruction, but it might not be fatal. And so, what about things that aren't within one of a square, but are still something where there's an obstruction? So, this list is going to get expanded, he says optimistically. To get expanded, he says optimistically, but the computations aren't finished yet. So, Samir and I are proving a variety of results along these lines. So, this list should include all the primes that are not within one of a square, up to 100. Right now, it's missing 31 and 41 and a couple of others. They'll probably get there eventually, but the problem is that the linear form and log bounds are really bad, and then the machinery from Fry curves is a little bit slow. So, we're starting to collect. So we're starting to collect these things. So some of these are bad primes where, again, for the most part, some of these ones are ones where the Fryker method just says, okay, you're done. Most of them aren't in that category, but they're ones where the Fryker method, combined with linear forms of logs, allows you to sort of eventually solve them. And we'll get there. But notice again, none of these primes are within one of a square. We can't really say anything about those, except for two. And two is sort of cheating because two is an odd. Is sort of cheating because it's a two is an odd prime, the oddest of primes. So, in the positive case, we can do much better because in the positive case, you never have this analog of this obstruction where you have a y to the n where y has modulus one. So there never really is an obstruction you can't get around in this case. And so, here we've basically gone ahead and solved all of these things with Q up to 100. These things would queue up to 100. And really, the ones that require work, the ones that don't just follow from the quote-unquote easy stuff, are just the primes that are 7 mod 8 in here. So that's 7, 23, 31, 47, 71, 79. These require work. To give you an example, I think it was 79 required many thousand CPU days. Days spread over just 30 cores. So it's a couple of months of real-time computation to actually do this. And I say, this is the statement here is just to make this thing fit on a slide. You actually, the n equals three cases, you can all write them down. It's about the same number again, maybe a little bit more, maybe, maybe twice as many. So these are all, this is sort of thing basically saying you can completely solve these kind of equations. And a last one, just to just to show off a little bit. So here, that last one up to q equals 100. This one, you can go to q equals 1000 if you make an additional. So this is a minus case, but I'm making the exponents even, which is sort of cheating because it makes the thing factor nicely. But nonetheless, you still have to combine these techniques. These are still things that can't be done, couldn't be done previously. So let me just talk about. Talk about some of the ingredients in the proof here. So, to handle these things, so first of all, you have these obstructions coming from the modulator method, but the thing is, the obstructions in some cases are because we're trying to have a Z to the N hiding in there beside the Q to the A. So instead of a 1 to the N, we're putting in a Z to the N. And so we actually have a lot more information here because we have that Z is 1. Here, because we have that z is one. And so, using certain auxiliary primes, I mean, mostly I'm making that sound fancier than it is, it's mostly looking at the prime three. We're able to actually rule out some cases where the modular method doesn't a priori work, but in fact, by making a simple observation, we can completely solve these things in those cases. So, the complex linear form bounds are kind of unpleasant. People have worked at these things. We end up having to use this sort of This sort of statement. I mean, for these things, the main work involved is working for lower bounds for linear forms in three complex logarithms. Now, the statement for two complex logarithms is kind of pleasant. The statement for three that we have to use is from a paper of Mignot. And people who have seen this, the statement is 12 pages long. You say, well, how long is the proof? And that's a very good question because it's not clear there is. A very good question because it's not clear there is a proof. But nonetheless, the statement is 12 pages long. So you end up with the very complicated situation where you've got dozens of parameters. And so it's sort of a linear programming problem to actually find out how to choose them. And then you have to iterate this process. This is one where you kind of, you kind of use it once, get a bound, and then feed that bound back in, and you keep this going until you don't get any gain. But this takes a fair bit of work. So we've done. Work. So we've done a little bit of sharpening along these lines, but not too much. There's not much we're able to do here. But one thing that really is a major ingredient that goes in is we have much more careful use of sort of qadic logarithms. And so we end up with results here that are roughly 30 to 50 times as good as what Bugeot gets. And that's sort of necessary to carry these computations out. And the main work, and again, I've And the main work, and again, I've hidden all the details, is that you've got a bound, you've got these, you use this machine to get bounds upon n, but then you feed this back into these Fry curves. And so what you do is you take a collection for a given prime n, you take a collection of primes that are one mod n. And you go back and look at the Fry curve, and you see for each of these primes, call it P, the Fry curve by looking at the P-Fourier coefficient for that curve. P-Fourier coefficient for that curve, it tells you some local information about what's happening at P for the Fourier curve. And you feed that back in, and that gives you some local information about X and A modulo P. And so that gives you some, and then you keep using this. You have to use a number of these things. Symplectic criteria are basically things of looking at certain images of inertia when you look at the representations here. And this is something that basically And this is something that basically allows you to rule out certain families of exponents n. So, a lot of this comes from the work of Freitas and Krauss mostly. And so, what one finds, I'm picking an example here that people have written a number of papers on. So, again, Samir and Jan Bujot and Maurice Pignat solve the equation x squared plus 7 equals y to the n, this conjecture of Lungern and Cohn. And so we And so we went to look at x squared plus 7 to the a equals y to the n. And what we're able to do, and this again is particularly using this sort of part three, the qadic logarithm bound work carefully, is that we end up getting a bound upon n. This is again, a is just left to be a variable. We end up getting a bound upon n that is very, very close. It's only about 3% bigger than the bound you get by just taking a equals 1. So we end up with almost the same upper bound. So that's sort of the. Almost the same upper bound. So that's sort of the starting point. You get this upper bound, and then there's no way we can solve degree 100 million two equations. So we have to then go back and use these other techniques with Fry curves. But then, and that's just what also has to happens in the paper of Buja-Mignot and Sixsec. What they do then, so they do the A equals one case, they then sieve using all these primes that are one mod n and are able to sort of eliminate that possibility. Now we have to sieve with more primes. With more primes that are one mod n, because we have to then sieve out all the possibilities of a mod n. What we do is we do some prime that's one mod n, and that rules out certain congruence classes for a mod n, and we keep going until we've got them all. And a priori, when you look at this, it looks like, well, maybe one of them is quadratic in n, and maybe one of this is cubic. It might be quadratic if you're doing the a equals one case, which people have done before, and maybe r thing's just cubic. And if it's cubic, then you don't really. And if it's cubic, then you don't really expect you're going to be able to handle things up to 100 million. But it turns out, I don't have a good, I actually do not have a good complexity understanding of this. It turns out that the time seems to be only greater by a linear factor than the previous result when we're sieving for just fixing a equals one. We seem to be able to sieve out all the values of a mod n with only about 20% more sieving. Maybe there's a good Maybe there's a good heuristic reason for that, but I don't see it necessarily. Okay. And the one thing, last thing I want to mention is, again, for that very last one I mentioned where we do all the Q up to 1,000, this is a much slicker result. We actually use sort of a more elementary argument to handle the case where y is odd. And the y equals even case, we actually strengthen the bounds in the literature for these sort of strange binomial Tui-Mahler equations. And we're Mahler equations. And we're able to get something that's about 100 times stronger in terms of constants than what was known. And for our purposes, if we're going to go up to 1,000, we really need that. That the computation, well, we would not like it to be, because again, it's not linear. So if we had to go 100 times further, the computation would take many, many years using 1,000 cores. So the fact that we get this down by a factor of 100 makes this thing something we can do in a weekend. So anyway. So anyway, I think I'll stop there and thank you for your attention. Any questions? Yeah, Mike, what do you use for your computations? So these are done almost entirely with Magma, and that does raise philosophical questions since it's closed source. But a lot of the packages here are actually written by Samir and myself. Samir and myself. So, originally, so we have some confidence that it's okay. And I try to do things that can be done in C. I do in C, but a lot of this, the functionality is there in Magma. My experience, I've done a lot of computation in the last few years on different problems, and I'd love to use Sage more, but life isn't long enough for the most part. So, it's the idea then you're developing. the idea then you're developing a lot of this computing machinery along the way of with these techniques and it's being added to magma or was it all there already so some of it's there and some of it we're developing okay so and and i've i've hidden other stuff under the carpet there's some there's some really extensive work that's been done by uh adela gerga uh some your sex so we we're using these so our end game computations here to finish this i said our bounds This said our bounds, the machinery gets down to sort of around seven, and you think, oh, well, that'd be easy. But that still leaves you with a bunch of, say, fifth-degree 2A mahler equations. And that's something that would have been completely out of reach only a couple of years ago. But there's a very big package being produced that is not publicly available yet. It's still a work in progress, but it's working enough to do this kind of thing. So that's something that sort of watched this space kind of. Something that sort of a watch this space kind of thing, I think they will announce that relatively soon. But they've built this tremendous thing, and it is many thousands of lines of code. It's a real beast. It's one of these things that Toua Mahler equations are always something there's a paper saying, oh, you can effectively solve this. And the arguments, it's a very beautiful paper, but the arguments essentially work for the Tue Mahler equation that they solve. And they will fail, and it is set up to be sort of perfectly solvable. Set up to be sort of perfectly solvable. It's like the class number is one, it's like everything works perfectly. And if you change almost anything, it basically goes to the lifetime of the universe if you try to do it. And so what Samir and these people have done, Adela and Samir, and it's also Raphael von Kennell and Bento and Matsuke, they produced something that really is functional. And it requires enormous numbers of new ideas and stuff like that. And this is something, so this is something that'll be coming. And more generally, it's something that should be able to. Generally, it's something that should be able to solve fairly general S-unit equations and not just in sort of trivial cases. That's kind of what we are, where we are right now: we can solve some of these things in completely trivial situations. And if it's anything but trivial, it doesn't happen. So it's a sort of early stages for this stuff. But that's all hidden under this. So there's some pretty heavy computational stuff there involved in this. All right, let's make the speaker again. I should stop sharing, shouldn't I?