In the middle of the screen, there's a big thing that needs to be put in first one. Yes, yes, yes, yeah, yeah. Recorded all the garbage. Okay, so yeah, so on the other side, we have these much more holders inside of P and infinity. P and infinity, which is basically defined something that we can define over depending only on p. And if you don't know what that is, it's not really important, but we just know that we can do that. Like think about like a q vector space of dimension four, essentially, if you just want to get the idea. And then lattices, the q vector space is the quantum algebra, and then the maximum orders are simply like lattices inside of that. Inside of that. So, yeah, we have this thing, and it's kind of explicit in the sense that we can get the maximum order related to the curves by looking at the isomorphism class of the on the morphism of the pain. So, yeah, that's like the basic part of it. But in fact, we can give more names and other objects that are going to be useful for us. Going to be useful for that, obviously, or isogenies. Let's say from curve E0 to E1, and on the other side, I get this kind of ideal that I'm going to write here, like from O0 to O1, where here O0 is going to be isomorphic to the endomorphism ring of E0, and O1 is isomorphic to the endomorphism of E1. Okay, so these are other types of objects. Once again, lattices, and once again, it won't really matter what zone. And once again, it won't really matter what those objects are exactly, but just they kind of exist, and we have this kind of correspondence between the two. And it's really like one-one, meaning that every object on one side has an equivalent on the other side. Okay, so that's like the basic results about that. But this is all theory. And then the question is that, okay, but what do we have in practice? What can we do with those objects? We do with those objects, and so this is where I can talk a little bit about algorithms that we have and what kind of like problems that we know solve and those that we don't really know. So first we can say like the kind of translation problem, meaning that I have something in one side of my table and I want to go to the other side. To the other side. So, first, I can start from a curve and I want to compute the corresponding order, or I can do the same with like an isotony with the corresponding ideal. Then we have the reverse problem going from small order and from an ideal into an isogeny. And I also add other problems which are not directly related. Which are not directly related to the During correspondence, at least one of those, but I think they are going to be, I know they are particularly useful. So we have the so-called isotony problem, which is given two curves, E1 and E2. I want to find an isotony connecting them. Okay. And then the translation of each problem of the quaternions, which is going to be, I have like two like two um two autos and then one um some kind of idea for anything box and uh he tells that that um well some of those problems are actually hard and we can base cryptography upon those and some of those problems are actually easy and this kind of duality is actually nice because in cryptography we kind of need both some things that we can do efficiently Happen in both something that we can do efficiently and something that we cannot do efficiently. So, in fact, whenever I start from the quaternion world, it turns out that all those omens are kind of easy. So, easy in the sense that let's say like in the right setting, we have like efficient polynomial time algorithm to solve them. And on the other side, those problems are believed to be hard in the sense that, yeah, there are some. In the sense that, yeah, there are some very hard instances, and by hard, I mean like the best-known algorithms are exponential. Okay, so this is the little bit of our setting for, let's say, the ski-sign family of schemes. And now I'll try to explain a little bit maybe it's better that both me. Oh yeah, I guess you cannot see any more. You cannot see more uh it will be more sorry Okay, so now let's talk a little bit about Ski Sign. So the idea of ski sign is essentially to use those kind of things that we know how to do That we know how to do, uh, maybe just quickly. So, those problems, those fast algorithms, I'm not going to talk about them today because they were quite complicated, and it's I just want to give the intuition about the protocols. So, I'm just going to use them as kind of black box, and I'm not going to get to too much on details. Okay, so saying that, so ski time, what is the idea about ski time? So, this is a signature scheme, okay, so and that's what. Okay, so, and that we are going to build from an identification protocol. So, the idea of identification is that you're going to have some public information, which is your identity, and you want to prove that you're really like person behind that public identity. And usually in public cryptography, this means that you're going to have some kind of public key and that everyone knows and can see, and then some kind of secret key associated to it. Associated to it that you only know. And the goal of this identification protocol is like to prove that you indeed know the secret key. So in our case, private key is going to be some curve E, and the secret key is going to be its on the morphism. Okay, and the hardness of recovering the secret key basically is based on this onomorphism ring problem here, where the goal is to you have a curve and you want to compute the key. You have a curve and you want to compute its on the MOP circuit. And this is supposed to be hard. So, this is why recovering the secret key is hard. So, this is our setting. And there is another hard problem that we are going to use for our protocol, and it's the isogeny problem. Okay. And we see that from the world of curves, so when I have only two curves, this problem is supposed to be hard. But when I start from quaternions, meaning when I know the endomorphism rings. Meaning when I know the endomorphism rings of my two curves, basically I will be able to solve this problem quite efficiently. And ski sign is all about making that happen. Like the prover is going to be able to solve this isogeny problem, whereas everybody else should not be able to. So yeah, the goal of SkiSign is basically to set up some kind of instance of the isogeny problem that only the prover can solve. So this is the idea and for that we are So, this is the idea, and for that, we are going to use this kind of three-round interactive protocol that is quite classical in cryptography. So let's start from some curve E0, which is going to be like some kind of constant of the scheme. I start by doing some kind of secret rules toward my public key that I'm going to write EA here. So, this is the colour of EA. This I got in tau is supposed to be. This identity tau is supposed to be secret, and this knowledge basically is going to be equivalent to the knowledge of the under-morphed. Yeah, the two are actually equivalent because once I know the morphed dorm, I'm capable of computing a certain issue and this kind of stuff. So, yeah, so this is the start of point. I have a secret. So, this is what happens at the beginning of my identification protocol. Then I add the first round, which is the commitment. So I choose a curve, I just going from a curve E0 to a curve E1, and this curve E1 is going to be sent to the verifier, but not the commitment. This part needs to be secret. Then there is going to be a challenge. So this is the part where the verifier is going to send something to the prover that will force the prover to solve an instance of my ID. To solve an instance of my isogeny problem. And the idea, of course, is that this challenge cannot be guessed by the prover, and this is why it will force him to behave honestly, essentially. So this is done by the verifier. This is another isogeny pie. And this B2 E2. So this isogeny pie is sent to the prover. And then here we are our setup. And now the goal of the prover, as I said earlier, is to solve this. As I said earlier, is to solve this isotony problem. So you can do that by computing some isotony, collecting EA and E2. And then the verifier can just take this isotony and verify that it is indeed an isotony between the two things. And if that is the case, then basically by the hardness of the isotony problem, it must have been computed by the prover. And so this is really the idea of. Is really the idea of the scheme. And so this works for both the original ski sign and the new ski sign HD, which is simply a variant of this first scheme, where we use basically the new ideas introduced with the attacks against SIDH and the Canislema and everything. And we just use those ideas to modify the way we do things. So to understand the difference between the two, I need to go a little more. I need to go a little more into the details of how do we do this concretely and obviously the more efficiently possible. So for that, I need to explain to you what was the idea behind the first ski time. So I guess at that time, so before I get a little bit of a message I guess at that time, so before we became really aware of Kenny's lemma, there weren't many ways we had to actually give and efficiently compute an isogeny. So essentially, the best way is to have something which is smooth and where the smoothness bound is actually the smallest possible. So this is why in the original ski sign we decided to take like a degree of C. Like the degree of sigma to be power of two. Because in that case, verification will be very, very efficient. Because the main job of the verifier is to compute this isotopinisigma to check that it goes from EA to E2. So we wanted the verification part to be quite quick, and this is why we choose this decree. The problem is that, well, this is like a very strong constraint. This is like a very strong constraint, and it's actually very hard to find isogenies of these forms. So I said to him, Yeah, don't worry, we have a polynomial time algorithm. So it's true, but this algorithm is not like performing miracles. So we can do things and we can find a suitable solution, but it's going to be actually very big. In practice, the size is going to be, at least in the setup of ski time, almost setup of c time almost equal to p to the four whereas the optional solution we can expect it to be like approximately of size p so this is much bigger than what we could have uh but the thing is that the only uh the only size we know how to find efficiently so um so this size like this very big size it's going to be an issue and it's going to be make the computation To be make the computation, the actual computation of this isotony sigma by the prover quite costly because so I don't want to get too much into the details, but essentially we how we find this asoty is that we perform a bunch of operations over the quaternions. So this is this we use this algorithm here to get from the two on the Morphisms to some ideal, and then we translate that ideal into an isotony. That ideal into an isogeny, and the isogeny is sigma. And then we reveal that isogeny to the verifier. So, this part we can perform it when the site is pretty big, as I said, and then we need to do the translation part. But the translation part is not free either. So, it costs actually a lot, and we have to like so for efficient computation of schema, We need to choose very, let's say, weird parameters. We need to have, so I'm not going to explain why, but just take it as it is. We need to find some big smooth odd number t that divide p squared minus 1. Minus one where t is roughly p to the five divided by four. Okay, uh, yeah, the best algorithm that we have for performing this translation needs these kind of parameters to be run as efficiently as possible. The problem is that this t is actually bigger than t. And so this means that it will be very hard to find a t that is very smooth. Why do we need t smooth? Because in this algorithm. Need T S news because, in this algorithm, in this complex mechanism, we need to perform T isogeny computations. And as I said earlier, the smoothness of the degree is the key in the efficiency of isogeny computation. So, this is why we need this setup, and it's quite problematic. So, we can find some T, but obviously, the smoothness dome is going to be quite big. And this is the main bottleneck, in fact, behind. In fact, behind the efficiency of the first ski sign part. So I think in ski sign, we choose parameters to make some kind of trade-offs. We choose to have the fastest possible verification because usually in signature schemes, this is the part that we want to be as fast as possible. And the problem is that it comes at the cost of a very slow signature process. Slow signature process where we have to do this translation for a very long isogeny, and this is quite painful. And we need these parameters, which are very hard to get. And another problem, I guess, is that this does not scale very well because the smoothness bound of T, I think you can prove it's like growing sub-exponentially in the size of P. So as big as P will get, then in the angle random we've Then in the end, we'll hand them with the T, which is not very smooth, and this is not very nice. Because, yeah, if we need to scale parameters, the efficiency will be a lot worse. So, our ideas with SkitHan HP was to try to overcome this obstacle by using the same. The thing that we learned with Canny's lemon. And in particular, I think the main result that is very useful for us in this setting is the fact that so for any uncertainty signal. Sigma. Okay, so here from EA to E2, we can, and here I'm going to quite pay, but represent in some way sigma by this the following information. First, it degree of thing and then And then points and the image of those points under sigma, where PQ is a basic of, let's say, a well-tried torture. So in our case, we are going to try to use like a power of two. Okay, and And here the size requirement that we have on this 2 to the F is that 2 to the F must be bigger than essentially square root of the degree of sigma. Okay. And here the important thing is that there is no Important thing is that there is no kind of restriction on the degree of sigma. We don't need it to be smooth anymore. And this is the part that's going to be important because as you see, like the only requirement is on 2 to be 10 here, and it just needs to be big enough. But on the degree of sigma, so if we reverse the inequality, we have an upper bound on the degree of sigma, but we don't have any more constraint on its smoothness, which means that we can. That we can avoid this complicated operation that we did earlier to find a suitable isogeny of smooth none. Here, we just have to find like the smallest isogeny that we need, essentially. And this is where this becomes quite interesting because now we can avoid this complicated mechanism and we are going to be able to select. Going to be able to select parameters which are, I mean, much friendlier than I see. I'm sorry, I'm sweeping a lot of details under the rug. I don't really have the time to. Is under the rug. I don't really have the time to explain exactly how this representation form works. Sorry, maybe I can just mention that it's really using heavily these new techniques by essentially the idea is that you can embed in some sense sigma inside a higher degree isogeny of dimension D and degree like to the F to the D and And yeah, that basically we can kind of compute this hypotenuse quite efficiently because it had it has a power of two. And yeah. Is the two to be a torsion? Is this rational or is it a high extent? Oh, so yeah. Okay, yeah. So the question was that what is the like the requirement in terms of field of definition for this 2 to the end? So obviously to keep things as compact Obviously, to keep things as compact as possible and also to enable the efficient computation of this to the F to the D dimension D, and certainly, we are going to want that to be defined over FP squared. So, this will be part of our parameter selection. Yeah, so okay, so yeah, we have this thing and it works with like this dimension D isotony computation. Azergini computations, which are not completely trivial, but we have algorithms that are somewhat efficient. Maybe I can explain a little more how the signature process is supposed to go. So I think that the signature part, so if you look at the diagram that you have. At, like, the diagram that we have, and as what I said to you, so this basically, this information is going to be the signature. This is the part that we're going to reveal to the verifier. And so, the job of the verifier is going to be to compute this like that higher dimension isogeny. And the role of the prover is to compute all those information. So, well, the degree of sigma is going to be quite easy to get because it's Be quite easy to get because it's just like once again, we are going to use ideal, so you just take the norm of the ideal, and as I said, you can just take it basically very to be very small. So, yeah, maybe so the first part is like compute a small connecting ideal and here. And here, like the smallest that we can hope for, basically will have a roughly sized square pill. So, if you compare that to the almost picture that we had before, in terms of size, it's going to be much better. Then, the second part, let's say, is to use like so. So psi and phi that gives me a path from EA to E2 to evaluate somehow my isogeb sigma on my basis PQ and then I'm done actually so this is the good part like in ski sign entity the signature Like in ski sign entity, the signature process is much easier. So, of course, there are a few technical details about how do you choose psi, pi, and toe in a way that allows you to make that computation from EA to E2 quite efficiently. But yeah, I'm just not going to explain how it was works, but you can do that. And then it is just like pushing the points and essentially you're done. And then we have the verification. And then we have the purification, which is going to be one step. So compute essentially the five-dimensional associate embedding signal. Signal. So, in terms of concrete efficiency, this part, as I said to you, it's much easier, much simpler. It's going to be much, much faster than what he had for Skisa. That is not for sure. The verification part is a bit trickier because, well, we are only at the beginning of the real study of the efficiency of this high-dimension isogenic. High-dimension isogeny computations. And in particular, in our case, we are going to need dimension at least four. And this is like the big problem because dimension two, it has been studied. We know how to do some things. Dimension four, it's still like basically unexplored territory. And so there are a lot of efforts right now. And so there are a lot of efforts right now to actually make those computations efficient. We have some estimates that the actual complexity might not be completely crazy and that we could actually run this thing, but it's never been actually implemented. So this is like a big question mark about the efficiency of this new scheme because we know, yeah, signature is going to be much faster, verification, we don't really know. We don't expect it to be faster than ski-fine, but we expect it to be. Key sign, but we expect it to be not so bad and maybe like a little bit slower. That's key sign, but yeah, not like 1000 times slower. But only actual implementation will answer to that question. I guess I'm running a little bit out of time, so I'll just wrap it up very quickly. Yeah, I'm just going to mention very quickly that another advantage of this new scheme is Advantages of this new scheme is the security. For some reason, security is a bit cleaner. In particular, one part that is very important for the security is that this isotony sigma is actually kind of random in the sense that it does not reveal any information about the separate. Okay? And in ski-sign, it turns out that, like, the original one, this is something is not random at all. It's computed in a very specific way. All it's computed in a very specific way, and basically, our security assumption is that, well, even though it's very specific, to the eye of an attacker, it's going to seem random. But this is not like a clean and nice security assumption. So one of the advantages of our new scheme is that essentially, we can take sigma to be essentially the smallest isotones there is between EA and E2. So, in fact, to make it work, we have to tweak it a little bit so it's not those. Tweak it a little bit so it's not the smallest, but it's really one of the smallest, and it makes the distribution of sigma much cleaner. So we got a better sense of the security with this. And so we introduced new problems, but that seems like more plausible than the one we had for a ski sign. And yeah, I'll stop there. I don't know if we have some time for some questions. So you can ask questions while I change the setup. So the letter talkers in that. Oh wait, let me unmute the people. Okay, I muted you guys because you were still talking about the recording after it was recording. Sorry. But you're now unmuted if you want to ask questions. Sorry, it's not fifty attacks. Yeah, so the question is, does the new attacks against PSIDH affect the security of SKISA? And the answer is no, absolutely not. The setup was quite different for PSIDH and here it does not apply. And here it does not apply at all. Yeah, I guess this is the tricky part, but it's all like hidden behind what I written here that you only need the evaluation of the isogeny of those points to kind of represent the isotony. I guess I don't really have. I guess I don't really have the time to get into the details, but the idea is that there is some kind of isogeny of high dimension that kind of embeds sigma in the situation because like this high dimension isogeny, you can make it so it could be an isogeny between like a product of Pa and the product of L. And you can see that as some kind of matrix here. And one of the components of this matrix One of the components of this matrix includes this hydrophysium, and if we compute the kernel of this high-dimensional hypothety from those points, then you just compute the identity from the point and check basically that one of its components is indeed an isotony between EA and yeah, I don't have time to explain more on that, sorry. Yeah, do we still use a generalized TLP algorithm to compute sigma and then push the points through, or do we use the other ones? So the question is, do we use the generalized KLP to compute the sigma or we just use another method? So in the first original skin, we use this kind of generalized KLP stuff. Yeah, the reason is that, well, this is the only way we know how to compute something of smooth snow. But the thing is, as I said to you, I can take Sima as one of my small, one of the smallest, essentially between EA and ET. And how do we find one of the smallest? But it turns out that this is one element inside one of the ideal lattices that I have. And I can find small elements just by doing some lattice reduction. And since those lattices have. And since those elements have dimension 4, I can actually find the smallest elements very easily because the dimension is very small. And this is how we get the sigma in that case, in the SCISIM HD case. So we have a question from Peter. Yeah. Peter, you can speak. Can you hear me? Yes, we can. So my question is: is there any hope of currently writing the verification, you need Verification, you need to stay either in dimension four or eight. I guess if you mostly in four, if you guess it's the sum of two squares, issue whether it's four or eight. But is there any hope of like weakening the item gene representation idea to get down to dimension two, like the tricks that are used in tests, for example? Yeah, so that is a good question. Oh, yeah, sorry. So the question is. So, the question is: can so, well, right now we're using dimension at least four, as I said, and obviously, like the complexity of this algorithm grows very like exponentially in the dimension, actually. So, obviously, we would like to keep the dimension as small as possible. And so, the question is, can we make it work in dimension two? So, this is something we considered, obviously. The thing is that it's really related to the way. So it's really related to the way this kind of competition stuff works. But it turns out that if you want to do that in dimension two, you need complete two isotopes. This sigma and then another one, beta here. And computing this isotony beta is kind of hard because you don't control its degrees or you don't control the smoothness. It's legal in Canada. And this is what makes me difficult. Not legal to do it there. It's legal to buy it. It there, it's legal to buy it. It's not so gonna have it in public, I don't think. Oh, yeah, sorry, uh, but yeah, we talked about uh going to the we have some ideas, but uh, it's uh it's not so easy, so like I can do it for future work, yeah. How could the sum s function change and uh so the good point is that the sum s stays? Part is that the sum nest stays essentially the same. The sum nest relies on the fact that it's hard to find automorphisms, essentially. And well, this remains the same in both ski-sign NTV and Ski Sign, because in any case, we're kind of solving the same problem. So, of course, we are not giving the same solution, but in terms of verification, you're kind of accepting any isogene that works before. Setting any isotopy that works between the two. And so it does not change the two settings or similar in that sense. Sorry, I don't know why it's not displaying everything. You know, not the webcam. It just should be displaying what's on my computer and stuff. Of course, the webcam is not the same. Yeah, another speculative question. Focus on my laptop. But it's not up there. I don't know why it's not up there. Is there something that you thought about? Like for example, something on this one? So I guess since this whole diagram is really similar, it's just that the difference between Skit Han and Skit Han H would change the way in terms of the... We're just changing the way we perform this computation, but the idea is the same. To answer your question, I thought about doing group signatures or other types of signatures with C-time. For now, I've failed to do so. And I'm not sure using this high-dimensional stuff will really help. I think it said that the scheme mostly remains the same, and this is just detailed about how we perform actually in the computation. In the computation, so but that this does not mean there are some better ideas that we could use in the future to do more than that. But my experience for having different things is that this FIFA framework is not really easy to modify to make like group signatures or other types of signatures, I guess. Sorry, Antona, you're getting very many questions because we're having technical problems. We're just trying to get our display working here. Sorry, Andrea. Do you want to take five minutes to get your display and we could just grab coffee? Yes, please. Okay. Is that okay? I'm going to push the back complaints. Go very quick because we've actually got it working. Go grab your copies and come back in five minutes, yeah? Yeah, that's that's it, that's it.