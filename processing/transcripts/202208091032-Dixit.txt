And I'm really happy that a lot of speakers, including Andrei just before me, have set a very good stage for me to talk about what I'm going to tell you. And at the end of this, hopefully I would have convinced you that of a new way of thinking about input-output relationships in cell populations, especially when cells are heterogeneous. So, just a brief introduction to the people. So just a brief introduction to the people because of whom this work was possible. This is my current group. We are a new group. We started during the pandemic, but I feel like they have done a lot of interesting work. Ours is a computational biology group in a physics department. We are interested in many things in biology as well as in physics. So, if you're interested in talking to me about these things, we can always chat offline. Today, I'm going to talk about a work in signaling. Work in signaling done by two graduate students, Hoda Akul and Andrew Gilles. So by now we know that signaling networks allow cells to interpret their environment. Yesterday, Andrew, they were talking about how cells can sense external ligand concentrations in order to kind of move towards the direction of a flow. And if I look at, let's say, inside of a cell as to how that computation. As to how that computation is actually being done, I will see a signaling network. So, in this case, I'm looking at an EGF, EGFR signaling network, a central mammalian signaling pathway. And the idea here is that the ligand will bind to the receptors and it will lead to a whole bunch of downstream cascading, including phosphorylation of proteins, translocation, and so on. And I can look at the cellular response to this extracellular input, which is the EGF concentration. The EGF concentration. For example, I can look at what is the amount of receptors on the cell surface. So, here I am showing you the steady state level of cell surface receptors as a function of EGF concentration and which I am considering as a response, which is just an abundance of some intracellular signal in species, in this case, the receptor level. And you can see that there's a huge variability between different cells. Cells. So, for any given ligand concentration, cells can behave very differently, and as a result, even across different ligand concentrations, there could be a confusion in the population. I can go a bit downstream and look at, let's say, phosphorylation status of some downstream protein. I'm going to see the same thing. Across different ligand concentrations, different cells behave very differently. I can go further downstream, look at some translocation status. Now, this is the amount of translation factor that is present. Amount of transcription factor that is present in the nucleus. And again, this is when you're exposing cells to IgF, not EGF, but quite similar story. And again, you can see that the distribution of floxo-levels inside single cells is quite different. And this may make you believe it may appear like cells really don't know what's happening on the outside. They can't really read off the environmental ligand concentration if you just look at the report. If you just look at the nuclear proxy. And a way to quantify this particular intuition or feeling is mutual information, which allows us to quantify how much information is present in the nuclear levels, let's say, or in some output as a function of the input. So, if I just define some quantities, we can imagine u to be the input. In this case, it would be an extracellular ligand or the concentration of an extracellular ligand. X could be X could be your output of choice, which is something that you can measure. In this case, it is the nuclear levels of a transcription factor. And then you have this distribution, you have x given u, and you can at least get a histogram of that from single cell data. This is something that you can, in principle, measure. And then what information theory will allow you to do is to calculate a quantity mutual information. I don't need to give any introduction about this, which depends on a distribution over the input states. Over the input states. And I can imagine a different distribution over input states, which is something that is not accessible to me. But I can then look at the maximum of this quantity, which is typically called the channel capacity, which is the maximum amount of information that is contained in this output with regards to what's happening with the input. Now, this is a reasonably straightforward recipe, and you can go ahead and then calculate the mutual information. Ahead and then calculate the mutual information for many signaling pathways, and this has been done. And it looks like, based on at least these mutual information calculations, that signaling species seem to carry very little information about the environment. So this is one of the original papers that Andre's paper that he talked about, where a signaling network of choice here, the TNF-alpha NF-kappa B network was exposed to different levels of TNF-alpha, and you can see the And you can see the distribution of the NF kappa B in the nucleus. And based on just these distributions, you can calculate the channel capacity, tensor to be one bit. You can go to a different network, which is the ERK-MACK pathway as a function of EGF concentrations in the environment. Here you can look at your output not as just the concentration of a protein at a given time, but let's say across multiple time points. And depending on how many time points you include, you may get slightly different. Many time points you include, you may get slightly higher visual information, but it typically plateaus out around one and a half bits. And similarly, for an optogenetic system where you are also changing the definition of input, instead of giving the constant input, you are now giving cells an oscillatory input. And you can get mutual information which is somewhat high. But in all these cases, it looks like cells are basically able to tell whether an input is present or absent. One bit of information would basically. One bit of information would basically mean that you can distinguish between two states of the environment: between the very low state, presumably, and the very high state. And this is somewhat surprising because why do we have cells respond in a manner that is gradual over an entire range of ligand concentrations while cells not being able to tell what is the difference between the lowest and the highest ligand concentration. Lowest and the highest in concentration. So, we can take a step back and try to understand what are the sources of these variability. So, we now know that two factors contribute to the observed cell variability. So, here I'm showing you some experimental data. We are a computational lab, so this is not our experiments. But some previously measured experimental data on the amount of FOXO in the nucleus following the introduction of IgF in the N. And again, when you add And again, when you add IGF in the environment, FOXO is pulled out of the nucleus and you basically see a decrease. And each trace here is a single cell, and different traces are obviously different cells. Now, this cell-to-cell variability that you're observing here has two contributing factors. One is something that all of us are very familiar with, which is stochastic fluctuations, and these happen because of small number-related noise. And this inherently corrupts information transfer. Information transaction, right? Because even for a given input, you're going to get a random output. And then there is a more important variability, and I'm very happy that Andre talked about this just before this talk, is cell state-dependent variability. And many talks here have already underscored the importance of this relatively stable cell-to-cell variability. And this is inherently not corruptive and tips larger than the stochastic fluctuations. Fluctuations. Now you can kind of idealize or make a mathematical idealization to put these things in perspective. So, what I can do is I have biochemical parameters and these could be parameters relevant to a signaling network, let's say receptor levels, reaction rates. And I assume that these parameters are roughly constant inside a single cell, but they vary from cell to cell. To cell. Then I can think of the measured output in a cell population as a marginalization over the distribution over single cell parameter states. Now again, this is something that typically is measured in experiments. This quantity is basically the distribution of an output when you fix the input as well as the states of the chemical reaction network. And this quantity you can inform. Right, and this quantity you can, in principle, obtain by solving a chemical master equation if you had a reasonable idea of the underlying model for this system. I will state that this is not permanently accessible. The cell and torture it hundreds of times to get a histogram for this distribution because when you do that, the cell has already changed. And then you have this kind of irritating distribution of our cell states. Distribution over cell states, which is a reasonably difficult problem to solve, and it's an imposed inverse problem because you want to have this, you have a structure for that, and you need to kind of basically invert this to get that straightforward problem to solve, even though its marginals, for example, cell receptor levels, etc., may be accessible. And based on just this decomposition, now I hope I can convince you about. I can convince you about the two natures of the variability. So, if I look at, let's say, one cell and I see fluctuations here at the steady state, these fluctuations are because of the stochastic noise, versus the variability that I'm seeing here is because of the variability in parameters. Again, this parameter variability is quite challenging to infer, and we actually have published a paper previously as to how to do that. I'm not going to talk about that work here, but it's quite integral. That work here, but it's quite integral to what I'm going to talk about. So, how do you know that the slow fluctuations are due to the parameter and the fast fluctuations are due to just an assumption, or is there some way to know it would be quite difficult for a stochastic model to kind of fit this level of variability if I know the abundances of molecules. So, there are other evidence. There are other evidence also, as I mean, if I know the not for this particular network, but if I know the initial value of the receptors on the cell surface, that is quite predictive of what will happen at the end for that cell. So that's kind of a cell state variable that dictates the overall variability rather than the fluctuations around my cell state variability. You have self-exciting receptors like an K2 system. I remember the job. Yeah, yeah. Yeah, I'll number it. I just I th I don't see a a natural decomposition. Unless you assume that parameters are always slow. Yes, yes, correct. So this is this is a very definite assumption here that compared to the stochastic variability. And Andre actually showed some examples where that is not the case, right? In in that case, this won't be applicable. So how do we determine the so you're treating a theta, the ether as a prior distribution? The prior distribution? No, it's just a distribution over the parameters. How do you decide the distribution of theta? Oh, that's again, it's not a trivial problem. It's an entire thing that we did some time ago. So it's an ill-posed problem. There are infinitely many solutions to this. So we do an interrupt maximized solution. Like find P of theta with the maximum entropy, that kind of captures most of the thing. That's not a unique solution, but there are. That's not the unique solution, but there are other solutions that we can find, but that's the maximum entropy solution, so it's kind of. So, not from the Bayesian point of view. Yes, an inversion of this equation would be quite ugly because even if you discretize this, you can't really, it would be very spiky, the inversion. So, you will have to regularize the problem in some ways. So, if I assume that these theta parameters are slow and the Slope and the variability at a single cell level is due to the stochastic fluctuations. How does this translate into my understanding of whether cells know what's happening in the environment or not? So let me do a thought experiment. So imagine that I have some cells and I give them some low signal. Currently, assume that I don't really know what the internal parameters are. I see a distribution, great. I again impose a high signal to these cells. I see another distribution. Cells, I see another distribution, and these two distributions are overlapping. And that would mean that maybe these cells don't really know what's happening in the pattern. What may be happening at the single cell level is that for any given cell, the distribution of outputs might be quite well dissolved, even though the population distribution is overlapped. And that may mean that maybe at a single cell level, cells are quite cognizant of what's happening in the environment, but a population-level analysis. A population-level analysis does not let you to that conclusion. So, the question then is: how do we quantify information transduction when different cells are basically acting like different channels? That they are not instantiation of the same channel, but because they have different set of parameters, they are different channels. And the answer is already there in information theory, and that quantity is called conditional mutual information. So, again, let me repeat what mutual information is. If I have a bunch of cells, I put Of cells, I expose them to some signal, I get some outputs, I can calculate the mutual information if I knew the output distribution. I can do the same thought experiment for a single cell, where I have a single cell, I expose it to a bunch of inputs, and then I get a distribution over outputs, and I can calculate the mutual information at the single cell level. Again, this is a thought experiment. Most probably, I won't be able to do this experiment in reality. And then I take an average of. And then I take an average of this quantity, which is the mutual information at the single cell level over the entire cell population. And this is defined as the conditional mutual information, is a mutual information between x and u conditioned on some other variable theta. Actually, I can do some information theory tricks and I can in fact show that this mutual information, the conditional mutual information is always greater than the mutual information. And this is great. And this is great because I didn't really have to make any assumption about the underlying signaling network. The key assumption was that these parameters are constant. That's the main assumption here. So as long as the parameters are constant and cells are different in that P of theta is not a direct delta function, I'm guaranteed to have this conditional mutual information to be greater than the actual mutual information. And this is a consequence of the Jensen inequality, as you may have guessed. So this was. So, this was quite encouraging. So, we wanted to see whether we can compute this quantity and whether it is useful for us. We looked at some data that was collected on the IGF-FOXO pathway. And so now it's a good pathway because FOXO is a reporter that shuckles in and out of the nucleus and you can tag it with the GFP and you can track it in live cells instead of doing time-snap short measurements. So, just a cartoon for the pathway: you have receptors for IGF on the cell surface. When you add IGF in the Surface. When you add IgF in the environment, the receptors get phosphorylated. That phosphorylates a downstream protein called AKP. AKP then phosphorylates FOXO, and phosphorylated FOXO is kind of pulled out of the nucleus. So what happens is that when you add IgF to the environment, nuclear FOXO goes down. And so that's kind of shown in the video here, which works in that at time t equal to 0, you will see a strong concentration at the center of the cell, and over time, the center becomes dull and the periphery becomes. Dull and the periphery becomes bright, and that's basically indicating that the coxo has moved out of the nucleus. And one can do image analysis and make get quantitative measurements out of that. So we have now cell traces of foxo sort of activity or foxonuclear levels across different cells across different ligand concentrations. So we have that data, we have a reasonable model. This system has been quite well studied. And then we do this maximum entropy inference again. We do this maximum entropy inference again. Unfortunately, I don't have any time to talk about that to get the parameter distribution. And these are the ingredients that are needed to compute this conditional mutual information. So let's see how that quantity looks like. What is the prior failure between this? In this case, it would be all the rate constants and all the abundances of proteins. Let's say the IGFR levels, the internalization rate, the phosphorylation rate, the deposphorylation rate, and so on. So, how many divergent is your favorite? It would be something like 10 for this system. And so, at the population level, you build the histogram over all cells at the single cell level to get a distribution. Oh, we don't, in this case, we actually only use, even though we have single cell data, we only use the snapshots of the data. Because even though for this particular snapshot, Even though for this particular system, the thing reaches a steady state, I can't really consider that as sampling from the steady state. So I don't want to do that, I guess. Even though intuitively I can think of the pilot as it is real states. Yes. So the IGF is the input that you actually add to the media, right? So my question is like I just want to wrap up my head around this. So basically when a cells is in a particle concentration, the actual input that the cells see is also flat shapes, right? Also, flat-shaped, it's great in a way. But you're because of Brownian motion? Yeah, because of like a Baumian or something. So, but that part of the ligand. Correct. So, if I understand your question correctly, we have looked at, let's say, just the immediate neighborhood of the cell. At these concentrations, the amount of ligands that are actually present, as Andrew was talking yesterday, is quite low. It's going to be like at any instance around a cell, maybe there are two, three ligands present. Around a cell, maybe there are two or three ligands present. But the speed of diffusion is so fast compared to the time scales of binding and unbinding that we don't have to worry about the so the cell is actually seeing like a smeared out mean field version of linear concentration. So we did worry about that because it would be nice to add extra stochasticity to our model, but it unfortunately wasn't a problem. So the thing you're showing here is basically a TV. The two of your parameters across populations, right? Right, and so this this is already quite structured, so whatever Ki and Kj are, they're rather correlated with each other. Have you checked if we actually need all the ten parameters? Like in some sense, can you do some i? So we could say yes, if I have one more gradient. So yes, these parameters. First of all, it's a maximum entropy distribution, so it's actually not. Maximum entropy distribution, so it's actually not going to correspond to the actual distribution of these parameters in the cells. This is going to be a much wider distribution. That's one. Two, this is actually a Cartoon reality. But they are correlated. And yes, I think it will be possible to explain these in terms of two, three different variables. That's something that I'm really interested in doing, but I just need more people who are interested in doing that. Okay, so I do have ingredients for calculating this conditional which. For calculating this conditional mutual information, and so let's see how it looks like. So, here on the left, I'm showing you mutual information at channel capacity, so the maximum amount of mutual information, as a function of time, because I do have a time course. And on the left, on the right, I'm showing you the channel capacity input distribution, so the distribution that corresponds to the channel capacity, but just at 90 minutes, where you have the maximum amount of information. And this is the traditional way of calculating visual information between the input and output. And the value you get here is. And the value you get here is something like 0.7 bits, right? So, again, you will be able to detect either the ligand is present or it's absent, and that's actually reflected in the channel capacity input distribution, which has basically a peak at zero, no ligand, or a peak at 50, maximum. Now, this is just a sanity check that our model also, model fit to the data, also looks like data. So, I'll just skip that in the interest of time. This is the This is the conditional information. It's significantly higher, it turns out to be around 1.8 bits. And the conditional mutual information tells you that the cells can utilize all the inputs that were available to them and recognize between those inputs. So at the single cell level, at any time point, I'm getting one instance from One instance from the underlying master equation, and then I am getting an average over the master equations, and that is enough for me to compute like a maximum entropy average. And that's like a likely data. But it would be much better, and for technical reasons, I can't do it, to include single-cell dynamical data into this instance. This quantity is an average over multiple cells. There was a question. There's a question. Is it an average or multiple cells? I can also look at, because if you remember, this is an average over the P of theta distribution. I can look at, at least in my computational ensemble, what's happening to individual cells. So that's what's being shown here. So the dark shaded region is 50% of the cells around the mean value. And the light shaded regions is 90% of the cells around the mean value. So it looks like most cells are doing much better than what the population analysis would indicate. So this does. So, this does suggest that cells are able to tell what's happening in the environment. But I want to be a bit more careful and quantitative about what I mean by that. So, what do we think when I say that cells know what is happening in the outside? I can think of one experiment where I have the ligand as a function of time and I do like a step ramp of the ligand. Okay, now if the information Now, if the information was one bit and the cells were only able to detect this level and that level, what I would see at the response is that cells are basically here, they get confused in the middle and then they suddenly show a response over there. And that's what we mean by a one-bit information transaction. This experiment was also done, thankfully, and this is what it looks like. So, this is the population average response. The arrows here are when the ligand was added, and the population average The ligand was added. At the population average level, you can see that the cells do move at least in their mean value when you add new ligand. Now, if I look at the distribution, now this is distribution 90 minutes after adding that ligand concentration. If I look at these distributions, these distributions are indeed overlapping with each other. Yes. But it might not be the same cell that's acting all these. But it's going to be like this going to the next slide. Ah, excellent. In the next slide. Excellent. So, this population analysis will indicate that, okay, population responses are overlapping, which is consistent with the low mutual information. Now, I can look at, because I have data on single cells, I can look at what's happening at a single cell level. First I'm going to show you four, and you should trust me here, randomly chosen cells from my model. So, this is one cell. So, basically, I choose parameters from my underlying distribution of parameters. Underlying distribution of parameters and then a Ginnispere algorithm with sort of this protocol, and this is what happens to a random digital cell. So, a single cell is able to resolve these four inputs, even though the population seems confused. This is another random cell, this is another random cell, this is another random cell. So, these are all cells in the model. So, the model at least suggests that if I subject individual cells to higher and higher concentration of the ligand, they will vary in a Very, you know, with high fidelity, they will change their phoxo level. So, in some sense, at least at the level of phoxo, there is some knowledge of what's happening at the environment. Now, these are experimental data. Thankfully, we had experimental data on this. And the picture is the same. In the experimental cells, also, whatever sort of steady state data I could get, we see that at the single cell level, the distributions are quite resolved to each other. So, this does mean. So this does mean that responses at a single cell level are well resolved. That's kind of the icky part about this. The cells reach a steady state and then I can take the last 30 minutes. That's the uncomfortable bit. So if I add a ligand, cells reach a steady state and I can look at the last 30 minutes as a fake distribution. That's not a real distribution in a mathematical sense. It's just the last 30 points where Just the last 30 points where cells are, in principle, at least according to the model, fluctuating around a steady state value. It's not a real distribution, if that's a real cells, they kind of understand sort of the relative difference between these conditions absolute values, right? So is that because the parameters or is it sort of like my understanding of The problem is 125 is different than the next cell's understanding of 125? Is that presumably? But that's for the downstream machinery to deal with, I guess, right? So yes, cells that will have higher number of receptors will obviously have a stronger response, or cells with a lower number of receptors will have a slower response. Now, how the cells deal with that in taking action, that's not captured here in some sense. So it also implies that there's some constraint in terms of how the parameters vary across cells so that they can't even resolve the difference between different colors. So the relative distances are kind of understood by cells rather than the absolute. So if the graphs are completely messed up, right, so you would assume that they're just not so drastically capable. I'm not sure if I fully understood the question. The question. Could we could you? So I guess it goes back to what's the structure of the prime, the distribution of parameters seems to have some structures to make sure cells can resolve different sort of comments. Yeah, hi, this is Andrea. I was told to rudely interrupt, but can you hear me? Yes, it's very hard. Because I'm on Zoom and Because I'm on Zoom and there's no way for me to raise my hand easily. Maybe I can help the previous question and kind of dovetail my question as well. And, you know, it's something that people observe also in other systems where you look at, and this is sort of related to my example, of the non-orbotic systems, right? The cells that are stuck in a sort of state and they are able otherwise to do this higher informative. Higher informative process. The question that I pose in my talk, and it's still relevant here: how do you know which cell ends up responding to IGF-2, if it's a single cell, kind of being at the right place at the right time? You're choosing cells from a population, and each one is pretty precise. How do you know which one is going to be involved in the response? So, this added uncertainty, I believe, is related to the Is related to the uncertainty of the parameters that may define how much information you're essentially infusing into the system yourself and therefore gaining in the estimate by performing a choice. You're choosing a cell and that infuses an additional information that is defined by the positive by this primary distribution that I think previous question was about. But can I add maybe also maybe I misunderstood your question, but so it not only parameters, right, but there's also a model in here involved in there. So my understanding is that the underlying model would be in such a way that if I'm changing parameters, if the output would be, for example, always monotonically decreasing, right, I would get an order. No matter whether that function is starting here or That function is starting here or there or there. So I think that there must be something maybe evolved not necessarily to the parameter distribution but rather to the model which is kind of in between in this. Is this kind of also maybe a way of answering that question? Now I'm back to work. Yeah, all of this. Basically, there is some structure, model, and parameters so that you always get the right order, although you don't get asked about it, right? Ask if that is right. Yes, but the experimental cells don't know that a model exists, right? So. Yeah, but the source, I mean, if your model is right. So the parameter distribution is constrained to reproduce experimental data, so it will faithfully try to do that. Oh, by the way, we're at the 30-minute mark, so. Oh, okay. So maybe I'll just finish this with my conclusion, and then we can talk later. So So anyway, let me just go to the conclusion. So in general, cell populations, thankfully we now all know, cell populations comprise cells with heterogeneous states. Signal networks of individual cells are not instances of the same channel. They have very different input-output relationships and which could be quite close to deterministic. And the conditional mutual information is the quantity that allows us to quantify single infidelity while accounting for certain population heterogeneity. For cell population hydrogen. And what you need to compute this quantity is the single cell data that you already had, a reasonable model, and some inference to get the cell state variables and to get to this quantity, which should allow you to see whether individual cells are able to know what's happening in the environment. And I think we've had enough questions, so I'll wrap up and thank you. If there's any version of questions, we can do one more short question. Otherwise, we can have a longer discussion at lunch. I guess we should stop recording that we stop recording.