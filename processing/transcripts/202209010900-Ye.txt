Thank you much for the invitation to join the workshop of Applied Function Energy. It's a long time for me to travel abroad. I'm now at Guangzhou, China. Now the time is 10 o'clock p.m. in the evening. Now I want to give the talk if the just like the title is Machine Learning in Barkless Bay. In Balkan Spain, is our recent research. And that's all I give a subtitle: A Black Box or White Box Method. It is a question. Maybe you can find the answer when I finish the talk. Yes, I want to give the introduction. Now is something you can look at two mathematics, some is parallels. Plateau is in the philosophy of mathematics. In the philosophy of mathematics, parallelism is a form of a newness. Mathematics is a mathematics abstract, has no space, time, causal properties, and is immutable. Next is another guy from Germany, David Hilbert and everyone know him for the Hilbert space. Another philosophy of medicine, he mentioned is the formula. Is the formulism. Formulism says that the freedom of mathematical logic is the rules for certain streams operation. Now, this is now the philosophy of mathematics, many guys from the all almost all from the Western world. Now, for the current world, now we are doing the research for machine learning of something like the AI or taking AI. Like AI or technical NAC, maybe we need some new philosophy of mathematics to guide us to do the research. Now, and now we were talking about the big data. Now it's very popular topic for the big data. And when I'm a student, I run the big data from one document from Obama White House when I study in Chicago. And this file you can download from. From Google, you can search it, you can use it to download. One sentence from the document is say, we the spectator, we not only need computer science and mathematics, but also social science, communication, and legal discipline. Something like now, these things for New York Distant Living Perhaps, you can say the data science is a very important research field. Research fields, maybe it needs to combination for different areas, such as mathematics, computer science, domain, expense. So, in the recent world, we may need a new film or new philosophy to guide us to run the topic of machine learning or big data analysis. Something like two guys, something like the steep drop. So, we need the So we need the innovations of mathematics, innovation is to make all sorts of things together. So just like the data science, we may be in the in the region for the research area where combine different areas together. Another is a good art puzzle of Picasso. Picasso also says that good artists is copy, great artist is still. So our mathematical So our mathematician is sometimes we think our artist. So Azip Joe also mentioned this role for a product. So maybe we need to different knowledge together to do some revolution of mathematics. Now and we're talking about my mathematics trees. Now this is my three advisor. Is my free advisor? Uh, not this guy, Grad Grad Fast Hole is my own. I was talking about my master advisor, uh, Lien Huang, is at China, at South China Normal University. Uh, he's doing the research is automatizing. Another thing is my daughter advisor, Greg Faso. I finished my PhD at Chicago. So it is doing the research. So it is doing the research approximation film. Another is my postdoc collaborator, it's Yu Shen Shui. I do the postdoc at the Sejung University. So he's focused on research in invoice problem. Now, this is another three guys is my master advisor PhD advisor is Kong Fu Wu is from the Chinese University of Hong Kong. University of Hong Kong. Another is the Lady Summaker, is also an advisor for Flasho. And Vicheri, Vichori was a postdoc collaborator of Yusun. So this is something my research background from my whole life. So I covered the three area because I have different advices and optimization, approximation film, and inverse performance. Approximation freedom and inverse problem. So, this is also very important for my life to do the research of machine learning. So, everyone knows me, my research focus on the kernel-based approximation level. So, that is a sample in my library. Now, this toolbox is the blue one is from Graph Faso and something. GraphFasso and something like Veron and Berman is a radio-based function called as single-data approximation. This is the first nice is doing for the something like the engineer. Now the second the second nice is also mentioned for the kernel. Now, is for about for the machine learning. The three nice is from the synthetics. There are many There are many sentient there one research error is called creating is using kernel to doing that now so so just night that my research also cover for different areas something like engineering computer science and scientists so I am I'm very interested to read different reading different books so I'm talking about a simple example for the current A simple example for the kernel. What's the kernel-based approximation method? There's a very famous kernel. It's called Gaussian kernel. This is how we can find it. We can find the 10 mark. This is Gaussian. Gaussian mentioned it in his second book. Now you can see in the sentence, this is a Gaussian kernel for one dimensional. Now this is also a normal density function. Tensive function. So now, for my research, in my student, I also want to do the research is combine the finite different finite element and finite volume together in one system and use the kernel-based approximation method to combine these three methods together to solve the digital equation. So, my some paper, I'm doing this. My some paper, I'm doing there. So I think this problem for a long time, and now our research team also do the project. So for each area, some paper is doing that. I joined the Liberal Lin in Beijing University, so for doing the five different paper, combine the radio-based function. Now, I do the research area for. Do the research area for machine learning, I find an interesting idea. So now there are two methods. In the classical method, we call the model drawing method, something like the mathematical modeling. Another method is just like the data analysis, we will use called the data drawing method. For the data drawing method, I use to analyse, usually used to analyse the bad broad model. The bad box model and the model dry level are usually used to analysis the wide box level models. It's a question: is how we can combine the data dry level and model dry level together? Because for the classical level, we always use the data dry level. Just now we construct different digital equations to present the world, the new world. Now we use the machine learning. There are many, many users. Learning. There are many, many, you have many data. We use different algorithms to find the approximation solution and to solve the problem. We call the data drive method. It's the big question is how to combine these two methods together. So it's still a question. But in our Eastern philosophy, we maybe refine our answer. So just like that, for the data drawing level, we all also. Dry metal, we all also analysis the black box model. You can see in the black side for the model dry metal, I use to analyse the y-box metal, maybe in the y-side. How to combine together? You can see this is the tie-treat diagram. This tell me the answer, give me the answer. You can combine these two models together. It's perfect. So now I'm doing why some paper to Some paper to how to look at how to combine these two methods together. Then, in my idea, we use the discrete local information of the bad box model and the white box model to construct the global approximation solution by the algorithm of regularized learning. So, this is my idea. So, how I can think that this is because I not when I come back to China, I look at in some temple, I look at this. In some temple, I look at this figure, give me some philosophy. Now we're talking about the topic of machine learning in Balkan Spain. This is my long paper I write with Yu Shen Shu. We write the paper for a long time, maybe for seven years, maybe for seven years. Now you can we in the classical method, we saw the kernel. Store the kernel-based approximation method in the reproduction kernel Hilbert space. Now, we in this paper we generate the method in the reproduction kernel bar kind of space. Now, the paper is a very long, 122 pages. In this paper, we also discuss the one-norm reports of kernel of bucket space for the sparse running because the one-norm. Because the one norm space is not a Hilbert space, but it's a bucket space. So, you use the film in our paper, then we can give some best result for the sparse machine learning. So, after the results of reportation kernel barcodes bay, I'm thinking about in the for the general barcode space, how we can construct our How we can construct our bachelor learning algorithm in general broadcast space. So, we write two papers, one paper already published in NSA and application. It's just one for our general film in Baker Spain. Another paper is if you can find a job in the archive. And in this one, we give the whole film and not only for one film, it's whole film for the coverage film. The coverage freedom, implication freedom, or possibility freed, and so and in this paper. So, in this paper, we will contract, uh, discuss the general data. Why we want to discuss the general data, we will talk later. And in this walk of red-line running in Barclay Spay, provides another role to study the algorithm of machine learning, including the interpolated approximation film and the approximation film and then complexity and then smoothness in approximation film automatic film and the generation and overfitting in regulation film now regulation film is related to immers problem so you can this is i'm very lucky for this three important mathematical topic in machine learning i went and in my study backgrounds And in my study background, I have run it. Approximation film, I follow my grab. Automatic film, I follow my Dian Huang. Vergan film, so something like the immersed problem, I enjoy the work with a username. So this is the three important topic in machine learning for mathematics. So in my paper, I want to answer. want to answer this three question now this is uh the some talking about the the big picture of my paper for the red line learning for the ordering problem we want to find exact solution uh from this uh uh from this automatization uh minimization uh b is a buckler space and r is some expense And R is some expected risk function, some kind we can think about is the arrow. Usually, this R is very complex or even unknown. So, we need to use some data to describe it and compute it. So, in the middle sentence, we call a recognizing. So, we will So, we will show the machine learning in the red button in the middle term. So, many paper and many people are located in the middle, in the center field. But there are few paper, only a few paper discussed for the coverage film. In our paper, we want to complete the coverage film in another idea. Another thing, we want to put the machine learning problem in back. The machine learning problem in mathematics inside the computer science. We need another film, we call it reversal film or approximation film to transfer it to our finite dimensional automatization. Then we can solve the problem in the computer. Now we can solve the final dimensional optimization problem by ADNN or accepting level or compositive optimization level. For these two levels, we do not discuss in this talk. Do not discuss in this talk. Now we can look at what is the meaning of a general data. For our data, it's not, we have the input and output. And now for the input, we are not only discussing the input for vectors or something else, we talk it, looking is our operator. Now, V star is the PDU space of the bucket space. Of the buckler space, why is some output range? So, for the operator, why are we looking for the operator? Because in my first research, we want to combine finite element, finite difference, finite volume together. So, when we describe the digital equation, we get some operators. It's not only a data point. So, in my first research, in my first point, we want to look at the operator. At the operator. So we generate the film of classical machine learning to generate data. Another thing we look at for our loss function. This is just a rotation. You can think this is just something like the cascode loss function for this standard form. So something like the L is a heat loss. So then we can put the data inside this. Data inside this loss function, then we can compute it. So now we next look at another problem. It's not for the original problem, it's a regular running problem. It's another thing problem is just the minimize to solve the disminimization problem. Why we want to solve the this minimization problem? Because the ordering problem, we usually are not all complex. We cannot compute it. We cannot compute it. But for the original, the recognized running problem, we know the loss function, we know the data, and we can put the function f inside, then we can compute this guy. Another thing, because the space, the norm, we know that this is just a neural pressure term, we also know that. So we can put, we all know the whole term. So we can find the approximation solution. Approximation solution from the recognition. So another thing, this problem, because the bucket space B is usually in infinite dimensional space because our system computer science, our computer can only solve the finite dimensional problem. Sometimes we also change this problem to another problem. For this, UN is a subset of B, then subset is a subjection. then substanti is a subjection omega n from omega n uh a gamma n from omega n onto u n so this gamma uh omega n is a is a subspace or some dimensional a finite dimensional space okay i want to talk about that this u n may be not a subspace maybe it maybe it's only maybe it's only a subset just neither neural network oh because for this problem Because for this problem, the UN is only has a finite parameter. So it's a finite dimensional automation problem. So we can use some technique just like we're talking about for the ADNN or composite automation to solve it. So then we change the original problem to the regular name problem and also transfer it to the problem. And also transfer it to the final dimensional automation. Then we can, this for this rows, we can solve the problem from our computer. Now, and we want to talk about some freedom, just like the revalidation freedom, automatizing, and curved freedom of a real guide running. And here, for the courage freedom, there are only Country freedom, there are only a few papers to discuss it. Why? Because it's very difficult. Many, many freedom in machine learning, we need to suppose the data has some special property, maybe IID. Actually, in the new world, we do not know the data. We know the data, but we do not know the ordinary problem. So many assumptions may be. Many assumptions may be not true in the new world, or maybe we cannot check in the new world. Now, we give another assumption to prove the coverage field. It's one if R n is coverage pointwise to R, it's very easy to check. We can also check by the text function. Another thing is we only need to check the general input data is really compatible. The general input data is really compact in the PDU space. Another thing is the loss function satisfies some condition. Because the loss function is simple, always we know that this condition is easy. Another thing for this condition, it's also easy to check it because the space we can change it. We can give a special PDU spay. So we can also check the rated competitive for the general data. So we do not need to stop pause. So, we do not need to suppose. Suppose the data satisfies some assumption for the probability distribution. So, and for this, for this, the condition of second two, we can also imply that it's weakest star conditions on the cost ball of origin. So, we here, we discuss the courage in the weak star topo. It's not in the north topo topology. Topology. So, why? Because we use the regular term and from the norm of Barkless Bay, we can use the weak star complex of the sphere to do the proof. Another thing is that our general data is defined in the PDU space, so we can also make the connection of the big star topology. Topology. So, and here, this is our idea to do the proof of the cartridge film. So, and we have this free film, the regulation film is so that the approximation solution are equally sold by a finite dimensional automatization. This is just neither support vector machine. So, approximation film is so that the approximation solution are approximation sold by the finite dimensional automatization. Solved by the finite dimensional optimization, something like the neural network. For the current freedom, we prove the extent of the current of the exact solution. Another thing is if it's the subnet or the approximation we start courage, then it's also courage to the exact source. Another thing is for a spare soul, reduction parameter is also weakest courage. It's also weakest star courage. So for here, and we complete all the this film in the weak star topple. So this is the main result of my paper. Another thing is my paper also give an interesting idea for the bad box model or white box model. Something like that. We look at, we think about. We look at, we think about this problem. We use the B here covering up a bad box model. Maybe we can use some discrete data to give it that the real problem. Another thing is the white box model. It's very simple. We can combine these two models together. We can get a new model. So if the exact solution we can solve from these two models, the exact solution can also The exact solution can also solve from this new model. So it's a very simple idea. So another thing, when we solve the model, we maybe use some integration level, something like that. For the back box model, we can, if this guy, RN is a convex, we can use the possibility operator to find the solution. For the white box model, we can also do that in the same way. Now, how about Now, how about we combine these two models together? Look at for this figure. If we only use the bad box model, can we integration? Just like that, we only use for it for the integrated inside the bad box. And another thing also saying we integrated in the white box. But when we combine these two models together, we can do the bad box first time and white box next time and do the side. And white box next time, and do the cycle, then we can give the solution. This is very common for the accepting level, something like that. We can do the back box the first time, white box in the next time, and then come back together, and we do that again, again, when we cover it. So, for this figure, it's very similar to our title and our titan diagram. So, this idea. So this idea is close to our Eastern philosophy from China. Next one, I want to talk about our projects for the big data analysis in education and medicine. We also apply our method inside in many applications. One is for our mathematic. Our mathematics for high school mathematic education of middle school. In the middle school, we use this four step to get to do the system, data construction, algorithm design, text and improvement, and practical application. Another thing, we also do the big data analysis of digital imaging of parenthesis cancer. So we do the image enhancement, images segmentation, imagery, which are. So we apply our machine learning level inside in many applications. Now we're looking for our some results. This is our one result. We use the bad box method of supporting machine to analysis the data of methodic education for high LT teaching. For high LT teaching. So, and this is ready, we get the information from students, information from the examination. Then, we can do the use the support vector machine based on product kernel because we have different information. Then we can do the classify to output the student level. This is tell the teacher from middle school to do their teaching. Then we can also give some software copyrights from China. From China. So here we use the bed box model and method to do that. Another thing, we can also use the bedbox model of artificial neural network to see the same data. So this is also the input for the student, many information of the student can get output. So this is the two methods we use to combine our system, use the backboards method. Another thing, for some requirement for our project, is require, we how you get the bad box model. Some the some teacher maybe give a question. Can you give a white box level? Yes, sure. I can give you some white box method of decision tree to analysis the data of mathematical application. So because we use the tree, we can see that inside the logical. So we call this is a white box method. Is a white box method. So it means that we solve one the same problem. We can also use the white box method, we can also use the bad box model. So now our research team to discuss how to combine these two methods together to get the best result. This is one application for the machine learning. Another application for our team, if use the imager, which is Asian. So we use the So we use the is very classical method for the morphism dormant model. This is a why this is a model drawing method. So we do not we can use this because inside it have some physical meaning. So we call a model drawing method. Another thing is use the beta drawing level is the unit because it's the deep learning. It's the deep learning. It's very popular now. We do not need to any physics rules for the image regeneration. We only put inside the data and put inside the network, then it gives the answer. And why we call it a data joint? Because it depends on how many training data you have. So, and this is the example, we do some tests in the bridge. Test in the bridge. You can see for different levels, for this is a model drive level, you can get a smooth curve for the loss. But for the data drive level, it's very fast and give the best result. But the loss is lost. So now we are teams, how to want to combine these two methods together to solve the problem. So because the for the data drawing level and model drain level they have different properties now I want to give something by the film of requirement running we will combine the black box and white box method to contract the composed album to solve the problem of the big tendency in education and medicine. Just like I give an example. Our origin idea is inspired Our origin idea is inspired by the Eastern philosophy such as the golden bean and Taiji diagram. Just like the figure we're talking first, we can do the cycle. And now our research team is focused on these two areas. Not only the abstract freedom, just like that, we're talking, we discussed machine learning in weak star topple. This is something like the pure in pure mathematics. And now it's many machine learning paper, they will not decide. they will not decide not discard in the topple error and in for the for for their film but we want we can do something now another thing is for the numerical algorithm we can sort of different algorithm just like ADN and composite algorithm more and another thing we also do the practical application something like the education and medicine then we when we finished our application we can give some results then we can compete Can compete our mathematical film. Why are we thinking about how to prove the coverage film? Because when we do the project for the education and medicine, they give you some requirement to whether you can combine the data-driven model-driven method together to give you a better result. So now I write some paper to support my idea. Idea. Just like Plato and Aristotle, one guy's looking at the sky, another is looking at the underground. And I believe that the mathematics is not only for the object freedom, just like Portal thing. I also believe that the mathematics can combine the new world and we can solve the, use the mathematics, solve the new world, many new world problem now in the Now, in the new age of machine learning and data analysis. Okay. Alf, thank you. So thank you very much for your interesting talk. So now we are. I also want to do the some uh what uh what advertisement for for our uh lab. This is the conference in two thousand uh 2017. Now, Fong Dai. Now he's here. You can see it's in the photo. So now Slong Grace Micherry is also many guys joined the conference. I hope that I can do the travel in the next summer. Welcome to China. Uh to China, Guangzhou in the next summer. I if if I want to organize another international counter approximation film in 2023, welcome to China Guangzhou in the next year. Thank you. And you can some information of our lab. You can see the website. Thank you. Okay, thank you very much for your talk and the announcements. We have plenty of time for questions. So are there So, are there questions here in the audience? Does not seem to be the case. Are there questions in the Zoom community? Yes. Please go ahead and just speak if you have a question. So I yeah. So I know any question I I know any question. I can stop the screen. Okay, yeah. So there are no questions. Thank you very much for