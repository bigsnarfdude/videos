Thank you. Thank you very much. So, well, for the introduction, first and also for the invitation and for organizing this very nice workshop. I could actually attend most of the talks, but I have to apologize. I couldn't attend some of the talks because of some teaching and that I couldn't. Because of some teaching and that I couldn't postpone, et cetera, et cetera. But it was very nice. So I will definitely watch the videos of all the talks that I couldn't attend. So I want to also apologize with the speakers whose talk I couldn't attend. Yeah, but I will do it. So yeah, so I want to talk about a verbolic polynomial. So yet another talk on IP. Talk on hyperbolic polynomials. And so I choose to talk about this topic, which is spectra-hedial representations, which is the context of a joint work with Mario and Daniel of a couple of years ago, maybe three years ago. So let me give a sort of idea of what I want to talk about and what is the goal. what is the goal of this of this paper so in this in my talk uh in this talk uh i will have uh i will be interested in in a semi-algebraic set so which is a convex uh convex basic semi-algebraic set which we have already seen in the during the workshop so it's the hyperbolistic cone it's one of the hyperbolistic cones of a of a hyperbolic polynomials or hyperbolic polynomial so it's a it's a same algebraic set which is uh essentially encoded Is essentially encoded by just one polynomial, if you want. It can be defined just well, it's given so defined by many inequalities, but this can be just defined, encoded from the given polynomial and some fixed direction of hyperbolicity. I will recall the definition next slide. So I will have this convex semi-algebraic set, and I would like to represent this set in a Present this set in a good way, in a tractable way, let's say from a computational point of view. And so, what do we mean by tractable? I will mean I want to represent these sets as a solution of what we call a linear matrix inequality. So, a semi-definite representation. So, in other words, I will so the output, let's say, of the algorithm will be a matrix whose entries are some linear. Whose entries are some linear polynomials, and the set of points where this matrix is positive semi-definite is exactly the green region that I have in inputs. Okay, so this will be the good, tractable representation of my set. And the idea is that, okay, so the set is the hyperbolistic con of hyperbolic polynomial. So it means that there exists a curve. So this talk is about curves. Okay, so hyperbolic curves. So dimension projective dimension two. Dimension projective dimension two. So there will be a curve that somehow defines the closure of the boundary of this set. So if you take the boundary of this set and you take the closure, all the polynomials vanishing on this boundary, you will have that this is a hypersurface and yeah, this will be given exactly as the zero set of my polynomial f and then for my construction, so how to in order to compute this semi-definition. Compute this semi-definite representation, I will need another curve. So, in this picture is the green curve, which I will call an interlacer, which will be a curve of the degree of f minus one. So, if f in this case is a quinty curve, so the interlace will be a quartic curve with some special properties, and I will use this curve in order to. This curve in order to construct another curve, which I will call an extra factor, which will be very easy, which will be another hyperbolic polynomial, but very easy. So a product of linear forms, real linear forms. And I will use this new curve, this dashed blue curve, in order to get the representation. Okay, so the given representation, just to give a spoiler of the end of the talk, so the semi-definite. Torque so the semi-definite representation of the green region will correspond to a determinant representation not of the given curve but of some multiple of this curve. And the multiple, the multiplier will be given by this product of linear forms. So this is more or less the idea. Okay, so in the first part, I want to recall some definitions. And so I'm talking mostly to non-experts or non-familiar to hyperbolic polynomials. Non-familiar to hyperbole polynomials. So, if you are an expert, also, yeah, maybe you can skip the first part if you want. So, just me, let me just give some definition. So, hyperbolic polynomial is a polynomial that essentially generalizes symmetric determinants. So, if you take a homogeneous polynomial F, so it's called hyperbolic in some direction E, whenever the polynomial. Whenever the polynomial doesn't vanish in this direction, and the characteristic polynomial is a real-rooted polynomial. Okay, so this is a definition of a hyperbolic polynomial. This is an infinite family of conditions, right? So these characteristic polynomials is parametrized by all Rn. There are many characteristic polynomials, and all of these must be real-rooted. And we say that the polynomial is hyperbolic if it's hyperbolic in some direction. So there will be many directions, so hyperbolicity. Many directions of hyperbolicity. So, just some examples that people already talked about. So, products of real linear forms are hyperbolic. The symmetric determinant, so the determinant of the general symmetric matrix is hyperbolic, where I mean that the matrix, so it's full of variables and the matrix is symmetric, it's hyperbolic in the direction of the identity matrix exactly because the characteristic Matrix exactly because the characteristic polynomial of a real symmetric matrix is real rooted. But it's also hyperbolic in any other direction that corresponds to a positive definite matrix or maybe a positive negative definite matrix, because there will be many directions of hyperbolicity. And more generally, we have seen also in the previous talks that determinantal polynomials are hyperbolic, so polynomials that can be expressed like that. So, polynomials that can be expressed like that as a determinant of a pencil of symmetric matrices, these are hyperbolic. And more generally, if you have a power of your polynomial and this power is a determinant or maybe of a very large size matrix, these which have been called weakly determinant, if I'm not wrong, in the previous talks. So, these are all hyperbolic. Okay. Okay. So, this is the So, this is the algebra part of hyperbolic polynomials. Then, there is some geometry because every hyperbolic polynomial defines a convex set, which is a set of points where the characteristic polynomial is, well, we know that the characteristic polynomial is real-rooted points where the characteristic polynomial have positive roots, which is called the probabilistic calling direction of the given polynomial. And there are Of the given polynomial, and there are equivalent definitions that have been given in the previous talks and that can give you an idea of where to locate the hyperbolistic cones. So you can take the real variety and take the component, the complement of this variety, and then the component that contains your vector is exactly the hyperbolic con. And there are many hyperbolic cones. Many hyperbolistic cons. So actually, there could be also exponentially many hyperbolistic cones. So, what we know is that if the polynomial is a irreducible polynomial, there is only one pair. So, first, hyperbolistic cones are given in pairs. So, when you have a cone, you have also the minus cone, which is another hyperbolistic cone. And if your polynomial is irreducible, then you have only one pair. And in general, there could be very many. Be very there, could be many hyperbolistic cones. These have been bounded by Torsten and co-authors a few years ago. We know that they can be also exponential, there can be exponentially many, and this bound is also attained clearly in the trivial case of linear programming. So, in the case of where the polynomial is a product of linear forms. Okay. So, here you have some other pictures: quartic curve on the left, hyperbolic. On the left, hyperbolic, and the quintic curve on the right, still hyperbolic. Any line through the green region crosses the quintic curve only in real points, in exactly five real points. So every hyperbolic con defines one or many convex sets, and so we can make optimization. So if you prefer optimization to algebra, you should probably have this in mind. You have should have You have should have in mind these sort of a hierarchy of optimization problems. So, the first of which is linear programming, which corresponds to polyhedra and looking at hyperbolic polynomials, this corresponds to products of linear forms. Then we know that linear programming can be generalized to symmetric matrices, optimization over the cone of positive semi-definite matrices, which is called semi-definite. Which is called semi-definite programming. And we know that the interesting polynomial here, which is the determinant of the linear matrix, is, as I said, hyperbolic. And more generally, if you want to solve optimization problem over hyperbolicity constants, what you want to solve is what we call a hyperbolic programming problem, which is a very interesting convex optimization problem, which can be solved as happens for a semi-definite. happens for a semi-definite programming in polynomial time. If you work in finite precision arithmetic, there are interior point strategies which have been developed for hyperbolic programming. And now also there are some series of works relating hyperbolicity to non-negative polynomials, so certificate of non-negativity. So it's a very interesting optimization problem. Optimization problem. So, which is called hyperbolic programming, and which generalizes semi-definite programming. So, as I said, the goal of this paper was to have good algorithms for computing such a representation. So, what is a spectrahedral representation? If you have a set, well, the set is called a spectrahedron or set that has a spectrahed representation. If it is, it can be written as a solution. Is uh it can be written as a solution of a linear matrix inequality, maybe a fine or linear, it depends if it's a cone or just a convex set. And so an easy remark, a trivial remark is that if you have the symmetric determinant or more generally, if you have a weakly determinantal polynomial, well, each hyperbolistic cone, so we know that it's a hyperbolic polynomial, its hyperbolic cone is a spectrum, so it has a spectral header representation. A spectral hidden representation, and so, as we have also seen in other talks, so people have been interested in the converse. So, if you are given a polynomial, well, in the converse, in the general problem, so if you are given a polynomial which is hyperbolic in some dimension, in some direction, E, is the hyperbolicity cone a spectrahedron. So, this is maybe the most important question of the. Maybe the most important question of the theory in the theory of hyperbolic polynomials, which is called the last conjecture. So, the generalized last conjecture actually claims that this is true. So, the claims that your given polynomial, so the creblistic cone of a hyperbolic polynomial is always spectrahedral. So, it has always a spectrahedral representation. And let me mention, I don't know if it has been done, I think, yes. I don't know if it has been done. I think yes, actually. But let me mention that this should be seen as a sort of geometrical version of the Lux conjecture, which has also an algebraic version, which is the following one. So you have your given hyperbolic polynomial F in direction E, then there should exist another hyperbolic polynomial, another polynomial which will Another polynomial which will in the end be hyperbolic, G, of some degree, such that the product of the two polynomials is a determinantal polynomial. So this is really weaker than, is even weaker than weakly determinantal. So we are asking that in the ideal generated by your given polynomial, there exists some polynomial which has a determinant representation. And then there is a second condition. A second condition which says essentially that the cone of this multiplier is a sort of relaxation of the cone of the aperiobilistic cone of F. So if we have these two conditions, then what we can see is that we can easily see that the aperiobilistic cone of f is exactly the aperiobilistic cone of these determinants, and thus the aperiobilistic cone of F has a spectral representation. Okay, so this is just to prove. Okay, so this is just to prove that the algebraic statement implies the geometrical one. And actually, these two statements are equivalent. Okay, so in our construction, actually, we are interested in this algebraic statement of the algebraic version of the Lux conjecture. And we would like to construct such spectra representation by constructing a determinanta representation of some multiple of the given polynomial. Some multiple of the given polynomial F. So, this is more or less the idea of our contribution. Okay, so maybe I will drink some water and ask if there are maybe some questions. I don't know. Also, have a look at the chat. I cannot see the chat actually, but if in case there's no, there's nothing in the chat. If there is open, I will let you know. Okay, okay, very good. Thank you. Very good. Thank you. Okay. So let's go to our construction. So, as I said, in my, so the goal will be to represent this green region, the hyperbolistic cone. So F will be the blue curve. And as I already mentioned in the first slide, the extra factor, let's say this multiplier. So the factor that I need in order to get the In order to get the polynomial which has a determinant representation, this factor will also be hyperbolic, will also be hyperbolic with respect to every direction of hyperbolicity of f and it will be the easiest possible hyperbolic polynomial. So it's a product of linear forms. So my goal now is to tell you how to where does these lines come from. From okay, so in order to do that, I have to give you some definitions, which I don't know if they have already been given during the workshop. I will give three definitions. The first one is very classical in the theory of determinant representation. So, is the definition of contact curves? So, if you have a curve, say a parabolic in direction E, in general, if you have any curve actually, you can define contact curves. You can define contact curves as any curve that has intersection, so whose intersection, whose complex intersections with the original curve. So this is H, clearly, it's not G. So whose complex intersection have even multiplicity. So these are contact curves. If we just ask that the real intersections have even multiplicity, we call these real contact curves. Call these real contact curves. Okay, so I will show some picture later of real contact curves. And then there are special real contact curves, which we call interlacers, which have the following property, which are still hyperbolic polynomials. So it's a polynomial H such that if we take the two characteristic polynomials, so the characteristic polynomial of So, the characteristic polynomial of f and h in some direction a, then the roots of these two polynomials as univariate polynomials interlace. So, they alternate exactly, okay, perfectly. So, interlacers are very interesting objects that can be constructed from a given polynomial, for instance, taking a derivatives, as it happens in the univariate case. If you take a univariate real-rooted polynomial, Univariate real-rooted polynomial. You take the derivative. Well, there is only one derivative because it's one univariate problem. So you take a derivative, then your derivative will be again real-rooted polynomial and the roots will interlace. So this is a sort of generalization of derivatives to multivariate, well, yeah, to the interlacing property to the multivariate case. And what do I mean by that? I mean that, well, every interval. mean by that i mean that well every interlace it is a real contact curve every contact curve is a real contact curve and uh in general computing or well determin yeah computing contact curve is hard it's a hard problem in general even deciding whether they they exist for a given for a given curve whereas it will be easier for us to compute interlacers so interlacers so the set of interlacers So, the set of interlacers is a tractable set. And I will give a definition and I will try to convince you that this set is a tractable. So it can be sampled efficiently using, for instance, a semi-definite programming. And this is not the case for general contact curves. Okay, so I will need the definition of interlacer. And so, as I said in the abstract of this talk, the in the abstract of this talk i wanted uh to try to to describe the dixon method which is uh which is a which is a classical uh algorithm for computing determinant representations and so uh it's a little bit technical i don't want to go that much into details but i want to try to give you at least the idea and then i will mostly focus on the variant that we have given with my Given with Mario and Daniel. So I will present the Dixon algorithm in a variant, which is described in a nice paper by Daniel and Sincia about Hermitian determinant representations, but essentially it's the same for my purpose. So the Dixon algorithm, which has been described in a paper in early 20th century by Dixon, 1902, if I'm not wrong. 1902, if I'm not wrong. It's based on a linear algebra argument, which is the following one. So if you take a matrix A and you multiply the matrix by the adjugate matrix, you get a diagonal matrix whose entries are all equal to the determinant of the given matrix. So now if you try to read these in the context of hyperbolic polynomials, well, you know that the determinant is a hyperbolic polynomial, right? So suppose that A. Polynomial, right? So suppose that A is now not a matrix, not a numerical matrix, is a symmetric linear matrix. So determinant of A is a hyperbolic polynomial. And so if you look at this equation modulo, the ideal of the curve, so modulo F equals zero, modulo F, modulo my given polynomial, you will have zero on the right. And so what you will have is that your matrix, which corresponds to a determinant representation and the adjugate matrix, will have. And the adjugate matrix will have, well, we will have, say, a complementary rank, in the sense that the corrupt of the given matrix will be equal to the rank of the adjugate matrix. And it will be equal to one if you look, if you specialize to a point on the curve. If you take a general point on your curve, or if you even allow that your curve is smooth, then if you plug in this point in A, so you will have a. In this point in A, so you will have a rank D minus one matrix A, and so a rank one adjugate matrix. And essentially, this is more or less the main idea of these Dixon methods. The idea of the Dixon method is to construct the adjugate matrix of your representation and then to give in output the adjugate of this matrix, essentially. So in output, you will have exactly the matrix that. Exactly the matrix that whose determinant is equal to F. And the idea is that you start with some good curve, which in the original paper of Dixon was a contact curve and which has been generalized to interlacers in several in some papers, including our paper with Daniel and Mario. So if you start with this contact curve, essentially the idea is that you compute, so what you do. Is that you compute so what you do you have to do is that you have to compute the intersections of your curve with the contact curve and then to work in the vector space of all polynomials that vanish on this intersection essentially. You extend this to a basis and you construct with this basis the first line of your matrix of your adjugate matrix and then you use the fact that the adjugate matrix has rank one over the curve so when evaluated on So, when evaluated on a point of the curve, which means that all the two by two minors should vanish because this is equivalent to being rank one. And so using this and Max Nethert theorem and etc., you can essentially construct this adjugate matrix. So, I didn't want to go to details, but this is essentially the idea of the general classical Dixon method. Dixon method. Okay, so the output will be the linear matrix satisfying this equation, so such that f is equal to the determinant. Okay, and but as I said, in input you need somehow a counter curve, at least for classical Dixon method. And whereas, well, computing this curve is hard in general. And on the other hand, computing or On the other hand, computing or pre-computing an interlacer is easier. And this is given by the fact that the set of interlacers, so if you fix your curve and you fix a hyperbolic direction E, and you look at the set of all interlacers, so it's a set of polynomials in the vector space of degree D minus one, in the vector space of polynomials of degree D minus one. If you take all polynomials that interlace F in direction E, then this is a convex set. Then this is a convex set, it's a cone, and it has a nicer representation. It's a section of the cone of positive polynomials in some degree. And which means that in particular, if you want to compute interlacers, you can use well, let's say some of squares relaxations, for instance. You can relax this non-negativity constraint to sums of squares. You can ask. To some squares. You can ask that what is called the Wronskian of the polynomial F with the interlacer is not non-negative but something stronger, so a sum of squares, and so you will have sort of a semi-definite condition and you can compute an interlacer. So I will show an example in the end where we actually compute an interlacer and I will give also the output of the, let's say, of the algorithm. Of the, let's say, of the algorithm. Okay, so our idea: the idea is that instead of looking of using countercurve, which are hard to compute, we want to use interlacers. And let me tell you first what is the main result of the paper so that then I can comment on it. So, the main result is the following: you start with a polynomial, so hyperbolic curve, so in three variables, homogeneous polynomial of degree D in three variables, which is Of degree D in three variables, which is hyperbolic with respect to E, and you have also the you know an interlacer. You suppose that you have computed this interlacer using maybe a sum of squares relaxations of the set of interlacers, etc. So you have this interlacer. You define the following linear forms. So you know that the interlacer is a real contact curve, which means that the real intersections with the curve are. With the curve are of even multiplicity, but possibly the complex intersection are not of even multiplicity. They could be really normal closing. So if you look at the complex and non-real intersection, they could be normal closing. And so you take the line joining the pairs of complex intersections. Okay, so you will have real lines if you take. If you take the complex intersections of f and h, these are organized in pairs of vectors and conjugate pairs. And the line joining this pair is a real line. And so this is how we define the lines L1, LC. And then this, so the main theorem of our paper says the following: so that there exist matrices of some size. Matrices of some size. So the size is, let's say, quadratic on the degree of the input polynomial. But there is also this minus r, which is the number of... Okay, I didn't write what is R. R is the number of real intersections. So you have C is the number of pairs of complex intersections and R is the number of real intersections which are double. Intersections which are double, okay, number of real intersections of F with the interlacer. So the sides of these three metrics will be exactly this number, quadratic in D, and there is a minus R component here, such that, well, the hyperluistic con of F has the spectrahedal representation given by these three symmetric matrices, and also F times this extra factor has Extra factor has a determinant representation. Okay, so this is the representation one would like to have in the generalized Lux conjecture for every hyperbolic polynomial. So what we could prove is that for curves, such a representation exists. Even though for curves, we also know that the Helton-Binnikov theorem tells us that F is already a determinantal representation. But in order to compute such determinant representation, you would need Determinant representation: you would need in principle, you would need contact curves. So, this is a sort of a method which gives in output a weaker result because we have a determinant representation of a multiple of f, but which is easier somehow. So, the algorithm is easier because we just need an interlacer. And we have some okay, we have some genericity assumptions. Okay, we have some genericity assumptions on H, not on G, sorry, so on the interlacer, which are the following. So there are very, well, let's say generic assumptions, genericity assumptions in the sense of algebraic geometry. So you have that you want that three intersection points of F with the interlacer do not lie on the same line, or that three lines are not crossing in the same point, etc. So this kind of Same point, etc. So, this kind of genericity assumptions. Okay, so we have some assumptions, we have this kind of genericity assumption, but under these assumptions, we have this nice representation. So, the main point is that this factor essentially, let's say, that corrects the failure of the given interlacer to be a Given interlacer to be a contact curve. If you think about this interlacer for one moment, so your interlacer will be a real contact curve, which means that the real intersections will be double or even multiplicity, but the complex intersection will not be even multiplicity. So if you add the line crossing this complex intersection, essentially you add multiplicity and you let this intersection be of even multiplicity. Of even multiplicity, you correct the fact that the failure of H to be a contact curve, and yeah, this is let's say the main point, geometrically speaking. Okay, this is why we have to add these lines. And there are some positive aspects that I want to highlight in the last part of the talk. Talk. Well, the first good aspect is that the multiplier is the simplest that we can imagine because it's a product of linear forms. How? And also, we know how to describe, how to define this, how to construct these linear forms. They come from the complex intersection of the curve with the given interlacer. Also, we have a link between the size of these representations, so the size of the matrix, and the number of real. And the number of real intersections. So, in principle, if someone gives me a good interlacer in the sense that an interlacer with the maximal number of real intersections, then I have a good spectral header representation. I have a spectral header representation with the minimal size somehow. So, the size of this representation in our construction depends on the well, depends, let's say, monotonically decreasing on. Monotonically decreasing on the number of real intersections of the curve with the interlacer. And then for maximal R, as I was saying, we come back to the Helton-Winnick of representation, which means we come back to the representation of F as a determinant. So maximizing this parameter, this number R, means minimizing the size of the representation and means that somehow your interlacer That somehow your interlacer should be special, should be an extremal interlacer. So now I want to just give a definition what is an extremal interlacer. So let me make up. I have these results that say that if I have an interlacer with R intersections, with R real intersections. What with our real intersections with the hyperbolic curve, then I can construct, I can somehow compute. There exists a spectral representation of sides, the square plus d over two minus this number. And so the question is, how many? Yeah. Can I ask you two questions regarding the pre one? Is Papri asked, she's wondering if you can please say some words how to find such a contact curve. And I have another question. And I have another question. Is you say you take lines through the complex intersection points, but you cannot compute them. It's not algorithmic to compute them. How do you get that without computing the intersections? Yeah, I mean, I'm not, yeah, sure. I'm not claiming it's how to say, efficient. Yes, you should, at some point, using Dixon methods or its variance, you should pass through. You should pass through this problem. You should compute the intersection of two curves. Yeah, that's clear. You mean that this is algorithmic? I mean, I mean that using this approach, you cannot avoid this step. You cannot, yeah. You have to work in the yeah, in the let's say in the Let's say in the yeah, you have to work in even clearly in some extension of the rationals, but which comes from the yeah, from the intersection of these of these two curves, actually. Yeah. Anyway, the result is nice. So Papri asked whether you can, let me read it again, you can please say some words how to find such a contact curve, she said. Then the yeah, the interlacer. So, yeah, so the the idea is that, so how to find um well, once you have once you have your polynomial F in your direction E, then you can take the Bronskian of your, well, this is a, so H clearly is unknown, right? So you have. Is unknown, right? So you have a polynomial of degree d minus one whose coefficients are unknown. So you want that the Wronskian of this polynomial is positive. So instead of asking that the polynomial is positive, you ask that the polynomial is a sum of squares, which means computing, yeah, solving a semi-definite feasibility problem of a semi-definite program. So the question that you ask is a good question in the sense that. Is a good question in the sense that it depends what is your computational model or complexity model. If you want to, yeah, in exact arithmetic is a very hard problem, but in finite precision arithmetic, it can be computed efficiently. I will show an example of one example where. Yeah, I will show an example. Thank you. Please go on. Thank you. Yeah. Thank you. Yeah, thanks. Yeah, so this was just to say that interlacers with many real intersections with the given curve should correspond to extremal points of the set of interlacers. So the set of interlacers, as I said, this has been proved by Mario and Cynthia and Daniel. It's a cone and it has a semi-definite, well, it's a section of the. The section of the PSD of the set of positive polynomials in some degree. And so it's a cone, it will have some extreme points. So we wanted to know what's the number of real intersections for an extremal interlace. An extremal interlace will be an extreme point of this cone, and counting with a simple count of dimension, essentially, we have this. Dimension essentially, we have this lower bound on the number of intersections. Okay, so if you take an extremal interlace, so an extreme point of the cone of interlacers, then your interlacer will have at least this number, which is this number of real intersections. Okay, so here you have a table which gives you this number with respect to the Belzo number. So what you have in So, what you have in the last row, you have the Bezou bound. So, this is the maximal number of real inter well of complex intersections. So, in particular, the maximum number of real intersection. And this is exactly this number here. So, let me remark that for quartics, for instance, we have, yeah, we don't have, yeah, there is a gap here. So, we don't know, we still don't know for quartics. Let me show you some picture. We still don't know. Let me show you some pictures. We still don't know if there exists, at least at my knowledge. Maybe someone here knows the answer, but at that time, we didn't know if every hyperbolic vertic admits an interlacer with six real intersections. So since this is a workshop on counting real solutions, I thought that this could be a good question. So the question is: you have a hyperbolic quartic and you want to. quartic and you want to uh comp you want to you want a um a cubic uh cubic interlacer having exactly six uh real intersection six times two makes 12 which is the bezo bound so there cannot be more than six intersections and here you have some pictures we could we can say that okay in the case when the outer oval is non-convex there is uh there already exists there is there already exists such a cubic but if if it's not convex if it's convex sorry the outer oval is convex we have some problems okay so yeah this is an open question find an interlacer with the six real intersections for quartics and so let me just finish with two examples so one is an example of a cubic which is well this a cubic which is hyperbolic A cubic which is hyperbolic with respect to 100. It's this blue curve, and so the hyperbolic cone is the green region. And here you see two interlacers, well, three interlacers actually. So the green one are I computed these using using Spectra, which is a Maple library that I had developed when I was a PhD student, but I PhD student, and but I mean, I'm not claiming is the most efficient way of solving this problem, but uh, just to reply to Papri that there are, yeah, I mean, there are methods for solving SDP in exact arithmetic, but they are very costly, right? So, you cannot solve large-scale optimization problems using exact algorithms, using Grubner basics, etc. But in this case, I had I think a six by six linear matrix and By six linear matrix, and I could solve this. I could compute in exact arithmetic these two interlacers, and then I could find a rational interlacer inside. And these, using these and our construction, you can compute the determinant representation of these polynomials. It's not of f, but f times a line, which is this line. And this yields the spectrahida representation of the The spectrahida representation of the green region. If you take all points where this matrix is PSD, it's exactly the green region. And then let me just finish with a second example concerning rational representations because we also have these rationality results. So if you start with a rational, well, so start with a hyperbolic curve with rational coefficients, you would like to have a rational certificate of hyperbolicity, let's say. I would like to prove that the polynomial is hyperbolic. Prove that the polynomial is hyperbolic by computing a matrix with rational coefficients, okay? Which is not always possible if you ask determinant representations, but which is possible if you ask just spectraheda representations. And here's an example of a cubic which doesn't have, so this cubic is hyperbolic, so by Halton Vinic it's a determinant, has a determinant. It's a determinant, has a determinant representation, but it doesn't have a rational determinant representation. But his hyperbolistic cone has a rational spectrahed representation exactly because some multiple of this polynomial has a rational determinantal representation. So yeah, so this was another interesting result of rationality, which is very natural, I think, in this algebraic setting. Yeah, so thank you very much. So, I want just to say that this is the paper I was talking about, and there are many paper, many related papers, just choose a couple of these papers. So, thank you again for the invitation. Thanks to you. Papri says that your answer was cool. Okay, are there any questions, remarks? So optimally to get the Helton-Vinnikov type presentation, you would have to find a maximal error on the number of real intersection points. So do you have any strategies to maximize them in practice that work or some heuristics? What worked for Quartics is Is a very easy argument when the outer oval is non-convex, and the argument is that this is what I wanted to try to show with these pictures, which are not that clear maybe, but okay, take this quartic, which is the typical hyperbolic quartic with the with non-convex outer oval. Well, I mean, non-convex outer oval. I mean, the ovals are not convex. I mean, the inner oval is. I mean, the inner oval is the boundary of a convex set, the outer oval is the boundary of a non-convex set. And in this case, you can always find an ellipse which touches in four points. And then you just add a bitangent which exists. And so you have a sort of reducible cubic interlacer, right? If you now add a Now, add a real by tangent which exists because you have a non-convex outer oval. Then you have your interlacer. So you can construct it. But in this case, for instance, you don't have. So you cannot use this argument of the bitangent, but we could somehow find for this example, maybe you can see just five intersections. Just five intersections, but this one is of multiplicity four, actually. So this is also a good interlacer. It's not a counterexample, so it's a good interlacer. So it's an interlacer which has six, well, let's say 12 real intersections counting multiplicity. It's four plus plus two plus two plus two plus two. Yeah, so it's uh so we don't I think we don't have a counter, I think we don't have. Counter. I think we don't have examples of quartic curves without good interlaces in this, I mean, good in this sense. But I don't know. Yeah, we don't know. You see, this gap clearly becomes larger and larger. We don't expect, I don't expect that we can. I don't know. Actually, I don't know what I should expect. This is a question for people. Expect this is a question for people studying topology of real curves and real solutions of polynomial systems. Thank you. Thanks.