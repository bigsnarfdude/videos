Organizers, for inviting me to speak. I hope to give a rather general overview of the things I've been interested in for a few years now. Tropical geometry and non-Archimedean geometry play a prominent role and I hope to convince you there are some intriguing connections, maybe even compelling connections that we might have looked at. Since the word kind of is not necessarily Not necessarily used by all algebraic geometers. I can tell you what is our cell of geometry in like one minute. What compels us to look at sort of the type of question that we look at? Maybe you have some equation with integer coefficients. You might want Coefficients. You might want to think of this as a variety which sits over spec z. And you might want to do algebraic geometry relative to this morphism, and then you immediately have a problem. It's very natural that you might, maybe you have a line bundle, as I will have, very soon here, and you want to pull it back here. And then if you have a bunch of line bundles, you might want to complete degrees, you might want to do intersection theory, and there you go, you immediately get. So it immediately gets into trouble because this is not. So you would like to think of this like a one-parameter family of a curve. And you want to think of this as a curve. And this is not a proper curve in any good sense. So you cannot do degree intersection theory, things like that. Intersection theory, things like that. And the solution is: so that's one problem. I'll talk about the second problem, which is not super important for my talk. You solve that by compacting other things. Well, how do you do that? It was a brilliant idea of Archelov that spec Z is the generic point zero and prime numbers two, three, as per set. Two, three, a set of points. But then number theorists would say, well, there's a place at infinity. Any prime gives you an equivalence class of absolute value called places. And then there is an obvious absolute value which doesn't count on the prime, the absolute value that we are all used to, so-called infinite prime. So you compactify this by sort of the solution is you should put Archimedean data here, and then anything that happens upstairs. And then anything that happens upstairs, you should maybe if you have a maybe you should also look at the C points of your original variety, and then you have to have more analytic data attached to it. So it's a kind of a combination of arithmetic or algebraic geometry and analysis. In a way, analysis becomes the generate number. Number three. So that's Oracle of Geometry. The second issue that I don't it doesn't Issue that I don't, it doesn't appear prominent in my talk, but classically, if you have maybe a family over a curve, nice curve, and you have some invariance over x, then this curve is defined over some field, so you have another morphism to spec k. And you can sort of push everything down here if you have some object up there. Down here, if you have some object up there, you can look at vector spaces over k. And you don't have anything down here. That's another issue that I don't concern myself at this talk. But that's sort of the source of some of this F1 geometry, at least from the R-Kell point of view. People might want to think there is something down here, spec of F1, and whatever that is, it's above or beyond me to talk about. Anyway, so that's our sort of geometry. That's our kind of geometry. And there is, so I'm not going to teach you RTO geometry, but there is a fix, and you will have intersection theory and you will have a degree. But it's non-trivial, extremely difficult. Moving demos don't exist. You have to actually work hard. People have done that to some extent, and there are lots of other problems. And my talk will mostly be related to the kind of things that we as a community can help. Maybe you can hold the other. Maybe you can go beyond that. So let me start by my actual talk. I'm going to, as a motivation, since we already saw some heights, I'm going to start with heights, our type of heights of abelian varieties. I know that this is a conference on curves. I will talk about Jacobians afterwards. So I'm going to work with over another field. You're welcome to just think of Q and then immediately say everything, pretty much everything I say as a function field analog. I might even say a few things. And then I have a And then I have a principally polarized abedian variety, principally polarized abelian variety over k of dimension g. And if you don't exactly think about these things, you're welcome to think of g equal to one case and elliptic curves. Already, actually, some of the things I will say are interesting. Some of the things I will say are interesting probability curves as well. And then there are two heights notions of complexities. So think of this as complexity attached to A. I'm not very much concerned about points of A as it was described in the of A as it was described in the previous talk, I'm mostly concerned about K. So think of this as an element of a moduli space and I want to know how complicated of an element is this. The first one is that's called stable faulting site. I'm going to probably just drop the word stable. This was introduced in the work on faultings and Odill conjecture, which was mentioned in the previous talk. Mentioned in the previous talk. I'll say a few words how this is defined. And the second one is neuron height height. It's the same name you saw proving the canonical height result in the previous star. But let me. There's a distinction. So, what is faulting site? I just want to. So, we are in a conference that we don't define many things, but I felt like this is far enough from what people are comfortable with that it's good to have some feeling about what kind of animals I'm talking about. So I'm going to look at the neuron model, which is sort of the nicest possible model as a group scheme. As a group scheme, you can write over the ring of integers. I guess you can think of this as push forward of A. And this has a zero section, because obedient variety has zero. That's a boom. And I'm going to look at, so faulting side doesn't actually use the lambda, it doesn't use the polarization. Polarization. What I'm going to do, I'm going to look at what notation I will use. A sheaf of relative differentials of this morphism. And I'm lying a little bit, but please don't catch me right now. And then I pull, so this is a line bundle here. I pull it back along this zero section. You mean it, the terminal? Yes, so this is the terminal. So this is the terminal with an opportunity. I call this omega, which is some line bundle here. And then I want to take the degree, and I warned you that you should be worried about this, but it's been solved. There is a degree of this line bundle. So this is a line bundle, and you can take the degree. So a little bit I cheated. I want the stable one, so I first have to base change to make sure I have some neobedium deduction. Let's sweep all those things under the row. Let's sweep all all those things under the rug, and there is some kind of a normalization I have to worry about. All I want you to remember is that there is some degree, a televis degree, so I put a hat there, which gives me the 14 size. I then use down. Okay? So height equals degree for that. And there is another one there on faith height, which is intersection number. And degrees are intersection numbers. Numbers. Maybe I'll write that down as well. And the same thing that many speakers have said, please feel free to ask questions. Yes, of course. Let me finish that. There are some tangential directions that I'm not going to answer. Just to explain what. Um so so the the RK log input there is just that once I have a line bundle on spec okay, I can attach a rational number to it. I can attach a rational number to this? So, this thing has canonical Hermitian, there is a Hermitian product on the Archimedean side, with some integral of some something times x something. That's the Hermitian input, the R tel of input. And that will come into the computing degree. Degree is some kind of intersection a classical kind of degree intersection theory plus some Greens function coming from some permission data. So the this thing is not actually an integer necessarily, there is some analytic new picture. There is some analytic input. So the input is some Hermitian, usually the metric on some line model. In this case, there is something that I think actually Arkhalov himself defined, but Fault insert can be right. So it's in order to do this, I need a line bundle with some extra structure. Yes, yes. And the line bundle, I told you what it is, it's determinant of the. And then there is a metric that I didn't tell you, it's hidden in this hat. In this hat. So it's not necessarily rational. It's not rational. I mean, not necessarily rational, but it turns out it will be rational. The stuff that I'm describing. But in general, it doesn't have rational. Degrees non-directional. So for neuron tates, what we saw in the previous talk was neuron tate height as a point. You can think of it like a zero cycle, but it can be extended to higher dimensional cycles. And I want to do Cycles. And I want to do neuron tethytes, not have a point, but rather a nice tail divisor. So, what I'm going to do is let me call this HF and this H in T of theodron. And what is this theta? So I have a principle of polarization. You can think of this principle of polarization as a line bundle with one dimensional space of polarization. A line bundle with one dimensional space of global sections. And that has a divisor, or many divisors, in fact. And you can pick a divisor which is symmetric and effective. Of course, you have to make some choice of a two-torn. It turns out what I'm going to describe is not going to depend on the choices. Then you do you enrich this line bundle as it was already worked on a signal. We were concerned with by putting metrics at every place. This is a canonical metric. There is some metric related to this quadratic expression that Madma mentioned. It's a canonical metric you can put at every place. And then the neurotate height of theta is some intersection number, some lower. Number, some normalization factor, g times g factorial, and then you have an intersection number, or a field of intersection number, which is you have this enriched line bundles, you intersect them with themselves, I think, g times with respect to zero. And again, you have to be worried about can I do this kind of intersection and you can't do this. Possibly this is the question I should ask, but like lambda doesn't determine L, where it's just. But like lambda doesn't determine L versus torso, but it doesn't matter which one I choose. No, it doesn't matter on the choice. In fact, yeah. Let me, for this audience, at least the part of the audience that is okay with record spaces, say that if you understand some of the work of Chamberlain Chamberlain and Juliet. So this is a longer line. This is one name. And some computations of Googler. We can actually give a formula for this neuron plate height, which probably is incomprehensible, in terms of very concrete integrals over analytic spaces. This is some, again, some normalization factor, but we need not worry about that. It's some integral over all places. And place if you All places, and place if you're over Z, you can think of like all time numbers and infinity. Of some integral, identification of A, so if B is the Arc-median place, this is just some complex for us, otherwise it's the Berkeley space. And you take some log norm of S, norm that I have fixed, V mu. Mu is the Mont Jamber measure, or Chamber-Law measure. Or a Chamber-Long measure, and in the case of Archimedean, it's just the hard measure and the complex box. All I want you to remember is that there will be some summation formula in terms of some logarithm of something. The word means function is also related to this. Yes, please. Yes. All but the final of any of these terms we're not sure or not. Of course. And it doesn't depend on the choice of the global section S that I pick. And the question that I want to answer, one of the questions I want to bring up is, is there a relationship between 1 and 2? And also, how does that relationship look for Jacobians? So these are two chapters. So, these are two notions of complexity. Are they related or not? People have thought about it, and we provide an answer which has a lot to do with child code geometry. Any questions? I'm going to erase this definition because it's all I want you to for now remember is that there is some summation from that for neural categories. Or there are data. Okay, now coming back to down to Earth, some analytic invariants. And these analytic invariants really are, as you can see in the non-Commended situation, are trot involved. An Arcimenian situation are trouble. Let me start with the anarchomenian version. For that, let me go down to combinatorics. I have a lattice. This is the lattice. I don't mean a posted lattice, I just mean old-fashioned lattice, together with a bilinear form. Together with a bilinear form, field values, symmetric, and positive elements. You're welcome to think of your favorite lattice in C2 or maybe more generically a triangular lattice in R2. And I have the ambient vector space. ambient vector space. Read it this way. For this lattice it will be the or and I'm going to define a function which I suggestively will call theta. It has nothing to do with the theta of Jonathan or this is old-fashioned theta in some sense from the vector space from the word real numbers which does Numbers, which does the following. You give me a point from the vector space. I'm going to find the closest lattice point, minimum of z minus lambda, z minus lambda. This is square of the norm induced by the bilinear form for all lattice points. So if you give me a point here, I'm going to record the square of the distance. Where the distance to the closest starts. Are you taking a minimum of twice the same thing? What about minimum? Well, you have C minus of and C minus. Just the inner product. Is there a mistake or? No. This is the if you like the tropical theta. I don't wanna use norm is yeah. This is not tropical theta, this is tropical normalized theta. Tropical normal x theta. It's related to theta too. But it's actually the next thing here you will see why not. This descends, this sentence will to the quotients. And theta is not supposed to be a function on the space, it's supposed to be this function on the universal colour. I'll say something about what's the analog answer. So you're saying this descends to a function or a section? To function, because if you give me a translate, just you remember that blue was bad, what that? You subtract some linear curves. If you give me another point, which is a translation, the closest distance doesn't change to the lambda. So it's a periodic function with respect to lambda. So it's a use of notation, I'll use the same thing. Now you have a function, you have a torus, integrated. So I'm going to define my first article of invariance to be I of st theta. We are calling lambda together with the right. Together with the bilinear form, to be the integral of this function against the Hohr measure over the torus. And you can actually think of this very concretely in terms of Boronian decomposition and even more combinatory, but I hope this is okay. Hard measure is only determined up to a scaling. I'm going to normalize it to half. I'm going to normalize it to how power. So mean power, this is power. Mu power of the whole torus is normalized to the power. And I'm going to call this in the future tropical moment, or moment at the number 16. And as I said, there is an interpretation in terms of Boronoid composition, which I am happy to discuss later, but you can probably see in a few seconds. See in a few seconds, but if you have more in the compositions, is this clear? Can you say something about what kind of function this is? Presumably, it's not harmonic. It's a quadratic convex function above. I'm going to talk about Voronoi after all. So, this function is some kind of a piecewise quadratic function, and I'm just taking the Integral of that over the volume. It's not piecewise energy. It's closely related to tropical theta function. You can actually, if you expand this and remove the term z times z, the quadratic part, you get the tropical theta function. It's a trick to make, it's a useful trick, basically with reason, but you want to have a function on the torus, not on the universal colour. In fact, this is a trick that was done by Faulkner. And in fact, this is a trick that was done by Faultings. That's the next thing. Not in the non-Arcania situation, but in Arcaninian situation. So Faultings wrote a paper called Calculus on Irmatic Surfaces a few months before he solved the Mordell conjecture. And he has a lot of really interesting stuff over C. There exists a unique C infinity function. A unique C infinity function, smooth function. I'm going to call it again theta. For some reason I put a square there. From C point to BL. Such that EBC, or read this as Laplacian. So A is C to the G modulo modulo lattice. It's a complex source. This is another thing. It's a complex force. This is analytic. DDC of logarithm of this function is something predictable by mu minus this might look a little bit annoying. I'm using measures on the right side. Really, I want to think of my Laplacian as a measure-valued operator. There's an analysis to that. You really want to think of this as sort of what happens when you integrate against functions. And this means that this is so-called current of integration. It means that the integral of a function against this measure is just the integral of a theta. And theta is the theta divisor. V-mount theta divisor. The zero locus of the L-mount theta function. And then there is a normalization we can find in Birken-Haq and Land. We can find in Birken, Hawke, and Lang a computation that suggests if you integrate against against R measure again to the minus g of So what is the new? So this is the one one form the translation invariant one one form on the universal cover but that's very Universal cover that I should have written this, thank you. Euclidean one model. Is that if I say canonical, then I haven't really answered your question. Euclidean one model. Think of dz, dz bar, dzi, sum of dzi, dzi bar, and then some pi over two or something. But it's actually, okay, I don't want to write an expression. If you have seen Wiemann's data function, Riemann's theta function in terms of some infinite sum. Theta function is not periodic, it has a factor of odomorphy. So you write theta of z plus lambda is equal to some factor of odomorphy depending on z and lambda times theta. And you look at the factor of odomorphy and you sort of factor the right thing to the left-hand side so that you get a function which is actually periodic. So you sort of force your Riemann settle function to make sense on the base. To make sense on the base, on the albedian variety itself. There will be a formula that I don't write because it just takes time. But that's the funny norm of theta function. And then there is a definition, I of A theta. Now it's Archimedean stuff, which looks a lot like my previous definition. Because I have tropicalized, I probably should have a log, and then I have this theta squared. Squared R, the same normalization, and I integrate over the entire complex tool. And this is the definition due to post. Henry, unfortunately, I believe these were not in published work. Articilla has a paper in Compositio that writes this and investigates some of the problems. Some of the problems. So, this is, I don't think they use this terminology, but I want to call it Archimedean moments. And for the experts, there are some, depending on normalization, you might want to add some something there, logarithm of two or something, depending on how you normal this thing. But I'm going to not do that. Okay, so these are our Kelloff invariants, Archimedean, non-Archimedean, and I can now write a theorem. I can now write a theorem, my first theorem. This is the drawing negligent. Sorry, so A is here a complex ability, right? A is, yes, this notation is really C points together with analytic topology. So this is C G not. I hope Manta is okay. Because we have an A defined number field or an alpha. Correct. Correct. So it did uh yes, yes. And you can base change to complex numbers. All right. Now the publication here for this, I believe, is 2022, but the paper has been unarchive longer. Which we answer this first question I'll post. What is vaulting height? Well, it's supposed to be in the rotate height. There should be some normalization, that's not a big deal. But it's not equal, and the difference comes from something about the base field. Essentially, I want to say the difference comes from these moments. The difference between the two is I have to say what analysis is here. I have to say what the latest is here, but these are real where all places, but annoyingly I have to separate finite and infinite places. I have to do finite first. And then I have to have a log term to size up the residue field. Don't get distracted with that. Like if I was, if k was q, I have to put that t here for any pipe. And then there is a contribution, let's put it with parentheses, from non-Archimedean prime, sorry, from Archimedean primes, infinity in the case of Q, which is just like is it minimal? Is there any way of viewing that as like a push-forward or a degree? I'll talk about it. As you can imagine, this problem has been around for a long time and there are data history. I have to say something which also relates to what Eric is asked to. Let me say. Let me say, over function fields, the same thing holds. Over function fields, you don't worry about infinite primes. Finite primes are closed points. So you have faulting height will be just degree. You don't need RKL of degree. The only theta height is just the intersection number. And then this summation is going to be over close points. Essentially, the same proof we have. I think we only make. We have. I think we only make a remark in the paper. And the way that we prove it is by doing analysis on berkeley spaces. So there are terms in our colour of geometry, Green's functions, various things that people have looked at, and we use analysis on berculi spaces to interpret what's happening. And then we show that certain things can be computed using integrals on non-Reclaimed spaces. But I think that's not clear. One thing that's not clear, so what is I of AB lambda V? Well, so if V is finite, for infinite cases, I've already answered it. Well, there is a uniformization theory for working spaces, where you look at you complete your number field at the place. At the place V using the V addict absolute value, and then you look at as you break closure of that, then you have to complete it again because it might not be complete, and that means you stop. You call it C V, the analog of C. And then you have a abelian ride over C V and identification, so this is over C V. An identification of that has a As a uniformization theory, there is something that replaces C to the G. There's a beautiful story here with Reynolds and written down by Push and Dothken Bohmer. I'm using, and then your polarization here will give you a bilinear form here. So you have a lattice, you have a bilinear form, and I told you how to compute moments of lattices with bilinear forms. For this, I should put the P here. And then this is I of L Okay, it's a theorem clear, and the proof again is not what And the proof again is not what Eric suggested. We do not do. Okay, that's ongoing work and we have theorems. But let me switch to the history of this problem. Very brief history. I mean, this is a well-studied problem, but if g is equal to 1, neural take height is 0. Theta is a two-torn point, and if you know anything about heights, heights are torsion points. Heights, heights of torture points. This goes away. You can compute these things very easily. Whenever you have a, by the way, this is a finite sum. This moment of a, if your lattice is a point, you don't have a moment, you get zero. And you get non-zero numbers exactly when you have a bad reduction, meaning that you have a non-zero stealth in the vector space. So this is a finite sum. For elliptic curves, whenever you have a bad reduction, you get a cycle. And computing moment of a cycle is super easy. Of a cycle is super easy. And then there is some Archimedean computation. And if you do that, you get exactly what Faulting did in his original paper, and silver man. So it's called Faulting-Silver Manifold for HF. In that formula, there is no nailing tate, but I told you it shouldn't be because it's zero now. And if you have seen farthings like that, that's the only formula that's sort of. Things like that's the only formula that sort of people like that. For function fields, if you have good reduction everywhere, there is a problem whenever you have a bad reduction, you have these funny things coming from perkball spaces you have to worry about. But people haven't looked at perkball spaces. But you can wonder how a good reduction case Well, the formula says faulting height of A is 2G neuron tate height. And that's weird. Neuron tate height depended on the choice of polarization. Balthings I didn't depend on the choice of polarization. And this would remind algebraic geometers of some kind of a Riemann rock phenomenon. Kind of a Riemann rock phenomenon, something that's supposed to be complicated turned out to be easier than you thought. Some dependence, like in the case of, anyway, two things are equal, and in this case you can actually prove this using protein degree monitor. Or better, there is a formula claim or key formula of Love Day. Is it L R L Y? Two L's. Two L's. You can actually prove this by computing. So there is some isomorphism of line bundles that explains this. You take the degree and you get this over function field. Already over number field, the theorem is more complicated because then even though even if you have good reduction, this Merkovich stuff goes away, but you still have things in place. Goes away, but you still have things in place, and you still have this. And that's a theorem that was proved by John Benoit-Host, Mark Henry, and others here. In the same situation I described before. I think the Henry and Bost's work were sort of reports and unpublished, but as he writes it in his compository paper. Number field and good reduction. This is the work of host, separate Henry and L C I hope that's double S right. Correct me if I'm still wrong. And then there are a bunch of inequalities. Let me not write names. But you can show, for example, named theta is positive. That gives you a lower bound. This is also positive. This is also positive. And for example, say h f of a is positive. HF of A is possible. And that was a theorem. Or you can progressively enhance that, and they were all theorems, different theorems. So they all come from, this explains all those things. And I'm going to stop with the history because I want to move to, there is more history, but our work completes a line of work that has happened before. I guess our contribution was to look at reference spaces. So how geometry helps. Remember over there? What's it easier to say what the one bundle is? Which mind bundle? You said that this comes short. Oh, this? It's easy, but I don't want to do it. I'll actually load it here. But it takes some time. I'll have to talk and see. Other questions? Okay, now let's. Okay, now let's talk about Jacobians. What I'm going to do for Jacobians to tell you how to, so Jacobians will have graphs whenever you have bad reduction, and I'm going to tell you how to compute these contributions using graph theory, using actually electrical networks. So faulting's height can be computed using electrical, or has contributions coming from electrical networks. That's a problem in this room because sometimes the electrical height. And I was an electrical engineer before becoming a mathematician, so this is particularly satisfying when you apply applied math to it's like an evolution, the child applied very quickly. The story is that you have I'm notification of X at that C V. This thing has its Jacobian, or J n. And it's known that skeleton of Berkeley spaces, this is, let's say, unit of Arcadia. And I'm looking at the identification at V over C V. It's well known that there is a graph, metric graph. So metric graph, you don't know the definition of graph, but metric graph is whatever you think the graph is, but every point is accessible. You don't have vertices and edges, you have just points. All points are created equal. And then there's a notion of the shortest path on that graph. And then this thing also has some torus which turns out to be a very important point. Which turns out that you can actually describe directly by combinatorics using chip firing or otherwise. And so this can also be described. Everything in this diagram is well understood. What I want to say is, can, so the question is, can we compute I of Jacobian, which comes to the Jacobian, which comes to the principal polarization. So I will even drop that, canonical principle polarization in terms of combined works, in terms of graph theory, or more precisely, electrical networks. So I'm going to think of my graph as being made out of wires, copper wires. The longer a wire is, the more resistance it is. Well B so let's this is something like my skeleton of the perfect space. So this is my gamma. Think of this kind of object and these are resistances or wires and there is something called a resistance function. There exists a function r you give me two points And I can compute, I can give me two points, I can get a all-meter, put it there, and then compute what's the effective resistance between the two. We have done this kind of things in high school practice outside of physics. If I give you like x and y, I would say r of x. R of x, y, its inverse as the parallel rule. Right? And serious law. But you can do it for all points. There exists such a function, extension of the function from the finite graph to the parametric graph. Now I want to say what the I is. I need some a little bit more than your high school Kirchhoff laws. It's capacity theory on graphs to flow. So for any measure, any new measure of total mass one, with this is just a normalization because I want to on nothing probability measure. This measure can be negative, and in fact it won't be for my application. On gamma, you compute energy of the measure to be measure to be double integral effective the distance between the two points according to this measure and for some historical reason I to the one half don't worry about that effective resistance is a distance function so it's not the original shortest path distance function but it's a distance and I'm saying sum of mutual distances. Mutual distances. And there is a theorem, essentially, due to Schinberg and Randy, both arithmetic geometer, and Chopu-Jern, arithmetic geometer, that says there is just a unique nu, maximizing, maximize or minimize. I think I wrote maximize, but I'm a little bit yeah maximize. Maximizing This thing. What are we talking about? Forget about graphs. Take a piece of metal and put electric charges on it. And of course, I'm putting the same type of electric charge, but in this situation, logarithm of positive things can be negative. I'm doing tropical geometry. I allow negative charge. Charges of the same type contact each other, they repel, and when things set up, you will have. And when things settle, you will have all these charges going probably to the boundary. And what do they do physically? They want to maximize their mutual distances, total of mutual distances. And that's a way of measuring the complexity of a piece of metal inside R2, or complex plane, just capacity of the set. And I'm computing the capacity of a graph with respect to a very Very interesting internal of integration. So, this max, I'm going to define the maximum to be tau of the r think of it as a capacity object. And it can be completed very completely. We have formulas in terms of combinatorics and Laplacian matrices and things like that, which I both write. But let me also add. Right, but let me also advertise this morning there is a paper by my former postdoc, myself, and Chenji Wu. That actually, if you like this kind of stuff and you wonder why didn't you see this before, and the case of finite graphs, give analogs of this and give some applications to something always care about. So, finite finite analog. Unarchive today. It helped that I was away from my children to do the final touches to automatically pick it up. This is with Richmond, the former postdoc and Chengji Wu and myself. One remark. One remark, which I will come back to, is that we did. Okay, let me write a clear up. In fact, maybe let me do that in a market. Not only in this new paper we make connections to what probability theorists care about, there's also a relation to some matri inequalities. Some matroid inequalities that I know many people, like Mason's conjecture, things like that, we give some bounds on things that people look at. Also, connections completely irrelevant to my talk, you see. But nature is in a balance. But let me say the theorem I intended, this is also a bit beyond. I intend that this is also the beyond. The publication is, I think, this year actually. Likewise, this has been an artifact for a lot. The I of Jacobian of gamma, which is the skeleton of the Berkeley space, which is the term going into the sum I wrote down, is one-eighth total length of gamma. Total length of gamma. So this is sum of lengths of edges. That was 1, 1, 1, it would be 3. If it was 2, 1, 1, it would be 4. Minus this tau. One half capacity. And as I said, tau can be computed very efficiently. So I'm telling you, you can compute these things very well. For arbitrary ability varieties, I expect this to be very hard. To be very hard in the sense of complexity theory. Like, if you give me a 200-dimensional polynomial variety, which is not Jacobian, I think computing these kinds of moments are difficult computational problems, unlike computers. But there are actually computations for root analysis and etc. by Hundley and Sloan. So another remark is that this term This term is quite trivial to the graph. It's a point, so quick question. 0, 0, 0. Okay, so there's a correction that's happening at bad lunch of products. So another thing that I was hoping you asked is that if you add an edge to the graph, Jacobian doesn't change, like a bridge to the graph. This shouldn't change, but these two change exactly the correct amount. So tau will go up one-fourth of the length. One-fourth of the length. Again, you have an identity that you should wonder. Does it explain? I mean, again, this number is bigger than or equal to zero. It was known an inequality between these things by Romney. And we again are looking at some kind of a Riemann log type statement, seemingly, that we are, some inequality was known as like Riemann know some inequality, and then we are finding the error. And it's an advertisement of. And it's an advertisement of on point work, that that's also true. It's some kind of a line bundle. It did be of some line bubble. Yes? Sorry, so this is defined on the skeleton, correctly? Everything is about, yes. So I hopefully understand this. So, how is it related to the previous? That was something for an Obidian. For an obedient right of the value of an alpha view. And is this a specialization of that in some sense? Yes, so I unfortunately erased the, let me write that. The relation comes from the fact that whenever you give me a Jacobian, it comes from a curve, and it's known that the skeleton of the curve is some graph, it's known that the Of the curve is some graph. It's known that the skeleton of the albedian variety that we care about is also a torus, which I'm going to call it Jacobian Archana. And I'm saying that if you want to compute the moment of Jacobian Jn, it's enough to do it on the skeleton. So that invariant that you define depends only on the skeleton. That's what's what the location is. Correct. Yes. It depends only on the skeleton. The reason is the integration, in fact, The integration, in fact, in our paper, first we integral over the entire background space, but the measure is actually due to the work of Googler, it's supported on the canonical skeleton, which is just a torus. Is it the same? I think it was roughly in this question. So basically, if I add on some arbitrary trees to gamma, that's what I thought was asking. If you add a bunch of edges, so If you add a bunch of edges, so this will go up. It turns out you can figure out, this will also go up, but in a controlled way. One-fourth, if you add like 10, an edge of length 10, or 3 of a tall edge of length 10, then this will go up by whatever 10. So 10 over 4. So yeah, it's luckily it doesn't depend on the choice of the skeleton of the curve. But it's not that the mat, it's not that it's not concentrated. It's not a down thing. It's not concentrated on the minimal skeleton. What is not concentrated? These things are for any graph, for any skeleton that you pick. Luckily, this thing doesn't change as you change the shape. It's a different formula to the same thing for every model. I think I started five minutes late, right? Well, trust this, but I don't want to figure out. Will trust this, but I don't want to freak out about the newer stuff. So, the proof of this is electrical networks, convex geometry, all sorts of things that doesn't require Berkeley spaces. We do mention Berkeley spaces just to sound fancy, but we have the application in mind. But in reality, the proofs are just elementary. Elementary is I think they're difficult, difficult computations, but they're all Difficult computations, but they're all sort of graph theory type stuff. But we couldn't have conjectured this formula if we hadn't seen a result of Robert Wilms, our ongoing collaborator, so he did a PhD on default things and he was looking at Archimedean invariants attached to Riemann surfaces and he proved something which is analogous to this. Analogous to this, which something called delta invariant of faultiness of a Riemann surface minus twice phi invariant of a Riemann surface is equal to 24 phi invariant of the Jacobian. I'm not going to define what is delta and phi, but we sort of knew what these things should mean topically and sort of we said, okay, this formula is correct for Archimedean places. Can we do it for non Archimedean places? Do for non-Romidian places, the poofs are totally different. There is no computerics obviously here. I think it degenerates to the locus of hyper-electric curve and shows that there is some continuity involved and then does some explicit computations. But immediate thing that I was wondering is that can they, first of all, the first question is are they minimal working grounds? The second question are um can they be put in on equal footing? Very good questions. Very good questions, which I would like to understand, and I think you understand. Okay, from now on, I think I said all the rather explicit things I wanted to say, and I'm going to say a few more vague things. One of the questions we have to discuss is what makes a good talk. Questions: We have to discuss what makes a good talk. I had heard this advice that a good talk, the first 30 minutes, everybody should understand the next 15 minutes. The expert should understand the next five minutes, the speaker should understand, and the last part. One more thing that I and perhaps some of the audience would understand is: so, these are some more recent stuff. That's called asymptotic. And stuff, let's call it asymptotics. It's some question that tropical geometers must have wondered: is not Archimedean I tropicalization of Archimedean I? I mean, I just gave analogies. In our formula for Falthin's height, they are put on equal footing. There is no conceptual reason that says that limits of I over, say, moduli space is controlled by. Space is controlled by non-Romanian I. And that's a theorem. So another theorem, which I will state vaguely. So, first of all, I as a function over AG, complex points of AG, so I'm thinking of complex obliging varieties to R. In some precise sense, which I will make it a little bit more measures. Measures distance to the boundary. This was, in fact, observed by Attas here, or expressed by Ates here, distance to the boundary of the module. And you have a precise statement, namely okay. This is my KG. This is my AG. I don't mind. Let's say I have compactification AG second born. And I'm going to start with the points A and compute I of A, and then I'm going to go to the boundary along the holomorphic arc. So it's a one-parameter generation. And we prove limits of I, let me say I are unequal is some non-Archimedean i targs logarithm Army the minus of some real torus. Real torques that we can write on in terms of the mid-meet touch structure. Point log T, T is my parameter of degeneration. So this is the T path plus some lower order term, which can be described in terms of Haush theory. So, I mean, for charging geometry, you can sort of, yeah, you're taking logarithm. Do I want a logarithm here? I think I dropped a logarithm. Point by log t and send t to zero. That's sort of chopitalization statements. And this has the theorem is. The theorem is vague. I'm happy to show you the precise statement after the talk. But this has an application in so-called height of chairs of cycle. Vocation to heights height jumps. So series of cycle is the image of the whole Jacobi map minus its inverse. It's a claimous cycle that generically is supposed not to be at geopolitically zero, but it's homologous to zero. And there's a notion of complexity of this thing. And then you compute the height of that. And then as you go to the boundary, it jumps. And we actually say what those jumps are. And we actually say what those jumps are, and this is a key to our results. So, this theorem was proved by Robin and me and independently at the same time, roughly at the same time by Willem. So, Willems gives a different application in directional problem of conjecture. And let me end by just uh ongoing work. Ongoing work. There is a beautiful theory due to John and Yuan, Yuan and John, 250-page paper on archive, on idyllic line bundles, which gives us the tool for the dream that we have. We upgrade the question of little teeth versus faulting. Then on tiny versus halting side to brand models to isomorphism of line models. Meaning you show two line models are isomorphic. If you compute the norm of the isomorphism, you get the identity. So it's some kind of a upgrade. And then the second claim that I had was. And then the second frame that I had was also not only upgrade but put on equal footing our other identity about I versus tau and Robert's identity on delta invariant, which was our motivation. Also in the setting on equal footing and stated as a Miami dot 50 and there's an isomorphism of line bundles whose B is the identities we have discovered by bare hands. So upgrade. Um i versus tau and delta versus delta i versus i. Our result, Robert Will's result. And that's the basis of our ongoing work. Worked it worked with Robin Deong and Power Corps. And that's all I have. Have identical calculations in mind for this exact comparison with the quadrant size of the model? I wish. So there are understanding. So what are I think? So, what are do we have arithmetic applications of faulting-site identity? In a way, understanding bounds on Faulting Height is, as Shoe Bujan called it in one of his talks in IHGS, is the key to everything in arithmetic geometry. There are bounds for faulting site that if we prove ABC conjecture, all sorts of things are a result. Our identity shows that faulting site is as hard as... That faulting site is as hard as a neurotate type. The discrepancy I understand, these eigenvariance, I understand very well. For graphs, even better, but even for general lattices, if you're using Chowsky-type arguments, you give bounds. The problem is Neuron-Tate height, which initially I thought was the easy one, because Falfin's height is just a clear definition for me at the beginning. Neuron tait height is hard to understand. Apart from saying that it's bounded below form zero, people don't know much. So somehow our Know much. So, somehow, our contribution is that understanding the rotate height is the key for everything. I can talk about dreams, but especially when it's in videotape, I don't want to say things that are embarrassing. Yes. So, this last theorem. So, this function is a function defined on, this is really Defined on this is really a functional TG on the complex model, I suppose. Yes, it's a simple. It's a data analytic definition that you gave. Yes, yes. Okay. So you take your, it's a principally polarized, AG for me is principally polarized, my guys. And then you put the Riemann's data function, tweak it a little bit, take an integral over composite. This has nothing to do with Arcadov, this function. This function has nothing to do with ArcLov, except that it's. Nothing to do with ArcLov except that it's been key to many things and fault things and things. So what is it? So there was, I remember there was this some single looking function of SAR and kind of minimal effect of a period or something like this. Is that the two-author paper about the thin part of moduli? In fact, so I gave a similar talking over Wolf Arch and Bergwalcan pointed me out to that paper. I have looked at That paper. I have looked at it and I haven't found the connection. So you look at, in that situation, you look at the, so there is another function you can associate to complex abelian varieties. Namely, you have a lattice. You can look at the shortest vector in the lattice. And that gives you a number, and they have some cool results about how this measures the distance to the shot key locus or something like that. The point is that you can then, with that, you can bound the shotgun. Found the Seichalte constant of the Jacobian and can recognize actually distinguish the Jacobians from general abelian variants. The only way that I can distinguish Jacobians from other abelian varieties for me is Jacobians are computable and other Abenian varieties are not computable, but I don't have any sort of distance to the Schottky Loffest results. To be honest, I haven't thought about it much, but it doesn't seem obvious to me how to. It doesn't seem obvious to me now to apply the type of techniques that Saranak had done for this function. But I mean, it's a good question. Maybe I should actually mention it in the process. It's a question that I haven't exhausted, but a very good question. And I think I should point out that Either Nehru Schambergo pointed that out after I gave a talk in Oral Far. And I haven't listened. Yes, Dave. Is there the final year on the board? Is there also a question for? On the board, is there also a version for when you approach a high codimension stratum at the boundary? There's a corresponding party statement? So, yes. When I said that, how I had some of the paper that I gave us. So, the top thing is that we can now using this technology. So, we have been. So, if you prove a theorem like this on a higher-dimensional base, meaning that instead of just. Base, meaning that instead of just having a disk where the origin is missing, you have a disk origin is missing to the end. If you prove it, then you get a lot of really cool results, including uniform bound on the faulting side. There were two issues. We were stuck on some of the approximations we had. It's too much analysis for my taste. The second thing is that those fancy applications were. Applications are now done by Lars Kule using the work of Gal Dinitrov and Haubeger. He improved on it using some echo distribution and he got the ultimate application of that multi-dimensional base result. Now we can have that. So we have a Juan had another proof. Now we have a third proof of bounding the number of rational points using Rational points using exactly what you recommend, but we also use the work of Yuan and Zhang. So, my hope, and we get something weak here that we conjecture should be true, but it is true that you have a multi-dimensional base in the sense of your bi-extension singularity paper. The error term is not exactly as well as we think it should be, but we still get the application that we want. There's no urgency. We want, but there's no urgency at this point. It's rises won't be.