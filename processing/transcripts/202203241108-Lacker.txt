I have to follow Walter's act from yesterday. My board talk will nowhere near match his in terms of technical sophistication. I'll be sticking firmly with my 20th century format here until I can figure out how to do what he did yesterday. So I'm going to be talking about some work I've done recently that I'm very excited about on a class of mean field diffusion models, which is a Models, which is not squarely, let's say, in the subject of the workshop, maybe, but really at the heart of the method are transport inequalities and related functional inequalities. And that's really, so I want to emphasize this point for this audience in this talk. And also, I suppose mean field models of this form have really been prominent in optimal transport theory for several decades now. But to get to Now. But to get to the point, let me mention what I'm going to be talking about here: which are systems of interacting particles, let's say n particles which live in Rd and obey some stochastic dynamics, where particle I has some drift, which feels an average of pairwise interaction forces exerted on this particle by all of the neighbors, by all of the neighbors. Particle by all of the neighbors by all of the other particles in the system. And to keep things simple, I'm just putting an additive Brownian motion. And to keep things concrete for now, let's say the initial positions are IID, but this will not be essential throughout. Okay, so this class of models is very much classical. It's been studied for many decades now, originating in physical models of many body interactions. Many body interactions, and there are still many interesting physically relevant models where we don't understand how things work here. But more recently, there's been a resurgence of interest in these kinds of models coming in part from mean field game theory and in more recent work on mean field analysis of neural networks. So, I'm not going to say much about applications. I do want to mention this includes without loss of generality. Includes without loss of generality, you can put here, let's say, a self-interaction or confinement term here just by playing with you know adding a function that doesn't depend on the second variable. And some of the results I'm going to share also will apply to the more general kinds of higher order, let's say, rather than pairwise interactions that come up in particular in mean field game theory, where you have a function of your position, but then let's say the empirical measure. Position, but then let's say the empirical measure of the other particles in the model. So, this could encompass not just pairwise interactions, but maybe third or fourth or infinite order interactions. And you can do some things there, but things are cleaner with pairwise interactions, which are quite prevalent anyway. So, I'm going to stick with that setup for the talk. Okay, so the first kind of basic question in this business is how to identify. This is how to identify and rigorously justify the mean field limit, which is when you send the number of particles to infinity. And I was, I'm kind of happy in this work to have a new method for doing so in a field that's been around for a while and doesn't have a whole lot of different approaches to this problem. So, first, I need to explain how do we take a large n limit in a model like this? Okay, as n grows larger, you have more and more particles. Grows larger, you have more and more particles. So, what exactly should we be taking the limit of? Is the first question here? And the kind of first way this was done, going back to the 50s with the work of Mark Katz on the foundations of kinetic theory, the perspective he adopted was to fix, let's say, k particles out of your n and study their marginal distribution when k remains fixed as n goes to infinity. Okay, so I'm going to write p. Okay, so I'm going to write P and K for the joint law of, let's say, the first K particles in your model, which just to be clear, gives you a probability measure on Rd to the K. And if you assume, as we've done, that we have exchangeable initial positions and this B is nice enough to make this equation well posed, then this n-particle system is exchangeable at every time t. So this really represents the joint law of any. The joint law of any group of k particles out of your n. Okay, so this idea going back to Mark Katz is this idea of propagation of chaos, which has sort of become a kind of a buzz term by now. But to carefully explain what this means requires I first state what it means for a sequence of measures to be chaotic. And basically, the idea is that idea is that we would like to think that if we start from IID, then somehow these particles are nearly independent if n is large. Now, why should that be the case? Well, the pairwise interaction strength, let's say, between any two particles, one and two, the pairwise interaction strength is order one over n. So if n is very large, you'd think that two particles maybe are decoupled. And extending that logic to three, to four, or to k particles, you'd expect that. Particles, you'd expect that, you know, boundedly many particles might decouple as n gets very large. So you'd expect them to be independent roughly. They're not actually going to be independent because this interaction correlates them immediately, but you can still expect approximate independence. So this notion of chaos would say that if we fix n and send, sorry, if we fix k and send n to infinity, then maybe this is converging to. Is converging to an IID. So here we've assumed IID initial positions. Maybe I should remove that here. This statement I've written here is what you could say means that Pn0, the sequence of probability measures, is mu zero chaotic. This is a definition you'll find, for instance, in Snitman's famous monograph. Snitman's famous monograph on the subject. And this is basically a statement about triangular arrays of random variables. Basically, if you take the k-particle marginals, you want those to converge to iid. Whenever k stays fixed, this n goes to infinity. And this idea of propagation of chaos is that this chaos property should propagate over time under these dynamics. If it holds at time zero, then it should hold at any time t. Time t. So at any time t in the future, it should also be the case that for each fixed k, as I send into infinity, I have some IID limit here. So this symbol upstairs is the tensor product. I hope that's visible. And what remains to be explained here is what is this measure mu t that we get? And this is characterized by what's come to be known. Characterized by what's come to be known as the McKean-Vlassov equation, which is one way to write this is as a stochastic differential equation in which the law of the solution appears here. So mu t will be the law of the solution of this equation. And we will also use mu t in the equation itself to integrate this drift b in the second variable. The idea being that if we think these particles That if we think these particles are asymptotically independent, then we would expect the law of large numbers to turn this empirical average into an integral with respect to whatever this common distribution of these particles is. So, this is what happens in this McKin-Blassov equation here. Okay, so kind of the meta-theorem in this field that you expect and has been proven under many different kinds of assumptions on the model. Assumptions on the model, the theorem would say that, you know, okay, for my given initial distribution mu zero, let's say there exists a unique solution of this McKinne-Vlassov equation, and this implication holds. If I initialize the n-particle system from any distribution obeying this chaos property at time zero, then this chaos property will propagate at all times in the future, which gives us a sense in which indeed the A sense in which indeed the n-particle system is converging to this McKin-Vlassov equation. Now, there's an equivalent and maybe more familiar way to state this in terms of empirical measures, which I'm kind of deliberately postponing for now. But if you're wondering why I'm not talking about empirical measures, I ask for your patience. I'll come back to this in five or ten minutes. Okay, now this perspective, though, on the marginals is kind of the original one anyway, so I do feel justified. Original one anyway, so I do feel justified in focusing on this here. And the main subject of this talk is how to quantify this convergence here, this mean field limit in this sense. Okay, and to provide some context, I want to mention not the only prior results, but sort of two typical prior results in this direction under different kinds of assumptions on the dynamics here. On the dynamics here, the first being the kind of easiest case where this interaction function b is Lipschitz. And this you can find in this monograph of Stittman. He calls this the laboratory example. It's a good way to kind of get a feel for how this is working. And he doesn't state it in exactly this way, but you can extract from his argument the following bound. If you look at the quadratic transport. Quadratic transport distance between, let's say, the k-particle marginal and its supposed limit as n goes to infinity, then the square distance should be order k over n. And I don't need to define this distance for this audience here, so this will save a little bit of time. And let me mention actually on the side here, one nice thing about working. The side here: one nice thing about working quantitatively in this propagation of chaos story is that it tells you a little bit more. It actually tells you that k does not need to stay fixed as n goes to infinity. And this is a phenomenon known as increasing propagation of chaos, which I first learned about in a paper of Ben Aru and Saituni from the 90s. Basically, all you need is k to be little low of n, and then you need. Little low of n, and then you do indeed have this asymptotic independence still. As long as you're looking at a negligible fraction of particles, it doesn't have to stay bounded. So, this is something nice that you can only learn from a quantitative study here. Okay, so this is kind of the first and easiest way to quantify this mean field limit. More recently, there were results on the case where this B, this interaction function is just bounded and measurable. Function is just bounded and measurable with no continuity assumptions. So you can find this in the paper of Jabin and Wang from 2016, and then a paper of Jabir from 2019. This is Jabin, this is Jabir. They are different people. And the result they found would say that the distance. The distance between these measures, these same measures, but now in total variation distance squared instead of transport distance squared, this is also order K over N. And actually, they have something stronger than this. They deduce this from Pinsker's inequality and a relative entropy estimate, where they show exactly the same order K over N. You know, order K over N for this entropy. And I'm sure most, if not all of you, are familiar with this, but it'll play a central role in the talk. So let me just remind you of the definition of relative entropy, which is the log density between these two measures integrated with respect to the first one. And Pinsker's inequality lets you bound this total variation squared. Total variation squared by twice the relative entropy. Okay, so they get somehow the same order. The you know, distance squared between these measures is order K over N by quite different methods, though. And the punchline of the talk, you can say, well, for one, is that they have a kind of new approach to proving these kinds of things, which unifies these two cases. Things which unifies these two cases, which were very much parallel universes before. But not only that, but both of these orders can be improved to K over N squared. Okay, so this is the kind of main result of this work, and I want to spend the rest of the talk explaining why this is surprising and interesting and where does it And interesting, and where does this come from? And some philosophy around it that I can't resist going into. Okay, so this thing I should say about this is that this is sharp. You're not going to be able to improve this order, at least not for the kinds, not for these two cases, at least. And the simplest way to see this is by taking a Way to see this is by taking a linear interaction, a linear function b here, which gives you a linear stochastic differential equation to work with. And you can explicitly identify all of these distributions as Gaussians with various covariance matrices. And you can then explicitly compute actually all of these distances I've written above and really see that they are k over n squared and not k over n. not K over N. So this order really is optimal and cannot be improved. The other thing I'll mention here, just to make this maybe a little bit more concrete, is that this gives you in turn, let's say, the optimal order for linear statistics. If you're not super compelled by this story about k-particle marginals being About k-particle marginals being close in various distances. If you look at something maybe a little bit more concrete, like do we have a rate for the law of large numbers here? So we, let's say, look at some average of a function of these x i's, these particle positions, and compare this sample average to what we're told the limit should be, which is the integral of this function f under this measure mu t. Okay, then you, if you if you take the expected square difference. If you take the expected square difference here, well, what you can get then is that this is order one over n, which is exactly what you would get if the x i's were already iid mu t. This is just the classical variance computation for the weak law of large numbers in that case. In this case, these xi's are dependent, weakly dependent, but still dependent, and you still get the same order one over n from my bound of k over n squared. You actually only need k over n squared you actually only need the k over two case here on the other hand if you use these these prior these k over n bounds you would only get one over square root n here which is suboptimal in this case okay so this maybe makes it a little bit more concrete the meaning of these bounds that i'm reporting okay so another thing i want to mention here is that this is in a way this is This is in a way, this is kind of out of the blue. This is one of the surprising features of this. There was not a conjecture that this should be the right order of convergence in these models. And in fact, in prior works such as this Jar Bean Long paper, you can read a remark that says K over N is widely believed to be optimal. So this was kind of a surprise. I didn't anticipate this. In fact, I was skeptical of my own work until I worked out the Gaussian example to. out the Gaussian example to confirm that maybe I didn't make a terrible mistake somewhere. So this is the first surprising feature of this. The other I want to come back to after first finally talking a bit about empirical measures for another perspective on what's going on here. So for another perspective on what's going on here. Perspective on what's going on here, I want to recall here or tell you about the well-known equivalence between two different statements here. The first being what I've defined as this notion of chaos, which is that for any fixed k, if I look at k particles at a time and send n to infinity, then I get this iid mu t limit. And as a second statement, which turns out to be equivalent, this is the statement that the random empirical measure, where I just put a point mass 1 over n at each of these random particle positions, this random measure converges, say, in probability, to the non-random limit μt. So these two statements are equivalent, and this has nothing to do with the dynamics I've written down here. This is a complete. Dynamics: I've written down here. This is a completely general statement about exchangeable triangular arrays of random variables in Polish spaces. You can again find this in the Snitman monograph. And this is not difficult to prove either. But I want to highlight this because even though these are equivalent, they're only equivalent in a qualitative sense. And there does not seem to be a good or canonical quality. Be a good or canonical quantitative version of this equivalence. Okay, and for that reason, I like to distinguish them as local versus global. The first being local because it's dealing with finitely many particles at a time. We're fixing k and sending n to infinity. The second is global in the sense that it deals with the entire configuration, the entire empirical measure. And you know, these again are equivalent, but only in a qualitative sense. And it's actually supposed to. Sense and it's actually surprisingly tricky to pass, say, optimal quantitative information from one of these to the other, some say from global to local or vice versa. Now, one reason you should be suspicious already that it would be possible to pass quantitative information between the two is because a lot of global bounds often work by estimating. By estimating, say, an expected distance between the empirical measure and its limit. Like, if you look at, let's say, the transport distance W1, WP, whichever you want here between this empirical measure and its limit. Well, you know, this linear statistic case shows that these particles are weakly interacting, but we still maybe expect things to be of the order of the IID case. Case, we certainly won't do better than the IID case. And in the IID case, this is going to be of an order which depends on the dimension, as we just saw in several talks already today, who introduced and explained this idea very well why this happens. So let's say in dimension greater than or equal to three, the order of convergence to this expected disc is going to deteriorate with the dimension, whereas I've just claimed. Dimension, whereas I've just claimed that the bound I have in this local context is order k over n squared, regardless of the dimension. Now, the dimension could appear, and it does appear, in the constant hidden in the O notation here, but not at all in the exponent. Okay, and this calls into question, you know, this makes you suspicious that you could possibly derive this sharp local estimate from the sharp global estimate. So, this is one difference between these two perspectives. There is a way to pass from global to local information. There are several ways. The most popular that I want to mention is using what's known as a subadditivity inequality. And I'm going to use it a good deal, so I want to define now just a shorthand for this relative entropy. For this relative entropy between the k-particle distribution and its limit, the subadditivity inequality says that the k-particle entropy is bounded by k over n times the full n-particle entropy. And I should write hnk here, maybe, but I'm going to start getting lazy about the n dependence because all the results I'll present will actually be. The results I'll present will actually be non-asymptotic with respect to n. Okay, so the subadditivity says that you know hk is bounded by k over n times hn. At least that's true if k divides n. Otherwise, you need a factor of 2 here, which I want to ignore to keep things simple. And how should you interpret this? Well, I like to think of this as, you know, if this entropy represents some kind of energy quantity, then this Energy quantity, then this says that k out of your n particles cannot have more than their fair share. They're even fraction of the total energy in the system. Okay, so we have n particles, and if we look at k out of them, then they have no more than k over n of the total entropy. And again, this statement has nothing to do with the dynamics here. This is a general thing about exchangeable measures on polar spaces. So this is a kind of a well-known general inequality. Kind of a well-known general inequality here. And this is where comes in another surprise about this K over N result I found. So a lot of prior works on this subject use this inequality in the following way. They show that this Hn, the full n particle entropy, is bounded with respect to N. And this is the best you can do. This takes work. This is not easy. And you can definitely not show that it converges to zero. Show that it converges to zero. So a little o of one is never going to happen here. The full n-particle joint distribution does not converge to iid. It's only when you look at few enough particles at a time. So the best you can do is to get a uniform bounded n here, which then using subadditivity transfers over to an order k over n on this entropy, which is not as good as what I claimed, which is k over n squared being the sharp. Which is K over N squared being the sharp rate. Okay, so this is the other surprise here, which is that as a result is somehow beating subadditivity. Subadditivity is not giving you the sharp thing here. In fact, smaller collections of particles have much less than their fair share of the energy or entropy. And I can't say I have a good intuitive explanation as to why this is happening. And this is something I would like to. And this is something I would like to kind of understand better here. In this class of models, it just works out to be the case. Excuse me, Dan? Yes. Are you working under the Lipschitz assumption throughout or under these two assumptions you mentioned before? Good question. So I haven't yet given you clear assumptions yet. I will soon give you a theorem statement that I'll convince you encompasses both. That I'll convince you encompasses both of those cases: the bound case, the Lipschitz case, but also a broader class of examples. So, I do owe you still a precise statement. This is still philosophy at this stage, let's say. And do feel free to interrupt me with any other questions. Okay, so I should mention there's been a lot of other work on quantitative propagation of chaos. Quantitative propagation of chaos, notably in recent years, from kind of many folks in different camps. But I want to particularly highlight these authors here, among others, who have devised much more general and versatile methods than what I'm going to be explaining to you that don't seem to get to this sharp local rate, but can cover much broader families of models than I'm able to. And I'll refer you. And I'll refer you to the paper if you want more references. This is really a rich topic that's picked up a lot of steam in the past decade or so. And there are much more general approaches out there than the one I'm presenting here, but I don't know of any others that can really get to this sharp, this k over n squared rate that I'm claiming. And really, all of the other approaches that I know of out there are fundamentally global in nature. They work with either. In nature, they work with either the empirical measure or this full n-particle distance h n here, or something of the sort. I found a way to really work directly with these local objects here. So this is what I want to try to explain. But let me first give you a more concrete theorem statement. And I'm going to state this kind of a bit abstractly as like a black box. There's going to be an a priori assumption in here. An a priori assumption in here that I take as an assumption, which will look outlandish, but I'll give you some examples of how you can check this in practice. So there are four assumptions. The first I'm not going to dwell on is just some sort of well-posedness. I'm not making assumptions on B that ensure well-posedness. I'm rather just assuming well-posedness, which is known how to check in many cases, but of course. Check in many cases, but of course, if you want to show one equation converges to another, you better know that these things actually have solutions. The second assumption is pretty modest still. This is just an L2 bound on the coefficients along the solution. The precise form of this may look, I don't know, a little bit mysterious, but basically B itself squared, the pairwise interaction should. squared the pairwise interaction should belong to l2 but also this if you integrate out the second variable using this limiting measure this should also give you something finite here the precise form is is just convenient because this is how it shows up in the proof but think of this as just an l2 bound on the n particle system and the limit and really these quantities should depend on n but i'm suppressing that because this is really But I'm suppressing that because this is really a non-asymptotic statement. This is for a fixed n here. Okay, the third assumption gets a bit more important here. This is, you could call a well-preparedness condition for the initial conditions. I want the entropy at time zero. I remember this HK is the entropy that I'm studying here between k-particle distribution and its limit. I want this to be bounded by a This is to be bounded by a constant times k over n squared. And this is, I guess, natural. If you want to prove that this holds for all times t, it better be true at time zero in particular. But also just keep in mind, this covers the IID case, right? If we start already from IID, where this PNK0 is actually equal to mu zero to the k, then this C0 is zero in the IID case. Is zero in the IID case. Okay, now the most important assumption by far, which I previewed at the beginning of the talk briefly, is what I'll call a transport type inequality. And this is sort of a crazy thing to make as an assumption in your theorem, but I really think this is the way that kind of unifies these different perspectives, these different kinds of models. This is really like. Different kinds of models, this is really like the key a priori kind of assumption you need to check to make this method work. And I'll give you some examples afterward of cases where you can check this. But the abstract assumption here is that there exists some constant, which I'll call gamma, such that the following inequality holds. If I take my interaction function and I fix the variable x, And I integrate that with respect to this mean field measure. This is the thing that shows up in the drift of my limiting equation. But I compare that then to integration with respect to any other possible alternative distribution, then I want this squared to be controlled by a constant times the entropy between these measures. So this should be true for all x, for all t, and for all. For all t and for all other probability measures that you might give me. Okay, so this, you know, this probably looks like a very heavy assumption, but let me just right away mention that if you're in the case where B is bounded and measurable, let's say norm squared is bounded by R, then this inequality holds with gamma equals 2r by Pinsker's inequality. Okay, so this at least covers one non-trivial case, which is this bounded measurable drift. But I'll explain to you in a moment how this covers much broader class of examples. I call this a transport inequality because it's very similar to what are known as transport inequalities in the literature. Let me actually go ahead and mention example two, which is if B is Lipschitz, let's say L is. Let's say L Lipschitz, then the left-hand side by Kantorovich duality is no more than the, or L squared times the squared W1 distance between mu and mu t. Okay, and using this inequality, then the goal becomes to show that you have a transport inequality. That you have a transport inequality in the kind of classical sense that this W1 squared between any measure and μt is controlled by the relative entropy between that measure and μt. And, okay, indeed, in many situations, you can actually check this assumption. Mu t is characterized as the law of a solution of a certain stochastic differential equation. If B is Lipschitz, then in fact, you have a Lipschitz. Then, in fact, you have a Lipschitz SDE. And pretty much everything is known about Lipschitz SDEs, they do propagate transport inequalities. If you start with this being true at time zero, then this remains true at time t. And so this is how in the Lipschitz case, you can check that this assumption does indeed hold. And let me mention there's been some interesting recent developments on transport inequalities for SDEs due to Daniel Barzel, who might. Daniel Bartel, who might be here, Ludovic Tengpe, and some co-authors have kind of pushed the envelope in terms of what kinds of SDEs will propagate transport inequalities. And now, okay, I suppose I should elaborate a bit more on what transport inequalities like this are, but I'll refer you to this lovely survey of Ghoslan and Leonard on the subject. These kinds of These kinds of inequalities, if a measure satisfies this property that the W1 squared distance between μT and any other measure is controlled by a constant times the entropy, this characterizes a certain concentration of Lipschitz functions property under mu t. And there's a kind of broader zoo of transport inequalities out there that characterize different sorts of concentration behaviors. And really the most, you know. And really, the most concise way to think about this inequality, if it looks a bit strange to you, is that this is basically saying in some sense that B is sub-Gaussian under mu t somehow uniformly with respect to t and x. So you can translate this into an integral criterion if you want that might be a little bit more transparent. But this is really precisely how it's needed in the proof. So I kind of prefer this statement here. Okay, so this has been several. Okay, so this has been several minutes and I haven't even finished stating the theorem, so let me get back to business here. These are the four main abstract assumptions, and once you have them, you can achieve the following conclusion here. If you have n not being too small, at least, and you take any number of particles, k ranging from one to n, then this k-particle entropy uniformly on compact time intervals. Uniformly on compact time intervals is controlled by a constant times k over n squared. As announced, or to be precise, there's an additional exponential factor, which is even better than order k over n squared, as long as k over n is small enough. So this is the positive part squared of this constant minus k over n. So as long as As long as k is little o of n, we get the k over n squared here at the end of the day. But this is a non-asymptotic bound, and actually the statement, the constant is very easy to get a handle on. This is a pretty clean constant, in my opinion. This is nothing crazy complicated or abstract. I have it in my notes here. Not that the precise form is important, but I just want to illustrate that this depends in a very simple To illustrate that this depends in a very simple way on the constants of these main assumptions. Right, so C0 came from the initial condition here, m came from this L2 bound, and gamma comes from this transport inequality. And of course, T is the time horizon, and these are the constants that show up here. Okay, now let me just mention briefly that these constants do deteriorate exponentially as t goes to infinity. Exponentially as t goes to infinity, as the time horizon goes to infinity. And this is to be expected. I have a work in progress basically under stronger assumptions that gets a uniform in time estimate, which is relevant in a variety of contexts. But this is just, if you're curious, this is more of a detail maybe for now. Okay, so feel free to interrupt if you have any questions about the main theorem. These are the two main examples. These are the two main examples I've highlighted for the talk, but there are others that fit into this framework. For instance, if you take b to be any uniformly continuous function, then you get the same rate k over n squared. This takes more work, but this is kind of interesting because, as far as I know, there was not even a qualitative problem. Was not even a qualitative propagation of chaos result for this class yet. I should mention that this assumption, this transport of type inequality, and it's really its integral form, rules out the possibility of taking any sort of singular interaction function B, which are kind of prominent in modern physical applications. But nonetheless, you know, even if this isn't pushing the envelopes in the physics applications, it is getting Physics applications is getting a kind of new sharp order for a pretty broad class of models that are still applicable in plenty of contexts. Okay, so this is the main result and a few examples. In the rest of the talk, I want to try to explain where this comes from. Okay, and the idea behind this comes from combining two ideas that are reasonably known, at least. Reasonably known, at least in different communities, one is the what's called the BBGKY hierarchy, and the other is a kind of increasingly popular form of relative entropy estimate. Okay, so let's start with the second one here. So, the kind of entropy estimate I'm working with is pretty well known. If we take Well known. If we take two different SDEs, let's say, with different drifts, but the same additive Brownian motion, and they look at the relative entropy between the law of the first one with respect to the law of the second one. And I differentiate this, this will be no more than a half the expectation of the difference. Expectation of the difference between these two drifts squared. And in both of them, I put Z1. So this is an integral with respect to the measure that's in the first argument of this relative entropy. Okay, so this is the same Z1 showing up in B1 and V2. This is no mistake. These are both Z1. Okay, so actually, if I worked with the law on path space, so Z1 up to time t. Up to time t and z2 up to time t. This would become equality. But just to keep notation clear, I'm going to stick with the time marginals here. And then you only have inequality. Okay, so this is very convenient. I think this is, you know, the reason entropy estimates are so powerful in working with diffusion models is because it gives you an L2 quantity to work with, right? And then, you know, L2 is as convenient as it gets. Convenient as it gets. So, this is a general principle. This works for SDEs on the same dimension of any order here. And I'm going to apply this, but to a very, in a specific context here, and this is where this hierarchy idea comes in. Okay, let me remind you what the n-particle system looks like. We have these n-particles with these pairwise interactions in the drift. And there's this idea that comes up in the BBGKY hierarchy in the stochastics community. This is known as the mimicking theorem. So this particle system is for n particles at a time. But let's say I just want to focus on k of the particles instead of all n. And what I can do is isolate a self-contained, a Markovian S. Contained a Markovian SDE that's obeyed by the first K particles. So, what I can do is basically take the conditional expectation of this drift with respect to the first K particles in order to sort of average out the remaining n minus K particles that I don't care about. So, if I just look at, let's say, the first K particles instead, and what I can do is put here just the conditional expectation. Just the conditional expectation of this drift. So, this is part of a more general principle where if you have an SDE with additional randomness in the drift, then you can just sort of condition on the solution to get rid of this extra randomness. So, this is now for I going from 1 to K. And I should write maybe X hat and W hat here and define a function. w hat here and define a function representing this conditional expectations. This is not the same x, this is not the same x in both of these cases necessarily, but the idea is that this this SDE here gives you the same dynamics, has the same law PNK as the k particle marginal from this first SDE here. So this is a way to find a Markovian SDE now that gives you the same distribution. Same distribution. And the reason this works pretty well will become apparent soon. But first, let's simplify this conditional expectation a bit. If we look at what this is saying, well, we're conditioning on k particles. And if I look at this summation, I can split it into two. If the particle index j is less than or equal to k, then both of these two particles, i and j, live within this group that we're conditioning on. Within this group that we're conditioning on, so they just come out of the conditional expectation, and then what remains are a bunch of terms where I have j larger than k. And when j is larger than k, all of these terms will actually be the same by exchangeability. And I can just write them as let's say b of xi xk plus one. So, whether I put k plus 1 here or any j larger than k, this will give me the same thing. So, all of those remaining terms take exactly the same form. And I can write this a little bit more suggestively as the conditional law integrating this function b in its second variable. So, here this pk is the law, the conditional law of xk plus 1. Law of xk plus one given the first k particles. Okay, so I'm, you know, not being super rigorous here, but I hope the idea is reasonable, at least if you've seen this mimicking theorem before. The idea is to write, again, a self-contained SDE system that describes the evolution of this k-particle distribution. And what's funny about the SDE that you get. And what's funny about the SDE that you get is that it actually, the coefficient, this drift here, involves the conditional measure of the next particle, the k plus one particle. And in turn, you could see this as really depending on the k plus one particle joint distribution. Okay, so the coefficients of this evolution I've written down for the k particle marginal depends on the k plus one particle marginal, which in turn. Marginal, which in turn depends on the K plus two particle marginal. And this is why this is called a hierarchy. And this has been used in some kind of abstract context, in some qualitative context, particularly in the study of the Boltzmann equation. But as far as I know, this was not successfully used before to do any sort of quantitative analysis, this hierarchy idea. So at this stage, this probably looks, you know, this doesn't look totally simple. We have this. This doesn't look totally simple. We have this conditional expectation floating around with respect to this measure that we don't have a very clean form for. But once we put these two pieces together, something very nice happens. Okay, so if I then use this form I have for the drift of this k particle marginal distribution and apply this with this entropy estimate. And I want to compare basically to the SDE system for. SDE system for the tensorized limiting equation, which would look something like this, where we have mu t integrating the drift in the second variable, like so, I going from one to k. So, if we combine these two key ingredients here, we get this entropy estimate. We get a bound of a half times the x. Get a bound of a half times the expectation of the norm squared, the squared difference between these drifts evaluated at x1 through xk. So they're k different terms here. So this norm squared becomes a sum over k things. And then I have this drift here, this complicated looking drift, which I'll write out to be completely clear. Completely clear. We have this n minus k and this conditional measure term. And then we have a minus of this McKinnev term here. This is all squared. Okay, so what do you do with this? Well, the first thing you can do is group this last term here in part with. This last term here in part with the first term and then part with the second term. There are k minus one terms in this first sum. So a k minus one over n minus one fraction there. And the remaining n minus k over n minus one goes with that second term. And then I can bound the sum of the squares by twice. The square of the sum can bound by twice the sum of the squares. So the half cancels out. And if you bear with me, we have this. With me, we have this sum j less or equal to k of this b x i x j minus this mu b term here and then plus an expectation and these last two terms combine very nicely and based on the the general theorem I dwelled on before you can start Before you can start to see where this is going by writing it in this way with this conditional measure integrating B, we see that combining these two terms here gives you exactly something that you can apply this transport type inequality assumption to. Okay, so the first term is something that you can't do a whole lot with, but there are not too many of them, basically. This sum is over k minus one terms. I forgot a sum. I forgot a sum of I going from 1 to k throughout here. So the first term, you have n minus 1 squared, you have k here, you have k minus 1 in the sum. You can bound this kind of crudely in terms of this L2 bound m that was part of the assumption. And then the second term, you can just throw away this fraction here. This is less than or equal to one. Than or equal to one. And the second term here, we use this transport type inequality, and this is controlled by the entropy between this conditional measure and mu t. Okay, this is what this transport type inequality does for you. And then the last key point here is that this expected entropy of the conditional measure is something that you can apply this famous chain rule of relative entropy to. Or if a simple calculation, if you haven't seen it called the chain rule before, just shows you that this is the entropy of the k plus one particles minus the k particles here. Okay, and that was the technical part of the talk. At the end of the day, what you can show using these assumptions from the main theorem are exactly what I've written here. Basically, you have this m term plus a have this m term plus a gamma, and there's a k I forgot times hk plus one minus hk. So this is really the kind of center of the whole proof is this differential inequality you can derive that relates the k particle entropy to the k plus one particle entropy. Okay, now this might look a little hairy. Look a little hairy at first because you have this factor of k here, which is getting worse as you put more and more particles into the hierarchy. I mean, the immediate thing to do is apply Gronwal to bound this HK in terms of some integral term, getting rid of this HKT here. And this minus HK is what really saves the day. This gives you a minus, a negative exponential in your. A negative exponential in your integral hitting your next term in the hierarchy. So there are other constants and things I'm leaving out here, but basically, what you do then is just iterate this inequality until you run out of particles, until you get all the way to hn here inside the integral. And at the end of the day, you use the single, the only global bound that the whole proof needs, which is a very crude, easy one. Easy one that I won't explain where it comes from. Really, any polynomial would do here, but the very proved global bound is all that you need to close the iteration and get something you can actually work with. There's plenty of work to be done still estimating the iterated integrals that come out of this whole iteration. But this differential inequality is really the key thing going on here that lets you kind of bound the entropy. Kind of bound the entropy throughout this hierarchy and then a careful iteration of this gives you the results we're after. The one last thing I comment on is that this is not the right order here, actually. This should be k squared over n squared. And there's a kind of cute last step of the argument where after a first pass through the argument, you get a suboptimal rate of k cubed over n squared. But this is good enough. But this is good enough to go back through and sharpen up the argument that gave us this bound and remove one factor of k here by dealing with the correlations in a sort of more intelligent way. So there's two passes through the argument to get to the optimal order of k squared over n squared. But anyway, I think this is a good place to stop. Hopefully I've gotten us back on time here. Thank you for your attention and I'm happy to take any questions. Thanks a lot. This really was a pleasure. Are there questions or remarks? Jonas? Yeah, hi. Thank you for the talk. I was wondering if this K over N squared is now just fitting to your model or if there are different models where you also expect the same rate. Like, let's say it's. The same rate, like let's say, also spin systems or other discrete models? Yeah, this is a good question, and I don't have a very general answer for you. But there are some other kind of notable examples out there. One famous one in particular, actually. If you look at how does this work? You take, let's say, the uniform measure on square root of n times the sphere in dimension. The sphere in dimension n. So Pn, let's say, is this measure here, and Pnk will be its marginals. Then this is known, this is a famous old theorem that for a fixed k, as n goes to infinity, this will go to the standard Gaussian in dimension k. And it was shown by Diaconus and Friedman that the total That the total variation distance here is exactly this order K over N, which is, I mean, the entropy would be K over N squared. This total variation is K over N here. And there's by now a family of related examples where you basically replace the sphere with an L P ball and a similar rate appears, but with a different limiting measure. So if you take the L1 ball, you get the exponential measure here. You get the exponential measure here, and there's a kind of family of results like this that all get the exact same rate as mine. But I don't know of any similarities between these other than the rate that's appearing here. So that's the best I can do, I think, to partially answer your question. Thank you. Hi, Dan. I had a question as well. So, for a moment, it looked like you could. So for a moment it looked like you could maybe say something about the not only about the marginals converging but the processes or you know some higher dimensional in T distribution. But I guess the mimicking thing makes it really hard to see how this means to cut you off if you weren't done there. No, no, no, how it's house. I mean if you could ask it already then that's great. Okay yeah so actually in the paper So, actually, in the paper, everything is stated at the process level. So, indeed, on a bounded time horizon, all this whole entropy bound holds at process level. And instead of this mimicking theorem, there's a path-dependent version where you condition on the whole path. I don't know that this has a name. This has been used in filtering theory for many decades, the version where you condition on the whole path up to time t. And this entropy estimate works just as well, even if these coefficients are path-dependent. So, really, all this technology works just as well in the path-dependent setting. The one place it doesn't work is if you do want to get bounds that are uniform with respect to the time horizon, then you really need to focus on the time marginals, and you can't expect something process-level to happen uniformly on the infinite time interval. Maybe Aaron, what's next? Very nice talk. I was wondering if is there any way you can get like a handle on like the leading asymptotics to describe the correlations of the particles? For instance, using an approximation of this k plus one given k marginal in the mimicking process. Process. When you said leading order, my mind kind of immediately went to somehow the kind of zooming in on this difference here and trying to get a handle on some sort of fluctuations here. But maybe this is not what you meant when you referred to correlations. Can you elaborate? Yeah, yeah, I mean, that's what I meant. So the. Okay, okay. Okay, okay. Yeah, so this I did think about, but I didn't find a good way to get through here. I'm not really sure what this should look like or how you would go about it. I mean, in the Gaussian case, you can compute this thing. I can't remember the, well, I guess you put like an n over k here, and you can compute the limit in the Gaussian case, but I don't know what the general principle there looks like, or what this would even mean. Or what this would even mean exactly. Okay, thank you. Yeah, good question. Thanks. Hey, Max. Thanks, Daniel, for talk. It's really great. So I think I was the your remark about the Jacobins-Friedman theorem made me wonder is, okay, so this one is a particular avatar of the central limit theorem and usually Central limit theorem. And usually, indeed, in the central limit theorem, you have a rate for total variation in square root of n. And this is one instance when you have improved rate. Actually, the phenomenon is more generic than that, in that it's true as soon as you start summing symmetric variables. So, if you start doing the classical central limit theorem, you take your sum of variables and you do a Taylor expansion of the entropy along the Of the entropy along your central limit theorem, the leading order term, the one that gives you the one over n usually, is zero for symmetric random variables. And somehow the symmetry seems to play a role in these improved rates in the central limit theorem. And I was wondering, is there a similar kind of like symmetry somewhere that says, okay, you would have a... Yeah, I'm not sure what my question is, really. Not sure what my question is, really. No, this is. I'm glad you brought this up. I'm not familiar with this perspective, but this is very intriguing to me. And I've been kind of puzzled over the, you know, what is the right general principle behind the scenes here. I mean, there is very much, you know, there's symmetry here where there's exchangeability everywhere. So maybe this is somehow the culprit. But I'd be very curious if you had a reference you could share or could we could discuss more offline maybe. I'm not sure where this first appears. I learned this stuff in the work of Kachteiger, which I can send to you with some references. Okay, okay. Thank you. Okay, then thanks a lot again, indeed. And I guess we resume after break. 