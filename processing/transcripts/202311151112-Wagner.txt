I'm actually gonna interrupt my own talk and maybe I'm gonna go off on a little tangent first just because meeting you guys and like I've sort of talked about my experimental research portion that I do that I guess it's a little bit different so I just want to talk about it briefly and I'm hoping it'll spark eventual projects with some of the people here. So I'm an engineer by training and I think a lot about soft matter and I think about mucus as a main model system and I'm really interested in the role that it plays in disease processes. Role that it plays in disease processes and sort of the biophysics of transmission. So, I'm sort of showing this cartoon to say we think about aspects happening in hosts where mucus is like this interesting barrier that can track pathogens that try to move through. And so I'll talk about that in a little bit. But then also what happens at the point of transmission when you sort of emit these mucous particles that are laden with viruses. And I'm really interested to also how that interfaces with climate in terms of seasonality of transmission. So, what my goal is is to eventually take But my goal is to eventually take this insight and tie it back into models at the population level. So that's one thing we're working on. And then also, we just independently developed population models. So I'm going to talk today about the stuff with wearables and how we're thinking about that in the context of HV-based models. We also think about the impact of, say, vaccination, like Yitzhen spoke to you about. So some of our techniques are, we use rheological techniques, which means studying the mechanics of soft materials. So this is what a funny instrument called a rheometer does. It just measures. Instrument called a rheometer does that just measures mechanical properties. I can put mucus in there and learn something about what its structure probably looks like at the protein level just by how it responds macroscopically. And then we use this is the world's most boring video of small fluorescent particles wiggling around just by thermal fluctuations in the soft matter. And so the goal is to track how these things move and then tease out, like, okay, what happens if it's a virus with different surface properties? Will it move different? Will that impact, say, the dynamics in an That impacts, say, the dynamics in an in-post modeling framework. So, I'm going to just sort of pass over this, but then we also look at what happens outside of the body. So, this is like this is work from Lydia Bariva at MIT, which I think a lot of people have probably seen at this point. So, she really showed people how bad costs and sneezes are in terms of showing you how much really gets out there. And this is a nice visualization, too, I think, of what happens if you change the material that you're aerosolizing. So, the left is just a Newtonian fluid, the right is a polymer fluid. A Newtonian fluid, the right is a polymer fluid, and the mucus is a polymer fluid. It has this protein in it called mucin. So, we do sort of stuff like that. We're trying to look at how droplet size distributions change for mucosal fluids. This is a project that my grad student, Nicole, was working on. And I'm really keen on this idea that somehow the pathogens might also be doing something to impact this fragmentation process. So, I'm really hung up on why are some pathogens more aerosol transmitted? Why do some have a really high R0 and some have a really low R0? A really high R0 and some other really low R0. To me, it's not obvious that we know the answers to these questions. So I was wondering: if you just put small charged things in polymers and then fragment them, will that even change how these fluids break up? And we're seeing some interesting evidence that it does. So I want to move this forward and put, like, you know, let's say I can put a virus-like particle that has some surface properties, or I could change its surface proteins to look more like flu instead of RSV or SARS-CoV-2. Will that change the fragmentation that we see? The fragmentation that we see. So, we're seeing some interesting evidence that potentially that does, which I'm really excited about. And then the goal is to also tie that together with climate, for instance, so we know that there's seasonality in these patterns. Is it because somehow, say, temperature and humidity are changing the way that these droplets evaporate, sort of the size distribution, but then is that somehow doing something to the viability of the pathogen that's in there? So, that's sort of stuff that we're thinking about on the biophysics side, and then hopefully, at least this crowd can see how that takes. At least this crowd can see how that ties into the modeling side, but that's something I'm facing as a challenge in terms of a new researcher trying to get grants, sort of convincing people that those are related subjects. So anyways, that's my digression. I'm going to come back to the work that we're doing with these agent-based models. So this actually, I have to admit, is work that this amazing grad student just sort of put on my desk one day, and I've never had that happen before, but he's a really talented guy, Nathan. You'll hear about him more in a second. You'll hear about him more in a second. But he basically said to me, Here's a paper that I wrote that was already in extremely good shape, and then we worked on sort of fine-tuning these ideas, and we've been building on them ever since. So the idea is basically building on the fact that since the pandemic, there's been this explosion in new technologies for detecting infection. We're going to talk mostly about some of the stuff we've done thinking about smartwatches, and we can think about sort of different ways that these technologies might operate. Are they sort of Operate? Are they sort of rapid or are they more delayed? Are they quantitative or qualitative? Are they multiplexed or single-pathogen? So, sort of developing refinements or thinking about diagnostics on different ends of these spectrums, obviously you can think might impact our ability to detect disease in different ways. So for this project, sort of a timeline of what we did, we thought first about this pilot study that was actually using, it was full compartmental models. So I'll talk about that first, sort of doing a counterfactual evaluation. Doing a counterfactual evaluation of what, if we had smartwatches relatively well distributed within the population, could we have thought that they might have mitigated what we saw in terms of cases? And then that sort of led us to saying, okay, but particularly for technologies like smartwatches that really are stratified within the population by socioeconomic status, by heterogeneity with different groups, we thought that moving towards an agent-based framework would be more appropriate, and now adapting that to a multi-pathogen system. So, this is just an example of this is work out of the Snyder group at Stanford showing the actual apparent feasibility of smartwatches for detecting COVID-19 infection without necessarily symptoms. So, this is a signal. So, what they do is they measure physiological responses like heart rate and temperature and stuff like that, and they can sort of look for anomalies and sort of ping you as, okay, you might have an infection right now. So, this is a signal, I think, from A signal, I think, from a single patient. I don't think this is aggregated, basically, showing that it was able to pick up the infection. What's nice about them, too, is like you don't really need to do anything, you just need to wear the device because as always, you want to minimize the work of the people participating in these kinds of studies. And there's also pretty good machinery in place already for privacy-preserving purposes. So, Nathan, this is Nathan, who is now working in. Who is now working at BCG, which is very sad, but he was fantastic during his time at McGill, who developed this, and we've seen many of these models in this workshop, so I won't go into the details too much, but it's really just a basic SEIR model that allows for quarantining, and we basically divide the population into: do you have a smartwatch or do you not have a smartwatch? So if the smartwatch gave you a signal that was correct, that That was correct. That would mean that you were in one of these groups to begin with. You either actually had an infection or you were in the exposed compartment. But we also defined, we also used actual parameters to, like sensitivity and specificity for the smartwatches, because they're not perfect. And we said there's a likelihood that you might be in, say, the susceptible compartment and you got a notification, in which case the watch got it wrong. So, at first, what we did is we said if you get a notification, Said if you get a notification, with some likelihood you're going to quarantine and until you get the results of a PCR test, and then if it's positive, you'll stay in quarantine. If not, you'll reintegrate. But we vary basically how many people decide to actually go along with those things. So we found, like, sort of even, and this is not, you know, in any way sort of calibrated very specifically to any region in Canada, but using, just using this IH. Just using this HME model, and sort of we estimated a transmission rate based on that, and then ran the model forward, assuming a certain effectiveness for the smartwatch and then a given uptake and adherence rate. We found that feasibly a lot of infections could have been averted, about 16%. But what was interesting was seeing where that was coming from. And it turned out that a non-trivial amount was coming from the fact that we had so many people incorrectly in quarantine that it was driving down the size of our susceptible population. Driving down the size of our susceptible population. So we said, okay, that's obviously not going to be an accept policy to roll out to people, so we need to think through that a little bit further. I say a sizable now, but not all. A good amount is coming from the ability to detect infection in the first place and remove those people from the population. So, probably not shockingly, we found that more sensitive tests were better at reducing infections, but this dependence on specificity is really because you sort of had more people who were susceptible to begin with. People who are susceptible to begin with in the population. Yes, sir. Do you have other mechanisms for people to be tested, or is it in your model, like the only way to recognize I have COVID is if I have a smell? One second. We're getting there. Okay. Yes, so that was sort of our, what we took away from this. We said, okay, this wouldn't be feasible, right? Given the level of specificity that these devices have, we'd need another system in place. So what we did was say, okay, what if we could also offer, say, a rapid antigen test? Also, offer, say, a rapid antigen test. So, you could take that after getting the smartwatch notification. We think that these would be more specific than the smartwatch. If that were positive, then you would indeed quarantine and wait for a PCR test. If not, you would sort of ignore the notification and go back. So, in that case, what we found, so here the black curve is the baseline, the red curves are a certain degree of uptake and inherence, the blue curves are increasing those values, but the dashed ones are when we also give people the rapid angel test. So, what you see is. Test. So, what you see is: okay, we compromise a little bit on what we can avert because, again, we're not just forcing people to stay in quarantine for no reason, but we really lose how much of that sort of societal cost we're imposing at the same time. And you can see also we reduced the burden of the necessity to perform lab-based tests, which we were finding was like truly huge if we were assuming that you would get a PCR test every time you got a notification. So, that was sort of. So that was sort of what we got out of this study. Like we say, it was a pilot, but there were some limitations to it. So it didn't account for any heterogeneity, which at first we said we can justify that in the context of this preliminary study, but specifically, like I said, in the context of smartwatches, it's probably not a valid assumption to make within a population. We also wanted to be able to just incorporate heterogeneity and epidemiological parameters and behavioral parameters as well, or contact patterns. As well, or contact patterns. We were basing things off this IHME model, which may have some limitations as well. And yeah, we also had to assume some sort of uniform uptake and adherence within the population. So we said, okay, can we move this to an agent-based platform where we could capture a lot of these things that we weren't able to capture in the compartmental framework? And we said, can we, what we liked about this was we were also interested in looking at what I mean by individual is actually. mean by individual is actually in-host viral kinetics and looking at things like viral load but within individuals as well and would support more of this variability that we were interested in looking at. Okay, so that led us to the first foray into using these kinds of this kind of framework and we didn't reinvent the wheel and maybe we should have called NATO before we did this but we didn't. So we chose this platform COVID, which is this open source ABM that had been developed. ABM that had been developed in the context of COVID-19. So, this is the reference down here. It's nice because there's a lot of flexibility in terms of setting up country-specific population structures and size and transmission networks, and also incorporating real-world settings like schools and I think assisted or long-term living facilities and things like that. And it does some approach or some estimate at in-host viral dynamics. So, it assumes some viral load-based transmission. So it assumes some viral load-based transmission, which is how it incorporates this heterogeneity within the population. But it's a pretty simplistic assumption for what that response curve would look like post-infection. And you can implement things like MPIs and the ability to test and isolate. So we took that at the starting point and we added some features to it based on what we were looking at, we were interested in looking at. One thing that we've been keen on, especially when we thought about, okay, let's distribute these rapid engine tests in the context of the previous work, was. The context of the previous work was how does the use of these tests differ at different stages of the pandemic? So, you know, early on, if we were fully isolating and we really only expect, say, COVID to keep you circulating, then we think that sort of there was the utility that we get out of different testing systems would be different than if, let's say, there were a lot of circulation of other pathogens in the background, and a lot of the use of these devices, say, owing to symptoms, was because of infections that we weren't necessarily keeping track of. So we wanted to increase. Really keeping track of. So, we wanted to incorporate that back we call it influenza-like illness, ILI proportion within the population. We specified the types of symptoms because we were interested in using that to specify different testing protocols, and you can get a test if you exhibit the following symptoms, for instance. We included more flexibility in quarantine behavior, and then we also tried to generate more variability in terms of generating these viral load curves. So, for instance, this is an approximation. This is viral. An approximation for viral low is since, and this is day since it rose above a certain amount, but basically it would be the trajectory of virus tighter within an individual post-infection. So this work has been done by a super undergrad, Richie, and so he's been working with playing around with this framework to say, you know, if we change around, say who is test eligible, who actually seeks a test, and then who receives a test, how does that impact what we see in terms of infection in the population? So here's just a really simple Population. So here's just a really simple example. This would be a simulation of incidence of infection, and then Richie implements a certain testing pipeline or a certain set of rules about who can get a test. And then that would basically say who's actually eligible. A subset of that would actually seek a test, and then an even smaller subset would receive a test. And obviously, those numbers would change over the course of an epidemic as the number of infections to change. So this is some preliminary data that I have to say. Some preliminary data that I have to say, I'm still in the process of thinking through, but I'm excited to be getting some results that show some variability as we introduce different testing protocols. But Richie's been thinking about some different parameters that we could sort of tease out of these data to look at basically the impact of the different rules that we set up for testing in terms of their efficacy. Like, say, the delay between the signal that we received from tests versus infection, or our measure of sensitivity, which we're calling total. Of sensitivity, which we're calling total positive tests for COVID-19 divided by actual incidents, things like that. So, what we do is play with things like the background level of ILI within the population or how good our test is. So, a small limit of detection is a good test and a poor limit of detection, a high limit of detection is a poor test. And we can see maybe some sort of intuitive results. This is cumulative infections. So, if you have low background dialy, which means basically everyone has an alcoholic change, so we get the And I'll change this so we get the criteria. So, here on the left, Richie was using quite a stringent testing criteria, which was you had to be symptomatic or you had to have severe disease to take one of these tests. And sort of intuitively, then, if there's nothing else going around and it's just COVID, then basically you can expect everyone with symptoms has COVID. So, having tests is useful because then you can identify those people, so your cases should be lower because you can get them out of the population. But as you start to compound that by having other illnesses, you're Having other illnesses, you're less, in a sense, these tests become less effective holding the number of tests constant because more of them are being used to detect other things. And this is what I'm still scratching my head over, trying to work through some of these responses. But now on the right, what Richie does, for instance, is really broaden the criteria for receiving a test. And what I'm intrigued by is we start to see different effects of, say, circulation of different pathogens in the background. And to me, that's interesting because it means that potentially over the course of Because it means that potentially over the course of the pandemic, after you've loosened restrictions, or as other pathogens come more into play or less into play, if their circulation's been affected by MTIs, then potentially you have to think through the ways that you use tests or diagnostic measures within the population. Okay, so that brought us to basically summer 2023 when we decided, okay, we were seeing some cool results with the background nyloni. With the background nylai. And not only that, we became keen on this idea, especially given the in-host interest that I have, of saying, you know, what really are these physiological signals that these wearables are picking up on? Are they pathogen-specific? So to me, it would be really cool, for instance, if we could conduct a huge study where people wore wearables and we could know, okay, this person had flu, this person had RSV, and are the physiological signals different? Could we ever get wearables that would be specific? Could we ever get wearables that would be specific enough to pick up on that? And what would that tell us about the differences of infection kinetics for these different pathogens? So, we haven't done that study yet. I'd like to try to pitch it to someone who would give me a lot of money one day. But prior to that, we thought about let's at least expand our framework so we could think about multiple co-secret pathogens and what the impact of that would be. So, we called this framework Pathosim. So, it's the updated version of COVISIM that allows for interacting. Cobacin that allows for interacting multi-pathogen circulation that can potentially interact. And basically, our goal with that is to, again, use it to assess the efficacy of different interventions, but now in the context of controlling the spread of multiple pathogens. So the person who really did this is Felipe, who's an amazing undergrad. He's a computer scientist. And I think I was really, really struck by the talks yesterday from Irina. From Irina and Steve, about sort of working with computer scientists versus maybe people who don't have formal training in that. It's really amazing, but you know, I feel like I'm almost embarrassed to show my code to computer scientists because it's like, I know it works, but it's probably like the least effective way that I could have done it. So anyways, really has been fantastic in terms of showing us how to build code in a smart way. Yeah, so that's sort of just some of these, and just sort of going over some of These are just sort of going over some of the different things we implemented with respect to COVIDSIM. But we can change, so yeah, the big takeaways with that would be: once you, if you are infected, say co-infected by multiple pathogens, we can change basically the course of disease that would have resulted otherwise. So we can program, first off, for a single pathogen. COVISIM had built-in parameters specific to COVID-19. So we've made this flexible to any kind of pathogen you might want to simulate. But then what we also did. But then, what we also did is say in the context of co-infection, we could say that that would impact the disease course for, say, the single pathogen if you had been infected by only one pathogen. Full list. I won't go through all this. These are, again, some totally example results that we're starting to get. So, for instance, this is a reference simulation that Philip could run. So, this is very simple. We assume no pathogen interactions here. We introduced pathogen 2 30 days after SARS-CoV-2. 230 days after SARS-CoV-2, and we put no MPIs in place. There's a lot of infections. This is not particularly revolutionary, but what you see is sort of two independent peaks, which is what you would expect if you just burn through two pathogens that don't interact in any way. But now, if we do say that there's some sort of interaction, and how we came up with these numbers, we're still working on, but there is a good amount of literature that will look at, say, flu plus SARS-CoV-2 infection and come up with some estimate for how that might impact transmissibility or duration. Impact transmissibility or duration of symptoms or infective ear, something like that. So now you can see when they do interact, you can get the second little peak that pops out for the SARS-Povin 2 curve, which is because of that interaction with our pathogen 2, which is just some made-up pathogen at this point. And we've done that sort of for different choice scenarios. Okay, so now I just want to sort of conclude by saying, talking about some applications that we have in mind for this. Some applications that we have in mind for this, and we came to explore other ones, obviously. So, the first application is in the context of zero surveillance programs. There's a group at McGill, and that's going to sort of come out of the CITF and all this work that was done during the pandemic related to zero surveillance. And they're trying to come up with a platform where we could use residual blood or other kinds of sera that were collected within the population to see whether it would be feasible. To see whether it would be feasible to set up some kind of monitoring service system in peacetime or in sort of pandemic time and see if that could help with mitigation for pathogens. So Alina is the great undergrad who's been working on this, but essentially what we're doing is interfacing this with pathogen to translate what they have as this sort of rudimentary nutrient antibody estimate that you get when someone is infected, and then translate that into an IgG. Into an IgG time course, which we could then sort of connect to our made-up sero surveillance system, and we could read out what IgG levels are within the population. How we make that connection from neutralizing antibodies to IgG is sort of based on estimates in the literature, which again, there's probably room to refine. It's probably very pathogen-specific, but that's how we've been approaching going about it today. So, what Alina's been playing around with for now is looking at, say, okay, what happens if you? Is looking at say, okay, what happens if you specify within our profession population, let's say, a cohort that looks like a very broad, you know, Canadian donors, broad age, different sexes, versus if you use, say, antenatal seras, that would be a much smaller subset of the population, or one that's popular based on availability of data is this CAN PAC PC Generations project, and then playing around with different kinds of tests to look at the signals that we get. So, for instance, Lena ran this toy simulation where Lena ran this toy simulation where we implement this kind of it's a quantitative immunoassay in this case with a certain limit of detection. We introduce a pathogen and then she implements this kind of cross-sectional surveillance program, let's say using this broad Canadian blood donor characteristic, where she would take 100 samples every three days over four months. So, what you can see is obviously when there's no pathogen, there's not a lot of signal from the test, but as the infection is spreading within the population, you see that You see the sort of record within the population of IgG levels going up. And what we're trying to figure out now is sort of what are the best signals that we can extract from this, either to inform policymakers, okay, when do you act on a signal coming out, what kind of features should that signal look like, or if we could, another big goal would be to be able to really rank our population up into appropriate subgroups so we can say, okay, what are sort of dangers to look at in a specific subpopulation in terms of emergence of IGP? In terms of emergence of IGP signals, that might say we should maybe vaccinate or we should maybe implement some other kind of intervention. And one last application. So this is with the team at Oxford that we've been collaborating with who are interested in sort of different kinds of biosecurity questions. So this would be related to surveillance in the UK. So what Conrad's been thinking about is using Pathosim to look at the cost-effectiveness and comparative efficacy of different surveillance programs based on. Or programs based on sequencing data, so either clinical, community, or environmental sources. So, here, this is just an example that he has been thinking about for now, where he basically comes up with some evaluation of the efficacy, let's say it was a very specific program, so community-based surveillance of a given size, and looks at basically what would be the cost of implementing that kind of a program versus other kinds of of detection program and and versus the what you get out of it in terms of its ability to detect infections. Of its ability to detect infections. Yeah, so with that, I think I pretty much said what I wanted to say. This is the team again who's been really working on the Pathosim and the EVM stuff and the sensor stuff. Acknowledge funders and very happy to take any questions.