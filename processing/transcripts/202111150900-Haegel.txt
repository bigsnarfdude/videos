I'm happy to at least present virtually this seminar and I hope to meet all of you very soon and that you will have a very good workshop. So this seminar concerns using gravitational waves to search for new physics and especially during the propagation of the waves. So, I know that most of you, if not everybody, is aware of the latest development and release. However, as I am the first talk in this workshop, let me give an introductory slide about what we have achieved. Last week we have published the gravitational wave transient catalogue number three, and what we can see is the number three because it corresponds to the third of the Number three, because it corresponds to the third observational run. And specifically with the latest release, it was the latest release from the second half of the third run. And it's really an exponential catalogue that we're having because we went from three detection during O1 to A during O2 to 79 during O3. So that's really impressive. We're still measuring only the coalescence of compact objects. We have numerous black holes, few neutron stars in the middle. Middle. And we have one multi-missander event that has enabled us to do tremendous physics. And I will discuss how they can be used for the search of new physics. In total, it's 90 detections that have been reported. The mass range is about 1.4 to 95 star masses, so it's still the stellar mass range. I'm putting the mass of the individual component pre-coalescent. And in terms of descent range, it goes to And in terms of descent range, it goes to 40 megaparsec for a very close binary neutron star merger to up to 4.4 gigaparsec for the furthest event. And we can proprietify up to 0.45. This is quite important in terms of propagation. A lot of the effects are expected to be larger with larger distance. We're still in a relatively local universe. But what we see is that as we are improving the sense. As we are improving the sensitivity of instruments, we can go further, and for this type of test, it's very important. When we use gravitational wave, we have many, it gives us the opportunity to test general relativity in several ways. We can perform residual tests. We can look at the noise that we have when we remove ZTR options and look if there is any residual power of signal. Residual power of signal. In theory, this is a very informative test. You're not supposed to see anything in your noise if you remove the totality of the signal. But what we know is that we don't always remove the totality of the signal because we use approximate models to reconstruct our signals. And also that our noise is very non-stationary. And actually, recent studies have shown that this type of test can see some deviations from GR, but Deviations from GR, but mainly relatively large one, and it's very important to actually tackle the question of looking at deviations or inconsistency in or signal as predicted by general relativity with different approach. Another approach is to look if there is extra polarization in the gravitational wave signal. We can look at parametrized deviations, for example, so that we see. Deviation, for example, is what we see in the median plot. Here, you add, you have additional degrees of freedom in your waveform, and you see if those additional degrees of freedom are actually non-zero. It could point to a lack of physics in your waveform model, or it could point to, especially for some specific coefficients, to the existence of new physics like dipolar radiation. In the ring down, it's the ring down because it can be analytically computed. Computed is a very powerful place to look at alternative, especially to derive phenomenology of alternative theories of gravity. However, right now we're not really seeing the ringdowns of events very well, so it is observationally a bit complicated to see events on this part. And a lot of those events are in fact with gravitational wave generation. We also can look here, we can see. Here we can see, we can look for echoes that have been suggested as a sign of structure inside a black hole, but that can explain the information paradox. For now, there have been numerous studies, different claims, but the most robust study are not seeing the presence of an echo, which is not very surprising because you expect to have, even if a couple were to exist, you expect them to be smaller in amplitude, and it's very unlikely. Amplitude and it's very unlikely, and in the wind-down part, as I said, it's hard to detect, so it's very unlikely to see them. And on the right-hand side, it's just an example of a consistency plot where you're just going to check different parts of your waveform and seeing that you are recovering what you want. So all those are different ways that I think are very important to check that our signals behave as general activity is predicting. And also because also. And also, because although we have better signal-to-noise ratio, we still do not see or signal really under the amplitude of the noise. And then, for this reason, it's very important to tackle different to use different tests to ask those questions, because you may see some tests have been shown to be more sensitive than others in seeing deviations, and therefore it is totally conceivable to have. Is totally conceivable to have a deviation appearing in the test and not seen by another one. So, talking about gravitational wave propagation, that I actually have not discussed in the previous slide, why it is important. First, contrary to looking at an effect that would affect the generation of the gravitational wave, in the case of an effect that would, of new physics that would couple to gravitation and appear on the Gravitation and the pyramids of propagation, then the effect can be independent of the source. So you can be able to analyze different sources, black hole, neutron star, even in some cases, supernovae, if you were to detect them, continuous wave, and to have the same framework to study this. Secondly, if you want to look for deviations that would occur during the murder part. That would occur during the murder part. It's a very complicated thing to do because this is what is a very non-linear regime of general activity, and that's why we need numerical relativity simulations to compute this part of the waveform of the gravitational wave signal during the coalescence. And it's already very hard to do with black holes. And there have been some attempts to do this, that have some successful attempts, I would say, or it is very interesting. I would say, or it is very interesting stepping stones towards having numerical relativity simulation of the coalescence of binary black holes in some alternative theories of quality, such as Tron-Simons. But they are not in sufficient number. Well, they have some assumptions that need to be understood, to be used, and they are not in sufficient amount to be able to be used to do inference. But if you look at something that is going to affect the propagation, Is going to affect the propagation. Most of the time, you can compute it as an effect that is going to appear during the propagation equation, and that will be a deformation of the overall signal that you can derive for your whole waveform. So, you don't have this issue of not being sure what to do with your motor part. There also is a possibility that very small deviations can be amplified with a cumulative effect, and there are some. Cumulative effect, and there are some prospects to maybe detect quantum gravitational effects that are extremely small on Planck scale or a bit above, and that may be amplified during the propagation of gravitational wave and therefore be seen this way. Finally, the universe is expanding so that we're still in a relatively local universe, but we can probe already the expansion of the universe. Already the expansion of the universe, gravitational waves, and as we're detecting further and further events, we're really in a dynamical region. So if we were to look a bit about how to parameterize gravitational wave propagation, we have on the top the propagation equation in the general activity case. And we can see that deviations that occur during the propagation equation. Deviations that occur during the propagation are given in the bottom equation, and they can occur in different ways. The first term, Î½, is a running Planck mass, and it basically it is consistent with what we call gravitational wave friction. That's a generic term to say that you will have an amplitude that doesn't scale at one over the distance. So, the main effect is that you're not going to reconstruct a luminosity distance that is Distance that is the one that you would predict with GR. The rest of the waveform doesn't have to be modified. And the difference in the factor C, that is the velocity, is the speed of gravity. So you would have a gravitational wave velocity that is different from the speed of light. Both of those effects can be probed with multinesenter events, especially if you have a new, so if you have a gravity that is going at a smaller speed than light, or if you have Speed and light, or if you have some new physics that is only going to impact the gravitational sector but not the electromagnetic sector, then you will have a different distance reconstructed from a gravitational wave compared to the electromagnetic event. And therefore, you can do consistency tests between different signals to prove those two effects. Mu would correspond to a graviton mass that is non-zero, that can create some dispersion effect. Can create some dispersion effect, can also affect the speed of gravity. So there is not one, or it's some of these effects can be proved with different terms. And the last term consists in mode mixing, where you have the mixing of H plus and H cross polarization, for example, or anisotropic stress. And those are effects that can be also probed with only the gravitational. So let's start looking at. So let's start looking at the case of gravitational wave frictions and how we have been studying this in particular. So as I said, we can use the multimescender event to check if the to measure the distance from a single event, a single source, with two independent signals. From the electromagnetic signal, we use the radius. The light is redshifted and we can reconstruct the... The we can reconstruct the position and from the gravitational wave, we're going to reconstruct a luminosity distance. This is a study that has been done because the event GW170817 was a coalescence of binary neutron star event and it was simultaneously observed by the LBC, like a Virgo, but also several electromagnetic observatories on the front there, BCNR, it was Fermi and Integral, but there was a lot of observatories. Was a lot of observatories that have been following this event over days and months, and looking at the afterglow and doing some astrophysical research. It's a very local event, it's at 40 megaparsecs, which is why we've seen it so beautifully. But it's not as strong because we could see it so beautifully, it was close, and therefore we do not expect to have a lot of community. Effect to have a lot of little effects. It's still very important to check what we can do. And one of the studies that has been done is to see: is there a leakage of the gravitational radiation that would occur to extra dimension? Then we would see the source, we would construct a distance of further than what we expect because the strain is proportional to one over the distance. And if we parameterize, if we have not the luminar, the gravitational. Not the gravitational wave luminosity distance that is equal to the electromagnetic luminosity distance, but if we parameterize a term for the gravitational wave leakage that is equal to this extra term here, where we have d is the number of spacetime dimension, n is a transition step, SMRC is a screening scale where this occurs. Then we can put some constraint about the number of extra of spacetime dimension. And we see that for now, we're consistent with four, this is the white band. Consistent with four, this is the wide band, depends on the assumption that we do on the screening scale. But we're ruling out a lot of more than four dimensions. Now, there is a question, what can we do if we see events that are actually further? And the Zveki Transient Facility has recorded a signal about the same time that GW190521 that. TW190521, that is one of the furthest black holes that we've seen, which is at Z equals 04. So it's not thought that these events can be actually associated one to each other, because the event seen by ZTF is actually really on the edge of the 90% sky localization control, and it's a binary black hole event. So if you want to have an A binary black hole event. So, if you want to have an electromagnetic signal, it means that you probably have you would need to have an accretion disk around it. It would be a turbulence that would create the electromagnetic signal. It's not physics that is as it's not as straightforward as in the binary neutron star case. So, most of the thought of the community about this and my two is that those two events are actually, this is not a multi-mesander event, those two events are not associated. Central events, those events are not associated. So ZTF event is coming from another source. But we have done the study of saying, okay, let's imagine that it was, and then let's see what we can do. If we were to detect actually a type of new multimicenter event that comes from binary black holes in accretion disk, what type of physics we can learn with this for the friction study? So we have redone the study with the The study with the number of space-time dimensions. And because new physics can also impact the measurement of the cosmological parameter, this is a joint feat that we have done of the Hubble constant, the matter density, and the number of spacetime dimensions. And here we have assumed that the transition stiffness Rc is actually much smaller than the electromagnetic distance. Um, electromagnetic distance. Therefore, we can see this simplifies the equation where we don't need to take some assumption about the value of this stiffness and also the the also sorry this other transition stiffness is not uh entering the equation. This is why we don't infer it. So, what we can see here is that in the one signal. Here is that in the one sigma control, we are still going with d equal to 4, which is what is shown here, but we can actually have when once we let the Hubble constant vary, what I see is that we actually don't have such a good constraint because we can go to almost five in terms of a load value of the distance. It's about 4.7 at once. 4.7 at one sigma. What we recover as a value for the Hubble constant and the matter density is consistent with Planck results. We have done some other studies that were to check other parameterization that contains two parameters and therefore that requires two events to be inferred. And this is a parameterization that has been proposed by Bell Cassem and other researchers from the And other researchers from the University of Geneva, where they have looked at the modification of the luminosity distance, of the difference between the gravitational wave luminosity distance and the distance control from the electromagnetic signal for different scalar tensor cells. And they have inferred parametrization that depends on this xi term and this n-value. And this n-value that enables to check several stellar tensor series of gravitation with a single parametrization. So this is equal to gr when xi is equal to one, or in general if n is going, is being also very large. So we have we have measured this, we have measured this parameter still using Parameter still using the same analysis framework, where we also vary the Hubble constant and the matter density. And we see that we infer a very small value xi, and we have almost no sensitivity actually on the value of n. So this is not something that is very well resolved right now. It needs better accuracy, but the results are consistent with general activity. No, there is different ways to parameterize friction terms, and some postulate that it actually depends on the evolution of the dark energy content. And therefore, there is this alpha n parameter that is the friction term, is going to depend on the dark energy present as a certain redshift compared to the dark energy around us right now. And this would create a modification of the luminosity distance. Create a modification of the luminosity distance following this equation here. But this is something where there is only one parameter, that is Cm. And therefore, we can compare the constraints that we obtain from GW170817, so the close by BNS event that is in green. And we can see that for CM, for example, we have almost no constraint with the green curve. Curve and we compare with GW19 of I21, so the event that is further, and that is probably not a multimeter event, but that we assume to be. And then we see that at larger rate chip, then we have a constraint in blue that is much more resolved. And then the joint one is slightly better, but it's very similar to the blue constraint. So this is really driven by the large redshift measurement. However, we see that for H0, We see that for H0 already with the BNS, we have a good constraint, and we actually have almost nothing from the further event. So those are analyses that have been done with the current detections, and there is a question of what we can do in the future, in which way will we be able to better. To better to those are quite preliminary studies that show that for no existing thing is consistent with GR, but that's relatively large posterior. We don't expect to see deviation at this level of sensitivity. What can we do before we actually go to the next generation of cross-base detector? And what is and one thing that is possible is that we detect a lens event. We at advanced LIGO and vergosensitivity, we expect to have one. And regal sensitivity, we expect to have one lens seven per year, of which one-third should be quadripley lens, and therefore, what we see actually is different signals arriving at different time in the detector, and the fact we have different signals enable us to have a much better reconstruction of the distance with a 10% accuracy. If we have a much better reconstruction of the distance, then we can associate the event with the host galaxy if we have. If we have a sufficient enough galaxy category, it depends where the event is. And in this case, we can have a multi-messenger event, multi-missener information without a certain electromagnetic signal. So this is about doing tests of general activities that are with multi-missenter events that are less based on timing, as a lot are, but on the distance, as we've been showing before. And here we've been, and we can also see events that are at larger reject with lens. Are at larger project with lens demand. So we have been studying on the bottom here the difference between the modified luminosity difference in gravitational waves as a function of the redshift. And we can see that for almost everything it goes, well, for all the events, it goes, the difference is larger at large redshift. And on the right, you can see a study by. The right, you can see a study by Finke and other researchers from the University of Geneva, where they see how their model in XI is actually better resolved with cradlerously lensed events at increasing redshift. So even with one event, as you can see, detected at Z equal 1.5, you can see the constraint is much better than what we have at 0.2 or even 0.4 that is correspond to a further statement, right? Want to have further statements right now. So, this is a study that we are looking also with a researcher at the University of Utrecht about studying how we can use quadrupled length events to better constraint two different gravitational wave friction parameterization and perform better tests of generativity with the current detection. With the current detectors. And I would just like to note that, compared to the equation that I've shown before and has been used in the literature up to know, there have been recently a new derivation by Corman et al., where they see that there is actually a dependency of the redshift that is not appearing for it's because of the modification of the redshift, it is impacting at large redshift, so it is not going to. Shift. So it is not creating a sensible modification for the binary neutron star that is in the mega-parsec range. But as we are going to a larger redshift, then we are using this updated parametrization to take into account properly the modification of the luminosity distance. Now, if I move to the speed of gravity, when we have detected the binary neutron star, it was a transient event, and then we can very well see. And then we can very well see on this image here that from with the spectrogram on the bottom from the LBC, the spectrogram is the frequency of the gravitational wave as a function of the time and you can see the intensity in the pins. So you can see gravitational wave events. And on the top you have the light curve from Fermi. First in the 10-50, so small KV range, then 50 to 300 keV range. To 300 kV range, and then by integral. So we can very well see the delay that is on the order of two seconds. And from the delay, we can compute, we can constrain the speed of gravity that we see. We see a deviation from the speed of electromagnetic wave that is on the order of 10 to the minus 15 at most. So, this is one of the strongest constraints on the speed of gravity. And further than just setting bounds, we can use those bounds to actually check the existence of space-time symmetry breaking. If we have a breaking of Lorentz or CPT symmetries, then it can induce a modification of the gravitational wave speed. And there have been an effective field theory framework that has been developed. That has been developed to explicitly search for violation of Lorentz invariance or some CPT breaking. It's called standard model extension because it was first developed to perform sort of Lorentz invariance violation with particle physics, but recently it has been developed to be applied to, well, it was developed since a long time to be applied to a gravitational sector for solar system tests, for example. For solar system tests, for example. But recently, there was also gravitational wave radiation that has been included. And what you can see is that basically it consists in having the linearized GR Lagrangian to which new fields are added of increasing mass dimension and taking care of gauge invariance. Then, according to the value of the smooth fields and their mass dimension, so D here is the mass dimension, dimension. Here is mass dimension, small space time dimension. It can have different phenomenology, and when you look at d equal 4, what is going to so this corresponds to this s field, you just assume the other one are null for this, if you only look at this mass dimension, then what will happen when you add this term in the Lagrangian is that you will have a different gravitational wave velocity, and this is going to give you the impact on the gravitational wave velocity. impact on the gravitational wave velocity is given by this formula here where you see this term s is a term referring to the gravitational sector and c it corresponds to the electromagnetic sector so with the gravitational wave we can constrain those lorentz violating parameters and on this table you can see the constraints that have been derived from the observation of the binary neutron star that are already with That are already with one event better than the constraint that were performed with pulsars. They have been also tested of the equivalence principle, but they're quite stringent, but not yet competitive with Shapiro delay measurements at this time. So looking at the mass of the graviton, there have been several proposals where gravity is massive. They have different motivations. They have different motivations, such as explaining the acceleration, the accelerated expansion of the universe or other theoretical motivations. And what happened, and there is different parametrization to look at the effect of the graviton mass. If the graviton is massive, it can induce a dispersion of the gravitational wave signal and we can And we can see this dispersion in the energy relation that is not going to be just the first two terms as in GR, but where we had add this extra term with A, P of alpha, C of alpha. Adding this extra term is going to create a frequency dependent dispersion of gravitational wave that is actually this is wrong, it's not anisotropic, so it's isotropic. I will correct this and is polar. Correct this and is polarization independent. But it's going to induce a deformation of the whole signal. So instead of having a gravitational wave signal, as is shown here in red for coalescing binaries, it's actually going to modify this morphology depending on the frequency to give another signal. And therefore, by parametrizing this modification, Parameterizing this modification by introducing this extra term and looking at if we see actually modified waveform, we can constrain those extra parameters. So this is a constraint that has been obtained with the GWTC2 catalogue. So the article on the test of GR with the GWTC3 catalogue has not been made public. Catalogue has not been made public yet. It should be made public very soon, probably next week. And currently, the constraints that you see in blue are the latest. And we can see that what we do is that we are actually measuring this parameter A alpha will have a different value according to the value of alpha because you see that it depends to alpha is the power of the momentum. And it's a And it's a continuous parameter, but for feasibility, we evaluate it at a specific value at half integers, and those specific values can be mapped to certain theories. So for a value of zero, we can extract the mass of the gravity, the constraint of the mass of the graviton. That is now 1.7610 to the minus 23 EV over C square. And that is the best concept. Is the best constraint that is comparable now with improved solar system task that has been recently released. And when we go to two, you can see that we do not measure the value at two because there is a degeneracy with the coalescence time. It's just going to create a shift in the waveform that cannot be measured. And this is why you also see that the constraint is not as good around two because. As good around two because we're getting close to the degeneracy and is getting better further from two. If we have alpha equal to three, this can be mapped to doubly spatial relativity and alpha equal to four can be mapped to different proposals such as extra dimension or Hora values sheets and non-communative geometry. So, this is currently the constraint we have on massive gravity, but as you can see with this parameter, Gravity, but as you can see with this parameterization, with a large range of other proposals. Now, I'm going to move to the last part concerning the mode mixing. And I'm going to spend a little more part discussing this because this is the end of this I've been working on during the last year. And I'm going back to this effective field theory framework where we are deriving a phenomenology for the breaking of space-time symmetry. For the breaking of space-time symmetry. And here I'm not looking at the mass dimension four that was inducing a difference of velocity for the gravitational radiation, but to mass dimension for higher, like five or six. And this is actually going to create a dispersion effect that can be mapped in a part to the dispersion effect, dispersion parametrization I just shown, but that is going further. Is going further. What we can derive from the addition of those new fields to the Lagrangian is that it's going to modify the full momentum according to this equation. So it is whole new term is new. And those different bar sigma terms that you can see are actually including the coefficients that are the components of the fields that are added to the Lagrangian. To the Lagrangian. So you can see that the Ki field corresponds to the equal 4. So they are not going to create dispersion in this case, but the Ke, Kb and Kv that are 5 and 6 are going to create dispersion. And there are the coefficients that we are trying to constrain when we are trying to present bounds on violation of On violation of Lorentz or CPT invariance. Here for D equals six, so the Ke and Kb terms, it's CPT even, there is no CPT violation, only Lorentz invariance violation. But for Kv, that is for my dimension 5, then there is also the presence of CPT violation. So in the end, this is going to modify the gravitational wave signal according to this big equation. According to this big equation, so H plus, here, H cross, here, and there are all GR signals and they are going to be modified by the terms that are in front of it. What we can see from analyzing this equation is that first it depends on the size, sorry, on the polarization of the gravitational wave. So, this can create a different effect according to the polarization. It's analogous to a barefringent effect by consequence. And this effect is all those parameters delta, beta, t var theta, var phi are actually proportional to two and the var signal that I presented in the previous slide, where two is a cosmology term that is going to take into account the redshift. So those two, we have seen, depends on omega, that is the frequency. So it's a frequency dependent dispersion, but also on the spherical harmonics. On the spherical harmonics. So it's those theta and phi are different than the var theta and var phi here that are those are alternative, those are space-time symmetry breaking parameters. Those theta and phi that are here are actually the scale localization. So it's actually an anisotropic effect. And this is why I'm saying that this is an extension of the previous parameterization is because it includes anisotropic and polarization dependent effect where the other one was isotropic polarization independent. Isotropic polarization independent dispersion. And finally, we have our parameters that we want to constrain. And what we do is that we actually constrain one mass dimension at the time when we do this analysis, mainly to ensure feasibility and sensitivity to the parameters. So if we look at the mass dimension 5, where dispersion starts and where we have possibility and Lorentz environment violation, then we have 16 coefficients and the parameter beta. And the parameter beta that corresponds to this parameter beta that you have here is corresponding to is actually when you derive all the spherical harmonic sum is going to have this expression. So we can see very well here the dependency on the scale localization and the numerous coefficients that are parametrizing the deviation. If I look at the modification of the gravitational Look at the modification of the gravitational wave that I can have. In blue, there is a gravitational wave as predicted by GR. And in black, it's the gravitational predicted by GR. But in blue, you have the modified signal. And what you see is that if we have one of the KV coefficients of the order of 10 to the minus 13, then the deviation is very strong. It's at 10 to the minus 14 is very hard. 14 is very hard to see it, and 10 to the minus 15 is almost the same gravitational wave event. And this is very consistent with what we've seen when we've done sensitivity study with injection and event and full inference of the data using the LIGO and Virgo inference algorithm. Then we see that with a single event, we record a constraint that can be seen on the order of 10 to the minus 13. 10 to the minus 13. This is this. We have injected a value of 10 to the minus 13 and we report, but 10 to the minus 13, we start to put constraint from 10 to the minus 14. So we are now performing the analysis of this event and we are analyzing the events from the three catalogues of events. So I'm showing here preliminary results. So I'm showing here preliminary results with 20 events from the GWTC2 catalogue and what we can see is that as we have predicted with sensitivity analysis, there is about we have an individual constraint for event of about 10 to the minus 13 on the coefficient and the combined limit is about 10 to the minus 15. We don't have all the events but we also see with the line in color that there is actually That there is actually some deviation that are seen from certain events that we are investigating. It's extremely likely that it's due to degeneracy with GR parameters that we are observing and not to violation of GR parameters. And this is why this study is important because some measurements have already been done without using the strain, with using posterior analysis. Using posterior analysis and looking at the fact that if you expect to have a barifrangence effect, you may have a double peak appearing in your data because you would have the H plus and the H cross polarization not arriving at the same time. And from the non-observation of the peak, constraints have been established, but such analyses do not take into account the correlation with the source parameters. So when we do an analysis directly from the strain where we do a full inference of the source, We do a full inference of the source and the GR parameter, what we see that there is a degeneracy. That starts to be seen in other analyses that are published. And it enables us to understand in which case we can actually put constraints and in which case we actually have degeneracies with source parameters that we need to take into account in the limits that we show. So, in conclusion, this was an overview of the different An overview of the different ways to test GR during the propagation of gravitational waves. There have been numerous proposals, so I have tried to give an overview of the different aspects of the phenomenology. There are more existing, there are more studies, there are sensitivity studies, other already performed study with analysis that exist out there. I encourage you, if you're interested in the topic, at looking at some of the links that I provided to some of them are review articles that Some of them are review articles that provide a very good overview on the topic. And this is a very interesting topic because it shows that we can do things with gravitational wave radiation only, but also that multi-messenter events are very complementary. And that probably as we detect few more multi-messenter events, then we will have stringent improvements on some. Improvement on some of those tests. However, clearly the best is yet to come. The Einstein Telescope and Cosmic Explorers are a third generation ground-based detector that has been proposed, that are under evaluation, under study. And we can see here, for example, in blue, this is the maximal. The maximal redshift, the horizon of the ratio that can be seen by advanced LIGO. So, when we will have reached the advanced LIGO sensitivity that we have not reached yet. And in green, this is what we expect for the Einstein telescope and in pink for the Cosmic Explorer. So we see that we will have horizon close to Redshift 100. So this is a horizon, doesn't mean you see that this band means that 10% will be detected and this band 50%. This is bent 50 percent. But clearly, it's with the next generation of interferometers that we will really reach a precision era and that we will be able to perform the most stranger of test of fundamental physics. However, we need to prepare them now. I think it's very important to start to do some study, not only sensitive study, but to look at what is in our data first to do consistency test, but also to prepare the analysis that we will. Prepare the analysis that we will do in the future. Of course, there will be LISA that as a space-based detector will have increased sensitivity, and several studies also ongoing with this for LISA as well. So, thank you for listening, and I'm ready to take any questions.  Okay, I see a question from Michael. Are there any lessons learned here from our electromagnetic observers, specific need for constraining GR with multi-mesander event? Well, I think the main lesson is we need more multi-missener events, but that's not going to help you. No, I think that actually there will be. I think that actually there will be probably refined analysis we can do more analysis with multi-messenger studies because right now we are assuming GR for detection of both gravitational wave and electromagnetic counterpart, which makes sense. I think it's interesting to have a look of if we don't assume GR, what does it Assume GR, what does it impact on those searches and maybe design new searches? I don't think it's something that I'm going to ask a full follow-up low-latency team to look at because you just have enough work, assuming GR, but that's something that actually something that we start looking into at the APC and that I think is complementary to what is done for regular ectomenetic follow-up. Thanks, Laila. Laila, can you hear me? I think I can. Okay, if could I ask a question regarding your talk on Let's Mark. Regarding your talk on Les, Mark, who you wanted to go ahead first. Okay, maybe I'll just go ahead anyway, Leela. Can you hear me? All right. Okay, I was wondering, so you mentioned about this one event where you do see a deviation in your K parameter, but it's likely, you also mentioned it's likely due to a degeneracy with GR parameters. And I was wondering. And I was wondering. So, two things. Firstly, what's I'm assuming that these are universal, so you can stack these quantities together to get a joint measurement. Have you done that? And secondly, if there's a degeneracy, what is it degenerate with and in what post-Newtonian order? So, when I mean degeneracy, I was thinking about degeneracy with the source parameters. So, basically, we see that. So basically, we see that we don't recover the same source parameter, and that there is a coupling basically between notably the inclination of the inspiral. So this is what I was talking about, not specific PN order. It could be, so I think it could be an interesting analysis to inject a signal like this and to try to recover it with, for example, For example, with a parametrized post-Newtonian framework, but we have not done this study yet. And the first question was, yes, I started to do a combined study. It doesn't, it's not as, it doesn't pull that much with a combined constraint. It's still centered, it's still consistent with zero. But because just we're waiting for a few results of the We're waiting for a few results of the inference. I'm not showing the full combined result. Okay, just another quick follow-up. So is the, so you said it's degenerate with inclination, which means are these deviations in the amplitude then? So the modified signal, the modification is going to, it's a frequency dependent dispersion, but as a frequency dependent modification. As a frequency dependent modification, but is going to change both the amplitude and the frequency of the signal, right? So, maybe there is some dependence of inclination in the phase, and that's what I guess I'm a little confused about. Yeah, it's something that we're investigating, as I'm saying. So, we're seeing some mainly some degeneracy with the inclination of the binary. The inclination of the binary and with the spin parameters. The spin parameters were more expected. We're trying to understand why we don't recover all the time the same inclination. It might be just adding an additional degree of freedom in the inference. Yeah. All right. Thank you. Thanks for the good talk. So lie live. Lila, I have two quick questions. The first question is: the equation that you showed with the modifications of GR, is that the most generic equation you can have, at least linear order? Yeah, this one. Yeah, this one. Sorry, it's molecular, I think. Yeah, that's, I think, that's the most generic that I know where you can take into account, where you take into account that you. into account where you take into account the different um in the in the propagation equation the different uh phenomenology possible and the second and this the second quick question um so you you can set limits on the number of dimensions Limits on the number of dimensions. Can you also set limits on the size of the possible excellent dimensions? Yeah, there are different parametrizations for that. And when I showed this, you can see that in a way, RC can be computed, can be seen as a scale where the extra dimensions enter. And some parametrization take it really RC to be. Take it really RC to be the size of the dimension. It's not exactly the same equation. And I think I have, I can give you a reference of an article where they constrain the size of extra dimension. I think they just assume there is a fifth one. But they can derive a modification both of the distance and of the time deal, of the different time. And they actually derive. And they actually derive the constraints from the difference in time arrival. So we try to reproduce it with the distance, but actually, the distance is not giving enough sensitivity. I think we don't have a good resolution for that. So yeah, there are several parametrizations. We'll look at this at truly a dimension size because this is only for non-compactified extra dimensions. Thank you. Thank you. So, if there are no other questions. Oh, yes, Sean, go ahead. Hi, Lyla. So, one of the interesting things was towards the end of the talk when you talked about Cosmic Explorer and newer third generation detectors. So, I was just wondering: are you also doing some sort of waveform systematic studies? Because this is going to be more important for more sensitive detectors. Sorry, okay. Yes, absolutely. That's something we started to do, and I totally agree is going to be very important. I think we're seeing it actually with the latest detection that it's obviously when you want to, as long as you implement a new DRFF to be a modification of an existing signal, then you assume that your existing signal is. Then you assume that your visiting signal is, in a way, the truth, while we know that it's not really, and we absolutely, I don't know if you're working on this specifically, but that's something we're starting to look at and that I think we should look further. Yeah, thank you. Any other questions? All right, I think we can thank Lila again. Thank you very much. And we can move to the next talk, Michael Kaflin. And he's gonna tell us about inference as a service for gravitational wave astronomy. Astronomy. Michael, are you there? I am. Can you hear me? Can you? You can hear me, right? Does someone want to raise their hand? No? Yes?