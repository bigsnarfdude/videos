Thanks. Thanks to the organizers. It's great to be here and also great to meet up with all of you in person rather than over Zoom or something like that. So it's a great opportunity here. So I'm talking about this paper which was presented in a problem. Presented in a promise last week. And the authors are the same set of people as what Ishan presented on Monday, but the topic is rather disjoint. So, Ishan, you know, he presented on Monday. That's myself. Logan Graut is moved to industry now. And Sharakta Brian Poor completed PhD with Swami last year and he is now postdoc with Neil Olwar and Tatsi Beek. Farworth and Tlassy Gig. Right, so I'll be primarily talking about unweighted graph. And we should think of the vertex set as being partitioned into. Partitioned into terminals and sterile nodes. And thanks to Zwandi for the notation which I am also adopting. So, k is the number of terminals, n is the number of vertices. So, this k pattern. So, this k parameter, the number of terminals is going to be small. So, just to give you a kind of theme of what we are doing in this paper. So, that was proxy. Last week. So, just to give you a kind of idea of what the paper is about. So, I guess half of us are from network design, so everybody is familiar with the Steiner tree problem, but the other half may not be. Anyways, let me just try to Um So that's an old algorithm due to Reyfuss and Wagner, 1971. 1971, not yet. So if so, I'm just sort of connecting it to this parameterizer. It to this parameterized complexity. So if we think of this as some function of k, this is polynomial in n. So that's FPT10, right? As Zwande had told us in the previous talk. So okay, so the standard Okay, so standard tree means we have to find a minimum cost connected subgraph of G that contains all the terminals. So, it may not be a spanning tree, but it should contain all these terminals. This is NP-hard problem, but when k is small or constant, we do have f b t right. So since this So since this is a rather active area, this whole network design and parameterize complexity, we could ask the question, what about styler networks with higher connectivity? Right? So this is FPD. So And the one-word answer is nothing. There is nothing. And so you could ask why, why not? Or why or why not? Now this is an excellent question to ask Chad GPT. I didn't try it, but it is a good question. But what I'm trying to do in the talk is to hopefully give you a more illuminating answer than what you get from Check. Get from Chinese. Manf means manfin now. Sorry? Manfin means manfin now or nothing new. Yeah, it is open. Yeah, it is open. So we don't have a hardness result, W hardness result. Not really have it. Okay, so let's just shift focus a bit. So there's To this, what I call H-Steiner cycle problem. So the setup is the same. We have most of the talk I'll be talking unweighted, right? And I'll be focusing on optimal algorithm, one that finds. Optimal algorithm, one that finds optimal algorithm. So then you say that the talk doesn't belong to a hardness and approximation workshop. But the thing is, when we go to the weighted version, then rather than optimal algorithm, we have F betas. So there is an approximation for the weighted code. Anyways, so K-Steiner cycle. Same setup there. So does GF cycle contain alternates. So, of course, there is the So of course there is the decision or feasibility question and there is the optimization question. So and by the way what I mean by cycle is the usual one the circuit. So if you delete an edge from there you get a path with all vertices disjoint. So it's not connected already in graph. It's just the usual set. So So, feasibility there is actually a polytime algorithm. So, think of k small, k constant, right? So that's a good thing. So from the graph minor theory and Robertson-Siegel's results, we do have polytime algebra. But for the optimization question, so if you want a shortest case panel sorry, or not? Shortest or minimum length. So deterministic, there's nothing, but randomized, there's a very nice Algorithm from Soda about 10 years ago. Randomized. So that is a randomized FPT algorithm, right? So it's a very nice FPT algorithm. Uh so I I maybe spend a few minutes on this here because what we are going to do is we are going to address the two connected Steiner network problem. So, we are going to address the two connected Steiner network problem and we are going to use this as our key subroutine. As our key subroutine, right? So, as we'll see, once we have this subroutine available for us, it's kind of piece of case. So, I'll just spend a couple of minutes here. So, Joseph, you're saying disjoint parts is sitting in the case time of cycle, or disjoint parts are sitting in the cycle. Exactly. So, just a couple of minutes on this. Couple of minutes on this here. So, what's happening is that this case annotation problem, well, okay, so back up. This major theorem, so you know, the storyline behind Graph Minus is that they were, Robertson and Seymour were. Robertson and Seymour were interested in this Wagner's conjecture, which says that if you have an infinite sequence of graphs, then one of them is minor of other in that sequence. If you have this infinite sequence d1, g2, g3, there will be a pair di, dj such that let's say di is the minor of dj. So that's the storyline. But actually a major concept. Major consequence is the disjoint paths algorithm. So it says that if you have k pairs of terminals, so let's say S1, T1, S2, TT1. And if you ask for For paths between these SITI pairs that are just disjoint from each other, then that actually is characterized and moreover a polytime algorithm is given by Graph Minor theory. So in fact, one could sort of flip the storyline and say that Graph Minor theory is actually Is actually addressing the disjoint parts problem, and Wagner's theorem is a kind of consequence. Once you develop all the machinery for handling disjoint parts, you also get values here. So you could actually make a storyline like that. So So you just guess the ordering of the terminals and then ask for this job passed, right? That's what we Yeah, yeah, yeah. Because k is constant, let's say, right? So you can try out all possible sequences and then it's just this one path. So I guess the question I had, and I asked some of the experts in graph miners, is that given that you have this feasibility algorithm here. Algorithm here, can't we exploit it to handle the optimization? And the answer is no. I mean, the simple answer is no, because so you see the whole theory is being built to address a feasibility question. And somehow it's not at all going into the optimization. Going into the optimization. Right, so let's take a quick look at the so this is PHP So incidentally, as far as I know, if we are looking at three disjoint paths, there is no combinatorial algorithm for this. There is one through graph minus, but there is no combinatorial. Is that right, Jens? Shortest? Three, three no not shortest. Uh just three disjoint paths. I want to check feasibility. Check feasibility graph minus is common training. Sorry? Graph minus is common training. Okay. So let me put it differently without graph minus. Is there any way to okay? So let's take a quick look at what VHP does just to get some insight. So this is. So they have the Sura paper and also it's in Nina Castleman's thesis. So what it does is, very briefly, we are going to iterate So we are trying out all possible length for that case standard cycle. So we have so it's like this randomized matching algorithm that kind of split it. That kind of split it. So we have a finite field Q Q is equal to the and we simply pick a random label for each edge, right? So Joseph contains a cardinality. The cardinality case? I'm just talking about the cardinality case, not weighted. So in the talk we'll be really talking about the cardinary. Bit fuzzy, we might use some weights here and there, but we'll get there. So choose random. And then what they do is they compute a Wach polynomial. So they compute this Wach polynomial. So think of it as some polynomial coming from those guys. This is actually a set of boxes. This is actually a set of hops for you by dynamic programming. And then you just look at that, right? So if it is if this guy if this guy evaluates If this guy evaluates to non-zero, then you say yes. Then you say that there exists case standards, I hope. And if it is zero, you say no. So you can. So, so you just keep it a different. So, that's the BSP algorithm. Okay, so let's go to our paper. So, I'm just going to discuss this one. So, the paper has essentially two parts. The one I'll talk about is the two-connected design. The second and more functions. Design. The second and more complicated part is somewhat connected to what Ria and Kishan were talking about on Monday, the flexible graph connecting structure. But I'm just going to talk about the usual setup. Do you have any questions? Right, so the point is that once we have the BHT, Have the PHT subroutine available to us, it becomes a piece of cake. I mean, we can't do deterministic, we have to be randomized, but it is a piece of cake now. Sorry, what? What is R of scale? Yeah, I didn't get it. Uh, yeah, I didn't get into that. So, uh, this CL is going to be, I'll just explain it, it's going to be a set of closed walks that contain all terminals. Of length L. Yeah. So it's a set of closed walks of length L that contain all terminals. And that polynomial is what it does is for each walk. Is for each walk, you just take the product of the r values and then you sum up the thing for the different walks. So that's R of C. Okay, so think of H as our candidate solution subgraph, right? G is our big graph, and H is our solution. Orbit graph and pH is the solution. So, another way is it's a connected graph that has no button ones. So, now think of pH as a solution to a problem, right? A solution to our problem, right? So we want this two-node-connected graph which contains all terminals, right? So we have this pretty easy decomposition lemma. And again, I'll skip over some standard notions. So what it says is that this H has an open unity composite. As an open middle decomposition with at most k years, such that, moreover, the number of high-degree nodes, which is what I am writing here. High degree means 3 or more, right? So high degree is 3 or more. So what this little lemma says is that the number of high degree nodes is going to be at most 2 k. So, again, you know, just a kind of hand-waving proof that you Giving proof that you so we have these terminals sitting around here, so we find a cycle through two of them, right? It could cover more, but we want at least two of them in our cycle. So that will be our first year, right? So year one. And then what we'll do is we'll pick a terminal outside and we'll ask for two disjoint paths. For two disjoint paths from that terminant to this base graph, right? And you could pick more terminals there, so that's fine. And so on. So you just keep on hooking up these outside terminals to your base graph. You need at most as many as number of terminals, and the high degree nodes will show up only where those things are hooking up. Things are opening up, right? Okay, so just one example to keep in mind. So, okay, so now I'm getting a bit fuzzy because I'm going to. Getting a bit fuzzy because I'm going to put weights on this one just to make it easier for us to digest. So these are the terminals here. So let's call it T1, T2, T3. And we'll put, so this is H, this is C V cost of H. Now we put some more edges and these guys will have a bigger post. So if you just I won it a bit, so those are the three terminals, right? So if you just I borrow it a bit, what you see is the Bit. What you see is the optimal is this K23 with those two Skyner nodes. And that cost is 30 plus 3, right? On the other hand, if you run a kind of naive algorithm, what Nahib algorithm, what could happen is you'll end up with, so you know, if you just focus on the terminals, right, and look for a two-connected graph there, you run some kind of greedy algorithm. Maybe what your algorithm will do is it will pick this guy and the one-on-one, and it will pick those two terminals. So this is the first year, 19. And then you have to hook up the remaining terminal. The remaining terminal. So there. But you see, here we are doomed. The trial algorithm we are trying is doomed because you see it'll just pick those A's. Okay, just some kind of intuitive explanation here. And the cost would be at least 40. So what our algorithm does, I'll try to conclude in two minutes or so. In two minutes or so. What an algorithm does is it guesses a set of Steiner nodes which will serve as these guys. So I'm kind of writing out the pseudocode, almost the same. So we'll start with. So, we'll start with think of that as our candidate solution, right. Then, for all S subset, V, so think of these as the high degree nodes, our guess for the high degree nodes with S okay for So, those are the number of years we are guessing, right? So, that's high-degree notes, that's the number of years. For ordered partitions, so that's the number of sets in the partition that I. Number of sets in the partnership that I'll be able to write down the rest. So, what we'll do is we'll compute. So, here is where we are using the So here is where we are using the VHD cycle as the thing. So what I've done here is I'm trying to guess the terminals that go into each of these years, right? So we have these maximum of k years. So what I'm doing is I'm trying to guess the I'm trying to guess the terminals that go into year one, the terminals that go into year two, and so on. So I'm trying to guess the, so we are going to try all guesses exhaustively. And then what we do is we run VHT cycle with the terminals that go into the first year and so on, like UVN with VHP power. Of right, so again, I'll just give a bit of hand maybe because to folks who are working with this, I hope it's pretty transparent what's going on. We are just guessing the high-degree nodes. Guessing the high-degree nodes, partitioning terminals plus guess into little sets of terminals that are supposed to go into each of those gears, right, those gears. And then run BHT algorithm to actually string up things appropriately. So that's a whole algorithm. And a little bit of analysis shows that it runs in time. Analysis shows that it runs in time n to the p. So this is XP running time, but it's not FPT, right? And we had got this result about a year ago, and we have been off and on trying to go. Trying to go further, but go further in the sense of either show FPT or show W hardness, no luck so far. Thank you.