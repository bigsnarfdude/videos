Thank you so much to the organizers for inviting me to talk at this conference. It's been a fun, really, really fun two days. Lots of fantastic talks. So I'm really enjoying it. So I'm going to tell you about some of our recent work on using deep learning models for understanding immune cell differentiation. And as you'll see, it follows a lot of the themes that you saw in the first day of the conference. So, but first, more broadly, I wanted to first introduce our research of my lab a little bit. Research of my lab a little bit. So, in the last six to seven years, since I've started my own lab, we've been really interested in questions around genome interpretation. So, in one direction, which actually I won't tell you much about today, we are really interested in understanding the impact of genetic variation across individuals on all sorts of molecular and disease phenotypes. So, some examples of recent work include models for identifying a small For identifying a small set of causal variants in rare disease settings, where we start from a much larger set of possible candidates, and also models for modeling the impact, the propagated impact of genetic variation across multiple layers of cellular phenotypes, for example, gene expression and epigenomic measurements and things like that. In the second direction in my lab, and this is the last three or four years, we've been really interested. Years, we've been really interested in understanding how the same genome in an individual gives rise to so many different cell types and tissue types. And this is based on a collaboration that we've had and you're going to hear about with the Immunological Genome Consortium, where we are asking these kind of questions in the immune system. So, yeah, the motivation, kind of as you saw, and I think Anshu did a really good job of giving the overview on this, the motivation is really to This the motivation is really to understand how sequence genomic sequence gives rise to functions. So, what are the properties of enhancers, promoters, and their combination that allows certain cells to have different, for example, expression patterns? And in this direction, I'm going to tell you about three kind of projects, one that's kind of concluded and republished, but two that are actually still ongoing. Are actually still ongoing. So, comments and feedback really appreciate it. So, in the first part, I'm going to tell you about Sasha's project on developing deep learning models for understanding immune cell differentiation across a very finely defined set of immune cell populations. Then I'm going to tell you about German's project on using similar types of models to understand cross-species differences in regulatory regions. Regions. And in the third part, I'm going to tell you about Shimming's project and how to better understand or how to make models that better capture causality and genetic variation so we can have better interpretations from these models. Okay, so let me first tell you a little bit about the data and then we'll talk about the models. And I'm just going to keep track of the time here. So the data for this comes from this collaboration that we've had with the immunological genome. With the Immunological Genome Project, or IMGEN for short, and in their latest data generation effort, they actually produced this really nice and fine-grained data set in the immune system. So, what they did was apply ATAC-seek or ATAC sequencing to 90 different immune cell populations that are isolated. So, we actually know what those cell populations are in adult mice. And adult mice's immune system is pretty much similar to the human immune system. So, a lot of these things are shared. system so a lot of these things are shared um so what i'm showing you here is basically a dendrogram of immune differentiation tree each node is a um is a cell type and we know their relationship with each other and i'm color coding these nodes um by the lineage they belong to so if you haven't done a lot of immunology work uh you might not be familiar with with these more fine-grained um kind of naming system but they um so this is to show So, this is to show that within lineages that you might have heard of, like T cells or B cells, there are very specific and diverse set of subtypes that are captured in this data. So here's another way to look at the data. So you can say we have like 90 different immune cell types, and for each one, we have ataxique data that basically gives us sort of regions that are accessible in that particular cell type. So for example, Cell types. For example, NK cell TR, these are the regions that are accessible with some sort of signal of accessibility. So we can parse this as the probability of that region being open or potentially regulatory in that cell population. So just one terminology note is these regions that we find with atoxic assay, we often call them OCR for open chromatin region because that's what the assay is capturing. So how do we model this data to kind of understand the rules? To kind of understand the rules of cell type differentiation, what's the difference between these cell types as encoded in the genomic sequence, one way to approach this problem is through the lens of supervised machine learning, so-called sequence-to-activity types of models. So the idea is that we can use sequences, genomic sequences underlying each of these OCRs as input to a machine learning model to predict which cell type these sequences are regulatory. Sequences are regulatory and/or active and based on the measurements that we have from our assays. And there's been lots of really exciting work in this direction. I've listed some of this at the bottom. So given this kind of inspiration, what we wanted to do in this work is to answer two questions. One is that, well, we know that models, these kind of sequence to activity type models, generally work well to define, for example, enhancer regions or differences between distance. Or differences between distant tissue types, but can we really apply them to kind of closely related cell types and still be able to extract sequence features that are distinguishing very finely related cell types? And the second question is, how do we robustly interpret models to extract features that are actually meaningful and tell us something about biology? So I'm going to tell you a little bit about each of these in this project. So why is it kind of training is hard? Why is it kind of training is hard in this setting? The training is hard because I call it, you have a kind of a class imbalance issue. It's not the classical class imbalance issue, but let me explain what I mean by that. So I showed you this dead nogram before. I actually didn't tell you what the size of these nodes mean. So remember that each node is a cell type. The size of the node actually is proportional to the number of unique regions that that cell type has compared to other. As compared to other nearby cell types. So, one difficulty that arises is that cell types that are nearby to each other in this dendogram, so, for example, T-naive cells and T-regulatory cells, if you look at regions that are captured in T-naive versus T-regulatory cells, which I'm showing you up here, you'll see that there's a lot of regions that are shared. But you know that functionally, these cell types are very distinct, that they have very distinct functions. So, this distinct function. So, this distinct function arises from a handful of regions that are only active and, let's say, T-na√Øse and not T-regs, and vice versa. So, if we actually are not aware of the small differences and throw everything to a machine learning model, what it's going to learn is what is common between cell types and actually what is not, it's not going to pick up on what's different because the thing that's different is captured by a small number of regions. So, in our work, which is published. So, in our work, which is published, and you can go and take a look at it, we kind of played around with different kinds of loss functions on how do we make models actually focus on the small set of regions that are different between nearby cell types. And we show that, you know, by really making models aware or upwing certain regions, you can improve your performance. So, what I'm showing you here is the prediction in terms of correlation of the model, what bottom model predicts, and the ground truth on real data. And the ground truth, unreal data, and some null data where we shuffle the labels to kind of just come up with a statistical metric to say how good are our predictions. And with this metric, we can see that, you know, for 60% of the regions that are in the test data set, we're actually making statistically significant predictions, which is much more than we could do if we kind of used traditional mean squared error and things like that. So one nice example was, so how Example was so, how well can model actually distinguish or predict attack signal across closely related cells? So, something that I forgot to mention actually, but it was in the picture is our model is a convolutional neural network model that it's a multi-task model. So, it makes prediction across all those 90 cell types all at once. So, for a given test sequence, we can make prediction across all cell types and compare to ground truth. Ground truth. If you do this, what you see is that even sequences that are activated, let's say, in T cells broadly, they still have a lot of fine specificity within T cells. And the model is picking that up really nicely. So encouraged by this result, we wanted to figure out, okay, how do we robustly figure out or dissect these complex models to understand what has been learned? And I actually really like this paper. Really like this paper that was recently published by NJMLR, showing that in the last two or three years, there has been a huge number of algorithms proposed for how one do a post-hoc interpretation of neural network models to kind of extract features that were learned. So it seems a little bit daunting that there's just so many different ways to do this, but it turns out that like many cases, that all of these algorithms can actually be understood as a form. Be understood as a form of a feature removal, um, with a feature removal recipe. And for those of you that are interested in this, I encourage you to look more into this paper. And essentially, that's the recipe that we follow. So, we came up with a very simple interpretation technique, which has one step that turns out to be very critical that I'm going to tell you about. So, our interpretation technique is something that the first two steps is something that's been routinely done. It's basically a simple no. Done. It's basically a simple node-based interpretation. So, what we're going to do is look inside the neural network model for each node in the first convolutional layer. We're going to figure out what PWMs or short sequence motifs that each node is capturing. And you can do this two different ways. A simple way would be just to look at the weight matrix learned by the filter and translate that to a PWM. And the second is you can. PWM. And the second is you can find out which subsequences activate a given filter and construct a PWM from those activating sequences. So either way, we can come up with a bunch of PWMs that the first layer filters are learning. That's the first step. The second step is we want to say, okay, how important is each PWM that's learned to the model's prediction? Because we know that high capacity model also learned lots of useless features as Um, features as part of training. So, to do this, a second conventional step is to do an ablation test. So, the idea is that you have your train model, you remove or ablate one filter at a time, and you measure the performance before and after ablation, and you just quantify how, you know, on average, how much your predictions change after you ablate that particular node. And so, that comes up, that gives you a measure of importance or influence per. importance or influence per node of your neural network. So in the third step, which we thought actually was really important for having a robust prediction, is actually considering uncertainty in the parameters that are learned by models. So we know that neural network models are non-convex and depending on your initialization, you're going to end up at a different local or local maximum or minimum. And so any, even if you have the exact same You know, even if you have the exact same training data set, if you train the model twice with different random inertialization, you're going to get slightly different parameters, which leads to slightly different features that are learned. So how do we incorporate this? Again, we had a simple strategy for this. List trained independent model on the same data set. The only thing that's changed is the initialization of the model. And then we're going to repeat this step one and two that I mentioned on these 10 separate models. On these 10 separate models. And then for each motif or PWM that's learned, we're going to say how reproducible it was across the 10 separately trained models. So with this, we can come up, we can kind of make a plot like this. So what I'm showing you here is each dot here is one PWM that's learned by one of our models. The color denotes how often do we find the same PWM across the 10 separately trained models. Across the 10 separately trained models. And on the x-axis, we have the information content of the motif. So, how different is it from random? And on the y-axis, we have its influence. So, how important was it when we ablated it, when we removed it from the model? And what we saw kind of repeatedly is that in these kind of models, often you find that many of the patterns or motifs that are learned are actually not reproducible. And you can see that clearly. And you can see that clearly. So, there's a bunch of red dots here. Those are the ones that we keep on finding across separately trained models, but then there's a good portion of them that we don't, we only find once. And supposedly, these are because of overparametrization of neural network, which is an important part of accurate training, but leads to features that are actually not that interesting. And the second thing that we showed was that if we actually account for this uncertainty, If we actually account for this uncertainty, then if we compare two different kinds of model interpretation techniques, we can close the gap in kind of what the two different techniques find. So uncertainty is really important if you want to extract robust features. And so once we kind of had this robust set of PWMs that the model finds, we can go and look them up in known transcription factors. And look them up in known transcription factor multi-databases to see if they resemble things that were previously discovered. And again, this was really interesting to see that a lot of these TWMs that were learned actually are known transcription factor binary sites that are important in the immune system. So it's kind of an internal validation of these motifs that are reproducible or actually biologically meaningful, which makes the next question more interesting, which is that we'll be new a lot of these. Which is that, well, we knew a lot of these motifs already, but neural networks presumably find interesting combinations of them that are predictive of accessibility in certain cell types. So how do we find those combinations? And I would say, I guess, for this is that finding combinations robustly is a little bit more difficult because the conclusions that we came up with is that any given combination is shown, is actually seen only a few times. Only a few times. There's only, let's say, there's transcription factor A and B that work together sometimes, but that sometimes is only, we're talking about five to 10 enhancers. So because of the sparsity of interactions, it's statistically hard to find ones that are actually robust. But what I wanted to show here is that how complex is the regulatory code and how many filters or equivalently, how many TWMs are used. Equivalently, how many TWMs are used to make accurate predictions for a given OCR? So, this is the distribution of how many filters are influential for making prediction for a single OCR. And what you can see here is that on average, two to three PWMs are used for making prediction for a given OCR, but there are OCRs in this long tail here that are a lot more complex, that require a lot more PWMs to be predicted well. UMs to be predicted well. So I'll move on to the second part. And I think there is a discussion part. So if people have questions, we can discuss these then on using these sort of models to understand differences across species. And so this question was motivated by some of the observations that we have when we were looking at results of the AITAC model. So one kind of data set that we found to use as external That we found to use as external validation data was atox-seq data across immune cell types in humans. So, remember that our models were trained on mouse. And the question that we asked was that if you take our model that's trained on mice and apply it to human data, how well can we make predictions? This is what I'm showing you here. It's similar to what you saw before. So, we can have predictions on the correlation and predictions of real sequences. Predictions are real sequences versus shuffle data, you'll see that. Well, obviously, the real sequences have a little bit better predictions. The predictions are not as good as we're seeing in mouse. Maybe that's expected. We're going across species. But again, this is a very hard problem that we're trying to solve because we know that regulatory regions between human and mouse actually don't align all that well. But the model still has found signal that's predictive in cross-species. So we went a little bit further than this and said, well, can we? Little bit further than this, and said, Well, can we use cross-species data as a form of data augmentation to improve accuracy during training? And what I'm showing you here is, you know, a model that's only trained on human data, this is the range of predictions we can get on average, correlations of about 0.43. But if we first pre-train the model on mouse data and then test and then fine-tune it on human data, we can significantly improve on that. But while we were discussing, But while we were dissecting these models, what we noticed was that, I mean, if you look at motifs that are important to mouse and humans, there are slight differences. So what I'm showing you here is the influence of PWMs that the model learned in mouse and in human. And there was just said that are more influential in mouse and some that are more influential in human. So our question was that, can you understand what's happening here a little bit better? Which led us to ask a new question. Which led us to ask a new question that wasn't kind of asked in this way before. So, we said: Can we train a neural network model, a convolutional neural network model that takes as input these sequences underlying OCRs and can predict species origin. So, you know, all I'm doing is now feeding the CNN sequences that are under attack peaks, and I'm asking it to predict whether or not that sequence came from human or mouse. Came from human or mouse. So, what should happen here? I guess if we go by literature, the answer is that we couldn't really guess what would happen. I had my own guess, but it was contradictory to guesses of other people. There's lots of different literature on this cross-species conservation of regulatory regions. There's some papers that say, especially human and mice, if you look at regulatory regions between those, it's hard to align them and there's lots of. It's hard to align them, and there's lots of rewiring of regulatory mechanisms. But there's other papers that say that there's lots of conservations, and pretty much all regulatory motifs should be conserved between them. So because of this, we really didn't know what to expect. But once I show you the results, maybe you can say, actually, we could have guessed what would happen. So what did happen is that we saw this model actually makes pretty good predictions. So what I'm showing you here is a chromosome leave-out experiment where we leave out data. Where we leave out data from a given chromosome in both a mouse and human and train on everything else and then test it on data from the left-hand chromosome. We can see performance in terms of AURC and AUPRC pretty much around 0.7 to 0.8. It's not bad. It's actually pretty significant. And we try this with different kinds of models, you see the same thing. So what's going on here? So to make sure that this is not just fitting to the noise in our data or something. The noise in our data, or some sort of batch effect. We also applied our train model on external data that was from a different tissue, different context, and we saw similar results. So again, we can make, you know, with the trained model on our data set going out of sample, we can actually make reasonable predictions. So what's going on here? So this allowed us to interpret this model pretty deeply. Model pretty deeply, and now we have a much better understanding of actually what is going on. So, what I'm showing you here is one dot for each PWM that's learned by the model. The size of that dot reflects whether or not it matches some known transcription factor binding site in external databases. And the color reflects whether or not it overlaps some repetitive element in the genome. In the genome. And what you can see is that basically we found lots of PWMs that resemble repetitive elements. And in hindsight, we should have known that there's lots of repetitive elements that have diverged between primates and rodents, for example, B2 elements and ALUs that the model is going to pick up on. But the interesting part was that that's not the full story. You see these blue dots that actually don't overlap. Dots that actually don't overlap repetitive elements. So, what are these? So, I would say there's probably two patterns to these. So, there are some really well-known motifs, for example, CTCF, that we see that the model finds two or three versions of them, one canonical one that's shared between human and mice, and one that's slightly more frequently occurring in mice. So, in the case of CTCF, it turns out that there's been a recent discovery that Been a recent discovery that there is a mouse-specific CTCF element that actually explains differential looping between human and mouse. But there was maybe two or three other ones that we found to follow this pattern. Another pattern that we saw was some motifs are just much more prevalent in humans compared to mouse. One example is the Foss June D motif. So I don't know how much, how am I doing for time? For time. There are not a lot of time. I think you should try to wrap up so we can have. Okay, so what I'll do is just skip this part and maybe go to just acknowledgements. Thank you. So for this, yeah, so this is work on incredible group of people. Sasha and Mark on the first project, German on the second. Shiming was also helping on the second. And Shiming was also helping on the second project. And our collaborators, Christophe Benoit and Kat from his app. So, thank you so much.