Truly marvelous meeting that they have put together. Chris, Margarita, Natasha, and Marielle. So by way of Javier, we will send to Marielle. And so I think we should end the first day with a round of applause for the fact that I'm a director and so have to organize stuff myself has nothing to do with this. Do with this. But I do take great pleasure from the fact that Natasha is a personnel in the center, and Margita was one of our absolutely amazing first cohort of those top state leaders. So we're proud of what they've accomplished. And so today I'm going to be talking to you about a barrier high problem for RNA branching. Many of you in Noah have seen me speak before, but actually I realize that some of you have not. And so I'm going to go through my stock opening slides. Stop opening slides fairly quickly because many number of people have seen it before. But what I work on is discrete mathematical biology, and so I am very interested in the interaction of molecular biology, which here, these are, this is actually for fluorescent bacteria pictured in a petri dish, so the biology is real. These strings of numbers are one of the ways that combinatorialists like to, so the way that biologists demonstrate that they understood a system is by. Demonstrate that they understood a system is by generating an experimentally testable hypothesis and showing that you've been run the experiment and you've really understood that. So, this is not an example of that. A way that combinatorialists demonstrate that they've understood a system is by, say, counting the number of objects that it has with different parameters. And so these are two counting sequences that will come up during the talk. The connection between these two is the site. Is the secondary structure of RNA sequences? And I thought I was going to be the first person to be able to say RNA in this beating, but Amy beat me to it. And so she had an RNA secondary structure pictured on her slide. So this is an example of an RNA secondary structure like the ones that were shown in the Petri dish. And this is an example of a combinatorial object known as a plain tree. I'll tell you, I'll give you a precise definition soon. But now you can really see the interaction between these two objects. Interaction between these two objects here. So, the biology on the one hand, the math on the other, and I really hope that they each inform each other. So they're just assignments out of it. So, you know, once upon a time, every RNA ribonomics person had slides like this in their talks to convince people that really RNA mattered. But now I just like to think we're just living in an RNA world. And so, if you're not aware of the fact that viruses, both their genomes and RNA, I buy. Both their genomes and RNA. You've been living on a different planet for the past four years. If you didn't get an mRNA vaccine, then I don't necessarily want to be in a room with you. And if you, you know, and there are lots of roles for small RNAs in gene splicing, editing, and regulation. So it really is, you know, a workhorse of a biological molecule, much more, not only, but beyond just mediating the production of proteins from the DNA. Proteins from DNA. Okay, so we're, but so in one way, RNA is very much like DNA. It is a nucleotide sequence, and so we have a four-letter, you know, four-letter nucleotide alphabet. U's are replaced, t's are replaced by u's, if that matters to you. It's not going to be important in this talk. And so, this is the sort of primary secret. So, the one-dimensional structure of RNA is like a DNA. The three-dimensional DNA. The three-dimensional structure of RNA is very much like proteins. They assume structures that perform functions. And if you want to understand the function of an RNA molecule, you really need insights into its structure. The two-dimensional structure is uniquely RNA. And so these are the intra-sequence base pairs that form. And so they form short helices that then arrange themselves in three dimensions. And this part of it is what's called a secondary structure. What's called a secondary structure. And for the purposes of this talk, what you really need to know is that the stacked base pairs are energetically favorable. The loop regions, these are the open sort of parts, the circles, are generally viewed as being energetically destabilizing. No further thermodynamic details are really going to be needed, but you do need to understand that sort of there's these two fundamental types of structures, loops and helices. Helices sort of are viewed positively. DLCs sort of are viewed positively, that is, favorably energetically. Loops, generally, not favorable. Okay, so I was actually a postdoc at the University of British Columbia once upon a time, and while I was there, I worked with Anne Convin. And so she introduced me to this idea of trying to design RNA psychedelic structures. And so, if you're trying to design an RNA psychiatric structure, you might start with a psychiatric structure that looks like this for me, you know, this close. This four leaf, you know, this clover leaf shape we've been saying on these different sides. You would say, okay, I'm going to think of that as like the tree abstraction, so that's kind of the skeleton of this secondary structure. And then I will put base pairs where I want base pairs. And the most favorable type of base pairs are GC pairs. Those are the most stable. So I'm going to put G C's there. And then I'm going to put something that does not interact with, that interacts neither with G nor with C on the loops, and that would be an A. That's why I have to put these on my loop. That's why I have to put these on my loop regions. And so I have produced a structure that can, sorry, I've produced a sequence that can fold to the desired structure. But it doesn't. So the problem is that your sequence is going to exploit some symmetries in your coding. And it's going to, and so its optimal, its preferred configuration is not going to be this four-armed one, which has a central loop with four helices. Central loop with four helices radiating off of it, it's going to be this one, which is basically sort of still has four helices, but they have a different branching arrangement. And so what it has done, and here are quite preliminary details so that you don't have to worry about it, but what it's done is it's exploited symmetries in the loop, sorry, in the helical encoding to reduce the cost of the loop structures. So our solution to this problem of how can we design RNA secondary structures. Can we design our secondary structures? Was a classic computer science one? Well, we have a hard problem, so we're not going to actually solve it. We're just going to show it's as hard as another problem that we can't solve. So, if you want to design our secondary structures, well, we're going to reduce it to the concept of designing these helical encodings. And so, to design the helical encodings, we're going to figure out how to bound the loop energies so we can figure out how bad a squirt of, you know, or it's like a lackable. So, you have to figure. It's like a whackable. So you have to figure out, you know, how much could the sequence gain in terms of the loop energies by doing something you don't want to do? And then you have to make sure it pays a greater penalty in terms of the helical encodings. So helices versus loop trade-offs. And then this led to a whole research program going on with Skelana Postanovic, where we look at the comet forks of the loop energies. Of the loop energies. And so we have been using techniques from geometric cometorics to do that. And that has produced some interesting results here in the Siat Siaga, for instance, where we're finding better branching parameters on the basis of life. And so I had the opportunity to talk about this at the joint math meetings back in January, which I was really appreciated. And so I decided I was not going to talk about that today. To talk about that today. So, instead, today we're going to be talking about the helix combinatorics. So, you know, we're instead of talking about the loop energy trade-offs, we're going to be thinking about this helical encoding problem. Or actually, more precisely, we're going to be thinking about what happens when we can freely exchange all of the possible ULIC combinations. So, here are the five saturated, meaning they have the maximum number of base pairs. Number of base pairs. Secondary structures for this particular very pathological combinatorial RNA sequence. So I've got strings of A's, strings of G's, more strings of A's, strings of B, multiples of C. And so the G's and C's can pair up. The A's are just kind of hanging around as spacers. And there are then five different ways that that can happen. And so you can see the five configurations here. And then there are. And then there are ways that they relate to each other. So, for instance, this central one looks very much like a fairly nice sort of helical structure. But if I pull apart, say, these two helices and then repair them in the opposite way, so instead of the second one pairing with the fifth one, it pairs with the third, then I get this sort of structure. So I can move around in this configuration space with this idea of sort of this breaking apart. idea of sort of this breaking apart and de-pairing exchange operationally. And then this leads to different mathematical results. So there are results on meanders because the structures here, so this particular structure, if I write the indices on a line and I use arcs to indicate the ones that are pairing up is this rainbow set of arcs on the top. This structure here I've written on the Here, I've written on the bottom, and then you'll see that this forms a single closed loop. So, that is one way of describing a structure from physics that's called kind of meander, and still an open enumeration problem. There's also results on Krebler's complements, but today we're going to be talking about barrier height results for these secondary structures. Okay, so here is your definition of a plane tree. So, Stanley calls them a plane tree. So Stanley calls them a plain tree, and that's what we're going with. But they're also, should you find yourself trying to do a literature search on this, then they're also known as ordered or linea trees, just to complicate matters. And it is a rooted tree whose subtrees at any vertex are linearly bordered. So if I look at this set of trees, if they are unrooted, then I have exactly two different types of trees. I have a tree that is a star, meaning I have one central vertex and it has three arms radiating off of it. Three arms radiating off of it, or I have a tree that is a line. So, this is unrooted trees. Now, if I choose a root for the star, then that becomes two different types of trees. I've either chosen one of, you know, I've chosen it so that the central loop is in the middle, or I've chosen it so that the maximal degree loop is the root vertex, and so it's distinct. That distinguishes these two trees. So, for the line, if I choose one that has valence. If I choose one that has valence one, then there's only one possibility for that. But if I choose one that has valence two, then these two trees are indistinguishable without an ordering. And so they linearly order means that you know the order in which your children appear. And so if I stand at the root vertex here, then this root knows that its first child is not a leaf, but its second child is, versus this one. Second child is versus these ones. And so there are exactly five trees on four vertices that do this because this is one of the very many colonitorial families that are enumerated by the cattle numbers. Okay, so we're going to think about our trees as the edges in our trees as being composed of half edges. So a single edge is actually two half edges that have been stuck together because I'm really thinking about them as being RNA sequence segments. Being RNA sequence segments. And so to keep track of that, I'm going to label the boundary of my tree with the integers from 1 up to 2n. And I'm going to represent an edge with an ordered pairing. So the i is the first index and j is the second index for my edges. And then because the, so the difference between i and j, if I have an edge with indices i and j, then the difference between edge. I and J, then the difference has to be odd because I have to have a complete subtree below it, and that has an even number of edges in it. And so I'm going to call this edge odd if the first index is, and I'm going to call it even if the first index is not. And then, and I'm going to let the count of the tree just be the number of odd edges. So, for instance, this tree has one odd edge, this tree has three odd edges, and these three all have. Edges, and these three all have two odd edges. So it's a way of partitioning my set of trees. Alright, so here are two edges that are incident on the same vertex. And I've actually represented them as fat rectangles that I can divide in half so you can see the two half edges. And then we're going to define a pairing exchange on these trees as pulling apart these two edges into their four half edges. Two edges into their four half edges and then repairing them in the opposite way. Exactly. It is exactly that. Now, the important thing though is in this picture, so I have, you know, I can think of this as A, B, C, and D. And then I have this part here, which was this loop, sorry, which was this vertex or a loop. And there could be a whole, there is a, there could be a whole tree up here. Whole tree up here, or two parts of it. This one, there could be a whole tree hanging off of here, and down here, and over here. And so these sub-trees are getting pulled and pushed by this branching exchange operation. So it is a local move that has a very large effect on the global structure of the tree. The other thing that will be important. The other thing that will be important to us is it changes the number of odd edges by exactly one. So if you start with an odd parent, it must have an even child. In this case, you end up with two odd signals. So you can just go through the sort of parity argument, but the effect on the count of the odd edges is very precise in efficient. Okay, so here we're going to think about, so this is the, this is. Think about, so this is the graph from the slide where we had the saturated secondary structures, but now I've drawn it as trees rather than secondary structures. And the dash edges indicate one of these pairing exchange moves. So this graph is, of course, connected, but we want to know if that's true in general. And it is because we can inductively convert everything. Which one did I choose? Yes, we can inductively convert everything. Yes, we can inductively convert everything into something that looks like this tree. So this is the tree. Oh, no, sorry. Yes, UN. So this is UN here is the tree that is the star that has a root vertex with n children. And then, and so I'm going to think about some other tree in this graph, and I'm going to think about its first edge. And so if it is, if I It is, if I don't have, if the second index is not 2n, then t composes into subtrees at the root, in which case, inductively, I've connected, it's worked. And if it is 2n, then I can apply one of these pairing exchanges to that edge and its first child, in which case I get one that meets this criterion. So basically, what I'm saying is every tree has a is every tree has a path, every tree in my graph has a path to this star. So therefore the graphs are connected in general. Relate to things like branch rotations completely different. Maybe. I mean the answer is not at all. It's next door and I'm going to need to think about it for the rest of the talk and I still may not. No, no, it's great because then it's No, no, it's great because then I get it. Perkolate. Okay. So like the the graph is connected, but the paths that we're getting are we would call high barrier. So the question is, what in the world do I mean by that? Okay, so there are a bit of literature, and some of the references are here, and on what are called barrier height problems for RNA-fold. Barrier height problems for RNA folding. So, BAMP is an absolutely marvelous place to talk about this problem because the theme is what is the cost of transitioning between configurations? So you might think, I'm in this valley here, and I'd like to get to that valley there, and maybe I can do it without too much pain and suffering because it looks like there might be a fairly low ridge that I could. Ridge that I could follow. So we might say that's a sort of low barrier height path. On the other hand, getting from this valley to that one looks worse, right? You're going to have to climb a hill. Now, you don't have to go over the mountain peak, right? We're just, we're asking, you know, what is sort of the best path that you can find? What is the lowest cost path that you can find? And there are any number of variations on this. So, you know. On this. So, you know, it won't like when you say cost, how are you measuring that? Is it the average? Is it the maximum? And by the way, what is it that you're measuring? Are you measuring the MFV value? Are you measuring some other quantity? What exactly, what do you mean by cost here? Then what do you mean by step? We're talking about pathways. So what are like, is it, if I'm thinking about RNA secondary structures, is it one? Secondary structures? Is it one base pair? Is it an entire helix exchange? You know, what exactly do you mean by steps? And what, you know, and your configuration space. Are you thinking about secondary structures at the base player level? Are you thinking about them in terms of branching configurations, which is what we're going to be doing? So there are many variations on this. Most people do think about it in terms of secondary structures at the base pair level, where your staff is one base pair, and you're really thinking. Is one base pair, and you're really thinking about it in terms of the minimum free energy as determined by the nearest neighbor thermodynamic model. All right, we, however, are going to be thinking, so our configuration space are these plane trees. Our step is one of these helical, you know, one of these pairing exchange operations. And then our sort of cost is going to be. Is going to be the amount of branching. And so, and why is that somehow a reasonable way of thinking about cost? Well, we know that branching is actually, that high degrees of branching are not thermodynamically favorable. And the way that we know that is because you can think about these five trees, and I apologize, you know, you slice and dice from different talks to produce new ones. And so the trees, when there's this open vertex at the bottom, you're supposed to. When there's this open vertex at the bottom, you're supposed to understand that's the root in the non-conventional biology orientation. And when it's at the top, then it's mathematically, you know, the tree is growing downward. So these trees are growing upward, but these are still the same five trees that we've been thinking about. And you can assign a score to the loop energies in a way that is consistent with the thermodynamic model. And then you can ask what is the tree or trees that minimize the free energy. Minimize the free energy, and then you can start at, and then you can ask why. And so, in this particular, for this example, this is the tree that has the minimum loop energy. And that is true in general, meaning that the total loop energy is going to be minimized for a tree with the maximum number of vertices of degree 2. And the reason for this is because branching is sort of locally favorable, according to the thermodynamic model, but it's globally. Model, but it's globally balanced because hairpins, that is, leaves in your tree, are the most energetically expensive types of structures. And so the more that the higher fan out that you have in your decree of branching, the more hairpins, that is leaves that you're producing, sort of that you don't need to. So you want to branch so that you're in this category of function, not that category of function, but you want to keep the degree of branching minimal. Real branching, then Andrew's frowning, but I'm going to ignore that and move on for the story. All right, you're not going to let me ignore it. Okay, I promise you that if you take these equations and you write it down, this is the optimum. And we can argue about why these equations, not other ones. But the. Oh, sorry. Degree, but sorry. Begins. Slice and dice. Down, like, it should be down degree. Like it should be down degree. Down degree. Or up degree. In this case, it's up degree two. So this is a vertex of up degree two because it has two children. Yes. Apologies for that. Okay. Yep, I got it. Slice and dice tech. All right. Okay. So our goal is to characterize low barrier paths in these graphs. Our graphs are always going to, you know, and our graphs come in this sort of multi- And our graphs come in this sort of multipartite way. On the left-hand side, we have the star tree where the central vertex is, where the high-degree vertex is in the middle. On the right-hand side, we have the star tree where the high-degree vertex is the root. And then we have these sort of ranks of trees in between them. And so the left and right ones are clearly the highest branching trees. And then that changes as you. And then that changes as you move between them. And so rather than try and track the branching of individual trees, we're going to track sort of which rank they're in. And these ranks are exactly the number of odd edges that they have. So this tree has one. I've done a pairing exchange, and so all of these have two odd edges. All of these have three, and this one has four. And then as the size of the tree grows, you get more. As the size of the tree grows, you get more different ranks. So the trees that would sort of have the lowest degree of branching on average are the ones that are going to be in the middle two ranks. And so we're going to, the middle two ranks will be n plus one divided by two. And then so we're going to take the number of odd edges that they have and subtract that off. And so this branching skew is the lowest. Skew is the lowest if I'm in the middle, and then it is increasing the farther that I get towards the star trees. This is our cost function for the barrier heights. And so then we want to characterize these minimal skew paths, and there are sort of four different versions that we're going to consider. First, we're going to consider moving only left to right. So, you know, starting with the tree. So, starting with the tree, starting moving this direction in the graph. Then we're going to consider a reverse direction only once. So, I either go left to right and then right to left or vice versa. Those will be called the V ones. Our one away from optimal. So, that means that I have, so basically, the trees start in ranks, and so then the best skew that you could have is to never go beyond those ranks. To never go beyond those ranks, to only go within them. So if you stay within, that is bounded. But suppose you start with trees that are at the same rank. Well, clearly you're not going to do anything, or maybe one away. And so if you're at the same rank or one away, so then they would, sorry, that would be tightly bounded is I never go beyond the ranks that I start with. Bounded is I started too close, and so I have to allow the deviation of one in order to be able to do something. Or our bounded. Or our bounded geodesics. So here the geodesic is the path length. And we can actually, we know precisely what that is. The link, the path, the minimal path between any two trees here is exactly the number of edges minus the number of loops. I haven't told you what loops are yet. You know what this is. And so we can also think about their being maped geodesics. Okay, and so the answer to all of Okay, and so the answer to all of this is this concept of a tree partition. Okay, so I'm going to, so first of all, I told you that the trees are labeled by the integers from 1 up to 2n. And I'm going to think about just the odd indices from that. Those are the ones colored in blue here. I'm going to draw them on, I'm going to have them on a line, and I'm going to draw an arc between when they form. When they form an edge in the tree. So these are sort of, these are the non-crossing perfect matching representations of the same trees. So here are four trees. And I've taken the first tree, and the rainbow is always on the top. And then I've drawn the second tree on the second, third, and fourth trees on the bottom. And so these are the closed, these are the loops from the previous slide. So I get some number. So, I get some number of closed loops. The minimum is n, the maximum is 1. And then, and so I think of these as the simply aligned subsets. So, given two trees, I get a set of simply aligned subsets, aligned because they have to match up, simply so that I don't take meanings of them to start with. Now, here I've got this tree. I've got this tree, L4, forms. I get this one edge here, and then these three bumps. And so I get a total of three loops. And when I look at the induced, the subtrees induced by these loops, sorry, the subsets induced by these loops, they are actually subtrees. So there's one loop here that is 1, 8. 1 and 8. One and eight are a subtree here, and one and eight are a subtree here. Two, seven, six, and three, two, seven, three, and six are a subtree. Two, three, and six, seven are a subtree here. Similarly, four, five. Same thing for U4. But if I look at this tree, now I have two loops here, but one, eight, five, four. 5, 4, 1 and 8, 4 and 5 are not a subtree in this one, although they are here. And the other, and the same thing for the other loop. So this gives me simply aligned subsets, but I need sub-trees. And so the tree partition here is exactly the odd integers that come from the loops, the odd integers that come from the loops. That comes from the loops. The union of the two that gives me a sub trees that come from the loops. So this partition is the full one. Now, if you're thinking this seems a lot like non-costing partitions, it very much is. But I'm not going to say any more about that today because I want to finish telling you about paths. Okay, so a forward path here. So a forward path is one that only moves. Here. So, a forward path is one that only moves left to right, and it is equivalent to having a min-max decomposition. So, 2 to T has a min-max decomposition with T prime, and this is an ordered relationship because the path has direction. If there exists a tree partition of these two trees, where the induced sub-trees are each a star, where the opposite choices of root are determined by edge parity. By edge parity. So these two trees are a tree partition, satisfy that, but these two do not, for instance. Now, and then, but these two have as their apex a V path that satisfies a design. And then in order to think about sort of staying bounded, we're going to think about zigzag paths. And we can bound the skew tightly. Skew tightly when we can have the skew bounded tightly unless we're too close. But the path length grows badly. If we want to have a bounded geodesic, so and then this is the path length, then we can do that if the trees have what we call the block decomposition, meaning that if the induced sub-trees from the minimum tree partition are simply aligned. Are simply aligned. So we have a sufficient condition for having a bounded geodesic, but we don't know if it's actually necessary or not. And I claim that this relates to, well, the proofs for this actually provide some insight to the hairpin stability for RNA and its different architecture. So I went and hunted up why you might care about these things. So the hairpins, you know, hairpins are the primary focus for Focus for protein biting. And sort of, there was this paper on Huntington's disease where they said that the misfolding of the RNA produces hair pins that then they think are binding with the genes that lead neurological condition. And then here is an example of domain architecture. So here is, you know, one, these are motifs in influenza viruses. And so you, you know, this confirm right nation is less bad. Mitonation is less bad than this one. But there are profound changes in the body secondary structure of protein function. But there, and then I actually need to end with some math questions for once. So thank you for your attention.