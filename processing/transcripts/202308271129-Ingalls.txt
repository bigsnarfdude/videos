So, I'm going to tell you a couple stories about model calibration that we've been working on in the group. Okay. So, yeah, so start about model calibration for agent-based models. For agent-based models of mixed microbial populations. And then, depending on time, a little bit about some of the recent work in experimental design as well. So, we'll start here. And so there's one advantage of going at the end of the meeting is that I said I don't have to do a lot of my motivation and backgrounds because I get to piggyback another people's style. So, Ophilia did a great job of giving us an overall picture of the idea of manipulating microbiomes. We're not doing it well. We're contributing to that in a small way. So, here's a review. So here's a review. Affiliate was on this with Chris Larson. Went from top down, looking at action microbiomes to bottom up, which is where we are in the math department looking for the simplest possible communities made of two cousins of E. coli that are intermingling. And we're looking at a few different aspects of delivering engineered mobile genetic elements. And so Long Cheng did a great job of introducing us to conjugation. us to conjugation and motivating that so this is this is where we are so we started this uh work a while ago with just a very simple description of simplest description we could come up with for a conjugation process describing the dynamics of the conjugation process so two populations donor population specific population and then a conjugation event and this is one of the first experiments we did in the lab and so we wanted to keep things simple and so we just did filter mating so we just played the plate the two populations let them sit and grow Let them sit, grow, and mingle, and then shake them up into a fluorescent time points with fluorescent signals here. Let fluorescent signatures indicate which population is which, just depending on the population. So very simple. We're just getting triplicate observations of populations through time. And so that's a simple description of averaged population behavior and aligns very well with the very simple differentiation models. This is Bruce Levin also was. Territorial vinyl also was mentioned in Long Chu's talk. And this model is 45 years old. Very simple model of conjugation. You've got the three populations growing exponentially and just a map of action from conjugation. So, and this is from an epidemiological perspective. It just looks like an SI model. So, this is very familiar. Yeah, what's the black RP represent? Oh, this is just the this is the this is just the chromosome so why is it one plum sprang? Because they're different they're different so they're just chromosome one chromosome two just to show different strengths different backgrounds. The transcontinent is sprag so the conjugate oh so the so the the conjugative plasma is the green which is transferred into a recipient making a transconjugate okay so this earlier work that we did is just look at this Levin What we did is just look at this Levin model and extend it a little bit to try to get a decent agreement with these filter mating results. We did some model comparison there and some uncertainty analysis. I won't go into details, but the one thing I want to sort of highlight is the model fitting was very straightforward because we had data that exactly matched with a simple deterministic ODE description of what's going on here. So just a regular way to sum a squared error is all you need. Errors is all you need. It's a textbook goodness or fit function. And what we're doing now is moving closer to reality and so looking at spatiotemporal behavior. And this is where this question of calibration gets a lot less obvious. So we're using here these microfluidic chips, which Matt Bennett introduced yesterday. So we're not going to tell you about this. So this is how we have been set up the assembly trapped in monolayer. So we've been during focal playing the entire experiment. Playing the entire experiment, and um, so we this was set up with college and campus hearing um at Waterloo, and so we can we can collect a lot of data from this experiment. So, this is all from a single experiment, right? The multiple traps and the microphone is on their stage, but this is small, this is over a day and a half, so they basically run forever from what we can tell. And we can image them regularly. So, we do phase images every 90 seconds and fluorescence every six minutes for going to photogleching. So, we get a really good description of what's going on here in terms of the type of. Going on here in technical type population behavior. We don't once they fall out of the trap where they're gone. It's like a mother machine, but you're charactering a population to a typical mother, essentially. That's essentially the same, exactly. And then Caleb mentioned today that red plus green makes yellow. So that's what we're saying here. We're starting, it starts with red population, green population, transfer of that color is giving us that yellow population, which you can. Population, which you can see start to kind of emerge through time, and then in some cases, basically takes. Okay, so this is a lot of data, and it's messy data, but it's single-cell data expected to be messy. And so this is sort of, we're just, this is where the progress, but we're getting to the part where we're going to sort of embrace this messiness of conjugation at the single cell level. So not just arriving at a single number that is conjugation efficiency, but thinking about how conjugation relates to Relates to contact or proximity, how it relates to factors of health, like the alumni rate, and that sort of thing, and transient effects of conjugation from individual cells. So that's where we're headed with all of this. And one of the first steps then is to think about, first of all, getting from videos to data. So Marcella just mentioned this image posting steps that are required. And this is lots of tools developed from the computer. Of a tool developer from the community to do this. This didn't show up at all, but that's a raw image and segmented, and then tracking in terms of cell motion and vision. And then we go from these videos to data sets, which are relatively low-dimensional descriptions of the cell in terms of position, orientation, length, fluorescent signature, that sort of thing. And then we want to do is really use that to calibrate some descriptions in terms of models. And so, again, the Terms of models, and so again, the obvious choices here are agent-based models, which are morphologically accurate. So, we're using here a tool for Tim Bridge's proof, or we're also looking at coarse-brain PV models to look at density. But I want to talk about the agent-based models today. And so, some of the parameters of those agent-based models we can just observe directly and just plug into the model. So, how long are the cells? How fast are the elongating? When was the length of division? What's the length of division? We're observing those, so we can just collect those distributions and then assign them and have a related model. But then there are other parameters that have to be inferred. So see, these are some of the biophysical parameters that come into what happens when cells grow and start to push one another around. So there are various ways this could be done, but you need a handful of such parameters to describe those effects. And then once you're going to do some interesting biology, so population for instance that we have these additional parameters are going to. Parameters are going to describe that process. And these are going to have to be inferred. And so, in the context of the OD model, that inference was very straightforward. We just do a theater sum of squared errors, minimize sum of squared errors, such as maximum likelihood, and done. And here it's much more complicated, right? Because now we have something that looks like this, and we want to compare it to something that looks like this and say somehow this one's more like that, that one looks, right? So, and there's a lot of stochasticity, and so. And so it's kind of a it's it's there's a number of ways one can proceed, and one that we've taken some inspiration from comes from ecologists, so people who do macrobial ecology, elk, plants, they've also been doing agent-based modeling with spatial and spatial temple data for a long time. And a paradigm that's emerged within that community is what's called pattern or modeling, which sounds kind of hand-wavy, it is kind of hand-wavy, but basically the idea is you identify Basically, the idea is you identify patterns in the phenomenon, and then you want to match those patterns. And the thing that's unsettling about that is that you, people, have to open it up. People have to be clever to identify those patterns. So that's not entirely satisfactory, but that's one way to proceed. So the first task we're giving ourselves here is just to look at the biophysics of growth, sort of the simplest piece of the The mechanism that we're looking at. So, here are a bunch of individual microcolonies growing from individual founder cells. You can see there's a lot of variability there in terms of colony shape and distribution of cells. And then we have the ability to generate lots of simulations. And we want, again, the idea is we want a collection of these to look like this collection in some way. So these patterns can be lots of different things. We put together a little review that kind of describes how some of these tools directly from ecology can apply to. Directly from ecology, you can apply it to microbial setting, and other groups have done a little bit of this as well. And this kind of looks like a collection of image features you might see in an close-cig list, right? Again, it's kind of like maybe this, maybe this, that. And so this is things that are sensible to be looking at, but again, it's a little bit uncomfortable to have humans make that call. We can look at things like sensitivity analysis to gauge which of these might be more or less informative, but ultimately you're relying on. But ultimately, you're relying on the cleverest of humans, which is as a human, I don't have a lot of common cleverness. Okay, so what we've just started looking at is a complement to that, which is at least systematic, if it's not entirely satisfactory, which is to look at reputation learning to identify features. It's basically just PCA. Think of reputation learning as fancy PCA. And we were aspired for this paper that came out recently from Stacey Finlay's group, so they were looking at From Stacey Finlay's group, so they were looking at a similar task, calibrating H-based models. They're looking at images of tumor progression, where individual pixels are scored based on the population density within that pixel or the subpopulation. And their agent-based model is an on-lattice model that generates data of the exact same thing. So they've kind of got a simpler task in the sense that the model and their data are directly commensurate, and they're all these fantastic tools in terms of building analysis. Tools in terms of looking at representations of images, right, in learning and learning. And so that's sort of what they were doing. So we want to follow the same path, but we have something a little bit trickier to work with. In particular, in terms of comparing images, we don't really expect to be able to look at the image features here and the direct connection to image features here. So what we've done again is extracted the extracted data in terms of where the cells are, where they're oriented. Cells are, where they're oriented, what their, in this case, their elongation rate, that sort of thing. And that's the exact same data that you get out of this. That's what the simulation produces, those pieces of information. Okay, so then what we've done, this is, we've just started a sort of, we're playing with different things, but a representation learning approach, essentially we choose somewhat arbitrarily an embedding dimension that we're interested in using to represent our original input. There's a challenge here, which I'd be happy if anybody has it site on. I'd be happy if anybody has a website on, which is our inputs are time series, but the amount of data from time point to time point grows exponentially between the experiments. And so the standard ways of doing this thing is just zero padding. So the first, the first input has almost all the zeros and a couple of cells at the top. By the end, you have 200 cells. And that doesn't seem to be the smartest way to do it, but I've talked to lots of smart people. I haven't been pointed yet to any solutions. Anyway, if anybody has any suggestions there, I'd like to. If anybody has any suggestions, I'd love to hear them. Maybe you could generate a latent embedding space with like an autoencoder that has the longest time series. Yes. And then consider projections on that space, random projections to capture shorter truncation. Yeah, okay. So that's something we're doing is we were looking at the, we're capping the longest size and then we're just zero padding. And I hadn't yet, so we thought about. And yeah, so we've thought about a couple different ways of doing that sort of representation. And I don't know what's the best way in terms of capturing the time series features accurately. So yeah, so that's it sounds like a good idea. And then we're using kind of standard time series layers here and the triplet loss, which is essentially utilizing the model for putting parameters that should be. Parameterizations that should be separated nearby in the latent space. And this seems to be working pretty well. So, this is just four different clusters from four different parameterizations, so simulation, four different parameters. And this is just PCA recognization of four-dimensional vending showing that they're sort of clustering separately. It seems to be a promising approach, anyway, and a nice compliment to this idea of human-inspired feature selection. Inspired feature selection. And then just standard Bayesian approach, Bayesian inference to arrive at these parameters, but also just direct regression in terms of this deep learning approach. Okay, and then beyond that, we have these conjugation effects, and there are additional complications there. So what we're seeing is the signature, the fluential signature that comes from a conjugation event, but that's delayed, of course, because of depression and maturation. And so the video here. And maturation. So the video here is showing individual signaling events. First time you see the color change. And the conjugation event appeared 40, 50, 60 minutes before that. And so this is the contact network that corresponds to the cell type. And then so the task here to go back in time to figure out what the complication event occurred is exactly analogous to a contact tracing in evidence knowledge. If you got sick on Friday, they want to know who you were hanging out with on Monday. You were hanging out with a Monday. So there's some nice tools from that literature that we're able to take advantage of. We have the advantage of full data, right? We know where everybody was basically all the time. But we also have a slightly more complicated scenario where, for instance, our patients are vitamin two at the same time to kill us. Infection process. Okay, I think I'm just about out of time. Do I have five minutes? So, the second part, this is all published stuff, so I'll just go briefly through this. Okay, all right, seven, I'll do seven. Okay, so we've done a little bit of work recently on optimal experimental design. Again, so the theme here is sort of thinking about how data fits into calibration. So, Brian mentioned this morning this idea of fisher-information-based optical primary design. Basic idea, right, is that we're going to end up with some inference of parameters that characterize. Parameters that characterize behavior, and we like this 95% confidence region to be small. And if we choose a well-designed experiment, we can have more. And the tool that we're using is this fiscal evasion approach, which is a local approach that is complementary to what Jared described in terms of different approaches. And this is a set of tools that are particularly useful when you've got dynamic experiments. So when you've got questionable. Someone when you've got questions about when to measure things and when to perturb things. So, this is a review we put out a couple years ago, sort of highlighting that a lot of those types of experiments are becoming more accessible in this area. And so it's a good time to be thinking about applying these kinds of tools. So three really quick stories here. So this one we're looking at characterizing effects of physiology on gene expression. So that I'm not On gene expression, so that's come up a couple times of this week with Terry's talk last night, which also discussed this as well. And we're using Terry's framework here to think about growth rate as a sufficient statistic for a lot of those features. And so we put together a model that kind of explodes that base model of gene expression, again, like what Sarah did last night, where we're separating out gene-specific parameters, which should be portable from context to context. From context to context, from physiological parameters which are specific to the context. And these are all based on the wealth of data that's available for E. coli and balance growth. So the generalization is a second task. And then in terms of the experiment, so again, Brian had a list like this about an hour ago of what sort of things might you want to consider. So here we're considering features, constant features like the growth rate, which we think of as fixed by just by the media select. Think it was fixed by just by the media selection, and then an alpha activation, and so we have a time variant input that we select, and then when we sample, what we sample, and how often we sample at time points. I'll go through, I'll skip the details of the optimization task here is challenging, and so we recast this as an awful control problem and use the multiple shooting approach, which is on that slide. But the details are published there, so I won't go through them, but let me just skip the pipeline. them but let me just skip the punchline but this is an optimal experiment that we sort of set for ourselves which is uh sampling uh growth rates at the two bounds that we had considered looking at these are these are screen size input profiles kind of thing that would be very difficult to kind of imagine it to kind of come up with and then likewise sampling schedules and densities that are not critical and this this was all simulation study but we compared to null designs in terms of Null designs in terms of the virtual optimality score, the optimality, parameter variance, and prediction accuracy and feminal design. Often ephemeral design seems to be going well. The student who did this work was then going to move into the lab and validate, and that was beginning 2020. So that did not happen. So he shifted peers and put together a Python package that describes the same very nice contribution. So this is a fairly general use Python package for Python package for auto-terminal design and related methods, so meant to be kind of worked off shop, and a couple standout features addresses non-Gaussian distribution data. And the sensitivities which are needed for the visual construction of H matrix are all generated by audio differentiation. So that's an efficient and accurate way to get that. Yeah, that done. And also a non-trivial thing to code. So this is a toolbox that allows. This is a toolbox that allows for that to be a bit more accessible than it would be otherwise. I'm going to skip through this very briefly. One little project looking at applying these vocal approaches to multimodal systems, which is for not normally fit. And so we looked at a single dimensional auto-activating module and put together a populate law of likelihood as a Gaussian mixture. Use some controls from stochastic analysis to arrive at predictions of those behaviors at the branches and between the two branch points, and arrive at optimal designs, which have the sort of standard flavor of sampling at the extremes, and in this case, sampling at the middle, which is where the possibility of the interesting stuff is happening. And I'll close with this. So, this joint work with Chris Barnes at UTL looking at a deep re- At a deep reinforced learning approach to optimal terminal design. So, you can frame optical terminal design as a feedback problem where the idea is at each time point wants to make a selection in terms of the most important next step in an experiment. And so, reinforcement learning is one way to do that, right? So, the idea is the agent is aware of the system, it chooses the next experimental action, and then it receives as a reward the fish information that it's done. Fisher formation that is achieved as a content for that action. So, we looked at this simulation study in the context of a fermentation process. And the advantage here compared to sort of standard approaches is that we should be able to have something a bit more robust to model parameterization and that can mix optimizing an objective along with learning the model, as Jones approaches doing as well. Approaches playing as well. And the limitation, of course, appears that it's data hungry. And so, this is an emulation study, but we kind of got to skip that. And we generally had a discussion about parallel bioreactors to do this sort of thing, but that's a challenge. Our baseline here was sort of standard approaches to optimization. And the out-of-the-box reinforcement learning algorithm kind of did okay, but was not quite. Was not performing as well as the model predicted control, which is standard here. And so we made some modifications to allow the agent to have more access to information and to have a simpler avenue for exploring the action space. And that led to something that has roughly equal agreement with equal requirements for quality predictive control. And then what we did is train that agent over a distribution of parameters. Distribution of parameters so that it was able to essentially learn not only what it should do but also where it was parameter space. And that sort of robustly trained agent performed as well as a model pressure controller who knew what the parameters were. So in a sense, the MPC had embedded over the agent and they performed roughly equally well. So we saw that as a decent first step in this structure. Okay, I will end there. So just thanks, Leslie. So of course, we don't. Just thanks to the students who of course did all the work, especially Aaron, who produced a lot of the signal cell data and that a lot of the analysis. Nate, who drove a lot of the public federal design stuff, and Nathan Trellier did the deep learning and then support, and that's it. So thank you very much.