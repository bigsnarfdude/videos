Not in the title. When I start to work on this problem, that's the picture I like the most. It's a picture of the river Nile in Egypt when it's flooded. The flood in every year, the river is flooded, but for Egypt, the river is flooded. For Egypt, the river is a lifeline. Once flooded, you see the muddy water. It brings the soil and fertile nutrition for agriculture. So this is basically the lifeline of Egypt in ancient Egypt. And so for that purpose, it has been recorded every year for Every year for about 3,000 years, they had a record of the level of flood every year and use it to compute the tax of next year. So when you look at the time series data they got, they found out the water level, they're not independent. They are not independent every year. They are actually quite dependent. If one year is more flooded, next year likely to be more flooded as well. So this is the first time series data, probably very well known, to look at a random evolution of phenomena with auticorrelation. And these are these pictures. These pictures, these are the this is the way they measure how much the flood comes in. Now, scientifically, this started from Pharaoh the first and he started to work in the service department in Egypt, recruited from Oxford. And so, what he did. So, what he did, he made some experiment. They found that, you know, you can look at the water coming in or the water level between discharges of water dam. They found that this interdependence between water flows and the covariance decays. decays with respect to the time is t to the the is t to the h and this actually was useful for proposing that these the famous ashwan dam project to be built with the aim of 10 years rather than just a few years For 10 years rather than just a few years. Here, mathematically, of course, we, this group, I said I'll give a comprehensive elementary talk. So now, Brownian motion is what we know in Ito calculus. We based on the idea the increments of Brownian motion are independent. This independence is inherited also by the integrals and the solution of stochastic differential equations. Now, the fractional Brownian motion is distributional derivative. They are correlated. So, in another word, this is the simplest stochastic process. Process is Gaussian processes with self-similarity and stationary increment, but with a correlation decay T to the 2H minus 2. So we take a increment of length 1, look at another increment of length 1, time t away from this one, and then the correlation decay decays. Correlation decays a little bit by 2h minus 2. So if h is greater than a half, it decays much slower than h is smaller than a half. Now, obviously, when h equals half is this one emotion, we shouldn't use the same formula for that. So with this prototype, This prototype for non-Markovan process with polynomial detail correlation is actually follow is sort of locally mimicking fraction brown motion. That's a standard now by now a rough differential equation. Of course, I could make b greater than a half than this young integral. Even in this case, what we're going to In this case, what we're going to talk about is still fairly interesting. Now, other examples of non-Markov noise, I think it's been sort of fractional brownie motion, which is H bigger than a half. I think Marty talked about it. There's also non-Gaussian stationary increments, self-similar processes, and these are given by sort of marking. Sort of marky-winner integrals with this particular kernel here. And there are also other moving averaging process. So you take a Hermit process convolve with a kernel of certain decay. So these are certainly quite interesting objects in statistics. So So that's the noise I'm going to talk about. The other thing I want to talk about is called multi-scale. Multi-scale is about, no, I think I'm doing a bit slowly. So that's 15 minutes to go. Let's see. Multi-scale is about you have a family of random variables, they evolving. Evolving and interacting with each other. But the natural scale for the evolution are different. Mostly we should be thinking about maybe virus living in a host body, and the virus evolves much faster than the other one. And then you could look at it from lots of other applied signs. We naturally see different time scales. They interact with you. They interact with each other. When this happens, we could write down equations for the evolution dynamics. We would like to separate the different time scales. So something we are interested in, we call that a slow variable. Then something evolving much slower than the one we're interested in, we treat it as a constant in time. In time, if the faster will pick up the faster one and study two together. The idea with the fast one is that since it works, moves like white noise, what is left over, what we want to see is the background. The background random noise is left to the slow motion. In this way, Slow motion. In this way, we wanted to seek out an equation of dynamic for the slow variable when the separation of the scales is getting further, further away. And this slow variable can be seen as sorted by, say, a vector field. And this vector field has taken into the effect the fast motion already. Motion already. So typically, the fast motion would be some kind of a has ergodic property. Sometimes the one people use is periodic. Now, so what is the two-scale system come from? Is typically you come from an equation like this plus perturbation, and then you try to find out before perturbation. before perturbation what sort of quantity are invariant in time and that one is usually a slow variable and you could be something staying on the manifold the perturbations kick it off for example very well known ones by fried and weasel you take a hamptonian equation take a perturbation then the energy the hamtonian is a Is a slow variable, and that one's a typical two-dimensional story. To go to truly above two-dimensional, and one can study a stochastic Hamiltonian, you could have a family for Hamptonians, the vector fields, the Hamptonian vector fields they generated commute with each other. However, because you have different However, because you have different independent Browning motion and they do interact with each other, that's a higher-dimensional case. In here, if you have more than one, they add it together, that's another Hamiltonian. So this was, I started to work on that in 2008. So the first paper I got myself interested in that. There's also other ones, which is geometrical frameworks. Which is a geometrical framework. Now let's look at another story. So now we put this two-scale differential equation, assume we already separated the slow and the fast motion. In this case, you have an equation. And here's some noise, can be wet noise, can be correlated noise. Can be correlated noise. And then the y could be solving another equation with a noise eta. And we could assume these two to be independent, but the fast feed into slow, the slow would further influence the x, we influence the fast motion, and that's some kind of interacting and feedback model. And feedback model here. Now, traditionally, this was only done for ODE case or for Brownian motion. So, this is Brownian motion. And that's what we do know, periodical motion. In the ODE case, there's also maybe some other dynamical systems, chaotic dynamic systems. So, let's So let's what we're interested in is look at the noise we just considered the simplest Gaussian noise with autocorrelation. Now started this work. This somehow is new because to solve the typical question with winner. The winner process, the main procedure is identify sort of titanium. Titanus is extremely trivial to get because we have E2 isometry and so on. If I have the boundary, that's trivial. And then identify the limit usually obtained by the multiple method to prove the generated converge. The generator converge. So that's a sort of a tread and pass. Now, suppose your noise is now driven by a fraction Brownie motion. And we something like this without this part. So the equation like this. And so why is a typical process, but we speed it up by one over epsilon? Now the question would be actually the is the limit theorem or not is Limit theorem or not, if yes, what should be, and how it converges. I think we were totally confused when we started with. Now, luckily, Johan Gehenge, and he started to do a PhD with me in 2018. And by the time, a few months later, he already understood quite a lot. So, we worked with a homogenization problem. With a homogenization problem, which is typically you don't have this part, so only have this part. But now we assume f averages to zero with respect to y. You take expectation and fix this variable with average to zero. Then we usually rescale it. And that's the homogenization problem. By this stage, we tried tentatively to understand what To understand what works if we take an Einstein Ullenbeck process with noise given by fraction body motion. So that was developed further, but Hammer really understood it. So the way we prove it is using raw pass theorem. Treated the equation as a raw pass driven by noise coming from this. So this is our driving of This is our driving object. But in the beginning, we cannot dealing with this form, we can dealing with something like this form. The reason is this guy, you integrate out, I can look at it, consider as a driver, and this driver could converge. So, in that sense, we understood in the homogeneization theorem for classical one, there's always a Classical one, there's always a central limit theorem, the founding of central limit theorem, most famously known as Kipney's Varada theorem. So that is the foundation. You start from there, you have to work a lot to get to homogenization. And we realize in some stage, yeah, so we do have some functional Linear theorem, not the same at all as the one for brown emotion, but they work very well. And we can Well, and we can show this the usual function limiting theorem is like you take 1 over t integral 0 to t f y s d s. So this converges to square t converged to winner process, but then you can do the process version of it converges to running motion. And so we some stage understood that's over the convergence. That's over the convergence distribution. And Johan, so he understood how to, what is the problem. So, the first one we did is for one-dimensional proof of CILT for fragment Browning motion in the holder continuum, holder topology. And so, I think that's probably the first one we know to work with holder tomology, which is, of course, is rougher topology. Rough topology. If we work on high dimensions, we just work out the same limit and these geometric lift proofs converge to Brownian motion and lift Brown emotions. So this we call rough. So we prove some rough Lind theorem essentially. So, rough functional CLOT theorem. Later on, we started to adapt on other different noise. And finally, with Julian and Johan and me, we proved the case, the generic case for that. So, there's also interesting thing that is a different. Interesting thing that is different from the standard homogeneization. To start with, the limited object is not always a Markov process. It could be something driven by a fraction Bronyo motion. It can be driven by a Hermit process and so on. And if you started from a Hermit process, interesting enough, you always get within a Hermit process. So that's a sort of a self-contained Self-contained limit object. And then another different place, we were taking slow variable, basically containing a bit of noise. Before we just take a white field, which is a fastly moving environment here. And then for averaging, we would take equation like this. But to make life easy, This, but to make life easy, we make this process Markov. Now, that worked with Martin Hera in two papers. So, one paper we worked for H bigger than a half case. And we found out this guy actually does have a limit theorem. The limit theorem would be very different from the averaging theorem these. Averaging theorem, the so-called averaging theorem as we know it. If this were Brownian motion, this epsilon object converted to solutions, some average equation. But the average equations, you're going to average the generator. It's never G itself, it's a generator. It means that I take a square of this average and take a square root. But what we do is we straightforward average it. Straightforward averaging and converges in probability, which is not the same as in Brownian motion. For Brownian motion, you can just take a standard function limit theorem, take Einstein-Ellenbeck process, take a Winner process, you look at them in convergence in distribution. But if you take a fractional Brownian motion, it actually converges into validity. It really. Now, when I give this talk a slightly different version for this talk, I suppose because we done different aspects, two weeks ago, Schmarfos come to me and said, look, I have a county example for you. It cannot be true. Just as you said, you look at the limit theorem without x, so I'm just taking the integral of this. So I'm just taking the integral of this object and then what this converges to without x. No, just a static limit theorem. So I claimed it converges in probability. He said, you know, it's totally wrong. You take a cosine, T over epsilon. I said, yeah, actually, it's not a county example. I did the computation for the Y being Oinstant alumbagic process. Then I co-cut. Process, then I come home, compute with periodic, it's all correct. So he was quite surprised, and I was very happy. So, you know, this is a very new type of theorem hasn't seen before. And other ones is what is if you take your fast motion to be non-Markovan. The environment measure theory has been studied by lots of people. People, I think with different notions of the environment measure. I think Ohashi there and with Martin Ohashi and quite a lot of people work on it. So the difference is if it's not Markov, you no longer have a PDE to solve for your environment. So and I think I've got it too long. And so there we have to look at And so there we have to look at the Gaussian bank and so on by hand. I guess I'll stop here. That's 25 minutes, all right? I think you could still use five minutes, but it's me for questions, I think. I think we should take questions now. Okay, that's okay. Question. Okay, so we stop here. Any questions? 