Okay, let's start. Great. So, hello, everyone. I'm Guilla Deutsch. I'm a master's student in Technion. I'm working with Heinrich himself. And I'll talk about topological patterns in George L. Schless. So, how to but should I click to maybe towards the computer? Towards the computer. Okay. So, first I'll define what is a tree-velled tree. So, a tree-velled tree is an undirected tree such that every internal vertex is of the green sweet. And in the literature, those trees are also known as angut grinary trees or bifurcating phylogenetic trees. So, here we can see other trivial trees we've All the trivial trees with up to eight leaves. Notice that for n up to five, we have exactly one type of tree, and already for six, we have two types, and as m increasing, we'll have more and more types of trees. So now I want to talk about what is a subtree inside some larger tree. So suppose we have some tree, T, and some subset of its leaves, L. Of its leaves L. So for example, we work with the following tree, and the subset is the blue leaf. Okay? So the sub-tree of T, of the tree, with respect to the blue leaves, is the sub-tree with the minimal sub-tree that spans the blue leaves. So it would be the foreign sub-tree, but for it to be a true tree, we'll Shouldn't tree will need to suppress every vertex of degree two. And what I mean is deleted and connect these two neighbors. So we can see it here. I mark them in black. And that's the result. Okay? This type of sub-trees are called lift-induced sub-trees or topological sub-trees. So now if I have three So now if I have tree, I would like to talk about its topological density patterns. So first I need to say what I mean by pattern density of tree. So if we have a tree, T with n leaves and a smaller tree, S, with candies, I'll say that the density of S in T is the number of substrees of T that is homorphic to S divided by N choose K. And here, N choose K represents. Here and just k represents the number of all possibilities to just k leaves from the tree t, and therefore it would be all the number of all sub-trees of t. Okay, so now we can ask some exclamation questions about densities. So first, if I have some tree s and some fixed n, then I can ask what is the tree with n leaves that maximizes the density of s. That means Of S. That means which tree has the most copies of the tree, the small tree S. And usually we would like to ask this as N is relative big. And that motivates us to define the maximal disciplines of S, which is just the maximal density of S over all the trees with N leaves, S n tends to infinity. So we can write. So we can write it as this one expression and denote it by I of S. And now we can ask: if I have some true, then what is its impossibility? And it turns out to be, and it was in question, already for truth, if it leaves. We don't know the answer for this. But first, we'll start with a trivial case when we can tell what is the suburban. So for this trivial case, So for this trivial case, uh I'll define some trip uh type of tree which is a catabella tree. Uh this type uh the catabella tree is a tree which such that is eternal vertices induce f. So we can see for example here the caterpillar with eight leaves and notice that before you fix the number of leaves the caterpillar S, we have a unique tree in caterpillar tree. Okay? So the category has a special property that any of its subtrees is a category as well. You can quickly see that we still make a path in the internal vertices. And therefore we can conclude the disability of CK, the cosmic k leaves, is exactly one for every k. Okay, so that's what's trivial. But now we look for the first non-trivial case. First, non-trivial case. So we take the following tree. This is the smallest tree which is not the caterpillar. And we denote it by B6. Okay? And now we can ask what is the tree with n lifts that maximizes the density of B6 when n is a fixed parameter. And actually, we don't know the answer for that, but we have some suspects. So first, if n is 6, then If n is 6, then clearly the tree itself maximizes its own density. And from here, we can take this tree and expand them by connecting each leaf to two new leaves and getting the following tree. And we can continue expanding the trees in that manner and get some sequence of trees with increasing number of leaves. And so now if we take the density of BC along the sequence, Of B6 along the sequence, it gets some limit value, then this limit value should be a lower bound for the inducibility of V6. So that's exactly what I did. I got that the limit value is the following number. We call it alpha. So alpha is a lower bound for disability. And now we can ask maybe we can get some good upper bounds. And if we really think that the sequence Really, we think that the sequence, the sequence elements, are good candidates for trees that maximize density of B6, then maybe we can hope that the inducibility is exactly alpha. So that's really the case. That's what I showed. I showed that alpha is also an upper bound. This result includes non-trivial analysis, so it wasn't that trivial. And some here, after And from here, after we finished with the case for V6, we can work with routes of trees and ask some questions, but I move on to ask some probabilistic questions. So in order to do that, I need some probabilistic model on the tribal trees. So we'll work with the proportional to distinguishable arrangements model, which is the model where every labelled tree with n leaves is equally likely. Is equally likely. So here we can see all the label trees with four leaves. We see that we have three of them. So in the model, the probability of each of them is one-third. And we also can define the model without using label tree, but using some random process. So in this random process, we'll start with the tree with two leaves, and until we have n leaf, Leaves and until we have n leaves, we'll choose a random edge uniformly, and then we'll attach a new leaf to the chosen edge. So that's what I equip attaching. Okay? And just as a remark, this is not the only model we can work with. There are other well-known models for this type of trees. Okay? So now we can ask some questions. So first, if we have some tree S and some fixed M, And some fixed n, then what can we say about the distribution of the density of s in a random tree with n links? And also, we can ask what happens when we take n to infinity. Does the sequence of the densities have some limit distribution? And if so, then what we can say about it. So, I'll show you some of the things we already know, and I'll show it on an example case when I was. Example case when the tree we're working with is the category of six leaves. Most of the things we can generalize, but here we just work with C6. Then first thing we want to ask is can we get the expected value of the density of C6 in a random tree? And it turns out that it is exactly the probability that a random tree with six lives is a caterpillar. Six lengths is a caterpillar. It's not too hard to prove that. So we can actually calculate this distribution by the random process of the model. So we start with the unique tree with five leaves and check all the possibilities to choose an edge and connect into it a new leaf. And we can see that the first six options form. Options form a caterpillar, and the last one is not. And therefore, the probability is six-seven. So, now that we have the expected value, we can ask maybe we can also calculate the variance. And in fact, we can do it. It's a little bit harder, and this time it would be dependent on the end, the size of leaves in the number of leaves in the length of 3, but as enter 3. 3, but as n tenses to infinity, the variance approaches to this following number. Speaking of that one, then I'll just show the simulation that I did. So I took a random sample of 300,000 trees with 2048 gigs, and based on that, I plotted a distribution of the density of C6 in a And as I see this simulation and some other simulations, I noticed that it seems to be converting to something. So that gives us a good idea of how the limit distribution should look like. And that's it. Thank you very much. Questions will have to be at dinner, so we'll receive this rose. If there's any speaker throat, Something like sweet babies. Okay, so I want to start with a little bit of motivation behind this work. First, we have this overarching question of relating the combinatorics of link diagrams to geometric properties of their To geometric properties of their complements. So, this is falling under that question of how can we relate those? How much information can we get about geometry of the complement from diagrams of the length? And a family of links that have been especially helpful towards that question is the family of alternating lengths with our projection on S2 and complement in S3. So, it follows that we'd also like to find broader families that retain that helpful property. And a way in which to do so is moving into this. And a way in which to do so is moving into this realm of looking at generalized alternating links, now with diagrams on higher genus surfaces and complements in thickened surfaces. Another motivation is finding totally geodesic surfaces in link complements, and we'll see how that ties together in this work. Okay, so the links we'll be talking about are links that correspond to tilings, either to Euclidean tilings or to hyperbolic tilings. We're going to start with. We're going to start with four valent tilings. So here you see a four valent Euclidean tiling. This is this tiling by hexagons and triangles. Then we're going to resolve each of the vertices of that tiling into a crossing and choose to do so in an alternating manner. And then from that, we can then take families of quotient links with diagrams now on surfaces. So what you're seeing here is an example of what we call the semi-regular. Is an example of what we call the semi-regular links where you started with a regular Euclidean tiling. These were studied by Champagne, Kaufman, and Rousseau. Now, I'm going to refer to these links as right-angled if we put the conditions on the tiling that there's only one vertex type. So as I look at any vertex in the tiling, this is a uniform tiling, there's only one type. And as you travel about that vertex, the tiles follow this pattern of m number of sides, then n. Of m number of sides, then n, then m, then n. So tilings such as the one you see right here. One note is that m and n may coincide. It might be a tiling all by squares, for instance. Another note is that when I call this right angled, that is not referring to the interior angles of the tiles you see. So for instance, right here, these are not right angled tiles. What that's going to refer to is three-dimensional geometry this connects to. Okay, so we saw an example of getting a quotient link from a Euclidean tiling. Here's an example from a hyperbolic tiling. So we could start with a tiling by regular hyperbolic octagons. We put in this checkerboard coloring, and then we're going to take quotients that would respect that checkerboard coloring. So here I chose this fundamental domain of just four octagons. The coloring you see is how we're identifying those edges. So I'm kind of starting. Those edges. So I kind of started us off with these tick marks. You see that we identify this edge and this edge, this edge and this edge, and that gets us to the next step. We fold over, and then we identify to actually form our corresponding link on the genus 3 surface. Then we realize all those vertices as crossings in an alternating pattern. Okay, so we started with our link diagrams. Now we're interested in looking at the complements. We're interested in looking at the complements of these links in thickened surfaces. Let's talk about some of the terminology there. So, in the complement, we can form two checkerboard surfaces by connecting the different faces in the link diagram via twisted bands at each of the crossings. So, you see an example right here. The link is drawn in green on this genus 2 surface. It's colored with the checkerboard coloring. And so, we get one shaded checkerboard surface and one white checkerboard surface via these four. White checkerboard surface via these twisted bands that precisely intersect at those purple crossing arcs at each crossing. Now, to find the complement, we're not going to be splitting it into polyhedra, we're splitting it into generalizations of polyhedra, which are given by a colon on the surface with a cellular graph on the surface boundary. So here, this graph would be on that surface boundary. Okay, so Howie and Brussel actually proved this far more generally. And Purcell actually proved this far more generally. I'm stating their theorem just in terms of looking at links in three surfaces. What they found is that you can generalize the decomposition that Monasco and Thurston used for alternating links to links in this more general setting, where you can take the complement of a link in a thickened surface and split it along its projection surface F into two generalized polyhedra. So here we have generalized polyhedra. Here we have generalized polyhedron P and generalized polyhedron P minus, and that cellular graph on the boundary of each of these two generalized polyhedra corresponds to the diagram of the link. So in this little example, we're imagining that we have this face, say one of the white faces, then the edges, the faces, and the vertices correspond to that. Correspond to that original diagram we had of the link on the surface. We can also color in all of those spaces to have a correspondence to the checkerboard coloring we had on the tiling and thus on the diagram of the link on the surface F. And to recover the full complement of the link from this decomposition into P plus and P minus, we do that via homeomorphism that has a twist on each face. twist on each face. So to glue P plus to P minus, notice that we would take this white face and just glue it by a 1/5 rotation to match back the crossing parts. Now these families of links fall under a broader class that was going to have a hyperbolic complement by Howie and herself. So we know that the complement, that they are hyperbolic and thus have a complete hyperbolic structure on their complement. On their complement, the total JS boundary. But a further question to ask is whether you can get that complete hyperbolic structure on the complement from P plus and P minus with the same combinatorics. So can you take this decomposition into these two polyhedra, split along using the combinatorics as a diagram of the link, actually realize those generalized polyhedra as hyperbolic, so straighten the edges. Hyperbolic, so straighten the edges and have geodesic faces, re-glue them via that twist, and get the complete hyperbolic structure on the component. So that was first introduced for links in S3 by Atchison and Reeves, and here we're stating it, thinking about our links now in this fixed surface setting, and saying that they are completely realizable if you can take that decomposition, realize the two generalized polyhedra as hyperbolic, and glue them via this. And glue them via this shift map to get the complete hyperbolic structure on their populace. If, in addition, they also have this property that P plus and P minus have all right angles for their dihedral angles, then we'll say that the links are RGCR. So, right angle, generalized, completely realizable. They have both properties. Okay, so a natural follow-up. Okay, so a natural follow-up question is: what links have this property? Right? It seems like it would be a great property to have. You go from the diagram of the link, you get these right-angled polyhedra or generalizations of polyhedra from that diagram. So Gon's work showed that in S3, there are only three alternating links that have this property. That's it, those three. He proved that. And he showed that they have totally geodesic checkerboard services. Now, if we move to links, thinking back to kind of that initial slide of starting with Euclidean tiling and getting corresponding quotient links, if we move to links that come from regular Euclidean tilings, Champier, Karkoff, and Purcell showed that only the links corresponding to a tiling by squares or the links corresponding to that tiling you saw earlier by hexagons and triangles have this property of being completely realizable and having. completely realizable and having right angles generalized polynomial. As we move to higher genus, the following are equivalent. First, that the link is RGCR. Second, that the link has two totally geodesic checkerboard surfaces. And third, that this link is one of those right-angled pilot points. So what I want you to see from this theorem is that what we're connecting To see from this theorem is that what we're connecting is the geometry of the complement, right, splitting along those checkerboard surfaces to get two right-angled generalized polyhedra. Second, noting that those two checkerboard surfaces are in fact totally geodesic. And third, having those restrictions on the tiling we started with that corresponds to these quotient links. So this is saying that just by looking at this link right here, I could check that at each version. I could check that at each vertex I have the same MN, MN pattern going about that vertex, and see from that that I have a right-angled structure on its concrete. So it opens up our opportunities for finding links that have this right-angled structure. So in particular, if we wanted to move to looking at links on this two surfaces, this is the table right here. This is the table right here showing 14 different pilings you can start with to get corresponding questions. Thanks very much. Next speaker, again, we encourage you to ask questions, Gary Taylor. It's a great thing. The next speaker is Maria from Gathering. The first piece for us. Okay, I first I thank the organizers for inviting me here. So, I talked about this problem, no? So, this is about growing data, about density. So, I just asked, suppose this question asked by Kim Tikomotegi, no? Is there a universal per boom for the number of SK pieces that manifold of tanny by densorial manifold can have? One would expect that this is true, no, because if it has many toroids, we say very complicated notes. Well, another way is formulating this is no especially. So, any torus we consider this torus in the node exterior, it will be just a puncture torus lag in the node exterior. Now, for the case of For the cases of we use one puncture, which valides has proved that non-parabolic nodes can have at most five the unicompressible non-parallel genus one sections of these best examples of these things. So, in here, so in now what we do here, I show one feed the family of Here I show an infinity family of parabolic nodes, so that every family has a solid can produce five distance non-parallel and compressible to this is the yeah and more recently from Anna Randa, Europe Ramidis Resource Fuzzies have proved that per bolt node X0 can have at most six non-parallel incompressible and nested That control to I know. So this five and six is close to the balls. Okay. This note and are not random, no? I mean, if you choose another random, it's almost impossible that will have this property, no? It will be like we need the lottery ten times, no. But okay, but what is not exist, no? Okay, but but this not exists, no? Okay. I use other minds covers under multi-most tree. Consider this tangible. These boxes indicate crossings. So we have n minus zero n minus zero. So that is complicated. Now, so we have this problem. If we zoom with a rational tangle, we get a trivial node. rational tangle, we get a trivial note and we get we sum another rational tangle we get a a note that has five convey spheres. Now fields the problem the fields is just that the sequence is just here we feel this way now these two cancel all these two cancel cancels Cancels cancels and this cancels cancel and now we have to use to play with the note and there is a little bit now moving off while we keep moving. Okay, we get to a trivial note. This is part A. Now, part B is used here to close this way. Here you can see the five congo spheres. Just note that in inside of these spheres, there is a non-trivial angle, no? trivial time work no one it is I mean this time but these are not parallel no that these are not this tangible is not too two straight lines no I think we have to show that now we take the turrets coefficient we take the tango union r zero We take the tangle union R0, this is a trivial not. We take the Dolore Branch cover of K, which is again S3 because this is a trivial note. Then the tangle R0 gives the solid horse, but this solitaurus will be not found. This is the node we're looking for, no? Come on. Because yeah, because if we have it is not in our disorderly. In our Tsori, we get a total bus cover of the other notified conveyance fields. So, and each of the convoy spheres leads to one compressible tools. Now we have to show that what we see the correlation is. Which is the coro des auditoros? It cannot be made the job from auditorium here. This is a technical proof. And then the final theorem is that, okay, we have to put a case really and a permanent code means this follows because there is mean, there are, we have to show that there is none other. Are we have to show that there is none other incompressible tools on the exterior of the rooms? And for sector, it's row, did not contain fatty generals autopicompressible to write. Yeah, in fact, this manifold is a graph manifold determined by a graph that consists of six vertices, five edges. So the external vertices are CEFIFIBY space over at this point. External vertices are CEFIF. Do you think five is the maximum, or is there only one? Five is the maximum, or is there only six? Oh, I think five is the one. Yeah, because I before we have an example with four to eight and it was very difficult to produce the example with five to eight seem easy to find an example with six to easy. Examples with two, three, four, torrent are not so difficult to construct. Pipe was difficult to construct balance: if you take the number of punctures to be n, do you have any balance on how many Torah? If the number of punctures is n is and does that, I I have another example one to one four point two toes But it's more difficult to consume this  All right, so All right, so it's nice to be here. I'm not a not theorist. I mainly do probability and discrete math and other things that interest me. So for a long time I've been working, part of what I've been working on is self-avoiding walks. So I'll tell you about an aspect of that that involves knots. And there's mainly it's a big open question. Maybe someone has ideas about it. So, a self-avoiding polygon, these are all embedded in a lattice. And a self-avoiding polygon is just a simple closed curve whose edges are the edges of a lattice. Here, the square lattice, but of course, we'll be interested mainly in the cubic lattice, three dimensions, but in general, it could be said to be any dimension bigger than equal to two. So, here's an example of a 22-step self-avoiding polygon. It just doesn't touch itself. Just doesn't touch itself. And we can count these. Nice thing about doing finite discrete things. So P sub n will be the number of n-step self-avoiding polygons up to translation. So four-step self-avoiding polygons with only one in two dimensions, the square. For six step, well, you've got a one by two, two squares side by side, really, and you can either be a horizontal rectangle or And you can either be a horizontal, rectangle, or vertical. So that's two, a little more to count for eight. In three dimensions, four steps, you've got the square, but now it could be in the xz plane or the xy plane or yz plane. And more counting for p6 and p8. So these numbers grow kind of rapidly. And I'm just repeating that definition. So one thing we want to prove is some exponential growth of these. Exponential growth of these. So I'm not talking about knots yet, but the main trick for doing this is concatenation. So if you have two self-avoiding polygons, you can move them side by side. So take the rightmost, uppermost edge here, the leftmost, lower edge here, put them side by side, and then erase these edges and put on these two edges so you can stick them together. And you have now a self-avoiding polygon with n plus m steps. You can do this in many dimensions, in higher dimensions, three dimensions, a bit more, slightly more tricky because these edges, when you bring them together, they may not match up. Okay, so you rotate it. Not a big deal, but not something to worry about. So, one thing that comes out of an inequality like this, the multiplicative inequality. For multiplicative inequality, is that this limit exists. So the nth root of p sub n, going through even numbers, of course, exists. And we'll call that number mu. It happens also to equal the supremum of the nth root, the pn's. And basically what they're saying is gives an exponential growth rate, at least a leading order. So Pn looks like Î½ to the n, and then that's the leading term. Plus the lower band gives the order term. Okay, so my motivation for looking at this is to look at conformations of ring polymer molecules. And these things actually are fairly good models in some circumstances for those. You can embellish them, but these are the basic ones. Okay, so now knots and self-avoiding polyptopes, polygons, sorry. It can't be a knot type, so trefoil or leftover. Trefoil or left-handed trefoil or unknot, fix that and write PN bracket K. This is the number of n-step self-avoiding polygons in Z3 that have not typed K. All right, so what I'm interested in is the asymptotics. Forget about exact values. I don't do exact enumeration. Other people do that well. But I'm more interested in asymptotic questions. So, what does this look like as n gets large? Look like as n gets large, and k is fixed. Okay, so for the unknot, well, something right away is we know that there's a well-defined growth rate. And it's the same trick we saw before. If you take two unknots, n-step and m-step, stick them together, and do that. Well, you've got another unknown, n plus m step. So we've got the same inequality, and so the limit exists. Okay, so Okay. So, right, and I'm going to call this new and now dependence on the particular not type. So that's fine. Second, which is harder to prove, is that this exponential growth rate is strictly smaller than the growth rate for all self-avoiding polygons. So that is, the unnaught is exponentially rare in the class of self-avoiding polygons. And more generally, for any And more generally, for any fixed knot type, K, the number of knots of that type is exponentially smaller than the number of all polygons. This goes back to DeWitt Sumner and Stu Whittington and independently Nick Pippinger, oh yeah, 35 years ago. So, an open problem, and this is the one I wanted to highlight and mainly talk about. So, if we don't have the unknown, what we'd like to do is, The unknown. What we'd like to do is prove that this limit exists. So this trick isn't going to work, right? You take two unknots, stick them together, you're not going to get an unknown. You're going to get a composite knot. Okay, exists. And once you've proved it exists, or maybe even assuming it exists, show that that's equal to the same growth constant you get for the unknown. Okay, so. Okay, so it's definitely true, we just don't know how to prove it. So the easy part, which you may have already figured out, is if you take an unknown and a trefoil, say, you can stick them together, and you get this inequality, an n-step, unknot, n-step, trefoil, you get a trefoil, n plus m steps. And now you can fix m and take the nth root of this, let n go. Take the nth root of this, let n go to infinity. Okay, this part's a constant, it just disappears. You get that the growth constant for the unknown is less than or equal to the growth constant for the trephoid. And so that's if the limit exists, otherwise you get less than or equal to the limp of Pnk, Pn of K to the 1 over N. Okay, we still do know that whatever this is, the lim soup is going to be strictly less than. Still at the exponential range. Okay, so what's on a more detailed level, what do we really think is happening? So, simulations and theoretical physics theoretical arguments indicate that if you look at the ratio of these, Pn of K over Pn of the unknown, that looks like n to that grows, not exponentially, the exponential growth cancels out. You've got polynomial growth, n to the f of k, f of k is the number of prime knots. K is the number of prime knots in the knot K. So the idea is: if you have a knot which is two trefoils and a figure eight, well, you can take a trefoil, a small trefoil, and stick it on in N places. You've got N choose three places to attach it to trefoils, and it should be great. And essentially the belief is that's the whole story, these little knots. So the fact that you can have large scale knots, that doesn't somehow enter into the That doesn't somehow enter into the picture, but that's the thoughts. Okay, well, we don't know how to prove this. Can we prove this? Maybe, let's make it easier. Instead of three dimensions, let's work two-dimensionally two planes distance 10 apart. Can we do something with that? No, that's still too hard. All right, let's make it one-dimensional. Let's put in a tube, say a 10 by 10 tube, and infinitely long. Can we think about knots inside this tube? No, still too hard. Still too hard. All right, let's make it as constrained as possible. The tiniest, skinniest possible tube that allows knots, a 2x1 tube. Can we prove that? Yes. But only very recently. It took seven people and 44 pages to do it. I've been working on it for a while. And there's a lot of heavy lifting. So here is a sentence from the abstract. You can see there's really some. I see there's really some heavy machinery they need, some real knot-theoretic machinery. They need more not three than I know. So I haven't had the function to read through that all yet, but you know. So to generalize this even to the 10 by 10 doesn't seem like it's going to work straight through, but again, what we need are the three people need some new ideas. Okay, here's one more thing that we can prove. It's in a different Different, which is so I've shown for any fixed knot type, it's exponentially rare among polygons, but the commonest knot type is not exponentially rare. So if you, as n gets larger, if you let the knot type get more complex, well, so here's what I mean. So for each n, let k sub n be the knot type that maximizes the number of knots of that type, size n. So typically for larger n, it'll be. So typically from larger n, it'll be more and more prime knots in it. But we know that if you look at this number, take the nth root of that and take the limit, and that converges to mu. So the set of all, so it's got the same row of paths. Okay. I know, time to stop. Sit down bigger. So the last speaker, I think, will be Andrew Britton. I think we'll be end room, but I hope. Okay, we might be okay. I hope this isn't leading me into my time. Not yet. Not yet. Ten seconds. Let me see if I can get my computer out of it as well. Okay, it's a very low-minute screen. Let me see if I can. Very level screen, it's a picture. And then I think I need to press that. Okay. Perfect. Got it. All right. So, thank you very much, and particularly, thanks to the organizers for inviting me. And also, thank you very much for putting me after Neon. And also, thank you very much for putting me after Neil, because this will continue on a little bit from some of the things that Neil was describing. And so, one of the problems I'm looking at, I'm not a knot theorist, I look at problems of what essentially what do random curves look like. And so, I want to talk about something that we've been working on, namely how to actually sample embeddings of closed curves of a fixed topology. And this is, I worked together with Nick Beaton and Nathan Clisby, who are at various places in Melbourne. And let me keep going. And so, the basic question that I'm interested in is: what does a trefoil look like? And depending on how you want to look at that, this is either very simple, you could take some pretty energy-minimizing trefoil generated by Rob Scharine's knot plot, or it becomes incredibly complicated because here's a randomly selected 64-edge equilateral random polygon, smoothed out a little bit, and then. And then render. And so the real question then becomes: well, which trefold do you mean? And so, as is often the way, the word just here covers a large number of sins. So we just have to define a probability measure on the space of closed curves. How hard could it be? And use that to study a typical trefoil. So I've gotten myself into lots of problems, and I suspect Ben has done similarly by thinking exactly this. Thinking exactly this: how hard could it be to just do X, Y, Z? And you discover it sort of 25 years later and realize it's hard. So, two very popular measures that get used in this sort of literature is the self-boarding polygon, which Neil described. So, this embedding of a simple loop into a regular lattice. And so, we have one here, which we can turn around. The measure that we place on this is that every embedding. Every embedding, every valid embedding of length n is equally likely. Then we have another one which I've grown to love more recently and also cursed a lot more recently, which I learned about from Jason, namely equal across polygons. So we take just a bunch of unit edges in R3 so that the edges are chosen uniformly on the sphere and they're conditioned to close. And one thing you learn very quickly about this is that analytic results tend This is that analytic results tend to be extremely difficult, and there's a long time between sort of major results in this field. There's some fantastic work by people here, some of whom are in the audience here, and links to review. And we've just seen Neil's talk. And so, because our loop results are very hard, we do the next best thing, which tends to be a lot worse, unfortunately, but at least you can make some progress, and you do some random samples. And then there are really two main Sample. And then there are really two major approaches that you can do here. Namely, you sample a superset of the topologies that you're interested in and then sieve out the ones that you want. So if you want trefoils, you do everything and then say which ones are trefoils. And then you can also say, well, let me just try to somehow sample only trefoils. There's two major things that you might do. And they're both problematic, is the polite word that I'll use since I'm in Canada, but they're both very. In Canada, but they're both very problematic in different ways. Okay, so let's start with the first. So, sample of superset than seed. Well, there's two ways you might do it. There's some really good work by Jason Clay and others. And at the time I wrote this slide, I thought the best possible was n to the five halves to produce an independent sample of an equilateral dependent problem of n edges. But I think you'll hear on Thursday about how they can do this a lot faster now. So you can generate these things extremely quickly. You can generate these things extremely quickly if you live in the self-boarding polygon world, which is generally where I've worked. There are some very, very impressive algorithms, starting with basically based around the pivot algorithm, where you take a chunk of your walk or your polygon and you do some symmetry operation to it and plug it back in. I'll describe it a little bit more depth in a moment. And this is introduced by Lion69, studied in great depth by Neil Medras and others, proving that it is actually a very good. Proving that it is actually a very good algorithm, despite initial ideas that it might not be. And there's now a really amazingly fast algorithm for doing this for the walk problem, not closed up into a polygon, where effectively you can produce a statistically independent sample in less time than it takes to write down the sample, which is a bit confusing. So it's extremely fast to sample these objects without controlling the topology. Controlling the topology. Okay, of course, then the problem becomes you've got to identify the things, and this really becomes a bottleneck. And I don't think I need to tell anyone in this room just how much of a problem this is, but it also combines with some of the properties that we know about self-holy polygons and I think electronic polygons, namely that as you get longer, polygons of a particular topology become exponentially rare. So it takes longer and longer to identify a given polygon and then A given polygon, and then the thing that you're looking for is actually rarer and rarer in the space of things that you're looking at. And so you sort of this double factor making this approach really, really problematic. Doesn't mean it's impossible, but it means it's problematic. Okay, so the other thing you might do is you might sample things of only fixed topology. So there's a very, very standard algorithm for this, namely BFACF, which works on polygons of fixed topology. You have some little local deformations that you do. You make a little local. Deformations that you do, we make little local changes, which include making the thing longer and shorter and sort of shuffling edges around. And this has been proved to be ergodic of not type by Buckfriend Rensburg and Whittington and myself and Bucks a little bit later on, different buttons. Okay, so why is this a problem? Well, it's not. It works really well. It's been the, indeed, it's been the go-to algorithm for 40 years now. And there really isn't anything better if you want to sample curves of fixed topology. The real problem is, in order to get a Problem is, in order to get an actual statistically independent sample, you basically have to shrink the thing down and then grow the thing out. And because this is roughly doing a random walk on the length of the thing, it takes a long time for it to do that. Also, you know, how long is it going to take to take trefoil, trefoil, figure eight, figure eight, and turn that into trefoil, figure eight, trefoil, figure eight? For those two knots to pass through each other. I don't think anyone's ever run a simulation that's. I don't think anyone's ever run a simulation that's long enough to do that. So there are problems with this. So, at the risk of running out of time, I'll talk a little bit more about what I might even begin to get to what I do, what I'd be doing. So, there's another thing to do, which is to take the pivot algorithm and restrict it. So, how does the pivot algorithm work? So, you take a chunk of your polygon like this, you fix two vertices, you take one chunk of your polygon and leave it fixed, you take the other chunk of your polygon, and you pivot it by doing some geometric operation. Pivot it by doing some geometric operation on it. So if we want to preserve topology, you know, there's so many options here, we really can just rotate. And so this was first tried by Zhao and Ferrari back in 2011. And they basically did this with the idea that we map out some area here by these two segments, the initial one and the final one, and you would accept the pivot if nothing else crossed that area. Area because you wouldn't have done a strand passage. But if something did cross that area, you might have done a strand passage, so you should reject it. So you have this relatively simple rule topologically, but it turns out to be extremely difficult to code. And indeed, they could only do it for pivot segments of up to five edges. And Neil is appearing a fair bit here in my talk. At some point, you realize that it's not going to be a hurt, because you can't make the algorithm reach all possible concepts. Make the algorithm reach all possible confirmations while restricting the length of these segments that way. They have to be arbitrarily long. Okay, so I think I've probably got enough time to at least mention what I have been trying to do. We have to try to think about how to speed things up. And the answer is to be lazy in a very strategic sort of way. Namely, you want to have very, very good data structures which allow you to avoid having to compute things very explicitly. And so And so, sort of the takeaway from this is roughly that the data that you're using to model your curve and the things that you do to it should look like not a polygon, the thing that you're modeling, it should look like what it is that you're going to do to your model. So it should look like something that allows you to compute pivots and intersections incredibly quickly, whilst maybe being as lazy as possible with everything else. And I'm going to ask how much time I have left. Time I have left. Alright, I can at least show a picture. Okay, so here's how not to do it: is to start off with a polygon in memory that looks like a polygon. So you store things as a doubling linked list. You know, here's vertex 0, here's vertex 1, vertex 2, et cetera, et cetera. The problem with this is you're storing each of these vertices explicitly. If you want to do intersection chain, intersection testing, you think about taking a huge chunk of your polygon, doing something to it, where you're more or less just compared. It where you're more or less just comparing all pairs of edges, so it's an order n squared operation, and it takes order n to update this chunk if it happens to be successful. You can improve this a little bit by taking a polygon and instead storing the angles that you move in. Because you still have the same problem about intersection testing, but now when you do an update, you just have to change that angle there and that angle there. So at least you've got rid of the order n update and turn them into order. Order n update and turn them into order one update. And you can go further here and do a lot of pre-computation involving trees. And I'm going to stop here except to sort of show like a picture of a tree. But I'm happy to go into details here about what you can do to improve the storage here with a lot of pre-computation so that you can avoid these problems. That's roughly what I'm working on, and I can at least show somewhere down here where it's at least. Where's placed? Alright, we'll get there. Right, there we go. So that started off as an unknot, as a unit square, and after 16 million pivots, it's still an unknown. Okay, so this is working towards a method for sampling of a fixed topology, and it's hard. Just to say thanks for your standard. Just to say please use the internet for questions and let's say both speakers again so