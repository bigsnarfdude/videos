Okay And it's my pleasure to introduce the first speaker in the morning is Peter Birgesa from Berlin and he will talk about real zeros of random structure phenomena. Very much thanks the organizer Sonia Greg and Paul for setting up this workshop in such a spectacular place. a spectacular place. Right, so I've already told you what is the type, so let's start at the very beginning. Structured polynomials, I mean maybe the first thing that comes to mind is few terms, few nominals. So let me start detect this point. Okay, okay. Now I have to do it. Okay, so what do we have? So there is also some notation here. So I want to consider n polynomials in n variables. And for each of the polynomials I prescribe the support. So the set of monomials that will occur. And this is encoded in a set A sub i, finite support. You see, it's a subset of Z to the N. So I assume normal monomials, negative coefficients are okay. Then Ti is always. Then Ti is always the number of terms. Pi is the convex hull of the support. It's called the Newton polytope. And then what I look is I have these n Laurent polynomials in n variables. Looks like that. CIA are complex coefficients. I use this usual this notation. You all know that, I think. And then we wonder how many zeros. And there is this famous result due to Kuhnirenk and Bernstein. I think most of you will know it. It says typically, for almost all choices of complex coefficients, the number of zeros in C star to the N is given by the mixed volume of this collection of input freedoms times n by frequency. There is even, you know a little bit more, when you count non-degenerate zeros, meaning that your coordinate zero is not singular, then it's upper bounding. But it's a beautiful. But it's a beautiful result. I think it's been very inspiring. And what is this mixed volume? It's just a multilinear extension of the usual volume function. So the usual volume function is homogeneous of degree n, you make a multilinear extension of this. But this is all known. But the question is, what happens if you are interested in the real zeros? In many applications, you are interested in the reals, in positive zeros, and then the situation is different. Situation is different. We know much, much less. So let me recall a little bit what is known. So it's the same setting as before, except now the coefficients are real. So then this internation n of f1 up to fn denotes the number of non-degenerate positive real zeros of this system. Now the first thing to observe is you it doesn't make sense to talk about generic number of zeros anymore because you can this Because you can this function n of f can take different values on distinct open sets. There are like different regions, and so on. It's more complicated. So, right. The first result I have to mention it is due to Descartes. It's a consequent of the famous Descartes rule of signs. If you have just one variable, n equals one, right, then you can upper bound the number of positive real zeros by number of terms minus one. By number of terms minus one, that's optical. It's very easy to come up for an organist that has this. Then, okay, so if you have this, then you ask about systems, you can do a cheap trick. You just take for each index i, you pick such an optimal univary polynomial for the system, count the number of zeros, and then you see actually have equality for that system. The number of positive real zeros would be that product t1 minus one times t. That product. T1 minus 1 times T2 minus 1, etc. Why is it greater than or equal to? It's equal. I should have written equal. But I, okay, the greater or equal because I'm thinking now of lower bounds. What's equal? Okay, it's equal. Sorry, equal. I should have written equal. But there was a conjecture. Okay, now this is a story about the Kuznirenko conjecture. There was a conjecture around for some time called Kuzhnirenko conjecture. And which this correction said that this quantity is upper bounded by this product of the Ti minus 1. Guznirenko never believed in it, and you can go to Frank's homepage and read about the whole story, but he told me. Yeah, yeah, not that. But people, I mean, it was in the community. I have this book on algebraic complexity, it's mentioned as an algebra. And then Haas gave a counterexample. So it's false, but it's not, it doesn't seem to be very false. Doesn't seem to be very false. Actually, we don't know. Okay, so let's go on. It's false. Maybe not very false. Okay, so here is a theorem, not a conjecture, a famous theorem by Osko Kovansky. You know that probably. It it's an upper bound on this quantity, number of positive real zeros, in terms of the number of variables and the number of terms. The number of variables and the number of terms. So t is the number of terms, overall number of terms. You don't have to look at the bump too closely, but I try to memory it's roughly n to the old t squared. So there is no depends on the degree, and if you think a little bit about it, it has to be like that. Just imagine, replace xi by xi to the di. If you want to count complex zeros, what happens? You multiply for each i with di, you multiply with i. i with di, if you multiply with the product with di, but if you come positive real zero after that. So somehow it makes sense. Not a proof, but intuition. Okay, so this bound is exponential in a number of terms, so many people believe that's quite pessimistic, but we don't really know. There has been a small improvement by Johan and Frank Sotile. Okay, but actually, you don't know. I gave a similar talk in. I gave a similar talk in Oberwolfach maybe one month ago, and after that I talked to Alicia Dickenstein and she told me about the paper by Peter Strunk that I wasn't aware of. So the question is, is it possible that this quantity is bounded by a volume? Think of M being fixed. Okay, Bernd apparently there is a paper, one of his very first papers on the art status question. Found it interesting. So there is this. Number 50. One of his first. Yeah, no, maybe 20 years old. It's a very short paper. Fields used to get him something. Okay, I didn't know. He didn't even say anything, but he was in the audience. Didn't even look at it. Maybe God. He's also getting older. Okay, but there is something really amazing for young people. Young people in the audience. You are look for challenges. The case n equals 2 is. The case n equals 2 is not understood. So this means two polynomials with two variables. Is there anything simpler than that? You want to count the zeros in the positive order. How many zeros can there be? Question? Is there a bound on the number of these non-degenerate zeros which is polygonal f? We don't know that. And don't think it's so trivial. So there is a paper by Pascal Coiron, Natasha Courtier and Sebastian Cabinat. Natasha Porti and Sebastian Tabenas looked at it very seriously and they proved this bound here, which is polynomial in the number of terms of one polynomial, but in the other polynomial have it depends on the degree. So it's used the Ronskin determinants to that, it's quite sophisticated. So we don't know that, huh? That's uh n equals so. Okay. So then sorry this is cut down, but Sorry this is cut down, but maybe I should say counting understanding positive real zeros is important for many applications: algebraic statistics, chemical reaction networks and so on. There's a paper that I like much, but there's also Alicia Dickenshein, but she was cut off. Sorry for that. So there are many applications, okay? But personally, as you probably know, I'm more interested in complexity, which also has connections to application, but it's more theoretical. So there is a link complexity to complexity. Link complexity that I want to tell you, and it's one of the reasons I also was attracted to this. So let's go back to the case of polynomial in one variable. Okay, take out the rule, maybe you think that that's quite trivial, but it is not. Now think of structured in a more sophisticated way. So I want to build up my polynomials in a certain way. I start with sparse polynomials. These are the Fij. These are the Fij, and I form a product of k many of those sparse and sum m of them. Sum of product of sparse. It's a model that currently is quite fashionable in complexity theory nowadays. They talk about algebraic circuits, but it's not important here. So now if you just expand this, you have this polynomial capital F, you look how many terms. Okay, it's upper bounded by. Okay, it's upper bounded by m times t to the k number. So Descartes rule ps the upper bound m to the k. Okay? So what it can it is it really is it is it what it is or not? Probably not. Probably this is very pessimistic. And there is a conjecture due to Pascal Coron, he called it real tau conjecture for whatever reason. Don't have time to explain why. It's a very bold conjecture. Very bold conjecture. And it says if you have a structured polynomial of that kind, then the number of real zeros is bounded by a polynomial in these parameters, m dk. Why is that interesting? There's not so much evidence for it. But Pascal, he also not only came up with a conjecture, there was an implication, he said, Well, if this is true, then you prove the whole egrain of algebraic complexity theory. Of algebraic complexity theory. So there is, you know, the PNP question, and there is an algebraic version for that question dealing with computation of polynomials. Nowadays it's called VP and VLP for value. So this harmless looking conjecture has this consequence, separates these classes, which means super polynomials, lower bounds on the size of arithmetic segments. So if you solve this really different VNT, you don't get the You don't get the billion dollar because it's just the algebraic model, but you know you get eternal circles for sure. That's a very hard problem. So that's a lot of motivation to think about this real tau conjecture, real algebraic geometry in a quantitative way. So maybe I should say that the idea behind the proof of possible simplication was based off an idea that I had in an older paper. Had in an older paper combined with the reduction to depths four circuit by Agravalum D9. And then Sebastian Tabinas, student of Pascal, in his thesis, looked at it a little bit more closely, and then he realized, actually, you don't need this full conjecture. You can have even, you know, it's enough to prove that. If you can bound this number of zeros by polynomial m t 2 to the k essentially, then you are done. And you see, if you compare this with this. And you see if you compare this with this, you have two to the k log t, you have two to the k log, it looks almost the same, but of course it's not. Okay, so so much for that link. But right, so if you think about the real problems, often it's good about think about complex solutions as well, you know, that we have to the shortest connection between the real problems goes over the complex plane maybe. Goes over a complex plane, maybe. And here it's a bit similar. There's an interesting result due to Pavel Hubert that I want to tell you. So if you... Now you have one polynomial in one variable. Counting zeros is not interesting. It's not only. But you may wonder where are these zeros? How are they distributed? You think about the distribution of the angles. So if you have this polynomial like x to the d minus one, okay. minus one, okay, then you know this has very low complexity, just log d times log d squaring, okay, so it's a very cheap polynomial, but you see the distribution of the zeros is uniform, perfect. So it's a bit of an inspiration for what I tell you now. So let's say n alpha beta counts the number of complex zeros between angle alpha and beta. Between angle alpha and beta. And somehow you want to measure how much it deviates from the uniform distribution. And so, that's what we have here. So, here you have this number. And you compare with what you would get when you have uniform distribution. And the statement of the theorem is that if this is bounded by a polynomial in my parameters n tk, then this is equivalent to the real time. This is equivalent to the real Tau conjecture. So you can also prove that. Take G polynomial in one variable, prove that the deviation from uniform distribution is very little. You prove this V P different. Very surprising. Okay, so, but this is, I'm still in the motivation. You see, this is all motivating. I want to convince you. These are interesting problems. They're also balanced. Problems, right? There are also bounds on this. This is called angular discrepancy. There are papers by Jerus, Turan, and others, but they cannot give this, right? They didn't deal with this structured type of polynomials. Okay, so this is all motivation. I think n of motivation. The title of the workshop contains randomness. So now you have to throw out randomness. And now if you throw in randomness, you could say more. Somehow. You could say more. Somehow it helps. You know, in physics, also, you think about randomness, because problems are too complicated. So let's do it as well in algebra. I think that's a very good idea. So there are two results I want to report. The first one is that this real tau conjecture, okay, it has this catchy title is typically true, so what does that mean? It means the following. In this setting of sum of product, Of sum of product of sparse polynomials, I fix the combinatorial structure. I fix all these supports iij, aij, okay, cardinality of most key. Then I look at fij, which is now a random polynomial with the fixed support, aij. But I assume all these coefficients are independent standard tax. So it's like plain bonina randomness, right? And then my capital F, I hope you remember. Capital F, I hope you remember, is this some, this guy, is now a random polynomial. The number of zeros is a random variable, so what can we say about it? What is the expectation? Then I proved to Dirny Brickel, this upper bound, which is very polynomial. It's just m k squared, it's real, very polynomial, it's complete linear. Unfortunately, it doesn't say anything about the complexity. But what does it say? I mean What does it say? I mean, it's very hard to put our hands on this problem. I mean, if you go for a counterexample for the real tau conjecture, you don't find it by randomness. You have to do something sophisticated. So that's it. And the proof, I don't have time to go into the proof, but just let me mention the method is the so-called Katz-Reis formula from the theory of Rand. So that actually was my first Benz workshop many years ago. Ben workshop many years ago. I was invited to Random Fields and I met all the experts, it was very helpful. So, much for interaction. So, right. So, if you are interested, you can ask me offline. I'm happy to talk about it, but I think I don't have time to go into that. Rather, I want to talk about the other more recent result, because it's also a little bit technical, right? But it's a very powerful method. It's like the main tool that they have in the field. The main tool that they have in the theory of random fields. So the other result I want to mention is, so let's go back to the phenomenals. But now random phenomenals. So now it's nice to introduce some notation. So I have my system of Laurent polynomials. It prescribes supports Ai, right? But the coefficients now I assume are independent standard galvan. Assume are independent standard gulf. It is now the random model. So it's probably the first random model you think about. And then let's give a name to the expectation. Let's call this E like expectation of A1 up to A. Now this expectation is some function of an n-touploff sequence that I want to study. Okay, then, but if you look at what people have done, like the Kovansky bound, actually. The Kovansky bound. Actually, these bounds are not for polynomials, it's for something more general. So, this has been on for a very long time. Actually, you can assume that all these exponent vectors are reals. It doesn't change anything. Namely, what we actually are doing, we're counting real zeros of polynomials of this kind. So, I make a change of variable instead of x, I say e to the w. Of course, this is e to the w1 of the wn. And what you have. W n, and what you have here now is a sum of linear combinations of exponential function, linear functions. So these are the functions that we look. Okay, so now this E of E1 up to En, you may know, probably you think over the complex number, this was mixed volume. It had some invariance properties. Also, here you can easily show some invariance properties. Okay, first maybe is easy. So you have these Newton polytopes, you add them up, and you can always assume it's full dimensional. Otherwise, there is no non-degenerate zero. There is not enough dimension to get it. So actually I can always assume full dimension. And so, but then here are the invariance properties. Most of them are pretty obvious. So first one is to permute. First one, you can permute the support because nothing changes, it's trivial. You can also shift the supports individually. So, what happens? If you here, let's say you put here, replace E by A by A plus B one, I mean, then you can pull out the whole factor of Fi and it doesn't change the number of principles. So this is also obvious. The third maybe requires a little bit of a closer look. Requires a little bit of a closer look. It says that you apply an invertible linear transformation, the same one, to all of the supports, there will be no change. And if you compare with the mixed volume, there is also such a property, but there it's only true for orthogonal transformations. But here you can do any linear I instead of writing the proof, just remember of the example I gave you, just for English, I think you do For the English, if you do replace this by that, you would affect, this would affect the number of complex solutions, but not the reals. And this means that for the linear transformation, it would be like a bismatrix. But for the reals, it doesn't. Anyway, so this is a nice object, but that is it's more complicated than it's not a mix. So we don't know really what it is. So we don't know really what it is. But there is a question. It's a recent question, I don't know the answer. It's about the monotonicity. So what happens when you, I mean, when you grow these reports? So I believe, well it's a question, but actually I believe this is very likely the following is true. When you enlarge these supports, okay, make them bigger. Okay, make them bigger, but without changing the complex hull. So it's like you have this Newton polytope and you throw in more points. And I believe, I have some reasons to believe that it should be monotonous, but actually I don't know. I don't even know for any good wrong. I gave it to a student, but you were a student. Maybe I can find it out. It's not trivial. I mean, it's not trivial. I mean, it can be wrong. Okay. That's a question. There's a question. There are many questions here. It's a fresh question. So I don't know. Also. Well, it could be. Yeah, I mean, if you do this sort of one term at a time, if you initially add the term extremely small, it's not going to affect the number of zeros because it'd be small per division. So most of the number of zeros will go up. It's not going to go, the maximum number of zeros will not go up. Going to go, the maximum number of zeros will not go down. But it's not just for small. I mean, you'll. No, no, no, no, no, no, no, okay. There exists if you increase the support by not changing the convex hull, then there exists, you know, if you just hit M11, then there exists a coefficient there, which the number of zeros is the same as the maximum number for the previous case. So I think they equal involves pretty straightforwardly. Maybe I don't understand what you're saying. That's talking about. Let's talk about it. Well, it's expectation, I'm sorry. Expectation. It's an expectation. It's an expectation. I'm happy to talk about Luvian. It's an expectation. Okay. So, and now here is the second theorem. Not my star theorem, it's just I mark it so I can refer to it. And maybe they like it at ISAC, I don't know. Likely that I suck, I don't know, I submit to there. Okay, so what does it say? So it's an upper bound on this quantity. And what is, let's look at this upper bound. You see here this product, T1 minus 1 up to Tn minus 1. This is what enters the Kuznirenko projecture, which is... And then we have a dependence on the Newton polyp. On the Newton polytopes, somehow the combinatorial structure. So the P is the sum of the Newton polytopes, and it has a certain number of vertices which I denote V0. So this enters here. So there is a depends on the combinatorics with some constant. So this generalizes and in some way improves a result I had with Albert Erquer, who is here critically listening. Listening to what I'm saying. And what we did in that paper was the case where all supports are equal. So it's the unexpected case. And we proved the bound, here is it written, 2 to the 1 minus n binomial coefficient. Okay, and this bound actually can deal with any variance is why this result cannot work. So let's see. C. Just it's always good to have a sanity check, okay, comparing. If one of the ti equals one, then this bound says zero. Well, that's true, because then you cannot have Peter, you asked me to be critical, right? So right of course, seems like our early result is for any variance and your new one is only for unit variance. Correct. So it's critically not right to coin as generalized solar. I said in sorry. I said in some way. You know, but the slide ends here. I said, in some way. You were my mentors, I'm following your request. You're right. Albert, I agree. This is all recorded on video. You're right. Okay, and the other okay, maybe that's no interesting. Okay, that's uh that's not so interesting. The next thing. So interesting in the next thing. So, optimum, optimality. So, we know we have an optimality result when, in the one variable case, and there's another paper by Jindal, Pandey, Schukla, Sisopoulos, computer scientists. They proved the square root of t upper bound. Now, this is the univariate case, on expectation that this is optimal. So, they came up with a support, some strange support, where you actually. Support where you actually have the square root of the index definition. So then, because you know, I'm interested, of course, in the multivariate situation. So, if you take this, I mean, just take this example by these guys and play a little bit with it, it's not so important now, then you find an example of very special supports that the expectation is overbunding by the product of the tees. And then okay, and actually I have a conjecture. No no, no. We need to work. So my conjecture is like the true upper bound should be like that. Square root of the product of the number of terms times something which depends on n and say the number of terms. So I believe square root of the product of terms is the right of s. Can you go to the previous slide so we show what you have? So, it's some it's in a way an analysis problem. Analysis problem. Okay, so I think now it's time. Okay, I have maybe 15 more minutes or so. So, I want to give an outline of the proof of this theorem. And there are two aspects that I want. And there are two aspects that I want to explain. Also, I want to my focus is a little bit on explaining what is different to the group that was in the Friedrich Alper and Pojou. So let's talk about the first aspect. So what happens when you go when you have different supports? Well, you have to do something. And at the beginning, you also follow a basic idea which goes back to Ederman and Kostran, which is a To Edelmann-Costland, which is a link to integral geometry, and I'm sure many of you will know it. So, what do we do? It's a geometric deformulation of this problem. But here, since we have different supports, I have to deal with the product of real projective spaces. I call it omega. So, it's P to the MR times times P to the Mn, product of real projective spaces. On that acts a group which is the product of your formal groups, and it acts. Product of the orthogonal groups and it acts transitively. So this is a homogeneous space. Now, okay, some location, but it's not bad. So to each support Ai, I assign a function, which is in a way a Veronese function. It's just not all the monomials are there. So what do I do? Mi is always a number of terms minus one. That's convenient. So I have this map. So an n-tuple X of positive reals is mapped. Of positive reals is mapped. I take the vector of all the monomials that I have in my support AI. But I think of this as an element of projective space, so I have this vector. If I would take all the monomials, a certain degree would be a Veronese, but now it's Verunese-like. Let's also assume that the sum of the supports, some of the Newton polytopes has full dimension, then this is easy to see that this combined map here. That this combined map here is injective. So, this map is now, it goes from R to the N, positive, to this product of real projective spaces. And, right, and what you observe, if you think a little bit about it, is basically what you do this. You look at the image of psi, I denote Z, right? The image or the closer of the image, algebraic variety, some kind of toric variety. Tauric variety. And then we intersect it with linear stuff. What is linear stuff? I mean, with linear hypersurfaces. So I have here in my product of real projective spaces, I have n different types of hypersurfaces. Like I have an H1, what is it? I put the linear constraint on the first block of variables, and the rest I leave. This is H1, etc., up to Hn. But this H1 looks like a But this H1 looks like a hyperplane in special position, so I will apply a random element of the orthogonal group. So this means it's like in general position. I do this for all of this. And if I intersect Z with that, and you think about what does it mean counting the points here, the map is injective, it means you count the point in the system. So my expectation is this. Now I have this geometric rephrasing, I have this variety z. Have this variety z, I intersect with the product of the n hypersurfaces. But don't you need like some coefficient in front, like the cost-round distribution, that you need to normalize by this binomial coefficient? No, it's not needed. I can do standard formal. So there is a difficulty. What is the difficulty? In the Edelman-Koslam paper, you just apply integral geometry. But here is a problem. The problem is that this kinematic formula, some of you will know it, and I will say more about it. When you have a situation, as is general, of a sub-manifold such that this group acts not also transitively from the tangent spaces, this is what's called co- And this is what's called cohomogeneous, and this appears in the type of couplings. This is co-homogeneous. The coherence is a nice situation. Then, if you have this, then this expectation has this very nice formula. Basically, product of the volumes of all the actors here normalized. But the problem is if you have more than one factor, you are not called homogeneous anymore. So you lose that property. Anymore. So you lose that property. You have to do something about it. Okay? So what we do, so what I need then is a more general kinematic formula, a formula actually that is well known. It was in a... So what was M? M is the number of... M is M is N. Excuse me. This M is N. Sorry about that. It's the number here. So it's N. Is n. So, so we need this formula by Howard. And I have a paper with Antonio Derari, but in the appendix, we maybe state it in a little more general. Basically, it's Howard, right? So, we need that. Okay, now I want to explain a little bit about that. It's related to work I have with Leo Martis and Antonio Lerari on Paul, so a little bit advertising it secretly, not very. It secretly, not very secretly, but actually I liked, you know, I thought, okay, why that's a good occasion. The paper is not finished. So, quantifying relative position of subspaces. So, we have a Euclidean space. Then we have the exterior algebra. Say on the level K we have an inner product, which is this formula looks maybe it's very natural if you think about it. It's very natural if you think about it. That's the linear product on it. So then, if you have two linear spaces in E of, say, of complementary dimension, you want to quantify the relative position. So the right way of doing is doing these principal angles. But these are several parameters. Here, I only want one parameter, and this is basically the product of the sign of the principal angles. But here, one can define it this way. So in V, I choose. So in V, I choose an orthonormal basis, V1 up to Vk, and in W as well. And then I watch all of this and take the norm. It's a number between 0 and 1. I call it sigma. Somehow measures the relative position and intuition is this. Sigma equals 0 means they meet non-trivially. Sigma 1 meets 0th or 1. Somehow it's some kind of an angle thing, but it's just one parameter. Just one parameter. And this is essential for the integral geometry. Okay, this slide is technical, but I try, please try to bear with me. So this makes these links to work with the zono winds. So I have my product of real projective spaces, and I think what I'm telling you is better, it's easy to understand if you think more abstractly. I believe. I think omega is a homogeneous space. So it's a G-multiplace. So it's a G mod K, and these are compact Lie groups. So this is how they are concretely. Then this K is the stabilizer group of my point 1. It's like a distinguished point in my homogeneous space. It induces an action on the tangent space, which happens to be in this situation is just a standard action. You see, product of orthonormal groups acts on those just the normal way. Acts on those just a normal way. So I have the action of the stabilizer on that. So now what I want to do, okay, it's technical the slide, but the intuition is easy. I want to have some kind of intersection theory about four years. That is the point. So now I have this sub-manifold Z, mention N, and I want to assign to it something. So in intersection theory, it's the number of the Chowry or cohomology. The chowing or cohomology, but what is it for the reals? Okay, so in the paper with Leo Antonio Paul, we have some answers, it's some zoning, but I cannot tell you more secrets here. Here, okay, I will just assign to the set some number, okay, but actually there is more. But just this, it will be just a number which can enter the formula. This is like the inspiration point for so now, how do I get this number? It has to do somehow. Number. It has to do somehow how is the position of Z relative to this special hypersurfaces. Now here is the definition. So here I pick a point P in Z. It has a normal subspace. Okay, then I move my P to my special point one. I can do that. And then I define a number, I we call it average scaling factor. And so what do I do? Scaling factor. And so, what do I do? So, my normal space NP also has moved to 1. It's G of N P. And then I measure the relative position with the product of lines. Why lines? Because lines are the normal vectors to my hyperplane. So these lines, yes. So, and you see, there seems to be a dependence on the element G, but it's not there because these lines are random. Lines are random. So this thing does not depend on the choice of G. It only depends on the sub-manifold and the point. And it's now a function, okay? This average scaling factor, which looks technical or complicated. But the point is, this kinematic formula. Wait for a second. Yes. The question was too fast. Go back. I wanted to ask you to go back. Shall I go back? If you can go back. Correctly, if you can go back. So we take n random lines. Yes. Right. And what is the relation we see? This is, okay, Z. I don't know if it's related to the normal bundle, but yes. So this is a normal subspace. Think of G equals one. You have this normal subspace. And then you have the sigma. You have two subspaces. This has dimension x. This has dimension n and this has co-dimension n. And then I have this quantity sigma I define, kind of measures the relative position. It says how this normal space or tangent space is not important. What is the average angle it has somehow with this? And I guess all that's homogeneous is a K, so it doesn't matter G. Okay, now this kinematic formula. Okay. So there's this. So, there is this theorem, and it comes out from Howard. Basically, if you look what Howard does. It's the kinematic formula for products of projective spaces. But actually, I've never seen it before written explicitly. But it comes out. And what does it say? You have an n-dimensional sub-manifold Z of this product of projective spaces. This expectation we're interested in is, okay, some factor. And here you have the integral over this average scaling factor. So this thing somehow is relevant. And then this paper that maybe someday we finish, I think maybe we continue here during this workshop. I'm very happy also it says more about it. And you know, this looks very technical, but it will be very nice. Then you have this sort of Really, very nice. Then you have these operates and you multiply that on this algebra. This becomes algebra. Okay, so much for the motivation. But this is the last thing. There's a generalization in terms of cross-manson algebra. I like this very much. Okay, so you can ask us. But time is running. So now, now, proof, I have time for the other theorem. What was the theorem? That was the random The random could be a random system of phenomenals. Okay, here. Okay, I want to make life easy for you. In that paper, I managed to do the mixed case. But let's go back to the case where all the supports are equal. That was covered in the paper, the Cauchy-Herd algorithm. But this proof is a little bit different. So I want to really emphasize how one can exploit the polyhedral. Can exploit the polyhedral structure of moving polyphones. Something I missed to see for many years, actually. It's very easy when you understand it. That's how you say. Okay, this is like a new proof of the bound, but okay, it doesn't give everything. Okay, so setting, I have my support A, utopolyto B B B, and I want to outline the proof of this bound. So what is it? This binomial coefficient here. Binomial coefficient t minus 1 choose n, number of vertices, and this divided by the volume of the p. I start like before, I have my very noisy like map. Now it's only one because it's only once or I call it psi. But then I do a change of coordinates. So I already said before we should actually this change of coordinates is very important. We don't look at polynomials, we look at these exponentials in forms. So, this is my map psi of the change of coordinates. And this Edelman-Costland formula, which is good here because I'm in the cohomogeneous case, it's no problem. This integral geometry formula immediately tells me, sorry, this is the typo, this should be E, this expectation is given by the volume of the image. Okay, and then you have to normalize. You have the image of that. Omit, you have the image of that, historical right, detect the volume, and basically that's what it is. And so, what I want right, and I have to bound this by this. So, I have to bound this integral by number of vertices times t minus 1 choose a. So, how can I do that? The volume is the integral volume and the usual volume that you take. Volume. It's the integral volume. It's the usual. That's the usual thing because what I can use this in. Thing because what I can use this integral geometry because I have the transitive action pattern. So, but now here comes this idea for people working in toric variety, it's very clear. For me, it was not clear. So, for each, okay, I have my Newton polytope P and the vertex small p, and then I have normal cones. Okay, this is called the inner normal cone, which give it. Normal cone, which give it the composition of R to the n. So maybe here is an instance, instead of looking at the formula, let's look at this. It's a little bit small. So this is like a two-dimensional. This is my corner. I have a vertex P of my polyto. Then it has a cone here. It's called, I think, tangent cone. Then look at the dual cone, but it's more easy to visualize the outer dual cone, which is this violet stuff, yeah. Violet stuff. It's this thing. Okay? And then, for instance, in this example, if I have a polytope, then all these violet cones give a partition of R to the M. Now here I only draw the full dimensional parts, but there are also lower dimensional parts, which this is called normal fan, but it's not relevant for my integral geometry because they have much zero. So, but I have now the space I have to integrate over all. Have to integrate over R to the L, right? But now you see this integral will be the sum over all vertices when I integrate over Lp. So I have to bound this. And it suffices to prove that this integral of this Jacobian over the normal cone is bounded by the normal recognition. Okay, but now that's now not too hard. So now what I do is I make a change of coordinate. Well, I go to an affine local chart. I go to an affine local chart. You don't need to know chart, but actually, what I'm doing. So I fix my vertex. Then, in this affine local chart, before the psi, the image of the psi was in projective space, but now this is in affine space. So there's a bit of notation. What I actually do, I have all these vectors of e to the, I don't know, but I have all these. But I have all this based. Okay, and this runs over A, and then I have picked one special position and I divide by this. So as a result, I get this, and what I have achieved now in this chart, all of these values are bounded by one, and at some position, the concordant is one. And then I Okay? And then I prove, I'm almost through, don't worry. So then I prove that the the the Jacobian is upper bounded this way. And you see there is some factor which is in red, which I bound by one. This is of course bad, and that's why my bound is not optimal. I should not do it. But this is actually one bound, and so I bound the Jacobium of psi by the Jacobium of the affine chart. But the affine chart. Chart. But the affine chart is now much easy to handle, and now it's the same trick as in the paper with Alter and Roger. I use the B Negauchi to upper bound this. So the square of the Jacobian by B negauchi, what do I do? So I have this like a rectangular matrix, okay? And then you pick all, you know, you pick all these full minors, sum the squares of the determinants, right? That's what. Of the determinants, right? That's what is written here. Okay, basically. And then I do, what do I do? I bound the L2 norm by the L1 norm. I get rid of the squares. It's technical. So I bound this by this. Now you see, but this is this sum over picking t minus 1 exponent vectors. So how many terms do I have? T minus 1 choose any. So the number of terms here is So the number of terms here is what enters the bound. And I'm left with bounding the integral over that guy. Enough to prove that. But how can you prove that? So I do a calculation. There's a little calculation. You don't have to worry at it. This comes out very explicitly. So the determinant, okay, what is Pi? I shift Ai by P. What these are these vectors Pi. So these are these vectors pi, the group of linear independent, I mean a corner. That they have a determinant, and then this function, and then one proves some technical proposition, which I haven't seen anywhere. So it's a lemma. I have a pointed n-dimensional convex cone, so it will be like the tangent cone of my Newton polytope. And then I have vectors B1. And then I have vectors B one up to Bn, which are in the dual cone. And then it is true that if you take this integral here, and I say something about this integral over the cone of the exponential function, multiply it with the absolute value of the determinant is bounded by 1. It's exactly what I mean. And this function is a very well-known function. So this function has a name. It's called the characteristic function of. It's called the characteristic function of the column. So people doing in convex geometry know this function. Sometimes it's called the also cost to Wingbert function. It's also the element quite unfinished. And also if you are interested in optimization, this is the self-concording barrier for this function. So it is also very important for convex optimization. But here it's just like an auxiliary thing which is needed for the proof. If it's what it is actually structured systems. Yes, I know that additive complexity. Time is over, but we are answering questions. Um no? You ma is your question related in connection to randomness? Related in connection to randomness? I don't know, or not. I mean, in general, it's true that this Kowonski bound gave a bound, a lower bound for additive complexity. So this is by now quite simple, and this was Gregorier resender. So that's but I don't for random, for example for random for random, I'm not aware of anything. For random I'm not aware of anything. So the random good point, as we know, this is the first website on random alternative geometry ever. I believe. Right? No? Ah, sorry about that. Did it just give them? No. I didn't even remember the titles of my paper. It was a school. It was a school. It wasn't a word type. It's bubble. This is one of the very first average real talk conjecture and the average number of real zeros and so on. Anything about the variance? About the number of zeros. There are. I don't know of any results related to the zero. I don't know of any results related to pure women systems. So there are these results where Jebo Armentano and this Uruguay school, but they don't deal with phenomenal systems and I'm pretty sure one can do something about it. For the real half conjecture would be quite relevant, right? But if you look at my proof, it's not an easy proof. So but yeah, it's right. But it's a very good question, right? Just fulfilling my assignment again? Just fulfilling my assignment again. I think Hosho has some results for higher months, it's economics and also there will be another talk by Hosho with a very besides very you are using uniform inner product or uniform coefficients for to represent the polymorph. So, no and not wasting the sort of thing. Now, if you change those coefficients, the worst case results default? That's a very good question, Gregorio. And I think as I said in the paper we dunno and caused, it was for any variances, in particular for the cost down. in particular for the cost line. Here, um right, so for the cost line I think I wouldn't get it. I mean I would get an additional factor which is like the maximum of the variance divided by the minimum of the variance, which is not nice. So I mean it's a really an open problem to the bound that I have to generalize to any variances. That's not obvious how to do it. But it's a very good question. It's a very good question. Thank you. So you can't kind of call it the number of zeros like in the bold or in the zero. If I want to look at the number of zeros in a particular region, I just say segment and I want to know like the number of zeros there. I mean it's all accessible because the integral geometry formula talks about it. So there is this word by Zeltichiefman. By Telvichieveman, very impressive work for counting complex zeros, where they give a lot of information about that. You could also do it. I mean, it's all in the range of the method. I think so. Okay. Looks like we are done, so let's thank each other. To meet again 30 minutes today. I know the central center.