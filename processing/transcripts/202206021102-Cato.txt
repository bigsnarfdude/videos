University and what I'm going to talk to you today about is what I hope is a success story that talks about how we can put together our interdisciplinary team to achieve the promise of predictive analytics-based clinical decision support. So, I'm a clinical informaticist, so my talk is going to be to Tony's chagrin: there will be no proofs. Proofs and the work that I'm talking about is covering about 10 to 11 years, so it's going to be very high level. And so, you know, ostensibly my talk is about how we're modeling clinician behavior. But as you, oh, that's weird. Why did it do that? As you might know, I mentioned that I was an infantryman for 10 years in my youth from when I was 25 to 35. So this is, so everything that I do, I have a mental model that runs through the infantryman. And in the infantry, we have this saying called embrace the socket. It's actually a philosophy that kind of encapsulates everything. Kind of encapsulates everything. And what it encapsulates is, you can see here, there's a young, you know, these folks, they're in the Syrian desert, and they've got, basically, you carry every, in the infantry, you carry everything you need with you. And you work in teams. And it kind of, and this guy's getting up, and it sucks when you take a break and you have to get up, and it sucks when you're walking, and everything basically sucks. And there comes a Zen moment where you just. A Zen moment where you just embrace the suck, and you're just like, I'm going to get done whatever I need to get done with my team, with the equipment I have at hand. So that's kind of the philosophy that I use for all of life. And so this is the problem. So I work in the inpatient setting mostly. And in the inpatient setting, a lot of people die every year. And we consider some of these deaths preventable. In the sense that if a clinician knew that a person was deteriorating, they could intervene early and keep the person alive. So, clinicians want early warning, what we call early warning scores or early warning systems. And the problem is, and because the EHR is such a rich place for data, everyone's like, let's get data from the HR, let's get data from systems. Systems. The problem is that there are a lot of problems, and we've talked about some of these problems until I think did a really good job of enumerating the issues. But the data is messy, and also it's time-dependent. And Dave and I talked a lot. Dave's talked a little bit about that time-dependent nature of data. George talked about the healthcare process. And it's difficult. And so to model. Difficult and so to model. And then also for us, there's a difference of from our research, us meaning Sarah Rossetti, who's a co-collaborator with me, there's a difference between physicians' expectations of physiological deterioration and nurses' expectations. And I'll talk a little bit about that. And then it creates sub-optimal communication in the team. And then finally, this is work that. Finally, this is work that George did a while back that influenced our work, was that when you think about the data that nurses are putting into the EHR, no one looks at it, not even other nurses. And George's analysis showed this in a paper that he published in 2011. They weren't looking too much at doctor's notes either, to be honest. They were more much lower rates. They're looking at much lower rates than nurses' information. And it was interesting when you read the paper. I mean, the interdisciplinary team weren't looking at nursing notes, and nurses weren't looking at other nursing notes. So all of this was happening when I was a graduate student and sat as a postdoc, and it all kind of influenced our work. And so, some of the solutions we came up with, and this is based on the work that we've been doing over the last decade or so. So, we've seen that We've seen that, and I also neglect to mention that I'm also a nurse. And so for me, the work that I do, I like to look at nurses and model nurses because they spend the most time with the patient. I think they're a really good sensor of what's going on with patients because of that. And so we know from our work that when nurses are concerned about a patient, they increase their surveillance of the patient. And then also, nurses often synthesize their information in a different place than physicians do it. And Tal mentioned that it's this horrible place called the flow sheet, N-E-H-R. And so there's structured data in the flow sheet, and then nurses write free text notes as well. And so you can see an example here, but nurses articulate their information. Their information about the patients in those two places, and we thought that we could exploit that information to do prediction. And so we did early work. Dave was on this, where we basically looked at patients that had a cardiac event and we tried to understand what nursing behavior could predict that event. And we found that there was work that nursing. There was work that nurses were doing in the flow sheet that could do that. And that was basically the foundation for our work. And we have a model we created called healthcare process modeling, which borrows heavily from the work that Dave did and the work that George did, where it basically says that you can, using the HR, which is our system, you could detect proxies of nursing behavior, look at patterns of documentation, and actually. Pilots and documentation, and actually, we're using natural language processing to look at concepts in the notes. We take that back to the domain experts and nurses and also physicians and say, what does this mean? And we build, we figure out those features. We do some feature engineering and figure out what those are proxies for. We build models to basically model the healthcare process. For this work, and I'm going to show, we're doing it for deterioration, but you actually do it. We're doing it for deterioration, but you can actually do it for basically anything that you're concerned about in the healthcare process. And so, one thing I skipped over is, you know, in the long, basically, it was like two-year conversation that we had with myself, Dave, and our data engineer, who's actually a theoretical math guy, was how we're going to model this. And we started out at the time doing the same modeling that was being done. Modeling that was being done by other folks where we're modeling basically physiological changes, and we were just like, you know, our background says that we need to model the clinician. So we're actually modeling a clinician's concern for deterioration instead of a patient deteriorating to get to predicting patient deterioration. Does that make sense? Okay. Say that you have one more coming up. So we are not modeling the patient. We're modeling the clinician's expert opinion that the patient. Clinician's expert opinion that the patient is interrogating. And so I wanted to just show you some data. So this is the y-axis is the probability of a measurement being taken over a 24-hour period of time. And we're looking at blood pressure entries right now that would be entered in the system. And the orange dots are during the day, and the blue dots are in the day. It during the day, and the blue dots are. I mean, I'm sorry, the orange dots are night, and the blue dots are during the day. And you can see that there's a distribution, there's a nice distribution there. And so, this is just some of the data that drove some of the decisions that we made about our modeling. And I think at the end of the day, it's a fairly simple modeling approach. Uh, we so I talked about concern. So, concern it stands for communicating narrative concerns entered by registered nurses, and it's funded by the National Institute of Nursing Research. It's actually a six-year study, and Dave is one of the co-investigators, and it's a pretty large team. Sarah Rossetti, who used to be Sarah Collins, is the multi-PI with me on this, and it's between Columbia University and Harvard. It's between Columbia University and Harvard University, New York Presbyterian and Mass General Brigham, two health systems. And so what concern really is it's an early warning system, which I mentioned. And as I mentioned, we are actually modeling nurses' expert clinical judgment that a patient is going to deteriorate. And so these are the aims of the study. These are the aims of the study. So, we spent aim one, we spent a long time building the models, basically. And what we use, you know, I think Tale talked about it when we were looking at the historical modeling. At the time, we were on two different EHR systems, so we had to harmonize data and then do modeling on it. There were lots of decisions, lots of work that Dave did trying to figure out what. Trying to figure out what were the features we were going to use and what were the outcome, just looking, understanding the system and what were the basic definition of deterioration. And our definition of deterioration is unexpected transfer of the ICU from MedSurge, the ultimate deterioration, death in the hospital, something called rapid response, which is either a family member or clinicians can call a rapid response team because they think the patient's getting worse and CEPs. Patients getting worse, and sepsis, which is bloodstream infection. And so, those are many, we have a composite model. So, it's if one of those things happened, so you can see that we're modeling something very broad, right? And we also had to do NLP work to pull out the concerning concepts. So, this is just a graph of some of the results of the natural language processing work we did. We have a whole program of research. We have a whole program research where we went to nurses, all types of nurses, both in Boston and New York, and said, What would be concerning for you? If you were concerned about patient deterioration, what would you put in the record? And then we use NLP and term expansion to build models to identify those concepts. And then we actually map those concepts to a standard terminology, a nursing standard terminology, that is then mapped to SNOMED, which was mentioned. Snowmed, which was mentioned on Monday, which we informaticists like to use for interoperability. And so all this shows is, so red is somebody eventually has an event and green is a control. And we're looking from 24 hours to either the event or discharge. And you can see over time that we could detect this concept in the node. And there are 64 concepts that we looked at. There were 64 concepts that we looked at. So, in our modeling, we used these features, very simple features, features that we felt that we could harmonize and get from the HR easily. So, you can see things like heart rate measurement, blood pressure. On the left, we don't really care that much about what the value is. We actually care about how many of these were taken and when they were taken over a certain period of time. And that's where the the modeling found signals. Where the modeling found signals. And also, these things like month, day, the week, hour, patient hour in the unit is actually very important because the behavior changes. Clinician behavior changes. You can see very clearly that clinicians behave very differently Monday morning than they do Friday morning. They behave differently Friday morning than they do Friday night and so on. So it's important to understand and it's and depending on how long the patient's been on the unit Depending on how long the patient's been on the unit, as well. And then on the right are the high-level concepts that we're extracting out of the node. And all this stuff goes into our models. So we did a bunch of modeling. And we ended up doing basic linear base modeling, some gradient-boosted XG boost. We used five. We used five years of historical data to both sites. We modeled each site separately and then together. And we ended up, the approach we ended up taking, and this was a kind of success story where basically myself, Dave, and our data engineer had lots of lively discussion. Was we ended up building, we ended up modeling every hour. We built a model for every hour of the day. And that's how we got around. Are the day, and that's how we got around the time-dependent nature of the issue. And then, and then we also created additional models. Uh, so there's a set of ICU models for every hour of the day, there's a set of acute care models for every hour of the day because the behavior is very different. The actual environment is different if you ever spend time in those two settings. And we learned that from the data. And then we found cutoffs, and this was just through experimentation of creating models. Experimentation of creating models for a person who's on the unit for three hours, 12 hours, 24 hours, so on. So we end up having 1,226 models, and this basically helps us in our implementation when we're actually doing the clinical decision support. So then the second aim was actually creating some type of intervention that clinicians were used. And Lena talked a lot about this. The approach that we took was a The approach that we took was a user-centered design approach where clinicians actually told us: we started with nurses and physicians, focus groups and interviews, and they told us things about the requirements for the workflow and also for the actual app that they're going to use themselves. So they helped us build that stuff. And so, one of the major things we learned is that we were planning to generate a score, we still generate a score, and then do an alert. Generate score and then do an alert. And they very strongly told us that alert was not going to work and the score wasn't going to work. So we created levels. The other thing that was really important that they told us is, and I think Dave mentioned this before, they told us they can tell what a green patient is and what a red patient is, but they wanted us to be able to maximize what a yellow patient is. So when we're setting our thresholds for our models, we use that information. And then another thing that was really important is we found Was really important: is we found racial bias in nursing behavior. And I won't go too deeply into this, but the take-home message is that for white patients, as they got sicker and had a deterioration event, nurses paid more attention to them than black patients. And then, interestingly enough, for Asian patients, it was almost flat. And so, we, you know, we very strongly knew that we need to make sure that we could adjust for that. We could adjust for that. And so, one of the things we did in our post-processing, after we did prediction, we did some post-processing adjustment for risk ratification, and then we did a test where we compared concern to the news and muse, which are two early warning systems. And we actually found that when we looked at a moderate patient, there wasn't a statistical significant difference between white and black patients. Black patients, and so, and there was with the other two early warning systems, and that was after we played around with post-processing. So, that was really important for us. And then finally, I just wanted to quickly show you. So, this is what concern looks like in EHR. It's this column here that, and it's in the patient list because clinicians told us that's in the workflow, that's where they go through, and that's where they would. That's where they go through, and that's where they would see it all the time. And if you were concerned about a patient, you would click down and go in here. And there's some really important stuff in here. This is our app. It's a web-based app that's embedded in the EHR. It's built with FHIR, which I mentioned before, which is an interoperability standard that allows you to theoretically build it once and plug it into different systems and be able to pull the data out in a standard way. But the important thing is. But the important thing is the explainability of the model, which came up a lot with focus groups, with clinicians, and we've talked about it a lot. So our model underneath, we've got, I think, something like 86 features, and you're not going to be able to explain that to a clinician, right? So what we came up with was this fact, what we call the factors pain, and we basically use what-if analysis. We basically use what-if analysis to bucket the models into these groups: nursing node content, vital sign frequency, nursing node frequency, vital sign comment frequency. And a comment is a clinician can right-click on a flow sheet and write a comment, for example, if they see some vital signs out of range. And then we also found signal in medication administration. So this line here shows the rep for this line here shows the relative contribution of this concern score of these. Concerns for these kind of buckets of features. We also, at the bottom here, clinicians also said they want to understand where this individual patient sits within the distribution of concern scores of other patients for either ICU setting or med search setting, wherever they are, right? And so we're showing that there. And these two, the other really interesting thing is in here, when you click on vital sign frequency, you actually see all. You actually see all the vital signs that were taken. And for clinicians, they didn't want to have to go back and forth between our app and then look at the vital signs. So, actually, putting everything together contextually is really important for them. So they can see what, so a physician could see what the vital signs the nurse was taking and what they might be concerned about, what was actually driving the score. And then they can have a conversation with a shared understanding of what's going on with the patient. One of the reasons we have the word communicating and concern is that. Have the word communicating and concern is that Sarah and I both started this research around the idea of how do we communicate nursing expertise to clinicians. And we actually want to drive, one of our goals was to drive, how much time? Yeah, 80 or 10 minutes. Okay. Was to improve communication. And so some good news. So as I mentioned, in AIM 3, we've been doing a randomized control check. We've been doing a randomized control trial both at Columbia and Harvard. The control trial is going to end in October, but we did the interim analysis just up in Boston. We found that for our intervention units, there's a 27% reduction in mortality. And we just looked at mortality because that's all, we have other outcomes, but when you do this type of analysis in the middle of a controlled trial, you try not to peek too deep. Control trial. He tried not to peek too deep into the data. So we feel very excited that we have some good results. And so, in summary, I just want to say I think the whole is greater than the sum of its parts. So our team coming together, all the folks that work together iteratively in every step, we're able to do something. And then, you know, that whole kind of what we call a military rucksack idea is that we have all the tools that we already need amongst a team to answer really. Amongst the team to answer really hard problems. So, some of the hard problems that we're still trying to figure out is the bias that I mentioned that's in the workflow, how we deal with that in our analysis and then in our clinical decision support. Generalizability, how do we generalize what we found in our randomized control trial to other settings? Communication between teams, and I mean teams like between me and Dave, for example. I think it took us probably like six years to really. Probably like six years to really start communicating really well. And then we also, you know, for us, we're leaving patients out of our concern. We want to pull patients in because we think we can build, we know that there's lots of information that we're not getting from other work that's been done at Columbia from patients that can improve the accuracy of our predictions. And then also, we really don't know a lot about how, we still don't know, I think, on a basic label. Know, I think, on a basic level, how clinicians and patients make decisions, and we still need to do a lot of more basic research about that. We talked about uncertainty yesterday and how to show that. And so finally, this is the concern team. You know, what I presented was done by all of these folks, and that's about it. Thank you so much. That was a lot. That's great. So, I mean, you're very straightforward about the fact that you're modeling behavior, especially behavior. And there are baked in things in behavior that have to do with like work cycles of people. They vary in the morning, afternoon, day of the week. Afternoon, day of the week, weekend, and potential versions of bias that come in in terms of the nursing staff patient relationships that appear to be related to race. And so you might think, oh, look, I've detected these things, right? And then Things, right? And then, so then maybe we ought to work on ways to reduce those biases. And then, if you do that, you introduce more another set of biases. Then of course you're going to end up introducing more biases, right? But you're going to have to retrain the model. Yeah. Yeah, it's a really interesting. So I feel like where we're at is this is, from our perspective, at a very basic stage. Even though we have good results, there's a lot we don't understand in the system. We don't understand in the system. For example, I have a graduate student who looked at variability of just clinicians, the variability of nurses, you know, and we're not accounting for that very well. And we've learned about behavior based on if you're a new nurse, a new nurse in the sense of how many years you've been out of the school, but also are you new to the EHR as well, right? There's all of that stuff that we're not accounted for. We're one of these traveling nurses. Yeah, or a traveling nurse, yeah. And so we actually have an R01. So we actually have an R01 that just started last month where we're using COVID as a natural experiment to understand some of that stuff too. But yeah, there's a lot that we're not accounting for. There's a lot that we're not modeling. The question is, I think ultimately the question will be what do you try to model and what do you not try to model? What is, what can you model? But I do think there are situations, for example, we're moving to Peattle. We're moving to pediatrics, where right now we're not modeling the patient interaction, but in pediatrics you can't ignore parents, right, especially, and kids. And so we're going to have to figure out how to be able to bring that into our modeling as well. So stuff like that. So I mean, are you going to, do you expect that the model that underlies this detection system, a warning system, is going to have to evolve with a... Have to evolve with organization or organism of so we took an approach. I mentioned we have 1,226 models. We took an implementation approach where we could put different models for different situations. So I didn't mention the model runs once an hour. And that's because you're not getting, we figured out that that was the timing. And we're really thinking about change on a kind of shift level because of how. Shift level because of how clinicians write notes and things like that. You can't really get more discreet than that. But in our implementation, we can embed the model in the database and understand the patient characteristics and run it for that appropriate, the model that performs best for what we think that situation is. So if we learn more, if we have better models for, for example, where there's race concordance between the patient and the clinician. Between the patient and the clinician, and you know, all this other stuff, we can have a model that works really well for that situation and run it for that patient when we're trying to do prediction, run it for that patient every hour. And right now, our process for all the patients in our hospital, even processing notes, it only takes 14 minutes to do prediction for every patient. So, that's the approach that we're taking: is that we know we're going to have to learn, create better models over time, swap out. The thing is, for us, we also The thing is, for us, we also want models that we can put in a database and query the database and run it for each patient in an efficient way. So that's one of the limitations that we have on an implementation side. But yeah. We can go ahead and issue. So can't you have a positive feedback in the sense that your model is based on behavior, and that your output will affect the behavior? Yeah, so that's it. Yeah, so that's come up in the sense that Clinician said to us. The sense that a clinician said to us, hey, if nurses know what behavior is.