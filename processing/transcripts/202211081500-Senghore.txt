So, yeah, please go ahead and yeah. Perfect. Thank you so much. So good afternoon slash evening. My name is Madike Sengor and I am a postdoc at the Center for Communicable Disease Dynamics here at Harvard. Disease dynamics here at Harvard. And I work in the lab of Bilhanij. And I'm going to talk to you today about a project that I've been working on for some time using deep sequencing as a tool for inferring transmission pairs. So I am, there are a number of reasons why I'm interested in transmission. And one of those reasons And one of those reasons is that transmission plays a very important role in the life cycle of organisms. And understanding how transmission occurs, who infects whom, is very useful for informing things such as epidemiological parameters, like the R0 or the secondary attack rate, which can determine how many people we expect if a case pops. We expect if a case pops up in a house, for example. It also can tell us where the pathogen of interest is spreading and who is driving transmission. Are there super spreaders or is it just sporadic transmission? And also it can identify novel routes. So my work really is focused on using genomics to gain more insights into how organisms are transmitting. So, I thought it would be nice to start with this example of genomic epidemiology work that was done during the provincetown COVID-19 outbreak earlier this year. And I think what really stood out when you look at the graphical abstract is how implementing genomics alongside conventional approaches like contact tracing prevented the outbreak from surging out of control. Break from surging out of control. And I found it interesting how they really depicted a lot of my thought process when I think about transmission in this image, where they showed links based on contact tracing data, and then they also showed putative links based on genomic data. And then they sort of merged these two to come up with a set of strong links that are likely to be. That are likely to be genomics, that are likely to be transmission. Now, one of the challenges that we have when we look at transmission is that using classical phylogenetic approaches, which are based on single nucleotide polymorphisms, sometimes you have a situation where there are a lot of samples that are almost identical and the genomic data doesn't really give you much more. Then, there are also, there's also. Then there's also the case of oversimplifying the data, where you're taking data, which is basically from 0 to 100% of the read's mapping to a certain allele, and you're condensing it into a simple binary of is the SNP available or is it not available, or a multinomial of four different potential nucleotides, for example. So, my thought process was how much more information can we get from the genome? And we really touched. And we really turn to using within host diversity. And if we think about an infected host, but we think about the infection as a combination of different strains that may be closely related to each other, either by introduction or by evolution within the host. When this individual transmits to another individual, they transmit over a snapshot. A snapshot of that diversity to the other person, and if we were to look at that in sort of an alignment form, and this is a very simplified version of it, but essentially what we would find is we would find sites in the genome where some of our reads are mapping to one allele and other reads are mapping to the other allele. And what we have seen is that if we look at these sites and we represent these as ISNIVs or as within-host variants, mapping the Those variants, mapping the presence and absence of these ice nibs can inform which isolates are linked by transmission or not. And this is very useful. The challenge is that the ice nibs that are most informative are the ones that are rare in the population. So that narrows down the scope of how much more you can learn from them because they're only present in a few isolates. The other challenge is that, well, if the isn't present in three or four. Present in three or four closely related isolates, for example, you're back to square of having basically things that are almost identical. So the question is, how can we get quantifiable data from this scenario? And how can we make that output actionable so that a public health official, for example, can tap into this data and get a good idea of who's likely to be affecting whom? So the work I'm going to be presenting is based on a transmission model. Is based on a transmission model that was done by our collaborators in New Zealand. And in a nutshell, this is a controlled transmission experiment where we have a mouse that's infected orally, put in a cage with another mouse until it infects that mouse, and then we continue to do that for 22 steps. At each step, we collect a sample of the feces, and the feces are mapped with a fluorescent, so they become fluorescent whenever the mouse is infected, and we do deep sequencing on them, so we capture within host. Sequencing on them so we capture within host diversity. And the rationale is very simple. Based on what we observe of within host diversity, can we identify transmission pairs? And this is just an overview of the bioinformatics pipeline. I'm happy to leave the slides available for people to query it, or you can look at it in more detail in the preprint. But in the interest of time, I'm going to skip over it. So, the aim really is to use heterozygous sites to improve the resolution. So, what we're doing is we do a standard bioinformatics pipeline, but instead of just defining things as a homozygous SNP or not a homozygous NP, we take those values that we would have otherwise just labeled as N, and we actually measure the allelic frequency at these sites. And what's different about this approach is that we're quantifying the difference between. We're quantifying the difference between the allelic frequencies at all the sites in the genome, and we're using that information as a proxy for how closely related two things are. And we really developed that rationale based on what we observed in the data. So this is like a classical phylogenetic tree showing how these samples are related. You have 10 different transmission chains, seven out of them developed a fixed mutation, a few of them develop only one mutation, some of them. Develop only one mutation, some of them three, some of them two. And you're looking at a scenario where you have about a new variant emerging every seven days. And out of those, maybe 10% or so will become fixed. So one of the things that we observed early on was this sort of drifting effect that variants emerge, some of them sort of become submerged back, and some of them drift off gradually. Of them drift off gradually until they become fixed in the population. We do have instances where things they become selected for and the increase is very rapid. We do have cases also where there appear to be multiple strains competing. But we thought, on average, if we sort of looked at things in detail at sort of the whole level of the level of the whole genome, that these would essentially be a That these would essentially be a general trend, and a generally increasing trend with the number of transmission steps. And in large part, that is what we saw. So when you look at the distribution of changes in allelic frequency, in this case, the mean change in allelic frequency, then what we're finding is that over one transmission step or two transmission or three transmission steps, we're seeing a gradual increase in the mean change in allelic frequency. The mean change in allelic frequency per site. And we use this metric to essentially calculate the likelihood, which I'll talk about in the next slide of how we do that. But all three of these likelihoods, if we use a simple area under the curve approach, all of them seem to have a pretty decent sensitivity. Now, I remind you, this is a data set of almost 200 strains where the most strains that a transmission chain has accumulated is three. has accumulated is three. Almost every strain in this data set has another strain that it is identical to. And at the base of the tree, there are about 149 different samples that are all based on conventional SNP metrics. They're all identical to the index strain, the strain that started all the transmission chains. So this is a substantial improvement on what we can get in terms of identifying who infected whom. And this is just, you know, these are just box plots that are showing how. Plots that are showing how these metrices are distributed in transmission pairs versus things that are not transmission pairs. And the one that sort of separates the two populations out the most is the likelihood. So that is the one that we went with. We also looked at how much it changes if you restrict by time. So can we see if we compare two different strains in a population, can we see if they are from the same transmission chain or? Are from the same transmission chain or different transmission chain, and how well does this improve when we restrict by time? So, when we say we're only going to consider things that happened before, for example, and we can see quite a marked improvement once we incorporate just one additional variable of time when did the sample become collectible. So, I also looked at the bottleneck estimates of these comparisons of the transmission pairs just to be sure that there is some support for what we're inferring. We're inferring, and for the most part, the credible intervals appear to be between 1 and 30. When you go above that, essentially, what happens is the confidence intervals for the bottleneck estimates just keeps increasing and increasing and increasing. So, there's not much confidence there. But Maddie K. Yes, can I hi, it's Jesse. Sorry, can I interrupt with a clarification question? Um, so I think I missed this, I just about sort of your. I think I missed this. Just about sort of your ground truth of the transmission pairs. Like, these are like multiple mice in a cage or like, what's the so you know, this is single mice. So we know exactly who infected whom. So each transmission was done one-to-one. So you have the index mouse and the next mouse in the chain. And when that mouse becomes infected and the poop starts to become fluorescent, we take that mouse. Fluorescent, we take that mouse out, which is newly infected, and we make it the index in the second cage. So we build the transmission chain gradually, like that, one mouse at a time. Okay, and I guess the non trans so what would be a non-transmission chain pair? Those are mice from different pairs, and it would also be mice from the same transmission chain, but not directly adjacent. So, for example, a mouse. So, for example, a mouse at step one would not be considered as a transmission pair to a mouse at step four, for example. I see, I see, I see. Got it, got it. Thank you. Perfect. So, basically, what we tried to do is to understand if we could to try and get this metric of the change in allylic frequency in the context of what's happening in the population. So we took. Population. So we took all the ones that we knew were transmission pairs and we fitted their mean change in allelic frequency to a truncated normal distribution. And we did the same for the ones that were not transmission pairs or essentially the data set as a whole. And this is where it gets a bit tricky because in like a population database data set, for example, you can get this from your data. You would have to find a way to infer this. You would have to find a way to infer this. And I haven't quite figured out how to infer it, but I am thinking about a method where you can use the bottleneck size estimate and the mutation rate to get an idea of, well, in an average transmission chain, how much drift would I expect to see? And that would essentially determine what this distribution looks like. So essentially, yes, so this is basically. The approach that we use, a simple Bayes approach, where we do the probability of transmission given that we observe a certain change in allylic frequency, and we plug that into Bayes' formula by simply sampling these two distributions. So I'll jump straight into some results. And essentially, I think the easiest way to do it is just to pick out samples randomly from the tree. So this is the phylogenetic tree, a minimum. So this is the phylogenetic tree, a minimum spanning tree showing which chains are developing mutations. We do have one case of convergent evolution here and I'll show an example from there. But essentially, if we picked a sample from the base of the tree in this transmission chain, for example, we can actually see that there is a pretty good signal identifying things that are like both the donor and the recipient, and also something that's like two. And also, something that's like two transmission steps down the line. There is one sort of thing that is in a different chain. But again, given that we're coming from a scenario of 149 different samples that are all identical by SNP difference, I personally think this is a very good step in the right direction in terms of getting more resolution out of these guys. And if we go further down on that transmission chain, so now this chain has acquired a mutation and fixed the mutation and it Fix the mutation and it even, I mean, the signal becomes even clearer then, becomes even clearer then. So here's another example here again. This is at the base of the tree. This is a lineage that has a convergent evolution mutation before the mutation becomes fixed. And after the mutation becomes fixed as well, we see again decent patterns, but there is something that's worth pointing out here. Something that's worth pointing out here. Now, what happens is, if I sort of just flip back a few slides, I'm not sure if this is something that was noticed or not. But essentially, over the course of multiple transmission steps, when a SNP becomes fixed in the population, it's almost like a selection sweep. So, there are a few transmission chains where there's basically no within-host diversity. So, what happens is without within-host diversity, Without within host diversity, our approach is basically useless because there's nothing to latch on to to tell you that things are more similar than not. And what's happening is you're seeing it identical to things that are sort of immediately next to it in the transmission chain, but also it's similar to other things here because the same thing happened here as well. When these two other strains acquired the mutation, they also went through a selection sweep for a few steps and there was nothing that could distinguish them. Could distinguish them. And when we sort of try and put this in like a context to see how well it's actually doing, so this is a very crude sort of approach to sort of measuring how well it's doing. But it's basically saying, okay, out of my top hits for all of my sample, what percentage of them are within one transmission step, two transmission steps, three transmission steps? And again, it does a decent job considering how much information we're gaining. Information we're gaining from things that are otherwise identical. And, you know, if you look just at the top hit, only about 50% of the time you get the actual transmission pair. But this includes things where there isn't any within host diversity, so you can't really tell. But when you look at whether they were within close proximity, so within three or four, well, in this case, five transmission pairs, 80% of Five transmission pairs 80% of the time the top hit falls within five transmission steps of the question of the query isolate. But also, if you really wanted to find the actual transmission one, in about 80% of cases, it's within the top 10 hits. So if you're a contact tracer, for example, imagine having this sort of metric in your database. And when you click on a sample, it gives you a list of 10 or 20 potential transmission pairs. And you can use that to sort of as a short list. To sort of as a short list to look at your contact tracing data and other epidata to help you to identify which one is the likeliest, of course, transmission. So, the final thing we did was we thought, okay, well, let's try and reconstruct the network based on this likelihood metric that we've calculated. So, this here is the experimental data. So, this is the ground truth where we know who infected whom. And here, what we've done is we've basically said, well, Basically, said, well, if there is a clear-cut top hit, if there is one strain that is more likely to be the donor than any other strain, we're going to take that as basically what we are taking to be our donor. So a very, very, very basic decision algorithm, right? And we only thing we did was we restricted by time. So we said, if we're interested in a mouse that was at step four. In our mouse, that was at step four. We're only going to consider things that happened step four or before. I think we did like three or five steps before step four, for example, right? But we didn't discriminate by time. So if the metric said that step two is closest to step four, we assign step two as the transmission pair. And you can see that it does a pretty decent job of identifying things that are in the same chain. Things that are in the same chain. In some cases, it gets the order right. In other cases, you know, it might flip the order around a little bit, which is to be expected given fluctuations in allelic frequencies there and there. But overall, it's pretty useful, I would say. I think there's a lot of potential in this. And I think there's also a lot of potential for refining this. This is a very crude way of looking at this. I think you could, you know, someone smarter than me. But someone smarter than me could definitely build a much better decision algorithm around this, and someone more aware of how the contactation data and EPI data is structured can fit this into that a lot better and get a lot more out of it. But it's a start, I think. And I think it's a good indication that there's a lot more we can get out of genome sequence data in terms of understanding how bugs are spreading. So just to sort of wrap up, I think I hope I've convinced you that. I hope I've convinced you that within-host diversity is informative, which we've known for a while, but also that how much within-host diversity changes by is also very informative to the point that it can help us distinguish transmission pairs from things that are otherwise identical, like have the same SNP difference, for example. And I think that if it is used in the appropriate way, I think that this method can significantly complement contract. Significantly complement contact tracing and other epidemiological data or processes, sorry. And just sort of a caveat for, you know, I think really in order to use this method, you need to be, so you couldn't use this method if you picked single colonies, for example. You have to be sure that your methods actually allow you to capture within host diversity, which sort of comes naturally to viral genomics since you sort of do like a metagenomic approach anyway. But in terms of bacteria, Anyway, but in terms of bacterial, you need to really think consciously about capturing within host diversity and how you culture and extract your DNA. And also, it would work if there are multiple hypertypes in the host. So if you have a selection sweep and there's only one dominant strain, then there's not much more you can get out of this. And also the bioinformatics counts as well to avoid having too much fluctuation. I didn't touch too much on the bioinformatics, but we had to do quite some stringent filtering to get to a set of SNPs. Set of SNPs and within host variants that makes sense. And finally, I think, you know, not a replacement for EPI data. I think this is a good complement for the EPI data and the contact tracing tools that we have. And also, just be aware that you could have spurious matches, you know, convergent evolution, you could have, you know, sequencing error and all sorts of things. And this is just a big thank you is a big team from Bill's lab and also from Susie's lab, the bioluminescent supervisor. Susie's lab, the bioluminescent superbox lab in Auckland. And yes, I think I'll wrap up here. So I leave a few minutes for any questions. And this work is available now as a preprint on bioRxiv. So please feel free to download it and have a look. I'd love to get some feedback from the community on the paper. Thank you so much. So, I think we have a few minutes for questions. Actually, like quite a few minutes. There's a question there in the chat. Can you see it? So it's from Leonid Attens. He says, sorry, I cannot ask my question out loud as I don't want to wake up anyone. But this was really an interesting talk. I wonder if you deal with a full metagenomic data set or only a specific set of pathogens. Or only a specific set of pathogens, and if so, and if so, which ones? Thanks, Leonid. I think that was a very important point that I didn't clarify. So, this is with Citrobacter Rodentium. So, we use Citrobacter Rodentium, also commonly known as mouse E. coli, and we only looked at Citrobacter. So, we extracted the Citrobacter. The only difference is when we grew the Citrobacter on the selective media, we didn't pick a single colony. Collective media, we didn't pick a single colony. We took the whole population and extracted the DNA from the citrobacter. Anybody else has some questions here, Sam? Hi, Malike. Thank you. Great, great presentation. I just wanted to ask sort of how much coverage do you need to be able to get a signal? What's the minimal amount of coverage do you need to be able to sort of use this technique per sample? And then, sort of, following on from that, how much does And then, sort of, following on from that, how much does that cost? And is it feasible to sort of apply this into general transmission chain analysis? Perfect. Thank you so much. Yeah, so this is definitely a very important question. I haven't tested it formally, but in this data, we had pretty deep coverage, which was about 700 or over 1000x in most cases. In most cases, I haven't tested it, so I haven't essentially downsampled and run the analysis again to see. It's probably something that I should do, given I get this question quite a lot. But my inclination is that sequencing technologies are improving, and also the bioinformatics pipelines that we use to analyze them are also improving. And my hope is that we can get it. And my hope is that we can get it to a situation where somewhere around 100x or 200x coverage would be feasible, and you could get reliable data from it. I haven't tested it. It's something that I should definitely do. But then, if that's the case, you could do this experiment on an Illumina MySeq, for example. You could easily run a batch of 20 or 40 samples on a MySeq, and then you could apply this type of analysis there. But I haven't But I haven't tested it formally yet. Anybody? I cannot see the Zoom panel, but here in the room, anybody else has some questions? Hi, Meike. Great talk. So I was wondering, did you use the whole genome sequence or just the core genome? So we just used the core genome for this analysis. So we did basically. So, we did basically the phylogenetic pipeline as you normally would. But when we got to the stage of deciding what is a SNP and what is not a SNP, we kept the sites that you would normally label as an N, and we analyzed numerically what is the coverage at these sites and how is that coverage changing over time or in different patients and use that as a proxy. Um anybody else? Any questions? Jesse? Hey, Madica. One more question. Great talk. Very interesting. And this is sort of follows up on my clarification question that I asked. I guess I'm wondering, so like you've got different steps of the same transmission chain, which are probably easy to confuse with each other. So that's like a hard task to figure out. Task to figure out the order of those change. And then you've got these completely independent chains, right, where evolution just takes an independent path. Presumably those are harder to confuse with each other, easier to distinguish. So I mean, is that the case? I couldn't really see in your inferences. Presumably, I assume you do a pretty good job of distinguishing like completely separate transmission chains from each other, but it's harder to. From each other, but it's harder to say: did step two infect state step three, or did two infect state step four, or something like that. That gets tricky. Is that the case? I think you're spot on. I think you're spot on. That is definitely a challenge. I mean, in some cases, it does a pretty good job. So, if you look at, for example, this transmission chain here, which is, I think, N4, if you go from eight, nine, You could go from eight, nine, ten, but eleven sort of latched on to eight, for example, and twelve is sort of latched on to nine. So you would get some level of confusion here. But the nice, I think what sort of what complements that in my view is that it's showing you where the transmission clusters are. So it's going to be, I mean, the deeper you. To be, I mean, the deeper you get into it because of the fluctuations of you know, you have bottlenecks involved in transmission, you have multiple like cells multiplying within the host, and there's factors within the host as well. So, naturally, there's going to be some fluctuation. But even when it doesn't tell you exactly who infected whom, it gives you a really good idea of where the cluster is. So, these are the ones that are most related, but it also, in some cases, It but it also, in some cases, does a good job. Like here, it goes from 13, 14, 15, and then it goes sort of 16, 18, 19, 20, 21, 22. But it's not perfect, but it does do a decent job. You know, it does do a decent job. Yeah, thank you. Very cool. You're welcome. Thank you, Jessine. Any Any questions? If not, I think we can move on to the last talk of the day.