Irina is a professor of mathematics at the U.S. Naval Academy. Let's see, tell us about self-repelled sports. So I'll turn it over to you. Thank you so much. Thank you very much again. Thank you for the organizer and for all of you for being here. The work that I will talk about, this rigorous approach to the dynamics of self-propelled swarms, is joint work with my colleague Kostya Medinets and midshipman Carl Kolla. The system that The system that I'm going to work with for almost the entire presentation consists of n agents. Think of them as oscillators. And their position vectors are vectors in Rq. And the way they change, so their acceleration, has two contributing factors. The first of them, the non-linear path, controls for speed. If the speed exceeds one, it's normalized. If the speed exceeds one, it's normalized to one, then the system slows down. If the speed is under one, it accelerates. And then the second part is the linear coupling. In the vast majority of the slides, and I may not even get more, the coupling is one to all. If I am going to denote by capital R for the rest of the slide presentation the center of mass, then this second control is that the particles don't be too far from the center of mass. Center of mass. Many people prefer to think of this system in terms of describing the potential that generates the coupling. So these are also known as parabolic potential or quadratic confining potential. They go by different names. It's always the case that agents that are coupled have a little bit of a paradoxical dynamics. If I am to ignore the coupling entirely, so all the term that has the average 1 over n, the linear term, and you look at the In the linear term. And you look at the dynamics of one agent isolation, it turns out that whatever the initial velocity is, that direction gets maintained, and the particle eventually reaches speed of one in a monotone way, and it maintains the direction of motion. So if you look to put together the particles in isolation, you see them shooting into on their own line of support. The moment you introduce coupling, though, it turns out that regardless of the initial conditions, the age Regardless of the initial conditions, the agents remain in a spatially cohesive configuration around the center of mass, and the center of mass itself can have two different behaviors. If the center of mass escapes to infinity, then all agents synchronize their direction of motion. So you see them kind of wiggle about the direction of the center of mass. But if the center of mass remains bounded, then the agents oscillate about this moving center of mass. Moving center of mass. Now, if you do some sort of simulation and just try simulation for the couple system, and I have two different illustrations, the first one is associated with a center of mass that stays confined in a bounded region in the play. I have the frame moving so that the frame be centered at the center of mass. When you see that the When you see that the wiggles slow down, it's because the center of mass had become nearly stationary. And the particles have uniform distribution minus 2 to 2 for position, but they start from rest. So here is the animation. Eventually, they are going to have a steady rotation around the center of mass that's nearly stationary, and you see unitary speed over there. I'm going to start in that dimension. We call that conflict. We call that configuration a rotating state. One of the things that I want to draw your attention to is that this doesn't have uniform distribution. The fact that we don't have the assumption of uniform distribution of the particles on the unit circle for the angles, it's a major technical difficulty. Now, in my second animation on the right, again, the frame is centered at the center of mass, but this time the center of mass escapes to infinity, so you're going to see the frame kind of move down. The frame kind of moves down because the center of mass moves up. And the particles have velocities that have all pointing up and to the right, yes, where the center of mass is going to go, and otherwise uniformly distributed position in minus one to one. And this is what their behavior looks like. They have smaller oscillations around the center of mass. Eventually, they could collapse all into the center of mass and move with the rectilinear motion that I presented earlier. Now, for people who work with coupled systems, I just want to draw a very quick comparison with the better known classes of swarms or oscillators. If we assume that the position of the particles were not in the plane, but all in one dimension, you can just assume that it's on the real line, and if you go from the system satisfied by velocity as opposed to position, so you just differentiate once both sides, you get a system of 100-port oscillators that, again, are coupled with the. Oscillators that again are coupled with a linear therm. And this has been studied intensely in electrical engineering and whatnot. Again, our problem is two-dimensional, and this feature would be like an unstable configuration when you embed it in two dimensions. If you think that the oscillators synchronize, that maybe you should look with the same techniques that you look at the Kuramoto oscillators. That's not the case for us because we have a higher dimensional both acceleration. We have a higher dimension of both acceleration and possession, and the angles that are associated with the position and with the velocity actually are not only influenced by each other, but also by spatial conditions, how far the oscillators are from each other. And sometimes these are known as swarmulators. Maybe you can that. And finally, the work of the Bertosis group at UCLA, they have looked to explore similar self-propelling conditions. Similar self-propelling conditions, right? We have here the energy conglomerate motion single-tower term, and the potential that decreases much faster. It's a Morse potential, exponential decay at infinity. But their assumption is that the particles have large numbers of particles, they're rather uniform distributions, so you can go to a PDE model and think of it as a continuous model. Again, because our distribution are all for clumps and gaps, and maybe have just three particles as opposed to 10,000 oscillators. Opposed to 10,000 oscillators, we have a very different setup and the results are different. Okay. I just want to go quickly to the naive approach to the dynamical system. So, well, if the purpose is to kind of stabilize the speed around one, let's just pretend that the non-linear factor goes away because the speed is one. Then, what you have is a very simple linear system of copper oscillators. You can get right away that the center of mass has to have zero acceleration. Of mass has to have zero acceleration, and so what you're going to recover is the two animations that I showed. That if you have constant velocity, you have this translating state, and if you have stationary center of mass, right, still constant velocity by velocity is zero, you have these oscillations, the rotating situation. And unfortunately, this naive approach does not capture the full dynamics, and I just want to show one last. Dynamics, and I just want to show one last animation: that you don't have these global attractors because it is possible that your particles have a center of mass that has a stable oscillation. So it never goes to zero. And this would be a new pattern that we found through theoretical techniques because it was in a small parameter cell. So exploration alone was not enough. Okay. Okay. Today I want to focus my talk on the rotating state because I think it's the easiest to illustrate the technical difficulty and the solution that we propose to overcome that. So I will talk exclusively about this rotating state and perturbation near it. By that, I mean that the center of mass eventually will approach a stationary location and then the particles themselves will spread on the unit circle in such a way that their position In such a way that their position sums up to zero, so the center of mass is at zero. But again, not uniformly around the center of mass, just the sum is here. Now, the problem has some sort of invariance. It is invariant to rigid rotation, so if I have such a state and I rotate them all by the same degrees, or if I translate them all by the same amount, we still get the solution. Unfortunately, once you exceed three parameters, these states of ours have a lot more deformation. A lot more deformation and a lot more configurations that don't come just from rigid rotation. Think of an equilateral triangle. If you only have three sides of length one, they are all going to be equilateral triangles. But if you have a rhombus, now you can have it a square, but you have additional deformations in the configuration, not just the rigid rotation. And that's why the problem is very complicated if you don't have uniform distribution like the regular polypodies. Okay. Well, because we expect that things are going to rotate with speed one, we right away want to move with a rotating frame. So we are going to remove the e to the i t part of our configurations. We are starting with some initial condition angles theta k0 that are summed up so the center of mass at the origin. And we do this local rotation so that after we So that after we remove the rotation, the fixed point becomes all at coordinate one. What I am showing in the diagram here at the bottom is the original configuration with five angles. The sum of the center of mass is at zero. But if you think that they are placed so that you do the triangle rule of adding vectors, you have like a polygonal that has all sides of length one and they kind of close back to zero. And as you pull Back to zero. And as you push into it like an accordion, you get other configurations that are still stable points, that are still equilibrium points in this new frame. That means that the new fixed points are not isolated. Near each configuration you can deform a little bit and you have a new equilibrium point that it's going to mess up with our calculations. Well, first thing you do, you try to linearize and maybe try to learn enough from the To learn enough from the linearization. Unfortunately, the Jacobian matrix, which by the way has many, many parameters in it, as many as the angles at the beginning, has a very, very large number of neutral directions. So if n is odd, you have an n-dimensional central manifold, and if n is even, you have n plus 1 neutral directions. So although you can reduce dimensions somewhat, you are still left with a very, very difficult dynamics. Yeah, so typically people try to eliminate the stable directions and just stick with the neutral direction by going to the central manifold. The idea is that if you have a change of basis and you have separated away, for me the central directions, the neutral and are in X, is that the ones that contract, the Y, you can eliminate out of your dynamics by going to the manifold that's a central manifold. That manifold Manifold. That manifold, although it's not unique, its Taylor expansion is unique and it's computable. You can find approximation for the central manifold so that your problem now becomes smaller dimension. Instead of 4m for me, it becomes of dimension n or of dimension n plus 1. The trouble is that when you calculate the Taylor polynomial and you truncate the substitute the formula for the central manifold, For the central manifold, there's no guarantee that the truncated system captures the original dynamics after you truncate it. And this is very little documentation in literature that the Taylor technique is guaranteed to fail if you have non-isolated fixed points. If you look at the stability or robustness of dynamical systems, they all start, assume that you have an isolated cycle or an isolated fixed point, and then maybe you have some sort of almost hyperbolicity near it, we just don't have that. Deniering, we just don't have that. And I want to show you with a simple example what can go back and what does go back with stellar polynomials approximation. So the simplest dimension where you can capture that is a three-dimensional system for which the central manifold has dimension 2, and within that, the equilibrium points or the fixed points have dimension 1. And again, the equations themselves are kind of irrelevant. So in x and y, Irrelevant. So in x and y, I'm going to have the central manifold, and in the direction z, it's going to be the stable one. And actually, the differential equation for x is built up. So you can see how the manifold parameterized by any y and z being x sine x is invariant under the motion. So that is an explicit formula for the central manifold. So we know what the flow is to compare the truncation against that flow. Again. Against that flow. Again, the fixed points, easy to see that y and z have to be equal to this x and x. And if you look at the correct dynamics, I should take a breath. I'm using the simplest function that does not have a finite Taylor polynomial expansion, right? My point is that Taylor polynomials don't work, so I use the function sine of x, which has a infinite Taylor polynomial. Infinite table of polynomial table of expansion. So, the exact dynamical system now becomes two-dimensional on the central manifold, and I substituted the exact formula for zx sine x. And it turns out, I'm just going to go to the picture, that this is what the correct flow looks like. The fixed points are marked in black, the curve y equals x sine x, and then the vector field is marked with the blue arrows, and trajectories. Arrows and trajectories that are in the upper half plane all approach the fixed points, but not the origin. Yes, the only one in the upper half plane that goes to the origin is on the y-axis. Everything else leads to a fixed point nearby, so we have stability, but the origin is not asymptotically stable. Well, typically these parameters feed in into other parameters of the system, so having zero parameters and having positive parameters makes a huge difference in coupled dynamics. A huge difference in couple dynamics. Now, let me show you what happens if you now use a Taylor approximation for this central manifold. Well, it's an odd polynomial sine of x, so you can go into over approximation with Taylor polynomial or under-approximation. And in my diagram here, I'm showing what happens if you under-approximate. So here it is. My original dynamics has the y change replaced by the approximation. Change replaced by the approximation, again, odd polynomial for the function sine of x. And it turns out that the two isoclines, right, you solve for x dot equals 0, y dot equals 0 to find your fixed point, because of the error in Taylor polynomial, the isocline is now split into two different curves. Where x is not changing, it's still the original kernel x sine x, and then at the bottom is the dashed line in black, is the second Line in black is the second isocline where y itself does not change. So, because of the errors that you have to make if you truncate with stable polynomial, you are creating transport through the isocline. So, where the motion was supposed to stay fixed on the upper curve, it actually trajectories penetrate there from the up and from the bottom, and the trajectory get trapped in the region created by the two isoclines and forced to go to zero. So, no matter how high you go in the detail. So, no matter how high you go in the degrees, you're either going to create an asymptotically stable origin which it wasn't, or you're going to create a region of repellent if you go to overestimate in that case. So, you have to do something else. Okay, so I just have here a picture of side-by-side of what we have to do. Actually, let's keep going. Okay, so the focus that you know, I'm going to use five more minutes to discuss. I'm going to use five more minutes to describe how we went around and how we prioritize creating a new approximation for this central manifold. The whole point is that you need to have an explicit approximation for the central manifold so you can actually manipulate the flow. So this implicit, if there exists something that does such and such, is not good enough. So we wanted a constructive technique. We are assuming that we have equilibrium points that are at least of dimension one, at least one curve. Although in our application, we have a slab of dimension n minus one. Have a slab of dimension n minus 2 or n minus 1 additivity points. So we want that at all costs we maintain zero error in our approximation for the fixed point. So all the approximations that we create have to be error term smaller than the distance to the equilibrium point, as opposed to Taylor that created distance to the origin itself or your center of the Taylor polynomial. So it's like So it's like preservation of isoclines. If it's possible to explicitly solve the equation where the contracting directions are exactly equal to zero, you would start from there. We have an iteration that follows the theoretical construction of a contraction operator, of a space of slogans, just a mouthful of things. But how you initialize that is the kind of important thing. So if you cannot solve that explicitly, then just go and find. Just go and find a solution that is approximating the stable solution being zero so that the distance to the fixed point is preserved. And something very simple. You have to know what the fixed points are for your system. If you don't know what your equilibrium points are, you're doomed, right? So at least you need to know that. And one way to start with H0 is for each point in the tangent direction, just go at one of the nearest points on the fixed point line. Point on the fixed point line, on the fixed point submaniflow. So at least you can do that. And then what you do, you plug that into our iterative technique. And remember that your goal is to approximate not the central manifold, but the vector field that you have produced on the reduced dynamics. So your goal is to approximate what happens if you plug the central manifold into the flow. And that actually is always at least one order better than the approximation in agency. Um, by the time you're done, what you want is that the error that you have introduced is always much smaller than the vector field itself. You have a lot of fixed points. At all these fixed points, the vector field is zero. For the error to be smaller than something that's zero, the error has to be zero. Okay, so that's kind of the philosophy behind the choices that we have made and. And with that technique, we are actually able to work in our original problem. The problem with the particles that rotate and proving that we have stability for the rotating state could not possibly be asymptotic stability, yes, because you have non-isolated fixed points, so that means it cannot be asymptotically stable. It turns out that it becomes very difficult if you have an even number of particles, because Because, in the case when they are very much clumped into polar opposite kind of configuration, you have an additional level of degeneracy. And in order to handle that, it's the dispersion within the two clumps that you have to control. So, long story short, we were able to prove that these rotating states are stable and the limit of the accumulation points has to be another rotating state or the module reach out. Rotating state of the module region. Another advantage of working with constructive techniques is that you can now control how slow is the rate of convergence. And unfortunately, it turns out that the rate of convergence is very slow. It's of the order 1 over the square root of t, which means that numerical simulations become very problematic because it takes a very, very long time to see a motion that has this rate of convergence. And I am going to go over very quick animation to show that actually, let me explain what you're seeing. The left side are actually particles, I mean the single dot are actually particles that have already nearly collided, and the other one are just as many, but they are now started separated. They will eventually collapse into each other, and they just remove lots of tiles to lead to the eventual collapsing of the whole system at the Of the whole system at the convergence. Rate of convergence for logic squared. Finally, this sort of results can be carried over, at least of the configuration in space, to dynamics for which the positions are not in the plane but in higher dimensions, for particles that are not necessarily normalized to have a common speed of one, but different speeds, and for coupling that are linear but maybe. Coupling that are linear, but maybe with symmetric and positive semi-definite connections. For example, nearest neighbor would be an example, would it have it? As long as they have a predetermined topology. It's not like dynamically allocated nearest neighbor, but you set it up from the beginning. And we can prove things about whether the location stays bounded in time or whether it stays in a bounded configuration. Or whether it stays in a bounded configuration relative to the kernel of this new configuration matrix. But I think that I'm going to start here because it starts with a bit very technical. For those interested, I have a skeleton of bibliography. Perhaps we start with questions on Zoom. Are there any questions on Zoom so far? There are no currently questions. There are market current questions on the whole screen goes out.