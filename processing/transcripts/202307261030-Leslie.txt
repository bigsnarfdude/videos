So today I will talk mostly about two relatively recent papers. One very recent paper with Chiang Wei. Second paper was posted just yesterday on the archive. So basically I'm going to talk about the 1D oil alignment system. So I think So, I think for this audience, and especially since Cheng Kui gave a nice introduction yesterday, I won't talk too much about just what these equations say, but let me at least write down the Cucker-Smail system, how I align the system. So here's Cucker-Smail. We've got capital N agents with velocities VI, positions XI and masses Mi, subject to a communication protocol mean. Communication protocol for me. And what each term on the right-hand side of this momentum equation is doing is trying to bring the velocity of agent i a little bit closer to that of agent j. How hard it tries to do this depends on the mass of agent j and also on the strength of the communication. As encoded in this communication protocol, we'll always assume that the communication protocol is non-negative, and we'll also assume that it's radially dependent. And we'll also assume that it's radially degrees. Euler alignment system is basically a hydrodynamic version of this Hugger's nail system. So here, rho is the macroscopic density, and u is the macroscopic velocity. And as Chankli pointed out yesterday, the fundamental character of this system depends strongly on whether or not, well, it depends on properties of your communication protocol, Thieve, but Communication protocol fee, but maybe the biggest dichotomy is in terms of locally integral versus not locally integral. So we are going to focus exclusively on the locally integral case of this talker. I put everything in scare quotes here, but basically this dichotomy corresponds to hyperbolic versus parabolic character of the Okay, so one reason that Cucker Smail and Euler Alignment have received a lot of attention recently is basically because of their long time dynamics. So one example of interesting kind of long time dynamics that these systems exhibit is something that we refer to as strong flocking. At the discrete level, what we mean by this is that the That the configuration of the agents should sort of crystallize in the time asymptotic limit, whereas if we're talking about the continuum level, what we mean is that the density profile converges to the travel assumption. Of course, you need to specify a topology here, but in general, for us, we'll be talking about situations where our density doesn't have to have a lot of regularity, so this conversions might happen even just like in the Inversions might happen even just like in the weak star sense of measures, and rho bar might just be a measure. So strong clocking is guaranteed for all initial data under this heavy-tail assumption that again changes. So we say that a communication protocol is heavy-tailed if it's non-integrable at infinity. So the thing that I want to talk about today is basically what the density profile looks like after a long time. And in particular, where the density is large. When I say large, really what I mean is infinite, or what I mean here, in the case where there's a sort of a mass clustering effect at a single point. Just a Just to motivate this, in this case that we're considering where the communication protocol is locally integrable, we know that diract masses can appear in finite time, even if you start out with smooth initial data. And even if your solution is smooth for all time, we can get this mass concentration effect in the time asymptotic 11th. So this row function. This rho bar could have direct masses in it, even if rho is smooth for all the time. So we want to predict where this mass concentration, where this mass clustering happens, and we want to do so from the initial conditions. That's sort of the goal. And in the case of smooth solutions, we'll talk just a little bit. Solutions. We'll talk just a little bit, or I'll mention what you can do for unidirectional solutions, but mainly this is going to be a 1D talk. Okay, so since we want to talk about the situation where the density profile develops direct masses, we're necessarily, most of our conversation is going to happen in the context of weak solutions. And I'll talk about the weak solution theory that Chenki has. I'll talk about the weak solution theory that Tankli and I developed in some detail. But I'll also talk about smooth solutions because the weak solution theory is very much informed by smooth solution theory. And finally, I'll talk about mass clustering, which is sort of our main focus. So for smooth solutions, we'll talk about the critical threshold condition, which tells you which initial data corresponds. Initial data corresponds to global and time existence of smooth solutions and which corresponds to finite time global time. And also tell you how to look for this time asymptotic concentration of mass for smooth solutions. For weak solutions, the theory depends on two separate viewpoints, which are nevertheless compatible, and the compatibility of these two viewpoints. And the compatibility of these two viewpoints is what gives us both existence and uniqueness of solutions. So, these two viewpoints are the following: First, we are going to build our weak solutions by first writing down atomic solutions to our system. And the atoms, and these atomic solutions, will follow what we refer to as the sticky particle CuckerSnail type. So instead of just following Cucker-Smail, they will follow Cucker-Smail. They will follow a cooker snail, but whenever two agents collide, they'll stick together for all future times. The post-collisional velocity will be determined by conservation of momentum. The other perspective is that we are able to reduce this system of two equations, in 1D at least, into a single scalar balance law. And when we have a scalar balance law, it's natural to write down an entropy condition where you can, it's non-trivial. It's non-trivial to prove, but once you have an entropy condition, you can sort of expect that maybe that there's there. So these two viewpoints turn out to be very much compatible. And like I mentioned earlier, this is what helps us to get both the existence and uniqueness for weak solutions. So once we have a good understanding of the weak solution theory, I'll move on to I'll move on to mass clustering. First, I'll tell you exactly what I mean when I say cluster. I mean, intuitively, a cluster of mass forms whenever there's this Dirac mass. But I'll give you a more precise definition that'll make the theorem statements a little nicer. With the right definition, it turns out that it's very natural to describe exactly which regions of the initial data correspond to, well, no clustering. Well, no clustering, which portions in the initial data correspond to always clustering and which depend on what your protocol is. And we refer to these as the subcritical, supercritical, and critical regimes, respectively. So we'll probably be running pretty short on time by the time we get to the theorem statement. So if I manage to prove anything, it'll just be the proof that clustering happens in the supercritical region. Critical region. Okay, so let's talk about smooth solutions for just a moment. This quantity E that you see here made an appearance yesterday. Chiang Peng called it G. It's basically the same thing. So this quantity E, the derivative of u plus our communication protocol involved with the density, obeys this continuity equation. And the critical threshold condition. And the critical threshold condition says the following: if E is positive everywhere, then we have global and time smooth solutions. If it's negative somewhere, then we have that time block. And if it's zero somewhere, well, what happens depends on what the communication protocol is. If the communication protocol has happens to be bounded, then we sort of revert to this sub-critical case here. Some critical case here. And we have, if phi is bounded, then even this case is okay. We get global times mean solutions. But if phi is weakly singular, and what I mean when I say weakly singular is that it blows up at the origin, like r to the power minus beta, for some beta between 0 and 1, in particular it's integrable. Then finite ten globe is possible. It's not guaranteed, but it's possible. It's possible. So, this is one version of the critical threshold condition. A pretty much equivalent perspective you can get if an equivalent, but what I think is an informative perspective is one you can get by looking at an antiderivative. So, this quantity, which I'll call C, again, is just an. Again, it's just an antiderivative of E, but it's the velocity plus the odd antiderivative of our communication protocol convolved with the density. Using this quantity, we can write the Wendy Euler alignment system in a way that's very reminiscent of the Wendy pressureless Euler system. So this function c plays the same role that the velocity plays for pressureless Euler in a lot of For pressureless Euler in a lot of contexts. In particular, well, you can sort of see just from the equations, but for pressureless Euler, the characteristics associated with this equation transport velocity. For 1D Euler Limit, the characteristics transport velocity to C. For you get crossing of characteristics for pressureless Wheeler, if and only if the velocity, initial velocity decreases somewhat from left to right. Decreases somewhat from left to right. For one alignment, what you look at is the monotonicity or naught of the quantity C naught. So this is another, I think, nice characterization of the critical threshold condition in terms of this quantity. And I think it gives a useful interpretation in terms of these characteristics. You can actually make You can actually make these observations quantitative if you happen to know that C is not even heavy-tailed and you have a global Lebanese move solution, but in other words, V naught is known to be non-decreasing. In this case, well, if phi is bound in a heavy-tailed, then we have strong flocking for all possible initial thetas, so it makes sense to talk about the limiting trajectory map, which I'll call that. Limiting trajectory now, which I'll call xy. So, what this comparison says is that the limiting distance between two trajectories is bounded above and below by a constant times this difference in the C naught values where these trajectories initiated. So, this statement is interesting in and of itself, but it takes on a special significance when this right-hand side is zero. Hand side is zero, right? Because it means that these trajectories end up in the same place, and all the mass that was initially between them sort of gets crushed to a point. So this is this time asymptotic concentration mass phenomenon which girls. So this gives us one way to predict exactly which location. Predict exactly which Lagrangian labels correspond or contribute to the mass concentration. It's precisely those in the set Z where C naught is locally constant. In fact, we can be a little bit more precise even. We can say that if Phi is not in the heavy tail, I guess I forgot to write this down, but if C naught is also not a great taxi. C naught is also non-decreasing. Then the density profile converges, a weak star in the sense of measures, to a limiting, a limiting profile, a limiting measure, which has an absolutely continuous part and a singular part with respect to a vague measure. And the singular part precisely corresponds to the portion of the density profile that lives in the set where CNOT is initially constant to be through the push forward. So, this is the sort of basic statement, and in this paper, we used this characterization of the set of labels which contribute to this mass concentration to do a couple of different things. We applied it to unidirectional solutions as well. Similar characterization there. Draw some nice pictures. We can also cook up initial data where the mass concentration. Where the mass concentration set, or the support of the singular part of the Limits profile, has like a fractal Hausdorff dimension, which I think is pretty cool. I won't talk more about that now, though. I want to move on to weak solutions. So, first, we would like to know where we should look for weak solutions. I think it's natural to look for weak solutions. And I think it's natural to look for weak solutions in the space of measures, or density should be a measure, because we know that in general trajectories can cross-sometime at time. It's natural to look for measure-valued density. The simplest kind of solutions to Eidel alignment that are measure-valued are atomic solutions. So, in particular, if these If these discrete quantities, xi and vi, obey the Kucker-Smail dynamics, then this is an atomic solution. This is a solution in the sense of distributions to alignment. But these are very far from the only atomic solutions. So in a typical case, some trajectories will actually. Some trajectories will actually cross each other, right? And when these xi's cross, you can impose basically any collision rule that you want that conserves momentum. And the result will still be a distributional solution of Euler alignment. So we need some way to choose between these different possible collisions. So you could have the free flow dynamics, the particles just pass through each other without really noticing. Particles just pass through each other without really noticing. We get to have elastic collisions make bounce off each other completely inelastic collisions. Something in between. We need a way of designing. So even at the discrete level, one way that you can sort of, we end up choosing the sticky particle dynamics with completely inelastic collisions. One feature of these Of these collision rules is that they happen to dissipate the most energy. That may or may not be convincing, but it turns out that these are also, they play a significant role in the theory of pressureless weight equations. So it sort of makes sense to look for a selection principle that's compatible with these sticky particle technologies. More importantly, though, we want to make sure we want a selection principle that We want a selection principle that doesn't just work for atomic solutions, but for any possible initial data that measure value of initial data. So we're looking for a selection principle that satisfies both of these properties. And once we have solutions, they're unique, we want to go back to our original question. Where do Dirac masses fall? By night or right minute time. By not already all time. As I mentioned earlier, we're trying to look to the pressureless Euler system for inspiration. And this is a particularly simple case because the free flow dynamics are just straight line patterns. So there's been a lot written about 1D pressureless Euler. I will not go through all of these results. The most relevant for us The most relevant for us, the situation that actually generalizes, most of these don't, is this 1998 paper by Franier and Frenier. They are able to reduce the 1D pressureless Euler system into a single scalar conservation law. And they get uniqueness at the level of this conservation law. One thing that I'll, so I mentioned, I won't go through all of these, but the other I won't go through all of these, but the other paper that I'll mention is this 2009 paper of Matthiel and Savare. You can actually write down a basically explicit formula for the pressureless Euler dynamics. And I'll talk more about this in a little bit. It turns out not to work for wanting Euler alignment, but it's something that's worth trying, and I'll explain why it doesn't work. Why it doesn't work. Okay, so here's our framework and our theorem of existence and uniqueness. So we start out with some compactly supported probability measure as our initial density and an L infinity velocity with respect to that probability measure. And well, there is a unique entropy solution associated with this initial weight. Associated to this provincially. What do I mean when I say unique entropy solution? I mean uniqueness at the level of some scalar balance law. We are able, like Prenier and Prenier, we are able to reduce one new pressureless Euler into not a scalar conservation law, but a scalar balance law. We're still, we can translate our initial data for pressureless Euler into initial data and flux for that scalar balance law, write down an entropy condition for the scalar balance law that you can. Condition for the scalar balance law that gets uniqueness, solve our scalar balance law, and translate back. So that's what I mean when I say that we have a unique solution. In order to actually generate this solution, what we do is we basically discretize. So we use a front-tracking approximation scheme to generate discretized solutions of autoscaler balance law. And what I think is really remarkable about And what I think is really remarkable about this is that we can use sticky particle cucker smail dynamics to tell us how to evolve up fronts. So we encode the initial, we discretized initial data and flux into sticky particle cucker smail initial data. We run our sticky particle cucker smail dynamics, and then that tells us the locations and positions of the fronts. Take n to infinity here. To infinity here, and with the entropy condition is preserved, we get a unique solution of our scalar balance. All right. So I won't prove this, but what I will do is I will give a formal derivation of the scalar balance law that we reduce our system to, and also define each of these discrete. Define each of these discrete quantities to give an idea of what this differentization looks like. So let's go back to the 1D pressureless Euler system as we wrote it down when we tried to compare it to the 1D Euler alignment system in the formulation that we wrote down and tried to compare it to. That we wrote down and tried to compare it to a pressureless Euler. These are two continuity equations for the quantities ρ and ρ times C. If we take antiderivatives of each of these quantities, the resulting m and q both satisfy a transport equation, A. So this is where the derivation becomes formal. If everything is smooth, then the solutions to this equation should be unique. Should be unique. Rho is a non-negative function, so m should be non-decreasing. We can find some function q naught that satisfies, sorry, we can find some function a such that the initial q and initial m are related in this way. And we expect that relationship to propagate. If we just plug that relationship into That relationship into these equations, what pops out is exactly the scalar balance law that we're after. Here it is. So emphatically not a scalar conservation while we have this non-local source term that causes us some problems when we try to do the analysis. But we can write down a very natural guess for an entropy condition. An entropy condition for the system. This turns out to be good enough to guarantee uniqueness of climate solution. To prove uniqueness, we basically run the Khrushchev doubling of variables argument. And we, well, this takes a while because we have to deal with extra labels from this poster. Okay, let me be a little bit more specific about how we. More specific about how we translate our initial data. So, our initial data for the scalar balance law is just going to be a cubit distribution function associated to our initial density. We shift it by a constant for technical reasons I don't want to get into. We also define the generalized inverse of m0 as follows. As follows. So if m0 is a strictly increasing function, then this really is just like the inverse. But we need a slightly more subtle definition to take into account that while it is monotonic, it might not be strictly increasing and it might have jumps. So here's our definition of sort of generalized inverse of M0. I'll refer to I'll refer to the domain here of x0 as a set of mass levels. So our flux is defined in terms of x0. So really what this is, is I'm taking another antiderivative. So our flux is like an antiderivative of C naught, but in mass coordinates. So our precomposition. So pre-composing with x naught, so everything here lives in mass coordinates. It's not difficult to show that even with this funny definition of inverse, this flux obeys the relationship that I want it. Okay, what about the discretization process? Well, I want to replace my initial Initial m0 with a piecewise constant function, step function. And I would like to replace my flux by a piecewise linear function. And again, I'm not going to go through all the details and how we pick all these different quantities, but the point is that we have a procedure for doing this discretization that gives us sticky particle covers. us sticky particle cocker snail initial data and also initial data and flux for the discretized scalar balance law. The one thing that I will emphasize here are these quantities C I naught. So these are like the discrete analogs of the quantity of C from earlier. And just like C is sort of the derivative of A, Of A, these discrete quantities give you the slope of the discretized flux in between the breakpoints. Okay, if we run the sticky particle Kucker-Smail dynamics, what happens? So I realize there's a lot of notation here. I'll try to make it a little bit more intuitive. So our completely inelastic collision rules guarantee that at a collision time, or really any time, That at a collision time, or really any time, the velocity associated to a given agent is like the averaged velocity of all particles involved in the collision. So J sub I here is the set of indices corresponding to agents that are stuck to agent I. As a consequence of our completely inelastic collision rule, we can actually show that our quantities Ci Ci have a similar relationship. But we get this not just at that input here doesn't have to just be immediately prior to a collision or immediately prior to time t. I get this for all times between 0 and t. Basically, because the quantities are conserved along the cover-smail dynamics in the absence of collisions. So if we evolve the sticky particle Kucker Smell dynamics, what happens at a collision time? Well, these CIs average out. So this is what happens if agent 2 has collided with agent 3. The picture that we can. Okay, and as I mentioned previously, I'm going to go ahead As I mentioned previously, the sticky particle Kucker Smann dynamics tell us how to evolve the discontinuities in our discretized scalar balance law and how to evolve the atoms in our atomic solutions. Write down an explicit formula for these guys if we know all the sticky particle covers male dynamics too. These discretized quantities converge. Converge in natural ways. So the discretized solution of the scalar balance law converges to a true entropy solution associated to our original initial data in the L1 sense. And the time derivative converges to be started sense and measures. What this means at the level of our Euler alignment variables is we get convergence in Latin 1 for a density profile and convergence weak star in the sense of measures. And convergence weak starts as measures of our momentum. Okay, so I wanted to go through this discretization procedure, not because, because it does get used in the proof of mass clustering, but I will try to, I know the notation is a little bit heavy, so I'll try to motivate what I will say about mass clustering without explicitly referencing. Explicitly referencing all this notation. Okay, so the one piece of notation that we will use is this generalized inverse. So the generalized inverse of our cumulative distribution function assigns a position to each mass layer. Right. I want to know where the solution has gathered this much mass. Well, I look for this input and I trace it to its position. It's given by x0. So we define clusters in terms of the locations of these mass labels associated to this function, this generalized inverse function. This function, this generalized inverse x of t. So we say that a cluster forms, or we say that a cluster forms when x is constant on some interval of mass lattice. So it assigns the same position to an entire interval of mass lattice. And the largest half-open interval on which x is constant is going to be the cluster that's. Cluster that's associated to that mass level. So, this is for finite time clusters. Infinite time clusters, we say, occur if the diameter of some interval containing our favorite mass label shrinks to a point if we apply x to it in the time asymptotic frame. So, in this case, So in this case, so jumps in M0, of course, or jumps in M of course correspond to direct masses, the level of density, and intervals where x is constant. Our big question is where do clusters form? So, as promised, let me tell you something that doesn't work before moving on to what we actually did. So, for pressureless Euler, we have essentially explicit solutions. And so, it would be rather silly to do a lot of complicated analysis on one D Euler alignment if there were just an explicit representation of the solution. We would just know where all the clusters were. But what works for pressureless Euler doesn't always work for one the Euler line. Want the oil alignment, and here's an illustration of why. So, this very nice result by Natiel and Sabare says that you can recover the dynamics of pressureless boiler by running the free flow dynamics and then projecting. So, when I say projecting, I mean this is like a projection, this is an L2 projection onto the convex cone of non-decreasing functions. So that's a little bit of a mouthful, but let me describe how it, well, the situation for us to keep particle cocker snail. So if we've got, say we've just got three particles, x1, x2, and x3, and these sort of intervals represent the, let's say, the support of the Let's say the support of the communication protocol. So X1 here never talks to X2 or X3. X2 and X3, however, they collide very quickly and they stick together under a sticky particle called CuckerSmail. This is different than what happens for CuckerSmail, right? Because these agents are allowed to cross paths, and as soon as And as soon as this agent on the right crosses, it starts talking to agent one. If we project these onto the closest non-decreasing function, it turns out to look like this. The x1 still drifts to the left, even though it's not talking. Even though it's not talking to agents two or three. And so I think this is a pretty convincing argument that what Natila and Savare did is not quite work. Of course, they have a lot of extra structure in their equations because they have like a gradient flow structure. But worth checking, I think, to make sure that it really doesn't work for us. Okay, so what do we do? Well, let's go back to what we already know for a little bit of inspiration. So to go from E to C to A, we kept taking antiderivatives, basically. So our flux is like an antiderivative of C naught in mass coordinates. And the relationship between A and E is like this, if everything is nice and smooth. If everything is nice and smooth. So positivity or non-negativity of E0 should be related to convexity of A somehow. And that's going to be sort of what motivates our discussion. Let me also just note that I'm going to use A double star as a notation for the lower convex envelope of our flux A. This next statement is maybe a little bit less intuitive, but I'll try to explain what I mean. At the discrete level, we can immediately rule out certain types of collisions using the lower convex envelope of our discretized flux. In particular, if If there are agents that have collided with agent I, then the corresponding interval of mass labels has to be one on which the flux is linear. What does that mean? Well, it means that, for example, agent one can never collide with agent two. Because while the lower convex envelope of this discretized flux, I mean, it looks like Flux, I mean, it looks like this, right? So, in particular, it's not linear on this interval from theta 0 to theta 2. These two agents are never going to collapse. But this collision that we sort of already drew on a previous slide, this collision is allowed because A double star is in fact linear on this interval. And you can And you can sort of guess that these agents will actually collide because, well, we talked earlier about how collisions do occur when C is decreasing somewhat. So here, the slope of A decreases as I go from here to here. So these two sort of guess are going to collide, and they do. The proof of this lemma is Is non-trivial, but it boils down to two very simple ingredients. First, I mean, we obviously have to use properties of complex functions throughout. But the other, I mean, the dynamic thing that makes this work is, well basically that if you've got a collision, the agents that are coming in from the left have to have agents that are or have to have velocities that are no greater than the velocities of Than the velocities of which it's coming to the right. You apply property convex functions on this very centric one over and over and over again, and you eventually follow your nose to this conclusion. I won't get into the details, but this sort of gives us very convincing evidence that the A double star should enter our analysis. With that in mind, let's break up the interval of mass labels into three different sets. So, first, sigma plus is basically going to be the set where A double star is convex, or strictly convex, I should say. Right, sigma minus is where A and A double star. A and A double star are separate, whichever they're different. And sigma 0 will be the region where A and A double star agree, and they're both linear. So this lemma tells us that, at least at the discrete level, linearity of this lower convex envelope is a prerequisite for collisions. Is a prerequisite for collisions. So we expect that there shouldn't be any collisions involved in this sigma plus. All of the collisions are going to happen here. Or here. Or here. So here's our main theorem. Actually, not quite. Let me give you slightly more careful definitions of Definitions of these three regions. So, the subcritical region is going to be defined as the region of mass labels such that A double star is not linear on any interval to the left. So, this is basically like strict convexity of our flux, of our lower convex envelope of our flux. The critical region is where A and A. A and A double star are equal, and where the both linear and the supercritical region is where A is bigger than A double star. Roughly speaking, our conclusion is that clustering never occurs on sigma plus, this subcrane region. It occurs at every single mass label, sigma minus. And if you want to look at mass labels other than sigma plus and sigma minus, or Than sigma plus and sigma minus. Or this only has to do with finite time finite time clustering. If you are interested in time clustering, then you have to look at what phi is. It depends on the behavior of phi at the origin. Okay. So first two statements are basically just a a recap of what I said for the A recap of what I said for the subcritical and critical regions. More interesting, let me tell you a little bit about what happens if you, in the case where the clustering behavior depends on what phi is. If phi is bounded, then there are only two types of finite time clusters that can occur. Either it has to be there from the beginning, there has to be a Dirac mass that's already Has to be a Dirac mass that's already in the initial data. Or the cluster has to basically be inside a single connected component of this supercrypto region. So if phi is bounded, then no cluster can go, like, there is definitely going to be finite time clustering at every single mass label in this interval, but I can't go beyond. If I look at infinite time clustering, the situation changes a little bit. Let's assume that our communication protocol is heavy to build. Then the infinite time clusters can extend beyond a given connected component of the supervariable region. In particular, So, the infinite time cluster associated to, let's say, this mass label will be exactly this largest interval on which a double star is linear. So that's sort of like an analog of E0 being identically zero on this interval. I mean, it's not, but it's sort of the replacement if we allow for finite time collisions. So the clusters will be separated by the non-degenerate agents, right? Yes, yes. So that's good. Otherwise the blast will capture the whole meaning of region. Right. But you don't see it in this picture, but you can also have things like two of these supercritical intervals right next to each other, maybe possibly corresponding to a single. Possibly corresponding to a single interval where a double star is linear and all that sort of thing. So that's if phi is heavy-tailed. It doesn't matter whether the protocol is singular or bounded at the origin. If you're only caring about infinite time, then that's what the situation is. If phi is both weakly singular and haggy-tailed, then all of this happens at phi. Detail, then all of this happens in finite time. So this whole interval will collapse to a point in finite time if your communication protocol is both heavy-tailed and deeply seen. Okay, so that's our full theorem, and I think I have just four minutes left, so let me try and convince you at least that this statement is plausible. This statement is plausible. So, what we do when we prove that clusters actually do form in the supercritical region is we zoom in on a single connected component of this supercritical region. So let's say that m minus to m plus is this interval that we're looking at. It's one challenge of proving that clustering occurs. Challenge of proving that clustering occurs here is that it might be the case that m minus and m plus remain separated for all time. We've defined our supercritical set to be an open set. So even though mass clustering is guaranteed to occur at every single point inside this interval, these two labels might not ever meet. So we sort of have to move in just slightly if we want to prove this theory. If we want to prove this thing. So the other thing that this picture sort of incorporates is that we've subtracted off a double star inside this interval. It's linear anyway. So this A minus A double star should be zero at each of these endpoints. What that does for us is it allows What that does for us is it allows us to compare what's going on near these endpoints in terms of, well, basically the velocities associated to each of these labels. So if there is a cluster here, the value of C at that cluster Of C at that cluster will basically be this slope. If there's a cluster here, then the value of C will be this slope. Now, our C's are not precisely velocities, but remember that they act like velocities in a lot of ways. So, morally speaking, this cluster over here is Is and this cluster over here are moving towards each other, right? Because this slope is bigger than this one, and we can actually put a lower bound on this difference in slopes. And so they're moving towards each other. We can actually put a bound on the time at which they collide. Because before they collide, these slopes are different. Slopes are different. So, the one tricky thing here is that we have to make sure that the left endpoint of the cluster here doesn't move outside of the supercritical interval. Because once it does, we're no longer guaranteed this lower bound on the difference in slopes, on the difference in speeds. So, So, I won't get into the details, but once again, we need some sort of technical lemma to show that indeed this alpha here, the left endpoint of the cluster at A sub H, cannot move beyond M minus, at least before it collides with this cluster over here. So in the weekly So, in the weakly singular case, I can actually have this cluster expand beyond this interval. So, it is a little bit delicate. But the time at which this happens has to, at which alpha moves to the left of m minus. This can only happen after the whole interval has sort of collapsed. And so we prove basically a discrete version of the state. Basically, a discrete version of this statement. And actually, the discrete version is what we use to prove the finite health clustering. But we also prove fully this sort of statement at the continuum level. And that's helpful in analyzing the critical routine as well. Okay, so I think I've talked enough. So thanks a lot for your attention. Any questions? So the first question is what sort of communication weights are you considering? So any locally integrable communication protocol that is non-decreasing, or radio. So, it is weekly simpler. It could be bounded or we could see. Okay. So, the second question is: what is your time and regularity of your solution? What is the time and regularity of your solution? So our solutions are so they live in space BV on 0 to T. On 0 to t cross R. So they're bounded variation in tactics. Okay. So one comment. So your psi, your quantitative psi, which is sort of like the antiderivative of that integral, right? So it has a very meaningful representation or understanding when you look at the particle system. Yes. Because you can do in 1D occurs mail, you can integrate the system in time. What you obtain is something that is almost like the Kuramoto model of oscillation. And the natural frequencies, so the parameters that sort of describe the tendency for large-time behavior is precisely your side. is precisely your side. And this was uh used by uh Sengil Ha and his uh collaborators a couple of years ago paper this complete predictability of large time here. So this is somehow I mean it's not the under alignment in the sense that it's not quite okay, but it's somehow there. Right, so so this is This is true. So, when they talk about clusters, their clusters are very different than the kind of clusters that we're talking about, even at the discrete level. So, this is another sort of motivation for this picture. Their dynamics are just cover snail. So, there's no way that we're going to be able to recover. To recover sticky particle cockers male from their result, or the clusters of sticky particle cockers mail from their result. But I agree that it's very relevant. Any questions? Go back to the conservation law or imbalanced conservatory. The right hand side, Solutions, they are monotonous, there are no shocks. No shock formation during these systems. So there can be shocks, there are no rarefaction. Wait. There can be shocks, but no rarefaction. I mean, there is a weak formulation for this, right? Yes, yes, of course. Worried about the right-hand side of the cassette, did anybody. Ah, okay. We do write down a more careful weak formulation. But by definition, I always want decreasing functions. Yes, yes. Okay, but everything depends on the flux, of course. Another question is that there is a uniqueness rate for this balance law, right? Remember that there is the issue when you go back to the original system, right? Why don't we uniqueness there? Okay, so um the only choice that we make um so um So we do indeed make a choice when we choose a flux that satisfies this. But the only time that this is really a choice is if our initial data has Dirac masses or if the, so this is totally, this is not any sort of choice if m is surjective on the interval from minus one half to one half. Right, and if there are Dirac masses in our initial data, what's going on is we are choosing A to be linear on the interval of mass labels associated to that direct mass. So let's say this is our This is our interval of mass labels. So A has to be linear. We choose A to be linear on this interval. So it turns out that we can replace linearity here with any flux that lies above on this interval and still get the same dynamics. The only problem is that if we choose something that lies below, then it yields different dynamics. Then it yields different dynamics. But what's happening if you choose a flux that lies below? Well, basically, you're telling the velocity, you're telling the Dirac mass to spread out at time zero. Because this has a lower velocity than this. So we We did not prove this rigorously, but I think if we went back and tried harder, I strongly suspect that we could really get uniqueness at the level of the Euler alignment variables if we imposed some sort of one-sided Lipschitz condition that guarantees that the direct masses can't spread out. That the direct masses count spread off at time zero. Any other questions? I don't know if it's a key I've got too many I mean still make it