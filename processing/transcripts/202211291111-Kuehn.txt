All right. I'm still sorry for not being there, but yeah. So I've learned my lesson and I've already looked up flights for Portland in May to be there a couple of days earlier. So if you want to hang out, then yeah, so I will be there early. All right. So what I'm going to talk about is basically PDE theory and fast flow systems and geometric singular perturbation theory combine. As a motivating example, you could think about this reaction diffusion equation. This reaction diffusion equation here. If the Laplacians wouldn't be there, then you would have a normal sort of fast flow system and standard form. And there are lots of techniques that you could apply. It's basically a toolbox, and this toolbox is very well set up, and you can analyze all sorts of invariant sets and orbits with this toolbox very easy. But now, if you don't have a toolbox, and that's sort of the problem, I think, for PDEs, you need to, I think, understand a little bit how to develop that toolbox. A little bit how to develop that toolbox a little bit better. We have something like spatial dynamics, and we have also some sort of techniques, for example, using center manifolds in certain cases, and so on. But I will show why somehow I think these techniques are not quite yet enough to treat even such simple examples as the ones that I have up here, like standard Neumann boundary conditions of a reaction diffusion two-component system on an interval. So, there will be first steps. So, this is a long Will be first steps. So, this is a long-term sort of program with a couple of people. And we already have seen a couple of talks yesterday, for example, Thomas's talk, and also to a certain extent Dirk's talk, where people are like sort of interested in developing this theory and bringing up sort of new techniques to cover such systems. So the first part I will talk about will be how to do this sort of finisher theory type for more general fast flow PDEs than we were able to do previously. And then, second of all, I will give some comments how to generalize the blow-up method. To generalize the blow-up method, and then third, I thought I would talk about a few minutes about new directions that we are currently working on. So, the main papers that I will address are in some sense these. And in particular, I will talk about the first one, so normal hyperbolic theory and the second one, normally hyperbolic theory. The first one with Felix, and the second one with Felix and Maxi, where we really look at attracting critical manifolds and how to perturb them to slow manifolds via two different methods, and how these methods are related. Different methods and how these methods are related. And then I will talk a little bit about the blow-up analysis, loss of hyperbolicity, how you do this in the Galerkin setting, similar to what Thomas did, that he sort of historically sort of did before with Maxi in this preprint here. And then later on, I will try to sort of smoothly try to lead into Sam's talk, which is yet another take on trying to improve our methodology by sort of trying to do geometric blow-up for amplitude equations. Amplitude equations. And the theme of discretization will appear several times, but for now, for the first part, you don't need to discretize. So, what are the problems with the theory in infinite dimensions? Why can't we not just say the stuff from finite dimensions really works? So, let me go over this for five minutes again. So, Thomas sort of hinted at that yesterday already. So, think of a linear equation for now. It's not really a linear versus non-linear problem, but it's a problem. Linear versus non-linear problem, but it's a problem. First of all, the first problem that you find is already there on the linear level. Suppose this has a nice solution semigroup and there's a small parameter epsilon in the sort of second component for the V, and you formally define your critical manifold as the zero set in a suitable domain, so as a subset of your Banner space, so in the domain of A, operator A and the operator B. And then you ask yourself, why can I not perturb this to another object? Hopefully, again, you know, imagine. Fully again, you know, a manifold if the original guy was a manifold. And the best available theory, I think, that you can find is this theory from Bates and collaborators that were published in the late 90s and the early 2000s. And if you delve into this theory, there's one sort of critical assumption in there that requires a C1 continuity of this semigroup. So this is also true for the non-linear caste. You still linearize and then you require some C1 continuity of the semi-group when epsilon tends to zero. semi-group when epsilon tends to zero. And then the claim is that this entails that naturally then b must be a bounded operator. So the main example already fails. And in particular, you sort of have this problem that intuitively you can think of epsilon times the Laplace is like zero times infinity. So something small times an unbounded operator. And you somehow don't know what to do with that. So let me make this claim a little bit more precise that B must be a bounded operator. Is that B must be a bounded operator if you actually try to sort of use this semi-group continuity and you are starting to work in C1 spaces and let epsilon tend to zero. So this is the claim. So you say, okay, the claim is that this entails that the second component means B is a bounded operator. So you can show, first of all, that the solution, if you make reasonable assumptions, satisfies an a priori bound. Do some goodball over a finite time scale, assume everything's the same. Finite time scale, assume everything's sufficiently smooth, that that's quite easy. And then using one, you basically look at this sort of difference in your second component space. So y denotes the Banner space for the second component V, and X denotes the Banner space for the first component X. And you do a supremum estimate, and you let epsilon tend to zero, and you look at the ball. Okay. And then you project onto the second component Y and you look at this projection and you look at the norm. If you write this. The norm. If you write this all out and you write the mild solution formulation, this is just the sort of equality in the next slide. And then you can bound that from below by basically using triangle inequality and putting a minus. So then this gives you basically splitting of two parts, this first term that comes with the initial condition and this second integral convolution type term. And then you see that indeed the second term using properties of the semigroup will go to zero. Of the semi-group will go to zero, but then the first term is this. But this is less or equal to zero. This means this actually goes to zero as epsilon tends to zero. So this means the semigroup generated by B is norm continuous at t is equal to zero. That's just what norm continuity means. So this is just the definition, effectively, of norm continuity at zero. But then it's known from abstract semi-group and operator theory of norm continuity at zero if a norm. norm continuity at zero if and only if b is a bounded operator on y so this means that this condition is actually pretty strong yeah and that tends to be tricky so how to sort of circumvent and how to lift this condition is one obstacle in developing a finisher a more general finisher theory um on banner spaces effectively well it's already on the linear level one problem but there are more problems so let me go through the problems one by one to understand where all these problems Want to understand where all these problems come from. So, suppose you just even take two heat equations, even decoupled again, and you can explicitly solve them using Fourier. Yeah, that's perfectly fine. So, you solve these guys with eigenpairs on the interval, and you ask yourself, does this exhibit sort of fast slow dynamics? And then normal trick you do when you have explicit solution is you look into sort of where the t is and where the epsilon is, and you're asking yourself which guys are fast and which guys are slow. Yeah, but if you do that. Slow. But if you do this, the intuition is that the modes in V, so eventually some modes in V can become fast if even if the epsilon is small, because if you take the lambda k, the eigenvalues, these go to infinity. So this means eventually you can have fast modes despite the fact that epsilon is small in the second V component. So that's sort of the intuition here. Epsilon gets small, but somehow the eigenvalues of the Laplacian, when you multiply them by epsilon, Clausian, when you multiply them by epsilon, they get large at some point. So at some point, it's order one again. So although v is sort of formally a slow variable, it's not actually a slow variable. It's not a true slow variable because there's hidden fast dynamics that comes from the sort of very fast sort of eigenvalues of the operator. So the direct splitting, you just declare u to be sort of fast and v to be slow, doesn't really work. So the intuition is of So, the intuition is, of course, that at some point you can use spectral gaps to rectify this problem, meaning that you somehow try to split off certain eigendirections. Let me make this maybe a little bit more visual. So this is unfortunately cut off on the top right. So these are the eigenvalues of the Laplacian shifted by minus 20 and Laplacian eigenvalues shifted so that it's visualizable. And we do this on the torus with periodic boundary conditions, but it doesn't really matter. You can do this on the interval with Neumann boundary. Can do this on the interval with Neumann boundary conditions as well. If you had finite-dimensional matrices, you could have a spectrum like this. If you then scale this, then this means the A part that comes from the sort of operator and the fast equation, that means you can move the spectrum around because the one over epsilon moves the spectrum and you can easily have a gap between the fast and the slow directions. So far, so standard. So you just split them and say, okay, the red guys are actually the fast guys, and the blue guys. Are actually the fast guys, and the blue guys are the slow guys, and then you have your normal finisher theory. But if you have the Laplacian, so this is for the visualization purposes, has shifted the blue eigenvalues up and the sort of A eigenvalues a little bit to the left, then you actually see that if you do that, then somehow it's not so clear which of these guys are now fast and which of these guys are slow, despite the fact that I scaled all the A guys by one over epsilon. Then, still, I don't know. So, that's the problem. Yeah, so that's the problem. But if you look at this picture closely, of course, you can, in the simple case of the interval, you can show quite easily that the gaps sort of grow like one over the square root of epsilon. And then sort of using this spectral gap, you can hope to separate and basically take everything sort of to the left of that gap as fast. And then only the stuff that's sufficiently sort of close to the imaginary axis that's on the right, you can try to take as slow. Try to take as slow. Okay, that's the way you could try. And indeed, so suppose, and that's what we do: we take the V component, the second component, we sort of chop that component apart, and we sort of take our Banach space and project it into two pieces, one fast piece, one slow piece. And this can be done if you actually do a spectral gap analysis. So there are parts in the YS space that contain the parts that do not decay very fast. That do not decay very fast. Think about the attracting situation for now. The parameter now that you have to use is somewhere there's, of course, a parameter that controls where you actually do the cutoff. And that's natural. So the problem in some sense becomes, if you think about it conceptually, I think correctly, it becomes a double singularly perturbed problem. And some PDEs are most likely to become sort of k-fold singularly perturbed problems with k-small parameters. And you know, if you would know how many, how big. If you would know how many how big K is for Navia Stokes, I guess you would, you know, I don't know, win sort of the Nobel Prize Emptyfields Medal. But for at least reaction diffusion, you probably, for many stuff on the line, at least, and when you have a spectrogap condition, you can get away with two, namely one guy, the zeta, that will control where you do cutoff, and one guy, the epsilon, that controls the small parameter that you started with. So, and we denote the projections onto these spaces by P R. These spaces by PR, and you get the projected space YF and the projected space YF. But there are more problems. I mean, this is the unfortunate part. This theory looks a little bit like you could immediately try to sort of convert inertial manifold methods that are, for example, very well known since, I don't know, the 80s, I guess, into this sort of fast, slow setting. But there is unfortunately a little bit of a trickery. So for Fenisher, what you want is you want to. Fenisher, what you want is you want locally invariant patches that you can actually apply near certain solutions that you have computed on the critical manifold, and you want sort of finite time chunks where you can follow your dynamics. Most of the theory in inertial manifolds is set up completely globally. So you basically first show that there's sort of a global attractor, and in this global attractor, there is one finite dimensionally invariant global manifold on which you have a nice semi-flow. So you need. So, you need to sort of localize and make this theory patchable. And, you know, of course, we are sort of, in spirit, we are using the same sort of gap assumptions because currently you cannot get around them. There's even more problems. So the next problem is you might argue, well, there are many slow manifold results for particular concrete PDEs. Well, that's true. That's certainly true. Maybe most famous, for example, the Alan-Carney equation. Example, the Alan-Kahn equation, where there's these results by Carr and Pago that you have finite-dimensional slow manifolds that describe the propagation of fronts in Alan-Kahn. So you basically, what you do is in Ern-Kahn, there's a small parameter here that sort of implicitly also does this sort of splitting of this one component equation into fast and slow components. But here, the splitting of fast and slow components is basically giving you automatically a parametrization by knowing that the phenomenon you are interested in is the ultimate. Phenomenon you are interested in is the ultra-slow motion of interfaces driven by diffusion. So the parametrization of the manifold is already given to you by the interface positions. And these interface positions can then be used to do an ad hoc construction of a slow manifold, effectively, or an approximate slow manifold, to be very precise. So you don't really want an ad hoc construction. You want sort of an abstract construction, but it's still computable and feasible to plug in certain equations to make this useful. To make this useful. All right. So, what's our setup? So, I did a little bit of, I guess, too long sort of explaining why it's tricky, but I think it's important. So, this is our abstract setup. We look at evolution equations with closed linear operators A and B that generate semigroups with gross bounds. So that's quite general. We use a scale of spaces called interpolation-extrapolation spaces. I will tell you a little bit more about these in a second. And local Lipschitz condition. And local Lipschitz conditions, which makes this sort of cutoff procedure possible. So, what we do is we say, okay, if you have something global and you want to do something local, then you do a cutoff. We do the cutoff concretely in certain spaces, and then you get local Lipschitz conditions. And then we look at the attracting case, and we look at the subspace in a Banner space that's given by solving the first equation basically, where the dtu is equal to zero. That's our critical manifold. Critical manifold. And then we want an abstract V equations splitting that are motivated by Zeta to make sure that the potentially fast modes that we pick up from the B operator can be incorporated in the slow manifold calculation. And we use a spectral gap type assumption. So many things might be familiar to dynamics people. Probably my guess was that maybe interpolation, extrapolation scales are the least familiar. So I thought I would say a little bit about that. So what you can do is if you have a general What you can do is, if you have a general operator, say t, let's just suppose we look only at the first component for now, you can do the same for the y component. And suppose t is just some operator, it's densely defined closed on x, and you have zero in the resolvent set, then you can just take the domains of these operators, and then you define new spaces by basically iterating these operators and looking at the domains of the iterated operators. And then you basically get these sort of sets. Get these sort of set of spaces. And after you get this set of spaces, you can actually show that there's a set of associated operators, the t k's, and you can also interpolate between these spaces from integer values. So if k is an integer, the definition is pretty obvious. But if k is not an integer, you can actually interpolate between these spaces, same like you have two sober left spaces of integer order. You can sort of fractionally interpolate in the sober left spaces by just making the assumption that you have a sort of parallel time. That you have a sort of Holder-type fraction, and then in the Holder-type fraction, you actually put the fractional exponent in the denominator, and then you have your fractional space. The same works more abstractly with these cases. And in the end, you get the scale of spaces. I will give examples in a minute. And this is a densely injected Bana space in the sense that you have injections from the guy with the higher index that is dense into the guy with the lower index. So a little bit like you are used to from Sobolev spaces. Sobolev spaces. And Sobolev spaces are an example. And you have these operators that are again very nice. And why is this a good setup? Why do we use this? Well, why are these scales useful? For example, a typical standard theorem why these scales are useful is that you can shift semi-groups on these scales. So the idea is if you have a generator of a semi-group, this is the operator, and you have a growth bond of that semigroup, which you need to use, of course, if you want to prove an invariant manifold result, if you want to utilize the linear operation. Result, if you want to utilize the linear operator, you usually do sort of a mild solution formulation. And then in the Lyapunov-Perron, or if you wanted to do with implicit function or graph transform, it would be the same. At some point, you needed linear estimates. But these linear estimates are not very good if they all live in one space. So yesterday there was one question, well, what if you fix one space? That's usually not a good idea. So if you would just fix L2, that wouldn't be good. But if you slide the semi-group across spaces, you can actually show that all these sort of generate That all these sort of generated interpolation extrapolation scales, you get nice semi-groups, and indeed, these semi-groups map between these spaces. And there are sort of interpolation bounds that tell you how, if you go from one space to another space, how much do you lose or gain by changing the space? And that's really useful if you want to do these sort of iterations to get the invariance slow manifold. So there are very useful reasons why you want such interpolation X. You want such interpolation extrapolation scales, all right? So, here's the theorem. Finally, let me see. Okay, so I guess I have like six, seven minutes or something. So, here's the theorem. So, if you have two parameters, one for the splitting, one for the epsilon, and there's a relation between them, then there exists a family of slow invariant manifolds that are close to the limiting critical manifold. So, H0 is the critical manifold. V0 is the remaining coordinates in the slow. The remaining coordinates in the slow spaces, meaning all the remaining coordinates that you haven't split off via the spectral gap into the fast spaces. And this new slow manifold is indeed close, modulo, the fast stuff you split off, that is small, in the sort of first order interpolation, extrapolation scale. And it's close in the sense that the closeness is constrolled by epsilon as well as the size of the spectral gap. So this 1 over ns minus nf. One over ns minus nf is a controller for the size of the spectral gap. If there is a good spectral gap, for example, in 1D reaction diffusion equations, there is a good spectral gap, then indeed you can show that one over this guy is indeed small. So the sort of denominator scales with O of zeta to the minus one half in this case. What method of proof do we use? Well, we use the appunov-Peron because I think functional analytically is probably the most elegant because somehow the proofs are always fine. Because somehow the proofs I always find when I do the opponent-Perron for invariant manifolds are sort of the shortest and most compact, and for PDEs, the most readable. But of course, you could do something else. You could probably try graph transform, and you could try trying to adapt methods like, you know, the urban type method and so on. And we used suitable a priori estimates by shifting semi-groups around. And we utilized the fact that we have split off the remaining fast modes. Okay. But now this is a nice and abstract result, and we can show approximation. Result, and we can show an approximation for the slow flow and everything that you would probably want, at least in the attracting case, to sort of in the tick on off case from a fast flow theory. So, can you apply it? That also was the question yesterday. So, I thought I would put the applications up that we used in the paper. So, the Strommel model already has appeared yesterday. So, this is in this case a sort of doubly diffusive variant of the Strommel model. We applied it to the doubly diffusive Fitzuna-Bummer equation that many of you know. And maybe what might be the most sort of nice thing that we can also apply. Most sort of nice thing that we can also apply to dispersive equations and all sorts of other equations where you have unbounded operators. Of course, we can apply it to the bounded case. If B is bounded, fine, everything works. But we can apply it also to something like Maxwell-Bloch. And for Maxwell-Bloch, there is actually an old paper by Gauvin Minnow and George Huller, where they proved the existence of a slow manifold for these Maxwell-Bloch equations. And I was always puzzled by this paper. I was thinking, is this special, is this a general thing where they use some specialized techniques? They use some specialized techniques, but if you take our method, you can actually recover this Menon and Haller result as a special case. And we can do more in my postdoc, Jan Eric Sulsberg and I, we are currently working on fast reaction limits that also sort of got a little bit of attention recently in the sort of fast flow community. So what are the example spaces that we use? For the first equation, for the Stommel, just, you know, we used periodic domain and we used the special potential spaces, which are actually general. Spaces, which are actually generate a sliding scale with the Laplacian of an interpolation, extrapolation scale. And then you can use Sobolev spaces. But we also used, for example, for this Haller-Minoi example, we actually used continuous functions, periodic continuous functions, and the operator that generates the interpolation extrapolation scale is a first-order operator. So you can actually use all sorts of spaces and plug it into this theory and get sort of invariance low-matter. And get sort of invariant slow manifolds out, even though B is an unbounded operator, which I think is very nice. Okay, so let me do. I don't know, do I have three minutes or something? I guess I will try three minutes to be brief. What's the problem now if you have these invariant manifolds? You still don't really have geometry and sort of loss of normal hyperbolicity in the blow-up method like we are used to. So, what now if you wanted to do blow-up? Then, these methods with the Apunov Peron and so on want. With the Apunov Peron and so on, won't help you. And I think the best way to go is to do some form of discretization. So I will present one form that's similar to what sort of Thomas said yesterday, but Sam will present in the next talk another form of discretization. So how to retain your geometry? I would say discretization is probably the best answer. What objects to blow up? How to treat the spatial domain and so on. We started with this sort of transcritical problem with Maxi. And why start with this? And why start with this? Well, the sort of critical manifold is basically the typical Grandler-Binowitz branch point type problem. So, this is a very good test problem. And the near-constant solutions, which are the ones we start with, so everything that's sort of close enough to the constants, should have ODE-like dynamics in this setup. At least, you know, that's what you can anticipate and hope to prove. And there's still non-trivial stuff happening because you have this sort of parameter mu here that is known in the ODE setting very well. What it does, it sort of switches between. It sort of switches between exchange of stability and junk case in a transcritical. And the local problem is very nice. As Thomas said, it's very nice and parabolically regular and everything. So if you now take this and you discretize Galerkian-wise, then the claim is you can try to apply the blow-up on every fixed level K0. The nice thing is with the logic, you take your abstract slow manifold that you got from the first theory, you flow it near the non-hyperbolic. A non-hyperbolic point, you take a sufficiently large k0 to have a good Galerkin approximation. Then, basically, your manifold has a correspondence. So, points in this Banner space have a correspondence with finite dimensional points that are approximated as coordinates in this Galerkin system. And then you do basically the blow-up on every finite level k0 of this Galerkin system. So, this is what we did. Yeah, so this is the theorem that says indeed this works. So, you do the blow. Works. So you do the blow-up technique on the level K0. I don't want to go into details because Thomas went into the details yesterday for the vault. This is very similar, except in this case, we had sort of more technical issues because we didn't spot properly that you could do a domain rescaling trick. So for us, the domain suddenly yielded sort of free boundary value problems in every chart. And these were very difficult to treat. And that's why we had to work quite a bit. And we sort of got a result that still is reasonable, but it's sort of, you know. Reasonable, but it's sort of you know more, probably more complex than necessary. But there's also many other developments. As I said, yesterday, Thomas presented how to do it with the fold, with some more clever domain scaling and with sort of more sort of better sort of estimates in some sense. And the next talk, Sam will present a little bit of joint workers felix, how to do basically discretization on the leading order critical modes for fast low amplitude equations. And this theorem tells us that indeed the Galerkin manifold, so the Indeed, the Galerkin manifold, so the Galerkin manifold that you come in with is the same as the abstract Bano space manifold. So there's an approximation result that says if you take the Galerkin manifold Hg and you compare it with the sort of abstract guy we constructed from the Apunov-Peron and these interpolation extrapolation scales, then these two guys are close and the close control is given by the spectrogap basically. Okay. All right. So yeah, so hopefully I'm roughly on time. Hopefully, I'm roughly on time. I will spend one minute maybe on an outlook. So, there are several PDE projects in progress with all the people that are listed up there. For example, the fast reaction case, when you have a different structure of your plasma system and only the sort of reaction terms in the first component are fast. We are currently writing the paper that's almost ready with Jan Eric. There are new blower variants. Sam will present one. We are looking at other singularities. We are looking at links to spatial dynamics. Singular dynamics. Dynamics, singular domains. One of my PhD students is looking at what happens when you have a singular domain, and you can actually try to do PDE fast flow analysis on this singular domain. And of course, eventually you might want to try a bit of turbulence, although it takes like 40 years probably to get an epsilon closer. But we have already a few nice results on spatial dynamics. Maybe these could be also phrased as blower problems in the sort of setting I presented here with Maxi and Bjorn. And yeah, so all the papers and And yeah, so all the papers and stuff are on my website. And I'm very sorry that I couldn't be there. But yeah, sometimes the airlines just make you go mad. And I hope you still got something out of my talk. And thank you very much for your attention. We have a couple of minutes for questions. Thank you here. Here. I was wondering. So, if you get it wrong and you split your eigenvalues in the wrong way, so you maybe have ones that should be slow and you add them too fast, that's probably not so bad. How about you do it the other way around? You have the gap in the wrong place. How much does that matter? How do you see that? Yeah, so this is sort of the HOL problem, I guess. If you try to start splitting. If you try to start splitting, if there is somehow no gap or you do something wrong in the case, you know, this can go horribly wrong, I think, because then there can be transfer in some sense on an arbitrarily small scale across this sort of gap that you try to identify, but that's not there. So this is effectively what in fluids is very well known as this problem of energy cascading transport from the microscopic scale to the macroscopic scale. It people don't know in these fluid problems. People don't know in these fluid problems where to put the gap. In reaction diffusion, at least in low dimensions, you can do it. In other PDEs, it's actually known that nobody has sort of at least figured out so far where to do it and how to do it and whether it's even possible. So this can happen. And what would happen then is you try to prove a result that relies on sort of a separation of fast and slow scales, but you have done it wrong, which means even though you try to split it off, there is still a communication between the fast and slow mode. Communication between the fast and slow modes that messes up any calculation that you attempt by using this dimension reduction or splitting. So, of course, yes, if you try to do this when there is nothing sort of helping you to do splittings, then you will get it wrong. Well, it's quite different from in very manifold theory where you can choose the gap wherever you want and there'll be something. Yeah, so in finite dimensions, you always have one by making the epsilon small, but By making the epsilon small, but in infinite dimensions, you somehow, you know, you don't. You can have the case where from an arbitrary mode, you can transport across any arbitrary mode up or down basically the mode ladder. And so you can have bunched eigenvalues everywhere in some sense. And then that is in some sense a situation people don't understand, right? This is a sort of holy grail, if you wish, of PDE dynamics, I guess, one of the holy grails. Not many, but this is, I guess, one of them. And of course, we are working. And of course, we are working towards this, and eventually, there will be a boundary where we sort of hit this same boundary that other people have hit when they're coming from, for example, Navier-Stokes type equations or so. This is clear, this is unavoidable, but at least we can try to understand those equations where there is some hope to have an implicit, fast, and slow decomposition, make it more explicit, make it better to compute, make it easier to work with. And I think that's very much worthwhile because it improves our. Much worthwhile because it improves our methodology. And eventually, when the methodology is good enough, maybe we have a hope to understand the hard guy, the really hard problems. Thanks. One more short question. Your estimates and the existence of this low manifold relies on the spectral gap, similar to when you have inertial manifolds. So does that mean that you're dead in 2D? In 2D, like inertial manifolds, or do you have any ideas how to go like two spatial dimensions? No, you're not completely dead. I mean, there are a few papers, even in 2D for inertial manifolds that appeared recently out of the, you know, Costiango, Selix school, where they can do 2D inertial. Yeah. And it's not, I mean, for reaction diffusion, it's somehow you always think, okay, then maybe if the spectrum is bad, you are dead. But we sort of believe that there are still sort of. Believe that there are still sort of hopes to do this in 2 or 3D. And even for other PDEs, I think it's still very useful, right? I mean, all the others, think about it this way, right? If B is a really tricky operator, it has really bad spectral properties, these are the very hard cases. But we include all sorts of other B's, finite dimensional B's, integral operators, transport type operators, operators with good spectral gaps, operators on domains where the spectra behave well, and so on. So one should And so on. So one should not, I mean, one should not think this is sort of, you know, completely hopeless, but it's sort of equally sort of bad, of course, at some point in terms of like, if this theory works for the fast-slow case very well in these sort of fast-slow systems contexts, then the inertial manifold theory should somehow in the more abstract setting of a global attractor should sort of work equally well. And eventually both should hit a boundary where you have energy. Hit a boundary where you have energy transport across all scales. I think it's time to thank Christian. You gave a tremendous overview of the very broad landscape you're setting out here, which is really interesting. So thank you very much. Christian is participating. He was at talks yesterday and he was participating in the rest of the meeting. So if you want to talk with him at some point or have a further question about his presentation today or any papers, just send him an email and arrange time to Zoom or Skype or whatever. Thank you again, Christian. Speaking of Sam Jelber, who did his PhD with Mark Levixberger in Sydney and his