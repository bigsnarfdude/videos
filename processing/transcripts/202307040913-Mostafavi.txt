and work in building these sequence-based deep learning models for understanding gene regulation and also using the same models to understand kind of genetic variance effects across individuals. And maybe we won't get through the whole thing, but just kind of conceptual ideas of what I think is really exciting in this direction. So as you know, in our bodies, we have many different cell types. Immune system is a really good example of that because many of those cell types are worked out and we actually understand. Types are worked out, and we actually understand the relationship between them. So, here is the immune differentiation tree, a cartoon of it with a bunch of different cell types at the leaf nodes, but there's many more than this. You have markers for them, they can be isolated, and you can also find them in single-cell data. And one of the bigger questions in biology for many decades has been, how is it that in an individual, you have all these different cell types. Individual, you have all these different cell types, yet all of them are somehow operating from the same constant genome. So, of course, we also know that a major part of it is transcriptional regulation, where different cell types are using different regulatory elements to specify basically gene expression. So, you have a cartoon of this, even if you have a genome, there's different regions that we can annotate to different cell types, and supposedly or presumably those regions contain Those regions contain regulatory elements that encode transcription factor binding and other regulatory processes that are upstream of gene expression. So, a major hypothesis here is that these regions, regulatory regions, or cis-regulatory elements that are cell type-specific somehow encode within them combinations of transcription factor and regulatory binding elements that specify cell type specificity. And I'm going to pick. And my big question is: how do we discover this code that's encoded within these regulatory elements? So, there's been lots of progress in this direction in terms of data generation. So, in the last 20 years or so, with major consortium efforts, initially with bulk sequencing and more recently with single-cell data, have generated or applied all sorts of epigenomic assays, for example, CHIP-Seq, DNA-seq, ATAC-seq, and all sorts of histomic. And all sorts of histo modification, assays that measure histome modification to identify regulatory elements across many different tissue types and cell types. So this data is accumulating. And this has given rise to a class of machine learning algorithms that we and others have been using that we call sequence to function kind of deep learning models. And here is kind of the core premise. The idea is that if you have all sorts of annotations, If you have all sorts of annotations for regulatory elements across different cell types, what we can do is we can train models that take as input a region, a DNA sequence segment. These could be short, like a couple of hundred base squared long, or much longer, like a couple of thousands of base squared long. And essentially, we can train these models that take as input these sequences and then predict all sorts of functional properties from the input sequence. So, this is an example where. So this is an example where the model is trained to take as input sequences of about 200 base variant long and predict as output chromatin accessibility across different cell types. And so why is this interesting? There's two reasons why these models could be really interesting. One is that, first of all, if they can really take an input sequence and tell you stuff from it, for example, whether or not it's accessible in a given region or whether or not there is a genes that's expressed. There is a genes that's expressed to a high level in a particular tissue type, then the model has decoded something about the information that's encoded in the sequence, and maybe we can learn something about mechanism of gene regulation from these models. So that's one kind of motivation. The other is this possibility to perform in so-called mutagenesis analysis. And the idea is that if we have such a sequence-based model that just sees sequence and predicts all sorts of stuff, then we can, once it's trained, we can use it as some. Once it's trained, we can use it as some sort of powerful encyclical engine to ask hypothetical questions. For example, what if I introduce, why introduce a mutation from a G to an A, how does that impact my predictions? So these are kind of the motivating kind of questions or motivating aspects of these models. And in this talk, I'm going to tell you about some progress on two fronts. One is using these models to better understand gene regulatory mechanisms. Gene regulatory mechanisms, and the second to use them to predict variant effects. So, the first part, the data comes from a collaboration that we had with the MGen Consortium, or also called Immunological Genome Consortium. So, what this consortium did in their latest data generation effort was to isolate 90 distinct immune cell types from adult mice, which are shown as the nodes in this demogram here. So, each node is So each node is a known cell type that you have markers for, and you can sort cells and generate data from it. And what they did was generate ATAC-seq data and triplicate from each of these cell types. So here's another way to look at the same data or summarize the same data. So now for the many different immune cell types that we have, so I have like, for example, NK cells, CT cells, and V cells at the bottom, we can annotate the genome to segments or regions that. Segments or regions that are found to be accessible in each of the cell types, and associate those regions with some sort of quantitative accessibility value, which is the proportion of reads that are found in that region, which is a proxy for how accessible that region is in a particular cell type. So, and together, this big data generation effort resulted in about 500. Resulted in about 500,000 of these attack regions, which we sometimes call open COVID-19 regions, along with kind of accessibility measure for each of those across the 90 different cells. So what we did kind of in this initial project in this direction was train this convolutional neural network model, which we call AITAC, that takes as input 200 base bare sequences, DNA sequences, and on the basis of this sequence, And on the basis of this sequence, it's trained to predict in a multitask learning fashion the accessibility of this region across the different 90 different cell types that have been measured. And actually, we spend, you know, we started this project in 2016 probably, and it was published in 2020 because we spent a lot of time trying to figure out, first of all, what did it learn? And does it really make generalizable prediction? If we can we really evaluate it stringently. Stringently. So, for the sake of time, I'll just tell you the first step of evaluating this model, which is cross-validation. And so, in cross-validation, what you can do is leave out some chromosomes or some regions of the genome that are not in your training. Once the model is trained, you can ask, how well can I make predictions for the regions that are left out? And if you remember, so this is a multi-staff model that for an input sequence, it's making prediction about accessibility of It's making predictions about accessibility of 90 different cell types. So the output is a vector of length 90, essentially. So, how you can measure performance is to take this vector of length 90 prediction and correlate it with the actual observed accessibility. So, you have one correlation value per region that was left out. So, what does the predictions actually look like? So, this is in cross-validation. The orange histogram is the correlation values for the left out region and the Left out region, and the blue is kind of the null. What would it look like if you had random sequences, essentially? So we can shuffle the sequences and ask the same question again, and how well the model can predict that versus if you actually had the real data. So what we saw here is that for about 60% of the left-out region, you can actually make a statistically significant prediction for. And here is a particularly nice example of showing like I've shown how well they can perform in certain regions. So, this is for one input sequence that was left out of the model. This is the observed ground-truth accessibility of that region across the different cell types that we have. And I'm grouping the cell types by their lineage. But I guess the point that I want to highlight here is that within lineage, for example, in T cells, there's many subtle variations of T cells or T cell subtypes, and they vary in their accessibility. Their accessibility, and the model seems to pick up on that pretty impressively. So, we went on to show that this model also generalizes: if you train it on mouse, you can make predictions for human and all sorts of other stuff. And once we were convinced that it's actually learned something about the logic of sequence relationships to accessibility, then the biggest question is that, okay, how do we dissect this model to understand what did it learn? How does it make these predictions? And I guess historically, And I guess historically, people have viewed neural networks or complex models like this as some sort of black box. But because they're performing so well in recent years, there's a whole slew of algorithms that have been developed under the guise of explainable AI algorithms to try to dissect these models. So I'm kind of delving into these literature for a couple of years. We ended up actually writing a review on different explainable AI algorithms that exist for more of a genomics audience. For more of a genomics audience to actually organize this for ourselves, having applied these models. So, for the sake of this initial work that we did, we ended up showing that a simple model-based approach, as we called it, is actually performing well enough for us to figure out what it's doing. And the approach is essentially akin to how you would dissect a complex system like a cell if you were a biologist. So, the idea is just this like three-step approach where for each node, Where for each node, well, first of all, let me tell you how the model actually learns. So, the idea is that it sees a sequence, and these are the convolutional neural networks. So, the first couple of layers are convolutional, past convolutional filters that learn short sequence segments from this larger sequence, and those are combined in the later layers to make predictions. So, what we can do is go through the model and figure out what is each node learning. So, for example, to figure out what is this node learning, we can, what's This node learning, we can, once it's trained, we can apply the model to a bunch of sequences and figure out which sub-sequences are activating this node. And we can get a motif that looks like that. So imagine that for each of these nodes, we can kind of figure out the motif that it's learning. That's the first step. The second step is like, how important was that feature that it learned? Basically, so it learns a bunch of features, it combines them, and it makes predictions. How do we figure out how important is each feature is through this nullification process? So we can also just So we can also just set the output of each node to some average value and say how much, if I nullify that filter, how much did it impact my predictions? So if I nullify this, I can look at the predictions before and after to quantify how important it was and average that across my test set or any other set that I like. And the third step that we ended up kind of figuring out that was very important was uncertainty in all of these interpretation techniques. In all of these interpretation techniques that people apply. And the idea is that if you train multiple models, they learn slightly different things, and the predictions are not going to be exactly the same, even if you have the same training data and the same model architecture. So it's going to be variation based on the initialization of the model. So in the third step, what we did was basically repeat this process of finding the motifs and nullifying each filter 10 times and say and twice. Times and quantify the reproducibility of each learned motif and its influence. So, with that, we went on to show that if you kind of do this, if you adjust or account for uncertainty, what you can show is that majority of these filters that we find or motifs that we find actually map onto known transcription factor binding site. So, what I'm showing you here is that each dot is one motif that was learned and those first layers. Motif that was learned in those first layer filters. And you have the information content of that motif or equivalent PWM on the x-axis and its influence on the model's prediction on the y-axis. And then we can color code that by whether or not the found motifs actually map on or match a known transcription factor motif in databases like JASPAR or SysVP. And I think the thing that was really amazing for me was that what we saw is that the majority of these like What we saw is that the majority of these important or influential motifs that were found actually match existing motif. Which is to immunologists when I was talking about this, they were like, well, so what else did you learn? But I'm like, it's already amazing that the model doesn't know anything about biology and it's recovering all these motifs that have been put together for like over decades. So we did a lot more on this and I'm happy to chat afterwards, but for the sake of this short talk, I wanted to also touch on the second. I want to also touch on the second part, which is how do we use these models to actually make predictions about the effect of genetic variation. So, one really important motivation has been that, you know, if you train a model like this, then you can ask hypothetical questions of, you know, if I were to take a sequence input and change a T to a C, how does that change my prediction? And you can do this combinatorially, or you can actually assess indels of other kinds of structural variation and all sorts of arbitrary. And all sorts of arbitrary genetic variation between people. So, to be able to actually evaluate models to do this, what we, we have two separate papers of like showing how to evaluate these models that do this, but I'll tell you one line of work, is that we made a slightly different modified version of this model that was trained on F1 hybrid mice. So, what is special about F1 hybrid mice? So, the data that I showed. So, the data that I showed you in the first part is based on inbred strains of mice that have been used for a long time. And one important observation is that if you have two separate inbred strains of mice, which are homozygous across the genome, if you mate them, the offspring is heterozygous across most of their genome. So, you have this property that if you generate functional genomic data, like atax-seq data, then for a given allele, That for a given allele, you can quantify separately the accessibility, or for a given region, you can quantify separately the accessibility of the two alleles because the alleles are heterozygous across most of the genome. And because you have this property, then you can assess when genetic variation actually impacts readout-like chromatin accessibility. So, we built this model called DeepOVO that essentially is trained on this sort of data where it takes as input It takes as input the sequence of pairs of alleles and make predictions about the chromatin accessibility of each allele as well as the ratio of their accessibility. So now that we have this model, we can actually evaluate its prediction on unseen genetic variations. So if we leave out some chromosomes, now what we can do is look at the chromatin accessibility across these left-out chromosomes and stratify them to two groups. Stratify them to two groups. Groups where there was a genetic variation and one of the allele, but there was no difference in the accessibility versus a second group that there was a genetic variation, but maybe there was a difference in the chromatin accessibility, observed chromatin accessibility. Then you can ask, can my model basically predict when does genetic variation lead to differences in chromatin accessibility? And we showed that with this, actually you do get a pretty reasonable You do get a pretty reasonable performance where you can predict the effect of unseen genetic variation with some reasonable accuracy. So, this is our model, and we compared it to a few different architectures that we could use to do this. And this is my last slide. So, here is an example of how you can actually use these models to interpret what's happening locally in the genome. So, this is the region in the genome where in one of the alleles, so the gray. So the gray kind of highlighted here is the actual chromatin accessibility that we observe for the two alleles in this region. So you can see that one of the V6 allele has much higher chromatin accessibility than this PWK, which is the other strain. And in this region, so this is the genome in that region, there are four SNPs that are in this region. And what our model can do is And what our model can do is to actually tell you exactly which of these variants is causing this difference in accessibility, because you can ask it what would be the effect of each of these mutations separately. And what we showed was that there's this one variant that actually impacts a motif that the model has learned, and that leads to the differences in the accessibility that you see. So with that, yeah, there is this kind of whole line of sequence-based deep learning. Kind of whole lineup sequence-based deep learning model that I think is very exciting and it's connecting some of the genetic questions that have been percolating for a long time. For example, relating genetic variation to molecular features and kind of all sorts of functional genomic data that we can measure nowadays. And I think there's lots of promise for using these models to understand the impact of genetic variations. So, this was done by a couple of Berlin students. A couple of brilliant students, Jimmy Tu, Anna, and Alex, as well as my previous student that was at UBC, just graduated last year, and also a collaborator, Christophe Benoit, who's the PIA of the MGN Consortium that I mentioned. So thank you for listening, and I'm happy to take questions if there are case. Great talk. So this sequence. So these sequence to function models, they are trained on data that's aligned to reference genome. Exactly. And do you think there is any information to be gained by training them on models that are aligned to personalized genomes? Exactly. So that's the exact line of work that we are going into. So initially all these models were just trained on the reference genomes. I showed you the equivalence of mouse version of that, whereas the mouse reference genome that they were trained on. The mouse reference genome that they were training on, but on the human side, it is the same. Recently, we had a bio archive that showed that actually, if you train a reference genome, you make a lot of mistakes about the impact of genetic variation. And that's somewhat expected because the model doesn't really know which region are where variant even exists across the genome. So yeah, I guess the next line of work would be to try to personalize these to learn from whole genome sequencing across different individuals. Sequencing across different individuals match with different outputs. We have a great system for that. I mean, you use CAS, but the diversity outcross is great for that. Okay, sorry for the breakout colour. So I have a question about the multitask. So is it multi-label or is it multi-class? It's regression, so it's continuous value. These are like So, these are like predefined cell types, and we have a continuous value for each cell type. So, I guess you can call it like multi-refression. So, for each cell type, you have a sort of a proportion of cells that are which the teeth is accessed. Yeah, it's kind of a proxy of that, yeah. So, how easy then, in your experience, to distinguish very similar cells? Yeah, that's a great question. So, definitely, you can distinguish cell types at lineage level, like, for example, in the At lineage level. Like, for example, in the immune setting, you can distinguish B cells from T cells or macrophages. But within a cell type, for example, T cells, it's not as easy. I would say it's better than chance, but there's still a lot of room for improvement. And the reason why it's so hard is because actually, within subtypes, you have very few regions that are different from each other. So, for example, CB8 versus CB4s, there is CD8 versus CB4s, there is like maybe a thousand of regions that are different. And that's just not enough data for the model to deduce a more generalizable logic. But for some subtypes, you can actually tell the difference. You think those sequences that are very specific, cell type, can be used as the anchor sequences. So the model learn more about the same thing. Yeah, exactly. Yeah. Yeah, so one thing that I didn't show is that to actually learn cell type-specific information. Learn cell type-specific information, it's very important to have a loss function that emphasizes that, which we did in this line of work. So, if you just use like an MSC loss or something standard, what happens is that models typically just learn from other logic, which are regions that are accessible across all the cell types. But if you want to actually learn something about cell type specificity, you need to upgrade those examples that are specific to each cell type. So the the weighing parameters. So the weighting parameters, type of parameters or do you learn those parameters as well? Yeah, I mean I think there's a lot of flexibility in the way you can do this. No, we don't learn this parameter, but sure I think there's a lot of fancier ways to do this. One way would be just to weight each region based on whether or not it's cell type specific or not. If you've tried that direction a little bit, another would be to actually have a loss function that, for example, correlation loss does that it emphasizes predictions that are Emphasizes predictions that have more higher variance, which would emphasize these cell-type-specific regions. So we've tried simple things, but I'm sure there's much fancier things to be done. Maybe we should move on? Okay, sorry, guys, we should move on. Okay, sorry, I forgot that I was changing. Hi. Thank you. All right, so my talk today is about analysis of differential pseudocan trajectories with multiple samples. And there are many ways people can use to study cellular dynamics using single-cell data. For example, you can do pseudo-time or trajectory analysis, you can do angular velocity analysis, or you can Velocity analysis, or you can also do DNA lineage bio. And my talk today will be focused on the first one: pseudo plant. And Cole Chapno's Monoco paper pioneered the analysis of the trajectory analysis in single-cell analysis. So in their paper, what they do is they invite cells into a low-dimensional space and then construct a cell trajectory using minimal spending tree to reflect the progressive changes of gene expression. Of gene expression, and each cell will then project to the tree to get a pseudo time. And after that, we can analyze how gene expression changes along.