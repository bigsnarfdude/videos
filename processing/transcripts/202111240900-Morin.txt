So, I'm going to talk today about graph product structure for non-minor closed families, but specifically, sorry, first of all, this is joint work with Vita and David. And what motivated this work is, of course, we had a product structure theorem for planar graphs and graphs on surfaces and sort of And sort of other minor closed families of graphs, more general than either of those two. But we didn't have something for k-planar graphs. So these are graphs in which each edge is involved in at most a crossings with other edges. So for example, in this graph, in this drawing of this graph, these edges. Graph. These edges in orange here are all crossed by some other edges, and one of those edges is crossed by two other edges, that long edge across the bottom of the picture. So this particular drawing is a two-plane drawing of this graph. It's surely not the best you can see. But so the k-planarity is a property of... K-planarity is a property of the graph, but you can, for a particular drawing, you can count this number, and then you take the minimum over all possible drawings of the graph. So this is a two-plane drawing of this graph. And one thing about k-planarity is that it's not a minor closed property. So, for example, if this were my graph, then, well, now. And well, now, so all I did here was subdivide one edge, but now every edge is only involved in one crossing. So, this is a one-plane drawing of this graph, and yet the previous graph is a minor of this one, and it had two crossings in the drawing. And you can imagine then, of course, that this means that by subdividing edges, you can make the number of crossings go, you can definitely make the number of crossings go down all the way to one. So, so. So I will stay in this meeting. Okay, so it's a sort of a first example of a non non-minor closed property that we would hope to get some. Oh, I see what's happening. I see what's happening. Good. Then we might get to some product structure there and forth. So the question is: if you have a k-planar graph G, is it a subgraph of a strong product of H and P, where P is a path as usual, and the tree width of the. As usual, and the tree width of h is some function of k. So rather than tackle that directly, we decided to abstract it a bit to something more, maybe slightly more general. And that's where we introduced these KD shortcut systems. So if you give me a graph, nothing about planarity here. This is just a graph. There's no requirements about planarity. A KD. Planarity. A KD shortcut system is a collection of paths in your graph, each of which is of length at most K. So in this picture, although you can't tell from the colors, the paths are the ones that pass directly through vertices. So they cross through. The longest path here has length three, one, two, three. So each of which is here of length at most three. At most three. And if you look at a vertex in your graph, you look at the number of times it appears as an internal vertex of these paths. And that's the value of D. The maximum thing there is the value of D. So here, each vertex appears internally to at most two of these paths. And it's important that we only count. We only count internal vertices of paths for this because you see there's three of them that actually share an endpoint here, but the number is not three in this ticks. Right, and then you say, so that's P script P is the name of this shortcut system, and then G to the script P is just the graph G, but now you add an edge between the endpoints of every shortcut. Between the endpoints of every shortcut. And there's a reason this picture looks like this, and that this looks so much like the previous graph, because there's a sort of obvious observation that if you're k planar, then you are a subgraph of one of these shortcut graphs where, so G0 to the P, where G0 is planar and P is a K plus one. And P is a K plus one, two shortcut system. So there's G0. You just introduce crossings, or just introduce vertices for each crossing in the graph. And then for each edge in the graph, you introduce a shortcut, which does the obvious thing. And then, of course, G0 to the P contains all the edges in your K-planar graph, all of the ones that were crossed. were crossed. Okay, so here's the main theorem. So now we can forget about k-planarity. What we have now is a graph G that has product structure. G is a subgraph of H times P times some clique, where the tree width of H is small, P is a path as usual, and the clique has small order L. Then you give me a shortcut. Then you give me a shortcut system over G, a K D shortcut system P. And now we want to know is there a product structure for the power graphs of G to the P? And indeed, the theorem says that there is. So G to the P is a subgraph of some H prime times P times K L prime. So the tree width of H prime gets bigger, whereas the tree width of H was T. This has Of h was t, this has tree width k plus t choose t. And whereas before you had a clique of size L in the product, now it blows up to size dl k cubed plus 3k. So for example, if you have a graph G prime, which is K planar, then I just explained that G prime is a subgraph of G to the P, where G is planar. G to the P, where G is planar and P is this shortcut system. And now you plug in all of the numbers. G is planar, so we know the planar product structure theorem for that. You plug in all the numbers, and you get that G prime is a subgraph of H prime times P times Kl, where the tree width of H prime is about K cubed, and the size of the clique is also about K cubed. About K-cubed. But there are other examples. So you don't have to be K-planar. You can be G-K-planar, meaning the same thing as K-planar, but now you're talking about embeddings on surfaces of Euler genus G, with at most K crossings per edge. G-delta string graphs. Again, these are string graphs drawn on, so the vertices are. So the vertices are curves. Each curve crosses at most delta other curves. They're drawn on a surface of genus G, and it's the intersection graph of these curves. So you can convince yourself that you can get those this way. K-nearest neighbor graphs of points in two dimensions. These also happen to have this structure. Counted degree graphs from proper minor closed. Graphs from proper minor closed families, and basically any power of a bounded degree graph. So, if you think of the graph power, what is it introducing? It's introducing, you know, if you take the square of a graph, it's introducing shortcuts of length two. And if the graph has bounded degree, you can convince yourself that the resulting shortcut system has some parameters, K and D, which have to do with the degree of the graph. To do with the degree of the graph. Okay, so those are sort of things that it applies to that give we now have product structure for. And then of course, there's all the applications of product structure, things like queue layout and various coloring problems and universal graphs. So now you take your favorite thing, type of graph that has this product structure and your favorite application, and you have a result for that, most of which were not known. Most of which were not known before. Okay, so here's the picture that I would like you to have that you've seen a few times this week. So what does H times P times times K, what does that look like? Well, you start with H and you multiply by P. That's this picture that we've seen over and over again. These copies of H on the rows and these copies of P in the... The rows and these copies of P and the columns. But now you multiply by a clique. So the image I want you to have there is that every vertex of your graph, this picture, blows up into a clique. And I drew the edges, suddenly the edges got thicker. That's because when you see an edge in this picture, I want you to imagine that this is what you see. It's the complete bipartite graph on the endpoints of that edge. Of that edge. That's the picture to keep in mind. All right, so now we're going to try and explain the proof of this theorem and the sort of things that come up. So, the first issue is we have shortcuts in this graph. These shortcuts have length up to k and K. And we've seen repeatedly in this product structure that you think of the rows as layers, and we only are allowed edges between consecutive rows or within rows. And these shortcuts don't do that. Shortcuts can skip over K rows. So that's the sort of first and easy thing to deal with. And to do that, we just take groups of K consecutive. Take groups of k consecutive rows and contract them, treat them as one. And in this picture, in this product picture, so one way to catch all of that and not, I mean, to get all of the edges that we need is to just imagine taking K consecutive cliques and just merging them all into one big clique. That has more edges than we need, but that's okay. Need, but that's that's that's okay. Um, and then once we do that, we'll see that the shortcuts now cannot span more than a single uh they can't go, they can't span two rows, which are not consecutive or the same, just because they have length only K. And in terms of product, that just means we're now multiplying by a clique of size KL instead of a clique of size size L now. And the path gets shorter by. Then the path gets shorter, but I mean, the path is shorter by a factor, okay. Okay. And the shortcut system that we had before, which we were thinking of being over H times P times Kl, is still a shortcut system over this thing. This is just a graph somehow with more edges. All right. Now, this picture is getting messy. There's all of these cliques in here, and I get tired of drawing all these cliques, so I'd like to forget about them for a bit. So imagine that you contract each clique into a single vertex. So that does something to the shortcuts. What does it do to the shortcuts? Well, they're still. Well, they're still of the same type as before. Shortcuts still only go between consecutive rows or stay within a row. But now, if you looked at this one, there was no vertex involved in more than one shortcut. But after this contraction, there are vertices that are now involved in potentially in more than one shortcut. So if you just count, you'll realize that now. You'll realize that now, if a vertex only appeared within the interior of D shortcuts before, and that happened inside to every vertex inside one of these cliques that's contracted, then suddenly you get a new vertex which appears in D times K times L shortcuts. All right. So, and the shortcuts still span only one row. So now we're getting closer to Getting closer to something that's easier to understand, that's h times p. So, this is the sort of easy stuff to do. All right, so we have this new shortcut system over H times P that somehow represents the original one. We can convince ourselves that the graph that we're interested in is a subgroup. graph that we're interested in is a subgraph of H times P raised to this new shortcut system and then times the clique. And the shortcuts in this shortcut system, well, they project onto edges of P. That's because they only span one at most one row. But if you look at what they do in H, well, they actually project onto paths in H. Onto paths in H. So the vertices at the endpoints of a shortcut may not be adjacent in H. So when I introduce the shortcut, I get a new graph, a new edge in H. So we have to study this new, in particular, this tree width of the new graph that we're going to get when we introduce these shortcuts. So far, so good. Anybody have a question yet? Have a question yet? Okay, good. This is where things can get confusing. All right, so we're going to be studying the tree width of this graph H prime that I get when I add the shortcuts to H. And for that, it will be helpful for us to imagine: well, we have to work with treaty compositions, and there'll be a sort of handy sort of handy view of these these things for us so um we're we're we have a tree decomposition of of h the uh the original one that that was given as actually part of the the assumptions of the the theorem um and if you look at a particular vertex of h and what it Of H and what happens to it in the treaty composition. Well, which bags of the treaty composition it appears in, they define a connected subtree of your tree. And if you are a little bit careful about your treaty composition, you can make it so that connected subtree, if you root the tree, it has a particular root. So I can think of, for instance, like here in this picture, I have a vertex. Here in this picture, I have a vertex X in H. If I look in the tree, it appears in some of these bags of the tree decomposition. And one of those bags is the ancestor of all the others. And if I did my tree decomposition carefully, then actually that taking the mapping from X onto the root of its tree in the tree decomposition, that'll be a one-to-one mapping. So every, you can imagine every node. Imagine every node in the tree is labeled with a vertex of H. So there's this one-to-one mapping. And actually, you realize you don't need any other nodes, just the ones that have labels this way. So you can, the other nodes are somehow redundant. So weirdly, this sort of says you can assume that the vertices of the tree, the nodes of the tree, are exactly the same as the vertices of H, the same set. And that's helpful to sort of, that will be helpful to us. That will be helpful to us. And then the tree decomposition property implies that if there's an edge xy in H, like there is here, then either X is an ancestor of Y or Y is an ancestor of X in the tree. Right. So that just means Y first appears, the highest occurrence of Y is somewhere within the subtree of Within the subtree of X, or vice versa. Okay, so there's another way to look at this, which is the following. I give you H, and I give you this tree with this property that if there's an edge X Y and H, then X is the ancestor of Y or vice versa. But I don't give you the bags. But I don't give you the bags. So I don't tell you what the contents of the bags are. Well, then it's actually easy to define the contents of the bags because I look at an edge in H, like the edge xy here. You have given me a tree where x is an ancestor of y or y is an ancestor of x. So I need x and y to appear somewhere in this in the common bag. And the easiest way to do that is to take x. Easiest way to do that is to take x. Well, first thing to do is just put every vertex in its own bag. And then to get the edge x, y, I take x and I drag it down along the path from x to y. Then x and y appear in a common bag. That's good. And certainly, if I do this, I'm keeping the subtree of x connected this way. So those are the two things that I need. So, those are the two things that I need from a tree decomposition. So, somehow the tree is enough. I don't need to know the contents of the bags. I can deduce them. Okay, so here comes. Yes. So you have edges between Y and Z as well? Or? Yeah. So here, no, no edge between Y and Z in this graph. And indeed. And indeed, Y and Z, neither is an ancestor of the other, so you couldn't have an edge for this tree. If you were find yourself in the situation, then what would you then then that is not an appropriate tree for this graph H. That's all you say. Okay, so here's a nice lemma from Philipchuk and Sieberts. And yes, this is the And yes, this is the same Palipchuk and Siebert's paper we've been talking about all week, but this is not the theorem that you keep hearing about. It's actually a really useful lemma that I've used twice now. It showed up in the universal graphs work, but much very deeply embedded. So you didn't hear about it yesterday. But it says the following. If I have one of these. If I have one of these nice tree decompositions, meaning that the vertices of the tree and the vertices of the graph are the same set, and I do the following, for a particular vertex z, I count the number of ancestors of z in the tree, so that's these x's up here, such that the graph H contains a path from Contains a path from that ancestor X down to some descendant of Z in the tree. And that path is of length at most K. Then the number of such ancestors is K plus T choose T, at most K plus T choose T. It's a really pretty result, the really pretty proof, as you can imagine. Really pretty proof, as you can imagine from the pretty answer. And it's tight. Okay, so that sounds weird, but maybe a little bit helpful. So why is this useful in the context that I've been talking about? Well, in the previous slide, I talked about a way in which if I I talked about a way in which, if I give you a tree and I want to fill the bags of the tree decomposition, then what I can do is, you know, to add the edge x, y, if x happens to be an ancestor of y and the tree, I drag x down into y's node. Now, in shortcut systems, what is an edge xy? Well, that I'm adding to the graph, it's the end. Adding to the graph, it's the endpoints of a shortcut. What is a shortcut? Shortcut is a path of length at most k. So this is saying that if I do this, so if you give me this nice tree that has the property that I need, and I add these shortcuts, then Then, and do fill the bags in this way, then the bag at Z is not going to blow up. Its size is not going to get bigger than K plus T choose T. Okay, that's great. So awesome. The problem, of course, is if I have some shortcut in my graph, H, I had a I had a nice tree decomposition of H that used this tree T. But the shortcut might go from, let's say, X to Z prime, like in this picture here, but there's no reason in the tree decomposition that X should be an ancestor of Z prime or vice versa. So it's not quite that easy. All right. All right, so we have to do more here. What do we have to do? So, if I look at a shortcut, it's actually a path in H times P, which projects onto a walk in H. And if I look at the internal vertices of that walk, actually not just internal ones, all of them, all the vertices of that walk, they project onto a set of nodes in my tree. In my tree. Remember, H and the tree. So this is the tree decomposition of H, not H. Well, there is no tree decomposition of H prime yet. So this is the tree decomposition of H. The sequence of nodes that I get has a property that everyone is the ancestor descendant of the one that came before it, but that's not so important. It's a set of nodes. And okay, so for every shortcut, I get a set of nodes in my Shortcut, I got a set of nodes in my tree. So now if I focus on a particular vertex in V, there are a bunch of shortcuts that use V as an internal, internally to their shortcut. Each of those shortcuts projects onto a bunch of nodes in T and I can take the union of all of those things. So V is union. So, V is used in a whole pile of shortcuts. Each of those shortcuts projects onto some stuff in T. And then finally, there's a lowest common ancestor of all of those things. And that lowest common ancestor, that's what I'll call A of V. So somehow it has something to do with how high up V needs to go in the tree to capture all of the. Tree to capture all of these shortcuts. Okay, and so now that I can turn that into a partition where I say for a node in a node X in the tree, just look at all of the vertices that picked this X as their A value. So that gives me a set that I'll call SX. It's a partition. Call SX. It's a partition of the vertex set. And now if you carefully step through the definitions here, what you'll find is that if for any shortcut in your graph, you will get that, so if the shortcut has endpoints V and W, that A of V will be an ancestor of. A of v will be an ancestor of A of W or vice versa in the tree. That's what we want in order to build treaty composition. That's what we need. All right. So here's where the craziness happens. I'll take H prime. Uh, I'll take h prime, so this is the graph that I'm going to use in the product structure. It's going to be the graph that I get when I take g, my original graph, and I take the quotient with that partition that I just defined. Okay. All right. So, um, and now the claim is that H prime has tree width k plus t choose t minus one. t choose t minus one so so first of all so h prime is uh is what i get when i i take this partition s and let me remind you what s was that's just everybody uh everybody in h picks uh a node called uh every v picks a node called a of v and everybody who picks node x uh that that's the set That's the set SX. Okay, so that naturally sort of means that when I do this contraction, that the vertices in the contracted graph H prime, they naturally map onto vertices of the tree. I mean, some vertex in H prime is the contraction of Sx. Well, it's natural then for that vertex to map onto node X in the tree. And that's a one-to-one. And that's a one-to-one mapping. So great. And we have this nice property up here that I've recalled about this ancestor relation for shortcuts. And there's a little technicality. I'll assume that the graph also contains, the shortcut system contains every length one shortcut corresponding to edges in your graph. Otherwise, at some point, you lose something. You at some point you lose something. We want to keep all the original edges as well. Okay, so here's the sketch of the proof. So for each X in VH, it's obtained by contracting SX. So we start with our tree T from the nice tree decomposition of H, the one we were originally given. And now for H. Well, for each edge, xz prime in my graph in my actually, that's it shouldn't say h set e of h prime. This should be in the shortcut graph. So basically, in for each of the shortcuts. I do this operation of dragging. Operation of dragging one of them is the ancestor of the other, and I drag the ancestor down into the other one's bag. And now, if you check definitions carefully, you'll realize that this gives you a correct treaty composition because of this property up here. And then the point I've been alluding to. I've been alluding to it all along. Is that when you do this dragging down operation, it's really if something ends up in the bag of some vertex Z, it's because it had, so X ends up in Z's bag, that's because X is an ancestor of Z, and there's an edge shortcut from X to Z prime, which is a descendant of Z. And this lemma of Pilipchuk and Ziebert counts the number of upper bounds, the number of bounds. the the number of upper bounds the number of of such such things um so that's the that's the the the proof of the the tree width claim um yeah good question the dependence on d is gone here or is it hidden in some t part the dependence on d is is yeah it doesn't show up in the it doesn't show up in the tree width it shows up in the uh in the clique size d is the number of times a vertex is used internally in shortcuts okay um all right so now uh All right, so now there's some cleanup to do because we worked our way all the way down from H times P times K down to looking at H. Now we have to back out and carefully count things. If you go and look at this paper, it's written entirely in the language of layered H partitions. So I tried to turn it into the language of product structure here. So you didn't have to learn a whole new thing. But if you do this carefully, and I think. Know if you do this carefully, and I think somewhere you may lose something if you only use product structure, but you know, do it carefully, and this is the final result that you get. g to the p is a subgraph of h prime times p times k d this this big clique and the tree width of h prime is k plus t choose t minus one It's just the statement of the main theorem. Okay. Good. Now you can, this was for this abstract shortcut system. If you go back and look at that argument directly for k-planar graphs, then something new happens, which is mainly due to the fact that Which is mainly due to the fact that the vertices which are internal to shortcuts in k-planar graphs, they're not actually vertices. They were just things that you introduced to do this. And that means that instead of a k cubed for the l here, you can get a k squared. Save a little bit there. And the tree width of h, that's there's nothing. There's nothing nothing different there. It's the L that changes. It's still, the tree width of H is still in the order of K cubed. And if you optimize for one planar graphs, these have a lot of structure now. So these are just edges are only involved in one crossing. If you think about sort of the edge maximal versions of these things, they're basically triangulations, but sometimes you have a pair of triangles carrying an edge and you. Triangles carrying an edge, and you put the other edge in. So you get these little kites in your picture. Of course, they have more structure that you can make use of. And in particular, you get h times p times k30. The 30 is not the interesting part. The interesting part is that the tree width of h is upper bounded by 3. So that leads to an open problem, which Leads to an open problem, which is, is there a fixed universal constant so that if you're k planar, you're a subgraph of one of these products and that the tree width of h in the product is upper bounded by this constant. And as far as I know, that's not even known if that constant is bigger than three. So it could be that every k-planar graph. That every k-planar graph, the sort of the h part of it only has tree width three. We're very far from that. Ours has tree width k plus three choose three. It's actually k plus four choose three. So that's all I have to say. Thank you for your attention.