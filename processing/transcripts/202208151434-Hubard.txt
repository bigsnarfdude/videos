It's really nice to be back to conferences, especially to this place. Uh stop me at any time. Um it's a weird thing. I put two topics together, which you shouldn't, especially in a 30 minutes talk, but somehow the I mean, somehow ExcelNets popped up in two different things, in a very fundamental way, meaning the definition popped up. And in both cases, it sort of surprised me. Cases, it sort of surprised me. And so that's why I decided to talk about both. But maybe I'll just talk about random polytals. We'll see. So in one word, epsilon nets are closely related to random polytals when epsilon is small and are center points when epsilon is large. You'll see. So let me start with random polytopes. So I start with a measure. Let's say in the plane. Everything works in any dimension, but let's. Plane, everything works in any dimension, but let's just talk in the plane for the rest of the talk. I start with a measure, it's a probability measure, and I take independently at random, according to that measure, points. And then at the end, I take the convex hole, and I count the number of vertices on the convex hole. Because it's the expected number of this number of vertices. And the question is, what's that? Sulanki and Glendi were the first to ask this question. To ask this question in the case in which the measure is uniform over a convex set which is either smooth or a polygon. And then Ingra Barani and Larman developed that quite a bit to any dimension and to any convex set. And here I'm interested in any measure. And the second sort of concept that I need is the theta depth. I think this was introduced by Taki. And so if you have a measure. And so, if you have a measure, then you look at a point, you look at all the health spaces that are containing this point, and you look at the one that has the least measure. That's the depth of a point. And so here's, for example, this is a uniform measure on the on the square, and this sub this is as all the points of a certain of a certain f. And F. This has a different name in random polytope theory. It's called the well, the part inside is called the wet part, sorry, the floating body, and the part outside is called the wet part. And you should imagine putting water here. You feel a little bit your convex body, and then you start moving it. And then some part gets wet, that's the wet part, and the rest is the floating body. Okay? Okay, the definition is clear. So it's the same thing as Toky's delta depth. So a point has depth less than T if there's a half space containing this point that has measure less than T. Okay, and use little W to denote the measure of the wet part, of the part that is kind of outside. Right? So. Right, so oops. So T and epsilon, sorry, in this slide, should be the same parameter. So I have my floating body, my wet part, and then the measure of the wet part is little w t, or epsilon, whatever parameter. The other direction. And so this is what Imre and David. Sorry, there are accents missing here. This is what Imre and David showed. Essentially, Essentially, they're kind of the same. Well, a good way to estimate the expected number of vertices in the convex hull, of the random polytope, is to take sort of the expected number of points that you'll find in the wet part with parameter 1 over n. So if you're taking n points, you're taking parameter 1 over n. So you see this, this is you can think about as a probability, and this is the no-performance. Okay, so the question that we asked was: is it true for a general measure? So, yes, so this theorem is important. The measure that I'm using here is uniform on a convex body. So, you can think of the convex set having area one, so it's a probability measure, and it's just a uniform measure on that convex set. And so, the question is whether that's true. So the question is whether that's true more generally for any measure. So the picture that morally you would have in your mind is you draw the convex set, the two pictures that I showed you before, and that convex set should contain the floating body. That's this inequality. Well, that's more or less this inequality on this side. And the other inequality comes from a different reasoning. That's not quite true. You'll see why I draw this. Why I draw this picture. And so, this is what's true. So, it's not true, but if you just put a log n here, then it's true. Is that okay? So, this is true for convex sets. This is true for any measure. Yeah, so there might be a constant So there might be a const, yeah, so I said, right, so d equals to 4 if I'm just talking in the plane. And I think the lower bound doesn't need the correction with the dimension. Okay, so is the statement clear? This is a decent way still for any measure to approximate the the number of vertices in the commaxial. The number of vertices in the comics one. It turns out that this is pretty easy, or rather, known. You just have to interpret the literature well. And the main result of that paper was this. We constructed a measure for which we showed that the previous result is best possible. So there's many ways you can interpret that this is best possible. You could just find one measure for which there exists. measure for which there exists an n for which the other inequality is true. We did something slightly better than that. We showed that for in infinite, there's one measure for which for infinitely many n this inequality is true. Okay, so let me tell you, I mean to discuss this whole thing I have to discuss Efron's formula. And this is just a way to relate the expected number of vertices in the Expected number of vertices in the convex hole to the expected measure of the convex hole. And in fact, it's a convex hole of one point less. And the idea is simple. If you have a vertex and you want to check whether it's a vertex in the convex hole, one way to check it is it shouldn't lie in the interior of the previous ones. The probability that it doesn't lie in the previous ones, or the probability that it lies in the previous ones, is exactly the In the previous ones, is exactly this expected error or this expected measure. Okay, so here's the lower bound. The main thing that I want to sort of share with you is that it's very simple. And this is a result of Barani and Larman. So it it the same exact same proof that works for uh convex sets works for any measure. Sets work for any measure. So, I mean, the key observation is: so, if you take, so here's my convex set. This is the wet part. If I take some point x here, I want to bound the probability that is not in the interior. And all that I said is what is written here: the probability that is not interior is. Interfigure is bigger than the probability that a half space, some particular half space H that contains that point does not intersect the random polygle. And this is, I mean, this quantity here is very easy to control, right? Because all the points are independent. And so the probability that one of the points does not light on this, one of the points of the random polyfill does not. Of the random polyfill does not lie on this region as one minus the measure of that thing. And so if I do it n times, I just take the product. And that's it, more or less. Then you just have to plug that in here and do it all. So at the end, you have to substitute t equals 1 over n. Okay, so that's the lower bound. And the upper bound. And the upper bound. For the upper bound is where epsilon nets arrive. So the surprise is that this is just the definition of epsilon nets. Indeed, this picture that I was showing before is sort of the definition of epsilon nets. Or let me be more precise than that. So if I have a measure, let's say in the plane, an epsilon net is a set, finite set, so that for every hot space that has enough measure, let's say epsilon, That has enough measure, let's say epsilon, there exists one point in the set that intersects that half space. The classical definition that goes back to learning theory like Pacnic and Chernikovic. And it was sort of discovered in geometry by Wessel and Hauserl. And I put here Communus Pakner because that's the bound we use to get a very precise. So I was interested in. I was interested in we were interested in a very precise constant here and that's what we use. So let me tell you what the statement. Okay, so one more time. An epsilon f is a finite set so that every half space that has enough measure intersects this finite set. And the result that goes back to Berknuk and Germanikovich is that with very Is that with very high probability, a mu sample? So if you take the points at random from mu independently, then if you take enough points, and enough is this precise thing, and with high probability what you'll get is an absolute limit. You think about what that means. It means exactly this picture. It means exactly that the Exactly, that the convex hole of this sample, of this set, because it's an epsilon net, it has to contain the floating body inside it. And then the inequality just follows by taking measures. So that's the bound. And this was observed by Wu. It's slightly different, but he already observed this sometimes. So here's the example. So this is an example just for one. So, this is an example just for one n. And it's very simple. You take two circles, and you put a, I mean, the measure is going to be rotationally invariant. And the probability that you land in the inner circle is really large compared to the probability that you land in the outer circle. And so, let me just for intuition imagine this as a process. So, I'm This is a process, so I'm dropping points. And for a long time, they will all land in the inner circle. And so the convex hole will be just, I mean the number of vertices will be just n, the number of points that I. And all of a sudden, after a long time, I will find one that is outside. And in expectation, this will make the number of vertices go down by more or less n over 2 plus 1. Right, so you can imagine this circle you have to imagine it really tiny, so it's packed with points, and they're sort of uniform. So when I put a point here, you sort of take out half of the circle. So that's a huge drop. But in fact, if you think about the other drop, the drop of the wet part, that's much worse. So what happens to the wet part? So I need to define this tau. I need to define this tau. Tau is how much measure I have. I take a tangent to the inner circle. I take that half space. So all the measure comes from this fraction of the circle. And so what happens is that for t smaller than tau, the wet part is the outer circle. For t larger than tau, the wet part is everything. And I have this huge drop. And exactly at that huge drop, I will have a control. I will have a counter example to the, or a bad example for the theorem I was telling you. So, this is from your paper. This is how. So, the white part looks like that. So, now I'm parametrizing by n, and there's some rescaling of the axis. But so, the point is that this drops really immensely. And so you can see that, for example, here, the two quantities that I wanted to compare are really people. That I wanted to compare are really people. Is that clear? Clear enough? Okay. So the bad example in general is just you take this and you repeat it. So you take circles, you can make the radius go like that to one. And the essential thing that you want is that the whole measure outside one circle is very similar to the measure in. One circle is very similar to the measure in the last circle before that one. So it's decaying incredibly fast, the measure in the circles. And then this, so this part needs more tedious work, but it's essentially the same idea, and that gives you an infinite number of bad ends, but numbers when it drops a lot. However, before I continue, let me say, I mean, even if I mean, even in this bad example, for the most part, we have a really, really good approximation. So it's an interesting question whether in some sense for most and the inequality is still true for general measures. Okay. Let me skip this. So that's that for random polytopes. And And I don't know how much. Yeah, so you have 10 minutes left. So that's that for random polytope. So that was when epsilon was small. Now I'm going to use when epsilon is large. Are there any questions about the random polytope side of the story? We're all good? We all have launched recently. So, okay, so you know that center point theorem. So, again, it's So again, it's a statement about measures. It says that for any measure in the plane, for instance, there exists a point such that any half space that contains that point contains at least one-third of the measure. So if you think about it, that's the same thing as saying that the the The floating body of parameter d over d plus 1, or 2/3 in the case of 2, does not empty. I never thought about this before. Sorry, yes, right, and that's the same again as saying that there exists. That there exists a V over A plus one net that has a single point. There's three ways to state this. Okay, so just to finish, let me tell you a problem. So this is a general statement. Let me state it for d equals 2. So here. So this is the theorem. For the equals 2, for any measure measure in the plane and g equals 2 as well there exist three points x1 x2 x3 such that for every polynomial which is positive or let's say not negative on three of them Sorry, so there exists some alpha which is greater than zero and three points so that the measure of the positive side of that polynomial, so for every polynomial that is positive at least three points, the measure of the positive side is bigger than L. So that's the statement. So that's the statement. No restriction on degree of quadrature? Uh sorry. Thanks. Any for any P the degree tool? Thank you. For any quadruple? Um yeah, there is yeah so right. Yeah, so this is stated for a general degree in that side. And I'm stating the one that I like the best, which is quadrics, because it's the only one that I actually know the number. Okay, for linear things, of course, this is the center point theorem that I just told you. And in general, I have these two bounds, which are kind of far from each other. And then in dimension two, for any 2 for any G, I have something slightly better. So, is the statement clear? You want to see the proof? It's a very simple proof. You take your measure, you plug it into the Baroness surface through the Baroness map. So now you have your measure part in the in space of this dimension. And there you apply the center point theorem. You apply the center point theorem. Now you find a point. That's a point that doesn't have to be on the Veroness surface, but it is a convex combination of points on the Veroness surface. That's easy to show. And so then you apply Carathodori theorem and you get this number of points. So this, I'm showing you this. And then the other two is just improvements on the Carathodori number of the Beronese surface, which I think. Veronus surface, which I think is a really fundamental problem that we should all solve. Or more generally, like finding good algebraic conditions for the character number to be smaller than what characteristicorems tells you. Okay, thanks for your attention. Any questions for Alfredo? I have a very vague question. So, you had this first example with a very heavy circle and then a very light circle. And it seemed like you were sort of almost looking at the limit as that heavy circle became infinitely heavy. And then the second example, you were... Where were they? Oh, I said, it sounded like you were sort of almost looking at the limit as that inner circle became infinitely heavy. Yeah. Right. And became small. And it just, it seems. And it became small. And it just, it seems sort of surprising that your next example was much smoother in some sense. Yeah, that's true. I did that just to explain the phenomena, but if you do the and yeah, so. I don't really have a question. It's more I'm just. Yeah, yeah, no, no, you're absolutely right. So the first version of this measure that we had, the circles were going to infinity, and then we thought about it, and that turned out to not matter so much. Um it actually sort of helps you with anything. Maybe not. I mean the so this example is difficult to analyze, but in retrospect the main thing is just that you have this really large really fast decay of the amount of measure that is in the left circle as you go parallel. I don't know. One of the co-authors of the paper is here, maybe he has further comments on that. Has further comments on that. It was an issue, like at first, we had something going to infinity, and then we thought, oh, it would be nice to make it compact, and then we had to work a little more, but it didn't matter that much. Although the intuition comes from different size of circuits. In this example, it is actually the cartadori number of something or does the cartaderi number of something? No, it says you can define MD of G as Cathadori number of something. No, no. This I don't know. Okay. So the proof that I told you was you start with something, you plug it in through the varieties map to some like large thing here, and then if you bound the character number of this thing, then you bound the nothing that you wanted. Nothing that you wanted. But not the converse. But I don't know the converse. So I would. My guess is that the lower bound is tight for this problem. I have no idea for the cartoon number. Berony surfaces. And yeah, the lower bound I didn't mention, but it's very simple. You just take, so you have a certain number of So you have a a certain number of points, you just take a polynomial that passes through them and then you take the square of it. So that's a polynomial that has nothing on on the or minus the square of it. That's a polynomial that has nothing on the positive side. That's the idea for the lower null. It's also very true. Well, if not, let's thank Alfred again. Okay, um, were you sure?