Thank you very much for the internet. Thank you very much for the invitation. Thanks for your persistence in making this happen. And thanks to who I think I first spoke to in Khang many years ago when I was still quite young and terrified of anyone whose name I knew. And so it was so nice to talk to someone who not only, I was giving a talk largely about pre-projective algebra, so someone who obviously Pre-projective algebra. So, someone who obviously knew their way around pre-projective algebra, but was also so approachable. Okay, and there's a yeah, well, let me just get on with the talk. Okay, so I might be able to scoot through some of these early slides. So Q is a quiver, meaning a pair of sets of arrows and vertices without loops or two cycles. So the usual rules. Cycles, so the usual rules, though I'll start to bend those rules quite soon. Actually, before getting into all this, maybe I should give some motivation. So, what I want to do today is talk about quantum cluster algebras and, in particular, positivity conjectures or theorems about them from the approach of quantum theta functions, which I believe will mean I'm doing Gregor a favor. Gregor, favor. Yeah. So, yeah, we'll get there. But for now, again, just some preliminaries. So, as ever, such a gadget is determined by its signed adjacency matrix, precisely because we've ruled out loops and two cycles. So, I label that with B. It seems to be the convention that, yeah, you label your vertices one to m and the first. To m and the first one to n of them are the unfrozen vertices, even though m becomes before n in the alphabet, but this seems to be what everyone else does, so I'll just stick with that. L is going to be the lattice of dimension vectors for the full quiver. So the lattice with basis given by these elements E1 up to Em. So initial seed. So here where I put a Here, where I put a bold y and a vector in the exponent, it's the usual convention that actually it's y1 to the power of the exponent's first entry, dot dot dot dot dot. Yeah, so here's my initial seed. It's some set, subset of the lattice. And I'm going to define mutation in a kind of two-step process. So I've So, I really want to separate out the birational transformation part of that process, which is this bit. And then there's a second bit, which is the kind of tropical part, which is a substitution rule. And I think of that substitution rule as being essentially changing what we think of as being a true monomial as opposed to a Laurent monomial. It's just a sort of, yeah. It's just a sort of a change in what we consider the positive oxidant to be. Anyway, the real juice is in this birational transformation, which you're all probably quite familiar with. So yeah, usual mutation rule for quivolus, which I'm not going to repeat because I have my limits. And AQ is the algebra generated by all of the cluster monomials. So I take my initial seed, I take all possible sequences. I take all possible sequences of unfrozen vertices. I take all monomials where I demand that for unfrozen vertices, the exponent is positive. And at that point, it does matter that we have this rule here. Okay, so this is absolutely the usual definition. And so for this audience, I'll just push past. So let me just remind you of some general results. So the first, and the sort of most important, I suppose, is that this definition actually. I suppose, is that this definition actually makes sense, i.e., that if I keep mutating, I do get things that lie in this z times L, in this ring of Laurent polynomials. For any sequence of mutations along unfrozen vertices and for any starting monomial, I get a Laurent polynomial. I get a Laurent polynomial with constants given by integers. So I can keep mutating. So, somewhat later, it was proved by all of these authors that the cluster monomials that one gets by iterative cluster mutation are linearly independent. And for kind of philosophical reasons to do with the origin of this subject, that's an important sanity check. So, this is an important result. Somewhat later still, Somewhat later still, there's the positivity result due to B and Schiffler, that these constants that appear in the expansions of cluster monomials are not just integers, but actually positive integers. And for this, there's a kind of combinatorial proof. And then for the final thing, this is much closer to what I'll be talking about today. What I'll be talking about today. These four authors proved that there is a possibly slightly bigger algebra called the middle-class algebra, which has a basis of theta functions indexed by this set here, capital theta, which is some subset of L, which at least contains all of the cluster monomials and enjoys a stronger positivity property, namely that the structure constants with respect to this theta base. Constants with respect to this theta basis are all positive. And if you think about it, this does strong positivity does indeed imply the positivity result above. Okay, so those are the main results I wanted to recount about cluster algebra. I should say I'm taking a very sort of generalist approach in this talk. I like cluster algebra talks where someone explains an example to me. There are going to be very few. Example to me. There are only very few examples in this talk. These are just results about what happens if you supply any quiver without worrying about what the origin story of that quiver was. So these are indeed very general results for, I can't make it do what I want it to, for skew symmetric cluster algebras. Okay, so I wanted to talk about quantum cluster algebras. So let me set about quantizing. Set about quantizing the story that we've already seen. And I'm going to start off by being very naive. Okay, so set beta i to be this linear combination that appears in the exponent when we defined cluster mutation. Then the cluster mutation of an arbitrary monomial can be written as follows, some kind of binomial expansion, where I just pick out the ith entry of the exponent of the monomial I'm mutating. Of the exponent of the monomial I'm mutating. And yeah, get these coefficients. Okay, so I'm going to start off by just quantizing the binomial coefficients, which is quite easy to do. So we start off by quantizing numbers themselves. So the quantization of n is this Laurent polynomial. And it's a quantization of n in the sense that if I plug t equals one into the normal, I plug t equals one into this, unless there's a really egregious typo, I should get n. And this polynomial, yeah, I mean, whatever, it's a natural thing to study. It's a natural thing to study from the point of view of quantization, but it also appears in a number of other contexts. So, for example, if you're learning about the representation theory of SL2, and you're trying to write down what are the characters of all of the irreducible representations, you find that they're exactly given. You find that they're exactly given by these polynomials. So that's a kind of link with representation theory. A link with algebraic geometry would be the following. The hard-Lefschetz theorem tells us that we have something called a hard-lefschetz operator on the cohomology of a smooth projective variety over the complex numbers. And if you unravel what that means in terms of Betty polynomials, it tells us that the Betty polynomials of smooth Polynomials of smooth projective complex varieties are linear combinations of polynomials like this. So these polynomials are somehow fundamental from at least three different points of view, but for now we're just using them to quantize numbers. So once we've quantized numbers, it's obvious how to quantize factorials. You just take the definition of n factorial, which is the product of one up to n, and you just quantize one up to n, take the products of all of those Laurent polynomials in t. Those Laurent polynomials in t. And then, you know, we learn at high school the formula for the binomial coefficient in terms of factorials. And so we just quantize all of the terms appearing in that. And there we go. We've got our quantized binomial coefficients. One thing to note in passing, I suppose, is that the way I've done everything, the way I've normalized everything, everything is invariant under the substitution t goes to t inverse. There are different ways of. There are different ways of defining the quantization of the binomial coefficients, which I've rejected because they don't satisfy that property. Okay, so we started off this slide by observing what quantum cluster mutation does in terms of binomial coefficients. So why don't we just quantize by replacing those binomial coefficients with their quantum versions? Well, it's easy to show that this is just not an algebra homomorphic. Not a algebra homomorphism, so it's not good. But if you've ever wondered why do Berenstein and Zelovinsky insist on having what's called a compatible pair or a Lambda matrix, it's the following. It provides the fix for this problem. So the solution is you find a skew symmetric form on Z to the Q zero such that you have the following thing, such that at least if I At least, if I evaluate this form on B applied to EI and B applied to EJ for E and EI and EJ coming from unfrozen vertices, as long as we have this compatibility, then after we decree that in the ring of Laurent polynomials in Y, the ring itself is going to be non-commutative, i.e. there's this slight non-commutativity sort of baked into the definition of the ring. The definition of the ring of non-commutative Laurent polynomials in y, then everything works. Then this definition makes sense and it provides a sort of fairly naive and straightforward way to quantize cluster algebras. Okay, so that's what we're going to do. The punchline is these monomials y no longer quite commute. They have this failure to commute. The failure to commute given by this skew symmetric form lambda. Okay, so once we've changed the kind of ring in which we operate, everything goes pretty much as before. So we have a lattice L with a skew symmetric form omega. Then we define the quantum ring of Laurent polynomials as follows. So it's the free module over Laurent polynomials in T it generated. The generators given by y to the v for v and l, and multiplication given by this rule. Okay. So, yeah, and we're going to apply this construction with omega, little omega, given by our skew symmetric form lambda. Okay, so now with this little bit of preliminary stuff done, I can define the quantum cluster algebra in a way that is basically copying and pasting. That is basically copying and pasting the definition from usual cluster algebra. So it's the subalgebra of this ring of non-commutative Laurent polynomials generated by all the cluster monomials, the same things as before. Yeah, as defined before. We start off with the same initial seed and we mutate via exactly the same rule. But now we're working in this non-commutative ring. Okay, so. Okay, so this gives us a completely uniform way to define the quantum cluster algebra in the same way as the usual cluster algebra. Okay, I feel like I'm just rattling through this, but because of who the audience is, but if anyone wants to stop me and ask what I'm doing, then that's also a lab. Okay, so that's the definition of quantum cluster algebra sort of on the board. On the board. So, what are the general results? Well, they look a bit like the general results from usual cluster algebras, except there are different authors attached to the different results. So the first one, as always, is you have to check this actually makes sense. If I take some sequence of unfrozen vertices, take a quantum cluster monomial, which has positive exponents at the unfrozen vertices, mutate along this sequence. I at least stay in. I at least stay in this ambient ring of non-commutative Laurent polynomials. So that's what this mess of symbols says. Yeah, that if I keep mutating, I get Laurent polynomials in the cluster variables, where now the coefficients are no longer going to be integers as they were for usual cluster algebras, but are themselves Laurent polynomials in T. Okay, so that's a good start. So that's a good start. Yeah, there was a second one which here is missing. So the one that's missing here is that the quantum cluster monomials are linearly independent. But this in fact follows from linear independence for the classical version. If I had some linear dependence expressed over, yeah, if I had some linear dependence. Some linear dependence relation with coefficients given by Laurent polynomials in t, then if I just evaluate all of those t's at one, t's at one, then I get a linear dependence relation in the classical sense. So that one's missing, and we go straight on to number three, which is the analog of positivity in the quantum setting. So this is the statement that these Laurent polynomials that appear, they themselves have positive coefficients. positive coefficients. So they're coefficients in, so they're Laurent polynomials in T, where all of the coefficients are positive. And they are moreover Lefschetz, which is a fancy way of saying that they are positive linear combinations of polynomials of the form quantum n. So remember, one way of sort of thinking of where quantum n comes from is the is from the hard left sheds theorem. So yeah. From the hard Lefschetz theorem. So, yeah, that's the reason for this notation. We say that a polynomial is Lefschetz if it's a positive linear combination of quantum ends for different ends. Oh, yeah. Okay. Yeah, I think that's, yeah, okay. So there was also a fourth one, which was strong positivity due to gross hacking Q. Positivity due to gross hacking Kiliman Konsevich, but that's not on this side because that's the content of the rest of this talk. Okay. Okay, so this slide is pretentiously titled bosons and fermions. Really, I'm just going to introduce some notation. So yeah, I feel like if you've worked in cluster algebras for a long time, you're bound to have seen quantum dilogarithms, which are really Bathistic exponentials. So this will be. So, this will be maybe familiar to half the audience and unfamiliar to the other half. So, let me maybe slow down slightly. So, in this box, we have the definition of the platistic exponential. So, I start off with some formal power series in t, which throughout this talk I'm treating as a kind of special kind of variable, and z1 up to zr, which will be some other variables. And it's given by, yeah, some formal power series with coefficients. formal power series with coefficients f n v where v sits inside here this plus means that if I evaluate all of the z's at zero I get zero i.e yeah the usual sense I'm sort of in the maximal ideal defined by the union of all of these Z's okay then if I have such a formal power series then the plathistic exponential the plathistic exponential is defined in a fairly straightforward definition, but hard to motivate. But anyway, here's the definition. I just take all of these coefficients that appeared in this big sum, and now I just form this big product where these coefficients now sit as exponents. Okay, and this is what's called the plephistic exponential. And yeah, I've done something a little bit funky with the T's. So With the t's. So, I mean, you could ask me, why don't you just express it as a big formal power series in T's and Z's? And then that would change the signs of some of these and maybe get rid of this sign here. It will hopefully become slightly clearer later. But anyway, so with this definition of the plathistic exponential, let me define this bold face E applied to a formal power series as the plathistic exponential of that formal power series multiplied by this. Multiplied by this formal series in t. So this is what t plus t cubed plus t to the five plus t to the seven so on. Okay, so that's the definition, two definitions. And now let me try to motivate them to some extent. So this is how I think about logistic exponentials. Let v be a graded vector. Be a graded vector space where I have a multi-grading where the first component is somehow special, and that's going to be what the T records, and then the other components are a bit less special. That will be what the Z's record. And given such a multi-graded vector space, I can form its characteristic polynomial. So, this is just some big formal power series where these coefficients, up to worrying about sines, are just given by the dimensions of the graded pieces. By the dimensions of the graded pieces corresponding to the exponents. Then, I mean, this is somehow the right way to think of platistic exponentials. If I take such a graded vector space and I take the free super commutative algebra generated by it, I get some new vector space which inherits a z cross ends the r grading. And I can take the characteristic function or characteristic formal power series of that new thing. It turns out. New thing. It turns out, and it's not hard to. I mean, if you're bored, you can do this right now. It's not hard to show that that's the same thing as taking the characteristic function of my original vector space and then applying the plathistic exponential to it. So the kind of snazzy tagline is that plathistic exponential is the decategorification of forming the free super commutative algebra generated by something. And so let me at least say a few words about the super here. A few words about the super here. So, when I take a vector space, let's assume it has a cohomological grading, as well as maybe some other gradings. If I take the super commutative algebra generated by it, it's the same as the commutative algebra, except I apply the causal sign rule. So what that means is that if I have two odd elements, instead of demanding that they commute, I demand that they anti-commute. So, in particular, if the entire vector space was odd cohomologically, Space was odd cohomologically. I wouldn't get a free commutative algebra. I'd get a free exterior algebra. And that's kind of the reason for this minus sign here. I want T, this first grading, to not just be a grading, but secretly be a cohomological grading. And that, if you sort of trace through the definitions, that implies that we have to put these signs here. So maybe a couple. So, maybe a couple of examples will make that clearer. Okay, so example two: I take this graded vector space. So, it's graded by n. And in the nth piece, I take the cohomology of BGLN, or the stack theoretic quotients of point by GLN, and I shift it up cohomologically by n squared. Then, a cool thing happens. If, I mean, this is an enormous. If I mean this, this is an enormous. I mean, each graded piece is infinite dimensional, although each bi-graded piece where I take as well the cohomological grading is finite dimensional. But yeah, it's an infinite dimensional bi-graded vector space. It looks a bit chaotic. But if I take its characteristic function, I get precisely this E thing applied to a very simple formal power series, namely Z. So that might explain. So, that might explain or sort of justify introducing this boldface E thing in the first place. Okay, so that's one example. The next example is really the same one. So, note that the cohomology of n by n matrices, mod G L N, because N by N matrices are themselves contractible down to a point, this is the same cohomology as up here. It's just I no longer impose a cohomological shift for reasons left under the rug. Left under the rug. Then that changes the characteristic function because I've changed the grading slightly by not imposing those cohomological shifts. And now, if I take the characteristic function of this massive bigraded vector space, I get, again, something quite simple. Again, it's a very basic formal power series, but now it's not just z, it's z times t to the minus one. Okay, but the point. Okay, but the point I want to make is that although these look very similar, you might wonder, you know, what difference does it make if I just multiply my one monomial by t inverse? But it makes a huge difference. And the reason is that if I just take Ez, so I put a z here, and then I have this thing here, then the whole thing is cohomologically odd. I'm just looking at odd powers of t along the line. Whereas here, Whereas here, for the same reason, I'm just looking at even powers of t. So, this you should think of this example two as being, or example in bullet point two, as being an enormous infinite dimensional free exterior algebra generated by something. And the example in bullet point three as being the free commutative algebra generated by something. And you kind of see, yeah, just by basic calculation, you see this just by taking Plathis. See this just by taking plathistic exponentials. So, if I take the plathistic exponential of Tz, what I'm doing is really I'm trying to calculate the characteristic function of the free exterior algebra generated by a one-dimensional vector space, which winds up being this. Whereas here, it turns out I'm calculating the characteristic function of a free commutative algebra generated by one-dimensional vector space. So I get something infinite. Yeah, so. Yeah, so what's going on in the background is that the examples from bullet point two and three are the DT invariants of the zero loop quiver and the one loop quiver. That's just some background information that may become relevant later. And yeah, this, you think of this as the example in bullet point two as being somehow fermionic, i.e., you know, like fermionic statistics is the statistics of a Is the statistics of exterior algebras, whereas bosonic statistics is the statistics of symmetric algebras. So, how to motivate this? So, what's the one thing everyone knows about bosons and fermions? Fermions don't like being in the same place, bosons don't mind. So, if I look at the sort of the characteristic function of the cohomology of configuration spaces of bosons, I get symmetric algebras, whereas Symmetric algebras, whereas what this exclusion principle ends up telling us is that if I look at configuration spaces of fermions, then I get exterior algebras. And that's okay. That's just some physics that explains the names behind these two. Okay, so how to use any of that stuff. And it turns out we only have to use the kind of fermionic half of what I've just explained to get towards. To get towards mutation. So let K be the semi-group of unfrozen dimension vectors. We form the quantum torus just as before, where now the skew symmetric form is this signed adjacency matrix B. So again, we just form in a fairly simple-minded way a ring of non-commutative Laurent polynomials. And via the compatibility. And via the compatibility between B and gamma, we get that this assignment defines a homomorphism from this new quantum ring to the ring of Laurent, quantum Laurent polynomials, where the non-commutativity was sort of encoded by this lambda matrix. And then it's an easy calculation to do the following, that if I is not the same as J, so I take two different vertices of my quiver. Vertices of my quiver, then this iota applied to this thing commutes with yi. And yeah, I mean, it's it's this one is not very hard to show. It boils down to the fact that IOSA replied to XI commutes with, oh, that's a typo. Sorry. This should be a YJ. Sorry. It's easy to show that IOSA replied to XI commutes with. To xi commutes with yj, and then whatever this whatever this thing is, well, anyway, it follows from that. But if i is equal to j, then something much more interesting happens. They no longer commute, but rather, if I take the commutator or the group theoretic commutator of this thing applied to yi, I get this thing, which one can show is this two-term thing. So even though these are So, even though these quantum dilogarithms or plathistic exponentials just have infinitely many terms and look a bit scary, somehow this calculation simplifies in a big way. And we recover quantum plus the mutation via this operation taking add of these plathistic exponentials. Okay, so cluster mutation in the quantum setting. Cluster mutation in the quantum setting is performed by letting plathistic exponentials in the x coordinates act on the a coordinates via conjugation. Okay. All good. All right. So on to the kind of the gadgets for this talk. So when giving a talk about scattering diagrams, I think the thing not to do is give the definition of scattering diagrams, but rather start with examples. But rather start with examples. So here's everyone's favorite non-trivial scattering diagram. So here there's going to be some slight non-commutativity between these two variables, x10 and x01, which will be dictated by this condition here. Okay, and this will be inconsistent. And what inconsistent means is that if I take two rays or two paths going around the origin, there'll be Around the origin, there'll be certain operations assigned to them that won't be the same. And the way we make this consistent is by adding a new ray like so. And what this means in concrete terms is that if I trace a loop around the origin, and every time I pass a wall, these things are called walls, I either multiply by the thing on the wall or multiply by the inverse, depending on which way I'm crossing it. Then if I do that loop, I get one. Then, if I do that loop, I get one. Without this extra wall, that's not the case, precisely because these two, the two things on the original walls don't commute. Okay, so we add one outgoing wall to make it consistent. And yeah, job done. But we can make life more difficult for ourselves by just changing the skew symmetric form. So now instead of being one, it's some number at least three. And this is a Three, and this is again inconsistent, the scattering diagram. I.e., if I do a loop around the origin and either multiply by the thing on the wall or its inverse, depending on which way I cross the wall, then I don't get one. It's fixable, but the fix is not quite so pretty. There are infinitely many new walls that we have to add in order to fix this problem. And indeed, there's a region of non-zero. Um, non-zero volume here where the walls are dense, where every single possible rational slope has a wall on it. Okay, so whatever. Um, these are two scattering diagrams that you may or may not have seen before. And now, um, overdue, I'll give you a definition. Uh, okay, so a wall is the following. So, we saw some walls before, uh, but here's the actual definition. So, um, this uh Um, this uh math rec d is an n minus one dimensional, so some part of a hyperplane. Um, it's a rational polyhedral cone in my lattice that I started with. So, this was the lattice of all dimension vectors for my quiver, but realified, and it should be parallel to the perpendicular of b applied to p. So, uh, this is why I don't leave with the definition, um, but this is the this is. But this is the definition. And it's called incoming if closed under adding BP. Again, I'm not sure whether it's possible to pass that in real time, except just to sort of cast your mind back to the pictures. The two walls that went all the way across the screen are the incoming walls, and the walls that look like they were coming out of the origin are the outgoing walls. And that's a good enough working definition for the purpose of this talk if you're new to scattering diagrams. If you're new to scattering diagrams, maybe it's from outside. So, a scattering diagram is a union of walls in the realification of L. And I've added some dot dot dot here because, of course, this isn't the full definition. You have to make a whole bunch of demands, blah, blah, blah. But let's not get into that. The joints are just the sort of bits where the walls end or where they meet each other. Or where they meet each other. And yeah, so given a path into L tends to R, we can always make it avoid the joint. So let's go ahead and do that. And let's say it crosses walls W1 up to WR at times T1 up to TR. So recall a wall was not just some subset of L adjoined R, but rather each one of the But rather, each one of those subsets has a function sitting on it. That's why when I did my examples, I didn't just draw lines, I shoved, you know, I shoved functions on those lines. So if I have a path going through L adjoined R, which crosses these walls in this sequence, then the transformation associated to that path is just the following. Each time I cross a wall, I take I cross a wall, I take add of whatever sits on the wall with a sign depending on whether which way I'm crossing the wall. So remember in this sort of check for consistency, it was, you know, when I took that product, I was either taking the thing on the wall or its inverse, depending on the way I crossed it. And that's encoded in this sign here. So, yeah, so this notion. So, this notion that if I go all the way around the origin and take the big product that I see, that that be equal to one, that's really a demand on what the psi I assign to that loop around the origin is. And it's the demand that it just be the identity operator. Anyway, so any path, I get some big product of functions like this or operators like this. And my And my scattering diagram is called consistent if that operator only depends on the endpoints of gamma. So, another way of saying that is that if gamma is a loop, then that operator is the identity. Okay, so that's as much of a definition as I want to give. And yeah, it's a fundamental theorem that those two examples I led with are not in some way. Examples I led with are not in some way not special. I. One can always achieve this. It's just it might be messy. Every scattering diagram can be made consistent in a unique way up to some notion of equivalence by just adding outgoing walls. And that's what I did in the two examples. Okay, so this time I am leading with the definition. That's a bit controversial. Okay, so let Q be a point in my L adjoined R. In my L adjoined R, and let's say it isn't on a wall, and let P just be a direction in L, just let it be an element of L. So that starting data is going to define the sort of the two ends of a broken line. So a broken line with ends P and Q is a piecewise linear path sort of coming in from negative infinity and being mapped into L adjoint R, which avoids the Into L A joint R, which avoids the joints and meets the walls at certain points in its sort of life. So, S1 up to SR are numbers between minus infinity and zero. And each piecewise linear section, so this is part of the definition, between time SI and SI plus one, the wall is straight. Sorry, the broken line is straight. And a lot of the And along each segment, the thing is labeled by a monomial. So this CI, T to the EI, Y to the VI, satisfying some conditions. So just for notation, let me set S zero. So time zero is when this thing is at minus infinity. So we require, firstly, that it ends up at Q. So the end point gets mapped to Q, this thing in. Gets mapped to Q, this thing in allerge. So that's telling us what happens at one end of the broken line. Secondly, that if I look at one of these straight segments of the broken line, the direction in which it's traveling in is dictated by this exponent here. So the thing that sits above the monomial that sits on that bit of the broken line, the exponent, tells me what direction the broken line is traveling. Tells me what direction the broken line is traveling in. Yeah. And the label at the beginning of the broken line has got to be very simple. It's just y to the p, where p is one bit of starting data. This also tells us the direction that the thing is traveling in at minus infinity, i.e., it's traveling in direction minus p. So this starting data, p and q, P and Q dictates where the thing ends up, but also its direction asymptotically as I go backwards in time. And each time this thing hits a wall, it's allowed to change direction and it's allowed to change its label, but is only allowed to do so in quite a prescribed way. So recall on each wall, I have this operator, add of whatever function sits on the wall, applied to whatever wall. The wall applied to whatever I want to apply it to. So, if I apply that operator that sits on the wall to the monomial coming in, I get some binomial expansion involving a bunch of new monomials in y, and I have to pick one of those. So that means there are only finitely many new labels that can come out the other side of the wall, and also only finitely many directions. Okay. Okay. So, yeah, I desperately need to get onto an example to make this a bit clearer, but let me just make a passing remark, which is that as long as only elements, and this is just an easy calculation, as long as only elements of this form appear on the walls where g has positive coefficients, then if a broken line is coming in with a positive coefficient, i.e. a positive CI, then it will always come out with a positive coefficient. Will always come out with a positive coefficient. Okay, so this is just a piece of high school algebra. Okay, so let me revisit the easy example. So we started off with our inconsistent scattering diagram. We added a single wall in order to make it consistent. And okay, so now I set my ends to be, so here's where the thing has got to end up, and the asymptotic direction has got to be one, zero. To be one zero, so coming in in this direction, and there are three broken lines that achieve this. So, recall: when a broken line hits a wall, it has a decision to make. You take the monomial that sits on the broken line as it goes in, which in this case will be y to the minus one, zero. You apply the operator on the wall to that monomial, and then you get a bunch of, you get some new polynomial. You get some new polynomial coming out, you have to pick one of the monomials from that new polynomial, and that determines the new label coming out, the other side of the wall, but also the new direction. And it's a sort of easy observation that one of the options is always to just keep going the way you were. So one of the monomials that I get by applying add of this to anything is the original monomial. So I can always just blast straight through the wall. Just blast straight through the wall. So there's always this straight line, but then there are ones where I've done something a bit more elaborate. So now I add up the contributions from broken lines. So the contribution will be the label on the broken line as it reaches its destination. So here the label starts off as being y to the minus one, zero. And because I don't do anything to the labels as I go through, it finishes y to the minus one, zero. Whereas here is something more. The minus one, zero, whereas here something more complicated happens. When I go through this kink, the label changes, and similarly, here. Okay, so I get three contributions. And if I sum them up, I should get something that you recognize as a cluster monomial. And that's not an accident or a coincidence. And let me try to encode that. So we define the theta functions associated to a scattering diagram. Functions associated to a scattering diagram by summing over broken lines in the scattering diagram. So I fix my sort of ending data by the asymptotic direction and also the end point. And I take the sum over all broken lines with those ends. And I sum up the monomials that appear on the final segment of my broken line. As I approach Q, what is the monomial attached to my broken line? I take the sum over all those things. Line. I take the sum over all those things, and that's a theta function. Okay, so this definition, when you first see it, I mean, when I first saw it, I thought, well, you know, what's the use in that? For a start, I mean, it's all well and good drawing these very simple examples for talks and whatnot, but presumably, as soon as you get these horrible examples with infinitely many walls, this will always blow up and always be strictly formal. So the first surprise is that that just doesn't happen, that this is any use at all and is often This is any use at all, and is often a polynomial, a Laurent polynomial in the wise. But yeah, for now, just bear with me. So, in general, this may be a formal function that can happen. Let me just make the following observation, which I won't dwell on, I think, that if I take a path between two different candidate endpoints, then recall to that path, I have this automorphism given by just taking Given by just taking the product of all of the automorphisms associated to all of the walls that I pass. And there's this basic transformation law of the theta functions that the theta functions defined with respect to this different choice of endpoint are just given by this simple formula. And since this thing, by definition, is an algebra automorphism, these structure constants don't depend on Q. So let's assume, as indeed it's true. Let's assume, as indeed it's true, that I can always express the products of two theta functions as some possibly formal power series in other theta functions with Laurent polynomials and T as coefficients, then these Laurent polynomials don't depend on Q. So I get some kind of intrinsic algebra associated to my scattering diagram. So, in particular, we can just fix a generic Q. And let me say something, just something. Something, just something about the combinatorial definition of these structure constants. They are themselves given by summing products of the final monomials of pairs of broken lines with ends given by prescribed data, like so. Okay, so again, these coefficients are given by sums over broken lines. Just this time, it's sums over pairs of broken lines. Okay, so by definition, the middle cluster. The middle cluster algebra is the Zt module spanned by theta functions such that this theta function theta p is a Laurent polynomial, not a strictly formal power series. It is an algebra and contains the quantum cluster algebra, with cluster monomials themselves forming part of the theta basis, i.e., appearing as theta functions. Okay, so at this point, given that the place we wanted to get back to was strong positivity, we see the Strong positivity, we see that we're in, sort of, after quite a lot of work, a fairly advantageous position. What we wanted to show is that these things are positive Laurent polynomials in t, given that by sort of taking the sum total of everything that appears in the final bullet point, these do indeed form the structure constants for quantum cluster algebras, or at least some slightly enlarged version. Okay, so Okay, so the goal for the rest of the talk, all like three or four minutes of it, is to show that these are positive Laurent polynomials in T. Okay. So let me get there. So let D be the scattering diagram with exactly one wall for each unfrozen vertex v. So the diagrams, the inconsistent scattering diagrams that formed my examples are special cases of these. Are special cases of these kinds of scattering diagrams where I just put a single one of these boldface E functions on each wall. Then, I mean, this is not a very nice English word, but at least it's probably easy to understand. So let D plus be the scattering diagram I get by hitting the theorem that there is a unique way to make this thing consistent by just adding outgoing walls. So the consistentification. So we define theta functions with respect to this consistent scattering diagram, the quantum theta functions. Okay, so after a bit of work, one shows that cluster monomials and structure constants are given by sums of broken lines in this consistent scattering diagram. So positivity reduces to showing that all of the functions on the walls have this form, that they are these bold-facy blah blah blah where g hath Facey blah blah blah, where g have positive coefficients. Recall that there was this high school exercise that, as long as this happens, if a broken line comes in with a positive coefficient coming in, it has a positive coefficient coming out. So this will imply positivity for all of the broken lines. Okay. But yeah, I mean, at this point, it still looks difficult, right? Because recall that even for quite a simple example here. A simple example here. After I consistentify the thing, I could have infinitely many walls with all kinds of junk appearing as functions on those walls. So yeah, this might look difficult, but at least it's easy to reduce it to four times infinity special cases. So via perturbations of scattering diagrams and recursive arguments, sort of mirroring what GHKK do, we can reduce the proof of positivity. Proof of positivity for the functions on the walls to at least a bunch of two-wall cases. So we can assume that the functions on the walls are of this form. So either fermionic or bosonic quantum dilogarithms on the walls. And unlike GHKK, we can't assume that this number is one, but we can at least assume it's n sitting inside n. But these examples get pretty. But these examples get pretty hard to calculate. So let me just run through one example. So, this here, I've done the thing that's meant to make my life easy by setting the skew symmetric formula to be one, but I've done something a bit wacky. I've put a bosonic thing here instead of the usual fermionic thing, like the one you see here. Okay, but still I can make it consistent. And here we go. I just, you know, start going, start going. And yeah, after infinitely many steps. And yeah, after infinitely many steps, I can at least make it consistent up to order two in x to the zero, one. But it's still inconsistent. And indeed, I have to add yet again a dense load of walls. So yeah, I mean, at least for the functions I put on the walls here, you can see that these have positive coefficients, but yeah, the situation might still look hopeless. So let me, yeah, I'm almost there. Yeah, I'm almost there. So, in general, the problem of deciding what goes on the walls comes down to this factorization problem, right? So, if I go back, one of these factorizations is going around this way, and one of these factorizations will be going around this way. So, if I go around one way, the simple way, I just see two factors. And if I go around the other way, I get some incredible mess where I reverse the order of the two basic factors. Reverse the order of the two basic factors and have to decide what goes on in here. But yeah, it turns out all of these problems can be solved using what's called cohomological Donaldson-Thomas theory. So if I take a quiver with vertices one, two, so just two vertices, and minus alpha i loops at each i, so either zero or one loop, an n arrow is going from one to two, where n was the value of my skew symmetric form. The value of my skew symmetric form. Then, yeah, cohomological Donaldson-Thomas theory gives us an interpretation of what these functions are. They are the characteristic functions of cohomology of stacks of semi-stable representations of Q of varying dimension vectors. And here something sort of rides to the rescue, which is an integrality theorem due to myself. An integrality theorem due to myself and Sven Meinhart, which says that the right-hand side can be precisely expressed as this bold-face operator E applied to something called the BPS cohomology, which is an honest cohomologically graded thing, and in particular has positive Betty polynomial, is manifestly positive. And this solves the problem. So, yeah, that so in the end, the facts that no matter what sort of mess of outgoing rays. What sort of mess of outgoing rays you have, all of the functions on the outgoing rays are positive, comes down to this integrality theorem. And so that gives us the main theorem. Right, so the main theorem is that there is a subset of L and quantum theta functions indexed by this subset theta mid, such that each theta function can be written in this form with these coefficients invariant under t goes to t inverse. Goes to T inverse. But moreover, this part says that the structure constants with respect to this basis are positive, positive Laurent polynomials. What's more, this, oh, I should say, yeah, theta p for p in here contains all of the cluster monomials. And this is the atomic basis. I'm not, I have zero time to say anything about that. But let me instead say an application for Bernard's birthday. For Bernard's birthday. And since we proved this, I think, almost two years ago, I suppose this actually is a timely birthday present. It's a very slight generalization of a result on specialization of quantum cluster algebra, as user Geisler Clerk and Schreur. So there is always this, if I take the quantum cluster algebra and I just mod out, I just set t equals one, you expect to get the usual cluster algebra where Um, where what type of cluster algebra you're considering is given by the star. So it could be the lower, or the middle, or the upper. But it turns out to be quite a delicate problem to show that that's actually true. And here we have some result that uses this positivity that says the following. Let me just get to the punchline: that if the ordinary, sorry, the ordinary cluster algebra is equals the middle cluster algebra, i.e., has a basis given by theta functions, then indeed this is an isomorphism. Then, indeed, this is an isomorphism, and this is proved using our main result. And I'm a little bit over, so thank you for your patience. I'll take questions. All right. How do I not show there are any? Oh, yeah, someone's. Oh, if you're in Zoom, if you have questions, sorry, yeah, different, different pan. Okay, so I guess I have to add a question from the room. I think now I have to I have to take the microphone. Sorry. Okay. Yeah so maybe the broad question is what's the geometric picture sitting in the background? Let's say like a little bit more precise would be in the commutative case. All these scattering diagrams are motivated by this mirror symmetry picture that was maybe made precise by Kilan Yu in this case. This case, yeah. So, in this quantum setting, is I mean, is there some interpretation for or expected interpretation for broken lines or or this quantum scattering diagrams? Oh, yeah, um, let's begin. Well, um, yeah, I mean, in some sense, the Yeah, I mean, in some sense, the quantum counts that you get out of counts of broken lines are meant to recover things like Gromov-Witten invariance. And here, it's a familiar story in enumerative geometry that we're going beyond numbers and replacing numbers with polynomials. So, what this is meant to be is some kind of refinement of the enumerative invariance. Refinement of the enumerative invariants. But at the level of generality at which I've given this talk, where I've just taken any input with any skew symmetric cluster algebra. Yeah, it's hard for me to say what those are supposed to be. So yeah, I guess that's a long way of not answering your question. There is a question. Yeah, question. Take it away in the classical setting, broken lines. I think you mentioned in like the SYZ mirror symmetry heuristic should correspond to counting like a homomorphic disk whose, at least heuristically, whose boundary is like on an SYZ fiber. And then in the quantum setting, you would count homomorphic disks, which also have some boundary on the positive real locus, which should be a. Locus, which should be a Lagrangian section of the SYZ map. Again, this is heuristic for now at least. But then, so that, well, yeah, so in the quantum setting, you need to use that sort of open string picture, and the power of t would correspond to like the integral of some V field over that disk. So you need to turn on the B field, and that quantizes things. Quantizes things in mirror symmetry, I guess. So, yeah, these powers of t and this quantum stuff is the B field area of the disks you're counting. Okay, perfect. Yeah, please. I don't know if I should wait for myself. Oh, yeah. So, I noticed you worked with skew symmetric cluster algebras, and I have a vague recollection that something breaks for skew symmetrizable. Could you say what is currently known about that? Well, it's definitely not true. Certainly, the strong positivity statement is not true, and I think. Statement is not true, and I think even the weak positivity statement at the quantum level is not true. And why is that? I mean, apart from just giving examples, well, I mean, the proof breaks, but of course the proof had better break if the theorem is not true. Theorem is not true. Well, let me put it this way. Yeah, I mentioned very swiftly towards the end of the talk that in the GHKK setting, in the classical setting, there is this gigantic reduction we can do for scattering diagrams, where we, after perturbation and lots of other clever arguments, can always assume. Can always assume that we have two walls coming in with the very simplest functions on them and with this sort of non-commutativity, this lambda being set to one. And then, you know, I told you how to make that scattering diagram consistent. There's only one new wall, and you can see that the thing on S is positive. That reduction just can't be done. Just can't be done at the quantum level. It's a similar problem to, it's an almost identical problem to the fact that the naive way to quantize, the sort of hyper-naive way to quantize cluster mutation that I got halfway through a slide before correcting doesn't work. For that same reason, their reduction doesn't work in the quantum setting. And so you really have to come face to face with these scattering diagrams where you have. These scattering diagrams where you have lambda possibly a larger number, but also face to face with bosons hitting fermions, bosons hitting bosons, so on and so on. Yeah, so yeah, that's so are there skew symmetrizable ones for which it is true or might be true, such as those that can be folded from a skew symmetric server skew symmetric cluster also they're all Make a cluster on because they're all, yeah, I don't know. That's a good question, and that's yeah, that's a really good question. And I don't know, yeah, no, that's yeah, that's at least something that one can grab hold of, yeah, but I don't know the answer. Yeah, yeah, I can't remember. Travis, is it like the matrix 0230 or something? Something you'll know. Okay, whatever. Yeah, there are counterexamples. Any more questions, comments? Oh, yeah, yeah. Thank you. Yes, first, let me thank you for your birthday present. Birthday present. And then I would like to know when I'm allowed to use it. So, can you specify a little bit more this condition? Are there some nice classes of algebra or when is this true? Or are there some criteria? Don't include the batteries, you know. I fear I am guilty of that. Yeah, I mean, I'm not sure when this is true and when it isn't. If, okay, so if you want to avoid mid completely, then I mean, there's the easy fact, which is that it is sandwiched in between the ordinary and the upper cluster algebras. So whenever, yeah, whenever they come together, then all three will be the same. But this is slightly more general than that. But yeah. Yeah, but yeah, sorry. Yeah. So, I mean, in the commutative setting, GHKHK also are able to define theta functions on X varieties going through a brain. Yeah. I am just wondering if there's something similar that can be done in this case. And so you can identical. Okay. Okay. Yeah, I didn't declare. Okay, yeah, okay. Yeah, thank you. Any more questions? Any more questions in Zoom? Also, feel free to unmute yourself. Okay, well, then let's thank Ben again.