All right. Well, thank you very much for the organizers for inviting me here. I've been to Banff several times, never to Kelowna, and I'm loving it already. It's wonderful. So I'm going to talk about recent work that I've done with a number of colleagues. The work is in three different papers, and one of them is still on the archives, it's submitted. Wonderful colleagues. And I'll be glad to answer questions anytime. So I don't know, the schedule is, should I wait until the end for questions? Yes. Okay. All right. Okay. So how does this one work? Oops. Okay. So I'm going to. Okay, so I'm going to talk about causal inference. Okay, so half a century ago, different disciplines had their own opinions about causal inference, many of them actually very negative opinion in terms of the hope of being able to do causal inference. But that situation really have changed a lot. Today, there is nearly unanimous acceptance of causal inference. And actually, the causal revolution. Actually, the causal revolution in great part is due to the emergence and adoption of two formalisms. One of them is counterfactual models, and the other one is graphical models. The two are actually quite intertwined, but today I actually want to concentrate on graphical models and, in particular, their use for disentangling efficiency concepts. So, graphical models are responsible in a way. Are responsible in a way for the acceptance and adoption of causal analytic techniques in epidemiology and medical research, which is the area that I mostly work on, because they facilitate encoding causal and complex causal assumptions and reasoning in a very intuitive way. In particular, there are simple graphical rules that explain the potential biases. The potential biases of one's preferred estimation procedure and the possible remedial approaches that one can take, avenues that one can take to correct for those biases. So graphical models, as I said, you know, they really made causality be a reality for EpiWork, especially because of the Of the ability to encode very intuitive assumptions and to communicate potential biases in a very intuitive way. Yet, no graphical rules exist that explain efficiency. While there are rules that explains biases in one's analysis, there's very few rules, if any, that explains efficiency in estimation. So, what I want to do in this talk is present Is present some work towards filling this gap. All right, so here is basically a big picture of what I'm planning to do. So here is a graphical model. We'll discuss briefly what a graphical model is in a minute. And these two variables, couch and fitness level, are actually suffice to control for confounding in this graph, assuming the graph, et cetera, that I'll explain in a minute. But these two other. minute. But these two others, oops, these two others here also suffice to control for confounding. So the question is, which one should I use? Should I use both? Should I use one set, the other set? Which one produces estimators that are more efficient for estimating the causal effect of the variable warming up exercises on injury during exercise. So, what I'm planning to do today is to give you first Today is to give you first a gentle introduction, very brief, 10 minutes only, to graphical models, to causal graphical models, explain what those that picture stands for mathematically, then give some results on optimal adjustment sets, which will include rules for comparing adjustment sets for point exposure studies and rules for comparing time-dependent adjustment sets for time-dependent exposures. Exposures. I will also briefly discuss some results, recent results with Richard Wu and Emma Perkovic on uninformative variables and graph reduction, and I'll explain hopefully what those are. And then some final remarks. Okay, so here is again our graphical model. So this graphical model is actually taken from a paper, an expository paper in a biomedical journal by Schreer and Platt, where the authors were trying to explain. Where the authors were trying to explain the use of graphical models to communicate the potential biases of one's preferred method of analysis. Okay, in particular, confounding bias and selection bias. The graph is supposed to prepare the graphical model for an observational study where the intention is to analyze the effect of different warming-up exercises, different types of warming-up exercises. Types of warming up exercises on injury during the practice of sports. Okay, this is a paper on sports medicine. All right, so what is this graphical model standing for? Mathematically. Mathematically, a graphical model is a set of nodes and a set of edges, okay, directed edges. Now, each node is a variable, it's standing for a variable. And what this graph says is that each variable is generated. That each variable is generated according to an unknown function, f, for example, v5, is generated according to an unknown function of the variables that are parents of that node in the graph. In this case, B5 has as its own parent B1. The parents are the variables that have directed arrows, okay, directed edges into the variable. So B5 has only parent B. As only parent D1. So the graph is standing for a process for generating the data where each variable is a function of its parents and some omitted causes. Okay, some omitted cause. That omitted cause, the key to the model to be graphical, to be a causal model, is that we are assuming that those omitted causes are non-common, okay? Meaning that there is no single omitted cause. That there is no single omitted cause that is a common cause of two variables in the graph. If such an omitted cause existed, it has to go in the graph. So in other words, when you look at the graph here, there may be variables that we cannot even think of measuring, for example, genetics. Okay, but nevertheless, if we believe it's a common cause, it should go into the model. Okay, if it's a common cause of more. If it's a common cause of more than two variables. All right, so the assumption, the formalization of the assumption of omitted non-common causes has seen many different approaches, many different structures of formalization. And the one that I will adopt here is the one given by FERM, where the non-emitted common cause assumption is formalized simply as saying that the epsilon Simply as saying that the epsilons, the errors, or the omitted causes are just mutually independent. So now we have a system of equations that generate the data. Okay. And I ask, okay, based on this assumption, what can I say about the data generating process? And what I can say is that the data generating process has a law, P of B, okay, a density. Okay, a density with respect to some dominating measure that factorizes according to a set of conditional densities, one for each node, where the conditional density is the density of that variable given its parents in the graph. Okay? So when I think of the collection of all laws that satisfy this factorization, I'm actually thinking of a model, of a statistical model. That statistical model. Model. That statistical model is called a Bayesian network. Okay. And a graphical model from just view as a model for the data generating process of the factual variables, the variables that we ideally could measure, if we could measure all the variables in the graph without intervening, is basically assuming only that the law of the data. That the law of the data factorizes according to the Bayesian network associated with this graph. But the graphical model, the causal graphical model, also indicates what would happen in an ideal world, a counterfactual world, where we were to intervene on certain variables in the graph, okay, and set them at particular values. Particular values. So, for example, if we were to set, remember V11 was exercise, the type of exercise. So, if we were to set V11 at a particular value, let's say zero, level zero, okay, what will happen is that we essentially, the model is assuming that what we do is we erase the function, the structural equation that was generating. That was generating V11 in the factual world, and we replace it with an equation that would occur if we were to intervene and force everybody to take level zero for B11. Okay? And then the rest of the variables propagate. Okay, so V12 now will be a function now not of the V11 in the factory world, but in the counter-factor world, okay, and so forth. Okay, and so forth. All right. Okay, so for this model, okay, for this particular setup, now I ask: well, what would be the law, okay, the joint data law, if I were to see live in that counterfactual world? Okay, and it's very easy to see that the only difference with the law in the factual data, okay, the law of the factual data. Okay, the law of the factual data is that the distribution, the conditional distribution of V11 given its parents in the original graph, is now replaced by a point mass probability, okay, where V11 takes the value zero. All right? It's simply, we just are erasing the equation, the initial equation, and replacing it now by a point mass problem. By a point mass probability. Okay? Everything else stays the same. Okay? All right. So the cousin graphical model then is not only assuming a model for the factual data, but it's also assuming a model for the counterfactual data. Okay, it's telling me how the counterfactual data law relates to the factual data law. But there's more. I could also think of a scenario. Think of a scenario where I imagine a counterfactual world where we are going to intervene and force everybody, V9 was previous injury. So force everybody that had previous injury to take a low level of exercise and everybody that didn't have previous injury to take a high level of exercise. Okay? So now we would be living in a world, a counterfactual world, where V11 will be a Where v11 will be a function of v9, okay, and that function g will be known, okay, because we are imagining that world, okay, just as before we were imagining that v9 was just equal to zero, the constant function equal to zero. Now we are imagining it's a constant, it's a function of v9. Well, in that setup, the counterfactual law will again be like before, except that the Except that the distribution of V11 given its parents will be replaced now by a point mass probability, but that point mass probability will depend on the value of V9. Okay, if V9 is low, then I will assign G of V9 high. Okay, if V9 is high, I will assign G of V9 no. But I could even think more. I could think of a scenario where not everybody that has. Not everybody that had previous injury will be assigned to B11, low, but it will be assigned with certain probability. Okay, so now I can imagine that V11 is some function of V9 and some known random variable, okay? A random variable that is independent of everything and is, you know, it has some known distribution. Unit has some known distribution. In that case, the counterfactual law in this intervene world where I intervene with a random treatment regime will be then this will have this joint distribution. Okay, the difference now is that pi of V11 given V9 will be the distribution of V9 or the probability, sorry, of V11 given. Sorry, of V11 given V9 in this counterfactual world? With which probability will a person that has V9 low have V11 high? Okay, and that's something that I will specify beforehand. So the bottom line, okay, is that this slide will just summarize what a Telsar graphical model is standing for. It stands for an assumption about the factual world, okay, the world that we Okay, the one that we could potentially observe without intervening, just indicating that the law, the joint law of the variables, follows the Bayesian network. And the counterfactual world indicates, more generally than what I indicated earlier, that if for any set of variables, subset of variables, let's say I want a S that is included in V, I consider it a regime that has Consider a regime that assigns little AT to a capital AT with a certain probability given some variable Zt, okay, where Zt are non-descendants of AT, okay, they happen before AT, then the probability in the counterfactual world, the choice probability will be this formula of the data. So the important message of this is that if I were able to measure all the Measure all the variables in the graph. And remember, I said some variables may not be measurable, okay? But we include them because they are common causes, okay? Because otherwise, the model is not a causal graphical model. But if we could measure all the variables, then we could estimate those conditional probabilities of VJ given its parents, okay, potentially consistently, so we could. Consistently, so we could consistently estimate the counterfactual distribution, okay? The joint counterfactual distribution. So, P of W, P of P of pi is identified from P. Now, I want to stand up for a minute and briefly go through a very important graphical tool, which really stands at the basis of one. The basis of why graphical models are so incredibly powerful, which is a rule for determining what independences logically follow from the assumption that P of V factorizes according to that formula over there. Okay? So clearly, if you think of V1, V2, V3, et cetera. Of v1, v2, v3, etc., okay, and you think of the law of uh, you know, of total probability, you know that vj, this particular assumption means that vj is independent from all the v's in the past given the parents, okay, because of the factorization. But it implies many more things, okay? For example, it implies that VJ is independent of the parents given its non-descendant. Of the parents given its non-descendants, and the non-descendants could be later in the list. So one can ask, is there a graphical way of determining if I give you a graph and I tell you, here is A, here is B, here is C, okay? Can you tell me if A is independent of B given C, okay, for any law that satisfies this? For any law that satisfies this factorization. Okay? In other words, can you give me a graphical rule that actually establishes without any doubt or a sound and complete algorithm that establishes which conditional independencies hold for every law in the Bayesian network, okay, in the Bayesian network associated with a graph. Network associated with a graph. And yes, amazingly, there is such a rule. It's called deseparation. And it's a sound and complete graphical rule for determining whether a conditional independence holds under any law in the Bayesian network. Okay, we write it as a independent or the symbol. But this is a graphical rule. Okay. And then there is a theorem, a very powerful. And then there is a theorem, a very powerful theorem that says that if A is disseparated from B given C, then A is conditionally independent of B given C under any law in the Bayesian network. Any law. Okay? So why is, let me just briefly, briefly, briefly say what desparation is, because otherwise you won't understand anything. So for a set of variables A to be deseparated from another set of variables B. It from another set of variables B, given another third set of variables C, what has to happen is that every variable in A is deseparated from every variable in B given C. And what does it mean for a node or a variable to be deseparated from another variable given a third set of variables? Well, what that means is that all paths between A and B Between A and B are blocked by C. So, what does it mean to be blocked? Well, here is the definition: A path is blocked by C if either at least one non-collider is in C. So, colliders are those variables like D in there. Okay, this is a collider, okay? So, you have a variable, another variable, and D is a collider in this path, okay? This path. Okay? So for a path to be blocked, what has to happen is that if you have a path that doesn't have colliders, okay, then at least one non-collider has to be in C. The idea is you have association flowing through paths, okay? So you can think of this variable causing this variable, and this is an intermediate variable in the path, okay, in the causal pathway. Okay, in the causal pathway. So, if you condition on this variable, you block the association that flows through that particular path. Okay? The same is in this situation where C is also a non-collider and it's a common cause. So, common cause is cause association between two variables, between the two common effects. But if you condition on the common cause, at least for On the common cause, at least for that particular path, you block the association. Okay? So these are two instances where the path between A and B will be blocked by C. But there's another situation where it will also be blocked. It's if along the path the path hits a collider, okay, where neither the collider nor the Where neither the collider nor the descendant of the collider are in C. Okay? In other words, you have two common causes of an effect, okay, of a given effect. And if you don't condition on the effect, the two common causes, if they are independent to start with, they will remain independent. Okay, but if you condition on the common cause, they no longer are independent. Okay, this is called patron bias. All right, so. All right, so that's so much that I can say for the separation, and you'll see why it's important. But now let me go to the counterfactual law. So for the moment, I've already explained you the implications of having a Bayesian network for the factual data. I want to talk about the counterfactual data, the counterfactual law. Okay, and in particular, imagine that you are interested. That you are interested in estimating, okay, in learning about the mean of a variable, let's say it's the last variable in the graph, vj, okay, when you consider a counterfactual world where you're going to intervene on a particular single variable that I will call a. It's a sub, it's a variable included in v okay, and you're going to intervene using some kind. Going to intervene using some kind of random regime, okay, pi of AZ. But when I write this, this is completely general because pi of AZ could be a non-random, you know, could be a point mass probability. And it could even be a point mass probability that doesn't depend on Z. If it doesn't depend on Z, it's a static regime, okay? It doesn't depend on anything. Otherwise, it's a dynamic regime. It's a personalized treatment where I am thinking of a world where I. Am thinking of a world where I will assign you the treatment conditional on, you know, I will see first your z-values and then decide which treatment I assign you to. Okay. All right. If you look at this formula here, this formula here is obviously the one that comes from this formula, right? All I'm doing is I'm marginalizing, okay, over all variables, all the variables, you know, in the graph, taking the You know, in the graph, taking the integral of y times the density. Okay, so that's the law. But it just turns out that, okay, this is an identifying function of. Okay, this is what I will have to estimate if I wanted to estimate the mean of y in the counterfactual world. But it turns out that there are many other functionals, many other functions of the distribution of the factual data that also agree. Data that also agree with this particular functional for every law in the Bayesian network. So the math problem here is: I give you a functional, okay, and I ask you, give me every other possible functional that agrees with this functional when I tell you that p belongs to the Bayesian network, okay, generated by G. Okay, in particular, okay, there are functionals. There are functionals that are called adjustment functionals or g formulas. Okay, these are the simplest possible functionals. They are functionals that, if you look at this expression here, think about the simplest case when pi is a point mass at a particular value. Okay, let's say that pi is a point mass at a value a equals zero. So this is just the indicator of a equals zero. Okay, so I will have here a. So I will have here a equals zero. The summation will go away because only when a is equal to zero, this will evaluate to a non-zero value. And what formula do I have then? I have the usual adjustment formula, right? I have the standardized adjusted mean, okay, where I standardize according to the distribution of a particular set of covariates L. Okay, so think of this. Okay, so think of this formula as just the standardized generalization of the standardized adjusted mean. And that translates, I mean, one can show very easily that this is equal also has this other expression as an expected value of an IPW type of expression, the weighted mean of y, where the weights are according to the random Nicodem derivative of pi with respect to p. Of pi with respect to p. And of course, I'm going to call this, I mean, I'm going to say that this formula is the adjustment formula. And I will require, of course, that Z is included in L, okay, because otherwise, you know, I don't get the expression that I want. So we are going to define a Z adjustment set for a single treatment A on outcome Y to be any L, any size. Be any L, any subset L of V disjoint with A and Y, that satisfies that L includes Z, okay? And that under the causal graphical model for any regime pi that depends on Z, the mean of pi is equal to the corresponding adjustment formula. Okay, so in other words, think of L as a set of covariates that suffice. That suffice for controlling for confounding, okay? Because if I just do the standardized mean, okay, controlling for those L's, I actually get the counterfactual mean, okay? And that now, you have to think that I am assuming a graphical model. Okay, I'm assuming a graphical model, and I'm saying, okay, what are those L's? Okay, how do I are the rules for determining from the graph what those L's are? And there are. By the way, And there are. By the way, when Z is empty, we say that L is a static adjustment set. Okay, when I'm thinking of treatment regimes that don't depend on any Z, that are one size fits all. I call L a static adjustment set. So I said there are a criterion when Z is a static adjustment set. Sorry, when L is a static adjustment set, the computer The computer scientists have derived a graphical criterion for determining all the static adjustment sets given a graphical model. And those are the conditions for L to be a static adjustment set are that L is neither a mediator, a mediator is any variable that is in a causal path, okay, a path that is directed, okay. Directed okay, any variable that is in the causal path is a mediator, okay. So, if L is not a mediator and is not a descendant of Y or of any mediator, okay, so A cannot be a descendant of A in a way, okay? Then, well, no, it can be a descendant of A, but it cannot be a descendant of a mediator, okay, or of Y. Or of y and L blocks all the non-causal paths between A and Y. What are the non-causal paths? Are paths that are not directed? Okay, that are not directed, okay, that have some arrows that go in different directions. They are not one, one, one, okay? Well, if those two conditions happen, then L is a static adjustment set. And this condition is an if and only if. Okay, so I can check, I can go and list, okay? And in fact, there is a program called Dagity that. A program called Dagity that will list you, you give them the graphical model and it will list you all the adjustment sets. Okay, well, what we shown in one of our papers is that if now I have the class of all Z adjustment sets, then I can compute that class, okay, essentially as taking a subset of the adjustment sets that are static. Okay, what are those? Okay, what are those? The Z adjustment sets are just the static adjustment sets that include Z. Okay, so that's a theorem. Okay, so we now have a theorem that says if you want to find out the effect of a particular personalized regime that depends on Z, okay, and you want to figure out what are the adjustment sets that suffice for controlling for confounder, just use the rule of. Just use the rule of Spitzer, but now keep only those adjustment sets that include Z. Okay? All right. So here is the deal. Okay, so for a static adjustment set, these two variables, couch and fitness level, suffice to control for confounding. They are a static adjustment set because they block all the causal pathways, sorry, all the non-causal pathways between injury and warm-up exercise. And warm-up exercise. Okay? And they are not descendants of any mediator of A, of the relationship between A and Y, nor mediators, you know, nor descendants of Y, nor mediators themselves. So these are one, these are others, okay? These are also adjustment sets. What about adjustment sets that are for a personalized regime? For a personalized regime where I'm going to assign you treatment dependence on your previous injury. Well, it just turns out that I cannot simply take an adjustment set that was static and take the union with the Z, okay? Because that news adjustment, that new set of covariates might no longer block all the non-causal path between warm-up exercise between A and Y. Between A and Y. For example, in this case, if you go to Y, injury to pre-intragame pre-propriob conception, contact sports, previous injury, because previous injury is a collider, and if I am conditioning on previous injury, then that opens a path. Okay, then you go to total motivation and then warm-up exercise. And all of a sudden, by including previous injury, By including previous injury to an adjustment set that was static, okay, I now no longer have an adjustment set. Okay, so even though this new set of covariates includes Z, it's no longer an adjustment set. But if I take this new set of covariates on this one, contact sport, if I add contact sport, now these initial three covariates were adjustment. were adjustment sets, static adjustment set. And in fact, when I add previous injury, they remain a static adjustment set. So now they are a static adjustment set that includes Z, and then they are a valid Z adjustment set. All right. So finally, let me go to the rules for comparing adjustment sets for point exposure studies. Okay, so if you recall, I said that it's the adjustment. I said that a z adjustment set is any set of covariates L that includes Z, okay, and such that for any random regime pi of AZ, the functional that is given by the IPW functional or the G functional actually agrees with the counterfactual mean for every law in the Bayesian network. Okay, so I'm going to call. So if I wanted to estimate. To call, so if I wanted to estimate, suppose that I have an adjustment set and I wanted to estimate this functional, okay, I will need to estimate either the propensity score, okay, and do, you know, PN of the propensity score, or I will need to estimate the counter, the cognitional mean of y given treatment a equal a and l. Okay, so either the outcome regression or the propensity as always, but now suppose. Propensity, as always. But now, suppose that you do estimation where you're going to estimate the propensity score or the outcome regression non-parametrically, okay? Or maybe you do a doubly robust estimator where you estimate both of them non-parametrically, okay? So in that case, if at the end of the day you did it under certain assumptions, okay, if you, if you, if the propensity score and the outcome regression have certain And the outcome regression have certain smoothness assumptions, you're going to end up with a regular asymptotically linear estimator, which essentially you can think of it just as an asymptotically normal estimator. But the interesting thing is that because you estimated those two functionals, the propensity and the outcome regression non-parametrically, using, let's say, smoothing techniques or whatever, the asymptotic variance of your estimator will be the same. Of your estimator will be the same regardless of how what particular non-parametric approach you took. Okay, so long as the approach yields a regular and asymptotically linear estimator. So that means that now we are in a set of problems. We can define now our target estimators of the target functional, just as what I called the non-parametrically adjusted L estimators. Okay? So L. Estimators. Okay. So L non-parametrically adjusted estimators are just the ones that estimate this functionality by using non-parametric estimators of either the propensity score, the outcome regression, or both, okay? And that yield regular asymptotically linear estimators. And because they all have the same limiting distribution, that limiting distribution will only depend on L, on which particular set of particular adjustment set you chose. Adjustment set you chose, and on the treatment regime pi. Okay, not the treatment regime, but the Z variable. Well, actually, the treatment regime, but I'll be more precise in a minute. Okay, so the important thing is that there is a unique variance, and that variance is the variance of the unique influence function of the functional psi pi L under the non-parametric model. So, this part, you know, if you don't know semi-parametrics, you don't know. Know if you don't know semi-parametrics, you don't know what an influence function is, just ignore it. Just think about the fact that we know how to calculate the variance of those particular estimators, the asymptotic variance, doing some very simple calculation. So the questions that we addressed was: well, if you give me two adjustment sets, are there graphical rules to determine which one yields an estimator with smaller variance, smaller asymptotic variants? So you pick. Parasymptotic variants. So you pick up two different L's, both of which are valid adjustment sets. Okay. You want to target a particular treatment regime pi. Okay. And I ask you, can you compare one L versus the other in terms of their sigmas? Okay. Are there rules that tell me, you know, if you use this L versus this other L, you have guarantee an asymptotic variable. Guarantee an asymptotic variance that is smaller, okay, for the first choice of L than the second one, regardless of what P is, so long as P is in the Bayesian network. Okay, and moreover, is there a universally optimal adjustment set? And if so, what graphical rules determine it? Okay, so what I'm going to do now is basically put this in perspective, okay, and tell you our results. So, this work that we've done is very related to an earlier work by Henkel Perkovit and Matt Chuats, where they basically thought of the same problem, but they were first of all thinking only of static adjustment sets. They were not thinking of regimes that could be personalized. And they assume a linear graphical model. A linear graphical model, meaning that every function, every f function in that graph was linearly related to the parents plus an omitted variable, okay, where the epsilons now are independent. Okay, so they had a linear model for every functional. We are agnostic. We don't say what f is, okay? And their estimation procedure, they consider as the equivalent to our non-parametrically adjusted. Non-parametrically adjusted L estimator, they consider simply estimating the treatment effect via ordinary least squares of the outcome on the treatment and the adjusted covariates. Our work, as I said, generalizes that because we are no longer assuming linear models and we are not estimating via OLS. Via OLS, the treatment effect. But there's, of course, a lot of work connected with efficiency implications of inclusion of overadjustment and precision variables in regression and semi-parametric regression of average treatment effects. That dates back, it's a long, long history that dates back to Cochran and Mantel Hensel. I mean, for nonlinear regression, there's a lot of work that I don't have time to describe. And there's also work in semi-parametric efficient testing. Also, we work in semi-parametric efficient estimation of the counterfactual mean. But our work, okay, the contributions are that we prove that the rules of Henkel apply to the causal graphical model that is agnostic, okay, when the treatment effects are estimated via non-parametrical covariate adjustment. We also derive rules for globally, for determining the globally. For determining the globally optimal adjustment set for personalized treatments, okay, that depend on Z. And we also consider a problem that is a realistic problem, which is, well, it's really true that it's not the case that you will always be able to measure all the variables in the graph. Okay? So if you exclude the variables that you cannot measure, but you still have identification and you still have a set of adjustment sets, can you now? Adjustment sets, can you now restrict attention to the adjustment sets that you can measure and tell me which one is optimal in that subset? Well, we consider that problem. We gave a negative result and a positive result, which I may not have time to explain. And we prove also, we actually extended the rules to time-dependent treatments and confounding. And we prove that an optimal time-dependent adjustment set does not. Time-dependent adjustment set does not always exist. Finally, we characterize graphs under which the optimal estimator, the one that we would be able to estimate if we could measure all the variables in the graph and did the most efficient estimator of all, not the efficient adjustment estimator, but the most efficient of all, the semi-parametric efficient one. Are there graphs where I can ignore all those other variables and just look at the Other variables and just look at the optimal adjustment set because the optimal adjustment set gives me an estimator, an adjustment, adjustment estimator that is asymptotically equivalent to the semi-parametric efficient estimator. So we've done all of that, unfortunately. So how much longer do I have? Five more minutes? Well, so let me let me go just to very briefly to one set of results. I mean, I have. Of results. I mean, I have twice as many slides to talk about, but let me just talk about one result. So, here is one result for comparing two adjustment sets. So, suppose that you started with an adjustment set B, okay, that is a Z adjustment set, and you have a set of variables G that is disjoint with B, but that it satisfies that G does not further predict the treatment given the variables, the adjustment variables that you are. Variables, the adjustment variables that you already have. Well, then the union of G of and B is still an adjustment set, and it holds that it's always preferable to use G union B than to use only B in the sense that the asymptotic variance, regardless of what the treatment pi is, so long as it depends on Z, right, is always less than or equal. equal the asymptotic variance of the non-parametrically adjusted estimator that only uses B. And the gain in efficiency is actually super interesting in a very simple case in which the treatment regime is actually a static regime that doesn't depend on Z and that sets A to little A. Well, in that case, one can show that the difference in the, you know, the increasing The you know, the increasing variance for omitting g, okay, for not including g, remember g basically what's happening is g is not creating overadjustment because g is uncorrelated with treatment. Okay, so that's good news when g, you know, when you have a baseline variable that is uncorrelated with treatment, you condition on that variable, you don't create over adjustment. Well, that formula gives you this expression here, and this expression basically says it's G. Basically, it says it's G further predicts Y within levels of B and among people that were treated, okay, with A equal A. If it further predicts Y and if it predicts it a lot, okay, especially for those B's for which you have a very small chance of seeing people treat it, okay, for those B's for which one over the probability the propensity is very big because the propensity is very small. Big because the propensity is very small. Well, in those cases, you incur in a lot of efficiency gains by including G. Okay, and the picture, the graphical picture, should be something like this. G is not correlated, you know, it's independent of A given B. But G predicts Y, okay, for every level of B. Well, if this red arrow here encodes a very strong association, you really gain a lot by including G. And you really gain a lot by including G. And think of the special case in which B is the empty set. Okay, so imagine that B didn't exist, so that you have a clinical trial, okay, a randomized trial where you have A randomized because it doesn't depend on anything causing Y. And G now stands for baseline covariates. Okay, if those baseline covariates don't predict A, okay, but do predict Y within levels of A, they are good. Okay, you want to include them. They are good. Okay, you want to include them in your analysis. You want to adjust for them. Okay. And this is what the graph, the result, is saying for non-parametric estimators. Another one is deleting over adjustment variables. So if you started with a set G, union B, okay, a big set of variables, G stands for good and B stands for bad. Okay, so that's so that nemotechnic rule. So if you started with a union of two variables that are that together comprise Are that together comprise a G adjustment set, but B doesn't predict Y conditional on G and within levels of A. Okay, so B is not really helping you to predict the outcome. Then you can, so long as G includes Z, you can erase B, okay, you can delete B, and you still have an adjustment set. In other words, G alone is an adjustment set, and it's much better. And it's much better, well, it can be much, much better than having the union. Okay, so you can delete that variable B because B is only creating over adjustment. B doesn't predict Y within levels of G and A. And there is a formula again that has a very nice interpretation. I don't have time to do it. But again, you know, the graph is something like this. If B is a strong predictor of A, but Predictor of A, but doesn't help you to predict Y, don't include B. Okay? G alone is much better. I mean, B here is an instrumental variable. Okay. All right. So putting the two things together, suppose that you have G and B that are two adjustment sets, such that A is independent of the part of G that is not in B, conditional on B. B, conditional on B, and the part of V that is not in G is independent of Y, given G and A, then what happens is that it's always better to keep G that to use G than to use P. Okay? And again, the proof is really straightforward, but again, I don't have time to do it. And I'll go through one more thing and I'll stop there because obviously I don't have time. So not all adjustment sets are comparable. Adjustment sets are comparable. Here is an example. Suppose that the graph was this graph, okay? So here you see that there is a perfect mirror, okay? I mean, you have a graph on the top and a graph on the bottom, okay? And W1 and O1 stands, you know, have like a mirror here, you know, a mirror on W2 and O2, okay? And now think about O1 and W2. They suffice to block all the non-causal paths between. To block all the non-causal paths between A and Y. But likewise, W1 and O2 suffice. Okay. And they stand in equal footing. Okay. So when is there one of the two that is better than the other universally for all laws that are in the Bayesian network? No, the answer is no. Because if O1 and W2 are such that the green association, the green arrow here encodes a strong association, then O1 is a good predictor of. And then O1 is a good predictor of y, an association that is much stronger than the brown association. And then the blue line is encoding a weaker association than the red line, then O1 and W2 is preferable to W1 and O2. But of course, I can revert the order, okay? I can revert the scenario, and now I will have the other ones being preferable. So there's no universally. So there's no universally preferable between the two of them. Yet there is one set of covariates of adjustments that is universally better than all the other adjustment sets, and that's O102. O1 and O2 beats all of them. Okay, so what we have is the following results. If you have non-descendants, if you collect, if you take the collection of all non-descendants of A that are parents. That are parents of y or of vertices of mediators of y between mediators in the causal pathway between A and Y. Then, for that set of covariance, it just holds that for any other adjustment sets, the two conditions for making O better than L holds. And in that case, okay, then just using our results, we prove that O is globally optimal. And it's an globally optimal adjustment set for a static regime. And then what we showed is that if we add to OZ, then in this particular case, we still have an adjustment set and it's globally optimal Z adjustment set. So let me just show you one result and I'll finish here. So here is the set of, in this particular example, the set of globally optimal static adjustment sets. Optimal static adjustment sets. Okay, they are, if you see, they are all the nodes that are parents of a variable that is either a parent of Y or a parent of a mediator between the treatment and outcome, okay, in the causal pathway between treatment and outcome. So those are the optimal adjustment sets. And what about if I wanted the personalized adjustment set where I'm going to personalize given previous injury, I just Previous injury, I just add previous injury to this already optimal static adjustment set, and now I have an optimal personalized adjustment set. All right, so I think I'm going to stop here because I'm over time.