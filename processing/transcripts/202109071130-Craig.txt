Thank you very much. Thank you for that introduction and for inviting me here to speak. So like was already said, my talk will be on a blob method for degenerate diffusion and applications to sampling and two-layer neural networks. And this is based on two joint works, one already complete with Jose Antonio Carrillo and Francesco. Antonio Currillo and Francesco Patakini, and another one in progress with Karthik Elenfasuthi, Matt Haberland, and Olga Turanova. So the motivation for the problem that I'll consider in today's talk comes from either sampling in statistics or maybe even a control theory, like a robot coverage algorithm in engineering. So I'm going to put both of these applications in a somewhat similar framework. A similar framework. In both cases, we have some desired target distribution, rho bar, which I will always normalize to be a probability measure on d-dimensional Euclidean space. So the goal in a sampling context would be how can we choose in samples, so in points in d-dimensional Euclidean space, so that perhaps just with high probability, they accurately represent this desired target distribution. Target distribution. A similar, the problem can be framed in a similar way in robot coverage algorithms. In that context, what they're interested in is how can we program robots to move so that they distribute their locations. So we can think of this as in robots with in locations in Euclidean space, and we want them to distribute their locations according to rho bar. Though a key difference here is that we want this to be a deterministic algorithm. But in both cases, But in both cases, we seek to approximate our target distribution, rho bar, by an empirical measure. So if we put a Dirac mass at each one of these n locations and average them, we hope that this will converge in some sense as n goes to infinity to the desired target distribution. So there's a long history of how PDEs can inspire new ways to construct this empirical. Construct this empirical measure. So, to talk about a little of the classical theory, I'm going to assume that my desired target distribution is log concave. In other words, rho bar is given by e to the negative v, where v is a convex or maybe even strongly convex function. Maybe Hessian is strictly bounded below by a positive number. So, the most classical connection between PDEs and Between PDEs and sampling algorithms, comes from the Fokker-Planck equation, which I write here at the top. Here, I write it in a little bit of a funny way. It almost looks like a non-linear equation. But if we expand out the right-hand side, we get the familiar Fokker-Planck equation. So we have a linear diffusion term and then a drift term according to the gradient of the logarithm of this desired target distribution. So, you know, one of the wonderful parts, one of the The wonderful parts, one of the wonderful attributes of this equation is that along solutions of this equation, they dissipate the KL divergence exponentially quickly in time. So if I take the KL divergence between the initial conditions and our desired target distribution, and then I consider the KL divergence at a later time, T from the desired target distribution, we can see that here, lambda, this would be the lower bound on the Hessian or the kind. Would be the lower bound on the Hessian, or kind of the convexity parameter of our potential v. We can see that if lambda is positive, in other words, if v is strongly convex, this decays exponentially quickly in time, which is one way of measuring how quickly rho t is approaching rho bar, the desired target distribution. So, because solutions of the Fokker-Flag equation move so quickly to the desired target distribution, it's a this Distribution. This provides a natural dynamics that you might try to follow for a sampling method. And indeed, Langevin dynamics follows exactly this approach. You consider a spatially discrete particle approximation of the Fokker-Planck equation. So here we have Brownian motion, and here we have a drift term. And so this is, of course, a stochastic particle method. Of course, a stochastic particle method, but it can be shown that if you construct the empirical measure for the stochastic particle method, as you increase the number of particles, this converges almost surely to a solution of the underlying PDE. Okay, so this is really the classical approach. And in fact, there's many, many connections between this particle method and the Fokker-Planck equation. This is just one of them. So if you want. So, if you want to sample rho bar, a classical thing you would do would be to evolve the particles according to this equation. And if you had enough particles and you let them run for long enough time, you could expect that these locations would accurately sample from the desired distribution. So in today's talk, I'm actually going to propose that we consider a different type of PDE for sampling and predictably from the theme of the workshop. It's a nonlinear diffusion equation. Diffusion equation. And so, if we have the Fokker-Planck equation up here, you can see that the degenerate diffusion equation that I propose is like the Fokker-Planck, but as if we got rid of the logarithm. And so, I have it here. I won't expand out the right-hand side because it gets a little messy, except maybe in the case that rho bar equals one. In that case, it just becomes a porous medium type equation. Okay, so why is this degenerate diffusion equation something reasonable that you might try? Something reasonable that you might try in these applications and sampling. Well, first of all, it turns out that again, if rho bar is kind of strongly log con or strongly log concave or the potential is strongly convex, solutions of this equation also dissipate the KL divergence exponentially quickly in time. Okay, so it has this nice property of the Fokker-Planck equation. But it's maybe a little bit less clear for this equation what would be the appropriate particle method. What would be the appropriate particle method? Over here, where we have the linear diffusion, you know, we have a nice theory of stochastic particle methods for diffusion operators like that, but here with the non-linear diffusion, maybe it's not so clear. Okay, so my goal for today's talk is going to be to introduce how you can use a Wasserstein gradient flow structure of this equation to define a particle method for this type of PDE. So, why would someone want to do this? I mean, we already Would someone want to do this? I mean, we already have this great approach using the Fokker-Planck equation and Langevin dynamics, incredibly popular. Why would we want to use this nonlinear diffusion equation? So let me give you a few items of motivation. So first of all, it turns out that this degenerate diffusion equation appeared very recently in the sampling literature and statistics as a toy model for Stein variational gradient descent. So this is a So, this is a very popular sampling algorithm. And it was identified that maybe one way you can think about the success of stein variational gradient descent as is interpreting it as a type of kernelized chi-squared divergence, or excuse me, as a type of kernelized gradient flow of the chi-squared divergence, which is exactly this PDE that we have here. Again, that connection to the chi-squared divergence, this is one of the, you know, okay, we have the KL divergence, but there's also chi-squared divergence. There's many, you know, divergence. squared divergence as many you know divergence operators and statisticians use um to measure kind of the approximation of a desired target distribution and so maybe if in your problem of choice it made more sense to be trying to to get close to your desired target distribution and chi-squared divergence as opposed to kl then this could really be the design the perfect dynamics to follow um this is turns out as i'll mention on the next slide to be the the two vasso sign gradient flow of the chi-squared Vosserstein gradient flow, the chi-squared divergence. So these dynamics are dissipating it as quickly as possible with respect to the Vasostein structure. Another motivation you might want to have for a particle method for this equation is maybe, you know, like me, you're coming from numerical analysis of PDEs. And in that case, these types of nonlinear diffusion equations show up in a variety of applications, such as models of porous media, biological swarming. And so a particle method could help us simulate this equation more. Simulate this equation more accurately in applications. Another reason that a particle method for this PDE could be useful is that it turns out the method I'm going to introduce is a deterministic particle method. This is in contrast, of course, to the stochastic particle method we have for the Fokker-Plunk equation. And for applications in control theory, like these robot coverage algorithms, having a deterministic particle method could be really useful because then you can have things like convergence gaps. Things like convergence guarantees and stopping criteria on the first run. You don't need to average this somehow over a lot of runs. And then finally, a last motivation is it turns out that the method that I will introduce turns out to be exactly the same as these toy models for studying training neural networks with a single hidden layer with a radial basis function activation function. So, in fact, our result in which we'll introduce, I will introduce. In which I will introduce this deterministic particle method and prove convergence to this PDE, will actually identify that the continuum limit when the variance of the radial basis function goes to zero for these models of training neural networks is exactly this kind of nonlinear diffusion equation. And what's great is because this has a nice gradient flow structure by looking at the continuum energy, we can say things about when the continuum limit of these optimization problems. Continuum limit of these optimization problems have good convexity properties. And that's nice because in optimization, they often observe that their discretizations converge to a much better global minimum than they have any reason to hope for. And perhaps one of the reasons that is true is that maybe we can think of their dynamics as actually sampling from a continuum distribution that does have good convexity properties and a unique global minimum. Okay, so with these. Okay, so with these motivations in hand, now let me go forward and tell you a little bit about how we use the two Wasserstein gradient flow structure of this equation to define a particle method. So I think for this audience, talking about Wasserstein gradient flows is not such a foreign thing. A Walserstein gradient flow is just describing the evolution of a probability measure where it evolves according to the negative the Walserstein gradient of some energy. Walserstein gradient of some energy. The Fokker-Planck equation is maybe one of the most famous examples of the Wasserstein gradient flow. It's the gradient flow of the KL divergence. And the degenerate diffusion equation that I'm talking about today also has a gradient flow structure. It's the gradient flow of the chi-squared divergence. And just to remark, two other equations that Other equations that have been of interest in recent years, which have these Wasserstein gradient flow structures, and that will turn out to play a role in my analysis of this degenerate diffusion equation, are first, this type of aggregation equation with drift. So here I have an aggregation equation with my non-local interaction term, and here I have a drift term with my external potential V. This is a Vasserstein gradient flow of this energy, where I have a Energy where I have an interaction energy and an external potential here. So, this is one equation that's been studied extensively over the past 15 years. And then very recently, there's been several works, which as I've already alluded to, looking at training dynamics of two-layer neural networks as a Wasserstein gradient flow of this energy. So, here you can see all I'm writing down is the energy. I'm not writing down the PDE in this case because it gets a little long. In this case, because it gets a little long. But you can see what's going on by just looking at the energy. So here we have some sort of activation function, capital Phi, and there's a variety of choices of phi that arise in practice. Maybe very famously is the Relu activation function, but most relevant for what I'm going to talk about today is a radial basis function activation function, where you can think of psi as a Gaussian. So we have an activation function here, and then I have my measure rho, and I rho. And row represents the parameters I'm choosing, and I want to choose my parameters row so that this integral approximates my target function, f naught, as accurately as possible when measured on my underlying data distribution, nu. So here I'm measuring the accuracy of the approximation in the quadratic loss. There's a lot of other loss functions that people consider. But the reason that I mentioned the quadratic loss is because it has a close parallel. Laws is because it has a close parallel with these energies that have already been well studied in the PDE literature. And that can be seen if I just expand the square here. I end up with my first term when I have put the square here. Looks like this. If I kind of apply Fubini, I can gather my integrals in Z and realize that this here is just a term, a function, Kx of Y. So this is very reminiscent of these interaction type energies. Reminiscent of these interaction type energies, though, of course, it depends on x and y individually instead of their difference, unless I'm considering a radial basis function, then it does depend on their difference. And then here, I have an ex when I expand the cross term, I get something that looks like an external potential, exactly like we have up here. And then the third term, that squared, doesn't even depend on rho. So that's just a constant in rho. And so when I take the gradient flow, it doesn't affect the diagonal. Take the gradient flow, it doesn't affect the dynamics. Okay, so you know, because of this analogy with these, you know, energies that have been well studied in the PD context, there's been a lot of interest in these models of two-layer neural networks. And especially in this case of the radial basis function activation function, if I simplify this, I get something that looks like integral of psi convolved with rho squared d nu. So keep this energy in mind. So, keep this energy in mind because it turns out that this is going to appear again when I tell you about my particle method for this equation. And that's the connection between this degenerate diffusion equation and these training dynamics of two-layer neural networks. Okay, so how am I going to use the Vosserstein gradient flow structure of this equation to define a particle method for it? Well, something that, you know, I think many experts in the room already know is that a key fact about A key fact about Vosserstein gradient flows is that all Vosserstein gradient flows are solutions of continuity equations where the velocity is given by negative the gradient of the first variation of the energy. So in particular, you know, they all kind of conserve mass and positivity, obviously, they're, you know, gradient flows in the space of probability measures. But using this rigid structure of that, they're continuity equations is a natural way of defining particle methods. Way of defining particle methods. So I'll say just a little bit about particle methods for a general continuity equation, and then I'll specify in to the one that I have in mind for this talk. So if someone just gives you an arbitrary continuity equation with a uniformly Lipschitz continuous velocity field, and here by uniformly Lipschitz continuous, I mean uniformly in rho. You know, as we see, the velocity field in general can depend on rho. And assuming this is uniformly Lipschitz continuous, Assuming this is uniformly Lipschitz continuous in row is often going to be too strong of an assumption, but let's just take it for now. So now I have this continuity equation. We most of the time think of it as an initial value problem. And so if I want to numerically simulate this using a particle method, the first step is that I take my initial condition and I want to approximate it by an empirical measure. So you can do that in a variety of ways. Honestly, in numerical analysis, we often just approximate it on a grid. Made it on a grid. Then I take the locations of these initial particles in my empirical measure, and I evolve them according to a system of ordinary differential equations. And that's exactly the same system of ordinary differential equations that would come if I took this velocity and I evaluated it at the empirical measure. And sort of what's very nice and natural about this perspective with the continuity equation and thinking of weak. Equation and thinking of weak solutions of the continuity equation in duality with C infinity compactly supported functions is that evolving the locations of my particles according to the system of ODEs is exactly the same as evolving my empirical measure as a weak solution of this continuity equation again with the same velocity field. And what's great is if I have the same velocity field here as here, and I know that it somehow uniformly Lipschitz in all of my row, I can In all of my row, I can use nice stability estimates to get convergence of my particle method. So I know, for example, that as long as my initial conditions for my particle method, my empirical measure, is converging as n goes to infinity to my exact initial conditions, this provides an upper bound, of course, you know, depending on time, degenerating as t goes to infinity between the solutions of my evolving. The solutions of my evolving empirical measure in the exact solution of my continuity equation. So, if this goes to zero, maybe on a bounded time interval, then I will be able to conclude that this evolving empirical measure converges to a solution of the actual continuity equation that I wanted to approximate. Okay, so this is sort of the general recipe for particle methods. So, okay, the particle method sort of lists the solutions of ODEs into a Sort of lists the solutions of ODEs into a PDE framework, you know, weak solutions, and that's the Wasserstein gradient flow perspective comes in because it gives us good tools for getting that our velocity field satisfies this type of uniform Lipschitz assumption. But of course, the key problem with this whole thing is that what happens when my velocity field is not uniformly Lipschitz? And if I go back to these examples that I mentioned before, in fact, both of these will kind of in general, for you know, In general, for a wide range or row, fail that sort of uniform Lipschitz condition you might want to have. And here, I maybe only get it as long as, for example, my interaction potential and drift potential are uniformly bounded. So, what can be done? How can we somehow make this degenerate diffusion equation more like an aggregation equation so that we can give So, that we can get that uniform Lipschitz continuous property of the velocity field and be able to define the particle method. So, the solution that I'll propose in today's talk is to regularize. So, what we're going to do is we have this degenerate diffusion equation we're interested in, which is the Falserstein gradient flow of this energy. Okay, you can see I've actually modified my chi-squared divergence. I expanded out the square and I removed the term that depended on a constant, and then I used the fact. And then I use the fact that these are both probability measures. So this takes a slightly different form from what I wrote before, but the reason I wrote it in this form is it makes it a little simpler to see the regularization that we're considering. So what I did is I took this energy and I said, well, I want to be able to evaluate this when rho is just a sum of Dirac masses. And of course, it doesn't make sense to take a sum of Dirac masses and square it. So how can I fix that? And so I'm going to fix it by convolving rho with a mollifier. By convolving rho with a mollifier by epsilon. So you can think of this as a Gaussian mollifier. Now, suddenly, this energy, it makes perfect sense to evaluate this when rho is a sum of Dirac masses. And I can look at the two Wasserstein gradient flow of this energy, which has a little bit of a weird form. It was a pretty intricate looking velocity field. But the good news is this velocity field for epsilon strictly positive will satisfy a global ellipsid. Satisfy a global Lipschitz condition. So we have that, you know, in particular, we prove that this velocity field is Lipschitz and, you know, clearly depending badly on epsilon as epsilon goes to zero, but it's at least well defined for all epsilon positive. So since we have this nice Lipschitz condition, we can define a particle method. So here's our particle method. And we know that for any fixed epsilon, For any fixed epsilon, as n goes to infinity, this will converge to a solution of this equation. But of course, the key thing that we're interested in is we want to send n to infinity and epsilon to zero to recover our original degenerate diffusion equation. So it turns out, oh, and here, let me also remark, this is where the connection, this is where you can really see the connection to these models of two-layer neural networks. This energy I have here is exactly. Energy I have here is exactly that first term from the model of two-layer neural networks where my desired target distribution plays the role of like one over the data distribution. There new is my one over rho par. They also had another term depending on an external drift potential, but everything that I'm going to say is totally fine if you want to add in an external drift potential. I'm just leaving it off my slides for simplicity because adding in an external drift potential that In an external drift potential that doesn't complicate the analysis. Okay, so what's cool is that by our analysis of the limit as n goes to infinity and epsilon goes to zero, which was motivated by developing a particle method, a numerical method for this equation, actually turns out to sort of shed light on these toy models, showing that the limit of these models as n goes to infinity and epsilon goes to zero is exactly this type of degenerate diffusion equation with, I guess, an extra drift term arising from here. Drift term arising from here. Okay, so there's been several previous works looking at convergence of these types of methods, but all in the case where the underlying data distribution was identically one. So for today's short talk, I won't go into too many details. So the key novelty of what we were doing is that ours extended to target distributions. Target distributions that were not identically one. So ours work for any target distribution that's log concave. A funny assumption that it's a technical assumption from our analysis is that we have to assume that you're approximating the exact initial conditions with the empirical measure very quickly in epsilon. So it's sort of intuitively obvious that there must be Relatively obvious that there must be some relationship between n and epsilon. As you're sending into infinity, epsilon can't be going to zero too quickly. But this is a very, very, this is saying n has to go to infinity really fast as epsilon goes to zero. I expect that this is not optimal and could be improved. It's just a kind of a technical condition that comes from our analysis. But we weren't too worried about it since, honestly, we were very happy to get. Honestly, we were very happy to get anything outside the case where rho bar was identically one. And because we're using these gamma convergence techniques, our result's not quantitative. So we do succeed in proving that this particle method proves, converges to a solution of the degenerate diffusion equation, but we don't get a rate on it. And it only works on bounded time intervals. Okay, so I'll flash a few numerics at you to conclude the talk. So this is just to give you a rough idea. So, this is just to give you a rough idea of how this actually works in practice. So, in each of these figures, the desired target distribution is represented by the dashed purple line. These other lines here, these show a kernel density estimate or kind of a functional approximation of my empirical measure at different times. So, that's my initial condition, and then this is how it evolves over time. So, looking at these. So, looking at these profiles, you can see that indeed they are kind of converging to this desired target distribution, which is good. That's what we wanted to happen. We knew that that would work in the case when the desired target distribution was log concave, as in these two cases, but it does even numerically work even when the desired target distribution is not log concave. So, that was a nice thing to see. And at the bottom here, what I actually have are the evolution of particles. Evolution of particles over time. So these are the particles that underlie these kernel density estimates. So here's time in this case is going up. So they start at some initial conditions and evolve over time. Some nice things that we were able to see is that if you remember at the beginning, one of the motivations for considering this type of degenerate diffusion equation in sampling applications is that it dissipates the KL divergence exponentially quickly, like the Like the Fokker-Planck equation. And we observe that exponential decay of the KL divergence, even at the discrete level of our scheme. And clearly, as the number of particles gets bigger and bigger, that exponential decay of the KL divergence sort of lasts longer and longer before your numerical kind of discretization error kicks in and starts to saturate. We can also look at the rate of convergence of our particle approximation to the underlying target distribution. To the underlying target distribution and the number of particles, and it looks like it's roughly first order. Okay, so there's many directions for future work. Our result currently only works for rhobar log concave. In fact, we really feel like we can push it further than that, but as many people in this audience probably know, the gradient flow machinery just gets a lot harder to work with when you push outside the case of convex energies. And that's exactly what we'll have to do here. And that's exactly what we'll have to do here. Like I said, we have nothing quantitative. It would be great to get a quantitative rate of conversions depending on the number of particles and the regularization, especially for using this in applications. Another question is, you know, everything we've done so far is with a very naive choice of mollifier, just a Gaussian mollifier, sometimes called a Gaussian radial basis function. But we know from vortex blob methods in the classical fluids case that smart choices of Smart choices of convolution kernel can really give you faster rates of convergence. So that's an interesting direction to explore. And then lastly, there's been some interesting work on, you know, a downside of our method is that it's really an order in squared method. It's an interacting, the movement of each individual particle depends on all of the other particles, in contrast, of course, to Langevin dynamics, though that is stochastic, so you have to average over many runs. But then there's been some interesting. But then there's been some interesting work showing how you can take this to be instead of order n squared, order n by introducing some stochasticity. So while that might not be as desirable in a control theory application, like in these robot coverage algorithms, it could be totally fine in a sampling application. Okay, so thank you very much. Thank you. Thank you very much for your nice talk. Is there any question? Fashionable, maybe you have just a small comment. I probably mentioned it, but I'm not sure if I missed it. What's the difference in the two like? So, what's the difference between like particle method and the block method? Yeah, this is probably a semantic difference, and perhaps different people would give you different answers. You know, I'm having a little feedback. Would you mind muting for a second while I thank you, sorry. So, yeah, I guess the distinction that I would make would just be to say that kind of a particle method, this is well defined for a continuity equation. Defined for a continuity equation. There's no blobs here. You know, there's no modification here. And I guess the distinction I would say between a particle method and a blob method is I would say that's when you introduce a regularization. So that's maybe I where I would say, maybe I'd say a blob method is a regularized particle method. So whereas our naive particle method would fail for this synergy because of the lack of a kind of a global Lipschitz estimate. Lack of a kind of a global Lipschitz estimate on its velocity field, especially when rho bar is an empirical measure. Once I introduce a regularization, then I would call it a glamour.