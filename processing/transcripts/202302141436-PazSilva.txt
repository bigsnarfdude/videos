So, I'm very excited. And I mean, great location. So, anyway, thank you for that. So, what I'm going to do is talk about today about our efforts into trying to, let's say, predicting the behavior of, and eventually controlling the behavior of open quantum systems. And I will start, I guess, by introducing what is our point of view of the problem and hopefully a solution that we have devised that can move the problem forward. So come on. Okay. So the usual setup, I guess I don't have to convince anyone here. What is that the typical thing? We have a system on a bus, and there is some Hamiltonian that can brutal dynamics. And what we can do is put in control. And the controller is a knot that we can turn on some Hamiltonian, which may be noisy, it works only on the system. And at the end, what we can do is just put some apparatus that gates statistics of zeros or ones that it's only observed. Ones that are only observing the system. And of course, from this, we can calculate expectation values cooperators on the system only. And the question is that we typically want to ask is, well, can we predict this evolution or this performance or the evolution of these observables and eventually control them to achieve whatever we want, let's say, for a high-fidelity operation, whatever. Now, and so that's fine, right? So the typical way that we do it, we go to the textbook, we start with, let's say, Over to the textbook, we start with, let's say, initially, maybe some initially factorizable condition. We have some Hamiltonian, and from this, we can eventually find some way using whatever method you want to calculate the expectation value. Now, the problem, or one problem I guess, that I can see, that is a bit, that sort of bothers me a bit, is that if my control is system-only and my observables are all system-only, if you promise me that your Hamiltonian is of this form, that initial state of the bath is of platform, I cannot experiment. is a platform, I cannot experimentally verify your assertion because I can never measure directly the button, right? So I can only see the effect on the system. So I can never falsify or verify your term. So this tells me that, okay, well, so this is one observation for the moment. So let's see what is that actually matters for the QT. So we can go and use the usual setup, right? We go into some interaction picture with respect to the path, the system, and the control. And we have this sort of interaction picture Hamiltonian here, unitary, that is really Here, unitary, that is ruled by the interaction picture Hamiltonian, where essentially you have now a bath operator, which is maybe time-dependent because of the interaction picture. Then we have, of course, this, we call the switching functions, which capture essentially the fact of your control and the system-only operators, I guess, that you have introduced. And you see that this American really actually is the one that captures, let's say, the interaction between your control and the button, right? Is that all good? And then what you would do is say, well, And then, what you would do is that, well, I can go and calculate my expectation value of the observable in the system. And what I can show, of course, is that you can always write it in this way, but essentially, this operator here is the one that captures the interaction again between system and math. If there was no math, there was no noise, or the coupling was zero, then this term, this view operator here would be an identity, right? And there would be no noise, as much. So this is the one that tracks the evolution, or the let's say the influence of the path of my system, right? Of the path of my system. So let's go forward. And then we say, well, we can actually calculate this trace over the path here. This is a system operator. Now, when we take the trace over the path, the one can show is that this is always, you can write it as a functional of integrals that look like this, which at least is some overlap between your switching functions and the higher correlation functions of the path, right, of these path operators, relative to the state of the path at the time zero. And so, whatever functional you have here, And so, whatever functional you have here depends on what is your favorite expansion. You can do your master equation, a dice, or equivalent, whatever you want. But they're always of this form. And so what this is telling us actually is that the qubit, as we were saying, cannot fill the path in the sense that it doesn't care about the Hilbert space, it doesn't care if you have a spin bath, a phononic bath, whatever. It only cares about the correlation functions that it can see. So different types of baths can mimic the same correlation functions and The same correlation functions, and the QED. And so, the real message that I want to say here is: like, really, we should care about the correlation functions because these are the ones that matter, but also these are the ones that can be experimentally verified. I can actually go and do, and we have done this over the last year, design protocols that you ask the qubit and the control, you do basically modulate the control on the qubit, you measure you do the experiment many times and from the response of the qubit, I can learn what these correlations functions are, right? What are these correlations functions? So, what I'm trying to say is that this is verifiable information. And so, and really, I don't want to go into the discussion whether it's Markovian or not. The only thing that I want to say is that if this is delta correlated, then there is no amount of control that I can do that will help. And so this is, for me, this is Markovian. Anything else, then there exists a controller strategy that will help me. On the other hand, if I have a fixed controller capability, then there will be noise that Will be noise that it looks like Markovian, but is not delta-correlated. So, I mean, we can talk about this later separately, but at least my view on Markovian versus non-Markovian scenario. But I guess it's not so relevant. I will just consider the situation for now where this is not delta correlated. That's all I want to say. Right, and so in particular, if this is delta correlated, this integral is independent of the y. Is independent of the y. And so if I want to do, for instance, if I want to do, let's say, the coherence suppression, if I want to suppress that incoherence, my objective would be to make this integral as small as possible. So if this integral is independent of the controller, for example, because if this is delta correlated, you can show that this integral doesn't care about the y, right? Then in that case, it means that I cannot mitigate in any way the coherence. So, okay. So, if we go there, okay, having this made this point, let's talk to the actual setup, right? So, we start again with this state, and then we could try to, for example, try to propagate the system bath state, and we know that this is a general problem, it's a difficult problem in general, and we heard, for instance, of these numerical methods that try to do propagate this, and they are very efficient. But, of course, for a fully general model, it's perhaps not possible. I mean, at least very difficult. And so, of course, sorry about this weak. Of course, sorry about these weak green lines, but hopefully you can see it. So, because you cannot really propagate the full system math evolution, what you have is some method to propagate your system density metrics by tracing all the math. You can do whatever, you can do master equation, cumulants, etc. And of course, if you had information about all the other, you know, the full, all the correlation functions relative to the state of the batter time zero, then in principle, if you had infinite tag in your hands, then you could do a perfect. Type in your hands, then you could do a perfect prediction. And of course, if you're limited information, if you have limited information, maybe because a graduate student didn't want to compute all the higher-order correlations, or maybe experimentally you can only access in a finite time up to a certain order of correlations, then your prediction power is limited. And so essentially, you would say, well, if I only have these correlation orders, I would predict that at some point, then eventually my evolution becomes whatever, right? It doesn't feel, it's not accurate. And so that is, of course, And so that is of course a sign of the question is then of course how do we use better this initial information? So whatever method you want to say you have here, I would like to convince you that we can do better with the same limited information by just using it maybe in a smart way. So this would be the objective of my talk. So let's do this. So the basic idea is the following. And this is a bit the first in the first setup is a So, in the first setup, it's a bit far-fetched, but I mean, we will get there eventually. So, of course, same scenario, if I hold my correlations, I can do some reasonably good prediction up to some point. But imagine that someone, very powerful, tells me that at certain privileged times, tj, the state is always of the factorizable form. And more only that, this guy is so powerful that tells me that what are the correlation functions relative to this initial state of the state of the bath at that point. Then one can imagine that what I could. Then one can imagine that what I could do is, okay, I can move to this time and then restart my method at this point with now perfect information about the correlations and extend my prediction capability a bit further, right? And so you can imagine that I can do it further and further and eventually if this very powerful person gives me this information and guarantees this, then if my delta tj is sufficiently small, then I would win and I would predict for very long conversations. Now, of course this is non-physical because Of course, this is non-physical, because demanding this is actually quite the fit, right? For any time, for a very, very long times. And not only that, but this information is like God-given, right? So it's kind of makes no sense. So the question is then, how do we deal with this problem? How do we get rid of this assumption first? I mean, clearly I cannot demand it, so I have to learn how to deal with it. And so to do this, I'm going to use some results that we had a few years ago, and I think Andrea has also worked a bit over this, played with this a bit. Played with this a bit. So the idea is that, of course, in the traditional sets, when you have the factorizable condition, we have the CPTB map, right, that rules of dynamics. And this CPTB map, however you want to write it, is still a functional of the correlation functions relative to the reduced dynamic, the state of the path. However, when the state of this form, which is not factorizable, then things get a bit tricky, right? Because you can say, first of all, you cannot write a CPT model. That's the thing. So, and not only that, it's not even. And not only that, it's not even known, or well, but we know now, but it is not even clear if what the real quantity that matters are the correlation functions relative to the instantaneous reduced density matrix of the body. And that is a subtle point that I will cover later. So let's imagine that. Let's imagine, for now, that I could always decompose a state in this form, where crucially, imagine that I could always force the state such that the density part of the density matrix, the part of the path is always a density matrix. This is maybe something. Density matrix. This is maybe some basis that you want that is usually defined. And maybe there are some weights that can be a probability distribution or whatever. Let's imagine that this is possible for now. So if this is true, then let's try to calculate the evolution of the system. Well, I can go through the math, et cetera, it doesn't matter. And so what one can show, right, is that it is actually, what this evolution is actually captured by a set of CPTB maps now that depend on this alpha. And each of these depends on the correlation functions relative to D. On the correlation functions relative to these sub-density matrices that we had. And essentially, what you have to keep track, and each of these is acting on one of the elements of your basis. So, what you are doing is actually evolving your basis weighted by these initial p-alpha values. And so, well, this is great, of course. If we could do this, that would be awesome. But the question is, of course, how to do it, right? Sorry, is the q alpha here is this a system operator or? So this is a system operator, and at this point it's hydrofargo. And it's usually defined. This point is I mean it's usually defined. However, making the assumption is there is no entanglement between this issue. So at this point there is entanglement. I cannot write it in this form. But why is it formed? So what my claim is that any state, regardless if it's entangled, I can always write in this sum. Writing this sum. And I will show you that it's possible. Q is not positive. Yeah, so Q is not a positive variable. And I will show you that it's possible. And so the way to do it is to introduce in frames. And frames is, I mean, they've been using mathematics for a while and signal processing. They are awesome tools. And the important thing is that you can think of this as an as an overcomplete on autograph basis if you want. And the idea there is that you can for a frame you can define an infinite number of frames, and in particular there are some privileged ones, doesn't matter for now. Privileged ones, doesn't matter for now. The idea is that when you have a frame on a dual frame pair, what you learn is that you can expand, it's a way of learning basically how to expand any operator in terms of the frame or in the dual frame by using the input or the dual or the frame, respectively. And so if you choose, let's say, your dual frame to be a positive set of operators, then you would say, well, how do I expand in the non-positive in this q alpha frame? So then I would go to this procedure, I can put it in here, and so what you can show is that, of course. And so, what you can show is that, of course, because this P is a positive operator, then automatically, this trace over the system is a positive operator, right? It has to be. And so, if you normalize it, then you get to the condition, to the form that we had, right? We are guaranteeing that this guy is always a density matrix. And depending on what sort of P you use, this can also have some neutralities. For example, if you define these P alphas to form a POVM, then you can show that these guys, these P alphas add to one and they are stop the behavior basically. Add to one and they behave basically like a priority distribution. So there we go. And so this is just an example of what it would be like a frame, like how it will look like, what the dual frame and the frame will look like. And they are, because you are taking the same dimension of the Hilbert space. They don't have to be of the same dimension, but in this case, we chose it to be of the same dimension so that you can ensure this sort of biotogenality. And you can actually make the motions that are invertible. You can do, I mean, they're very friendly and very flexible. Flexible. Okay, so we know now that we can actually write any state of this form, right? We know how to do it. And the question is: what are these things? What do they mean, right? And how do we came? So the first thing to notice is that if I take the trace over the path, I would like to recover the initial state of the system. Well, I get this expression. It tells me really that all the information about the system is stored in this PR file, about the reduced density of the system. And of course, if I were to take the, if I had a row. To take that, if I had a rho s cross of m situation, what I would find is that all these Fubi alphas are essentially the same rhogi, right? And just to say it's a consistent check, that would say. Now, what it gets interesting is that in the case of the factorizable condition, the statement is that there is a single CPT map that captures the dynamics of every initial state, let's say. That means, of course, that it is invariant and the action of the local actions of the system, right? Of the system, right? The key statement for these maps is that the same maps actually are capable of ruining the dynamics of your state or system out of the state, right? Have two operations from the system, which is exactly the perfectly equivalent statement. So the only thing is that what changes is, let's say, the coefficients in front of each of them. But in the end, the same for, in this case for acuity is four, the same for CD maps through the dynamics of every system at a state up to local. State up to local operations for the system. And so, moreover, you can also, each of these CPT maps can be characterized in the usual way. You can do process tomography, the usual scenario, right? You can even do noise spectroscopy. So, I can actually go and do, characterize these correlation functions relative to each of these guys. And we in the paper we show how to do it. And basically, what I'm trying to say is that I can verify or falsify whatever assumption I have over them. Experiment. And so there are also some cute connections, or interesting connections with the process tensor, with the steering, and particularly with the process tensor. We have been trying to sort of figure out how the two languages, so we know how they map in some senses, but in others, it's still unclear how one goes into the other. But it's an interesting direction and on forward. Nevertheless, now that I have introduced this, let me show you, okay, what how was a problem How was our problem progressed? So, the first thing to notice is that now I don't need a reverse crossover condition. So, the only thing that I need to know is how to propagate these correlation functions relative to each of the alphas. If someone, this very powerful person, would give me this information, I would do it. Of course, we still have the problem that demanding, and I know this for intermediate times, is kind of unphysical still, right? It's God-given power. And so, I don't want that. And so, the question. I don't want that. And so the question is: well, is there maybe a way to propagate this information by exploiting the scalable equation? And that's what I want to show you now. So the reality of things is that one can do many, so there are some of the typical equations, you say, well, if I want to calculate these PA's, which remember is the state of the system basically, then what I can do is propagate it from a previous time, PJ, right? And what I know now is that this, you can write it in many ways, but this is a particular form of writing them. It depends on. Form of writing them, it depends on the correlation functions relative to the state, to the substates of the bath, which I changed the patient a bit, relative to the term tj, right? And so that's great. But of course, then it means that I need to know this at time tj, right? So let's see, well, what I can go and say, well, actually, if I wanted to know what is this correlation function at time tj, I can go through the same process, and what I can show is that they actually are a functional, which is a well-defined, I mean, you can write it down, of the I mean, you can write it down of the correlation functions at the previous time tj minus 1. So, what you see is that you get a hierarchy of equations where essentially the mth correlator relative to the state at time tj can be related to the mth or larger correlators of the time relative to the state at time tj minus 1. And so, this is very similar to when we divide totalization, right? It's kind of a totalization in the open quantum system, though. I'm separating in times and I'm propagating the information. And I'm propagating the information, but not the full system bath, right? But the correlation information, actually, not that Hilbert space information, that's it. And so this is essentially what we exploit, right? And so the question is, how is this actually solving the problem, or how is this helping us? So let's do this very quickly exercise. So imagine that I want to predict, so to propagate the information from T1 to T2. So normally I would need all of these guys, all the correlation functions up to infinity, right? And so that is of course, of course. Infinity, right? And so that is, of course, the problem. And of course, the issue is that, moreover, there is finite information. I can only calculate so much for my initial coefficient function, or my computer even. I can only calculate so much, right? And so there is, let's say, let's demand that there is some sort of fixed knowledge that is limited to whatever number you have, right? And then also, it can also be that you're only interested in weak coupling. So if your time is if the interval is short enough, then you can actually say by saying, well, actually this guy will only be influenced. Will only be influenced heavily by the next, by the lowest order, or the one and two, let's say, of the next ordering correlation functions. And that is fine, right? The problem, of course, is that if you start trying to go forward, what you realize is that at some point, you will ask for information. You see that this point requires these three, but to update this, I need this tree, and for to update this, I need this tree, right? And eventually, I will start asking for information that I do not have. And so the problem is, how do I truncate this in a natural way, right? In a natural way, right? That is not maybe too determined. And so, what we came up with is this sort of controlled or generalized Born approximation. So, the Born approximation tells you that the state of, very roughly speaking, tells you that the state of the bath does not change. In reality, what matters for the qubit is not, or for the system, is not that the state of the bath doesn't change. It only cares that the correlation functions that that state of the bath induce does not change relative to the state of the bath. Does not change relative to the state of the bath. That is really what is important. And however, and then once you have that, then you can say, ah, wait a second, what if I said I don't want them all to be constant? I only want for all the four higher to be constant, let's say. So actually, there's limits, right? I can actually move this bar up and down to say how much I am updating about the path, right? So in that sense, it's a controlled board approximation. Of course, when I say that they are all constants, I go back to board. That's fine. And so, what this happens if I say that, okay, from a given point onward that are constant, then what happens is, of course, that you see, when I was trying to update this, I need these three arrows, from this I need these three, right? For this, I need these three, but to update this, because it's constant, I no longer need any more arrows, right? So effectively, I'm tracing, I'm saying that I don't need this information at time zero. So, and this is of course the most naive way of doing it. This is, of course, the most naive way of doing it. I can actually do it such a way that it's not a line, but maybe like a curve. But the important thing is that it's polynomial information. I can make it polynomial however. I mean, I can control it, right? This is the simplest and most naive one, where essentially the cost of taking more time steps is linear in my number of time steps. And so now that I have shown you this, let me show you some examples, right? Because this is the believe me. And so I'm going to do two things. The first one is I'm going to take I'm going to do two things. The first one is I'm going to take the Spin Boson model, right? The typical scenario, or in this case, I don't even have to specify that it's a Spin Boson. I need to specify that it's Gaussian. Because remember that we are focusing on the correlation functions. My only assumption now is that it's a Gaussian process. And that's it. Basically, what I'm saying is that the cumulant 2 of the math is some function, right? And any other cumulant, because it's zero mean, is zero. And that's it. And so I know that you can write an exact solution in this form, it's a well-known result. Solution in this form is a well-known result, right? Another rate, the other one I'm going to consider, is this case where essentially the path itself has no self-dynamics, right? And it's just a coupling that actually drives the evolution of the path. And so this is an example that actually we learned from one of the papers later, earlier. So anyway, so let's try to do a very simple metrony. Let's do Dyson. Of benchmarking. Let's do Dyson, a Dyson expansion. And so we know that a Dyson expansion, of course, is not exact for the Gaussian case. We will need a calcumal expansion to have an exact solution. And so I can, so this is a good toy model because I can do very easily calculate to order 4, 6, whatever, right? Or I can go very high if I wanted. And on the other hand, what I'm going to do is the simplest non-trivial thing, the simplest step beyond full one. I'm going to update only the first order correlation. Going to update only the first-order correlation of the value, right? And I want to see what happens, right? So if I do that, I compare the two, so I get this. So this is very messy, no, but what this is saying is that the red line is the exact solution, right? So the dotted lines are Dyson approximations. So when I say, so we copying Dyson, we copy in order two, right? It gives me this one, right? When I do other four, I get this. And finally, when I get order six in this time scale, I get very good agreement, I guess, with the exact solution. Exact solution. On the other hand, I do our approximation with weak coupling two only. But I'm keeping track of the update of the first order. And here, what I'm showing is that in the blue line is when I only update three times during this time. Then I update now six times, you know, and every 0.05 and every 0.001. And what you can see is that the more often I update, right, I actually start essentially tracking the exact solution extremely well. Extremely well. And so you can see, well, okay, so what? So it's perhaps a bit confusing here, but the question is: what is actually, what are you doing? So let's try to calculate the error and the expectation value, right, between the exact and let's say second order, exact and fourth Dyson, six order Dyson, and we've updated them. And what we see here is that even though this is that the orange line is our method, right? So it's actually outperforming the, I mean, the second order Dyson with coupling tool with no update, which is natural. Weak coupling two with no update, which is natural, but it's also performing the fourth order diaspora, which is weak coupling four, and we're just using weak coupling two. It's just that we are using information better, right? And so for me, this was very surprising, but I mean, we are very happy, of course. But this is just to tell you that, I mean, if you build as much as possible from the Scholaring equation, you can do much better. That's, I guess, the central advantage. And so we can also do, I mean, when we bring something like a Jimmy's Balancing for the Fonon For the funeral in an environment in a media example. And here, what we do is we compare, for instance, that here again, red is the exact solution. Nakadima Svansek is to order 4, but we are using order 4 in perturbation theory. And we are comparing the situation where we use, again, order 2 in perturbation theory, but we update up to the 4th order in correlation and up to the 7th order in correlation. And you see that, again, if I update up to the fourth order in correlation, I immediately say get a much better performance than I can. Get a much better performance than Akademus Bansik to the same order, actually, to the same high-ordering perturbation theory, but same seed information. And of course, if you up there to the seven, I get much better, I can actually track reasonably well, or much better, I guess, the exact solution. This is just to show that indeed one can track the mean and say the correlation function reasonably well for long times. Of longish. And of course, the more we update, essentially, if you, the message I guess is that if you want. The message, I guess, is that if you want to do better, you don't have to go in high-rot and recoupling, you just have to update more, right? Keep track of more information. That's the message. And so, these cards are reasonably that, almost done. And so I put this slide here for two reasons. The first one is that we want to also compare it to the speed boson, and to do that we need exact form, exact solution for the speed boson. And so, we're trying to do this calculation of trying to track the bath and trying to write an equation for the speed boson of the bath. An equation for the supposed bath. And it turns out that, and I don't know if this was known, but for us, I didn't know it. So, if someone knew about this result, please let me know because I'm planning on writing a paper and I'm not sure now if it's new or not. Anyway, the point being is that we know very well that for the spin motion, we can calculate the unitary exactly for the system path, right? I can calculate the reduced dynamics exactly, right? But then the question is, can I calculate exactly any system path operator? Any system bath operator. And moreover, what happens when the state is not thermal? So it turns out, so this is the expression for when the state is thermal, which actually tells us, for instance, that the mean relative to this thing actually changes in time dramatically. And not only that, but it actually becomes non-stationary even. And also, well, the Gaussian also, this is the second-order correlation that also changes. And not only that, you can show that at intermediate times, the state of the centennials, or part of the state of the path, for each of these beta-alphas. The path, which of these beta alphas are even non-Gaussian at that time, at that moment. And this is because the path is changing altogether, right? And so, anyway, so we can show that actually one can calculate exact things when the state is non-terminal. It is non-Gaussian actually. There is some trick to do it, but anyway, so you can do it exactly, which is, for me, was quite surprising. So, if anyone knows that this could be done earlier, I'll be happy to hear. Anyway, and so here this is just a plot. Of course, I should have plotted some Akabima. Course, I should have plotted some academics fancy here or not, but these are methods trying to compare. I mean, this exact solution is tracking just a very weak order two, weak order two. There's nothing super fancy here, updating up to order three. And we see that we can track reasonably well, right? Of course, there is no comparison. I should have in academia here. But we can show that we can track basically things reasonably well for some states. Others actually deviate as time goes on because my approximation is not perfect. And if I wanted to get better performance in time, I would just. And if I wanted to get better performance in time, I would just have to update more and more information about that. And so that brings me to the end of my talk. I guess my messages again are that really path correlators are what matters and what I can experimentally verify or falsify, that any open quantum system is really just a function of these initial correlation functions. That if we can actually use the Schrodinger equation to its maximum, we can actually propagate these correlations, which is again very fine. And which is again verifier information. And basically, that's saying that, I mean, hopefully, this is that if you use perturbation theory in a smart, smart way, then you cannot perform high-order perturbation theory that is basically in a more, let's say, straightforward or layer way. And something that I'm really looking forward to is this notion of can we combine this with these ACE type of methods like Eric was showing, that essentially rather than propagating the full path, right, I propose. In the full path, right, I provide just the correlation functions. And the screen equation gives me this correlation functions. It's just like, I mean, it's like a master equation, but just for functions, right? So it's small. So the cost is not exponential in the dimension. This polynomial is something. And my degree of accuracy is a high-order polynomial if I have a better degree of accuracy, if I want more accuracy, right? But it's like a control thing. It's again a matter of compressing as well. So this is all for me. Um hopefully there are some questions and There are some questions and yeah, nice talk because I suppose it's a fourth point. Just wanted to know the DNA connection. So there was a paper, like I said, two thousand and six by Lockheed Gamma and Moya and Gamma and Royer and others. And also, I recently did something on that in context of finite bars, where you can see that instead of tracing out the full bars, but you keep some limited amount of information about the bars, and you do like, say, the born approximation with respect to that, and you do second order there, then this is way more accurate than putting the standard trait over the bars, like a German fancy second in fourth order in higher audience. Basically the little idea is that perturbation theory with respect to an approximate state which much better approximates the true state than the naive system tensor, the Basin the Gibbs state forever. Is that similar to your? No, so so I guess in this case our reduced system we always trace out the bath in full. And you don't update the state of the bath in any way? We don't update the state of the bath in any way. No, but we update a correlation function that the state of the bath. So the state of the bath evolves, right? But we cannot keep track of the state of the valve in general. However, we only care about the correlation functions that the state of the valve uses in maturity. And those we can propagate by describing the equation in this. So rather than so the path yeah, so we only keep track so the notion of keeping relevant information about the path is just a correlation from the information. Is just a correlation problem. And the important thing is that the subtopy, I guess, is that there is not a single path state. It's not that reduced the length of the path by 100. That's right, I reduce density metrics of the path by taking trace of the system. At least these substrates are actually carry the fulling functions. Are there any questions from people online? Thank you for the very interesting talk. Could you please show once again how So, once again, how do you propagate path correlations? So, the crucial point of your method. Sorry, potential. Yeah, okay. So, let's look at this one, right? So, this is the propagation of the state, of the information of the state. This is Of the state. This is, if you want, I mean, what I have to do is just take the trace, right, or the project, the dual frame of this. And I can always write this evolution of the state, the density matrix at some S. I can always write it as the evolution from some time tj to s of the state, the system math state at time tj, right? And I mean, there's a trick to it, of course, I want to do the calculation, but the important thing is that, okay, so this is just, I mean, I. Okay, so this is just, I mean, I can do, let's say, a Dyson expansion or a cumulative expansion of this thing, and I will get a function, for example. However, when I try to say, well, can I propagate this correlator function, I can try to repeat the same trick, right? I write again my projector. The only difference is that I have now the live, let's say, bath operator. This bath operator is here. And again, I have this time expression. And what you can see here is that I have the unitary, right? I have this, which is essentially now playing the role. I have this, which is essentially now playing the role of my system, my system side of the system, or the state, sorry, weighted by these things here. And this is now the state of the bath, right? And the problem, of course, is that here I have this P alpha, B alpha, right? So that the simplest solution, right, is to just, let's say, you could expand each unitary, for example, in Dyson, right? And this expansion, and when you take this trace over the path, but this tells you that. Trace over the path, but this tells you that this trace here only depends on the correlation functions of the path operators that are embedded here in the unitary relative to this state. And of course, the full trace over the path here actually contains also this extraterrestrial, which of course then you say, well, from each of these guys, you have bath operators, but then you also have the presence of this guy. And so it's perhaps, I mean, if you do this trick, I mean, here is sort of a general idea, but you can. I mean, here is a general idea, but you can see the effect more concretely in this slide, right? Where actually I computed directly for the spin boson. So in this case, for example, if I go through the calculation for the mean, this is the mean relative to the state at time T1, right? So you see that it actually depends on the history of the control, sorry, of my correlation function up to the time T1. Up to the time T1, right? And then there is this integral here where the live bath operator is this BT1S, but then it depends on this sort of commutator, anti-commutator, depending on what this is, right, relative to the state of the system, of the battery, at time, in this case, at time zero, right? But you see that this is the, so that this evolution depends on this second-order correlation function, right? And similarly, if you were to do, for instance, for this time, for the second-order correlator, you have, ah, okay. For the second-order correlator, you have, ah, okay, I have the same as if I didn't have any evolution, but then I have these corrections, which, and this is, of course, clearly non-stationary anymore, right? Because this is not dependent on the difference, right, between actually S1 and S2. But of course, you see this is a product of the two correlation projects. And these are exactly right. But the trick is to use essentially your favorite expansion method. Here for the bosonic case, we can use the cumulative, which is perfect because it gives. We can use the cumulative, which is perfect because it gives us a close expression and allows us to get exact expressions, right? But if you have a general model, you can use Dyson or whatever you prefer, right? And that will give you this same sort of type of relationship where the correlation functions of order two depends on correlation functions of order two or higher. Thank you, thank you very much. In the interest of time, I'll suggest we take further questions to the coffee break. We'll start again in about 20 minutes at half past. That have asked. So let's thank Herrado and all the speakers again.