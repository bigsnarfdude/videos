So I'd like to report on an ongoing work with Samuel Lops and Isaac Opung. And we are discussing derivation of quantum algebra. So the quantum algebras I have in mind, they are not exactly the kind of quantum polymer algebras we've just seen. Or quantum nilipotent algebras for those who know already what they are. So I will redefine them. So I will redefine them. A special class of non-commutative polymer algebras with nice properties, I guess, and they include in particular things like quantum Schubert cells. And so our motivation for this work started with trying to find nice algebras that looks like viral algebras and test the Dixmere. And test the Dixmere conjecture on this kind of path of algebra. Now, of course, maybe I should not mention the Dixmere conjecture today because it was announced last week. So maybe it's not interesting to think about that anymore. But that was the main point. So how do we create this non-community, well, quantum analogues of bio algebra? Biogebras, I would use the following theorem of Dixmier. So you take N to be, or I will call it G plus an important finite-dimensional complex algebra. You can consider its enveloping algebra and take QB a primitive idea of this enveloping algebra. And then in that case, you always get as a quotient an algebra which is isomorphic to a vial algebra. To a Vial algebra. Okay. And the n here is something which is basically given by the Gelfand-Kiralov dimension of the quotient. Right. So we thought in this term, well, we know how to quantize this subject. Well, I don't know. I mean, I'm lying, certainly, because I don't know how to quantize any enveloping. Know how to quantize any enveloping algebra of any important algebra, but I know how to quantize some of them. And so we could look at their primitive quotient and see the kind of algebra we could get out of that. And here, well, it's a n-spy algebra. Do I need to define that? Is that a one? So A1 here is C of X. of xy takes a quotient by xy minus yx equals one and a n is just a one times a n times a one sorry okay and so in that case the the gel from kirioff dimension of of this thing is actually 2n so the n's reflect From G plus, well, you've got to formula appearing here. So it would be the dimension of this, the GK dimension, minus the height of your primitive idea. Okay. Right. So as a deformation of u of g plus, we can take Uq plus of G for G semi-simple. Okay, and so if you look at the curvative coefficient of this of these quantized enveloping algebras, then you should get something interesting. Now, these algebras are example of a wider class of algebras that we know of. So let me just say. So let me just say something like this, u q plus of G sits inside this class of protein sugar cells, which sits inside what are called QAs, and I should say or CGLs, CGL algebras, depending on how you want to. To well, the history of this, but it's exactly the same thing with two different names because we called them CGL extension at first, but then the name was not very good. So we thought, well, Milan Yakimov actually implied the name quantum limit potential algebras, which we favor nowadays. So maybe I should remind you what uniparameter. And QA's fort. So my algebra is an iterative extension of a base field. So I'll take something like this. Start with the base field K. Start with the basic K, any characteristic, and then add variables. N of them. And I'm requiring that all these sigmas are automorphism and the deltas are due derivation of the corresponding subalgebra. Subalgebra and to be a QA, to qualify as a QA, you need to satisfy a few properties. So with an action of a torus H or T, so I usually call them H, which is K star to the something. Such that. So you require a lot of funning. So So, you require the following. So, first of all, the automorphisms are not overly complicated. Sigma k is acting on xj by multiplication by a scalar. And of course, I want this color to be non-zero, to have an automorphism. But here, I want a uniparameter QA, a uniparameter QNA. So, I will ask that all those colors that appear are powers of the same non-root of unity. So, it's Q to the So it's q to the a j k x j or all j less than k where a i j k are scalars and q is not out of unity, not out of one. Okay, um I also ask that q derivation that appears in this uh entitlement. That appears in these iterated extensions are locally important. Okay, and finally, I mean, you won't see much of this at play in what I will show you today, but it's very important to have this condition. And then for all k, I can find an automorphism of my torus which extends. Which extends sigma k in such a way that if I make h k act on the next variable, so x k I get something which is u, and I would say bullet x k with bullet being non-zero. So, I don't need to specify what this is, only that this is non-zero. So, it's a nice definition. So, you probably have seen many examples of this. So, if you look at the skew polynomial algebra that we've seen yesterday. So, I usually tend to call them quantum affine spaces. So, I will probably just write that down. So, these are examples of these algebra. Any UQ plus of G is such a structure. Any UQW has such a structure. So, these are the quantum Schubert cells. Quantum shoulder itself. All right. So we have plenty of examples like this. And a lot have been done on these algebra. Usually you look for, well, people have looked, for instance, at the representation theory of this algebra, so the primitive ideas, and we know a partition of those. Usually we don't have an explicit description by generators for the primitive ideals. But in that case, for the UKW. But in that case, for the UQW, we have generating set for prime ideals which are invariant under the action of the torus. And I should say that all primes are completely prime in that context. So I'm not going to be bothered by the difference here. Right. So Gudol and Yakimov. I've worked quite a bit on these algebra, and one of the things that they did prove is that basically the They did prove is that basically the n that appears here. Well, you can take it maximal, the n is actually the cardinality of the number of i, such that delta i is actually zero. If I put curly brackets, that will be great. And I don't need to see okay. Okay. I will take them as an integer because this is all I need for these things, for instance. And I will be even more restrictive a bit later. Right, so we could look at primitive ideas in the Rhine-2 case. So R is. So, R is always a QA from norm, a uniparameter one. And I would like to tell you about what's going on in rank two. And I'm sure I should actually say UQ plus here of G. Of G. Okay, so just to give you an idea of the kind of algebras we are getting. So if you take G of type A2, then the kind of algebra you're getting for these quotients are either generalized by algebra. So if you don't know what they are, I'm not going to define them, but all you are, okay. All you okay all you need to know is that there are nice GK dimension two algebras and simple in that case or C. Or K, sorry, I wrote down my notes thinking my base speed is C with C being of any characteristic and not algebraically closed. Okay, right so. Right, so this case is obviously not interested if I want to get a deformation of a bi algebra, so I should focus on those guys. And I mean, I've just writing this down to make it kind of explicit that this algebra has a lot of invertible elements which are not in the base field. And that's quite good if you want to test, for instance, if endomorphism or automorphism, because you can make your endomorphism act on the group of units. Act on the group of units, and that puts some restriction on the form of your endomorphism. And it's not too complicated in that case to push that line to put that every endomorphism in an automorphism. So it's nice to obtain algebras which are kind of analog of the first by algebra. But if you want to get an idea of what they're not that close in some sense, too many invertible elements. Now, so we thought. So we thought, well, okay, let's go to the B2 case and work a bit harder. And then in that context, you get three isoclasses of interesting simple questions of GK two. Of GK2. And out of these three isoclasses, two of them are again of this type. So generalized by algebra over a long permearing. So again, plenty of units. And there is a third one, which does not have this property. And unfortunately, we can't decide whether endomorphism or automorphism because it's probably getting a bit too close to a very algebra. And so we can't do anything. Or I can't do anything. Or I can't do anything. So, in the G2 case, a similar phenomenon appears, except that you construct simple quotient of GK4. So you're kind of constructing analogs of the second variable algebra. And again, if you look in the right place, there is one isoclass that is very interesting and that does not have any non-trivial units. Non-trivial units. And again, we can't do much about this algebra, but it sounds like an interesting one. It's not being big. So with Isaac and Sam, we said, okay, if we can't actually decide what the automorphism group is, then maybe what we could do is see whether the infinitesimal symmetries are computable. That is the derivation. And that would be a first approximation to compute. First approximation to compute the kind of automorphism group of these cushions. So, in each case, for the interesting interesting questions, simple questions. We can prove. We could prove that the derivation are somehow what to expect. If you think of a viola, one of the first things Dix may prove, which is not completely trivial, is to prove that all its derivations are inner. And actually, we can prove that. So all derivations are inner. So I'm just talking about B. Derivations are in there. So I'm just talking about B2 and G2 for interesting quotients. So I'm not telling you what they are, I will, in a moment, in a general context. But basically, you're looking at primitive ideas that do not contain any homogeneous elements. And when I say homogenous, this is with respect to the attraction. Okay. Right. So that's where we are. And so the question is: can we compute this derivation? So This derivation, so we went back a step and said, Could we compute actually derivation of Q and A's? So, question Okay, so I should say for R. Say for R, you have a good idea of what you should expect, at least in some cases, because of Milian-Yakimov's rigidity theorem for the automorphism group. And that should, that inserts actually up to a finite group. So, automorphism group is just the torus. And so, you expect the infinity most similar symmetries to be basically Basically, inner division plus some well a free module over the center of rank the rank of your toys. Of course, you need to make that too. So, but indeed it works, at least under some assumptions. So, I will state a first theorem. Assume so the first one. So, the first of this condition is really important: that all normal elements are central. Okay, so remember, normal element just means that left IDs and right IDs coincide. Assume that each time you have such an element, it has to be in the center. So, that's quite a strong. So that's quite a strong assumption. And the second one is more to make things work in a beautiful way. None of the Xi is central. Otherwise, the result has to be slightly different because if I allow for this, I would allow for a polymer algebra, a commutative polymer algebra in one variable, and what I will say is obvious. The state is obviously false, but you can. Obviously, false, but you can make it work with a bit more work. And so, what is our result? So, then if you look compute the first homology group of your QNA, that is derivation module inner derivation, then this is a free module, is a free module over the center of rank. Oh, Frank. So, what is the toss? I said n, right? So, the maximum, so the number of skew derivation which I put to zero in my way I'm writing rather than as a Q ⁇ A. Right. So, that's the first result. And before I go to questions, so you should ask. So, you should ask me whether I know any example of QAs with these properties. That does not look easy. I can see that thinking, oh, it's an empty CRM. I can prove whatever my assumption is wrong, right? This happens at least for, I've not looked more than that, but examples. If you take G, simple. Of rank bigger than or equal to two, that's to ensure this condition is valid, and the value zero is minus identity, then it will ensure that the first condition is true. So, at least this is not an empty sum, it will be valid for this for uq plus. Then uq plus satisfies One and two. Okay, two is not really a problem. One is more of an issue. Okay, and then you should not expect this theorem to be valid when you don't assume the first condition, nor the second condition. Actually, well, maybe you can when I will give you a more precise statement. Certainly, if Certainly, if contra example when one is not true, well, you can take a specific quantum three-dimensional quantum math in space. Namely, if you take xy is qyx, yz is qzy, and zx. And Zx is Qxz. So this is a quantum affine space, so it's a QNA in a kind of trivial manner. So the theorem says it should be rank 3 over the center, and actually it's rank 4. So, probably you can't hope for more, or you have to understand a bit better. Or more, or you have to understand a bit better what's going on. Right. So before I tell you what happens for primitive quotients and which one are interesting, I think, I need to state a CRM of Buddhor and Yakimov. And let's see, I should probably be able to write it down here. Right. So I'm assuming that no modes are controlled. Okay, then starting with this presentation, they construct algorithmically a bunch of elements equal y. So I'm not going to give you the definition, I'm just going. Not going to give you the definition, I'm just going to give you the properties. But for those who are used to cluster algebras, what they're doing is actually construct an initial cluster for this algebra. So then there exists elements y1, yn in R, such that so a bunch of conditions. So first of all, if I look at the sub-algebra geetic by the white, this is a quantum of. By the wise, this is a quantum affine space. So I should say this is yiyj is q dij yjyi plus monomials in y are linearly independent. The center, and I mean, if you look at the SCRM, it's not stated in that under that assumption. So I'm taking full advantage of this to simplify a bit the SCRM in some sense. That's what we need. So the center of this algebra is a polynomial algebra in the y at the end of this list. Right, so I'm hoping that there are not many people who have read their paper carefully because otherwise they will know that I'm cheating a bit by putting them at the end, but otherwise it's the notation are a lot more cumbersome and that not really needed for this talk. Okay. Right. So three. So at the moment, I'm just saying there is a quantum motive space, and some of the indeterminates, the y's are central, but how does that relate to the algebra R? It relates in the following way. So any y1, y. One Y n minus n generates a NOI set in R and in R such that well it's not completely trivial but they prove that all the Y's actually individually they generate the multiple system generated by a Y is actually an ORS set and because they Q commute either generated Commute the integrative system generated by all of them will generate an OS set as well. And the point is that my quantum affine space generated by the Ys. So it certainly sits inside my regular R. Okay. And then inside this. Then inside this, I've got the localization of this R. So let me call it E, this multiplicative system. It sits inside the localization, but this localization is simpler. At the moment, I didn't win that much. But actually, I won a lot because this algebra, I can rewrite it as my quantum affine space. Space in which I invert all the y's that are in E. So it's clear that the y's are normal in my quantum affine space, so I can localize at those guys. Okay, so all this makes sense. And this algebra sits in the quantum torus associated to this quantum space I started with. So it's inside k cube of y1 plus or minus 1, yn plus or. Y n plus or minus one. Okay, right. So, why is that a good thing? This I want to compute derivations. So, at some point, I will need to control center. So, the idea would be start with a derivation of R, extend it to a derivation of these things. Can always do that. It's a derivation. And then, maybe I know what the derivations are in D. know what the derivations are in this algebra. That gives me a form for D as a derivation here, but it has to respect this sub-algebra. So maybe this will give me enough information that I can prove a form, a specific form for my derivation in this algebra and go back to R this way. Along the way, usually you describe your derivation when you view them as module over the center. Because if the center is changing, then Because if the center is changing, then that's a problem. And often, this idea I'm describing can't make it well, we can't make it work very well because the center is not under control. But this embedding are quite nice, and we control completely the center. So the center of the final shape R, so this is TQ, my control to us. I know what this is. This is exactly the Laurent polynomial ring generated by. Loren polymer ring generated by the y's that are central. So this is k of y n minus n plus 1 plus or minus 1 y n plus or minus 1. And every other algebra in this list have the same center, and this is the center of R. So Z AQ equals Z R. equals that R equals Z R E inverse and as a reminder this is just the polymer algebra in the y's that are central so I have a I have a full control on the of the center of all these algebras by doing this that's quite uh that's quite interesting when you want to compute derivations Want to compute derivations. Okay. Now I should be able to tell you a second result. So I'm still assuming that uh normals are central. Normals are central, and that none of the xi are central. And I can give you a bunch of primitive ideas which are actually maximal. So if I set u lambda to be generated by, so y n minus n plus one minus lambda one y Y n minus lambda n is maximal for all lambda in k star union. Okay, so if you're used to edge stratification, these are exactly the primitive ideas coming from the zero stratum, so not containing any homogeneous elements. Homogeneous elements. So it's not very complicated to prove in that case. And then you can look at the derivation of the quotients. And you can prove that h1 of the corresponding quotient is zero. So all derivations are inner. Right. Okay. So interestingly, when we do computation, so Interestingly, when we do computation, so we didn't check that in full generality, but when we did the computation in B two and G two, when you look at primitive ideas coming from other stratum, other strata, then you lose this property most of the time. Okay, so it's really the one for the zero stratum that seems to provide something which is close enough to the to the well, the vari algebra from the point of view of of the derivations, at least. Of the derivations, at least. Okay, so basically, the methods to prove CRM1 and 2 are roughly the same. So, I will stick to sketching the proof of CRM1 for much more for the next half an hour or so. So, I'd like to give you an idea of how we can pull that. I think this Underlying the proof, maybe this will not be apparent, is really the quantum cluster algebra structure of this algebra. Also, I should say, even with the assumption I'm keeping, I don't know whether a Q ⁇ A where normals are central is always a quantum cluster algebra because Milen and Ken Gooder did prove that you have a quantum cluster algebra structure only for A quantum crest algebra structure only for symmetric QNAs, and I'm not sure if normal being central implies that you have a symmetric structure on your QA. That's a different member. So sketch of COM1. Right, so I say the idea is to extend using this embedding here. So let D be a Um so let D be a derivation so you can see D as a derivation of this localization of course this R localized at E is still quite complicated unless I see it as a derivation of Aq E inverse. And what is this guy? Inverse. And what is this guy? This is just a quantum affine space in which I have localized some of the variables. So actually, I have localized exactly the variables that are not central, and everything that is central is left. And the non-central, the variables that are non-central, will actually generate a simple quantum torus in that case. Because if this was not simple, I will have an element which is central inside this smaller torus that will form. Smaller to us, but that would force a contradiction in forcing another variable to be central if I rewrite it in a different manner. So the first thing we did is to so we call that a semi-localized. It's not a quantum to us, it's not a quantum affine space, it's a semi-localized quantum affine space. And in that case, you can pull the following result. It's not a very difficult result to pull. So if you want to look at the derivation of this semi-localized space, then you got the inner derivation coming into the picture. Then we've got a derivation corresponding to any of the generators which is non-central. So I going from one to non-invertible, inverted, sorry. Z of, I should give myself some notation. So yeah, Z is will be the center of this algebra. The I plus plus a derivative. Plus, a derivation coming from each of the central variable, and this is Z partial J. So, what are this derivation? Where so di is a derivation that takes a y k to delta y k delta y delta. Y delta i k y k and torsion j of y k is delta j k y k. So the kind of normal derivation in a competitive Permian algebra here when you have a central derivation, when you have a central indeterminate, and when this is a proper quantum indeterminate, you have this Jackson derivative basically. This Jackson derivative basically coming into the picture. Okay, so how do you prove this? Well, it's already written here. You use this embedding there. Why? Because we know all the derivation of a quantum toss from a result of Osborne and Passman. And they prove that every derivation of quantum torus is inner plus a derivation that acts by on the variables by integration by the central elements. So it's not too far off being. So, it's not too far off being of this type, and then you work a bit by saying that your derivation has to stabilize this set. It's really not difficult at part. Okay, so at this stage, I can leave that here, at this stage we we start having a nice form. Form for this algebra for our derivation. So at this stage. So if I look at D, I know it inside on the Yi. It's a derivation, a linear derivation applied to Yi plus a beta alpha i Y i. Y i and an inner derivation plus beta i. So I need to tell you that it's if i is less than or equal to n minus n. Okay. So that's corresponding to y being a non-central indeterminate. And if i is correspond to a central indeterminate, we are in this case. So where so my x is So my X is not in the right place, it's in the algebra AE inverse, so in the semi-localized quantum affine space, and alpha i and beta i are in the center of this algebra. But we have already a nice thing here happening, and that's why we wanted to work with this intermediate step. With this intermediate step, it's because the center of this semi-localized quantum affine space is actually the same as the center of my algebra R. So that's where I dealt with the problem of the center changing through my chain of embedding. And so that's good because at least I've got elements which are in the right place here. Here. Okay. And now my problem is this x and making x into algebra R. So that's the difficult part to X is in R. Right, so how do we do this? So I need even more localization. Yeah. Oh, no. Sorry. Thanks. Yeah. Thanks. Yeah, thanks. That's just a normal derivation in a computer for immediate algebra. So yeah. Sorry, thanks. Right. So the idea is to is to, we won't prove directly that x is in R. We would put x, we know this is here, and on purpose I've left a bit of space here, because I will introduce some additional localization. Additional localization here. And I would put X in a bunch of this localization, but it will be in the intersection. And the magic of being a, so what I will say is probably not quite correct, but almost correct. The idea is that you got a quantum cluster algebra, which is actually an upper quantum cluster algebra. They coincide. In that case, if you're in all the kind of quantum toi. Quantum tori associated to your seeds, then the intersection is exactly your quantum cluster algebra. So I will put my x in all this kind of quantum tori and then intersect and that would be magically in the right place. So I think this is the idea. I don't think this is written like this in the quahead. We won't write it in this way, but I think this is really the feeling you should have for this kind of things. Right, so let's. So let's introduce this additional OS set. So for all k corresponding to one of the variables in the generating the multiplicative system E, then I will denote by E k this is the multiplicative system generated by Y one. Y1, YK is removed, Yn minus. So I'm taking exactly the same list as for E, except that I'm removing one of them. And again, this is an OS set. And just because Elena and Ken did prove that they generate each of them individually generates power set and the Q commit. So that means that. So that means that in between I have this R localized as EK. And the idea is to prove that first this X belongs to these guys, intersect, and the intersection is basically coming for free here, but this is R. Right. Okay, so note that the center of this new localization is completely under control because the center of R and of this localization are the same. And so this is the same as the center of R. So I'm not creating more problems for me by localizing. So what I would like to do to prove that X is in this localization is Is in this localization is I will construct an almost central element of this localization and use it to for my purpose. So let AK be the subalgebra of so I will use R at well of R R E inverse generated by, so that's where I should do it carefully, y i plus or minus one where one less than i different from k less than n minus n. Looking at the y that are not central, they're inverse, but I'm not picking up the case one, right? Why do I do that? Right, why do I do that? It's because, oh well, this is a quantum torus. All the wise Q commute and they are invertible. It's simple. Can't have a center, otherwise, you will have a central element in the center of your. Right, the center of your algebra R will be bigger. And of GK dimension, n minus n minus one. Okay, that's the number of y's I've left here. Right. So you start this number and you think, ooh, can I say something about it? Which is odd. No, why did I say simple? It's not simple, this one. Did I say simple? It's not simple, this one, which is odd. That's exactly the point. Um, so why is that odd? This thing, um, it's because if you look at the ideals that I call q lambda, okay, in theorem two, the height of this was L the GK dimension of R Was this number of variables to define this extension? So, this is capital N. And you've got a very slight formula for this algebra for this QNA. And this is telling you that the decay dimension of R over Q lambda is n minus n. It's n minus n. Right, good. But we also prove that in a QA, in a Nipparanometer QA, every primitive quotient has even dimension. Even as GK dimension of a primitive quotient. Of, I should say, uni parameter, but I will skip that of a QA. Right, it's a nice result you can prove using the notion of T-degree stable algebra from GEMS. Okay, so now we have an odd quantum toss, and an odd quantum toss always have a non-trivial central monomial. Okay, and because this is uniparameter. Because this is uniparameter, so you should take your matrix defining your relation. This is a skew symmetric matrix, and you can use the chemical form of any skew-symmetric matrix, integer matrix, to actually create your central monomial. So at this point, AQ, AK, sorry, as Sorry. Non-trivial central monomial. And I will call it Z. I could put it as ZK, but I said, but I don't want to introduce connotations. So it will be of the form Y1, let's say L1, YK. Y K L K I'm removing this Y n minus N L N minus L. Okay, so this is sample in AK. So this element, this element commutes with almost all of the generator of this algebra Re. It commutes, so it certainly lives in Re. In RE. It commutes with every Y I, which is different from K and less than N minus N. But it's also commuting with every, let's say, YJ, where J is bigger than N minus N. Why? Because this guy is thoughtful. Okay? So I'm not telling you anything. Paying anything. So if it was to commute with yk, then it would be in the center of my algebra R E, and so in the center of the algebra R. But the center of the algebra R is generated by this yj with j bigger than n minus n. So that would be a contradiction. So that means that Z does not commute. Do not does not commute with yk. Of course, if I look at this extension, that means that they q-commute because yk q-commute with any of the y's. Okay, so z, so let's see if I can make it the same old. The same order as in my notes, I can write it as q to the something ykz with bullet just being different from zero. So I've constructed an element which is not quite central, but almost central. So the idea now is to is to use this element to put x into the right place. Into the right place. Um, so where should I do that? Maybe, yeah. Okay. So let's move. Uh ah PK Right. So set PK, so this is a subalgebra created by the Yi, so such that one less than I different from K. From k less than n minus n union, I should do something like this, I guess. The yi, such that i is bigger than n minus n. Okay, so I'm taking this time the sub-algebra. Ak is slightly too small. I need to also add the commutative variable here. So it's not r ek, it's almost. Almost all I'm missing in this list are actually the powers of yk, which are still inverted, right? So, uh, so but it's a it's certainly a direct sum for m being z. So I can see this algebra as a BK module and with basis, it's a free module with basis yk to the n. So my x. So, my x, I can write it certainly as a sum of, let's see if I can try to stick to my notation, to the am yk to the m, where m is understood to be an integer here. Right. And now I will use this description. Why? Because what I know is that this part, because yi is in R. Because yi is in R, this is in R. And this part, because alpha i is in and yi are in R, this is in R. And this is in R as well, because this is in the center of R. So each time I know that add x on the yi is in R. Right. And what I want to do is apply dz, apply d to z, the element I've just To Z, the element I've just constructed for you, and what happens is that this is add x of z, I'm not saying much here, plus something which will be actually eta z, right? How do I know that this is where eta is in the center? Why is that the case? Because the y's. The case because the y's that are defined in my z are only smaller than n minus n. So I'm never involving those guys in the monument defining z. So I know this will be of this type. And so d of z to the i, it's add x z to the i, which is add x of z. When you have I got the I minus one, I guess, plus eta i z i, I guess, something like that. Right, I think my notes are not quite correct, but that's okay. Right, so now it's good because It's good because we can actually take advantage of this. So plug X, the expression of X here. All of this will be in R. Okay, so I want to say this is in R. So multiplying by the inverse of Z minus even if this is a negative power, this will not be a problem because Z actually lives, it does not involve Y. Lives, does not involve yk, so it lives in the algebra R localized at BK. And so this takes me to add x z to the i belongs to R B inverse. Right, so there's no magic here. I'm just using the fact that Z does not use YK, so it's invertible basically, and push everything, everything else is in R, so no problem there. So, no problems there. Right. Um, so if you write down what this is, this is a sum. So, let's say m going from minus one to minus d of am 1 minus q bullet, where bullet has been defined earlier, I n y k to the n z i and this belongs to this algebra, but the z i is This algebra, but the zi is not a problem, as I said. So this says these things belong to our in k inverse. Let's call them, give them a name and rewrite that as a as a system as a metric system. And you can rewrite that as one minus q bullet, one minus q du bullet, one minus q. Why my SQ deliberately minus one y k inverse a minus d y k minus d So chi 1 minus d is equal to chi one chi d. Okay, so you just rewrite everything as a system. And now you're very happy because this is a matrix which is equivalent to a van der Monde matrix. So this is invertible. So this means I can express all of these things, all of these terms, as linear combination of the chi i. Combination of the chi i, but the chi i belongs to this localization, so it means that all of these terms will belong to this localization, okay? So that means that the problematic term, that is the one where you have a negative exponent, will actually fall into this localization. And everything that has a positive exponent for yk was already in the right place. So because of this, Because of it, you get a very good deal. Okay. So you're happy with that? Because it's not exactly what I promised you. I promised you that R will be, X will be in R, and actually it belongs to the intersection for k going from one to n minus n of this localization. Actually, you can pull. Actually, you can prove. So, when R is the symmetric QA, you can use a property that Milen and Nken have proved. You have unique intercept, basically. If you don't have this symmetric property, you have to work a bit harder to prove that, but you can still prove that the intersection is reduced to R. All right. So, okay. So, okay, So add x is a derivation of R and remember we had D which was add x and when we apply it to yi we knew that this was so I've forgotten which notation I've used so alpha i y i if i I if I is smaller than or equal to this core ang, and it's equal to beta i if i is bigger than the core rank, where the alpha i and beta i are in the center of r. All right, so but now this is the derivation of my algebra R, okay, because I proved that x is in r and d is the derivation of r. So, this is the derivation of r on which. Of R on which I have a good control on how it's operating on the Ys. Okay, and the Y's generate by quantum affine space, it sits in R. So then you do sit down and try to think about how you can control what's going on for the axes. So that's where I'm going to say you probably look to enter into gory details because you need to understand really. Because you need to understand really the relationship between the y's and the x's and play with the explicit construction. But what you can prove is that, so we control the action action of D on my eye and then one show one can show. I mean, this is highly technical, so this part I'm not going to really discuss, but you have a group of homomorphism from where, so I will call it eta from Z to the N. So N is still the number of derivations which are zero in my Q ⁇ A into the center of my algebra R such that such that D minus the inner derivation is actually of any element A which is H invariant, which is an H eigenvector. So E is equal to eta acting on the H weight of A times A. Times A. So my derivation becomes homogeneous. Okay, and you do that step by step for a QA. You basically iterate on the number of steps you have to define your Q ⁇ A. So you can iterate on capital N to do that. Okay, so then you win. That's exactly what I promised you because this is free of dimensions rank and you can produce great division. You have great division, and maybe as a corollary of this result, maybe I should state that explicitly. So, if you assume G is simple, rank of G bigger than or equal to two, and you assume that W0 is minus one, then is given by this formula. And actually you can actually describe the derivation here forming a basis for the Russian energy by saying each time you have one less than i less than i one less than i less than n. So if you know the definition of this algebra, they are generated by n generators E1, En corresponding to the simple roots of your algebra UQ plus of your Lie algebra G and subject to the quantum seration. And on these generators, this algebra, this derivation acts by multiplication. Well, act like this, as you expect. So, there's no surprises in some sense. We don't know if this is true, if you can hope for it to be true in the general setting. I mean, if you look at, we looked at a few SLM case, and you can still get this type of results. But of course, the method we used don't apply here. Okay, and maybe I should just finish with a slight remark. With a slight remark, maybe this was not completely all connected to what has been discussed so far, but I will use James' strategy freely and say, of course, we know that there are Poisson version of that. I was hoping to actually present the Poisson version of these results, but I've not finished writing down the details. So that's why it's only the quantum setting I've been able to present. It was supposed to be a more of a Poisson talk. All right. Poison talk. All right, thank you very much.