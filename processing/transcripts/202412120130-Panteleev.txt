Today's tutorial, so I'm gonna tell you first about classical ODPC codes, and then so I will try to explain our construction of asymptotically good quantum ODPC code. But in my view, in order to understand it completely, first of all, we need to understand how classical ODPC codes are usually constructed. Are usually constructed. And so let us start with the standard definition of a linear code. So linear code is just a set of bit strings that satisfy some parity check matrix, yes, and so some system of linear equations. And so we have the standard parameters of the code, like the lengths, the number of bits, yes, like the dimension, the number of useful. The number of useful bits that we can use in this code, and the minimal distance. And this minimum distance controls the reliability of the code. And so we can represent this code geometrically as these bit strings in some metric space. And this metric is just the number of positions, different positions in two bit strings. Different positions in two bit strings. And so we have a standard problem in coding theory that is usually called dense packing problem when we need to put as much as possible points, code words here, but at the same time, we should have as much as possible distance. And so it means that these two parameters, so it's So it it's impossible to achieve the best possible parameters simultaneously, but so we need to always find some compromise here. And this classical error correction was initially introduced by Claude Shannon, as I think most of you are very well familiar with this picture. Yes, when we have some data, we send it first win call. We send it first. We encode it, then we send it through the channel with noise, we decode it, and finally we get it at the destination. And so for classical codes, so there are basically two types of codes, algebraic codes, like old school codes, Heming codes, Reed Muller codes, PCH codes, Reed-Solomon codes, and the modern codes. And the modern codes that started with the revolution with the introduction of turbo codes and rediscovery of LDPC codes and then polar codes followed. And so let us talk about classical DPC codes because LDPC codes is the main topic of my today presentation. So they were initially described by Robert Gallagher in Described by Robert Gallagher in the 60s, and then they were rediscovered. And what are low-density parity check codes? These are linear codes with very sparse parity check matrices. And by sparse, I mean that just the number of non-zero elements in this parity check matrix grows linearly with the number of bits in our code world. So it means that, so we can represent, we usually represent LDPC codes using special graph. It is called Talar graph. So and in this graph, so for each check, for each equation, so we have a special node, and for each bit, we also have a special node, and we connect a check with a bit if this bit participates in this check. And so we have a standard decoding algorithm. Standard decoding algorithm for classical DPC code that is called belief propagation, and the idea of this algorithm is quite simple. So, when we have some message, yes, for example, we miss some bits. And so, we consider this parity check matrix, this set of equations as kind of Sudoku. And we try to solve this Sudoku. Yes, and what a simple strategy to solve a Sudokooko. A simple str strategy to solve a Sudoku. When we have, for example, when we already know all the numbers, for example, in some line, yes, except maybe one, then we can reduce it. And we use exactly the same idea here. Yes, when we have some check where we know all the numbers except maybe the one that is missing, so we can deduce it from this check. Check. And so we, of course, this is a little bit simplification because, in reality, so we also used probability distributions, but this is actually the main idea of this algorithm. And what is known about classical DPC codes? It was already shown by Gallagher in the 60s that there are good families. So, by good, I mean that the number of The number of useful bits, so the dimension of the codes and the minimum distance, they both grow linearly with the code size, with the code length. And there are also some explicit constructions. The most important one is the Sipser-Spielman construction that is based on earlier work of Michael Tanner. Okay, so. Okay, so but in order to describe the practical DPC codes that are used in real applications, so I need to introduce the notion of a lift of a graph. So I assume that everyone is familiar with the notion of a graph. So for example, we have a graph and to each edge of the graph we assign some permutation. So we have some set F and we have a permutation and have a permutation and and for each for every edge we assign some permutation um and using this uh assignment so we um can construct a new uh larger graph which is usually called a fold cover of the original base graph and it is constructed in the following manner so we connect so we we um we have a replicas We have replicas of each node, of each vertex, and of each edge, and we connect them using the following pattern. So we use this permutation and we connect these clouds of vertices using this permutation. And maybe it is easier to understand this by looking at the example. So here I show you the example of a graph, and this is a And this is a graph of some code. And by using these operations on tanner graphs, we can also apply this operation to codes. So here we have a graph and we assign a permutation. And these permutations are very simple. So our group is a group of three elements, and these permutations are just shifts. And so you can see that, for example, here we have zero shift, and which means that zero can. And which means that zero connects to zero, one connects to one, and two connects to two. And for example, here we have shift one, yes, and here you can see that we have a cyclic shift by one position. And there is also a very important way to describe this code algebraically. So in this case, so we encode each these three Each these three bits as an element of the ring, and in this case, this ring is just a ring of polynomials, and so we encode each chunk of data by this polynomial, and we also encode the parity check matrix by this polynomial. So, this way, so we can describe such codes in a very compact way, and here, by the way, so we And here, by the way, so we can, of course, from this representation, we can go again to the binary representation, which will have L times more, three times more rows and three times more columns. Okay. And so, why are these lifts important in classical codes? Because the usual way The usual way to obtain practically good ODPC code is just to start from some small base graph, which is usually called protograph. And then what we usually do in practice, so we perform some special procedure that estimates, that predicts the performance of this graph when it will be lifted. So we have two-step process. We have two-step procedure. Yes, so we want to obtain a large code, but in order to get a large code, we start with a small code. And this small code contains information about this large code. And by analyzing this small base graph, so we can predict the performance of this large code if we run it on a standard belief propagation decoder. And so this second step, lifting power. Step lifting part. So, it is also done with some special algorithms that try to construct this lifted graph. So, it has as small as it tries to minimize the number of cycles in this graph. And so, in the very final step, we just simulate several candidates and choose what works the best. And so, in here, I can show you some. Can show you some very practical LDPC codes, the codes that I actually use in 5G standards. So, as you can see, here we have two base graphs, and so I represent this base graph by the corresponding parity check matrices. And so, 5G standard has a lot of different codes, it's several thousands of codes, and all these codes. These codes are obtained just from these two very small codes. Yes, and it is done, so we have this flexibility because we can lift these codes using different sizes of lift. Yes, we can lift it two times, three times, ten times, 100 times, and each time we obtain a code of different lengths. But what is really But what is really important? So, why these lifted codes are used everywhere in the classical of DPC area? Because first of all, I already mentioned that we can estimate the performance of the large code. This is very important. Another very important property is that we obtain an infinite number of codes just from one code. And what is really important. Code and what is really important that this sequence of code that has some rate that is low bounded by some number, in particular, the rate of this base code. Yes, because when we lift, yes, we just increase the number of bits and the number of checks. But the rate of the code is at least as good as it was. As good as it was for the base code. And this is very important because it solves the problem of constructing codes where the dimension grows linearly. And another very important problem of these lifted codes is that they allow parallel processing. And I believe, so it's very important for classical codes, but I believe it is even. But I believe it is even much more will be much more important for quantum codes because what do I mean by parallel processing? I mean that if you look at the syndromes, then you can see that almost all the syndromes in one group, and these groups in practical codes are really large, for example, 100. And all these syndromes are independent. So they, if we look at them, yes, so they the beats. Yes, so the bits that participate in them are independent and there are no intersections, which means that we can process and calculate the syndromes. Yes, we can calculate the checks in parallel, which means that all the algorithms can be run in parallel. And this is one of the main advantages of, for example, DPC codes over other codes like polar codes. But in quantum settings, I But in quantum settings, I believe this is also very important because it allows you in parallel measure the syndromes using quantum circuit. Okay, but how we can construct good classical DPC codes using L-lifts? In fact, there is such a construction, and one of the construction was already proposed in the original paper of Gallagher, but here I consider a little bit more. Here, I can see the little bit more simple idea. So, we start just from a complete biparted graph, for example, the one that's shown here. And then in this complete biparted graph, so we just choose random permutations, random permutations on L elements, and we use this random permutations in order to obtain L times larger lift of this graph. And what is known is that. And what is known is that on average, so almost every such random code will have a linear distance. And of course, the rate of this sequence, of course, is also grows linearly. So the rate is at least one-third. So in this case, so we obtain asymptotically good family of codes. So it's very simple. And another example, unfortunately, this example. Example, unfortunately, this example is not explicit. Yes, so we use some randomness. But there is also a very explicit way to obtain it using so-called Zamer code. So Zammer codes is a slight variation of Sipster-Spielman Expander code. And so if you are interested, what is the difference? So I encourage you to read this lecture written by Spielman when he describes what's the difference. Yes, what's The difference, yes, what's what's the Zammer codes? Um, and so these are exactly the codes that we used in two hour papers on lifted product codes. And so that is why I want to describe it. So, but in order to describe it, so first I need to describe what do I mean by tenor code. So, tenor code is a way to construct LDPC. Is a way to construct LDPC codes out of a graph, but it's a little bit different from just so it's the same guy tenor that is responsible to the native tenor graph, but this tenor code is a little bit different and I will explain it in a minute. So the idea is as follows. So given a graph, so we assign bits to edges and we also assign some small local codes. Some small local codes to every vertex. And in fact, we usually assign the same local code. So we can see the regular graph, so it has the same degree, or vertices has the same degree, and we assign the same local codes to each vertex. And then, so what is the code word? The code word is the assignment of the bits to the edges that satisfy all the constraints. All these constraints. All these constraints for all the vertices. So, in fact, we can also represent this as a standard of the PC codes using this parity check matrix as shown here. Okay, and but in order to construct a good tenor code, so we also need this notion of expansion. And here I can see the some variant of this. Um variant of this notion that is called small set expansion. So, what is small set expansion? So, given a deregular graph, a small set expander, so it is called a small set expander if for any sufficiently small set of vertices, almost all edges go outside. And so, by almost all, I mean that, for example, we can fix epsilon. Can fix epsilon like 0.01. So it means that 99% of all the edges that go, yes, they go outside of this set. And if it happens for all sufficiently small sets, then this graph is called small set expander. And in fact, there are many known good small set expanders. For example, the famous Romanujan graphs, this is a special graph that has This is a special graph that has some very good spectral properties. Okay, and what are the Zemmer codes? So, Zemmer codes is just a tanner code defined by on a special graph that is called double cover of a Kelly graph. And so, this graph is constructed in a very simple way. So, first, it's a biparted graph. So, we have two parts. Two parts and each part can be identified with a group. And we also have some small set, some generator set for this group. And we connect each vertex G with vertex G S I and we do it for all generators. And so it means that it's W regular graph. Yes, and what is interesting is that this code can also be represented. Also, can be represented using this idea of the lift. Yes, and so we can represent it. So, it's in fact it's the lifted code, and it can be represented by the metrics shown here. So, it's so maybe it is easier to see it on example. So, for example, in the case of a cyclic group, so we have that this ring is isomorphic. Isomorphic to this polynomial ring. Yes, and for example, if our local code is a Heming code, then the Zemmer code has the following parity check matrix. And so I want to emphasize that this matrix, it's a polynomial matrix. Yes, so each element here is a polynomial. And of course, we can then convert back again this polynomial matrix into binary matrix. Yes, in the same way that. Binary metrics, yes, in the same way that I showed before. Okay, but now let us switch to quantum LDPC codes. So, what are quantum LDPC codes? So, as far as I understand, I was told that there are many specialists here in quantum information theory, and so I expect that you know something about quantum and particularly the definition of a CSS code. So, but let me just briefly remark. Just briefly reminded. So the quantum CSS code is represented by two classical codes, CX and CZ. Each code is responsible for correcting X and Z errors, poly errors. And so here I use Q, but I always assume that Q is equal to 2. So it's just a bit. So, it's just a bit, yes? So, we do not consider non-binary alphabets here. And so, in order to be a correct quantum code, so we need this condition that can be represented in the following form. So, it just means that every row of matrix HX is orthogonal to every row of matrix HZ. And so we. And so we can also express this idea in terms of these codes. Yes, so HX is a parity check matrix of CX and HZ each parity check matrix of CZ. And we can equally represent this condition in this way. And we also have some parameters of this code, and they are very similar. And they are very similar how we define it for linear codes. Yes, so we have a dimension, so it's just a dimension of this quotient space. So, since we have this condition, so we can consider quotients, yes? So, this, if you're familiar with stabilizers, yes, so this is some stabilizers, stabilizer group, and so it's some Z stabilizers, yes, but here. Isaacs, yes, but but here, uh, so this is some degenerate errors. So, so this set is usually called the set of degenerate errors, and this is the set of all errors. And we define the dimension in the following way, and we also define the distance in the following way. And it is very helpful to consider this quantum CSS code as a kind of quotient code. What do I mean? Quotient code. What do I mean by quotient code? By quotient code, I mean that our code words now are cosets, and the distance between two different code words is just the distance, the minimal distance between the elements of the coset. Okay, and of course, as you know, these quantum LDPC codes are expected to be used in fault-tolerant quantum computers, and they are also. They are also very connected to what is called chain complex. So, chain complex is just some sequence of linear maps with some special property. And here, so I showed you examples of chain complex with two terms, yes, and chain complex with three terms. And we have in the chain complex, we have this condition, which is exactly equivalent to this condition of the CSS code. To this condition of the CSS code. So, in different terms, so we can just say that quantum LDPC codes is just a chain complex with any chain complex with three terms can be identified with the CSS code. So, it's exactly the same. And how people usually construct this quantum ODPC code. So, the standard approach is just to take some topological space, find it, find some Find some finite cellulation for this topological space and obtain a chain complex using this topological space. And then we can convert this chain complex into the quantum LDPC codes in a natural way. And an example of this is very well known. So it's a famous Kitaif Torik code. Yes. So here we start with the simulation of a Taurus. By the way, the distance. By the way, the distance here has a very natural representation, yes, as a C-stall, the smallest non-contractable loop. And so we convert this code into this sequence. So here we have the space linear combination of faces, linear combination of edges, and linear combination of vertices. For example, this face. This face, so we send it. So, this operator sends it to linear combination of the edges connected to this face. And for each edge is, so we send it, so this separator send it to linear to a zoom of the vertices connected to this edge. And so, one can easily check that if we apply. That if we apply this operator, so we obtain zero. So it's a valid quantum code. And here I show you the tenor graph of this code. Okay, but in order to obtain, so unfortunately, so this code doesn't have very good parameters. It can be shown that it has, so it's. That it has, so its dimension is only two, and its distance grows just like square root of n, where n is the length of the code. And that's not enough. And so, people for many years have tried to find some better ways. And one of these ways is the hypergraph product code. So, what is a hypergraph product code? But before we describe the hypergraph product code, I would Product code, I would like to first show you what is just classical product code. So, classical product code is a very, very simple construction. So, we start from two linear codes, and then when we apply this tensor product to them, so we obtain a new code that consists of all the matrices, and each column of this matrix is a code word from the A code word from the code A, and each so each column and each row is an element of the code B. So this is shown, this condition is shown here. So it's a very, very simple code. And we can also, if we choose parity check matrices A and B for these two codes, so we can also describe it in a very compact way here. Yes, so it's the set of matrices W. It's the set of matrices W that if we multiply W from the left by matrix A, we should obtain zero. Because when we multiply from the left, it means that we just apply this A linear transform to each column. And when we multiply from the right, so it means that we apply this B linear map to each row. And if we obtain here zero and here zero, so it Here zero and here zero, so it means that all syndromes for this check and these checks are equal to zero. And this is exactly the same definition as above. So what is known about this product code? They're very predictable. Yes, so we so we have this very beautiful formula for their parameters. So we just need to multiply all these numbers. Hypergraph protocols are a little bit less predictable, but still a very Less predictable, but still are very, very nice. And the idea here is to start essentially. So we use the same code as before, yes, but here, so we start from the standard classical Tensor Product Code and we describe these two operators that calculate syndromes. So I showed it here. So when you So, when we apply this matrix A, multiply by matrix A, we obtain a new matrix. And then when we multiply by matrix B, we obtain this matrix. And how we check that this is a code word. So we check that this is equal to zero and this is equal to zero. So this is exactly the same condition. But what is really important here that we see that these syndromes, they are not, they are dependent. So there are dependencies between them. Are dependencies between them, and we can easily see what are the dependences. So we can multiply this syndrome V by B. Yes? And we can multiply this syndrome U by A. And as you can see, we obtain exactly the same, which means that there are some dependencies between U and V. And this allows us to construct a quantum code in a very simple way. So, how we do this? So, we construct the following chain complex. So, this complex sends W to these two syndromes. Yes, and Yes, and it sends this U and V to the sum of these elements. Yes, so we apply matrix A and B and we just calculate their sum as it is shown here. And as you can check, yes, since we have this condition, so if we apply this map to times, yes, and we obtain zero, we obtain zero just because of that. Obtain zero just because of that, which means that this is a chain complex. So we constructed a chain complex. And using this chain complex, so we can get a quantum code because as I showed before, quantum codes just can be constructed from any chain complex. So, here, how we describe this CSS code. So, here, above, I showed you the You the code that contains all X errors. And here below, I show you the degenerate errors. Yes. And so the errors, so this is a code word and this is a degenerate code words. So the code words are defined by this condition. Yes. And the degenerate ones are defined by this condition. So they are just generated when They are just generated when we multiply by matrix A and B. And in fact, it is much more convenient to consider not this product, not of matrix A and B, but the product of matrix A and B transpose, because in that case, this picture is much, much More simple, much simpler. And so, in this case, we have a very, very simple equation that describes this hypergraph product code. And what is known about these codes? It is known that if we use, if we combine the codes that have distance d, then the resulted quantum code. The resulted quantum code also has a distance d. But unfortunately, since our length is equal approximately to the square of the length of the code, so this D is just the square root of n. So in terms of the distance, so we almost exactly, we have almost exactly the same distance as for a kitaev Tori code, but in terms of the Um number of um information bits qubits in in terms of the dimension, so we have a dimension that grows linearly, which is really nice. Okay, and so the natural question, can we generalize this hypergraph product codes to get codes with much better parameters? And the answer is yes. And here I will present you one of possible ways how to do it. One of the possible ways how to do it, and there are other ways, for example, twisted product codes and balanced product codes, which are very similar, and in fact, they are all more or less the same in the most general cases. So, here the idea is as follows. So, we start, so if you remember, yes, in classical codes, we constructed from small codes, large codes. Small codes, large codes. And these large codes can be represented by the parity check matrix, where instead of bits, yes, elements were elements of the ring. And here the idea was as follows. Okay, if we have this representation, but maybe we can also apply this idea of the lift to quantum codes and why it is could be beneficial because. Could be beneficial because so classical codes we can easily uh we can easily um leave them, yes, but for quantum codes we cannot just arbitrarily assign these shifts because we need to so we need to make sure that we obtain a correct quantum LDPC code. Yes, and um but if we can do it then we are very lucky because we immediately get We immediately get codes that have linear dimensions, so dimensions that grow linearly, because just because when we leave the code, yes, we just increase by L times qubits, X checks, and Z checks, which means that the dimension also grows linearly. So we already solved this problem. And we also possibly get the distance and this. Distance and this is because, just by analogy with classical codes, yes, for classical codes, you saw that if we use some kind of random lifts, then we obtain something similar to random code. And it basically usually has a distance that grows with the lift size. And maybe it also happens here. And in fact, it is. It is indeed indeed happens here. And so. And so, the answer to this question: how to do it, is just to apply this idea of the product code, but instead of field, make the standard product of a ring that we discussed before. So, the idea is as follows. So, we start from the two matrices, and these matrices are now. Now they do not consist of bits, they consist of elements of the ring. And we obtain the analog of this classical code, classical product code. But here, instead of bits, yes, our elements are just blocks of bits that represent the element of the ring. And so our matrices, our elements, they are all. Our elements, they are all consist of these ring elements. Yes, but the definition is exactly the same. So it's exactly hypergraph product code, just like non-binary hypergraph product code. Yes, we just replace bits with these elements of the ring. That's all. And in fact, as it turns out, that's all you need. That's all you need because it is possible to construct the code. Construct the codes. For the classical codes, it is very easy to show that this generalization has optimal parameters. Yes? I don't have enough time to prove this, but the proof is very, very, very simple. So if you look at it, think about it for a couple of minutes, I'm sure you will deduce it. But for quantum codes, But for quantum codes, the situation is much, much more complex. So, unfortunately, if we try to construct a kind of hypergraph product code, yes, using this idea, then we also get some interesting code, but its parameters are not very well understood and controlled as for hypergraph product code. So, unfortunately, we do not have this very good formula for. Very good formula for the minimal distances we have for hypergraph product codes. But anyway, so we can still try and try to construct this code that has optimal parameters. And in fact, it is possible. And so before I move on, let me just give an example of a special case of this lifted product codes. In the case when our matrices A and B, Case when our matrices A and B are just one by one matrices. So these are matrices that consist of just one element. So this is a very, very simple, special case. In this case, our equations are very similar. So here A and B are just one element. So this is just the set of ring elements. Yes, that satisfy this condition. So this is our code words, and this is our degenerate code words. Works and it turns out that this idea, first of all, it's not a new idea. So, this is something that was known for quite a long time. First, it was invented by Ha and then Kovalev-Britko proposed a very general scheme that describes such codes. And also, there is a not very well-known paper by Hastings, where he introduced so-called left-right codes. So-called left-right codes, and these left-right codes, they, if we try to construct the tanner graph for them, then we obtain what people now call left-right complex. So in some sense, Hastings invented left-right Kelly complex almost 10 years ago, but nobody noticed. No, nobody noticed that because his findings was not published and it only appeared in 2018, as far as I understand. So, but anyway, so this is a special case of this lifted product code. And there are also very interesting cases of this code construction. If we use one plus X and one plus Y, then we Why then we and if our group is just a product of two cyclic groups, then we get toric code, exactly the same toric code that I showed before. But when we applied it to a product of three cyclic groups, so we get a three-dimensional code. Yes, so the group here controls the dimension. And this is a famous Haag 3D code. And we also can obtain Uh, we also can obtain other codes that were studied in the literature, for example, this quasi-cyclic generalized bicycle codes that we used to beat the surface code, and also the famous bivariate bicycle codes that were used in IBM's paper recently. Yes. And they have very interesting properties. For example, you can do transversal edge gates. Can do transversal edge gates with them. And it applies not only to bivariate bicycle codes, it applies to all possible, so to all left-right high-slings code. But now let me switch to the construction of asymptotically good code. So here, so we apply this idea of Zammer codes that I mentioned before. So we first proposed them in 2020 when in the paper then When in the paper, then where we introduced lifted product codes. But in that paper, so we used not exactly these codes, so we generalized them and used some the generalized version that allowed also it was also possible to use not only non-abelian groups but also abelian groups. And so here, so we start from And so here, so we start from these Zamer codes. And so I already showed and explained it to you before, what are they? And here, so we just apply this lifted product construction to two matrices. And each matrix has the following form. So we just apply it to two such matrices. So first matrix is just standard matrix, and the second matrix is transposed. What is important here is that this local. Important here that these local codes, yes, like for example, like here, Heming code, they should be different. And this is turns out a very, very important property. And they should be not just different, but they should be very, very specifically chosen. And the reason for this is related with a very advanced topic that unfortunately I don't have enough time right now to explain in full detail, that is called high-dimensional. Full detail that is called high-dimensional expanders. And so, in fact, you can try to construct, so in a naive way, just to try to replicate the standard hypergraph product construction. Yes, just multiply code by its transposed version, and it already gets very good codes. But quite strangely, in the case of lifted product. In the case of lifted protocols, this idea completely fails. So, you get so, using this idea, you get only codes where the distance do not grow at all. And this is really weird. And this also can be generalized to balance product code, and it can be used to show a counterexample to the conjecture by Conjecture by Bruckman and Eberhard about Bevan's product code. And okay, so but let me explain how we can get linear distance. So the idea here so we first proposed it in the paper after the breakthrough paper by Hastings and O'Donnell that showed that it is possible to break the square root by Possible to break the square root barrier. And they also introduced a lot of very interesting things. So they proposed some construction that works with arbitrarily non-abelian codes. But the problem with that idea was that it wasn't symmetric. And so our idea of lifted product codes was symmetric because it allowed you to obtain constant rate codes. And in our paper, we already showed that it is possible to obtain constant rate codes. To obtain constant rate codes, and I already showed you before that it is very simple. Yes, when you leave the code, you just multiply the number of checks and the number of qubits, and you immediately get constant rate. And but the second idea, yes, what's the condition of this we should impose on these local codes? It was so we borrowed it from the another paper. So this is there were two papers that were. There were two papers that were not very noticed because they also provided some kind of breakthrough, but it wasn't so much. So they constructed codes that a little bit more than has distance a little bit more than square root of n. But in fact, they constructed something much more powerful because they propose a way how to construct codes with linear distance. And so it was so, in order to find So, in order to find this, you need to very deeply read this paper. But in reality, the result was amazing because this is exactly what allowed us eventually to construct codes with linear distance. So, we use the idea of high-dimensional expanders, and so we apply it to our constructions that are based on Zemmer codes. And it turns out, It turns out, so using this idea from this paper about boundary expansion, so we managed to find the right property of these codes that gives you the linear distance. And as you probably know, so after we published our paper, there were a lot of some other works that also constructed using similar ideas. So, for example, similar ideas so for example the famous there's a famous paper by levier and zemor that showed that if we just truncate our lifted product codes or remove some unwanted qubits from this in some smart way so you obtain a very beautiful construction called quantum tunder codes and it is much more so people and I personally People and I personally like it significantly more than our construction, so because it's very intuitive, and so you can easily prove things about this. And there were also some follow-up paper that also studied one of the versions that we also mentioned, briefly mentioned in our paper that could also possibly give a linear distance. Linear distance, so they considered this version. So instead of transpose, yes, so we remove this transpose sign, but actually it is almost the same code. And it turns out that you can also construct asymptotically good code in this way. And as far as I know, so currently, maybe I'm not sure I know all the possible. I know all the possible constructions. These are all the constructions currently that exist that we have proof that we obtain the distance. And so here, let me briefly describe this idea of this property. So unfortunately, I don't have a lot of time to describe it in detail, but To describe it in detail, but the idea, so I hope I can explain it in more detail in my next talk that is planned later. Yes, so maybe I will have more time to explain it in more detail. But the idea here is just to generalize the notion of boundary expansion. So, caboundary expansion of a graph, what is a caboundary expansion of a graph? If you have a graph, yes. If you have a graph, yes. So we already saw this with edge expansion. So we have some sets of vertices and we calculate the edges connected to them. And the size, so we calculate the size of the edges connected to them. And we have good expansion if we have a lot of edges that go outside. Outside. And so we can generalize this idea to product codes because product codes can also be understood. And this was first noticed by Tanner, that product codes can be understood as Tanner codes on biparted graph and full biparted graph. So how we can understand it. So we have two. Understand it. So we have two parts, yes. And so we have edges. So every vertex from this part is connected to every vertex from this part. And so here it's so it's not the same size as shown here. So it's here we should have sorry. Here we should have five vertices and here we should have four vertices. Have four vertices. And so if we try to apply the standard definition of boundary expansion from graph theory, and if we take into account these codes in a smart way, so we obtain exactly the definition of this property that I mentioned before. And this definition, in some way, it plays the role of the minimum distance. Okay. Okay, maybe so I can proceed to open problem. So, right now, maybe the main unsolved problem in this area is whether we can also construct a four-dimensional analog of this of the current construction of good QDPC code. So, all current construction is like a product of two codes. It's like a product of two codes, yes. But maybe so we can take a product of four codes, or maybe not a product of four codes, uh, something similar to a product of four codes. So eventually what we need, we need to have a chain complex with five terms. And if we can construct a complex with exactly with the same properties that we have for current For current constructions of good pure DPC codes, then we can construct so-called quantum locally testable codes. So, this is a quantum LDPC code that has very nice properties that so we can so for X checks and for Z checks, or if we can see that these codes, then these codes are locally testable. And by locally testable, I mean that so we can. So, we can easily find the distance to the code by looking at the number of unsatisfied checks. Yes, if we know the number of unsatisfied checks, so we approximately know the distance to the code. And so if this code and this code, yes, code that defined by matrix HX and matrix HZ, if they both are locally testable, then this is called a quantum locally testable code. Locally testable code. And this is why this was interesting. So initially, the idea was that you can prove an LTS conjecture, but now an LTS conjecture is proven using the existing GutQL DPC codes. But still, I think it's an interesting theoretical problem. But first of all, it is p also possible to construct a linear distance decoder, a very simple linear distance decoder. Simple linear distance decoder for QOTC codes. And also, an open problem that I want to mention is efficient decoding of general QODPC codes for circuit-based model. As far as I know, this is still open. And another problem, how we do gates. Yes, of course, we have these codes with very good parameters, but we still don't know how to How to do any gates on these codes. And another problem that is kind of different, but I think it's maybe related, is whether we can use similar ideas, maybe not the same codes, but some similar ideas that were invented during these constructions to construct passive error corrections with QDPC codes. And by this, I And by this, I mean, of course, in three dimensions. And so I think that's all.