See a slight simulation in the models here. We're going to have a fewer compartments than we've seen in the last couple of talks. Secondly, so I'm a statistician by training, so although I work a lot in disease models, I'm usually thinking about the data and how we extract information from the data. That's going to be the focus of this talk, which will be in sort of two halves. The first half will talk really about the Bayesian part before we get on to the behavior. The Bayesian part before we get onto the behavioural change. And I will point out that Madeline's talk sort of follows from this afterwards as well when we mention some of this work. Okay, so I can rush through this because basically the model I have is a discrete time stochastic SIR model. So everybody in this room understands that. I'll just point out I'm going to use I star T to represent the instance, new cases at a given time point, and R star T. time point and R star T to represent the number of newly removed individuals at a given time point and then being that this is discrete time we've got a series of difference equations and stochasticity comes in in the usual way which is we'll assume that the new set of infectious individuals comes from a binomial distribution as does the new set The new set of removed individuals, and then my force of infection is going to be the usual one. Okay, so that's our basic setup. And obviously, if we simulate from a stochastic model, there's 500 epidemic curves there you can see generally. Now, when we're thinking about we've observed the data and we want to fit the model to that, we tend to think about this in a Bayesian framework for a number of Framework for a number of reasons, some of which I'm going to focus on. I know many of you will be familiar with the Bayesian framework. For those of you who aren't, I'll talk a little bit about it and point out some of the reasons why we use it. So the basic idea behind a Bayesian analysis is that anything you're uncertain about, you want to measure with or capture that uncertainty and that knowledge that you have with a probability distribution. So that extends to the parameters. Extends to the parameters. So we're going to be interested in the parameters given the data, and then we have a distribution there, and we can feed through our uncertainty about the parameters into things like forecasts. We can also go further than that by including things like uncertainty we have about the data or the structure of the model. And all of these different layers can be fed through one probability distribution feature. Probability distribution feeding into another. Skip over that. And the basic idea is you start off with a prior distribution for your parameters, theta, characterizing your belief about those parameters. You update that with your data through the likelihood, and then that gives you the posterior, which is the probability associated with the parameter, conditional on the data. Then we're going to use MCMC or something similar. MCMC or something similar to generate samples from that lost area in order to estimate. Right, so why do we do it this way? So there are two sort of, well, there are a bunch of, I'm going to say religious, but more conceptual reasons we would like to be amazing. But there are some practical reasons as well. So the first thing that I want to emphasise is obviously that epidemic data is often incomplete. We don't generally Incomplete. We don't generally observe infection times, we don't generally observe removal times, so we have some uncertainty there about what the true data we would like to see actually. And in the Bayesian framework, the fact that the parameters are random variables, as well as the data being realizations from the random variables, means we can sort of treat those things as being the same. So, where we have missing So, where we have missing data, I can think about the joint posterior of the parameters and that missing data, and then condition on what I have observed, which might be reporting times. Now, in this case, what we're actually going to be doing here is I'm going to think about the model parameters, and obviously I just have two because it's an SIR model. I'm going to assume that I know the infection times. I'll base those on the case reporting date. Those on the case reporting dates. I don't have to do that, I could put those over here as well. But here I'm going to condition on those and assume that they're true. But I'll estimate the removal times, which obviously in this context means the number of removals at each time point. So I'm assuming that these are essentially things to be estimated. Now, that of course leads to a complex over-specified model because I'm trying to estimate some of the data as well as the parameters. Estimates a lot of data as well as the parameters. But then the other side of the Bayesian framework is the prior knowledge, right? Which we often have when we're dealing with a disease system. We often have information about the infectious period, whatever it is. So we can set a prior on the parameters that we're interested in that incorporates that knowledge, but also allows for some uncertainty. So this sort of compensates to some degree to the added complexity. To the added complexity I'm putting in there. Now, anyone who's done this, this is called data augmentation. Anyone who's done this knows that it can be a little bit cumbersome to implement. But I'll just illustrate sort of some of the advantages that can come from doing this. So, this is going to be a different model. I want you to imagine now a model, an individual-level model, where the disease can essentially pass. Where the disease can essentially pass through a network. And what I've got down here, the top line here, is showing the probability of being infected at a given time point depending on the number of infectious contacts you have. So if you've got five infectious contacts at a given time point, under this setting, you've got about a 65% chance of being infected at a given time point. Now, if I try to fit this model, Try to fit this model to data that's generated and my infection times are known correctly. What I've got under there is the estimate of the network effect from fitting that model using MCMC. And you can see we do really well. If we start introducing some noise, and that's what's happening as we go down here, so this M is basically representing the noise that we're putting on. Noise that we're putting on, in this case, the infection times. You see, by the time we get to the bottom one, we're really underestimating the effect of that network. The probability of being infected at a given time point now has gone down to 0.2 when it should be 0.65. Now, actually, the reason that's happening here is because I've actually, in the fitted model, I've got another mechanism allowing for importation, so random sparks. So, random sparks. But once you mess up the infection times, the data suggests that it's really disease coming in from outside, right, which isn't the case here. Now, if I do the data augmentation, which is more computationally cumbersome, you can see, and these are just the posterior means, and that's for the lowest amount of noise I just showed you and the highest amount. We're certainly doing much, much better and much nearer to the truth. Nearer to the truth, right? We can really take the signal out about the effect of this network much better. And if I put the credible intervals on here, which I hadn't, they're actually containing the true line there. So that's a slight illustration of why we might want to do this and go to this extra layer of complication of doing the data augmentation. Okay, so let's go back to my essay. Okay, so let's go back to my SIR model. This is the likelihood, we don't really need this. I'm going to put the prior on my two parameters, and then I'm going to think about some real data. So, this is, there's no announcement to this, but this is the second part of the channel. So, let's look at these COVID cases. So, this is from Calgary. You can see the different peaks, there's Omicron there. Now, everyone in this room will be aware. Room will be aware that we get inflections in these curves basically because the population behaviour has changed. The epidemic got going here, we had severe lockdowns, the epidemic died. Obviously, that doesn't happen in the SIR. The inflection that occurs here is because we have depletion of susceptibles. So, and obviously that happens in all sorts of. And obviously, that happens in all sorts of diseases. It happens in very severe diseases, but it can happen in seasonal influenza, right? In a severe season, people tend to take more care, washing their hands, or get vaccinated. And it also happens in agriculture and ecology, because humans are getting involved essentially because there's disease in the system. So how do we model this? Well, the usual way, I suppose, is This? Well, the usual way, I suppose, is by using some sort of covariate. So if we know that a government intervention, a lockdown measure is coming in at a certain time point, we can introduce a step function in our transmissibility, and that's often what we'll do. In COVID, we had a wealth of things like mobility data, the stringency index, things like vaccination intake, and obviously we can put those in our model. But often we don't have those things, right? Depending on the disease system that we're trying to model. And even in COVID, we don't have those things in the future. If you want to make a forecast, you have to make some sort of guess about how the population behaviour is going to change. And so, what I was wondering and had been wondering for some time was, and this Was, and this isn't new, right? How we can model that using just the case data that we see. So we sat down a couple of years ago and thought about a very simple model framework that we could introduce. And we came up with this idea of, well, once again, it's not new, of an alarm function. And we're going to bound this alarm function on 0, 1. And the way I'm going to define this. And the way I'm going to define this is: I'm going to say that if the alarm function A is 0, I'm assuming my population is behaving in its natural state. If the alarm function is 1, then I'm going to assume the population is in such an alarm state that infection is not occurring anymore. Okay. And then the alarm function itself, well, that's going to be a function of. Well, that's going to be a function of a recent event in history. It could be a function of prevalence, could be averaged prevalence over some window model or something. And then you can introduce it into the force of infection just by multiplying it by 1 minus a. And obviously you get the SIR model, that's 0. You get no infection at all if that equals to 1. Okay, so then there's the question of what form should that LARM function take? What form should that alarm function take? And there's various parametric forms you could use. So, an obvious thing to think about is a sort of change point or a threshold alarm where the alarm, you've got on the x-axis here, some measure of disease prevalence or incidence. And as that goes up, the population remains unalarmed, and suddenly the alarm kicks in. So, this might mimic lockdown. Might mimic a lockdown measure at the beginning, that sort of thing. Or we can have something smoother. So, a very simple example is this power alarm here, so just one parameter, whereas as the proportion of population newly infected is what we've used here, the alarm goes up, and obviously that will bring down the transmission rate. Or, and what I'm going to talk about, ah, so you said the alarm goes up, but you also said the alarm goes. Alarm goes up, but you also said the alarm is either on or off. So, in this case, if you the alarm will click on, but in this case, yeah, the alarm will rise continuously. Thank you. But then the other thing, and this was where, so I forgot now to introduce my collaborators at the beginning. This is a collaboration with Alex Schmidt at McGill, who is an expert in non-parametrics and spatial modelling. And spatial modeling. So we wondered: how strong can you get away with making no real strong assumptions about that Lamb function? Can we use something like a polynomial spa line or a Gaussian process? If you don't know anything about these things, they're basically smooth but very flexible functions. Something that could look like this, you wouldn't expect an alarm function to look like this. This is a regression plot. A regression plot, but something with a lot of flexibility. All right, I'm going to skip over the shiny apple. So the way we implemented this, we used a package or language, if you like, called Nimble, which is implemented in R. It's a Bayesian modelling language. The syntax is based on the older Bugs JAGS framework. JAGS framework. So it's nice in that there's lots of examples on the internet fitting different models using this language. But the other thing about Nimble that bugs and jags don't have is, well, one, it's a compiled language, so it compiles your MCMC into C. So it tends to be quite quick. But the other thing that's really nice is that you can go under the hood and change things. So we actually have. Right, so we actually have to do this for the data augmentation because you can get some complexities when you're updating the number of removals and that you could have situations where in your MCMC proposal you end up with more removals than there are infected individuals, right? You get a non-symmetry to the updates. So you can go into Nimble and change your sampler to make it more effective. Sampler to make it more effective. You can actually go in and, well, Nate's not here, but you can implement particle filtering or particle MCMC, all sorts of stuff. We found it really nice for this problem. All right. So, oh, and I should say, I'll give you a reference to the paper at the end. All the code that we used to do all of this is available from the GitHub rep repository, which you can get from Repository which you can get from the paper. So, I'll show you what the some simulation results before we look at some real data. So, up here I've got three different parametric alarm functions and I'm going to use these to simulate epidemics. Okay, so you can see down here, typical epidemics under these alarm functions. As the epidemic takes off, the alarm kicks in, brings down the force of infection. Kicks in, brings down the force of infection. Eventually, you reach a point where the alarms come down enough that the epidemic gets going again. So you can get these oscillatory effects or you can get a slow decay, depending on the parameter settings here. But the threshold, at least for this one, you see a much bigger drop-off. You can actually get some really slightly strange dynamics as the alarm switches on and off. So probably something like. On and off. So, probably something like the threshold might be good for modelling, say, the beginning of a wave when lockdown measures are brought in or whatever. Maybe not so much in the longer term. And then the Hill function here, which is just a more flexible growth curve with three parameters rather than one. At least for these settings, you see sort of similar dynamics. Now, what we're going to do is we're going to take this data actually, for these. Actually, for these results, we'll take about half of the data, in fact, exactly half of the data that's been simulated, fit the model to this half using a spline or a Gaussian process, and then look at how good our forecasts are for the rest of the epidemic. So, here I'll show you results for cubic splines where we have two knots. So, there's not a particularly flexible cubic spline, but as you'll see. Cubic spine, but as you'll see, it works pretty well. And then a Gaussian process with a squared exponential covariance function. Right, so first we can see how well we estimate the alarm function itself. So the thick line here is showing you the true alarm function. We've got the spline results up here, the Gaussian process results up here, and they're actually quite. Results up here, and they're actually quite similar. So, both the power and the hill, we tend to estimate the alarm function pretty well. Remember what we're doing here, right? We're just using the case numbers, we're estimating the removal times essentially, and we're getting the behavioural dynamics as well as the the epidemic parameters, the epidemic model parameters. The epidemic model parameters. So we're extracting quite a lot of information from the data there. I will point out, of course, that both the Spline and the Gaussian process struggle a bit with the threshold because the threshold is not smooth, but they still do reason. Then if we look at the forecasting, so first off, if we just fit the SIR model to that epidemic or one of the Um, that epidemic, or one of those epidemics I just showed you. So, this row up here is for the true alarm being the power alarm. You can see the SIR doesn't understand why this inflection is occurring, so it does the best it can, which is essentially a line through the middle that we don't see, projects on from there, and it's obviously a terrible forecast. If we fit the true model, as you'd expect, we do pretty well, but we also do very well if we use the spline or the Gaussian process. Spline or the Gaussian process. And you can see that this carries on with the threshold alarm. Yeah, we don't quite pick up those weird spikes we were seeing, which we wouldn't see. But we're still doing a reasonable job at getting those. And then with the Hill Alarm, which is a bit more flexible, once again we we do much better with with any of the uh behavioural trend models. Behavioural change models. Alright. So the other thing we can do, of course, is look at the real data. See what these alarm functions look like for something we have a reasonable understanding on. Well, COVID inspired this work, but also is the obvious place to go. So here we've looked at a number of cities in different countries. This is work that we did from New York City, and I'll just And I'll just show you the results from the spline alarm. And the alarm function here is going to be informed by the average incidence over 30 days. So we found quite a large window works quite well. We took the first, whatever that is, the first 18 months and divided it arbitrarily into three peaks. So you can see the Omicron here. Four peaks, sorry. And then fitted And then fitted the model to each those formats. And then, if we look at the alarm functions that we estimate, and I haven't got the results here, we get reasonable estimates for the beta and gamma, the texture period and the transmissibility as well. You can see that the alarm functions are sort of what we would expect, right? In the first peak, we get something approximating that threshold alarm when the restrictions came in. When the restrictions came in, and they were very well adhered to. In peaks two and three, things are much slower, but of course, we're starting from a very different baseline because many of us were already living in our basements by the start of the second, third peak. And then in Omicron, well, this looks a little similar, unless you notice that the x-axis is completely different. The alarm is going up much, much more slowly in Omicron, which is also important. And then we've got the reproductive numbers down here make some sense, but I think I will ask those. The other thing you can do is to use information criteria. The DIC is one that's used a lot in Bayesia modelling. NIMBL actually uses something called the WAIC, which I think stands for wine. AIC, which I think stands for widely applicable information criteria. But it's a similar idea: the lower it is, the better the fit, and it compensates, sorry, it penalizes for complexity. We can see that with the spline alarm, we're doing much better than the standard SIR model. And you can also, I haven't got the results here, but you can use this to choose between the different alarm functions reasonably well as well. Meanwhile, as well. Alright, so some future directions. One of these Madeline's going to talk about in a minute. So there's lots of things we can do with these alarm functions. So as I said earlier, there are covariates available, certainly for COVID but other diseases. We can incorporate those into the model. We haven't really done very much of this yet, but I would be very interested to see, for example, Interested to see, for example, if we put the mobility data into the alarm function, does the disease prevalence part capture some other behaviour that the mobility doesn't have? Does having both of those things improve our fit? You can also have multivariable alarms, so we've been doing some work on that, where the alarm doesn't just depend on, say, the number of cases, but it could depend separately on hospitalisations. Separately on hospitalizations and deaths. The early results suggest that if you put two of those things in the model, it improves the fit noticeably, and it doesn't matter which two. If you put all three in, it doesn't really help. But they are very primitive, so it's changed by now. Madeline's going to talk about time-varying alarms. So one thing people have talked a lot about is lockdown. A lot about is you know lockdown fatigue, the fact that maybe we adhere less to restrictions over time. So we can look at that sort of thing. And you can have things like spatial heterogeneity. Is what's going on in your local area more important than what's going on globally that you're seeing on the news, etc., etc. And then there are things like so that incidence. Well, one, should we use incidence or prevalence? And two, what size window should we use? And two, what size window should we use? So far, we've just taken an ad hoc approach, chosen a window that seems to do reasonably well. You can incorporate that into the model and try to estimate that to improve the fit. Then, of course, this is implemented in an SIR model. You can do it in more complex models. So, we've done it in spatial versions, individual-level models. Level models with a spatial focus that seems to work quite well. We've done it with models where you have, like for COVID, you've got asymptomatic cases, that also seems to work quite well. And then there are things like metapopulation models, all sorts of things we might want to look at. And then another thing, and you know, the work that's going on with the data pool. Going on with the data portal might feed very much into this is to look at historical diseases. So if we go back and analyze these different diseases over time, what do we see happening with these alarm functions? It would both validate that the alarm functions telling us something sensible and hopefully something interesting about those diseases. We have applied this to Ebola and you see at And you see a sort of threshold thing that you would expect. We've applied this to foot and mouth disease in facial context and picked up some weak behavioural change there. All right, and then just to finish off, so now I'll go back and introduce my collaborators, which I should have done at the beginning. So, most of this work was done by Caitlin Ward, who was a Caitlin Ward, who was a postdoc of mine and Alex's. She's now at the University of Minnesota in the Biostats Department. All the work I've presented here is in a paper in infectious disease modelling. Madeleine, there's no relation to Caitlin as far as we're all aware. Her work on spatial models was, well, there's a preprint available and hopefully that will be in the Canadian Journal of Statistics soon. Soon. And like I say, the code for Caitlin's work is available from the GitHub repository. I don't think our code for this paper is up yet, is it? It will be. And this wasn't coded in Nimble. This was coded in Julia because this stuff's a little bit more computationally intensive than the population level. Okay, and that's it. Thanks very much. That's it. Thanks very much.