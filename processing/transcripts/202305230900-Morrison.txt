Uh so in this our extra log today we have our board logs pay close attention. And our first talk is Scott Morrison and Chaga looking so good. Great, yeah. So before I get started, I just want to very quickly advertise something that's not at all about my talk. If anyone wants to play with Segredo, which is this neat little thing that hooks up GPT-4 and Lean and has them. Hooks up TPT-4 and Lean and has them talk to each other. Please come and just ask me, and you can play on my computer with it. I don't know, you write a statement, you write Bisagredo, and it talks back and forth. We're not going to do that now, though. Okay. So let me kill that. Keep it running. Well, I'm worried what that'll do to my computer. Okay. So So let's see. A few things to say first. My apologies that this is in Mathlib 3 rather than Mathlib 4. I feel dirty. The reason I'm giving this particular talk is I saw Adam post on Zulup, I don't know, a week or so ago, about this neat little definition of singular homology, just chaining a few functors together. And he pointed out that this was really close to being ready in Mathem 4. So I spent, I was kind of thinking, oh, let's get all these into Mathem 4. And so that went on Friday. 4, and so that went on Friday it was time to think, I really should write a talk. That's what I've been thinking about, so I wrote a talk about what we can do with that. But then, of course, it's still in Mathlin 3. Okay, so we're going to talk about singular homology and some things we can do with it. You can probably guess, just from the list of imports, what we're going to do with it. It's a good exercise. But let me first of all note that Brendan, I think right after my talk, is going to give a talk where he actually proves stuff using this definition. Where he actually proves stuff using this definition, whereas I'm just going to throw a whole lot of sorries at you, which I think is really appropriate given that we're in Canada. And so you should think of this less as me trying to show you some cool new maths that we've just got done in lean because everything's got a sorry in it here. Everything's got a sorry in it here. This is more just to sort of intended as sort of exploring what we can, the boundary of what we can't quite do at the moment to give you a sense of where some parts of the interaction of the homology libraries and the monodal categories libraries are at the moment. Also, given that there's so many sorries here, and this file is a branch on MATLAB, Heather just posted a link to the branch, so if you need to follow along. Posted a link to the branch. So if you need to follow along or want to go back a slide or something, just check out Tuesday underscore 9 a.m. and this file I think is called oh it's actually called Tuesday underscore 9 a.m. There you go. Contrary to what I had a header post. Sorry. And in particular, there are 87 sorries in this file right now. And I'd be overjoyed if at 10 a.m. There's a different number because one of you guys who stopped and got bored with my talk and either filled And got bored with my talk and either filled in a sorry or done the usual thing with sorry exactly. I'll be even more excited if there are more sorries than they started with, because of course that's a sign that someone has taken a big, difficult sorry and broken it down into a few smaller sorries and that that still counts as progress. Great, okay, yeah, let's look at some code. Is that how are people with font size? Can you make it one bigger? Can you make it one bigger? Let's try one bigger. Okay. Thanks. Okay. Yeah. So our starting. I don't know if there is a Tuesday 9am file. Okay, maybe on the branch it's still called Kunath and I renamed it locally on my computer. Sorry, okay. Yeah, maybe look for Kunerf. It will certainly be under roadmap slash something slash either Kunath or Tuesday 98. Okay, so the beginning So, the beginning is just this functor that we already have that gives us the functor from topological spaces to simplicial sets, which just does, it's just the usual thing. I mean, it sends a topological space to the functor that sends a simplex to the maps of that simplex into the topological space. We could click through and read the definition, but it's something very unatary because people wanted to define it in a way that you've got some adjunctions for free or something like that. Some adjunctions for free or something like that. But it's just the usual thing. Okay, so we start building up from that. And so the next thing that I want to do is this one. We'll pick some ring R, and we're going to build a functor from topological spaces now to simplicial modules rather than simplicial sets. And all that we're doing is taking that functor to simplicial sets and then composing it with the free module functor. So it just takes formal linear. Just take formal linear combinations of those simplicities. And you can see this is defined in terms of something, I mean, the definition is something whiskering, because of course sequential objects are just functors, and all we're doing is composing with the second functor. Okay, so then we get to singular chains, and again, we're just composing our functor to simplicial modules with the alternating face map complex, which is a bit of a mouthful. Which is a bit of a mouthful. And that just does the usual thing. It produces a chain complex indexed by the natural numbers. The chain groups are modules. They're just the values of our simplicial module on the different n simplices, and the morphisms of the alternating sums in the usual way. And then you get to the definition of singular homology, which I've written in a slightly complicated way. You might think that at this point I've constructed the singular chains, I should just apply the homology functions. Singular chains, I should just apply the homology functions after that, but I'm going to do something a little bit weird. I take the singular chains and then I drop down to the homotopy category from the chain complex category down to the homotopy category. And then out of that, I use the homology functor as defined on the homotopy category. Now, that seems completely pointless because these two, these, this, this functor here is sort of defined as the factorization of the normal homology functor through this guy, but later on there'll be a definitional equality that will. There'll be a definitional equality that will work nicely because we directly passed through there. Not sure it's essential, but it seemed useful when I tried to write this. Any questions so far about that? Okay. Okay, so obviously we should try and compute examples. And so the first thing that came to mind was RP2. And I've abjectly failed to compute any homology groups of RP2. Fail to compute any homology groups of RP2 on this slide. So here's your first sorry of the day. Great, okay, thanks. Yeah, obviously, so we have the definition of a projective space just with these hypotheses, a division ring and a module, but we don't have a topological space instance. Obviously, there needs to be more instances there before you're. Topology on chaos. Yeah. Well, and I mean, RNA's the. And I mean, R needs a smaller change in front. Yeah. Okay. So Heather will add some instances and we'll go to topological space. And then if we've got that instance around, we can just define RP2 as an object of the category of topological spaces. Just in the usual way we deal with concrete categories in MATLAB, we have one of these functions, top.of, which takes the type, which must have the relevant type classes. Which must have the relevant type classes and just bundles them up into the bundled object in top. Is that not RP1? Oh. Oh, damn it. Okay, well, it doesn't matter. They're all sorries anyway. Which one am I actually trying to do? I'm trying to do the homology groups that I've written down there are for RP2. Yes, they're for RP2. So let's quickly change that. Don't worry, nothing in the file breaks as a result of RP. Don't worry, nothing in the file breaks as a result of change or anything like that. Yeah, is that more plausible now? That's a music thing, yeah. Okay, okay. Okay, so the point of this talk is not to try and do these computations. They'd be interesting to do and and some of them are easier than others. Some of them are easier than others. Someone wrote up, has written Maya Viatorus on the board already. So, okay. Let's pretend, though, that we know how to do things like that and press on a little bit. What I want to do is these sort of calculations here, calculations of homology of a product. So, we're going to talk about a Kunot formula. So, since homology was a Was a functor. We're going to want to work sort of functorially here. So I'm just going to put a monoidal category instance on top, which is just, of course, the Clartesian product of things. So you can see, I guess that's the key definition there. Tensor on objects is just the topological space on the product of the underlying types. But one shouldn't really write the definition this way. There's a comment telling you: don't fill in those sorries. Telling you, don't fill in those sorries, just work out how to write that, and it'll all come for free. And it's a symmetric category as well, but okay. And so this is really what we want to try and do. We want to do these sorts of calculations, the homology groups of these products, taking as assumptions those earlier sorries for the individual homology groups. Sorry, it's a question about elaborate kind of material, but why do you need P unit to be? Why do you need p unit to be unit plus one? Yeah, exactly. So we just, yeah, we just need to have everything line up there. Possibly you can just drop the dot u and it works it out. I'm not sure. Yeah, so less confusing if you don't have to look at it. Okay. So, okay. Okay, so let's go on and just completely fake the Kunneth formula for the product. So, what we're going to, so we want to have this little short exact sequence that computes the homology of the product. And so let's just pretend we have the maps. So we're going to have this map from, so we've got a byproduct that's just the direct sum. So it's a product. So we're trying to calculate the k-thomology group. So we're going to take a byproduct. Homology group. So we're going to take a byproduct over pairs of natural numbers adding up to k, that's what anti-diagonal does, of homology applied to the first natural number there, the i-thomology of x and the j-thomology of y. Noting you avoid nat subtraction. Noting I'm carefully avoiding nat subtraction here. Yes. That's why you use antidiagon. And we're just going to say sorry for now. We're not going to. Okay, but we're just going to say sorry for now. We're not going to actually try and construct that map because we tend to. Now, skip this for a moment and let's look at the epimorphism part of the short exact sequence. Now we want to map out of the homology of the product, and we know that that's meant to go to some sum of tor groups. But there's an awkward shift by one. Now we need, we're taking a torr between an hi and an hj where i plus j is equal to k minus one. k minus 1. Okay, so we could have written here anti-diagonal k minus 1 and we'd get the wrong answer because of course if k equals 0, 0 minus 1 is still 0 and this would be a direct sum with one term. So instead we just do a little hack here and have antidiagonal of the previous number before k which carefully checks whether you're zero or not and does the right thing. Is H integral homology in this file? No, no. Uh no, no uh well okay yeah so um what was the question? Yeah, so the question is is what are the coefficients? Yeah, what are the coefficients? So let's go up and see what coefficients they said so far. Did I say any coefficients so far? I think I've well, did I say Z? The functor H just hard coded. Oh, the functor H. Oh, hard-coded Z, yeah. So this is, yeah, so this formula is right for Z, and it's right for. This formula is right for Z, and it's right for PIDs, I think is the right level for that formula. And I think in a moment later, we pay more attention to the ring. Okay. And so then the theorem somehow you want is just that those two maps, once you've actually built them, really do form a short exact sequence. Okay. We've entirely faked the We've entirely faked this now. So, what we're going to do now is use these entirely faked ones to try and do the calculations. Then we'll come back and replace these surrees with sort of the next layer down of surreys. So, let's see that we can use this formula to do a calculation before we go on. Okay, there's a little bit of annoying missing API about short exact sequences. So, maybe these are good sorries if someone wants to. So, maybe these are good sorries if someone wants to tackle them. They probably have the wrong hypotheses. I just want to say that if you have a short exact sequence and the right object is zero, then the left morphism is an isomorphism. Get the hypotheses right so that that's actually true. They're surely in LTE, aren't they? Yeah, but like, come on, Adam. You can just copy and paste them directly into this branch. Sorry? Yes, yeah, they're all there, but that doesn't count. Okay. Okay, so that's just, yeah, some API missing for trying to do the calculation. Oh no, there's a bit more API missing. Okay, these are pretty boring statements. Let's just pick one in the middle. They're all kind of the same. It's just saying that if you have anything, any function that takes a pair of natural numbers and spits out some object, and you have a byproduct over. And you have a byproduct over nat anti-diagonal two of that function, then it's just f02 plus f11 plus f20. It's just expanding out those. And there are formulas somewhere in the library for expressing the byproduct of something that's a disjoint union of things as a direct sum. So those should be pretty easy to unravel. But it's obviously a little annoying that I'm writing one of these for each k, and maybe there's maybe you want to. Maybe you want tactical to do this for an arbitrary phone type or something like that. Okay, so those ones are not very exciting. So we can now try and do a calculation again, this time not just saying sorry right away. Okay, so we're going to do the H0 and the H3 calculations. They're sort of representative. So our goal is to just show that H0 of RP2 cross RP2 is. H0 of Rp2 cross RP2 is just Z. And what we're going to do is look at the Kunneth formula in degree zero. And we're going to assert that, oops, that the right object, that is all the things with TORs, is zero, and therefore the left thing is an isomorphism, and that isomorphism gives us the answer. So at this point, I think I need two screens so that the goal view can come up. Not sure how we're going to cope with this. Okay, so there's the goal. When we start the proof, There's the goal when we start the proof, and as soon as we assert, um, word wrap on the left hand can even do that. Oh, sorry, option W? Option Z. Option Z? Ooh, okay. You said it was a good idea. Okay, so let's see. So, after the have a statement. So, after the have a statement, we have two goals. The first goal. Have two goals. The first goal: everything should be easy. We know that the monomorphism, the short exact sequence, is an isomorphism, and then we've got to solve our problem. And then the second goal is to show that all the TORs actually vanished. So let's, since the left-hand side is an isomorphism from something to the thing we're trying to calculate, our next step in the tactic proof is just use that isomorphism composed with some unknown final step. Known final step. So the goal now becomes showing that this direct sum of tensor products of homologies is just Z. So we use our lemma that we wrote a moment ago that tells us how to unwrap a byproduct of one thing as just that one thing. Well, maybe I can throw in a desymp at that point because it just has annoying lambdas in it. Okay. And so there we've got just H0, tensor H0. 0, tensor equals 0, isomorphic to what we want. So we use our assumptions that we knew those already, and we just get z cross z isomorphic to z. And at this point, I'll resist the temptation to go and work out what library lemma tells you that that is true. And just remember, we're in a monodal category, so just the left unitor is the isomorphism that shows you how to do that. And so that's why this lambda underscore here is just the left unitor. The left unitor, and so we're done there. Okay, and then in the other branch, it's pretty, it's extremely easy because this is a direct sum over an empty set, and so we just use that lemma that says those objects are zero. Okay, so it goes very similarly, obviously, when you want to do H3, this time you go the other way around, you assert that the object on the left is zero, and so the morphism on the right is an isomorphism, and so you get this goal. You use that isomorphism. You use that isomorphism you've just obtained, and now our job is to show that some direct sum of tors is what we want. So we blow apart this sum over the fin set into three different pieces that still look incredibly ugly, just there's lambdas and things there, so we hit it with a desymp. And now this is a calculation we're not going to attempt to do today. Someone needs to actually do some calculations of Tor, but you can see here, like, there's a, there's what I There's a there's what a a tour of of Z and Z and a tour of what are they? Z mod 2 and Z mod 2 and a tour of Z and Z again. Okay. Hopefully we can show. No, so which one did I get wrong? The last one. You have an H2 that this last one. So those are both Z and Z? So these first and last ones should vanish, and this last one will give us the thing we want. So it vanishes. Oh, sorry, sorry, sorry. It vanishes. Even easier. We could depending on their sign zero or something. Yeah, I mean, I suspect that, yeah, showing. If you know it's pretty verse colour, yeah, okay. Yeah, okay. I'm not sure we even know that Tor is additive or anything. I think we know quite a lot about Tor. I have a PSC sheet that's proved by A equivalent criteria for MATLABs. Okay, great. Okay. Okay, so these calculations should be doable by the right random project outside of MATLAB. Okay. And then the other bit we had to prove was. The other bit we had to prove was easy, so I'm not even going to do it at all. It's just there are no groups that appear in that sum that aren't zero. Well, at least one thing on either side is of the tensor product is always zero. Okay, so modulo all the actual calculations, you can use this formula to do the things you want to do. Okay, so what is it going to look like? So, what is it going to look like when we. Where was the actual? So, these are the huge missing bits. What is it actually going to look like when we want to prove these things? So, these are already obviously way too specialized. They mention topological spaces. And so, our first thing is a bit of planning. We're going to split this up into the stuff that is about topological spaces and the stuff that is about homological algebra and the bits of glue we'd be talking about. And the bits of glue in between, and try and refine things into further stories about these. So there's three bits here. One is very easy, and so we'll actually do parts of it, which is just that when you go from topological spaces to simplitial modules by taking linear combinations of chains, that's actually a monodal functor, a strong monodal functor. And that gets you part of the way through the problem. Part of the way through the problem. Then there's dealing with how alternating face map complex deals with tensor products. And it's a bit complicated. When you think of it just as the functor to chain complexes, it has a laxmonodal functor structure and an op laxminodal functor structure. But these don't make a strongmanodal functor. But these don't make a strong nodal functor. However, when you descend to the homotropy quotient, the homotopy category quotient, you get the right homotopies between them, between the compositions of them, and you do end up with a strong monodal functor there. So strong means abuse of definitional equality. Strong is a. No! No, not at all. No, not at all. Strong here just means that the laxator and the op laxator are their inverses. Yes, yes. So this is just axioms. So this is just axioms. This is nothing funny about quote. No, yeah, nothing evil is going on in it. And so what is the topological factor you need to prove, I guess, in is it part one that has the topology? No, no, part one is really trivial. I think we'll do, we basically do that without any sorries. These are these ones, constructing the Eilenberg, Zilboro, and Alexander Whitney maps, because they're all a bit about chopping simplicities up into chopping products of simplices up into into simplices again. Up into simplicies again is the sort of, but that's not really topological there. That's simplical stuff. There's almost no topological content. Yeah, I think that's right. So, what are the categories already, Matthew? Yeah. Yeah, let me. Next time we get to it, I'll click jump to definition. Okay, and then. Okay, and then finally there's a statement purely about chain complexes and taking homology of chain complexes. So the first observation is that when you think of homology as a map from chain complexes to graded objects, so taking all of the homology groups at once, with a few extra assumptions on the category you're working in, that's a laximer nodal functor and the And the laxator, so this map from h of x tensor h of y to h of x times y tensor y, I guess these are chain complexes now, is a monomorphism. And then the point of the code of the formula is that you can actually explicitly identify the co-kernel of that monomorphism, and that's what gives you the short exact sequence and lets you do computations. We already have the minoidal structure on greater objects. No, but it's a sorry a peak below that is like someone could do before the end of the talk. It's that one should. Do before the end of the talk. That one should be really easy. For that matter, I mean, we don't have the monodal structure on chain complexes either. I feel like that's also one that we could do by the end of the coffee break. Maybe not by the end of the talk. Okay. Complaints about the plan? This is not maths that I actually ever think about, so if it's horribly wrong, then please let me know now. I think it's right. Okay. Okay. So let's. Uh okay, so let's let's just try and do these some of these bits and see what what's easy and what's available. So the first part is just checking that the map to some visual modules really is a monodal functor. But we just don't have any of the monodal structures defined in Mathlib so far, even though they're completely trivial. So when C is a monodal category, simplicial C's is a monodal category just in a trivial way. Is a monodal category just in a trivial way. It's just the pointwise monodal structure. The simplicial objects are just functors into C. So if C is monodal, then you can tensor functions together by tensoring them pointwise. So you get that instance just by desyncing the definition of simplicial object. Presumably, at that point, you actually see that it's a functor from the simplex category, and then you can just apply instance. Similarly, of course, simplicial set is just a special case of simplicial. Simplicial set is just a special case of simplicial objects. So the same trick gives you the monoidal structure there. And so then we want to check that the functor from topological spaces to some platform sets is monoidal. So all of this is saying... I get a perverse pleasure seeing goals being proved by split. Yeah. I'm actually a little bit. That one's a little bit upsetting to me because I tried right. Because I tried writing the term and I couldn't get it to work, and then split just works. So, if someone wants to treat this as a sorry and work out how you actually say that one, I'd be very pleased. That one upset me for a long time. Okay. Yeah, so the point is just that if you have a map of a simplex into x and a map of that same suplex into y, then of course that gives you a map into x times y. And similarly, if you have a map into x, well, and that's the first part. You have a math indirect. Well, that's the first part. I mean, just take products of continuous maps. But there's actual data. Well, yeah, there's sort of data left out from this definition. Because you're meant to check that this tensorator really is an isomorphism. This is just the map one way. And so this, sorry, down here, mu is iso, is going the other way and saying if you've got a simple x in x times y, then you can just apply the projections and get the simplices back in x and y. So I've left out some data writing those steps. Backing those steps. But nothing is going on there, or at least that's the last of the topology that we're going to need, I think. It's also like the model structure is the Cartesian one, and the functor is the right add point. So that's going to be something. Okay. Yeah. I don't know how easy that is. That's probably harder to determine this. Yeah, I mean, given that how easy the data is, but it might be worth doing, it's probably worth doing anyway. It's probably worth doing anyway. Yeah. Okay. So where were we? That's just, we've upgraded our functor to simplicial sets to a monodal functor. Next, we want to do the same thing for simplicial modules. And so here there's just some abstract nonsense that if you have a monodal functor from D to E, that gives you a monodal functor from functors from C into D to functors from C into E. I couldn't find this in the library. I couldn't find this in the library, so I wrote the data and a few stories. And then you can specialize that in the case where just replacing these, specializing that to the case where C is the simplex category. That's just this statement. So instead of the functors out of C, we just have simplicial objects. And so then to get our functor from topological spaces to simplicial modules, To simplicial modules as a monodal functor, because taking our monodal functors to simplicial sets and taking free modules over those simplicial sets, but happily noticing that the library already knows that the free module functor is monoidal, takes products of sets to tensor products of modules. So we've already got the monodal functor. We need to whisker by available there. Okay, so I think that was all that there was to do, step one. These stories are all extremely trivial, and we could have done right away. Okay, so then we get on to the two parts that actually have content, and we're not going to get done right away. So I'm going to jump over to sort of step three, the stuff that's purely about chain complexes. And so here we get to Adam's question. Adam's question: We don't have the monodal structure on graded objects. Here I've proposed just writing the instance for the monodal category of natural number graded objects, because there it's pretty obvious what to do. You just take this byproduct over nat antidiagonal of k to take the sum, and that's always going to be a finite set, and so we don't need to assume that much about our category. We just assume that it, well, that it has finite byproducts, essentially, is the main thing. Anything. Obviously, I mean, people are going to want to do bounded below complexes and things like that. And we're going to have to think about how to provide the type classes there basically to ensure that we won't be able to use the anti-diagonal. We're going to have to use something else and have some extra machinery that pipes in the proof that that type we're summing over is a fin type when we're tensoring bounded below things. So there's a little bit of work, thinking work to do about how to pipe in. Thinking work to do about how to pipe in that finiteness, given the assumption of boundedness, bounded belowness. Okay, so what did I do at that point? I defined the tensor unit, which is just the graded object supporting degree zero. Given the tensor unit of V in degree zero, the byproduct of the tensor of objects is just the sums on the antidiagonal. And now for the tensor. Now, for the tensor of morphisms, well, I think we could write this, sorry, right now if we wanted to, but let's not. There is a function byproduct. So before the byproduct.map, our job is to produce a morphism between one big byproduct and another big byproduct. But the point here is that these are both byproducts over exactly the same index set, and we're just meant to be working. We're just meant to be working component-wise here. So byproduct.map just tells us we need to construct a map at each point in the index set. So yeah, you could write that very easily. It's just a lambda of, what is it? It's like lambda b f of b.1.1 tensor g of b dot one dot one or something like that. Okay. So Okay, so that sort of thing. I would hope that, yeah, and then I think the associators and unitors will be relatively easy to write. They will involve mucking about with iterated sums, but they'll all obviously be defined in terms of the associators and unitors back for the ambient monodal category. I guess it's, yeah, I'm not certain how much. It's yeah, I'm not certain how much fighting with sums is going to come in. Okay, so similarly, we need to do the same thing for the monoidal category structure in chain complexes. So let me just go back up a bit so we can see what we're doing. So we're in the same setting, a monoidal category with finite byproducts. I think you have to do something silly like this here, where you define. Like this, here where you define an id or zero morphism. So here we've got some family of objects x in our category v indexed by beta, and we've got two indices i and j, and then we want to construct the morphism from xi to xj, which is sort of the identity written as one of these ector home tricks if i and j are equal and it's just zero otherwise. Now, with that in hand, I think it's actually pretty easy to write down. It's actually pretty easy to write down at least part of the tensor product. So the tensor product of two chain complexes in degree k as an object of v is just the same byproduct we were using in the graded case. But then we need to write down the differential. And I think this is, it's no worse than this. The differential is a map from some big direct sum to some other big direct sum. So we can use the function byproduct. So, we can use the function byproduct.matrix, which just requires us to give a map, to give all the matrix components of the map. And so, some people, I mean, maybe I should pause here a little bit and remind everyone how chain complexes work. Most people in the room, I think, know extremely well. Maybe not. But chain complexes in MATLAB are very confusing. For every pair of chain groups, i and j, there's a differential between them, which feels completely insane. Which feels completely insane, but it turns out that it's easier if you just say, we'll write down some morphism between every pair of objects in the chain complex. Then we'll add as an axiom, after we've given all that data, that all the maps that go between the wrong places are zero. And then we'll say that the composition of any two maps is zero. Now, most of them will be zero because they were individually forced to be zero because they went in the wrong places, but occasionally they're valid ones and they. But occasionally they're valid ones and they line up, and then we have to insist that the composition is zero. It's not a functor. It's not a functor, no. The map from X to itself is zero. Yep, the map from X to itself is zero, yes. Each thing. So, I mean, the reason for this is, and the underlying reason for this for people who haven't suffered through this themselves is just that you often have equalities at the level of objects. You might have i plus 1 minus you might have i plus 1 minus 1 equals i. And if you find yourself trying to take some morphism from some object to another object and then realizing you want to move that object via an equation in the index set, like in the natural numbers, then you end up in hell. But if you just remember that you've got some morphism to the i plus 1 minus 1 thing, magically things work a bit better. Sorry, that it's Sorry, that isn't a particularly good explanation. But I think that, nevertheless, once you remember that what we're trying to define here is a whole bunch of differentials from any point in the chain complex to any other point, I think this becomes the right thing. So we've got two points P and Q. Both of them, remember, are like a pair of natural numbers. And so what we're going to do is we're going to just write down the differential in the first factor between those two places, which, remember, will be zero. Which remember will be zero unless q11 is one, which way are we going? One smaller than p11. Okay? But nevertheless, we can write down this differential wherever p and q are. And then we'll tensor with that, idor zero in the second factors. Okay? So when p and q are sort of the right distance apart, I guess this is the kind of the horizontal direction, then this. Then this will be an interesting differential because they're the right distance apart in the horizontal direction, and this will be an identity because we've only moved in the horizontal direction. But if we've gone somewhere off that horizontal direction, then this factor will give us zero. Go away. And then you just have the other term in the other direction with a minus sign. So e to the zero is a focus. Yeah, yes. The category structure on beta is the only more positive. Category structure on beta is the only morphisms or identities. Yeah. Yeah. I mean, so this is, I mean, this is just a proposal. Obviously, we haven't actually, these two stories are somehow the most interesting ones maybe of the talk in terms of doing today because they check if this definition of the differential and intensive product is actually usable. So we need to check. that we need to check that with this with this definition, morphisms that go between the wrong places are necessarily zero, and that the composition is of two differentials of zero. But I think those are going to work. We should try. And then, okay, so we go onwards. The tensor products on morphisms, at least the data of it, is very straightforward. You just sort of do everything pointwise in the kind of obvious way. Point-wise in the kind of obvious way. And so that gives you most of the data you need, or the first level of data you need to define the monodal category structure on chain complexes. I forgot what the words are. Symmetry. No, so I mean, I don't think to set up this so far, we didn't need to say anything about V being braided or symmetric or anything. No, I mean, is the tensor product this tense o tensor odds G, you have a minus one to the P. You have a minus one to the p. Yes? And so when you switch x and y, you'll have a different sign convention. I'm not sure what you mean by switching x and y. I'm just wondering if you can compare x tensor with y tensor x. Yeah, so there's definitely some very delicate sign issue going on. Yeah, but I think that I mean these are just the ones that you always have to. The ones that you always have to do when setting up tensor products of chain complexes. Certainly, I mean, when you'll need to say that V is monoidal, as V is symmetric before you can even ask that chain complexes in V is symmetric. But yeah, I think that's going to work. The braiding will be interesting. The braiding on chain complexes has signs in it. Yeah, yeah. But that's the usual deal. The usual deal. Yeah, but again, I mean, it's a good test that this definition of the differential is usable, that we can do that calculation. The symmetry gives a symmetry. Even the grading of the graded objects would be better than the volume. Yeah, that's a, yeah, I guess. We're going to have two graded if we want to graded objects at some point, right? Like, sometimes you want to use one side to use, sometimes you want to use the other. So, yeah, I mean, well, I mean, the oh, I think when Well, I mean, oh, I see when we do the homology functor. Yeah, to graded objects. Yeah, that one will definitely need. So, I mean, yeah, I mean, maybe we need a synonym, supergraded objects, things like that. Yeah. Scraded? Okay. Yeah, okay. So, these sorries are the ones that I'm most interested in actually doing in the very near future. Okay. So, with all that out of the way, With all that out of the way of setting up monodal category structures on things, oh, okay. I guess we have to do it on the homotopy category as well. In some ways, it's kind of easy. The way we've set up the homotopy category, the objects are exactly the same as the objects were back in the chain complex category. No quotient. There's nothing funny happening on objects. So on objects, you just say, be as you were. Be as you were. But then there's a calculation in the home step that homotopies on one side of the tensor product give you homotopies of tensor products of morphisms. And you probably should do this in some fancier way, talk about monoidal congruences and check that the homotopy congruence was monoidal and use that machinery to generate this monoidal category instance automatically rather than embedding the calculation in here. Embedding the calculation in here. Me as good as that. Sorry? Yeah? Yeah. Amelia's done that one? Excellent. Those sorries will be ticked off soon then. Okay, so sorry. Are we now out of the way? No, there's still things to say. Okay, oh, okay. So we want graded homology, that is taking the sum of all the homology groups. The sum of all the homology groups to be a Laxmanoidal functor. And so, what it comes down to is just defining, constructing a map like this, homology of sort of xi, the ith homology of x, tensor the j-thomology of y, a map into the i-th plus j-thomology of x tensor y. And I'm not really sure what hypotheses we should prove this with. I think there are actually maybe several sort of over. Several sort of overlapping but distinct sets of hypotheses where you might want to prove this sort of thing. Like, yeah, I don't know. I would do this slightly with everything being regular minoidal, but I think other people wouldn't care then. And probably something abelian works. But I'm going to leave that to other people and punt on how you actually do that. Okay, so if you're just pretending we knew that the total homology was laximonodal, Was laxaminoidal. Oh, oh, fun aside. Okay. I think probably everyone who's been around Lean long enough remains traumatized by Reed's commutative differential graded algebra challenge, which we still haven't solved. So his challenge is just define what a commutative differential graded algebra is and prove that its homology is an associative algebra. Sounds easy. Algebra. Sounds easy. But we still don't really have a nice answer. And so this laxmonoidal functor would give you a kind of a silly way to do it. I mean, a differential-graded object is just a monoid object in chain complexes now. That's a commutative monoid object, maybe, if you want a commutative differential-graded algebra. And lax monodal functors take algebras for algebras, so we're done. Of course, you'd have to believe that monoid objects in chain complexes really is what you wanted to be talking about in the first. Is what you wanted to be talking about in the first place. It's not clear whether this would really count as an answer. I mean, I think it's a great answer, really. Yeah, because where did the definition of CNG come from? Sure. Yeah. Okay. I mean, show it like, yeah. I mean, at some point, we should be able to write down with your bare hands definition and check that this thing is that thing. Even if we went via this route to do the proof, that checking this thing is that thing still sounds. That checking this thing as that thing still sounds pretty gross. Okay. Okay. And then there's a big, there's a mathematical fact here, which you can't, I didn't, you can't. Yeah, anyway, that we, to be able to do anything with a Kunneth formula, we need to be in a setting where not only do we have that laxmonoidal structure on the on the homology functor, we need to know that that tensor, that tensor. That tensorator that goes from hx tensor hy to h of x tensor y is a monomorphism. And that again requires some additional assumptions on v, but certainly for modules of rowing, that'll work. And the proof there, I think, is easy. But someone might want to think about what generality that works in. Okay. So, oh, there's so much more. There's just piles of stuff here. Sorry. Sorry. What else do we need to do here? Oh, okay. So here I'm just saying you can take the graded homology functor and have it descend down to the homotopy category. Those are easy things to do. And then once you've got the graded homology functor on the homotopy category, it gives the factorization of the original graded homology functor. Okay. This is then just hopefully relatively cheap that Given what we've done before, that homology thought of as being defined on the homotopy category is a lax monodal functor, but hopefully that's just formal in terms of the steps we did earlier. The tensorator is still a monomorphism because it's just the same tensorator. It's just a morphism in V. It doesn't care whether you took whether your chain complex is up to homotopy or not. Okay, and then, then we're ready to do some homology. Okay. Okay, so we'll go to a PID, and we've got a whole bunch of examples here that just check that for modules over a PID, we have everything we could possibly need in order to do homology, in order to do tensor products of chain complexes of modules, and in order to define Tor. But where do you need is principle ideal, Ren? For those three steps, we don't need it, and in fact, nothing I'm going to do needs it, but the Kunath formula won't be true. We won't be able to do that identification of the. Be true, we won't be able to do that identification of the co-kernel without that. I think is where it goes, but someone should correct me. Okay, so the idea that we want to do, I guess this is, yes, this is the hardest, this is the most work, sorry, the most maths. So the point is here, we've got two chain complexes of modules over R. And I read in the books that you need to assume that one of them is a chain complex. Assume that one of them is a chain complex of free modules. And then the point is that you can identify the co-kernel of that tensor strength, the map from homology of x, tensor homology of y to homology of x tensor y, with a sum of tor groups. Okay? And we're just not going to go there today. But there's lots, there's like a couple of pages of informal math or a dense page of informal math. This wanted generation of a spectral sequence. Yeah, so when you're not over. Yeah, so when you're not over a PID, there's a spectral sequence instead. That's a lot of two cards, two something, between non-zero and row. Yeah. Yeah, I'm certainly not going to fill in this, sorry, ever. So if the person who does prefers to do spectral sequences first, then off you go. And then this statement down here is just the same statement, but starting in the homotopy category and should be purely formal. It's just saying again. Should be purely formal. It's just saying again you can explicitly identify the co-kernel of the tensor strength in terms of a sum of 12 groups. Okay, so that's all I'm going to say about sort of the homological algebra formula. And we haven't, of course, haven't done anything. We're just putting everything into that. Sorry. Okay. Whatever, some missing API about short exact sequences that I'll just skip right over. They're all in LTE, presumably. They're all in LTE, presumably. And so then you get the final statement of the Kunneth formula. You have a pair of chain complexes, you have a short exact sequence where the left-hand morphism is the tensor strength, and then the right-hand side is, well, whatever the co-kernel of that tensor strength is, composed with this isomorphism, identifying that co-kernel with the sum of tors that we wanted. And then a version for. And then a version of that in the homotopy, starting in the homotopy category instead. There's not even a sorry here. This is just easy rearrangement of short exact sequences based on what we had before. Okay. And then the third component is all of the Eilenberg-Zilber stuff. So here we've got the, I've just got a shorthand C, which is just take the alternating face map complex of Face map complex of some simplicial object. And the point is, in basically complete generality, you have these maps back and forth at the level of... So these are just chain maps. And they're and they're not particularly hard to write down. I can never remember which one. One involves shuffle products and one involves... Anyway. Full products and one involved. Anyway, they basically come from the combinatorics of chopping up products of simplicities. Okay. And the thing that you want to go away and prove is that, not that these are inverses as chain maps, but of course, but that they're homotopy inverses. And I think Brendan was proposing to me yesterday that some of his work on the, he's got the method of acyclic models set up, and that that might make it cheap to construct these homotopies. To construct these homotopies. Ah, okay, okay. Ah, indeed. Okay. But it's also. What's that? Only for V is set. Like for. Ah, okay. And I mean, here we're using it for module. So, but maybe, I mean, we're only using it in module in an extremely weak way. So I wouldn't be surprised if you can, if that's not an issue. Oh, oh, okay, okay. Well, then they're no good. Yeah. Okay, well, then they're no good. Yeah, sorry, that would make no sense for you. Okay, good. Yeah, but you could also, I mean, this is just some combinatorics, if you like your combinatorics. Okay, and the point is that once you've got those homotopies, if you take this Eilenberg-Zilber map and sort of shove it down into the homotopy category quotient, then it becomes an isomorphism with the Alexander-Whitney map. With the Alexander-Whitney map as its influence. And so we'll use that in just a second in the conclusion of the proof. So now we're just putting those facts together, that if we think of the alternating face map complex composed with the quotient to the homotopy category, that thing is a monodal functor from simplicial objects in an arbitrary v to the homotopy category with values in v. With values in v. And so now we've basically got everything we wanted at the beginning set up as a monodal category all the way to the homotopy category, and then we finish by using the Kunneth formula, the sort of the homological algebraic Kunneth formula, the homotopy category. Okay, so we can put it all together, and from this point there are no more sorries. So we can put together the singular chains azimonodal functor. So this goes from Functor, so this goes from topological spaces to the homotopy category of modules, just by stringing together the various monoidal functors we constructed today. We can observe that, so that was honestly monoidal, strong monoidal. And then when we further take homology and end up in graded objects, that's only lax monoidal, but that's fine. One thing that we stop and check here is that if you take Check here is that if you take this lax mineral version of singular homology that we just constructed and actually apply it to some object, you get the same thing as the original definition that we cripped from Adam. And you can prove that just by ruffle. You should take that ruffle with a slight grain of salt. There are a bunch of sorries along the way. And appropriate use of sorry can make things definitionally equal when they're not going to be later. But I think that I actually did define. But I think that I actually did define nearly all of the data that goes into that riffle, because this is just at the level of objects. It's not referring to any of the tensor structure, which is where we were cheating. Okay. And then we need one little observation before we put everything together, which is just that if you take singular chains on some topological space, that was a free module, and it's just you unfold the definitions and check that that was by construction. Okay, so then we're going to set up our code. We're going to set up our Kunneth formula. So, we're going to write down the monomorphism in the Kunneth formula. And the point is that that's just the tensor strength of singular homology as a laxmonodal functor. And then we have this preliminary lemma where most of the work happens. So what are we saying here? So given x and y, topological spaces, we're saying there exists some morphism from the homology of the product to the To the byproduct of all the Tor groups, such that the monomorphism, the nice monomorphism, forms a short exact sequence with whatever this other crappy G is that we don't really care about. But obviously, in this proof, we have to construct the G. So we start by just unfolding some definitions. Let me see if I can bring up the goal view again. Okay, so our goal is to prove that there exists something and that that's something. Something, and that that something forms a short exact sequence. And we've desymptifunged, so it's a god-awful mess, but it'll get better in a moment. Okay, so we do split at the beginning, and since we're splitting an existential statement, this gives us two goals. There's a goal way down at the bottom, this morphism we're meant to construct, and then the goal at the top, that it's part of a short exact sequence. And we're going to do this nice move in this proof where we're just going to not worry about the meta, the variable g. The variable g, we're just going to directly construct the short exact sequence, and the value of g will just pop out by the short exact sequence that we stick in. So we're responsible for constructing some short exact sequence. And so what we're going to say is, well, I'm going to construct this from some other short exact sequence by tweaking the object in the middle by some isomorphism. That's what this line says. It says, if you've got a short exact sequence and you compose in the middle with some isomorphism. And you compose in the middle with some isomorphisms and you get another short exact sequence. So at that point, you get two goals. Remember, the goal for G has disappeared because we've entered this curly brace here. But the two goals are, well, you've promised me some short exact sequence with some unknown middle object and an isomorphism of that unknown middle object to somewhere else. And so the second goal is that unknown isomorphism to somewhere else. So we say we want to work on that. So we say we want to work on that. Oh, sorry, it's not. Sorry, can't scroll. Why can't I scroll? Oh dear, what have I done? I thought this should be an isomorphism to something that we don't know the target of, but it's not saying that at all. It's saying we've got some isomorphism, that some specific morphism is an isomorphism. Oh, I've forgotten what I wrote here. It was only a day or two ago. Oh, no? So we had So we had some short exact sequence. We're trying to. But isn't it that the map on the left is composing with something that's supposed to be an isomorphism? Oh, and the point is the map on the left already was an isomorphism. No. Well, the map on the left is something composed with an isomorphism. At least that's what you're trying to show. Oh, uh. Yeah. Okay. Oh, okay. But why does it? Sorry? Upward or complex in the middle? The one I think you're using. Of the lemma that you're using that line. Yeah, compy so middle. Yeah, so what is it saying? It's saying that if you know that f compose i and g is a short exact sequence, then you know that f and i compose g is a short exact sequence. I see. So the point is the goal looks like a composition and something else. And so doing this apply now is asserting to it. We think that that thing you see in the composition really is an isomorphism. Really is an isomorphism. Great. And that thing that it sees there, well, happens to be something that we know is an isomorphism by all the Eilenberg-Zilber stuff. It's exactly the tensor strength down in the homotopy category. And so Eilenberg-Zilber says, okay, yes, I believe you, that was an isomorphism. Good. Okay, sorry, I forgot what I was doing there. Now we've got some other, some strange, short, exact sequence we're trying to prove now, but the point is that. Trying to prove now, but the point is that that one is exactly the short exact sequence, the purely homological algebra one that we had before. And so we just use a convert with the short exact sequence that comes out of that. And now we've got some crazy, the convert said, oh, well, that didn't look exactly right. Your maps didn't match up. But of course, the map that we're trying to match up with has this unknown G in the existential statement in it. And we get some crazy. Central statement in it. And we get some crazy goal at this point that says some crazy map composed, some crazy map, and these are just all things in terms of tensor strengths, composed with your unknown G is the projection to the co-kernel that you're after. And you say, oh, okay, we know how to do that because we proved that all of these crazy maps coming from the tensor strings were isomorphisms because these are all strong mineral functors. So you just move them over to the right-hand side, and we get a goal of the form. A goal of the form the unknown morphism that the existential statement asserted is just some crappy composition of monodal tensor strengths, and so we can just say, Yeah, use that, and you're done. And finally, there was a goal left over that singular chains was free so that we could use the algebraic homology print formula, but you end up done. Okay. Sorry. Using goals with meta-variables technique, using what it says is eh? Using what it says is E? Yeah, no, I mean, I think we, I think, like, so in lean four, it gets better because you can use refined statements with named meta variables. You don't have to write underscore. You can write underscore that stupid epi. And then in the later goal views, you can pay attention to it. I think we should double down and write tactics. I mean, have you, so I was telling Johan about this. There's this great, anyone who has kids, there's this great computer game called Dragonbox, which A game called Dragonbox, which is just like an iPad game or something, which is just teaching you how to do basic algebra, but you don't know, like, it doesn't even tell you that these are numbers and plus signs and multiplication signs. There are just some rules for like clipping boxes together and unclipping them and rearranging them. And the aim of every level is to solve for X. And so several years later, one of my kids came back and said, Dad, algebra is just Dragonbox. And like, it was great. But we should do this here. So this goal that we had here, where was it? It. We saw, like, oh, we've got some crazy composition of crazy maps, compose, compose, compose, composed with our meta variable equals something. We should have tactics that are like, oh, I can solve for the meta variable. Because I mean, you can't just say riffle here, because the meta variable is deep inside, but if you solve for it, then you're done. And because this apply is iso.pen, you just want to write dragon box. Yeah, yeah, that's dragon box there. Yeah, looks how to isolate the meta variable. Why not? Why not? Unfortunately, the first apply would fail in 4 because it will complain that it doesn't have a night in its ISO instance. Oh, okay. Yeah, okay. Some adds and some extra underscores. Okay. Good point. Okay, so I think that's all I've got on the Gronoth form now. So, do we can I pull? Did anyone do the I shouldn't publish it? I can do the topology. Oh, oh, okay, okay, okay, sorry, okay. What? New terminal, get stash, get pull, the constant continuous map. The constant continuous map. I have no idea how it's going to be. What did I say? 87 before? Oh, there's still 87. What? Ah, okay. Well, maybe someone added on its own. Oh, the git log, yeah, that's a better answer. Okay. Oh, oh, no, no, no, because I renamed my file to Tuesday 9 a.m. and they probably all worked in Kunath, which was what the commit. Kuneth, which was what the commit actually names it. Okay, so let's find here 86. Yay! Okay, live linear one with us. Has any real complained about confers? About converts. He says it's an evil tactic. And converters are great. Yeah. Non-terminal converts, he said they were bad. They were bridging them. We need to re-educate. Yeah. I mean... Well, some goals that exact doesn't argue with that screen that made the use of it. We could, no, I mean, I think that we could fairly have more show statements immediately after converts that attest to what the Converts that attest to what the goal should be now. Yeah, I mean, convert, yeah, yeah. But uh, we can't obviously. Yeah, obviously, we can't do without them. Yeah, that's good. I'll do it all. 82. Whoa, whoa, okay, okay. At this place, yeah. Okay, great.