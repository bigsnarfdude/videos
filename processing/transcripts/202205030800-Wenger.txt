You are. And it's a pleasure to introduce Stefan Wenger to talk about isoparametric subspace distortion in metric spaces. Okay. Can you hear me? Sorry. My. Ah, here we go. Yes. Okay. Good. Yes. So thank you very much for the kind invitation. It's a great pleasure and honor to talk here. I'm going to talk about. Here. I'm going to talk about isoprometric inequalities in the setting of metric spaces and report on the recent joint work with Giuliano Basso and Robert Young, who is the chair here. So if you have any question and you write in the chat, he's probably going to be able to answer them or surely be able to answer. And I can just tell you, I'm not very good at giving online talks. There's too many things going on. And so I don't think I can actually follow the chat while giving a talk here. While giving a talk here. So most things will be in the setting of metrics basis, but if you feel more comfortable, just think about remoney manifolds. I think most results are already interesting and non-trivial in that setting. So, let me see, it already starts. Here we go. Okay, so the classic classmetric inequality just says that among all closed Among all closed Jordan curves or Jordan curves of a given length, the circle encloses the biggest area. And in particular, for any Jordan domain, the area is at most a factor 1 over 4 pi times the length of the boundary squared. In this talk, and of course, you have an analog also for higher dimensional sets, right, with finite perimeter, but in this talk, we'll mostly talk about filling. Talk about filling, say, for example, curves in a higher-dimensional space. And of course, there you don't have the enclosed area, but you have to actually construct a surface, for example, two-dimensional surface with given curve as a boundary. And you ask yourself how efficiently you can do this. So, what is the smallest area you need to fill a closed curve in the space with a With a two-dimensional surface. So, this kind of isochrometric inequality appears in many contexts, in many branches of mathematics, in particular, of course, in metric geometry, where somehow the way you can fill a curve or how efficient you can fill the curve is closely related to upper curvature bands, for example. And for example, Gromov, he discovered that He discovered that delta hyperbolicity of a space, so a large-scale notion of negative curvature, is actually equivalent to the fact that you can fill closed curves with a linear amount of area. And in geometric group theory, such isoprometric inequalities appear as Dean functions, and these, in some sense, measure, well, you know, they measure. Measure, well, you know, they measure how efficiently you can fill a curve by a surface. And their growth says something about the complexity of the word problem. So, you know, for given a word that represents the identity, how many conjugate of relatives, conjugates of relatives, you need to write this trivial word in relators. And then, more generally, we'll be Then, more generally, we'll be interested in filling k-dimensional cycles in a space by k plus one-dimensional chains in x. And of course, before really starting, I should at least say one word about the notions of change we're going to use. So there are several notions of change in a Vi-Money manifold or a metric space. Or a metric space. And the easiest probably is that of a Falips chain, which is just a formal finite sum of Lipschitz maps from the standard k simplex to X and into two weights. So exactly the same definition as an algebraic topology, except that we add this Lipschitz condition, and this Lipschitz condition allows Flipschitz condition allows us to define a volume or a mass of a chain just as the sum of weights times parametrized volumes. What is the parameterized volume of a Lipschitz map? Well, if X is a norm, say a finite dimensional norm space or a Riemannian manifold, then by Warden-Macher's theorem, Lipschitz maps are differential almost everywhere. And so you can take the Jacobian. You can take the Jacobian of the differential and integrate it over the k-simplex. And when x is just a metric space, of course, you don't have any differentiability anymore, but you still have a notion of metric differentiability first discovered by Kirkheim. And then you can still define a Jacobian and integrate this Jacobian. And basically, when phi i is injective, then this gives you just the house of This gives you just the house to measure of the image. And the boundary is just defined as for singular chains in algebraic topology. A bit more advanced notion of chain was already introduced yesterday by Christina, and that's the notion of integral currents by Ambrosio Kierkeheim, which generalizes the Federal-Fleming theory of integral currents from a Euclidean setting to that of a leading setting to that of a general metric space. And these integrals currently come with a boundary operator and also a notion of mass. I will not say too many things about these. Christina has already explained quite a bit about them. I just would like to maybe emphasize once more, you know, they are certain functional on k plus one, two plus of Lipschitz function, so f pi one of the. function so f pi1 through pi k and such a tuple should really be thought as the differential form f d pi1 wedge to wedge d pi k. Okay, so they're functional, so we can also talk about like weak convergence, so pointwise convergence of these guys. And maybe just think of an integral current as a suitable limit of Limit of Lipschitz chains, and we'll actually see something in this direction a little bit later in this talk. Okay, so if you're familiar with the Fidel-Fleming theory, just think maybe free money manifolds and Fidel-Fleming integral currents. And if you don't know this notion, then just think of Lipschitz chains. Basically, all the subtleties or the problems that I'll discuss, they all appear. That I'll discuss. They all appear already in this setting of Lipschitz, of Lipschitz chains. Okay, now let's talk. Now we can define the filling volume of a cycle, so of an integral current without boundary. Well, this is just the minimal mass you need of an integral m plus one current whose boundary is t. And here I illustrated this a little bit with a relatively complicated curve in R3. In R3, which, when you want to fill it, you need actually or fill it minimally. You know, the minimal filling has infinite genes. And then what we're going to talk mostly about is Euclidean isoprometric inequalities. So I'll say that a metric space has Euclidean isoprometric inequalities up to some dimension k. If for every integral m If for every integral m cycle with m smaller or equal to k, the filling volume is bounded by a constant times the mass of t to this power m plus 1 over m. As we will see, that's exactly what you get in Euclidean space, and that's why, of course, they're called Euclidean isochrometric inequalities. Before I go to this Euclidean isochrometric inequality, let me just make one basic observation about chains. Observation about change. So, one-dimensional integral cycles, they're relatively easy. One can show that they're just sums of closed Lipschitz curves. And so, if your space is nice enough, for example, a Rn or a Banach space or a cat zero space, then you can just fill these curves by coning off your geodesics to a point on a curve. You can do that for each curve. You can do that for each curve. And then you get an integral two current, you know, whose mass is bounded by the length squared of each curve. And then summing up, you get that this space has a Euclideanized primatic inequality in dimension one. So a quadratic isprimatic inequality. And this, of course, holds more generally if your space is Lipschitz one connected. So this would be Lipschitz. One connected, so this would be Lipschitz one connected, which just means that you can extend Lipschitz maps from the circle to the disk with a linear bound on the Lipschitz constant. Well, in contrast, higher dimensional cycles, they can be extremely complicated. And the same procedure of coning off doesn't work anymore. Doesn't work anymore to give you a Euclidean isoprometric inequality because they can be, you know, have very, very small mass, but huge diameter and still be connected. We've already seen pictures yesterday from Christina with things like this. And here is a bit of an abstract picture that allows you to imagine how badly they can look. They can actually look, they can fill up in some sense the whole space if the underlying space is. Underlying space is separable and still have a very small mass. So before we go Euclidean ismatron equality, I would like to discuss briefly two other measurements how to fill k-dimensional objects, so k-dimensional cycles or k-dimensional asphalt. K-dimensional spheres. You see, I mean, you can easily also construct just a sphere, right? A Lipschitz sphere that has, you know, a very small volume, but very, very large diameter, right? So already there, you have problems. But so two other notions. The first one is Lipschitz connectivity. I call a metric space Lipschitz K-connected. Lipschitz K connected, and we'll abbreviate this with L C K. If Lipschitz maps from M spheres with M small or equal to K can be extended to the closed M plus one dimensional pole with linear increase of the Lipschitz constant. So, this notion of Lipschitz connectivity plays an important role in Lipschitz extension results, for example. And X, I say that X has coning inequalities up to dimension K. Well, if every M cycle with M smaller equal to K has filling volume at both the constant times the diameter of the cycle times its mass. And you see already, right, exactly. Well, let me first maybe say two more things. So, L. Things. So L C zero, so Lipschitz zero connectedness and Koning inequality in dimension zero, they're just equivalent to quasi-connected. So that means that for any two points, there exists a curve which joins them of length at most proportional to their distance. So compact K-connected Riemanni manifolds, they are Lipschitz K-connected. And what we already discussed is What we already discussed beforehand, this procedure of just coning off to a point that you can via geodesics in Banach spaces or cat zero spaces shows immediately that these are Lipschitz K connected and have coning inequalities up to dimension K for every K. And then Alexandrov spaces are with lower curvature bound, while locally around the point they have a neighborhood. Point they have neighborhoods that are Lipschitz contractible, and so they also have the same properties. And some spaces that don't have, that are not Lipschitz connected for every K are, for example, the Heisenberg groups of dimension, of topological dimension 2n plus 1. They can be shown to be Lipschitz K-connected for K strictly speaking. For k is strictly smaller than n. And this was proved by Gromov using microflexibility. And together with Robert, about 12 years ago, we gave an elementary proof which used ideas, heavily used ideas of Robert, in which he proved Euclidean isochrometric inequalities for the M. Heisenberg group. Okay. Okay, so now let's go back to isoprometric inequalities and let's look at the very classical case of Euclidean space. And as far as I know, the first people to prove Euclidean isochromatic inequalities for k-chains or k-cycles in any dimension in N were Federal Fleming, who proved the following theorem, which is called the Federal Fleming. A theorem which is called the Federal-Fleming deformation theorem, which allows you to push an integral current into the k-skeleton of a cubical subdivision of a given length epsilon. So it says that any integral current can be written as the sum of a polyhedral chain in the k-skeleton plus an integral k-current r plus the boundary of an integral k plus 1. Of an integral k plus one current, and you can get bounds on the mass. So the mass of p is at most proportional to the mass of t, and the same thing for the mass of the boundary. And the mass of the higher dimensional is at most epsilon times the mass of t, and similarly for the current R. And here is a bit of a picture. So in blue, So, in blue, I marked this current T. Then you push it out into the here, it's the one skeleton that would be our P, the green one. And the red one is this rest. And these the higher dimensional one, this yellowish one, that is S. And the main idea is that basically in each of these cubes, you try to find a good projection point and then you radially project. And then you radially project your current out first into the N minus one skeleton. And then you do the same procedure in the N minus one skeleton. You push it out into the N minus two skeleton, etc., up until you land in the K skeleton. And of course, you have to be a bit careful not to use the wrong projection point. For example, if you use this projection point like inside this very small cycle here, then you would blow up the cycle to Blow up the cycle to a potentially very big cycle, but Fedora Fleming showed that you can choose in each one a good cycle so that you get these inequalities. Okay, so what does that help for our isoprometric filling problem? Well, so now if T is a cycle, then P itself is also a cycle, and R vanishes, okay? Vanishes. And if we choose epsilon sufficiently large, namely this constant up there times the mass of t to the one over k, then necessarily p has to be zero. Why is this? Well, because each k phase now has volume epsilon to the k, so that means c times mass of t. And since p is an integral or is a polyhedral. Integral or it's a polyhedral cycle, it has to have more than one phase, right? And so, actually, if it's non-zero, it has to have a bigger mass than what is allowed by this inequality. So then P is zero, R is zero, so then T is just the boundary of S, and the right-hand side here becomes exactly what we want, namely the mass of T to the K plus one over K. Plus 1 over k for some constant which depends on n here. Okay, so this is the first isochrometric inequality k change. And of course, one asks oneself, what is really this constant D? Does it really depend on n or just on k? And actually, it only depends on k. So the optimal constant was determined by Almgren. By Almgren about 25 years later in 86. And he showed that the optimal constant is exactly when t is a k-sphere. Okay, and then, well, let me maybe go back quickly. So let's talk about other spaces. So clearly, if you go to an infinite-dimensional Banach space, for example, well, you don't have a Fieder-Fleming theorem anymore. Feeder-Fleming theorem anymore, or if you have a Riemannian manifold, well, then you can still make sense of a Federal-Fleming theorem. Well, at least if you have a good group action for epsilon small, but not for epsilon large. So in general, this approach of Federal Fleming doesn't work in infinite dimensions or, for example, in Riemann manifolds. But nevertheless, so Gromov showed the following thing. Well, he showed. The following thing. Well, he showed it for Riemanni manifolds and finite dimensional norm spaces. Then I'm prosperous for dual spaces. And I showed it in my thesis in the generality of complete metric spaces that whenever you have a Koning inequalities up to some dimension k, then you also have Euclidean isopometric inequalities. Okay, and what is the idea of the proof? Well, the idea is to try to... is to try to, we already said that cycles can have very very large diameter and very small mass and so the coning inequality doesn't give you anything useful for those of course but if you can somehow restrict the diameter if you have a small diameter or a diameter at most proportional to the mass to the one over k, then the Koning inequality of course gives you immediately a UK To immediately a Euclidean isomatic inequality. So the idea is to decompose a given cycle into a sum of round cycles, that means where the diameter is exactly small enough that you can use the coning inequality. And if you achieve this, well then without adding too much mass, well then you can just fill by the coding inequalities each of the TIs and you get it. T i's and you get it. So, how do you decompose? Well, the idea here is a cycle up here which you know extends very far. And the idea is just to take a point and then look at the growth of the mass of balls. And then, you know, as long as this grows like R to the K, the diameter is proportional to the mass to the one over k. So then you're in good shape. Okay, so then you're in good shape. But once your radius becomes too big, then potentially the mass growth is too small. And when it becomes much smaller than R to the K, well, then you can cut off. So then you can cut off. And the boundary that you create, because the growth is slow enough, well, the boundary doesn't have very much mass either. And then you use, well, you do everything by induction. Do everything by induction, and you use the isochrometric inequality that you've proved one dimension lower to fill the created boundary. I tried to mark it in red there. So you fill something, of course then you add mass, but this allows you to show with this growth thing that you don't actually add too much mass. So you do that at one point, and then you need to use some covering arguments to show that you can do that. To show that you can do that and efficiently decrease the mass to get this. So to get this, I mean that you don't add too much mass. So the sum of masses of these Ti's is at most a constant times the mass of T. Okay, so now I think it's interesting to ask and natural to ask what are the relationships between What are the relationships between these various quantities for like the Lipschitz connectivity, Euclidean isochrometric inequalities, and Konin inequalities? So we already saw that Lipschitz one connectedness implies isochrometric inequality in dimension once over curves and the Koning inequalities imply Euclidean isochrometric inequalities. So now the question is: well, what happens, for example, with Lipschitz-K-connectivity? With Lipschitz-K-connectivity, does it imply isoprometric inequalities? And do Euclidean isoprometric inequalities imply Kohling inequalities? So, right, when we looked at Banach spaces and Katzero spaces, for example, there it's very easy to prove Koning inequalities. So, maybe you ask yourself, well, okay, why should I want to know whether Euclideanized primetric inequalities? Euclidianized primetic inequalities actually imply coning inequalities because the other way it seems to be, you know, yeah, it's harder to prove Euclidianized primetic inequalities. But coning inequalities actually have become quite important. Oh, I forgot to say that these were first, I think, introduced by Gromov in his Filling Riemann in Manifolds paper from 83, you know, where he proved this version of the ice-prometric inequality. And they have become quite. Quality and they have become quite important, for example, in recent work of Bruce Kleiner and Urs Lang on higher-rank hyperbolicity, and also in recent work of von Kleiner and Stutter, and two very long papers on Moore's quasi-flats. And one reason why they're so they're usually there a standing assumption. And one reason why they're somehow nicer. Why they're somehow nicer than Euclidean isochrometric inequalities because you can prove certain things that you can't prove with, in general, not prove with Euclidean isochromatic inequality. And one of them is this following thing, that, well, if you have a sequence of cycles that converges in filling volume to a given cycle T, well, then the convergence. Well, then the convergence implies also weak convergence. So, this is true in any space, but actually, when you have coding inequalities, even just local coding inequalities, the converse is also true. And this is often quite useful because very often you can show weak convergence of at least a sub-sequence of a sequence that you have. That you have. And then it's not so easy to conclude something about the limit. But once you have this filling volume convergence, it sometimes becomes easier. So for example, there's a conjecture with Kromov that above the Euclidean rank of a Catio, of a co-compact Catiro space, the space should admit linearizer primetric inequalities. Linearizophrometric inequalities. So, this conjecture is still widely open, I think. And the only thing that I have been able to prove is that you have at least something strictly better than Euclidean isochrometric inequalities. And this also works when you have coning inequalities instead of cat zero. But it uses exactly a factor like this. Okay, so now. Okay, so now what we will be able to do, we will be able to give relationships between these three notions for spaces of what is called finite Nagata dimension. So let me briefly say what that is. So a metric space is said to have Nagata dimension at most n if for every s there exists a covering of the space with sets of The space with sets of diameter at most constant times s, and such that any set of diameter s, so this red set, meets at most n plus one of these sets in the covering. So this is like a quantitative version of topological dimension and is closely to relate it to Kromov's asymptotic dimension. And maybe just a few remarks. And maybe just a few remarks and examples. So, the topological dimension is always at most the Gauta dimension. And when you have nice bases like compact Riemanni manifolds, they're actually the same. Then, while Hadamar manifolds, at least those who are homogeneous, and Hademar manifolds with pinched negative curvature, have finite Nagar dimension, it's actually an open question whether all Hademar manifolds have finite Nagar dimension. Have finite Nagotta dimension. But three-dimensionals, also, that's the number two. This was proved, I think, by Lung and Schlichenmeier in 2005 based on ideas of Romov. Then three-dimensional Hademar manifolds, they have negotiated dimension three. That has recently been proved by Long and his student Jürgensen. Then planar geodesic metric spaces, these are geodesic metric spaces that admit the continuous injection to The continuous injection to R2. They have an Agalta dimension. And doubling metric spaces, so spaces where you can cover any R ball by a uniformly bounded number of R half balls, so balls of half the radius, and they also have finite Magazine dimensions. So, for example, you know, the Heisenberg groups, or more generally, Carnot groups, so sub-regional. Generally, Carnot groups, so sub-Riemannian manifolds, Carnegie groups, they have finite Nagata dimension. Okay, so now we can finally state our main theorem. For this, I need the notion of isoprometrically undistorted. So let's start with a complete metric space Y. Metric space Y, and suppose X is a closed subset, then we say that X is isoprometrically undistorted in Y up to dimension K plus 1. Well, if M cycles for M smaller or equal to K that are supported in X, they can be filled in X almost as efficiently as they can be filled in Y. Okay, so here the red curve is a curve in this. Is a curve in this space X here. Here I feel it, I have to go relatively high up. Whereas in Y, you can see Y is the whole space, let's say whole R3, you can fill it like this. And what we prove with Giuliano Basso and Robert Young is the following, that whenever y is a complete metric space and X is a closed quasi. And X is a closed quasi-convex subspace finite Lagarde dimension, then if X is Lipschitz K connected or has isoprometric inequalities up to dimension K, then X is undistorted in Y up to dimension K plus 1. So Robert proved a first version of this theorem where, if I remember correctly, his Y had to have finite adult dimensions. Had to have finite dot dimension and x had to be Lipschitz K connected. So here, this distortion constant C that we have here actually doesn't depend on y, but only depends on the data of x. So the Nogata dimension and this constant in the Nogata dimension and the And the constant in these quantities here. So, in particular, right, because x always embeds isometrically in a Banach space, so in L infinity of X by Kuratowski embedding, and actually, you know, you can say that X has the side same as can be, we can fill cycles as efficiently in X as in L infinity of X. As in L infinity of x, and that's actually the best place you can fill, okay? Because L infinity of x is in the injective metric space, and in injective metric spaces, you know, that's in some sense the nicest space to fill in where you can do it most efficiently. So this theorem, I think, is mostly interesting when you have Lipschitz-K connecting those isochrometric inequalities up to some dimension, but not in all dimensions. But not in all dimensions. Because if you have this LCK or EIK up to the Nagata dimension, then by a result of Langsch Lichtenmeier, the space is an absolute Lipschitz retract. And then you have a Lipschitz retraction from any space it lives in. And then the theorem becomes trivial. So the setting where you have Lipschitz K connected up to some K, but the Nagata dimension. Some k, but the Nagata dimension is a lot higher. That's in some sense the interesting case. So, for example, Hadamar manifolds or Katzi row spaces, finite Nagata dimension, they're not so interesting for this theorem. On the other hand, I think for Carnot group or Heisenberg groups, the theorem is interesting because typically there you have Lipschitz-K-connect and is up to some constant, but the dimension of the space. But the dimension of the spaces is much, much higher. And now let's see quickly how we get these relationships. They come out now very quickly. So if X is a complete quasi-convex metric space of finite Nagar dimension, then if X has L C K, then it also has Eik. So what we saw in general for Lipschitz one connectedness implies connectedness implies or quadraticize the primitive inequality for curves. Now with finite Laganta dimension you have it in all dimensions. And the converse to Gromov's theorem that Euclidean is practicing inequalities imply Koning inequalities. And then you get these theorems like the flat convergence is equivalent to weak convergence. You get those for such spaces as well. And yeah, and for example. Well. And yeah, and for example, what you get is that the Heisenberg group of topological dimension 2n plus 1, either equipped with a sub-Riemannian or a left-invariant Riemannian metric, and they have Koning inequalities and Euclidean isochrometric inequalities, because as we saw, a Lipschitz K connected for K is to be smaller than N. But actually, the Euclidean isochrometric inequalities, as I already mentioned, were earlier proved by. Earlier proved by Robert Young already. And our Lipschitz extension results are based on ideas in his proof or the methods he developed there. So it's not really something completely new. But I have the feeling that in general, because Lipschitz spheres are so much nicer than general cycles in principle, in Carnot groups, it should be easier in tendency to prove Lipschitz connectedness than a Euclidean ispinatric inequality. You clicked in our sprouting quality. Okay, and the proof I basically already see whether I can pull that up the chat. I could read it to you. The question is by Konstantin Vernikos, and he asks: quasi-convex means what when there's no outside space? Ah, so wait, sorry. I have to try to get. I have to try to get the chat. Well, quasi-convex are quasi-convex means that it need not be the space need not be geodesic, but in some sense, you know, you still have curves of length, you know, at the at most a constant times the distance. Okay, so it's a bit less than a length space. Does that answer the question? Okay, good. Okay, oops, no, I don't get yeah, okay. So, as I already said, you know, X embeds isometrically in the Banach space of bounded functions on X with the succ norm by Kurotovsky embedding. And so now, by the undistortedness theorem, you know that cycles in X can be filled almost as efficiently. In X can be filled almost as efficiently as in this Banach space, but Y as a Banach space has coning inequalities and thus also isochromatic, Euclidean isochrometric inequalities, and so X has to have the same effects. Okay, so let me see how much time I still have. Yeah, so before discussing the ideas of the proof for this undistortedness theorem, I would like to first show you what else you can do. What else you can do with the methods that you developed to prove this? And one is to try to come up with a version of Federal Fleming's deformation theorem in metric spaces where you don't have cubical subdivisions. So as we already said, you don't have cubical subdivisions of any size, even in Riemanni manifolds. And of course, in metric spaces, even if the Nagata dimension is not. Spaces, even if the Nagata dimension is finite, you have no chance of having things like this. And so, you know, yeah, you need a substitute. So we define the following substitute for a cubical subdivision. We take X a metric space and then K an integer and C and epsilon some positive numbers. And we call K epsilon polyhedral structure a triple of. Triple of consisting of a finite dimensional simplistic complex sigma with a length metric such that each simplex is a Euclidean simplex of side length epsilon and then a map from the zero skeleton of the simple complex to x which is quasi-isometric and Lipschitz and has C epsilon dense image in X. So here you have the Lipschitz condition. Here you have the Lipschitz condition, and here that's the quasi-isometry lower bound. And homomorphisms from the spaces of polyhedral M chains. So these in sigma, so these are just sums, weighted sums of m-dimensional phases, simplicities into the space of integral currents, such that they commute with the boundary operator. The boundary operator and such that they are well adapted to our map phi in the sense that point masses are mapped with the zero currents induced by points, but they are just the zero currents which are the points mapped by phi. And the n-dimensional sympices, they are mapped by this homomorphism to homomorphism to integral currents that are supported in a sufficient in a good ball and have good good good bounce on the mass now given such a polyhedral structure called polyhedral structure we can define polyhedral chains and these are just these images under lambda m of polyhedral chains in sigma and now In sigma. And now we can state a version of the Filter-Fleming deformation theory in metric spaces of finite Nagar dimension, which are Lipschitz k connected or have Euclidean isochrometric inequalities. And that's the following. Well, for every epsilon, there is a k epsilon polyhedral structure on X with constant With constant independent of epsilon, such that we have the following version of the Federal-Fleming theorem. Well, any integral current in X of dimension at most k can be written as the sum of a polyhedral chain in the sense that we just defined plus an integral m current plus the boundary of an integral m plus one current, and such that we have exactly the same mass bounds. Exactly the same mass bounds, except for this term here, where in the Euclidean case we don't have a second term. And this term here comes basically out of applying our non-distortion theorem at a certain point. So a consequence is the following. Well, if x now is Lipschitz K connected, then the map phi in this polyhedron, in this In this polyhedral structure, is actually not only defined on the vertices, on the zero skeleton, but actually on the k-skeleton. And the homomorphisms lambda m that just given by pushing polyhedral chains forward by this Lipschitz map. So this phi is actually Lipschitz map. And yeah, by pushing forward polyhedral chains. Uh, polyhedral change. And in particular, then, no, because this is just a sum of Lipschitz images, and so this is a sum of Lipschitz images. So the elements, so this polyhedral change in X are then also Lipschitz M change or induced by Lipschitz M change. And as a consequence, as a direct consequence, we obtain that in such spaces of finite Nagar dimension, which are Lipschitz K connected up to some K, every integral. Okay, every integral current is the weak limit, or actually the filling volume limit of a sequence of Lipschitz of Lipschitz k-chains whose masses and boundary masses are uniformly bounded. But actually, we get even something better, not directly, but with a little bit more arc, namely that we even get, we can approximate integral currents in such space. Integral currents in such spaces in total mass by Lipschitz k-chains. So that means up to a loss of very small mass, every integral current in such a space is a LIP induced by a Lipschitz chain. And we can get the difference of the masses and the masses of the boundary as small as we want. Okay, so now you can really think at least in such spaces as integral currents as, you know. integral currents as limits even in mass of integral k of k chance okay in the remaining time i would like to discuss very briefly the ideas behind the non-distortion theorem here i stated it once again so first of all of course we can assume Of course, we can assume that our ambient space is a Banach space simply by embedding y into a Banach space. Then one can use the finite Nagar dimension condition on X to construct a Lipschitz map from Y to Y, which on X is the identity and which outside of X. Which outside of x, so in y without x, factors through a simplicial complex. So, sigma is an n plus one dimensional simplicial complex where n is the Nagata dimension of X. And H sends the vertices to X. And so we now equipped this simplistical complex with the L2 metric. So, you know, we The L2 metric. So, you know, we view it. Every vertex is an index. And now we take the L2 space of sequences with these indices, and then we take it as a subset, as an actual subset there. So this simplicial complex has actually bounded diameter, and all the simplices are standard Euclidean simplicies. And so this G, this map. And so this g, this map, is Lipschitz, but the Lipschitz constant blows up points very close to x, it blows them up quite a lot. And the further you get away from x, the smaller the Lipsis constant is. And h, which goes from sigm back to y, has exactly the opposite direction. So points in simply t's that come basically from That come basically from stuff that is close to X, while there you map them close together. And when you're far away, then it's the opposite. Okay, I just maybe have a little sketch here. So how do you, I should maybe say that this construction of these maps, this is really follows from techniques of Lange Lichenmeier in their paper from 2000. In their paper from 2005 about Lipschitz extension. So, if you analyze this, you can easily get what I stated there. And so, what is the idea? Well, you cover, you use the finite Nagata dimension to cover. So, here is my X, and this outside here is Y. So, Y without X, you can cover with sets a little bit like in a Whitney Cube decomposition. Bit like in a Whitney cube decomposition. The sets have about diameter the distance to x and they have bounded multiplicity. And then you take as sigma in some sense the nerve of this covering. So I try to illustrate it here. So this red, this red set becomes this. Becomes this red vertex here, the yellow is here, and they all meet. So this makes this two-dimensional simplex. So now you take a and you see what happens here. You have small sets, they all get mapped to simplices of diameter one. And here you have very big sets, and they also get mapped to simplicies of diameter. Simplices of diameter one. And now you take a cycle in X, you fill it with a chain in Y, and now you try to push this chain to sigma via this map G. Of course, when S, for example, already has parts in X, this is bad because there G is not even defined, right? So what you do, you basically restrict S to outside. To outside a neighborhood of X. Okay, so I tried to show it here. You have it in purple. This is everything inside a little neighborhood of X. And so then you take the rest here, which is outside, and I map this with G to the simplicial complex. And what is close to the boundary, but close to X, this gets distorted a lot, and which is far away, this has a very small distortion here. Here. And then you apply the Fieder de Fleming, or a suitable version of the Fieder de Fleming theorem, in this finite dimensional simplistical complex. This gives you this red polyhedral chain here, plus a rest, which I did here in green, at least one part, the other one will be out here. And then you use this map page and either the Lipschitz-K connectedness. Lipschitz-K connectedness or the isochrometric inequality, you can build a homomorphism from the M-dimensional simplices or the polyhedral M-chains back to X by using the Lipschitz K-connectness or the isochromatic inequality. And then you can transport this red chain here. You can transport back to X, okay, then. Okay, then this is a nice so this s was k plus one dimensional, and this image here is also k plus one dimensional, but the boundary doesn't really coincide with t. And then you want to prove that when you go, you cut off less and less, that then this actually converges to a filling of T. Okay, I think I'm basically out of time. I have one. Basically, out of time, I have one minute, so maybe just a little bit more precisely. You take the distance function, you take a chain with boundary in x, and then you cut the part off that is too close. And by maybe pushing it a little bit and doing some construction, we can assume that what actually is close to x has small mass, and you know, the boundary when you cut is also not. The boundary when you cut is also not too big. And then you push your current into sigma. For almost every r, this is an integral current. So you can use the Fiddler-Fleming deformation theorem. And for simplicity, maybe just assume that X has LCK. Then this map page is even defined up to the K skeleton. Up to the k skeleton and maps it into x. And so the push forward is an integral current in x. And then you can prove these things. And well, the weak limit is then exactly a filling of the boundary of S, and it has to write the right thing. And I think I'm already over time. So thank you for your attention. For your attention. Thanks, Stefan. Are there any questions? I have a question. Yes. Um Yes. Yes. Do you have a picture of a nice example with where there is no such deformation, no approximation by chains of an integral current for a bad enough space? Yes, as soon as you're not, you can construct easily even subsets of Rn where Where you can make this happen. So I think as soon as you don't have Lipschitz K minus one connected, then basically you can't do it anymore. So basically one thing that you can do is you can take a ball in Rn and then take a lot of balls out. So basically a dense sequence of balls out such that the Such that the complement or the ball without these small balls has a measure zero and such that you still find a k current in there, which you cannot approximate by Lipschitz change. And you can't, right? Even approximating it within a bonus space. Approximating it within a bound space, okay. Yes, that makes sense. That makes sense. Um, thank you. I think there's a question from Alex. Yeah, yeah, Stephanie, thank you for the great talk. Uh, so the results, are they new even in the Kanziros? So then there's approximation results, they're new also in Kanziro setting and in Banach space setting? And then Bannock space, Seth? No. So in the cat, well, in the Cat Hero space, I think no. I think Thierry Dupeau, Thierry Dupau has some results in this direction for Bannock spaces. And then a student of Urslang, Goldhirsch. Goldhirsch. He has also some theorems where he has very strong conditions on the space. But I think in Banach spaces, it goes back to Thierry Dupont, who used basically, well, okay, he does it in L infinity and uses the metric approximation property. So basically, you take you take. Basically, you take an integral current, say with compact support, and then you use the metric approximation property to project it with only a very small error to a finite-dimensional subspace. And then you can use the result, the classical result that you can approximate by Lipschitz change of Fieder-Fleming using the Fieder-Fleming deformation theorem. Information theorem. And then you connect back because the metric, this projection that you have of norm one onto a finite dimensional subspace, this only moves things very quickly. Thanks. Yeah, and another question. So so does this does this approximation does resolve some other technical issues? So do you? Technical issues. So, do you get something? Yeah, also something. Well, I think if we could get rid of this finite Nagata dimension, then this would be very interesting. For example, then it would follow relatively easily from known results, for example, that if you have that, okay, maybe. Okay, maybe one needs some more, but I mean, one question would be about isoprometer Euclidean isoprometric inequalities passing to ultra-limits or to asymptotic cones. And so now to approximate integral currents in an asymptotic cone by integral currents in the space is very difficult. But for Lipschitz maps, it's very easy. Lipschitz maps, it's very easy. So, if you knew this result that you can approximate, then it would be easy to approximate or much easier to approximate these Lipschitz chains. But of course, as soon as you go into cat-zero spaces and find that Nagata dimension, then you're always in an absolute Lipschitz retraction, and then the results are not so interesting. I think we're running low on time. So thanks, Stefan. Let's thank the speaker again. Thank you for listening. And I think the next talk is Florent Polishev. Hi, everyone.