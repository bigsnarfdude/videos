So, I'll be speaking on Hardy-type ineucalities as a critical cases. So, let us start with a very, very old result, classical result by J.L. Lewis, or maybe even before that, the boundary Hardy inequality. So, it states that if you start with a domain, Lipschitz domain, let's say. Lipschitz domain, let's say bounded domain in Rd, and your range of P is in one to infinity, then the following inequality is true and it's a very classical result. So the feature of this, the main feature of this inequality is that this weight, this singular weight, one by delta omega, basically this is the distance function from the boundary of omega, is singular on the whole boundary. Okay. Whole boundary. Okay. And this result. So now this result holds for the main point is that this result holds for all p in between 1 to infinity. So what I mean by critical cases in the title of my talk, by critical cases, I mean, let's say for this inequality, the critical case would be the case when p is equal to 1. Okay, so what I would like to address by the end of this talk. By the end of this talk, what would be the appropriate inequality to expect for the case p equal to one? But the first observation is that if you plug p equal to one in this inequality, this inequality will fail. I mean, this inequality in this form cannot be true for p equal to one, and that can be seen with an easier example. Be seen with an easier example with an example if you take omega to be zero to one dimensional and some u alpha which which behaves like t to the power alpha near origin and then you can make it a cis infinity function. If you plug it in, then you can see that the right hand side will stay bounded, the left hand side will go to infinity. Okay. I mean but the proof of this, the proof of the critical case which I want to present, actually, I mean, this result, this inequality is the local result. This inequality is the local result, goes via non-local results. So, let us study, let us ask a different question, actually, which is the non-local version of this boundary Hardy inequality. Okay, so this is a result by Bartolomeo Deda in 2004. So, he says that, I mean, it says that if you have a parameter S between 0 and 1, and S P is strictly bigger than 1, and your domain is still a bounded. And your domain is still a bounded domain, uh, a leaf is bounded domain in Rd, then this is the this I call it as a uh non-local boundary HADI inequality. So it's very much like uh boundary HADI inequality in the local case. The right-hand side is the semi-norm of WSP spaces, the left-hand side is uh this weight function, the and you have a sp here, and you see the range is. Here and you see the range is very much like the local case where you have p in the local case, you have p between one to infinity, in the non-local, you have sp between one to infinity, right? So it's very similar like a local result. Now, what would be a critical case? What I will call as a critical case for this inequality is the case when sp is equal to one. So I call the case sp is equal to one as a critical case for Critical case for this inequality. And Deda himself in this paper shows that this inequality, like in the local case, cannot be true if you just plug in S P is equal to one here directly. And he gives a sequence of functions for which the right-hand side will be bounded, left-hand side will be infinity, which will fail. The basic reason is that this weight function, the distance function one by delta, it's too. Delta, it's too singular. It's too much singular. Okay, so throughout this talk, I mean, I'll try to present the proof of the appropriate inequality, what will be the appropriate inequality for the case SP equal to one. But before that, let us review a little bit of literature that were available to us when we started doing this problem. So now, actually, I'm going to. So now, actually, I'm going back to a class to the classical Hadi inequality. So, this is the classical Hadi inequality. The waste constant is also known. Throughout this talk, I will not be concerned about those constants. In all the inequalities that I will be mentioning, the constants will be a C, will be some C. So, this result is true for in the range P equal to 1 to D. And so, the critical case would be the case really when let's P equal to D. To D. And in this case, there is a result by Adimurti, Maithili, and Nirmalendu, where they show that if you are in the case P equal to D, P equal to D, the appropriate inequality is this one, even a stronger version of this one. I just wrote a basic one. You have to kill the singularity. One by x to the power p is too singular. So you have to multiply it by one by log x terms. Basically, a term, you make it less singular. And then the appropriate inequality is this. Appropriate inequality is this one. Okay, so basically, the upshot is that a lot of correction is required in the case of classical Hardy inequality. And in the case of fractional boundary Hardy inequality, fractional HADI inequality. So, fractional HADI is the case when the singularity is from the origin, one by so. One by so zero is the only singular set, one by modex. Okay, so uh in this case, the result that is known, uh, the it goes back to 1999, the paper by Edmund and Tribal, where he considered the case S P equal to D. And he shows that again, like in the case of the local case of point Hadi, point Hadi means the singularity is from the origin. This shows that you again. The origin. This shows that you again need a log correction. And he, the techniques that he uses is techniques from interpolation spaces and so on. Okay. And then finally concludes the result. But the one, the paper, a really recent paper by Y Min Nguyen and Marcus Swasina, they also considered the case SP equal to D, and their technique is really the techniques from calculus. And they study more generally capricon nearby inequality, not only Hadi. Nielmanic inequality, not only Hadi, the full range Kafer Eliconic Nielenberg inequality, and they consider the case S P equal to D. And their paper has also, this is a part of this paper, their paper has, they also consider the case S P less than D and S P bigger than D. And they show that when you consider S P equal to D, then also you need a log correction like in the local case. Okay, so again, the upshot is that so these are the three results that were known to us, which dealt with the critical cases. Dealt with the critical cases. Okay. And all of them have the same feature that when you go to the critical case, you need a log correction. Okay. So given this scenario, now let us come to our, let us come to study the problem that I stated the boundary HAD inequality for the non-local boundary HAD inequality. Now let me. Now, let me. Yeah, so the inequality, let me show you once more the inequality, the non-local boundary. So, this is the inequality, non-lique boundary had inequality for which I want to do the case sp equal to 1. Okay. Yeah, now the point is that, as I said, the kernel one by delta omega. 1 by delta omega in this inequality is too singular. So basically, at this point of time, it is clear that we have to multiply by a function 1 by psi x, which goes to 0 near the boundary to make the whole thing a little less singular. But there is one more problem in this case, which was not present in the three results of Edmund, Skasina, and Adimuti that I stated, was that so. Was that so? If you close, I mean, I write it this things for CC infinity, but basically, this inequality, whatever we are trying to prove, would be true for us on the closure of the CC infinity with respect to this norm, WSP norm. So the additional problem is that in the case SP equal to one, the space W0 SP, that is the closure of CC infinity function with respect to this Gaddafi seminar with the full norm and WSP, they become the same space. So basically for SP less than or equal to one, the SP less than or equal to one, the WSP spaces take the character of more like LP spaces, where they don't have a trace. And when SP becomes strictly bigger than one, they have the character of W1P spaces, where CC infinity function of CC infinity function is really a strict subset of W1P, provided omega is a bounded subset. Okay. Okay. So the constant functions are in this space W0SP. So in other words, the inequality that we will be trying to prove would be. The inequality that we'll be trying to prove would be also true for the constant function, which says that an additional LP correction would be required, whatever we are trying to prove. Okay, now what is the shy? And as I said, that one of the natural candidates sitting for the choice of one of the shies, log, because log has appeared in all the three results. At least, this is what is known to us till now, also, the previous results. Log has come. Log has come. And then actually, this is the result that we prove for the dimension one, it's by Adimurti and Jana, with Adimurti and Jana, and for dimension B bigger than one with Adimurti and Vivekshahu. We prove that the following inequality for SP equal to one is a critical case. We don't see S here because we don't see S here because S P is equal to one being used here. So this, you see. Used here. So, this you see that I have for S p equal to one, this is the power is one and the extra log correction. And we have this inequality. So, I would like to guide, I would like to give the proof of this, at least some parts of the proof of this result. And one more comment is that this weight that we prove here is optimal. In which sense, in the sense that once I have. In the sense that once I have killed a little bit so once I have killed the singularity of one by delta by multiplying one by log, so it may happen that I have killed too much. Probably it is still possible that if I can make it a little bit more singular by putting another function f which goes to zero near the boundary, right? So, but this is not the case. If you cannot have another function f. You cannot have another function f multiplied here, which goes to infinity as x goes to the boundary. So the result is optimal in that sense. And now I would like to take you to the proof. The idea of the proof comes really from the paper of Naguen and Nguyen and Squasina. So what they do is that so I'm presenting So, I'm presenting the simplest case of the proof in the dimension one, zero to two. So, they do a direct decomposition of the first of the interval zero one. So, this is an direct decomposition of the interval zero because for k equal to minus one, you'll get t to the power zero, which is one. So, only half of the interval. Okay, and then and then start with estimating the left-hand side of the required inequality. So, my required in my left-hand side is this thing, I mean, dimension one. This thing, I'm in dimension one, so this is the appropriate term because delta in dimension one it is like from distance from zero is modest. So I have this. So start estimating this term. So the first step is trivial. You just x is in a k. So x has a range. So you pull out the weight function in some fashion and then you use a triangle inequality and some convexity to get this step. And then And then, on this thing, on the first thing, you use Ponka inequality. Ponker inequality, and the main feature of these three steps that the constant that you get here is independent of k. That means independent of the domain. I mean, in general, when you do Ponker inequality, Ponker inequality depends on the domain. The constant depends on the domain. But here, I have a diary decomposition where A k is becoming smaller and smaller as I go near the origin. But the constant that will appear will be. But the constant that will appear will be will be independent of K because it uses precisely the case that we have, where in the case SP is equal to 1. Okay. And then just sum this inequality over from m to minus 1 to get this. Now, this term, so just from this, I take the summation from over 2 to the power m, m is a negative integer and it will go. is a negative integer and it will go to minus infinity it will go to minus infinity so so this left hand side is going to the after fuening it will be going to the integral of 0 1 and this term is just the sum and this term can be dominated by the full WSP norm of 0 2 because many cross terms are being left out and this term is the important term and this term estimate of this term needs to be done so and we'll will be done if we show that Will be done if we show that this term is dominated by the full WSP norm. And once we show that this term is dominated by the full WSP norm of in the interval 0, 2, then we are done. Then basically we get this is less than a constant times WSP plus the LP norm, right? As expected. So the key step in doing this is precisely estimating the average. So this is this is the average. So, this is this is the average. This notation is the average of u on two subsequent AKs, one and another. So, this step is using Jensen inequality and triangle inequality, some convexities. And then once you sum it over, and from this step, you go to this step by using the appropriate inequality of the form A plus B to the over P is less than constant time A to the over P plus some convexity inequality will give you this type of inequality after taking. This type of inequality after taking a summation. Okay. And then the nice part, then the beautiful part of it, the thing is that, like the magical thing that happens is that in this summation, you see that the first term for k equal to m is this. And then all the terms from m plus 1 to minus 1 matches with the from the first term that starts here until the minus 2 term here. So you can actually take everything to the other side and get this constant precisely, which is. Get this constant precisely, which is exactly the behavior of this constant, is like this, and which gives you the exact estimate of the term u that you required in my that I required in my previous step. So, and then that get an one term at the end for k equal to for k equal to last m equal to minus one, you get this term, and which actually gives you the. gives you the LP term which can be dominated by the LP term from here to here. Okay, so that finishes the proof of that finishes the idea of the proof of the boundary Hardy inequality and this is the optimality part. And I said in my result is that in this result, this is an optimal inequality. This is an optimal inequality that you cannot, it's not possible that you can multiply another function f here, which goes, which is, which becomes singular near the at the boundary, and still get an appropriate, and still ensure that an equality like this would be true. And what is the proof of this would be the following. And the proof of this is actually stems from a different question of asking, I mean, I showed Of asking, I mean, I showed in the beginning of my talk that in the critical range, when I'm in the case SP is equal to one, that W0 SP is the same as WSP. That means that the constant functions are being approximated by CC infinity functions in WSP norm. So if you ask yourself the question that, let's say, in a simpler domain, what is this exact sequence of? Can I write down the exact sequence that approximates these constant functions? And one can show that, for example, in Show that, for example, if it's in the domain zero to two, I'm doing, if you do like a linear cutoff to approximate the one function, they will not approximate. They will not approximate, what you need is a log cutoff. And that sequence is I have written down. You need a log cutoff to approximate the constant function. And asking this question is actually has the implication of Has the implication of finding the optimal constant in the inequality that I stated. So basically, if you plug in this u epsilon and you make this calculation, so okay, so there is a little bit of change. So the inequality that I proved, just I make a comment and then I go to that. In the inequality that I proved here, you can neglect this term and you can think as This term, and you can think as u minus u average of u, right? Because you can, in this inequality, you can just put u minus average of u. I mean, like in Ponker inequality, subtracting the average or putting the LP term on the right-hand side, they're basically the same thing, right? So, I chose to prove this version, but the calculation that I'm going to do in the optimal case is with the version when u is subtracted with the average of u. Okay. So, basically, that's what in the case, I mean, I'm showing the calculation in a. In the case, I mean, I'm showing the calculation in a very simple case when p is 2 when is 0 to and sp is equal to 1. So the left-hand side is this, and you can get the exact asymptotics. One can do the exact asymptotics in terms of epsilon of the left-hand side. The right-hand side is also the same asymptotics. So once you see this, and then you say that, okay, if I had another F which was singular near zero, then this asymptotic will break. You can see immediately that the left-hand side will go to infinity, right-hand side will be. Hand side will be bounded or something like that. Okay, so basically, the upshot is that this sequence of functions, if you plug into your inequality, you get the exact asymptotics in terms of epsilon. That plays a crucial role in proving the optimality result. Now, yeah, so now we are at this stage. We prove this result. The for the case sp is equal to one for. P is equal to one for more general domains, for domains in Rd, Lipschitz boundary Lipschitz domains in Rd. Now, at this point, we can ask the question again, a further critical question. This inequality is true for P bigger than 1, because S P is equal to 1, S is less than, P has to be bigger than 1. We ask the question, what happens for the critical case P equal to 1? I mean, for this inequality, P equal to 1 is the critical case. We can say that this is a critical case. So, why are we asking? So, why are we asking this question? One we proved our theorem. So, this, if I when I write L1, Lm, these are log terms. So, basically, log of this L M minus means log, log, log until m minus one times. So, that's the notation. We proved that if you have a beta strictly bigger than one and m is bigger than or equal to two, so the following inequality is true. And what is the difference between? And what is the difference between this inequality and the previous one? Here, you don't see a p, you see a s. And basically, this is a result you can see in the WSV space. So, s into p in my in my previous result. Sorry. S into p in my previous result was one, was the critical case. But in this result, we are asking a question at the subcritical level. So, s into p is s and s is less than one. So, s p is strictly less than one. And when you are in the subcritical level, And when you are in the subcritical level, SP less than one, then this is the appropriate inequality. You have a, this is how the weight functions can be. Okay. And the proof is again, the idea of the proof is again, the kind of idea that I have presented in my previous two slides. You do appropriate calculations and you prove this. But the good part of this thing is that, of this result, is that we got after doing making all these calculations, we got. After doing, making all these conclusions, we got one minus s as the appropriate constant here. And that helps. And that is a big step. It helps. Because once I take, now I'm free to take the limit of s tending to one as s goes to one minus from the left hand side. And then once I take from the left hand side as s tend to minus one, I can see immediately that this term after using Bridgesburg and Mironasku Davila, the celebrated goes to the B V norm of you. V-V norm of U, right? So, what does it give me? It immediately gives me that this inequality is true. I mean, this inequality, this theorem is just a consequence of this theorem is just a consequence of taking S equal to one, taking limit S tending to one in this inequality, in this inequality, right? And this inequality, which I started in one of the first slide of my talk. First, talk of first slide of my talk that the critical case for p equal to one in the boundary hard inequality, right? You see, this is no more a non-local result, it's a completely local result. It's completely a local result and in the space of bounded variation. So, you see that I have one by delta omega, which was there for p equal to one. But the additional correction for p equal to one that needs to be done is this, this log term. Okay, uh, yeah. Okay. Yeah. So this is the result. And in fact, the techniques that I prove is quite, I find it quite powerful. And I mean, there was a result. Just I give a last comment and finish the my talk and I'll finish my talk. I mean there was a result. So basically I have presented a Hardy inequality. So this is the singularity at the boundary, boundary had inequality. And I presented a result of point Hadi, like whether the singularity is the origin. But in the Singular cities origin. But in the paper of in the local case, in the paper of Philippis, Barbadis, and Tetikas, you can actually consider a k-dimensional sub-manifold of a d-dimensional domain omega. And then can do a Hadi inequality. So these techniques can be actually taken further to do such a thing also. You can actually, and you will see that S P equal to That sp equal to one is the critical case because you have the d-dimensional d minus one-dimensional set as the as the singular set. When it's a point, it's a zero-dimensional set. So, sp equal to d is the is the appropriate thing. But if you have a k-dimensional sub-manifold and if you consider Hardin equality from k where the distance function is replaced here by a d time from a k-dimensional sub-manifold of domain, then the critical condition would be sp equal to k. So, you can we can also do this. So, you can we can also do this distance from this from sub-manifolds using the techniques that I have, the main techniques that I have introduced before. And this is what I actually wanted to present. So, thanks a lot.