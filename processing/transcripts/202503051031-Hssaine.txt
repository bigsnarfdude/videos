Let's see Marshall talking about target quality online resource education, which is prophecy assignment. Thank you so much. Thanks to the organizers for an amazing workshop so far. Today I'm really excited to tell you about a project that came out of my postdoc at Amazon on target volume online resource allocation, D Proxy assignments. It's a mouthful. I'll explain a couple of these terms in due time. This is joint with Garrett Van Reisen, who's my manager at the time, and she's saying select to Palo Lu, who's also Saying hello to Palwoo, who's also an amazing collaborator on this. So, to motivate this work, I want to give you some context around a problem that Amazon was having at the time, which is what they call case breaking at crosstalks. So, if you're not familiar with what a crosstalk is, these are basically just these massive warehouses that Amazon owns and they serve as the first point of contact that any seller or vendor has with the Amazon network. With the Amazon network. So there are very few of them in the network. There are approximately 20, as opposed to hundreds of downstream fulfillment centers, and they process a huge amount of units each week. And the way that it works is that sellers or vendors send in their shipments in very large cases to these crosstalks. So here I'm using units to unit a product. Think of an individual product as a unit. And these cases are prepared for transfer to downstream FCs. Transfer to downstream FCs. And what I mean by whether or not a case is broken. So, right, so the first question that's asked about each case when it arrives is whether or not it should be broken and how. So, to break a case means just physically opening up the case and splitting it into different units to be sorted and transferred. So, if a case is broken, that means the units will be split and sent to multiple downstream. Sent to multiple downstream filament centers. And if it's not opened, if it's not broken, the entire shipment or case will go to a single downstream film center. And again, so it can be performed in a number of ways. A human being can do this. Robotic machinery can do this. Either way, it's very time and labor intensive. And this is a really impactful decision for Amazon because it's made on the order of tens of thousands of times per day for each crosstalk. And moreover, Each crosstalk, and moreover, whether or not a case is broken impacts downstream inventory positions, right? Because if a case is not broken, only a single FC will get those units. So this is a problem that matters a lot to them. And how do they determine whether or not a case is broken? The first thing that goes into this decision is what's known as an assignment cost for breaking the case. So this depends on both the resource that On both the resource that is making the case as well as the case type. So, for instance, if a case is very large, if it's over 20 pounds, there's a specific robotic machinery for that 20-pound case. And moreover, right, so as I mentioned, the inventory positions will determine whether or not the assignment cost for breaking is high, right? So, if multiple fulfillment centers really need those units on that day, the cost for breaking that case will be very low. For breaking that case will be very low. If a single fulfillment center really needs that case as opposed to multiple, the cost for breaking will be very high. So, Chance to understand the cases because individually sorting out packages or data. Exactly, so individually sorting units to go down to multiple places. That's the 20 pound units seems to not be that heavy. Yeah, but the for robotic machinery works better than others. Okay, and so that would be and robots. Okay, and so that would be, and robots would be much better at doing that than human beings who sort of very slow. Okay, and so the other thing that goes into this decision is what's known as these targets. At a very high level, Amazon uses targets for two reasons, to load balance amongst resources, as well as to coordinate with downstream execution systems. I'll make this more clear in the next slide. But at a very high level, think of High level, think of a target as some advice or some guidance as the fraction of cases or shipments that should be broken by each resource by the end of each product, by each hour, right? So it's just sort of advice on the assignment rates. Sort of concretely, think of these targets as schedules that will say if manual labor is a resource, by the end of 9 a.m., manual labor should have processed. Manual labor should have processed 10% of all arrivals. By the end of 10 a.m., it should have processed similarly 10%. By 11 a.m., maybe people go out to lunch, and so that drops to 5%. So that's what these targets look like. The percentage of kids is Broken? Yes, correct. By that resource. And the remaining 70% don't get Broken. Do not get Brogium, correct. Yeah, yeah, yeah. Okay, cool. So why did you get the broken body? Okay, cool. So, why do they work with these targets? So, first of all, notice that these are not hard budget constraints. They don't say that a human being cannot process more than 100 units per hour. So, this is the idea that the rate of assignment is what really matters in many physical processing systems. You can always flex labor up or down. And these rates also allow us to encode trade-offs, such as assigning too little means cost to the island of. means costly idling of resources and assigning too much means costly backlogs could occur. Notice moreover that these targets can be non-stationary and in fact in the data we see that they're highly non-stationary and so the reason for that is that staffing levels can vary wildly throughout the day, right? So the timing of assignments or case breaking is going to be very important here. And then finally the fact that they're cumulating And then finally, the fact that they're cumulative is very important. And the reason for that is again related to backlogs, right? So if we didn't model these targets as cumulative, essentially if we over assigned, our system would not be penalized for over assigning work that still had to be processed in the next hour. Chelsea, can you explain what cumulative penalty is? Right, yeah, so it's a running average of assignments. So notice that here I'm not saying that. Here, I'm not saying that I need to process 10%, I need to break 10% of resources at 9 a.m. I need to process 10% of resources between midnight and 9 a.m. And then when I move on to 10 a.m., it's not at 10 a.m. It's between midnight and 10 a.m. So that includes everything that was processed beforehand. That's what I mean by cumulative. I realize those numbers are just examples, but when you say that overall the time. When you say that overall assignments between 12 a.m. and 11 a.m., 5%? Yeah. That requires a lot of packages to show up between 10 a.m. and 11 a.m. with you at 10%. Yeah, yeah, yeah, correct, correct, yeah. Okay, yeah, yeah, yeah. And so all of these things that at a high level you can think of as like a model-free or interpretable way-to-load balance, right? So this is just saying, like, I don't want to overload my human beings, I don't want to overload my robotic labor. And you can ask, okay, so why? And you can ask, okay, so why would you not model this via cues? You could do that if all you cared about was load balancing, but these sort of targets also act as an important coordination mechanisms for downstream execution systems. So all that means is that downstream systems plan with the expectation that approximately these targets will be hits by the end of each hour. Yeah, I'm not. These targets are like upper bounds or also. So, what they use on the ground is think of it as like absolute deviation from the target. So, again, they're not hard constraints. You need to assign at approximately this rate, and you don't need to assign at exactly that rate. Okay, and so while this was the motivating problem, this is what we solved at the end of my post talk. I'll note that targets are used everywhere in the Amazon network. They're used to determine, for instance, what. Used to determine, for instance, what fraction of shipments should be sent to different cost stocks or different fulfillment centers. They're used for last mile reasons. So, this is just a helpful way for Amazon to plan this keyboard. Great, so doing well according to either of these metrics is quite easy. You could either assign very greedily according to the assignment costs, or you could load balance very aggressively to make sure that you pay. Aggressively to make sure that you hit these hourly targets exactly, but trading off between the two is what's challenging, which is what motivated our problem. We wanted to understand if we could design fast, lightweight algorithms that optimally trade off between these two considerations. And fast and lightweight is really code for primal dual algorithms, right? So we want to avoid these sorts of large-scale convex programs that need to frequently be used for. That's the high-level question. So that's the high-level question. The motivation query? Yes. Don't these cases have to be broken eventually somewhere? So they will be broken eventually somewhere, but downstream in a fulfillment center. So what's the cost of, if you break that too soon, then you have all the parts going the same place. Is it cost to want to ship parts after the case is broken? Is that the cost? So the reason that you wouldn't want to do that is that that uses up labor in the Uses up labor in the warehouse, in like that crossock that could be used to break something else. So that's the reason you would want to do that. Okay, so I'm next going to actually formulate the problem mathematically, situate this within the literature. I'll spend a bit of time describing why this problem seems fundamentally hard. Why this problem seems fundamentally harder than what's been studied. Describe our algorithms, these are the proxy assignments that are in the title. And then I won't have time to discuss experiments, but this was, I think, a very exciting part of the project is that we were actually able to get some real world data at Amazon and see substantial gains relative to what they were doing at the time. Okay, great. So, what's our model for this? We have a discrete time horizon, a sequence of arrivals, one in each. Arrivals, one in each period. So an arrival is a case or a shipment that needs to be broken, and you have M resources that can break this shipment. Each arrival has a type, and a type is defined by a vector of assignment costs associated with breaking. The no-break decision has a cost of zero, and so we'll allow these assignment costs to be negative. And so these types are drawn IID from an unknown distribution. What's the target following piece? So, our horizon, so think of the horizon as a day's worth of arrivals. Each horizon is partitioned into k epochs of equal length, and epoch is like an hour's worth of arrivals. And so we have these exogenously given targets that specify the assignment rate for the resource by the end of each epoch. Let me be very concrete about this with an easy example. So, this is my Easy example. So, this is my little robot. He's the only resource that can process shipments. If we have four time periods and two epochs, suppose the first target is 0.5. The way that I would hit that target by the end of the first epoch is obviously to break or to assign at a rate of 0.5. My second target by the end of the second epoch is 0.75, which means that I should accept at a rate of 100%. Of 100% in the second week. As Andres asked, we don't need to hit these targets exactly, but if we don't, we incur some target deviation cost for each resource at the end of each epoch. Think of this as the absolute deviation between my actual fraction of assignments and the targets. This is just prorated by the number of periods we're averaging over. Periods we're averaging over. In the paper, we allow for general Lipschitz convex functions with additional dimensional regularity conditions that are quite mild, but for the purposes of this talk, you can just think of this as absolute deviation from target. Sorry, is the number of items of each epoch deterministic? Correct, yeah. So you have, yeah, yeah, yeah, yeah. So you have capital T over K items. Our results actually allow for like a random. Allow for like a random number of units. Like, you can accept a results for a random number of units in each arrival, and that can be drawn from a distribution as well. And as long as that's sort of valid, that's totally fine. But think of it as like a single shipment arrives. That's one thing that it's processed. Okay, so you have any defects or not? Oh, you have constant images. Constant, yeah. Yeah. Okay. Cool. So. Cool. So the goal is going to be to minimize. So why is it that you're modeling the targets as something exogenous? Because the targets seem something soft. How are the targets? Yeah, so the way that it works is that these targets are typically determined ex-ante via some forecasts. So like Amazon has forecasting systems that thinks it'll get these, you know, a certain number of arrivals over. A certain number of arrivals over that day, and it'll solve some like fluid LP and then say, well, this you know, you should try to track that. Yeah. But so, I mean, this is a very good point because it is true that on the fly, like within the warehouses, these targets can be adjusted given. But I think, you know, that's that's what it's all about. But is is is to plan, like it's because you plan beforehand for how people you have before. Yes, exactly, exactly. Yes, exactly. Okay, cool. So we want to minimize assignment and deviation costs throughout the horizon, and we're going to benchmark against the hindsight optimum that has access to the entire sequence of arrivals at the PDAFT. Okay, so how does this compare to the literature? Obviously, an extremely rich line of work on dynamic resource allocation. What I want to highlight is typically what's been considered in the literature very appropriate for airline revenue management. For airline revenue management, online advertising is minimizing some cumulative assignment costs or maximizing some reward, subject to some end of horizon budgets constraints. So this is not what we have in this setting. We would fall under the subclass of regularized online allocation, which basically says that in addition to the sort of separable reward maximization, we have some non-separable convex or concave regularizer. Concave regularizer, right, which acts on the average assignment throughout the horizon. So the case where k is equal to 1, so think about having a single target at the end of the horizon for each resource, has been studied. That spells are et al. in 2021, and sort of a number of papers similarly essentially think about end of horizon regularizers. And so as I mentioned, And so, as I mentioned, Belser et al. 2021 showed that you can do no better than t relative to the hindsight optimum in expectation. Okay, so because k is equal to 1 is a subset of what we consider, which is constant k, this is also going to be our lower bound. We generalize this to be very clear to capital K difference regularizers, where you have a regularizer acting A regularizer acting each T of capital T over K periods. So that's sort of the contribution, very simply put, generalizing work for K is equal to 1 to K greater than or equal to 2. When we started this project, we actually thought that this would be a trivial extension. This was really meant to be just a practical contribution for this case-breaking problem and target following more generally. What we actually realized early on is that these primal On is that these primal dual base methods using state-of-the-art for k's equal to one will fail quite poorly, right? So naive extensions won't work. And I'll illustrate that shortly. This motivated this algorithmic contribution of proxy assignments, which seems generally useful when you have these sorts of non-stationary capacities and writing brisers throughout the horizon. And as I mentioned, some nice results on real-world data. Results on real world. Right, so let me illustrate what goes wrong when you have multiple targets. And I'll do that by illustrating that the natural Lagrangian-based algorithm that you would think to apply here. And again, this is an extension of k is equal to 1. What I would do here, that the most obvious thing is to set up my offline optimum, minimize assignment cost plus deviation costs. Plus deviation costs. Remember, what's hard about this problem is that these two problems, doing well on these separately is easy, doing well on them together is hard. And so I'm just going to decouple these two problems by proposing an auxiliary variable, A, which represents the running average assignments by the end of each EPI. And then I want to make the problem easier by Lagrangifying this constraint, and then I can solve these two things separately. These two things separately. So, what's the primal dual algorithm that arises from this? I'm going to maintain a shadow price that's going to represent the extent to which I'm deviating from this constraints in each period. And then in each period, I'm going to observe my arrival and the associated costs. I'm going to shade those costs by the total impact that it has on future epochs, if K is my current epoch. If K is my current EPOP, right? So this again just arises from the Lagrangian relaxation. I'm separately going to solve a target minimum, a deviation minimization problem, which basically says what load should you try to get for each future epoch. And then finally, I'm going to update my dual variables to reconcile these two decisions. So if I over-assign today relative to future periods, my dual variable is Periods, my dual variable is going to decrease. So I'm going to start rejecting in the future. If I underestimate, it's going to increase and I'm going to start accepting. So that's sort of the natural primal dual algorithm. Let's see how it does on our trivial example where, remember, this was, I mean, like, we can solve this problem offline, right? So I should accept 50% of arrivals and then 100% of arrivals. So I can do optimally on this. It actually performs very It actually performs very poorly. So rather than converging to an assignment rate of 0.5 over here in the first epoch, it converges to an assignment rate of 0.625, which is the average of both targets. And so you can show that this convergence to something that's a constant away means that you incur linear regrets. Incur linear regrets for this very easy problem. So, if you change the dual variable update to the first-order method that has last iterate conversions, would that fix the issue? No, it would not fix the issue. Yeah. Maybe we can talk about your specific idea offline, but I don't think it'll. I'll show you what the issue is now. Okay. So, the main issue is that this obvious extension tries to simultaneously track all targets at each period, even though the future target is a future target. Though the future target is a future target, it doesn't understand that. It thinks that they're targets for my current equipment. And the way that this is encoded in the algorithm is that in each period, I'm sort of penalizing my decision by all future targets. And then I'm using the same decision to reconcile with all future targets. So that's the problem, right? And so this highlights the main challenge. And so what we show in the paper is that the only fixed point to these equations is one that actually averages. Is one that actually averages between targets. That's the only way to do well, if that's the true problem. And this highlights the main challenge relative to having a single target at the end of the horizon, is that you only have one decision. I have one decision I can make today, accept or reject. But that impacts multiple targets over different time scales. And so having a prime control algorithm understand that a future target is indeed future. Future, right? And will be accounted for or could be adjusted in the future is the challenge. Are there any questions about this wide sample? Yes. Just one clarification problem. I mean, in practice, why would I penalize if my utilization is below the target? That's beneficial for the overall cost? So, yeah, yeah, so that's a great question. So, I'll note that in general, this needs I'll note that in general, this need not be the case. So, utilizing under-assignments, yeah, so that's not necessary, and our results allow for just utilizing over-assignments. So, general lipships context founded function is fine. Here, again, because it matters for like downstream execution systems, they basically assume that what they'll receive approximately hit those targets. And so that's where they care about absolute deviation. But I need not be the key to that. I need not need a key step. Wait, so have we tried resetting the dual validators from one epoch to another? That's not going to work yet. This actually does reset dual variant. So let me show you the fix, right, using what we call proxy assignments. So this notion of proxy assignments is actually very simple. Think of it as predictions of what It is predictions of what my algorithm is going to do in the future, and using those predictions of future assignments in my decision today. And this is similarly a primal dual algorithm, but slightly different. So we're using this notion of an auxiliary variable still, but now this represents the average load in each epoch. So it's no longer a running average, and that's going to allow us to decouple future epochs. Future epochs. And we're going to maintain a dynamic dual variable still. And in each period, not only am I going to observe a current arrival, I'm also going to replicate a future proxy arrival. I'm going to fake an arrival for each future epoch, right? Which basically says, if I saw this arrival in a future epoch, what would my algorithm do? And this is the prediction step. For each problem, For each proxy arrival, I'm going to solve a separate assignment cost minimization problem, or shaded assignment cost minimization. And notice the main difference between the bad algorithm before and our algorithm, I'm not using all future dual variables in my primal assignment decision. I'm only using the dual variable associated with the relevant EPOC for each proxy arrival. So, this is the key step, the decoupling, that is going to predict independent decisions made in future epochs. Now, and so importantly, again, like these proxy arrivals are only for prediction. I'm not implementing any of them. I'm only implementing the decision associated with my current pot. Yes, yes, no question. I was trying to understand your algorithms. Yes. Can I view it as? Can I view it as for each epoch? So right now you have these cumulative targets that are preventative of your problems. Correct. Can I convert them into per epoch targets and then try to follow the per epoch targets? So we should that's going to perform very poorly actually. So you could say like if I make them per epoch targets and make sure that the per epoch targets are going to achieve the overall human like you did for your example right your per epoch. Example rate. Your period of target that was implied was 50% and then 100%. If I can figure that out, and then use my algorithm on it. Which I think use the normal algorithms. I don't think that would work, yeah. So biopic wouldn't work, but converting into, because you still would get that mixed game. But for a future epoch, you're going to assume that you hit the target and subscribe. So I'm not sure. So you're saying, so what we do is in our So, what we do is in our experiments is convert the running average targets to per epoch averages, and then go ahead and run like a myopic algorithm in each epoch. And that we show performs very poorly. So that encourages linear requests. Yeah, I was actually just trying to understand your algorithm, so I have obviously not understood it. Because I'm not done. Yeah. That's one minute. No. That's one minute. No, I'll show an example, Yash. But yes, please speak about Yash. Oh, Yash, I was just kidding about it. Okay, so then we're going to solve a deviation cost minimization problem. So here, this looks slightly different from what I had before, but it's just a reformulation to account for the fact that I'm considering the average load in each clock. And this is the recoupling step because it's determined jointly across. Determined jointly across all epochs. And then finally, I'll update my dual variables as I did before. And again, the main difference here is that remember, before I was using a single assignment decision to reconcile with all future epochs. Now I'm using only the proxy assignment decision associated with epoch K prime to update my dual grade associated with epoch K prime. Let me show an example of this. Let me show an example of this. Again, this is my remaining example throughout the talk. What's going to happen is, I'm going to observe this arrival. I'm going to simulate a proxy arrival for the future, and I'm going to solve two different assignment cost minimization problems. Maybe I've accepted both. And then I'm going to ask, well, have I over-under-assigned in each epoch? I've over assigned for epoch one because I've assigned it 100% when I shoot. At 100% when I should be hitting 0.75. And similarly, for epoch 2, I've projected over-allocation, right? Because I've allocated 100% when I need to hit 0.75. I go ahead for period two. This is my real arrival. This is my prediction. Maybe I start rejecting. These are separate problems. So let's say I've rejected these. Maybe you mentioned the projected. The projected arrival? Is it just another IAV? No, it's not an IAV. So we don't know the distribution. You can imagine we can sample from the past. But it's actually even stupider than that. We're literally replicating the exact same arrival. Yeah. So now I'm done with epoch one. I move on. I see that in epoch two, I've projected that I've allocated at a rate of 50%, so I need to start accepting. And this is my last view. And this is my last epoch, so I don't need to project anymore, right? So I can go ahead and solve essentially a single epoch problem. And this does the right thing for the dumb example. In particular, it converges to a rate of 0.5 and to 0.75. Yosh, is this clear? Do you have any more questions? I think I have missed a few pieces. Okay. Is it basically that you're doing multiple? Is it basically that you're doing model predictive control framework? Yeah, yeah, yeah. I'm basically doing model predictive control within the primal tool within the primal tool frame framework. That's correct. So in cases where in the fluid limit you can achieve all the targets, it reduces to basically... I mean, a way to view it is that you reduce it to a period target. In cases where you cannot have to do the full calculation and that's correct. But we'll see actually that, like, in practice. See, actually, that in practice, frequently, you cannot hit all the targets simultaneously, but that's exactly the right interpretation. Yeah, so it might be related to what Jash just asked, but it seems like there are two questions the way I understand them. One is sort of a very complicated question of for every possible thing that arrives, do I or do I not? And like, I want to hit build respective targets for them. The other question seems much easier, which is in each epoch. Is in each epoch, what fraction of cases do I want to break? And that, it seems like it's a very simple optimal LP to solve because there are only like, I don't know, 10 epochs or 15 epochs over the course of a day. Sure. The offline is just a convex program, correct? Yeah. So would it make the problem a lot easier to solve that and then just That and then just within each epoch, just ignore what happens in future epochs entirely and just focus on hitting that target. Yeah, so we tested that algorithm, and that algorithm performs very poorly. If you try to modify the targets to just figure out what you should hit in each epoch and then solve for that epoch ignoring all targets, that would perform very poorly. In simulation, please. But we see linear, but we observe linear regrets. Simulation, but we observe they regrets. Yeah. So would the algorithm that just suggested, would that basically be fine for this example where we have like a thousand and then a thousand? And is the weakness of that more when there's more epochs and fewer items per epoch? So if you're that would be fine if you could hit all targets, which is what Jash said. But if you cannot hit all targets, it's a problem. Okay, so. Okay, so the main result is that this achieves the optimal regret guarantee. I'm over time. I won't be able to say anything about the proof, or I'll say very few things about the proof. So the way that we show this is basically balancing regrets via two sources of laws. The first is to say, well, what if I could implement these proxy assignment decisions? So, with respect to some proxy offline optimum that we define, how does my algorithm do? And we actually. Algorithm do. And we actually show that what our algorithm is basically doing is solving k single epoch problems for some well-defined proxy offline optimum. The other source of loss uses the fact, as Rod points it out, that our proxy assignment decisions, or proxy arrivals, excuse me, are not exactly the arrivals that we'll see in the future, right? So these were incorrect predictions. But the idea is because these arrivals are IID. Because these arrivals are IID, that's not going to be too bad. And so both of these incur regrets of Route's VFT. And let me just wrap up. So I think at a high level, even though sort of this problem was motivated via case breaking, I think more generally, when you have these sorts of non-stationary capacities, proxy assignments seem to be a useful framework. Another way to think about it is essentially MPC within the primary framework, as Yesh said, and they've already And they've already found applications at Amazon elsewhere. In terms of future work, I think thinking about what this algorithm would mean if you have non-stationary arrivals, how to modify it. As Tipate just said, moving targets, endogenous targets, that would be interesting. Let me wrap up here. So thank you so much for all your questions. Is it actually smarter than the mid-predictity control because I think it can be a little bit more? Uh meet with the control because you can't see with the features. You have to find a smart way of having