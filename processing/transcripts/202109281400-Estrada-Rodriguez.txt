Thank you very much. Thank you very much for the introduction and also thank you for inviting me to give this talk. I hope next time we'll be in person in Mexico, hopefully. Okay, so I'm going to present some work I did during my PhD in collaboration with Heidelberg. In collaboration with Heiko Gimperlein, with Kevin, with Jakob Stoszek, and Dernesia Strada. And actually, the end of the previous talk fits very well with what I'm going to talk here. So thank you very much, Jay. So my talk will be divided mainly into two parts. So in the first part, I'm going to derive Derive macroscopic PDEs from the non-local individual movement of organisms. In particular, I'm going to focus on, well, I'm going to derive fractional chemotactic equations for the case of the bacteria E. coli and also space-time fractional diffusion equations for the case of T cells in the brain. Moreover, I'm going to also Moreover, I'm going to also compute biologically relevant quantities from these equations. In the second part of the talk, I'm going to study these diffusion and super diffusion processes in general in more complex domains, in more complex environments. And for that, I'm going to introduce a new notion in networks, which will be In networks, which will be a network of subdomains, but we will get to that later on. So, I know that everyone in the audience is very well familiar with this terrorist and with this introductory part, but I always like to go from the easiest to the non-so-easy. So, chemotaxis just describes the bias movement of organisms in response to a chemical. Organisms in response to a chemical gradient in the medium. And in the classical case, we have an individual that starts at some point, it runs for a time tau, stops and tumbles and chooses a new direction. And one of the main characteristics of this movement is that the run time tau follows a Poisson process. Then at the macroscopic level, this movement is described by Patla Keller-Skiel equation. By Padla-Keller-Steel equations. Here, μ is the density of the population, and ρ is the concentration of the chemical. This is very classical and very well known. But it has been observed that when the chemical concentration in the medium is sparse or absent, then the individuals change the search strategy. And instead of doing a very localized search, what they do is Localized search, what they do is they keep moving in the same direction for longer times, describing a non-local diffusion, a long-range diffusion. And it's basically a change in tau distribution what provokes this non-locality in the movement. So that's why, in the first part of the talk, my main assumption will be that the runtime tau. That the runtime tau is distributed according to a power law. So, a heavy tail distribution, which means that the probability of having a very long run is non-negligible. And this is supported by biological evidence, biological experiments, as I will discuss in a few slides. At the microscopic level, this non-local diffusion is going to be described by fractional By fractional differential operators. So, superdiffusion is a term that I will be using throughout this talk. It's kind of a type of anomalous diffusion that Jay was talking in the second part of his talk. But first, I would like to briefly give some ideas of what is superdiffusion and what are the main characteristics of this process. Of this process. So, as we all know, the diffusion is described at the particle level by Brownian motion, where in this case, the mean square displacement grows linearly with respect to time, and the distribution of the displacements, in this case, follows a Gaussian. Of course, this Brownian motion is described at the macroscopic level by Laura. At the macroscopic level by a Laplace operator. On the other hand, a non-local diffusion is described at the individual level by a levy motion. So here we observe a strong presence of long runs, so almost a straight line motion, where in this case the mean squared displacement grows non-linearly with respect to time. And in fact, for alpha between one and two, it grows. Between one and two, it grows faster than just normal. So that's one of the reasons why it's called superdiffusion. Another characteristic, as I said previously, is that the distribution of the displacements in this case follows a power law, a heavy tail distribution. And at the macroscopic level, it will be described by fractional Laplacian, fractional differential operators in general. General. At this point, I would like to remark that the systems that we are going to study here don't follow a Levy process in space. Remember that is the runtime tau, the variable that is distributed according to one of these Levy distribution of power law distributions. So now to see the connection between this fractional Laplacian This fractional Laplacian and the jumping process of the particle or the individual, I'm going to start from a very basic random walk, right? So let's consider that we have a particle in a one-dimensional lattice, and this particle can give a jump to the left with probably one half, or to the right with probably the one-half. Then, this jumping is described by this equation here, right? Doing so. Doing some very simple manipulations, we can write it in terms of different portions. And when dx and dt goes to zero, so in the limit, what we obtain is a diffusion equation. So a classical heat equation where d is the diffusion coefficient. Okay, but now what happens if we allow this particle to give very long jumps? Now the Now, the probability, of course, is not one half anymore. The probability of a jump of length d decreases algebraically with this distance. Okay? And if we follow more or less the same steps as before, we can write this expression where again, we don't have one half here, but just this new probability. And if we take the limit of this expression when dt and d. Of this expression when dt and dy goes to zero, we obtain this fractional diffusion equation where the fractional Laplacian is defined here. So basically, this becomes a Riemann integral of this of this singular kernel here. Here, C alpha n is just a normalization constant. Pv is the Cauchy principal value of this integral. So, I mean, in a very So, I mean, in a very intuitive and hand-waving way, I've just tried to relate this fractional operator, this non-local operator, with the type of processes or the type of movement that we are interested in this talk. So, as I mentioned previously, this long-range diffusion of the individual Of the individuals has been observed biologically. So, these are just two examples that are relevant to this talk, but in the literature you can find many others. So, on the left, we have the mean square displacement of 12 individual cells, pictostillium cells, in a medium without any chemical. And we see that for some times, tau that are, let's say, greater than That are, let's say, greater than 10, these trajectories lie between normal diffusion with slope 1 and ballistic transport with slope 2. So these cells are moving faster than just normal diffusion. The second example here is the distribution of run-unsembl time intervals for the case of the bacteria E. coli. This, the black line, the black distribution corresponds to the run times. And here we see that this is a heavy term distribution, which again is characteristic of these non-local superdiffusive processes. Okay, and it corroborates our assumption for the distribution of the runtime tau. So with this. So, with this in mind, I think we can start describing the microscopic movement of the cells, of the individuals in general. And here we consider an individual in a medium in Rn and no boundary conditions. This individual is going to run in direction theta for some time tau, which is distributed according to this running probability psi. Psi, it's a power law where alpha is between one and two. And S is a function that not only depends on the concentration row at one point, but also on the total variation of this concentration along a run. Theta, it's an angle that takes values in the unit sphere S. So after some time, tau, the individual The individual stops with the frequency given by beta, and then it chooses a new direction, eta, which is symmetrically distributed with respect to the previous direction. And this turn angle distribution, k, it's also a normalized one. So, we have just given three very simple rules to the movement here. So, we have described Here. So we have described for how long it's going to move, with what frequency it's going to stop, and how it's going to choose the new direction. Nothing more. So the general strategy here starts with this system of transport scattering equations for the mesoscopic density sigma, where on the left-hand side just describes the run phase of the movement. The right-hand side gives the density. Hand side gives the density that is left behind after stopping with frequency beta, and thus, those individuals that stop they immediately start a new run at tau equals to zero in a new direction, eta, which is described by this second equation here. So we just introduced the scaling and space and time, where epsilon is a small parameter that it's equal to the That it's equal to the mean runtime over the macroscopic time. Here, mu is greater than zero, and gamma is something that is between zero and one. This we could think about as quasi-parabolic scaling, like fractional parabolic scaling, to call it something. Then we integrate with respect to tau because we want to get rid of these. To get rid of these microscopic quantities, and then by integrating with respect to tau, we end up with this kinetic equation here, okay, for the new density sigma, which is independent of tau. This operator, capital T, is this turn-angle operator that describes how the individuals are going to choose the new direction. And the most important part is this curly A here, this convolution. Here, this convolution where all the non-local behavior of the system is encoded here in this non-local term. This convolution can be explicitly written in the Laplace space. This operator here can be explicitly written. In order to simplify this. In order to simplify this a bit, what we do is the following. So, we consider a quasi-static approximation of this operator. So, we write it in the Laplace space where lambda is the Laplace variable and we introduce the scaling. So, since gamma is between zero and one, as epsilon goes to zero, this will go to zero faster. So, with this simplification, With this simplification, then this convolution is much easier to compute in this case. So then we can easily obtain a conservation equation from the kinetic equation, right, just by integrating with respect to theta. And here U it's a macroscopic density that will only depend on X and T, and W it's the mean direction. W is the mean direction, so the flux of the cells. Finally, well, the last step is to obviously compute these flux in terms of u. And for that, well, we go back to this to this equation, we do some manipulations, we multiply by theta, integrate, and choosing the appropriate scaling, we arrive at this. Arrive at this fractional chemodactic equation here. And I would like to discuss a few things about this equation. So first of all, we observe that for alpha equals to 2, we recover the classical case of chemotaxis, the classical paterlake-caler equations. Also, we see that this parameter alpha, which is related to the non-local movement of the cells, Local movement of the cells only appears in the diffusion part. It only affects the random component of the movement. It does not affect the chemotactic part of the movement. And also, this diffusion constant can be determined explicitly from the microscopic parameters. So just to briefly summarize, we started from the describing the The well describing the individual movement, we were able to write a kinetic equation, and then in the limit, we obtained this fractional chemotactic equation. The second experiments that I would like to discuss are concerned with the movement of T cells in the brain when they are in the presence of some infection. And in this case, what we are going to do is in the brain, What we are going to observe is the combination of long runs and long waiting times. So the movement is not only non-local in space, but also non-local in time. Okay, here we again have the mean square displacement that we see that grows non-linearly with respect to time, which evidences this type of superdiffusive movement. And similar results were obtained. And similar results were obtained for the waiting times in this paper in 2012. So here the methodology is very, very similar to the case before, right? We define a running probability where tau again is the run time. And in this case, we don't have any chemical. So there is no chemotactic component of the movement. Chemotactic component of the movement here. The new ingredient is that we include a waiting time probability, ψ r, where r is the waiting time, and kappa is a new parameter that is between 0 and 1. The kinetic system now is given by these two equations because now we will have two different populations, one of moving particles and the other one of moving particles and the other one of resting particles okay and if we recall from the previous from the previous case so if we have well the density of particles that are stopping with the frequency beta they will go into the resting phase into the resting population where capital T just takes into account cells coming from all directions in the same way particles that are Particles that are resting, but they are starting a new run at tau equals to zero, then they will go into the moving particles density. Okay, so by following more or less the same steps as for the previous case, we obtain in the limit this fractional, well, space-time fractional diffusion equation for the total density of the population. So, moving and resting. Resting cells. And in this case, well, just for you to have a general idea, if kappa is equal to one and alpha is equal to two, we have the classical diffusion case. And of course, here we don't have any chemotaxis because it's in agreement with the experimental results. And also, this fractional derivative in time will take into account. In time, we'll take into account this delay between runs, and it's introduced by solving the equation of the resting population. Well, with this equation, we have a good news. And the good news is that we can write down a fundamental solution for this equation. And with this fundamental solution, we are able to compute, to analytically compute by. Analytically compute biologically relevant quantities. So, for example, heating times. So, heating times is the time that it takes for a T cell to find a distant target. Okay. And here, well, D is the solution, the fundamental solution of the equation. And here we want to find the time T0 at which the density of the solution at the target position, capital T, is equal to. capital T, it's equal to some threshold delta. Okay, X is the position of the target and U naught Y is the initial position of the T cell. And here we have the heating times for different values of alpha and different values of kappa. So remember that kappa equals to one, it's no delay, so no waiting time, and as kappa decreases, the waiting time increases. So, for example, for alpha, very close to one, so when the process is very super diffusive, of course, the heating time is very small. So, the T cells find very quickly the distant target, while as we move towards the diffusion case, then it takes longer times. And obviously, as we increase, sorry, as we decrease the waiting time, also the heating time increases. Also, the hidden time increases. Okay, so far I've just described the movement of cells in Rn. So there are no boundaries, no interfaces, re-entering corners, nothing. But what happens if we want to study these processes in more complex geometry? So, for example, in the brain. Example, in the brain, or in this type of not complex domain that I've just drawn here. Well, in this case, a very general approach is to approximate each brain region by point node and then study the diffusion or superdiffusion process in the network. But of course, with this approximation, we lose a lot of information about the processes happening inside. About the processes happening inside each brain region. And then, yeah, what we observe at the global scale, we don't know how it's influenced by this internal structure of the nodes. So that's why what we propose is to study these diffusion processes in a network of subdomains. So now the So now the nodes of the networks are domains in R2 where we are going to study a continuous diffusion process inside each node, but also a discrete diffusion process across the network. So the main question here is how the global diffusion in these metaplexes, which are these network Metaplexes, which are this network of domains, how this global diffusion is affected by the geometry of the nodes and the connection between the nodes. So for that, I'm going to formally introduce a metaplex. So a metaplex is a portable where VE is a graph. So V is the set of vertices and E. Set of vertices and E is the set of edges. Omega is the set of domains where each domain can have a different geometry. So for each j, I can have any geometry I want with a Borel measure muj. And I is a map that is going to assign every vertici to a different geometry. Okay, so this is a very, very general definition that we could think of, for example, this. Could think of, for example, this complex landscape here where each domain has really complex geometries. But for simplicity here, I'm going to consider in this talk that my nodes are going to be a ball of radius R as a subset of R2 with a Le Verre measure in the domain just to account for the density. For the density, and I, the map i, is going to be constant. So each node will have the same geometry. So, here, for example, we have a metaplex as described here, where these are the nodes where some continuous process is going to happen, and also the nodes are interconnected in some way. This could be also very, very general. Okay, so as I Okay, so as I said previously, we are going to have two different diffusion processes, right? One that is discrete and will be, let's say, in the external part of the metaplex, the exoskeleton, and another one that will be continuous and will happen inside each node. So the external dynamics is controlled by this equation here where Here, where this is the d-path Laplacian operator on the graph. So, this intuitively, this operator allows the particle to jump not only to nearest neighbors, but also to neighbors that are at the distance d. D is the shortest path distance between two nodes. So, for d equals to one, this is the classical path Laplacian operator on the graph. This operator here is built. Well, it's a matrix that is built. So you get minus one when the distance between two nodes is equal to d. You get something that is similar to the degree of the node if v is equal to w and you get zero otherwise. So that's how you build this d path Laplacian. The coefficients C D are going to tube C D are going to tune the hopping of the diffusive particle, of the diffusive density. Okay, and this could be either long-ranged with this C D equals to this or short ranged for C D equals to the exponential of the S net. S net, it's a parameter that we are going to play with later on to control this diffusion in the In the external part of the metaplates. Okay? So the internal dynamics is controlled by this equation where uj is at the density in node vj and at s node again it's something between zero and one and this is um another parameter that of course we are going to play with uh to to control the To control the diffusion inside the nodes. As previously, the Laplacian, the fractional Laplacian is defined in this way. And we consider this fractional Laplacian in bounded domain with Neumann boundary conditions. So this can be computed and actually was computed, numerically computed in this previous paper. So now we have the internal dynamics and external dynamics. So, how do we describe the diffusion in a metaplex? So, here U it's a vector where U, well, each entry, UJ, corresponds to the density in each node, Vj. And this D operator here, it's an N by N block matrix operator, where N is the total number of nodes. The total number of nodes. Okay, so H will describe the internal dynamics, so the diffusion inside each node, where a divergence of Ji is the generator of a diffusion process inside each node. The operator capital T will describe the jumping across the metaplex, so the external dynamics. Metaplex, so the external dynamics, where Tij are transition operators between nodes omega i, omega j. And these transition operators will be defined in terms of sync and sources. So a source is a subdomain inside of a node where the density from another node is going to arrive. Is going to arrive. And similarly, for a sink, it's just a subdomain inside the node where a diffusive density leaves this node to travel to the next ones. Alpha ij are parameters that are going to control the transition probabilities. So it's going to give, let's say, some strength to this, it's the strength of the coupling, right? If we want a weak coupling or a strong coupling. weak coupling or strong coupling. In general, this alpha ij could depend on x as well, on x on the on the domain, but um here we don't consider it like that. Okay, so just to have some general intuition about this this methodology, let's say. We have a toy model, so we consider Toy model. So we consider a metaplex of 51 circular domains in a form of a graph, a linear graph. So just connected in a linear way. And we start with a uniform distribution in node one. We are going to study different processes inside and outside the node. So to play, we are going to play with SNES. So, to play, we are going to play with SNET and SNOTE. Also, we are going to consider different types of different sizes of the nodes. So, omega-S with radius 1 and omega B with radius 100. We also consider different coupling points. So, the nodes could be coupled through the center, but also they could have a disjoint coupling, just as before, just as in this case. Just as in this case, this disjoint couplings. And also, we are going to consider different nature of the coupling in the metaplex. So, as I said previously, it could be either a short-range coupling or long-range coupling between the nodes. Okay, so first we are going to investigate what is the influence of the The influence of the internal dynamics, the endodynamics. And for that, we consider a central coupling. And here we have the time evolution of the density inside each node. Okay. And well, for short times, we see that the red color, which is super diffusion inside the nodes, it's going to equilibrium faster. To equilibrium faster, right? So, super diffusion inside the node, irrespective of whatever is happening outside, it's equilibrating the density in the metaplex faster. So, nodes that are very far away from the initial condition are having some density that is larger than for the normal diffusion inside the nodes. However, as we increase time, we see that actually normal diffusion inside the nodes. Actually, normal diffusion inside the nodes equilibrates the density across the metaplex faster than the super diffusion. And this is very counterintuitive because you will always think that super diffusive density will move faster across the metaplex and will accubrate faster. But what happens here is that the following. So, since we have nodes that are coupled through the center, when a dense Center, when a density leaves, when it's a diffusive particle, let's say, when a diffusive particle leaves one node and appears in the other one, it stays very close to the sink and moves quickly to the next node. On the other hand, a super diffusive particle, due to the nature of the levy walk, when it arrives at the sink, it will immediately jump far away from the sink. And then it will take some time and then it will. It will take some time and then it will until it finds again the sink to move to another um to another node. So that's why the internal superdiffusion accelerates hopping. So it moves faster across the metaplex, but the global equilibration is slower than for the normal diffusion inside the nodes. The second The second thing that we are going to investigate is the influence of the size of the node. So, for this case, we consider a disjoint sink and sources and a short-range coupling. And what we have in this plot is the equilibration of the density in the first node, in node one. Okay, so u node x is the initial density and n, remember, is the total number of nodes. N remember is the total number of notes. So on the left, we have the results for small nodes, and on the right, we have the results for big nodes. For the small nodes, we see that, well, the straight lines corresponds to super diffusion inside the nodes, and the discontinuous lines corresponds to normal diffusion. And again, we see the same behavior as before. The same behavior as before. So, neural diffusion inside the nodes equilibrates the density faster than super diffusion. And again, it's counterintuitive, but the explanation is the same. So a super diffusive particle, it's not very move across long distances, but in order to culibrate the data. In order to culibrate the density in this small node, it's not more efficient than the normal diffusion. On the other hand, for the big nodes, we see the opposite. So here the continuous lines are super diffusion inside the nodes, and the discontinuous again are normal diffusion. And for the big nodes, of course, the Coolibus. Of course, the collibration is much much faster when we have super diffusion. And again, this is because of the same nature. So, for the big node, we have the sink and sources very distant from each other, right? Because they are very localized and very distant. And then a diffusive particle will arrive at the source and will stay for a very long time until it finds a sink, while a super diffusive particle while a super diffusive particle will arrive and then it will move very quickly away from the sink, from the source, sorry, and then probably will find faster the source. So, okay, and these observations has also been supported by analytic, by looking at the analytical properties of the spectral. Yeah, of the of the operators okay then okay just the next thing that I'm going to see is whether super diffusion inside the nodes could trigger superdiffusion across the whole metaplex. Okay? Whole metaplex. Okay. Whether this internal dynamics is strong enough to change the external dynamics. And for that, here we have in the top the short range coupling and at the bottom the long range coupling in the network in the metaplex. And as we see, irrespective of whatever is happening inside the node, in this log log plot, the density is decreasing. It's decreasing exponentially, which is natural for a diffusion process. And in the other case, what we have is this linear, the density is decreasing linearly, which means that we are in the presence of a superdiffusive process. So for this type of metaplexes, it really doesn't matter what happening. It really doesn't matter what is happening inside the nodes because the global dynamics is governed by the external coupling of the metaplex. So just to conclude, I'm going to briefly discuss two real-world examples where, well, the first one is fragmented landscape in Madagascar. Landscape in Madagascar, which is made of 183 nodes, and it's very, very similar to the linear metaplex that we just discussed in terms of characteristics and geometry. And for example, the maximum diameter of the network is 32, which means that that's the longest distance. And the second example is And the second example is the connection between different regions in the macaque visceral cortex, which is composed of 30 nodes. And this is a completely different type of metaplex. It's actually called a small word metaplex, which is a very densely connected network. Okay, so in this case, the longest distance that a particle can travel is That a particle can travel is equal to three, which is very different from the previous one. Okay, so the results for the landscape are very, very similar to the ones that we observed for the linear metaplex. So in this case, we always observe a trade-off between the endo and exostructure, depending on which dynamical process we have in the nodes or in the external. Nodes or in the external exoskeleton, and also we see that the size of the nodes have the same influence as for the linear metaplex. On the other hand, and much more interesting, it's the case for the Macaque metaplex. So, here we have the equilibration of the density in each node. In each node. And well, the internal dynamics is the same. So we choose super diffusion inside the nodes, while the external dynamics is very, very different. So the red line, it's diffusion and the blue line is super diffusion. And what we observe is that both behave the same. So both equilibrate at the same time, which means that the internal dynamics in this case. The internal dynamics in this case completely dominates the dynamics of the metaplex. It doesn't matter what happens in the external one for these highly or densely connected networks, it's the internal dynamics what really governs the movement or the jumping between nodes. Okay, so just to summarize a bit these results, we just saw that the geometry of the nodes. Saw that the geometry of the nodes and the coupling really play an important role in the global dynamics. We also saw that superdiffusion by itself cannot trigger superdiffusion inside, well, in the whole metaplex. And also, that for this type of small world metaplexes, the external dynamics doesn't really play any role. It's actually Any role. It's actually the internal dynamics what governs the process in the metaplex. So with this work, there are many directions that one could take. So for example, related to the first part, we could think of including some internal biochemical pathways into these chemotactic systems, especially in the runtime probability. Especially in the runtime probability distribution. For example, we can tailor this to more specific systems. Also, we can develop asymptotic preserving methods more into the numerical side for the fractional chemotactic equation, just to see whether the fractional chemotactic equations that we are obtaining actually corresponds in the limit to the kinetic system that To the kinetic system that we initially want to describe. And more related to the second part, I would like to maybe combine this idea of metaplexes with, for example, robot swarms, where they want to efficiently search, for example, a building, right? Where then each room will correspond to a note of the Will correspond to a node of the network, and then the corridors and stairs could be the vertices and the connections, the edges between the nodes. And then with this idea of metaplexes, we could obtain efficient search strategies for the case of swarm of robots. Okay, and with this, I think that's all from my side. So, thank you very much. So, thank you very much for your attention and for staying until the very last minute. Thanks a lot, Gisel. Very nice talk. Tour de force of mathematics. Really nice. I have a question right away. I was wondering about patch models. I was wondering how different are metaplexes from patch models, or is this just a new word for an old thing? The problem, maybe there are some. The problem, maybe there are some patch models that are more interesting than the one that we chose. But the thing with this one is that it was very similar to the linear metaplex. So the characteristics of the network were very similar to our toy model. So what we observed was very similar to what we obtained for the linear one. The big The big surprise was with these small world metaplexes because actually it's very interesting how you obtain how these dynamics it's completely governed by what happens inside the nodes. But maybe with another type of landscape network, we could obtain different results also. Results also other types of coupling. We didn't investigate, for example, couplings through the boundary, which in a type of landscape would be the most suitable. But yeah, probably choosing different metaplex, in the case of the landscape, we could obtain more interesting results, but not in this case. Yeah, this was not my question. Yeah, this was not my question. So there's a big theory of patch models in biology. For example, Jim Cushing worked on this for about 30 years or so. So I'm wondering if the metaplexes, how this relates to the patch modeling theory? I don't know the patch modeling theory. Okay, this should, yeah. So the idea is the same. You have different patches and then you have transition probabilities between those. But what happens inside each patch? Each patch? In each patch, you can have diffusion or you can have predator prey or any kind of dynamics. Ah, okay. Okay. And how are they connected? It's a special way or you just define it. Typically, you have a constant transition probability, but this can also be made non-linear with non-linear probabilities. Okay. Okay. I think it would be worthwhile to check that up. Yes, sure. Thank you. Yes, sure. Thank you. So let's open the floor for questions. I have a question related somewhat to Thomas's. I didn't fully understand how you're setting up the connections between the local domains. So within the local domain, I have diffusion, et cetera. And now I want to connect that. How precisely do you? How precisely do you set up the connection? Yeah, so these H and T are operators, but let's take two patches and a connection between them. How would I define the flux along the connecting patch? Well, you know the solution of the, I mean, the density. Of the, I mean, the density in each uh in each point in this mesh, right? Because you computed the solution, and what we did was to take the solution at specific points. So you choose a subdomain here, we take the solution at those points and you print it back into the next node with certain probability. Because also, this density, I mean, depending on the coupling that you have, if it's a short. That you have. If it's short range, then it will be very strong here. But if it's long range, then you could also have some density from here that is moving to nodes that are far away. But basically, if we just think about these two nodes, you know the solution in each of these points and you just print that solution into the source. The source. So your connection is at a finite number of points in omega 1 to a point in omega 2? No, to the same finite number of points in the other one. Okay, but it's still based on a finite number of points. So that gives you a very coarse description of what's happening in omega 1. I mean, I thought what you were leading to was that you have some function. That you have some functional which defines how the whole space is sampled, but in fact, you're just picking a selected number of points. Yes, you leave, I mean, yes, you leave the density here evolve, but in the sources and syncs, you don't define a function such that some density is moving from one node to the other. It's just you take the Take the subdomain and you move it to the next one with some probability again, given by this alpha. So it's not really diffusion between the patches, is it? Because you're dealing with point sources. It's discrete diffusion in the external part, yes. Okay. That's very close to what people did long ago with What people did long ago with finite-dimensional representations of pattern formation in networks. So if you were to think of each of your subdomains as well mixed, then you would have exactly what people had done there. So, a limited case of what you're doing is what people did in pattern formation some time ago. Okay. Okay, I was not aware. I mean, I we worked with people in the network community, and what they have done is a network of networks. So instead of having a continuous space, you have another network. But yeah, okay, thank you. I was not aware of that. Oh, and I think it would be very, very interesting to generalize the connectivity, but I don't see immediately how to do it. Don't see immediately how to do it. Yes, you mean with a let's say like a mapping function from one to the other. Exactly. So this connection takes some functional of the solution up here, not just at a finite number of points, but some functional of it and maps it into here. But okay, that's another problem. Anyway, thanks for a very interesting talk. Thank you. I would like to get some of your papers. 