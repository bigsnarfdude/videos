Inviting me to give a talk. It's really an honor to get to speak first and give a survey talk about quasi-periodic water waves, which is something I've been very interested in for maybe the last 12 years, but really computing truly quasi-periodic waves for the last few years, maybe five years. A lot of this work is joint work with Xin Yu Zhao, who's I think our third speaker today, and then other collaborators that I don't think I have anything with them in this talk, but they're definitely collaborating on related areas. Collaborating on related areas of the work, which is David Nichols, who's our second speaker, and Ahmad Abbasi, who's a current graduate student. All right, so historically, I would say that quasi-periodices came up sort of in the era of Poincaré when he was thinking about the stability of the solar system. So why doesn't the moon shoot off out of the solar system and the Earth fly into the sun or the planets collide with each other? So it's a really tricky question because it's stable both forward and. Question because it's stable both forward and backward in time, right? It seems to be. The equations are reversible, but in neither direction is there a problem. And everything's interacting on here. So it's a very surprising result that any of the planetary systems actually haven't all fallen into the sun or something. And it took some really great mathematicians to sort of develop a theory. So, Kolmogorov and Arnold and Moser are famous for KAM theory, among many other things. Some of the challenges involve small divisors. So there's a lot of very interesting mathematics involved. Very interesting mathematics involved in quasi-periodicity, so aside from water waves. And then, sort of related to that, so integrable systems, prior to Poincaré, people hoped that every ODE was integrable. It turns out the three-body problem is not. But there are a lot of integrable PDEs, such as KDV, Benjamin Ono, and NLS, for which there are huge families of quasi-periodic solutions that you can enumerate in some cases, or at least have a really good description of what. Have a really good description of what the systems are like. So I think this motivated a lot of work in quasi-creaticity just to understand these equations and their solutions. And then within waterways specifically, you have nonlinear actions of various things. You have traveling waves where you can collide them into each other. For some combinations, you'll end up with standing waves. You can end up with more exotic things. So all of those are examples of quasi-periodic solutions. Traveling waves are the simplest one, but they're still quasi-periodic with one quasi-period. And then a lot of And then a lot of the examples I will give you sort of are built up from those sort of things and then maybe tuned to actually have the quasi-periodic property. And then another place, I guess, since in the 60s, it was a really big sort of discovery of Zakharov and a number of other people, Newell and Seeger and Abelowitz, who sort of understood that if you look at perturbations of traveling water waves, of ocean waves, and perturbative long wavelengths or wavelengths. With long wavelengths, or wavelengths that are different than the wavelength of the main wave, you can end up with instabilities there that aren't there if you just stick with harmonic perturbations. And when you excite a wave of a different period than the traveling wave, and then it grows exponentially until nonlinear effects stop it from growing, you start automatically in the realm of quasi-periodic solutions of the water wave equations. And so, because it grows exponentially in the linear regime, eventually you leave the linear regime. Exponentially in the linear regime, eventually you leave the linear regime. So you can do weekly non-linear theory, which is what Tsakarov and the others have done. But we're the first to actually be able to do this for the full water wave equations, to have multiple periods going on at the same time. And actually solving the water wave equations to full accuracy, to double precision or more. And then also just assuming periodic boundary conditions, which is a very common thing, or decay at infinity, which is the other common thing to do, really, there are many systems for which that is too restrictive. For which that is too restrictive. So, like ocean waves, if you're flying over the ocean and look down, you wouldn't say it's periodic, but it also doesn't seem to decay. You just sort of look forever and it's doing things. So, hopefully, adding quasi-periodicity as a type of boundary condition is expanding the type of rich solutions that you can observe in nature, especially in the ocean. My own motivation, I guess I had been working, it started off working with David Ambrose, which is why we worked on this Gore-Tech-G problem since he was. Core-Tex sheet problem since he was working on that when we were postdocs together. So, some years after that, we computed this way. So, this is a, you have two fluids, top fluids moving to the left, and bottom fluids moving to the right. And there's an interface in between them. It's an inviscid flow. This is a vortex sheet, so it exerts pressure based on curvature. And this thing is time-periodic, which is a particular type of quasi-periodic solution. So, I became fascinated with. So I became fascinated with time periodic and more exotic water waves through this work from about 10 years ago. So that was sort of the launching point for this line of research. What David and I did to begin with, actually, before we tackled the full vortex sheet, was the Benjamin Arno equation. And I had no familiarity with integrable systems until working on this problem. But anybody who's ever worked on integrable systems, always there's some moment where they're just blown away by the beauty of things that fit together. By the beauty of things that fit together, sort of surprisingly. So, we were using PDE methods though, looking ahead to the vortex sheet to look for time-periodic solutions of this simple equation. H here is the Hilbert transform. And it's sort of like KDV, but you replace one of the derivatives with the Hilbert transform there, which makes it non-local. So, what we found is that you can start with a stationary solution or a traveling wave and find the right amplitudes and the right The right amplitudes and the right periods to perturb that and end up with an actually time-periodic solution. And then you vary some parameter and you end up at another traveling wave. And we, just through numerical computation, found that they always ended up at another traveling wave somewhere else. And we could even, once we figured out how to characterize the bifurcations that are possible, we found mappings between the disconnect or the connection on the other side. So, whatever this means. So whatever this means, 1, 0, 4, 1 was one of the bifurcations we looked at, that would connect over to a different bifurcation to 5 minus 1, 4, 1. So we had this nice hierarchy of things. And it turned out all of these solutions that we found fit into this more general framework than just time periodic solutions. So this is where I'm introducing Quasm periodicity. So the idea is that you have this higher dimensional torus, U. Well, Tn is the torus, but U is a function on it. And it's a periodic function on the higher dimensional torus. But you have valid. Dimensional torus, but you evaluate to get your solution in the lower dimensional space, you evaluate along some sort of wave numbers and frequencies, and then you have phases theta. So that's the definition. So if you have n quasi-period, or if you have three quasi-periods, this would be a three-dimensional torus. If you have two quasi-periods, then it's just defined on T2. And Satsuma and Ishimori, using bilinear formalism or something like that. Bilinear formalism, or something like that. And Dobrakotov and Preachiber were using an inverse scattering transform for the Benjamin Arno equation. This is their version of it, which is particularly beautiful. So they are able to give you a quasi-periodic solution of the Benjamin Arno equation just by picking a bunch of parameters. So you pick these numbers, arbitrary. You define these sort of phases. I guess the CMs are also things you're picking. Things you're picking. Yeah, and then you just form these products involving these sums. You form this matrix, which is fairly ill-conditioned. It looks a lot like a Hilbert matrix or a Cauchy matrix. And then it has this on the diagonal. So the y-dependence, so y is a vector of n components. So the components are sitting in e to the im. So that's why it's a periodic. This is the periodic function, so that's playing the role of u. And then if you just If you just plug in this formula here, so a derivative of a log of the determinant of m, and then evaluated at those kappas are related to the b's and a's, and the omegas are also related to the b's and a's. If you plug that in, you'll actually get a solution of menagero. It's hard to work with. Like actually computing this thing is really a mess if you have very many of those components. But it is just a very nice closed-form thing. The reason I decided to present Benjamin Unroller. I decided to present Benjamin Arno, first of all, I've worked on it before, but also it's all of these things are just rational functions of e to the i x. So instead of having Jacobi elliptic functions, which come up for K dv, we just have all these functions. And a lot of times they look like 1 over cosine. In Fourier space, they look like e to the i beta x. You have different powers of beta, but it's just the same, the same e to the i x multiplied by powers. So it's a really simple function in Fourier. So, it's a really simple function in Fourier space, which is the only reason I sort of was able to rediscover a lot of these things by accident is that I was looking in Fourier space of the solutions. So, that was my first introduction to integral systems, and I kind of couldn't believe that all of these things worked out. So, okay, so here's a question. So, are there analogs for the water wave equations? This is integrable. The waterways presumably aren't. I think Zakarov thought they are, but I really don't think so. I've looked for a lot of the things that he was saying that would be. That he was saying that would be the sort of the building blocks for the solitons and so on, and they're usually not exactly solutions. All right, but that's anyway, that's a different talk. So, okay, so the organization of this talk, I want to talk about first quasi-periodicity and time. I'm purposely doing these parts first, and then maybe I'll have to rush or skip some of these because both Dave and Shane are talking about spatially quasi-periodic periodic waves later. So, I want to talk, I need to say what the equations of motion are. I'll try not to dwell. I'll try not to dwell on it since I think most of you know. And then I'll go through a lot of examples that hopefully some of you haven't seen me talk about before of different kinds of waves that you can get with two quasi-periods. And then I'll talk about a shooting method for three quasi-periods, which is related to work of Berti and Montalto and a number of other people, Baldi and Toms Alazar. There are a number of works now that prove existence of quasi-periodic solutions that didn't exist when I first started. When I first started computing these waves. But I'll explain that as we get there. So, to start with, what formulation do I use? So, I like to be able to parametrize the free surface with an arbitrary parametrization. So, c is the x component, a is the y component. If it's in 2D, we complexify it. If it's in 3D, as Aph will do, then we can't use the complex analysis tools. Let's see, I don't know if this actually works. So, anyway, these are the equations: this potential flow used gradient of phi. flow you use the gradient of phi. The probability equation here, if you take its gradient, you get the Euler equations. And then this is the kinematic condition here that has particles that are starting on the surface, stay on the surface. And then the hard part is that you sort of have to solve in the bulk. I guess it's actually better than actually solving the full 3D PDE, but it's hard because it makes it non-local. This is sort of the Craig and Sulim idea to think about that. idea to think about that abstractly as an operator, as a Diersley Neumann operator, and then work out the derivative that you need u dot n there by computing dφ dn on the boundary from the value of phi on the free surface. So that's the Dear Shenoman operator. There are a lot of ways to represent the curves. I'm only actually going to show you the equations for the simplest one, which is the graph-based representation. So the C in this case is just alpha. Zeta is C plus I alpha, so Zeta is the whole curve. C plus i alpha, so zeta is the whole curve in the complex plane there. And then eta is the wave height as a function of, alpha is just x in this case, so as a function of x. So that's our graph-based formulation. That would be the formulation that Sakharov wrote about in his 1967 paper. I would say this would be sort of the default if you're not doing anything too fancy. So the equations of motion from the previous slide, if I'm looking at, well, CT is zero because you're Is 0 because you chose that first component to just be alpha. And then eta t ends up being that this is the Deutsche-Moment operator. Putting square root of 1 plus eta alpha squared makes that thing self-adjoint. And it's also what comes up in the equation here. So if you just take the imaginary part of our zeta dot n equals u dot n formula and figure out what eta t should be, then you'll end up with this nice method. Then you'll end up with this nice F form and F for A to T. So, the other two methods, I have another talk where I focus on how to actually compute these things. The second method is the Havelow and Grub and Shelly method where you're doing angle arc length variables. So, that's nice because it keeps the curve uniformly parametrized and it does allow for overturning waves. And the third method, which I will actually use a lot and later in the talk, is the conformal mapping method. And I will have some slides on that. I just didn't want to go through the detailed derivation here. Detailed derivation here. All right, so the conformal mapping method you will have C and A will be related by a Hilbert transform. So the idea is that the mapping that they use to describe the curve is actually conformally maps the half plane onto the fluid domain. In error. So the Diersley-Neumann operator, if you're doing one of the first two methods, either the graph-based method or the Howland-Grub and Shelley method, I have found, at least especially in 2D, that just I have found, at least especially in 2D, that just doing Cauchy, representing the velocity potential using Cauchy integrals and then computing the normal derivative using potential theory from the Cauchy integral calculator, from the Cauchy integrals, I guess it ends up looking like the Flomelli formula. When you have a Cauchy integral, you can compute the normal derivative using the Flomell formula and taking the limit to the boundary. And this is what the system looks like for the simple case of no, it's not a multiply connected domain. This one's infinite depth, even I didn't put the linear image curve on to represent the interaction with the bottom boundary or anything. So you have, first you have to solve for this mu, so the velocity potential off of the curve ends up looking like this function that involves the complex cotangent. That's if you sum over periodic images of 1 over c from the Cauchy representation. So when you get a cotangent, Representation. So, when you get a cotangent like that, all you've done is summed over periodic images of a standard Cauchy integral. And then you represent it away from the curve by this dipole density mu, or the double layer density mu. And then when you evaluate on the curve, you have to figure out what value of mu will actually give you the velocity potential that you have. And that's a really nice limit because you end up with the second kind of equation here. So you just solve this for mu, and then you take. You solve this for, and then you take a regular derivative with respect to alpha, and then you use a different thing. So g and k are pretty similar, except for beyond imaginary, and I think beta and alpha switch. And then you evaluate this, and you'll end up with the normal derivative. So that's, it's actually, it looks expensive because it involves a lot of these cotangents, but it's really easy to parallelize. And especially if you have a GPU, it makes it as fast as the conformal mapping approach where you're just applying Hubbert transforms. So depending on what hardware you Transforms. So, depending on what hardware you have, this is actually often just as fast as doing conformal mapping. And some greater flexibility in how you're parametrizing the things. If you do conformal mapping, the Bernoulli equation ends up just being a quadratic algebraic equation of the velocity potential in the stream function, which is the conjugate variable to the velocity potential. And yeah, I skipped the derivations of the formulas. But anyway, the important thing is these are just squares. Is these are just squares and ratios. So that's why this is so nice to evolve numerically, is that you don't have complicated functions to compute, and you've actually put all the non-locality just in a single Hilbert transform, which is almost trivial to do in Fourier space. Take an FFT, multiply it by minus i times the sine of the wave number, and then take an inverse FFT. So it's very fast. It's just two FFTs to compute H there. And this is what the full set of equations look like. And this is what the full set of equations look like for the conformal mapping method. Eta, so the alpha is now not physical space, but you have to compute the Hilbert transform of H to figure out how the X component is working. So C, if you're given Eta, you can puke C in this way. Some choices of some of these parameters eliminate this X0. So X0 is 0 in this case. Or what I've often done is had C of 0 T be 0 so that you're always parametrizing 0 in the office space to be the point at 0. Alpha space to be the point at zero in physical space. So that requires a slightly different choice like that for anything. Okay, so anyway, so we have a number of different formulations of the water wave equations that are all equivalent. I often switch between them. I have some codes that do one thing and some codes that do the other, so you just have to do a change of variables essentially to work out what c is. If you want the eta if you want the graph-based formulation, you just have to solve c of alpha equals whatever to get e i equals x to find alpha and then the value of beta there and then you'll get your graph. And then evaluate beta there, and then you'll give your graph. So it's actually not too hard to switch between the various formulations of the water works. All right, so quasi-periodicity, I defined it for the Benjamin Ono equation, so here it is again. So for the traveling waves, you just have n equals 1, so it's going to look like eta 0 is the capital U here, x minus ct and phi, so it's like this is a vector instead of that being a scalar. So you have two components for your quasi-quiet function. Function, eta zero and phi zero, and you're just plugging in x minus c t to play the roles of kappas and omega. So I guess that kappa is just one, it's just a scalar one, and omega is c in this case. So here's a movie of a traveling wave. I didn't explain how I computed it, but I'll talk about some of the computations in the more difficult case later of the spatially quasi-periodic traveling waves. And these visualizations, the particles are just to help you be able to see what the fluid is doing. Be able to see what the fluid is doing. The actual calculation is only defined on the free surface. And this one's getting pretty close to Stokes' 120-degree corner wave. And let's see, I also color code the particles with the pressure. So as you go down, the pressure increases. So those are all things you can do, compute easily. But that was done with a graph-based formulation. All right, so standing waves are another thing that I worked on for quite a long time, especially, say, 10 to 5 years ago. Say 10 to 5 years ago, where we looked at numerical methods for studying these things and really understanding their behavior: like, does it actually form a corner? Like, penny and price predicted, and so on. So, these are waves where I have a lot of examples of them that I've computed over the years. And so, that's part of what I'll share with you a little bit later. So, standing waves, it has two quasi-periods, and you can just think of eta tilde and phi tilde as being defined on the Taurus. So, it has two arguments. So it has two arguments. And to make it 2π periodic in both, I already sort of non-dimensionalize so that everything's 2π periodic in x. But I just have to put an omega in front of t, and then that will be 2 pi periodic in the t direction. And so then these are your torus functions. And essentially, I mean, if you just do a shooting method where you log from 0 to capital T, it's just a sort of stretched torus, and that's all that's happening. So those are standing waves. And then And then, what am I doing there? Oh, so this is the shooting method formulation of it. You kind of forget about the torus and just evolve the equations of motion from zero to capital T, and then you have to figure out how do I tune it to actually be a standing wave. And that's a lot of the trouble of computing standing waves is figuring out what perturbations of the initial condition will cause it later to return to itself. So that's the idea. And I'll actually explain the shooting method in the context of traveling scan. Explain the shooting method in the context of traveling standing waves. So here's another more, this one's newer. This, I think, the paper is published in 2021, roughly. So these are like standing waves, but when they come back, the crest shifts. So the next time it'll come over here, and every time it just shifts by some phase. And the phase I'm calling theta, I think. One forward. Theta. I think c times t is theta. So what happens is that the later time eta of xt is equal to the shift of the solution at the initial time x minus ct0. So c is like the average velocity of the wave over one cycle. And it's sort of a hybrid between the traveling wave and the scanning wave. So this is a new family of waves, new in the last five years. And so the idea of, I guess the definition that I just gave you here was that You here was that at the later time, it's just a shift of its previous position. And then these guys are the torus functions to put it in this form. I always think about it in terms of shooting method variables instead of directly on the torus for these parts. All right, so the definition of a traveling standing wave is that at the later time, you just come back to a phase shift at the earlier time, and you can just And you can you can just do it at t little t equals zero, and then it will work out the same way from then on, because then the initial condition at the capital T is the same as it was at zero. So they'll evolve together, with no change other than what time you've attached to the solution. So that's the definition. The waves that I'm computing all have this particular symmetry. So the standard wave symmetry that we use, where you only have to evolve over a quarter period, is that the wave comes to rest at capital T over 4. comes to rest at capital T over 4. There are a lot of good reasons for doing that. That's when the wave is sharpest. So that's when you want it to have the most active Fourier mode so you don't have to solve for them all. So I usually set it up at zero to have this kind of behavior where initially if you shift the wave by pi in space, you'll come back to yourself for eta, but the velocity potential changes sine. And then as you evolve to the later time, the velocity potential is zero. So that means the wave came to rest. Is 0, so that means the wave came to rest, and then there's a time reversal about t over 4. So when it comes back to, when it evolves onto capital T over 2, then what happens is eta will be the same, but phi will reverse time at that later time. And then you actually are now phase shifted by pi, and then later will evolve over that and come back again. So it sort of goes back and forth between a peak at the origin and a peak at pi. For the traveling standing waves, we sort of set it up a little bit differently so that. So that initially it is even, but we also put phi to be odd instead of even. So there in the scanning wave case, phi is even. So in this case, we set phi to be odd initially. And then the requirement that we have is that at a quarter period, so it's nice to only evolve over a quarter period. It saves a uh fourth of the calculation. But also if errors are growing exponentially in such sense, then you can be saving powers, um like a power of four in your errors. Going to power up floor in your errors. Well, an exponential. So, anyway, the idea is that if you can achieve this, that this eta at x plus theta over 4 is an even function of x, and phi at x plus theta over 4 is an odd function of x, and also this is true initially, then it will turn out that this is true. So that's a nice symmetry argument, which is a little bit more general-looking than that one, but it ends up including standing waves as a special case for some parameters. Standing waves is a special case for some parameters. So if you start with, let's start with this condition. So if you start with eta of x plus theta over 4 t over 4 as even, then I write down the thing that eta of x plus theta over 4 t over 4, I can change the sign of this without changing eta because I said it was even. Phi can change the sine of x, but it changes the sine of phi here. And then because we have these initial conditions where eta of x0 is even and phi of x0 is odd, if you reflect space, replace x by minus x, it's the same as time reversal. So then I can. So then I can change the whole argument, which puts a minus theta over 4 here, if I also reverse time. And then if I compare these two things to each other, they're almost the same. We have a x plus theta over 4 and an x plus theta over 4 here, and a t over 4 and a minus t over 4. So if I reset what I mean by t equals 0, then you'll end up with a x t plus little t plus big t over 2 is a of x minus theta over 2 t. So just like over here where it shifts halfway across at the halfway point, Halfway across at the halfway point. These guys also have the property that they're actually already traveling standing waves at t over 2, theta over 2. And I just maintained the connection with those waves, which is why theta, like I could have defined this as already the traveling standing thing. Then a standing wave is traveling standing with pi always. It goes through one cycle, and it's just pi pi. So you could call that the traveling standing period of the pure standing wave. Okay, so then the question is: like, okay, how do I parameterize all these things? There are a lot of new functions. Parametrize all these things. There are a lot of new functions. We have these thetas involved. And so, what I like to do here is go down to the linear regime and look at what are the general solutions here. So, we basically have two, for pure scanning waves, you basically have wave trains passing through each other that have the same amplitude. And for pure traveling waves, you would just have them like, let's see, for pure traveling waves, you can set it up so that these things actually add to a simple. I'm confused now. How do I get rid of the. Oh, okay. So you can make this term be zero if you choose theta to be pi over four so that you're evaluating cosine at pi over two. And then you just have the right traveling term. Or if I make these guys zero, I'll just have the left traveling term. So these represent all the phases of standing waves and traveling waves you can get for the linear problem. And then I was looking at Fourier space, if you just take these. Fourier space, if you just take these functions, so beta is just parametrizing different linear combinations of the coefficients of a right-moving wave and a left-moving wave. So sine and cosine are just making sure that the amplitude of that thing squares to one. And so if you look at the, for different choices of beta, if you look at the trajectory of the first Fourier mode of eta, it executes an elliptical orbit in the complex plane. And if it's flat, if there's no space, like if it doesn't open up, it just goes back and forth or up and down. And just goes back and forth or up and down, you'll have standing waves. And if it's a circle, you'll have a traveling wave, and all the other ellipses are somewhere in between. So the trick was: so the pure traveling case turns out beta is pi over 4 plus pi over 2z. Any of those numbers will give you a pure traveling wave. Pure standing wave case is where you're just a pi over 2 multiple of an integer. And those are the ones where the ellipse collapses into a line that just goes back and forth in one or the other direction. So trying to fit, looking at this and trying to figure out how can I define At this, and trying to figure out how I can define like a traveling parameter. So, what I ended up doing is just looking at three of these guys and saying, well, this looks like cosine theta sine theta in the linear regime when I add this factor 2 to eta 1 to rotate it back to the origin. So I'll just define beta to be what you get in the linear regime to describe these various families. So I take the argument in the complex plane, so the arctangent of this over this, to define what it is. These are both real by the assumption that this is even in. The assumption that this is even, and I guess I'm just dealing with eta. So this is even and this is even. So that makes these things both real. And so that gives us a traveling parameter. When you evolve at finite amplitude, then you'll actually get these theta. So this, it comes back to an, it shifts by an angle theta at the later time. And so what I defined for the beta, the traveling parameter, is sort of when you're a quarter of the way through that trajectory all the way around, what is the The width or the distance, or the distance from the origin there of the first Fourier mode. And then when you come up, you start off with this one, that's what middle A is. At the quarterway around, the whole thing, quarterway around, you have B as the length, and then I just make a triangle and call beta that angle. And that beta can be any sign. If this thing's going the other direction, then we'll have the opposite sign. And that gives us a way to parametrize all of these things. I later thought of a different way, but it was more complicated to explain, so I thought. More complicated to explain, so I thought I probably maybe this is the right one to show you guys. So, how do you actually compute them? So, this is our initial condition: we know eta is even and phi is odd. So, that means that the eta hats are just going to be real numbers. The phi hats will be purely imaginable numbers. And they have the symmetry that eta hat minus k equals eta hat k and phi hat minus k equals negative phi hat k. That keeps the functions real. So those are the initial conditions you search for. So, those are the initial conditions you search for. You also have to find the period. You also have to find the theta. That's the phase shift in space. And what we impose, we want to actually set the energy, so that's our amplitude. And we set that parameter beta, which is that crazy thing. And then I also need to drive this thing to be an even function. If I evolve for arbitrary initial conditions, it won't be. So that's what my objective function just imposes that all the imaginary components of this function as a function of x. This function is a function of x after I take the f and t here, r 0, and all the real components of the phi part are 0. So that drives the thing to be even at the time t over 4 after you shift by space. And then you use like a Lefenberg-Marquardt method to vary these parameters until that reaches 0. And whatever precision you're in, you usually end up with the square of that. So you'll get f being 10 to the minus, because it's a square here, R transpose R, you'll end up with 10 to the minus 30 or something, or 10 to the minus 32 in double precision. 10 to the minus 32 in double precision, or 10 to the minus 63 or something in quadruple precision. So that's the idea. That's the framework. And for pure standing waves, they fit in this framework too. We ended up with this whole family of traveling standing waves with different parameters. And when you go around and find a new standing wave, often the phases have shifted. So like this wave and this wave have the same properties. But when you're defining t equals zero and x equals zero to b have shifted. So like this spot. It. So, like, this spot ended up with the origin. Alright, so that's traveling standing waves. So, this is, I think, a new family of quasi-periodic waves. And if theta is an irrational number, then it will shift sort of forever and never exactly come back to where it started. Sort of another way to think about quasi-periodicity is that it comes back arbitrarily closely to where it started, but it never exactly gets there. So, patterns repeat almost. Almost. If you look at now for different choices of amplitude or different choices of beta, how does the period change and how does theta change? Theta changes the most for traveling waves. It doesn't change at all for standing waves. So zero is a standing wave. These are standing waves. And the period changes the most for standing waves. And the period for a traveling wave is kind of hard to define. But here you would define it by bifurcation to the neighboring families of the traveling species. Of the traveling standing waves. So, I mean, a traveling wave has any period, you just evolve. So, theta and t are a little bit ill-defined for the traveling wave, but it fits in this family if you actually have the right value so that there's a liabilization to the case, the nearby ones. One thing you'll notice is there are these little white squares in here. That's where a solution couldn't be found. And I think they don't exist. Like, you just end up with these complications due to small divisors. Like, that was the first bullet point on the first slide. But that just complicates. Slide, but that just complicate anytime you're computing quasi-periodic things or standing waves. You have technical difficulties in the proofs, but they also manifest themselves in real life, that there aren't solutions in places, and resonances actually do lead to multiple solutions and things like that. So at higher amplitude, you'll actually see, like if you make plots, you see these disconnections in the curves, and those things are due to resonances, and they actually persist to zero amplitude. They actually persist to zero amplitude. So, looking at my solutions, they were accurate enough to actually discern what the coefficients of the Fourier nodes look like as a function of beta and epsilon. And some of the terms, the ones in blue here, actually have a zero in the denominator if beta has, I forget what the value is, like 15 degrees or something. If cosine squared 2 beta is equal to 3 fourths, then you'll end up with a 0. And that 0 persists as you increase the amplitude. You just keep seeing that. Able to, you just keep seeing that resonance there, and it kind of grows, and you get these more complicated things. I think I have one more slide on that. So, like at really large amplitude, they break up completely, and the traveling wave, like the scanning wave, doesn't actually make it over to the traveling wave anymore. It sort of loops around itself. And as you look in, you get more and more complicated vibrations. So, it's one serious challenge in computing these things is actually staying on text. Is actually staying on task and not like getting lost or thinking or claiming that you found something that doesn't exist and so on. So you have to compute with a lot of digits to actually determine that these are real. Okay, so anyway, I think that's it for traveling standing waves. Oh, no, not quite. So here is a traveling standing wave that has a negative, like has a dimple at the crest, if I can remember which one it is. I think it's this one down here where the curvature went negative. Where the curvature went negative. So, solution C is this solution where when it goes up to the top, it actually has a dimple in the way it's pressed. And then I've computed a lot of other things. This is a, also, it fits in the traveling standing framework. I didn't compute it by numerical continuation. This looks like a funny waterway because I scaled it this way by a factor of 42. But it's a solution of the variation of actual waterways with a small depth. And you end up with the large spike going faster than the small spike. Going faster than the small spike. So, after a number of cycles, it actually comes back to itself, but it doesn't exactly land on its initial condition. So, that's a neat type of solution that looks just like here. You are in the KDV regime, but you've tuned the thing for the full water wave equations to actually behave like interacting solitons. And the one way you see that it's not quite the real KDV is that there are these background ripples that travel also at a different speed than the two solitons. And they all fit together to actually be. Together to actually be a quasi-periodic solution. Here's another one. This is something I worked on with Paul Milewski a while ago. We never published it. We'll have to get back to that sometime. But this is the microsizing problem. So what I'm showing here is the pressure beneath two counter-propagating waves with almost the same wavelength. So over many cycles, it's periodic now because I sort of rescaled the thing to be periodic. But you can see there are actually. Thing to be periodic. But it has, you can see there are actually a lot of fine waves there. But because they don't match up exactly, there's interference in places where the amplitude is essentially zero and other places where they constructively interfere. And that leads to these interesting pressure waves that are on a much larger scale than the waves at the top. And so you can imagine what is the bottom of the ocean feeling as all it sees is the pressure if waves like that are happening at the surface. And you can end up with these sort of large-scale things moving along that. Scale things moving along that, I don't know, perhaps could excite resonances in the elasticity equations down there, because these travel a lot faster than the waves at the top do. And that could actually cause the earthquake sensors to actually feel the water waves in the ocean, even though the waves themselves don't seem like they're doing that much. They work together to create these large-scale structures. And so, this is definitely a quasi-periodic solution because you have these two waves of different wavelengths moving around, and they are. Moving around, and they are time periodic with a phase shift. That's how we compute them. All right. And then this other thing Paul and I started working on too a long time ago. This is the breathers. Yeah, we should definitely get back to this. So here, what I'm doing is looking for breathers of the waterway. This is what the Karno. The reason I did this is because Zakarna was claiming that these breathers would be the narrows. Trended the 7x or something like that, so that positive and negative are still seen, but it pulls the waves apart so you can see what's happening at small scales. So this is 10 to the minus 10 to the phase speed and an envelope speed that are different. And as the wave, as that happens, and I probably should have also shown you one where I didn't scale the thing in such a funny way. I didn't scale the thing in such a funny way. But the only way to actually get this thing to exist, and the reason it's a traveling standard computation, is that I need to go through one cycle of the higher frequency wave to come back to the previous cycle. So it's sort of like the rolling tire problem where you have treads on the tire and you roll through one tread block and you're back to where you stop. So it goes through one shift to where it was, but everything also shifts because of the It was, but everything also shifts because of the group velocity of the wave. And then it's a solution to the full Euler equations. But the funny thing is, the only way I could get it to work is if there was also a counter-propagating small amplitude wave, remember that's 10 to the minus 7, going in the opposite direction. As you increase the amplitude, that wave is more and more important. At first, I thought something was wrong with my numerics, because I could get it down to, like, F could get it down to 10 to the minus 16, and then it would fail. And I think it turns out that physically, the only way these waves exist is if they talk to infinity. As if they talk to infinity with a positive amplitude, essentially Stokes waves. So I imagine that if you build that into the asymptotics, you could actually show that this works. So that's kind of what I'm hoping Paul and I can do someday. Okay, and then we have a counter-propagating depression waves. So this is where surface tension is the main thing. The waves look pretty different because instead of the waves that we're used to, they're depression waves. But they still go back and forth and collide into each other in very unique ways. Here's shallow, so this is the opposite. So here are, this is the depth is 0.05, the wavelength is 2 pi. And this one's, they are actually time periodic, but this one is actually unstable, and you can see it's really crazy. There's a lot of high-frequency notes involved. This one turns out to be stable, so I'm not talking about stability much, but I'll just say that that wave there, if you compute the flow k multipliers by linear. Multipliers by linearizing the problem about the wave over a whole cycle and looking at the eigenvalues of the monotony operator. Yeah, you just look for eigenvalues of that. They all lie on the unit circle, at least not for subharmonic perturbations, but for superharmonic perturbations. And so if you now perturb, so what am I doing? So I'm taking this wave and I'm perturbing it with, instead of this one, which is tuned to be time periodic, I start with. Which is tuned to be time periodic. I start with two Stokes waves, like actual Stokes waves that would, if the other one weren't there, would travel forever. And I collide those into each other. Well, they don't like the other one being there, so they're not quite Stokes waves anymore. But they stay really close to that solution I just showed you, because that one was stable. And so we collided it through 5,000 collisions and just looked at the location as a function of time of, I think, the A function of time of, I think, the position of one of the waves at the half height. And ended up, it just ends up looking very messy. So if you take an FFT of that, you end up with lots of spikes. And so I'm curious, like, is this an almost periodic solution where there are an infinite number of quasi-periods? Where you're linearizing around a stable solution. You have a perturbation of it. It was a pretty natural one to just look at the collision of two Stokes waves. And if the nearby actual time period solution is stable, maybe you just always. Stable, maybe you just always, it's some sort of orbital stability when you stay nearby. So that would be cool to actually know, but it seems a little like a pipe dream to prove. Okay, so the shooting method for n equals three quasi-periods. I have a feeling I won't say much about spatially quasi-periodic waves because I know what my next two talks are about those things. So, okay, so time quasi-periodic in n equals three. So Berti and Maltalto and a number of people who I'll list on a later slide have Who I'll list on a later slide have proved existence of these things using Nashmoser theory. Like in the same way that Toland and Muse and Flodnikov proved that for scanning waves, they've been able to show that this type of sort of more exotic, quasi-periodic scanning wave exists, but nobody had really seen them. And the question is, how should you compute them? And I really prefer shooting methods to the kind of iterations that they would do. They would solve the PDE on the whole torus and iterate on that. So it fails to satisfy. Taurus and iterate on that. So it fails to satisfy the equation. Every iteration it satisfies the equation a little bit better. Here, we failed to satisfy the boundary conditions, and every iteration we satisfy the boundary conditions a little bit better, but the equations are always satisfied. So that's the difference between shooting and sort of the more traditional PDE-based approach for this type of problem. So my idea is I will define these H and capital Phi to play the role of that torus function. And what I'll And what I'll plug in there, I'll plug in, this will play the role of kappa, so just the first component is dealing with x. And then these are the two omegas, so those are the components of t. And then theta1, theta2, and theta3 are phases. So that's the on-size. We're going to look for these periodic functions h and phi to make this satisfy the water wave equations. If you just shift time and space appropriately, you can eliminate theta one and theta three easily enough. Theta 1 and theta 3 easily enough. And so then you'll just end up with one thing that I'll call theta 2, or I'll just call theta since there's no more other thetas around. So this is the torus version, just writing this in a more compact way. Looks like h of x theta plus alpha t beta t. So alpha and beta are the omegas, so those are the time quasi-periodic parameters, and then theta is a phase representing how the different wavelengths or wave numbers are interacting. Alright, so what am I going to do? Alright, so what do I mean by different wave numbers? So this is a lot like the traveling standing idea, except that instead of putting cosine x plus t and cosine x minus t, I'm going to put cosine x here and cosine 2x here. So the second wave actually has a different wavelength than the first one. And so if you just look at the linearized water wave equation around a flat state, the beta and phi, you'll need a square root of 2 here. Actually, so alpha and beta turn out to be 1 a square root of 2. So alpha may turn out to be 1 and square root of 2 if you're going to have a different way of, instead of just playing cosine x, now you have cosine 2x. For the time dependence, you need a square root of 2 on that term for it to satisfy the linearized equations. And here you don't want, so alpha is just 1 in this setting. But this framework would work for other choices of alpha and beta. 1 and square root of 2 is just the only one that I've actually tried to compute. And then phi is the relative phase between these two components anyway. So cosine alpha t plus theta is the time dependence of all. Is the time dependence on the cosine x term. And then just cosine beta t without a phase is the time dependence on the second term. So what I'm trying to do here is marry these two waves. And like at the linear level, they're both happily propagating as they are without interacting. But the full water wave equations have them interact. And so the question is, can you tune things to make this satisfy the water wave equations and still have this structure where you have two dominant modes that are simultaneously Modes that are simultaneously evolving together and not ever leading to overturning or having them evolve into the sun or whatever. So, that would be the analog of the planets, is that we're trying to get this thing to work out and end up with a single quasi-periodic solution involving multiple wavelengths that at the linearized level at small amplitude exist already. So, okay, so that's the copy of what I just had there, and this is just a copy of this. So, I'm writing down. A copy of this. So I'm writing, and actually, what I would like to do here is solve for H in terms of eta, because I want to think about it as a shooting method. So my goal is to eliminate capital H and phi. I started with that as the onsets, but in the shooting method, you're really just going to have all eta and little phi. Okay, so let's see. So beta t here ends up being the time component of eta. Theta is the phase parameter. And so if you want to extract h from a solution eta, you'll H from a solution eta, you'll end up, it does depend on the period. So capital T there, sorry, tau is the torus variable for the other wavelengths. Sorry to interrupt. Is there anything of Wilton ripples? No, because Wilton ripples would have the traveling speeds being the same. Let me just think about that for a little bit. About that, for a little bit. I mean, I have a later slide on Wilton Ripples for the spatially quasi-periodic case, but here it's more of a temporal thing where you're trying to fit them together in time. But yeah, I'm not totally sure the answer is now, so I have to think about that some more. All right, so my idea for the shooting method is that for each theta, maybe I should have drawn it, but I have x this way, I have t this way, and then I have theta this way, and theta is just parameterizing. And then I have theta this way. And theta is just parameterizing a bunch of solutions of the water wave. For each theta, I have all theta and phi to the time capital T. So capital T is going to replace beta as the unknown. And then, what I want to require, if this capital H is going to be T pi periodic in all three variables, then when I evaluate eta at time t and just look at my formula for what that means for h, we're actually starting here, figuring out what does it mean to plug in t, you'll get eta plus alpha t t pi. alpha t t pi. But h is periodic in that slot, so I can replace that with zero. And then now I can use this formula for h to replace that in terms of eta. So what has happened here is that at the later time t at a given theta, what you do is you shift the phase of the initial wave. So I did draw a picture of that, but before I do that, let me just say what But before I do that, let me just say what the parameters we're actually solving for. So the alpha and beta in the KAM world, you would freeze those. Those would be like the average frequencies of the planets. Instead, we're going to solve for those guys, but we're going to be specifying some of the Fourier modes in the 2D Fourier version where you have both theta and x for the initial condition. And I'm just solving for things at t equals 0, no evolving, to the capital t time at that later time. Time at that later time. So here's a picture I made to try. I think this makes it pretty clear. So what I have is here's my x variable. For a fixed theta, this is just a water wave solution. So you have evolving in time. Each of these little lines represents a solution of the water wave as I go up. And then at the final time, I want the final time theta to be a shift of the initial time theta plus gamma. And the way I did it, because of Plus gamma. And the way I did it, because of the way square root of 2 works, I drew it this way so that it moves this way, but actually the gamma is moving that way. Since it's periodic, it doesn't matter. But this one, as written, pops out and lands there. And this one, I guess, lands, it goes around once and once here. So at the final time here, it's supposed to agree with the initial condition here. So you have all these waves that are defined at t equals 0, little t equals 0, that you're trying to find. That you're trying to find them, each one of them, all these initial conditions simultaneously, that when you evolve, one becomes the next one, and that next is a shift in the theta parameter. Does that make sense? So that's the idea, is to try to glue all these things together at the final time so that all you've done is shifted the initial family of solutions. And in between, you're just evolving the water wave. So that's the shooting method version of the. Yeah, of these kinds of work that they've done. I mean, they have the same onsets and they have the same intuition about what symmetries to choose for the waves and everything, but they are solving the PDEs out in every Newton iteration and proving existence on cantor sets. And I'm evolving these things and finding places where you can't find a solution and so on, which is playing them all with those cantor sets. Can I just call it? Yeah, so in the work I lost nothing. So in in the work I know Nasiliano and the collaborators, they cannot have web directors for two reasons. One is the one you mentioned, that they are truly quasi-pyramic, and the other is that they don't allow for resonances. They don't allow for resonances. Yes, yes. So there are two reasons. One is that they are not unique frame, and the other is this resonance. Okay, yeah. I mean, I guess with the resonances, if you try to do it as an iteration, then you'll end up dividing by things that you can't have zero. That you can't have zero. So, yeah, so that's right. So, those resonances are to be excluded, but it leads to cantor-like structures, I guess, when they exclude them because of the way the number three works out. You need not only that it not be zero divisors, but you need the small divisors to be bounded below. And I think that's the, there are a number of theoretic reasons why that will lead to canter size. Right, good, good. So, okay, so the form of my initial conditions, if all I really want is that. If all I really want is that the theta equals zero solution is even initially and phi is zero initially, so I'm setting it up that way. From that, you can actually just infer, assuming time reversibility, that as you march forward through a number of cycles, if you came close to it marching backward, that you'd have to end up with this thing being an even function of theta and tau, and capital phi will have to be an odd function of theta and tau. So just this one small assumption actually tells you. This one small assumption actually tells you a lot about the structure of the torus functions. And then I have to solve for all those Fourier modes and the torus functions. And I'm basically just looking at symmetries here. Like if I know the function is even in Fourier space, like if the function is real, then I really only have to represent some of the modes, the modes in the right half plane saying, so this is for an arbitrary real value function that modes in these quadrants have to be related in this way. This is A bar, this is B and B bar. Is a bar, this is b and b bar, if you just, or maybe rotate. And then if we know that these properties that the functions even in x means that a equals b, so I only actually have to solve for these guys, and I impose these two as externally and solve for all the other ones. And then that's the, this is what the solution looks like. So this is a time-quasi-periodic solution of the Euler equations where Equations where on each of these slices I'm solving the weather equations at the final. What I did there is sort of look at the boundary of the box. If you look at what the boundary of H is, like I'm not actually plotting it with H, but if I had it, then this would be the boundary of H. That's like the boundary of the left boundary of the Taurus function H there as it evolves through the family of solutions. And the shape that you got at the end matches the shape that I started with. Oh, people won't show again. Right at that moment, that's the final shape. All right, good. That's probably as much time as I want to show. I'll just say one more thing. So that was not a 3D wave. This is a family of 2D waves that are forced to be quasi-periodic. Work with Chris Rycroft also about 10 years ago. We looked at true 3D scanning waves, and you can end up with some really interesting solutions there, too, where you have these hybrid waves with. Hybrid waves with multiple, they're sort of mixed waves, similar to what Jen and Sapphon were doing for traveling waves in the late 70s, looking at combination waves. So, for standing waves, you get a lot of these things too. And this is one particular one that was here on this combination branch. So, you have like the pure zero one mode solutions, the pure, I've forgotten what the other one is, two, four solutions, and then this combination solution also satisfies the wave equation. Also satisfies the wave equations, and you have some interesting bifurcations. A lot of those resonances causes trouble in the theory, so you exclude them, but they actually often have multiple solutions. That's usually the explanation, is that the reason you can't converge to one is because there are several. And so this is the kind of thing that you'll end up with where you have a disconnection. All right, good. So I think I'm probably not even in. Oh, okay, so that's what Chris and I did, how we did the wave. It's not an easy calculation to do a 3D. It's not an easy calculation to do a 3D by scanning it. So I think I'm just going to stop there. So thanks for your attention. So that's a lot of time-quasi-periodic work.