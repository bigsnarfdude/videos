All right, so good morning, everyone. Thank you to the organizers for organizing this workshop at this very beautiful location. It's been wonderful being here. My name is Ditamra Singh. I'm an assistant professor in the computer science department at Brown. And today I'm going to talk about an interesting work that we've been doing in our lab, which is trying to use deep learning models to explicitly model the underlying spatial and The underlying spatial and temporal structure in the data. So it all starts with our observation that just knowing the genome sequence is not sufficient, because while all the cells in our body have more or less the same DNA sequence, they all are expressed differently. And this is because of the differences that arise in the way different genes are expressed in different ways. Are expressed in different cell types. And this, in turn, is controlled by different types of local and global epigenetic factors. So looking at multiple spatial scales. So starting with some of the mechanisms that we know that the transcription factor binds to the promoter site of the gene and starts the gene transcription by recruiting the RNA polymerase. Now, this is not very simple because if Very simple because if this gene is close to a site of a histone around which the DNA is wrapped around, these histones can have tails that can have chemical modifications. And these histone modifications can have effects like enhancing or repressing the gene expression. Now, making the story a little bit more complicated, let's zoom out where we see this phenomena that an enhancer, which might be really far away in Really far away in linear dimension because the way that the DNA is arranged inside the 3D structure could be very close to the gene of interest and could be regulating its expression. So we have this notion of the local epigenetic factors that could be regulating gene expression, but then also this global epigenetic factors that could be regulating gene expression through long-range interactions. Let's think about gene regulation. Let's think about gene regulation in another dimension. And we talked about the importance of motion yesterday already. And so the idea here is that the gene regulation is not static. It changes over time. So certain genes that are expressed at certain stage during the cell development may not be expressed as the cell kind of goes through different developmental stages. So the whole story basically boils down to, again, all the cells, they start with the same genome, but as Same genome, but as the cell starts developing, the chromatin landscape of these cells changes and results in very specific kinds of differentiation of all of these cells. And so trying to study this regulation in a spatiotemporal manner is very important. We not only want to know what is happening spatially inside the cell, but also how the gene is regulating over time. And this is relevant because when we are talking about diseases, these are some of the factors that are also. These are some of the factors that are also involved in these diseases. So, in order to understand that, we need to study about these. So, the big question that we are trying to answer here is how is transcription regulated in a spatio-temporal manner? And it's a very ambitious question. So, obviously, ideally, we would want to tackle it together, but we'll start with smaller steps where we break down it into two projects. The project one discusses how do we incorporate the spatial information. Incorporate the spatial information to try and model gene regulation. And then the project two focuses on how do we model the temporal regulation during cell development. So today I'm going to talk about these two projects, starting with the first one where we are trying to predict and interpret how the local and global epigenetic factors could jointly regulate the gene expression using deep learning models. So back in 2016, we started focusing first on the local We started focusing first on the local epigenetic factors and we went about answering the question, how trying to tackle the question how histone modifications are related to gene expression. Now, this is a very important question in genomics because unlike DNA sequences, histone modifications are potentially reversible. So you can imagine that researchers are very interested in trying to answer this question because it could lead to development of epigenetic drugs. And in trying to understand that questions, we have And in trying to understand that questions, we have collected data, we have gene expression, we have ChIP-seq data that measures histone modification. But as mentioned yesterday, it all boils down to large numbers, right? So we are looking at 20,000 genes, combinations of 20 or more histone modifications, and we of course need to study multiple hundreds of cell lines. And if somebody was to experimentally test all these different combinations and figure out how the genes are regulated, that is practically impossible. So as machine learning people, the So, as machine learning people, the idea is: well, we have the data, can we leverage the collected data to try and get some insights from it? So, we decided to look into neural networks to try and answer this question. And this audience doesn't need a lot of motivation, but neural networks are very good at not only capturing relevant features from the data, but also the combinations of all these relevant features to make accurate predictions. So, if this model was trying to predict This model was trying to predict and classify this image, it can not only capture the local features in the image, but also the combinations of these local features to make an accurate prediction. So our idea back then was to say, let the histone modification signals be the input, and let's try to predict the gene expression from it. We can look at different parts of these histone modification signals as local features, and then the combinations of these histone modifications. Of these histone modifications as the combinatorial features we want to learn. And since a neural network can do this well automatically, let's just use a neural network to do this task. So what we showed in our paper then that the model was able to make accurate predictions, suggesting that it was able to capture the combinatorial relationships of the histone modification and connect it to gene expression. But more importantly, we dug deeper into the interpretation side of things and tried to extract the relevant. And tried to extract the relevant features from the model that were leading to the accurate prediction of the gene. And one interesting insight we found was that when the model was making the prediction of the gene to be repressed, it was focusing on K27Me3 and K9Me3 marks, which are known in the literature to be repressive marks. And this is something it learned from the data, which was very exciting. Now, something that we didn't do at that time, and nor did the studies that came after us doing a similar task. After us, doing a similar task was to model the long-range interactions. And so, this brings me back to the complicated picture that we have, where we are not only interested to look at the local factors that could be regulating the gene, but we are also interested in looking at the factors that are further away and somehow could be regulating the gene just because of the way the DNA is arranged in the 3D space. And this is not just a hypothesis because there is. Just a hypothesis because there is actually evidence in the literature that these long-range interactions are involved in different types of diseases. So again, being machine learning people, the question we want to ask is, well, can we learn these relationships from the data to try and answer the questions that do 3D contacts really influence gene expression? And so the idea here is that we have this predictive model. Can we now integrate the spatial information? Now, integrate the spatial information into it. And so, this project has two parts. One is just doing the integration and making accurate predictions, but just like the previous project, going more deeper into the interpretation side of things and seeing if we can extract relevant features from the data that guide towards a particular prediction. And this information can help us in doing any sort of analysis, comparative analysis that we may want to do. The reason that we have got to this. The reason that we have got to this problem now is because, thanks to the development in sequencing technologies, we can now actually capture the information about the DNA organization. And one of the way to do that is through high-C experiments, where we get this nice matrix where the rows and the columns represent the genomic regions and the values in the bins represent how frequently those two regions are interacting inside the cell. And so, our formulation is to basically. And so, our formulation is to basically take this matrix and formulate it as a graph. So, now the nodes of our graph are representing different genomic regions, and we connect these two nodes with edges if there is evidence that they are interacting. I'm sure you all can tell where this is heading next. This is heading to graph neural networks. A lot has already been talked about this, so I'm sorry, but I do have my own primer on graph neural networks. So, as already mentioned, So, as already mentioned, this is on a very high-level conceptual case. This is very similar to the regular convolution we do in the case of images, where we learn a representation of a pixel by doing a weighted aggregation of all the neighboring pixels. So the same thing happens in the graph, where we try to learn a representation of the node by taking a weighted aggregation of all its neighboring nodes. Now, in the case of images, it's a nice grid structure. Case of images, it's a nice grid structure, so we know what the neighbors are. But in this case, we actually have to provide that information explicitly. So we provide the model information about node features, which are a numerical representation of the properties of the nodes and an ages and C matrix that tells us what are the neighbors of the node. So, for example, if you were dealing with social networks, you can imagine that the node features could be the age of the person or whether that person is employed or something like that. And the age essency matrix. And the adjacency matrix could look something like this: where the rows and the columns are the nodes in the graph, and we give a value one if they are connected, zero if they are not. So, there are multiple formulations of graph neural networks out there. The one we use is this one. So let me walk you through what these equations are doing. So, we are basically trying to learn the representation of the node of the graph that I've marked with the star. So, we start with the original representation, which is whatever the features of the Representation, which is whatever the features of that node are. And in the first layer of graph convolution, as I mentioned, we do a weighted aggregation of the neighboring nodes. And you can see we also normalize it by the size of the neighborhood to counter for that effect. Then what we do is we also add the previous representation that was learned in the previous layer. And then because this is neural networks, there has to be non-linear activation. And so that produces the output for this node. Produces the output for this node for this layer. And this happens for all the nodes in the graph. Now, the next time, the same step gets repeated, the previous information gets added, there's a non-linearity, and then we do this, you know, k number of times to learn the final representation of the node. Because this is happening for all the nodes, you can imagine that the number of layers we add, the more further away information we are aggregating for. So if we do this K number of times, So, if we do this k number of times, we are aggregating information from nodes that are k hops away from this particular node that we are learning the representation for. All right, so let's fit all of this into our framework, which we call GCMERG. We are trying to predict the expression of the gene, Y, so we have the expression associated with it. We look at its genomic region and get its list of neighbors using the Hi-C contact map. The features of the node comes from. The features of the node come from the average IP-seq signals for the histone modifications. So we have the node features, we have the information about the neighbors, it fits very elegantly into the graph neural network framework. And so once we have learned the representation of the node, it goes through fully connected layers and we make the final prediction for the gene expression. So as far as the experimental setup is concerned, we run our experiments on these three cell lines. As I already mentioned, Cell lines. As I already mentioned, the inputs is the graph structure that we get from the Hi-C map, and the node features are coming from the ChIP-seq of these six histone modifications. And then we are trying to predict the gene expression signal. We do the standard train validation test split. So let's see what the prediction results are. So the prediction results are good. We see a high correlation between the gene expression that is predicted by a model versus the true gene expression values. Versus the true gene expression values. We also compare it to some baselines, some deep neural network baselines, and we see that overall the model does a good job of predicting the gene expression. But just like the previous project, what we really want to dig at this is now that we have modeled this data in this predictive task, can we now extract the information about, and that question is missing, but what genomic contacts would be related to the gene expression? To the gene expression. And for that, we integrate the GNN explainer method into our framework. And the whole idea here, what this allows us to do is for a particular node that we are predicting, for which we are predicting the gene expression, we are able to assign important scores to the neighboring nodes that are relevant for that node's prediction. And we are also able to do this at feature level, where we are able to assign important scores to the features that. Important scores to the features that may be relevant for that node's prediction. And the way this works is we maximize the mutual information between the original predictions of the model versus the predictions of the model when we mask out the nodes and the features of the graph. And so we minimize this objective function. And let me walk you through it. So basically, what we are trying to do is learn these fractional masks, M and N, M over Tasks M and N, M over the neighboring nodes, N over the features. And the idea here is that we, given the original prediction of the model, we look at the prediction, which is conditioned on these masks being applied on the nodes, neighboring nodes, and these masks being applied on the feature masks. So the intuition here is if you map something out and it changes the prediction drastically, clearly that is relevant. And if it doesn't, then clearly it's not that relevant. Then clearly it's not that relevant for the model's prediction. So we apply this on a list of genes for which the model is doing a good job in predictions. And this is just a small subset of examples from that list. So what we are showing here in the yellow circles are the genes for which we are making the prediction. The circles around it are the top 10 neighbors of that gene. The size of the circles is representing the importance score that GNN explains. Important score that GNN Explainer is assigning them. And the circles in red are the ground truths. So we took this study that I have cited, which has information about experimental validation of long-range interactions. And so we use that as the ground truth to see if the interpretation matched what was seen in the experiments. And it did, which is great. We also get these important scores for the features, which are the histone modification signals, but unfortunately. Signals, but unfortunately, we can't verify it without doing any experiments. But what is promising to see here is that the model is picking up on K27AC and K4Me3 marks, which are the promoter in handsome marks that are known to be involved in long-range interaction. So that's kind of nice to see. Right, so I'll wrap up the first part of my talk. So GCMERGE integrates the spatial information to predict gene expression. It's able To predict gene expression, it's able to capture long-range interactions. But more importantly, the explanations that we get from the model can serve as a hypothesis-driving tool. The paper's out and the code is available. And another interesting thing is just how science happens. A recent paper came out around the same time as ours from Christina Leslie's lab, who are also trying to do basically the same thing, which is modeling the long-range interactions using graph neural networks. Interactions using graph neural networks, but they're focusing specifically on the enhancer-promoter interactions, and they also do it for data sets with very high resolution. So it's nice to see that this formulation is a lot of people are thinking about this formulation and thinking of graph neural networks as a reasonable setup to formulate this task well. All right, so now I'm going to move on to the next part of the talk, which is about modeling the temporal structure. The temporal structure. Now, this part of the talk is not polished at all because this is work in progress, but I thought I would pitch this to this wonderful audience here. This is the correct audience to pitch this idea to. And then you can let me know whatever feedback or input you have. So when we think about modeling the temporal structure that happens in gene regulation, it's very natural for us to look into the single cell domain, right? Because the single cell data, especially Because the single cell data, especially the single cell gene expression data, provides a very nice, fine-grained landscape of how the cells are changing over time. And to give you an example, we have this one very beautiful data from the Waddington OT paper, which is showing how the gene expression, you know, the gene expression of the cells is plotted in 2D, and you can see how these cells are across the time. And that's great. Unfortunately, when we do work with single cells, When we do work with single-cell data sets, a lot of times these experiments are noisy. It's not always easy to get these large-scale experiments with thousands and thousands of cells. And a lot of time, these time studies tend to have coarser resolution. So while on one hand, you have this nice data over here, you also have nice data, but a little bit more coarse, at a little bit more coarse resolution where you don't have those fine time points. And so as a biologist, Points. And so, as a biologist, you can imagine if you are trying to understand gene regulation, you would want these gaps that you see here to be a little bit more filled so that you can do some robust analysis on the trajectory of the cell development. So there is already consensus in the field that we can use computational methods to do data augmentation for doing statistically robust analysis. And because we are talking about cell development and cell digitity, About cell development and cell trajectory, we would want these methods to be able to infer and predict the changes that are happening in the gene expression as the cell differentiates. There are already methods doing point one, which is generating in silico de novo gene expression profiles. And I'm sure Jessica is going to talk about the methods that their lab is working on. Our idea is to basically do something similar, but explicitly model the underlying temporal structure. Model the underlying temporal structure using a neural network. And there are other methods that are trying to predict gene expression in the future or in between of developmental trajectories, but they make very strong assumptions of what this developmental process looks like and what it is a function of. And what we are thinking is, well, let's not make any assumptions and let the neural network kind of learn whatever this function is as the cell develops. Is as the cell develops. Now, I'll make a distinction over here. We are not trying to explicitly learn a trajectory or infer a trajectory. This is something we are hoping that the model will do implicitly and then generate gene expression profiles for time points that we don't know. So, the question goes back to: can we generate gene expression profiles for future time points in a completely data-driven manner? So, the idea here is we have this summary. Is we have this some information about the time the gene expression of the cells for certain time points. Can we use that information and then kind of make a prediction of what that gene expression would look like in the future? Again, in a completely data-driven manner. So the setup is something like this: we have some cells with the gene expression profile at time point T, and we want to get to the gene expression profiles of cells in time point T plus one. Our model is. Plus one. Our model is a mix of variational autoencoder and a recurrent neural network. So the variational autoencoder is basically to model the underlying low-level, robust representation of the data. And then the recurrent neural network is the dynamics model, which we are hoping will capture the changes as this manifold changes over time. And then, you know, we'll be able to generate the gene expression profile at time point t plus one. So, starting with the structure model, so autoencoders are really good at learning a low-level representation of the data if you have enough data points. For example, in this case, the image, the autoencoder, which is a neural network, will take this image and will learn a represent lower-level feature representation of this image through a bottleneck layer. And then the decoder, which is another neural network, will take this low-level representation and recreate the image. And we have a reconstruction loss, so as the model So, as the model tries to reduce this reconstruction loss, it will learn a more and more accurate representation, this lower level representation. And this is what the neural network looks like for this particular model. Now, a variational autoencoder kind of takes us into the more probabilistic space, where now we are saying that instead of representing these low-level features as discrete values, how about we represent them as distributions? So, giving the model a little bit more flexible. So, giving the model a little bit more flexibility, a little bit more variable representation, letting the model learn a more variable representation. And so, now, instead of learning just a latent vector, we are learning a latent vector that represents the parameters of a Gaussian distribution. And so, once we learn this, the model samples from this Gaussian distribution and then recreates the output, which is, you know, which should be close to the input, but also have some variation in it. Also, it has some variation in it. So, going back to the example, now the encoder is learning the distribution over the feature space. Then, the model samples from this distribution and then recreates. So, the key idea here is that we use two loss terms. One is the reconstruction, but with also a KL divergence. So, the whole idea is that we want this to be similar to the original distribution, but also have some variance in it. And this is what the neural network is. And this is what the neural network of this looks like. So that's the structure model that we are using. For the dynamics model, we decided to use a recurrent neural network. And so the recurrent neural network, the whole idea is you take an input, it gets processed by the hidden unit of the model, and the model produces an output. Now, for the next input that goes into the next hidden unit, the hidden unit not only looks at the input, but also the output of the previous hidden unit, and so on and so forth into this sort. So on and so forth into this sort of a recursive structure. And the idea here is that we are trying to learn conditional probabilities. So, what is the probability of output t given all the inputs that we have seen before? And this works really well in case of text because sentences tend to have that conditional probability structure. Now, we are not entirely crazy trying to use this method for modeling the single-cell trajectory because this paper back in 2016 showed. This paper back in 2016 showed that an RNN with a Wascherstein loss is actually able to model the diffusion of large populations across time. And we, you know, we got a little bit of insights from this paper to try and use for our model. Okay, so what we have basically are gene expression profiles for cells across times. So this is the matrix that we tend to use for single cell RNA-C, but we also now have a time dimension. And our experimental setup. And our experimental setup is such that given we have experiments from time t1 to capital T, we do the training and validation, keeping one time point completely out. So we use T to T minus 2 for training, T minus 1 for validation. And then finally, in the test phase, we bring in that held out time point and see how it works. And what the actual framework looks like, we have the structure model, which takes the gene expression profile, going into the Expression profile, going into the encoder, sampling from the encoder, and producing the original trying to produce the original gene expression profiles. As I already mentioned, we have a deconstruction loss and a KL divergence loss here. And now this particular distribution representation goes into the RNN, where the one hidden unit is learned from the previous representation, gets combined with the current representation to produce the hidden. To produce the hidden unit representation for the current time point. And this is basically used to generate the representation for the future time point. So, this is how the model will generate. Of course, when we are training, we use this Washerstein loss to basically train the model. So we see the distribution for t plus one, and then we have the original distribution for the t plus one, and we try to minimize it. There is another bit of information here, but I didn't add it because it was making the figure very. didn't add it because it was making the figure very messy. We also have a reconstruction loss up there. So we sample from that distribution that we are learning, feed it through the decoder, and we get a gene expression profile and we have a reconstruction loss there as well. And then finally, the current time point information becomes the previous time point information and so on and so forth. Right. Now you may be wondering, because this is not lineage data, the cells get destroyed across time points. So how are we? Destroyed across time points. So, how are we matching cells that are different from one time point to the other? So, we have this, we're using this linear sum assignment algorithm with a KL divergence-based distance matrix to kind of map the cells across the time points so that we can make this model work, especially in the RNN case. So, does it work? Well, no surprises, the structure model works because there are multiple studies out there that show that the variational auto-encoder. That shows that the variational autoencoder is able to capture a good low-level representation for the trends. And this is something we see as well, where we have the original, a low-dimensional representation, and this is what the latent space representation looks like. And as you can see for the Waddington OT data set, it's doing a good job capturing all the profiles. And then when we take the gene expression profiles that are produced from the structural model and combine it with the original data set, there is very good mixing happening, which we see. Mixing happening, which we see, which we quantify using the MIEC score. The idea between the score is that it ranges from one to two. Closer to two means there is good mixing, closer to one means there is not. So all this looks fine. Does the dynamic model work? Well, it's a little bit more complicated. So this is, I'm showing you, we are trying to predict the blue cells, which are at time point three in this trajectory. This is a nice baseline where we are. Of naive baseline where we are saying that the gene expressions from the previous time point can kind of predict the gene expressions in the next time point. And while this baseline is naive, it's surprisingly really good for a lot of time points. So we decided to include this in our analysis. And then this is the result of our generative RNNS. And as you can see, it's doing a pretty good job of predicting the gene expression profiles at time point three. Profiles at time point three. So that's a cool result. There are also some not so cool results. And again, I'm sorry that these figures are not very polished, but this is an example where the model is failing. So we are trying to predict the last time point in this trajectory. And as you can see, the model is predicting the gene expression absolutely at the edge and really missing out all the cells that are still at the last day point, but are kind of, you know, spread across much before. You know, spread across much before in the trajectory. So, this is where the model is failing, but you can see that the baseline is doing pretty okay, the biological baseline. All right, so summarizing everything. So, okay, the main point here is that, yes, the model is not perfect, but it does look very promising. And of course, there's a lot of more work to do to get it to work perfectly. But to summarize the whole story, But to summarize the whole story, the idea here is that we can now develop deep learning models with a better knowledge of what is the underlying structure in the data. So we have a notion of what is the underlying structure in the data. We can really leverage that information to build deep learning models that can make the most out of it. And as I showed already, the GNN framework is really good at capturing the spatial underlying structure in the data. The data. And our VA plus RNN framework seems to be promising for modeling the single cell developmental dynamics by capturing the underlying temporal structure in the data. Finally, I would like to thank all the members of my lab. It's a wonderful team to work with, but specifically point out the students who have been working on these two projects. So these projects are from the thesis of my PhD student, Jeremy, who is held by GRG and three very talented undergraduates. And three very talented undergraduate students. Zavi, who is now abroad, Justin is starting his PhD at UW, and Sharlin will be graduating next year. A big thanks to Elika Larshan, who is our biologist in the loop. It's very important to have her because she lets us know what is crazy and what is not. And then, of course, thanks to all the funding sources. And I'd be happy to take any questions.