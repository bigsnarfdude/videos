Okay, so let me get started for the recording. So the considerable we all got class of variational problems and that involve non-vocality and the kind of functions we consider will be integrals that depend on fractional and non-local weightness. So before I go more into details, maybe I'll just say a few general words of I don't convince a lot of convincingly that these non-local variation problems are relevant artists to slide. So I mean there's interesting I mean there's interesting mathematics going to happen and also there's a lot of applications where like longer range interactions and global effects then really come into domain should be concerned. So our main motivation is in... Our main motivation comes from solid mechanics. So there really the first approaches to non-local modeling date back to the late 1960s. But then the big step was 30 years later when M. Seling introduced the theory of peridynamics. Use the theory of periodynamics at least. A lot has happened in this direction, both into mechanics and the mathematics. And so there's also other directions where you find non-local effects, for example, in continuum to discrete limit passages, or when you look at macroscopic models or heterogeneous media, for example, in the fiber-reinforced material, also in theory of phase transitions, non-local effects, plano-class. No local effects, play no quoted role. And yamming off another direction here, thinking towards imaging and machine learning applications. There are people who use non-local regular brisers to reproduce sharp features and to avoid these staircasing effects. And also machine learning nowadays, when you think of optimization, the bi-level optimization, for example, the science model of the faith in Russia, you produce prompts and results. These problems themselves. So, this is just my small mist of non-local variation of problems. Now, independent of which type of problem we look into, I mean, relevant questions are existence theories and asymptotic analysis. And the point here is that, yes, all these methods we are so much used to from the local setting, they often rely on their localization principles and they do not carry over easily. So, it's really important to have some new ideas coming in to tackle different types. Coming in to tackle different types of model features. And so, this is like general context. And now I'd like to dig in a bit further here into this into solid mechanics and precisely into peridynamics. So, I'm sure most of you have heard of it. So, just to save, so it's a description of continuum mechanics that tries to avoid any kind of derivatives. And the idea is that this way you can model material behavior with this. Material behavior with discontinuities and singularities, like hypostasis or fracture. And the most basic model, also like the first one, is bond-based periodynamics. And so there, the functionals one considers are of double integral type. And you have here an interaction energy that measures the connection between different points by taking into account the difference in the reference and the phone configuration. Reference and default configuration. So there's a drawback about this model. It's very restrictive in the type of material properties that it can describe. Therefore, people have extended that to what's called bond-based aerodynamics, where you look into, for an individual point, you consider the combined effect of the bonds that you find in a neighborhood. And based on these ideas, in a recent paper here, Bilido Kirtomora Corral. Belido Ketomora Coral, and they took somewhat a step further and introduced these models of non-local hyperelasticity. So, what is that? So, you have integral functions that depend on objects like this. So, these are non-local radians. Yeah, so what are they? So, you have a difference quotient here. You integrate that with respect to a certain kernel. So, a way to think about it is like an average linear approximation. And yeah, so if you compare. And yeah, so if you compare with the bond-based periodics formally, what has happened is one integral has moved inside the density. So this will be the motivation for us to study the class of variation problems that I have here. So we'll be looking into energy densities that don't depend like usual on classical gradients, but instead on fractional gradients here, so always in green, or truncated versions of that. So here Versions of that. So here in blue, truncated fractional gradients, to keep it a bit simpler, I'll speak of non-local gradients. Can you go just one slide back so that I can see the definition? Because I need to. It will be back. If I say more about it. Sorry. Okay, this will be, I promise it will be back. Okay. So then, um, so this is the kind of functions we want to look into. The kind of functions we want to look into. So, the technical setup is like this: so, omega is a bounded open set, we have a bability parameter strictly greater than one. Here we have these densities here, currently Buri function is suitable, p growth and cohesivity assumptions, and we have important two parameters involved. So here we have S strictly between 0 and 1 is our fractional parameter. So, that controls kind of the regularity of the functions that are admissible for our problem. And if S is strictly, Problem and if s is small enough, so this can also include effects like cavitation, fracture cracks, and so on. And the second parameter here is the horizon parameter. And this controls the range of non-local interactions. So if in our non-local case here we have this delta here, it means points can interact that are with each other, that are most apart. And in the case of the rest fractional gradient, all points can talk. Gradient, all points can talk to each other, and so we have in this case that horizon is infinite. So, this is the setup. So, now what do we want to do with this? So, the overall goal is at some point to contribute to a comprehensive theory of existence and asymptotics for these kinds of. Have some topics for these kinds of variation problems. And so, yeah, we'll work within the direct method. And there are a few relevant questions that I'd like to address. And so, here, yeah, you have them P1 through P4, and they'll also serve a bit as a guideline for us at the top. So, the first question here, very natural, is wonder about lower semi-continuity of these functionals. So, with respect to green topology, that's the right one to consider. And so, we wonder what are necessary. Wonder what are necessary and sufficient conditions on our integral, we always continue being influenced. Then you have question Q2, closely related. So that's about relaxation. So what can we say when the conditions in Q1 fail? And can we get a good representation formulas for low-semacontinuous developments? So then, next in the program is Q3, it's about the asymptotic behavior of how families are functions of this type. And then Q4. And then, yeah, in Q4, natural to assume, you would assume that these problems, SS, the fractional parameter goes to one, you would converge to a local model. Can we make this? So this is shedding some light on that is the agenda for today. And I'll start by explaining first our underlying function spaces. So, as I said, so now here, number of gradients here again. So, as I said before, So, as I said before, this DS is the reach fractional gradient that was introduced first, or five, one should say, in a work by Xi and Spector. And yeah, it's exactly of this type, so a non-local gradient, but with a specific type of kernel. So our choice here is that we take a multiple of the release fractional kernel, sorry, the rest potential kernel, and of order 1 minus s. So, and there's a constant up front. So and there's a constant up front here and this constant here just controls the asymptotic behavior as s equals to 1. Now when you think of defining fractional derivatives, I mean there's always many different choices you could make, but So Shah Habi recently showed that there's something really nice about this one because it's really the only fractional derivative operator that is so translation and rotation invariant and also as homogeneous. And this makes it a very nice choice for all kinds of problems. For all kinds of problems, physics background quantity. So that's why we choose that one. On the other side, here we have the non-local gradient. It first appeared in this paper here. The difference is now that we're introducing an additional cutoff function. So the star delta lips means that it has compact support in our radius around zero all about around zero radius delta. And we make some further assumptions on this cutoff. So we want it to be radio. Cutoff, so we want it to be radial and nicely decreasing, and want it also to be equal to one in a small neighborhood around zero. So, in this sense, we end up with an integrable kernel here that resembles this fraction of one in a period of zero. Okay, so in a similar way, we can go along and define also the divergence, so fractional and non-local divergence. And the important observation about this here is that. This here is that we have a connection between the gradients and the divergence in the sense of integration by Piel's formula. So it's like what you need to know, you can take the derivatives from this vector psi and pull it on phi at the expense of minus psi. So with these integration by parts formulas, we can then extend our definition of gradients, so in a distributional way to all locally integrable functions. And so you see here how this is done. And so you see here how this is done, so it's in the classical sense. So we get the weak fractional and the weak non-local gradients like this. And then I'm going to take inspirations from Sobolev, our superficial theory of Sobolev spaces, and we can define our corresponding function spaces that we'll be interested in here. So, like taking all Lp functions whose non-local or fractional gradients are in LP, and these are the natural norms to work with, also wanting a defined With also wanting and convergence in the natural size. So these spaces here, you can really think of analogs of the classical fractional Sobolev space, so we find the Galjago-Slobodevsky norms. But they have an advantage, namely they have a distributional character. And this makes them very nice and well suited for your PD in general, but also calculus of variation. So that's why we bring this. So then you may remember from one of my Then you may remember from one of my first slides that these spaces here appeared with a little subscript zero. So this has to do with the notoriously difficult question of imposing boundary values in non-local problems. And so the way we go about this here is working in complementary value spaces. So we prescribe values outside of our domain omega. And for simplicity, we always assume that these values are zero. Always assume that these values are zero, we can also deal with something more general. Now, if you look at these two spaces here, they look very similar, almost identical, but in fact they have a qualitative difference. Namely, this one here is really a space of functions on Rn. So the following sense. So if you have a function with compact support, that its fractional gradient really has a support that spreads out, so that is unbounded. So in that sense, That is unbounded. So, in that sense, here it's really a space on our n. On the other hand, if we look here, this is a space of functions on bounded sets. And so the way to think about it is like this. So if we have our set omega here bounded, and we have u with zero here outside, and then we'll know that the non-local gradient here will be zero outside this like enlarged set here, so this is a fixed delta here. So, this is a thickness delta here, and this thickness omega delta, so just arg by delta. And in order to define this non-local gradient of omega delta, we need a little bit more space, but it's enough to consider of thickness 2 delta. So, for this observation, you can also write this PSP and delta omega as the functions u. As the functions u in Lp omega2 delta with the property that the non-local gradient is Lp omega delta and this will have the same value conditions in omega 2 delta well omega. So in this double layer strip. Okay, so on the next slide you will see that the properties that we appreciate so much about the classical Sobolev spaces, they carry over to the setting. So we know they're Bana spaces and they're reflexive for p greater than one. We have density of sweet functions. Then also MC and Spector observed that the fractional spaces are equivalent to the best potential spaces, which has some very nice implications. And in general, we have And in general, we have a good toolbox of inequalities available here. So, and like analogs of Poincaré type inequality, there is Sovo-Lef-Mori inequalities with the corresponding embeddings, and we have Relicha-Rahov-type cactus results. So, these are nice spaces to work in. So, what else are we going to use? So, along the way, we'll be doing cutoffs and for that, um this light width rule here, these lightness rules are important. Laglish rules are important. So, if you were to calculate these expressions here on the left, you would end up with some unpleasant-looking integral terms, so non-local ones. But luckily, they are all hidden in these expressions chi and L, which turn out to be nicely bound operators on the P. So there you have good control, which is going to be helpful. And so, then, as a corollary or consequence of this Lightnitz rule for our complementary value spaces, Complementary value spaces, we can show what is called strong convergence in the complement of colour. So, here's what it says: if we start with weakly converging sequences, then we know that the corresponding non-local or fractional gradients here converge strongly outside in the complement of omega or in the colour. So, and the proof of that is actually quite simple. So, it only requires a few ingredients. Whereas two ingredients. So, on the one hand, the Leibniz root here, and the compact embedding between the strong conversions of this sequence UJ in LP. So, we'll see along the way that this result will have some implications for our analysis. So, then I continue with the next ingredient. And this is about really the basis of our analysis. So, the next section is about the connection. Section is about the connection between the different types of gradients and particular connection with the classical gradient. So, Arnon, let's see you. So, if we start with smooth functions with compact support, she and Spector show in this work here that the fractional gradient is the gradient of the Riesz potential. So, Ries potential is the convolution with the Ries kernel that we've seen earlier. And yeah, so this is a nice formula. There is also a non-local counterpart here. Non-local counterpart here, where the kernel function here Q delta is integrable with compact support, and given by this integral expression here, it involves this cut function. That's what I showed you earlier. And yeah, so these are really nice formulas. And the only problem is that they're restricted to a smaller class of functions only. So you may wonder, does this extend, for example, to subtle functions? And well, the answer is yes, if we're willing to ignore a little issue related. Ignore a little issue related to local integrability. So here's what you have in the non-local setting. If you convolute your function with this term of delta s, you get a function whose gradient is equal to the non-local gradient of the function you started with. And in the fractional case, here we can also find a locally integrable function, as locally w1p function, whose gradient is equal to the fractional percent. So this is nice. So this is nice because it tells us from the, we can turn local and fractional gradients into local ones. So then you wonder, does it also work the other way? And to see this, you look here. So it is well known that the fractional reflacian is inverse, the inverse of Reese's potential. So if we then, with this in mind, apply the DS, the model of radius. dA ds, the non-local gradient, to the fractional Laplacian of order 1 minus s over 2, then we are able to recover the classical gradient. So again for smooth functions with compact support. In the non-local setting we came up with an analogous operator that helps us out here. So summarily what it does, it inverts convolution with q delta s, so with this kernel function, in Fourier space. And then we need to make sure that this operator is well defined. Sure, that this operator is well defined, which that one can do by the properties of the Fourier transform of this q delta s. And then you see that this construction really does the job you want it to do. If you apply the non-local gradient to p delta s, you again end up with the classical wave. Here again, question, does this extend to the soboleft setting? And answer here is yes. And the reason for that is because the fractional applaution also the zoom operation. Laplacian and also the super operator P delta S, they can be shown to be bounded linear or extend to bounded linear operators from the local to the non-local spaces. And so this proof here goes back to work by Colmy Stefani in the fractional Laplacian case and for the operator P delta S we can use it together. So let me show you the picture. So now we can switch back and forth between non-local and Between non-local and fractional, non-local, and classical gradients. And then, just out of curiosity, also people might wonder: is there a horizontal connection? And yes, there's also a horizontal connection, which is not difficult to see. So, if you have a look at the difference of these gradients here, you see that they can be written as a convolution expression here, with a function a defined like this. And because a is equal to 1 in a small neighborhood around the origin, this is locally equal to. This is a locally integral function, which tells you that this convolution operator is a Meissen bound operator on Lp. And with that, you can then make this connection in the lemma here, show that the fractional and the non-local spaces on the whole space are equivalent with equivalent norms, and you can really change from one to the other with this cognition operator. So, all in all, so now we have arrows going in. So now we have arrows going in all directions, and this is like the complete picture. Now, these technical tools at hand, I'd like now to come back to the functionals we were interested in, so non-local fractional functionals, and start on the question Q1 about lower semiconductors. So let's compare with the classical settings. So there I'm not saying anything new. If we have a functional that depends. If we have a functional that depends on a classical gradient, weakliovosmic continuity is characterized by quasi-convex sounds. So, this we've heard a couple of times. Now, the question is: what is the right convexity notion in our setting? And there have been some literature around unsufficient conditions. So, there was first convexity, Rashi's factor, and there was then over convexity later on, but there hadn't been any necessary convexity. With any necessary conditions. And now, together with Jach Hide in the fractional setting and with Javier Hide in the non-vocal setting, we were able to come up with a full characterization of sound. And this is what I want to show you here. So this is the theorem we have. It says that, okay, under these assumptions, the functionals we are considering here are weakly lower semi-continuous if and only if f is quasi-convex. Okay, so this is the Now, okay, so this is the what it means. So we have this Jensen's type inequality where the test fields are classical gradients of Lipschitz functions with periodic boundary conditions. So I like to stay with this result or claim for just a bit longer because there's something that may be potentially confusing or astonishing about it and that is the characterizing condition. The characterizing condition is independent of s, so the fractional parameter, and the delta, so the horizon parameter. And also it doesn't involve any fractional or non-local derivatives. And now maybe some of you may have conjectured something different. Maybe instead of this classical gradient here, a non a fractional or a non-local gradient, the notion of convergence sorry, the notion of convexity would then be something like V nause, or V s delta quasi convexity. For BS delta quasi convexity. Okay. I promise I'll come back to this point after I explain to you. It's okay for P equal to 1, right? P equal to 1 should be okay. P equal to 1. Okay, so we didn't, to be honest, we didn't look into... Well, if you stay within space. Ah, so. Yeah. P equal to 1. If you stay within space, right? Ah, yeah, okay. So. So, okay, now I wanted to get you the idea of the proof. So, this is the overall proof strategy. So, that builds on this connection between the different types of gradients we just discussed. And the idea is like it's a translation procedure. And here it's like, okay, super bold and simple. So, if you want to prove a result in the fractional, in the non-global setting, then what you do is you transfer your gradients to classic gradients, then you're in a standard situation. There you have a lot of results to choose from. Have a lot of results to choose from. From the classical setting, you pick what you need, apply it, and go back. So, this is roughly speaking the idea. Sounds very easy, also almost like trivial, but of course there are some technical delicacies one has to be careful with. And I'll show you now a bit more about the proof of lower semi-continuity and point out to you what works well and where one really has to be a bit careful. So, I look at first into Yeah, so I look at first into um sufficiency in the case of non-local gradients and the idea here is to split and the integral in two. So we're um working over omega where we do this translation procedure I just explained and then we're working in this boundary layer, so in this strip here, omega delta with omega, and there we explore the strong convergence of our non-local gradients. And so yeah, just to show you like in detail how it looks like, if you have a weakly converging sequence in our A weakly converging sequence in our complementary space, then we can find classical Sovolef functions whose gradients correspond to the non-vocal gradients of the functions we started with. One can show that they also converge weakly in W1P. So then it's what you do. You're interested in this lib-inf here. You split F into two parts here. In the first part, you apply this identity to pass to classical gradients. In the second one, here, this boundary layer, you use strong. Boundary layer, you use strong convergence to pass to the limit. So then the second term here is happy already. And then it's just about applying the classical lower semi-continuity result here. So recall that f was quasi-convex in the second variable. And yeah, eventually we translate back, put everything together, and this is the sufficient condition. So there, everything went very smoothly. Now, if we think the Now, if we think in the other direction, so about the necessary conditions, there are two technical issues that I'd like to point out. And the first one is related to boundary and complementary values. So as nice as this translation method is that we discussed, it doesn't behave well with boundary and complementary values. So there's something to watch out for. And the way we deal with this is with careful cutoff functions and these Leibniz rule estimates that I explained. Leibniz rule estimates that I explained earlier. So then there's a second issue, and this has to do with the fact that there are no affine functions, at least not non-trivial affine functions, in our non-local space HPDL. So in these complementary valve spaces. And yeah, so this is something we would like to have in principle if we wanted to mimic classical arguments which have the idea of gluing some oscillation functions on top. Some oscillation dating functions on top of affine functions. And so the way around it is that we simply construct a replacement. So we construct functions here, phi, with smooth with compact support, that have a desired value in a prescribed point. So now since these are non-local operators here, this is not immediately obvious, and I'll show you how this construction can be done in a simple Can be done in a simple setting for the fractional gradient. So also if we recall the properties of the fractional gradient, so the invariance properties and the homogeneity, it's enough to reduce this construction to finding a smooth functions. Fractional gradient in zero is a multiple, so now zero multiple of the first unit vector. Okay, so how do we do this? So we do a multiple. So, we do a multiplicative ansatz here with functions psi and theta that satisfy this list of properties. So, part is just look at the picture here. This is what it roughly looks like. And then you can do explicit calculations. Then you can calculate the fractional gradient of phi in zero in the first and the second component by evaluating these integrals. Then you explore the properties. So, you see, this is an integer, this integrand is. And this integrand is odd with respect to the y2 variable, so the integral is zero. And here you see the integrand is strictly positive, so we get here positive value for the first component, and this is what we wanted. Okay, so that's all I wanted to say about the proof of the lower semi-continuity result. And now, as promised, I'm coming back to this question of quasi-convexity versus ds or vs delta quasi-convexity. And here is And here is what we would not the precise definition of what we would mean by ds or ds delta quasa convexity. We just plug in in it the Stensen's inequality these test fields and that are non-local fractional gradients and we take Yoda functions with p equal infinity. So now comes the good news because no matter what you conjectured earlier you were always right because all of these notions All of these notions are actually equivalent. So, and this again has to do with this translation procedure that allows you to preserve periodicity. So, if you remember, so the translation didn't behave well with respect to boundary and complementary values, but periodicity does go through. And once you have this, you can easily show the equivalence of these three notions. So, in this statement, it's enough that the H is ds was a complex for one s, right? Not for all of them? Yes. Yes, yes. Okay. Then it is quasi-convex and it's quasi-convex forward. Exactly. Yes, yes. So and now. Okay, so now I think with that we can close the. I think with that we can close this question Q1 because we've even found three equivalent characterizations of weak lower stellar continuity, one of which was a quadrat convexity. So this can be considered the right notion for all three settings. So Q1 is done. So we have three more to go. So the other questions fall under this headline here. And I'll just call Q3 next. So this was about the Next. So, this was about the asymptotic behavior of families of variational problems. And yeah, so this calls for gamma convergence. And based on our translation mechanism, we can prove a general gamma convergence result, which is stated here. So, let me just give you the ingredients. So, we have Cardi functions fj, so j natural number over infinity, with let's see over growth and coercivity assumptions. So, we use Assumptions. So we use those to define three types of functionals. So first functional is a functional depending on non-local gradients, so these are the FJs. So then we define the local analogs, so depending on classical gradients, these are the dijs. And then we define these local boundary layer integrals, like here. So you integrate over the boundary layer and plug in a matrix field, LP matrix field. So the theorem now tells you that if we know that Tell you that if we know that the local analog is gamma-converge and we know point-wise convergence for these boundary layers, then we also automatically have gamma convergence of our non-local functions. Well, this solves then the question Q3 about gamma convergence. So now, what does this mean? So essentially, this result gives a nice tool to carry gamma convergence results from the local to the local Convergence results from the local to the non-local setting without any additional effort. And this is what's nice about it. And so, in that sense, this can be considered maybe a useful tool. And I'd like to illustrate this with two examples. So, they are very basic examples, but I think they help to make the point. So, the first one is one of the most popular applications of gamma convergence. So, this is in homogenization. This is in homogenization. And we've seen during the week already very nice recent developments in this direction. But since the literature is so huge, I decided to just focus on very classical results here to make the point. So this papers by Grey Zenberg. So what they considered was the local analogues of these functionals f epsilon here, which involves a fast variable, the capital. A fast variable that captures the periodic structure of the heterogeneities in our material. This F here is assumed to be periodic in the first variable. And now if we combine this classical result with our result from above, we automatically, and with no extra work, really get a gamma convergence result for this family of functionals at epsilon, where we observe, yeah, so they gamma converge, and the gamma limit is given in the And the gamma limit is given in this proof. So let's have a look at this. So it has two ingredients, sorry, two terms. So the first term here is the integral over omega, where we find as an integrand, the homogenized integrand of these classical results, which are given by this multi-cell formula here. And in the boundary layer, we get an integrand that results from averaging just F over the periodicity cell. The period is D Cell. So, this is the capacity. This might be jumping a little ahead, but can you take epsilon and delta simultaneously to zero? Okay, so okay, let me come back. This is on my last slide on outlook. Okay, and so then this is also the second application, also very basic and simple, about relaxation. So, relaxation is about Is about characterizing this Huig-Lower semi-continuous envelope. And you know, very well in the classical case, this is done by quasi-convexification. And so since this Huig-Lower semi-continuous envelope corresponds to the gamma limit of the constant sequence, then it's again an immediate consequence of what we've discussed earlier to find this relaxation formula here. So in the integral over omega, you take the quasi-convexification of f and Specification of F and in this boundary layer, just keep F unchanged, and this gives you your realization. So with this, then also question Q2 is answered. So yeah, so then only remained question Q4 about localization for the limit, so as fractional parameter S goes to 1. And so what the question was, do minimizes of FS converge to minimize of a class value? Converge to minimize the superclass of a local problem, and the answer is again consequence of this theorem that we have here. Yeah, let's see what it says. So, under these standard assumptions, and if we assume that f is quasar convex, we see that what we expected, that these f s gamma converge to a classical local functional that depends on a local classical gradient. And important, we also have along with this the corresponding. Along with this, the corresponding compactness, so incursivity of these functions FS. I just give you a few ingredients of this proof. So there are three main ingredients that go in. So the first one is this translation procedure that we discussed. So this is going to be handy. Then second ingredient is the localization of the non-local gradient. So meaning the following, so this showing that these non-local gradients for smooth functions come. Gradients for smooth functions with compact support converge uniformly to the classical gradient. And this is pretty easy to prove here. It's just like two lines. So you show that this kernel function q delta s has an L1 norm that converges to 1 and that it localizes around 0. So then essentially this q delta s converges to a Dirac delta and this then gives you this conversion. Gives you this convergence that you want. So, and finally, last ingredient that we need is a non-local Poincaré quality. And this per se wouldn't be such an issue because they are available. But what we need is we need the constants to be uniform in S. And this requires a bit of extra work. And here's just how we go about that. So, a general difficulty when you want to prove Poincaré inequalities with these A. Comparing equalities with these HSPs on our spaces here is that when you look at the L p norm of the non-local gradient, there can be some cancellation effect. So that's because there's an integral inside the absolute value. So if you compare, for example, with the Galviardo slope that's the type semi norms, and that wouldn't be the case. And so in this work here by Liluque Domora Coral, they go about this by proving a non-local fundamental theory. They're proving a non-local fundamental theorem of coverings. So, what do you mean by that? So, they can recover functions in C C infinity by convoluting the non-local gradient with a boot kernel function, V delta S, which is defined by Fourier transform. So when you look at the results, it's pretty intuitive that this is what the Fourier transform should look like. The difficult technical part is to ensure that V delta S is really a function. So this is where all the work goes in. This is where all the work goes in. So now we were trying to work with this, but since this V delta S is so implicitly given, we couldn't really find a good bounds based on this approach. So that's why, and then Lide came up with a different idea, and this then worked out well. So it was about proving a uniform estimate like that. So estimating the L P norm of the non-local gradient of order. The non-local gradient of order s by the L p n of the non-local gradient of order t, where t is greater or equal than s, and important, with constants independent of s and t. So, once you have that, it's pretty immediate to see that this will be the most good from bound in the Point-Carl inequality. And so, how do we do this? There is a simple case when t is equal to one, so this simply follows by Jans-Karvin inequality. So, I think this is basic. Basic. In the general case, we work with Fourier multiplier theory and show that this function here, MTS we called it, which is the quotient of the Fourier transforms of these kernel functions q delta s and q delta t, is actually an L P multiplier with norms independent of S and T. And yeah, so for that we use the Michelin-Permander multiplier theorem. And once you Theorem and once you establish that, then you see: okay, so this non-local gradient here, ds, is the same as taking the Fourier multiplier operator of the non-local gradient of order t. And then, I mean, your estimate up here is okay. So now let me just wrap up, because now we have all our three ingredients in hand, and this is all we need. In hand, and this is all we need in order to conclude the gamma convergence and the corresponding compactness. So we combine the localization of the non-local gradient with the Poincare inequality to get this compactness result. And it says the following. So if we have a sequence of uniformly bounded gradients in a sequence in our complementary value spaces with uniformly bounded non-local gradients, then we can show. Then we can show that there is a sublime function, W1P, so that we have strong convergence in Lp and weak convergence of the corresponding non-local gradients to the gradient of the C. So then once you have this compactness for solid hand, then again equicorciity is an immediate consequence. Then remains the LimInf and the Limsuk inequality. For LimInf, we use this language. For the inf, we use this lemma together with our translation procedure, and the zoo inequality is actually pretty simple. You can construct a recovery sequence based on this localization of non-vocal frequency. So then everything is done, and we have proven our localization limit for S1, and this answers the question Q4. So then, with this, I can wrap up. And give you a summary. So, what we set out to do was to contribute to a variational theory of these non-local and fractional functions here. Our main ingredient, main technical ingredient was this translation mechanism between the three different types of gradients. And based on that, we could then identify classical quasi-convexity as the correct notion also in the fractional. Correct notion also in the fractional and in the non-local setting. And also, this translation mechanism helped to carry Yama convergence results from the local to the non-local world, which I should illustrate it to you or try to convince you that was helpful with homogenization and relaxation in statements. And then eventually every solar, the localization as it tends to happen. So there are many different directions where you could take this forward. So I've just listed. This is forward, so I have just listed three here that I find pretty interesting. So the first thing we've started to work on with Gide is looking into non-local inclusion problems. So where we're not just interested in working in complementary value spaces, but also understanding the role of different types of boundary data, boundary assumptions. And so a first step towards that direction is And towards that direction is really to get a better understanding of the structure of these non-local gradients in a particular characterized set of functions for which the non-local gradients vanish. Just to say it's not just constant functions. And so the next interesting point I find is the varying horizon asymptotic analysis. So this goes in the direction of what you said, taking limits in delta, delta to C. In delta, delta to zero, and delta to infinity. So we haven't come find it with any other parameter, but yeah, so this would be the first thing to do. There's also partial results in these papers available about the limit delta to zero, but then they don't have a corresponding compactness result, which would really be the tricky part to add here. And another interesting point also to consider inhomogeneous horizons. So delta x dependent and getting smaller and smaller the closer you. Getting smaller and smaller the closer you go to bounding. And finally, then just a bit more on the applied side, you could wonder whether those functionals that I showed you could also serve as good regularizers in applications in image. With this, I'll stop here in case you're interested in the references station here. So thank you very much. Yes? I have two questions. Well, thank you, it was very nice. The first question is: you have these different notions of quasi-complexity, right? And you said they are equivalent, I mean, qualitatively equivalent. They're also equal. Exactly, yes. So you're saying you have a formula for quasi-complexity that does not depend on distribution of the gradient. So that doesn't depend on classical gradients, yes, Roger, but on these non-studio algebraic definitions. This is an alternative definition, yes. Yes. So this becomes the translation, so you can go back and forth and the per dubicity is. So I have a have a stupid question. I mean, you have to go back to lower, lower, standing content. So this is all the way I I'm a bit confused. I mean why? Explain to me why the why this doesn't follow from ALSIC. I mean they have okay they have operators with constant coefficients, but you can take differential operators. I mean you have on your field. As far as I understand. That's an AO view. Sorry? This is what you call an AO view, right? Right, right. So you have a, I mean, what happens as hard as I am? What happens, as far as I understand, right, is that you can have a quasi-convexity, so you can't define quasi-convexity for an operator. And it may have, you know, this is a notion that is in some sense independent of the operator. It only depends on certain bundles such as the operator. You have to look at the characteristics of the operator. So the C pairs C and lambda such that A of C at lambda is equal to zero. Is equal to zero. And I think it must happen that, you know, if your gradient is just a multiplication in Fourier space, so then the bundles are the same, therefore the notions of Hasi convexity are the same. And I would think this must follow from what I read in the league step in. Yeah, so I think what I like about this approach here is that you really get an intuition for the problem and because it could be that maybe we should have checked this that eight markets is powerful, right? So that can do a lot. Okay, well, so I actually have a question. Well again, exactly the same thing. You can do this for any order because again Order because again, for correct, it doesn't fit. Yeah, okay, that's true. There was a question that I saw somewhere, Andrew. So one of the simplest differential inclusion results would be if you have, say, 2 by 2, two matrices that are not connected, and you have a differential inclusion integral, then it's constant either one or the other. Can you do something like that in a fractional setting? So I think this is what I was trying to say. I think this is what I was trying to say. So it really depends on the kind of boundary values that you pose. So if you do the whole plane, no boundary values at all? Yeah, so there is still this issue of basically identifying the functions that have zero non-local gradient. So basically, this is what we're trying to do. And these are not all constant functions. So I mean, in some sense, the idea would be really in that direction I'd identify the functions. I'd identify the functions with zero non-local fractional gradient, and then basically applying the translation procedure to take the results that are well known in the classical setting to transfer them. But then the difficulty is preserving exact inclusions is maybe difficult. So by now we can go from exact to approximate inclusions. But as I said, it's something we just started, so it's maybe a bit too early to tell more. It's too early to tell more, but yeah. I think we'll need to stop here. Thank you, Kylie. Can you set up your machine for you guys?