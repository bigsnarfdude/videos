University. So, what I do is to sorry, I want to take a little bit. So, I'm going to present our method that is second-order invariant domain preserving, but in the Domain preserving, but in the ELE framework. Okay, sorry. So, this is the model problem that we solve. This slide is just to introduce some notation. So, we consider this hyperbolic system. So, U is the solution, difficult solution. F is going to be the flux. So, for simplicity, we consider a periodic boundary condition or that. Condition or that U0 is constant outside a compact set. So, this is a general way to write Euler equations or shallow world equations, for example. So, if we solve this hyperbolic system using arbitrary Lagrangian, Eulerian ALE, because we want to combine the advantages of the Lagrangian and Eulerian descriptions, the classical descriptions. When we do ALE, we can move the notes. We can move the nodes with the flow, the nodes of the mesh, or we can keep them fixed, or even we can move them in an arbitrary way. What we do is move the mesh nodes with the flow, and then we apply some smoothing. The main motivation to use this ALE techniques is because if we keep the mesh motion as close as possible to the actual fluid motion, fluid motion, we reduce the effects of the artificial viscosity. So in our work, we formulate the artificial viscosity problem with hyperbolic system using these ALE techniques, but also we use continuous finite elements and an explicit time stepping. First, we proposed some years ago a first-order artificial viscosity. A first-order artificial viscosity method. The advantages of this viscosity is that it does not depend on any parameter, also leads to precise invariant domain properties and satisfy some entropy inequalities. Then, after some years, we start to combine this low-order method with an entropy consistent high-order method using a convex limiting process. So, at the end, we obtain a second-order method that also Second-order method that also has the boost properties as the low-order one. In this talk, I'm not going to go into the details of the mathematical formulation that we need to prove all the good properties of these two methods. What I'm going to do is to give the details of the computational implementation and mainly focus of how we compute the ALE motion. The ALE motion and how we do the ALE formulation with these techniques. This is the outline of my talk. First, I'm going to talk about the ALE formulation and the approximation of the ALE motion that we do. Then I will introduce briefly the first order viscosity and the second order viscosity. And then I will explain the convex limiting technique all. The convex limiting technique only for Euler equations because I'm going to present the method, a simplified version of the method, just for Euler equations. And then I will show some numerical results. And finally, I will show some conclusions and the future work that we are planning to do. So I will start with the ALE formulation. In this scheme, you can see the relation between the Lagrangian and Between the Lagrangian motion and the ELE motion. Essentially, to obtain the ELE motion, we optimize the mesh that we obtain when we use the pure Lagrangian motion. At the end, what we need is an ALE motion that is uniformly ellipsed mapping. And we denote with BA the spatial description of the associated velocities. We are going to approximate the motion using Lorentz finite elements because it Finite elements because in that way, the ELE motion is going to be fully described with the motion of the Lagrangian nodes of the mesh. We denote with NGO the number of nodes of the mesh because I'm going to use N for the nodes of the degrees of freedom of the discretization of the hyperbolic system and NGO for the Lagrange nodes of the mesh. Of the niche. So, a key issue for defining the ALE motion is the optimization of the mesh. And we do this in two stages. First, we do a high order reconstruction of the low-order velocity because we solve Euler equations using P1 finite elements. We can define the ALE velocity. Define the ALE velocity in the easiest way that is set the ALE velocity equal to the Lagrangian velocity. But if we do that, we obtain also a low-order motion. And with this low-order motion, maybe we cannot capture all the features of the flow when it has some vorticity. So we need to increase the order of the ALE velocity. And we found the answer to this reconstruction problem. This reconstruction problem in this paper related with computer graphics literature. They do in this paper this butterfly subdivision algorithm and the main idea of this algorithm is in this picture. So if we have the P1 velocity defined on the vertices of the mesh and we want the velocity to be P2, that means we need the values on the midpoints of the we need the values on the midpoints of the of the elements what we do is also uh sorry what we do is to construct this macro element that this form with the with the element this element and all the neighboring nodes and then we assume that the velocity is a p2 in this macro element and then we just need to evaluate the in the midpoints of the triangles this p2 velocity defined in the macro element True velocity defined in the macro element. This is something similar that is used in the local projection stabilization methods that also use two measures and define also these macroelement measures. If someone in the audience is familiar with these kinds of methods, it's similar to that. So once we have the velocity defining all the midpoints of the mesh, points of the of the mesh we can continue doing the same process and we can obtain a p4 velocity well maybe we can continue and have more order but we just consider it consider p2 and p4 once we have this this reconstruction we compute the lagrangian motion of the nodes with this scheme we know that using well also That's using, well, also is supported in the later actual that if we use higher velocity, the mesh is going to collapse later, or even in some cases, we avoid the collapsing of the mesh. And one example of what I'm saying is: if we try to solve this isentropic vortex, that is a vortex that is moving in this direction and to the right, and we And we move the mesh using just the Lagrangian velocity as we obtain that from Euler equations. The mesh is going to collapse at t equal to two seconds. But if we use P4 elements, we see that the mesh collapses two seconds later, almost one and a half seconds later. And a half seconds later. So, these results make the point that we really need to use higher reconstruction of the velocity. But we know that the mesh eventually is going to collapse, so we need to add some smoothing. So, what we do in every time step is to smooth the mesh. Another option. Another option would be to use a purely Lagrangian velocity and when the mesh collapses do some smoothing. But the problem on doing that is that when we apply the smoothing, the velocity is going to be really different to the other one in the previous step. And sometimes we have problems with the algorithm. So what we propose is to do a small smoothing of the mesh in every time step. And we consider these And we consider this method. What we want is to optimize the position of one of the nodes of the mesh, for example, in order to have this element as close as possible to the reference element. To do that, we define this reference application, this is the classical reference application with four finite elements, and the Jacobian of this reference, of the reference application. Applications and we write the Jacobian in that way, so that A is the position that we want to optimize. So the Jacobian depends on this position. And then we define one target optimization convex functional, consider that one, that takes into account all the elements where the note AEA is. Well, in this literature, Well, in this literature of optimization of measures, you can see many different functionals. This is the SS one that at least easiest to program. So it's what we choose. And when we have defined the functional, we do one Newton step, just one Newton step, and we do it locally in every node because, well, we don't have the computational The computational capacity to solve a global optimization. The idea of this method was taken from these two papers. This second one uses a very similar procedure, but they do it for straight elements. But we tried the same one and it was not working properly because of that. was not working properly because of that so we take the the idea of this other paper when where they use high order elements once we have the the smooth version of the mesh on the lagrangian version of the mesh let's call it like that the final node location can be computed as a convict sorry as a linear combination of the two versions of the mesh to do that we use a blending parameter that is going to be Parameter that is going to be between 0 and 1. So if this parameter is 1, we use the smooth version of the mesh, and if not, we have a combination of both. At the beginning, we start using a constant blending parameter, but we realized that sometimes we were introducing too much smoothing in the mesh. So we realized that this blended mammal. We realize that this blend diameter has to depend in any way of the formation of the mesh or maybe on the solution. So we consider this definition of the blending parameter. We consider this mapping and also the Jacobian matrix. And then we can define the right Cochiguing straight tensor and compute the eigenvalues. We are going to assume that the first eigenvalue is smaller than the second. Is smaller than the second one, and we compute these eigenvalues in all the Lagrange nodes of the mesh. Then we compute the ratio between the two eigenvalues, and we compute the mean value in all the elements that contains this node. Then we use this definition of the blending parameter. This definition of the blending parameter. This definition of the lending parameter is based on this work of Lubert and colleagues and is widely used in the ALE methods. At least it's what I saw in the literature. So this is the definition of the blending parameter. And as we are going to construct a method that does not depend on any parameter, we are On any parameter, we are defining this blending parameter using this S. And we have to define or set one value in every simulation. And in most of our simulations, we choose S equal to 2, but we know that we have to set maybe equal to 3 or 4 to have a mesh that is more. To have a mesh that is more smooth, so we don't want to be touching this parameter in every simulation because we want a parameter-free method. So we need to work a little more about this parameter. Once we have the final location of the mesh node, we define the ALE velocity in this way, and as I said. And as I said before, we define the ALE motion just using the final location of the notes of the mesh. Well, in this slide, I will compare the difference between the Lagrangian and ALE formulation. Maybe this slide is a little basic for the audience, but maybe if someone is not familiar with these techniques, it could be. With these techniques, it could be helpful. So to do that, I will consider just the transport equation. And you know, if you compute the time derivative of the solution along the characteristic course of the fluid, if we use a Lagrangian approximation, this time derivative, the standard derivative is equal to zero. But if we use a Lagrangian ALE motion, what we have here is What we have here is the difference between the ALE motion and the Lagrangian velocity or the free velocity. So, if we use an explicit Euler method with the Lagrangian approximation, our solution is just translated along the characteristic course. But if we use an ALE approximation, we have this term that depends on the difference between the two velocities. In our first paper, In our first paper, we proved this lemma, which is the main motivation to obtain our ALE method. So we are going to discretize this equation. In this equation, what we have here is a modification of the flux of our hyperbolic system using the ALE velocity. And we are going to call this ALE flux. That is going to appear in many definitions of our method. To discretize, To discretize the hyperbolic system, we consider continuous finite elements. In our case, we consider also Lagrange finite elements, in particular P1, but any other finite element spaces can be used for definition for the discretization of the hyperbolic systems. As we are considering an ALE approximation, we have to consider the Have to consider the domain in every time steps. Also, we move the nodes of the mesh, and also we have to update the shape functions using this ALE motion. So, we are going to approximate our solution in the instant gn using this approximated solution in the finite element spaces. The main steps of our algorithm is first we initialize the mass matrix, we use the Lambda mass matrix. Matrix, we use the lampet mass matrix, then we approximate the velocity given. As we have a higher velocity, but we are using P1 in our case, we have to do this approximation of the ELE velocity. Maybe if you use another finite element space, you have to do some interpolation. Then we move the mesh. Well, this third step can be the second one. You move the mesh and obtain. You move the mesh and obtain the final location of the mesh, and then you update the mass matrix using the Reynolds transport theorem. We update the mass matrix in that way because it's the only way that we can use strong stability preserving methods. In fact, in our scheme, we consider Rho Hebuta 3, so our method is order 3 in time. With this notation, This notation is for the support of the shape functions. And then we compute our new solution using this scheme. As you can see here, it appears again the flux of the hyperbolic system modified using the ALE velocity. And with this calligraphic I we denote the neighbor nodes of the node I. So the matrix CIE is as usual, I think it was defined before in another talk. And we consider this artificial viscosity. So the method is going to be order one or order two, depending on how we define this artificial viscosity. So I will describe how we define this first order viscosity. To define this viscosity, To define this viscosity, we consider the one the Riemann problem. So we have the solution in the nodes i and j, and we define the one the Riemann problem. But in this case, we have to define the flux using also the ALE velocity. Well, as you may know, we define the fastest wave speed in that way. And also, we have these left and right wave speeds and modified using the And modified using the early velocity. Once we have this lambda max, we can define the viscosity, the low-order viscosity, using the lambda max for the maximum value of the lambda max for the node J and for the node I. And then we consider these diagonal elements, but it's just to define the CFL condition that we need. We prove in our first paper about this topic. About this topic. We prove this theorem that the mass, this quantity, is conserved and also provide the CFL condition. We have local invariance and also global invariance. So the scheme preserves all the convex invariant sets and also satisfy this discrete entropy inequality for any entropy pair for the hyperbolic system. For the second order method, we define an entropy viscosity. So, for every entropy pair for the hyperbolic system, we need to define an entropy pair for the modified flux with the ALE velocity again. So, we know that the exact solution of the hyperbolic system satisfy this relation. So, we define this entropy commutation. So, we define this entropy commutator to see how well the approximate solution verifies also this relation. Once we have the entropy commutator, we construct a normalized version of this entropy commutator we call RR and is between 0 and 1. Once we have this entropy residual, we can define the high-order viscosity in that way. So, if the residual is one So, if the residual is one, we will cover the lower the viscosity. And again, we define the diagonal term for this matrix. I'm going to present how we do the convex limiting in a general setting, and then I will focus on other equations. To do this convex limiting, we define these numbers, lambda, that, well, they assume one. I think in our paper. I think in our paper we give another definition for these numbers, but well, in the code we use that one. So the high order solution can be written in this way as a combination of the low order solution plus a matrix that depends on the difference between the high order viscosity and the low order viscosity. So our goal is to find symmetric limiting parameters so that this Parameters so that this limited solution satisfies the expected bounds. So if the limiters are one, we recover the high-order solution, and if the value is zero, we have the low-order solution. So we have a solution between these two low-order and high-order solutions that they are going to satisfy the expected bounds. In this paper of German and his colleagues, And his colleagues, they prove these results. So if we have a convex set and we know that the low-order solution is in this set, where we have a quasi-convey functional, they prove that there exists this limiting parameter that is defined in that way, such that the limited solution is also Solution is also in the convex set. And then we just need to symmetrize the parameter considering the one between lambda i, between the node i and j and the opposite. And once we have this symmetrix parameter, we also have guarantee that the new solution is in the convex set. And how we do this convex limiting for Euler equation? Well, we know that the Euler equation and That the Euler equation can be written in the general form that I show in the first slide, where U is this and this is the flux for Euler equations. We also need to define the specific energy and the specific entropy, and we also use this equation of state. So, we know that this set is invariant for any S-min entropy, and we want to enforce And we want to enforce also these local bounds. Well, in the talk that Manuel gives on Monday, he explained better than me what are the differences between the global and local bounds. So maybe I don't need to explain so much about that. So we want to enforce also these local bounds and to define these local bounds, we use the AUCR intermediate states that were also defined yesterday by Hens also and many others. Also, and many others that are called also bar states. But these bar states, in our case, are also modified using the ALE velocity. This is the difference with the other bar states that other speakers talk about. So we use this bar state to define the local bounds and then we apply the conductivity technique. So we define these functionals. These functionals. The first and the second ones are just to keep CT between the bounds. And then we are going to define another one to ensure that this inequality is verified. We define this CI mean so we know that this inequality is equivalent to that functional V greater than zero. And then we define this set B all of the solutions. This set B of the solution that satisfies that all the functionals are greater than zero. In our paper of 2019, we proved that if the previous solution is in B, then provide the CFL condition again, our limited solution is again in B. That means that if our ALE velocity is smooth, the scheme is going to be not only Scheme is going to be not only invariant domain preserving but also is going to satisfy the local bounds. Finally, I'm going to show some numerical results. First, we solve the no problem. We know that the solution of this problem is a wave propagating radially upwards with a constant speed. This is the exact solution. We consider this domain, this computational domain, and we are going to. Domain, this computational domain, and we are going to simulate until 0.5 seconds. As we are doing ALE, we know that our mesh is going to move to the center. So as the wave is propagating outwards, we only can simulate until these seconds to avoid the shock touches the boundary. And we consider these measures and we are going to solve this problem using all the schemes that we... A all the schemes that we have: the low-order one, the high-order one, and the one that is limited. Here you can see the convergence test. With the low-order method, we obtain order one, that is, it corresponds to what one can find in the literature. When we use the high-order one, the one with the entropy viscosity, our error is smaller, but Smaller, but we lost some order. But if we do the limiting, we still have smaller errors, even smaller than the higher order one, and we recover the other one. In these figures, you can see the difference between the three methods. So the first one is more diffusive. Is more diffusive, then we have the solution with the high-order one, and then with the limited. Maybe in these pictures, you can see better what is going on with the three schemes. With the low order, you see that it's much more diffusive. With the high-order one, we have overshoots and undershots, and with the limited version, our solution fits better the exact solution. Still, we have some overshots. Still, we have some overshoots, and this is related with the problem that we have to relax the bounds, the local bounds, in order to maintain the accuracy of the method. If we don't do that, we don't have the order that we want, the second order. Here, we compare the ALE technique with anablorian one. So, I solve with the best. I solve with the best of our best scheme, but without moving the mesh. And this is just to justify why we need to use ALE instead of Eulerian. You can see that the Eulerian solution is much more diffusive than the one that we obtain using ALE techniques with the same scheme. Then I will show you the results that we have with the double Mach reflection problem. Problem. This problem involves a strong shock that is moving in air and hits a wall that is situated with a 60 degree angle. So when the shock hits the wall, the solution starts to form this structure. You see that two triple points are formed and also these structures that are formed here. Structures that are formed here are very difficult to capture. You need to use a very fine mesh. In this, well, I take in this scheme of this paper, in this paper, it's about how to properly set this problem, because it is, well, in my experience, a very difficult problem to solve. As in the paper of Goodwater and Colella, what we do is to rotate the coordinate system so. The coordinate system so the wall is aligned with the computational grid. So, what we have to do in this case is to situate the shock also with this angle. This is a scheme of the boundary conditions that we have to impose in our scheme. So, we can see that flow, we set here the post- and pre-shock states, and here we use the post-shock state. And here we use the post-shock states. So the velocity is moving in this direction. The problem is that we are solving this double mark problem using an ALE technique and set the boundary conditions for the ALE velocity is even more complex. Because if we do what we need to do, this boundary should move with the fluid velocity. Should move with the fluid velocity. We are doing ALE. I haven't seen many codes, many ALE codes that solve this problem. What I saw is that they set the ALE velocity here to zero. But if I do that, I obtain very bad elements here just at the beginning of the simulation. You can see here some few pictures of what happened with With the mesh at the beginning. So, what I thought that it would be easy is to make bigger my domain so the mesh can move free. I avoid all these problems that I have at the beginning. So, I consider this domain because at the final time I have exactly the same domain as in the scheme. And with this, And with this technique, I avoid all the problems in the boundary. Then I consider this mesh that is much more coarse, the meshes that you can find in the literature that are formed by millions of elements. And then I solved the problem using ALE techniques and the Eulerian description. And as you can see, the ALE method, even when with Thought even when with this coarse mesh can capture a little bit these structures and the triple points that this is not happening with the Eulerian version of the code. Then we solve the triple point problem. You can see the description of this problem in this web page and also the way that this solves this problem is amazing. This problem is amazing. What we do, because our code is not prepared for multi-material, is solve this Riemann problem with one single material. When we do this setting, it's going to happen here. A vortex is going to be formed. And what we want solving this problem is to see if our code can handle this complex mesh motion. Mesh motion. Just before trying to solve this problem, we just consider that we move the mesh using the Lagrangian velocity and then we apply some smoothing, just considering the average of the neighboring nodes, just a very simple smoothing. But when we try to solve this problem, we realize that we need more complex motion. So this is the problem that make us do more research about. us do more research about how to move the mesh. So these are the data for the simulations. We simulate this triple point until five seconds. The mesh is not very fine also. And we solve it with the low order method and with the high order one but using the limiting technique. So in this video you can see how the vortex is formed and also how the and also how the ALE motion is following or try to follow the vortex formation. The problem that we have here is that the mesh is not following exactly the vertex, at least as we wanted to do it. But well, at least the message is content. This is the meshes concentrator where it should be concentrated. So, here you can see the difference between the low-order solution and the high-order solution with the limiting technique. So, the precision for the accuracy is much better here. Even we cannot have the same structures that Arturo were showing yesterday because we don't have also. Yesterday, because we don't have also computational capacity, and here you have the final mesh. So we see here some where the elements are close to the vertex, but we are not very happy with the image motion, not yet. So as a conclusion, we have shown our high-order entropy consistent method. Our high-order entropy consistent method. And we made this method second order using a convex limiting procedure, second order, and invariant domain preserving, because it was second order before. And with our formulation, we can use strong stability time discretization techniques, as I said before. And we test these new methods and the limiting procedure on a series of benchmark problems, and we observe. Math problems, and we observe that we have the same accuracy or similar to what is reported in the literature. And we, well, you can find more details of, especially on the mathematical derivation of these methods in this reference. And well, many more results, numerical results. And just to finish, I want to show Wanting to show the work in progress that I am doing now. So, as I said before, we were not very happy with the parameter dependency of the blending parameters. So, as in our method, we have many quantities that give us an idea of the solution, how it's going, if the mesh should be smoothed or not. Be smoothed or not, we have this residual, this entropy residual, but also we have the artificial viscosity. So, I made an initial guess. I don't know if it's well done or not, but maybe we can discuss it. So, to define a new blending parameter, I consider the diagonal elements, the absolute value of the diagonal element of the matrix. Element of the matrix, the viscosity matrix. The problem is that this matrix is defined only in the vertex of the mesh, but we have all this high-order reconstruction technology to define it on the Lagrangian nodes of the mesh. So I apply this reconstruction and then we do the same simulation of the triple points I just shown. And you see that more or less is the same solution. solution we well related with the with the mesh motion we can see that it's not so smooth but it behaves the same it follows the the vortex so yeah it's not so smooth especially here and you can see the difference between the two blending parameters if we consider s equal to If we consider s equal to, we have the final mesh here. And if we consider the diagonal of the viscosity matrix, we have this final mesh. And well, this is definitely more smooth, but it's very similar. So maybe it's a way to start to define a blending parameter that does not depend on any parameter that we don't have to do. Any parameter that we don't have to touch in every simulation. I also solve the double Mach reflection. Here you can see the velocity and the final mesh for the all blending parameter, the one that is defining the code. And this is when we use as blending parameter the artificial viscosity. And you can see that it's very similar. And again, the other one was more. The other one was more smooth, but the solution is very similar. So maybe it's a way to start a definition of a new ending parameter. And well, this is a future work that we want to do. We already have done something, but we are not finished yet. So we want to work on multimaterial. We want to properly solve this problem, and we have to define properly. To define properly our method to solve multimaterial fluids. So, well, this is a slide to propose Jaluk to go back to this work. So, well, thank you for your attention. That's all. Thank you very much, Laura, for this very interesting talk. The triple point results are awesome. All right. Questions for Laura? Mitri, please. Laura, I think it was slide nineteen, you introduced the generalized Riemann problem for the bar states, and the the flux function of this Riemann problem depends on the matched velocity. Depends on the mesh velocity. So, do we calculate DIG using the maximum?