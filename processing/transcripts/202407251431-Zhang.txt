Thank you for the introduction and thank you for the invitation. So today I'm excited to share a few computational methods that can help us making use of GIOS results. So the first challenge in making use of GOS results is the high dimension knowledge. So for example, if we're zooming out a small signal here, we can see that it was We can see that even in this small block, we have a lot of parts that have very significant p-values. So, are they equally important? And the next challenge is the correlation structures. We have correlation between different traits and different phenotypes. And we also have the correlation between genetic variants. So, this is something called linkage distributor. So, here we are covering the The LD between different pairs of generic varieties, and each red block represents a group of variants that are highly correlated with each other. And a useful tool to tackle this type of challenge is probabilistic graphical model. So basically, in this morning, we have seen a lot of graphical models where we use the nodes to represent variables and the address to represent. And the address to represent the dependency between them. And to make the graphical model into a probabilistic graphical model, we simply add distributional assumptions on each node, which is variables. And we color what we have in the data, which is what we observed, into our shading notes. And now we'll be able to infer the posterior. The Poissier distribution of all the latent variables. So, this is the general framework of probabilistic graphing model. So, a lot of models that we are familiar with, if you write out all the assumptions, it can be formulated as a PGI. So, here is a simple example of a linear regression. So, we got all those nice features. All those nice features with PGM, and now we pay the price at the inference state. So we can use the Bayes theorem to write out the posterior distribution of latent variables given the observed data. And then usually if you have a good enough model, you will have a very complex computation to invert the posterior distribution because the denominator here. The denominator here requires integration over all the 10 variables. And this is usually computationally expensive. And so over the history, people kind of avoid using TVM because of the high computation cost. And the good news is that now we have computers. So instead of doing the exact calculation, Exact calculation. We can do numerical approximation. So the idea is we use something that we can optimize to, so this is something we can estimate and manage, and this is the posterior distribution we want. Instead of doing the direct calculation, we figure out a way to minimize the difference between the variational distribution and the design. The design posterior distribution. And this is the idea behind the technique called vibrational inference. And today I'm going to use this technique to develop a series of methods that are efficiently making use of the drought results. And the first one is called fine mapping. mapping. So the purpose of point mapping is to identify potential causal markets for experiment validation. So our method is called Spartro and is published in the beginning of this year and now all the codes to reproduce the analysis are openly available. So we have so the goal of find mapping is to identify potential causal racks. So we want to integrate So we want to integrate the statistical evidence as well as the functional impact of the genetic variants to prioritize targets so that we can have a very efficient follow-up and increase the yield of the experiment analysis. And let's begin with the statistic evidence. Together with the dual summer test and the LDA information, we can have a rough general idea. Have a rough general idea of where the colour signals are, but we don't really know for sure which variants are the exact color barrel. And this is a limitation of the statistical evidence only. And then, in graphical model terms, this means that we actually observe the genotype, but we don't know which is actually the causal brand. So we have a Causal part. So we have a weird graph model now. And the solution we propose is actually to decompose this into the observed genotype matrix and the latent group indicator to group the correlated variables together. So this is why our method is called sparse probe because it introduces a sparse projection on the tilt matrix so that you have a Matrix so that you have a reduced dimension. So basically, the key idea is to work with the groups that are independent of each other instead of working with variants that are highly correlated with each other. And with the variational inference technique, we can first identify roughly which group is the most relevant candidates. So, this is the first step, and this is actually. Is the first step, and this is actually equivalent to the system model. And then we can add in the function annotation information. So we achieve this through introducing another latent variable, which is the variable probability of being causal, estimating from the function notation with the image from weight. So this is the complete sparser model. And with And with functionally informed requirements, we can further prioritize the causal variant from this group of highly targeted variants. So this is the key idea behind this version method. We did a lot of simulations, and they always work. So here's an example. Here's a real different example. So finally, the GCKR of a foot house rate. So this is what the draw summer step is. So, this is what the drill summary stats look like. And without functional annotation information, we can identify a group of correlated charts, but they are not really that different. And with incorporating the functional annotation information, we can further prioritize that part. And now we are doing functional experiments with it. So, this is the This is a finite which works with the zero summary stats for one trace. And now we're going to look at dura summary stats for multiple trace. So this is an analysis called color quite data. And this was recently published. And all the codes to produce the analysis is also available. And so we have a lot of discussion about TWAs and MR. So colour position is actually taking us. Is actually taking a step back. So we're not really enforcing a directionality here. We're just saying: are they even sharing the same causal variance? So this is the percentage of collocalization and the difference between colloquialization and TWAS and VR analysis. So traditionally, collocalization is performed with co-loc. So it assesses the probability. That's the probability of four different scenarios. So that this one is actually the code of settings. So it has a very limiting assumption, which is only one causal market are allowed for each trait. And people have been working on relaxing this assumption. And the natural thought is that um can we just do fine mapping on each trace? Find mapping on each trace and that do co-correlation with all the causal variants we have identified. And this is exactly what people are doing. So they are using climatic methods to identify the signal first and then do pairwise collocalization. So this is, so they perform on fine mapping with this and the fine mapping with this. But we just talked about that when you do fine mapping. That when you do fine mapping, there is a lot of uncertainty on which variants are causal. So, if you're in this two-step strategy, you're actually promulgating the uncertainty into your politicalization analysis. So, can we do better? So, this is the idea for SHARPRO, which stands for Shared Sparse Projection. So, we use the projection. Projection data variable again. So, where the idea is to use the effect groups to align the causal marks together. And then the cover collarization question is converged to whether a group of verts is caused for both traits. So, we are inferring the probability of a group of verts being caused for both the intermediate and the compass phenotypes. Compass phenotypes. So, to build the sharp pro model, we'll start with a smartphone model, one for each trait. So, we want to use the grouping strategy to align the signals. So, we want to merge those two S. But then we want to also to allow uh for the color signals to be diff uh to be uh trait specific. So, we need to add a different color indicators. Additional colour indicators. So, this is how we build the shelf pro model. So, we merge the S and add additional coupling indicators. And now, our goal is to infer the posterior collocalization probability, which is simply the probability of both cover indicators equals one. So, we also use efficient virational inference algorithm to achieve the posterior analysis for this one. The posterior analysis for this model. And we did a lot, we also did a lot of simulations, but here is an example. So it is known that the RSPO3 regulates bone mineral density through the activity of steel blasts. So this is actually a biologically collocal example. And this is the geos. This is the drill summer stocks. So they look like a cover-quite scenario. However, because the leaf firms are swapped here, although they are in high current, are swapped here, so existing methods cannot really declare collocalization for this example, or share effectively identified this. And we also have examples. Examples are liquid-lowering drugs. So, these are the known liquid-lowering drugs. So, we curated the GWAS-Sommer statistics for different pairs of liquid-lowering drugs, protein QTR for liquid-lowering drugs and the lipid traits. So, the x-axis is different prior to the collusion probability. And each row is a pair of nuclear drugs, and they're Lower drugs and their lipids. And we can see that SHARPO is the only method that can consistently identify collocalization across different prior settings. And this is about different German summer sets for different traits. So we also can use it to study the German summer sets for the same traits in different populations, in different Different populations with different environmental exposure. So, this is usually under the context of GYE analysis. So, all the codes are also public coded. So, GYE analysis is very important for understand disease heterogeneity. And usually, the bottleneck of GYE analysis is the high multiple testing burden because we are testing. We are testing one variant at a time. So here is a simulated example to illustrate this. So we have ising one causal market with different intact size in a population with the exposed population and the unexposed population. So we can see that as a result, the GMOS pattern looks very different. And if we were to perform a GYE analysis, If we were to perform a GMA analysis, a regular GMAE analysis in this setting, we got a very noisy signal. And after multiple testing corrections, there's nothing. And again, we adapt the shared model for genetic analysis. This time, our goal is to identify the group first and then assess the genetic effect heterogeneity at the group level instead of the variant level. Farrendal that can greatly help with reducing the multiplexing burden. And this is the expected results. So we jointly by mapping the exposure stratified to us, and then we identify the effect loop first. And after we have identified the effect loop, we perform the GYE test without without worrying about the multiple testing burden. out the multiple testing burden. And here is an example. So we look at the G by smoking parameter impact on lymph fracture. Basically we use the equivalent to perform smoking stratified GWAS on the FFR. So we have current, and this is the regular GYE results comparing the current smoker versus past smoker. Versus past smoker, parent smoker versus never smoker, and past smoker versus never smoking. So the only signal we have is the famous smoking drink, CHR93. And with SharePro, we can see the first thing is that we have greatly reduced the multipotesting burden. And as a result, we can identify more genes that are mapped to smoking-related pathways, including airway inflammation. So, in summary, we used the probabilistic graphical model and the variational inference technique to make use of geosummer stats. And today, we covered the fight mapping, which is the purpose is identify potential colours, and colour furtherization analysis, which is detecting the shared genetic signals, and the GYA analysis, which is used for prioritizing these derivatives. This period. And in the end, I would like to thank my supervisors, Landis, and the funding agents. That's a question. So, I think the group could be very common for state analysis. Of signatures. So if the CB is correlated with all the other streams, how do you decide which one are interesting? So the grouping is not uh not ideas, I'm adapting to work. So basically oh so it and so this is the latent variable. So it's adaptively learned. So if depends on the statistics depends on the statistics uh statistic um power and the uh intensity of the correlation. So if you have a high power then you can distinguish highly correlated variables. But if you have a rather small power they're more flat. It's latent variables so it's learn from now. I'll people take a coffee break as well let's take all the other Coffee break as well. Let's take all the other questions that I'm here to handle all the other speakers.