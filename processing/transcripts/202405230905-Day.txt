I hope to at least not take it anywhere down in the downward trajectory today. I'm going to talk about some work that was done primarily by a former host officer of my group, Olivia Cotton, who's now in India in France, and is looking at this problem of, and I'll go into details in a second, about trying to understand the distribution of fitness effects of mutations. And I should say at the outset that nothing I'm going to talk about today, there's no new mathematical results in here. Really, what I'm going to do is show you how the analysis. You is show you how the analysis of this problem sits kind of nicely within a well-known area of mathematics where we can maybe get some insight from those already known results. Now, before I start, because the problem is a little bit subtle, I want to start with a warm-up example of what we're trying to do. Okay, so put aside mutational effects for a second. I mean, this is a histogram of metabolic rate scaled in a particular way. And what I want to do is imagine I'm interested in trying to understand the evolution. Interested in trying to understand the evolution of this shape of this distribution. Why does the distribution of metabolic rates look like this? And so I want to build an evolutionary model to try and make predictions about this distribution. And if you go to the literature, there's a variety of ways people have tried to predict metabolic rate. One of the simplest is by just assuming that metabolic rate is the sum of, or some linear combination, of a set of traits like body size, mass, a variety of things people have used to try and predict a metabolic rate. And try and predict it metabolically. So, what I want to do is build an evolutionary model where I'm going to be interested in the evolution of some arbitrary number of traits here. Those would be x n's. I'm going to suppose that each of those traits are subject to stabilizing selection. I'm going to suppose the population is large, so there's no demographic stochasticity. No environmental stochasticity either. I'm going to imagine there's unbiased mutation in transfix. So, all these traits are evolving in a very simple stabilizing selection. Stabilizing selection is where mutation is not really direct on the selection. I'm going to make things a little bit simpler. So I'm going to allow there to be an arbitrary number of these traits, and I'm going to make it a little bit simpler. I won't tell you the details really, but you can make some symmetry assumptions and reduce the number of parameters to two, where one of the parameters is sort of an effective number of traits that go into this, and another parameter governs in a sense where the thing is centered. And then I'm going to let this thing run, find the evolutionary. I'm going to let this thing run, find the evolutionary equilibrium, and I'm going to have a distribution that I predict that I'm going to fit into the data and see how well it does. And when I do that, it looks like that. Okay, and so my conclusion is that metabolic rate seems to be the result of the evolutionary optimization of a number of traits all subject to stabilizing selection. Everybody happy with that conclusion? It seems again as a strong state. What's wrong with that conclusion? It is a conclusion. What's wrong with that conclusion? It is a conclusion. It's a shitty conclusion. What's wrong with it? So, this is sort of the motivation for what I'm going to talk about. You haven't shown anything that's optimized? I haven't shown anything that's optimized. Any other worries? Not a very specific version. I've found many ways to get that distribution. Yeah, yeah, exactly. There are many ways. In particular, the central limit theorem tells us that it would be really hard not to get that distribution. And so that's the basis that I want to base everything we're going to talk about today on, in the context of studies of distribution of thickness threats. So it's a little more subtle to try and address that problem, but that's what I want to try and do. And so in these studies, the idea is you start with the ones I'm going to be interested in, you start with a wild type, you generate a panel of mutations, and you measure the fitness of those mutations. Usually it's the replication. So you measure it relative to some standard and you ask how much, what factor did you? Did you ask how much, what factor did the population grow by over some period of time? And when you do that, and this is, I'll talk about this a little bit later, but this is a bad measure of fitness, but that's usually what's used. And when you do that, you get distributed. So usually there's a spike here of leads and things. I'm going to ignore that. And then the rest of it sort of looks, well, this is one example. This is a panel of mutations in E. coli. These are the same mutations, but in different environments, different antibiotic environments. Environments, different antibiotic environments. And the question is: why does the distribution look like that? Can I predict the distribution? And in particular, when I build a model and I predict that, how do I make sure I don't fall victim to that problem that I just showed you? And that's the idea. So, one way to think about the distribution of fitness effects is that really what it is, is it's a map from genotypes facing to fitness. So, here I've got So here I've got there's a wild type here. So this is the space of all possible genotypes, let's imagine. I've got a wild type labeled GWT here. I generate a bunch of mutations from it. That's what's in the red stuff here. And then there's some map that maps those to the fitness axis. And so the distribution of fitness effects can really be viewed as that map. There's not a one-to-one relationship because, for example, if I swap those two arrows, I'd have a different map, but I'd get the same. Have a different map, but I'd get the same distribution of fitness effects. So I can think of it as maps in some way, and that's really what the distribution of fitness effects is. And most of the models for the distribution of fitness effects build something that kind of goes in here and tells you how to make that happen. Most of the models I'm going to be talking about, at least. And I'm going to, there's a variety, which I've a few I've listed in the box here. I'll just tell you a bit about a couple of them. So, probably the most well-used. The most well-used and well-understood model is Fisher's geometric model. And the way that model kind of builds something in the middle here is it takes this space of all possible genotypes, and then it makes this kind of abstraction where it says, well, let's suppose we could embed that in Rn. So there's sort of mathematically what you'd call a metric space here, where now I'm imagined as a continuum of phenotypes. And I have a way of measuring the distance between genotypes. And typically, that's Euclid. Of types, and typically that's Euclidean distance. It might be a weighted Euclidean distance, but it's typically Euclidean distance. The dimension of this space can be anything. In fact, that's one of the parameters in Fisher's model. So it can be a very high-dimensional space, and it's thought to be sort of representative of the phenotype of an organism. And, you know, without any loss of generality, you can suppose that the best genotype is at the origin, and you can have some smooth decrease in fitness as you move away from the origin. And then with a model like that, you can plop a wild type in. You can plop a wild type anywhere, generate mutations, typically by nearest neighbor in immune distance, and then ask what does the distribution of fitness effects look like. An alternative, less used, but same kind of idea, is instead of embedding it in putting in an ORN, in the simplest case, you'd have a bit string. So you have ones and zeros, and you have a space of all possible bit strings, and you have another metric in that space, which is something like Hamming distance. And then you do the same thing. Distance. And then you do the same thing, though. You have a nearest neighbor mutation, you assign fitness in some way, then you map that through and figure out what the distribution of thickness is. I should maybe explain the diagram here. So I'm going to have histograms for my DFE, but you can approximate those by a probability density pick of me. And that's all I mean by those two different concentrations there. Okay. So Olivier did this with Fisher's model, Fisher's geometric model for this data. And that's what the blue. For this data, and that's what the blue curves are here. So you end up with an approximation, which is a gamma distribution with two parameters, and then you fit those using maximum likelihood techniques to the data, and you ask, how well does that fit? And that's what the blue curves are. This is the same picture I showed you before. So here's sort of a standard background for these mutations in E. coli. And then these are all these different alternative environments that are contributing by others. And you can see that it fits really well. And so it's this, I'm in this. And so it's this: I'm in the same position now as that metabolic rating. Is that telling me that this model is, in some sense, a good explanation in terms of what's happening evolutionarily, or is there something like a central limit theorem going on here that I have to worry about? And it's not what I'm going to show you now, for those of you who know anything about information entropy or entropy in physics, all the physicists here, none of this is going to be surprising to you. But let's walk through it in a bit of detail to kind of get an intuition for it. In a bit of detail to kind of get an intuition for it. So let's suppose I have two fitness bins, high and low, and I have only two genotypes. So I have three possible DFEs. I could have both genotypes in the low, I could have one in each, or I could have both in the high. So there's three possible DFEs, and there's four possible genotype fitness maps. One of them is this map that maps them both to here. There are two maps that produce this. These ones go like that or the other way around. That or the other way around, and there's one map that produces that DFE. So, this is the point I made earlier: that there's not a one-to-one relationship between DFEs and maps, it's more than one map that gives rise to the same DFE. And what I'm interested in is what happens, because genotype space is huge, what happens when n is big? And I'm going to let the number of bins be big too, but I'm particularly interested in large numbers of genotypes. So let's carry this through a little bit more. If I have four genotypes, two bins, how many DFPs are there? Types, two bins, how many DFEs are there? Combinatory plan here in a very simple way. There's five possible DFEs, and I can quantify them by how many of them, and there's only two bins, how many of them are global, for example. It's five, it's four, sorry, there's four genotypes here, four, three, two, one, and so on, right? So I have those genotypes, and I can quantify how many genotype sickness maps correspond to each of those. Again, there's only one that corresponds to this. There are four. To this, there are four now that correspond to this. It's just determined by which one gets put in the high-bid and so on. And the question is: how does this scale because n gets great? Now, one thing I want to say before I go on is you might object a little bit in that if you look at, you know, this particular map here seems like an implausible one in the sense that I may never really be interested in that biologically. Because what does that mean? That means all the mutations that I generate. That means all the mutations that I generate have higher fitness than the wildlife does. And you probably would never have an organism like that in the first place. So you might instead want to exclude some of these if you were trying to come up with some sort of null expectation about what you'd expect to observe. But I can start to do things like I can ask, what's the probability, if I was just to choose a genotype fitness map at random, what's the probability of observing different DFEs? And, you know, if there's this one, it's four out of the six. There's this one is 4 out of the 16 DFEs, so there's 4 over 16. That's the quarter probability that I would get that in this simple case. And if I start to exclude some of them, like I said, maybe I don't want to know about, I don't care about those high ones because that's not something I would ever be in a situation to observe, then I can do the same sort of analysis. I can ask, well, what's the probability of this? And of course, it's a little bit bigger, right? Because I've just gotten rid of some of the chief type of max. And so, more generally, what you might imagine doing is. Generally, what you might imagine doing is trying to characterize how well the wild type is adapted to the environment when you're doing this analysis. And what I mean by that is this is a situation where, in a sense, you're kind of, there's a good match between the wild type and the environment, because most of the mutations are deleterious. And here's a case where maybe it's a medium match, and that's the case where it's really a poor match, where all of the mutations that happen are beneficial. And so, I want to somehow do this analysis where I'm going to. Do this analysis where I'm going to imagine choosing a random map subject to some constraint within the space of all possible maps. And I want to do that, I want to know how that scales, right? So you can, none of these are particularly difficult to compute. So I can ask how many different possible DFEs are there if there are M bins and N genotypes. And this is just, you can use different names for it, stars and bars. Or stars and bars arguments, or sticks and stones. I think Feller might have been the person who first popularized those. You can write down that as the number of possible PFEs. The number of possible genotype fitness maps is exponential according to this formula here. And you can write down the number of maps that correspond to a particular DF as well. And then you can ask what happens as n gets big. And as n gets big, well, if I look at this. Uh well, if I look at this in particular, as n gets big, the number of maps that correspond to a particular distribution of fitness effects is exponential in the information entropy of that DFE. So this is a useful result, and then it starts to allow me to figure out what sort of DFE I expect to observe as the number of genotypes gets large. And I guess the other thing to note is that the growth of this thing is polynomial. Is polynomial, the number of DFEs is polynomial, the growth of the number of maps is exponential. So there's going to be a lot of maps that have to go to a small number of DFEs basically. And so in the limit, the idea is maybe these things concentrate in some way in space. And there's a nice theorem in Sanov's theorem in probability theory that you can strip down to a simple version and analyze it using that. And the paraphrasing the result is. The paraphrasing the result is: suppose I choose a genotype fitness map at random within some subset of all possible maps, so I can exclude some like each of those. Then as n goes to infinity, the likelihood of choosing any particular map concentrates in a particular spot, and it concentrates in the spot with the highest increase. So that's in some sense the analog of the central limit theorem in this problem. But if I was to just randomly put this together, If I was to just randomly put this together, I would expect to find a DFE that had the highest information entropy, subject to any constraints that I would want to impose on. That's the idea. So I'll show you how that works. So what Olivia did is then analyze all the data you could find doing this to see how well that it matches the data. So to do that, we have to decide, like Johanna has told us, we have to decide on how to measure fitness. And it matters. And it matters, just like in the metabolic rate case, I could measure it on an additive scale or a logarithmic scale. I'm going to get a different result. And maybe the central limit theorem is not going to work so well. I mean, I have to make some choice. It's going to make a difference. Most of these studies are conducted by putting, usually the microorganisms, measuring them at some time, measuring them at another time, and looking at the factor by which they grew relative to the wildlife or some other stream. So, what I'm going to use as the measure of fitness is just the growth factor. It's the factor by which the population. Factor. It's the factor by which the population multiplied relative to some standardized case in the wild type. And I need to choose some appropriate subset. If I want to restrict the space of all possible genotype fitness maps, maybe I don't, but I want to deal with that problem. There's going to be some that are kind of irrelevant. So I'm going to do that in some way by choosing, I'm going to measure that, choose that space by using a measure of how well the wild type is adapted to the environment in which you're conducting this space. So a good map. So, a good match, a medium match, or a poor match. And I'm going to measure that as in terms of the mean, in this case, of the distribution of things. And if you do all of that, again, these are standard results. The null model for the growth factor is a kind of exponential distribution, a kind of exponential in that it's sort of slightly more flexible when it's on a bounded domain, typically. I mean, I can expand it to an out of a domain. I can skim it to another domain, but it's for a bounded domain, it looks like this, and I can flip it around. I can have it increasing or I can have it decreasing. So that's the maximum entropy distribution subject to that particular constraint that I mentioned. Now, I mentioned that there was this kind of poor measure of fitness that people use. Usually what people have measured in these experiments is not this growth. Well, they do measure that growth factor. That's what they do measure. They do measure that growth factor. That's what they do measure. Then they convert it into something else. They convert it into a measure of the Malthusian growth rate. So you're changing from a multiplicative scale to an additive scale. And then they look at the ratio of the Malthusian growth rate of the mutant to the Malthusian growth rate of the wildlife, which is not a particularly good way to scale things because you've moved from a multiplicative scale to an additive scale and now you're using a multiplicative standardization. So it's not a good measure of. It's not a good measure of relative fitness, but it's how most of these studies have presented, at least the ones that we analyzed. So, if you do that, the red curves here are the, so you get a two-parameter distribution, the Gomfort's distribution, and the red curves are the fit, maximum likelihood fit to these data. This is the E. coli data. And the blue curves are the Fischer's geometric model. So, I mean, neither of them fit well for some of these where there's these bimodalities, but you can see that. Where there's these bimodalities, but you can see that you get a distribution that is kind of indistinguishable from the distribution that the Fischer's geometric model gives you, and that matches the data really well. And so you might start to think, well, maybe this is sort of that central limit theorem-y kind of problem here, where there's kind of an attracting distribution here, no matter what I'm doing, because of this, the way that the genotype fitness maps scale relative to the distribution of fitness effects. You can look at, so the, again, most of the data that a living So again, most of the data that Olivier found, and I think it's true, most of the data that exists is in microorganisms. So some phage data, some other bacteria, some viruses. Data is maybe less complete, but that's what the fits of both the Fisher model and this Gomfertz curve look like. Again, both of them do a reasonable job. And a reasonable job that's sort of indistinguishable from you can also build, take Fisher's model, and you can write a bunch of. Take Fisher's model, and you can run a bunch of simulations and generate the distribution of fitness effects under different conditions and ask: does this null model, this Gumpert's model, work well for that? I mean, it should, given that it looks like they both match the data. And that's what this shows, where these are just different degrees to which the wild type is adapted to the environment, from poor up to very highly adapted. The histograms are the data, the simulation data from the Fisher model. From the Fisher model. The blue curve is a gamma approximation that's usually used under certain conditions for the Fisher model. And the red curve is this comprehensive gamma. So again, you can see that it's kind of indistinguishable. I mean, even a little bit better than that gamma approximation in this case. So again, to me, the conclusion is the fit you see here between the Fischer model and the data is not a very strong indication that what's going on in the Fisher model per se. On in the Fisher model, per se, is something we should think is actually driving what's happening. And so the question then is: how can I figure out whether, when I build a model, whether there's any utility to it or whether it's just kind of all attracting to the same kind of maximum entropy distribution? And there are a couple of things you can do. The first is if you don't do this weird data transformation where you're measuring the relative fitness in a multiplicative way with an additive. In a multiplicative way with an additive measure, but you instead measure it just on the original multiplicative measure of fitness, the distributions start to be a little bit more distinguishable from one another. So maybe not surprisingly, when you start to take random variables and you run them through weird transformations, you can get things that are kind of hard to figure out where they came from. And it's a bit hard to know how to judge one versus the other. So if you sort of go back to the very basic thing you might measure and ask how do the distributions of that thing you might measure Distributions of that thing you might measure differ, you can start to distinguish them. They both do reasonably well when the wild type is badly adapted. They kind of do reasonably well when it's really well adapted, but in the intermediate region, they make very different predictions. The exponential model, of course, can't give you a hump shape, right? Dumperts can, and so there's this weird the transformation is what in some ways makes those two things indistinguishable. Another thing you can do is you can make predictions for things in addition to the distribution of fitness effects. To the distribution of fitness effects. So, Fisher's model you can use to make predictions for epistasis among loci as well. And there's a prediction you can make about epistasis from using this null model as well. Because if these genotype fitness maps are randomly chosen, then any double mutant is just a randomly chosen one, just like any of the single mutants are. And so, you can ask under that situation, what should the epistasis look like? And you can make predictions about what it is. And so, this is just, I can't remember. About what it is. And so, this is just, I can't remember what the data came from here. The histograms are data of epistasis, and this is data on fitness. And you can make predictions. So, this is a curve for the predictions from the null model, the Gumpert's model, for what epistasis should look like. And you can see that fits quite well as well. But it's quite difficult to fit that and a fitness distribution at the same time. So you can fit one and the other doesn't fit so well, or vice versa, but it's hard to fit both of those well. But it's hard to fit both of those well at the same time. And so that's another way you can start to try and distinguish between models, I think, is to make predictions about more than one thing, not just this distribution of these effects. And maybe I'll just finish there. These are the final thoughts I have. So I already talked about these first two. One thing you can do to better distinguish between models is use what I call raw fitness measures. You can examine multiple predictions simultaneously. But to me, I think in some ways, I don't even want to view this as a In some ways, I don't even want to view this as a null model. I want to view it as another model that has certain assumptions that go into it. And what we might be better off doing is competing models against one another statistically. And so in a sense, what I've done in this null model is I've taken all the spice, in Alune's terms, out of the model, or I'm asking how much spice can I remove, and well, people will still be willing to eat. Salt in here, but nothing else. Salt in here, but nothing else. And so you could put a little more and more spice in and see how much spice do I need to actually predict what I produced. And I think that might be the more promising. Okay, I'm happy. Let's take four questions long because we'll have some stuff. So I think you kind of addressed this, but it seemed really, you started with the question of With the question of fitness effective mutations, and then the model is about the whole like genotype to fitness map. So, with the experiments that you're praying with this, are they like, I wasn't sure whether they were affects single mutations or effects of more long-term mutations? So I think maybe someone here knows better than I do, because I can't remember off the top of my head. I think there's just single mutation counts. Single mutation panels. So each, you mutate site-specific things, and you have a panel of these things. So it's not the whole genotype space. It's a very tiny subset of them. So is there a difference there between experiments measuring single mutation and your framework measuring for predicting the entire genotype of fitness map? Well, I guess the way I view it is that you generate these mutations by You generate these mutations by some, you have some tiny subset of genotype space, and the model is making some prediction about the entire genotype fitness, entire genotype space definiteness map. I guess it's, and so in the model, when I choose a random map, that is the result I get, I guess, in principle it's possible that that particular subset is some very abnormal subset of the whole gene type space that's in a very unlikely corner of it, so that when I do. Unlikely quarter of it, so that when I do that random sampling of maps, I'm pulling them randomly from a place that's kind of relevant. I mean, in principle, that's possible, I guess. You could also think of your genotype space as being the genotype space of one-step newtons from some gene. Yeah, but not all gene goes. But then, I mean, as n goes to the frequency, it gets super quick, but the end point has been how we get on. Thanks, Roche. All right, our next speaker. Alright, our next speaker today is Yuar. He's going to be talking about how fast adaptation can be played.