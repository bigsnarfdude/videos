A lot. Many I learned that uh nothing about DNA is simple and everything is much more complicated than we thought. But you know, since I'm a container scientist, I'm gonna be one of those people who touch the tail of the elephant. So for me, the DNA is like a long string and it's like a sequence of letters. This is my view. So what I want to talk to you to you today is look at the information that is contained in the genomes and study the mathematical patterns of the genomes. Mathematical patterns of the genomes, and then how one can use those mathematical patterns that are pervasive to a genome to both extract taxonomic information, which is sort of surprising but expected, but also to share you a recent insight that also extreme environments leave mathematical imprints in the genome. So, this is what I want to talk about today. So, first, I'm going to discuss the mathematical representation of DNA sequences that we have been. Of DNA sequences that we have been using for this research, which is called TLSDM representation. Then I'm going to show how one can use TLSDM representation or CGR in connection with supervised machine learning for taxonomic classifications. And then how one can use the same CGR with unsupervised learning for taxonomic identification. And then show how we can use the same methods, supervised and unsupervised learning with CGR, in order to detect the environment. In order to detect environment-related mathematical factors in extremophile genomes. So, that's my plan for today. So, let's start with a mathematical representation of DNA sequences. So, I will be using a graphical representation of DNA sequences called chaos game representation, whereby from every sequence you can extract an image, or you can construct an image that is a unit square with corners labeled ACGT, and the algorithm is basically like that. And the algorithm is basically like that. You start to read the DNA sequence from left to right. The first pixel of the CGR image is the square center. And then when you read the DNA sequence left to right, a new dot is plotted. Every time we read a letter, a new dot is plotted in the middle of the segment between the current pixel and the corner labeled by that letter. Well, a picture is worth a thousand words, so let's see how it works. So, how do you construct the CGR of the demi sequence A, C, G, C, D, C, C, C, C, C, Then is equal as A C G C T G. This is the CGR square. The first pixel is in the middle. And then the first letter is A. So I'm going to draw a dot here in the middle of the segment generated by the current pixel and the corner label A. So I'm going to have a red dot right there. The second letter is C. So I'm going to look at the current point and the corner label C and draw a dot there. And so what? The next letter is G, so it's going to be probably. Letter is G, so it's going to be probably right there. The next letter is C, so I'm going to go probably somewhere here. The next one is T, it's going to throw me somewhere there. The next one is G, it's going to throw me up there towards the corner G, and so on. So if you ignore the dotted lines, you know, for every DNA sequence, you can plot an image. Let me show you some CGRs of mathematical sequences. Okay, so first of all, you know, there are all kinds of theories that you can prove. For example, you can prove That you can prove. For example, you can prove that given the exact coordinate of a CGR point in the plane, you can determine its corresponding letter and the position of the letter in the original DNA sequence. So in principle, if you have the last point of the CGR, you can reconstruct the entire sequence. This is in theory, but of course in practice, computers cannot store the exact coordinates of all CGR points, so we are always limited by some resolution. So mathematics is always prettier than reality, but but we knew that. Reality, but we knew that. Okay, so let me give you some other way of thinking about CGR. How do you store it? Because you want to store the information, but it's not only a theoretical image. You want to store it as a matrix. And for example, if you think of the CGR image, all the nucleotides A are going to end up here by the geometry of it. All the C's are going to end up in this quadrant, and so on. This quadrant, and so on. And you know, if you can subdivide the square according to the resolution that you want, you know, every k-mode is going to fall into an exact little square of the CGR image. So basically, if you decide on a resolution, let's say 2 to the 2 by 2 to the 2, the CGR image can be stored as a matrix that contains simultaneously all the counts of all the tumors, of all the subwords of length to index sequence. Towards a flank to index sequence. So basically, it's like a simultaneous recording of all the K-mer counts, where k is the resolution. Okay, so I'm going to talk about this interchangeably, about the image and the K-mer frequency of the signals. Alright, so let me give you some examples. These are CGRs of computer-generated DNA sequences, all of them of length 150,000. So I'm going to talk about like long sequences today. So a random DNA sequence looks random, which is good, but it's Which is good, but it's not a given because, for example, if you try to play the CGR game on a triangle and over a three-letter alphabet, because of geometry consideration, in that case, a random sequence will look like a Sierpinski triangle. So, actually, it's sort of a lucky coincidence that a DNA has four letters, and if you play it on a square, you know, with four corners, a DNA sequence that is random looks random, it's like a good for us. This is the mathematical sequence A to the M. So, you know, we have A, A. M, so you know, you have gonna f A, A, A, A, and they are all bunched on this diagonal. This is ACGP to the M. So, you know, everything, all the A's are sort of bunched here in the quadrant A, one on top of the other because of the resolution. They are 150,000, but they are all compressed. So, periodical sequences are going to look boring. This is a sequence that avoids, like, it's random except that avoids all A's. So, you see, nothing falls in here. This is a sequence. In here. This is a sequence that avoids the pattern CA. This is a sequence that avoids CT, and so on. And you can find very nice mathematical theorems that connect the symmetries of the square with the permutation. So once you know what pattern is avoided here, if you rotate that sequence, you know for free what patterns is avoided in that one. So there are very cute mathematical results that you can prove. You can also plot interesting words from the formal languages and combinatorics from words. Languages and combinatorics on words for people who are interested in that. So, you know, you can have Fibonacci words. These are words that people in combinatorics on words spend their entire career studying. Okay, you have like Fibonacci words, you can construct them like Fibonacci sequences, except that instead of condition, use catenation, and so on. Lefonachi words, two M worse words, Lindon words, the Blue words and so on. Okay, so that's what they look like. So for me, look boring in the sense that you you have two extremities. In the sense that you you have two extremities. Either that they have very high periodicity, so there are very few points bunch on top of each other, or they look almost random. And actually we can try to plot interesting numbers, because of course you have a number in base 10, you can change it to base 4. So we try to plot pi, square root of 2, e, you know, get me anything interesting. Nothing, okay? Nothing. We tried Mercene primes, whatever. So everything looked either random or very periodic. Random or very periodic. So we have yet to find interesting, a number that is interesting mathematically, that gives an interesting pattern. If you have any idea what to try, tell me. I'd be happy to try it. However, if you look at the CGRs of real DNA sequences, they start to look very pretty. This has some structure to them. So this is a CGR of a nuclear genome from Homo sapiens, and this is the CGR. Sepiens, and this is the CGR from Anarchaeum. So, you see, you can have patterns that tell you something about the words in the sequence. And this is, you know, if you look at all 16 kingdoms of life, these are the patterns of the DNA genomic sequences extracted from those. This is all of them are 150,000 base pairs. So, this is from Homo sapiens animalia. This is a fungus, this is a plant, this is a protease, this is a bacterium, and this is an archaea. So, people who have studied this, not So, people who have studied this would notice that species that are biologically related have similar patterns. So, there are interesting observations about the CGRs that I want to summarize here. Basically, real-life genomic CGRs are species-specific in the following sense. So, patterns are similar for DNA sequences from the same genome. So, it doesn't matter where you take it from the beginning, middle, end, gene, non-coding, coding. They all have a similar pattern. Similar pattern. On top of that, they are different for DNA sequences that come from different species. That's good, so you can use them as the differentiator. And also, these patterns are preserved regardless of the length and the location of the DNA sequence. So it doesn't matter how long it is, right? If it's very long, the picture is going to look dark. If it's shorter, it's going to look light. But the pattern is the same. Yes? You can use image distance, for example. There are many distances you can use. You clear the There are many distances you can use. Euclidean image distance, all of them, something similar. For, you know, at the first approximation is visual, but of course, at some point, you cannot tell the difference anymore by eye. They have to employ some mathematical distances. Okay, so how can you use that, right? So let me go back to that. So this means that we can use CGR as a genomic signature because it's like different for different species, and we can use it for alignment. And we can use it for alignment-free species classification and identification. Because you know, previously, people did taxonomy, phylogenetic trees, and taxonomy classification. You see the Heming distance, the number of insertions, deletions, and substitutions. And if it's big, they are distantly related. If it's small, they are closely related, and so on. This has nothing to do with alignment, nothing to do with gene and non-GM. It goes sort of miraculous when you notice that, right? No, you just take a DNA. Is that right? You know, you just take a DNA fragment, it doesn't matter from where, and then because this is like a little bit like a watermark signature, you know, you can use the CGR in order to classify species. And we did that, you know, with the, you can do this in two ways. So I just want to say like very briefly, how does that work? For example, we use supervised machine learning based on CGR for taxonomic classification. How does this work? We select the random DNA fragment from each genome, the length variant. Each genome, the length varies, you know, it depends on the you know how closely related they are. You know, if it's bacteria, it might need longer, sometimes it works shorter. So, you set a fragment, you set a length of fragment, and you select a random fragment. You compute a CGR, a TMA fragment, one per species, and then you train a supervised machine learning algorithm on a set of known pairs. So, you say, you know, this CGR belongs to a mouse, and this CGR. belongs to a mouse and this GR belongs to a fish and this one belongs to a plant and so on. And then you test it. You take, you know, you give it a new DNA fragment and you ask, what is it? So you know you can do this with tempo cross-validation and so on. You see the accuracy and you can predict the species of new DNA fragments. So this method has been very successful. You know, if you put on top of CGR and the distances, if you put machine learning, the accuracies are in the high 90s. You know, usually this is very, very effective. So sometimes you So sometimes you don't have the deficiencies of this supervised learning for classification is that you only know about 2 million of the 20 million species of Earth. So the training set is very sparse. And you might be unlucky and you throw something new from a pool of water, something that it hasn't been trained on. So what do you do then? Because this this method cannot correctly classify something that it has not seen before. Something that it has not seen before at all. So in that case, one uses unsupervised learning. Unsupervised learning, this means that you throw at the algorithm only sequences without any label. You know nothing. And then you just ask it, you know, go find out which one are similar and give me some clusters. And then I'm going to see in what cluster my new DNA sequence belongs to, and I'm going to, you know, classify it like that. So this is just like a high-level representation of that. A high-level representation of that. So we give DNA fragments from, you know, let's say from a metagenomic data, from a drop of water from a pond. And what we do is the following. So we start blind. We know nothing about any clusters. But you've got to start from somewhere. So you have to tell the algorithm somehow what kind of similarity you are looking for. And we achieve that by generating artificial, we call them mimic sequences, where we introduce. Mimic sequences where we introduce some artificial mutations in the original sequences, and we tell the algorithm, okay, this is the original sequence. I mutated a little bit. These two belong to the same cluster. I don't know about anything else, but these two should belong the same. So this sort of seeds the cluster, and then if you iterate, you know, you can minimize the loss function. So this is how it works. So we have the, you know, like, you know, we have big data sets, you know, hundreds of thousands, a million and a half. So without labels, So, without labels. Then, for each of the original sequences, we generate mimic sequences. And then, you know, we pair the originals with the mimics, with their CGRs. And then, you know, we train several artificial neural networks. And usually there is some variability depending on the parameters. Then we take a majority voting and we get the classification. So, this has the advantage that you don't need a training set. You're not dependent on the training set. The disadvantage is that the accuracy is slightly lower than the Accuracy is slightly lower than the supervised learning, obviously, since you don't know anything. So, we use this, and this has also been very successful in classification of various data sets. So, as a sort of a summary of that, machine learning methods that are using CGR have been highly effective in taxonomic classification of DNA genomic sequences for many data sets in many countries. For many data sets in many contexts. Mitochondrial DNA, bacterial metagenomic data, classification of COVID-19 virus genomes, DNA barcodes. So they have been very successful in many contexts. The reason why this works is that, as per conventional wisdom, each genome contains in itself the memory of its ancestors. So it does contain evolutionary information. Information in it. So then, you know, so we sort of could explain to ourselves why this works. But then we had this like wild idea. Is it possible that a genome contains some other kind of information? Is it possible, for example, that the environment can induce a detectable evolutionary independent mathematical signature in genomes? So this is a little bit of a crazy question, right? So we thought that probably. So, we thought that probably if you take like normal environments, we're going to get nothing. What's the chance that the fact that you live in Arizona or in battle is going to affect your genome or then that of your kids? Zero, right? So, the only chance to get an answer to that is to look at the very extreme environments. So, this is why we looked at extremophiles. Extremophiles are organisms able to live and indeed to thrive in extreme environments. For example, very high temperatures, you know. Very high temperatures, high radiation, salinity, acidity. So you find them in lava vents, in the Arctic, in the ice, in all kinds of places where nothing should live, you find these extremophiles. So we concentrated on microbial extremophiles, namely extremophile bacteria and archaea. And just to give you an idea where they are in the tree of life, so the tree of life has three major domains: bacteria, archaea, and eukaryotes. And then, you know. Eukaryotes, and then you know, these eukaryotes have four kingdoms: proteins, plants, fungi, and animal. So, the reason I have this slide here is to point out that the difference between bacteria and archaea is huge. They are part of the big limbs of the three big limbs of the tree of life. They shouldn't be simulated in any way whatsoever. Okay, so we did that and we tried, so we had some data sets of extreme. Of extremophiles regarding temperature and pH. And we had about several hundred of them. This is just like a summary of our data sets. And from each genome, the genomes are 2 to 3 million for bacteria in archaea, something like that. We extracted from each genome a fragment of 500,000 base pairs randomly as the sort of representative fragment, but just random, right? And, you know, these sort of groups, they are psychrophiles, the ones that lead in. Look, there are psychrophiles, the ones that lead in the cold, mesophiles, thermophiles, hyperthermophiles who, you know, thrive at plus 100 degrees Celsius and so on. And these are darchea, these are acidophiles and alkaliphiles. So this is the summary of our data set. And just to give you, you know, there is lots of literature in this. And as often in biology, there is no standard. Okay, so we have to decide what are our thresholds into differentiated cyclophiles from You know, cyprophiles from, you know, mesophiles from thermophiles. So these are the thresholds that we used. So cyprophiles, the optimal growth temperature is under 20, but of course it can be as low as 0 or minus 12. Now, hyperthermophiles, anything that thrives at over 80 degrees, it's hyperthermophile. And you know, acidophiles, the neutral pH of water is 7. Acidophiles have optimal growth pH less than 5, and alkalophiles greater than 9. So this is like high acid high solid. Than mine. So, this is like high acid, high salt. So, these are our parameters. And let me give you some examples of this, like a really amazing organism. So, this is Hirocopus furiosus. Gotta love the name. It's an Archeon isolated from heated sediments on volcano island. The name says it all. So, this is a hyperthermophile with optimal growth temperature of 100 degrees. So, it's called Hirococcus furiosus. So, it's a fireball that is furiously. Fireball that is furiously swims at plus 100 degrees Celsius. So, this is like one of those. This is another example: Cycromona syngrami. This is a bacterium isolated from Arctic polar sea ice. So, it's a cyprophile, optimal growth temperature. So, this is only, it's not only that it survives at that temperature, that its optimal growth temperature is minus 12. So, this is the lowest recorded growth temperature to date, and you know that the Date. And you know, the name comes from Cycros, which means cold or frozen. Then this is Picrophylus toridus, it's archaeon isolated in a hot spring in Kaleido, which is acidophile, and it's also thermophile. So some of them are polyextremophile. They resist several things that you throw at them, like high temperature, high acid, some of them high radiation, high pressure, high anything. Some of them are polyextremophiles. And this is the And this is the Natromorasparonis archaeon found in a salt lake. This is altalophile or allophile, thrives in extremely high soil concentration, pH 11, which is like more than a cup of salt in a liter. And they love that. So this is similar to Lyso for the Dead Sea, where nothing lives. So these are some examples of the extremophiles. And let me tell you what we found out. So we tried to classify. So let's say we concentrate on the So, let's say we concentrate on the temperature data set. Okay, so the temperature extremophiles. So, we tried the same data set, and we tried supervised learning in two scenarios on the same data set. So, for the first scenario, we trained the algorithm with taxonomic labels. You know, this sequence is bacteria, this sequence is archae, and so on. And we asked the question, you know, for a new one, what is it? Can you tell me? So, for this, for example, at k equals to 6, this is very small here, we got a very high idea. Small here, we got very high accuracy: 99.5, 98.5 by multiple algorithms. So the taxonomic classification accuracy was very high. So then we said, okay, we can learn taxonomy. How about we remove, we delete all the taxonomic labels, and instead for every sequence, we put the environment labels. So, you know, I don't know what it is, but this sequence is hyperthermophile, this sequence is mesophile, this sequence is cyclophile, and so on. So you train it with the environment. You train it with the environment. So then you throw a new sequence and you don't ask what it is. You ask what kind of environment does it like. So it turns out, to our surprise, that you got very good accuracy. You probably cannot read it. You know, over 83%. So that was a surprise to us. Like really, it's not expected. So then we said, okay, there might be something wrong. Maybe this is something wrong with the algorithm and you can learn anything. So let's label them with random labels in the tree. Let's label them with random labels in the training. Let's see what we get. Well, no, the eighth is tapped, 27%. Which is, you know, if you use four labels, it's like probabilistically what we expect, right? So it was not a fluke. And we got the same things for the pH, right? We used for, sorry, for the pH data set. I'm not going to go through this, but you know, maybe the numbers are bigger. If you classify, if you use supervised learning with taxonomic labels, With taxonomic labels, accuracy was very high, over 98%. With environment, it was not as high, but it was very high too, 92%. So there is something there. There is some signal there in these K-word frequency patterns that can tell you something about the environment. So I didn't believe this. Actually, you know, for three years, I didn't believe it. So we tried lots of things to disprove the hypothesis because it's so unlikely. So here is, if you look at the CGR pack. If you look at the CGR patterns, you see that indeed, you know, if you hear you have like hyper-turbophiles, there are different camers that are darker, which means they have higher frequency than the ones that are darker encyclophiles. So we looked at it this way from this angle, and we still got the same thing. There is something about the environment that changes the K-mark frequency. And then we looked at the deviation of here for k equals to 3 of 3-mark counting x chemophiles. Three more count immediate chemophiles, deviation from the mean in the data set. And you saw this green are the relevant K-marks. We saw that, for example, you know, you had the, these were the psychrophiles. You know, for example, in psychrophiles, this three mark AAA is overrepresented in psychrophiles. In mesophiles, overrepresented by a little less, but then in thermophiles, which are like, you know, this is cold, this is hot, they are underrepresented. And in hyperthermophiles, it's very. And in hyperthermal files, it's very much underrepresented. So there is something to it. We are not seeing things, and there was not something wrong with algorithms. I still didn't believe it. Okay, so then we tried unsupervised learning. So let me tell you how this works before I get into our findings. So unsupervised learning, the very same data set, you know, nothing to it, except that we erased all the labels. And you just, you know, go crazy, find me similar clusters, buy whatever you think similarity is. By whatever you think similarity is, because machine learning is like a black box, whatever you think is similarity, find similar stuff. So, by and large, you know, we found some, you know, hyperthermother bacteria, hyperthermathic archaea, but there were some things that were really unusual. And let me show you some of them. For example, we found some clusters that contained, grouped together, hyperthermophile bacteria clustered with archaea. Archaea. I don't know if you realize how crazy this is. This shouldn't be similar by any measure whatsoever. Any distance measure should throw them as far apart as possible. So this is some of our examples. We had many. This is thermocrinous ruber. This is isolated from a hot spring in Yellowstone. It's a bacterium. And these tree are archaea. This is my favorite, the Tirococcus furiosus. Eurococcus Kitonophagus looks similar. Also, from a Also, from a hydrothermal vent, also high temperature, and then this is Thermococcus retoralis from aquatic thermal hot spring. So, the only thing that we could find that this had in common, genetically are as dissimilar as possible, the only thing that they had in common was that they all were thermophiles. So, this told us, now that I have some specific things in mind that I found, that no matter how I try to. Found that no matter how I try to classify them, you know, they are grouped together, there must be some environmental signal that is in, you know, that is encoding this K-mer frequency. And, you know, in case I didn't make clear how crazy this finding is, this is akin to finding, you know, we have an algorithm and it clusters together as genomic similar, the follow- the genomically similar, the following thing. So, you know, you throw lots of things at it, DNA sequences. And it clusters. C plus. And it clusters plants with plants, mammals with mammals, fish with fish. But then you have this cluster where you have some mammals with bacteria. You know, so it is that crazy. Why would they be there genetically completely similar? And then you start to look at it like, what do this have in common whatsoever? And then you see that all of them are from pants. So, how unlikely that is, right? But this is exactly what we found. This is exactly what we found. I still didn't believe. What we found. I still didn't deliver it. I said, okay, let's try these same ones. Maybe there's something wrong with our clustering algorithm because you know, none of these algorithms have 100% accuracy, right? All of them. So maybe it's a mistake. So then I said, you know, take this and do supervised learning. Okay, so let's do supervised learning by taxonomy. Okay, surely that one should group things okay because those algorithms, if you remember correctly, they had over 99% accuracy, right? 99% accuracy, right? But we found that when we used the same data set and we applied supervised classification to it, then when we tested, use that test sequence bacteria, they were wrongly classified as mammals. You see? They are part of the errors of that algorithm. But that algorithm, as exactly as it was, found the same thing. So, you know, so this is our conclusion. So, this is our conclusion. I tried all of this. We didn't try a single clustering algorithm. We tried like eight different clustering algorithms, like 15 different supervised learning. We tried ROSE. All of them gave the same thing. These guys, somehow they are genomically similar. So, this is the conclusion. So, this sort of shows that there is a new dimension of the genome. So, not only the answer to the question, does evolutionary relatedness produce a detected Relatedness produces a detectable mathematical signature in genomes. Not only the answer to that is yes, no, that was surprising, but at least it didn't contradict conventional wisdom that the genome is a repository of ancestry information. Also, there is a new angle on this. There is a new insight because the answer to the question, can the environment produce a detectable evolutionary independent mathematical signature in genomes, the answer is also surprisingly yes, at least in the middle of the moment Surprisingly, yes, at least in extreme events. I also wanted to mention that this is not like you discovered in a fish that lives in the Arctic, you discovered a gene that is the lanthophase gene. It's way more than that. Because this extreme environment signal is not localized. It is genome-wide and pervasive. It's everywhere. These changes are everywhere. It's a change in the syntax. So this is our finding. And what we want to do next, we want to look for other extreme environmental To look for other extreme environmental signals, for example, radiation resistance. There are some of these things that you cannot kill, this Glynococcus radiodurus. Recent research showed that it can survive for three years in space. It can survive in a nuclear reactor. It can survive anything. So we want to study that. We want to look for polytremophiles, maybe have signal interference, you know, combination of them. And we want to look for eukaryotes and multicellular organisms. I have to put this slide because my daughter loves cardigrades. Because my daughter loves target grades, so you know, I have no choice but to look at target grades. So, that's what I want to tell you today, and this is these are my excellent research collaborators. Thank you. Time for one or two.