Subject of that subject doing a particular task, let's say a working memory task. So when I take one functional connector, I'm going to compare it one by one to the entire read spool through some similarity or dissimilarity measurements so that I can decide, okay, based on my prediction, this subject must be subject 2 or 12 or 15. So this is a toy example where we're playing that game and I'm using correlation of the entire congregation. Correlation of the entire connectivity profile as my similarity measurement. So, for instance, this subject that I don't know who it is, the functional connecton correlates a little bit above 0.6 with respect to subject 1. So, maybe subject 1, maybe not. It correlates higher with subject 2. So, for now, I will say subject 2. But when I compare it with the entire cohort, a small cohort size here, just for the convenience of an example. For example, I will argue that this must be subject 4 because I'm getting the highest correlation, the highest similarity with the subject 4 retest. This is the scatter plot that corresponds to the cloud of points that will lead to such a high correlation. And for instance, I would argue it's extremely unlikely that it's subject 15, because among the 20 subjects is the one that correlates. Is the one that correlates the least with my question mark subject. So, based on this strategy, if we play the question mark guess who for each and all the individuals, I can report on average the level of identification rate. The level of identification rate is the percentage of times in a functional connectomp's data set that has a test-retest function. A test-retest fashion is the percentage of times that I was successful identifying the subject from one pool to the other one. To go into further detail, you should play these games in both ways. You should pick functional connectors from the test pool and try to predict who is the subject in the retest, but also the other way around. That will give you two measurements of identification rates, and it will usually take the average of Take the average of both measurements so that we can characterize the entire data set with a single identification rate value. If my identification rate is 78%, it means that 78% of the time you gave me a functional connectum and I was able to identify the subject in the other. Okay? So we are not the pioneers playing this game. One of the seminar papers was by One of the seminal papers was by Emily Finn in 2015, where she took a human connection project data set and she played the identification rate game in several different ways. All the y-axis in this plot are identification rates. You may notice always a darker column and a lighter column. It's because she is reporting when you play the game from one pool to the other, and vice versa. And this is depending on whether you are targeting a specific function. You are targeting a specific functional circuits to play this game, think of it as filtering certain rows and columns in the correlation matrix, or when you're doing whole brain assessment for the fingerprinting. When you read all, it's actually you're looking at whole brain. And here, for instance, the test and the readness sessions are resting state sessions, R1 and R2. But she also challenges a more difficult situation where you have different fMRI tasks in the test and in the retest pool. In the test and in the retest pool. Obviously, with respect to functional reconfigurations of our functional connectors, we will pursue different tasks. So, this game should be more challenging, more difficult when my test and my retest pool are different tasks. And you can see, for instance, that from the emotion task with respect to the resting state task, identification rates are lower because it's more difficult, because the subjects have undergone changes in the functional reconfiguration, because now they're doing a task as opposed to At ask as opposed to being a task. So, this paper for me was incredibly exciting at the time. And I felt like I really want to dedicate a good amount of my work on digging into this more and more. And that's what we did at the Complexity Lab. And one of the first steps we took, this was 2017-18. It was, well, It was, well, when you're playing this game of comparison, at the end of the day, you have compared all the functional connectons to all the functional connectons in order to make the decision, one at a time, of who is the subject in the other pool. So why don't we put this into a matrix? And we call this the identifiability matrix. Don't get confused, this is not a correlation matrix of brain regions by brain regions. This is a correlation matrix of entire connectivity profiles Entire connectivity profiles of all the subjects in the test session versus the retest session. The main diagonal is very powerful in this representation because it's how similar is your functional connectom in day A with your functional connectom in day B or test retest, however you want to call it. Any other entry outside the diagonal is a comparison of the test-retest between different subjects. So intuitively, by a color bar here, does we get By a color bar here, that will get more yellow brighter. The concept of a fingerprint in general is that I put my fingerprint, I put another one, and they are similar. That's great, otherwise it wouldn't be a fingerprint. That corresponds with a bright diagonal in this matrix. But I want you to think something that is very obvious that we tend to forget sometimes. That's not enough. Because what if Javier puts a fingerprint near my mind, and it's also very similar? Also, very similar. Then we don't have a fingerprint. So that means in this matrix that the off-diagonal entries, I would like them to be less similar than the main diagonal entries. That's how this matricial object represents the concept of fingerprint when comparing full connectivity profiles. So in general, I want this diagonal to be brighter than the off-diagonal. We thought of putting that a value. Thought of putting that a value that could maybe complement identification rates. So, the average brightness of the main diagonal, literally, we will take the mean of the main diagonal and we call that I self. It's on average in your data set. How similar are the subjects that we would like, that they are similar because they are the same. I shouldn't say the subjects, I should say, the sessions of the same subject. And then we also define eye others as the identifiability when I'm comparing. When I'm comparing different subjects, which is not, if we put it in terms of what I want and what I don't want, it's not that I want them to be zero at all. I just want that they are less than when I'm comparing the same subject. So you can take it as a contrast if you wish, and then you end up with the differential identifiability score, which is nothing but the main the average of the main diagonal minus the average of the entire of diagonal. Average of the entire of diagram. And then we multiply it 100 for convenience, so that we can talk about points if you don't. What does it mean that my data set has 28 points of identifiability? It means that on average, the correlation of the sessions of the same subjects correlate 0.28 more than the correlations among different subjects. So, this is kind of a complement to identification rate that That it's a little bit of a winner-takes-all. If you're not able to predict the subject, you get a zero. If in one shot you're able to predict the subject, you get a plus one. And then the relative frequency of success is identification. Both measurements are very valid and they complement each other. You can think of differential identifiability as a more continuum measurement. And it depends on the importance of your project that it has to be that you find the exact subject or whether you care more about. Exact subject, or whether you care more about a tendency of the same subject, different sessions looking more alike than different subjects. So, small scenario here, again, 20 subjects, three different regimes that we have seen in data sets of the identifiability matrix. So, in this regime, yeah, I'm very happy. The main diagonal is very bright, the functional connectance of the settings of the sense objects. Connectons of the settings of the same subjects correlate a lot. Unfortunately, the functional connectons of different subjects also correlate a lot. So I don't have a good fingerprint situation here, here denoted by a very small score. Remember, this means that functional connectors of the same subjects correlate 0.02 more, almost 0, than functional connectors among different subjects. At the other side of the picture, I have kind of the The picture, I have kind of the opposite problem. Even when I'm comparing the same subject, it's quite different. There is a little bit of brightness in the main diagram, you squeeze your eyes a little bit, but it's almost indistinguishable. This subject, test retest comparison, are as similar as comparing with maybe seven or eight other subjects. This subject actually has an even brighter position when compared to subject 12 or 13. So it's the Theme. So it's the opposite problem. Even when you measure the functional connector in the same subject again, it has changed a lot. Where you want to be is in the middle, in the middle in the plot and in the in-between situations, where the main diagonal is simply brighter general than the off-diagonal. And I'll talk about this situation in a second, but horizontal dark blue. So Dark blue. So, for the second time, if you're old enough, you might remember this movie where everybody looks like John Malkovic. So, the data sets that follow this routine, we say that they have the John Malkovic syndrome, where everybody looks the same. On the other side, when we get data sets like this, we said that they have the carnival syndrome. It's like if you are in a carnival wearing a mask, but I mean not more beauty masks than the regular ones, then some. The regular ones, then suddenly in the middle of the packet, we all exchange the masks and it doesn't make any difference. In other words, if you were bringing new subjects to this proportion or the same subjects, you could barely notice because they are as equal and as different as the others. Here is where you want to be, where your subjects have all brain functional connectivity characteristics that keeps happening to a level of similarity that is higher than between different subjects. Okay? Different samples. Okay? I want to emphasize that by no means I'm aiming that this main diagonal is one. I have zero expectations, I will be worried, I will think it's a bug in the code if two functional connectors of the same subject measure in two different days doing the same task as much as you want to control the conditions, will be correlation. But I want, my expectation, is much more modest. Is much more modest. I just want that they look alike more than when I put in a difference. Okay? All right. Why this is important? Because sometimes I get this question. Okay, it's academically fun to look for these fingerprints, and it is. But why is this important? Well, it is important for a number of reasons. The first one is that, as you know, there are multiple ways of processing fMRI data. Processing fMRI data. There are even multiple ways of establishing what is a functional coupling. Correlation of the bold process n-series is one way, but there are others. There are multiple ways in which you can end up with a data set of functional connectons so that you aim your project. Your project might be making associations with depression, making associations with working memory capabilities, making associations with certain Associations with certain evolving diseases for which you have a score of progression. You could look at sex differences, you could look at phenomena related to aging, but in most of those projects, the reality is that you're going to have one behavioral, cognitive, you name it, measurement per subject. So it's convenient for you to have one. One kind of static stationary, even though we know that functional connectivity is not such a thing, that to the best possible way represents your functional couplings between your brain regions when you're doing certain tasks. So, fingerprinting measurements, differential identifiability, identification rate, and there are others, looking at the identifiability matrix even before deciding what the measurement you're going to take is critical so that you know. So, that you know how well suited you are to proceed with approaches. This is one of the possible models, one of the most standard ones, is called CPM, in order to establish associations between behavioral measurements and connectivity couplings. You want to have the best possible description of the functional connection of each of the subjects when pursuing or doing certain tasks so that you are well suited to have accurate. Accurate findings on the associations. And this is powerful because these measurements and fingerprints are completely unrelated to your hypothesis. They have nothing to do with the personal scale or working memory capabilities or disease progression score. So this is a very nice third-party way of measuring or deciding your processing steps before doing your final analysis on the resulting connectons with your behavior. With your behavioral mesophytes. And it's a very clean way of doing these steps, as opposed to being exposed to a plethora of dozens of ways of processing your data until hopefully you will be finding an association that you're interested in. This is a completely unbiased estimate of reliability based on fingerprints before you move forward and make the associations. Forward and make the associations with your behavioral autographs. There are many extensions of the identifiability framework and, in general, of assessing fingerprintings. I don't have time to talk about all of them, but in the past we have worked on a challenge where the test and the retest of the same subjects are collected in different scanning sites. And we actually saw that through a framework that we proposed, you can actually uncover fingerprints. Uncover fingerprints and let me use metaphorically the word clean the functional connectons to remove the scanning side effect. You can also go temporal and look at dynamical functional connectons and proceed with levels of fingerprinting and also for instance assess to what extent how much how many time points you need in your time series or what's the scanning length that you need your time series for the fingerprinting to arise. And you can also And you can also extend, and I'm going to be talking about this today, among other things, the idea of test retest for reliability to an expansion of the fingerprint to a fingerprinting gradient, where I care about what happens in test retests of the same subjects, but also in twins. Okay, so this paper in 2020 by Vancatis et al. was very important for me in our Very important for me in our path of assessing fingerprinting because they brought a framework that I was completely ignorant about, which is called Riemannian geometry. So, according to Riemannian geometry, when you're looking at correlation matrices, and remember our functional connectors have nothing but correlation matrices, there are better and worse ways, let me put it this way, of comparing them. You can establish a Euclidean distance. Euclidean distance between functional connectons. Let's think that I have two functional connectons A and B, and I'm going to assess the Euclidean distance between them. And then, if I'm playing the finger at the identification rate game, whichever is the shortest distance, I will say that subject X is actually B or A, in this case both or X. From a Riemannian geometry standpoint, that's not ideal because the Euclidean distance is ignoring that for many of these coordinates, as you go. That for many of these coordinates as you go along the space, there is not a correlation matrix that exists for that. You're just ignoring the space in which your correlation matrices live and you're just pretending a shortcut and a straight line is a valid measurement of equipment distance. Depending on the underlying SPD manifold of your matrices, depending on the region where you are, if the region is more flat, you might be lucky and the Euclidean distance actually. Be lucky, and the Euclidean distance actually is almost the distance in the manifold. And if you are in a part that have a higher rubosity, you will be making higher mistakes, assuming the Euclidean distance, as opposed to the distance that belongs to the manifold, that distance being the geodesic distance. And in the geodesic distance, I'm basically going through the surface as opposed to making a straight line. So, in this particular example, I'm Particular example and trying to decide, this is by Vanca Disetal, you have a participant X, and you're trying to decide if this functional connectum belongs to Alice, and here is a functional connector of Alice, or to Bob. If I go visually, and I think if I go visually, and because for many years I've been using different correlation coefficients, I will have put a lot of money into this movement. In geodesic distance. In geodesic distance terms, this matrix is closer to Alice than to ball. When you measure the Euclidean distance or the correlation distance, one minus the correlation, it will tell you that it's both. When you account for the space in the manifold and you preserve the characteristics of correlation matrices as you go along, you actually reach that is Alice. But rather than a discussion of whether it is Bob or Alice, what they did, For ALICE, what they did, they took the human connection project data set, they took all the fMRI conditions, resting, emotion, gambling, language, motor, relational, working memory, and social, and they said, with the same data, the same correlation matrices, so I'm not even adding degrees of freedom on the processing, how is my identity identification rate when I use, let me say, the traditional Pierce and correlation approach, or what happens when I use the geodesic distance? When I use the geodesic distance. And they found that massively, with a few exceptions where it's more closer, but for the majority of the fMRI conditions, actually using the geodesic distance led to a better identification rate. So it looks like it's not only that from the Riemannian geometry standpoint, geodesic distance is a more appropriate way of comparing correlation matrices, but it looks like that also goes along finding higher fingerprinting identification rates. Fingerprinting identification rates in the same data set. I'm not changing anything in the processing of the data. So, there was one technicality that we learned when reading this paper. When you're measuring geodesic distances between correlation matrices, you need that the correlation matrix is invertible. If it's not invertible, you cannot compute geodesic distance. There is this, I'm going to say, beautiful understanding of this with respect to the data that we have. This is with respect to the data that we have. A correlation matrix, a functional connector, will be invertible for us if we have more time points in the time series than brain regions in our parser. So if I'm choosing the motor task, which is really short in HCP, if I recall probably less than 300 time points, if I try to establish geodesic distance between two functional connectors doing the motor task in a 400-grin region parcelation, I cannot because those. I cannot, because those correlation matrices are not invertible. Well, it's not true that I cannot. There is an algebraic trick that we call it like that, so that you can, which is called regularization. If you add an identity matrix to your correlation matrix, that automatically is invertible, regardless how many time points or the balance between time points and number of gradients. And that's what they did to ensure that they could. Sure, that they could obtain identification rates based on geodesic distances. Yes? Abi Avisis, how do you measure the geodesic distances? So it's a function of the eigenvalues that I'm not going very mathematically here, but I can show you. It's a function of the eigenvalues of the correlation matrix easy. And actually there is this interesting property that if you forge a single entry of a correlation matrix, it makes a valuation of the eigenvalues be all of them greater than zero. So it's also a very high. So it's also a very good way of checking whether a correlation matrix is a legit correlation matrix as opposed to it has been forged or rounded software. So we said, well, they chose to add the identity matrix, literally adding once in the functional connectons to the main diagram. Who said it has to be once? We could add 0.5, we could add 2, we could add 3.7. This still guarantees. This still guarantees that the matrix is invertible. And then we were wondering: does it make any difference in identification rates? Because we didn't know. So I want you to think, well, this is not very handy. I want you to think of two things that happen when you increase regularization. Your data is shifting in the space. This is without regularization and then it's moving. But it also happens. But it also happens that it's being compressed in a non-linear way that is impossible to represent in any possible way in a figure. So we said, okay, let's understand what happens when I'm compressing the space. When I'm compressing the space, I was told by an expert in Riemannian geometry, your space is shrinking, your geodesic distances should reduce. And globally speaking, the average global geodesic distance of a data set. As global geodesic distance of a data set, when you disregularization, it decreases by what it looks like and maybe a negative exponential distribution. That's okay, but that's not very exciting in terms of fingerprinting. What is really exciting in terms of fingerprinting is what happens in the similarity or dissimilarity or distance between different subjects. So we decided to track three subjects of the read spool with respect to a subject A test and see what happens as you are compressing the space. You are compressing the space, increasing regularization. And it's really interesting what happens. We call this internally in the lab the tornado figure. The retest of subject A, which is actually the same subject that subject A test, how many subjects I have that are more similar than that one to subject A test, I had maybe seven or eight subjects that were more similar to myself. As I increase regularization, fla. Suddenly, I am the top one. So as I'm compressing the space, the two subjects that were In the space, the two subjects that were actually the same became the same. Everybody's reducing their geodesic distance, but in that compression, I happened to match myself at some point. And some other subjects that were fairly close, like the red one, subject the retest, kind of started to take off. Take off, they're still closer and closer, but I start having more subjects in between. Okay? So, exactly by this, we assess what happens with regularization. Happens with regularization. What happens with regularization with weighted regularization across all the fMRI conditions? And the big lesson of this is that regularization is, you know how they talk about personalized medicine. So we have weighted personalized regularization. The optimal regularization to uncover fingerprints, to maximize identification rate. It depends on the task, it depends on the partial agent, it depends on the scanning length of the task. And I cannot give you a universal. And I cannot give you a universal regular basis. So I'm going to go very quickly, but in the last minutes, I'm going to talk about the most recent findings that we have, where we kept digging into Riemannian geometry. So maybe I'm going to push it at the right half zero minutes if that's okay. So we kept digging into this fascinating area of Riemannian geometry, and geodesic distance is not the only thing that you can do. You can actually do something that is called tangent space projections. You have your matrices, you choose a reference point in your SPD manifold, which is used. In your SPD manifold, which is usually some kind of centroid of your data. And there are up to seven ways of measuring the centroid. And then it's like you project all your data into a two-dimensional space where the Euclidean distances represent the underlying geodesic distances in the SPD manifold and your functional edges are now independent variables if you were to do any machine learning project based on functional calculus. Project based on functional calculus. Independent, identically distributed action. There are some similarities with the challenge of making a two-dimensional atlas from the Earth, depending on your reference point. I'm from Spain, I would have never chosen this one. But the amount of distortion or preserving the characteristics of distance and shape in your two-dimensional landmass will greatly depend on which is your reference point. And I've been checking. And I've been checking about this, and actually, it's an amazing topic of research: how to do the two-dimensional projections of planet Earth. Okay, so we said if we do tangent space projections, what happens if we compare the identification rates in the Euclidean distance with respect to correlation distance in the traditional FCs before doing any projection? And what happens is that overall, it outperforms. Overall, it outperforms. You do better in the tannin space projections using Euclidean distance, if your aim is to maximize identification rate, than correlation distance images. And then we tried something else. We said, well, what happens if instead of Euclidean distance in the Riemannian tangent space, we go back to correlation in the tangent space? And you will not find any paper on Riemannian geometry saying this and I have looked like there is no. Like, there is no tomorrow. This is what happens. Identification rates go up even more when you use correlation as your similarity measurement or dissimilarity, if you do one minus correlation, in the tangent space, in order to maximize identification rates. But actually, it gets even better because the results I've been showing you in the last two figures, I was finding the optimal regularization level that will maximize identification rates in each of the conditions and parcelations. In each of the conditions and parcelations. These were the optimal ones when I'm using correlation in the tangent space projection. Practically, for all cases, the minimum value we were trying. It just needs the most minimal regularization and it works. As opposed to using the Euclidean distance in the tangent space projection, where I go back to personalized regularization, depending on the task, the duration, and the parcelation, the level of regularization is different. To the extent that when you flip Extent that when you flip, you impose the regularizations of one into the other, the Euclidean distance in the tangent space gets horrible in terms of identification rate. I cannot apply these values and hope to have good identification rates, whereas the correlation in the tangent space doesn't care what level of regularization you have. So now I have moved back from personalized regularization to just do a little bit of regularization, go to the tangent space projection and use colorision and you're good. And use pluralism, and you're good. So I'm skipping a few details, but I'm going to check a more challenging situation. Now, I don't only have test retest functional connectors, but in the human connector parade, there are pairs of twins, monopsygotic and dipygotic twins. Monopsyotic same genetic material, dipsygotic are unhalf genetic material, in all cases a highly certain vitamin. This works horrible when you use traditional functional. When you use traditional functional connectons, it's very challenging, and you barely get anything above 0.6. And if you go to isygotic twins, it's even less. Actually, you only reach 20% in a couple of cases. When we do Euclidean distance in the tangent space projected data, you actually get much better results. Monozygotic twins is not as retest anymore, it's different subjects. Highly related, but different subjects. It bumps up a lot identification rates. Lot identification rates and still doing really poorly in monopsygotic twins. When you actually do correlation in the tangent space for the identification rates, your levels of identification rate in monopsygotic twins are at the same level or even better than test-breathed tests in the original FCs. And you have increased a lot with some variability that isygotic identification of rates. We also check, and I'm about to finish, what's the impact of the scanning length? This is for resting. The scanning length. This is for resting state because shortening fMRI tasks is kind of tricky what you're really doing. So we see that for test-retest, we just need barely 200 volumes, and we have a 100% identification for test-retest. And we have this amazing behavior in blue when we're doing correlation in the tangent space projection for the monozygotic tweets, and a really promising behavior when you do isygotic twins that we cannot reach with any. That we cannot reach with any other approach. And the last slide that I want to discuss is that we took another data set collected under different ephemera sequences with 181 healthy controls. We imposed the regularization that we learned in the correlation data space, the minimal one that we learned from the ACP data set, and we got 100% identification rates for any partialization granularity just by doing the correlation. By doing the correlation as the distance in the tangent space projected data, and we get good, but not so good, results when we use the typical correlations in functional connectons. So just to finalize, I hope I have convinced you that tangent space projections are really worth it to be assessing functional connectons, that correlation is a really promising measurement in tangent space projected data, and that our findings of universal regularization work for any fMRI conditions. Works for any fMRI condition as available by HCP, for any partial acid granularity from 100 to 900 brain regions, for any scanning length that we assess in resting state, for any fMRI sequence modestly because we try to data set with two different acquisitions, and that they keep the fingerprint gradient, test retest, X-twins, and DC twins. All right, this is all. Thank you so much for attending, and I'm happy to answer any questions if I didn't go too much with time. Thank you, Pregnan. We have time for one or two quick questions. Yeah, so I don't need pushy buttons, just have points. And this is what this part which you skipped. So you saw the blue bar, right? So they so there I say even this is peculiar individuals who are very different from all the others. Do you have any insights into that? Yes, and I'm sorry I promised that I was going to discuss that so I don't know here but here's a quick explanation. One of the benefits of looking at the identifiability metrics is to see specific session outliers. Subject, let's say subject 14, in the three test session is completely different to all the 20 subjects in the test session, including quite a lot of him or herself. This is a really good test to identify outliers. If I were to publish with this data, this is just a cool example, I could go back to that subject. Example, I could go back to that subject session, I would really look at head motion and what are the ball time series and what happened, because this is a clear outlier that something went not ideal in the estimation of the functional parameter. Or the subject decided not to do the task, for instance. That would be another possible experiment. And it is something else. Yes? You might have said this, but I didn't get it. So using the same. Of this, but I didn't get it. So, using the same data use case, we'll be able to take out individual differences to what you have. This is a very promising area that we're working. All the data that I presented here is healthy controls, but we also want to look at the impact of diseases and the progression of disease and what we capture in the tangent space projection. You can think of two ways. You can think of trying to remove that effect or actually trying to isolate that effect if what you really want to track is the disease pervasion. And I don't have anything here to. That is probably basically. And I don't have anything here to show that we're working on that math as well. We're running out of time, so thanks now, Mr. Speaker. I know there's something blinking, and I think I've made this the sound upper right one.