So very much for the invitation. Can everybody hear me? Is the microphone okay? Yes, perfectly. Yes. Thank you. Okay, so I'm very happy to be present virtually for this conference this week. I would have loved to be able to come and see you all in person, maybe next time. Next time. So, today I will speak about some recent work which is about the stochastic wave equation with Levy-white noise. And this is sort of continuing what Karsten was saying. Of course, I will focus on a different equation, the wave equation. So let's see the outline of the talk. So I will give an introduction to To the topic, and then I'll spend some time again on SPDs with Gaussian white noise, Levy noise, and finally, I will look at both heat and wave equations. So the wave equation, as we well know, we all know, it's a model for the description of waves. And these can be sound waves, or water waves, or seismic or light waves. And in particular, in this talk, I will consider the wave equation. I will consider the wave equation in dimensions one and two, but I wanted to include also for the first few slides the third dimension. And if we look at the form of the equation, so we have the second derivative in time, which is equal to c squared multiplied by the Laplacian. And c is a constant, which basically indicates the propagation of speed of the waves. And w of t and x is the displacement of point x at time t. And if d is equal to 1, this And if d is equal to one, this is a model for the vibration of a string. If d equals two, this is the vibration of a membrane. If d equals three, this is an elastic solid. And we have some initial conditions. So we have at time zero, the displacement is given by function u zero, and the velocity is given by a function v zero. And it is well known. So, and here I'm giving the form just for the case when the propagation constant is equal to. The propagation constant is equal to one. So it is well known that the solution has this form. So it's basically a sum of two terms. Both of them are obtained using convolution. So we are convoluting the initial velocity with a function g, which is the fundamental solution of the wave equation, which is an object I will describe on the next slide. And then we also have the convolution with the initial condition u0. And for this term, we take the derivative in time. term we take the derivative in time and if in particular u0 is equal to one so we have a displacement a constant and v0 is a zero then this solution turns out to be identically one so that will be the case that i will be considering later on so the fundamental solution of the wave equation is given by different formulas in different dimensions so the simplest case is when Dimensions. So the simplest case is when d is equal to one. In that case, the function is just an indicator. It's the indicator of the interval around zero of a radius t. If d is equal to two, already the function becomes more complicated. It's a function which has, again, a compact support in the same type of region around the origin, but it has singularities around the boundary of the unit sphere. And I mentioned two. Unit sphere. And I mentioned three. The function g depends on the surface measure sigma t of the unit sphere. And in higher dimensions, the function g becomes a distribution. And the formulas are different for the case of odd dimension and even dimension. And in this talk, the modulus bar will actually denote the Euclidean norm. So a quick history about the problems. History about the problem. So, as we all know, probably this problem of vibrating string has been studied in the literature a long time ago. So, in D equal to one, this is the D'Alembert formula. In D equal to three, it's Kirchhoff formula. And in D equal to two, we have the work of Poisson, so Poisson formula or even Hadamard by the method of descent. In the case of the inhomogeneous wave equation, so Homogeneous wave equation. So we suppose that we are adding a source function f to the wave operator. And this function is supposed to describe the effect of the source of the waves on the medium which carries them. And in this case, the solution is obtained again as a sum. So we have a w, which is the solution of the deterministic equation. And we have a new term, which is another convolution. This time is a space-time convolution. Convolution, this time is a spacetime convolution of the function f with a fundamental solution g. And the quick justification is that if we let script L to be the wave operator, then we know that script L of W is zero. Script L of G is the delta, which is the direct delta distribution. And then using basic properties of operate, so operations on distributions and convolutions, we Distributions and convolutions, we see that in the end we obtain exactly f. So, in this calculation, the star denotes the space-time convolution. So, all of these are just a brief, so it's a brief review of deterministic case. So, what's happening if we are considering now a random noise which is acting on the equation? So, this would be the W dot, it's a formal derivative. The w dot. It's a formal derivative. In principle, this doesn't exist. So, I'm going to give more details about this random term in the future slide, but for now, let's look at what happens and how we can define a solution in this frame. So for now, I'll consider dimension one or two. So we are no longer considering the case when g can be a measure or a distribution. So in this case, the so-called random field solution of the wave equation. Solution of the wave equation satisfies by analogy with the deterministic case the same type of equation. So it's given by the deterministic term w of tx. And then we have a new integral, which is a stochastic integral. And this one should be interpreted as a stochastic convolution. So basically, if w would be a smooth term, which would have partial derivatives in space and time, this would recover the result from. Recover the result from the previous line. But in general, we will have to give a precise meaning to this integral. So similarly, we can talk about the stochastic heat equation. So this is what Carsten was also explaining. So in the additive case, the random field solution is now obtained as a sum of two terms. The first term is the convolution between the heat semigroup, which is denoted. Heat semi-group, which is denoted in this talk by small g with the initial condition u0, and then similarly, we have a stochastic convolution of the heat semigroup with W. So a more precise definition of the space-time Gaussian white noise. Well, we assume generally that W of A is a collection of zero-mean random variables which have mean random variables which have normal distributions and whose covariance is given by the Lebesgue measure of the intersection between A and B. So this is what's called the space-time Gaussian white noise. We can extend this process to a process index by functions. So we start with the indicators basically. So the W of indicator A will be W of the set A. By linearity, we can Set A. By linearity, we can extend it to the set of all linear combinations of such indicators. And more generally, by continuity, we can extend it to the closure of the set of simple functions, which happens to be the space L2. And we obtain in this way an isometry, which is very nice because it's basically Ito's construction of the stochastic integral with respect to Brownian motion. And the isometry is telling us. And the isometry is telling us that if we want to calculate the covariance between W of φ and W and ψ, we have exactly the inner product in O. When we come to the question of existence of solution, for the wave equation, we arrive to the following conclusion. So, if we want to have a solution for the wave equation with additive noise, so that was equation one, then this random field solution will exist if and only if. Field solution will exist if and only if the stochastic integral would be well defined. So that will basically require that the function g is in L2. And if you look at this condition more closely, so in dimension one, this condition will be satisfied automatically because this is just an indicator. However, in dimension two, this condition is no longer satisfied. So in dimension two, the fundamental solution of the wave equation is no longer square integrable. Is no longer square integrable, so we will not have a solution for that equation. And a similar phenomena happens for the heat equation, just the calculation is different. So in this case, we would like the heat kernel to be square integrable. And we see that this again leads us to the same conclusion. So the random field solution will only exist in dimension. So let's see what happens for the multiplicative noise. So in this case, we are looking at the same operator, so the wave operator, but this time there is a function sigma of u, which is multiplying the noise. And for simplicity, I will assume that initial conditions are zero, and sigma is a Lipschitz function. So by analogy with the previous definition, a random field solution of one will satisfy this integral equation. So the function This integral equation. So the function sigma of u of tx appears now in the integral. And u of tx is no longer completely described. It's an integral equation. U appears on both sides of this equation. So we cannot explicitly say at this moment what u is. And a similar definition, as we have seen in Carson's talk, is valid for the heat equation. We just replace the The fundamental solution capital G by the heater. So the existence of the solution is something which has been studied a long time in the literature, basically going back to the work of John Walsh. And in particular, there is a fundamental argument which has been made very clear in Roberta Langson. Clear in Robert Alang's work. So, the existence of the solution of the equation with multiplicative noise starts with a Picard iteration. So, we start our iteration at zero or whatever initial condition we have, and then we define iteratively the sequence un. So, here we are including sigma of un, and that is used for the definition of un plus one. And what it can be proved is that if sigma of u is just u, as it was the case in Just U, as it was the case in Carsten's talk. This procedure, more precisely, Un, is actually the partial sum of level n associated to a series of Wiener integrals. And the limit of this series is giving us the Wiener Causs, the composition of the solution. So remember, we are talking about Gaussian white noise, so a Wiener Caus is in the sense of Maliaving Kauf. But in the case, Maliyaving Kalpu. But in the case when we have an arbitrary function sigma, Lipschitz function sigma, we don't necessarily have that vienner-Calus decomposition. So what we do is the calculation which is explained on this slide. So here we start by evaluating the increment between two PCR iterations, so un and un minus one, and we are looking at the supremo index. Then when we evaluate the second moment, we see that We see that because of the definition, we have the difference between sigma of u n and sigma of u n minus one. And due to the isometry property, we can go from an integral which was with respect to w to a deterministic integral, which is now dy ds. So the next step would be to take outside the supremum in y and to use the Lipschitz property of sigma. So that gives us the constant C sigma. us the constant C sigma and then finally the remaining term which is an integral on r of g squared is something that is integrable as we have discussed earlier so it's dimension one here so this is a function which depends only on t minus s in fact we can compute it explicitly it's one over two t minus s and this is very nice because if we now take the the supremum in x on both sides we arrive to a form of We arrive to a form of Gronwa lemma. It's a different Gronwa lemma than the one that is used in classical SVEs. So, this one is specific for SBEs. And the same argument will work for any other equation, provided we can integrate the fundamental solution with a square. And in particular, it will work for the heat equation. So, let's see that Granois lemma. So, here is an extension of Granville lemma, which is due to lemma which is due to Robert Dalan. So we start with the sequence of functions fn. Initial condition is that the function f0 is bounded by m and then we assume that fn plus 1 is bounded by the integral of fn multiplied by this function j. So in that case, it turns out that the supremum of fn of t to any power 1 over p is summable. It's summable. And this is very, very useful for SPDs because it basically tells us that the sequence UN that we defined before is a Cauchy sequence in L2 of omega. And moreover, this is uniformly in Tnx. So the limit of this sequence is the solution of our equation. And a similar argument can be used to show that the solution is unique. This is This is the situation for the Gaussian. Now, if we move to the Levy noise, things start to become more complicated. So I will start first with the definition of the noise. So here again, we are looking at the collection L of A of random variables, which are indexed by bounded Borel sets. And I will focus on a Levy noise without any Gaussian component. So basically, if you look at this. Basically, if you look at this formula for L of A, we have three terms. The first one is the drift. The second one is the one which we call the small jumps. And there is a third one which is corresponding to the big jumps. And what's appearing in this formula is random, a Poisson random measure J, which is on the triplet space, so R plus times R D times R. The intensity of this measure is Lebesgue measure in space and time. Lebesgue measure in space and time multiplied by a measure ν. And this measure ν is a Levy measure, so it satisfies this integrability condition and it does not charge zero. So if you look at this formula more closely, we see that this is if we are mentally replacing A by, let's say, the interval zero key for a second, and we ignore the fact that we have x. So in that case, this would be precisely the Levy. Precisely the Levy eto, the composition of a Levy process without Gaussian component. So this formula, the extension to the space-time situation is appropriate for studying SPDs. And it has been considered in the literature a long time ago. So basically, if you look at works by Rashput and Rozinski in 1989, they can. 1989, they considered something more general than this, and they call this object an infinitely divisible independently scattered random measure. So independently scattered means that if we have disjoint regions in space-time, then so let's say these regions are A and B, and L of A and L of B are independent. And infinitely divisible stands for the fact that L of A has an infinitely divisible distribution. Distribution. And we also have a Levy-Kinchin formula. So we know what the characteristic function of L of A is. So it turns out that it's exactly the Levy-Kinchin formula that we'll have for a Levy noise, except that instead of the T, which is the homogeneity part of the noise for temporal component, we now have the Levesque measure of the set A. So there are several examples of There are several examples of such noise. In fact, there are many examples, but I wanted to focus on two cases. So the simplest case is when we have finite variance. So more precisely, when this z square is integrable with respect to nu. And this will be the so-called light-tail case. And there are many examples of Levy classes of Levy noise which satisfy this condition. One example would be, for instance, the gamma noise. Would be, for instance, the gamma noise. And in this case, if in particular we let's say we take the drift to be equal by minus the integral of z mu dz on this region. Then we can accumulate the small jump and the big jump component of the noise in a single integral. And we arrive to the conclusion that L of A is the integral of Z with respect to the compensated measure J tilde. And the story. And the stochastic integral of predictable process X with respect to the noise L is simply equal to the triple integral of X multiplied by Z with respect to J tilde. And this case is very nice because it's bringing us a lot of, it's allowing us to use a lot of tools from the theory of martingals. This time, these are catalog martingals, not continuous. Catalog martingals, not continuous necessarily. And we have Ito isometry property again. The only thing that is new is that we have this Z constant, which is going to bring us a new constant phi in front, which by simplicity, we may assume that it is one. And the existence of solution of SPDs with this type of noise follows exactly the same steps as in the Gaussian case. So nothing is really new for. Nothing is really new for this case from that point of view. So we have existence and we have units. What's more interesting is the case which is when the noise does not satisfy this finite variance condition. And one example is the case of the alpha stable noise, which appears, for instance, in other references, for instance, in the book by Samoraninsky and Taku. There is an entire chapter dedicated to this object. An entire chapter dedicated to this object called an alpha-stable random measure, and there we can also find the definition of the stochastic integral with respect to deterministic integrands and so on. So what's specific for this case is the form of the Levy measure. So the Levy measure nu is now given by a power function. So we have z to the power minus alpha minus one for positive z, and possibly with a constant. Z and possibly with a constant C1. And for the negative tails, we have another constant C2. And alpha is a value between 0 and 2. And certainly, we don't have the integrability condition that is mentioned in case 1. So the variance is infinite. So how do we define the integral respect to L in that case? So the procedure is similar to the Gaussian case. The procedure is similar to the Gaussian case. So, again, we start with sets. So, and then we extend to indicator of these sets. So, L of 1A is going to be LA. We extend this bilinearity to linear combination. And then we say that the integral of a function phi with respect to L exists if there exists a sequence of simple functions phi n which converge to phi almost everywhere with respect to the Lebesgue measure. measure and in that case we say that the limit of the integral of phi n with respect to l is what we call l of phi so that will be our stochastic integral and we denote by s of l the set of all functions for which this integral is well defined so let's now now that we have all these ingredients in place let's start to to look at the main topic of uh today's talk so namely uh Today's talk, so namely the SPDs with this type of noise. So suppose that we look again at this operator LU, and here we have the same function sigma. So this is a Lipschitz function applied to U, and the formal derivative of the noise L. So L can be a second order partial derivative, any second order partial derivative operator. But in particular, in this talk, I will consider only the heat and the wave operator. Only the heat and the wave outbreak. And the initial conditions are zero. So we can try to see if there is a way to make sense of Picard iteration in this case. So the idea is the same as before. So we start with u0 equal to 0, and then we define iteratively, so u n plus 1 will be the stochastic integral respect to L of the fundamental solution g, and then we have sigma of the previous peaker iteration u n. And this integral will have to be well defined at every single step of the iteration. So, in the finite variance case, the existence of the solution is no problem. So, basically, we proceed exactly as in the Gaussian case. The only thing that will be new is the fact that we have this constant v, which comes from the second moment of the Levy measure ν. But everything else is exactly the same. Same. So we will be able to show that the sequence u n is Cauchy in L2 of omega uniformly in space-time. And the solution that we obtain as the limit is the unique solution of the equation 6. So what happens in the case of general heavy noise when we don't have finite variance? So this problem has been studied in the literature for, or it exists in the literature. For so, or it exists in the literature since I would say the early 90s. So, here I'm going to give reference to some of the most important works. So, just to recall, the heat equation is the one which is written here. So, second derivative in time, one over to Laplacian, and then we have sigma of u. Dimension for now is the space dimension is arbitrary. Space dimension is arbitrary, and let's assume the initial condition is 0. So, in 1998, Stan Luberg-Bier, I think it was in his PhD thesis, he showed that if the measure nu satisfies this integrability condition, so basically this is a condition which will say that the noise has moments of order p for some p between 1 and 2. And in addition, p is smaller than 1 plus 2 over. Is smaller than one plus two over d, and we have seen this condition in Carstench also, then equation seven has a unique solution, and moreover, this solution will have also moments of order p. So this property of having a moment of order p is inherited from the noise, and we will have a uniform bound in TNX. So let's examine for a moment why this condition p smaller than one plus two over d. Smaller than one plus two over d. So we can look at this condition, we can express it in a slightly different way. So we can have d over two one minus v plus one greater than zero. And now if we look at it in this way, we see that this is basically coming from the requirement that the heat kernel has a moment of order p. Because if we evaluate this integral, remember this is the density of a normal random variable, variance t minus s, then what we end up Minus s, then what we end up with is this integral, and this integral cannot be finite unless this condition is satisfied. So that is where the condition comes from. Of course, when we will be moving to the wave equation, the calculation will be different and we will not require the same condition. So this is the form of the heat semigroup again repeated on this slide. And what is important is that previous Is that previous condition, the one about integrability of μ, so a p-th moment of ν, this condition is not satisfied by the alpha stable ones. So it's clear that this result, although it is very nice, it's not going to be satisfying for heavy-tail noise, for instance, for alpha-stable noise. So that condition excludes this noise. So, the new idea which is due to Karsten, I think it's from his PhD thesis 2017. So, he introduced the following assumption. So instead of relying on a single exponent, P, as Saint-Luberbier, it was assumed that there are two different exponents, Q and P, and these are corresponding to the small jumps and the big jumps. Small jumps and the big jumps. So p is the exponent of z for which ν is integrable around the origin. And at infinity, we have a possibly different exponent q. And this allows us, this type of assumption, as we will see later, it will allow us to include the alpha stable noise because in that case, we have more flexibility and we can choose indices p and q, which satisfy this assumption. And for technical reason, if p is And for technical reason, if p is smaller than one, we would need a special form of the drift. So the drift is given precisely by the integral of z on the interval around the origin. So that is the first idea. The second idea is to consider a truncated noise. So basically, if we want to have object for which we have moments, we will have to get rid of the big jumps. So this is the noise. So, this is the noise denoted by Ln here. It has the same drift term, it has the same form around the origin as the original noise. The only thing that is different is that for the large noise, we are considering only the value, for the large jumps, sorry, we are considering only the values z, which are smaller than n multiplied by h of x. And this type of truncation is very nice because we can basically manipulate. Basically, manipulate the space component of the noise at the same time as the jumps. And the function h is chosen in a specific way. So it's not identically one. That would be too rough. So it's actually one plus a polynomial. And we will have the freedom to choose the power of eta depending on what we need. And if p is smaller than one, this truncated noise. P is smaller than one, this truncated noise can be written very nicely as again one single integral with respect to the Poisson randomness. So we would need some tools for working with moments. And this is a lemma from Carson's work again. So what happens is that if assumption A holds, then we can very easily estimate the moment of the stochastic integral with respect to the truncated. integral respect to the truncated noise and the price that we have to pay so basically we can bring the power p inside the integral so x is a random process it's a predictable process so as when you look at the at the estimated term we see that a stochastic component disappeared and the price that we have to pay is this function h but remember this function uh we we have control on on this function it's uh it's just one plus y to the power so that is So that is when p is smaller than one. And when p is greater than one, something very similar happens. So basically, again, we can bring the power p inside, but there is an extra term g, which is added inside the integral. And a quick look at the proof shows that the argument actually holds for wave equation as well. And there is, yes. So in your Yes. So in your sorry, was the previous slide? Maybe. So yes, so is this uniform in capital N? Yes, yeah, the constant C doesn't depend on N. Okay. I think from memory. Karsten may correct me, but I think it's independent. So the main result is the following. The main result is the following. So now we have to be more careful in how we choose the constants, the two exponents, Q and P. So remember, these are the exponents which are balancing the two tails. Sorry, not the two tails, the big jumps and the small jumps. So in addition, we will need some further bounds for both of them. So an upper bound on P, we have seen that upper bound before, and a lower bound for Q. And moreover, we For q. And moreover, we need to be very careful with how we choose eta, and that is the interval where eta is allowed to be. So, under these conditions, the heat equation with truncated noise has a unique solution. And moreover, so that solution is denoted by um. This is for any n fixed. And moreover, this is going to have moments of order p, not any p, remember, it's just that p, particular p, which is given by assumption a. Assumption A. And for instance, for the alpha stable noise, we will have to choose that carefully, and there is a certain range of values of p for which this moment will exist. We will have a uniform in t and in x, but in x, we only have this uniformity around the origin. So it's not for the entire domain. So this is the first difference compared to the Gaussian case. And remember, this is the equation with truncation. And remember, this is the equation with truncated moons. Now, if we are trying to extend this to the entire to the original problem of the equation with Levy noise without any truncation, we'll need some sort of consistency. So, what happens when we move from truncation level n to truncation level n plus one? So, what's happening is something very nice. Basically, it can be proved that if we choose a certain stopping time, tau. A certain stopping time τ n in a very clever way. So, namely, it's the first time when the noise j will have a jump in the interval zero t and the space jump region, which is given here. So if we choose tau n in this way, then for any t smaller than tau n, un is going to coincide with un plus one. And because of this consistency condition, we can define u of tx simply by saying it is x simply by saying it is equal to u n of t x if t is smaller. And this procedure gives us a solution. It's not clear if this is going to be the only solution, but at least it gives us something to work with. It's something which shows existence. And we will not have moments of this solution, of course, using this procedure. We will only have moments of the truncated solution for t smaller than tau n. So this was a result of Carson. Result of Carson. And the sketch of proof is Picard iterations against. For each capital N fixed, we have now Picard iteration with level N plus 1. So here we have N plus 1 and N. And now we use the lemma. Here I'm illustrating only the argument for P smaller than 1. So basically, we push the power P inside the integral. Remember, we have to include the H, it appears with a P minus Q. And then additional. Minus q and then additional manipulations with Minkowski inequality and things like that allow us to arrive to something like that. And a key properties in this argument are the fact that the power p of the heat kernel is related to the original heat kernel evaluated at t over p and an extra factor of t. And crucially, this argument relies also on the semi-group property of the heat kernel. So it's clear that. speed current. So it's clear that something like that, at least from the first loop, is not going to work for the wave equation. Now, before going into the wave equation part, I would like to say a few words about the path properties of the solution. So here we're going to fix an interval t and zero t, sorry, and I'm looking. 0 t sorry and I'm looking at the same tau n as before but with a fixed interval 0 t. So in that case the stopping cow tau n is basically infinity and u of tx turns out to be equal to u n. So it suffices to study path properties of just u n. And in order to discuss these path properties, I would like to look now at To look now at a fractional Sobolev space. So, just to recall, this is a space of temporal distributions which satisfy this condition. So, the Fourier transform square multiplied by this power r is finite. And the Dirac delta distribution lies in such a space if and only if r is smaller than minus d over 2. And for the problem that we have, there is also the local fractional subolev space, which is defined by Space, which is defined by locality. So, basically, by multiplication with test functions. The basic properties of the heat kernel are that for t positive, gt is smooth. It's a function in s. And for t equal to zero, g0 basically is defined by continuity. So, if we look at what g zero x is, if x is not zero, if we take the limit as t goes to zero, this is going to be zero. To zero, this is going to be zero. But if x is zero, the limit is infinity. So this explodes. So for that reason, at time zero, the heat kernel is a distribution. And the result that I wanted to show you for the comparison with the wave equation result that I will discuss next is something that again was discovered by Karsten with Robert Dalang and Thomas Humo. So here we have Thomas Humon. So here we have the same type of assumptions which were needed for the existence of the solution. And under these assumptions, they prove that both processes, which is the solution of the equation with truncated noise and U, have Cutlap modifications with values in this fractional Soviet space for any R smaller than minus V over 2. And the quick sketch of the proof for P greater than 1. So we look again at the So we look again at the decomposition of the truncated noise. We have the drift, we have the martingale part, so that will be the LM, and then we have the compound Poisson part, that will be the LP. And this gives us a decomposition of the UN. Moreover, we are now going to chop the integral with respect to the martingale and compound Poisson part in two regions around the origin and outside the origin. And outside the origin. And the important term, it's one that I have underlined in red here, so that will be UT1. And this one is a term which is now an integral on a compact region. And because of that, it can be written as a finite sum. So basically, this is the term which is going to tell us the order of regularity because as I'm explaining here, the Poisson random. Here, the Poisson random measure in this compact region, the red region, has only finitely many points. And because of that, this becomes a finite sum. So if you want to study regularity in T of this process, it suffices to study the regularity in T of the function G. And this is something that we already discussed. So basically, this function is smooth for T. Is smooth for t greater than ti, and it's zero for t smaller than ti. And the only problem is what happens when t is exactly equal to ti. So remember, this ti is the point of the Poisson random measure. And in that point, the function is a distribution, and it's a distribution which is in the Sobolev space of order minus d over two. So this is where the order comes from. So yeah, sorry to interrupt. So yeah, sorry to interrupt again. So yes, is your uh sigma bounded here or is it can you yeah so for this uh yeah so uh the initial step is to consider sigma bounded and then the second step is to remove that assumption using um i think it's a truncation argument but you're right in in this what i'm explaining here is the simplest case when sigma is bounded but it's possible to move to the unbounded case To move to the unbounded case, but you still don't need any weight on your HR. I mean, the H of I mean your summary. The H is the same one plus polynomial power eta. So you do have some growth at infinity. Yes. Okay. So now let's see for So now let's see for the last part of the talk, now that I have reviewed all these results, let's see what can be said about the wave equation. So some of these techniques will not work and we need new ideas. Some of them will work in a slightly different way. So once again, I'm focusing on the case d equal one or d equal to two. So the more complicated case is when d is equal to two, but it's very instructive. equal to two but it's very instructive to look also at dimension one so the initial conditions are zero for simplicity and the same assumption as before so namely we will need exponents p and q for the small jumps and big jumps and if p is smaller than one we have a special form of the trip so the theorem is that under this assumption if we assume in addition that we need to assume in addition Uh, that we need to assume in addition that a p is strictly smaller than two if d is equal to two, and no additional condition is assumed for d is equal to one. So these are the main assumptions. We take an arbitrary eta greater than d over q. So this comes from the special form of the stopping term tau n, this assumption on eta. So under this condition, the way we can Condition, the wave equation with truncated noise has a unique solution. And this solution will have basically the same property. So its peak moment is going to be finite and uniformly bounded around the origin. Moreover, the same type of consistency condition will hold with the same time of stopping time, and therefore we can define a solution of the wave equation, and that solution will satisfy the same problem. So if you notice this. So if you notice, this result is very similar to the heat equation case, but the conditions on P are different. So the sketch of the proof for the first part, which is the interesting part. So here we are still going to look at Picard iteration for a fixed level n. That's for the heat equation. But remember, we don't. But remember, we don't have semi-group properties, and we need to be able to evaluate the integral of the pth power of G. So what happens is that this can be calculated explicitly. So I'm considering dimension two. So the calculations for dimension one are even simpler because the G is just an indicator in that case. So the basic properties that I The basic properties that are needed are these two. So these are elementary properties. And then there is something else which is not at all elementary. It's actually quite interesting and quite involved. So there is a recent paper by Golanus Guerrero Nua Lartenzen where they studied convolutions of powers of the wave kernel. And basically, this is the starting point of my investigation. Of my investigations in this area. So they have proved that if we look at convolution of power 2Q, where q is chosen in an appropriate manner, and then we take a power delta, which is also chosen in an appropriate manner, then we can integrate. So remember, we are interested in integrals of this form at some point in the proof. And what happens is, of course, we will not have an equality, but there is an upper bound which is very useful. But there is an upper bound which is very useful for calculations. So basically, we are having, we are looking at the function g appearing again with a possibly different power. So that's one of their results. And then interestingly, they have another result where they get rid of the function g altogether. So basically here, we are back to so basically we are only arriving to one indicator. So these are the tools and So these are the tools, and I will skip the rest of the argument. It's not a straightforward calculation, but it's not very difficult even. Now, for the last five minutes of the talk, I would like to say something about the path property. So, this result shows the existence of the solution. I don't know if this is unique, even in the case when sigma of u Even in the case when sigma of u is equal to u, which would be a sort of hyperbolic underson model with levy noise, I don't think this has been studied. So Karsten Gorg seems to be focusing on a parabolic case. So other than existence and uniqueness, another interesting thing that we can say about this solution is what type of path properties we have. And here I will. And here I will explain the path properties that can be obtained using similar methods to the paper by Karsten, Dalang, and Hume. So for that, we need to review basic properties of the wave kernel, G. So first of all, if T is positive, Gt is going to be in the Sovolar space of order R for R smaller than 1 minus D over 2. And that is this calculation. And that is this calculation. And then we need to examine what happens when t is equal to zero. And remember, that calculation is needed because that's going to dictate the order of regularity when we study the four integrals. So one of them will have a finite number of terms, and one of these terms is going to be of this form. So what happens in dimension one? G0 is just the indicator of the zero set. So that is A zero set. So that is very nice. And in dimension two, we have again the same phenomena as for the heat equation. So basically, if we try to extend g by continuity at zero, we see that if x is not zero, the limit is zero. And when x is zero, the limit is infinity. So g0 is going to be again a distribution in dimension. And the result that I wanted to share with you is the one with To share with you is the one which says that if we have that assumption A, and in addition, in that assumption, the value P is strictly smaller than 2, if dimension D is equal to 2, then we will have what solution? We already know that. But in addition, this solution will have the following regularity property. So in dimension one, we will have catalog modification with values in the Sovolev space of order. The Sovolev space of order r smaller than one over four, and in dimension two, we will have catalog modification up to so holder, sorry, the solar space of order minus one. So minus one is basically in this case minus d over two, because the dimension is two. So that is exactly as for the for the heat equation. But for the for dimension one, we obtained. For dimension one, we obtain something different than the heat equation. And the sketch of the proof is basically almost the same, but simpler, because remember our G now has compact four. And because of that, we don't really need to chop the integral respect to the compound Poisson part into two regions around the origin and outside the origin, because this is coming already with a compact support. So, more precisely, compact support so more precisely this this um uh uh this this uh this this term here in red is gonna be uh is gonna be uh zero so we we can neglect it and this is one of the terms which was actually quite quite painful to to work with for for the heat equation because it was using the smoothness property of gene so luckily in the case of the wave equation we we don't need to worry about this at all and the first term is treated And the first term is treated exactly as the heat equation. So, basically, existence of Cadillac modification using tools from Gekman and Skorohod. So, existence of processes which have Cadillac modification with values in arbitrary metric spaces. And we are looking at evaluations of increments, the moments of increments, things like that. So, the order of regularity comes from the third. comes from the third term and then the last one is just the drift. So that was everything. Thank you very much for your attention and I'll be here to take questions. Thank you very much, Luca. We have time for some questions. I have a question. Can I ask a question? Sure. Can I ask a question? Sure, just to my dog starting back. Yeah, go ahead. So, um, I have a question about um the relationship between the heat equation and the wave equation. So, correct me if I'm wrong, but I think you know, in the wave equation, you have a finite speed of propagation, right? So, that means you know, if you have a, you know, if you have a fixed time point t and a fixed spatial point x, the solution at The solution at that point will only depend on the noise that is in the light cone, no, the backwards light cone. Is that correct? Yes, yeah, yeah. So I'm wondering, you know, if that's true, then that would mean that, you know, for any TX, your noise is only on, you know, the noise that contributes to the solution at that point would only be on a bounded domain. So I'm wondering, you know, in that case, you can essentially pretend that there. You can essentially pretend that there are no big jumps, right? Because you're on a bounded domain. So, I'm wondering if you could, you know, because of that, use the arguments that you have used, I think, in your 2014 paper in order to show, for example, uniqueness. Yeah, I don't know. I have I have to. I don't know. I have to think about that. But that's an interesting question. Okay. Yeah, that argument was basically, so in this truncation procedure, this h of x was one. Yes. Yes. So that was simpler. But the problem was when I defined the tau n, if I remember correctly, there was a problem with this definition. Problem with this definition. I will have to look at that paper again. Okay, thank you. So I have a question. Yes. That is a little bit related to what Kirsten just said and probably stupid for all of you that are doing theory of SPD. But I would be interested to know if there is something some results for waiving. For wave equation or heat equation on a compact spatial domain with, for example, homogeneous direction variation or something like this. Is it something trivial that can be extended from what Kersen and Jura Luca did, or is it more difficult? I haven't seen work on something like that, and I haven't worked myself with equation on bounded domain. With the equation on bounded domain, so I think it's an interesting question. The form of the fundamental solution will be different. So that means we will need different tools, of course. This is the stuff that we will need if we do numerics on SPDs. Of course, I only worked on unbounded domains. I mean, and if nobody has another question, maybe I can ask a question too, another question. Uh, another question. I think we have time for one question. Marta is also a question. Okay, then, Marta. Okay, well, it doesn't matter. So, my question is just technical. So, if you go to slide number 30, so yeah, yeah, so you have on the bottom this estimate on the LP moment. Moment. So is this independent of n or what? I mean, should depend on whether sigma is bounded or not? Because I think that this is essential in the procedure to pass to the limit when you prove the existence of a solution, don't you? you so i so the the the the function sigma is is fixed here so the the constant uh that appears here in this estimate will depend on sigma um okay and but uh does it depend on n i think it depends on n too yes yeah but then you should you should know how it depends isn't it yeah let me Actually, I don't know if you have so you have a paper in archive? Yes, that's what I'm looking at. I will check. I will check. Don't worry, Laroca. Okay. Yeah. Okay. David, a very short last question or somebody else? Everyone is there. Yeah, I was wondering, I had some memories, but I might be wrong about Marta and Juice working on the wave equation on bounded domains. Am I wrong? Wrong, yeah, yeah. Well, in principle, I don't think that it should be more difficult. So, it's different because the green function or the green function is different, of course. But on the other hand, there are nice expressions in terms of series and so shouldn't, I mean, should be different, but I don't think that it would be essentially much more difficult than the case. Than the case on the whole space. Yeah. This is my feeling. Yeah, that's it. Thank you. Okay, then let's thank Raluca once more.