Giving me the opportunity to talk. So, I'll be talking about some joint work with Sharath Branpur. Sharath was my PhD student at Waterloo and now he's a postdoc at London School of Economics. So, I want to maybe, I guess, propose this sort of set of problems that I'm sort of calling under the umbrella name of stochastic minimum norm nominator optimology. So I'll primarily be talking about some results of the FOX Kenny Trinity papers. Results from the Fox community community papers with the Carnap's theme of not so resemble. Okay, so I want to start by collecting some features of optimization problems under uncertainty, some common features. So I have some problem where there are some underlying costs that are given by random variables, and I'm going to posit that we only take decisions using given only the distributions. Given only the distributions. So, this is usually called a non-adaptive setting or sometimes the one-stage problem. Now, so once I fix a solution that induces a random cost vector, and I'm going to look at settings where this entries of this random cost vector are independent variables. And then I have some objective function f, and I want to minimize the expect which aggregates the entries of this cost vector, and I want to minimize the expected objective value. So, I mean, so I'm not saying that like every problem with uncertainty has a step rate, but many interesting problems do follow this approach. And I mean, of course, it would be nice to relax these assumptions. Like, it does make sense to also look at adaptive solutions and drop this independence assumption. But, I mean, non-adaptive solutions are kind of easier to implement. So, I mean, they are often looked at. So, let's sort of stick with this setting for some objectives. And what are sort of some objective functions that are often looked at? So there's the L infinity objective, which is I want to minimize the maximum entry. So that's sort of like maxpan. Or the L1 entry, which is the min sub problem. I mean, in the stochastic setting, that just reduces to a deterministic setting. But I mean, even in deterministic settings, L infinity and L1 are quite frequently studied. And so Dipanu was talking about case intervals like L infinity for the Like L infinity for the assignment cost, but and L1 would be K-me. And people then sort of realize that L1 and L infinity can skew solutions in different directions. So I mean we can look at LP0 as a means of interpolating these two issues. Now in stochastic minimum norm optimization, I'm going to change this last part and I'm going to say that f is an arbitrary monotone symmetric norm. So I won't define what norm is. Okay, so I won't define what norm is, but what is monotone? Monotone is what you would think it is: that if I, I mean, I'm only going to be looking at non-negative vectors. So, if I increase the vector entries, then the norm does not decrease. And symmetry means that the norm is invariant under permutation. So, this is the same kind of sort of setup that Nickel was mentioning in his problem. And subnotation that I'll often use is. Notation that I'll often use is that x with this down arrow means that the coordinates of x are sorted in decreasing order or non-increasing order. So let me talk about two concrete problems, right? And then I'll pause to see if people have questions. So one is load balancing. So we have unrelated machines and stochastic jobs. So the processing time of a job on a machine is a random variable. And the independence here is And the independence here is that different jobs are independent. If I look at these random variables across different jobs, they're independent. But I mean, for a given job, these could be arbitrarily correlated. So I mean, xij and xi prime j could even be the same. It could be an identical machine set. And now I have this monotone symmetric norm. A solution is an assignment of jobs to machines. So that's what I'm denoting by sigma. And once I do that, I get this machine load vector. I get this machine load vector. So, here the load is just the sum of the job processing times. And that's this quantity here. And I want to minimize the expected norm of this load. Let me talk about another problem, sort of maybe probably the most fundamental network design problem. Let's look at spanning tree, but where the edge costs are random ranges. So now I have So now I have again a modotone symmetric knob. My solution is a spanning tree. Once I do that, once I fix the solution, I get this cost vector which is composed of the cost of the edges in my spanning tree. And I want to minimize the expected norm. Any questions? If you're thinking about how the norm is specified, just think of it as a specified value value or Okay, so now, I mean, a bit of sort of motivation for why we're looking at monotone symmetric norms. Right, so one is, I mean, sort of an obvious motivation that, I mean, they are a very broad class of objectives, right? So they capture L P norms, but they also capture a very sort of nice class of norms called toppel norms, which Nicola was also mentioning. So the topple norm of a vector is just the sum of the L largest quantities. Of a vector, it was just the sum of the L largest coordinates. In absolute value, but again, all our vectors that I'm talking about are non-negative vectors. So these turn out to be quite sort of nice. I mean, they, as we'll see, they kind of form a fundamental building block of all monotone symmetric nodes. And another thing to note here is that, well, so as I said, LP nodes are often used to interpolate between like this min-sum and min-max. And you can do that using top L as well. Top1 is just the max. As well. Top 1 is just the max, and top n, wherein n is the number of colours, is the sum. So it's a sort of a polyhedral way of interpreting G extremes. So then the hope is, I mean, so this is a sort of versatile model. The hope is that by studying this at this level of generality, maybe we can get a sort of unified way of tackling norms. So that's one motivation. The other is that, well, so this class of monotone symmetric norms is close. This class of monotone symmetric norms is closed under two prominent closure operations. I mean, taking a non-negative combination of them still gives you a monotone symmetric norms. Taking the max of a bunch of them still gives you a monotone symmetric norm. And this actually gives you some surprising amount of modeling power. So here's an example I want to mention. So suppose my problem had actually multiple budget constraints where I sort of gave you a bunch of norms. I sort of gave you a bunch of norms, monotone symmetric norms. So norm always means monotone symmetric in this way. And I wanted to sort of find a solution that satisfies all of these budget constraints. So it looks like a harder problem, but it actually isn't because I can, I mean, that constraint is the same as saying that this quantity is at most 1. And now I can think of this as another norm. That's a monotone symmetric norm. So minimizing G or just deciding, I mean. Or just deciding, I mean, finding a solution where g is at most 1 is the same, falls into this minimum norm frame. So the point here is that you can use this setup to actually capture multiple budget constraints. And that can be quite useful, especially in a stochastic setting, right? Because you can sort of imagine having constraints over the top one, the top two. Two, I mean, and so you kind of get a very fine-frame control over your cost metal. So that's a useful thing. And it turns out that for handling Poisson distributions, this is actually a very crucial property that's exploited. Okay, so let me pause here and talk about sort of some difficulties. I mean, three sources of difficulty, identify three sources of difficulty in this class problem. So, one is, of course, there's This class problem. So, one is, of course, there's this underlying corporate hole optimization problem. So, load balancing you would expect is more harder than spanning tree. Then, there's this distribution. I mean, so maybe there are more structured distributions that may be easier. And then, I mean, there's this other sort of wild thing that, I mean, how do I reason about an arbitrary monotone symmetric norm? I mean, it doesn't necessarily have an analytical flavor. Like, how do I think about what's a handle on monotone symmetric norms? Special problems. And so here is what we do. So we give a framework for tackling problems in this setup, and that has kind of maybe two components. So there's some sort of problem-independent components, which are going to talk about how to look at monotone-symmetric dorms. So, and this is something that we show is the following. So, you can actually work with simpler norms, just top. Work with simpler norms, just top L norms. If you wanted to control the expected F norm, then it's enough to look at the expected top L norms. And we don't need to do it for all L, it's just powers of L. What I mean by control is, or what I don't mean by control, is that I don't mean that when I say controlling all expected top-normals, I don't mean that find the solution that's simultaneously near optimal with respect to all of them. In your optimal with respect to all of them. What I mean here is that if I give you a norm like this, you can sort of come up with some budgets for your expected top L norms, and it's enough to sort of satisfy those budgets for these expected top L norms. So in that sense, the norm now has become simpler. I mean, top L is a very precisely defined norm. And then the second thing is we have ways of handling the expected top L norm. So top L, even top 1, it's not so easy, right? I mean, it's the It's not so easy, right? I mean, it's the expected max, which is not a separable thing. So, I mean, so that's the sort of the second component. There are ways of dealing with expected topple loss. And then using this, and now, I mean, one has to look at the specific problem, using this and other sort of problem-specific ideas, one can get approximation algorithms for stochastic minimum load balancing and span routing. And spanning tree. So, elaborating a bit, so here are these sort of approximation guarantees that we get. For the spanning tree, we get a constant approximation. For load balancing, we have, I mean, less of an understanding. The most general setting where you have an arbitrary norm and arbitrary distribution, we can get this log-log factor of it. Factor of it. If I specialize the norm to top L norms, then one can get a constant. If I specialize the distribution to weighted Bernoulli random variables, then again one can get a constant. And for, I mean, okay, so you can ask, all right, what about identical machines? And we did ask that question. We don't really have better guarantees in this setting, but the algorithms become simpler, also the guarantees. Algorithms become simpler, also, the guarantees become a bit more general. Here we do get actually a solution that is simultaneously good with respect to all normal spectral problems. And I should say, so the reason we looked at Bernoulli is because often in a lot of these stochastic problems, there is a, I mean, somehow the Bernoulli case is kind of a tricky case to understand. So just, sorry, and for Poissar distribution, Sorry, and for Poissar distributions, one can get much better approximations. And these actually go through a completely different route by reducing it to a deterministic problem. And here, it is crucial that we are exploiting this sort of modeling power of multiple spectral norms that, I mean, in particular, these closure problems. And sort of a quick shout out to previous work. I mean, so, like, the MakeSpan case was considered and recently a constant factor. I mean, relatively recently. Constant factor. I mean, relatively recently, a constant factor was given for unrelated machines. But Kleinberg, Rabani, and Tarosh, I mean, they actually, I think, initiated this line of birth. They looked at identical machines. And there, actually, they showed that the general setting reduces to the weighted pernoli setting. So that was our motivation for looking at weighted per lolli. And I mean, so it was great that we could get a constant, but then we got stuck and we could only prove this sort of log-log metric for log for the general setup. For the general second, it could be a console, it could be a console, yeah. So, yeah, that's a open problem. So, for spanish, is that NP hard? Like for some description, there's like 80s hard, like anything I don't know. Yeah, I don't know the the deterministic problem is polytime solvable from just a Only time solvable. Just a little spine should do it. Yes, I don't know. Just a gasting solvable. Okay, so I want to talk about, I mean, maybe in the rest about 10 minutes, I want to talk about sort of the setting, the problem-independent portion of the contribution. So, like, how do we deal with a motor-concentric norm? And maybe I'll say after that a little bit about, I think, the stochastic spanning tree case. I think the stochastic spanning trick case, and I won't really have time to go into the load balancing. Alright, so let's think about how to reason about a monotone symmetric norm. And so one other piece of notation, so one kind of norm that will be useful is a non-negative combination of topple logs, and that we call an ordered norm. So you can equivalently think of it as there's a decreasing weight vector, and you're looking at the sum of WL, I mean the dot product of W with the X sort. product of w with the x sorted vector so w1 times the largest coordinate and so on so one thing that I guess that definitely influenced my way of thinking is that so in in previous work with Deepana we were looking at the deterministic setting where so yeah the same setup but there's no underlying randomness and there we we had this structural result that if I give you an arbitrary monotone symmetric norm you can always write it as the map You can always write it as a match of a collection of ordered norms. And with some small loss, you can make this polynomial size, but that's not so important for what we are saying. So one way of thinking about this is that, well, as I said, you can take monodone symmetric norms, do arbitrary non-negative combinations and maxes, and you'll still get a monodone symmetric norm. But what this is saying is that you only need to take non-negative combinations once and then max once, right? And that is enough to capture all monotone symmetric norms. All monotonous products. If you think about like L2 norm, L2 norm of x is just like the max overall dot product of unit vectors. So that's maybe a good intuition here. Okay, so this structural theorem, I mean, was proved using elementary means there. But what one can infer from this is then the following result that if I wanted to sort of compare, get something which is good with respect to the norm of some other vector z, think of z as the. Other vector z, think of z as the optimal solution, then it's enough to be within alpha factor of all the top L norms. Because, I mean, this implies the statement here. And we don't actually need this characterization structural result to get this. I mean, you can also get this using Harry, Littlewood Polya, majorization theory. But this, at least, we use this to get this, to get here. And then, I mean, so in the deterministic setting, then you can imagine what's going to be our solution approach. What's going to be our solution approach? That we want to compare against the optimal solution. You can do some sort of guessing to guess these stop L norms for powers of 2 and then try to sort of come up with a solution that satisfies all of these. So this is, I mean, it's natural for this to be a starting point, that this gives us at least a way of thinking about an arbitrary monotonous symmetric problem. So now let's look at the stochastic setting. So here is my representation of the norm. So one can ask the following, right? So I mean, One can ask the following, right? So, I mean, this is my expected norm. What would be really nice is if I could interchange the max and the expectation, losing only a constant factor loss. But this seems like too much visual thinking, right? I mean, why should you be able to exchange the max and the expectation? Here's a, and that last term can be viewed as the norm of the expected sorted y vector. But here's an equivalent way of stating the same question. Stating the same question. So, what I just showed you is that in the deterministic setting, if the topple norm of y is at most the topple norm of z for all l, then the f norm is also at most the f norm of z. Now, I can ask the same question in the stochastic setting. If all my expected topple norms of y are bounded in terms of the expected topple norm of another random vector z, is it true that the expected f norm is within some constant factor of the expected f norm? Constant factor of the expected error. So this would be like a stochastic generalization of the majorizations here. And these two are actually the same questions. In fact, I mean, whatever constant you have here, you would get the same constant here and vice versa. And one of the main results of our paper is that yes, the answer to these two questions is yes. And the constant that we could get, well, in the archive version, we proved 28. We sort of already knew then that we could. We sort of already knew then that we could sort of improve this by a factor of roughly 2. Sharath in his PhD thesis used different techniques to get something which is about 7.7. And this leads me to sort of an open question that I wanted to mention, that we don't know what the best constant there is. So this is a sort of a nice, just a mathematical question, really kind of like an integrality gap kind of thing. I mean, there's no computational concerns here. I mean, this would. Concerns here. I mean, this would improve constant, would lead to improved guarantees. But I mean, this you can ask for, I mean, you can also ask this for a class of norms and a class of distributions. So I don't know, for instance, if I just had Bernoulli random variables, what's the constant? What I do know, and this is trivial, is that if f is a top L norm, then the constant is what? Because really the two sides are the same thing, right? I mean, this is the expected top L norm, and what is that quantity here? I'm summing up the Here, I'm summing up the sum of the L largest coordinates of the expected sorted vector. So, those are exactly the same thing: expected max plus expected second max. So, if I take a top L norm or an order norm, then the constant is one, but as long as I get into sort of maxes, the constant would. And I don't know maybe the best constant here is too. Okay, I mean, so there is a lower bound I can show. Sharath has. Show Sharath had a 1.21 lower bound. I mean, using some computational experiments, one can sort of push it up to like 1.33, but again, I mean, there's a fairly big gap between the lower and upper bounds. Okay, so let me try to give a sketch of this result here. So that's what I want to show. Let's start by thinking about just the f norm of y. So f is a symmetric function. A symmetric function. Since it's a symmetric function, I can look at this histogram, which is for each theta, I'm looking at the number of coordinates which are greater than theta. And if you think about it, because it's a symmetric function, that histogram is all the information that I need. Because using the histogram, I can find the largest entry, the second largest entry, and so on. And because it's a symmetric function, that's all I need to calculate my function. So that just depends on the histogram. So let's think about what would top L be? So let's think about what would top L be. So top L can be expressed as the following. Like you take a y-intercept of L and call the point where it intersects TL and the x-axis. That area under this curve, it's really a discrete area, but just think of it as area. That is actually the toppled law of y. And that's not so hard to see. Okay, so now I'm in the stochastic setting. So well, let's sort of pray that things work and let's look at the expected. That things work, and let's look at the expected histogram. And something analogous happens, something sort of quite nice. That again, if I look at sort of this L y intercept of L and now I look at the area under the red curve, the expected histogram curve, that turns out to be a good proxy for the expected top L dot. Here you lose roughly a factor of two. So, what this tells me is So, what this tells me is that since the expected histogram curve is determining all the expected top L norms, if I look at this quantity here, where I mean that's a norm applied to this vector, that just depends on the top L norms of this vector, which are just the expected top L norms. So, that right-hand side just depends on this red expected histogram. And now one can sort of think of a way forward. Think of a way forward, one can use Chernov to show that the probability that, so the green thing actually determines the norm of this random variable y. Using Chernov, one can argue that the probability that that green curve is too far from the red curve is suitably small. It's exponentially decaying in how far away you are. And once you have that, using just sort of simple integration, union bounds, you can argue that the expected fy. Expected Fy is close to this quarter. Are you using some assumption on Y like bounded moments or effective momentum? Yeah, this is for any Y that follows the product distribution. But maybe, let me just say here, so it could be that the expected max is infinity. Right? But in that case, sort of with a notational slide of hand, I mean, both sides will be infinity, and it's still true. But yeah, this is. It's still true. But yeah, this is completely general. As long as y follows a product distribution, that statement is true. It's no assumption of boundary problems. Yeah, so it's a, I mean, it's a, it kind of feels pretty powerful in some sense. Any other questions? Okay, so let me just quickly talk about stochastic spanning tree. So, right, so what all do we know from Uh right, so what all do we know from what we have inferred that it suffices if z star is the optimal cost vector from the optimal solution, for me to get something that's that's approximately a good solution, I just want to ensure that the expected top L norms are order of the expected top L norms of that star. From the proof that we just saw, basically I can look at these expected histogram curves and sort of this red area where I'm drawing this. I mean, where I'm drawing this, which is the thing that gives me the expected top L. Now, can be used as a proxy for expected top L. So I want to ensure that this red-blue area, which is coming from my solution, is order of the blue area, which is coming from the optimal solution. And now what one can think of doing is that I can kind of guess these tau star L's, I mean, which are coming from the optimal solution, and to ensure that this red area is close to. And to ensure that this red area is close to that, all I kind of really need to do is to ensure that this sort of y coordinate when I have, when I'm at tau star L is roughly L. That's what that's what this is saying. Sorry, that's what this is saying. That if I look at these tau star L's, the Y coordinate in my expected histogram curve should be roughly L. As long as I do that, you can, I mean, so that would kind of tell you that this red curve is keeping track of the blue curve. But there's one other thing one has to worry about is that the pole. One other thing one has to worry about is that the portion beyond task r1 should also be bummed. So, as long as I do these two things, I'm going to get a good solution. And now one can sort of write an LP that enforces these constraints and use iterative rounding. And that gives us a constant factor for stochastic minimum swarms. So, suppose each bar coordinate was normal zero one and I was looking at top one. I was looking at top one. So then you're seeing max of expectations with constant of expectation of max. After you take this, so there's a yeah you sort the expected vector there. But my f could just be a top one. Aren't you a zero? So if it's yeah yeah, so I mean sorry the the yeah but the ID normal zero one. So if it's a root log then, but expectation of max. No, so if this by, so if it's a topple thing, right, then this is this holds with equality because they're just saying the same thing. This is expected max, and that is also like max of the expected sorted vector. So that's the first point it did is exactly hold minus. But also, yeah, we need y non-negative, yeah, so okay, so yeah, so stochastic load. Yeah, so stochastic load balancing, I mean there's an additional complication which is that just so the issue there is that the components of the load vector, right, they're sums of random variables. And so having access to quantities like the expected number of the probability that this coordinate is larger than some theta, that's not an easy thing to do. So there one has to work harder to get a different kind of proxy for the expected top L or Top well, but one can, and it turns out that sort of this quantity here, which is looking at just the portion of the random variable that's above theta, for a suitable theta, that acts as a good proxy for the expected top L0. And then one can work with that proxy using ideas that sort of go back to Kleinberg, Ravani, and Kardos. You can, I mean, they define the notion of a deterministic effective size. Effective size and argued that in order to control this, this is roughly determined by the total effective size assigned to machine line. So, I mean, this gets a lot more technical and there are a lot more details which I'm not going into, but I'm happy to talk about it. Okay, so a summary and some open questions, some that I mentioned. So, yeah, we. So, yeah, we introduced the stochastic minimum norm optimization framework and give a framework for tackling these problems, which has these two sort of more problem-independent components, how to reason about expected norm and how to reason about expected top health. We looked at these two problems, load balancing and spanning trees, but I think these techniques should have broader applicability. And some open questions, so of course, like these two I've always. Of course, like these two I've already mentioned during the course of the talk, but let me again say that. So, from the approximation point, sort of maybe the most pressing question is: is there a constant for unrelated load balance? Or even for identical machines load balance. Again, I don't know anything better than that. In fact, I don't know anything better even if it's just an ordered log. So, a non-negative combination of topology. Probably that would be a first step to. And then there's this mathematical question: what's the This mathematical question is that what's the best constant that you can put there? That's a very, I think, appealing, enticing question. Also, I mean, you can ask this for different, as I said, I mean, you can also ask another kind of question is that, so we needed independence of the coordinates. Usually, when you have independence, things kind of carry over to negative correlation. We didn't quite manage to get there. didn't quite manage to get there. I mean, there is one portion that sort of really needed independence, but it could be an artifact for techniques. Of course, it makes sense to look at adaptive policies for the make span setting. There is work on that, recent work on that, but nothing is this sort of minimum set. And finally, a more open-ended thing is that, so in stochastic optimization, there is a setting that called the distributionally robust setting, which kind of addresses the The issue that, well, maybe we don't know the distribution exactly. So perhaps there's a collection of distributions, and I just know my true distribution is somewhere in there. And now I can ask about sort of minimizing the worst case expectations by previous collection of distributions. And that's all I have. Maybe a question? Good question. So, when you say the distributions are known, how are they specified? They are given to you. I mean, okay, so to answer your question, let's say there's... So what abstraction, what computational primitives do you need on the right? Okay, so for the spanning tree thing, we kind of need what's the probability that a random variable is above a threshold. So I guess for the spanning tree thing, I guess for this for the spanning tree thing, I mean, yeah, that's like really saying that we have all the distributions. For load balancing, basically you need to compute these effective size things. So anything that allows you to do that would be enough. Um you can say that's like It's not in size of expectations. You have to sort. That is important. Yeah, so that's my side. I mean, you can kind of handle it. Yeah, so you look at the vectors together. You can't just look at each plot itself. So but if you just kind of recognize things like spectrum. So but then we have to show them by statistics. So it's just like quite paramount. It's not anything. I'm not saying you're looking at this either. It's not really hard if this will be memorized. So then the problem is that it's going to deviate from if it goes at QL. It's like it's going to score it. And then you will take union number. It's like you consume one like this. Maybe like 1002 or something. Yeah, so okay, so there is. Okay, so there is some laws that's coming from equals or displaying. This is a proxy. That's the first part of the paper. That's the top level. I thought you said it's the same concept, top L and every year. Once you discretize, you lose a month. Correct. But so. Thank you. So topL, we don't lose anything in that state. But I mean, from this loop, right, we are working with this proxy. No, this is not exactly. So top L of a can be good as that's the first part of it. Right, so we are taking the expectation of this. Whether you put it in the These which are already on T. Okay, there are two things. L is varying, T is fixed. No, L is fixed. R is taking L is common. So liquidity is a little bit different. So it's the expected minute. If I interchange minimum of the expectation, I get L. Depending on the way you have to see what you are computing here is that you have to take T out. Correct. Because if I take T out and I look at the structure, T. When I look at the T that minimizes this, then it could exactly be the T for which this illustration. So that is a lot of the same. So the fact that you don't land something in there. And that completely don't introduce yourself. The problem is I don't know of a good algorithm, like so well on implementing the algorithm. I mean hope to God that it's possible that and use a cutting blade. And use a cutting, actually. Yeah, it's a nice thing. So we need to limit it. I mean people look at order statistics a lot but order statistics may usually assume it's IID every wire but also even even if that were not the case right that would give you I mean that would I still don't know how I would use that because I mean that would Use that because I mean that would tell you something about the expected top L because you could do expected match, second match, and so on. Right. But Uski Park, yeah, like I mean you added. Only tail bounce in the top L is something you can take in overall and those are the same. Yeah, yeah. So it's possible something else. I mean there are people who are statistics. Yeah, something else. But I thought, yeah, they always look at I. But who knows? Yeah, that is true. They do always look at I. I mean, there are people who are working. Yeah, there are people who are working their own lives in the first club. No, yeah, you may. I mean, so for instance, like there is this nice thing of four-pay, right? Like if you have different bernonis, you're like minimizing expectation, like you can assume that they all have the same sound. That's we know of it, but not many people know. You mean like that, I think I know what you're saying. E to the lambda square. If you look at the exponential or e to the lambda x, it doesn't matter what the. X doesn't matter what the bias of X is, you like 8 to the lambda square or whatever. No, maybe it's related, but like I'm just saying if you have like if you have independent Bernoulli's but different biases and you're minimizing some expectations of some functional lag, then you can assume like the worst cases when they have the same bias. So that's quite nice, right? Can you say this again? This sounds strong. So, if you look at Bernoulli red variants, so they're all 0p or something? No, they could be, yeah, the biases are different, like they're 0, 1, probability that it's 1. Yeah, like it's V P I and maybe you're interested in like summation X greater than T. Yeah. So if you know that the sum of the means Each one of them, you can pretend each of them is like the burst. And in some cases you have the sealant flow or yeah, so like this precise thing is like either 0, 1 or B. So I can imagine something like that like for ballones might be yeah we still use a couple of layers of ballonium praise like how they yeah we how precise yeah we are like remote right. Precise. Yeah, we got like road, right? I think you use that for like this generalized in some ways. Repeated together. Yeah, I saw that somewhere else, but then I'm not sure. Yeah, but I mean, yeah, he's this guy who's both. Oh no, he does not play, right? Oh no, no, no. So, what is the plan? So, I think that's a good question. So costs are random numbers. Yeah, it's a normal random spec. Yeah, you have to choose a spanning. I have to choose a spanning switch. Only the cost number occupation so it cannot end uh okay. Then you show up. So for this using your Uh