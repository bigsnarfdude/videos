It's already covered. I'll section off. Okay, our next speaker is War Lu Hao, Mathematical Models in Alzheimer's Diseases from Penn State. From Penn Stage, you have 20 minutes. 20 minutes, okay. I think it's Vassal, but it's okay. Okay, thanks for organizing your attention. And today, let me start with the mathematical model for disease. So, this is the kind of So, this is the kind of out of my I will first put a mathematical model based on all the clinical biomarkers for Alzheimer's disease. And then after that, I will use the clinical data to validate our model. And also, I will use the data to verify. So, here is a validation, the verification I will talk about later. So, the validation is we assume the model is correct and the verification is. Is correct and the verification is okay. Even we have lots of data, how you really learn a model through the pure data dream. People talk about machine learning AI is part of this. Okay, so after that, so I will talk about once you have this model, you can really do the personalized prediction for each subject or each patient. Then we talk about the optimal treatment for each patient. Okay, so let me start with Alzheimer's disease. Is Alzheimer's disease. So, this is Dr. Louis Alzheimer, and back to 1907. So, this is the first dementia patient. And I came to Dr. Louis Alzheimer, he just did a lot of tests for her, and some reading tests, and she can read, sometimes she cannot read, and sometimes she can remember her name, and after that, after a few seconds or a few minutes, she's forgotten. He just cheese off God. And at that moment, there was no treatment at all. And after, I think, five years, it died. So then, Dr. Louis was heimer to look at what happens in his brain. So this is use the microscopy, then draw on the paper. So you can see there are two key features. One is the plaque over here. So the other one is the tangles over here. So this is actually two key features for Alzheimer's disease. Features for Alzheimer's disease so far is called amyloid beta plaque and the tall fabulous tangles. Okay, so then people just named this disease after him. So this is called Alzheimer's disease. And back to the starting first patient, you can see we have a lot of milestones for Alzheimer's disease. And in early two thousand, people can start to collect the data and also talk about the treatment. And also talk about treatment. So then, what's the Alzheimer's disease? Actually, if you look at a cognitive function, so this is the life spine over here. So this is the cognitive function. You have two trajectory. One is normal people. One is Alzheimer's disease. So you can see for the normal people, which is yellow curve, you can see once we're getting older and older, we still have a cognitive decline. But as Heimer's disease is starting a little bit, Disease is starting a little bit earlier around age 60, but at the very beginning, you cannot really see the difference. So it's very hard to diagnose the Alzheimer's disease in early stage. But once you get diagnosed, you can see the cognitive function change dramatically. So you change, eventually, you don't have cognitive function at all. Okay. If you look at the brain, actually, this is the normal people. Actually, this is the normal people, you have luffy brain, then you have AD, is the kind of joy. So, if you look at the cross-section of the brain, so the Alzheimer's disease started the first memory area, so that means the first you cannot forgot this and forgot that. So, then after that, people start to tackle your language area, so you have a hard time to speak after that. To speak after that, it destroys the whole brain. So, this is how the Alzheimer's disease progresses. And this is one idea. So, this is an artist diagnosed by Alzheimer's disease in 1995. So, then he decided, okay, let me draw a self-portrait every year and see how my cognitive function. So, this is a very early stage. So, this is one year after last time. One year after last time, is this diagnosed? So then, after a few years, you can see even you cannot tell what he is doing. So, this is one of them you can see how they affect people's cognitive function. So, from the clinical point of view, so what we what the biomarker we have, we have three of them. I mean, beta, top protein, and the neuron degeneration. So, you have different resources, you have CSR fluid, you can have. You have CSR fluid, you can have C from the plasma, and the imaging data. So this is the imaging data is less accurate when it can reflect everything in your brain. So this is the kind of golden biomarker people talk about. Okay, so then how you have all the pyramids is actually eventually, because we know the cognitive function eventually is based on the neural network, right? So this is actually everything is. So, this is actually everything that affected your neuron. So, you have two of the key features: one is the amyloid plaque. So, if you look at amyloid plaque, actually there is APP, so this is a very long protein. And you have one of them is called the BSE1. So, actually, when you have iminoid beta cascade is over here, so actually, you can cut, right? So, eventually, you can have. Right, so eventually you can have this one is a beta immunodefoot, eventually you can resolve in your brain. But sometimes, if you have a genetic issue, most of it is called APOE4, and you cannot clear the amyloid beta plaque, and eventually it will come together, so you have the plaque formation. So, this is the outside of the neuron. So, another one is the inside of the neuron is called the tau protein. So, you have, so, from one neuron. So you have so from one neuron to another neuron, actually you go through this microtubule. So how you assemble the microtubule actually is through this top routine. You can make it well organized. But if you have any gene expression, it's also the genetic issue. What's the problem is actually we don't know. So you have this corporation for relation and eventually you have the disorganized. Eventually, this is the one neuron disorganized. This is the one neuron disconnecting the other neuron. So, this is the torture blood retempor. Okay, so clinically speaking, so there is a whole area is called the amyloid beta cascade hypothesis. You start with the amyloid beta, then you activate the top protein. And once you have top protein, you cause the neuron degeneration. And eventually, you have neuron degeneration, then you have cognitive decline. You have coordinating decline. So, this is the people think from the amyloid beta eventually go one by one. So, this is called the amyloid beta classic hypothesis. So, first we built a mathematical model based on this hypothesis. The first one is quite simple. So, we use a logistic growth model. So, you have amyloid beta over here. So, then once you have amyloid beta, then you can produce stimulate the top. Stimulate the top routine. So, once you have top protein, you still follow the logistic rules. So, eventually, once you have top rotin, then you have neuron degeneration. And the last part is neuron degeneration eventually caused coordinative decline. C is for coordinative decline, A is a neuron degeneration. So, then we draw this picture theoretically. You can see, so it's really follow, you can have the aminoid beta, then you can. Have the amino aceta, then you get the type tau, you have neuron degeneration eventually. This is the area I tell you what's the cognitive decline. But if you tweak the parameter, you can sometimes you can find is the top routine you can detect first, then you follow the amyloid beta, and then you still have this other part. So this is the four of them is early on-site, another one is the later on-site, top first amyloid of primary species. But this is very theoretical, you get the primary. Very theoretical, you got the parameter estimation, then you can solve. So, the whole point is: can you use this model to really do the personalized model? So, that means for different patients, can we learn the different models? So, here we assume the other model is the same. If you have personalized models, that means you have different parameters. This is just a very simple model, it's only an ODE model. So, we use the Model. So we use the data. So it's a hybrid of data. You have CSF data for amyloid beta and the top protein. Then you have MRI data for neural degeneration. So this is we use the hippocampus volume to calculate this MRI data. So the last one is for cognitive function. We use the ADS13, which is a score. So tell you if you have 0, you don't have cognitive function. If the above 85, you have not. If they are above 85, you have normal cognitive function. So, this is one of the we have each patient we have do have longitudinal data. You come to the see the patient doctor, then after that, we have six months, 12 months, 18 months. So, that's the longitudinal data for each patient. Okay, how do you do this? So, this is a kind of optimization problem. You have DXDT, you have any ODE model, right? So, this is the P equals. ODE model, right? So this is the P equals to be high-dimensional. So this is the axis for all the state variables in my model. How do we do this? We can use the data just to see what's the out to minimization find the P. But this P we have 16 parameters, but even such a low-dimensional parameter space actually is very complex, non-convex optimization. So if you randomly choose an initial guess, you probably start in a You probably stuck in a local minimizer. So, how do we do this? Since that's the amyloid beta cascade model, so we can just decouple the model. So, for instance, we can use the amyloid beta and data to fit the amyloid beta equation. You have three parameters. So, then after that, we use the uh fix the amygdala beta equation parameters, and then we can calibrate the equi uh parameter in tau equation by using tau data. By using taut. So then we can do eventually, then you do this equation by equation strategy, then you can solve the original optimization by using the coupled initial condition. So let me give you an idea why this works better. So this is if you do the equation by equation, you can fit all the data pretty well. But if you do a random initialization, you can, here we do a 100 initialization, find the best one, because it's highly non-conventional. Because it's a highly non-convex optimization, you could start in a local minimizer. Okay, so then we use this one. So, this is only one patient. You can see we use the first, you have five data points, use the first four to train our model, find the personalized parameter, use the last one to predict. You can see this pretty well. So, we train out for different groups, so different patients. You have cognitive. Patient. You have cognitive normal group, CN. You have AD group, this is a disease group. So you have another one, it's between CNN and the AD. This is a transition group. It's called the mild cognitive impairment group. So we have, so I just listed three of them. Actually, we run 400 patients. So we have training data. So you have training error is pretty small. So this is the number of patients. Number of patients, this is the training area over here. So you can see most of them is smaller than 10%. And then we do the prediction for each of them. So you can see this is real data, predict data, so this is real data. So for each biomarker, you have pretty nice fit. So this is when you have a number of prediction, so this is the prediction error is also around 10%. And here is quite interesting. And here is quite interesting. So, when you increase the number of data points, so how about your prediction error? So, when I have this one data point, two data points, three data points, that means if you have one data point, that means you have one data point for each biomarker. You have one A vapor, one power, one, and one C. So, you can see when you increase the number of data points, actually, you can also decrease the prediction error over here. Okay, so also we can use this one to do the classification. You have three groups, same group, AD, and then CI. So actually you can look at through from the parameter space to the PCA, then you can find that they can really cluster together on this one. Okay, so this is a prediction. You do the validation based on model by using data. Okay, so the second one is, so because we have very simple So, because we have a very simple ODE model, so why you write on like this? So, for instance, if we have data, we assume it's a follow-up ODE model. So, how about we learn the right-hand side by using data? Suppose I don't know what's the model you have. So, how do we do this? So, eventually, you can write down the right-hand side in any function representation. So, your full instance, the file is kind of basis function. I just learned. Basis function, I just learned what's the coefficient. Or you can use a neural network because you have approximations property you can learn. Okay, so this one actually you can write everything the LASO optimization, you can learn the W, which is a coefficient. It's pretty trivial. But when you learn the data from the real data, it's quite challenging. Because, for instance, this is from the CA, you have MCA. From the C, you have MCI, eventually you go to AD. So this is how each biomarker you have A beta tau and C housing progress. But the challenge is you can write on the model over here. The challenge of the data is that you have different time scale. So for instance, you have S beta, S patient, you have this time scale, you start the disease at 50, right? Another patient, you start the disease at 60. You start the disease ICT, right? So you have really different time scale. So, how do you use the integrated other time scale to learn the data? So, this is the essential way you want to learn. So, that means you cannot really use the one time scale for all the patients. So, you should see, so we define our disease progression score. So, that means you have alpha i times t is the age plus beta i. So, that means beta i tell you when you start the disease, and alpha i tell you how. Disease, and the R5 how fast you get the disease. Okay, so this is quite interesting. So you can see if we each patient you follow the sigma, which is a sigma function. So then you have each patient, you have R5, T plus beta. So what does this mean? So actually, this is essentially one hidden layer neural network. So you have each of a neuron, that means the issuation. So then you have So then you have a personalized model over here. You can find the reach of the alpha and the beta i for each patient. But over here, so you have weight over here, then you can find the population. So in another word, so each patient, you have different time scale actually. This gives you a basis. So then after that, you just learn what's the WI over here. So we can extend this idea to our model. idea to our model so we introduce the disease progression score so then we need to learn the w and we need also learn the coefficient for each patient okay so so we can write on the optimization so essentially you have bilateral optimization you solve w over here for fix the alpha n beta i so after that you need update alpha and the beta i try fixing w. So this is a our flow chart. Overflow chart so you can have your disease, so you have some basis function, then you have data, so you have disease progression score, so then you can learn a cost of model. So once you have cost of model, you can do the personalized, you do the sensitivity analysis, find the personalized parameter, then you can do the personalized model for each patient. So after learning, you can really see, so this is the first logistic growth model is enough. You can only Model is enough, you can only learn the quadratic term, and also you also learn this amuloid beta cascade hypothesis. You have amyloid beta for the first equation, then when you have a beta, actually you trade the top routine, and eventually you have neuron degeneration, and then neuron degeneration cause causative decline. So this uh even you don't know what's the cause of model actually you can uh use the data to to address everything. Data to address everything. So, this is the, we look at the population level, so we can do the classification. You have CN, AD, in between the MCL. So, then you can do the personalized models over here. So, you can have five points, use four of them to train your model, you use the last one to predict. So, then we across the data set, so this is 400 patients, you can see it's a prediction. Patient, you can see the prediction accuracy for each patient is around the average, is 90%. Our cognitive functions are a little bit lower, but it's already compared to the traditional method, it's much higher, it's 10%. Two minutes. Two minutes. Okay, so then we just talk about a little bit about. So you can use this model to do the personalized optimal control. So you learn the personalized. So you learn the personalized dosing regimen for each patient. So this is the we have clinical trial data. So you have an anti-amyloid beta which is proved by FPA. So we just use our model is cascade. You start with amyloid beta, go to tau, go to neuron degeneration, then you eventually have cognitive impairment. So we filter the data by using what we have here. So then we give a control function. So this is essentially our So, this is essentially our optimization problem. We want to minimize the cognitive decline and we also want to minimize the side effect. So, you square. And so then, so I just skip all the details here. So, let me jump to the conclusion over here. So, actually, if you start the treatment earlier, you have used a high dose, you can improve the disease pretty well, 5%. 5%. But if you start lower later, so actually it's not much improved. So, okay, so let me stop here. So, here is based on ODE model, we use the data to calibrate the model, but more importantly, actually, if you don't know the model, you can use this approach to learn the model. And so, right now we are using imaging data, so we want to expand all the ODE learning to a PDE part. Into a PDF. So, okay, so let me stop here. So, this is my collaborator, some doctor from Duke, and my students. So, he's also spoken by LSA from the NIH. Thank you. Thanks for that very quick presentation. I have two quick questions. So, each patient has the same