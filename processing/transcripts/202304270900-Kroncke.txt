So let's begin our first talk of the morning session. So this morning we have Klaus Kroeker who will start off telling us about a new mass-like invariant for asymptotically hyperbolic manifolds. Thank you very much. And first of all, thanks to our organizers for inviting me. It's a pleasure to meet you. First time in band and a great time, a really great conference. Enjoy it very much. Thank you for that, for setting that up. Okay, yeah. Okay, yeah. So the work I will be talking about is something that is soon to be finished. It's not yet in the arcade, but we hope to do it soon. Let's see how soon, but the results are there. And it's based on joint colleagues, Matthias Dahl, KTH, also, KH Soffold, and C. McCormick just recently went to the University of Lulio, North Sweden. We all located in Sweden. Okay, so let me start by introducing the setups we're working on. By introducing the settings we're working on. Okay, so asymptotic hyperbolic manifolds, we had a couple of talks already on geometric settings, so you know already those definitions, but nevertheless repeat them. So you take a manifold that has an aeroconvention dimension n, plus one, and the boundary has dimension n minus one. And well, the interior is just called n. Yeah, and then we take a boundary defining function, meaning we take a positive or a non-negative function that vanishes exactly on the boundary and such that the differentials never vanish on the boundary defining function. And then what is conformally compact first? So we call a magic, a Riemann magic of M in the interior. We call it conformally compact. If there is a conformal factor, which is exactly rho to the minus 2. So G is rho to the minus 2 for smashing. So G is rho to the minus two for some magic H, which you can extend to the boundary. So it's kind of yeah, it's a magic on a manifold with boundary, a remote magic. And then you have some interesting equity also that's the conformal boundary, that's the conformal class of H restricted to the boundary. It's also given play broadly. Okay, so when you have such a manifold, then there is a standard computation that shows you that the sectional curves of them all copied magic. The fractional curvature of the compact metric G goes to the minus the differential of rho squared with respect to the metric H as rho tends to zero. So then it's just natural to say well we call g asymptotically hyperbolic if this differential respect to h is exactly one on the boundary because it will tell us all the sectional curvatures go to one as well. Okay, so far is good. So what about examples? So, what about examples? Yeah, I mean, there's the obvious example, because otherwise, you wouldn't call it asynthetic hyperbolic. So, of course, hyperbolic space is an example, as you've seen. So, in the Poincar√© disk model, we take just the unit ball, and the hyperbolic metric is then just the Arguer metric times the conformal factor. Again, this conformal factor is just the CC is a nice boundary defined function. The row would be one-half times one minus x squared. This fulfills all the properties. So, that's a very nice. Of properties. So that's a very nice function. And then, yeah, basically, the notion of compolic properties cooked up from that poppery ball model. So just also say there are many examples of isymptotic hyperbolic metrics with region curvature exactly equivalent minus A minus 1 D. Calculator constant, of course, from this extra curvature going to minus 1. So these metrics are called Hokorean symmetrics, and they're really pretty metrics. Symmetrics, and they're really many. Plenty. It seems like an infinite-dimensional family of Greek answers. There is this classical perturbation result by Li. So if you take this sun hyperbolic space, then conformal boundary is the, yeah, it's the induced magic from the clear magic, so it's just the conformal class of the round magic. Then there's a result saying for every perturbation of the performer class of the round magic, you get a compared. Magic, you get the Ponkerian symphonic, and this is also generalized to other situations. So, there are really many examples of Pokemon symmetrics around them. They play, as we also heard, already an important role in the ADS-CFT correspondence. Not going to talk about this so much, but maybe this will play a role also in that. I don't know. Yeah, anyway, so you have to see the role. Now, also, I pick up this function r, which is a small. function r which is just nice log of row it's sometimes nice to think in terms of this function because r you can think as a distance function to a center and interior fixed point so i will sometimes also use the function r just think of it as a radius function okay now um i will talk introduce the notion about asymptotic asymptote two asymptotic and hyperbolic metrics as asymptotic metrics as asymptotic to each other. So you take mg and m hat g hat, right? So two asymptotic hyperbolic metrics, and you should think of m hat g hat. We always think of that as a fixed reference metric and g will vary. And we call mg isyotic m hat g hat or at all if if if one are enclosed subsets k in m k hat in m hat and it Hat in the M hat, and a diffomorphism between the complements such that in this coordinate, so to speak, the difference of the two metrics will be in a certain suball space, a weighted suball space. Yeah? I'm sorry, the tau doesn't actually have a taunt as well. Oh, then delta should be the tau. Sorry. Sorry, what should be L? Delta. L. Sorry, that's an overlooked that. Yeah. Delta should be telling. Yeah. Yeah, that shouldn't help. Yeah, so there's a certain weight sub of space and just yeah. Since so it appears in the the bottom subgroup is the weighting, so the top subgroup is the number of rubins or what. Yeah, exactly. Yeah, and the weight gives exactly that. You have small volt equal to minus minus top. Okay, so the R should be on top. And you mean L2 smolder screen? Yeah, L2. L2 sub. Exactly. Exactly. Yeah. Exactly. So and of course e to the minus tau R. I don't know, why not dislike so many times that I didn't discover that mistake. Yeah, but anyway, you know what I'm gonna guess. And of course you want like, okay, so you want compatible radius functions or compatible boundary functions ago with something. So when we fix. Something so we have a fixed one and we have like a one that's converged to the other one with some rate that's called error and now we pick up falling quantities okay so mg is asymptotic to n at g hat and we say well we define first quantities which you should is the classical boundary integral for the admas so you take the divergence of push The divergence of pushforward metric G with respect to G hat, and then subtract the grain, the branch of the trace of G hat, the trace of phi star G with respect to G hat, and you integrate that over the sphere of radius R or radius eta. Generally, we say that we fix the radius eta. So that's one quantity. The other one is kind of the difference of volumes. So you regard So we regard, we look at everything that is the whole value, volume that is contained in the addable in G, and you subtract the volume of the addable of G hat. So this is kind of a renormalized volume. Okay? So you take those and this ADM, final return, and then you get some interior interface. And this depends. At first, the turn is somewhere at that. And you should think of eta as being some kind of large rate is close to infinity. You have both of these concepts measured one metric relative to the other metric somehow. They're relative. Sorry, can I repeat that question? Both of these concepts are measuring one of the metrics relative to the other one. Yeah, but it's kind of anti-symmetric both if you want. Yeah, but yeah, exactly. It's measuring G with respect to G. Yeah, etc. And then, yeah, you could have the Yeah, you cook up this kind of linear combination, which seems to be off at first place. So you take this ADN boundary integral, you add 2 times n minus 1 times this Riemannized volume, and now you let this quantity go to infinity. And as we call, we didn't find any better definition, but I think this name is alright. It's the volume Riemannized mass, because think of the boundary integral as the ADM mass, but now you add this volume Riemannized curve. Okay, and now I will try to convince you that this linear combination is particularly interesting. Okay, so why is it interesting? Yes? I said at the beginning, n is the dimension of the interior. And n minus 1 is the dimension of the bundle. Okay. So, now wider quantity. Well, Um, well, there's maybe a first argument gives rise to renormalized Eisenstein-Hilbert action. So, okay, so now you demand a little bit more for your reference metric. And it would be kind of natural to take as a reference metric a concrete answer metric, but we don't need to do that. So, we so the minimal assumptions we want of the reference metric is that okay, another mistake, it's nothing, oh, yeah, no, it is right. So, the trick. Oh yeah, no, it's is right. So the tracery part of the rich intensor. Tracery part of the rich intensive should be del two. And the scalar code of t hat plus n minus one, okay, that is a topic, it should be n minus one times n. That's the scalar code, that's the constant it converges to. That should be in one. And then you want the tau, this as to rate to be at least n minus one over two. And then if you have that, you take the integral of square. Of scalar curvature is kind of the total scalar curve plus this natural constant you add to n times m minus one. So, of course, this integral converges to zero, the integral converges to zero. And then you add this edn term, exactly to add eta, or you subtract that and you subtract also this Riemann loss volume. So, kind of you want to subtract the volume, Riemann lost mass we had before. And then And then, if you have this rate, this converges to a real number, just like a total scale group of G with respect to G at the eta goes to infinity. And this thing I would like to prove on a blackbird, because then you see some things, then you see why this definition makes sense. So let me do it here. Okay, so I can't see it online. Okay, so I should use another colour. Or is it another one? Is there another black one? Oh. Yeah. Right. Cost tall. I should use the black ones. This black one is not working. Anyway. Okay. Well. Well, that's just for simplicity. It's just the case where the two manifolds are the same if Morgan is the other. The important thing happens at affinity. It's only important if the Morgan for that. Okay, so what we do is, okay, we look at the integral. So it's the scalar curvature of G plus N times N minus 1. Minus one. This is, I can integrate that, but that's that's the integral. Then we also look at one part two times n minus one. Let's ignore the ADN term for the moment. Question? Okay. So now we're trying to get a data expansion for that. Okay, the third thing is. Okay, the first thing is let's replace g by g hat here. This constant is still the same. Of course, if you do that, you have to add some of the linearization of the scalar conference. This is given by the following. So you pick the divergence which you have. Convergence, divergence or page page page. H is just the difference between those two. So then there is ring or phrase. And then there's the rick chain. Okay, and right, so this is this thing is the generalization. This thing is the generalization of the scalar code term. HG applied to H. So this takes care of this term. Now there's also this one term and there you go as false. Well you have again this constant two minus one and I have one half. One half h. So this is the linearization of the volume then you take the volume error with respect to g hat and then you get something that is quadratic at h and yeah, that's so let's discuss So let's discuss all the terms. So this is an L1 by assumption. This here is the divergence term. And it gets just off by the added term if you do integration parts. It's exactly the kind of flux on the other side of the match. Okay, so now here we can summarize these two terms as follows. As follows. You get a trace view part of Ritchie here. There's a tracing part of Richie, so you get the scalar curvature out of it, and you have some comparative platform. And what you get is 1 minus n scalar curvature g hat plus n times m minus one trace that she gets. Okay, so this is in R1 because both are in L2, and this is also in L1. So all these terms are integrable. And there's a quadratic term. This is also integral exactly by the decay assumptions, by the tau assumption. So you can integrate everything and this gives you real number. And this gives you a real number. And maybe the interesting part is if you compare it to the asymptotic Euclidean setting, the asymptotic Eclipse setting would have the standard ADMS. And there you wouldn't have this term. So this gives you like affinity some constant, gives you like a multiple of dimension. And this is the reason why you have to add the randomized volume, because you have some somehow complicated additional term that appears in the linearization of the scalar code term. In the linearization of the scalar curvature. As the value of volume with the right constant compensates that additional terminal decrease in the linearization of scalar curvature. Questions? You seem to exactly have a question. Eric is trying to figure out if it's obvious if you extremize this now, do you get Poincar√© Einstein? You mean you actually extremize the mass? That combination. Yeah, yeah. We are talking about the first reaction of the big guys. I'm talking about the first duration of anything. I thought you might try it. Okay, so that converges to something SFC bunch. All the right terms, they add up in the right term, and that explains the choice of the constant here. Oops, there was something I wanted. Yeah, right. Then, of course, like if you have scalar codes of G plus the limit constant n times n minus 1 in L1, then also the renormalized volume. Then also the real number is volume. The volume renalized mass as a real number. So that works fine. And now, yeah. Next thing is the perspiration of this scalar curvature. And it gives you kind of the right thing. So it's kind of, okay, you get the typical gradient. It's minus riggy of g plus one times half. Scale capital of G plus G minus the constant, which turns out to be exactly. The constant, which turns out to be exactly the right one. It's like, and this is kind of this proposition, kind of, yeah, gives a hint here. You got analyzed the Hilbert action for asymptotic and hyperbolic manifolds. And I don't know, we went a little bit in the literature. It seems like people were looking for this for quite a while. I'm not completely sure, but yeah, this thing does the right job, it gives you the right answer, how to action. And this is a very good motivation for studying webinars specifically. Starting that math specific edit gives you the right normalization, the right boundary term you have to add infinity to get equideralization of that cycle functionality. Okay, so from this proposition you can also use a couple of things. First thing, dimension two. That's always a neat baby example. Dimension two, of course, see the gradient is always vanishing. So this is a constant function. Of course, dimension two, constant thing that's Two possible thing that's that's massive topology, and then it's kind of um so you cause the natural reference metrics and the harbor magic on the podcast 2 ball. And it's kind of a nice little exercise playing around with Gasponi to check what kind of constant you get, and the constant you get is four times the Euler characteristic of the one-point complication minus two. So you just kind of you have to subtract one Euler characteristic sphere. One other characteristic sphere. And I didn't do the calculation with multiple ends, but I think then you just subtract two times the number of ends and you get like one compactification at each end. So it's a neat little exercise in dimension two. One thing in higher dimensions, well the critical points exactly the Pokemon symmetrix, the right constants, minus m of 1. And minus n of 1. And what you also see from the variation, yeah, so if you apply this variation to a linear derivative of a magnet field that's in H1, so sufficient K, then this is zero. It's just because of the second behavior I did at the end. And that's kind of, yeah, you get some kind of diplomorphism variance with respect to particular diplomorphisms that are generated by. Morphoses that are generated by X1 benefits. It's not, at the moment, this part is not completely satisfying because it seems like you only get morphism variants in particular diplomorphisms. And we're trying to generalize this a bit and figure out some idea that it's not yet ready to be sent, but I figure out that you can be on some conditions you can get quite general bunch of different morphologies and learners. Sorry, what's particular? Sorry, what's particular? Well, of course, the mass should be coordinate invariant, right? I mean, the mass should be coordinate invariant. At the beginning, we chose a diffimorphism, and it's up here not clear that this mass is independent of the diffimorphism. We're just to identify this. But of course, you want that. And I think, yeah. So there are some technical details to be fixed, but under some conditions, we can figure out for very generative morphisms that this is. That's this is the best way to see it. Okay, this is first the dimorphism variance of the dyspot of scalar curvature, the answer Hill action, but of course if the scalar curvature was n n minus 1, this is L1, you also get the dimorphism variance of the volume reinvolts mass. Okay, so Okay, so so can I just check so sure so how does this depend on the background logic? Oh yeah, so a good point is to do this as well. So that's actually like the next remark that I think I was present on the next slide. So of course you have made a choice of background magic also. But the thing is like up to a constant it's independent of the choice of background magic because RMS is also additive. So if you like take So, if you like, take three metrics once, and then you have kind of an additive condition. It gives you kind of just a well-defined functional, well-defined up to a constant. But perhaps there's some canonical choice of reference matching at a choice option. It doesn't need to be. In many cases, it makes sense to put it as an isometric, but it's kind of we just don't need to do it. You could kind of say. You could kind of say, you start with an isometric, and you pick another metric that has like integrable scalar curvature and converges fast enough, then the amount of battery is defined, and you could as well pick that as a reference. And you shift like the whole mass function by exactly this difference. Okay, so this is the first remark, up to concepts, well, remarked. But of course, concurrently would be a natural choice. Funk reancy would be a natural choice. And also, this is a very important statement. So, for every component class of every boundary, there is a possibly incomplete concern symmetrical component boundary that was like recently established by ERSG. And this is also pointed. I mean, neither the reference metric nor the metric we're looking at need to be complete. Be complete. There can be some interior, it doesn't really matter. It's just kind of you don't, you only need the volume difference at the finish, so to speak, so it needs to be complete. There isn't a reason why it should be complete here. You don't need that. And it also means like for every performance boundary, you get local and monkey answer matching, still you get locally nice reference matching. You can just get that. Okay, yeah, this is also a nice thing to observe. So if you fix a false metric, you take a reference metric G hat and you get an element G0, then you get an expansion. Some of you may know this expansion of Poincar√© answers at the corner boundary. So if you have a Poincare answer, And so, if you have a Poincar√© anti matrix and you try to expand it, like the make a delta expansion of the boundary, there are a lot of coefficients that are already determined by the boundary. So, if G0 is some reference element in the cohorts of boundaries, it's a boundary metric, then in order to be concerned with Einstein, you need a couple of coefficients to be determined. G0, G1, G, a couple of them are already determined actually up to n minus 1. The n minus one is the first undetermined term. But a couple of them are determined. And because you want the rich intensity of the background, the g hat, ridge of g hat, you want it to be in L2. So it means it has to decay sufficiently fast to like a proper realising. It means like this number of coefficients is determined by the boundary. And then basically you can say you look at all that checks for following some confidence. We fix some formal boundary, we look at all metrics that have this asymptotic expansion at the boundary. For all of them, and look at all of them, you look at all of them that have like integer of a scalar culture, mix one of them as a reference matching, and then they compute the mass of all the other ones with that expansion to the given one. That's also an interesting observation you can make. So if both are comprehensive, so the background metric as well, the reference metric as well as the metric you're looking at, then actually if the two terms in the road volume remotes lastly compared separately. If you have two point rings with the same conformal boundary, then the difference will occur exactly of order n minus one. And this will be exactly caught by the ADA. And that's what they've exactly caught by the air they have integral. So this will be finite. And so the volume River's volume also. What you call ADM wouldn't be called ADM in the Poincar√©-Einstein setting, but isn't the mass always zero for a Poincar√©-Einstein metric? Which mass? No, you take two, you know? You take two. So, I mean, the hyperbolic mass, not the given. This has something to do with the hyperbolic masses. Is the real mass small in all of the? Is the v is the real mass volume always zero? No. No, but the uh the hyperbolic mass, the usual hyperbolic mass is always zero. That's right, but it requires a different decay. That's the problem. So it's not really related to the. I will say a few words about the hyperbolic mass, but it's it's it's not really related to that one, because you will see in a minute. Other questions? Well, okay. Can I just check? So you're assuming these metrics are conformably. So, you're assuming these metrics are conformally compact, right? Yes. In terms of expansion. So, but you don't have vanishing of odd coefficients because you're not necessarily. Oh, yeah, just didn't want to make it too complicated. Okay, yeah. I didn't want to distinguish between even odd dimensions. You have some coefficients, but I'm just not. Yeah, I'm just saying there are some coefficients, but some of them are like, yeah, that's right. Ah, so you are imposing that it's quote-unquote partially even that the odd coefficients. Yeah, I don't distinguish between even odd coefficients. One of some of Between even odd coefficients, one of some of them, right, but the odd coefficients at low order are actually zero. That's what you're assuming. Yeah, that the well, I don't need to do the assumption. Yeah, just something like zero not assuming. Yeah, just a couple of terms of the term. Didn't want to go too much in detail here. Okay. Okay, so then, of course, there are other masses also around, and oh, yeah, that's also an interesting comment. I also forgot. Like, if the order is faster than MS1, then the ADA intern vanishes, because it's not seen by the boundary integral. The module recovery is just a redemolish model. That has been studied by various authors, including people in the audience. So, it's kind of, if you want, also our Want also our ordinary mass mass as an extension of the realms falling to lower falloff. So just to kind of regard this little discussion also. Okay, yeah, comparison to other masses. Of course, there is to separate the ADM mass in the asymptotic eucliding setting. Where now you reference that is ecclining. You want the metric you're looking at to be paid. This difference wants to. This difference wants to take faster than up to n minus 2 over 2. And then it's kind of the ADAM mass, the classic ADAM mass. And it's defined because, well, if you look at the total scalar curvature, it's the right compensation term. And if you have that decay, this combination is less than infinity. So if you have integral scalar curvature, you get well-defined as ADMS lessons. So our kind of So, our kind of mass is kind of a generalization of this attempt. It's kind of copying the manifolds. And, of course, as you were mentioning, there is also another mass for asymptotic hyperbolic manifolds, specific one with hyperbolic match with the backbone. And then, if order bigger than n over 2, still need a bit more, not n minus 2, not n minus 1 over 2, but n over 2. And if the scalar culture times an exponential factor is n. times an exponential factor is an L1. Oh, scalar encouragement plus the constant should be. You know one. Then you have this mass factor as well defined. So that's something the mass is a vector. Why is that? Because you take the usual ADM integral, but you weight it with vector function. And this is coming from Minkowski space. So you think of your mobile space as sitting in Minkowski space and then you take the Minkowski vector and adjust the radar function. The radar function, the identity function, and it just restricted the hyperbolic space. That gives you the hyperbolic mass, the usual anthropolic mass vector, which is kind of not really related, it seems, to our mass. A similar kind of formula, but it requires in the case there is not really an immediate relation. And of course, there are many other masses around. I'm not really so much of an expert in that topic, but I figured this out. These are the two most important ones to compare with our best. Okay. Yeah, there's another nice feature of our mass. It has like, it set us for some kind of conformal positive mass here. Now we're working in a complete setting. You take a complete back of metric, it has cluster scalar culture, and you take a confolio class that has large scalar culture. And then the relative mass. And then the relative mass of g with respect to the whole background g hat is non-negative, and you have equality only if and only if g is g hat. This is a very nice property, and this is also something that it shares with the classical ADMS, because for the classical ADMS, for a squadron clear manifolds, you have that explicit formula. If you had the scale of that, and G is. G had the scalar flat, and G is my confident factor, and you can just explicitly compute the relative ADMS G now respect to the scalar flat background, and it's just this integral weighted with the conformal factor phi. So there you immediately see the sign of the mass. In our proof, it's a little bit more complicated. It's not super long, but you have to play around with the factor a bit, and in the end, you get some kind of funny polynomial. Funny polynomial, or not polynomial, I should say, about a rational function in the coupon factor, but yeah, it kind of works. So, this is another similarity chair with the classical ADM us in the exymptic equivalent setting. And what we also get as a byproduct of this, we get a positive class here for rotational symmetric metrics on the unit ball. So, if you take a rotational symmetric metric on the unit ball, Symmetric magic on a unit ball as large as scalar pointer, then you also have one negative mass and zero mass if normally if you have the backdrop. And there is just, well, up to dimorphism, those are conformal to the hyperbolic space. Just, yeah, you just need to cook up the right conformal factor by changing the R chord a bit. Yeah, so this is also a very nice thing. And I think now, okay, let's see, let's see. See, let's see. Okay, 12 minutes left. So I'm going to something that's more related to the richer flow, I think. Yeah, the expander entropy. So, okay, there is some kind of complicated quantity cooked up. Same assumptions for the background as before. And two 23 parts of Richie and integral of the scale culture. And you cook up a quantum for fixed backgrounds, you take a match G, you take a function f. You take a function f and you kick it with this quantity. You have the differential for f squared, scalar curvature, minus 2n minus f. Add weight with e to the minus f. You add a constant times the integral of e to the minus f and you add the volume of g hat up to that ball, and you subtract this ADM theorem. Okay, that's one. Okay, this is inspired by some entropy for complex manifolds. It's kind of For compact manifolds, it's kind of the first two terms are actually accepted at once as in a compact setting, and the last ones give you the right renormalization in a long setting. Anyway, if you just insert zero function, you will just get the total scalar curve we had before. And then, so this is like a functional handling of magic, an f, a function f, and you want to get rid of f by just taking the info. F by just taking the info. So take the functional part u, the x spanner entropy of g with respect to g hat, as this is the infinite over all those functions. And yeah, of course the question is you want a function that realizes infimum and possibly it should be unique. We have that. Under the same assumptions before. Under the same assumptions before, the same assumptions that produce this realm was unsilvented action, we also get a valid point action P, and there exists a function that is minimized. And we also have some Euder Lagrange equations. So this is the Euder Lagrange equation. 2 times the Laplacian F plus green F squared minus Galician plus minus N times N11, plus this constant 2 times N minus 1F. That should be equal to 0. And I should say, and this is important for. And I should say, and this is important for that: this is the Laplacian that produces positive eigenvalue. So it's minus the trace of the hash. And so you have a slightly non-linearity here, the grain F squared, but you have also have a cost in the C2 MS F. And this has the right sign. So it has the right sign, so it works very well. And then you can also, you can also, if you want, you can substitute, but it's omega here, but saying omega squared. Omega here, but saying omega squared, it's e to the minus f. Then you can rewrite the Euler Lagrange equation, and well, we get zero. And the way to solve that is by saying, well, I first do it in compact subsets. I take a compact exhaustion with a compact subsets. In minimizing procedure, very much better if you write in terms of all. Much better if you write in terms of omega because and then it's kind of pretty much of a standard argument and then you get solutions of omega and here it's this equation is also almost linear even were mild non-linear just the log non-linear subcode. So you solve that on compact balls and then of course you take a complex desire, you get the sequence of mini voices and this equation informs And this equation, the form of f will ensure that it converges to something because this is a very nice equation to be can apply the maximum principle. And it will give you balance on f independently of the radius. It's kind of just more or less dark consequence because take maximum minimum point where you zero, you'll catch one at the time, then you can just you immediately get the guns. So this is very nice thing. This is very nice thing. Yeah, and so it converts to something, so it exists as a newness. So that's completely super. Okay. The interesting thing is there were also other attempts to define entropy, for example, ALE manifolds. It's got a recent paper with Beriel and Mazo. We use the ADM mass in that set to construct an entropy in lambda. So there are various entropies around for richer flow if one of them. Around for rider flow is one of them. You can generalize this to the ADs, I think, but it's not always defined. Like if you have negative scale countries, it's a bit of a problem. The funny thing is, their problem is the default is non-linear on the omega level. For them, they don't have the log term. So, okay, linear, should be nice. But if you look there, this term is gone. So you can't apply Max principle. So although our equation is non-linear, as opposed to the linear equation, ours is kind of better. Linear equation, ours is kind of better, and so we always have for every estimate, but it doesn't need to be close to conquering answer. It's always the fun. So it's very nice. Why is this quantity interesting? Look at the first variation, and you will see the region tensor popping up, plus the hash of the minimizer, plus the constant times the metric. And then there's some classical observations. The critical points are exactly comparable. The critical points are exactly concerned with Einstein. Here you have the grain in depth. So it's a maximum principle argument to ensure if you have an equation for the grain, if the grain is vanishing, there's a maximum principle argument telling you then also the function is constant. So it's Einstein. So the period bonds are also Einstein. And you have strict monotonicity under the rigid flow, like the right rigid flow for concurrent Einstein. And it lies. And unless your flow is a constant flow, you have string monitors. So that's also very nice. And I guess also helps with the rich flow, understanding rich flow for asymptotic and hyperbolic metrics. There are no solids. No solids. Exactly. As I write here, all non-trail equilibriums. Exactly. Same argument as in a complex setting. And then, of course, if you want a reactant, you can compute the second moration. They get this last formula: second moration, direction of the tangent HH. Let's look at the second first. Using it's zero in the direction of different morphisms. That's a different morphism in the functional parts, so zero. For the formula directions, the divergence free ones, you get minus one over two times the integral of m of And it's integral of n of operator Laplace Equal to H, square root of H. What is Laplace E? I usually call it the Einstein operator. And it's the following here. It's almost the term we had in Christine's talk, apart from the Rich term. It's the maximum of plushian minus two times the Riemann term. And Riemann term is just, well, you take a certain contraction of R. So it's almost the lichener for plus. So it's almost deletion airflow question. Apart, up to a constant deletion airflow question. Okay, so that's second variation. And now as a final statement, you can see I have four minutes left. Final statement is there's a whole composite mass here. So you take, I call that G bar, I complete Ponti Einstein manifold, and the following are equivalent. So first, okay, now I take the entropy with respect to G hat, so take for G overline, so take G bar as the reference matching. Then we say, well, we have a local maximum of the entropy at G bar. So relative to entropy is zero, at g bar itself. So local maximum or equivalent, say the entropy is non-positive or linear at g bar. Positive for G near T bar. And secondly, and this is what I call a local positive must, for all g near t bar, you have integer version positive positions integrable and non-negative. Then the model Reynolds mass is non-negative and then if G is also Pocker Rein't. And so these two are equivalent. Local maximum of the entropy is equivalent to a local positive mass. And both assertions hold if G bar is linearly stable and integrable. And if you don't know this notion, linearly stable just means the operator we have before designs the operator is non-negative and integral means the space of critical points is a manifold, with touch space being exactly one of that operator. Space being exactly developed that operates. It's just a very natural assumption. Let's see, I don't have so much time left, so two minutes. Yeah, so maybe I don't do the proof then. Well, I mean, the fact that this linear stability and integrability implies one is not really surprising. The more interesting equivalence is the one between one and two, but they can really realize that. I think I don't have time to present. I think I don't have time to present the proof. But, well, essentially, maybe let's lose a word about it. You can use the manifold C. That's the one where the scalar curvature is equal to minus n times n minus one. You take the manifold of matches, it's called scalar curvature. Then, On that manifold, the mass is equivalent to minus of the entropy. You can compute that. And then essentially, you have to check what happens in performance variations. Because, yeah, this is everything up to performer classes. So this is just, say that, this is what you have to check. And I'm almost done with the talk. Let me just start mentioning some couple of open questions or conjectures. Couple of open questions or conjectures, rather. Yeah, I mean, this is the only question is: it's really, I mean, you can have a mass and hyperbolic space is a suitable back, but of course you want to deposit mass for hyperbolic space. And there are some ideas around, but it's kind of far from being understood. So I will raise as a question a conjecture that for hyperbolic space we should have a positive mass here with respect to a mass under under some conditions. Under some conditions, global, not only under nearest conditions. So alpha-model states, of course, satisfy the conditions of the theorem. And then, second question, is one equivalent to dynamic of stability and the rigid flow? And I would say yes. So it should be true, because we have a quantity of the rigid flow. So local maximality should be equivalent to dynamic stability. There are some things to be done. There are some things to be done. We didn't yet have time to look at them, but this should be true. I strongly believe this is true. And another third question that I thought is a little bit different. But then this is also very nice. Back to the second point. So you would have dynamical stability is equivalent to a local positive mass. It's also nice. And then what I was also wondering about is things like this local positive mass is due to non-linear stability of. To non-linear stability of the Lorentzi cone over the Pokery-Einstein metric. So, this metric in Lorentzi cone is rich-flat, double-hyperbolic, and you could ask about its bundle stability. And there are indications, I'm quite sure that should also be true. There are some indications that the local positive mass should apply to non-play the non-ministability. So it's kind of it seems to be a quite It seems to be a quite well-cooked mask for Pokerea Aster metrics and for also backer models cooked up for the Pokerea Aster matchup. And with that, I want to conclude and say thank you for your attention.