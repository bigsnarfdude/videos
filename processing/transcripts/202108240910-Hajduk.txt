Workshop happen. And also, actually, I want to thank Dimitri and Manuel for giving me the methods that I'm going to present in the first part of my talk. So actually, my work is mostly on discontinuous Galerkin methods, but I would like to review some of their recent. To review some of their recent contributions in the context of continuous finite elements before I move to what I did recently. So we want to have property preserving discretizations for hyperbolic conservation laws. So let's dive right in. We consider a general system of hyperbolic conservation laws where we have Laws where we have a vector of conserved quantities u and the divergence of a hyperbolic flux term. So this is in general a matrix of dimension m times d, where m is the number of conserved unknowns and d the space dimension. We then perform the standard steps to get a continuous Galurkin discretization. Skellerkin discretization for this equation. So we get a mass matrix term times a time derivative of nodal values. And for linearization of the first order term, we use the so-called group finite element approximation. So we have a sum of products of fj's, which are just evaluations of the Are just evaluations of the flux in the nodal states times the entries of a discrete gradient operator Cij. Right away, let's perform row-sum mass lumping to have a diagonal mass matrix instead of the consistent one and rewrite also the flux term in this flux form where we employ the row sum. Where we employ the rowsum, zero row sum property of the Cijs. And of course, this will be an unstable discretization. It might even blow up. So we need to do something else. Way to do this is to introduce a dissipative term, of course, which would look like this. So we have entries dij of entries dij of algebraic Blacks-Friedrichs or Rusanov method. Those are proportional to the wave speeds between Ui and Uj in the direction of the Cijs and also proportional to these in case of the off-diagonal entries of D. And to ensure conservation we set the diagonal entries such that also D has a zero row sum. Also, D has a zero row sum property. So you can show that in 1D on uniform meshes, this is equivalent to the finite volume Laz-Friedrich method. So this is a stable scheme. And the analysis by Jean-Luc and Pojan Popov, where they proposed to write the scheme in terms of Write the scheme in terms of these so-called bar states provides a very nice framework to write it to show the stability properties and also entropy inequalities in a general multi-D case, or also when the mesh is not uniform. So, this scheme, the semi-discrete scheme, has now sort of the structure of Has now sort of the structure of a diffusion equation, and you can then get a lot of nice properties just by using convexity arguments. So for instance, so the bottom line here is that if we plug in these spar states into this formula, this is just the same method as up here. And if you're solving a scalar conservation law, you have the boundedness of the You have the boundedness of these bar states between Ui and J. And in the general case, these are average solutions to Riemann problems between Ui and UJ in the direction of Cij. So, and using these analytical arguments, you can show the admissibility of these par states, which is a very nice form of the scheme. The problem is, of course, The scheme. The problem is, of course, that this is just the first-order method. So we need a high-resolution method. And what Dimitri proposed was to replace the low-order bar states by these limited ones. So here Fij star is a limited counterpart of an antidiffusive flux with which you can recover the original. Which you can recover the original Galurkin scheme. And the way to do limiting is basically to impose local bounds on each component of these bar states, uij bar star and uji bar star. And if you use these constraints, you get this nice formula how to obtain fij star from the unlimited ones. This is limiting. This is a limiting necessary to get numerical admissibility conditions. And if you think, for instance, about the Euler equations, where you also have other constraints such as non-negativity of pressure, you would need to use additional limiting to make sure that these constraints are also fulfilled. So this is So this is a way to do this is by multiplying all components of Fij star with the same correction factor that is defined such that these constraints hold. Such an condition can also be derived from entropy inequalities. So we have not only the system of conservation laws, we also have an entropy. We also have an entropy inequality. And just for simplicity, if we assume that boundary terms are not playing a role, then we have the condition that the global entropy is decreasing. And something like that would also be nice in the AFC scheme, where AFC stands for algebraic flux correction, which is what we Which is what we're doing here in Dortmund mostly. So we have these terms, dij, which I just introduced to have both the low-order flux and the limited flux in the same symbol. And now if we look at Tadmore's entropy condition for this scheme, this would read somewhat like this. Would read somewhat like this. Here we have the entropy variable vi, which is the derivative of the entropy evaluated at node ui. We have an entropy potential psi, which is given by this formula. And basically, we multiply again this fij star with a correction factor. The correction factor. And if we try to enforce this condition one, then we get formulas for how to choose this alpha ij. And by that, we enforce this condition if we use this alpha ij. And from this condition, we actually get the semi-discrete entropy inequality. Okay, then we discretize in time. Then we discretize in time, where I now put again everything in the original AFC form with fluxes, but I can also write it in terms of bar states, which are now limited to ensure local bounds and also physical constraints. So the low-order bar states are modified to include this Fij double star and then And then, as in the work by Jean-Luc Boyan, and also what Dimitri does, we have forward Euler updates, which then look like this. So provided that this term in parentheses is non-negative, the new solution is a convex combination of admissible states, and by that argument it is admissible. And we actually use this condition of non-negativity of this term to perform adaptive time-step control. This, of course, also carries over to higher-order SSP Runge-Kutta methods, which is what we use in most simulations. Okay, so if I could already sell you something, that's great. We don't need to do anything else. Well, maybe you're not. Well, maybe you're not yet convinced, or we also want to see if these ideas carry over to other schemes than continuous Galurkin methods. As I said, I want to use DG, specifically high-order DG methods. And we want to further develop the ideas that I've presented so far. And in the end, we would like to be able to have a framework. Able to have a framework for solving shock-dominated problems or problems that are locally or globally smooth, and also time-dependent problems, steady-state problems, kind of like a multi-purpose tool. And the outline of such a scheme would be to, as I told you, first do limiting for numerical admissibility conditions and And then you could check if you're satisfied with the accuracy. For instance, in smooth regions, you might actually want to use the original Galerkin approach. This part two is something that is to do for me. So I'm still presenting work in progress basically. But once you have that in your scheme, you would then Scheme, you would then take care of the physical constraints, non-negativity of pressure for Euler, or entropy inequalities, which would be kind of the final step in the scheme. So before I show you the methods that I've been working on, I would like to just point out a few differences to similar methods. Similar methods. So, in the case of discontinuous Galurkin, there are actually few algebraic approaches, I believe. And most would be geometric methods like slope limiters, which are quite popular in the DG community. But the algebraic methods that I at least Algebraic methods that I at least know about for DG are all of the family of flux-corrected transport methods. For instance, there's the paper by the group in Livermore where they are using high-order DG methods for advection or advection-based remap. Then we actually also have some experience with that. Also, we have some experience with that where we try to make these methods matrix-free. But I think the approach we presented in that paper is not really feasible for systems of equations. And a paper by Chanluc and co-authors, where they discuss discretization-independent limiting. Independent limiting is kind of well. So I should say that in this first paper mentioned here, they use algebraic methods for the whole DG system. Whereas what we do in this paper here is we treat flux terms stemming from DG methods and volume terms separately. And this is also what I'll be presenting. This is also what I'll be presenting later on. And to the best of my knowledge, Janook also treats the flux terms and volume terms like the same way, incorporates them in the discrete gradient. And then just briefly, I'd like to mention Will Pasner's work from Livermore, who's doing FCT for high-order DG spectral element methods. And so the idea of flexible. And so, the idea of flex corrected transport is a two-step approach where you first do a low-order predictor step. Based on that, you compute bounds for limiting and then you make a correction step to add anti-diffusive fluxes. And of course, the ideas of this go back to Boris and Book and. To Boris and Book, and of course, Salizak's work. So, we think that now it's maybe time to try something else. So, the monolithic limiter seems promising also for steady state problems. And with that, I would like to move now to the DG schemes that I've been working on. So, I indicate the elements of my triangulation. elements of my triangulation with k and then superscript e where e is the element number. I have capital E elements in total and I split the boundary of elements into vertices, edges, faces, depending on what dimension we're in. I use DG spaces of linear or multilinear or higher order elements depending on the geometry. The geometry. So simplices are linear, quadratic, and so on, whereas quadrilaterals, hexahedra are multi-variable polynomials. And I get a local discrete, sorry, a local weak formulation for my DG method, which looks like this. So I just do standard things on one element, integration by parts. Integration by parts, and since it's a discontinuous method, I need to use a numerical flux. The easiest one would probably be a local Lux-Friedrich scheme. But for the systems that we're solving, we're also using HLL. And we can use any Riemann solver we want here. If we want to go to high-order elements, Want to go to high-order elements? We cannot just use Lagrange basis functions because they can be negative between the nodes. So, if we enforce constraints on the coefficients of the finite element solution and we make sure these are positive, we still don't have control over the values between the nodes. So, the nice thing about these Bernstein polynomials is that they're between 0, 1. Between 0, 1, and they form a partition of unity and have some other nice properties. So, for instance, if your local solution on just one element looks like this, then you have these bound constraints for the local finite element solution, and you could use these element global bounds for limiting. So, as I said, I want to treat the volume terms. The volume terms and flux terms separately when it comes to the limiter, and the reason is that I want to apply this so-called sparsifier, which transfers the consistent mass matrix MCE on the element level into the lumped one. So, if I multiply the consistent mass matrix in the left-hand side with this PE, I get just a lumped one. I get just a lumped one. And actually, I want to apply this not just to the left-hand side, but also to the discrete gradient operator CE. And then I get some other CE tilde matrix. And how this looks like, I will show you on the next slide. But what we can already say is if we now do the Rusynov matrices in terms of these C tildes. In terms of these C tildes, I will definitely have the same sparsity pattern in D tilde as well as in C tilde. So here's an example for just a Q2 element. This is one element of your mesh. This is an example of how this one component of the C matrix can look like. And we see that this is a dense matrix. Matrix and for high-order elements, we see that this will be not really a feasible way to move forward because we just want very local coupling mechanisms between the elements. But this is not what we get if we apply the standard Rusenov dissipation. This is, of course, just as dense as the matrix was before. But for some reason, Some reason, this application of the sparsifier does just what its name suggests. Only the nearest neighbors in this matrix get contributions that are non-zero up to machine position. So you actually only have the desirable couplings in this C tilde matrix, and the same goes then, of course, And the same goes then, of course, for the detailed matrix. So you add less diffusion and only local diffusion. And you can exploit this in a limiter. Here's the case for the simplices. So there's a caveat here, which is that you should not invert these element matrices. Even though they are just element matrices, they're extremely ill-conditioned. The nice The nice thing, though, is that these are explicit formulas or codes that can help you compute for a given polynomial degree and element shape the values of these matrices. And I've put these two references here of how this can be done. Okay, now let's move on to the flux terms. So we have originally from the DG method some numerical. DG method, some numerical flux and an integral over the element boundaries. And what we do is we to get a bound preserving low order method, we replace this with a local Lux-Friedix scheme, but actually we just use one nodal value in each equation, but still from both sides of the element here. So, due to the use of Bernstein basis, we already have the nice property that in this case, only four nodal values from each side of the face or the edge contribute to the value of the solution. And what we do is we do something that can be interpreted as mass lamping for flux terms, which is for equation i, we just use the values of u r. Values of Ui, but from both sides of the edge. And if we do this, this is a locally conservative method, and the law-order method can now be written in this way. So we see that the structure of these two lines, these two rows here, is very similar in that this is the sum of fluxes for volume terms. For volume terms, and this is a sum of fluxes for phase terms. So we can actually define not just these low-order volumetric bar states, but also these phase bar states. And we can now write this low-order method in this way, which suggests that all we've done in the continuous Galurkin case carries over now. And indeed, it does. The forward Euler. It does the forward Euler discretization looks like this. So we have an update, which is a convex combination of admissible states. And well, provided the time step is small enough. But again, we can just set the time step as such. And this is then something that we can also carry over to the high-resolution scheme because. High resolution scheme because this so far has just been the lower method. So, first, we try to recover the original DG discretization and we add volumetric anti-diffuser fluxes. These look similar to the continuous Galurkin methods. And we also have interfacial fluxes. And if we compute how these have to look like, this is basically the difference. Basically, the difference of the low-order Riemann solver and the high-order one. And since these are fluxes, if I look at it from the other element, they are also anti-symmetric. So we again have conservation if we make sure that after limiting, these anti-symmetries hold and we can recover the standard. And we can recover the standard DG scheme if we don't do any limiting here. So, unsurprisingly, since the volume terms and the phase terms have the same structure in the equation, we can perform limiting in very similar manners. It's actually easier for the interfacial fluxes because we have unconditional symmetry of these low-order interfacial bar states, whereas it can happen that the It can happen that these low-order volumetric bar states are non-symmetric. And then finally, we have the bond-preserving discretization if we replace in the low-order scheme these low-order bar states with these limited ones. So, this is numerical admissibility. When it comes to solving systems of equations, there's one observation. There's one observation to be made, which is that you can either do these numerical admissibility conditions for the conserved unknowns, but maybe you want to have discrete maximum principles also for specific unknowns, such as the velocity instead of the momentum. So in a paper from 2010, In a paper from 2018, a so-called sequential limiting approach was proposed, where you first compute a limited update for the main unknown of the system, for instance density, and then use the information and exactly the amount of limiting that was necessary there to get approximations for the Get approximations for the specific unknowns, limited specific unknowns. So when we want to put this whole idea in the framework of bar states, you can define specific bar states. So this would be a bar state for velocity. If these are bar states for momentum, then you have to divide by bar states of Have to divide by bar states of density. And then you have an anti-diffuser flux for the conserved unknown, where you split from a contribution that corresponds to a, well, it's a discrete product rule, so to speak, where you already incorporate information of how much limiting was necessary for the primary unknown. You get sort of an anti-diffusive flux for. Sort of an anti-diffusive flux for the specific unknown, you do limiting, and then you add again this blue guy here to get finally the limited anti-diffusive flux that you can put in your scheme. And again, since this is all in terms of fluxes, it doesn't really matter if it's fluxes of volumetric type or interfacial type, you can just use the same ideas. The same ideas in the DG context. So, how do we define these bounds for numerical admissibility conditions? We basically just look at the nodal stencils of the closest neighbors. And in the DG case, we sometimes have these nodal values with multiple well. Well, coming from multiple elements. So if a node is located in more than one element in physical space, we actually take the min and max values for each such node. So if we interpolated these bounds, we would get a continuous function. And these can be used for limiting. Limiting all the arising fluxes for scalar problems, whereas for systems we need to do something else. So we should definitely incorporate all the bar states. So for the density or the primary unknown, we look at all the arising bar states and we make sure the bounds are again continuous. Again, continuous and for specific unknowns, well, maybe there's not one right solution to do it, but I'm incorporating all the bar states and the nodal values that are defined by the quotients of the nodal values of conserved unknown and primary unknown. And finally, the one thing that's The one thing that's still missing is the physical constraints. So, think of the Euler equations again. We have the constraint that the total energy is not exceeded by the kinetic energy, or in other words, that the pressure is non-negative. So we have so far no guarantee that the bar states, the limited bar states, satisfy this property. Satisfy this property, but by the analysis of the low-order method that I mentioned earlier, we know this actually for the low-order bar states. So again, the approach would be to assume we have a correction factor here and we plug this definition in the actual constraint, which is again that the total energy is. Again, that the total energy is not exceeded by the kinetic one, and we use some estimates to get formulas for alpha ij. And this would make sure that the pressure is non-negative. And very similar ideas actually come into play when it comes to using the entropy limiter. So, again, all of this that was originally proposed for continuous Galerkin methods. Galerkin methods naturally translate to the DG setting. So there's not much new to say here. And instead, I can now move on to showing you some numerical examples. So easiest, of course, is a constant coefficient of vection equation. So the Lux-Friedrichs method simplifies to just upwinding. Winding and what I'm showing here is advection with periodic boundaries of one step function and one smooth feature. And we see that the DG method, classical DG method, is not too bad. It just has some oscillations at the discontinuities, whereas the low order method is quite unreliable here. Quite unreliable here, and we get sufficient accuracy with the limiter. I should say that all of these approximations are solved with exactly the same number of unknowns. So when I increase the order here up to P23, for instance, I'm derefining the mesh actually. So since I've not yet Yet, run this example with the smoothness indicator. I see increased amounts of peak clipping effects here at the smooth feature, which I don't have in the DG solutions. So this is still something that I want to implement. And it's also reflected here if I compute the orders for a smooth profile, but at least I get second order or a little more than second order in all. And second order in all the cases. Here's a solid body rotation example. We've seen this a few times now, so I don't have to explain it. This is just to show that the method that I've presented so far for the standard conservation law system thereof also works if we have a non-constant coefficient velocity. And yeah. And yeah, we do get reasonable approximations here. We can also, as I said, apply the method to steady state problems. So here we have an inflow from the left side, also a smooth and discontinuous feature, where the standard DG method just produces some oscillations at the Some oscillations at the discontinuity. And with the limiter, we have the solution that is in balance and actually converges to a steady state residual up to machine precision. We solve nonlinear problems such as Berges equation for a smooth initial condition and we stop the simulation before a shock develops and Shock develops, and we do this just to test again the accuracy. We have a nice first-order slope for the low-order method, and at least second-order for the MCL scheme. Also, this is an isotropic extension of Berges equation to 2D. And again, we solve with the same number of total unknowns while we derefine them. While we derefine the mesh when we increase the polynomial order, so the first picture here is just DG0 on the finest mesh. Standard DGQ1 looks okay, but actually it's just because I've scaled all plots to the same value range. This has severe oscillations at the shocks. This is non-recommendable and This is non-recommendable, and higher-order methods don't even make it that far in terms of simulation time without blowing up. The Q1, MCLQ1 results, on the other hand, provides a solution that is in bounds and also the lowest error here. Since this is a shock-dominated example, I think the best results are found on a Found on a fine mesh using low-order methods. But actually, it's encouraging that we can also get a solution that looks reasonable if the shocks are not aligned with mesh edges like this Q15 result. Again, we can solve a steady-state problem for a non-linear flux, which is not. Non-linear flux, which is now the space-time Burgess example. So I'm just interpreting time as one spatial dimension. So here we have two plateaus moving at different speeds and they merge into a single shock. We have a reflection wave fan and all the methods I considered, even on an unstructured mesh, are converging to a steady state. Converging to a steady state, as in the case of the advection equation. Now, we don't have any guarantee yet that just the bound preserving limiter will produce a solution that is converging to the right solution, the right solution being the vanishing viscosity or entropy solution. And that's what we need Tadmor's entropy fix for. Entropy fix for. So standard DG, I would say, fails miserably for this problem, which is the KPP equation. We have severe over and undershoots, whereas just using the limiter will give us a bound preserving solution. But we have two shocks that are merged that should not be at the same location. At the same location, indeed, it should have this nice spiral structure, which we do get if we perform the entropy fix. Okay, of course, we want to solve systems of equations such as the shallow water equations. We have here one variable h being the total water height, v being velocity, and then we have a pressure term that looks like this. Term that looks like this, where g is gravitational constant. And we solve a 1D Riemann problem given by these states, which is a so-called wet dam break example. Since this is a discontinuous solution, we can only hope for something like first-order accuracy here. And this is what we get with both DGP1 and DG P1 and continuous Bellurkin P1. So you see the corresponding pictures here. And when you compare these, there's no clear preference which to use. However, if the total number of degrees of freedom is fixed, keep in mind that the DG result is obtained on a mesh that is one level coarser than the continuous Galerkin one. Continuous Galerkin one. And again, another thing we can do is we can use high-order DG methods. So all of these capture the analytical solution quite well, I would say. And so we demonstrated also the high-order capability for systems. Again, I would argue that for shock-dominated examples, the best method is probably a low-order method on a fine mesh. On a fine mesh. So that's why for this circular hydraulic jump example, I am using just P1 elements on an unstructured mesh. So this is a quadrant of a square where in the middle you have a circular shaped inflow and the rest is just wall boundaries. And what you see is at first the solution decreases and then to Decreases and then two shocks form. And again, without a limiter, this would be hard to obtain such results because you would get oscillations that can cause your code to crash. Also, the conversions to steady states is something that needs to be investigated. So, for this constricted channel flow, you have You have oblique shocks that form at the boundaries, and then there's a superposition of these plateaus, where the standard DG method features oscillations along the shocks, while the low-order result is just totally unacceptable in terms of smearing. And again, with the limiter, we not only get a crisp resolution, but we also get conversions. But we also get conversions to steady states, which is something that is not possible with classical FCT schemes. And here I'm comparing this to a slope-limited solution, which features a stagnation of the error with respect to steady state, because for some reason there are some waves forming along the Along the incline walls. Another system of interest is, of course, that of the Euler equations. We additionally now have an energy equation, and I've already written down the pressure term. This is a result for Salt Shock Tube with high-order methods. You get some smearing at the contact with high order, but High order, but overall you captured the profiles quite well, as you do also for this Woodward-Kolela blast wave. And yeah, the choice of Riemann solver is not that important for this example, actually. So I'm also trying to resolve vorticities, as in this double Mach reflection example. Uh, reflection example where again I'm solving with p1 and q1, and sorry, q1 and q3 with the same number of unknowns. Um, and I definitely would say the smoothness indicator is still necessary to capture these vorticities even better. But so, so far, the overall trend that you should observe is definitely visible. That's also the case for this 3D SATOF blast, where I'm comparing a result of mine with a purely Lagrangian simulation obtained with the code from Livermore. And again, the trend is visible, but I think the accuracy can still be improved. But of course, the performance of these two methods might not be. Might not be comparable in this sense because the Lagrangian one might be the best to just get these shocks well resolved. So the encouraging thing, and maybe like the point where I should stop, is that if I don't do any limiting and just use the pure DG method with an appropriate Riemann solver, I can, for smooth problems, get the optimal convergence rates, which is nice. Rates, which is nice. So, in the end, if I implement a smoothness indicator, the hope is that I can retain these. But as I said, it's work in progress. So, yeah, in the end, hopefully, we can have both nicely developed shocks and smooth solutions as well. Okay, so just to conclude my talk, I've presented the Presented the monolithic convex limiting ideas first for continuous Galurkian methods. And some of the nice features are that it's a parameter-free method. It can be implemented without any tolerances that you might have to tweak. You can get steady-state solutions. You can also apply it to unsteady problems. Problems and it's promising to also include entropy limiters to make sure that you converge to the right solution. And some of the results from the work on DG schemes is that it works very similar to the continuous Galurkin case because we do a distinction between volumetric fluxes and phase terms. Fluxes and phase terms, the latter of which actually the use of low-order interfacial fluxes does not decrease the overall accuracy actually. So it's really the volume terms that are the bad guys. And again, if there are shocks, I'm mostly happy with the lower order method P1, Q1, whereas for smooth regions, the use of higher orders on. The use of higher orders on coarser meshes might be promising. And I will just show you here some of the references without going through them. And I would just like to give a shout out to the group in Livermore. I've used their code Lagos to compare. I'm using MFM as my baseline finite element toolbox, and along with it is. Along with it is coming GLVIS, which is for visualization. So, thank you. And are there any questions? Well, thank you, Anes, for your very nice talk. So, yes, we can take questions for five minutes or so. Any questions from the audience? Please unmute yourself and just ask the question directly. If there are no questions, I have. If there are no questions, I have a few of a few questions for you. So.