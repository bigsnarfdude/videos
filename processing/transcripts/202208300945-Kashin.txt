Thanks, Sasha. I should say that I have heard 100 talks using Zoom, but it's my first experience to speak. So maybe some technical mistake could appear. Let me start with thanks to organizer to inviting me to OHAKA. I couldn't do it this time. I couldn't do it this time, but I was lucky to visit this place a few years ago. So it's really a pity that I cannot be with you. So also I'd like to say that next to me is Yuri Malikin. We work together in Steklov Institute. But I realized only recently he is a speaker also. So our talks are intersected somehow, but maybe it's not too. The not too bad because it helps to understand better. But let me start with the definition of Kalmagorowitz. And one of the main messages of my talk is this definition. Talk is this definition. It's maybe a little bit strange, but look here. If you take the initial Kolmogorov original Kolmogorov paper, the definition of widths was not related with norm, but rather with linear functional space. So it means that for and in the linear metric space, we can define this quantity. As usual, As usual, but it turns out that even this definition is closely related with discrete mathematics and computer science. Here it's another definition from computer science. Let Mn is a set of matrices with real elements that approximate epsilon rank. Epsilon rank is this quantity. So we approximate matrix by another matrix of small rank rank such way that the uniform distance element by element is less or equal to epsilon. And it's important quantity. And here is a piece of propaganda from people in computer science. In computer science, you can see that it's related with important objects in computer science. But if you consider the rows of matrix A and take a convex of this rows plus minus, then you can see that this epsilon rank of matrix is just Kalmogorov widths of the matrix. just Kalmagorov widths of this set V is union of rows and it turns out that people in computer science repeat many results about widths but they only recently they start mentioning the colonovaro widths and even now you can see many some paper Some paper without indication of this relation between rank and tomogorovitz. But finally, we found one interesting case which was not considered in function theory, in approximation theory about widths. And this case was considered first by computer science people. Computer science people, but the wits of skew octahedron. But let me explain what I mean. Let me start with the unsolved problem about ordinary Kalmogorov widths of functions of W11. So you can see it's a class of monotone functions on 0, 1 bounded by 1 and positive. It was done by Kulanian. It was my. Lanyon, it was my PhD student in 83. This to estimate, and here on the left-hand side, with Malikin and Ruthin, by the way, Ruthin also here, we just remove epsilon in this estimate. In initial paper by Kulani, it was log one-half minus epsilon. But you can see that it's only case when for inter. For integer smoothness, Sobolev plus when width is an unknown, and it's related with skew octahedron. And Canaval remarked that this width is in fact the width of proportional with some constant of Kolmogorov with Q octahedron. Here Q. Hedron here Qn is the convex of this set of vectors vi so it's i one and then zero and the case of uniform matrix so it means the width of of the set in L infinity was not considered in the function theory maybe because w was Maybe because w11 is not a compact in L infinity, it was no sense to have discretization. But independently of functional class, this is very interesting problem. For computer science, this case is important and equivalent to the estimate of epsilon rank of this matrix Qn tilde. You can see this matrix. And what they did. And what they did in computer science. But first, we start to consider the case of fixed epsilon less than one half, say epsilon equals one-third. It means that if you approximate with such an error, you can differ zero and one. And what was done there is this to estimate it is. The result looks strange. So, such a big matrix, we still can approximate non-trivially subspace of such a small dimension. And when we realize this, when we see this result, we it was paper by myself, Malikin and Ruthin. And we try to improve it and we worked hard, but without any success. So, we have several proof of lower and upper estimate for this one, but all of them gives log square n and log cube n. So, this problem about widths of skew octahedron is important and unsolved. But let me describe one approach to the low estimate is a definition of notion of automaticity. I introduced in 2002, and this is such a quantity. In some sense, it's approximation of some sequence Fj from our functional class. J from our functional class of from our set by orthonormal system. So this supremum is taken over all orthonormal system phi j. And this quantity is interesting, it's connected with the problem about convergence almost everywhere for orthogonal series and this. And this we can generalize it the problem to consider instead of this matrix Q this set of all parallel pipettes inside of unit cube and the result is that automassivity of this set is for the log n power d using this estimate we can generalize this This result about Kolmogorov, this result, relation one to multi-dimensional case, but still we have non-sharp estimate. And it's another result. It's not connected with widths now, but if we consider the set of indicator of convex subset, then automassivity already have a The orthomassivity already has a polynomial growth. And Grigoryev obtained the upper estimate with different order and remarked that almost the same estimate as the lower one could be obtained as a consequence of the positive solution of the following problem. The problem I decided to Say about this problem because I consider it interesting. So it's a problem about the estimate of maximal operator with respect to triangle partial sum. So it's related now with almost everywhere convergence of triangle partial sum or double orthonormal series. Okay, but let me return to weeds. Ah, okay, so. Ah, okay, so the notion of automassivity is related somehow with Lova's theta function. It's a very well-known object in graph theory, but I don't want to go into detail here. But another important example about the widths of skew octahedron is it's exactly from theoretical computer science. Computer science is the following. So we consider set of integers from 1 to n, and for each subset S, this F S of X1, Xn is a Boolean function of disjunction. So, or function. Here it's a definition. So instead of 0, 1, I consider minus 1, 1. Minus one, one and this function is minus one if and only if there is just there exist j such that xj is true. So the problem is to estimate and it's important for computer science this with of course it's subset of L infinity to power n and first problem is to estimate to To estimate, to find such a dimension when the estimate is non-trivial. Here, it was proved in computer science these two estimates. The low one you can see in paper by Clevens and Sherstow, but based on the very non-trivial result by Razborov. Will result by Rasborov. So it shows that the estimate of widths for skew of Tahedron could be different type. First one was logarithmical, now it's this type. Okay, in the connection with. Okay, in connection with this result, let me make a step away from my main topic. Ah, sorry, to explain what kind of set we need to, the width of what kind of set we need to estimate, let me reformulate this problem, this result. For any set S, we consider this function just. This function is just polynomial with respect to Walsh function, specific type of polynomial. And the problem is to estimate this width of this skew octahedron. And maybe it makes sense to consider a general problem because, in both examples, for In both examples, for the first one and second one with disjunction, we know the gram matrix of this octahedron, skew octahedron. And maybe using this information, you can give a general estimate of widths. So the problem is the following: we have a set of vectors with and the And suppose we know the gram matrix and how to estimate these widths in L2, of course, it's standard, but in L infinity, it's a very interesting problem. But now also I would like to make a step away and to make propaganda to another. To make propaganda to another problem, another problem about width. It's not connected with steel, not connected with computer science, but in some sense, I believe there are some connections. Okay, so what is it? The problem is the following. We have a non-linear operator, and we are interested to this Into this number. What is this number? We take arbitrary n-dimensional subspace in the space X. And consider the image of this set under the operator Psi and try to approximate by linear subspace. Subspace and for this two number n and m we have a quantity, this width, this supremo. And I consider, I introduced this table in 88 already, and I consider the simplest case when x and y are L2 on 0, 1, and psi is just operator of absolute value. And here, recently, I got some upper estimate. It's not difficult. And the proof is somehow standard. They use a polynomial subspace. And in my first paper, I also use the polynomial approximation, the polynomial with respect to subspace. I don't want. With respect to subspace, I don't want to go into details here. But what was shown there, in some sense, it's similar to one result mentioned by Guideon Chefman yesterday. If we consider the approximation, if we try to approximate the image of n-dimensional subspace with error n power delta, and delta is negative. Negative number, then in such case we already need to exponential, need the exponential dimension. But here for fixed epsilon, I have upper estimate, but absolutely no lower estimate. So the problem is the following: fixed epsilon, and is it possible to approximate the image of the unit ball of L2? unit ball of L2 on some n-dimensional subspace by the linear space of polynomial dimension polynomial with respect to n so I'm sure that it interesting problem another important notion is signal rank but But you can use it, it appears in computer science. But I don't want to speak about this because maybe Yuri can say something about this topic. And he used this sigma ring. But this topic is matrix rigidity. And what is it? And what is it? It's very wide area in theoretical computer science. And the problem here is to estimate this quantity RA of R. So we try to change as small as possible number of element of matrix A. Matrix A and to reduce rank and I think it's clear what's written here. And in discrete mathematics, there is a very famous problem to find effective examples of matrices with a big value of A of R. It means that A of L. It means that to find a matrix such that frank say n big n such matrix matrix that in order to make rank of changed matrix smaller than n over 2, we need to change n square some of order n square elements. This problem is unsolved. This problem is unsolved, and until recently, the candidates for such example were Walsh matrices. It was all the result myself with Rasborov about low estimate here. But look, you can see that if we are interested to make rank, say, Say n over 2. Our low estimate became trivial. It's clearly just n. And it was ideas that it's just a weak result, but it is not completely so because in Ellman and Williams paper, it was shown that. Paper, it was shown that Walsh matrices are not rigid. It means that we can change just one plus n power one plus epsilon elements and to reduce rank to make it n power one minus f of epsilon. Here it's what f of epsilon means, but in But in fact, in the proof of this theorem, it was shown that Kalmogorov widths of this set. Now it's a orthonormal set, but the in-hemming matrix can be estimated by n power this width of order n one and power, sorry, n power one minus. Power one minus delta. It's less than n power delta where this matrix is just Heming metric. And I recall you the so smart was Kalmagorov when he wrote his paper, because here, in fact, we have an important application. Important application of Kolmogorov widths in metric space. But instead of using Heming metric for lower estimate, we can replace it by metric which is related with convergence in measure. So it's non-homogeneous matrix. Homogeneous matrix and for upper estimate, we can use any LP metric because Heming matrix is between two metrics. And Malikian, indeed, Malikian proved that Alman result could be improved a little bit, and he showed that this. That this Kalmogorov width of this octahedron in Lp is of order n minus delta. So indeed it's not rigid system. Of course in L2 it's just constant because it's usual widths of octahedron in L2. widths of octahedron and L2. We can introduce such a definition is the average width. So if we have a set of elements and we consider the best average approximation of this set by n-dimensional subspace. This quantity for p this for p equal one is just a rigidity function. If phi i is a phi i is rows of metrics and the metric metrics metric itself is a Heming metric and for p For p equal to it's such a result, it's also standard. But this notion was considered in function theory a long time ago, but maybe Yuri Malikin will speak about it. But we are Myself and Yuri Balikin, before it was Yuri and then myself, we obtained some estimate for this quantity. But I use it for application to M-term approximation. Let me recall some definition. M-term approximation, but I hope it's more or less standard, but it's written here. Or less standard, but it's written here. The best and term approximation is best approximation by the set of polynomial with fixed number of non-zero coefficients. And in L2 case, it is known method of lower estimate of M-term approximation by inscribed cube. By inscribed cube inside of the set. And similar result could be obtained for approximation in L0 matrix. L0 is just matrix which comes from convergence in measure, but not in such complete generality, but. Complete generality, but the following theorem is true. So if we have cube and generated by orthonormal system psi i, psi nu, and another orthonormal system phi, then we cannot approximate non-trivially by m-term approximation if m is less than some. Is less than some constant times m if you consider the set of all vertices of this cube generated by system psi. And in order to get this estimate, I need this theorem. And this theorem to give you the stronger results than the estimate of average widths. Here we have Here we have, we show that only exponentially small number of vertices can be approximated notrially. The same case. So it's one result when already this matrix converges in measure. Convergence in measure was used. And I think that, especially if you look what is interesting for computer science, where Heming matrix is basic, it makes sense to consider which estimate in linear metric space, not just in normal space. And next, a last result of mine. The last result of mine is about another problem which is important both for function theory and computer science. In fact, this problem was formulated by Alevsky in 75, but it's closely connected with classical Grotency inequality. So I don't want to formulate Grotin. I don't want to formulate Grotendik inequality. Instead, I consider equivalent formula. So it's the following proposition. So if we have two set of vector in Rn, Z and W, then the Gram matrix, or I don't know how to call this matrix, Z J W K. WK can be how to say imitated so by the gram matrix of uniformly the system of uniformly bounded functions. So we can find uniformly bounded functions, find fj and gk with the same scalar product. And it's exactly another form. Another form of Grotendic inequality. But what I would like to stress that if that and that equal to W, so if we have just quadratic form, not bilinear form, it is not always possible to find one system phij such as this quantity such as this equality for holds. False. In some cases, for some systems, Z, we need so the best possible estimate of maximum of uniform norm of Fj is log n one power and half. It's enough to consider a net on the small subspace, logarithmical dimension, and we can. Dimension and we cannot do better than log n but what was the Alevsky problem? Zalewski problem was about possibility to have such equality in case when this matrix Z has bounded operator. Bounded operator norm. And it, in fact, such kind of problem appeared in the theory of orthogonal system in the 20th last century. And Dalevsky formalized it. So the problem is: suppose that the Okay, the operator norm of this matrix is bounded. Is it possible to find uniformly bounded functions phi j f j f such that this equality for holds. But in computer science, Along with Causer introduced the following definition. So growth-indic constant of the graph is the smallest constant K such that for any functions on the edges of this graph, this This supremum on the left-hand side, where Fk is an arbitrary system, elements, system of elements from unit ball of some Hilbert space, can be measurized by bilinear form with coefficients plus minus one. And this notion, it's in fact, what is it? It's a What is it? We are looking for an analog of the Grotendik inequality, but for matrices with which elements are non-zero only if UV is edge of the graph, graph. So the vertices The element of the matrix is, how to say, enumerated by vertices of the graph. But okay. And here it's, I repeat the maybe it's not clear how this two problems are connected, but let me start repeat the Levskis. Repeat Zalewski's problem. Suppose that we have a system of vector norm less or equal to one, Euclidean norm. And is it possible, the operator norm is bounded by R, is it possible to find a set of functions such that they are uniformly bounded and we have and phi is satisfied. Is satisfied. It's not what I'd like to say for this system phi Fj, the scalar product are exactly the same as Zj, Zk. Not correct writing. And here it's a following theorem: if the condition five condition Condition five, condition five with boundness of operator null is satisfied, then we can find the set of unsuch that they are uniformly bounded, and in fact, the absolute value is constant. And this scalar product as a This scalar product are the same, but unfortunately, not for all JK, but out of diagonal. So this theorem gives estimate of this Grotting constant of the graph in case when we know the operator norm of corresponding gram matrix is bounded, but and it's enough for And it's enough for the most of application to orthogonal system theory. But unfortunately, we cannot guarantee that this equality holds also for on the diagonal. And here it's also very interesting problem. So geometrically speaking, what we want, we have a set of vectors. We have a set of vectors, one norm one, and we try to rotate them in a n to put all of them inside of the cube of the cube of the cube of with size and power. n power minus one half it's another normalization because here it's another scalar product but it means that after some normalization we need to put all set of bounded vectors inside of the cube it's not always possible but if the operator Operator norm of this set is bounded, so it's the system is close, is connected, uh, is close to orthogonal system. Maybe it's possible, but it's still it's still open problem. So I think my time is over, so thanks for your attention. Thank you very much, and questions? And questions? If somebody have questions, just ask it. You don't see it. I'm sorry, now I'm. What? No, no, I just see myself. Now it's my problem. It's my problem, yeah. Okay, if there are no questions, I could see many people, yes, for example. Well, okay, let me speak English. Um, I couldn't attend the lectures yesterday in the afternoon, and I will miss Vologes talk, but we I have classes. But fortunately, I could hear you. Thank you. The pleasure for me. Pleasure for me. Okay, there are no questions, so let's thank Boris again. And we have a coffee break till 11.