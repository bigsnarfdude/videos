Paolo, Ranji, Guido, and Min for organizing this workshop and for this invitation. So, this I'm going to talk about aligning shape data from brain imaging and applications to fMRI time series. I changed the talk slightly. I removed the diffusion tractography part completely. And instead, we'll talk about some unsupervised learning approaches for predicting a line. Learning approaches for predicting alignment and registrations. And this is joint work with my students, David Lee, who now graduated, Elvis Nunez, Andrew Lizaraga, and our collaborator, Catherine Narr. And that's really the students who've done the work I'm here presenting. So there's rich types of data that come from brain imaging. And these are a few of the data sets I worked with. And so these are shapes of function, sequences, signals, and time series, and so on. As signals and time series, and so on. So, here on the left, you have the corpus callosum, which is a shape, and you can think of the corpus callosum boundary as a mid-sagittal segmentation of a fiber tract that actually really connects two hemispheres. And you can analyze the shapes, and it's been implicated in many disorders, including fetal alcohol syndrome, schizophrenia, and many neuropsychiatric syndromes, such as autism. Such as autism. Then you have collections of curves, which, so here you have these fiber tracts which correspond to the diffusion of water molecules. And by this, by estimation of this diffusion, you can figure out what regions in the brain are connected to each other. And this is a compact representation of these fiber tracts. I mean, you can, instead of analyzing this unwieldy, complicated thing, you can actually efficiently compactly represent them or project. Represent them or project them onto some space, reduce them, and analyze them. Then you have time series data from the brain, and this is really what this talk is going to be about. I'm going to talk about this. So at each point in the brain, you have a time series signal, which is really a response to some stimulus in case of a task-based fMRI paradigm or a free-flowing spontaneous activity in case of resting state. And then this is And then this is a bit of an old work. There are very few people who work in this area nowadays with automated algorithms and registration. Yet I find this interesting because this is a collection of curves corresponding to sulci and gyri, which are these valleys, grooves, and ridges on the brain. And you can analyze the shape of these sulci and gyri, these features. And they're also implicated in many diseases, including schizophrenia. Including schizophrenia and so on. And one way to do this is to do some statistical analysis of these shapes and do inference. But today's talk is primarily going to be on time series analysis. So this talk is divided in three parts. One is I'll talk about task-based brain fMRI signals. I'll talk about the resting state brain fMRI signals, which is more of a global type of a Type of a scheme. And then, in the third part of the talk, I'll talk about deep learning approaches for alignment, for predicting alignment, for predicting registrations, for matching signals. So the first part of the talk, and maybe some of you have seen fMRI and some of you have not. So just in the interest of completeness, I'll just start with a background. So fMRI signals use. So, fMRI signals, usually in a task-based fMRI paradigm, a person is lying in a scanner and there's a stimulus to that's usually visual stimulus or auditory stimulus, which modulates some brain activity in the brain. So, this elicits some neuronal activity. And then through this neurovascular coupling, it actually generates or elicits a hemodynamic response. So, this hemodynamic response roughly looks like this, where it's a signal with respect. This is where it's a signal with respect to time. And you can see that there's an initial dip and then a rise and a slow dip and then a rise until it reaches saturation. So for each stimulus, you get a hemodynamic response. And this is what the fMRI protocol actually measures. And this is also called the blood oxygen level dependent bold contrast in response to neural activity. In response to neural activity. And so, for fMRI time series acquisition, for fMRI protocol, you have a spatial volume where each point has a spatial 3D coordinate, and at each point, you have a time series. So essentially, it's a 4D volume. So you have 3D, multiple 3D volumes sampled at different time points. And depending on the acquisition time or depending on the resolution, you might have 400 or 500 such. Or 500 such 3D volumes that are really captured very fast at a very low resolution in maybe five, five, or ten minutes, really. So there are two main paradigms or two main, two ways people do experiments with fMRI. And one is a task-based fMRI, where you have a stimulus function, which corresponds to a task. And then so maybe the task is they show a person some images of some objects or some. Of some objects or some happy faces or sad faces. And these stimuli really are presented either in an event-related paradigm or a block paradigm. So in a block paradigm, they're simply randomly distributed over time. And each of these stimuli generates a response, a bold response. And because fMRI is a very slow protocol, so it, and of course, the And of course, the time resolution of the activity that the FMR measures is very slow. You have to deal with saturation. So, in the sense where when there's a stimulus and when there's a response, the response takes some time to rise and to decay. And so, you have many stimuli in successive fashion. The bold response, really, what's measured by fMRI will be a superposition of these individual convolved hemodynamic responses. Responses. And they would just roughly look like the envelopes of these responses. So, task-based fMRI is heavily studied in many disorders and even in healthy subjects. And one way to simply understand this is, can a person with, let's say, psychosis or mental disorders, do they have difficulties in performing some task? Performing some task with respect to healthy controls. Different from task-based fMRI, there's another paradigm called the resting state fMRI, which is again very widely used, where a person just lies in a scanner and does nothing, and it's free-flowing, spontaneous brain activity that resting state of MRI measures. And here, since there is no gating of a signal, I mean, since these signals, they don't really correspond. Signals, they don't really correspond to each other across subjects or across regions. What people do is they find a pairwise, simplest approach would find pairwise correlations between nine series and generate a graph or a network and then threshold it at some value and then look at this network and try to see network differences between groups of populations. And this is something interesting because just purely based on Because just purely based on correlations and over large data sets and some interesting analysis using some independent component analysis and so on, people have shown that even if all our thoughts are random and we all are thinking about different things at any given point of time, there is some common pattern or common activity that corresponds to some networks that are generated from these signals. And you can identify these networks as the default mode. You can identify these networks as the default mode network in red here, the salience network in purple, visual network in blue, and so on and so forth. And so, these networks people have shown are quite stable across populations, across subjects. And then the question then is, are these networks different from one population to the other? So, here are a few just backgrounds in fMRI studies and In fMRI studies, and some of our own work previously showed that there's a frontal lobe hypoactivation in bipolar disorder. So, in bipolar disorder, even euthymic subjects, subjects which don't show any symptoms have a lower activation in the frontal lobe compared to healthy controls. In case of the Alzheimer's disease, the task-based fMRI in APOE4 carriers showed abnormalities compared to non-carriers. Abnormalities compared to non-carriers. And then there's some work from our lab, some old work, which shows that if for severely depressed patients, if they undergo treatment with, let's say, electroconvulsive therapy, ECT here, using task-based fMRI, you can show differences between differences with respect to the treatment within patients. So, what is the motivation? So, what is the motivation for studying this? So, really, what is the motivation for analyzing task-based fMRI resting state fMRI signals and to think of alignment or registration here? So, really, for task-based fMRI, there's an expectation of within condition response similarity. So, if people are shown similar stimuli, one could perhaps expect similar responses. Similar responses. However, due to scanner noise saturation and drift, that rarely is the case. And this task-based fMRI are heavily corrupted with noise. And so you can see unless it's a very strong stimulus, maybe event-driven design where there's some kind of a motor task, for instance, people are moving a finger or something. In those tasks, In those tasks, you do see visually that these within-condition responses do coincide and the shapes really look similar. And there's also variability in neural activity in response to the same stimulus. So, and this is a big question. Why is it or what it is? And is it purely scanner noise or is it purely, or are there parts of mental Mental drift that's going on in neural activity. However, because of this condition, you do not always get the same task responses based on stimuli. For resting state fMRI, you have noise artifacts, misregistration of spatial coordinates when you are comparing subjects or populations. Again, there's individual variability. Again, there's individual variability in neural activity, and most importantly, there's a lack of synchronicity of resting state signals across individuals. So, for instance, when I and you, we line scan at the same time, we're thinking different thoughts and our patterns, our time series signals are actually very different. And there's no, so they're not synchronized. And you cannot really say that at given time t, my signal and your signal are going to coincide because they're going to. Signals are going to coincide because they remove completely different. So, to counter this, people have come up with some naturalistic or synchronized resting state stimuli. So, like task-based fMRI, can we show the same movie, for instance, or same game to all the subjects? And will that somehow improve or will that attach some new meaning to this synchronicity of signals across? Synchronicity of signals across individuals. And this is an interesting thing that people are working on and want to develop further. And so, our interest is to model the synchronicity of the response, really, and to ask the question, is there some inherent synchronization of these time series signals? And by doing some kind of alignment, either global or local, can we actually capture it? So, that's really my interest these days. And so, for those of you who are familiar with image registration, the main idea here is this is a slide from this famous book by Thompson, where he wants to compare different shapes or different images. And so, this is an image of one species of fish with another species of fish. And instead of directly understanding these images, his idea was we could. His idea was we could transform one into the other and actually study these transformations. And this transformation he encodes the warping of the space, the underlying space in which these images lie. And by analyzing the transformation, you can essentially compare to objects. And for those of you who do registration, this is a very well-known thing. And so we want to ask the same question in the context of fMRI: whether Whether fMRI functional signals have shapes, and can we have a computational anatomy analog for functional time series data? And that is the question we ask. And so some ideas about functions here. So one interesting thing that comes to mind when you're dealing with functions and when you're dealing with signals over a domain is this idea of domain reparameterization using idea of domain reparameterization using warping functions. And so you can, so given f1 and f2, you can actually stretch or shrink f2 to coincide with f1. And this stretch, stretch and shrink can be encoded or can be captured by this transform phi had. And so like similar to this context of phi in images, which phi is your deformation map or the deformation field or your registration function. Or your registration function or an alignment function, we want to ask, or we want to model such alignment functions or registration functions in case of time series data. And so this fee will account for both amplitude and phase because for the scalar single one-dimensional functions, when you reparameterize F2 with any phi, Uh, phi, which has some special properties, uh, phi in fact a diffeomorphism. Uh, you will change both amplitude and the phase phase for F2. So, so, so then what we want to do is to model fees and understand what these fees are. So, this is a this is really walking through a very simple example of two domains, F1 and F2, of these two signals, two signals, data. Two signals, or two signals, really, F1 and F2. And we want to see how we can either compute phi or reparameterize F2 with some phi so that these two signals match. So in the naive case, this is a identity function or identity map. So phi of S is equal to S. And so F2 composed with phi is F2. And you can see that there's really, there's no movement. Fn and F2 are very. Fn and F2 are very distinct. So then you can select some fee. Maybe it's a random fee, maybe you know something about the signals. And then now you can see that F2 in this case has now changed to more, let's say, more closely resemble F1 than before. And then you can play with these functions either going, either having drastic alignments like these high slopes. These high slopes here, or very small slopes here. And then you can see that F2 here now is coming more and more closer to F1 until you find really an optimal phi, optimal warp, where both F2 and F1 are aligned in the sense these bumps go to bumps and these valleys go to valleys. And you can see that there's an optimal match that has occurred between F1 and F2. And these are the optimal warts we want to study, study, and model. And so this is essentially showing all these fees together. And you can see that different fees have different effect on the warping of these functions. So our proposed approach is to do a domain reparameterization. Domain reparametrization using some warping function to match or to align or register one time series signal to the other. And so here you can see given two time series signals, and I don't know what regions they are from, maybe they're very two different regions in the brain. If you simply connect them in a one-to-one manner, and what we call a linear alignment, it simply matches them one-to-one. matches them one-to-one and and only accounts for amplitude so you can see that these amplitude is what's what you'll measure when you take the l2 norm between these two functions or the difference in amplitude and then you can see that these functions are really not aligned in in all all uh across all time whereas if you do some kind of where you if if you estimate some kind of an optimal warp optimal alignment you can see that the these bumps are now starting These bumps are now starting to match to these bumps and these valleys to valleys. And then, if you overlay these two time series, you can see that the two time series signals now more closely resemble one another compared to the first case. So what does this mean? So with this idea, we go to or we study task-based fMRI signals. And so here, a typical task-based fMRI paradigm, as I said. MRI paradigm. As I said earlier, a person is lying in a scanner and they're being shown these stimuli, happy, fearful objects, neutral, and so on. And each of these stimuli elicit some hemodynamic response, hemodynamic activity in the brain. And when you measure the whole time series, these blocks or rather these conditions are nested within this entire signal. Within this entire signal. So, one could expect, or one could reasonably expect, although that does not happen in practice just because of all the previous confounding factors that I mentioned. But the expectation is that for a happy task or a happy stimulus, the response that I get in the fMRI time series should at least have the same shape. Should at least have the same shape. And one can debate as to how reasonable this assumption is, but the whole idea of statistical analysis of fMRI signals does kind of rest on this idea where you want to model within conditions, you want to model separate conditions within this whole time series. So then we ask the question: So then we really say that. So, then we really say that we can have this assumption that the same tasks are eliciting the same responses. And then the question then is what to do with it. So then one could model the block stimulus function and the hemodynamic response and really extract these different conditions for these different tasks. So for a given time series signal, and this could be five minutes or 10 minutes, and there might be about 400 or 800 samples. 800 samples along the signal, one can extract different conditions, let's say happy, fearful, and neutral. And one can then ask, what are the commonalities, what are the similarities in these patterns? And can we have a reasonable expectation of alignment for these conditions? Can we align these signals? And that is what we. And that is what we set to do. And so to start with, we used a previously established method that represents each signal or each function as a point on the manifold. And we call it the SRVF, the square root velocity function that encodes both amplitude and phase. And so here, each time series F2 and F1 is represented as a point on this manifold by its SRVF. Bytes SRVF, which is really f dot over the square root of the norm of f dot. And I'm not going to go too much into detail here, but the idea here is because of this representation, if you have a set of all reparametrizations acting on Fs, then the L2 metric between Q1 and Q2, between SRVFs, is really invariant to F, to Phi. To phi. And so, given Q1 and Q2, the SRVFs of two different time series, their L2 norm is really invariant if you were to apply the same diffeomorphism, same reclamatorization to both Q1 and Q2. And then when, and it's nice, Zavia is actually in the talk. We are all inspired by him in terms of both extrinsic, intrinsic estimators, intrinsic estimators. Intrinsic estimators or culture means and pressure means. So, here, using this representation and using reparameterization invariance, if you are given two points, Q1 and Q2, you can then compute a mean in intrinsic fashion without ever leaving the manifold on which they lie. And this is contrasted with the extrinsic mean where you have two points Q1 and Q2, and this is the manifold they lie in, but you actually embed them in some high-dimensional space. Embed them in some high-dimensional space, compute an extensive mean, or compute your Euclidean average, and then project it back on the manifold. And really, we are interested in these kind of averages on our objects, on our shapes. And that's all I'm going to talk about about this representation. So, coming back to task fMRI alignment, we have this original time course with many conditions: happy, fearful, neutral. And then if Neutral. And then, if we extract these conditions, these are how the unaligned signals look like. And so these are all happy, fearful, and neutral. And you can see that visually, they don't look nothing like each other, nothing like each other. And so the question that we ask is: if we align them, would it make sense? And so here, using this previous slides that I showed. Slides that I showed, SRVFs, we actually find a geodesic between two time series and compute a diffeomorphism that aligns these to each other. Here we actually go one step further. We extract all these sub-time series or sub-conditions, and then we compute a mean of these conditions using this cartridge mean. This actually. mean uh you this is actually the carture mean on this manifold and then you align each individual uh time series for these conditions to that mean and and this is how uh the means look like and and and and the gray shows the unaligned mean and the green shows the aligned mean so you can see that uh at least for uh fearful and neutral uh the uh for some some some uh parts of the time series the the the the aligned and the unaligned mean can coincide on some some can coincide on some some some uh intervals whereas for the happy condition which is which is uh which which uh for the for the happy condition you can see that the aligned mean and the unaligned mean uh coincide uh quite well and and so here maybe there's a rationale for aligning these within condition uh time series there's a big question of noise here and i'm which i'm not going to touch here uh touch in in this talk this time uh but but but But based on these observations, and we looked at many such observations, and this is by no means quantitative, there was some reasonable expectation that one could try aligning these within condition time towards. And so we aligned these time series for each condition. For each condition, and then reformatted the time series. So, put it back. And so, here, the gray time series is really the original time series. And the time series shown in color for each condition, happy, the green, neutral, red, and so on. The time series with color is actually the aligned time course with respect to the mean of each condition. And so you can see that. Condition. And so you can see that there are some changes in the aligned time series, but they don't drastically differ from the aligned versus unaligned. And since the mean shape for the happy condition, the green condition looked really similar for the aligned and the non-aligned case, you can see that when you reformat the time series and put it back, you can see that the aligned condition really doesn't differ a lot from the unaligned case. A lot from the unaligned case, which is something which is reassuring in this case. So then the question is: is this alignment, what does this alignment really do in the global scheme of things? And so we looked at a single subject without doing any population analysis, and we simply ran a general linear model, standard fMRI analysis, and we saw. fMRI analysis and we saw that there were increased number of clusters number of activations in a single subject activation map and so here the orange really shows activation in the in the warped data which is not there in the in the unwarped data so the so after warping it did show some activations which which didn't exist before and and and you can you can also look at the number of wax cells and then Can also look at the number of walk cells and the number of and the p-values which are obtained after a statistically significant test whether these activations are valid or not. And in case of the warped case, we had significant p-values as well. So going further, we took a group of subjects, I think in this case, about 10 subjects, and just looked at 10 subjects, and then just looked at these contrasts: happy versus objects and fearful versus objects, and just compared the original data and the warp data. So when you put together a big group, then normally you get much higher power compared to a single subject. And in this case, the warped data and the original data look similar, except that we observe in sometimes the warped data, you Sometimes in the warped data, the signals for these activations followed the anatomy much better than the unwarped data. And this observation has yet to be tested. And so much for task-based fMRI. And then we looked at resting state fMRI. And then we asked the question: since we do not have any inherent assumption of synchronicity for resting state signals across subjects, so each. Across subjects. So each and every subject individual, they're thinking very different things. How do we align resting state signals in this case? And so here, what we did was we, for a brain and for different regions in the brain, we actually considered a vector value function, capital Fi, which is simply all these individual time series functions put together. So F1 to Fn, where n are the number of functions. Fn where n are the number of walk cells or number of points on the brain, and then we chose a fixed template. Maybe you just select one subject, let's say, from the population as a template. And then we asked the question, how can we align FI to F template without doing pairwise alignment between voxel one to voxel two? So sorry, pairwise alignment between each point in the brain to each point in the brain. point in in the brain to each point in the brain for for uh for the template so uh so so then we we we so so doing a pairwise alignment so so matching this time series to this time series is not really a good idea because as i said these are not synchronous then then we ask the question can we define a global uh warping function phi which can align all of these signals all at once and and and this this is uh the the This is the cost function that we defined, where we sum fi over t minus fi of phi of t over all these n walk cells and then integrate it to solve for phi hat. To minimize this expression over phi to solve for this optimal time war. And so this leads to this idea of fMRI global signal alignment, where given Where given F1 and F2, which are these vector value functions, we can do many things to align them. And the simplest idea is to just do a global temporal rotation. And so we have some rotation matrix, which is S of T, where T is this really discretized samples of each of these time series. And then you can simply compute a rotation from one subject to the other to get some global temporal reparameterization. Parameterization, global temporal rotation. And then, in addition to this global temporal rotation, you can solve this cost function to actually get a global temporal reparameterization. And so, what does this mean? So, given an n-dimensional fMRI configuration function to align some subject F1 to another subject F2, we essentially solve for a global reparameterization and a rotation by minimizing. Parametrization and a rotation by minimizing this expression here. So it turns out that this expression here, this cost function, can just give rise to some family of, I should call them family of cost functions, where you can mix and match the rotations and reparameterizations and add the order. And there is obviously all such orders are not valid, but we just wrote them down just to understand. Down just to understand what this really means. But in this talk, I'm only going to talk about rotation and reparametrization. So, solving this cost function or this cost function or a combination of rotation and parameterization, what do we really get? So, here's an example of a fMRI time series, and blue is one subject I, and sorry, red is some subject I, and blue is a template. Some subject I and blue is a template. So, so after alignment, due to just phase alignment, due to just phase, due to just temporal reparameterization, due to just feed, we can see that these the subject I has has shifted, stretched and shrunk to match to the template. But if you do a rotation and phase alignment, you can see a very more drastic change of amplitude and phase. Drastic change of amplitude and phase compared to just the phase alignment alone. And we're still trying to think what, and we know why that is, obviously, because rotation is a very, very big kind of a deformation, but we're trying to figure out the interplay between these two transformations. So then we looked at a small data set of 12 subjects aged 28.5 plus minus 7 years, 7 males, 5 females, and looked at Five females, and looked at aligning them to each other. And so, if you have all these 12 subjects and fix one as a template, let's say keep one aside and have 11 subjects now and just register all of them to that first subject. This picture shows pairwise correlations or average of the pairwise correlations of time series from one subject to that template. From one subject to that template, or for all subjects to that template. And you can see that this is a very noisy thing. And so, if you average all pairwise correlations, you essentially you just get noise, which makes sense because we already know that there is no assumption of synchronicity for resting state across individuals. However, if you do a global phase alignment, you suddenly start seeing some interesting patterns and these. Interesting patterns. And these patterns are parts of what we call the default mode network of the brain. And this was only apparent after doing this global signal alignment. So going one step further, if you also add rotation to the mix, you can see that the signal is now much smoother. In fact, the signal-to-noise ratio here has gone up, and these networks are now much more pronounced. I would like to, what I understand is. I understand is rotation is a more global type of a deformation and much more drastic than this phase-aligned type transformation, which is going to have a shrinking and stretching of this time domain. And so my understanding is rotation may smear the signals too much, and you might lose specificity at the expense of sense, or you might decrease the specificity. Decrease the specificity at the expense of sensitivity if you do both rotation and phase align. But it's an interesting result which says or which shows that where before, if you averaged all the pairwise correlations and you just got noise, just by doing some clever global alignment, you now starting to recover some important patterns in the brain. And these patterns are not And these patterns are not random. They do correspond to the default mode network. So, parts of these patterns correspond to the default mode network of the brain. So, this is so much for resting state fMRI signals. So, I'm going to switch gears a bit. And you might think that this is all very half-bizar, very random, but the third part of the talk is we're going to ask the question. So we can have. So, we can have analytical solutions for estimating these vaulting functions, phi, and gammas, these diffeomorphisms. The question we ask now is: given a large set of observations, can we learn to predict these vaulting functions? And I know maybe I'm a bit short of time, so I may rush to this. So, this is a joint work with my student, Elvis Nunez, who is a PhD student in Dublin. And he asked the question: can we? He asked the question: Can we predict these warping functions? And so we started with a very simple idea. And maybe I can just directly go back to the network architecture. So we started with a simple idea using a temporal transformer type network, which has been previously used by Lohit et al. And so this is a very simple idea of a network where, given two pairs of shapes, and given a per. Of shapes, and given a perfect alignment that we somehow computed using analytically or computationally, and having a large number of observations, can we now learn how to predict a gamma? So this last output layer actually predicts the diffeomorphism. So I skipped this slide really, but the computationally, the gamma can be obtained using many different ways and one popular and a very nice. Popular and a very nice way of doing it is a dynamic time warping or dynamic programming. And so, given two shapes q1 and q2 or f1 and f2, you can use dynamic programming to find this optimal gamma. And so, we did that for all pairwise shapes that we had in our data set and trained this network. So, we use three different loss functions. I won't go too much into detail, but really differentiate between the first and the differentiate between the first and the second L1 and L2. So the first loss function only penalized gamma. So how different am I from the actual, how different is my predicted gamma from the true gamma? And the second loss function, in addition to this discrepancy between the gammas, also analyzed or minimized the shapes after getting reparameterized with that gamma. So this had the actual shapes along with the gammas. With the gammas. And this third loss function is really a variation of this L2 loss function for stability purposes. So L2 and L3 gave lower values in terms of cost, lowest cost. So L3 gave the lowest cost. And then how does the warping look like? So each row here is a specific example of bump functions. And so each column is a specific example of bump functions. And each row, the first row shows the The first row shows the gamma, where green is the ground truth gamma, and the red is the predicted gamma from learning. And these, the last two rows, so the last row actually shows the ground truth alignment, ground truth warping, ground truth matching. And the second last row shows the predicted matching. And then so these are very, very close to each other. So you can see, and we did this for about less than half a million. Did this for about less than half a million shapes training and validated on about 65,000 such random bump functions. And we really observed good results almost on all of these cases. The results are a bit mixed for shapes. Shapes are more complicated. For simple shapes like these rounded type shapes, the prediction actually does a much better job compared to the ground truth. For more complicated shapes like these animals with legs, Animals with legs. The prediction does capture the overall shape of the alignment, but does miss these important features. And I think that these features are important. That's where much of the deformation may be coming from. So then, okay, maybe I'll just take one minute just to touch upon this idea. So then we ask the question. So then we ask the question: instead of supervised learning, can we learn, given a collection or given a population of shapes, can we learn to automatically align this population to a fixed template in an unsupervised manner? And so here we use this variational autoencoder idea, where it's just a standard autoencoder where the first part is a reconstruction error. Encoder where the first part is the reconstruction error and the second part is the scale divergence between this prior on these hidden variables or latent variable z and this conditional z given the input data x. And I'm not going to go too much into this detail, but we proposed a few loss functions that could achieve this objective. And we changed this reconstruction error by incorporating the Error by incorporating these three terms. So the first term was the Fischer-Rau metric between SRVFs for a fixed template Q bar and some template and the individual shapes in a population. And we weighted them empirically. So we fixed these weights and did it over some batch for a given batch size B. And so this is This is how the network looks like, but I'll just jump straight to the results. So, for a fixed template, given all these original functions and a template which is shown by this orange curve, this network predicted the optimal watts given by gamma theta here and aligned all of these bumps to this template in a fully unsupervised manner. And when we tried this for two to two bumps and two to three bumps. And the training took longest, about 30 minutes, but the prediction was super fast. Then, skip this. Then we ask another question. I'm sorry, I'm rushing through this, but then we ask another question. Instead of having a fixed template, can we simultaneously predict both the template and the warps? And we did this with some trick where We simply replaced this template q bar by a warped average of the shapes in that population. So q bar here simply became q hat, which is a Euclidean mean of the wart individual shapes in a given batch B. And then using this new modified. Then, using this new modified loss function, now the input to the network was simply these bump functions. These are two bumps, the original data and fully unsupervised. And it automatically predicted both the template as well as the working functions all at once. And we applied this to brain data sets. This is to brain data sets. And also, I'll just jump to the final result here. So, here, these are the original fractional anisotropy profiles correspond to some signals in the brain along a fiber track. So, these are fiber tracks, and this function is actually a signal along that fiber track. So, this is how the original, the first column shows the original profiles for different fiber tracks, the RQAD, CSTN, and so on and so forth. At CST and so on and so forth. And the second column shows a warped profile obtained by simultaneous prediction of the template as well as the warping functions gamma. And so you can see that there's some interesting patterns that were lying, that were in this data, which were not apparent when you looked at all these original shapes all at once before, but they start becoming maybe clearer when we. Clearer when we work all of them. Of course, the big question is whether this is really noise and whether you're aligning noise or not. And that's our future work. And so to summarize, we looked at alignment in the context of task and resting state activity. And we looked at two approaches for predicting these walking functions or these registrations using. These registrations using deep learning, and I think more needs to be done on this. So, just before I end, quick shout out to both my students: David Lee, who graduated with a PhD and now doing a medical school MD. Elvis Nunez, who is a fantastic guy, came as a research assistant, but now is a graduate student in Dublin, won an NSF graduate research fellowship this year, and I'm just doing phenomenal work. So, with that, I'll So, with that, I'll just end here. Thank you. Oh, thank you very much, Shantanu. And please join me in thanking Shantanu for a wonderful talk. Yeah, it's a fascinating topic. I've always been really interested in trying to learn different ways of understanding the brain and how these statistical techniques help, and how it kind of just lies beyond networks. It lies a little bit beyond what traditional geometry is. So, we kind of have to expand our horizon. So, we kind of have to expand our horizons of these theories. So, I have a couple of questions, but maybe someone else from the audience could like to take this opportunity to ask a question. Would anyone want to ask Shantanu anything? Okay, so while you make up your mind, maybe I'll ask first. So, my first curious question is: I know that these areas are kind of more or less considered. Are kind of more or less considered a little data regime because it's like not as, you know, you don't have as many data points as like with image analysis or other things like that. And I have worked a little bit with the Human Connectome Project data. So I know. Have you thought about augmenting your data set in any way? Or how do you get around the fact that it's not a very large data set in order to get these very interesting results? Just to begin. Just to be clear. So, that's a good question. So, there are maybe two ways of looking at this. There are now new data sets. HCP is one of them, or the UK Biobank with excess of 100,000 subjects or more. That's still small data if you look at, if you compare it with the standard deep learning type applications on images and things. So, I think it's very hard to get at least a million. I think there's a project in China. There's a project in China where they have a 1 million brain project where they want to scan, they're going to actually acquire scans from 1 million subjects. So these are the projects that are going to actually give us these large data sets in brain imaging. But for now, yes, you're right. I mean, we just have to deal with this small data set. But I think that's where there's a challenge because the question then is: how can we design effective How can we design effective techniques for small data sets, both learning and inference for small data sets that one would typically take huge, very large database says to acquire? Another way to look at this is, I'm probably just being speculative here, is that when you are dealing with millions of images for let's say speech or natural images for deep learning and so on, there's a lot of variation in those images. So, pose, So, pose, angle, lighting, illumination, and even the number of subjects. In the brain, if you're going to focus on a very few specific regions anatomically, there's much lower variation if you think of it in that sense. And so, can we somehow then exploit? So, can we exploit this lower variability in certain anatomies to In certain anatomies, to actually have better and efficient algorithms. So, that is a question that I'm interested in. So, I don't know if that answers your question, but. Yeah, absolutely. I think it's a very good answer. So, if I have another two questions, so maybe I'll just go and ask for mine. And then if anyone else wants, they should also either. You can also use the chat if you don't want to. So, the second question is: here you focused a lot. Here, you focused a lot on learning directly on the signals, on the signal data as a time series. But what about the learning on networks that are inferred from the signals themselves? Because you did mention maybe the first third, getting this default mode network for the brain. So, is that something that you're looking forward to doing next? Or is that what are your thoughts on that? Have you already started? That's a good question. We did some. I we did some preliminary work on networks, but really very simple things. And especially from the previous talk, Anna's talk about DAGs. And I think that's more relevant for this network type analysis. And so learning on networks, generally, by the time you get to these networks, they are very reduced in size, very reduced dimensions. And so, and coupled with very small. And coupled with very small number of observations in terms of subjects. My sense is: if your question is about deep learning, my sense is classical models still do outperform deep learning methods in the context of networks for such small regions and small number of subjects. And so, yes, maybe there's something there, but. uh but uh my sense is that the representation has to perhaps uh we need we need a better representation and the second is we probably need more data thanks for the answer and there's a question in the chat which i'm going to read it says from yaim cooper in the first half of the talk how do you minimize the functions you are optimizing gradient descent Are you optimizing gradient descent, LM optimization, other? Yeah, so actually, we do a combination of gradient descent and dynamic time warping to optimize for phi. So to actually estimate phi. Okay, great. Thanks. Hopefully that cleared that out. And I guess my final question probably has to do a bit more with that other comment that you just mentioned about getting a better. About getting a better representation. When you were talking about dealing with noise, how can you consider ruling that out by maybe thresholding the signals? Or is that something that you think could also help to get a better representation of what I mean is the initial data set that you're collecting to get more specific data. More specific data. How is that problem something that you think about? That's an open question. And so it's very relevant to us because one could ask, hey, maybe all you're aligning is actually the noise and not the signal. So there are two ways of looking at it. One is, and we haven't actually done this, but to really do high spatial under sampling and try to see if these patterns persist across various Persist across very low resolution representations and across different subjects. And my sense is because the default mode network is kind of kind of obvious, and if it does fall out, and if it kind of is coming out, my sense is at least in terms of the global alignment, you are actually improving the signal-to-noise ratio with alignment. That is my sense. Is my sense, and we don't have any results to show this for the task-based fMRI signals. The answer is different because there, the signal and the noise, the level of noise may be much higher than the signal. And so, for very specific tasks, and here I showed tasks commonly used in psychology, like M back, go, no, go, and so on, happy, neutral, sad, and so on. There are event-related tasks. So, some motor functional tasks, for instance, pay patients with some motor disorders, and then they are doing some motor-related tasks. Are doing some more related tasks. I think those elicit more robust responses compared to these go, no, go type tasks. And there, I think you will probably have a much higher signal-to-noise ratio compared to these other tasks. So, there, yes, if you're doing network type approaches, you're reasonably in a better shape than. In a better shape than these other tasks. The only problem being these days, people almost always are simply doing a block design and not event level design. And so this is the nature of data we have to deal with. But that's still an open question. Well, thank you very much for the answer. It's very, very interesting. It's wonderful to know there are so many directions that are yet to be explored. So if no one else has So, if no one else has another question for Jantan just now, I guess we should all thank you again and thank you for the invitation. And thank you very much.