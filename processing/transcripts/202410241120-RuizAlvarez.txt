So today I'm going to talk to you about this work that we've been developing in the previous few years. It is a joint work with some colleagues, Sergio Amat from my university, University of Cartagena, David Levin from Tel Aviv University, also Professor Lee from North Carolina State University, Professor K Yapan from Chong Landa Sue. From Chongnan Dasue, Central South University in Hunan, Changsha, and Gioni Yanez, that is a very good friend from Valencia University also in Spain. So basically, you will see that the flavor of my presentation is not very much related to exactly to what has been presented here before, but we are working mostly on finite different. mostly on finite different schemes, finite difference schemes for approximation and interpolation. And usually these schemes somehow can go back and forth from the numerical approximation of PDs to other problems. For example, approximation, purely approximation or interpolation of data. So we've been doing that in the previous years. We have also worked with PDEs, mostly conservation laws. But yeah, so let me show you how I have organized the talk. So first of all, I will tell you about what I mean by BS applying approximation. I will be talking about the pause interpolation operator. And then I will show you, or I will talk to you very briefly about the three possible solutions that Three possible solutions that we have found to deal with the problems that discontinuities introduce in the approximation done through these quasi interpretation operators. Mainly we will be dealing with the Gibbs effects or Gibbs-like effect that appears close to the discontinuity, but also we want to deal with the smearing of discontinuities. And to do that, we will introduce three nonlinear approaches. three non-linear approaches. Then, first of all, I was thinking about only talking to you about the third point, but then I decided that the second point would also be interesting. So I will talk to you about a Wino scheme to deal with these problems. Then I will tell you how we solve the problem using correction terms. And finally, I will present the conclusions and some future work. Future work. So basically, what I mean by or what we mean by a quasi-interpolation operator is an operator that looks like this, where we have LP, that is a linear operator of the data, it has compact support, and a BSP base that also has compact support. So here you have the supports that we use and for the LP basically we can define it as a function of the data. In fact CP are constants that we have closed formulas for finding them. For example in the article by Spelliers in Advanced Computational Mathematics of 2017 we can find formulas for We can find formulas for those C. So basically, what we are doing is just take BS planes bases that are, in this case, they are piecewise polynomials, and we will multiply them by functions of the data that have compact support. This is for quadratic VSPLIN functions. In this case, LP depends on three data. This one, On three data, this one, this one, this one. And so everything has compact support. So basically, what we, the question that we ask to ourselves is, this approximation is nice if we are working with smooth data, but what happens if we have a discontinuity here? So we will see that as everything, I mean, the base plans are as smooth. The VS plans are smooth and the LP operators are somewhat finite difference operators. We will see that we will have some kind of numerical artifacts close to the discontinuity. So that's what we want to solve. So why this approach is nice if the data is smooth and everything is smooth? Because the quasi-interpolation of The quasi interpolation operator inherits the smoothness of the VS planes. So basically, if we have a P degree BS plane, we will have that QP is P minus 1 continuous. But we also have order of accuracy. That means that if we have a P degree BS plane, we will be able to reproduce polynomial spaces of the degree. Of the polynomial spaces of degree p. So that means that we also have order of accuracy very easily. But didn't find, as I mentioned before, if we have C P plus data that comes from C P plus plus one functions. So basically we will be working with expressions like this. For p equals two, we will have something like this. This is the L P operator. Then we have the BS plane function for P equals three. for p equals three this other operator and also the explan function for if we go up to farther further piece as i mentioned before we have expressions for the lp operator so that there's no problem on that so the problem basically comes when you introduce the discontinuity and you have to deal with this kind of oscillations okay so our question is if somehow we can modify the Somehow, we can modify the quasi-interpolation operator to make it non-linear so that we obtain an automatic adaptation close to the discontinuities. Or maybe if we know the position of the discontinuity, if we can introduce some correction that allows us to recover the accuracy close to the discontinuity and maybe to obtain as a result a piecewise continuous A piecewise continuous function that is what we really have, or what we really can see in the data. Okay, so basically, in 2023, we proposed the first approach for solving this, and it was to algebraically transform the LP operator into something that included the first order differences and a mean. And a mean, this is the arithmetic mean of the first order differences. Why do we wanted to do that? Because, in reality, smoothness differences are talking us about how smooth is the function. So, for example, if we have a look to the previous plot here, not here, here, if we look at the first-order finite differences here. Differences here, you see in the expression that we have basically, if you look at the two data that you have before and after the discontinuity, what we can see is that before the discontinuity, we are at a smooth zone. If we cross the discontinuity, the um first order differences will be of the size of the jump. At the smooth zone, what we have is that they are ordered H if we do Taylor expansions. The rates if we do Taylor expansions. So basically, the first order differences or the differences in general can talk us about if we are, if we are, if our extensive clause is discontinuous. So we are talking basically about these two data. Here, the first order difference is of H, here it is of 1. So if we are capable of replacing this mean by another mean that has good properties, close. Has good properties close to the discontinuity in the sense that it provides a result that is closer to the smallest of the arguments, then we are fine. We can obtain an algorithm that is adaptive automatically. So that's basically what we did. We replaced this mean by another mean, in particular, the harmonic mean, that has the property of giving a result that is always smaller or equal than two times. Uh, smaller or equal than two times the smallest of the arguments. So, this means that the result that we obtain from the mean will be closer to the first order difference that is at the smooth zone. Okay, so in that way we can make our algorithm adaptive. So, the second approach that we proposed, that is the first one that I'm going to go into more detail in a minute. More detail in a minute is this one where we saw that the VSPLINE functions, if we go back to the plot that I have shown you before, this one here, and we have a look to the value of the BS planning functions anywhere in the x-axis, and we perform the summation of their value in a particular point x, we will see that this. Point x, we will see that they sum up to one. So basically, what we have in this expression of the quasi-interpolation operator here is that we have a convex combination of the LP operators that are taking place in the approximation. So this is a way to include nonlinearity because if this is already a convex combination, we can A convex combination, we can use something like we know algorithm. Maybe you have for sure you have heard about it. We know algorithm is used, for example, in conservation laws, for the approximation of conservation laws, and it is based on a convex combination of approximating polynomials. In this case, we have a convex combination of LP operators. So, why not try to use here a winner strategy to adapt the PSP? To adapt the PS plane basis, that each point x, they are just coefficients that multiply L P and try to make them nonlinear. So that way, using smoothness indexes, we could try to adapt also automatically to the presence of discontinuities. Finally, well, we published this work in 2024 and then we asked our And then we asked ourselves, because this you have to pay something also for including this approximation here. Before I didn't mention it, but what we have to pay in the replacement of the mean is a reduction accuracy belt around the discontinuity. The same thing for the second approach. So then we thought about how to solve also this. Is it possible to obtain possible to obtain something instead of that is smeared, an approximation that is smeared close to discontinuity. Is it possible to recover a piecewise continuous function, for example? So we decided to modify the LP operator, including here correction terms that depend on the position of the discontinuity and the jumps in the function and the derivatives to try to recover an approximation with full accuracy in the sense that it has the accuracy of the It has the accuracy of the linear operator at a smooth zone. Okay, so let's go to the first approach. How do we propose the non-linear, the second approach? Because the first one, as I don't have much time, I'm not going to go in more detail. So how do we modify the VS plane base so that we can include a non-linearity here? As I have mentioned, VP, the The Vt is a partition of unity. So we will replace the VT that we call the optimal weights by optimal weights, CKP, sorry, CKP. We want the CKP to be equal as much as possible to the PP, far away from the discontinuity, and we want to modify them so that they are close to zero. If the extensive log the LP operator crosses the discontinuity. That's basically the idea. And for that, we need to assure all the time that the CKP are all the time also a partition of unity. That is the main property that we are going to exploit here. So I didn't mention that the CKP are always greater than zero, but you saw before that the CKP and the The CKP and the VP are VSPLIN basis, and they are always positive. Okay, so having into mind this property that I have mentioned, the objective that we want to obtain at this having, say, CKPs closer to the BS plane function, far away from the discontinuity. And close to the discontinuity, we want the CKPs to be zero. We introduce a We introduce the non-linear weights that are defined as some alpha kps divided by the sum of the alphas, so that we keep the partition of unity property. And we define the alphas as the CKPs that are the linear coefficients that I have mentioned before, the ones that are very similar to the The ones that are very similar to the BS planes far away from the discontinuities, times a C function of the smoothness indicator. The smoothness indicator is just a function of the data that tells us if we are crossing, if our extensive is crossing the discontinuity or not. Or as it is enough to use p-order differences. And this is basically because the properties that we need for the smoothness indicator. We need for the smoothness indicator are that they are order one if the extensive curve is discontinuity. Our differences satisfy this. In fact, they are first order differences are of the size, they have an order of the size of the jump when h goes to zero, close to the discontinuity. And we need them to be of h when h goes to zero if we are at the smooth. And this is to satisfy the accuracy that we need far away from the discontinuity. Also, we need another property, but this one is more technical. We just need it for the proofs, for the proofs of the accuracy. So I will just skip it. Okay, so we define the functions of the smoothness indicators C as one divided by the C as one divided by the small small c and we have this proposition where we find that the capital C functions, if they satisfy this property, then automatically we can satisfy that the nonlinear weights when we are at a smooth zone are very close to the optimal weights that we want to reproduce far away from the discontinuity. Reproduce far away from the discontinuity. So, this is useful to prove the accuracy. And in the process, we found that the C functions need to satisfy some properties. With these properties, you can find several C functions that can be useful for introducing non-linearity in our quasi-interpolation operators. So here I will present only three that we used in the experiments. That we used in the experiments. So the first one is the classical one used in Wino. So in Wino method, by in the original Wino method by Lugo Seran-shang, we have one divided by an epsilon that usually is in some articles it is taken as h power something plus x where x is the smoothness indicator. Then we proposed the other two functions. Proposed other two functions that I will show you in the experiments that also work. So, basically, once we have the properties for the C function, we can prove the accuracy for the nonlinear quasi interpolation operator. And well, it is more or less straightforward. So, we can prove that if the function is has C p plus one regularity, then we will recover far away from the discontinuity the order of accuracy. The order of accuracy of the linear splan, basically. So, what do we have to pay? Because there's no free meal for introducing the non-linearity. So, what we are going to pay is that around the discontinuity, we will have an accuracy reduction belt where we will have O of H accuracy, order one. Okay, but this is fine because before in the linear approach, we didn't have. In the linear approach, we didn't have even order one. We had completely lost the accuracy due to the oscillation. So another good property of this approach is that the generalization to any p or even to any order of or to any number of dimensions is very. Dimensions is very easy and also very easy to program because what we are doing is to introduce the non-linearity in the PPS plane base. So that means that we are only multiplying this PS plane base by something, by a function. Okay, so how do we usually go to higher dimensions in this kind of quasi-interpolation operators? We just obtain the expression in several dimensions of LP and the Of LP and the BS plane base in several dimensions too. So finally, what we do is obtaining something similar to what we had at the beginning. We have an LP operator times a PS plane base. Both of them are in several dimensions, but never mind. We introduce here the C function that I have explained before and a smoothness indicator in several dimensions. And a smoothness indicator in several dimensions, and that's all. We have a quasi-interpolation operator in several dimensions that is non-linear, that is capable of adapting to the presence of discontinuities. So let's go to the numerical experiments, and here I present the results for a smooth function. It is a polynomial of higher degree than the degree of the quasi-interpolation operator that we are using. That we are using. And you can see that for all the FC functions, we recovered the numerical accuracy that we were expecting. We measured the numerical accuracy through this formula in the infinity norm. So for P equals 2, we recover order 3, and if we go to higher ps, we recover the expected numerical accuracy. Order 4 for P. accuracy order four for p equal three order five for p equal four order six for p equal five okay so now we can check the numerical accuracy close to the discontinuity to see if it agrees with the numerical result sorry to with the theoretical result that i have presented before about the reduction of the accuracy around the discontinuity and in the interval that is just adjacent to the one that contains the discontinuity Ascent to the one that contains the discontinuity, we obtain always order one for any p. p equals two, three, four, or five present the same numerical accuracy. So this is what we have to pay. So anyway, here I present the results for the function that I have shown before close to the discontinuity. And you can see here that we have a smallest accuracy in the interval. Mallest accuracy in the interval that is close to discontinuity. The purple line is the result of the linear algorithm without modifications. So you can see that depending on the C function that we choose, the sharpness of the reconstruction is greater or smaller. But we get rid of the oscillation that we get in the linear approach. So for NEP, it works more or less the same. More or less the same. We can also go to 2D. We define a piecewise continuous function. In this case, it is inside and out and outside a circle. And we can see for the linear case, this is the approximation, this is the error, that we obtain oscillations close to the discontinuity and we get rid of them for the non-linear approach. The non-linear approach in any of the PCs that I have presented before. Okay, so why don't we go to 3D? We can also do it very easily. So here I presented the same, a similar experiment where we have a piecewise defined function inside and outside a sphere. And for the linear approach, you can see that there are high frequency oscillations here close to the discontinuity. I didn't mention, but this is a as Did I mention, but this is a as we have a three-variate function, this is an approach of the function in space. So the plot here is a slice contour plot. So what we do is just take slices of the result and each of them is a surface. So we just plot the contour plot. Okay, so basically what we want to check if we get rid of these oscillations around the discourse. Around the discontinuity surface. And you can see that here those oscillations have disappeared, and in the other approaches, more or less the same. Okay, so now we ask ourselves if it is even possible to get rid of the smearing that we observe here, the smearing of the discontinuity. So, we proposed another different solution that is the introduction of correction terms, that is more related to what Dr. Li does in the immersed interface method. Okay, so basically the idea here is that we have a discontinuity. We know or we can approach with enough accuracy the position of this discontinuity and Of this discontinuity, and we can also approach, or we know, the jumps in the function and the derivatives of the data at the x start, or of the original function at x start. So we can try to, in this case, we can try to have a look to what is the contribution of each of the VS plane bases to the global approach, to the global approximation. The global approximation. So, for example, here we have for p equals 3, which is a cubic BS plane. We have four intervals for the support, and each star can fall in any of them. So, in this particular case, I have labeled the data to the right of the discontinuity as a plus, and to the left with a minus. So, if we have a look through If we have a look to this particular use line and we are interpolating, approximately to the right of x star, we can see that the value at xm plus 1 from the LP operator belongs to the right side because we are approximating around here. But the other two values belong to the minus part. So it would be nice if we had an expression of the values f at xm minus 1. f at xn minus 1 and at xn, if we had an expression to write their values from the minus side in terms of the plus side, so that we could include in the approximation the local truncation error introduced by the presence of the discontinuity. So if we do that, if we do Taylor expansions of the F plus value, F plus value and the prolongation of the value from the minus side at the xn plus one. If we do Taylor expansions of those two values around x star, we obtain these two, well, these two expressions. And if we just subtract them, we obtain this expression where we can see the expression of f m plus one in terms. Of fm plus 1 in terms at the plus side, in terms of the minus side plus all the jumps in the function and the derivatives. So, basically, what we are going to do is that in the cases where fm plus 1 belongs to the wrong side of the discontinuity, we will use these expressions to express them in terms of the other side of the discontinuity. So, for example, here we would express this value and this. Would express this value and this value in terms of the plus side if we are approximating around here. But if we are approximating here, this value is on the wrong side of the discontinuity, so we would try to express it in terms of the minus side. That's basically the idea. So if we do that, we are capable of giving a lemma where we express the support of the VS plane as the uno of the four different internet. unum of the four different intervals where we can where we want to obtain the correction terms and just collecting the the the jumps in the function and the derivatives we get the the correction terms for for each case this can be done for p equal two for p equal three or any p in the article we present the expressions only for p equal two p equal three okay so these are the expressions of the correction terms that we will use in each of the cases That we will use in each of the cases that I have mentioned before, in each interval, depending if the discontinuity force on each interval of the VS plan. So, doing that, we can just introduce the non-linear VS plane LP operator that would be the classical one plus the correction and the associated non-linear operator. Okay, and we can find. And we can finally give a theorem that we prove that even close to the discontinuity, we recover the accuracy of the linears by introducing the correction. So basically in the numerical experiments, what we saw is that the full accuracy is recovered even close to this continuity. Here we have recovered a pinch-wise continued function and on the other side. And on the other side, here we have the linear, the results of the linear approach where we can see the oscillations and the smearing. This is just a grid refinement analysis to check that the accuracy of the method is in agreement with the theoretical results. Here we have for a quadratic polynomial a decaying of Of three. We have basically O of H2ICAC. The same thing for kings in the function. We recover the, of course, the king and here the linear result. And this is the same thing. We refine an analysis to check that. We also can go to two dimensions or Dimensions or even higher dimensions, but the problem here is if you are approximating the location of the discontinuity, you have to be accurate. So, the problem is to have a good algorithm for detecting and locating the discontinuity. If you have that, you can do it. And this is the result in our case. Here, you can see that we obtain a very small error in comparison with the error obtained by the linear algorithm. And also, you can Algorithm. And also, you can see here the oscillations close to this continuity. This has been done using a tensor product approach. That means that we are processing the data in a one-dimensional fashion, by rows and then by columns. So that's basically all that I wanted to show you. So finally, the conclusions and the outlook. We have presented here. We have presented here two ways of including nonlinearity. Both of them have advantages and disadvantages. For example, the Wino algorithm has a reduction accuracy belt around the discontinuity. Of course, both of them avoid the Gibbs-like oscillations. The win algorithm is very simple, even in the programming, it is very simple. And the corrected VS flying. The corrected VS flying recovers the full accuracy, but the problem is that you need to know an accurate, at least an accurate approximation of the position of the discontinuity and the jumps in the function and the derivatives. And in the present times, what we are trying to do is to extend these ideas to mesh-free methods. That means that instead of having a mesh, we just have sparse data over the domain, and we are trying to. Domain, and we are trying to work on that. And that's basically all. Here, you have some references if you are interested. And that's all. Thank you very much for your attention.