So this is Nguyen Chen and I'm going to present a sort of organization for the MNL model with repeated customer interactions. And this is a joint work of my student, Ming Gao, and also his student. And yeah, so it's a good work. So the study is motivated by Stitch Fix. As someone who just grabbed stuff from Costco, I wouldn't have heard of it, but I have to decide now. They actually have a very interesting business model. So essentially, if you subscribe to their service, they're going to send you a box. This, they're going to send you a box of clothes, usually four or five. You can decide frequency: every two weeks, every month, and the customer can pick one of it or like pick none and return all the box. So, they do it repeatedly, right? Every two weeks, they're going to send you a box of clothes, and the customer picks one, and then goes on and on. It's apparently a quite successful business. They went on IPO in 2017 and has more than 5,000 employees. And for our purpose, we're going to For our purpose, we're going to talk about the sort of monopetization, meaning that how do I choose the clones in each of the blocks? And if you compare this with classic assortment monophonization, you can easily see there are a bunch of differences. The first one is in classic assortment optimization, there's a single interaction. The customer comes, they pick one product or none, and then they leave. The problem is ended, that's stop-ended. In our case, they're repeating interaction. And because repeating interaction, it induces a few other. Induces a few other implications. One is that in the classic assortment organization, the customer chooses one product, while in our case, the customer would choose at most one product in every interaction, in every period. And one sort of further implication is that in a classic assortment problem, there's no learning. In our case, there's learning. And the learning here, there are multiple ways to interpret it. It could be machine learning, like statistical learning. You look at people's customers' costs. People's customers pass the purchase history and then formulate a covariate and then do some machine learning. Or you can do online learning, right? Learn their preference and apply social time. But in our case, we're looking at even more fundamental methods. There's no machine learning, no online learning. The learning here, we're just going to learn the realization of a random utility in the random utility model. Okay, so because over time, assuming the customer's utility are not changing over time, I can form a conditional probability and update. And form a conditional probability and update their preference over time. So let me first give the model over time. Just a quick clarity. So by learning, you don't mean the customer learning their preferences over time. But rather, the customer preferences are static, the firm has less chance to fit. Exactly, exactly. So the model overview is going to show this, but essentially, the customer arrives, they draw their random utility, and they are fixed over time. But from firms' point of view, they need to have an You need to have an updated conditional probability for those. So the model overviews: a customer arrives, they have a utility for each product. They are generated from a Gambler distribution, unconditionally. And the no-purger option is also generated with the location parameter zero. So once they're generated, they're fixed. And over time, in each period, what the firm observes is that What the firm observed is that a firm would offer an assortment, SM. So I use the square bracket to show that it's a sequence of offered assortments. And there are also observed choices. The choices could be zero or any one of the product. And if you look at history, the history actually can be written down as this intersection of events. In period I, the customer's utility for product CI is higher than every other utility offering. Every other utility offered in the same set. And then we're going to use this event to form our conditional choice probable. And then, right, this is the conditional choice properly. Then we're going to solve the sort normalization problem here at M plus 1. So the products are the same at your? Couldn't, that doesn't have to be the same. It could be the same, could be different. But we're going to look at those two extreme cases later on. So then the first question is, is it even solvable, right? Because if you can't. Solvable, right? Because, like, if you cannot write down the choice probability in a closed form, then game answer. You cannot do anything about it. So, now let me go to the literature. Again, I think more than 70% of the paper are actually from the audience here. So, one of the stream literature is random consideration set in which a customer arrives and they will form a random consideration set based on the placement of the products. It's similar to ours in the sense that the customers may look at. The customers may look at multiple pages, say, of products, right? But then, in this case, there's only one purchase being made. And another stream literature is multiple purchase models, like the one she just presented. And then the problem, the difference is that we are looking at not just one interaction. In this case, it's one interaction. You form a static choice model for the multi-product case, and then there's no learning. The one that's probably closest to what we're looking at. Probably closest to what we're working on is the sequential ML model. So, those four papers, they were the sort of essentially speaking, the sequential ML model is saying that each period, the firm is offering an assortment, and then customer picks one product according to the M ‚Åá L, well, either pick a product or don't pick anything according to the ML model. But in this literature, usually what I think all of them look at the case that the customer only proceeds when they don't. The customer only proceeds when they don't pick anything. When they pick one product, they quit the platform. Okay, so eventually there's only one purchase. And another one is that there's no updating of the random utility. So this paper in 2021, it's a similar setting, but they update the no purchase option. So if the customer only picks one product, and most one product, then over time, you only need to update the no purchase option. Because all the product in the previous period, In the previous periods, if the customer didn't pick it, it means the utility is lower than the no-purchase option, then I don't need to include it in future periods. So the learning is only for the single no-purchase option. And there's actually no adaptive assortment, meaning that if you look at the outcome, it's a binary case, right? But the binary in the sense that it only proceeds when there's no purchase. So when there's one purchase, the customer quits the platform and you don't need to offer a Platform, and you don't need to offer adaptive sort in that sense. So we change, like in our model, it's different from the Sakai Sharma model in those two regards. So now let's look at... So your model is like the opposite. If you buy, you move on. If you don't buy, you can also move on. Oh, okay, okay. Yeah, so it's just sequentially offering the choice, the soil ones. So let's first look at the two-periods model. Okay, we always start sample. So in the two-period model, in the first period, it's very simple, it's just standard MM. Is very simple. It's just standard M and I, right? So it's uvi divided by 1 plus V S1. So S1 is a sort and offer period 1. And we're going to use some of the notations over and over, so I will introduce them here. So V of S is the sum of the V i's in the assortment, and Vi is the exponentiated utility of each product. Okay, so now let's look at Pier 2. So in Pier 2, it's a function, the choice probability is a function of. The choice probability is a function of I, which is the chosen product in period 1, S1, offered assortment in Pier 1, and S2, the offered assortment in period 2. And there are three cases. In the first case, the customer ended up buying nothing in period 1. So this is the same case similar to the paper in 2021. And you can see that actually there's a very nice form, meaning that basically the no purchase option is inflated. The no-purchase option is inflated. Because in the first period, the customer didn't buy anything. It means they have you inflate their no-purchase probability. And it's inflated in a way that the no-purchase option basically combine all the other options in the first period. So they inflate it from 1 to 1 plus V of S1. And it's still ML model. But the only difference is that if you offer a product that's in the intersection of S1 and S2, the purchase problem is zero because they have been shown to be. Because they have been shown to be worse than the no-purchase option. Okay, so that's case one. Case one is simple. Case two is similar to case one, in which the customer purchased some product in the intersection of S1 and S2. And in this case, because you can interpret no purchase option to be always in the intersection, right? So it's a similar scenario in which the probability is inflated. So the no purchase. Inflated, so the no purchase option is inflated, but the everything. Oh, I think I it should be V up. So yeah, so this slide I need to modify, but essentially you inflate the product that's been picked and deflate everything else in that sense. I need to modify the slide, sorry about the typo. The third case is a little bit more complicated. So, in the third case, the customer picks some product that's Picks some product that's in S1, but this product is not in S2. So in this case, everything in S2 is deflated, right? And they're deflated in a way that can be written in a closed form. So that's actually quite surprising because you need to massage the property, the CDF of gamma distribution firewood. So if you look at a product that's in the intersection of S1 and S2, this would be their unconditional purchase probability. And you Purchase probability, and you deflate it with a fraction in the front. The same goes for the no purchase option, they're deflated. But now everything in the set that's in S2, in the set in S2 minus S1, they are inflated, right? Because everybody else is deflated, so they are inflated. And if you look at the form, it may look a little bit strange, and you may wonder: do they even sum up to one? I can guarantee you they do sum up to one. One. I can guarantee if they do sell it to one. So it's a sandy chat, right, to have. So this is the purchase probability, but this is only the middle of the story, because we need to solve the sort and optimization, meaning that S2 need to be decided. And it's not given. Quick question. So the condition random utility is not component distributed anymore. Say again? It's not. It's not component. Do we know anything about those condition random distributions? Think about those condition ones? So you can think of it, it's basically whenever you choose a product, right, you have a polytle in the valuation space, and it's a conditional probability of gumbo inside that polytale. So yeah, it's not gumbo. It's not gumbo. So the assumption here is that a customer has a total ordering, right? Like because at time t equals zero, they sample these utilities. They sample the data, right? And they stick to it. Stick to wing forward. So, and over time they reveal these partial orders based on the realization. Right, and then eventually you want to compute this conditional distribution given all the partial orders. Yes. Is there a two-period problem which can be done? Yeah, exactly. Exactly. Yeah, I had a related question. Like, is it easier to perhaps think about instead of looking at CDFs with couples, just thinking about, okay, the A priority. Just thinking about okay, the A priority, using the Placket Blue J interpretation, right? A priority, they have some distribution of lists induced by the MDL. And then when you see something, you can cross off some of the lists from the... It's possible. Yeah, we haven't tried the conditional probability of that model. It could be trackable, but it couldn't. No, I mean, yeah, I was going to say, so one of our previous videos, that's exactly what we do. So we do fact-based and minimal model, where we compute the conditional probability using the fact that it gives you a little more tractability. Gives you a little more tractability than having to worry about the contribution of the conditional thumb level. Okay, okay, that's a good point. Yeah, we haven't thought about this before. We'll look at this as a sea. Yeah. I think probably basically what happens is, yeah, over time you get a DAP. And then what you want to do is you want to compute these conditional probabilities conditionally data. Of course, one complication in practice is you may have cycles. So that's how you come to be an architecture. Yeah, yeah, yeah. No, that's a good question. Yeah, yeah, yeah, no, that's a good point. Essentially, what matters is order here. So, Gambo basically embeds order into a specific problem or structure that can be solved in a two-period model, not more. So, now let's look at the conditional assortment optimization problem for period two. So, the first case, there are multiple cases. The first case, there's no purchase in the first period, i equals to zero. This is the simple case, because we don't have to do any case discussion. So, you just look at because. You just look at because you would only offer the product in the set minus of S2 and S1, right? Other products will not be chosen anyway. So you can write down the probability, write down the revenue function. It still looks like M and L. So basically you replace 1 by 1 plus BS1, but they are both still exogenous. They are given. So it's still M and L probability and it's red water, right? So it's a very simple implication of the theoretical result. Of the theoretical result in the literature. For case two and three, so here we're doing case discussion. So know that we have to decide S2, but there are two cases, right? S2 could include I or it may not include I. So I'm separate the two cases. If S2 includes I, I can write down the expected revenue and the decision S2 is here, W S2 and VS, so W, maybe I introduce, so W is basically sum of all. So, W is basically the sum of RI and VI in the assortment. And it still looks quite a little bit like M and L, right? The only difference is that you have another term here. And this is no problem because we can show that they have the same structure, meaning in this case, you, of course, you are forced to include I. But besides I, you're going to include a revenue order subset of N2 set minus S1. Okay, so this is just saying keep I there, and I'm going to. Saying, keep eye there, and I'm going to pick a revenue order assortment in the offer in the universe of products in the second peer. The third one is more complicated. The third case is that I is purchasing peer to one, but S2 does not include I. So the expected revenue is going to be the summation of where J is inside the intersection and J is not in the intersection. intersection and yeah this problem we show some very limited structural result which is the products in s1 intersect s2 star are a revenue ordered subset of s1 intersect m2 so so the intersection part is easy to handle it's a it's a revenue ordered subset but we cannot say anything about the set minus one we don't know what products are there and we can show this problem mp hard and we developed a pdus but it's i think it's standard Develop a PDAS, but I think it's a standard technique. We discretize the space. So, case three is the case where it's very hard to solve. So, S, what is the objective function? The objective function is just the expected revenue in the second period. So, I'm now. S1 doesn't depend on. S1 is given. So, I'm only looking at the conditional solvent. Yes, that's right. That's right. Yeah, so this is the. Yeah, so this is the case one, two, three. So essentially, what you're going to do is that when i is zero, it's easy. We just look at the revenue order assortment. When s is not zero, I'm going to compute case two and case three and to see which one gives the higher revenue, and then I'm going to go for it. But in this case, case three is very hard to solve. And we give a sufficient condition in which you don't need to consider case three, but I think it's too strong. So basically, if the chosen It's too strong. So basically, if the chosen product in period one is higher than the potential revenue in the second period, then you would always include I in your second period and you don't have to consider these three. So that's basically eliminates the hard case from the problem. Okay, so this is a conditional assortment problem in the second period. Now I'm going to look at the joint assortment of passage problem, meaning that I decide S1 and S2. In this case, we were going to be looking at a special heuristic, which is a fixed assortment. So, fixed assortment basically is: I'm using, so I'm just using S1, S2 given a priori, without looking at the adaptive, without looking at the purchase product in period one. So, I'm comparing the fixed assortment against the adaptive assortment, which is the options. So, the benefit of looking at it is mostly computational because we know that unconditionally. We know that unconditionally, period one and peer two, they're just ML choice probability. So I'm going to be easily optimizing it. So I'm comparing this fixed assortment against the optimal fix. I'm first going to look at a special case, destroyed product sets. So for destroyed product sets, the two products in the two sets of product in period 1 and 2, they don't have any intersection, the intersection is empty. So in this case, the optimal assortment in period 2. In this case, the optimal assortment in period two is contingent on binary outcomes. So, in period one, I either buy something or I don't buy something. If I don't buy something, I zero. If I buy something, we can show that choice probability actually doesn't depend on what you buy. So, the adaptiveness is only a little adaptive. So, the optimal adaptive revenue depends on S1, S20, and S21. So, S20 meaning that if you observe no purchase in period 0, No purchase in period zero. Period one, what are you going to do? And S21 is if you observe a purchase in product one, what are you going to do in period two? Okay, so those are the three assortments I need to choose. And this is a revenue from period one, and this is a revenue from period two when you offer, when there's no purchase in period one, and another term is when you have one purchase in period one, and this is the revenue, expect the revenue. The revenue, expected revenue. So there are three terms altogether, and I'm trying to bound it against the revenue using the fixed assortment. The three terms, the first term is very easy. I know it's bounded by R1 star, right? Because no matter what assortment you choose in Pier 1, it's going to be upper bounded by the optimal assortment in the unconditional case. This is the second term. The second term we have. The second term, we have this thing here. I'm going to remove VS1. It's going to become WS2 plus O divided by 1 plus VS2, and that's going to be our R2 stop, right? Because this is the M ‚Åá L revenue, and I can bound it using the MNL revenue second period. And the third term here, it's a little bit complicated, but I can always extract this term here because I always want to compare it to R2 star. And what remains is this 1 minus. And what remains is this one minus a bit of uh fractional term. And for the fractional term, I can, well, v of s to one is a bit of trouble. So I can remove v of s to one, and this term actually can be reduced to one over one plus vs1 squared. That's good, because now I have vs1 here, I have vs1 here, it's a quadratic function, I can just maximize the quadratic function, and this is going to give me a bound, which is. Which is 504. Okay, so we can show it's tight by constructing an example. So, in two-period models, when the two sets of products don't intersect, the bound of the fixed assortment is, well, it's 25%. That's a bound. And now I'm looking at another extreme case in which, in the two periods, the product sets are identical. That's the extreme case. And in this case, you can see that the adaptiveness actually. The adaptiveness actually bifurcated quite a bit because, in the first period, you can be choosing one of the products, and depending on what you choose, because this product is still in the second period, you have a full range of contingency, right? But interestingly, the problem is actually very easy to solve because we can show that, this is basically the structure of the optimal assortment. We show that in the first period, you are going to offer a revenue audit assortment, and this A revenue-ordered assortment, and this revenue-ordered assortment is a subset of the revenue-ordered assortment of the unconditional MNO model. Okay, that's for the first period, so enumeration for the first period is sufficient. And in the second period, it's even easier. If the customer chooses something, I'm just going to offer this single product. And if the customer doesn't choose anything, I'm going to take all the products that's not in the first assortment and its revenue on. Assortment and its revenue order. So it's basically two-stage revenue-ordered scenario in the worst case, right? So you can enumerate it, it's not hard to compute. But we can still show a bound. The bound is actually quite simple to show. We show that the fixed assortment gives you 50% slightly lower revenue, and it's tight. And if you compare this 3 over 2 to the previous one, 5 over 4, it's slightly worse. I think it's. It's slightly worse, and I think it's probably coming from the more adaptiveness in the problem, like because there are more choices to make after the first year. So, now let's look at the general case. Five minutes, I should have enough time. The general case, it's really not tractable. So, we try to write down the choice probability. In certain cases, I can't remember, it's identical assort. I think it's probably the disjoint case. In the disjoint case, we can write down the choice probability. You can see that it's basically an up and down. You can see that it's basically an up and down update of U0, right? When the customer purchased something, U0 goes down. If the customer didn't purchase anything, U0 goes up. So the depth is the conditional probability is only for the no purchase option in the disjoint case. And we can write down the choice probability, but it's a huge sum of things. It's not really, I mean, it's a closed form, but it's a huge sum. So we will basically look at, again, the performance. Again, the performance of the fixed assortment. Try to get a bound of the fixed assortment against the optimal adaptive assortment. Okay, so first look at destroy case. The destroy case, as I've explained, you only need to learn U0. You're not learning anything else because whatever product you offer in the previous periods, they're not there, right? And you learn nothing. So you only learn U0. And because you're learning U0, the best. And because you're learning U0, the best case scenario for RA is that you know U0. If I know the realization of U0, then it's sort of better than any adaptive assortment I can have, because I just know U0. In this case, I can write down, so given U0, I can write down the expected revenue. I think that's from, I should have put the reference here, it's from Argus paper in Amsterdam. And I can write this as a function of S and U C. A function of s and u0, right? Give me the realized value of the no-purchase option, what's the expected revenue for the assortment. Now we keep going. I want to bound this with the fixed assortment, the fixed assortment. So I just take the ratio. I'm going to take the ratio of this one against the fixed assortment. So you can see that WS would cancel out, right? Because the fixed assortment revenue is Ws over 1 plus VS, and you end up with a And you end up with a term that's 1 plus Vs over Vs, 1 minus e to the power of minus U0 and Vs. So this is my ratio. There's two uncertainty here. There's two unknown quantities here. One is U0, one is Vs. Vs, I'm going to look at the worst case. U0, I'm going to take expectation. Because a priori, U0 follow the Gumbo distribution for the no purchase option. So what I'm going to do. No purchase option. So, what I'm going to do is that I'm going to look at the worst case for Vs, and this will give me alpha u0, and I'm taking expectation of alpha u0. And I mean, there's some numerical stuff going on, like we need to approximate the integral, things like that. But we can essentially get a bound that's 3 times e to the minus 2 plus 1.054. And the value of this is roughly 1.4 something. 1.4 something, 1.4. So that's the bound against the fixed assortment. And we can construct a case that the bound is 1 plus 1 over u. I think that's roughly 1.3, 1.35. So that's the case for the disjoint case. So when there's a disjoint product sets, I can use a fixed assortment, which is very easy to solve, and the bound is a join 1.3 and 1.4. The last case, so the last case is when there So, the last case is when they're general cases. So, the products are not necessarily disjoint. They may overlap, they may be identical, they may be anything. And I'm trying to get a bound for the fixed assortment. So, in period M, let me first re-index things a little bit. So, let's say the products 1, 2, 3, all of which NM. So, I know that index could be confusing because, but I'm just looking at this period, so I think the confusion is limited. I think the confusion is a bit. So they're one, two, all the way to nm products, and they are ordered by their revenue. So in this case, again, I'm trying to get an upper bound for the potential adaptiveness. And the upper bound is that when I know all of UI, right, that's the best you can get. When I know all of UI, what's the optimum assortment? Well, if I know the realization of their random utility, I'm going to offer the most expensive product that's above View zero. Above U0. That's the case. So if you look at this revenue, so again, I'm going to use this revenue as an upper bound for the adaptive assortment and then upper bound this with the fixed assortment. So if you look at the expected revenue for this scenario, when I know UI and I can provide an assortment like that, and then I'm taking the expectation over UI, it's going to be R1 times probability UI. R1 times probability U1 greater than U0. So this is a case when the most expensive product is above the no-purchase option, then I'm only offering U1. And then this is a sum of, basically I'm enumerating all the cases where product I is the most preferred. I'm taking expectation of that case. Okay, so this is the expected revenue for this clairvoyant firm. And I can write it down. So this is basically. So, this is basically ML manipulation here. I can write down the probability in a closed form, and there are a bunch of VI and RI. I want to convert it into W and V. So the first term is W over 1 plus V. And the remaining terms are, it's kind of strange because in the denominator, there's two V terms together. In the numerator, there's a difference of the W. And then it's a little bit like telescoping, but it's telescoping. Little bit like telescoping, but it's telescoping of two terms instead of one term. So I can take out one of the W here, and then the telescoping is like every two terms, it's like staggered terms. And then I'm going to bound those terms using the R, which is the fixed assortment revenue of that period. And what remains is a bunch of differences, and you can cancel them out. There are only two terms left. And for those two terms, I can use two to bound it. I can use 2 to bound it. So we can show that in this case the value of the fixed assortment is 2, 100% worse. And then the bound is also tight. But it's tight in a synchronic sense. When you have infinite periods, I can show an instance that the fixed assortment is exactly 100% worse than the adaptive assortment. So that's the end of the talk. Hope I'm okay with the time. Hope I'm okay with the time, and I thank you all for talking. Thank you. So we have a minute for questions.