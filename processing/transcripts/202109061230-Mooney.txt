And what I'll talk about is partly a joint work with my student, Yang. So, to begin with, let me recall the result of Bernstein from the early 1900s. So, Bernstein proved the following remarkable results. Bernstein proved the following remarkable result, which is that if you have any solution to the following nonlinear PDE, divergence of gradient over square root, one plus gradient squared is zero in all of the plane, then this function u has to be a linear function. So, I'm sure everyone in the audience recognizes this equation as the minimal surface equation. It says that the graph of U is the minimal surface in R3. And what this theorem is saying is that if you have any, let's say, minimal surface in R3 and it has non-zero curvature at some point, and you try to write it as a graph over the tangent plane at that point, then eventually this graph has gradient blowing up. You can't write this as a function over all of R2. And this result is, I think, surprising for a number of reasons, but one of them is that one can view the minimal surface equation as the geometric version of the Laplace equation. So it says that the sum of principal curvatures of the graph vanishes everywhere. And the principal curvatures are geometric analogs of eigenvalues of the Hessian. And on the other hand, we know there are many, many nonlinear global harmonic functions. You take the real part of any holomorphic function. So this is a case where the nonlinearity So, this is a case where the nonlinearity lends rigidity. You don't need to assume anything about the growth rate at infinity to get a rigidity result. And the Bernstein problem asks whether this same theorem holds in higher dimensions. So, extend to higher dimensions. Okay. Okay, so the problem with attempting to extend Bernstein's original proof to higher dimensions is that it relied on the fact that he was working in two variables very heavily. So one issue is that Bernstein's proof is very 2D. Because the proof is extremely beautiful idea. proof is extremely beautiful ideas. I'd like to briefly recall how the two-dimensionality is used. And the first place it's used is the following. So if you look at, let's say, the graph of u, I call it sigma, and you look at the unit normal to the graph, they'll call this new. And the fact that sigma is a minimal surface implies that Minimal surface implies that ν, which you can view as a map from the surface to the unit sphere, is a conformal map. So minimal surface equation implies that nu is conformal. And the phase of any conformal map is a harmonic function. It's like the imaginary part of the log. So. So, one could conclude if one takes the appropriate ratios of components of ν that the inverse tangent of a directional derivative of u is harmonic on the graph. This is the first place where two-dimensionality is used, some sort of idea. Two-dimensionality is used, some sort of ideas from complex analysis. And you know, morally speaking, if we have a bounded harmonic function, we expect it to be a constant, but of course, we're working on a geometric object right now, so it's not so clear. And the second thing Bernstein proved, which is on its own extremely interesting, is that if you have any bounded saddle function on all of R2, it's constant. And this is a bounded saddle function. So the eigenvalues of the Hessian are. The eigenvalues of the hash are mixed. So second thing he proved, which is totally independent, is that any bounded stadle function on R2 is a constant. So, as a result, all the directional derivatives. All the directional derivatives of u are constants and u is a linear function. And this theorem is proved using a topological argument. More precisely, it uses the fact that if you have any two-dimensional surface in R3, which is saddle-shaped, then the tangent plane to this object splits it into at least four. Splits it into at least four disconnected components that go off to infinity. You can think if you look at a tangent plane to the graph of a tangent inverse of ue, then it cuts the graph into at least four pieces. Maybe the function lies above there and below there. And these extend off to infinity because if they closed, you would violate the maximum principle, which holds for saddle functions. I don't want to go into detail there. So that's the key observation. So that's the key observation. It's not at all obvious how to use it to prove that bounded saddle functions are constants, but this is crucially used. Okay. So Bernstein's theorem had a very two-dimensional proof. And it wasn't for a long time before people came up with a new idea that had a hope of generalizing the higher dimensions. And this breakthrough was made by Fleming in the 60s. So, Fleming in 62, he introduced the use of a new tool, the monotonicity formula, which says that minimal surfaces in any dimension or co-dimension resemble cones at small or large scales. And using this, he proved that if there exists a nonlinear global solution to the minimal surface equation, any dimension, then there would have to exist an area minimizing hypercone in the Hypercone in the number of dimensions in which the graph exists. So if there exists a non-linear global solution to the minimal surface equation, then there exists an area minimizing hypercone. So I'll call it K. Let's say I'll call it k in Rn plus one. So, roughly speaking, if you have a nonlinear global solution and you begin to zoom out again and again and again, you see a conical structure emerging. And by taking an appropriate subsequence, one can conclude the existence of a limiting cone, which is area minimizing. And this gave a new proof in the case that is equal to 2. Roughly speaking, because when you have a cone, one of the curvatures you don't care about. One of the curvatures vanishes. So if you have one homogeneous object, an R3, then the radial curvature is zero. And because the sum of principal curvatures vanishes, the other one would have to be zero and you'd have to be flat. And from that point, the problem, the full Bernstein problem for minimal surface equation, was solved pretty quickly. So in 1963, DiGiorgi observed that this hypercone K has a special structure. It has a cylindrical structure, which comes from the fact that you're dealing with graphs. K can be written as a cylinder over an area minimizing hypercone in Rn. As a result, he gained the dimension. So he proved the Bernstein theorem in dimension n equals 3. And from there on out, the problem was reduced to proving whether or not there exist area minimizing hypercones in dimension N. So all the focus was on this issue. And a few years later, Aumgrin proved, say, gained one more dimension by the study of area minimizing hypercromes. Umgren in 66 proved that if you have, in fact, a stable minimal hypercone, so stable minimal cones are flat in four dimensions. We use the so-called stability inequality for minimal surfaces, it's just as that they're area minimizing under. Area minimizing under tiny perturbations. And as a result, the Bernstein theorem follows in 40. And then Simons extended this to higher dimensions via a more delicate use of the stability quality. So the same result in seven dimensions. Seven dimensions. And finally, one year later, Bombier de Giorgi and Giusti, in a remarkable paper, constructed a counterexample to the Bernstein theorem in dimension eight. They have a counterexample. Bernstein in R8. And this is deeply related to the existence of a non-flat area minimizing hypercone in dimension 8. So the cone over S3 cross S3. Because of time limitations, I don't want to go too much into this. I'll just say that their example has cubic growth at infinity. All right. So, this completely solved the Bernstein problem for the area functional. And now I'd like to turn my attention to a class of functionals which includes the area functional as a special case, but arises naturally in some geometric and applied problems and motivates the so-called Phi-Bernstein problem. So, in this case, we're again interested in hypersurfaces in Rn plus one sigma and Rn plus one hypersurface. And let's say it's oriented, so it has some choice of unit normal. Which again will call new. Call new and we're interested in critical points of functionals which weigh the area element depending on the direction of the tangent plane. So let's say for a function phi, a function Rn plus one, say a sub phi of the surface sigma is the integral is the integral of this function phi of new dA and the natural structure conditions that one asks for this function phi are exactly what gives you a decent say there's some convexity conditions which give you a decent existence in regularity theory for minimizers so phi is going to be a one homogeneous function Let's say positive on the sphere, and we'd like it to be uniformly convex or locally uniformly convex when restricted to hyperplanes that don't go through the origin. So, say the one level set of phi is uniformly convex. And such functionals are known as parametric elliptic functions. And they arise in several contexts. For example, if one is studying surfaces which favor facing certain directions over others. So for example, if one observes crystal surfaces, you'll see facets form. Crystal surfaces, you'll see facets forming and a tendency for certain faces to have unit normals in one direction versus another. Then, these types of functionals are useful models. So, it's interesting from the point of view of applied problems, but also I think it's very interesting from the point of view of pure mathematics. And the reason is that such functionals do not have a monotonicity formula. And anytime you manage to prove some result for critical points or minimizers of such functionals, Critical points or minimizers of such functionals where you can't rely on a monotonicity formula, it can give you new insights as to what's happening in the minimal surface case, more robust proofs. So that's some motivation for looking at such functions. And the natural question then is, if you have a minimizer or a critical point of this, such a functional, which is a graph of a function, then can you say something about global solutions? Global solutions. So, before I state what the Fei-Bernstein problem is, let me say a few words about what the Euler-Lagrange equation of this functional is. So, if you take the first variation, which you get, so if sigma is a critical point, then the equation you get for the hypersurface is that. Get for the hypersurface is that the trace of the Sehession of Phi and the second fundamental form of sigma is zero. So in the case that phi is exactly one on the unit sphere, the Hessian of Phi is the identity matrix, and this reduces to the sum of principal curvatures being zero. Of principal curvatures being zero, so the familiar h is equal to zero, or mean curvature vanishing for the area case. And in the more general case, this is a sort of positive weighted sum of principal curvatures vanishing. And the reason is that the convexity conditions imply that the eigenvalues of this matrix are between positive constants. So one could view this as a sort of a geometric version. View this as sort of a geometric version of the PDEs that were studied by De Maury and DeGiorgi and Nash in the solution of Hilbert's 19th problem, where the Hessian of the function under consideration is replaced by the second fundamental form of the geometric object. Now, if this, say, set sigma or this hypersurface sigma is written as the graph of a function, we can rewrite the PDE in a convenient way. function we can rewrite the PDE in a convenient way or rewrite this equation in a convenient way sigma is the graph of a function u then this equation is the same thing as a variational equation with a familiar form so phi ij at gradient u uij is equal to zero Is equal to zero. And this function little phi is the function you obtain when you restrict the values of capital phi to the hyperplane tangent to the north pole. And because capital Phi is one homogeneous, one could think that little phi is asymptotically one homogeneous. And that means that some of the second derivatives of little phi are very large compared to others. Some of the radial second derivatives of little phi are very small compared to the tangential ones. And so this is not a uniformly elliptic equation. And the ellipticity degenerates in a way that is reminiscent of what happens for minimal surfaces. We call such equations equations of minimal surface type. Equations of minimal surface type. And the Phi-Bernstein problem asks exactly what you would expect. Can one classify the global solutions to equations of minimal surface type? Okay. So before I state the main results of the talk, I'll state what's known about the five-Bernstein problem. First, what's known in the case of two dimensions is that the Bernstein property does indeed hold. This is a theorem of Jenkins from early 60s. He showed We showed that in dimension n equals 2 global solutions to equations of minimal surface type are linear functions. And this proof by Jenkins was again inspired by complex analysis. So now the unit normal to the graph is no longer exactly a conformal map, but it's a quasi-conformal map. And there's a very well-developed say regularity theory for bounded quasi-conformal mappings. Okay, but when one sees, say, a result about elliptic equations in two variables, it's not at all clear what. Of two variables, it's not at all clear whether it's supposed to extend to higher dimensions because, as we've seen, two dimensions is extremely restrictive topologically and energetically. But something surprising for equations of minimal surface type is that the Bernstein theorem also holds in three variables. This is a theorem of Leon Seineman from 77. So, same in dimension. n equals 3. And I don't have time to say much about Simon's proof, but I will say that it's significantly more difficult than three variables. And it relies on a regularity theorem of Almgren, Shane and Simon for minimizers of the parametric problem. This is quite a difficult theorem. Okay, but now that one sees this theorem holding in dimension three, it's natural to ask: okay, well, maybe in fact, this result that holds for minimal surfaces where there's this magic dimension seven, or critical dimension where the behavior of global solutions changes. Maybe that's not actually a result of the conical structure or monotonicity formula. Maybe there's a different way of proving this. A different way of proving this. And so the question of what happens between dimensions 4 and 7 remained open. And the main results, I'd like to state, take steps towards closing this gap. So I say dimension seven. Well, in dimension eight, there are these Bombier de Giorgi Giusti counter example. Georgi Giusti counter example for the special case of minimal surfaces. Okay. So the first theorem shows that in fact one could construct non-linear global solutions to these minimal surface type equations in lower dimensions than for the minimal surface case. There exists a non-linear. Exists a non-linear global solution to an equation of minimal surface type in R6. And in fact, this solution is a quadratic polynomial. Okay, so this theorem says that indeed when one relaxes the isotropy of the functional, it is possible to build these funny nonlinear global solutions in lower dimensions than before. And maybe one other smaller remark. So this example happens to be a polynomial. An interesting open question is whether or not there exists nonlinear. or not there exists a non-linear polynomial that solves the minimal surface equation, perhaps in a very high number of dimensions. It sounds to me like it has a very, this problem has a very algebraic nature. Okay, so that's the first result. And that leaves open the cases of n equals 4 and n equals 5. And the second theorem I'd like to state, which is joint with Yang. So maybe this is theorem 1. Maybe this is theorem one, theorem two. Is meant to give convincing evidence that there exist nonlinear global solutions to equations of minimal surface type in the lowest possible dimension n equals four. So the statement is a little trickier. So let's say for all values of a parameter, let's say I'll Values of a parameter, let's say I'll call gamma between zero and one-half. One could construct a parametric elliptic functional. Exists a parametric elliptic functional such that the analog of the Simons cone in R4, so the cone over S1 cross S1. Minimizes. And for completeness of references, I want to say the fact that the cone over S1 cross S1 minimizes a parametric elliptic functional was known since early 1990s, and this was proven by Frank Morgan. 76 90 but he used a calibration technique and the point of this result with Yang is that it's a proof bifoliation which gives useful quantitative information so each side of so I'll give this cone a name maybe I'll call it C one Maybe I'll call it C one one is foliated by minimizers A Phi such that and now I'm going to be fairly vague. I'll bring this parameter gamma into the picture. I'll just draw the picture. Yeah, I'll just draw the picture. So, if this is a copy of R2 here, this is a copy of R2, and the cone C consists of the pair of diagonals, C1, 1. And the minimizers, which foliate either side, look like the following. So they're invariant under rotations in the first pair of variables and the second pair of variables. Of variables and the second pair of variables. So a leaf and the foliation. That's what I've drawn here. And the point is that as you move out at distance r along the cone, say capital R, this, you see, the leaves in the foliation approach the cone asymptotically at the rate distance to the minus gamma. At the rate, distance to the minus gamma. And the reason that quantitative information is useful is the following, is that such hypersurfaces look like level hypersurfaces of a function which is, say, a smooth function which is homogeneous of degree one plus gamma. Of degree 1 plus gamma. Leaves look like level sets of one plus gamma homogeneous functions, which have locally bounded gradient. And this is, I think, exactly the perspective that was taken by Bombieri de Giorgi and Gusti. Was taken by Bombieri, DiGiorgi, and Giusti when they were constructing their counterexample in the minimal surface equation case. So they did a very careful analysis of the Simons cone, showed that each side is foliated by minimal hypersurfaces, and they showed that the leaves approach at the rate r to the minus two. And those, roughly speaking, look like level sets of functions which are homogeneous of degree three and have bounded gradient locally. And that explains somehow the cubic growth of their example. Somehow, the cubic growth of their example. Okay, so the second theorem, I think, is evidence that there exist nonlinear global solutions in R4 to equations of minimal surface type. And it suggests that the homogeneity should be something between one and three halves, because gamma is between zero and one half. Okay, so with that, I think I'll stop my talk there because I'll stop my talk there because if I talk about the proofs, I'll go on a bit too long, and I'm happy to take any questions. Okay, thank you very much, Connor. This was a very nice and interesting talk. And are there questions? Is there anybody willing to make a question? Make a question, a remark. Okay, if this is not the case, I would like to say something because of the interest of the talk coming in. It seems that there is a new renewed interest in these non-uniformly elliptic equations, especially of related, starting to the most famous example, that's minimal surface type. So you showed that when you, if I understood correctly, you So, if I understood correctly, you showed that when you make a small perturbation around a minimal surface, then these nice stability properties are lost in higher dimensions. So it's because there could be no linear, I mean, non-linear solutions. Right. Okay, so it reminds me of some old paper by a mathematician called Harold Parks, who considered minimizers. who considered minimizers of okay when you consider minimal surface equations then you do consider what you do consider is exactly the the minimizes of the square root of one minus the the gradient square okay what he was considering he was considering the p root of one plus du to the p okay so you lose multiplicity formula exactly exactly so what happens here Exactly. So, what happens here is that for p equals to 2, you recover the minimal surface. And so, this is the typical phenomenology of non-uniform ellipticity. When you look at the energy or the functional, they look very similar, but then all the differences you are able to understand when you look at the second eigenvalue, the lowest eigenvalue, I mean, the lowest eigenvalue, the growth of the second derivatives. And there, you see a difference. And then he was able. And then he was able to understand that for a certain P, then it's okay, for other P's, they are not okay. So maybe there's a larger theory available there, which is similar to the one of you cook up when you pass from P growth to non-P growth, like in all its setting. And then there are completely different behaviors when, not when you look at the functional, that is at the growth, but when you look at the small. At the growth, but when you look at the smallest eigenvalue, so in a sense, what it really matters is the rate that the smallest eigenvalue of the curve is the rate this is going to flatten. That's the point. So do you think there is some connection with the R-canto example that is the second eigenvalue of the second variation, a small second value of the second variation is going to Of the second variation is going to flatten more or flatten in a different way. Right. So this is exactly. Please, please. Sorry, was someone. Yeah, I think this is exactly the point of this. Yeah, the approach rate of the leaves in the foliation is exactly dictated by that eigenvalue. The smallest eigenvalue, the smallest eigenvalue. So it's probably interesting. So it's probably interesting to look at all these cases and to match these counterexamples with the regularity results available because there's by now a growing literature on non-uniformly elliptic problems where what you do, you look at the rate of decay of the smallest eigenvalue infinity, which is independently of the growth of the functional that stays linear, that stays linear. So it's the way the So, it's the way the smallest eigenvalue flattens, and it's all the same circle of ideas, like in this example by Bombier, the Georgian Giusti, because the second eigenvalue tells you the rate where the foliation goes to zero. Let's say it's X square or R square or R3 or whatever. So it could be interesting to look at these connections. And in this respect, there's another paper by Leon Sai. There's another paper by Leon Simon, exactly one year before, I think it's published on Indiana, where he analyzes a larger class of non-uniformly elliptic equations, extending some results of Lagicheska and the results of some 70. They were on CPAN, I think. So, I mean, it could be of interest to expand also in a positive way and to connect your counterexamples also to these positive results. Results. Yes. Because, in fact, what I can tell is that starting from the end of the 70s, people have studied uniformly elliptic equations. And one example is the Pilaplacian, which is degenerate, but it's still uniformly elliptic because the ratio between the highest and the lowest eigenvalue is constant, essentially. So many people misunderstand that. But now there is still a lacking a black hole on all these aspects of. On all these aspects concerning non-euro from the addictive case that have been started being examined only in the last years. So I think that you could look at these things to make further connections. I'll definitely look at these works. And just so I heard you, right, you said that for some values of p, one can recover the Bernstein property. Because the idea, yeah, exactly. The idea is that if you only look at the functional, then you do. You only look at the functional, then you do not see differences because all these functions are linear. But then, when you look at the second eigenvalue, which is really the one, the point that makes a difference for regularity, examples, country examples, and blah, blah, then you see a difference. And it's a difference that you do not see when you are above the linear growth. So, when you are above the linear growth, typically you have pea growth or polynomial growth in the functional, and then the secondary. The functional and then the second derivatives they scales like p minus two. But when you approach the linear one, then the linear growth, then the linear growth is always there. And then the second eigenvalues can essentially do, and then the smallest eigenvalues, sorry, they can do whatever they like. And they probably fit your context. Wonderful. Yeah. Thanks, Rosavia. Yeah, thank you. So the So are there further questions? So if this is not the case, so I would like to thank Connor again and I would like to say that we see tomorrow. I mean, everybody, I don't know how to proceed now. Andrea, what do you think? Yeah, tomorrow we start at seven. We start. I mean, we know that. Now, how to proceed now? How to proceed now? I can think. Now, I can sing recording and then you stop recording, exactly.