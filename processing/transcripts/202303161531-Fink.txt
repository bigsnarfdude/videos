Uh started when I had time, uh wrote three papers, and now I'm probably, you know, of the people in this room, I understand these papers' fifth best talks, but but I'll talk about them anyway. It'll be fine. So matrix organizers. What's the matrix organizer? This is right. So what I'm gonna do is take a little thing. Take the general linear group. This is the group of which I'm going to take orbits. General linear group across the torus. I want this to act on the space of our band matrices. Okay. If I've got an element in the group, I want it to act on B, a matrix. A matrix, just multiplying by G on the left and H on the right. Okay, I need to put H into a diagonal matrix to make it act on the right, and since it's acting on the right, I should put that. In terms of what the orbits are, this inverse doesn't matter, but they have action. So I act by the general linear group on the left of my matrix and by a torus on the right of my matrix. And why is this nice from the matroidal point of view? Because. To view because if I take the matroid, V is a representation of a matrix on the set of columns, once you're in. So, V is a matrix, it represents a matrix in the usual way, and these two groups. The usual way, and these two group actions are things that we well know do not change the majority represented. I just like reparametrizing the out in space or I scaling a vector. These things don't change. And so if I look at a g orbit, all the matrices in it represent the same matroid. And then if I look at a, you know, if I want to deal with a closed sub-variety, I take. With a closed sub-variety, I take the closure, and so that's what the main object is here. So, I mean, in our paper, we just called it make tricks for the closure. So, I will mostly be using the notation rare papers in which this thing is called X, but we can also, it has a dependence on V, so we'll record that. And so it is. Record that, and so it is just the orbit closure of Gv in this affine space of matrices, which is twisted. GL on the left, Taurus on the right, take the closure, and we get a nice affine variety. So we wanted to understand the classes of these things and a class. And a class from which you can get various other information is: I want to know the k class of this, okay, so the k class of the structure sheet. And I want to do it equivariantly with respect to the natural group that I'll say a little bit about, well, there's a few. About, well, there's a few reasons one could say why. I'll say one of the earlier reasons why after I say an example, because it's nice to do concrete examples of these type of things. So K D series or G equivariant K theory? G equivariant K theory. Yes. That's right. All right, Alex, so if you replace the torus with a Borel here, these things would be called matrix sugar varieties. Precisely, yes. Yes. And there are k-classes that make extensively. And there are K classes that have been extensively studied. That's right. They like bubble grown deep polynomials. And those will show up at the end. Yes. But here is a torus. What we expect in matroid theory is that columns really have independent identities. So we don't want to add a multiple of a column to a column. That does funny things to matroid line. Cool. Okay. So just to do this very concretely, I can take some particular Some particular metrics. The first interesting example is rank two on four elements. So modulo these things, right? Okay, so I'm scaling each column, so I have four points in P1 up to automorphisms in P1. So probably by this point in the week, the people in the room know that there is one invariant of this kind of thing. If it represents C24, that's the cross ratio. Sure. So, okay. Now, since, all right, so let's just write down the equation of this thing. Okay, so just for maximal concreteness, so the ideal thing, all right, this will lay over, all right, so I need some indeterminates, I need an R-band matrix of determinants, four in this case. 4 in this case. Well, okay. Normally it's some cross ratio thing. Okay. It's going to be, in this case, it's just going to be principal. It's a hypersurface, there's an equation. And so what does the cross ratio look like here? Well, I take, you know, a product of two of these determinants, and then I take a product of two other determinants. Like 1, 3, and then 2, 4. I'll just write this as like x star 2, x star 4 in the second and fourth column of variables. And then I get like the 2, 3 and the 1, 4. So that is how you compute the cross ratio, and you know the cross ratio being invariant. If this thing If this thing is uniform, so alpha is not 0 or 1, and of course, the way I've set this up, I can get infinity. You left out depths. Oh, I left out depths. I wrote debt once, and then I got excited. Okay. Vertical bars, and I don't have to write debt. Follow me. Okay. Yes. So, well, if alpha equals 0, 1, then I have a different behavior. And if alpha equals 0, then I really have three points in P1 with multiplicity. The second point and the fourth point are the same in P1. And GLT is 3 transitive. I can put the three points in there. I can even, with the closure, make them fall onto each other. The only thing I can't do is make the second and fourth columns non-parallel. Non-parallel, right? So, okay, so this, if alpha is zero, then I just get determinant of the second and the fourth column. And I guess similarly, the last case is I just get determinant of the fourth column. So this looks like just, you know, in this case, it looks like matro dilimence, right? No one here is going to be surprised. Surprised. Yes, there's something matroidal going on here. When we got U24, we had a cross ratio. When we got one of the Egyptian pyramids, we got something else. It's a label. If it's a matroid function, it's a label matroid function because I see which two things are parallel. Okay. Well, I wanted this k class, but I'm working in affine space. K class is just, you know, what Miller-Sturmfelds called the K-poly. What Miller-Stormfelds called the k-polynomial or numerator of the Hilbert function and appropriate grading. So, you know, really, this is a very, very easy thing to compute in Macaulay 2. Other systems are available. So, we just need to find the degree. In this case, I could either print. You just need to really find the degree of these things in appropriate grading. So, all right. Well, I guess I should define how I'm gonna write this k-ring. So, this is like the representation ring of my group G. And okay, so the first thing we do is we say since G is a reductive group, it has a maximal torus, and any G representation is determined by its torus character. I didn't define T as the maximal torus here. And okay, so this torus representations are just a Laurent polynomial ring. Okay, so that thing, the K ring on the right, I will write the equal sign yet, the K ring on the right, is just a Laurent polynomial ring in a set of R variables and a set of N variables. Okay, but what I need to get the things that appear as g characteries is I take the file group of g invariance, that's the symmetric group in the R things. Okay, so I guess symmetric Laurent polynomials of the U's and Laurent polynomials of the T. That's what this k-ring is very explicitly. These are the kinds of things that can appear as numerators of gm polynomial filters. Number 1 is a GL Filbert functions. And okay, now we can just read these things possible. Now each of these things has one step resolution or whatever, so we just write down the degrees. Okay, so u's our row grading, t is our column grading. Here I have each column in a term t returns each. Column in a terminal terms, each column appears once, each row appears twice, so I get one minus. Each column appears once, each row appears twice, and okay, there are negatives. Here, I had the like h acting inversely, but this was on the space, and so when I go to the polynomial ring, I get another inverse, so now h acts directly, and the gl acts inversely, it's okay. The GL acts inversely. So, okay, so there's inversely there. But I used to read this off the computer, but acting simplistically here. Okay. Can you come to the slide Ibitch? Can you comment on the slide Ibitch? Why is that why does the terms? The side convention is that, like, the degree of x, i, j. Of xij is negative ui ui tj. Okay, I just know quite a grief. I'll just write negative e i comma dj. And there's a negative here because there wasn't one here, but the action on the space is dual to the action on the ring. For the same reason, there is a negative here, so there isn't one there. All right. So, uh, figuring out your main theorem. This is a matrix. And maybe it's unimpressive not to have a positivity theorem or something as the main theorem, but this was a decade-long theorem, and we submitted false proofs of it twice, so it really took some work. So characteristics example. And okay. And okay, so yeah, that's the main theorem, I guess, in this series of three papers. Following a trick that we've seen a few times, people learn from other people, you know, if I have a thing that's defined for representable matroids and it's valuative, okay, any K-theory thing is probably valuative. You can also extend it to all matroids. Also, extend it to all matroids. Why don't I just say explicitly what it is, right? We haven't seen an equivariant localization formula on the board yet, yes? Can I ask you to say two more sentences about what you just said that any K-theory thing is polyvalued? Okay. Well, I... Right. So if I have a reducible variety X, then I have an exact sequence that goes between Sequence that goes between the structure sheets, and I'm going to get this the right way around. Here, I'll draw my arrows afterwards. And then I have the intersection. And I think I go this way other way. Yeah, okay, other way. That's right. That's right. Right. Anyway, the upshot is that now I get, you know, short exact sequence, which gives me an additive relation minus this stuff is zero. And well, for things like matroid polytope subdivisions, okay. These are going to be some kind of lifts of the torque rate of the matroid polytope. The torque vertical polytope where we have these degenerations. And so those are the value relations. That's precisely, I also meant the vague statement, but okay. So in the Matroid-Polytope case, I know how to prove that the computer data of the Matroid subdivision means that I really, means that the big guy really does degenerate to the union of the stronger. This is not a proof. Yeah, there's definitely something more to do than that there. And so rather than, this is why if you're saying, you know, I'll cut to the chase, you know, I'll just, we can get an equivariant localization. We can get an equivariant localization formula using some of the tools I'm going to say later. I'll just give that. Then it's useful defined, and then you just check it because you can do Riond stuff with it. Okay, so maybe I can pick that up. Indeed. So, yeah, of course, I'm lying a bunch here, or being moral instead of true, but But if you want a true statement, so I can define a class for any matroid. And so, you know, it's gotten a very localization formula, may as well just throw this. So it's some sum over orderings, and when you have an ordering, the thing you want to associate with it is if you like's first basis. The Lex first basis. Are we still in equivariant? Yeah, and this is going to be equivariant. Well, okay, this is not a K ring. This is meant to be a... I'll call it little K, okay? Little K. Changing my notation on the fly is is something to do at my own peril, but okay. Little K of G is now an element of big K of G. Okay, cool. Ah. Okay, cool. And so what does this look like? Well, okay, so you've got some kind of local contribution. I take the things that aren't here. Maybe you, okay, product over all eyes. Oh. Some products like this, and as is usual with equivariant localization computations, this one, you know, this is the inverted one, and next one is not. And the denominators that it looks like appear here do not actually appear here, and you add everything up. You really just get a Laurent polynomial. Ah. In the first product? It's this. Oh, it's a double product. Double product. Just to check consistency in your, I think in your second polynomial expression over there, it should be U1 to the minus 1, U2 to the minus 1. Should be similar. Oh, yeah, sorry. I wrote it because it's... Yeah. Thank you. Thank you. Go ahead. Right. So, all right. Alright, I'm a little bit slow. Maybe I'll just say, you know, say and not write one word about motivation for a second. So Andy and I started studying this stuff together when we were both in the Bay Area. I had just worked out K classes in orbits in the Grassmanium with David, and so K was. Andy was interested in some representation theoretic aspects of this, because if you take a T-graded piece of this ring, like the 111. Of this ring, like the 11111 T-graded piece of that ring, okay, that's of the coordinate ring. That is linear functionals, modular linear functionals that vanish on V1, I can tensor it together, tensor, linear functionals of tensors that vanish on the tensor, V1, tensor, tensor, Vn, and all of its GL images. And so these coordinate rings encode some representation. Coordinate rings encode some representation theory of representations generated by tensors, like this. And so there was representation theoretical interest in representations generated by a tensor, the GL orbit of a tensor, or even better, Chervile duality, SN orbit of a tensor. Then you have young symmetric and all that. So I think, Andy, your original way into this was like trying to crack these combinatorial behavior of these SN invariants and tensors and stuff like that. Series of stuff like that. So that's one reason to look at these matrix things. Okay. All right, let's put a bit more of the geometry up and define more than one variety. So, I have. Alright, I have geometry and for some varieties and some notation. Okay, so I bought my x. X of V, that's the thing over here. Alright, and as I've already said a few times, this is like a GLR lift of what we call in our paper Y. Well, this is just going to be the torus variety of the matrix polytone in the Grassmannian. If I quotient out by GL, then my ambient space. Then my ambient space becomes the Grassmannian. And the T action survives, so again, T orbit in the Grassmannian, and that is, as has been mentioned before, the torque variety of our Vitroid base point. And so that's something that is reasonably well studied. We've heard about it if you have today. And well, this week. And both this week. And we've also heard about some nice vector bundles that we have on the Grassmannian topological mind. So I want to put a vector bundle up here, which will be the R-fold correct sum of the tautological sub-bundle. Okay, restricted to tautological. So I can look at this. I can look at this. Now, the topological sub-bundle, right, its fiber over a point of the Grassmannian is that space, so it embeds the whole space. So I have an embedding of each copy of the tautological sub-bundle into a trivial Kn bundle. So each point, you know, this is like a space of matrices. So the true So, the trivial bundle that my bundle is a sub-bundle, they can just view it as matrix space product, my Torus or closure in the Grassmannian. This is nice to do because it partly resolves X. If I take a point in the Grassmannian and I take a generic R tuple of sections of S, well, S has rank R, and so a generic R tuple of sections of S spans, and I get down here, and I can sort of recover my matrix X. A general matrix X is just R goes from here. Yes, R goes from here. And so I get a nice birational projection there. And so this has some nice consequences. So in our first or second paper, for instance, we use this to give a stratification of X, which I love. I won't spend too much time on unless somebody asks. But why is a toric variety? We had a nice little stratification of toric varieties. Where the matroid polytope is given by, okay, bases the matroid polytope. So like sums of restriction contractions. And then kind of all you've got to do to that is possibly another projection. So you have strata here that are labeled by quotients of these faces. Probably don't. They're not orbits. Some of these try to have more than one orbit, but at least you have a nice stratification. You know which matroids show up in X. So just connecting it to the torque variety lets you ask your questions on which matroids show up here. That's cool. If you're happy with it, kind of the things that will probably excite people in this room are that you can tautological bundles. Tautological bundles, okay. What do we do with tautological bundles? We get something projective and then we run the Hodge package. Okay, so you can do that here. So Hodge package positivity called destiny. Oral for now. From this bundle, okay, I should projectivize it. Multi-projectivize it. And, well, what kind of positivity results do I get from that? Well, I can make statements about, okay, all this Hodge stuff is chow. So I don't get the k class of the x, but I can at least get the chow class of the x, the equivariant chow class of the x. Well, okay. Well, okay. Maybe not T upper variant, but at least the Chow class of the X in T, okay. Start area here. And the nice thing about this, this Hodge package, they can also do it for other matroids. The BEST paper told us what to use in place of this. Told us what to use in place of this actual bundle. If I have something that's not a major, well, I don't get a literal bundle, but I get some kind of like thing which behaves rather like a bundle and that it has turn classes that display the right properties. And so, just like the K-theoretic invariant is a matroid function that exists in. A matroid function that exists and is even defined for all matroids. Well, you can get the Chow class from the K class by the prescription in Miller-Sturmfells, for instance. And so there's a K class for every matroit. So in fact, there's a Chow class for every matroid, so we write down Chow, C for little C for Chow, equivariant of the matroid that lives in this ring, where the point is that the equivalent. Where the point is that the equivariant, if I do this with a matriarch of V, then I'm going to get the class of x equivalent. So just like there's an arbitrary matriarch version of the K thing, there's an arbitrary matrix version of the Chow thing. And because of the BEST paper, for this kind of positivity result, we can say something even if the variety Can say something even if the variety doesn't exist aesthetically. Do you really mean the direct sum of the projected bundles and not the projectedization of the direct sum? Yes. If you wanted to do some. It would be the final product of those if you wanted. Oh, I had it on side. You only forget that. So it's like a multi-threaded chart. Yeah, it's a multi-threaded chat. Yeah, so I can't direct some things. Okay, so fiber products. Okay, so fiber product into the upper product. That's right. I can't direct so I don't know. Say, well, I guess the thing I have to say is that R something minus R. If I take out this, well let's just do the full equivariance version, major equivariance in the two sets of variables. In the two sets of variables m and t. It is, in fact, implicit in this claim that it does come from these Turing classes that we so these things. So I can do the Turing class as torus equivariantly, so I can write down some Turing polynomials for torus equivariant degree star column. This stuff I use for coffee's this total turn polynomial combined in the VST paper in my new variables and the product of these things false. So just to briefly say why. Just to briefly say why. Okay, well, all right, the things which are behaving as positive for me are really the negative u's. Okay, so this is like churn product dual churn negative u's. And all right, really I want to reinterpret that as the product of segrays into the q, because I have this exact sequence where the s and the q thing together. Trivial bundle, I can change these to segrays. And now, well, the segray classes encode intersection of a bunch of hyperplane sections up in, say, these big trivial bundles up here. How do I find the Chao class of something? Well, I cut it with a bunch of hyperplanes, and I count the degree. So I count the degree. How to compute this seg grade class? I count it with a bunch of hyperplanes by computing the degree. So that is why this Chow class is expressible in terms of segue classes of these tautological bundles from the ESP. So this is for all M, and we get maybe this fact should be attributed to all four authors of that paper. To all four authors of that paper, that now I should do this. Oh, okay, I guess I'll write it this way. Ah, I may use a little notation here. This is just C porus of M. Alex. That equality isn't between the turn classes and the segregated classes in. Classes and the segregary classes aren't quite correct because we're in the equivariant. Oh, right. Off by some monolings. Product of all the uns to the negative R will be one plus. One plus. Oh, right, could you rich? One plus. Right, okay. Product. Yeah, thank you. Thank you. All right. So I like the tools of the main theorem. This matroid topological bundle stuff is spiffy, but we've seen it a few times. I guess we've seen some of the tools of this main theorem a few times as well, but they're more different. So let me talk about the proof of claim there. All right. So key observation, I think, is a thing that it took us a while to get. Well, control the copy approach. And the variety we're looking at for For how is rationalism invariant? In some sense, all of these Chow computations benefit from the fact that doing a computation in Chao is a birational invariance. You can do it here and there. You can put it in the beach around the Grassmannia or whatever. In K, not so much, but having rational singularities, at least there are tools for rational singularities which let you move things around a bit, like Lehman's geometric method, that mitigate some. Method that mitigates some of this difference. So by using this, we can sort of move our computations around to a certain extent away with this to a challenge. Okay, so I just erased my diagram, which said that I have a birational surjection from my x to this e, where I'm using e as its total space. And, okay, it's not a desingularization, but E is a total space of a vector bundle on Y, Y is a toric variety, Y has rational singularities. I could desingularize that, I could put a further map up here that made it a desingularization, and then by the Gritten-Deek spectral sequence, this E is basically as good as a full desingularization. As a full designularization for the purpose of what you get from rational singularities. So I called that section on this structure, I guess. And the right derived factor is a push forward of, now, okay, now E is going to make my total scope is just going to be, well. Well, as usual, you know, structure sheath pushes forward to structure sheath, even in this partially synchronization. And so we're going to, you know, so we can do computations on E, push them forward to inferentially. We can show E, this class of E is a neighborhood inherent. We can push that forward together as X is a neighborhood inherent. All right. Well the class of E we get something from this Kempflasku-Weyman geometric method. Our Vayman's book is 03. I guess I shouldn't put the day on this, which is more or less, I guess, so now E over each point. Over each point of y, e are the coordinate functions which I allow to vary when I choose my rows of x. So e is some kind of, I can build some kind of relative coordinate ring for x. And then it behaves for a relative relative coordinate ring. Sorry, what are x and e in not the current context of matrix orbit flow? X and E are the same thing as an all. So this is my matrix. The same thing overall. So, this is my matrix or the closure. This is the same thing, it's always been. And this is the total space, the total space of this Rex sum over. Toros orbit closure just point out. Same thing they were. Right, okay. So I want to use this E as kind of a relative coordinate ring kind of thing for X. So how do I do that? Well, I want to look at chromology. Or I want to look at, well, if I have a bunch of variables, how to construct the coordinate ring. How to construct the coordinate ring? Well, I take the symmetric algebraic dual. So that's what I want to do here. And using this rational singularities, you can get that just the, okay, this thing I call y. So I'm going to take a notation, that torus orbit closure, which is y. Notation from the paper. And This thing is equal to this derivative chord. So it's zero except for the zeroth cohomology, in which case I get rho x. And so in particular, the just a sum. And so in our paper, we do something else to argue that this is a matroid invariant. We say, oh, David and I proved that the class of Y is a matroid invariant, work the class of Y up into E. But now that we've seen a talk on BEST, they can say, oh, look, this thing is a matroid invariant. This is the tautological bundle. They told us that this is a matroid invariant. And so this thing is a matroid invariant. invariant and so this thing is a matriarch invariant and so is this. So that I guess is the power of rational singularities that then we could just work in this bundle and this bundle lives on a variety which we can connect to the whole matroid Hodge theory permutah variety bag of tricks. Push-forward computation is the issue of falsehood characteristic. This push-forward computation is the issue of positive characteristic. Yes, this is an issue of positive characteristic. Fuzzy characteristic, rational similarities is maybe the most fundamental thing we don't know how to do, but there's lots of things we don't know how to do. All of the results that use it, I think, we also don't know how to do. All right. So X has rational. So X has rational singularities, why not? So, for this, we used a paper of Binglin Lee, and Matt was just telling me. And Matt was just telling me, well, maybe I should be citing Backman or Simpson in this crowd. They do relatively similar things. So far I've been playing with the Fallen geometry. Take X. Okay, X is an orbit. I have a group on each side. I quotiented out this group and I left the orbit with that group. Could do it the other way. Take a quotient out this group, leave the orbit of that group. Okay, so then I'm quotienting out each column by the torus action and going to a product of n copies of p r minus 1. About n copies of PR minus 1. And I still have the GLR action. So I'm going to have money. I'm going to action on motion by my torus. Call this V. And then V is a G L orbit of the image matrix. All right, just guess this. And alright. And, alright, so this thing was a GL orbit. And reinterpreting this slightly, let me, well, how do I do this? I take my element of GL. GL sits inside R by R matrices. And because I'm taking the closure, if I act by any R by R matrix, what makes up the closure? So I can take any R by R matrix, and I can multiply it by V. multiply it by V to get an R by N matrix. Then I can take this map of quotient t by the torus over the interprojective space. And the point is that the image of this composition is the same thing here, right? I do, instead of acting, instead of treating this G as a group, I'm just treating this G as this linear space of matrices. Space of matrices, multiplying by a fixed matrix, which is my data, that's a linear map, and then I can projectivize column-wise. And now we are in a setup very parallel to the setup that Shoyer told us about from the LLPP paper, right? We took a linear space, here's my linear space, we took a bunch of surjections, okay, this is kind of a bunch of surjections to Kr, n of them, and then we projectivize each of the in. And then we projectivize each of the images, and we want to know what the closure of that thing is. Let me save. Okay. So, using, well, the same kind of tools to compute with this that Sharia told us about, or I will cite Binglund for this. There is a nice formula for the Chao class, non-equivariantly, but that's all right, of any such image in a productivity space. In this case, it looks like this. Non-equivariantly. And I guess the really important thing is that it's going to be a multiplicity-free sum of powers of the hyperplane classes. Okay, I have powers of hyperplane classes for consistency rotation. Let's call them TI. Then I get just a sum of these. It's a nice sum. Over points, unit are points. Even x minus, I'll just do a reflection up here, but the reflection of a generalized gradient is a generalized gradient here. There's something dual here. And if I wanted to write down the intersection, And if I wanted to write down the intersection polynomial inside this space height quality, that's the way that we ended it. And this polyhedron is just r times the matroid polytope minus one copy of the status. R times the matroid polytope because each of these rows is chosen from the matroid copy copy. One copy of the center. Simplexes as a general feature of. This incidentally is another evaluation of this Metroid chow thing. But the thing that's really key here is that it's multiplicity-free. That I mean, okay, in terms of the simplicial basis of the chattering, that all Of the Chao ring that all of the products are 0 and 1. In this dual perspective as a k class, all of the coefficients are 0 and 1. Distinct monomials in t, ones in front of them. And this is a tool to get rational singularities. We have a question? Yep. So maybe I will say just briefly, so two steps which So, two steps which I maybe won't spell out on the board, but this is beyond from 2003. So, B is multiplicity-free. In Brian's result, it applies in a general flag variety, so an algebraic reductive group modulo or parabolic. Okay, we know that PR minus 1 is a flag variety. I guess that's well known. Is a flag variety, I guess that's well known. But Pr minus one to the n is a flag variety because I can just take direct products of my parabolic. So this thing is a flag variety. And Brian says that anything that's multiplicity-free as a sum of Schubert varieties is rational single NRDs and they're authentically quoted Napoleon nice. Schubert varieties here are just like powers of eigen classes. Okay, so this is precisely the setting that Riolan tells us. My one tells us as rational separate varies and other nice stuff. And the other nice stuff, okay, you could write this in terms of some vanishing etymologies or injections in sections and so on, and plug all that stuff into another one of these. Of these things on a result by CAP, which says that you can pull this back. Non-directly pull it back. Again, you do this section ring stuff. You get line bundles on V so that the ring of sections gives you X, and then using this, you can transfer your rational singularities techniques. I have m different twists from I am different factors of tr. We get rational singularities from this Brian. Rational singularities from this Brian thing. We construct line bundles to represent the coordinate rings to move it around. We get it to the variety where we need it, and then we can do this. All right. I have between zero and ten minutes, so I will talk about some interesting positivity conjectures of a kind that we haven't had any exposition of so far. All right. For a discussion of I slipped in a result that says we can use the BEST apparatus to get some Lorentziality about the chow version of our polynomial. Okay, that's just the Chow version. What, if you want positive results which apply directly to the K version of the polynomial? Well there is a theorem of Anderson, Griffiths, and Miller that says in terms of, again, structure constants and Schubert's, the kind of thing you might hope for also using rational symbols. So they set it up in terms of flag varieties. Maybe I will not write out this theorem. Maybe I will not write out this theorem, but I'll say if you expand, if you take any flag variety, sub-variety, torus-fixed with rational singularities, and you expand it in the Schubert bases, then there is some positivity on the coefficients in terms of simple roots. So I'll say what that says for our case. We can do it in two ways. You could do it for this map to projective spaces, or you could do it for the map to the Crossmanian, and both of those are flag varieties. I'll say what it says for the map. I'll say what it says for the map of the Grassmannian. So this is the thing I call it the Y, which is more sort of Grassman. So take my G equivariant K class associated to a structure sheaf of X. Abstraction sheath of X and write it as a linear combination of classes of structure sheaves of Schubert varieties in K-theory. Well, the class of a Schubert variety in equivariant K-theory, as Nick was saying at the start, is a thing which has a name, the double root, Nick Paul. Double row with the polynomial. And okay, since we're doing this on the Grassmannian, in the Grassmannian, these u's don't appear only the t's, so when I decompose this on the Grassmannian, the coefficients are functions of t. And now c is taken calls. Call C. Pennyworth C. The coefficients are functions polynomials of t, but not of u. They're all polynomials of t, polynomial of u. Well, there is then some positivity that says things with rational singularities should be positive in the appropriate sense when you expand them into shoot varieties, and the appropriate sense is is that RAT up to a sine. Okay, the sine, may as well write the sine down plus the number of components of m minus the number of boxes in this index. Times this thing lives in Doesn't quite have non-negative coefficients as it appears here. That would be too much to ask for. But you can write it in terms of guys that look like this. These come from the simple groups like T minus V1, 3 of T minus T minus 1. And in those objects, it has positive coefficients. This is characteristic 0. And this is still characteristic 0. Yeah. And so here is a geometric positivity, which, you know, following the conference, seems, for the tests we've done, that it should be a matroid. In fact, that it should be a combinatorial positivity. And so that is the lecture that I want to end on. That the That the k class associated to the matroid is positive in the same way. Whether or not the things are presentable. Okay, maybe one specialization, one special take. One special case. In the paper, we give various specializations, but here's one specialization. Okay, first this is the k-theoretic positivity. But you can go from here back to Chao, and you get another notion of Chao positivity, right? This is just kind of equivariant positivity in Chao if I express the classical variety in terms of shape varieties. I still look like this. Like this, I do else, and I get some differences associated with positive groups like that. I can de-equivariantize, I'm just saying that I get positive numbers here. If I go de-equivariantly and into chow, and I want to write something like, okay, what I'm calling the Chow class. Yes. For a second positive idea, can you improve this conjecture by in the productive procedure by taking minors to get back to realizable matrix? So, I mean, it's just the other way we can, if we take prescription fraction, we get back to k3 of smaller matrix. Not that we need to trace these classes. I mean, we hoped for such a map. Did we get such a map? Did we get such a map? I mean, there is. David Brook the top. I mean, David wrote some geometry down which wasn't a map. I think Chris has a map. But I didn't look at it. You said you had this map. Well, but this is going the wrong way, right? I mean, there's more data in our access system in the top models, you shouldn't probably get out of the machine threshold. That's a very dangerous thing. Right. They just cracked. Yeah, there's a yeah, sure, I guess even if you did that, it's it's how to patch it all together is a lot of the problem. Right, okay, so I want to specialize this, make it non-equivariant, make it in chow. Okay, so now I have, well, okay, I guess I want to leave it, leave the u's in, but not the t's. So now I have integers here. Plain old Shur polynomials, double Grotendeaks, our K analogs of double Sures, and then we kill the T to get single Sures. And so the conjecture So the conjecture is that we use harder than not negative. And the point is that since the Shur polynomial is the class of the Schubert write, and you can pull that off of a Shur functor of a tautological bundle, then by some duality, this D is actually a is also the uh short vector as well. Sure functor and hotel. So polynomial. I wrote the right thing. I wrote a short polynomial of a topic magical, where this lambda star is the complementary coefficient of lambda r by n minus r box. So this is, I guess, related to the kind of Trying to posit any rebuild and hopological questions that have been blocking around. And this one, at least, is a special case of this case that I probably should be next. That is my, you know, the question I leave you with about this k-invariant and I'll sign that. Are there any questions? In positive characteristics, what are the best Mitroid invariants results known? Like as a child equivariant child class, or if I look at T equivariant kid or GL, something I could? I mean, I guess the BST package is not characteristic for everybody. I don't know of anything kind of between them. We've got characteristic zero and then we've got the the general stuff right now, I think. I don't know. I'm I'm afraid of that. All algebra's geometry and positive character and stuff. I think that this combinatorialized. I don't know, for example, whether the last conjecture is true. No, no, matrix invariance. I'm saying is the torso closure K class of matrix invariance. Oh yeah, that the torus overclosure, that works. Okay, yeah, torso closure, but like, what about like the, what if you look at the aqueous chow class of the matrix over closure, what if you look at the acquired idea. Is the equivariant theory does it even work in positive characteristic? Like, can you do other equivariant child groups? I thought so. Okay, so. Yes. But we can't access them this way. Haven't computed a lot in characteristic. Might be worthwhile to know whether, you know, whether skepticism is warranted about characteristic. Okay, so let's take a two-minute break. Yeah. They are, but I don't have to surprise you. And they're just like, not that if you're looking for the settings, there is a way to realize the Like the relation for the finger. Oh, yeah, yeah, that's true. That's the real possibility. Yeah, this is publication. So so for the the aquabiric chow class, the matrix or here's something that you care about. Yeah, there is really quite okay. So that's what we really think about localization. We wrote like creating papers and not description. I can't believe you're out of the way. So right if I queue something, but if I see the definition, try popping. Do you want to write it? Yeah, all the spinning sets partnerships. I mean, you have to take the RGB. Possible, but Dense just found a way of building the T a lot, just right down the spot that ends up being unloaded and everyone's very fine. Everything's fine. The first class is the first term. So maybe we get myself. You know, some of these chairs have all sorts of meals that stuff like that. My understanding of this there was something more difficult. I remember Andy and House's hyper moving point to maybe more separate than they wanted to see. I mean, in the freezer part. Yeah. Okay, so let's get going with the open chronicle session. So the first thing to organize is a scribe. Are there any volunteers? Please don't volunteer if you have a problem you want to suggest. Okay, that means everybody has a problem they want to suggest. I don't know, I think some people will be writing everything down anyway, so just raise your hand if you want to be the official scribe. I can do it again if I have experience. Just for paper. Okay. Nobody wants to save Alex from this. Okay. And you don't have a problem? That's right. Okay. Good. Okay, so this is open problems, not just question and answer like we had earlier. Does anybody want to kick us off? I've up to six problems, but I don't think I was going to five. I don't think people want to see up six. I think I'll do maybe three or four, depending on how fast I go. And what I think might be the order of difficulty, but increasing order of difficulty, but I'm always wrong on those things. Does that mean increasing monetary rewards for solves the difference? Oh, I don't know. Would the first like help in this regard? Like, help in this regard? Yeah. So here's a fact that kind of begins this question. Can you use like white? Oh, do you want me to use white? Okay, then I had to get my own chocolate. I'll give one to you later. So here's one fact. So here's one fact. If P is a generalized perimetahedron, so polytope whose edges are in the EI minus Ej direction, let's say it's a lattice, generally it's going to be different. So all the vertices are in the integral lattice. Bend P intersect. intersect any integer translate integral translate of the unit q is also so that that's just a fact not crazy hard to show but turns out it's very useful in many different contexts in particular um given any generalized permutahedra just take the boolean Just take the Boolean, uh take the tiling. You can tile R to the N by cubes. This always gives a decomposition of arbitrary generalized perimetahedra into generalized perimeter that's contained in some translator of a cube, but those also have a name, matrix polytops. Matrix polytopes. So generalized perimetahedra containing the unit Q is a matrix polytope. In other words, any generalized perimetahedra decomposes into translates of matriarch polytoles. And what's the question? Well, there are some communities who love to study. There are some communities who love to study polymatroids, or generalized permutahedra as a synonym for that. And I think one interesting thing to try to get a very explicit understanding of is to do this in whatever level of explicitness that one can get for graphical zones. So if I have a graph, I can consider the Minkowski sum over all edges in the graph. Overall edges in the graph. Oh, let me write, let's say V1, V2 is an edge, and I look at the convex pole of EV1 inside R inside G. A convex hole of whatever, whenever I have an edge, this is. This is well-studied polytope or generalized chromatohedra called the graphical zonotope. And it decomposes into major polytopes. And in some works of mine that's not published yet, I've been studying some notions of polymatric top polynomials and whatnot. And those are valuative in the sense that if you decompose, it behaves in a way that. It behaves in a way that it should satisfy the inclusion-exclusion relation. And for instance, if I want to compute the polymatriate polynomial of a graphical zonotope, this would be one way to do it. But I don't know how to do this explicitly enough. I think it could be interesting. That's the first open question. I think. I think it could be doable, but I haven't thought too much. It could be doable, but I haven't too much. So, precisely, you want to understand all the phases of that decomposition? Yeah, yeah.