Nostalgic feeling that this event brings, in which one of my last international trips prior to the pandemic was in 2019 when we went to South Korea. And yes, what an amazing travel experience that I collected many, many photo memories that I treasure very much. And just to tell you all a little bit about myself. Little bit about myself and my lab. I am a member of the complexity science group here at the UFC together with Jorn, Wilton and Emma. I'm just also switching on my timer here and so I can keep an eye on how much I'm talking. And under the umbrella of the complexity science group, my relatively small lab is named Complex Nanomaterials and here Materials and here we have our graduate students. Let me also test here my pointer. Here we have our graduate students. And I'm also a member of the HBI and the Institute for Quantum Science and Technology, also established here at the UFC. And our works also count on fruitful national and international collaborations as listed here. Most of this work that I will be presenting today is. That I will be presenting today is in collaboration with Professors Mauro Fehera and John Boland from Trinity College Dublin in Ideland. And my research falls within the scope of theoretical condensed metaphysics, complex systems, computational nanoscience, material science, and brain-spire systems, which will be the focus of the talk today. Be the focus of the talk today. Our methodologies and tools focus on the development of theories and computation and models that we can describe unique material properties and responses. But yes, we are in this synergy between theory and computation, computational physics, but we also count on great experimental collaboration. On great experimental collaboration in which we can have access to some valuable experimental data to assist in the development of our models and hypotheses. And in terms of materials that it can come in so many land scales, we have a wide variety of materials that we can investigate, ranging from nano to mesoscale sizes and mesoscope. Scale sizes and mesoscopic scale sizes of materials, and materials name it engineering, engineered or functional materials that are materials that have a purpose or an application in focus. This is more or less what the kind of research that we have been doing in the last years. And here is a bit of the outline of this talk that will not necessarily follow this order, but these are more kind of key points. Key points that I will be talking here in this presentation. We will certainly focus on the part that my group develops in brain-spired and neuromorphic systems. Also present a little bit of the research interests and challenges of the field. Talk about types of materials that can be used for neuromorphic. And we are going to discuss things at different scales: microscopic and macroscopic. Scales, microscopic and macro scale. I will also detail a little bit on our computational models to describe current flow in intelligent network materials. We are going to talk about the main mechanism that these materials rely to have this kind of a smart component in their electrical response, which is the property of being MADISTIV, essentially resistors that have memory. We are also going to talk about microscopic. We are also going to talk about microscopic conduction mechanisms, U-migration, and other types of properties. The cool thing is that these materials can also be used in other types of applications, and I will just mention a little bit of electro-optical properties that these networks can also exhibit and some conclusions. So, the story of brain spired systems, as the name indicates, is an area where Is an area where we take inspiration of the brain style of processing for designing smarter electronics. And the field also enables the other way around of study where brain spy electronics could also be good analogues to explain brain processing. And it's a very interdisciplinary field that relies on knowledge of multiple disciplines and Knowledge of multiple disciplines and research areas, as shown here. And it's also identified by another term, which is neuromorphic systems, which means taking the form of the brain. And this ambition to imitate brain analog processing has grown profoundly in the last years. And remarkable outcomes from the intense progress in this research field. In this research field, is the University of Manchester Spinacre supercomputer, which is a neuromorphic supercomputer, a million-core system, which operates based on spiky neural network architecture. That's why its name. And it's known to be the world's largest neuromorphic supercomputer capable of running robust neuromodels. And our main goal. And our main goal in this part of, in this research topic, is to research on material innovations to produce benchmark neuromorphic architectures. This cartoon here on the side illustrates really well what a neuromorphic researcher does, which is to take inspiration from neurobiology and put that into a device that processes information more like our Information more like our brains. And it's not only a matter of design, but also which materials should we use for this goal. The hope is that successful neuromorphic realizations could render smart artificial intelligence systems that could handle more efficiently real-world large-scale data sets. The problem is that the field still faces numerous. The field still faces numerous challenges. As even just recently, a prospective nature report that is shown here in this slide entitled Brain Inspired Computing Needs a Master Plan, It Does Need a Master Plan, has outlined really well many of the challenges that brain-inspired computing in particular has to overcome in order to continue evolving and show its main impact. Show its main impact. This research also, this report here also highlighted one of the biggest advantages that the field could yield, which is to address energy efficiency in smart electronics. As the report emphasizes, digital technology has for sure advanced enormously in the last decades, but its development has been a Development has been primarily focused on functionality and not on the immense amount of energy expense that it comes with the huge demand of data access and processing that modern society is requiring nowadays. And we are, as the report mentions, we are neglecting the energy component and therefore the environmental consequences that this seemingly efficient digital technology is imparting. Technology is important. And a big factor on what conventional technologies and many artificial intelligence systems stand on nowadays is the issue that the software is brain-inspired, it can be pretty smart, but the hardware is still pretty much digital. And our brain is a super very energy-efficient machine, is far from being digital, as we know. Digital, as we know. So, conventional microprocessors are built based on the von Neumann architecture, where data is constantly shuffled back and forth between the CPU and the memory unit, which are physically apart. And this is what it consumes large amounts of energy, causing a bottleneck for the operation of the device. And it is a rigid. It is a rigid, centralized unit that can manage multiple ports, and materials that dominate this technology are the semiconductors, for example, silicon. Now, how a neuromorphic hardware architecture would look like, or how can it be represented, or maybe the best question is, which types of features are we searching when we Are we searching when we wish to build a brain-inspired hardware? There are many interesting features that we know that our brain exhibits. It should carry all these brain-like attributes that are being summarized here. It should be a platform that follows a network layout as a neural network. It should be able to perform massive parallel processing and in-memory processing. In-memory processing. It should be reconfigurable and adaptable with task-specific connectivity, fault-tolerant, and do all these things at minimum power consumption. Because yes, our brain is an extremely energy-efficient PO machine, consuming about 30 watts of power, which is equivalent to a dim light bulb. But what about the materials that are About the materials that are dominating this critical technology, and there are countless materials that are being used for neuromorphic processing. The one that I will focus in this presentation today is the one that we have been modeling and describing the last years, which are random nanowire networks, which is a class of cognitive complex materials that can make this benchmark. This benchmark for probing collective features that are typical of biological neurosystems, such as it does present a level of adaptability, it does present a parallel processing, fault tolerance, and all of this comes with a price because then, okay, it depicts all these nice properties, but what exactly happens inside these nanowires? What makes them so special? So special. It starts from the materials that they are made of. And to really go into the bottom and the source of these brain-like properties, we needed to mention what are these nanowires are made of. They are special because they can somehow emulate artificial synapses by controlling mechanisms of resistive switching. Of resistive switching phenomena that take place at each wire-wire contact point. Each non-wire is made of a core shell made of a metallic material coated with an insulating layer. And so, when two nanowires touch in that middle of that vast network, when they touch, they form a metal insulation. They form a metal insulating metal layer at the contact point. And this insulating layer can break down if the voltage drop across it exceeds a characteristic threshold voltage, which leads to the gradual growth of a conducting filament inside the junction. And as the filament grows, so then the effective length of the insulating burial. Of the insulating barrier is hence reduced, and in turn, it decreases the resistance of the junction. And it is this resistance modulation that mimics synaptic behavior similar to neurons. And that is great, but then we should find ways to model exactly this property, this volatile resistant state that grows inside each special nanowire. A special nanowire that presents these neuromorphic abilities. And there are different ways of describing this. And there is a lot of complexity, in fact, in this. We are illustrating the mechanism, but it's quite complex mechanism to describe, even theoretically, and also to measure experimentally. A way to A way to view what this filament growth happens is to model these wire-wire junctions using a sort of a dynamic passive circuit element named MainRister, which stands, is a short for memory resistor, in which its resistant state can be controlled and trained upon repeated application of an external stimulus. Of an external stimulus, such as a bias voltage. And Mid-Easters exhibit a resistance that can change in time. And this response can be controlled by a dynamical internal state variable that we will discuss a little bit later in more details in a model that we develop. This internal state variable can be, for instance, charge concentration, filament size, lattice structure. Lattice structure, intensity of the input stimulus, among other factors that can dictate on the internal properties of the main ester. And the main distor fingerprint, the interesting is that if we apply voltage and measure current, its fingerprint is a current versus voltage hysteresis loop as it schematically represented here, which is a typical signature of a memory component. And then you can think of a mainistor as an adaptable pipe, as it is shown here in this schematics. But in the context of electrical current, a main ester would work as a pipe that adjusts its diameter in accordance with the amount of water flowing through it. Mainisters are also viewed as memory cells in which bits of information can be In which bits of information can be encoded and in these resistant states. But as I said, mainly Steve's mechanism, especially when investigated at the microscopic scale, can be quite challenging. And hysteresis loops are not always kind of so beautiful in this sort of perfect H shape because there is a lot of microscopic mechanisms happening inside one of these special nanowires. One of these special nanowires, which we did have the opportunity to study in the last years. For instance, we investigated complex mainstiff mechanisms found in transition metal oxide and wires. And as you can see here on these left panels, here, depending on numerous dynamical, physical, and chemical conditions, one may measure a wide variety of hysteresis loops that translate. Hysteresis loops that translate into the complex mechanism of EU migration occurring inside these special nanowires. And we proposed an extended ministry model to fit such complex hysteresis loops measured in doped titanium oxide nanowires synthesized by our collaborators in Ireland. And we wrote down a set of different Down a set of differential equations that capture this complex EO migration phenomena taking place inside these nanowires. The equations are essentially composed of a response function, which accounts for the measured electrical current resulted from the interplay of two contributions, a shotkeep barrier contribution and a tunneling barrier contribution. This response function This response function is coupled to a state equation that describes the time evolution of an internal state variable that we are calling X, which works as a weight that controls the contribution of these two conduction currents here. We are omitting a lot of the mathematical complication here just for the sake of simplicity, but this state equation depends on several parameters. Depends on several parameters and functions that resemble a neurodescription. For example, this function contains diffusion and rotation rates, which pretty much regulate the system capacity to retain past excitations. And we were able with these models to really describe what is happening inside the nanowires and to fit the complex types of hysteresis. The complex types of hysteresis loops that the experimentalists reveal it to us. Here is, for instance, one of our results. The gray curve is the experimental, and the red curve is one of our fittings using this set of differential equations. And this is only telling us that such rich main distributed dynamics can power the way for an enhanced multi-bit memory cell in which more information can be encoded. Can be encoded in a spectrum of resistant states, resolved from a single nanowire, as this study that we did reveals. The interesting thing is that, well, this is only one nanowire, and we just talk about networks. This is a workshop that involves networks. This is only one nanowire. So then the next step is to take many of these mini-steps. To take many of these MIDI stiff units and arrange them in such a way to form a network. How do these dynamical components communicate and interact with each other if they have the chance to be integrated in a network layout like that? Well, let's take many, many, many Steven Nanowires, spread them over a surface, and we want to try to emulate brain activity. To emulate brain activity. And in this study, we do take inspiration on machine learning methods and artificial neural networks to demonstrate that certain nanowire networks that we have the opportunity to work in our laboratories, for instance, the silver nanowire networks, they demonstrate a type of self-organizing learning, the competitive kind in which only a single conduction team. Which only a single conduction channel is activated upon electrical stimulus. And this is what we denominated Wi-Net XO conduction state. The type of modeling that we did to demonstrate this Wi-Net XO conduction, we devised a computational model that can simulate the conductance evolution of a nanowire network made with this special main steve junction. Is a special mainly steve junctions. And in our framework, its first stage is to convert an experimental micrograph image into a virtual version of the nanowire network by image processing it. All wire intersection points are identified and the network is mapped into a graph and a circuit network composed of numerous nodal. Of numerous nodal voltage points and passive circuit elements. The wire segments account only for static resistance contributions, whereas the wire-wire contact points, they are considered as these special main distors in which their resistance can change and evolve in time. It does depend on the history of the charge flow. And when we couple these two contributions, Couple these two contributions into this network frame, we can obtain the overall conductance of the network. And we do this recursively by conducting the whole network into a current source, and this current source will apply a current that will increase linearly with time. The analysis consisted in these four different realms. Different realms in which we look at the problem at distinct angles, and we carried out experiments. Our collaborators in Ireland carried out experiments and we conducted the computational simulations and we compared the outcomes. And we also studied the problem at different length scales at the single junction level, as shown here in this first row, and also at the network level, as shown here on the second. Level as shown here on the second row. And we also try to compare if there is an equivalence between all these two by two universes that is shown here. Though to the limited amount of time that we have here, I will not detail on all the plots here, but our analysis focuses on comparing the conductance evolution of single junctions and non-wire networks. Wire networks. And again, these are all MADISTIV systems. Therefore, their conductance varies with the electrical stimulus. And in this case, a current source. And when comparing the conductance behavior at junction and network levels, simulations and experiments reveal the same thing. Individual junctions and networks exhibit a self-similar behavior in which Behavior in which their conductance evolution exhibits a power alloy scaling with the input current. This is a quite remarkable conclusion because it indicates somehow that there is an equivalence between the parts, the junctions, and the whole, which is the network. And we put everything together in an animation that it can be shown here. I've already shown this animation. Shown this animation before. Let me just remove it here, my pen. Here is the network that has all its junctions being modeled with main distribution, so their resistances are switching on and off. The current in the source, it's been increased. And here is showing what we call the Winnotexo path, which highlights only the wire segments that are carrying most of the current. And then we see that. And then we see that rather than the network chooses several parallel paths to conduct current, it prefers initially to use one path until it reaches a threshold that will enables the network to open a second path. And now the network is propagating most of the current between these two paths. The first one is what we call winner texo conduction. And then at a certain stage, the network starts. At a certain stage, the network starts activating other paths to propagate current, and the evolution continues in this way. These panels here on the left-hand side are just bars that monitor the conductance of a few strategic junctions within the network. And we can monitor all the characteristics and conduction features of the network with this. Of the network with this simulation. It was also our experimental collaborators in Trinity College Dublin, they also have a way to, in fact, visualize this Winnite XO state in laboratory using a scheme that they call its passive voltage contrast measurements, in which the wires that are connected to a ground electrodes that Ground electrodes that are electrically activated, they appear with a darker contrast. And for instance, here in this panel B, the darker wires are indicating the formation of a winner techno conduction state. And as more current is sourced onto the network, secondary paths start to emerge from the top electrode, which is in agreement. Electrode, which is in agreement with what our simulations show. The next step that we are advancing is to understand and extend the notion of winotics or conduction into other architectures that admit multiple inputs and multiple outputs as a neural network and that can be trained to perform certain brain tasks as is being listed here. We want to test protocols. We wanted to test protocols for inference, associative memory, pattern recognition, multi-sensory processing, fault tolerance features. But for that, we needed to change a little bit the design of our nanowire networks, which we are doing it. We are, for instance, testing a new type of nanowire network design in which we simulate the conductance evolution of a nanowire network. Of an NOI network, but be interrogated by four independent electrodes, as is being put it here, labeled as A, B, C, D. And the first stage in this research is to characterize how Winetexo paths are activated with this changing design in the network. Before, the network was being excited by just a two terminal scheme of electrodes, but here now we are testing other types of architecture. Testing other types of architecture. And we are also testing the possibility of rewiring the non-wire networks when a defect occurs, because this is also something that should be accounted for. In certain stages, depending on the conditions, certain wire segments can break, and this can disrupt activations of winetics all paths. So, this is a study that is going on at the moment. We also have other studies that we are controlling. Have other studies that we are contrasting the network layout. We are also comparing a random nanowire network layout with a more regular kind of nanowire layout, which is taking inspiration from the so-called cross-bar arrays, which has been also claimed prone devices for neuromorphic tasks. We are testing all. Tasks. We are testing all these things at the moment. And I see that I think I am already running out of time. Just also to highlight here the last part that we have been dedicating quite a lot of our research time is also to determine transparency to model electro-optical properties of nanowire networks because they can also be used in other types of applications, as for instance, flexible displays. Flexible displays. And we also develop lots of computational packages in this research front. I just here would like to point out some of the conclusions that we are discussing in this talk today. And also to finish this presentation with a call for joining forces. So let's put our knowledge together. Our knowledge together, our knowledge of the brain, our knowledge of networks, and our knowledge of materials, and try to advance and solve the energy bottleneck existent in conventional technologies by moving the neuromorphic computing researching forward. So, I am very thankful for your attention. And yes, questions? Thank you, Plavia. I believe that we have time for maybe a couple of questions. Let's check also we have to go online, if not here. Tony, you've talked about the random networks and you have talked obviously about these, I think, the crossbar, some specific topologies. Do you think that potentially other network architectures that would be beneficial and would maybe outperform the one? And would maybe outperform the ones you'd be looking at. And if so, which direction should be looking? Should it be networks that have a strong hub structure, let's say two nodes that dominate, or would it be a more decentralized structure? Based on what you've seen so far, what do you think? Which direction might be the most promising one? That is a very good question that I may not have the right answer. The right answer, but there are indeed other architectures that even they favor even a hybrid of what it would be a neuromorphic element and integrating with conventional technologies. There are also those that goes with more with the electronic part of very large integrated circuits. So, there are many architectures, in fact. I focus on I focus on these two, the cross-par arrays and the random nanowire network, because they are made of nanowire. So then I am more kind of nanowire focused in this aspect. But there are many other neuromorphic materials that are not nanowire-based. They even go more towards electronic and integration of well-known. Of well-known electronic devices like transistor-based and memory cell-based. I wouldn't know to say which one is better, but the thing is to keep testing because it's not yet defined. Thank you. Any other questions here? If not, Claudia, I have one. You mentioned at the beginning that the systems have memo. You mentioned at the beginning that these systems have memory and when you stop applying the current and then you apply it again, it remembers the state. Is there a way to erase these memories also? Yes, there are. It can be erased mostly electrically. In the types of materials that we work, they have a treatment that they apply suddenly a really high electrical. A really high electrical voltage, and when they do that, this is kind of yes, it's a total reset, and then the network, the material tends to come back nearly at the initial state. It can happen that it will still destroy a little bit of the integrity of the lattice and some other things. This also needs to be studied. But yes, there are ways to do the erase in the network. Thank you. Work. Thank you. Namor? Hey, Claudia, great talk. I'm wondering if, either in your experiments or in the theoretical models, have you tried driving the nanowire network with like an AC source and seeing how that changes things? Oh, yes, yes. And we did that in two of our simulations here. Okay, this. Here. Okay, this last one here is not really a sinusoidal. Let me just. Here, for instance, is a simulation that we are already starting to do is a voltage pulse, a train pulse that we apply in some electrodes in the nano-air network. And the blue curve is the simulated current, and we can see the kind of a spiking kind of. The kind of a spiking kind of behavior of the resistance in the network improving after each pulse strain. But in this simulation here of the nanowire itself, we did apply in laboratory, they apply AC voltage stimulus to kind of move these mobile ions that are inside the nanowire and that they make this portray this hysteresis. Hysteresis. Yes, and this is the best way, in fact, to stimulate and control the resistance of these materials. And do you still see this emergent winner take all, even in that case? That is a really, really good question. We needed to test, but we would expect yes, but there is a lifetime for it because again, you start also damaging a little. Start also damaging a little bit. There's also some chemical factors that play a role, but in principle, we should see it, but the tendency is to die out after too many cycles of this AC simulation. Cool, thank you. Any further questions? Let's thank Chloe for the talk. I believe the last. Okay, I believe the last speaker of the day is going to be Nils Vorkar. So feel free to share the screen when you're ready. Hey, everyone. Hello. Just a sec. Where are your bookshelves in yours? I hope you can all see my screen. Yes. All see my screen? Yes. Okay. Stop the recording. Just a second.