So, when that happens, of course, if you had all the resistors had the same value and so on, you would expect to have a linear gradient, right, for the voltages. So, here, I'm not plotting the voltages, I'm plotting the power that will be dissipated by each of the resistors in here. So, you can see that there are some hot spots in there. So, the yellow means that those resistors are heating up much more than the other resistors. If the resistors are The other resistors. If the resistors are in black in here, that means that they are really cold, that there is no currents flowing through them. And the question is: can I get these resistors out of this data? So you can imagine an experiment we have the grid of resistors in here, and you're taking images with a thermal camera to see their temperature. So, can you get out of the temperatures of the resistors the values of the resistors? Okay, so in this case, you can kind of guess. Kind of guess what the solution would be. Well, I know because I did the simulations here. I just put a bunch of resistors in the middle in here, in some sort of inclusion, that have very high resistance or low conductivity. Okay, I might use both terms depending on what comes to my mind first. So, as you can see in here, these two hotspots are in here because this region in here does not conduct electricity. In here does not conduct electricity that well, so the currents have to go around that region, and the path of least resistance of the currents is going around that region here. So, you have a concentration of currents in there, and those resistors will heat up. So, you know that there is something in there. This experiment probably is not enough to tell you what's going on. Why? Because there is a bunch of resistors in here that are not heating up. All these vertical resistors in here have basically no current flowing through them. So, you won't get that much data out of them. That much data out of them to get the resistors. So that can be solved by running another experiment. For example, putting a voltage of one here at the top and a voltage of zero here at the bottom. If you do that, then you'll be able to find, to run current through these resistors, and you'll see also that you get some hotspots around this region, the central region where I put resistors with low conductivity. So, how can I get from this data to resistors? I mean, and if you see the relation here to a continuity respond, I will get A continuity respondent. I will get to that also in a second. Okay, so just to set up notation, everyone here knows about this. This is just Omslow and how you calculate the power that flows through a resistor. Just multiply the current times the difference of voltages that go through that resistors. And I will be working, I'll call them resistors, but I will be calling them disconductivities. Okay, so that's one of the resistance. So when you write the power in. Resistance. So, when you write the power in terms of conductivity, not resistance, then you need to use the square of the voltages, not the square of the currents. I mean, the way I learned this in high school was, you know, resistance times current squared, but you can also think of it as conductivity times voltage squared, or difference of voltages to be more precise. Okay, so far so good. So, here's the setup for that problem. So, I have a graph. A graph is just going to be a set of nodes. To be a set of nodes to fix ideas, you can label those nodes with numbers from one to the number of nodes. And the edges will simply be a subset of V cross V, just the Cartesian product. And the graph will be just vertices tacked onto the, well, toppled with vertices and edges together. So you have an example of this here. You can define this operator called a discrete gradient, which will be taken, which takes a function that leaves on the vertices. That leaves on the vertices, so a function that goes from V to R, and gives me another function that leaves on the edges, meaning that it goes from E, the set of edges, to R. And what does this discrete gradient does? It just takes the values at two different nodes. So remember, it takes a function that lives on the nodes or vertices. So we'll take a function that lives on these nodes and we'll take the difference of these two values and attach it to the edge that's in between the two. It to the edge that's in between the two. Okay? That's all it does. So this is node i, node j, and this is the edge between node i and node j. And here I'll just have the difference between the two. Of course, in this definition, there is a signing determination in there. This, you just fix it once and for all. We just agree on some sign convention. You keep it like that, and everything else will just fall through. You just get, it's consistent with that. Okay? Now, Okay, now out of that, you can define an operator that will come on very handy. It's called the discrete Laplacian, which will take a function that lives on vertices and give me another function that lives on vertices. And if I apply that operator to a function u that lives on the vertices, it will look as follows. So I first take the gradient of that function u, then I multiply that by some function here, which we have. Some function here with a conductivity function, which is defined on the edges, some positive function that's defined on the edges. And then I multiply that by the transpose of this operator or the adjunct. So that transpose will go from the set of edges to the set of two. Sorry. We'll take a function that lives on the set of edges and give me a function that lives on the set of nodes so that everything works out correctly. So this old dot that I have in here is just Hanamar product, like dot star in MATLAB, if you like that. So it's. That. So it's exactly that. And the physical interpretation of this is: this operator: if you give it a distribution of voltages, no matter what, it will tell you what are the currents that you need to inject at each of the nodes such that to maintain that voltage on this grid. That's all it is. Or you can think of it as it calculates the net voltage, the net currents at each of the nodes. That's all it does. So it essentially. That's all it does. So it's essentially a nice way of writing Kirchhoff's law for resistor networks. All right, so what is the inverse problem in here? No, I cannot talk about the inverse problem without first going to the forward problem. So here's the forward problem in here. I am going to first give myself a set of boundary nodes. So this will be the empty nodes in here, and the interior nodes will be all these solid nodes in here. Solid nodes in here. So the set of vertices partitioned between boundary nodes and interior nodes. And the Dirich problem will be: if you give me a function that's defined on the boundary, can't you find a function that's defined on all the nodes such that it agrees with my boundary data? That's what this means, and such that the net currents at the interior nodes are zero. And there are no sources or sinks or currents inside in the solid nodes. Solid nodes. One can show that this Dilke problem admits a unique solution provided that condition for this is that the conductivity be positive and that the graph here be connected, meaning that you can always connect one node to the other node through a path. And also that when you delete the boundary nodes, the graph that is left is connected. So if you have those, that's enough to show that this always admits a unique solution no matter what the record is silent. A unique solution, no matter what the right-hand side, and so on. Fine. What's the inverse problem that I showed you earlier? This is the inverse problem. So I want to find the conductivity sigma, so the values at each of these edges, from this data in here. So this is sigma times the gradient of the voltage squared. So again, this is a function that lives on That lives on the edges. And I do that for different experiments. In my example, I show you what happens when I do it for two experiments, but you can consider in general n experiments in here, and where each of the uj's in here solves the Diricher problem for the same sigma. That's the data, it's consistent with this, and it's, yeah, it's great. Because that is very similar to this continuum inverse problem. So I just Inverse problem. So I just didn't change the notation at all here, basically. So I just have a function here, sigma now, that goes from some domain omega to 0 infinity. And I measure this power density in here, which has sigma times gradu squared, where u solves this Dirichlet problem in here. So again, divergence of sigma gradu equals to zero means that there's no sink source or sources of currents inside the domain omega, and the function. The domain omega, and the function has to agree with your boundary data. This is a problem, an inverse problem with internal functionals that arises when you're doing either acoustoelectric tomography, acousto-optic imaging, or even when you're measuring just thermal noise. It turns out that when you measure thermal noise, you can recover this kind of data as well if you do certain experiments like hitting the domain. In particular locations. I should just say a couple of words about acoustolectric tomography. I think we saw it in a previous talk, but just for completeness, this is your domain omega, and what you're doing is you're somehow perturbing the domain inside with waves. And this, while simultaneously taking electrical measurements somewhere, and with this. And with this, you can recover quantities like this inside the domain because you can just move the perturbation around and sample your domain around, or consider more general perturbations. There's been a lot of work surrounding this problem, methods for solving it, that it's very beautiful for mathematics. There is like zero Laplace, and there are ways of propagating rotation matrices inside. Matrices inside. So there's very beautiful mathematics around this problem. But I'm going to focus on these two words in here, particularly to the approach of Baal, who considered this problem as a redundant system of PDEs. Okay? So what's the idea there? So it seems that it's That it seems a little bit wasteful to do this, but it's a good way of thinking about the problem. So, what it's done is instead of just thinking of sigma as your unknown, just think of sigma and the states or the voltages as your unknowns. So, you have sigma and u1, etc., through un are your unknowns now. And just what you get then is just a big system of partial differential equations. The only problem is this is a non-linear system of partial differential equations, right? Of partial differential equations, right? Because I have a non-linearity here, the gradient of u squared. So that's, yeah, when I did that, by the way, I just put everything equal to zero for convenience. And what I have in here is the measurements. These are the measures that I took with my thermal camera or whatnot. And this is the sigma and the u and the u's that I need to find, they should match the data. So these are kind of, you know, your, these are. Know your these are some equations that tell you that your U is consistent with the physical model, if you want, and this equation here is your data fit equation in some sense, in your system differential equation. I'm saying this is a little bit wasteful because you could think of this as just one big optimization problem where sigma is your variable and then this will be in your constraints. I mean, it's probably the cost is the same, but anyway. Cost is the same, but anyway. So, what's the idea of Jon Bau for this is to write this, linearize the problem. So, if you linearize the problem, again, I just want to make sure there's no confusion in here, I'm taking small perturbations about some reference values of u, j, and sigma. So I assume that I know what u, j, and sigma are in here. These are known in this slide. And the question is: can I find these small perturbations? Is can I find these small perturbations delta uj and delta sigma? And if you linearize the problem that you had earlier, you will see that the delta sigma and delta uj's have to satisfy this linear system of PDEs that you have in here. And it is what it is. You have delta sigma and delta u appears in these two equations. And the way Jon Ball approaches is using Agman-Dubis-Nier-Nberg theory. So he considered this as a system of pseudo-differential operators. Pseudo-differential operators and looked only at the principal symbol of the pseudo-differential operators. And once you put everything together, you get that certain condition has to be satisfied. And if this condition is satisfied, then your linearized problem is injective. Meaning that you get a unique solution for the linearized problem. This is local uniqueness property. It's always interesting to have something like that for an inverse problem. And what's nice about this approach is that it's pretty general. I mean, you can apply it to all systems of, you know, to all sorts of redundant systems of nonlinear equations. When you linearize them, you get that. The condition that he got in particular looks like this. So I just want to rewrite this condition a little bit differently as C star. So this is, this C by the way is the star. Is the spatial frequency variable. So it's the dual variable 2x, or in free space. And then I'm going to multiply this by some matrix, which will be 2 grad U, grad U transpose. These are hats in here, by the way. I'll explain what the hats are in a second. And minus the identity times C. And if this is equal to 0, then you're assuming that you can deduce that C is equal to 0. C is equal to zero. The condition is if this is true for all points in the domain, meaning that if I can prove that c is equal to zero for all points in the domain, if I know this for all experiments, for all n experiments, then the system here will be injective. That's the result. And the hat in here are simply, Are simply the gradients of u, j's, per renormalized so that they have norm equal to one. Okay, that's all it is. So in some sense, this is not like the usual way in which you show that you have uniqueness for PDEs, right, like for elliptics PDEs and so on. Here, you have an indefinite matrix instead of having a definite matrix, and it's not clear where this indefinite matrix is. Indefinite matrix is invertible or not. So you have to assume it. The problem has to, you know, have that built-in in order for you to be able to solve this problem. So how do you do this in the discrete case? Well, again, you can consider the problem as a big system of equations. This would be a non-linear system of equations because you have the sigma in there and the grad u squared that appear in there. But the nice thing is that once you have this, you're just working. That once you have this, you're just working, you can linearize, and then you're just left with matrices, right? So you can interpret this as a big system of matrices. It's going to be an over-determined system of matrices, because in general, you can put as many experiments as you want in here. And that's a good thing, actually, to have more experiments. But it's still a linear system in the delta sigma and in delta u. Even if the delta sigma appears in the L in here, the relation is linear, right? The relation is linear, right? In the way we wrote it down. So that's all linear. Okay, fantastic. I have this system. What do we get out of this? So the condition that we get is a little bit analogous to this condition. But I mean, you have to look a little bit from far away to see the analogy. So let me introduce some notation here. If I have a function here that's defined on some discrete set x to the reals, then X to the reals, the support of that function will be as in the continuum, just a set of x's where the function is non-zero. And I define this s of s, which just, this seems very arbitrary, it will just set a value of minus one inside the support of f and a value of one outside the support of f. So I'm just switching sides. And the condition that we got for uniqueness of for injectivity of this inner ice problem is. Of this inner ice problem is first of all that the support of all the gradients of all the experiments that you did is equal to the edges. This simply means that over all the set of experiments that you're making, you're covering all edges that are out there. So you don't have, if there is an experiment that is missing, that for some reason is not making currents go through that. Not making currents go through that resistor, then you won't have any information about resistors, you won't be able to recover it. So it's a very reasonable assumption to have. And the other assumption is that some sub-matrix of the Laplacian is invertible. So this is the condition that looks like this, because we need to assume it. And what is this matrix? So this submatrix, if you didn't have this S in here, If you didn't have this S in here, if it were just L of sigma, then this submatrix is guaranteed to be positive definite. So it's invertible and positive definite. But whenever you do this, which is just flipping signs of sigma in certain locations, you don't know anymore. It's not going to be invertible. I mean, it may be or it may not be. I can give you examples where if you switch the signs of the resistors, this matrix is no longer invertible and some others where it is invertible. And some others where it is invergible. So you need to assume this, but if you assume this, that system is injective. That's very similar to having something like this. Though, I mean, I didn't, there's no CDOs in the discrete case. I mean, maybe the thing that will be the closest will be to expand in the modes for the Graph Laplacian, right? Or the eigenfunctions of the Graph Laplacian, which will give you something like Fourier transform, but then Transform, but then you're looking at eigenvalues, and the condition will be: oh, there's no eigenvalue at zero, which is kind of what you're having here. So if these are all invertible, then you got injectivity. All right, so moving on, you can do this for the Schrodinger problem as well. So this will be like having absorption in the acousto-optics tomography problem. There is a diffusion term and an absorption term. The absorption term is what this would be. And in the discrete case, This would be. And in the discrete case, you can think of that as just adding a bunch of links in here to the ground. So, each of these red edges is a little resistor that is connecting the interior nodes to the ground. But by the way, this is only if whatever I call here a Schrodinger potential or discrete Schrodinger potential, if it's positive. If it's negative, you can still define the problem and it will still make sense. And it will still make sense, I mean, as long as it is invertible, but you can no longer interpret it as having a resistor because there's no such thing as a negative resistor. So the Dirichlet problem in this case would be to look at the net currents and say that they're equal to zero here, and to find a function that satisfies this conservation of currents law, given that it matches your boundary data. Matches your boundary data. So I'm doing conservation of currents at each of the solid nodes in here. Yeah, so this is, I already covered all this, perfect. And again, you need to, the condition for invertibility of this, I didn't write it in here, but you can prove that it's invertible in some cases. So the corresponding inverse problem will be to measure the power that's dissipated by each of these red edges. Dissipated by each of these red edges. So it's Q times the value of U squared. This is what makes sense in here because this is the difference between the potential at one of those interior nodes and the ground. So it's the difference between that potential and the ground, which is zero potential. So those are powers, and then you just assume that they satisfy the Driker problem. Once you do that, you write everything as a You write everything as a big nonlinear system of equations. Again, those are the m's are your measurements. And then you can get also a similar result. The result will have also some support conditioning here. So in this case, what can go wrong is if these voltages at the interior nodes are zero, then you don't get any information about the red link that goes to the ground, about that leak to the ground. The ground, about that leak to the ground. So you need to have the supports of all these voltages be equal to the hole into your nodes. And on top of that, you also need that, well, this matrices be invertible. That this matrix, this is needed for the Diricher product to be well posed. And also, you need the product to be well posed even if you flip the signs of a few of these links. So again, in the In the, let's say, the case we're most familiar with, where you can always find a solution, is when the Q is positive. So, when the Q is positive, this matrix here is positive, definite. This one will also be positive definite. So, the whole thing is positive. Definite, it's invertible. That's easy. But when you start flipping signs in here, this one is indefinite and positive, definite, plus, indefinite matrix. Who knows? All bets are off. So, but again, you get a condition like this one. Condition like this one. We also looked a little bit at the complex case, and I'm showing you here partial results about what we did for the Schrodinger potential in the complex case. So this is, I'm assuming here that the data that I have is real data, which is what you would expect from power measurements. Power measurements are real. So when you do that, only the resistant part Only the resistant part of that link to the ground, those red links, will be involved. So if I have a general impedance in here, which is written as a resistance plus j omega times something that I always forget the name of, admittance, I believe. But don't quote me on that, I might have gotten that wrong. So this the only part that will show up in the measure is Q prime. Of course, you do have. is q prime. Of course you do have a little bit of information about q double prime inside this, but it's given in in in in indirectly right because the u solves the problem with the full complex q if you do that you do get some conditions you follow the same approach but the condition is a little bit uglier because and I don't know how to simplify this and maybe there is no way of simplifying this that much but it's again that some matrix Much, but it's again that some matrix says have to be invariable, then the whole problem is injective. Anyway, so there's many open questions in here. I'm wrapping up here. For example, can you recover the sigma and the Q at the same time? How many experiments would you need for that? And what kind of measurements? You might need measurements on the nodes and on the edges for this, which is a little bit awkward in the discrete case. That's not something that you have in the case. Discrete case, that's not something that you have in the continuum case. You always have quantities defined on the whole domain omega. You can also show stability results, estimating the conditioning of these operations. Because you're looking at linearizations, you can consider our internal functionals. And these internal functionals have been considered in the discrete case. So this will correspond to measuring just the absolute value of the currents, and this will be corresponding. The currents, and this will correspond to measuring the currents themselves. So, this has been studied before, but you could do the same linearization analysis in here. We're also working with the multi-frequency data. So, what happens if you have data at multiple frequencies? Does the problem become easier or more complicated? I don't know yet. And the last part in here is where if you noticed If you noticed, in the inverse problem that I showed you, I actually have more data than in continuum because of this kind of artificial anisotropy that you have in a grid. So why? Because if you have a grid, so that would be the stencil for the grid, then, and I'm measuring the power dissipated by these two resistors here and by all these resistors, then it is as if I am measuring the power. I am measuring the power, instead of measuring sigma gradient squared, I'm measuring sigma times the partial with respect to y squared, and also sigma times partial with respect to x squared, which is more data than what you have typically in the continuum inverse problem. So there needs to be, if you want to use these results to solve the continuum inverse problem, which we already started doing, then you need to do some other work to match the Work to match them up, to match the two better. Anyway, so with that, I thank you for your attention. Are there any questions or comments? I was wondering if you've looked at how to deal with the noisy data so s so how you're kind of enforcing. So i i it this these problems are leap shits, okay? In the continuum, this is where the results of all the results that I showed you earlier for the continuum inform what's going to go, what's going to happen in the discrete case. Because those continuum results are leap sheets, I can infer that the well, the discrete ones will also be leap sheets. That doesn't mean that they're well conditioned or not. Actually, you'll get bad conditions. Actually, you'll get bad conditioning if some of these links have very small gradients, let's say, or very small currents. You'll get very little data, and then your fidelity for the reconstruction there will be worse. But this is pretty robust to noise. We're actually using very noisy data to do this at reconstructions for the continuum using methods inspired from these discrete inverse problems. And it And it works with horrible noise. I mean, I'm talking about noise that is, we're doing simulations with measurements that you would do with thermal noise. So you get an image that's all patchy and I should have put it in here, but you still recognize the conductivity that's behind and so on. So it does work because it's linear and not too bad. Yeah, so for your discrete problem, if you pass by to the continuum limit, that doesn't correspond to the continuous operator, right? Uh i it it sh should, no, it's just a finite difference operator. Yeah, on but on this regular graph we show it's just the discretization of the regular graph. You can just do the discretization like that. By the way, these results, they don't care about the grid that we're using, it could be three-dimensional. That you're using. It could be three-dimensional, it could be from a Titanahito, whatever, because I'm just doing things boundary and interior, it's very soft in that sense. I remember reading, learning when I was learning a little bit about graph La Pass, and I say you don't have, like, sigma is one, so it's like a really standard graph. But when they pass to the continuous limit, somehow the continuous limit is awaited in operating. Somewhere and it depends on, of course, it may be more general graph that they depend on the weight. Yeah, if it's a general graph, then maybe that's where you start getting like weird things. The distribution will kick in in that weight enough. You're talking about the Garcia-Trio's results and that kind of thing? Yes. So that's because they're working on, they're assuming something about the continuum problem as well. I don't remember exactly, but this is much simpler. If you just do finite difference discretization of what Discretization of Laplacian on your domain, then you'll get this. Or find items. You can use fine elements to its total discomfort. You're right. Yeah. Very nice topic and very interesting constructors. I was wondering, like, in the continuum case, an important step, improving the unique structure and construct solutions with author operating system. Is it easier in this discrete case for that your assumption is private? That's a very good question. Thank you. So it is that actually this result here tells you that you need only one measurement to find the conductivity provided that the gradient of u is different from zero everywhere. So if the gradient of u is different from zero everywhere, then you can zero everywhere, then you can recover conductivity. And it's because you have more data here than in the continuum, quote unquote. There's no notion of space, of orthogonality, of gradients in here. But yeah, the part where the orthogonality of the solutions will come in is probably somewhere around here. You need this to be. You need this to be to be invertible, but that it didn't come up. I don't see where it comes up. Yeah. In the continuous case, what you measure is the gradient. The absolute value of gradient here you can measure in two diagonal directions. So you really only need actually one to form this possible analytic one measured difference, I think. All right. If there are no more questions, let's thank Hernando and all the speakers of the morning session.  Technically, that's your mind. Yeah, so it's not the idea. It works in practice, but we have no theory for Georgia. I don't know that the continuum must be. Well, no, it is the absolute value squared. The problem is that people weren't agreed like this, right? I mean, if you think about the technology, No, I didn't realize that you're trying to use this for the continuum, right? I get like weird results. I didn't understand what you're saying. So, because you're mentioning the power of all these edges separate. It doesn't matter. But whoever it is, you're having a problem, so you tell me. Essentially, the gradient in this direction of the power problem is not much of a distance. So in the continuum, it would be like if I were measuring something like this. Should it be here? Should we be here? Yeah, yeah, I think it's a good idea. And also. Yeah, yeah, of course. Yeah, which is not that realistic. But yet you can play games, and this is what we ended up doing. To say, you know, oh, whatever. We we are going to say that the sigma is on the nose. And then we're going to have some interpolation operator to make it into the edges. To make it into the edges. To put it into the edge. And then whatever you're measuring will be essentially just a sum of the powers of the edges of the power. Yes. We haven't analyzed that particular dispute in the story. So it's worth having a little bit of ticket up somewhere because the things are so stable here. Yeah, yeah. Yeah, you can put so much lotus in mind. What's our question? If you add a little bit of ticker nothing worse, but we have to add tickets. There's some normally somewhere where there's another where I use something somewhere. I don't know what it is. We haven't tracked it down yet. But if we track it down, then that's another disputing problem, and then it's just better because it will be really a disputing problem that you can say you can use to solve the. Can say you can use to solve the continuum one directly. It's really hard to do. This one is just giving ideas about how to do it, but it's not good for that yet. I'm sure that because you've implemented this problem already, right? You never thought this? Ah, okay. What? Because we never thought this. Because I say if I'm re-implementing it, I will have this problem. Implementing it, I will have these problems anyway. So, all I'm saying here is showing that these problems are similar problems to the ones that we get in the continuum. So, yeah, it's not for this. Only today. Tomorrow we'll have the late Thursday. Cool. Thursday is rather. Thursday, I'd rather not have. I want to talk more about these areas. I have students doing discrete case studies but doing But doing one I think they are doing the gap or something. So they're doing like measurements and things like that? So the idea is to we haven't started yet, but we want to put the in a board, do all the so I wanted to make it so they can actually create the system. I wanted to do that at some point. And then do the the sort of The surface in the computer. Ah, I see. Yeah, because I mean, I wanted to do, that would be really cool to do. It would be good if we could collaborate on that, because I've been wanting to do this for a long time. And I actually, so the NSF grant that funded this, I bought some equipment for that. And I haven't had a student that's good enough to, that has the electronics chops to do that. I'm collaborating, so I have a collaborative that does in engineering, that knows how to do. Engineering that knows how to do all these things. Okay, because we can do. I mean, because I could do it, but I don't have the time to do it anymore. So I have a group of undergrads. So I just, I'm waiting for, I bought it, because we have only one Arduino and it's like they were playing only when they go to the lab. So I just ordered like several Arduinos so they can each of them have one at home and start doing Have one at home and start doing things, yeah. Yeah, otherwise, it's like it's impossible, yeah. Yeah, it's probably better. I mean, the one, the one thing that I bought because so I wanted to approach the problem a little bit differently, okay? But no, let me say this. In my mind, this is an EIT system. Okay, no, but that's fine. But EIT, you could do something like this, even with the Arduinos. Just do a little network of resistors, run some current with it, and you should see the powering, the thermal. You should see the temple camera or something that comes up. You could see like a democratic. What I wanted to do, the experiment I wanted to run, but I never convinced anyone. 