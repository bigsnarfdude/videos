Uh, thank you so much. I think I can do this one. Um, I would like to really thankful for the organizer to invite me to be here. This is not a typical community that uh that I'm in, but I think what I'm doing is actually very similar to what you guys are doing from medical imaging. I do have one example on medical imaging that this my student actually worked a while ago. So, um, so this uh talked mostly done by two students here of mine, this one and then Rusty here and then. This one, and then Rusty here, and then hi here. So, it's just a little bit of quickly to my group there. And now I'm gonna show you what I mean by digital twin. So, actually, originally, it was not in the abstract, but I think it's good to show you why we need to do real-time stuff, right? Because there's a demand here. So, what I mean by digital twin is the following where you actually have a physical access here, either your car, an engine, or our body that we want to monitor, right? That we want to monitor, right? Or we want to optimize, or if you have a hurricane that you want to track, you want to do real-time simulation where to put the sensor to actually get more information about a physical phenomenon. These are what we call physical twin or physical assets. So as we are, as a scientist, so typically we actually want to understand, we want to predict, we want to understand things. So what we typically do, we actually domain knowledge in physicists, mathematicians, engineers, we Engineers, for us here in this community in particular, we use mathematical modelings. We actually do them, we discretize with some methods, right? And then we get a digital model. It's not digital twin yet. If you go from here to here, it's just simulation, right? If you discretize PDE, you saw PDE, given initial condition, battery condition, parameters, right, or anything you discretize, that's a forward problem. You know, you mentioned forward problem. So this is a forward problem, right? And so it's not actually a digital trend. Of course, Digital trends. Of course, in your digital models, you have parameters that you don't know. If you're thinking about the weather forecast, initial condition, you don't know. You have to invert, right? So, so, so, this, you need to know initial condition. If you want to do, you know, for us, we do, you know, a lot with our industry, you know, I work with Axon Mobile before from Houston's. So, we want to see where are the oil residents or how big are these, right? So, these are parameters that you don't know in your model. So, you have to calibrate, right? You have to calibrate, right? Or you have to solve inverse problems. So these are actually similar to your imaging. You call imaging, we call inverse problems. Some community call parameter calibration. So basically, they are the same thing mathematically. Data assimilation, same thing as well, right? But the only things that you do continuously, right? Okay, so of course, you also, for example, for this case, for the car, you want to optimize as well, right? Not only you want to do calibration, but we want to optimize something. For example, you want to optimize the shape in order to have the, you know, the least fuel. The you know, the least uh fuel consumption, for example, right? So, all you want to control something about your physical system, right? Of course, you cannot control these uh things, um, but of course you want to ask yourself where I where should I put the next sensors? Because sensor could be very expensive and very difficult, right, to get maximal information about the physical system that I have. So, you can do this right on your digital model, right? So, so it basically, you know, inverse problem, optimal control, and so on and so forth. Then, what do you So forth, then what you do is actually do this of course based on information from the physical system, right? You get data from the physical system, you do this task, any of these tasks, and then you make a decision what to do with it, right? So either you get the optimal control on radio or optimal shape, you put in here optimal movements to achieve some health benefits, right? Or to burn the most calorie, for example, or you know where the sensor that you put should put to maximize information. That's where you make a decision to put it back to the physical systems. Decision to put it back to the physical systems, right? And then the physical system actually generates new data and then you update your model again. So, this is actually digital training. What I mean is a completely closed loop, right? It's just not a simulation code that we typically talk about. This is a closed loop online, right? Continuously coupling between the digital model and the physical model. So, you want to make this as most close as possible to here. On the other hand, you don't want to deal with here because that is too expensive or it's an Because that's too expensive, or it's you know, it's unreachable, right? For example, in this case, so that's so in this case, in order, for example, the hurricane is the best case. And I'm going to show you some earthquakes example later as well, is that, you know, if you want to evacuate people when a hurricane comes, you know, I don't have to deal with that problem, you know, except to be the Metro and Andres. You are in Houston, so next to the coast. So we don't typically in Austin have a problem with hurricane. But if you want to actually predict or you want to actually do any action, Or you want to actually do any action, right? You have to do it in real time, or even faster than real time, right? In order to evacuate people and so on and so forth. So, both of these, right, forecast and decision-making control optimization need to be in real time or even faster in real time in order to mitigate big consequences from your physical assets. So, that's actually where we need real-time or very fast things to do. So, in the past, my group actually would do. So, in the past, my group actually we do a lot of high-fidelity simulation. Typically, we do high-order discretization, finite element discretization. For example, so this is the example that I just mentioned to you, where we do actually earthquakes simulation and inversion on the full earth scale, right? This is actually we do like 10 more than 10 years ago on 222,000 processors on the largest supercomputer back then. So, this is just a simulation of a Japan earthquake, right? The Tohoku. And then we offshore, we use this. And then we upshore, we use this. We actually, this is just a forward model. We actually invert, we based on the real data, we invert for the material property of the Earth. So, this is another one that we do inverse scattering over a complete aircraft. This is what I showed you, the half-aircraft, this is electromagnetic scattering problems, right? And we have measurement, we want to invert for the shape of the property of the system. So, this is actually more on magnetic hydrodynamics and instability. Dynamics and instabilities. We are working on English problem for that, and so on and so forth. Okay, so high-fidelity is nice, but it's very expensive. You see that we have to do most of all of the simulation, right? On these. So this is a toy problem, but this is a more complicated problem. We have to, this is actually, we solve the full shallow water equation on the whole Earth scales here. So if you want to do inverse problem, even forward problem, this is actually required supercomputers already. And it takes, you know, minutes or weeks or hours on supercomputers. You know, it is impossible. On supercomputers, you know, it is impossible to do a real time. So that's why there's a need to actually do some kind of real-time possible or fast. If you don't want to say a real-time, then fast possible forecast and inversion. Actually, inversion is the key thing, right? Because inversion, where things become complicated. Actually, let me see how do I escape this. Okay, perfect. Okay, so that's actually a little bit of motivations. Now, let me actually go get into the thing that I'm going to show you. The thing that I'm going to show you today at a premise in the original abstract, but you know, a little bit connection here. So, we work on inverse model non-linear, right? What do we mean by that? We're going to show you later. So, this is actually the closest thing that we application that we do to this community is MRE, right? Magnetic resonant elastographies, right? So, this is basically the elastic wave equation, not acoustic, you know. And this is a frequency domain. So, what you want, you So, what you want to know is that you know the u, and then you want to invert for, you know, for example, xi modeling here, right? Um, this is, of course, we have to pose an infinite dimensional setting because these are functions, right? And we have to develop methods on an infinite dimensional setting and we discretize at the final because we want discretization invariant similar to the last talk. By the way, it turns out that you know, my Monday talk was canceled because, or was moved because you know, uh, we have the fly cancel, which actually is good because after Lucra talk is. Good because after Lucra talk is good because I do something similar, like the only things that I'm now going to do non-linear, and when actually we're not going to learn the primary regularization, we actually will learn the whole English map. We learn the ticket of English map. So actually, it's perfect. And whoever I strange, we will need to exchange my position with this position today. Thank you. And of course, thank you, the organizer, for being so flexible, right? Okay, so this is the inverse. So we do an invasion framework, of course, right? It's a Bayesian framework. This is a map. That's a maximum. Framework, this is a map, there's a maximum of hostority. So, this is the true, right? With the noise, and this is our reconstruction for the means, and then for the mean here, and then, of course, the weights, right? And we also have uncertainty estimation as well, but I'm not going to show it here. So, the key thing actually I'm going to show you, actually, what we do typically not done in practice is that because mu is a functions space, right? So, you invert for mu, which is in this case, the property of your material. The property of your materials is some function you have to discretize. How do you know to discretize? How many mesh points? Where should I put more mesh points than the others? I mean, that's a question that we have to answer, right? I mean, that's actually, but it's difficult. Typically, we do mesh refinement we do on the on the solutions. You, you know, doing mesh refinement on me is actually more difficult. So what we do is actually uncertainty-driven estimations. So what we do is actually, we saw in Bayesian optimization inverse problem, we estimate. The inverse problem, we estimate uncertainties. And then, where then, since uncertainty is lowest, right? We actually refine because when the uncertainty is lowest, it's the most meaningful or the best place or the most informative region that you know, right? So, you want to know more. So, what we do here is actually we looking for, we estimate uncertainty, and then we actually refine where the uncertainty is actually low, right? Because that's exactly what the region where we're most comfortable or confident about. So, that's how we actually. Confident about. So that's how we actually do mass adaptation for mu. Okay, so that's actually a little bit of connection with what you do in this community. So now we actually, now we go back to the more generic, of course, this is prototype problem here. So we do PD constraint inverse problem. That's it typically that's what I do in my group. So we don't call data, you call data fidelity, I think. But in our community, we call it data misfit, right? So it's a misfit. Misfit, right? So it's a misfit between your computer prediction and your actual data. Of course, you see the realization here, right? Of course, you can think this is actually Gaussian prior as well, if you wish. But for the simplicity, just look at the deterministic now. So for example, right, so the difficulty here is the pollen, right? It's unlike the medical imaging that you have shown, that is that even though even though our PDE, so this is a single possible. PDE. So, this is the single possible PDEs, right? Linear PDEs, right? Of course, now I'm showing you actually also, I work for the initial condition, right? It's the initial PDE, initial condition, then the relationship between W and U, which is G here, is linear. But most of the time, we actually would invert for K here, right, or V. So even the P V is linear, the inverse problem is actually non-linear because the relationship between W and K is non-linear, right? And they go through. Is non-linear, right? And they go through basically you have to invert for solve the PDEs, right? So each of the evaluation is very expensive for us, right? So for you, you apply A on something. That's how, you know, if you have A, that's not easy. But for us, this is a soft. You have to do simulation here. It could be very expensive. It could take hours, depends on where you, depending on the problems. So that's actually the first challenge. So that's what we call high-dimensional state. You have to discretize, right? Expensive forward solves. Expensive for solve. So that's the first challenge in our problem. The second challenge is the high-dimensionality of the parameters, right? So use again in some function space, you have to discretize, right? So even optimization in high-dimensional place, you know, could be, we do PV constraints. So that's could, you know, if you do it deterministically, that's fine. It could be not that big, you know, if you do Newton method, so that's not a big of the problem with the curse dimensionality. But if you do it in statistical saying, which Dimensionality, but if you do in statistical sense, which we do, then there are no points when you do sampling, right? When you have to do sampling on high-dimensional parameters, right? Here, it actually infinitely we digitize, right? We do sampling, it's actually very, very expensive, right? Curves of mentionality in particular. And of course, for our applications, another challenge could be is actually the data, right? The observation could be very high-dimension. Remember that the earthquakes problem that I showed you, you know, in the US, at least, right, we have, you know, at least some of the projects I'm not involved from NSF, right? From NSF, right? So they have about seven or eight hundred semimeters, you know, to sensing, you know, listen to the Earth, the real thing, right? They move around the US to listen to the Earth. Every silly millisecond seconds, you get terabytes of data. So you have a huge amount of data that you have to deal with, right? So that's you can have a problem with I.O. If you do back propagation or you do adjoint method, we call adjoint, right? We don't call it back propagation, but it's the same thing. So then that's what should be. So, then that should be very, very expensive in IO as well. You typically have to do checkpointing because you cannot fit the data in your memory at all. So, the problem with our computing system right now is that we are not computing valve, right? You can increase the number of processor nodes, but each processor, each node actually memory bow, right? So you have memory problem. So, this is actually a challenge as well. Okay, so that's the challenge that we have to deal with in our context. So, what we're going to show today is actually we So, what we're going to show today is actually, we're going to try to, you know, learn. You want to want to do this fast, but I'm not going to show this today. What we're going to show today is actually how to actually do the inverse problem fast in some meaningful sense from the inverse problem setting. And what we're going to do is show, so is that we use neural network. Okay, so let's see. Actually, let me, I'm going to show you a couple of things. Of course, this is the two things that, of course, this is the key thing that I'm going to show you today. Of course, this is the key thing that I'm going to show you today, but actually, I actually wanted to show you a little bit of our unified constructive framework for neural network universality, right? So we are, I mean, at least, you know, apply mathematician or mathematicians, we have density, right? So if you do machine learning, you don't call density, you call universal, right? Because that's universality is nothing more density of some function space into another function space. Okay. So what I actually Okay, so what I actually gonna try to do quickly on if you actually are interested in the universality, right? Because you know, right, any new network, you have, you know, activation function we discussed before, any different activation function, Rolu, you know, onki-sigmoy, different activation function can have different network, right? How do you know it's universal? Of course, if you look in the literatures, each activation function people have different proof, and it could be very technical, right? When if you look at the original proof by At the original proof by Hornick, I think, no, no, no, I forgot the name. It's actually Harm Ronach theorem, which is very complicated, very elegant, but complicated. So I'm teaching the class. I'm only trying to, you know, make something that's easy for the engineer and my mathematicians. So actually, what I came with actually actually easy, okay, of course, right? These are usual things, you know, we get funding from different federal agency. By the way, I'm actually jealous with you because I cannot. I'm actually jealous with you because I cannot never get into Air Force because it's very difficult in the US for some reason, very competitive. But you can get there for good. So you must be very good. Okay. So we use, we use, right? So what we do, what I'm going to show you, actually, we can apply mathematics here to understand deep network actually better. So for me, I'm coming from the finite elements communities. So this is the well-known hat functions in finite element approximation, continuous finite element methods, right? Continuous finite element method, right? So if you, this could tie your model or function with hat functions, right? Then we know that should converge at your refine the mesh. And you know, it's not something new, right? But this is how we take it here, at least here. For each half function here, you can actually a linear combination of three relu, right? So if this is actually a universal or dense, right, in the space of continuous functions, then the four ROLU automatically. So you see that immediately you have result from. So you see that immediately you have results from finite elements method if you make connection between ROLU and the half-function here, linear half functions. But the question is: okay, the ROLU is fine, but how about the other? Only, if you look at the literature, there's a zoo of activation function. How do you actually know the others functions? This is ROLU, of course. How do you know that the other functions? Actually, some of them actually doesn't have even proof for the universality, but people use it, experiment with it, and it's actually worked well. Experiment with it, and it's actually worked well. So, is there a way, a unified way, or an easy way to actually put one theorem, right? One single theorem that works for only functions? So, that's actually what that's what I'm trying to accomplish, right? Use using the simplest possible mathematics. So, actually, I'm going to go through a little bit. Actually, I still have, you know. Yeah. So, very, very quick, right? So, I actually use the standard thing from the function analysis if you have approximate identity or, you know. Have approximate identity, or you know, you know, a modifier, right? Some of us talk about before cut up, right? So, so you see, that you know, if any function, if I make a convolution with B theta here, right? So, B theta is actually a scale and then the stretch and then scale of some B, right? For B, you need to satisfy this, right? If B is actually integrable, of course, this is actually the key. This is actually easy, right? If B is integrable, right, then you can construct, you get Then you can construct, you get multiply a scale and then multiply one theta. This is one-dimensional setting. If you have n-dimensional, you have theta to the power n here. And then you make a convolution of your function with the b, then you have f tudal, right? Then of course, right, you know that f tudo is actually as close as possible to f in many norms, depending on the regularity of your f, right? This is a standard modifier results in functional analysis, especially if you want to show that. Analysis, if you especially if you want to show that you know uh the the space of infinitely continuous function with compact support, right, is then it's an LP. You know, this is actually a standard approach, okay. So basically, we say that, okay, we start with the uh standard result here, so it doesn't seem to be any connection with the PD of the neural network yet, but you know, wait for one second. So, if it's approximate identity, then you can show that F2 though, right, close to F in any norm, of course, depends on F, but in particular L2, right, with very mild conditions. L2, right, with very mild conditions. So, the second ingredient, so first ingredient approximate identity or modifier. The second one is numerical integration. So, I'm going to look at the function of continuous, space, continuous function on compact support. For now, I'm going to discretize with Riemann's integral. And so I can actually discretize and then look at Riemann sum, right? So, this is our original convolutions. This is our aptitude, which is an approximation. Then it will run Riemann sum on this because it has compact support. I can do Riemann sum here. Compact support, I can do Riemann sum here, right? In a deterministic sense, then I call this the F hat, right? Of course, we know F hat technology is to F turtle, right? Of course, I'm going to assume that's continuous. Now, I know the F hat is going to continue to F turtle in the uniform norm, right? F turtle in turn actually converts to the F in uniform norm. So, by simple triangle inequality, you know that F hat, right? F hat actually can be as close as possible to F in infinity norm, right? Password in infinity norm, right? In any design accuracy that you want, okay. That's clear. I mean, not even my result here, right? But actually, what you think, what you see here, right? As soon as you do here, this is the important step, right? If you look at here, actually, this is actually one hidden layer new network. So that's a key. So that's the key that I explore here, right? So far, I just, you know, a standard function analysis and the numerical integration, very simple. But what you see is actually, this is, you know, equivalent. So f hat is actually nothing more. Equivalent. So, f hat is actually nothing more than the one-hitter layer new network, right? X in here, and these are actually bias. You know, see that Y bias here. And then, with the activation, if B theta is activation function, this is the weights, right? Then actually, what I have showed you, I explicitly construct, right, one hit the neural network, explicitly, what the bias is, right? What the weight is, right? And what is actually coefficient here, right? That actually can make app have to be as close as possible to app, right, in any design. Close as possible to app, right? In any desired accuracy, of course, right? We have to assume that we know app, right? Of course, this is just the theoretical results, and nothing actually measured here. But the key thing is that you notice this is actually a one-layer neural network there. Okay, so as soon as you notice that, then you see that, you know, as soon as B theta is approximate identity, and you use an activation function, then automatically your one signal, one hidden layer neural network is universal or dense in the spacing. or dense dense in the sphere continuum function. Okay, so but the problem is that you know, remember that B theta or B, right? B comes from B theta come from B, B to be integrable, right? But you cannot use directly on these, right? These are none of these are actually integrable. But remember, remember the half function is a linear combination of the three, right? And the half function is actually integrable, right? So if I use, so if somehow I can find a linear combination of any of Linear combination of any of these, right? And the linear combination is integrable, then I'm done, right? So that's exactly the notion that I introduced now. So it's called the network approximate identity. So if you give me an activation function, any of them on the list, and if there exists a finite linear combination of your activation function at different ways and biases, and we assume that if that is in L1, then we're done. B, right? The linear combination is in L1, then B theta is approximately. Than one, then B theta is approximate identity. And because B theta is approximate identity, B theta is actually universal, right? And if B theta is universal, then sigma is actually universal as well, because B theta is actually a linear combination of sigma, right? So you still have one single hidden layer of neural network actually universal. Okay, so that's that's that's that's the key results. So again, let me summarize here: three ingredient approximate identity or modifier, if you wish, right? Which is standard. Which is standard mathematical community. Integration, very simple integration to approximate convolution. And then I introduce the notion of network approximate identity. Then what I need to do is so we have that, right? If you have these three, you automatically have the universal university. So the only thing that you need is to show this. Any activation function, if you show that actually there exists a network approximate identity for that activation function, then you're done. Activation function, then you're done. And that the proof is actually quite easy, right? And what we do is actually we define a difference. So it's actually that we borrow we give you on the standard applied mathematic tool here. So you see that, so these are these are sigmoid functions, these are tension, right? Hyperbolic tensions. This is the logistic functions. So these actually are poor, not L1, not integrable. But it turns out that, you know, the But it turns out that you know the finite difference are updated actually in L1, which is very nice, right? So, so that's that this is actually the approximate identity already, right? So, this is new network approximate identity because when I have a linear combination being ML1, I'm done. So, it turns out that all the activation function out there are actually L1 in this M or approximate identity in this M. It's actually, there's a linear combination. Linear combination. In fact, you know, what I didn't show you is a trick, right? If you look at the derivative of that functions, that's what I do, right? I look at the derivative of any activation function. So the first derivative or the second one, right? Or the third one, or so on. As soon as the derivative is actually L1, I'm done. Because then I just do finite difference approximation for that derivative of that function, right? Then become linear combinations and they become network approximate identity. So you see that, right? You see that the sigmoid hyperbolic tension and logistic function, they are not originally. logistic function they are not originally they are not not l1 right but you see this is the the the the uh the uh the the finite uh uh um finite element approximation of the uh first derivative or second i think the first derivative this is the first derivative that's second derivative all of them look the same all of them look at bell shaped function right and then 1d and 2d and multiple d's okay so uh uh um so i i i i i that's that's the key that's a very easy and it's actually worked for all activation function one single proof very easy right Activation function one single proof very easy, right? Uh, the only thing that the two activation functions that I cannot deal with is actually a sine cosine because no matter how many derivatives you take, it's still not lying right. So, that's that's one that I cannot deal with in this context. Of course, I also work on, I want to show, you know, how many, how many, how many, you know, neurons, right? This is one hidden layer, right? How many neurons? What I show you is a Riemann. Of course, doing Riemann restricted into the boundary domain and second. Into the bouted domain. And secondly, it's actually not general in the sense. So, what I do is I'm going to look up the again bout it, but I assume my app need to be lipstick and of course integrable, of course, right? Then actually, we can show, we can show we can do, and then we just do sampling. Instead of do Riemann, we can do Monte Carlo, right? M is a number of neurons or number of evaluation, right? Then we can show that the F hat that I showed you before. That I showed you before, numerical integration via Monte Carlo, is actually as close as possible to the original function in the infinity norm in any desired accuracy that you want, but with high probability, right? This is actually a concentration measure that we do here, not deterministic results. Okay, so actually, I'm going to move back to the main thing. I'm just excited to share with you if you care about, at least for me, right? But when I started, how do I know the new network is good for my? How do I know the new network is good for my purposes? At least, you know, have some indication that new networks actually can approximate anything well, right? Easy on any desire accuracy, of course, that's not what you want before you even use it, right? Okay, so hopefully, you know, if you're interested, you can look at that. It's a very simple thing, but actually work for own activation functions. That is the key. Now, I'm actually going to the main things, which is the learning inverse map directly. So, this is my two students again. So, this is my two students again who actually did on the work. And then we talked about uncertainty quantification as well. So, what we have here is actually the U. So, in the previous talk is an X. Y, I still use Y, but I U instead of X. So, to make connections. So, the naive way to learn the inverse map is to take from the data and then return the X immediately and minimize this, right? Purely data reverence. Of course, you can add regularization for the way in bias. Of course, you can add regularization for the way and biases. Of course, this way and biases regularization is very questionable because way and biases itself are they are they themselves artificial. What do you mean by the prior on something artificial, right? But let you know, stay with the purely data-driven for now. Okay, so we will start with the purely data-driven and then we ask ourselves, we're going to look at the core, we look, we work on a non-linear setting, but what we're going to ask ourselves, how about we're going to do a very simple setting, everything is linear, what actually the what does What actually the what does the new network actually tell me? So I assume that the forward map, right? The forward map is actually linear, right? And the neural network itself is also linear, then you can actually do solve an optimization problem very easily to get to the optimal solution. This is optimal way and biases. But then you plug in any new observations. You actually, this is your inverse solution immediately, right? You don't need to do anything at all. You should evaluate. But we look at here, we said, But we look at here, we said, you know, we see what the neural network was, but it's not clear, right? So we conclude that it's not interpretable, but maybe you can find something. So, what we're going to do is actually we're going to change a little bit, little bit, okay? So, recall that this is the purely data-driven approach where we actually regularize that way in biases. So, what we're going to do is actually going to do implicit regularizations. Forget about U0 for now. This is U, right? But I'm going to talk about U0 in a second. About user in a second. So, what I'm going to do is implicit regularization through the physics. So, that's the key, right? So, remember, the F is the forward map. So, that means you have to solve PDEs, right? Given U, we see the opposition of U. If you give me a U, right, I can solve PDEs and I get to Y. So, if you look at this, so there are two ways to look at it. So, the first way to do implicit regularization, right, through this, this, the physics term, right? We don't want to recover any inverse map. Want to recover any ingus map arbitrary based on data? We want to recover the inverse map such that when I push it through my physics model, it returns the data. So that's the first interpretation, implicit regularization. Second, if you do auto-encoders, you know, I think the talk before, the previous talk talking about auto-encoder. So you can look at this approach that we do here is auto-encoder technique as well, right? You start from a data, you go through a new network, but this is the encoder. This is the encoder. The decoder is actually a physics decoder. That's the only thing different than the standard out encoder, right? Where you put both new networks here, the decoder itself is actually a physics, right? But this is the expensive part, right? You want the new network output. When you put the input to the Ford model, you recover the output as much as possible. And this is how we train. And one more thing that we do is actually we don't use U. We U0. Zero can be some prior knowledge, right? Know some briar knowledge right about your system. Let's say if you want to invert for the heart of a person, you know, nominal shape for the heart, right? So, user is a nominal shape or some prior knowledge. So, why is it important? Why is it important? I'm not doing medical images, of course, I'm talking nonsense here, right? But thinking about this, in the practical context, you can do measurements, right? You may have measurement data, but you may not know the image of the harbor. Know the image of the horrible persons. So you can collect the data, but you don't know the image. So this framework automatically applies for that scale, where you have measurements for different people, right? As the data and training data says. So this actually not supervised. And it's actually called unsupervised either, right? Because it's not in the standard unsupervised. But all we need is actually observations, right, from different objects or different persons. And then we solve this, right? We optimize for. This, right? We optimize for the weight and biases, right, which is in the U star here. Okay, okay, so now, you know, what can it tell us? Again, we look at the simplest K linear model, linear neural network. What we actually saw is, again, it's very simple, linear Jebra here. You actually can show that the T-net with T-net, which is a Tiger network, right? A neural network. Actually, the solution, the optimal solution is nothing more than the Ticken of variables. Okay? So, so we mean, of course, in So, I mean, of course, on purpose, right, you see here. In fact, when you learn this, you learn the ticket of revelization. You see that this is a tick-on of revelizers here, right? U0 is a prior, right? This is a tick-on of revelization. This is the data fidelity or data misfit term, right? So actually, we learn the ticket of solutions, right? So we don't learn the inverse map directly because you know inverse map is actually unbounded, right? And for us, our case is not even injective, right? For our non-linear setting, it's not even injective. It's not convex. Setting, it's not even injective, it's not convex, right? And it's not stable, but we don't learn that. We learn the chipnot inversion, right? The chipnote inversion is actually map, is actually a well-posed, right? Map. So we learn the well-pose map, not the U-pulse map. Okay, so of course, we have some results for non-linear as well. Let me skip this basically on the universal. A universal approximation. So, what I'm going to show you here is actually because you talk about and we rely this as well, right? Regularization. So, we're going to do regularization, implicit regularization as well through data randomization. So, remember this, Y is our observation. Remember that, right? Why observation for different people for different objects, right? Which, of course, we don't know what objects, but we know the prior, right? So, what we do is if we do something very silly, of course, this is actually well known in the machine learning community as well, is that we actually randomize. We actually randomize the data, right? We randomize the data with some epsilon, randomize the data with some epsilon, and then we replace why. So we want to work with the randomized data instead of original data. So this is what we call randomized, you know, J or loss of T net. Okay. So what's the point? So the point is that, you know, on average, so what we can show that's on average, on average, the randomized loss is actually your original plus functions. Of plus functions, right, with that randomization plus realization. And this revelation parameter is, in fact, the noise variance here, right? We need to use Gaussian because we need some concentrations of measure here, right? Because we want this to be as close as possible here. And then add some high-order term here. But the key thing is actually this, implicit, right? Of course, this is just analytical results. This, we never add on D terms. What are the terms? So, D terms, if you look up here, especially. Terms, if you look up here, especially I'm going to focus on P1 and P3, right, first. So, P1 and P3, you see that basically I want actually to revel like the smoothness of the network. So, this is almost like sobolop regularization for the network, right? This is the gradient, the trace. This is positive terms. And then, P3 is actually because we minimize this. Because we minimize this. So, if we assume this is small, we actually make this one, this one to be small as well. So, basically, we want not only the second derivative, the first, but also select the second derivative of the network to be small. So, actually, it's implicit regularizations of the, so H2 symbol of regularization for the network. So, that's from the data misfit model, right? This is from the data misfit terms. Now, the beauty of this term, which is what we introduced, right, which is implicit regularization. We introduce right, which is implicit regularization term, is that of course we want the sign here, which is inverse, right? The right inverse of the forward map. That's what we want. This one, we want this to be identity. But if you do randomization, not only this to be close, because when you minimize, not only that to be close, but also you see that the gradient and also the second derivative also to be closed. So implicitly actually impose on not only the smoothness of the network, but also make sure. Network, but also make sure that the network to be act as a right inverse of F to the second order, right? So that's actually the key point. Actually, so it's some kind of, you know, the beauty is actually some kind of H2 sublux regularization implicitly, right, by randomizations. And actually, to do demonstration for you to convince you, right, we look at a very simple regression model where we actually can compute P2 and P4 directly. And this is, but remember the P2, P4 is from the physics term. P4 is from the physics term that we actually uncurl, right? So, if you don't, this is the true, if you don't, you do the original data, right, without any noise, this is what you get, right? And this is the true. But then you're starting at explicitly P2 and P4, you see that you get better, right? You get this one, it's not clear, right? It's actually better, but not here. But P2, P1, and P2, P2 and P4 together now is actually very stable and very close. We would recognize. So see that implicitly. Recognize so, see that the implicit regularization get it make it better, right? Think about like Hermit interpolation, right? If you do original one with that randomization, it's just you know Lagrange interpolation, right? Now we actually enforce the derivative to be closed as well. So, Hermit interpolation actually matters, right? We know that. That's another way to think about it, right? Okay, so I start a few minutes late. How many minutes late? I think seven or eight, something. Time is essentially all. I need is essentially all the types of user available. Oh, this is done. I'm done. Okay, so it's just a numerical result. I'm going to show you this inverse problem where I work for the heat conductivity, which is U here, right? The first one is heat conductivity problem. Second one is a Berger equation. And the third one is Navier-Stubb equation that I'm going to show you. Just very quick numerical results. So that's going to be taking one minute. So U is a parameter that we're in work for. This is very non-linear, right? Non-linear in this problem with a few measurements here, right? The question. With the field measurement here, right? The question is that what is the U, the parameters? The new network here, the T-NAP that we have here, this is a T-NAP, which we consider a gold standard, which is a percentage, the error, this is non-linear, right? So this is 50 data, 100 data, and 200 data. So you see that as increased data, the TNAT, our solution converges to the T-Net. Of course, we don't have quite the proof of the non-linear case yet, but you can see the T-Net is actually very close to the T-connect, which is the black here, right? The black here, right? But the purely data-driven is not very good. And of course, the axis is actually the regularization parameters. If you want to ask me what is the best regularization parameter, ask him. You can find the best. He will, you know, empirically show you the variations. So I'm going to show you for a particular case. Of course, this is unseen data. This is the TigerNov. And this is after you train, you should evaluate your network, right? This is our T-Net, of course, very close to Tigonov and to the exact one, but of course, the naive pure. One, but of course, the naive purely data even is not good. And notice that we only tram the data, right? So, thanks to the physics term, you use very limited amount of data without a physics term. Of course, you cannot learn anything with 20 data, not you know, let alone learn an inverse map, right? Okay, so we do similar thing, but now for the Berger equation, where we want to invert for the initial condition, this is non-linear forward map, right? And we only have measurement at the final terms. Um, so uh, actually, let me skip to the Navier-Stok equation here again. We invert for the initial condition. Again, we invert for the initial condition where we haven't had measurement at the final time, a few measurements. And this is a tick-no, right? Inversion with this data at a few point at the final time. And we invert for the initial conditions. It's a tick-on-up. The exact, of course, right, ticken up, do the best possible. T-NS is very close, but the other one is not good. Again, we use very limited amount of data because of the physical term. Okay, so what do you mean by real time, right? So you see that ticking up is actually, if you saw inverse problem, you tick and up is actually. If you solve inverse problem, you tick enough, it's actually take more time, right? When you have more complex problems, but T-Net, you know, regardless, you have a same amount of time, right? Very fast to solve. So the speed up actually, even for 2D problem here, is order of five order magnitude, you know, faster. Okay, and then we also do UQ, but the key question is how to do UQ in the new network. That's not going to be another talk, but we have a way to do UQ in the meaningful inverse setting as well. Setting as well. Okay, so I'm going to stop now.