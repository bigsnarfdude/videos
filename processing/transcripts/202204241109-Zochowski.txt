Um, today, so yeah, without further ado, my next speaker is Michal Prokovsky. He's going to be talking about evolving network representations during a sleep-dependent memory consolidation. Hi, everyone. I'm really sorry not to be there. And Jorn, thank you very much for the invitation. It was really a great workshop, and I was very happy to listen to many talks yesterday and on Friday night. So, before I get to the gist of it, let me just quickly tell this who. Of it, let me just quickly tell this who work on this. There's people from my lab, and it was in collaboration with Sarah Aiton's lab and Victoria Booth and Len Sandry from the Department of Mathematics and Department of Physics. Actually, I'll tell you a brief summary of work that's been done during the last couple of years. You'll see some citations to work that's already published. So, none of us have any doubts that neural representations in terms of firing patterns that Terms of firing patterns that you know form representations, and on the other hand, that we recognize, and on the other hand, they form decisions and actions. So, for example, here is a very simple, very simple picture of an orchid. And of course, if you want to generate a decision or action, that's the natural thing is to do to smell it. But of course, the picture gets slightly complicated because your decision and action and the representation you build depend on your previous interaction with the plant. Yeah, if it turns out that this build. With the plant. If it turned out that this beautiful plant would be a man-eater, probably smelling it would not be the right thing to do, but actually running away would be a better thing to do. And also, conversely, if I change the presentation and show you a lion, probably smelling the lion is not the right thing to do, more likely that you'll be try running away. But of course, again, it depends on your interactions and your prior knowledge about lion. If this lion would resemble a kitty cat that you have living at home and would... Have living at home and it puts pudding next to you, probably you will not need to run away. You will need to be able to pet it and have no problem. So the point I'm trying to highlight that the representations that we are building are based on the memories that we have and are based on a very complex interaction of different constraints and different dynamics of the networks. So trying to summarize it in some way, which is of this is of course not complete. This is, of course, not complete interactions. Yeah, but well, everything is generated through network dynamics. And this network dynamics will generate your function, you know, memory storage, memory recognition, behavior, actions, or pathology, like Klaus was telling us today in the morning. But now these dynamics can be formed through different venues. On one hand, there was a lot of talks that touched on not even synaptic plasticity, but essentially. Synaptic plasticity, but essentially wiring of the networks. Yeah, so the wiring of the networks will determine, which of course determines network structure, will determine network dynamics, synchronicity, other aspects of it. But then we have another branch, which is very important to remember. And Mahid Mojarani was talking about this, and Klaus, in context of epilepsy, the neuromodulation, how neuromodulation affects the behavior of a single. The behavior of a single neuron. But then, of course, the behavior of the single neuron affects the network dynamics, as I'm going to show you in a moment. And then, actually, the loop starts interacting here, because the fact that we are going to change network dynamics because of neuromodulation due to changing neuromodulation, this will, through synaptic plasticity, affect network structure, which will change network dynamics, which again can change neuromodulation properties. And we have those interacting loops and things get very complicated. So, I'm going to. complicated so i'm going to talk this in in terms of or in context of sleep and of course we know that you know we all need to sleep whether whether it's you know primates mammals birds this is again mammal i'll tell you a story about this in a moment that's why it's here and even slugs slug have very similar architecture in terms of dynamics to to to all those other species the interesting thing happens about in in in dolphins uh because Dolphins, because dolphins cannot sleep. I mean, usually sleep is considered a global brain phenomenon. So we fall asleep, we don't remember usually what was going through the night until we wake up. And of course, dolphins cannot do that because dolphins from time to time need to come and surface and catch a breath. So, you know, global brain sleep state, it would be detrimental for them. So, actually, biology couldn't get rid of sleep completely. So, actually, this is one of the few examples where what we consider Examples where what we consider there is a local sleep, yeah. So, one hemisphere at a time, yeah. So, one hemisphere sleeps, the other is actually paying attention, allow the animal to move, and then it's being reversed. So, of course, we, you know, sleep clearly is a very important phenomenon. We don't really know, understand what it does, but you know, assumption is if biology could get rid of it, it would get rid of it because, well, we are wasting a lot of time and you know, when we were living on savanna, that was actually pretty detrimental to our health. Actually, pretty detrimental to our health as during sleep, some predators could attack us and things like that. So, let me just tell you briefly about the structure of sleep because I will use some of this information later in the modeling. So, the sleep is not a continuous phase. Actually, it loops quite significantly through the night. You see this changes as we go through sleep. So, you know, we start from wake, we go into this non-REM sleep initially, deep non-REM sleep, then we come up after about the cycle. Come up after about the cycle, last about 90 minutes. We come up and we are in REM sleep, and then we go again into the non-REM sleep, and we oscillate five to six times during the night. But you also see that actually the times and the depth of the sleep changes throughout the night. So it's clearly not a uniform phenomenon. Just looking at the recording of EEG, so here you have wake, high-frequency oscillation. RAM is not that much different from this, but as you go. Much different from this, but as you go deeper into the deeper, deeper stages of sleep, you see this generation of this, what is called slow wave sleep. And that's why those two stage three and stage four are very often referred to as slow wave sleep. And what about the experimental facts in terms of what sleep does for the brain function? Well, there is a lot of evidence and starting actually very early because in 1924 it was shown that actually the consolidation of Shown that actually the consolidation of memory happens through sleep. And in this particular example, the subjects were asked to learn syllables, some number of syllables, and then they were allowed to sleep normally or not sleep. And the question was how many of those syllables they can remember some hours later. And generally, what people found out that after sleep, they remember more syllables than if they were not sleeping at all. So it was one of the first results that pointed in the direction that. Results that pointed in the direction that something happens in the sleep on a level of a network and on the level of memory consolidation. So, of course, the question is: what happens and what happens in terms of dynamics? And how does this lead to memory consolidation? And why does it happen? What's so special about sleep that this is going to happen and cannot happen during, for example, waking? Well, one part of the answer, of course, is very. Well, one part of the answer, of course, is very simple because during sleep we don't have inputs from outside. Yeah, we don't take environmental inputs. So it's easier to replay the memories or consolidate memories based on the internal activity of the brain rather than this activity be biased again by the external input. But this is not all of the story. So one thing that's very different, and that's where I'm going to go with this, is that the neuromodulatory milieu changes very significantly. Changes very significantly during sleep and wake cycles. And as I'm going to show you, this neuromodulatory milieu changes significantly the dynamics of individual neurons or the stability of the individual neurons, which then affect network dynamics, which then affect network rewiring and memory consolidation to our best knowledge. So the questions I'm going to try to answer, you know, so. To try to answer, you know, so the basic idea is this: right, right now you are listening to my talk, and I'm clearly not going to be, you know, I'm sure no one would want me to repeat this talk many times over. So, essentially, you're try, if you're interested, try to grab the information as I speak. And that's your only chance in terms of this conference. Yeah, so you're trying to build a very fast representation of what I'm talking about so you can maybe process this later offline. But this representation will generally not be perfect because I'm throwing a I am throwing at you a lot of words per minute. Yeah, and then you have another talks that happen, and you have next talks that will happen after my talk. So, clearly, you cannot attend my talk offline right now because you have other stimuli coming. But the question is, so how does it later happen that this representation can form and enhance during the sleep and based on the highly heterogeneous neurons populations? Because you will have neurons that fire a lot. Because you have neurons that fire a lot that correlate with some aspect with whatever with the scene it's in front of you. And for example, another question is how do you recruit new neurons into the n-gram? So engrams are the memory representations during later consolidation from this very heterogeneous population. This is what we're going to try to try to answer. So what is the narrow modulatory control of arousal states? And I'm not going to give you any details except this one slide saying that there's This one slide saying that there's a lot of going on. So we can talk about aceteholin, as Mahid mentioned yesterday, norepinephrine, serotonin, and histamine and others, which will change their levels during different arousal states. I'm going to concentrate only on atsteholin. So clearly, the models I'm going to present to you are not complete and by any means they were supposed to be complete. But just as an introduction, As an introductory salvo of what just changing one neuromodulator can do in terms of changing network dynamics and what can it explain and how it relates to real experimental data that I'm going to tell you about. So let me give you a brief summary on atsteholin. So levels of atsteholin release change significantly during different behavioral states. So for example, during waking, attentive waking, the atsteholin is quite high. During It's quite high during non-REM sleep, it plunges, it's very low, but then it recovers to a very high level during REM sleep. So it clearly goes through these oscillations. The atsecoline is kind of, you can say very dirty neuromodulator because it acts through many different receptors. And I'm again going to very quickly narrow down and honor. I'm going only to talk about the mascarinic pathway. I'm not going to talk at all about nicotinic pathway. And I'm going to talk about specific. To talk about specific muscarinic pathway that's associated with M channels, and so and this M channels are hyperpolarizing potassium channels. This is this Kv7 KNQ family. So essentially, I'm going to discuss neuromodulation through at the hollow into this one mechanism of changing response to muscarinic via muscarinic current. So now let's quickly So, now let's quickly quantify this and look at the dynamics of the network. So, I'm going to show you the dynamics of Hodgkin-Huxley. So, I'm just showing you a master equation for Hodgkin-Huxley. And NMH are, of course, have their own differential equations having the form, the general form that's highlighted here. But now we have this additional current. The other is the slow, this is called N-current, the slow hyper-polar polarizing and adapting polarization. Polarizing and adapting potassium current. And what happens is, in how do we link this to acetoholin? Acetoholin actually blocks this current. So essentially, your GKS is going to go to zero when aceteholin is high. So when this is going to be during wake and REM sleep. And GKS is going to be high during non-REM sleep. This is when aceteholin is low. Yeah. So just remember there is this inverse relationship. Yeah. High acetecholine, zero GK. zero GKS, zero conductance of the slow potassium current, low at the holiness, maximal conductance of this current. And then, of course, we are going to look at the networks. Yeah, so first we are going to look at what this does to a single neuron. This actually model was not even developed by us, but by Sinovsky group a couple of years ago. And then, of course, we are going to our main interest will be what happens on the level of networks. Yeah. And so then we're going to have Yeah, and so then we're going to have a stat or inhibitory network. I'll give you a topology of the network a bit later when we're going to talk about specific data we're going to try to match, but it's generally just conductance-based based coupling. So you have extatory coupling, you have inhibitory coupling, you have this double exponential interaction model of the EPSP or IPSP that will play a role. Okay, so now let's actually look at what Atsteholin, what does GKS current, because that's what we are concentrating on, does. Concentrating on, but does on the level of a single neuron. And actually, this multifold changes to X stability on a single cell level. So on one hand, what we usually do, we quantify the response of the neurons through IF curve. So essentially, we are injecting constant current into a neuron and we are looking at the response of a single neuron in terms of the firing pattern, in terms of firing frequency. And you can see. Frequency. And you can see that for high acetholin, so remember, high aceteholin, this is zero GKS. Yeah, you have this very well steep IF curve. So that means the frequency changes pretty rapidly with the increase input to the neuron. But on the other hand, as we go from dark blue to yellow, so this is we go to now low at stecholini state associated with, for example, non-rem sleep, and high GKS current, you see the flattening, flattening. Flattening of the IF curve. This is a transition from type 1 response to type 2 response. This is a continuous buildup of frequency. This is actually a stepwise. You have a non-linearity here, depending on the bifurcation you go through to achieve it. But the most important factor is here is that this is much flatter. So essentially, you can feed currents that change quite significantly, but there is not much change in terms of the frequency of the response. This is partial. This is partially to due to so-called spike frequency adaptation. This is what happens when actually this potassium current, this hyperpolarizing potassium current builds up after every spike. So as I said, this is hyperpolarizing current. So actually it will slow down firing of the next spike. So here you see comparison when GKS is equal to zero, here when GKS is equal to maximal value of 1.5, and you see here the Nevron fire does system. And you see here the Nevron fires that system, you know, you have a step current. Neuron fires with a relatively constant frequency, not much adaptation. Here, you see a very, very rapid adaptation. So Nevron starts firing with a high frequency, which pitches out until essentially this current step is going to be turned off and actually the potassium current is going to be reset. So that's another that partially relates, of course, to this flatness of the IF curve. To this flatness of the IF curve, but not only, as I'm going to show you in a moment. And then we have another important change, which is in the properties of phase response curves. And phase response curve actually provides you information about how neuron responds to a weak and short stimulation during its cycle. So essentially what we are going to do, we are going to stimulate, so we are going to treat neuron as an oscillator. So we know it fires action potential here. So we know it fires action potential here, then resets the charges, fires action potential here. So we can call this phase zero. This will be phase two pi or one if it's normalized or whatever. And essentially, we are going to perturb this neuron on different points of the cycle and see whether the next spike when the neuron is perturbed will come earlier. So this will be the blue spike, or it will come later. This is the red spike. The red spike. The perturbation is always extatatory. So essentially, that's maybe not trivial that it can actually come later. That the extatory stimulation can actually delay the firing of the neuron. And then we'll plot this as exactly phase shift. So what you're seeing here is exactly, again, phase shift for neurons exhibiting the different GKS currents. And you'll see that, again, when the GKS is high, acetecholin is low, you have this type 2 response. Type 2 response. So you have first a trough and then a peak. And for the high aceteholin, low GKS current, you have essentially always positive response. So for the dark blue, it means you're always speeding up the spike, versus for the yellow curve, it means you're sometimes slowing it down. That will be the red dot is this, or sometimes you're speeding it up. This will be again the blue spike. So what does it do in terms of natural dynamics? And I'm going to show you in a moment type one. Moment, type one, the network build of type one neurons generally are show low synchronizability, and type two neurons show high synchronizability. The other interesting factor is that they actually the type two neurons exhibit, you know, this resonance and fire. Yeah, so they exhibit resonances, which could be which could be also useful, but I'm actually going to elaborate on this. Yeah, so now we have an example of a network. We are keeping the network connectivity. We are keeping the network connectivity completely the same. Yeah, so we're not changing anything. The only thing we are going to change is the GKS level. We're going to change it from zero to 1.5. So high aceteholin means low GKS. Again, we keep connectivity the same. I'm showing you a raster plot. So it's time on the x-axis, the neuron ID on the y-axis. The red dot is the inhibitory neuron. The blue dot is extatory neuron. The neurons, the networks are relatively heterogeneous. The networks are relatively heterogeneous. They get different input. This is spursely coupled network. And you see not any specific pattern is forming. The other is essentially a random activity in the network. Again, now the only thing we change, we leave the network the same. The only thing we change is actually the GKS or level of ad stacoline. So now we are going to simulate the non-REM sleep. So we are going to do this type 2 phase response curve, and you'll see emergence of the synchrony. This is randomly connected network, so you don't see any specific structure, but emergence of the Don't say any specific structure, but emergence of this synchronous activity patterns. Yeah, so essentially, type one, no synchrony in the network, type two, high level of synchrony on the network. Now, let me show you another effect of changing the type of neurons from type one, so a high altitude, to type two, low alt-holing. Now, this is a two-dimensional network, and what you're going to see movie of firing frequency. The important thing is that now there are. The important thing is that now actually we have local excitation, global inhibition. So, this is kind of this Mexican head coupling. So, you'll have a well-defined area of high activity. So, again, this denotes frequency. We have periodic boundary conditions. So, you see the group of neurons is actually active, rest of the neurons is very minimally active, but the bump doesn't change. The bump is essentially very stationary. However, if we change again the same network, the same connectivity. Again, the same network, the same connectivity, nothing changes except the GKS level, yeah, to type two. You actually see a completely different dynamic. So, again, you have this formation of the bump of the activity, but now this bump actually move as possibly slow wave during slow wave sleep, which this would be a model. And we can actually put those two things together, and maybe we can actually even define slow wave ripples within these dynamics. Because now, if I look at the activity pattern within this bump, whether this is a station. Than this bump, whether this is a stationary bump, as the top picture shows you, or this is a moving bump, so that this bump is much shorter in time because it moved to the other place. You can see that actually you have very low synchrony in spikes within this prolonged bump. So it's really, and you can see this also in autocorrelation functions. There's really nothing happening here. Whereas even within this brief bump, this moving bump, when you activate the network at a given spot, you see high level of synchronization, which actually High level of synchronization, which actually could be related to shortwave reports, or at least this is what we expect, and this is what we're actually trying to show that this is actually a natural universal property. As yesterday, Mahid mentioned it, that when at the colony is down, you have a formation of the synchronous stage, which are which are slow wave ripples. Great. Okay, so now we have two states. Yeah, we have wake state, which is high-attech-holling state, which is actually this integrator type of dynamics, type 1 dynamics, type IFQ. Dynamics, type 1 dynamics, steep IF curve, and relatively low synchronizability versus non-REM state, which is low at stake-holing state, high level of the hyperpolarizing current, which leads to resonant type of dynamics, flattened IF curve spike, frequency adaptation, and sub-threshold oscillation, the state of frequency. This is resonant, which I kind of very quickly scan over, trying not to take too long. But now the interesting thing is: okay, so you know, as I told you, that changes pretty rapidly. It changes from wake to actually. Changes from wake to actually, you know, quiet waking to later non-REM sleep, the level of what's the calling changes horrendously. So, the question is: how does the brain as a network react to it? And essentially, there are two things. So, we can form a network. And essentially, we can look at dynamics of the same network. The network is heterogeneous in terms of the input to the neurons varies from neuron to neuron, spursely connectivity. So, connectivity is spurse connectivity. So, connectivity is different from neuron to neuron. Different from neuron to neuron. They can, this is a random connectivity. There is some distribution of connections per neuron. And now we can actually look at that covariance of frequencies of firing of the neuron as the GKS changes. And you can look at the mean phase coherence for the same networks. And not surprisingly, when you have a type 1 network, you see high covariance because every neuron fires with different frequency because this frequency is highlighted in your IF curve. So every neuron receives different So, every diabolon receives different input, and then it converts to different frequency of firing. But as we increase GKS, actually, the frequency difference, the frequency spectrum is quunched down. It actually goes to zero essentially. So here, the neurons essentially all fire at very similar frequencies. Not all, but no, most of them fire at very similar frequencies. And conversely, if you look at the red curve, so mean phase coherence, of course, if you have a set of oscillators and this. Set of oscillators, and those oscillators have a different frequency, you cannot have any synchronization. Yeah, so essentially, the mean phase coherence is zero, but at some point, it actually starts building up pretty rapidly. So, you have high level of mean phase coherence in terms of when you have actually this low atsteholing state, high GKS state, which corresponds to non-rem sleeping. So, essentially, the brain can go from this polarity in terms of. This polarity in terms of high spectrum of frequencies, no synchronization to high level of synchronization through measured through phase coherence, and clearly similar frequencies of firing. So, okay, but the question is fine, great. So now let's assume that the brain does do really that. And I will show you the examples of this in a moment if Jorn allows me in terms of time. But let's actually see how this code could be represented. How this code could be represented in one end versus the other end. Yeah, so essentially now we are doing 20 repetitions of different network configurations. We will change this network configuration by changing input to the network. So this is displayed by Lightning. Or we can change network configurations. We can change that connectivity of the network. Activity of the network. And the bottom line is that if you are in the high-attestholin state, the frequencies of similar network representations can be easily discriminated against all other network configurations through looking at their frequency profile of the different neurons. Essentially, we can monitor the frequency profile of the different neurons. While on the other end, when we are now looking at synchrony mean phase coherence between At synchrony mean phase coherence between different neural pairs, we see that we don't have any, we cannot separate them out for high at the colony case, but we can easily separate them out for low at stechon case. And we can do the same with the network connectivity. So essentially here, we are not keeping the inputs to the neurons the same, but we are changing network connectivity and we have the same thing. The same repetitions of the same network structure for a high G. For a high GKS, it can be separated through frequency profiles of different neurons, but not for high values of GKS or low acetecholine. And conversely, when you measure MPC profiles, then you can actually separate them out for low acetecholin, but not high acetechol. But when brain changes the state from wake to sleep, well, it cannot just forget what was stored as a frequency profiles. As a frequent in frequency profiles, there has to be some mapping, otherwise, all the information will be lost as it goes from wake to sleep. But of course, we know here is where physics helps us a lot. And we know that this is kind of universal behavior of coupled oscillators, which have somewhat different frequencies. So essentially, the oscillators that fire faster generally, but now can synchronize, will fire early in its phase. So we'll fire earlier on the phase. In its phase, yeah. So we'll fire area on the phase as comparing to other oscillators. So, this is actually a summary from our simulation. So, essentially, what you are seeing here: neurons that fired with high frequency in the wake, wake state actually fire early on the oscillatory phase as compared to the neurons that fire with lower frequency on the wake phase. So, we have this very nice correspondence that you go from frequency coding, which is actually shown here. Which is actually shown here as animation. Yeah, so you go from high frequency versus low frequency neurons to the ordering of firing. So the high frequency neurons fire first, the low frequency neurons in wake fire later in non-rem. But that actually will have an effect. Can you tell me how many more minutes do I have? Just, it will depend how much I will start skipping slides. You have two minutes. Two minutes. Well, so let me start going really fast. Yeah. Start going really fast, yeah. So, essentially, what I'm this will also have an effect on the structure of the network, yeah. Because if you look at the standard spike timing dependence, dependent rewiring rule, if we have two neurons, if one neuron fires before the other neuron, we'll have this connection to the being strengthened, this connections being weakened. So, if this pattern that I just show you of fast-firing neurons versus slow-firing neurons and the order of firing in the synchronous state. Firing in the synchronous state really plays out, what you're going to see is that we are going to have the squeezing of the distribution of frequencies as you go through this non-RAM phase. So essentially, you start with the distribution of frequencies of all neurons. If you go through non-RAM phase, you're actually going to see that the distribution is going to be significantly narrow because of this rule. So now let me actually talk about the experiment during one minute. So this experiment was done in Sarah Aiton lab, and this was actually In Sarah Aiton lab, and this was actually contextual fear conditioning. And essentially, so mouse is in a home cage, it's actually put in a new cage. At some point, it's electrically zapped in this new cage. Mice hate being zapped. That's the fear part. Mouse is being put back to the home cage again. And 24 hours later, it's being put to the new cage. And actually, we are going to look at the behavior of the mouse after 24 hours in the new cage without zapping anymore. And this is. Without zapping anymore. And this is really nice because this is one-time paradigm. Yeah, so it's enough to repeat this experiment once. Mouse is going to remember that it was not happy in this cage. It's going to be scared to be in this cage again. And actually, you measure this by freezing. Yeah, so essentially, if you measure the degree of freezing after the shock, this freezing actually increases more. But also, what do you see that if you allow the mouse to sleep? That if you allow the mouse to sleep four hours after the freezing, after the stimulation, then actually this memory is much better consolidated when you have sleep deprivation. So SD stands for sleep deprivation. So actually you see that here percentage of freezing was much increased as compared to sleep deprivation. And of course, some is when you don't have electric stimulus. So actually, of course, there is no real increase. Actually, of course, there is no real increase of freezing because there was nothing fear generating. So then we actually compared the model and the data. And I'm going to skip this for you, but generally what we have and what was observed in the data that after you have the CFC contextual field conditioning, you see emergence of the theta and slow oscillations in the network. And we model this as just changing the connectivity in the network, and you see emergence of this. network and you see emergence of this of this slow oscillation but now you see that the the these oscillations somehow depend on the cell id and we order them in terms of the input to the cell and you see that very nicely when this when this when this oscillations appear the cells that were firing the fastest in the wake state yeah so in the type one when the acetylcholine is high actually fire first on the on the on the oscillatory phase so we measure the stability of the representations i'm not going to go through Of the representations, I'm not going to go through that, that's not to prolong the talk, but we devise a way to measure actually stability of the representations. And if you measure the stability in the model and stability in the slow wave sleep, this is experimental data, you see this large increase as compared to sleep deprivation and SAM. So this is exactly the same thing that Sarah observed, observing the experimental data. And more interestingly, we can actually predict the behavior of the mouse 24 hours later by looking at the material. 24 hours later, by looking at the stability of those representations. Yeah, so essentially, this is the model. This is the freezing versus the stability of the representation, temporal stability of the representations. Here is the power of the theta band oscillation. And you'll see that actually theta band oscillation predicts the freezing 24 hours later. And also, stability of those representations. So, by stability, it's essentially the order of spiking. Yeah, it predicts what. It predicts what will happen 24 hours later because, again, we are measured this stability first four hours after the stimulation. But then we want to see what essentially happens when we transition from wake to sleep. And I'm almost there. So essentially, we are trying to look at asymmetry in the experimental data, because we are claiming that the neurons in wake state will fire faster, but the neurons in the non-REM sleep phase will fire first, like for example during gripples. Like, for example, during gripples. And we want to see whether this essentially we can see this in Sarah's data. And we devise a measure, so we actually look at the order of firing of cells within the burst, possibly sharp waves. And we actually code, so we align the neurons with respect to their frequency in the wake. And we look at essentially at the order of firing. So we call this a spike asymmetry. Who goes first, who goes later. And essentially, what do you see? And essentially, what do you see? We see exactly what we would predict. I'm going just to limit to this panel, not going to go to this panel. So essentially, the non-RAM asymmetry, so the order of firing is very nicely predicted by the wake frequency pattern, but the reverse is not. Yeah, we have to run controls just to make sure that not everything is, we can predict it both ways. So here we do reversal. So we essentially try to predict the wave asymmetry as a function of the frequency of firing during. A function of the frequency of firing during non-RAM, and essentially we don't see this. So, this is the Z-score. So, you see, significant values, those are mice that we had. Let's look at that only the yellow dots. You see significance of this asymmetry, non-rem asymmetry, but we don't have any significance in terms of the wake asymmetry. So, the last slide that I'm going to show you is actually this narrowing of spike frequency. So, this is the result from the model. So, essentially, we see that the narrow. We see that the neurons that fire fast start firing slower. So the change of the frequency is negative. The neurons that fire slow initially actually start firing faster. So this is exactly what this graph shows. And then we compare this with experimental data for CA1 supercampus for this conceptual fear conditioning. And essentially, this is the yellow line here. And later, if you look at sleep deprivation and inhibitory block and compare it to baseline. inhibitory block and compare it to baseline you see this this significant here is the significance of the of the changes of the of the distribution of the of the spiking frequency yeah and again this was later observed by other labs also so this is real phenomenon and what's interesting is the phenomenon not only in hippocampus but also in visual cortex yeah so all this what i'm telling you is maybe not related only to to hippocampus but also generally universally to the brain and i'm going to skip this slide and The slide, and this is my summary slide essentially telling you briefly what we think is happening. So, initially, you have a representation being formed during this rapid learning during the waking, but later you have this transition to non-REM sleep, which goes from frequency coding to a phase coding or temporal coding. And later, this, of course, affects the frequency when you wake up again and you try to, for example, retrieve the memory. Now, you have this enlarged n-gram because this allows the fact that all the cells fire. The fact that all the cells fire now with similar frequency and J-lock that allows to actually get the slower firing neurons into the N-gram and allows to actually magnify the N-gram or for bigger memory consolidation. So, thank you very much. Sorry for going so fast and sorry for going somewhat over time. Thank you. A pressing question. Thank you, Michael. I really enjoy your talk, and I hope that we can meet offline sometimes because there are a lot of interesting things we can discuss together. Yes, it would be great. One question that I have for you is more than actually, so I mean, again, when you really measure these things, first we see that there are different degrees of acylcholine change at different Change at different regions of the cortex? That's the first question. Second, even when the acycholine level is low during non-red, but there are actually fluctuators, kind of moving patterns across the cortex, which make it even more complicated. And I don't know whether that's a phenomenon or is actually have a function. This is something that is very difficult to examine using experiment, but perhaps using some modeling, you can have prediction. This is fantastic. This is a fantastic question. This is a great question. If I just may continue. Another thing that I wanted to bring it up, which is actually a general thing, you know, you came up with this local excitation and global inhibition. However, when we basically measure the dynamic within the neural network, now with either measuring gluten directly and GABA directly, you don't really see that global inhibition. You see also local inhibition. You see also local inhibition, which may actually complicate all the equation in a different way. But you know, this is something we can discuss in another time. So this is a great question, actually. Let me touch on the first question first. Yeah, so you're completely right. Yeah, and you know, for a long time, it was assumed that the levels of acetylcholine are universal throughout the brain. Yeah, so constant or uniform throughout the brain, I wanted to say. Yeah, and actually, we work with Martin Seiter. No, we work with Martin Seiter and he claims this is not true anymore. Now we have this new technique that you can measure the concentration of acetylcholine, and as you said, exactly. It's first of all local, and second of all, it changes. Yeah, and essentially, we just published a paper on it in PLOS Computational Biology. So we exactly look at the changes of the levels of ad steholin. We don't look so much at temporal changes, but we look at the spatial distributions of adstecoline and how it changes dynamics. So, you know, it's complicated. It's complicated. Yeah, sorry, I will not, I will, but I'm happy to talk to you offline about this. Um, in terms of the second, yes, we are exactly changing the network also, and we are looking at yes, you're completely right. This global inhibition is not a great model of what happens, it generates, and we can actually show that similar things start happening, you know, when you when you play with the with the topology of the network and essentially when you have local inhibition, but you have long-range excitation, which excites it. You have long-range excitation which excites this inhibition. It turns out you can get a pretty similar network response. Yeah, so you can get the same similar dynamics, not the same dynamics, similar dynamics. Thank you, Michael. Hopefully we can discuss more upline. That would be great. All right, let's thank the speaker again. So our next speaker.