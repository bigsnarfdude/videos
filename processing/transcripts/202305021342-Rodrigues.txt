So we are given a martingale X, a random measure μ, you can think of this as a jump measure of another accelerating process, a predictable process C, which is increasing like continuous, and it dominates the predictable variation of X and the predictable compensator of mu. Then, usually the driver takes values in R. It takes values in R and it has stochastic Lipschitz coefficients. We have a stopping time and an obstacle psi. We allow it to be minus infinity on zero T, capital T, but not at capital T, so that we can include the BSDE framework in this reflected BSDE formulation. And what we look for is a collection of processes within which there exists such a five-top of Y, Z, U, N, and K that satisfy. And k that satisfying this system here. So, what might seem odd at this stage is that we have the component y twice in the generator. So, usually the results in the literature have y is minus. This also makes sense if you have like America schemes for BSDs. But it actually turns out if you really want to study control problems of the Problems of the general type that I presented before. Turns out that what you also want is a dependence on Ys in the generator. And to convince you of this fact, I just want to show you a little toy example. Can I ask you about S Y and C? So this is the same Y, U depend on X and S? Sorry, Y, no, U, U, U. So is it a functional? Just what? U. Yeah, yes. U. Yeah. Yes. So it's the integrand of the compensation. Yeah, we do this the size of the jump and the integral respective S. Right? So that means U depend on S and X. Depend on the time and the size of the jumps. And just what? So the same U, right? The same U you have it in the generator. Yeah. Here. There and up. Yeah. Yeah. With the same U. Yes. But there it doesn't depend on X because you integrate only. Yeah, so you want actually a functional dependence on. A functional dependence on the generator. So the generator is on the whole function. Yeah, but there is x, the u depend on s and x. What is x? It's a functional function. Sorry, maybe I'm going to try it. Yeah, so the mu, this is an auxiliary random measurable on some space key. And you really want the whole functional in the generator key. And uh the general is right here. Actually, the segment I also depend on the function. Yeah, yeah, I yeah, I wrote it backwards. Okay, so we want yes as well because in this toy example we consider optimal stopping with discounting, and you want to optimize this criterion j here over stopping times that do not exist. Stopping times that do not exceed the stopping times capital T. So usually, as usual, you consider the remaining value process, you divide it by the discount factor D, you add the remaining interval on both sides, you end up with a Snell envelope of this process here. So you decompose, you get that Snell envelope can be written as a difference of a marking evaluation, an increase in process. The marking gave an increase in process. You multiply d again using integration by parts, you get this equality here. And now, if I choose the particular discount vector that is a stochastic exponential of an integral process with respect to C, I end up with this system here. So I really just replace this with this line here and then end up here. And this condition here, this follows from the And this condition here, this follows from the decomposition of this lambda column. So really, already in this uh simple case, I see that the dependence on y is through ys and not through ys minus. Okay, so of course there has been earlier work on this subject. I really just want to mention the ones that are sort of closest to the set objects we have chosen. So, in case this integrator C jumps, there's results by Bandini. She considers VSDs to are driven by a single integer value random measure, and where the integrator C there is not allowed to have jumps strictly bigger than one. Then there's work by Cohen and Elliot. Yeah, here maybe the setup is a little bit different because they do not fix a martingale in the beginning, they actually construct it in the space and the intuitive C, this is deterministic and strictly increasing and it may not be at all connected to the martingale which you use in the martingale representation. Then, of course, there's work by Delane Co-authors also on the BSD side. Also, on the BSD side and on the reflected BSD side, the ones that are closest to our setup are a series of two papers by Sigurova and co-authors. There they consider reflective BSDs where the obstacle exit is just an optional process, does not have any path regularity, exit boundary motion, we use possible random measure, but random measure but for C that can jump at least to the best of my knowledge there's nothing else okay so how do you show that there exists a solution so the classical ways to derive a priori estimates so what you want to control is you want to control the spread between two solutions with different Between two solutions with different data by the spreading of data. So, the usual way is to apply Ito's formula to the spread, then rearrange terms, maybe use one called the Davis Fundy, pushing forward. But unfortunately, in the generality that we chose, this does not apply to work. Then, there's a very interesting general well-post-non results obtained by other. Results obtained by Elkaro Nguyen in the famous Red BSD book. There they circumvent sort of the application of Ito's lemma. They have a more direct approach in the BSD case, which really exploits the L2 structure that they are studying. Unfortunately, this does not also not quite work on the setup that we have, but what works is if you combine the two approaches. is if you combine the two approaches. So let me tell you the results. So the approach to show well closeness is also standard. You want to construct a construction mapping on some weighted spaces and you want to introduce weighted interpretability conditions. So the kind of weights that we chose are stochastic exponential. We take the stochastic exponentials of beta hat times A. Times A, where A is sort of the integral process of the stochastic Lipschitz coefficients integrated with the integrator C. So this is actually analogous to what El Curu and Huang did. Just in their case, the C is continuous, so it's not a stochastic, it is a stochastic exponential, but it actually reduces to exponential function. Okay, so this is the kind of integrability we encodes here. So here I'm hiding something. So we need also integrability on the positive part of the obstacle, which depends on beta hat. And we then define these weighted orb spaces, which also depend on beta, and they're decreasing in beta as well. So, the post-resulta reads as follows. We suppose that the jumps of the process A, which are just given by the square of the Lipschitz coefficients, times the jumps of C, they're bounded by a constant which is strictly smaller than this value here. And there exists some beta star which only depends on this value here. This value here, such that if your data is integrable enough, meaning that it is strictly more integrable than beta star, so in this case beta hat integrable, then you can find a unique solution to the reflected BSV in this weighted solution space, which is also, which also depends on beta head. And because if your data is beta hat integrable, and this is increased. Integrable, and this is increasing in beta. It is also beta integrable for every beta that you can squeeze in between here. So you can do the contraction level on this space as well. And you end up with a unique S also in this space here. Here also, just a small remark. So you can make sure that the speed test sort of can make it very small, then this condition here, this also gets smaller and smaller. And maybe here, so this condition might look very strange, but it actually just comes from the method that we apply. So at this stage, I would say I do not expect any generic counterexample to this condition. So in the BSD case, we do the same thing. We do the same thing. So either we assume that the obstacle ψ is minus infinity on 0t but not on capital T, or we do the estimates again in this special case. And actually, if you do the estimates again, you can improve quite a lot. So the well-postnet result is similar, but now the condition is that the jumps of this A, so the product of the square of the Lipschitz coefficients times the jump of the. Coefficients like the jump of the integrator C. They have to be bounded by a constant, which is strictly less than one, to get workposedness here. And again, uniqueness also in between these spacing sphere. And here it really looks like that by some count. By some counterexamples by Confotola, Ullman, and Jacob, that at least in the framework we set up, if you're asking whether the theorem can be improved by changing this number here, it looks like by these counterexamples that this cannot be done. So at least this theorem is sharp in this constant here. And on this note, And on this note, thank you for your attention. Then we have time for questions. The last counter example is against the existence of uniqueness. Uniqueness. Yeah. So if we translate their counter examples into our setup, uh then uh the file that they have is uh The phi that they have is one, and then there they have an infinite number infinitely many solutions to the BSD. You can also counter examples to the DCS. What's the regularity of the ostecom? So The reflection be easy. Beginning. Yeah, so here, just to write it down, I suppose that the obstacle is cutlock, but to do the whole theory, you do not need to suppose any irregularity. So you just need to suppose that psi is an optional process, and then you can do everything. So this this is why I mentioned the paper uh the series of two papers by The series of two papers by Gilrov and co-authors. They study reflective VAC with a very general philosophy. If you go beyond optional, then you need another replay. So here I sort of hid it and wrote it in brackets. Yeah, so there should be more terms here. Why do you think that the terminal y t should be the same as the terminal of the other? Do you have a reason for that? I mean you can take any terminal condition and any other obstacle and then you just put them together in the qsi. I mean I could take as an obstacle or something better. So just for because it's simpler to write on. Questions? Very good. Thanks a lot, Marco. And the weather that you have, but   Oh, I don't know if questions in the next speaker is Navier President from University of Roland. We're going to talk about the role of correlation in diffusion control ranking gates. Thank you, Diane. So, let me thank the organizers for having us here. It's such a nice place. I'm learning a lot from the talks and from the discussion. Learning a lot from the talks and from the discussion, so thank you. So, yes, I'm going to talk about the role of correlation in a particular ranking game, and this is the joint work with Stefan Romkener and Julian Vann, who are both at the University of Vienna in Germany. And so, let me start by giving you an example showing the main method. Showing the main message I want to give you today. So, I'm going to look at the game between two players. So, what do you have here? You have two Brony and Marty gates driven by Bronyan motions W and T, which are correlated. So, we have a correlation coefficient rho between minus one and one. And player one, he composed this uh function a1, which is a function of time and Which is a function of time and R2. So he observes where he is, where the other player is, and this is function A1. Player 2 plus A2 in the same manner. And these functions are varying in an interval sigma 1, sigma 2, sorry, through the diffusion coefficient of this Boleyn-Mart index. To simplify a little bit the talk, I will assume that sigma 1 is strictly positive. And if you look in the paper, we allow sigma 1 to put it into zero. And the criteria. And the criteria. So you have a terminal time capital T, and each player aims at maximizing the probability of being ahead at time capital T. So let me show you. So if the correlation coefficient law is equal to zero, in the discussions I had with some of you, you directly guessed the solution, the Mash equation. Directly guess the solution, the mesh equilibrium in that case, is the following. If you are ahead, and just let me take another closure, okay, you are at some intermediate time small T, the white player is ahead, and because he is ahead, he is going to play safe. And playing safe here means choosing the minimal volatility, sigma 1, and the player behind choosing the maximal volatility, sigma 2. And this forms a nice. Two and this forms a Nash equilibrium. So you just need to look where you are with respect to the other person, and this could form a Nash equilibrium. So what? The boundary scale of rho equal to zero. And now what happens if rho is equal to one? So if rho is equal to one and you are ahead at time small t, if you know what the red player is doing, your optimal response is to do the same. Because if you do the same, you are going. So rho equal to one is the Bohr. You are going so rho equal to one, the bony motions are the same. So you are going to move in the in a parallel way until you hit capital T and if you were ahead, you are going to stay ahead. Now the red player knowing that you are going to imitate him, he has an incentive to change. And intuitively here, if rho is equal to one, there is not going to be a Nash equilibrium, at least in this strong formulation with strong control.