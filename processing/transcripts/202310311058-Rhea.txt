Forward to our discussions via Slack and setting up Zoom. So today I'm going to be talking about how we have been folding machine learning into standard model setting algorithms. And I just want to thank my collaborators at L'Unicé de Montréal, at Mila Ivado, which are the two main organizations for machine learning in Montreal, and at the Center for Astrophysics at Harvard-Smithsonian Institute. So today I'm going to be talking about two different ways we've incorporated machine learning. Different ways we've incorporated machine learning into model fitting or model algorithms, so fitting algorithms. And before I jump into how we apply these machine learning algorithms to help with our fitting processes, I'd like to first describe one of the two instruments that we've been using. So one of the main instruments that we've been working with is CITEL. CITEL is an integral or is an imaging Fourier transform spectrometer located at the Canada-France Wide Telescope on Mauna Kea. Mauna Kea. It's effectively, to those of you who are familiar with astronomical instrumentation, it's basically an IFU or an integral field unit. And the beauty of these types of instruments is that instead of just getting an image of our astronomical source or just getting a spectrum, so the intensity versus the wavelength of our astronomical source, we get the best of both worlds. So we actually get both. The resulting data structure from Sattelle or any type of IFU is known as a data cube. IFU is known as a data cube. You can see an example here. So you have, it's a three-dimensional data cube where you have the x and y spatial coordinates, but then also along the z-axis, you have all the spectral information. It's TELL is a really amazing instrument. It has an extremely wide field of view of 11 arc minutes by 11 arcminutes. Just to give an idea of what that means for the non-astronomers in the room, and certainly in terms of computational time, the next larger The next largest IFU is a factor of 100 times smaller in its field of view. That would be μ. And with Sattelle, like I mentioned, each pixel in your image will have an associated spectrum. And Sattell has over 4 million pixels in one observation. So every time I get an observation with Sattel, I'm given effectively 4 million spectra that I now need to analyze. And depending on the object that I'm studying, mainly we study. That I'm studying. Mainly, we study H-alpha, sorry, H2 regions. These are the regions where stars are forming. There's a lot of emission in H-alpha and nitrogen and sulfur. Those are these little lines that are popping up here that you can see. And our main goal is to fit these lines to a model that describes the instrumental line shape of Sattelle in order to extract fluxes and in order to extract the kinematics of the gas that we're observing. We're observing. And if you have one or two spectra, this is a pretty easy problem. When you have four million spectrum per observation, this can be a very difficult problem. And so what we did is we asked ourselves, how can we speed up our calculations? So there's a couple of things we did. The first thing we did is built a general purpose line fitting pipeline that was built with Sattelle Data Cubes in mind. We called it Lucy. That's the name of That's the name of one of my old cats, so there's no fun acronym there. And Lucy allows us to rapidly extract the amplitude, position, and broadening of the lines, which are the three main observables that you can extract from the line emission. And that tells you a lot about the kinematics and dynamics of your gas. And one of the main problems we realized: not only is it very expensive to fit these 4 million spectrums. Fit these 4 million spectrum per observation. But the fitting algorithms that we had previously been using were very susceptible to poor initial estimates. So when you're trying to fit some of these parameters, you generally want to have a good idea of the velocity or the broadening of these lines. If you have a poor fit, they fall very quickly into local minimum, or sorry, poor initial guesses. These fitting algorithms fall very quickly into local minimum. And this was a serious problem. So what we decided to do. So, what we decided to do was speed up our calculations and inform our calculations more by using a convolutional neural network that would take in the spectrum as is. So we take the spectrum, which is just a one-dimensional vector where each element in the vector is the flux at a certain wavelength. We then pass it through a convolution neural network. I can't take credit for coming up with this non-creative architecture. I mean, it's pretty simple neural network, but this was initially used. Work, but this was initially used to extract parameters from stellar spectrum. And so we decided to steal that architecture because it had done such a good job previously, retrain it, redo the hyperparameter tuning, and get it working on Sattel spectra to extract the velocity and broadening, which are two of the three main parameters we want to extract when doing line fitting. And what we found is that this. And what we found is that this works really well. It speeds up our calculations considerably because now all of our solutions converge on a much faster time scale, and it allows us to actually think about getting complete maps of these different parameters for all the different lines that might be present in a single observation. So, in a single one of these data cubes. And just for give the idea of the time difference it takes, it used to take up between It used to take up between five to ten days to fit one of these data cubes using the old software. With our software, you can do that. You can fit the exact same amount of data, so a full data cube, in more like five hours, maybe six, seven hours, if it's particularly difficult. Well, we decided this is really nice because this has now sped up our calculations and gives us point estimates for those initial line fits that we can then pass to your favorite fitting algorithm, say. Favorite fitting algorithm, say something simple like a Levenberg market algorithm or something more complicated like a full Bayesian approach. And in Lucy, our software, we have options for those depending on how much time you have and how much computational resources you have. We decided it would be nice if we could also look at the uncertainties from our machine learning estimates and somehow work that into our fitting algorithms. More specifically, More specifically, we wanted to use the fully Bayesian approach, which required us to have decent priors on our fit parameters in order to have good convergence rates. And so to obtain our priors, what we did is we updated our neural network to be what's known as a mixture density network. This is nothing too fancy. All you do is instead of outputting a single parameter or a single value for a parameter, you assume that that parameter has some sort. Assume that that parameter has some sort of distribution. We assumed a Gaussian distribution, and then you output the parameters of the Gaussian distribution. So, your neural network, when it takes in a spectrum, instead of estimating, say, the velocity, it estimates the mean and standard deviation of a Gaussian distribution describing that velocity. And we can use that as priors for a Fulbaysian fitting algorithm. And so, that's exactly what we've done. Our convergence rates have increased. Our convergence rates have increased by about a factor of 10, which allows us for, that doesn't really work for the 4 million spectrum, but when we're looking at individual regions of interest in a Sattelle data cube, this allows us to do a full Bayesian analysis of those even larger regions for the first time. But before this was just computationally prohibitive. But now by using a mixture density network to estimate our priors, we're able to reach reasonable convergence. Reach reasonable convergence rates allowing us to do this. There is a whole lot of documentation about Lucy. We've been very particular about it. If you're interested in learning more about it, you can head check out our GitHub or just type in Lucy Sattell on Google. It's the first link. We have full documentation and, of course, a cute picture of my former cat, Lucy. Okay, so I'm going to switch gears a little bit. So, this is how we, so I previously described how we've been using. So, I previously described how we've been using machine learning to speed up the convergence of our fits. And in the context of an IFU, specifically Sattel, even though what we've done so far is not prohibited to Sattel. So I'm going to switch gears a little bit to X-ray analysis, so looking at the higher end of the spectrum, and I'm going to be talking a little bit about galaxy clusters. The main takeaway here that I'd like to make is that when we look at a galaxy cluster, Is that when we look at a galaxy cluster, we are, when we look at a galaxy cluster in the X-rays, I should say, we're looking at the extremely hot gas, ionized gas, normally around 10 million degrees Kelvin. So it's extremely hot. And when we look at these spectrum with the state-of-the-art telescopes, such as the Chandra X-ray Observatory, if we extract a spectrum from our favorite astronomical source, we generally get something that looks like this. Generally, get something that looks like this, which is pretty featureless as far as spectra go. And if you're used to spectroscopy like I am in the optical, you would say, hmm, there's not a whole lot of features. I can't really do much with that. I expect to see something more like this on the right. And this is what the actual spectrum of the hot gas in galaxy clusters should look like according to our models. It's our best thermodynamic model. Models. So, our best thermodynamic models tell us that we should be seeing this nice power law continuum with very clear emission lines coming from the different metal species in the gas. However, when we look at our spectrum, that is not at all what you see. You instead see this very smoothed out curve. And there's a clear reason for that. When we look at something in the x-rays, it's hard to collect photons in the x-rays. I think that's the best way to put it. I think that's the best way to put it. And there is an instrumental response that gets convolved with the source's intrinsic spectrum. So instead of seeing this nice curve with clear emission line peaks due to the instrumental response and that convolution with the instrumental response, we see a smoothed out version of this. And we initially tried playing the same game we played before with Sattelle on for Chandra to extract some of the main parameters from the X-ray spectrum. Parameters from the x-ray spectrum, and we realized very quickly that the model wasn't doing nearly as good of a job because everything was so smoothed out and you don't have these clear emission peaks. And so that led us to say, well, is there any way we can get rid of the instrumental response so that we can recover this what we call true or intrinsic spectrum of our source? And this is a deconvolution problem. So another way to see this mathematically is. To see this mathematically is we have the observation or the source and the spectrum. So, this is our observed spectrum that we see here. And to get the observed spectrum, you take a convolution of the instrumental response, say from your favorite space telescope, here we have Chandra, and you take the convolution between that instrumental response and the true intrinsic spectrum, so the true spectrum of the source. Once you do that convolution, you end up with this mocked observed spectrum. Up with this mock observed spectrum. There's been some nice work showing that this actually turns into a fairly straightforward matrix equation. And you're probably thinking now that's pretty interesting, Carter, but I solved that back in high school. This is Ax equals B. You just take the inverse of your response. So we call this a response matrix. You take its left-hand inverse, and you'll end up extracting the true spectrum. So we also had that idea, and we tried it. We had a research note. And we tried it. We had a research note in which we tried a couple of different more sophisticated methods than just a simple inverse, different regularization techniques to try to solve this problem. And at the end of the day, the response matrix is so singular that it's impossible to get any sort of inverse, even with whatever regularization technique you're using. And it's simply impossible to recover the intrinsic spectrum. And so we turn to some of my colleagues who are much more experts. More experts in machine learning than I, and they said, Hey, we actually have been working on something to deal with 2D deconvolution for ALMA. And maybe you can take that same type of algorithm and use that for 1DD convolution on your spectrum. And the algorithm is known as a recurrent inference machine. And overall, the algorithm works in a fairly straightforward manner. The idea is you want to solve your linear equation with or with equation. Equation with or without noise iteratively. And you use a recurrent neural network along with several convolutional layers to give you the updated solution. If you're interested, I'm happy to share these slides and talk about them in more detail. But the basic idea is you're going to initialize your estimate for the solution and you'll update your solution by training a recurrent neural network that takes in the previous solution at the previous time step and also what we call the score in machine learning. What we call the score in machine learning, which is the gradient of the likelihood function. And we can write all this down. And so, how does this work? So, first we tested this on a large batch of synthetic data. Here, we can focus on the left-hand panel. This is the ground truth, so the real intrinsic spectrum in blue. And in the dashed orange line, you can see the solution that the recurrent inference machine or the rim recovers. Machine or the rim recovers. By looking at the errors, you can see that they are pretty much spot on with some slight errors where we have strong emission peaks. But in reality, we don't have the intrinsic spectrum to look at for real objects. We don't know what it actually looks like. What we instead have is the observation. So you can repass this solution that you get through a Ford model, or you can do the convolution again with the response matrix and then compare the observation with the reconstruction. The observation with the reconstruction you would get from the rim, and see again that within the noise level, they're in close accordance. So, up until last week, or not last week, two weeks ago, we were unable to get this to work on synthetic, or on real data. But as of last week, we were able, two weeks ago, sorry, we were able to get this to work on real data, where we can take a random observation with the Chandra X-ray observatory from any time over its entire lifetime. Lifetime and apply our methodology to extract the intrinsic spectrum for the first time. This was just accepted yesterday to the NERIPS workshop. The archive paper should be going up pretty soon. And so how do we plan on putting this all together? And why are we talking about folding in traditional or machine learning methods and traditional fitting algorithms? Our idea is to take a X-ray spectrum, use the rim in a pre-processing step to deconvolve our spectrum. Processing step to deconvolve our spectrum. This gives us a lot of power in the sense that we can now stack spectrum for the first time in x-rays. We can then pass that those stack spectrum through a mixture density network to extract our main parameters of interest, and then do the same trick we did with Sattel, run this through, use those as our priors for a full Bayesian inference to be able to get a much better idea of the parameter distribution underlying the emission of this thermal gas. Okay, so that was a whole lot of information. I hope it. That was a whole lot of information. I hope it was clear. That's it for me. Questions? So the PPO loop is very interesting. Have you guys checked to see how many counts you needed a spectra to actually fall as well? Because I press spectra to be types like huge code or they could be a lot brandier. I'm sorry, I missed part of. I'm sorry, I missed part of that question. I think a critical part. I'll speak a little bit louder. Have you tried to see how many counts you need in your X-ray spectra to run your G compiles? Yes, I have. The answer is you need pretty deep observations, deep in the sense that I'll talk about it in counts. So you normally need at least somewhere between 1,000 to 2,000 counts for it to be able to work. 2000 counts for it to be able to work. Obviously, it works better in higher signal and noise regimes. Thank you. Hi, this is Abramica. A very interesting approach to X-ray modeling. I was wondering if your method supports more than one temperature model. You have to say that it's one temperature or