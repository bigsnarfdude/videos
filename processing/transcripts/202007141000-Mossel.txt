Leaf blowing. Yeah, we can start streaming. Oh, I guess we don't need necessarily the oops slide. Oh, I just took it off. I can put it back though. As you wish, doesn't matter. And the people, the breakout room are back. Is that? Oh, I didn't do it today. Oh, yeah. Okay. Didn't do it today. Oh, yeah, okay. Okay, so we're back for the second lecture of the series of lectures by Al Ghana Marcel for the OOCS slash SMS summer school. He's been giving a series of lectures on simplicity and complexity on belief propagation. Again, the Again, the video will be recorded. So, if you do not want to appear on the video, please turn your camera and your microphone off. You will have a chance to post questions over the chat as well as once we stop recording the lecture at the end of the hour. Today's lecture will be followed after a half-hour break, will be followed by an exercise session that will Session that will be led by Frederick using some of the exercises that were mentioned in the previous lecture and possibly in today's lecture. So if you're interested in seeing some more details of proofs, please stick around in the same Zoom number for the exercise session. Okay? Okay, thank you. Please help me by slowing me down. Me down. I think whenever I teach a class, I ask students, you know, if I teach too slow or too fast. And I don't think I ever got the answer of too slow. So maybe I'll try in this lecture to teach too slow. I think I'll fail again, but please feel free to ask me questions at any point. Okay, so we will continue exactly where we were last lecture. And I'm going to share the screen with you. So we were looking at this picture in two different ways, if you remember this picture. In two different ways. If you remember this picture, this picture is a picture where, on one hand, we think about this picture as the broadcast process on the tree or this Markov chain on the tree, where each bit of this image is going through this process of copying with probability theta and randomizing otherwise to get these pictures of the leaves. So that's one way of thinking about it where the tree is known, and you're just looking at this broadcast process, and maybe you want to recover the wood. And now I'm going to And now I'm going to talk a little bit about formally, still, we are talking about the linear theory, if you want, about the other problem. In the other problem, we are... Ah, here's my pen. In the other problem, I will again erase the information that we don't have. In the other problem, we do not have any of the information up here. Even before, we didn't have the pixel, but now we don't even have the structure of the tree. And all we have is the vector in radio, and somehow from that, we want to recover the structure of the tree. Okay, so that's the problem I'm going to talk about. So that's the problem I'm going to talk about. And again, we are going to see the significance of the testing stigma. Any questions about this? Okay, so I'm going to give a simplified version of, you know, of a sequence of work. I mean, what I'm going to present today is much simpler, but not in a way that pertains very importantly to the first transition series of work that I did at the beginning of the 2000s. And then some with Mike Steele, some with the Skalakic, the Skalakic. Samis the Skolakis, the Skolakis, and Roch, and essentially say that there's an important phase transition that happens according to the condition if 2 theta square is bigger than 1 or 2 theta square is less than 1. The reason that we have a 2 here is that we are looking both at the case that Q is equal to, the symbols that we are looking at are bits, are either plus or minus, and at the case where D is equal to. So every node is going to have exactly two children, and that's the reason that this number two here is two. This is the D. Number two here is two. This is the D. And what does the theorem say? The theorem says that for this problem of reconstructing the tree, which I'm going to define in a second a little bit more formally, the amount of information that you need, you know, in biological terms, it's the length of the DNA sequence in terms of the picture that you had before, it's the number of pixels in the image that you need L that's needed to recover T is logarithmic in N. In n, I should say what n is. n is the number of nodes in the tree. It's logarithmic if n above the phase transition, if two theta square is bigger than one, and it's a power of n if two theta square is less than one. Okay, so somehow the phase transition that we've seen before for this correlation decay phenomena also plays an important role for this inference task and maybe. For this inference task, and maybe we'll see another example for a different inference task in a little bit. For this inference task of building the tree from independent samples or sequences, and again, it goes from logarithmic in the size of the tree to polynomial in the size of the tree. Another way of writing, so remember, log n is essentially the depths of the tree up to a constant. Okay, so the number of samples that you did is all the depths of the tree if two theta squared is bigger than one, and it's exponential. Is bigger than one and it's exponential in age if two theta squared is less than one. So this is a pretty radical phase transition in terms of this parameter. Questions about this? Okay, so maybe let me define the model a little bit more formally. So, I mean, so let me define the model a little bit more formally. And again, this is much more simplified than the simplified than the or a little bit more simplified than the processes that were described in the in the actual theorems and the reason is biology is is is somehow more less heterogeneous than you know this idealized model that we're looking at and i'll talk about it maybe in i'll comment about it a little bit but just to get a picture of the first transition i think we can do with this very simple model so we are going to consider the broadcast process on trees or the markov chain model on tree for h levels For H levels. So we are going to have the usual picture that we have here. This is going to be our vector xh, and this is going to be two. Again, this means that every node has two children. Okay, so this is going to be equal to, and it's a complete binary tree. Okay, so that's the picture that we're going to look at. And the key issue is that we want to recover the structure of the tree. And I don't really, there isn't a very compact way of saying it. One way of saying it is that there's an unknown permutation sigma of. mutation sigma of two to the of the leaves so this is s of two to the h because there are two to the h leaves and you know you don't know how to order them somehow and the goal is again again this is an h two to the h and what is happening is is what's happening is you're getting iid samples of the vector xh except you don't actually get the vector xh you get the vector xh H, you get a vector xh tilde, and what's the difference between xh and xh tilde? So maybe I'll draw the picture again. So if we knew how to draw the t, we would, you know, this is coordinate number one, this is coordinate number two, this is coordinate number three, this coordinate number four, and so on and so forth. And as biologists, we would say, ah, coordinate number one and coordinate number two are very close together. They are sister species. Okay, but we are not giving this information. We are given this vector permuted. So that's what's given here. So Ys are independent. So, Ys independent sample sample from the same distribution as XH tilde. And what is XH tilde? XH tilde is exactly XH but permuted according to the permutation signal. Okay, so maybe my first coordinate is going to be this coordinate, my second coordinate is going to be this coordinate. So, you know, it's just given by someone, you know, this is how you collected the data. You don't really know which pieces are related to which pieces when you collect the data. Species when you collect the data. Okay, and what is the goal? The goal is to recover the tree. Okay, so this is not really well defined. One way to try to define is that you want to recover sigma, but you actually cannot recover sigma. So why can't you recover sigma? Maybe I'll just say it in right. So this tree with species A, B, C, and D is the same as this tree. Is the same as this three, where here I have D, C, A, and B. Okay, this, of course, when I wrote it down, I wrote, you know, if you think about why am I giving the leaves names, the leaves are the species. These are, you know, this is one type of monkey, this is another type of monkey, or an ape, this is another type of ape, this is another type of ape. These are the names, right? But when I draw this tree and I draw these three, these are exactly the same three. It means that this species of ape is close, closest to this species of ape. Is close closest to this piece of f, and this piece of f is closest to this piece of f, and then they are joined together. So, this is exactly the same tree, right? So, when I write recover t, I mean I recover sigma, modulo, the ways of drawing the tree. So, modulo gamma, so you know, there's a group theoretic way of writing what this gamma is, but the gamma is all the possible ways of drawing the tree so that it's the same thing. Okay, so maybe just to make sure again that we know what we're talking about. That we know what we're talking about. So, if you look at h, if you look at h equals one, there's only one tree in our setting. This is the tree AB. Of course, if I write BA, it's the same too. If I look at H equal two, there are already four trees. I'm going to actually draw all the trees to you. It's AB C D. That's the one that we had before. It's A C B D and it's A D B C. B C. These are the three possible trees that you have when you have two levels. When you have two levels, once I decide which is the closest species to A, I also decided which is the closest species to, you know, this determines the partition and I get the three in this model. If you want to think a little bit about what happens when H is equal to three, you know, the combinatorials will give you seven times five times three times three. This is correct. I just calculated it five minutes before I joined the Zoom call. So, but essentially, A has Call so, but essentially, A has to be matched to something, then the next layer has to be matched to something, then the next layer has to be matched to something which is the determined, and then there's the ways of drawing the next layer in this way that we did. Okay, questions about what we want to do? Okay, so I'll tell you how to do that. Okay, so this is what you want to do. I'm going to tell you how to do that, you know, that's the best. I'm going to tell you how to do that. You know, that's the best thing in life. It's like you teach undergrad linear algebra or something. You need to solve linear equation. Here's how you solve linear equations. So, this is how you're going to do that. I want to recover this tree. It's going to be some recursive procedure, which I'm going to describe to you. The recursive procedure is going to be the following. For every two species i and j, so i and j are coordinates of the vectors that I get or species, I'm going to estimate the covariance of the ice coordinates of the j. Of the x-coordinates of the j-coordinate. So I'm going to look at letter number one of the DNA, letter number two, letter number three. I'm going to compute the empirical covariance, which is just an estimate of the covariance. Why am I going to do it? Then I'm going to say, okay, I'm node number one, which is the guy that's most correlated to me? Well, it's in the permutation, this is this node, so this guy is going to be my sibling. Then the next node I'm going to ask, who is the guy that's most correlated to me? This is going to be this guy, and so on and so forth. That's what I'm going to ask. This guy, and so on, and so forth. That's what I'm going to do. I'm going to pair them up in this way. Now, where is the recursion? So, suppose I did my procedure. So, I decided that this guy A is with B, this guy C is with D, and so on and so forth. I decided to match them up. Now I want to recurse. How am I going to recurse? I'm going to try to do the same thing for the parents. I'm going to try to match to find the right matching among the parents. But in order to do this for the parents, I have to know what's the sequences or what. To know what's the sequences or what's the values here, and I don't know what the values here because they are not given. I didn't collect data on species that do not exist anymore, that are distinct, that are extinct, right? So I cannot do that. So what I do before I estimate what are the sequences. So how am I going to do it? I'm going to do it, say, using the majority estimator. I'm going to define a new vector z. And z is going to be for each coordinate is going to be the majority of the descendants. Okay, so now some of you should have an objective. Okay, so now some of you should have an objection. This is a a little bit good point of an objection. Because what is the majority of two bits? The majority of two bits, well, it's the bit, it's that bit if they are the same. And you know, what do you do if they are not the same? So there are various options. If they are not the same, maybe you choose a random, or maybe you completely discard this sample and you say that for this sample, you're not going to compute the correlation. So this is a little bit of an issue you do with just two, but when you will repeat the process, maybe. But when you will repeat the process, maybe you will figure out that this guy and this guy are indeed connected, this guy and this guy are disconnected. So, when I'm going to repeat it again, I'm going to compute the majority on four values. So, when you do majority of four values, it's a little less likely that you're going to be in the situation that it's even out. So, these issues about things being not well defined is a little bit less of an issue, but in any case, it's not an issue. Okay, so we are going to repeat this in this way, we are going to recover the structure of the talk. Okay, so what are the exercises for you? So I'm not going, I mean, you know enough in order to prove everything that's written in the slides. I'll tell you what are the two exercises. So let PMH be the probability of recovering the tree from M independent samples. So the claim is the following. If 2 theta square is bigger than one, we are above the cast and sting on bound, and the number of samples And the number of samples is less than a constant times h, the constant may depend on, it does depend on data, then the probability that you recover the correct tree is at least 0.9. So you do this procedure with number of samples that is just a constant times the depth, and then the probability that you recover the correct tree is at least 0.9. On the other hand, if 2 tethered squared is less than 1, then the probability that this specific procedure works is less than no matter what, how large. Is less than, no matter how large M is, is less than the number of samples. M again is the number of samples or the length of the DNA sequence times some other number, C theta, which is less than one to the power h. What does that mean? It means that in the regime where two theta square is less than one, the length of the DNA sequence or the number of samples that you need is exponential in the depth of the tree. So it goes from linear when two theta square is bigger than one. When 2 theta squared is bigger than 1 to exponential where 2 theta square is less than 1. So M is what was L on the theorem statement? I have no idea. Yeah, M, so very good. Thank you, Omar, for remembering. M is equal to L. Locally, M is equal. So in this theorem statement, it was L. And I'm F, yeah. So in the theorem statement, it was L. Thank you. Good. Other questions? Okay, so nobody likes to serve. Okay, so nobody likes to serve exercise. Is that a question or not? There was a question in the chat whether the optimal constants are known. So the optimal constants are not known. I mean, this constant is not known, which I think is slightly less interesting. But I think this constant is actually interesting, and this constant here is not known. I mean, because this tells you what is the right exponent, and we don't know what is the right exponent. So that's a very good question. Know what is the right experience? So that's a very good question, and I think it could be a good research problem, right? So, definitely, the proof that I know are very fine enough to answer this question. But just to be clear, I mean, I think the right question to ask is what are the right exponents if you're using the best algorithm. Here, I just presented a specific algorithm. You know, you want to ask what's the best constant to use. Any algorithm, and maybe related to that, let me actually give you a way. Let me actually give you a way of proving exercise number two. And the way of proving exercise number two will show that this is not dependent on the specific algorithm that we use. In fact, any way you are going to try to recover this trees, you are going to be unsuccessful if two tether square is less than one, if the number of samples is not exponentially made. So that's what I'm going to do next. I'm going to prove something more general. So next, we're going to do something more general. And a clarification from Thomas Hughes that the covariance is the sample covariance. It's the sample covariance, yeah. Right, and the reason why you need log n, maybe I'll just give you a hint, is that you compute a lot of covariances, you want them to be concentrated, so you need to use some concentration bound to show to show that they are concentrated around what they should be concentrated on. And it's also known that there's other argument that shows that log n is necessary, you know, this log n or. You know, this log n or this constant times h is necessary from some simple information theory or counting algorithm. So, this law, the fact that you need more than constant times h is well known by classical work in phylogeny. Good. So, let me give you the more general argument. And the more general argument says that if 2 theta square is less than 1, then you need an exponential in eight samples in order to recover. In H samples, in order to recover the tree. And this is maybe I didn't say it in the title, no matter how you do it. Okay, so I'll just give you this argument. This is a very simple argument, and then I'm not sure if I'll give you any more arguments in this course ever because, of course, I'm running out of time. But let me give you this simple argument. Okay, so let's do. Let's do this argument. So, first, I want you to start with an exercise that relates to something that we've seen in the last lecture. So, what have we seen in the last lecture? We've seen this for a fixed tree of H levels. So, here we have H levels. We can either start with a plus, and then the measure that we get here is P T plus, or we can start at the minus of the root, and the measure that we get is P T minus. And if you remember in the last lecture, we had a very simple base rule, which is. Very simple base rule, which says what's the change of measure when you look at Pt plus, P T minus versus P T. And applying this change of measure, you can see that the total variation distance between P T plus and P T minus, this or the distribution on the leaf just for one sample, is less or equal than two times, I think it's, okay, maybe it's actually equal, two times the expected value according to the mixed measure, we take half of this and half of that, of the absolute value of m of h. Value of M of H. M of H was the magnetization of the wood. It's the value of the expected value of the wood given the boundary. And what we've seen last time by induction is that this is less than, sorry, applying Cauchy-Schwaltz. I mean, you have to prove this, but I'm telling you how to solve this exercise. Applying Cauchy-Schwaldz and using what we've seen last time about the exponential decay of this quantity, the L2 norm of mh, this is less than two times two theta squared to the h over. Okay, so that's. Okay, so that's the exercise that I want you to do, which follows pretty easily from things that we've seen in the last lecture. Okay, why does this help us? Now I'm just going to show you something a little weaker than the claim, but I'm going to look at two very big trees, each of them consisting with four sub-trees. So this is a big sub-tree, which I'm going to call capital A, capital B, capital C, and capital D. One tree is going to be this tree. And the other tree, say I'm going to match sub-tree. Say, I'm going to match sub-tree A with sub-tree C. Derrida sub-tree B and sub-tree D. So this is C and oops A, C, B, and D. Okay, but these are the same trees. A is some big tree of H level, B is some big tree of H level. So when I say A, I mean, you know, the names that are written here are exactly the same. The names that are written here are exactly the same names that are written here. The names that are written here are exactly the same names of the species that are written here, and so on and so forth. Okay, so that's the situation. And now I claim that from the previous claims, it follows that if I look at the total version distance of the full distributions that I see here, and the full distribution that I see here is essentially at most the same thing. So instead of two times this quantity, it's going to be eight times this quantity. Why is this true? This is true for some stupid reason. This is true for some stupid reason. What's the stupid reason? I'm actually going to condition on the value here, here, here, here. Condition on the value here, here. I'm going to tell you what are these values. So, if I'm going to tell you what this value, everything is independent, and I'm asking you, you know, what's the total relation that I get between this measure and this measure, this measure and this measure. And, you know, what you're going to see is you're going to see that the same bound that we had last time applies here. Okay, so the reason that there's eight, it's four times. It's sort of the fact that the total version distance, when you have multiple coordinates, there's a linear bound, right? So the triangle or the tensoring inequality holds. Okay, and once you have that, you can apply it for independent samples. So now if I have independent samples, again, I apply the same fact about total relation distance for independent coordinates. Distance for independent coordinates going up linearly, and I'm going to get that the total version distance when I have m samples, or independent sequence or a DNA sequences of length m is going to be at most eight m stamps two theta squared to the h over two. And what does that mean? It means that in order to distinguish between the two topologies, I need this quantity to be close to be at least one half, or at least, you know, it has to be a non-negligible number. Because if the two distribution of the samples Because if the two distributions of the samples that I get from one case and the other case are very close together, it means that the distributions are not distinguishable. In order to be distinguishable, the total version distance has to be close to one. So this has to be close to one. But in order for this to be close to one, it means that the number of samples that I need has to be exponential in h. It has to be at least two theta squared to the power minus h over two. Okay, and that's the Okay, now let me do something non-traditional. I think we are going to maybe take a two-minute break soon. This is the break I promised you tomorrow. But before I do that, I want to make a decision. I mean, another application of this is the block models, but I sort of have to decide if to talk about. It's sort of up to decide if to talk about it or to go into the non-linear theory. So, here are two questions for you, the audience. Let's see if you know how to press all of your buttons on your Zoom. Can they raise their hand? Yes, no, or no? We should be able to. So, you open the participant list at the bottom. There should be a button there for raising hand and such. Okay, so two questions for you. The first question is: how many? You. The first question is: How many of you have seen recent work on the block models and its relation to Kestenstein Gumbaum? So raise your hand if you've seen it. See one hand. Yes. Okay, that's quite a bit. Okay, how many of you want to hear about the block model and its connection to this detailed asteroid? To detail as to the equivalent stigma pound. That's a different question. Okay, now I know how many people are actually listening. Okay, let's lower the hands. Okay, maybe in order to know how many people are listening, how many of you want me instead to go and talk immediately about some non-linear theory? Some non-linear theory. I have to confess, I can't figure out how to raise my hand. Seems to be a comparable. If you're a co-host, you might not have this because it seems like fewer people. So, so, okay, so let's take two minutes break in which time I'm happy to take questions. And I will just in this, in the meantime, And I will in this in the meantime, I will I will think how quickly do I want to go over the block model, uh the block model slides. It seems like there's a slight preference that I say something about it, so I will. Okay, so is there any questions? So we'll start again in two minutes, which we'll talk about. Yeah, I can see the chat and one question. Uh, is there any guess what happens in the critical case when two theta squared is equal to? case when two theta squared is equal to one so everything is known about it in the case of the of the of the broadcast process for the broadcast process even actually the arguments that we gave with the second order term this minus theta to the four blah blah blah tell you that the information between the root and the leaves decays it doesn't decay exponentially it decays just polynomially i think for phylogenies nobody actually did this but you know Actually, did this. But I think somehow, what I didn't talk about in phylogeny, it actually doesn't make sense to assume that all the branches have the same theta. So, anyway, you need to assume that different branches have different theta. Somehow, maybe the critical case is less natural there, right? So, I think it was natural in our case to assume that all the edges have the same theta just to explain the main connection between the correlation decay in constructing the trees. But from people who actually do phylogeny, if you tell them that all the tests are the same, they will laugh and go. All the tests are the same, they will laugh and go away, right? So, that's you know, you don't want to do that. So, okay. Okay, so let me share my screen again, unless there are more questions. Okay, I'll share my screen again, and I'll continue with at least next time we'll do non-linear theory. I promise. Theory, I promise, or there's very little non-linear theory that we know something not good is happening. Okay, so I think maybe my iPad is look. Okay, good. Okay, good. So, this is where we were. Now, I'm going to talk another application. I'll try to do it briefly so at least we get a glimpse of the non-linear theory today. Okay, I will try to. Me today, okay. I will try to talk slowly because I wanted to talk slowly today. I will try to talk slowly and skip some information so we get to the non-linear theory. So, here's the block model. You know, this is a, you know, one of the reasons I wanted to skip it, this, I think this is a maybe more popular work than some of the other work I talked about, but I will discuss it nonetheless. So, it's a random graph model on n nodes. What's the twist? The twist is that the nodes have colors, half of the nodes are blue, and half the nodes are blue. Half of the nodes are blue and half of the nodes are red. If you want to talk about the case where Q is equal to 2, okay, so the case that Q is equal to 2 is there's going to be a generalization, obviously, for higher Q's in a little bit. When two nodes of the same color are connected with probability, which is given by this formula, I chose the parameters in a way that will be clear in a second. It's two, so every two nodes are connected with probability, d1 minus theta over n. But if they're the same color, there's an additional probability that they're going to be connected. An additional probability that they're going to be connected, which is to the theta order. Okay, so that's that's the basic model. And why did I do that? I did it in order so that you have to check that, or maybe this note should have been an exercise. You have to check that in this model, the average degree is d. And if u is a neighbor of v, so u sim v means u is a neighbor of v, then the expected value of x u x v now again I think about. X U X V now again I think about the colors as plus minus one is going to be theta so it's similar to what we had in the broadcast tree model in the broadcast tree model if you look at the the parent u and the child v the expected value of x u x v is going to be theta okay because it's probability theta i copy and otherwise i randomize okay so that's the basic block model i i sorry i didn't give the references it goes back to the 70s it's it's a widely studied A widely studied, widely studied model. And the inference question that we're going to ask now that attracted a lot of attention in the last eight, seven, eight, maybe ten years now, is which nodes are likely to be red or blue? Okay, so that's the question what we want to know. Of course, I told you that half of the nodes are blue and half of the nodes are red. And when I'm asking you this question, which are red and blue, which are blue, I'm not going to tell you which ones are red and which ones are blue. Okay, so let's see what do I mean by that. What do I mean by that? Okay, sorry. And maybe I'll tell you what got me into this business and a bunch of us into this business. This was this conjecture in a paper by Desel, Kazakhala, Muinorova, which says that belief propagation is the optimal algorithm for solving this problem. And you can do better than random if and only if d theta squared is bigger than one. Okay, so. Okay, so this sounds very related to what we are talking about. We are seeing the casting sting of bound again. Did d theta squared be greater than one? We are seeing belief propagation again. Maybe we'll talk about what belief propagation means in this setting, and it's supposed to be the optimal goal. Okay, so let me just maybe demonstrate in picture what this model is. So I start from this model. Okay, maybe this is not a good sample, but some of the points are blue, some of the points are red. Between two points of the same color, there's an additional sample. Points of the same color, there's an edge with some probability. Between two points of different colors, there's an edge with different probability. That's a sample for the model. What's the inference problem? Inference problem is that I'm given exactly the same graph, but without the colors. I'm given these pictures, and somebody is asking me, please tell me which nodes are red and which nodes are blue. I just want a picture of the goal. And what is the goal? The goal is to say, well, these nodes are blue, and which this node is. Well, these nodes are blue, and which these nodes are red. I mean, let me just mention briefly two comments: there's a natural symmetry here, which is the red-blue flip. So, if I switch all the reds to all the blues and all the blues to all the reds, you know, I'm going to get exactly the same probability distribution. So, if I get a sample like that without the colors, I can't really say which are red and which are blue. I can say, you know, this is one class and this is another class. One of them can be red, one blue, or one blue, and one red. Blue or one blue and one red, and the other thing is that I mean, we are looking at a pretty sparse graph, sparse random graph. So we cannot really recover everything, cannot recover all nodes, even up to this global slip. And this is because if you just think about it, if you look at an Erdogani random graph in average degrees, some constant D, then there are many isolated nodes. For isolated nodes, those. Nodes. For isolated nodes, there's no way for you to know if they're blue or red, right? Each of them is not connected to anything. And there's a bunch of small components, there's a bunch of stuff that does you. So what you really want to do is you want to infer a little bit better than random. So there's this notion of detection, which is to classify better than random. Okay, so that's that's what we want. Okay, so that's that's what we want to do. Questions Okay, so maybe I'll tell you one Elis theorem, which you know I will do by pushing slides forwards and moving my hands. Let's see if I can control my art, this art well enough in order to convince you that they know how to prove theorems. Of course, I'm going to cheat in. Theorems. Of course, I'm going to cheat in a number of places, but let's try to do it. So, this, you know, how with John Neiman and Alan Sly, we got into this. So, the easy direction is the following. If you are below the castenstigmum bound, if d theta squared is less than less or equal than one, then it's impossible to infer better than random. So, let me show you why this is true. I mean, this is so, like I said, the easy direction. So, I'll just show you in pictures. Okay, so what is the picture? So, the picture is if I'm able to infer better than random. If I'm able to infer better than random, then I'm able to say better than random if this node and this node, these are two random nodes, have the same color or a different color. If I have a classification that's better than random, then I can look at an average. If I give me two nodes, I can classify better than random. So of course, by symmetry, you might as well assume that I tell you that this node is red. And the question is, can I classify this guy, the green guy, better than random or not? And now, since I'm a very generous person, And now, since I'm a very generous person, I'm not just going to tell you that this guy is red. I'm going to expose a level H neighborhood of this vertex in the graph. A neighborhood of radius H of this vertex is going to be with side probability tree. And I'm actually going to tell you the colors of all level H of the tree. So I'm going to give you this guy and all of these guys. And your goal is to guess the value of this guy. Now, what is the point here? The point is. What is the point here? The point is that XH is essentially level H of our broadcast process. So you know that when detail squared is less than one, you cannot recover this guy, the green guy from X H with good probability or in the sense that as H goes to infinity, the probability of a correct recovery is or is going to a half or the magnetization is going to zero. Half or the magnetization is going to zero. Okay, but you say, what about this guy? There's still this guy. So now you use another property, and this is actually where most of the proof goes. Use the fact that this is essentially a Markov random field. It's not exactly a Markov random field, but it's essentially a Markov random field. So the Markov random field property, for those of you who do not know, says that conditional on this ring that separates this guy from this guy, the two colors are independent. So the additional information that I have in this guy doesn't give you anything. I mean, this guy doesn't give you anything. Okay, so you see a very, very clear connection to the broadcast at Tree Model, and of course, the physicists were aware of this connection. I mean, somehow they missed the theorem. This theorem is pretty easy. Okay? Yes, I should use that. I should I should use that. I should. An important fact is that this uses this paper that we talked about of Evans, Kenyon, Perseus and Schulman, which talks about the situation where the tree is not exactly regular, not all of the degrees, it is the same, but the average degree is d. So you can, all of the results we've seen that where the degree is exactly the k over to branching process trees where the average degree is. Okay, so I want to tell you a little bit, just in a few words, a little bit about the other. In a few words, a little bit about the other direction: that if d theta square is bigger than one, then it is best possible to detect. It's best, it's possible to infer this partition better than random. And I won't tell you much about the yep, sorry. Sorry, you asked us to slow you down. There's a question in the chat of why it's a tree. Right, so this is something. Thank you. Yeah, this is a good question. I mean, it's something that one has to prove, but it's very similar if. But it's very similar if anybody, if for those of you who've seen random graphs before, when you look at a sparse random graph and the average degree D is a constant, there are essentially no short cycles, right? So, you know, things are three, right? If you just try to think about the probability that you will have a triangle, you see the probability that you'll have a triangle around any node is going to be pretty small. So it's the same argument that you have for Erdogan in random gas when there's paths, right? So the key factors. So, the key factor is that d is some constant. So, if you want to think about it in terms of g and p, the probability of an edge is going to be one of two numbers. It's going to be either d plus some constant over n, or the, I don't know how to call this constant, or the minus a constant over n. Okay, but these are still just, you know, it's a very sparse, it's a very sparse underground. Thank you for the question. Okay, so what's the more exciting result is that if detected square is greater than one, I mean, this was proved by us and by Loan Masule independently, then it is possible to detect. I'm not going to tell you much about the proof, except a previous attempt at the proof, which eventually worked by another work by Massoule and collaborator. And I just want to highlight the connection to belief propagation. And, you know, And, you know, after we started thinking about it, we actually wrote a joint paper with the physicist that did not have proof of this conjecture, but it says the following. If you look at A, which is digency matrix of the graph, so it's very common to use spectral algorithm on matrices in order to find a partition. But instead of looking at the matrix A, you're going to look at this matrix, which is a 2n by 2n matrix, which this will. Matrix with this weird form, then the second eigenvector of this matrix is correlated with the partition. Okay, so you should all see the few faces of you that are staring, staring at this matrix. You say, why would you come up with this matrix and why D is the vector of degrees of all the vector? Why would you come up with this matrix? And what I want to tell you is that, you know, the reason that we got this matrix is that we linearize this belief population. Linearize this belief propagation. So, the thing is, you know, like I said, belief propagation, even when you don't have a tree, you can pretend that you have a tree. You can do the same recursion that you did on the tree, the recursion that we've seen last lecture, even though it's not a tree. You apply these recursions over and over again, and you get some probabilities, and you can classify according to this probability. What we did is instead of working with belief propagation, we look at this operator that non-linear operator that maps probability to Operator that maps probability to probability. We linearize this operator. By linearizing this operator, we got this matrix. And then they said, okay, it's this matrix that tells the story. And as I mentioned before, this conjecture was proved by Baudonaire, Lelarde and Massoulet a couple of years after we made this conjecture. So it's another instance where you see the leaf propagation and you see linearization and this gives you sort of the right answer. Okay, so maybe I will conclude this part just from a beautiful picture of that, you know, in this paper with the physicist of how does it actually look. So this matrix is not the kind of matrix that you're used to. It's not normal. It's not symmetric. So the spectrum is interesting, right? So the spectrum is complex. There's always this eigenvalue which corresponds to the average degree. This is not the interesting eigenvalue. This is the interesting eigenvalue, the eigenvalue and the corresponding eigenvector that corresponds to the. Corresponding eigenvector that corresponds to the partition. So, this is from a sample from this model. And our friends, you know, also applied it to a bunch of actual networks. And in many of them, the real eigenvalues outside of this circle of value square with the average degree seems to correlate with communities in the data. Okay, any questions about this part before I start talking about the non-linear? I start talking about the non-linear, the non-linear theory. Oh, you're muted, Donald. The non-linear theory? Second? It seems people are ready for the non-linear theory. Okay, so maybe we'll summarize the linear theory in a couple of sentences. We have this interesting. You know, we have these interesting models, you know, which have some hierarchical connection between random variables, which can be inverted via this belief propagation, which is this non-linear recursion. But somehow we found ways of linearizing it that gave us what is the threshold for this broadcast model, and it also gave us what the threshold for phylogenetic reconstruction, and it also gave us what the threshold for this partition, this one of partition of the block model. So we somehow by linearizing stuff, we got the right answer. Linearizing stuff, we got the right answer, which is Judaism. So, I'll tell you in advance that you know, in the non-linear case, we know much less, right? So, you know, there's going to be a lot of open-ended things here, but I'll tell you what we know. Okay, so for me, nonlinear theory is going to be large q, and I'm going to talk specifically about what this large q is, maybe in the next lecture, but for now, just assume that q is equal to 100. Just assume that Q is equal to 100, okay, or 20 or something. I mean, it doesn't, it can be smaller than that, but you know, the number of colors is bigger. We have exactly the same process. We copy this published data, we randomize otherwise, but you know, that's going to be the setup that we have. Okay, so the fourth thing that I want to mention is larger Q makes things easier in some sense, not harder. So, everything that we knew how to do before, we can do now. So, this is the claim. Now, so this is the claim for all Q, if d data squared is bigger than one, if you're above the cast and stigma bound, for the three broadcast model, the magnetization can distinguish. This means magnetization doesn't go to zero. The limit of the magnetization is strictly positive. Okay, so you know, if I run this process on the tree, I look at many levels, I do believe propagation, I try to infer the root, I get a random variable that's non-trivial. That's non-trivial. We can detect in the block model. We can find a partition that's better than the, you know, if q is 100, better than a random partition to 100 blocks. And we can recover phylogenies or these tree structures from sequences of lengths or the login. So everything that we knew how to do before, if b data squared is bigger than one, we still know how to do now. Okay, we haven't lost anything. So I'll give you a proof of this claim, actually, but I'll just do it for even Q because I'm But I'll just do it for even Q because I'm lazy. So here's the proof for even Q. It's a one-line proof. What am I going to do? I'm going to divide the Q colors into two sets of size Q over 2. My 100 colors, I'm going to divide into two sets of size 50 colors. And I'm going to say every all these 50 colors, which I partition arbitrarily, they are all going to be plus. And these 50 colors are going to be minus. And then you say, what does it happen? What does it do to the probability distribution? So you have to think for a second, but you see that plus go to a plus. You copy this probability. Plus, you copy with probability data and you randomize what you did before, you still do, right? You know, when you copied, you are going to stay in the same class where you haven't copied, you randomize, so you're still going to randomize. So, this gives us a trivial reduction from the case of even Q to the case of two, and it allows you to apply exactly the same algorithms and reasoning that you apply. I mean, it just exactly maps the measures in a way that the distributions are consistent, that lets you do. Are consistent that lets you do one, two, and three. Okay, so for those of you who say, okay, but what about odd Q? Okay, so for odd Q, you have to walk, and we won't do the work, right? So this is something that maybe we mentioned in answer to a question in a previous lecture. More generally, this is true for a broadcast process with smarkov chain M on edges. So when you have the same Markov chain on every edge, where theta is the second eigenvalue, so it's the maximum absolute. Value. So it's the maximum absolute value of everything in the spectrum of m a became this is m sigma of m so this is the spectrum of m so you look at the second absolute value of of in in magnitude in the spectrum the largest one is one so that's and you're going to call that theta and everything And you're going to call that data, and everything is going to all the results that we know are known to us. But this requires some work. So, for the broadcast three models, you know, you actually have to go through Kesten and Stegrom. For the block models, you have, you know, Bordeneville and Masulet and Abbey and Sandon work pretty hard to do it. For phylogeny, we've seen a joint work with Sebastian Roche and Alan Slime. We did it. So you can do it. It requires work. It's not straightforward, right? But it's something that you can do. Okay, so Emma's in the. Okay, so everything that we could do before, we now do. So now we are going to be more ambitious. We are going to ask: can we do what we did before, even if detailed? So maybe the next question, next, can you do it if, or for some data for which d data squared is less than one? So that's maybe the next question that you want to ask, right? So above the Kesten-Stigm bound, whatever we could do before, we can still do. What about below the Kesten-Stigm bound? The constant thing about so here is the result. So, for a large q, again, think about q greater than 100, and I'll give you more detail later. There exists a theta q such that if the so such that this theta q is below the castenstigum bound, so d theta q square is less than one. Okay, so maybe I'll do a little interval here. interval here this is zero this is one this is theta kestenstigum and now there's going to be this theta q such that when l theta is bigger than theta q for the three broadcast model you can distinguish you can do better than rather you can detect in the block model and you can recover phylogenies from sequences of length order log n so everything that we could do in the case where q In the case where q is equal to above the castenstigum bound, and in that case we knew that we cannot do better, then we can do below the castenstigum bound for some interval below the castenstigum. Okay, but there's a twist. What is the twist? I'm going to tell you what are all the twists. So you can do it, but you cannot. It, but you cannot do it using linear estimators. Remember, one of the nice things about the case q equals 2, we analyzed belief propagation and we analyzed another algorithm which was the majority algorithm, and they both gave us the same structure, then we were happy. But for large q, this is not the case. With linear estimators, you can only do things above the casting statement. Or you cannot do it with robust estimators. I don't know if I'll have time to tell you what robust estimators are today, but you cannot do it with robust estimates, right? So somehow you reconstruct. Estimate, right? So, somehow your reconstruction procedure has to be much. You can do the loop propagation, which is this non-linear iteration of founder variables, and this would work. But you know, if you want to do something simpler, simpler things are going are not going to work. You can detect in the block model, but what is going to be the twist? So, this is a twist that's not known to be not known formally, but it's believed to have a computational statistical gap. So, this is, you know, this conjecture was made many times. I think I'm citing these papers. I'm citing these papers as papers that gave some evidence of that, but it goes all the way back to the physics papers. But what does it mean to have computational statistical gaps? So, people have algorithms that can detect better in this interval below the curst and stigma bound, but these algorithms take exponential time. It's not like some spectral algorithm that you look at a matrix, compute an eigenvector. This algorithm is like, oh, I'm going to enumerate overall partitions. For each partition, I'm going to do something. So it's something that definitely nobody will apply in practice. Nobody will apply in part. And you can recover phylogeny from sequences of order loans. So this is not written. I mean, one of the reasons that it's not written is that in the very, very simple case that I told you right now. So why is it not written? So if all thetas are the same, you can apply the same algorithm that we've seen today. So, I'll recall what's the same algorithm that we've seen today. You find for each guy what's the most correlated other leaf, you merge them up. Now, but now you are not allowed to take majority, you are going to do belief propagation in order to estimate the roots. Okay, it doesn't matter. But the conjecture is again that it cannot be done robustly. What does it mean? It cannot be done robustly, it cannot be done in the setting that is interesting for biologists. What's the setting that is interesting for biologists is that the data. That is interesting for biologists is that the thetas are not all the same, or the tree is not exactly fully balanced. And this conjecture, I think, just for this lecture, I finally found two formal formulations of this conjecture that maybe I'll give in the next lecture. Okay, so what happens is somehow in the linear case, you know, we had very robust, simple algorithms or inference procedures that did what we want. Procedures that did what we want. They were optimal in the sense that when they walked all the way to the cast and stigma bound and above the cast and stigma bound, nothing works. Now, until the casten stigma, you can do whatever we did before. But above it, we have this influence procedure that are sort of nasty. They have to be non-linear. You know, the only way we do know how to do the block model is we have to do something that's running exponential time. The only way that we know how to do phylogenetics is to assume a lot of unreasonable assumptions. To assume a lot of unreasonable assumptions, so somehow you get the feeling that things are more delicate and hard. Okay, so maybe in the next few minutes, I'll just give you a little bit of a feeling of the fact that we know that things do not work. And next lecture, maybe we'll start with a few minutes or the first few minutes of the talk, I'll tell you a little bit more about some of the non-linear things that we believe or conjecture. In particular, I tell you about these two conjectures. You about these two conjectures. So, I'm going to tell you about two results that show that if you want to do something robust in some sense or something non-delicate, then the Keston-Stingo bound is the right bound even for large Q. So, I'm going to tell you about two theorems. One was joint with Evaltaz, and one was joint, or this is me actually, joint with Joint with Svante Johnson. Okay, never mind. But these theorems are the following. So we are in just the broadcast process. So we have one tree and Q is large. Q is large. I'm running out of the page. Okay, so I'll try to do it somewhere else. Okay, so Q is large. Is large and now I'm going to talk about a new notion which is called count reconstruction or sensors reconstruction. So count reconstruction and sensors reconstruction, you want to do the same thing that you did before. Here is xh. You want to say something about the root x0, but I'm going to limit your power somehow. How am I going to limit your power? Instead of giving you xh, I'm going to give you this information CHV. Formation CHV. So, what is CHV? Or CHA? CHA tells you for each color, how many indices of XH are equal to A? So instead of XH, I get the count of XH. And again, the count of XH, you know, XH is a two to the H dimensional vector. XH is the Q-dimensional vector. XH is the Q-dimensional vector. It just tells me in the vector XH, so many coordinates were color one, so many coordinates were color two, so many coordinates were color three, and so on and so forth. So what does the theorem about count reconstruction of sessions reconstruction says? It says that if the only information that you're given is not XH, but just the number of colors of each type, then the cast and stingle bound is the right threshold. So let's think a little bit what it says. Somehow it says that what belief propagation is using, because it's walking above the castenstigm bound in this case, it's not just using how many are there of each particular type, it's also using where are they. So it's not using the fact that there are so many blues, so many red, so many yellows, so many green. It's using something like, oh, this blue here, and there's another blue here, and the green is here, is here. It uses the more delicate information about the location. uses the more delicate information about the location. So that's one sense in which you need, in which, you know, if you want to do something robust, then you can only get to the custom stingo bound. And there's another notion which I'm going to talk, and I think I'll finish with this. There's a notion of robust reconstruction. So in robust reconstruction, we are, you know, what you're given, maybe I'll draw the picture here in robust reconstruction. I'm going to fix some noise level eta. And what I'm going to do is I'm going to do exactly what I did before. There's the root x0, then there's xh. Then I'm going to have a vector yh, if you want. What is going to be the vector yh? It's going to be exactly the same as xh, except I add a little bit of noise. So for each coordinating depth, bit of noise so for each coordinate independently i let yv equal xv with probability eta and yv is otherwise uniformly at random for some fixed eta okay so i'm introducing an additional level of noise which might be much bigger than the original theta of the tree right so it might be randomized much better so instead of actually giving you the leaps i'm giving you a very very noisy very very noisy level Very, very noisy level of the leaves, but all of the processes until the leaves I haven't touched. Okay, and the result that we proved is fun to gentlemen is for robust reconstruction. Again, the Kestenstig above is the right threshold. Okay, so again, it means that somehow what belief propagation is using, it's not just using in which direction you are tending to be, which color, it actually wants to know that it's very strong that you're going in this. It's very strong that you're going in a certain direction. Okay, so I think that's all I'm going to say today. I think what I'm going to start with next time, I'm going to start with this slide. I'm going to spend maybe 10 or 15 minutes, hopefully, more on non-linear theory. So, I'm going to start with this theorem that to some extent for large Q, the right threshold is d theta equal to one. So, it says that. To one, so it says that if d theta is greater than one, not d theta squared, but d theta is greater than one, then for large enough q, we can distinguish the root better than random. So, you know, what was before d theta squared now becomes d theta. And again, but this is using this much more fragile location-based non-linear algorithm, right? So, this is in the limit, and I'll tell you also about some other results and conjecture in this segment. So, I think I'll stop here for today, and I'm happy to take questions. For today, and I'm happy to take questions for as long as people have questions. Okay, so let's unmute all the participants so we can recording the stop. We can take more questions now. I don't see at the moment any in the chat, but until one comes, I just wanted to ask about the block model results. Did you always assume that the graph was? Assume that the graph was sparse or no? Oh, now Elkana is muted. Okay. You have to start again. Sorry. No longer. Am I muted or not? No. No? No, no. Okay. Okay. So, yeah, there's a very long history for the block model. I mean, definitely the earliest results in the block models were in the case. So let me just give you a little bit of context about the block model. Just give you a little bit of context about the block model. So, people have studied the questions of partitioning of block models for at least since the 70s, and definitely the first works in this way in the dense case. And the connection to random matrices and rank one perturbations, you know, go way back. And in fact, you know, if you want the state of the art until this work with the linearization of VP was to use results from random matrix theory or perturbation of random matrix to see what you can do, what you can do there. Do what you can do there. And in the non, it essentially works all the way up to the case where the graph is passed, up to the way where the average degree is logger nor less. When the average degree is logger nor less, you know, we are aware that somehow what happens to the spectrum of the UGL operator is that they're too much influenced by the high-degree nodes. So, somehow the high-degree nodes, you know, kill all the usual spectral methods that we use. And that's the reason that there was a need for something new. But definitely, the results. something new. But definitely the results about the denser case or the average degree speakers and login go all the way back to the 90s or something. Thank you. Other questions? So for the robust reconstruction, are you mainly interested? Is it mainly interested when theta is much smaller than theta? Since, as you say, let me say very Yeah, so let me say very good. You asked the right question. I was a little careless here. So the way it works is that you fixed eta after you fixed the theta. So you give me d theta square bigger than one. I'm going to find the noise level eta so that for this noise level, you will not be able to reconstruct. And the noise level is going to be much, much higher. Okay. But it's only at the leaf, right? But it's only at the leaf, right? So the statement is that if the eta square is bigger than one in one direction, if detested if the theta square is less than less or equal than one, then there exists an eta greater than zero, such that, or between zero and one, such that with this noise level eta, you will not be able to reconstruct. Okay, but this is asymptotic in the level of the tree. So the important thing is that eta does not depend on how many levels there are. That eta does not depend on how many levels there are to the chain, okay? Yes, only on the Markov chain and the entata. Okay, yeah, there's a question in the chat from Ratul. Could you explain how is giving the count providing lesser information? Isn't giving the same information as in the unknown permutation case? Good. So let me help clarify what's going on here. Maybe I'll try to find an empty page. I'm trying to dispense a lot of empty pages so I don't have to add a page to my notes. But okay, so the anode permutation case was a different problem. So in the phylogeny, I'll just try to sort of. So in the broadcast model, if you want, there's a single sample of XH. XH and the goal is to estimate if you want goal is to estimate X naught in the phylogeny case there's an unknown permutation but there are n independent samples from the process And the goal is to do something else. The goal is to recover the tree. Now, you may ask what happens if you are given a single sample and you don't know the structure of the tree. And this is a very good question, which I haven't thought about it until you asked it. So it's not completely clear that in this case you get something that is permutation invariant because the distribution of what you get is not permutation invariant. Is it permutation? It is permutation invariant. Permutation, it is permutation invariant. So, so in this case, everything is good. In this case, everything is permutation invariant, and the only thing that you can do is you can do counter construction, right? Because by definition, you know, what you you're given with the random permutation, so you get something that permutation invariant. So, all the information that you have is how many do you have in each type, and therefore, the only thing that you can do is counter construction. And therefore, for this parameter, when you don't know the tree, then the KS bound is The Ks bound is KS bound is always the bound. Always type. This means for every Q okay, so the important difference is between question number one and question number two. I'll just repeat it. In the broadcast model, we know the structure of the tree. We are given xh, but we know that these two coordinates of xh. That these two coordinates of XH are sister coordinates. So we know the full structure. We know we are given XH. We don't know what's inside the tree, but we know the structure of the tree. In the phylogeny problem, we do not know the structure of the tree. And I guess the question that you ask is, what happens if you are just given a single sample and we don't know the structure of the tree? If the meaning of not knowing the structure of the tree is what I said, it's, you know, instead of your actual sample, you apply unknown permutation of the leaves, then you cannot do anything better than the count. Do anything better than the count, and for the count, the custom stick on bound this time. Does this make sense? Yeah, so he says yes. So other questions? Questions in the chat. So the TA for the review session is Frederick, was it? Frederick Wallace. Is he here? I look him up and see. I don't see him on the participant list. I don't see him. Some people have already left. Some people have already left, but so I'm not sure. I'll even check. Yes, so the review session is supposed to start at half past and it doesn't have to be here right now, but it would be good a bit early. And people who are interested in this can either stay or This can either stay or log off and reconnect later. It will be at the same link. Sounds good. I'll stay here and keep the room open. Well, thanks, Algon. You don't have to exercise. Yeah, I think I'll go. Okay. Thank you. Okay, thanks. So, uh, see you tomorrow, thank you. Thank you. Bye. I'm gonna stick around to see if Frederick shows up. I sent him an email yesterday, just with a brief explanation of how we ran this. And he replied so he.    