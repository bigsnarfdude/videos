Of today is DC, and she's going to tell us about quantum spread complexity due to your simulations. So, I'll be talking more about the application of quantum information tools in particle physics systems. So, specifically, I'll be talking about this quantum spec component. I'll be talking about this quantum spread complexity studied in nuclear oscillation scenario, and it is based on this recent treatment that we just posted on last month. And this work is done in collaboration with Advid and Shulpa Design. So, this will be the tentative plan of my talk. So, first, I'll brief you with the motivation behind this work. Then, I will discuss about the phenomena of neutrino oscillations and spread complexity. And then I will discuss about my work, which is about the analysis of spread complexity in neutrino oscillations. And then, finally, I will conclude my slides. So, this pundo completely. This quantum computational complexity has been the problem of prime importance in the quantum information sector and computation sector. It basically estimates the difficulty of constructing a target state or a system of interest using some elementary operations. And apart from that, it also serves to study a completely different physical problem, which is about the information processing inside the interior of the. Inside the interior of the black hole. So, basically, the idea is that the growth of complexity can be put on the equal footing of the growth of interior of the black hole. And this is how it extends the connection between the geometry and the information processed in this black hole. So, it gives us the motivation that we should see the characteristics of this complexity for other natural sources, other natural processes of evolution. Evolution. Now, on the other hand, neutrinos have shown their ability to be utilized for different quantum information processing and computational tasks because they have their inherent properties such as entanglement and non-nuclear correlations. So, it gives us motivation to study this complexity feature for neutrino oscillation scenario. And it will be interesting to see if this complexity can probe some or any of the open issues. Any of the open issues present in the neutrinos issues. So, let me now introduce first the neutrinos and its properties. So, neutrinos were first postulated by Wolfgang Pauli when he tried to explain the continuous spectrum of beta decay. And to explain the conservation of energy, momentum, and spin in this process, he suggested the existence of this third particle, which was later on named as neutrino. And nowadays, we Neutrino. And nowadays, we already know some of its properties: like it has spin-half, very small mass, and it's a neutral, electrically neutral particle. And it comes in three varieties, three flavors associated to its charged leptonic counterparts, nuE, nu mu and nu tau. It participates in weak interactions only and in terms of handedness, neutrinos are always left-handed, and antineutrinos are also pretty right-handed. Also, for the right heater. Now, after photons, neutrinos are the second most abundant particles in the nature. So, about 65 billion of neutrinos, those are produced in the interior of suns, it crosses almost one square centimeter every second. However, in the very first solar neutrino experiment, which was the homestick experiment, it was seen that the observed neutrino flux was just one-third of the predicted one. Of the predicted one. Now, to explain this deficiency of neutrino flux, Pontecordo suggested the phenomena of neutrinos. He suggested that the neutrinos which are produced in the sun's interior are of new E type and since they travel from neutrino to from earth to the metal sorry from sun to the earth, it can oscillate into some other flavor for example NUMU or Newton. And since our detectors on the earth are sensitive to the new E neutrinos only. Through the new E neutrinos, only we are having this deficiency in the solar mutiny because similarly, the updow is symmetry that was observed in atmospheric muon neutrino flux that also gave the additional hint in favor of neutrino oscillations. In the year 2015, Takaki Kajita and Arthur McDonald, they shared the Nobel Prize for the discovery of this phenomenon. Nowadays, we have some experimental facilities like solar and atmospheric neutrino facilities. Neutrino facilities as well as some bandmeat facilities that use the reactor and accelerator neutrino beads. Now, the phenomenon of neutrino oscillation implies that the three flavor states of neutrinos are not exactly equivalent to the mass eigenstates. In fact, they mix via a unitary matrix to form these mass eigenstates. And this Newton oscillation phenomena occurs if the mass is. If the masses corresponding to these mass eigenstates are non-regional. So basically, we have two choices of basis over here: one is the propagation state or the mass eigenstates, another one is the paver state, nu E, nu mu and nu tau. So we can write the general state of neutrino in both of these two bases as a superposition of these three types of states and the coefficients in these two representations are connected via this cunatary matrix. Connected via this unitary matrix. A convenient parameterization of this unitary matrix was provided by Ponty Pervo, Maki, and Matakav and Sadhata. So we call it the preeminence matrix. So here these Cij and Sij are the cosine and sine of these theta ij, the mixing angles. And this complex phase delta over here, that is the parameter that can induce the charge parity violation in nucleinocene. We can also write the We can also write the evolution of mass eigenstates as given in equation 2 as a solution to the Schrodinger-Lag equations. And finally, we write the flavor states of neutino at time t as a flavor state, as a superposition of flavor states at initial time. And this UF here that represents the evolution in the flavor basis of mutations. So using the elements of this matrix, we calculate finally the probabilities of survival. The probabilities of survival or oscillation of initial flavor of neutrino. And we can see that these probabilities depend on the mixing matrix elements as well as on the distance travelled by the neutron or we also call it the baseline and the energy of nucleon. The delta n, delta ij over here is the mass square difference that is associated to the mass attitudes of nucleons. Now, nucleino oscillation is a well. Newtono oscillation is a well-established phenomena as of now, but there are some open issues present in this system. For example, the neutrino mass hierarchy problem. So, here in this figure, I have given the spectrum of neutrinos, two possibilities of this spectrum. So, from solar neutrino data, we know the relative position of nu2 and nu1. So, basically, nu2 is heavier than nu1, but we do not know the exact position of N3, whether it is the highest one or it is the lowest one. One or it is the lowest one. So, based on this, we call it normal hierarchy and inverted hierarchy. And basically, it represents the delta m squared, its sign. So, it will be positive over here and negative over here. So, that sign we do not know right now. Second one is CP violation. So, basically, in Newton oscillation, Cp violation can be seen if the probability of nu alpha bar going to nu beta bar is not equal to the probability of nu alpha going to nu beta. The probability of nu alpha going to nu beta. And this can happen for a non-zero value of delta. So basically, the experimentalists are trying to figure out the exact value of this parameter. The third one is absolute mass. So Newton oscillation scenario, it just depends on the mass square differences between these mass eigenstates. But it does not say anything about the exact scale of this mass. So that is again an open issue. However, we are, we will be discussing We will be discussing, we will be focusing more about these two problems in our book. Okay, so let me also give you a brief introduction about the Newtono experimental facilities. So NOVA and T2K are the ongoing experiments as of now and Dune is the future plant experiment. So their baseline ranges from hundreds to thousands of kilometer. Hundreds to thousands of kilometers, and the energy range of neutrinos over here is of GE recorder. So, here in this figure, you can see the underground facility of Yoon experiment. So, basically, the source of neutrino is placed in Fermila, which is 1300 kilometers away from the detector, which is placed in Stanford underground facility. So, while they travel from source to the detector, neutrinos have to face the metadensity potential. Phase the metadensity potential which is induced due to this Earth's crust. So, basically, nucleos can interact with the material medium via either neutral current interaction, neutral current peak interaction or the charge parameter. Now, the coupling for this neutral current interaction is the same for all the three flavors. So, that is why it just induces this term which is probably. Induces this term which is proportional to the identity matrix. So, in the oscillation amplitudes, this term appears as an overall phase pattern and it goes away, it vanishes from the probability expressions. However, the new E-neutrino can also interact via this charge current interaction with the electrons present in the metal, and that induces the meta effect in neutrino oscillation as it appears in over here with this diagonal matrix. Okay, so now let me come to the second part of this study, which is about complexity embedded in a general evolution of any system. So, complexity estimates the difficulty of constructing a target state through an initial state using some elementary operations or bits. Or, in other words, we can also say that it gives us the estimate of the minimum number of unitaries that are required to construct a target state through. Construct a target state through prong but different state. For example, if we have a system represented by this pi state and this is true for this evolution of this system where these u1, u2, u3 are the unitary gates, then the complexity embedded in this system will be equal to 4. It's like that. So now here we have seen that to estimate the complexity in a given system, we need a target and a reference state and a set of And a reference state and a set of unitary operations. However, a recent measure of this complexity has been given, which is more based on the minimization of spread of the wave function over all possible choices of bases. So, and also in this reference, it has been shown that the minimum of this complexity can be obtained through. Obtained through an ordered orthonormal basis, which is produced by applying the Grammat-Schmidtz procedure. We know that the general time evolution of a system can be represented like this by Schrodinger equation and the solution to this equation has this infinite exponential series expansion. So, we write, we can write actually the flavor, the time-evolved state as a superposition of infinite seigen series. finite sciences. Sign is nothing but the initial state operated by nth order of the Hamiltonian. Now it is not necessary that this set of science states will be orthonormalized. So we need to apply the Gram-Schmidt procedure to obtain an ordered orthonormal basis out of these science states. So basically we start with the initial K0 state as at the initial state of the system and then we apply Of the system, and then we apply the Gram-Schmidt procedure to get the 12-O pieces. And finally, we define, we quantify the complexity for a system in terms of this cost function. And n over here basically represents a real increasing number, and this specific choice of n is found to minimize the cost function as a number. Okay, so we studied this. Okay, so we studied this spread complexity for first of all for two-flavor oscillation scenarios. So we here have this flavor basis Hamiltonian which can be obtained using this formula and U and H M over here represent the mixing matrix and the Hamiltonian and mass matrix. Now here in this case we have two choices of initial state. So we can study the flavor evolution of these states and when we apply this Gram-Schmidt procedure for the both of these states Procedure for both of these two states, we figure out that the spillover basis will be just equal to the favourite state basis. And hence, when we calculate the complexity either for new E flavor or new mu flavor, it comes out to be equal to the oscillation of this flavor. It means the pi E will be P e mu and pi mu will be equal to p mu mu. So it means more will be. So, it means more will be the oscillation of the initial flavor, the more complex will be the evolution of that mutinous flavors. Also, one point is to notice over here that for standard vacuum and metal oscillations, these probabilities PE mu and P mu E are equal. Hence, we can say that the complexity embedded in either nu E or in nu mu flavor in this scenario will be equal. Then next we calculated this spec complexity for three flavor oscillation scenario and now we have three choices of initial states over here as represented here and the unitary matrix is now 3 cross 3 the PMNS matrix. In this scenario we interestingly find that Pello basis does not come out to be flavour basis exactly over here. For example if we start with the initial If we start with the initial new E flavor, then these are the forms of K1 and K2 states. They are not exactly equal to the 011, 010 or 001. They have this mixed structure. So hence, when we calculate the complexity for this flavor-state evolution, then we figure out that there are some terms proportional to PE mu and PE term, which are the oscillation probabilities, but there are some also There are also some cross terms available here. And that makes it to have more information about the nuclear system in comparison to the oscillation probabilities. Now so far I have discussed about the analytical expressions of this complexity scenario for neutrinos. However, we also studied the effects of different oscillation parameters on these. Different oscillation parameters on these complexities. So, here we have plotted the complexities for all the three flavors with respect to the L by E ratio for neutrinos. And we can see here that the rapid oscillation pattern is appearing due to the large mass square difference beta n31 square which appears in the oscillation phase and this large oscillation pattern that appears due to delta m21 square. To delta m21 square. And if we figure out, if we look at the zoomed-in picture of this, which is about the shorter value of L by E, which is also more relevant to the current nuclear experimental facilities. Then we can see that the complexity induced by chi E parameter or the new E state will be the least over here. While in the general evolution, we could see that the chi E was showing the maximum. Pi e was showing the maximum value. So, this result can be important from the quantum information sector because they look for the least complex systems to make the protocols of processing quantum information processing and competition tasks. Okay, so next we figure out the effect of the CP violating parameter, the complex phase delta. So, we plotted here the complexities for all the three. The complexities for all the three flavors with respect to Ly E value, and we also compared these with their corresponding total oscillation probabilities. And the different colors over here are representing different values of this data product. We can see here that complexities in all the three flavors mimic the features of the total oscillation probabilities. However, they have extra information about delta parameter because they can distinguish between these. Because they can distinguish between these values. Now we have seen that time u, pi tau, and pi e they have variations, they have sensitivity to this delta parameter and chi mu is obtained, is achieving its maximum value at minus 90 degree, while chi tau will be maximum at plus 90 degree. However, chi e is showing some other different value. Now, let me also mention Let me also mention over here that this plus and minus 90 degree is related, is associated with the maximum CP violation in neutrinos. So, how come this chi E is showing a different value, a different value of parameter? But then we realize that for a larger value of L E, which shows us the general picture, chi E is also maximum at plus minus 90 degree. So, basically, we can conclude by all these results that all these quantities. That all these quantities, all these complexities are favoring the maximum value of CP value in parameter by showing the maximum value over here. Now, next we consider the meta effects also in these complexities. So, we figure out over here that the initial two pillow states are just equivalent to the vacuum states. They do not get affected by the metal density. However, this last K2 states are the same. However, this last K2 state will have this metal just like shown over here in case of new E state. So, this V appears over here in both of these two non-zero components. Similarly, we also I am also expressing here the K2 state for initial new mu flavor. However, in this case, only D1 will be having this plus V effect over here. So we plotted here these three quantities with respect to the energy of neutrino and the solid and dashed perks over here are representing the case of vacuum and metal oscillation. So we can see here that all these real quantities are affected by metallic and it will be enhanced. The magnitude of this will be enhanced. And this significant enhancement can be seen in case of new bee because it is expected Because it is expected because NuP is the one that includes the meta-effect in nucleine oxidations. Now, here we have also given the complete picture of these complexities. How does it vary with respect to delta and as well as with respect to the energy? And here, this figure is corresponding to the T2K experimental setup where the baseline is of 295 kilometer. Is of 295 kilometer and energy is of 0.6 GeV around that. Now we see again that chi mu and ti tau they show the maximum variation with respect to this delta parameter. However, some variation is also there in case of chi. And again if we compare it with the total oscillation probability, so these quantities, the complexities are having more information about the system. And similar figures we also obtained. Figures we also obtained for NOVA experiment where now the baseline is a bit longer, 810 kilometers, and the energy range is of up to 6 GE. Basically, in the last figure, the T2K experiments, because of its lower baseline and lower energy range of neutrino, metal effect is quite negligible over here. However, it becomes more significant in case of NOAA. Of NOVA. Now, here we can see that both in case of experiments pi mu and chi tau they are showing their maximum value at over minus pi by 2 or plus pi by 2. And the features of these complexities for both of these two experiments are almost similar. So it means that the meta effect enhances the complexity embedded in the system, but it does not vary the characteristic of these complexities with respect to height. Respect to deliver. Also, one point is to notice over here that T2K NOVA experiments they use the mu mu initial beam. So the only relevant quantity, relevant complexity is chi mu that can be compared with the oscillation probabilities over here. And we have seen that for both T2K and NOVA, chi mu achieves its maximum value at minus pi by 2, which is also which is also consistent with the best fit. Is also consistent with the best fit value obtained in the T2K experiment. However, it is not consistent with the NOVA best fit value, which is basically in the upper half plane of delta, but it still lies in the maximum time u region. So, basically, it favors the maximum value of time u over this parameter. Now, if we compute, if we compare it with the oscillation probability P mu e, which is the only oscillation probability at C. Is the only oscillation probability accessible in the T2K and NOVA setups, then it becomes maximum at minus pi2 only. And this is compatible with the T2K experiment, but not with the NOVA. So if we compare the complexity with the oscillation probability, then complexity provides us more correct prediction about this data parameter. So in the final case, we also considered the effect of Case we also considered the effect of normal the Newton mass ordering. Over here in the first panel, we have considered the vacuum oscillation case and here it is the metal oscillation case is given and the solid and dashed curves over here are representing the normal and inverted mass function. So, basically the plus and minus sign of those delta 3 in parameters. And we can see that only in the presence of meta effect these two these two must These two mass hierarchy types can be distinguished. So, now finally, I'll conclude my slides. So, we have examined the spread complexity for both two and three flavor oscillation scenario. In case of two flavor oscillation, we have seen that the complexity comes out to be equal to the oscillation probability and hence it doesn't have much information about the system. However, in case of three-player oscillation, the probability is not. The probability is not equal to the oscillation probability only, and that's why it contains more information about neutrino oscillation cyrnum. And it can probe some of the important parameters present in this system. And we also found that the maximum of the chi-mu is obtained over the maximum value of CP violating phase, which is also consistent with the T2K experimental data. And so finally, And so, finally, I'll say over here that the quantum spread complexity is a potential tool to be studied for neutrino oscillation scenario because not only it reproduces the existing neutrino experimental data, but also it also gives us a theoretical tool to predict new outcomes in the neutrino oscillation set. Any questions? I guess that at the end of the day this is like a three-dimensional film space. I guess at the end of the day this is just a three-dimensional film space, you know, at this point of the video. And maybe uh you could study also like other notions of complexity that are difficult in other situations, but here I mean like simple complexity, maybe here it's simple to consider. It's simple to consider. Maybe you could compare to in this case. How do you thought about that? Sati-complex? That we have not studied yet, but that is our next part of the project. So we will be talking about that. So I don't know anything about complexity, but is it true that if I have a quantum system that's coupled to some environment, is it true that the more complicated the environment is, I would agree? complicated the environment is I would expect out towards more complex it should be but actually there are some literatures available on this so basically they treat the open problem open quantum systems for these kind of studies so yeah there is some uh issues related to that I'm asking that because um I'm wondering if for an application of your neutrino thing you know if in situations where neutrinos are moving through matter so Because we're moving through matter, so inside the sun, or maybe in near stellar space or something. I'm wondering if you'd be turning this into a prediction for what the matter-dependent effects might be, because there is effectively quite recent complex system that's holding why. Maybe you could make it in an explained explanation of why it be able to work better or not. So, you're basically asking why the meta-effectors are answering this question. Well I'm trying to think where the the because the thing is if you count the complexity I'm trying to think why should I think that it should be made maximized? The principle is that interactions with not many things make it be maximized then situations where the fingers are actually interacting with a lot of things might be the places where you're collecting maximum complexity a useful concept. I'm not very familiar with complexity, but is there any theorem about complexity that it should be axon or something? Like, I don't know what you think about any theorems about complexity. Or the games in the general, complexity should also. Like, for example, entropy. There is one scenario that I mean we had a another uh work where we studied uh cosmogeneous stellar probation models, right? Still a probation model is right, and then we basically uh studied all expanding accelerating backgrounds. That's all the considered at the highest result of complexity. Yeah, so there is a there is a I don't know I'm not aware of any therapy. So the complexity that you compute depends on the initial states you start from, right? So if you had chosen some other So if you had chosen some other linear combination with initial state, would these results still be valid or would they just shift by some unimportant factor or something? We already considered three references, right? Three different references. So if we consider a linear combination of the same thing. Yeah, what I'm trying to say is that, you know, complexity is always like it's it's a little bit like you know um It's a little bit like, you know, it's measured with reference to a reference state. So, what I'm saying is that, and you're trying to, but the choice of the reference straight can be arbitrary. It seems like, you know, why would nature choose them to be, I don't know, the flamework instincts? Or the, you know, nature could. So what I'm trying to say is that if I had chosen a difference. Chose a different state to start with, how robust these results would be. That's a continuity is not there, choice. That ambiguity is not there. At least in this computation, that ambiguity is not there. No, no, no. By construction, this is the crew of basis. So that ambiguity is not there. So what you are saying that you have to perform a function complex, then this will be reduced. Even then, I mean. You just have three line cost coefficients, three cross triangles. Even then, I mean, you have like, you know, you are starting with a fixed reference. No, no, no, no, no. But the point is that you start with t equal to zero, you start with one of the crylow bases. No, but I think he's asking if the crylow basis, the first state, is equal to change in the case. Yeah, but I'm saying the motivation is exactly. So you're starting with some particular colour, right? That's why you were studying it. What is the point? How much of the prediction is robust against this choice? Of course, for example, you could choose an energy eigenstate of these propagation states, and then it doesn't change in evolution, and the complexity will be zero. So typically these measures of complexity are thought for the situation in which you have some notion of initial states that are simple but they interact and and and and And the actual willsify the state. And you expect that it will be universal, that it wouldn't depend on the initial state, even some set of initial states that are not like that are simple, that are not some kind of am I correct, I think that complexity depends itself depends on the state also in Chinese, but in always increasing, for example, it doesn't ch whatever you change. It always increases? No, it's not very necessary in that sense because there's an expectation that it generically increases. The time scales involved are much longer than the entropy thermal. But, like, this is a conjecture given some system, but it's an initial state. Yeah, but it itself also depends on the reflexes that you choose. So I mean, but you can also just talk about the complexity of the inventory. In some sense it's simpler just to talk about the units. So like you need some robustness of this complexity. Complexity needs like an approximation. Okay, so let's uh go again. Hi, everyone.