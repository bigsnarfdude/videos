So, two things. One, I thought the screen would be a little bigger, so if there's anything that's too small to read, please don't hesitate to let me know. And two, I originally titled this talk Manifold Models for Dual Artin Groups because there's this big project that I've been working on. Everything today is joint work with John McCammond. And we've been speaking about this project in various forms for years now. And I was originally thinking I would focus on a particular aspect of this. Originally thinking I would focus on a particular aspect of that, but we just finished this paper that's titled Geometric Combinatorics of Polynomials 2, which is available on my website. It's not on the archive yet, but it's on my website as of Saturday or something like that, I think. So it's very new, and we're really excited about it. And so I made all these, well, we made all these nice pictures for the paper, and I thought it would be a shame if I wrote a talk where I didn't use them. Where I didn't use them. So it's going to be a little bit about dual art and groups, but the short version is that there's this thing called the dual presentation for the grade group and more generally for all artin groups. And what I'm going to describe is an intrinsic connection between that dual presentation and the space of polynomials with distinct roots. And this connection leads to actually a compactification of the space of polynomials and a cell structure. And a cell structure on that space, which ties directly to the dual presentation. So, to start, I'm going to say a little bit, just for those of you who aren't familiar with proxy groups and art groups, I'm going to say a little bit about that. But if you tune out during that section, there will be a place to come back when we're talking about complex ball melts. So, to start, Proxper groups and Arten groups, if you haven't seen them before, they're really beautiful classes. Them before they're really beautiful classes of groups. Both of these start with a finite generating set and a certain type of relation. All the relations are of the form, you know, essentially ABA equals BAB, but where they can, those words can be of some arbitrary length. But they have to be the same length. So ABAB equals BABA, that's fine. And all the generators square to the identity in the Coxeter case. In the Argon case, you just remove those, you know, the fact, the requirement that the generators be involutions, and you get. And you get the corresponding parting group. And I've made a little note over here that these mijs, they can be from 2 to any positive integer at least 2, or they can be infinity, in which that case that just means the two generators have no relation. So if you're not used to thinking about Cox-Greek groups and Ergon groups, you should think of W as being the symmetric group and AW as being the grade group. And virtually everything I say in this talk will be just good. This talk will be just good with that. And so, something interesting about this is that costing groups and art groups are defined by their presentations. So, they're handed to you like this, but it's natural to ask what other presentations are there, and can we get something useful from them? And so, an alternative presentation for Coxster groups emerged in the early 2000s. This is called the dual presentation. And this stems originally from the work of Berman Coe Lee in the late 90s and then Tom Brady. The late 90s, and then Tom Brady, Colin Watt, and David Basis in the early 2000s, did a combination of papers, started producing these presentations for the finite Coxeter groups that lead to presentations for their corresponding Argon groups. And I just want to give you a general sense of how you would construct this for an arbitrary Argon group, just to give you an idea of what this dual presentation thing means. So on the left-hand side, I'll show you what the generic definition. What the generic definition is, and on the right-hand side, what it looks like for the symmetric group. So, you begin with a standard generating set. That's the generating set I showed on the previous slide, where you have some finite list of generators. And in the case of the symmetric group, we think of these as the adjacent transpositions. Then, we're going to make a larger generating set out of that. And the first step is to take the set of all conjugates of your standard generators. Of your standard generators. So, T is going to be the set of all conjugates, and in the case of the symmetric group, that gives you all the transpositions. From there, you can now create, or first you take a special element called the Coxer element. This is just an element that you get from multiplying all the standard generators together in whatever order you want. In the standard case, we usually use the D cycle that's just take everything and twist by one. So one goes to two, two goes to two. So one goes to two, two goes to three, and so on. And then what you can do is create a postet called the interval poset, which this is where things get a little more complicated. You take the Cayley graph for your Coxster group generated by this larger generating set. You take the identity on one end, and you take delta, your Coxter element, on the other, and you look at all the geodesics between those two points. Those create for you a poset. A postet. And the way you should think about this is stuff that's in the postet is stuff that appears in factorizations of delta into elements of t. All the things that you can get in that way. And so in the case of the symmetric group, what you get is sometimes called the lattice of non-crossing permutations or non-crossing partitions. And I'm not going to, I'm not planning at least on going into the reason for why that is, but there's a nice common attraction. Is, but there's a nice like combinatorial picture for how you can present all the permutations that arise in this way. They come from diagrams where you arrange the numbers one through n in a circle and you take a partition of those in such a way that the blocks don't cross over each other. So now you have this post set, and we're almost to the point of being able to describe the dual presentation for W. And the way that works is that you now look at your postset. Is that you now look at your postet because it's in the Cayley graph, all the edges in the Cayley graph have labels, and they're going to be labeled by elements of t, but it might not be the case that every element of t shows up. Maybe some things do not. And so the last step is we take t0 to be the elements that do appear in that post set. Now, in the case of the symmetric group, they all show up, so there's no difference. So what this is telling us is that the dual presentation for the The dual presentation for the symmetric group is generated by all transpositions instead of just the simple ones. I'm going to jump to the next slide, and if you're worried about taking notes, I'm happy to send the slides to anyone, so don't worry about that. So the dual art group is sometimes written A W delta star, and it's generated by all the things in T0, and the relations come from that poset. Come from that post set. So you take all the loops in that post set that begin at the bottom and go back to the bottom. And this is basically just saying that any two ways of factoring in this post set, factoring something below delta, ought to represent the same word in the Hartman group. Or those words ought to represent the same element. Okay, so that was, if you haven't encountered dual presentations before, If you haven't encountered dual presentations before, that probably felt a little quick and perhaps a little strange, which leads to the next question, I think, which is, does this have anything to do with the group you started from? To me, this is extremely not obvious, and I think that I'm not alone in that. The fact that you started with an art group that's defined by a presentation, and then you completely demolished that presentation and did a bunch of other weird And did a bunch of other weird stuff. Now you have a different group. It seems like a tall order that this ought to be connected or even isomorphic to the original Artin group. In fact, there are some cases where it is known to be isomorphic, and there are no cases where it's known to not be isomorphic. So, what we know is that for spherical Artin groups, those are the ones where the Paxter group is finite. The Coxster group is finite. Originally, this was done by Brady and Watt and Besis in the early 2000s, but their proofs were case by case. And Chikuia Dufropoulos in 2015 gave a uniform proof of this fact. It's known for Euclidean artin groups. So those are the ones that correspond. They come from Coxer groups that act on Euclidean spaces. That's due to John McCammon and Rob Solway. And then another proof of this was in the recent work of Paulini and Salvetti. Paulini and Salvetti. And then it's also known for three generator ardent groups from Dilucy-Paulini and Salveti. We know of no counterexamples. And there's a subtlety here, which is that the presence of this delta, like maybe I chose a Coxter element from the beginning, it's not, it's not a priori, that could matter. But there are no cases known where it matters so far. Where it matters. So far, I should say, in all of these cases, the choice of delta didn't matter. But do you know, like, outside of those classes where from different deltas, you would get isomorphic groups, just not knowing whether it's looking at? That's a great question, and I should know the answer, but I forget. I would have to go back and look at my answer. Any other questions at the moment? Okay, so why do this? It's great that it's isomorphic, but why do this? The nice thing is that there are some really nice complexes associated to these dual parting groups. And they allow us to look at properties that are more difficult to prove using other complexes. So these are called interval complexes. In the case of the braid group, John and I often call this complex the dual braid complex. The dual-braid complex, but it goes by a few different names. So you can create a complex in the following way. You start with what I was calling the post set of non-crossing partitions or permutations or whatever. This is the interval from 1 to delta. We already described that. It's the interval post set that you get from this union of geodesics. From there, you can do this standard construction in combinatorics where you take what's called the order complex. You take Complex. You take the vertex set to be everything that's in your postet, and then you put an ordered simplex on all of the set of simplices that form a chain in the postet. And so that's going to give you a k simplex if you have a chain of k plus 1 elements. And in particular, you can put what's called the orthoscheme metric on this. The metric is really interesting, but I'm not going to focus on it today, so I didn't write it. But the orthoschemic. So I didn't write it. But the orthoscheme metric says I'm not just going to put in an arbitrary k-simplex. I'm going to put in a k-dimensional orthoscheme, which is where each of these edges would be of length one in between adjacent elements of the chain. And more broadly, if you have two elements that differ by height, like k, then the edge between them would be the length square root of k. So if you have three elements in a chain, then they would form a right triangle. Then they would form a right triangle rather than, say, like an equilateral triangle. So, this gives you something contractible, and if you blue up the sides appropriately, you get the interval complex. And basically, remembering that all of these elements came from a Cayley graph, when I create this complex, all of its edges have labels from the cockstroup. And so, what I could do is And so, what I could do is identify simplices if their labels are the same. And because these are ordered simplices, I know how to identify them. They come with an order. And so the way of putting this in the post-set language is that if you have two chains, then they represent identified simplices if the products in between, like the different quotients between adjacent elements in the chain are equal. So if you make So, if you make this identification, you get this interval complex k delta, and this was sort of the main thing presented in Brady's 2001 paper on the this, you know, it was called a new kπ1 for the break groups. This complex is a classifying space for the brake group. And in general, it is a space with. And in general, it is a space with a fundamental group, the dual argument group. It's not known whether it's universal cover is tractable all the time. But let me show you an example in the break group. So if I look at the symmetric group SIM3, my non-processing partitions will be this poset. Height in this postet is determined by how many transpositions it takes to express your element as a product. If I take the order. Product. If I take the order complex, then each of these maximal chains becomes a right triangle, and they're all glued along a common hypotenuse which corresponds to the chain that connects up the bottom and top ones. And finally, the interval complex, what you want to note is that things like this edge here would be labeled by the permutation 1, 2, and so would this edge, because that's what it takes to multiply. I guess I never said I'm thinking of this as the I guess I never said that I'm thinking of this as the right-feely graph. So you multiply 1, 2 on the right of 1, 3 to get 1, 2, 3. Okay, so those two hedges. Yeah, keep going. Remember you did presentation for the dual argument group and there were relations corresponding to cycles in the top pitch? Yeah. So uh today uh the cycles should act trivially on the side. Ah um I see uh so essentially what I'm uh what I was saying is that like if you think of this as being this, then you could write your presentation as being ABC such that you know AB equals B C equals C A. equals B C equals C A equals delta. And so in this context, maybe I don't understand the part about acting tributally. Okay, maybe if I just miss it. Okay, okay. I was wondering, just to confirm, what's the partial order in this postet? Is it just two elements or like when one is also equal to the other, there's a Judas from one that goes to both? Is that it? That's right. That's right. Yeah, there are other ways to define it, but that's. Yeah, there are other ways to define it, but that's the simplest way of thinking about progressions. So this is an example when you're looking at the three, so this complex ends up having the three-strand break group as its fundamental group. And it's a very nice complex to look at, although the combinatorics of this post-set can get very complicated. So there's plus a So, there's pluses and minuses. Let me tell you a little bit about what we like about this coset. So, one theorem that's very nice, and this is beyond the break group, is that if you know that this interval from 1 to delta is a lattice, which means that every pair of elements has a unique meat and a unique join, then the interval complex is a kπ1 for the dual Barton group. And so it's, unfortunately, And so it's unfortunately, and this is something I'm not going into in depth, that it's known that this is not always a lattice. So that was one of the main points of a paper John McCameron wrote in, I think, 2015. And then there was this follow-up with his student, Rob Solway, in 2017, which essentially said that there's a problem, but you can get around it. And this was one of the main ingredients in Paulini and Sylveti. Ingredients in Paulini and Salvetti's proof of the K-pi1 conjecture for Euclidean organ groups. But it's a very nice fact tying up combinatorial information about the lattice to this k pi1 property for the interval complex. And one thing that's conjectured, which I'm obligated to put here because it has to do with curvature, is that the Is that the integral complex is conjectured to be locally cat zero with the orthoscheme metric that I was describing before? So, this is proven when d is less than or equal to seven. So, I think it was four and five, three, four, and five done by Brady and McCammond in 2010, and then six was done by Tatil Kilak and Scher in 2016, and then seven was done by Jiang just a few years ago, I think. A few years ago, I think. Sorry to interrupt. No, no, no, no. I'm slightly confused because I thought you said earlier that the author scheme metric can give you triangles that are... Oh, they were just right-angle triangles. They're not spherical triangles. That's right, that's right. Yep, yep. Okay, I've uncomfortable. That's great. Thank you. Okay. So what would be, I mean, of course, so if you can prove this is cat0, or locally cat zero, then the ray group is cat zero. Or locally cat zero, then the ray group is cat zero, which is still an over problem. What makes this so difficult, though, is that this is a very complicated lattice. The number of, I mean, it's beautiful. There's a lot of really interesting features to it, but it has a lot of elements, has a lot of maximal chains. We're adding a lot of generators to this presentation. It makes it much harder to keep track of things. Okay, so there's this interesting complex associated to dual arden groups. Associated to dual arden groups, and if the dual arden group is isomorphic to the standard arden group, then you can use the complex to learn interesting things about that group, such as this. And maybe something to emphasize here is that there's not a lot, I mean, it's hard to prove things are cat zero, right, when they're not like acute complexes. And so there's a lot of for something like the break group, there's not a lot of promising directions for this. Promising directions for this. In particular, the things like the Salvetti complex are not viable. So let me say one more thing before we start moving into what John and I have done, which is just that in the case of the break group, this is of course a Kπ1 because the POSET is a lattice and the interval complex has been well studied. Complex has been well studied. But there's a lot of other K-pi1s for the break group. Namely, the configuration, the run over configuration space of D points in the plane is one of the best known complexes. But it's double the dimension. This is a 2D-dimensional space, and the interval complex I didn't really mention is d minus 1, which is the same as the Selveti complex, for example. For example, so it's a natural question to ask how the two relate to one another. You certainly know they're homotopy equivalent, but could you say something stronger than that? Since this one's half the dimension, ideally you'd like to stick it inside the other one and do some kind of deformation retraction. This was actually known to Basis in 2015 or something like that, I'm not sure. But we were looking for something a little more direct, and we were looking for something. Direct, and we were looking for something that would give us a structure on the whole space. So, what we would really love is if we could put a cell structure on this for which we could see the integral complex as an induced subcomplex. Like, could I put a cell structure on this whole space so that some sub-complex of it or some subspace of it is the interval complex? The interval complex. And that's tricky because this is not compact. Well, I mean, that's not a deal breaker, right? But like there are a few reasons why it's tricky. And what's really interesting is that it's not at all obvious how you should just embed this, you know, like where to even put the vertices. And it turns out that the main idea is that you ought to go through the correspondence with polynomials. So you should think of this. Correspondence with polynomials. So you should think of this space not as the unordered configuration space, but rather as the space of polynomials with distinct roots. And this was something that we got put on this path by Don Kramer in 2017 when he mentioned that one of the pictures that we showed earlier was, you know, looked a lot like a space he'd been looking at for the space of polynomials degree three with distinct roots. Three with distinct roots after you make some whittling away of the dimensions. So let me tell you a little bit about the connection with complex polynomials. First, a brief amount of terminology. So if p of w is 0, w is a root, and the roots of the derivative are the critical points of your polynomial, and their images are the critical values. And it's going to be important for us to. It's going to be important for us to abuse this terminology a lot. So, poly sub D upper mt of u is the space of monic degree d polynomials up to translation, I mean up to precomposition with a translation, with critical values in the region u. This mnemonic, hopefully that doesn't trouble anyone. Up-to-translation is our way of, it's sort of like if you were going to take the space of polynomials and try to. To take the space of polynomials and try to whittle it down to like deformation retracted onto something smaller. This is one of the first things that you would do is like make the roots all be centered around the origin or something, like do that kind of translation. And it turns out that's equivalent to saying that you're looking at polynomials up to precomposition with a translation. And composing with a translation doesn't change, pre-composing with a translation doesn't change the critical values. And so there's nothing. And so there's nothing, there's no funny business here. We're just kind of like trying to get rid of the obvious things to do to a space of polynomials. Are you just saying the second coefficient to different things? When you do them centered, yeah, that's right. So technically what we're describing are equivalence classes up to precomposition with a translation, and they all have a unique representative with a second coefficient. Okay, so now I can state some theorems. So let's let this, we like We like to use these little pictures to represent the spaces rather than introduce notation. So let's rectangle be a rectangle. Okay, so you pick your favorite rectangle in the complex plane. And I'm going to look at the space of polynomials where the critical values are constrained to live in that rectangle. So the first result is that this is a compactification of the space of polynomials where critical values can be anywhere. This is not. This is not terribly shocking if you think about doing the following thing. Take a homeomorphism from C to the open rectangle, and then take the metric completion. But you're using the metric on the rectangle, not the metric on C. So you're doing a little, not doing the quote-unquote obvious compactification, but you're taking this space of polynomials and thinking about them as. Polynomials and thinking about them as living inside having critical values in an open rectangle and then compactifying the rectangle. So that's the first thing. And the second thing is that we can put us, now that it's compactified, we can put a very nice cell structure on it. So there is a piecewise Euclidean cell complex on the space of polynomials with critical values in a closed rectangle, where every cell is a bisimplex. It's a product of two simplices. And this space is a subcomplex of the product of two copies of the order complex of the non-crossing partition postet, of this interval from 1 to delta. This is, in particular, it's a manifold with corners, but this is what makes that so surprising to us is that when d is 3, what we're saying is that What we're saying is that polysub three of the rectangle is sitting inside of two copies. I don't know why I'm drawing this picture now. I'm going to draw it again later. But now it feels better. It's sitting inside of two copies of that. Which is a bit odd. Because these things, I mean, in general, each one of these has. Each one of these has d to the d minus 2 top-dimensional simplices. It is very, very much not a manifold. So the fact that we are getting it as a subcomplex of the direct product of two of them is interesting. And the reason, just to explain the title of this talk, the reason why we're so excited about, or well, one of the, would be very excited about this if all we knew how to do was just the breakthrough, but we can tell you what subjects We can tell you what subcomplex it should be for any argument group. If you give me any artin group and look at the product of these two things, we can tell you what subcomplex of it should be the corresponding complex for that argument group. Okay, number three, if you give me a cross-section of that rectangle, like a horizontal cross-section or a vertical cross-section, then it's not gonna, like poly of that interval. Interval, this thing, is not going to be a subcomplex. It's not going to line up with the vertices. But it will be a subspace. And if you take the induced subcomplex on there, it's going to be crashing through cells. If you take the induced subcomplex, you will get the order complex. And so we get sitting inside of this big, you know, bisimplicial. You know, bisimplicial cell complex, we get the simplicial order complex as sort of a cross-section. Okay, so this is great. For the rectangle, but what I would really like to do is understand polynomials with distinct roots, which means it turns out that distinct roots corresponds to your critic, none of your roots overlap with the critical points. Because if you had a root in the derivative that was the same as the root in the original polynomial, then it must have been a double root. The original polynomial, and it must have been a double root. And that's the same as saying that zero can't be a critical value. So, really, what I want here instead of a square is like an annulus. I want to take the punctured plane and look at those blonde wheels. So, item number, hmm, that's blank. Here we go. Excuse me. Item number four. So, if you take the annulus instead of, you take your favorite annulus, anyway, Take your favorite annualist, anyway, it's going to be a compactification of the polynomials with critical values in C star. And what's more is that we can relate that to the previous self-complex by phase identifications. So if you were to take that your favorite rectangle in the plane where your critical values are allowed to live, and you were to continuously deform it until you identify the left and right, or top and bottom, doesn't matter. Identify those opposite sides. Identify those opposite sides, now you get an annulus, and that will induce identification, a quotient on poly sub D of the rectangle. And the quotient it induces is an identification by, or it's isometric face identifications. And so we know how to take that bisimplicial complex and glue it up to get something whose fundamental group is the break group. Fundamental group is the break group. And if you follow what happens to that inside cross-section, it glues up into poly sub D of a circle, which is isometric to the interval complex. There's something that I'm kind of swooping under the rug here, which is that I don't, it doesn't matter which line segment you pick. It doesn't even need to be straight. So basically, take any. So basically, take any arc in the plane, any path in the plane that doesn't intersect itself, take any loop, and the polynomials with critical values restricted to those things will be the order complex of this interval from 1 to delta and the interval complex, respectively, which is very popular. Last but not least, there is a deformation or traction from the From the space of polynomials with critical values in an annulus onto the circle. And the sort of way that you do this is like, I guess, quote unquote obvious, and that you, you know, this deformation attracts onto this, right? But the fact that that pulls back through the, you know, to that you can manipulate the critical values and that that induces a manipulation of polynomials is not immediately obvious. Polynomials, it's not immediately obvious. But, you know, I have seven minutes, I think, so I'm not going to talk about that. Okay. So are the two interval complexes here, like the vertical and the horizontal, are just the same? Yeah, that's right, that's right, exactly. Any other questions at the moment? Expand this on this example. Yes. Well, I'll try. So, yeah, let me give you an idea of what So, yeah, let me give you an idea of what the cell structure looks like. And it's going to start with a way of picturing the cells on the order complex. So, there's a lot of stuff going on here, and maybe for the sake of time, I'll encourage you not to read it. And instead say the way that you can label things in here, rather than thinking of these as chains where you specify points in the interval, really look at the gaps between the things in there. Because these are these gaps. Because these gaps are the things that product up to delta rather than something that sits below something that sits below something. You look at the gaps and they tell you how to multiply stuff together to get delta. And so you could label the vertices, say, rather than by labeling this vertex by the identity, label it by a factorization of delta into 1 times the identity, 1 times delta. And up here, rather than labeling this by 1, 3, Than labeling this by 1,3, label it by the factorization 1, 3 times 1, 2. And the real special features here are that the dimension of a face is determined by how many factors you have, and you get from a higher dimensional face to a lower dimensional face by merging adjacent entries. So if I want to get from here, or from here to one of But from here to one of these vertices, I can either merge this to get this vertex or merge these two to get this vertex. The other little thing is that we allow for the end points to be trivial, but not the stuff in between. So that gives you a labeling on this, which is on the order complex, and that induces a labeling on the interval complex by gluing them up. By gluing them up. Now, for this picture, like you were saying, there's a top and bottom direction, there's a vertical direction, there's a horizontal direction, but not every vertical factorization of delta and every horizontal factorization of delta is compatible. Not all of them, those pairs label a product of simplices in this complex. And the way that they are connected is by something called the Herbit. They're connected is by something called the Hurbitz action. So the Hurbitz action for the break group, and I should emphasize this is a different break group, right? Like the break group appears here no matter what art group you're talking about. The break group acts on products by rearranging the terms. And the basic idea is that if you, you know, here's a positive half twist, you know, one of the standard generators of the break group. Basically, when you bring a strand over, you move a term in the process. You move a term in the product, and the strain that goes under gets conjugated. And it gives you a new factorization of the same thing. I didn't change the product of this. I just rearranged some terms and did some conjugating to keep the product the same. You leave the endpoints alone, but you are allowed to do this on the D minus one things on the inside. And I say D minus one because we're really thinking about the maximal, like the top-dimensional cells in this complex. Dimensional cells in this complex. So those are going to be factorizations that are as long as possible. And those are always going to be like the identity. I should have just put the identity here. I'm not sure why I didn't. But it will be like the identity, D minus one transpositions, and then the identity. Those will label the top-dimensional cells in this complex. And essentially what's going to be the case is that two factorizations will label a top-dimensional cell in the big complex, but they are related by a certain type. But they are related by a certain type of herbit. So the cell structure here is that each face in this larger complex can be labeled by a pair of linear factorizations, which you should think of as one being vertical, one being horizontal, such that you can do merges and splits to get a pair of maximal factorizations, sigma prime and tau prime. And tau prime such that they are related by a Herbert's move via a positive simple grid. So, not just any grid, but that you can take a positive simple grid to get from the first one to the second one. That's not a symmetric relation because the break going the other way would not be positive. There is sort of a left-read thing going here. So, in the In the case I was describing over here, essentially what's going to happen is that this top-dimensional cell, 1, 2, 2, 3, there are two positive simple grades that you could apply to that to get another factorization. You could either leave it alone, or you could move 1, 2 past 2, 3. And naturally, I didn't label this cell that that would be, but it would be this front one here. This front one here. So basically, what that's telling you is that there are two bisimplices, like this times this is one of six bisimplices in like triangle cross triangle, which make up the top-dimensional cells of this. There are six of them in this complex when D is three. And this pair is one of them. This pair is This pair is another one. But this pair and the one back here is not because you can't get from the factorization labeling this one to the factorization labeling this back one via a positive vertical. I think I am virtually out of time, so I will just say very quickly that there are some really nice pictures associated to this of how you. To this, of how you get this information out of a polynomial. Because somehow, you know, this is going to relate to the space of polynomials. So if I'm given a polynomial, I'd like to know what cell it lives in. So I'm going to need to extract from a polynomial two factorizations of delta. And so here, I've shown a polynomial where its critical values are constrained to live in a rectangle. Here are the four critical values. And what I've drawn. Values. And what I've drawn is just the pre-image of that rectangle on the left-hand side. So everything else I'm ignoring. And you can ignore all these labels, but I've drawn a bunch of vertical lines here. Those pull back to be these red arcs in the pre-image. And this is kind of, you know, if we made a figure like this for every polynomial, it would be a little tough. You can make it a little more combinatorialized by drawing it. By drawing it on a hyperbolic n-gon, or I guess a 4 times d-gon. And from here, there's a very nice picture you can make by looking at what happens when you pull back, not just these arcs, but like the whole subsurface to the left of one of these arcs, or for a horizontal one, the stuff on top. It's going to pull back to give you a partition of the critical, well, you know, Well, it's going to pull back to give you some partitions, and they will look something like this. So, if I pull back this vertical arc, then this would create a non-crossing matching, is what it's called. It divides this polygon into two non-crossing partitions in a certain sense. And you could do that in both directions. So, if I took these vertical arcs, they would pull back to top. They would pull back to top-bottom, these vertical non-crossing matchings, and as I sweep from left to right, that would create like a chain of partitions. And the same thing is happening over here, where you pull back a horizontal arc and you get a matching. And what's cool about this is that if you take, I have one more slide, if you take two of them, right, you take a horizontal one and a vertical one and pull them back. Horizontal one and a vertical one, and pull them back. You get a pair of matchings where each arc in the matching, each pair of arcs intersects at most once. And these are called basketballs by work of Martin Savit and Singer from 2007. And like I was saying before, if you take your rectangle and drag it around to make an annulus and identify opposite sides. Make an annulus and identify opposite sides, then the effect on this picture, where we've got one matching, another matching overlaid to create this basketball, is that if you take these sides and glue them up like this, you get an annulus over here. And you get a picture where these circles represent, this you should imagine being a disk around zero. So its pre-images are the roots of our polynomial. And these are arcs going. And these are arcs going out to infinity, and these are the pre-images of a loop around zero. And you can do the same thing over here, and all together you get a picture that looks like that. Okay, so I will stop there. Thank you very much. Any questions? Can we go back just pretty step? I had one question, but it's not fair, but it's about the stuff that precedes your stuff, I think. But I you you you talked about the possibility about the possibility so you take this sort of lattice, this this this order complex in the lattice and you do lots of open faces. Then you blow up certain faces, and that gives you something that, if we're lucky, might be a model that might be a model for a break. And you were saying that we'd like that to give Canzumer a non-cosmic field base, maybe these fingers. Is it known that before you do the gluing, if you just have the low order complex of the latter's, is that known to have a does that have a nice zero metric and then and then the problem is the gluing, or is it the problem or is there already a problem to show that the metric on that? 