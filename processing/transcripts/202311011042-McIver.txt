So, gravitational waves in 30 seconds, here we go. So, they're very weakly interacting ripples in the fabric of space-time itself. And I'm going to give you just what you need to know to understand what I'm going to say later. But we can predict the amplitude of the wave based on the dynamics of the system. So the system is moving, it's doing stuff. Maybe it's rotating around itself, maybe it's two compact objects orbiting around each other. But this term allows us to predict exactly what the amplitude is going to be based on that motion. Is going to be based on that motion. This tells us that it's really, really small effect, and this tells us that if we have a good model for what that motion is, we can directly infer the distance from gravitational waves. And this is compounded, so because they're weakly interacting, GR, general relativity, is going to provide us with excellent signal models. So we don't worry about dust, we don't worry about galaxies, we don't worry about where it's coming from in the sky relative to the Earth. We have very good models, so if we can read out So, if we can read out what this amplitude is from how this wave is passing through the plane of our detector, so for example, if this wave is passing through the plane of my screen, it's going to stretch and squeeze space-time, which is why we build our interferometers as a great big giant perpendicular arc. So, we have a system, it does stuff, that next motion, we read the motion out here. This is sort of, I think, all we need to know. If you remember one thing about graphics, If you remember one thing about gravitational wave detectors from this talk, I think it should be that they are not directional like telescopes. They are like microphones. So if we want to see where something is coming from in the sky, we need more than one detector. So this comes from the relative time of arrival of the signal at each detector. So we have three of roughly comparable sensitivity: the two LIGO detectors in the US and Virgo and Europe. If you want to ask me why Virgo's not running right now, that's a conversation that maybe should be had over beverages. Over beverages. And then what does it look like? So let's say we have some signal, it passes through our detectors, and this is what our data looks like as a function of time. So it's a time series, essentially. And if we break that time series up in a frequency, we can see that the frequency sweeps up. And then, as Floor mentioned yesterday, so this is telling us that these two objects are getting closer and closer together until they smash together. This is what we expect also from general relativity. And now, how do we tell what something And now, how do we tell what something is once we have this data registered in our detector? So, here I've got some noisy data in blue. I'm going to compare my GR model to my data to infer what the system is. So, here I go. I'm evolving this model in mass. This is telling me about the phase evolution. I'm matching it to my data in phase. This tells me what it is. This tells me what that system is, which tells me what the amplitude should be at the source, and now I can scale it directly to the amplitude of my data. Directly to the amplitude of my data and get the distance. So, this is a direct distance estimate. And now, here's the global pipeline of how we get from the data. So, this is a data stream, a time series coming from each interferometer in our network. They are calibrated using a whole suite of thousands of auxiliary sensors. We intake also some information about the quality of the data and the environment of the detectors, and then there are two major phases. And then there are two major phases. So, one is identifying candidates. This is fully frequentist. We use match filtering to compare those models to our data, and then we measure inherently what's the likelihood that noise could produce an equivalent candidate. So, those go to a bank of candidates here, and then for candidates that are significant, we do Bayesian analysis to infer what their properties are. And then we do this on two different time scales. So, one is online, so this gives us near real-time answers, one is offline, so if you're willing to. One is offline, so if you're willing to wait 18 months, you'll get the full final analysis through the Gravitation Wave Open Science Center. Alright, so here's a challenge for you to build just a little bit of intuition. I've got an example spectrogram, three detectors that were online during a binary neutron star merger, two detectors that were online during a binary black hole merger, the colors, normalized amplitude, and then notice the very different time scales here. So let's just take a minute and think: which one of these do you think? Minute and think, which one of these do you think is going to produce a higher signal-to-noise ratio based on what you see here? And I'll give you a hint that this is going to be very non-intuitive. And maybe since I do expect to run out of time, I will tell you the answer. It is actually the one that looks quieter. This is a brighter source for us. And it's because when we're doing this match filtering, we're integrating over thousands and thousands of cycles that are in the data. That allows us to get a much better match with our model relative to a signal that's. Our model relative to a signal that's in the range of our detector for a very short amount of time. Okay, so now that you're all experts, here's how we actually do our Bayesian analysis. So this is an 18-parameter Bayesian fit. So these 18 parameters are describing the masses, the spins, where it is in the sky, how far away it is from us, what the orientation of the orbital plane is to us. And essentially, the framework is that we assume that our data is composed of the signal. Is composed of the signal as seen through the network of our gravitational wave detectors plus the noise. And we make a really key assumption here in how we construct our likelihood that if we subtract this signal model, a GitFit signal model from our data, we will get something consistent with Gaussian noise. And when we do this, we get these beautiful posteriors. We can infer mass, we can infer spin. So here are posteriors for, I'll just call this mass. Ask me more later if you'd like to know what a shirt mass is. And the spin in the system. Masses and the spin in the system relative to how it's orbiting. And here for a particular system are the individual spins that we can resolve. And now I want to show you where there be dragons in this approach. Two major places. So one is that this can be very expensive, especially for the systems that have those thousands and thousands of cycles, to compare those models to the data. So just to give you a frame of reference, to produce this Bayesian analysis for a binary neutron star signal with a high SNR, it could take signal with a high SNR could take about three months to run with a highly parallel analysis, whereas a binary black hole could take maybe a week if it's a very high-mass system. So we're including a lot more data, many more samples of data, and also a much longer model. So there's some really neat work going on here to reduce the order of the basis of the models. So I'll just flash this up if you want to learn more about it. The problem that I really want to highlight for your attention is that this assumption we know is wrong. We know it is wrong, and how we're calculating our likelihood. So, our data is not Gaussian, it's extremely ill-behaved, and this assumption has already caused some kerfuffles in the literature. So, here's an SOS for the statisticians in the room. Please help us with this problem. We agonize over trying to make this as true as we can by trying to model the glitches, the noise transients in our data, and subtract them out. But a better approach is badly needed. This can hold up the process for months. And what do I mean? Months. And what do I mean by non-Gaussian? So here's one day of data. You can see these gaps in the data. That means we can't make the light resonant inside the detectors. You see that it's really noisy. Each one of these dots is a burst of transient noise. And I'll zoom in on one of these. So this is actually light scattering. And you might notice that the frequency is increasing over time in parts of these sources. That is exactly where you'd expect a gravitational wave to sweep up. A sweet book, and I want you to also notice the time scale here. So, this is happening about once every other seconds when the weather gets bad. Two minutes. Oh my gosh. Okay, so we've got a whole bunch of stuff that can go bang inside the detector and look more or less like a gravitational wave. I'll just flash this up on the screen just so you can appreciate the scope of what's happening inside the detectors. Ask me more about any one of these. There's a story behind every one of them. So, we heard from Pauline. What would you like to know about gravitation? What would you like to know about gravitational waves? Is how to get at the results? So, there's two different sources: one for online, you'd go to GraceDB, which is where you'd find these sky maps that we've been discussing, this initial estimate of the sky map, what it most likely is. Does it have two black holes? Does it have two neutron stars? And the false alarm rate as well. And then after the data is released publicly, we will also publish our offline catalog with all of the updated calibration and data quality information included. And here you can actually And here you can actually grab the posteriors for all of those 18 parameters. I do want to say though that this is a no that did a dragon and she's watching you. There are assumptions that are going into the formation of those posteriors that are documented. I hope to a good extent, if you have any questions, please ask me. All right, so where are we now? So each one of these blue dots is the estimated mass of a black hole with gravitational waves. Gravitational waves are coming to dominate what we know about unique. What we know about undead stars, especially black holes. So we've got 90 total candidates, multiply that by 3 for the number of black hole masses we've measured. And here's where we are right now with the current observing run that started, and May with the two LIGO detectors. So we're building this rate up really fast, as Flo was saying. All right, so 90 seconds to talk about machine learning. So one minute, okay, 60 seconds. It may not surprise you to learn that we do not have a global machine learning model to Have a global machine learning model to take in LIGO and Virgo data and spit out these catalogs. But I do want to highlight that where we can give machine learning very particular tasks that are well-defined, where we have good data sets, it does do very well. So I'm just going to flash this up. Please read more about it. I've color-coded it for your convenience. I just want to mention these couple of tasks that my group is working on. So here is, for example, a signal versus glitch classifier called GSpinetry. Here we've got feature sets. Here we've got feature sets, so these are human-friendly, so four different durations that capture the behavior. I will flash forward and just say it does very well. It can tell you if there's a gravitation wave, if there's a glitch. This is also a gravitational wave, by the way, so it's starting to do better than experts like myself. And here are some other projects. They're really interesting. We've got explainability. We've got for Pauline this place where you can read more about our results. We've got a very quick advertisement. If you're a stronger, Got a very quick advertisement if you're an astronomer that we can now tell you ahead of time if a binary neutron star that is nearby is going to merge. That is operational. We can do that right now. Some more projects. There's a lot of stuff here. There's a lot of really interesting statistics problems and a lot of different ways to get involved. I would really love to chat with you. Also, we're having a meeting in June at UBC to discuss some of these topics. So thank you very much. One quick question, and the rest of the questions can be asked on Slack or during lunch if people agree. What kind of assumptions beyond the Gaussian were you looking for? What kind of assumptions are we looking for or are we making? Are you looking for?