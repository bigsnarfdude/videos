Right, so our next speaker is uh Anna Kevria. And she's going to talk about spatial temporal modeling extremely detailed analysis of the sketch. Thank you. Well, our aim in this work was to provide an approach to analyse heat waves, which nowadays is a quite common problem, especially here in Spain. Especially here in Spain. Of course, we were interested in analyzing the evolution of heat waves over time, but also we were aware that it is a spatial phenomenon. So we need space-time models. I'm going to start by motivating a bit more the problem, and I will present the temperature data we are going to use, and then I will describe the space-time model that we. Time model that we use, how to fit it, how to validate it, and the type of inference we can make. In particular, we were interested in analyzing the extent of string heat events. So, there is clear evidence of global warming in many climate signals. Here, we are going to focus on temperature to analyze. On temperature to analyze heat waves because they have important consequences in human health, in environment, agriculture. The first problem that we found was that there is not a specific definition of heat wave that can be widely applied. So, to avoid that, here we are going to work with the idea of extreme heat event, that is, a runoff. Heat event. That is, a run of consecutive daily temperature observations exceeding an extreme threshold. Of course, the perception of heat is not the same here in Granada that in the north of Norway. So it's important to use a local threshold in that definition. A quite standard definition in climate is the 95 percentile of the local temperature during the summer period, during the summer months. Period during the summer months in a reference period. And that is the definition we are going to use. In many studies of string heat events, in particular in most of the previous work that we did, they are based on individual models for one location. But of course, we know that spatial modeling is more interesting because we are Is more interesting because we are going to be able to predict the extreme events at and observe locations, also the extent of area affected by the heat wave, and also because a joint model for different locations that incorporates spatial dependence will borrow strength from other locations. And that, when we work with streams which are rare by definition, it's important so. So, to sum up, the space-time model is going to provide a better tool to evaluate all the possible effects of global warming on extreme heat events. So, our objective was to provide an approach to model extreme heat events during a period of time over a region using a spatially referenced collection of daily. Preference collection of daily maximum temperature series. And we want that the model is capable of predicting both or not only the incidence of the stream events, but also different characteristics, for example, duration. So what are the challenges of this model? It has to incorporate spatial dependence to capture non-stationary behavior, both because of global warming. Both because of global warming and also seasonal effects. And also, we have to consider the strong serial correlation of daily temperature. Also, it is important to take into account that if we model the entire distribution of temperature, that model will be driven by the bulk of the distribution, and in general, it will provide poor fits for the tails. Feeds for the tails, but in fact, that is our main interest. So I'm going to describe briefly the data. The area studies region around Comunidad Autónoma de Aragón here in Spain, in the northeast. This is the area. And these are the eighteen locations where we have the daily maximum temperature. The daily maximum temperature. As you can see, the area shows a high variation in climate and orography. For example, here in the north, we have the Pyrenees, which is a mountain area where there are some points with an elevation higher than 3,000 meters. Then we have this, this is the Deborah River and Deborah Valley, which is very flat with an elevation between two With an elevation between 2 and 400 meters. And here we have some mountains, but not as high as in the Pyramids. We are going to fit the model using the records from 1963 to 2015. We had the previous decay, but we use that to obtain the local specific thresholds that we are going to need to apply the model. Model. This is the map of the thresholds that we obtain. And as you can see, while in the Penis we have some areas where the percentile is around 22 degrees, Celsius degrees, in the Ebro Valley we have areas with 36 or even more. So let's see the model. I remember that our aim was to develop a Our aim was to develop a space-time model that is able to capture different characteristics of the extreme heat events. In particular, the incidence, the duration, the average and the maximum exceed and so on above the threshold. And in order to do that, we propose a two-state model where the response is the daily temperature at time t and location s, and the states are defined. And the states are defined by a binary variable, U, that defines whether the temperature is above an extreme threshold, Q, or below. Note that at the monitor sites, those state variables are observed. It was important that the model is capable of capturing the percentage of the model. Of capturing the persistence of extreme heat. That is that the probability of an extreme event one day is higher if the previous day is also stream. So to capture this persistence, we need to introduce in the model the information about the previous day temperature. So we are going to use an octoregressive structure. A structure. More precisely, we are going to define a joint distribution for the temperature and the state with a first-order Markov property. So given the information of the previous day, the joint distribution is the product of the conditional distribution of the state given the previous day temperature multiplied by the conditional distribution of the temperature given the The temperature given the state of that day and the previous day temperature. Or perhaps more clearly, what we have is that given the distribution of temperature in one day, we obtain the state of the following day, and then using that state and the previous day temperature, we characterize the distribution of the temperature on day T. And to start this process, we only need the temperature. We only need the temperature at an initial point. So, this model is going to require three sub-model specifications. We need the conditional distribution of temperature given the previous day temperature for the days above threshold, the conditional distribution of temperature given the previous day temperature for days below threshold, and also the probability. And also the probability of crossing the threshold. In the first two models, of course, we are going to need truncated distributions because in the first one, the temperature is going to be higher or equal than the threshold. In the second one, it's going to be lower than the threshold. And for modeling the state, we consider a probit model. We are going to see the details. We are going to see the details of each one. We start with the conditional temperature. For the temperature below threshold, we consider a truncated normal distribution with this structure. This is the mean and this is the variance. However, for the upper tail behavior, we need to incorporate upper stemmed dependence between locations and multivariate normal is tail independent. Is tail independent. So here we consider a truncated T distribution so that the tail dependent, because the tail dependence in multivariate T is not smooth. But as you can see, the structure is quite similar. Note also that we are considering different variances in both models because the range of temperature above and below the threshold is quite different. Threshold is quite different. Also, we are considering variances which are spatially varying because we found that in an exploratory analysis. And for the mean, we consider an autoregressive structure where the autoregressive term is centered in this way. So we only need to specify now these new terms. The specification The specification in both models has the same structure, but of course with different coefficients in each one. So we are considering a global intercept, but also a local spatial intercept to provide a better local adjustment, which is a Gaussian process. As geographical information, we consider the elevation and the latitude, and for the time trends, Time trends, we capture the anal seasonality with anharmonic, and for the long-term trend, we consider random effects which provide annual intersects. This is the probit model for the exceedance probability. So, this probability is going to be the normal. To be the normal distribution function of this linear predictor, which has this structure. Perhaps the most relevant feature is that we are considering that dependence on previous day is expressed in terms of the deviation of temperature from the local threshold, and that we are assuming that these coefficients are not spatially. Variant because we assume, and I think that it is reasonable, that the effect of the exceedances over the local threshold is going to be spatially homogeneous. However, we consider also here a spatially varying intercept to provide a more flexible intercept than just the local threshold. And also, we have And also, we allow the dependence of the previous day temperature to be different for days below and above the threshold. So, with all the terms in these models, we try to capture all the critical features that drive the daily maximum temperatures. But of course, we tried, we explored other specifications. Other specifications. We tried more geographical covariates, for example, the distance to the sea, other types of trend, but we didn't find a better model in terms of performance. So putting the three sub-models together, what we have is a mixture distribution for daily temperature, that is, a truncated normal distribution for the bulk of the distribution, a truncated T for the upper tail. For the upper tail and mixed chair weights according to the probability of being above or below the threshold. The model is fitted in a Bayesian framework quite standard. We use, when possible, diffuse and conjugate prior distributions for the autoregressive terms, non-informative, independent, uniforms, for all the fixed effects in the three models, diffuse. Three models diffuse normal distribution for the time random effects normal 0, 1. And we have five spatial terms, which are the intercepts of the three submodels and the logarithm of the variances of the conditional temperature. We model them as Gaussian processes with an exponential covariance function and we figure And we fix the range parameter. In fact, I'm not going to give the technical details of the MCMC fitting because Erin did all this hard work, but I'm just to say only that C uses a metropolis within GIF sampling algorithm for to obtain the joint posterior distribution, and in particular, an elliptic. And in particular, an elliptical slice sampler to obtain the posterior draws of the spatial effects. So, of course, we needed to evaluate the model. So, we implement an out-of-sample prediction of the characteristics of the extreme heat events we are interested in. In particular, we compare the posterior predictive distribution of the. Posterior predictive distribution of those characteristics, ratio, intensity, persistence, with the empirical counterparts. We implement a leaf one-out comparison with different locations. Here I'm going to solve the results for three locations with different climate characteristics. For the basic check, we use the entire time window, but we also compare two decades. Two decades, one at the beginning of the period and the last one, because we wanted to check that the time evolution was well captured by them all. So here we have the results for the duration. We compare the posterior mean and the credible interval of the proportion of extreme heat events with a given duration. This is for one day, two days. One day, two days, with the empirical counterparts, which are in black, the black crosses. These are the plots for the three locations in the entire time period. And as you can see, all the predictive intervals capture the observed proportion. We obtain the equivalent results for when we implement the analysis for each. Analysis for each decay. This is for the average and maximum exceedance in an event. So here we compare the posterior mean and the credible interval of the cumulative distribution at given values, two degrees, four degrees, of the average or the maximum exceedance. These are the plots for the maximum exceedance. Exceedance. And again, as you can see, the predictive intervals capture the observed proportion. And similar plots are obtained for other locations and also for the decades and for the average exceedance. But also, we need to check another important threat chart that is the exceedance probability and the persistence of the events. The events. Since the state is a binary variable, we use the following error rates. Also, we are going to consider that the most relevant case is the occurrence of exceedancies. So, we are going to compute the errors only for the observations which are above the threshold. We consider a type of global error. Global error defined by one minus the probability of being above the threshold given the previous state error. But for being more specific, we also compute the conditional errors given the state, because in that way, we can evaluate, for example, the prediction of the first day of an extreme event. We can do that with this measure, one minus the probability of being above the threshold. Of being above the threshold given that the previous day was below. And we can also evaluate the prediction of persistence using 1 minus the probability of being above the threshold given that the previous day was also. The rates are estimated by the average of daily estimates only for the observations above the threshold or by time window. AO by time window. Here we use the summer period, which is where heat waves are have the consequences of heat waves are worse. And well, it's noteworthy that these errors provide comparative measures between models, but they are not really goodness of fit measures because we are considering only a few of the observations in the time series, those which are. In the time series, those which are above the threshold, which is quite high. But in particular, we wanted to use these measures to evaluate the need of a two-state model. So we compare our two-state model with a model that ignores the state relative to the threshold. That is an autoregressive model for daily temperatures using again T errors with the same terms, but now Terms, but now only one single state. These are the results for two locations, for the first and the last decade. And as you can see, the performance of the two-state model is always better. The errors, both the global errors and the conditional errors, are lower, and the reduction varies from 70 to 70 to almost 50 percent. But also, we realize that, for example, the lowest improvement is obtained in the prediction of the first day of an extreme event. The results are almost similar. Well, the most relevant inference using the model is going to be the analysis of the Model is going to be the analysis of the stent, but just as an example, I'm going to show two examples. This is the posterior mean and the credible interval for some coefficients of the temperature sub-models. As you can see, there is a strong serial correlation with a coefficient around zero point seven in both models. As expected, the elevation has a negative coefficient. Has a negative coefficient in both models. However, the effect of the latitude is only evident in the below threshold model, not in the atmosphere. If you remember, we have used time random effects to model the long-term trend over time. So these are the box plots of the posterior distribution of those annual random effects. This is for the below threshold. The below threshold model, where we can see that there is an increasing time trend, and this is for the above threshold. And here, since the thresholds are local, we don't observe that trend. So, let's see now the main inference. Our final aim was to analyze the extent of string heat events. So, of course, seriousness of Seriousness of a heat wave depends on the duration and the intensity, but also on the percentage of area under extreme conditions. In the statistical literature, there are several definitions related to this concept, exceedance regions, exposure sets. So, following this idea, we consider the spatial extent of an extreme heat event as a stochastic. Heat event as a stochastic object. Of course, we cannot observe in close form the extent of area and extreme heat in a region. However, as we are going to see, we are going to be able to characterize moment properties of that extent using Monte Carlo integration. And also, we need realizations of temperature that can be obtained, for example, from Obtain, for example, from a space-time model like the one we have seen. So, more formally, the spatial extent of the extreme event in a region is the proportion of the region experiencing extreme heat at least W degrees above the local threshold. In fact, later we are going to see that we are going to work in the examples with W. In the examples with w equal to zero, but the definition is more general. So we have this integral. Then, given a selected or given set of locations and the corresponding thresholds and the posterior realizations of daily temperature, we can obtain an approximate realization of the strength using Monte Carlo integration in this way. And if we have a collection of temperatures. A collection of temperature realizations, we can obtain a sample collection of posterior values of the stent, and we can make inference using that posterior distribution. Here we are going to use a set of 500 realizations of temperature obtained from the previous model in a regular read at fairly fine resolution. I will describe that later. describe that later. Of course we need the models but we obtain them in a quite standard with a standard approach using elevation and standard trigging methods. In many cases, especially in global warming studies, the main interest is not to characterize the stent in a day, but the behavior of the stent across years or Extent across years or within the year. So we need the distribution of the average of the daily extent over a time period. In general, L days over T years. So the average, as you can see, we are going to use two time indexes, day and time. Depending on the fetch that we want to study, we will average on different periods, some amounts for a year or a decade. Are already categorized. Also, as I have said before, another relevant feature in the analysis of stream events is persistence. And to analyze this feature spatially, we consider the proportion of the region above the threshold for two consecutive days, defined now with this interact. Of course, it can be generalized two more days. More days. So let's see some results. We wanted to compare the evolution of the stent in two regions, in the Pyrenees, which is a mountain area, as I said. So here we use a one by one kilometer grid, and the Ebro Valley, which is a flat region, and here we use a two by two grid. Also, we want to analyze or to quantify. Analyze or to quantify the evolution of a time. So we are going to compare the behavior in different decades. Here we have the posterior mean of the average of the stent during the summer months in one year. In red for the Pyrenees and in black for the Ebro Valley. As you can see, the evolution in both regions is quite similar. The increasing The increasing trend is quite similar, but there is a difference in the mean. This is the same, but for the extent of persistent events of two days. Again, the conclusions were similar. The trend is slightly weaker, and of course, the magnitude also is weak. These are the posterior density of the magnetic magnet The posterior density of the average of the extent during summer months in two decades: in the first decade in black and the last decade, 50 years later, in red. As you can see, there is a clear shift in the central location, only also slightly higher variability. And the advantage of the analysis of using The analysis of using the scent in this way is that we can make inference for almost any feature that we want. For example, we can compute the posterior probability that the average stent in the last decade is higher than the average decade in the first one. In this case, for example, we obtain 0.8 in both cases. And there are many more inferences. There are many more inferences that we can do. But just to conclude, so we have presented a two-state spatial autoregressive model for extreme heat events that uses a truncated normal distribution for temperatures below the threshold and truncated T for exceedances and a probit model for the transitions. It is fitted using daily temperature in Aragon over 60 G. In Narragon over 60 years. And the model has captured the characteristics of extreme heat events we were interested in, that was incidence, duration, maximum, and average exceedance, and persistence. So, and then as a sub-product of the model, the extent of extreme heat events is defined using a Monte Carlo integration. Using the Monte Carlo integration. So we can obtain daily or seasonal averages of the extents, and using that, we can quantify and make inference about the effects of global warming over time and also to compare the effects in different regions. So, these are the papers where the work is described. And that's it. 