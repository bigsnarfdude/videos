Or resolution proofs, whatever you prefer. Let's start at the very beginning. So the classic DPLL algorithm from the 60s, the algorithm of SAT, and the idea is that we have some partial assignment to a formula, and then we take a formula, restrict it with that assignment, and then if we have a contradiction, we backtrack. If there's some unit clause, then that forces Clause, then that forces a value, so we extend our assignment with that value. And otherwise, we go and figure out one new variable to add to our assignment. How we do that, well, that's undefined for now. Then, a few years back, we had the CTCL algorithm, which is based on DPL. CDCL stands for Conflict-Driven Closed Learning. Close learning. And the key of this algorithm is learning. In that, whenever you find a conflict, then instead of just backtracking, what you do is learn a clause. So you look at how that conflict happened, you do some resolution steps, not explicitly, but that's what you're really doing, and then you add a new clause to your formula. And since now our state has both an assignment and this learned clause. And these learned clauses, well, then there are a couple more things that you can do so you can forget some of the clauses that you learned. And it also makes sense sometimes to forget parts of your assignment and start the search over again. But really, this doesn't matter. The key part is the learning thing. And now we want to analyze this algorithm. So, say what can we say about this? Does it solve? Does it solve that in polynomial time? Well, probably not. So let's use proof complexity to analyze this, right? Turns out that CDCL, the resolution polynomially simulates CDCL. What does this really mean uh for a proof system to simulate an algorithm? Well it means that if you take CDCL and look at um at the the execution trace, look at uh the steps that it's doing. Look at the steps that it's doing. You can think of that as a proof. And then you can see that what the clauses that CDCL is learning is something that you can do with resolution. This is something that Paul and others did. And of course they asked the opposite question, does CTCL simulate resolution? They could show that for For somewhat weird model, but still it was something. And there were a series of works in that direction until in 29 we got the converse result that well CDCL does polynomial simulate resolution but now we we might you might be very confused. Now you might be very confused because on Wednesday Albert told us that resolution is hard to automate. So what's going on? So what happens is that this simulation happens only when you are doing non-deterministic decisions. So if you remember that part of the algorithm where you had to pick a new variable, well, for this to work, we need to do a new variable. Well, for this to work, we need to make non-deterministic decisions. Otherwise, it doesn't work. Since we are talking about this, it's also worth mentioning that if you do random decisions, then Alberta and others show that then you simulate bandwidth width resolution with that algorithm. So even if you're not explicitly searching for small width proofs, there was nothing in that algorithm. Proofs. I mean, there was nothing in that algorithm suggesting that. But it turns out that it does that. So when you say decisions, I mean, there's multiple decisions, right? There's which variable to branch on, there's forgetting, there's restarting, so there's three. There's plenty of things. But really the only thing where you need non-determinism is in the variable selection procedure. But the other things, yeah, there are some standard techniques and this in And these seem to work, but the place where you really need to be non-deterministic is here in variable decisions. So, in the Zalius Vector Thurley paper, it's only the variable selection that's random, and everything else is deterministic. That's right. By bounded width, you mean constant or? So, the running time if you have a proof on in width w, then you the the algorithm will run in time into the w requirement. So we have automated. It's a way of automating. You could do that with brute force. So, but I mean the fun thing is that this algorithm that doesn't seem to do brute force turns out to be doing this. Anyway, uh this was what happens when you have the non-deterministic or random decisions, what happens when you have deterministic uh variable decisions. Variable decisions. But then it turns out that there is a separation. So there are the result I'm going to be talking about is that if you choose one class of deterministic heuristics that are the heuristics that are being used nowadays, then you can build a formula that has polynomial length resolution proofs but still requires exponential time to decide when you're using. To decide when you're using CPCL with deterministic origins. So, again, this is a much more limited version of the non-automatability result because it only applies to these class of heuristics. But on the other hand, it doesn't depend on any assumptions, so it's unconditional. No need for P different column and P here. What's the assumption on the other? What's the assumption on the other the s on the other heuristics? Like the deleting and anything goes. How long would go with anything? So yeah, as long as you're not doing anything too weird. For the one that restarts after every conflict, for example. Yeah, so let's discuss what do I mean with common decision heuristics. What are these things? Alright, so what we want to do is to fix a value of a variable and then if you ask practitioners what is a good variable to pick, they will say that, ah, it's a variable that will quickly give us a conflict, so that we will learn more clos clauses. Um is that a good thing? Is it not? Well, they're software and fast, so I'm going to Their software runs fast, so I'm going to believe them. But of course, they cannot predict the future yet, and they don't know what variable is going to lead to a conflict. What they do instead is to look at which literals gave us conflict recently. And they assume that, well, if this variable was very useful in producing conflicts, chances are that it's also going to give us conflicts in the future. So that's what they do. And one Do. And one example of a way to pick literals in this way is to use the visit heuristic. What you do here is that you give a score to each variable. Initially the scores are all zero. And then at every time that you are in a conflict, you look at the variables that were involved in that conflict. So they they were responsible for that conflict occurring. That conflict occurring. Those variables you increase the score by one, and then remaining variables you multiply the score by some constant close to one, so that the scores of variables that have not been in conflicts in a long time, they keep decreasing. This means that the variables that have been involved in many conflicts recently are going to have larger scores, so we're going to pick them. So, we're going to pick that. We're going to pick the variable with the largest score as the next decision variable. What about the sign of the literal? Or we just set the sign to be the same as the last time that that variable was assigned. Right. Is the definition of visit somewhat clear? Then let's think a bit about Think a bit about or analyze visits. What can we say about visits? Notice that if you have a variable that has been involved in a conflict at any point in time, that's always going to be picked before a variable that has never been involved in a conflict. Because the scores are of course they're decreasing and decreasing quite fast, but they're always positive. And this turns out to be the key to prove that result. The key to prove that result. We just need this property. Note, by the way, that in practice this property is not quite true because when you implement your scores, you don't use infinite precision, you use double to set fixed precision. So if your score is so, so small that's very close to zero, you will think of it as zero. Um and then what happens depends exactly on how you're implementing On how you're implementing this, how do you sort these variables? And then, if you're using a priority queue that respects the order, then this does hold. If you are not doing that, well, this doesn't hold. It gets messy. In practice, it seems that people don't care about whether they're using a stable key or not. It seems that it doesn't matter for them. But for now, But for now, for the result I'm going to assume that either you have a stable priority or you can imprecision. You check, so they don't implement stable, but I'm trying to see if solvers actually click the. So the mini-site implementation is not stable, the legal implementation is stable. Right. So now that we know this property, we can Now that we know this property, we can state our theorem a bit more properly and just say that, yeah, the decision heuristic rewards conflicts if it has that property that variable in a conflict is always speaking before a variable that has not. And then our theorem just says that if your hear is the rewards conflicts, then we have a separation. Okay, well let's give an Um give an idea of uh how to prove this, or at least how to build the formula. This is going to take us some failed attempts, a lot of pictures. The idea is that we would like to have a formula that has an easy part and a hard part. And of course we would like the so the easy part has a short resolution proof, and the hard part is where we want the solver to go. The good thing is that since we are reviewing Since we are rewarding conflicts, and if you find the conflict in the hard part, then chances are that the next conflicts are also going to be there. So these are variables that are in conflicts, so stronger color is a stronger score. That's what this means. The problem though is that hard formulas are very global. So if you have an assignment to If you have an assignment to, it's not too hard to satisfy a small part of the formula. So, after we have a few conflicts over here, chances are that we are going to end up finding a satisfying assignment, locally satisfying assignment. And then maybe the solver will now go and start looking at the easy formula. That's something we cannot control. And then as soon as it starts looking at the easy formula, well, it might as well solve it and work out Solve it and we're completely lost. Okay, so this doesn't work. Let's do a second attempt. Let's add some gadget so that if you start talking about the gadget like this, so we are now deciding some variables over here. Well, then we build the gadget in a particular way so that now you start talking about all these variables over here, which are the variables in the hard part. This you can do by forcing you This you can do by forcing unit propagations. A solver is very greedy, and if there are unit clauses, you need to follow this. And then, once it has talked about all of these variables, then we make it preach a conflict. And that conflict happens to involve all of these hard variables. So now the score of all these hard variables pass. And that's great because now the solver is stuck working with hard variables. So once all of these variables have been decided, and Variables have been decided, and these variables have not, then the solver is always going to be here. And all the conflict will happen here. We're happy, except that there's still a polynomial probability that the solver will choose the easy part first. There's no reason why it should start talking about these variables. Do we also have to fix that? Okay, well, let's fix it by. Okay, well let's fix it by adding some more another gadget, some more clauses, so that as soon as the solver talks about too many variables over here, so we are scared that it might reach a conflict over here, then it will immediately move here and then there will be conflict and we will talk about just these variables. Uh yeah, that's pretty much the idea of the formula, uh how the construction works. So we have this uh easy part, we have a hard part, which is uh essentially a setting formula. Um let's name this gadget to somebody, why not? Um it's not quite the the exact description, so it turns out that to make things work we need multiple copies of each gadget. We need multiple copies of each gadget. It gets messy, but I really don't want to go there. The thing I want to just mention is that the notation for the easy part, I'm going to call it gamma, the hard part, which I'm going to call TS4. And so now that we have an idea of what the formula is, let's give us a proof sketch. How would you prove? Prove a lower bound for this. The upper bound, you just look at the formula proof of resolution upper bound. That's not too hard. Let's try to prove the upper bound, the lower bound. So what we want to do is we'll say that we have a proof that never talks about the easy part, never talks about gamma variables. Then let's hit that proof with a restriction, not a random restriction, but a fake restriction. Restriction, but a fake restriction that leaves the hard variables alone and it satisfies all the auxiliary gadgets, those blue parts of the formula. So notice that if we had the proof of the whole formula, that might not be possible because the proof might be talking about the easy part, the green gamma part. And that is unsatisfiable. So there would not be such a restriction. But since But since we are not talking about the green part, then there is a general situation. And now, the way that we build the formula is such that once you hit the formula with this kind of restriction, what you get is a normal setting formula. And of course, for that, we have exponential lower bounds, which means that the original proof must have been exponential, and therefore the solver must have taken exponential time. The solver must have taken exponential time to produce this proof. That's a high-level plan. Now, of course, the hard part is to show that the proof does not use gamma process. And for that, well, we need to go deep into the details of the formula, of the solver, and analyze what's going on. What we want to do is to look at what the solver is doing and say that if the solver is in some state where not many easy variables have been assigned, the way we build the easy clauses are that they, if you want to falsify them, you need to at least set Falsify them, you need to at least set a few of the white variables. So, as long as you don't have two white variables set, you're never going to falsify one of the easy clauses. If you don't falsify an easy clause, then it cannot be involved in any conflict. So, we are happy. And then, what we have to do is the software starts in a state where there's no conflict, there are no assigned variables. There's no conflict, there are no assigned variables. And it's going to keep assigning variables for a while until at some point it might assign a pair of y variables, and it's going to move to state B. And then we had that gadget that said that if you talk about two y variables, you start propagating and talk about all the hard variables, and we reach state C, which is when you have a conflict that involves all of the. conflict that involved all of the X-rays. And now we have to do some extra work to show that you will never leave state C until the solar finishes. But that's all I want to say about the proof. So it's uh here. So the main result was uh that uh C D cell with visits does not simulate resolution. Of course there are plenty of open problems, so There are plenty of open problems. So, for instance, what happens when you have random decisions? The CDCL with visits simulates random decisions. Do random decisions simulate resolution? I mentioned that the lower bound was not very robust in the sense that, as if you have fixed precision, then this doesn't work. So, could we? So, could we prove a lower one that also works when you have fixed precision for your scores? Would we maybe use a simpler construction of that formula? Or would you find the more abstract proof using proof complexity techniques instead of having to go and look at what the solver is doing so closely? Is there a more general way to prove this? So, thanks. So thanks. Thank you very much. Maybe it is obvious from what you said, but let me ask anyway. So if you consider a model where you have semi-random decisions, meaning that you do the scoring, but in the end you flip according to the second value, would you get anything? I think that you could also prove a separation in that case. Going to be a bit more complex, mostly because in the initial case. So once you've reached the this large conflict then it's going to work. Might be a bit trickier to uh to do the first. Uh to the in the first case. But I think it should work. Um so if the solver isn't forced to unit propagate, um I mean, is it possible it still captures all the resolution? If the solver is not forced to unit propagate because you're using the fact, exploiting the fact that you always propagate, right, in your low bound. So if there are simulations in that case, like of visits plus like long terms. Not visit as far as I know. I don't remember exactly what. I don't remember exactly what assumptions you need, but you can prove some simulation if you don't ask the solver to be greedy. I mean, if you don't unipropagate, then everything gets very easy when it took counts. The whole hard part is that the solver is unipropagate. That's the like the major source of technical difficulty. But it's also like a very integral part of how SAT source works. It doesn't make sense to talk about Like it doesn't make sense to talk about the C D C absorber without unit propagation. It's very unclear what that would mean. It's things I you never mentioned those databases, so it's irrelevant. Sure, if you want to say anything about the size of the learned clauses, I mean do you learn big clauses in your counter example? example or yeah so the this counterexample uh has already large width uh so you must uh you must large width so yeah it's uh an open problem is to make this thing with work with uh small width formula apparently in the pitfall gadget basically you have to learn uh uh uh a clause that touches all the variables in the hard uh formula or or you can't like split no so the clause that you learn does not have to talk about all the variables? Talk about all the variables. Oh, but this is a chain of block. But the way you read it is right? I haven't followed it. Mark, I haven't said that. So are you assuming in the beginning that the algorithm does some random choices to choose what variables to start? Yeah, at the beginning, since the variables don't have any score. Any score, you order them in some random way. Is that essential that it's random for the lower valve to work? Yes, if you had a fixed order, I don't know how to make the proof work. So did you actually try it out and see that the information already actually doesn't work? Organic solvers it actually doesn't work? Yeah. It uh uh so with a solver it would take um uh hours and days, but uh no actually hours but you can craft um a different order and then it takes uh less than a second. So this is going to be in uh competition I hope. Why not? Why not? That's big. But then no solver will solve it and they would like it. More questions? If not, let's thank Martin. And let me maybe take a chance to say that on behalf of