Good morning, everyone, and welcome back to this first talk of new session. It's a pleasure to meet you to discover a webinar. We will talk about this journey and the mountain chief. Yes. Thank you very much. Thanks everyone for coming and coming back to the session. Thanks a lot to the organizers for inviting me and such a nice place. I would like to, this is a joint work with. Would like to. This is a joint work with Stephen. It's my first disclaimer: that it's really a work in progress. I'm showing a few ideas. The working paper is not completely set up. Maybe there will be two papers. It's still very much under construction. So any comments, any suggestions are very welcome. So let me give you the big motivation is If you want to cast it into climate risk, you can say countries are facing climate risk and it's very uncertain, you don't know its distribution, and maybe they need to come up with an ex-ante way of sharing it in the future. Because it's once it it's happening, then it's very hard to decide people to contribute and pay for it, whereas maybe the countries have goodwill to Good reason to think today: how we can think of sharing this risk in the future. So, this is the idea that we have: we have an aggregate risk, some risk that will come in the future, and we don't know perfectly its distribution. And we would like to know how to optimally share among N agents. First, I will explain what I mean by robust risk sharing, which is risk sharing under obligatory. Sharing under ambiguity. And then we look at two settings: mean variance setting in which the sharing is actually very simple and turns to be a proportional risk sharing with homonotonic allocation. And another risk sharing, which is kind of opposite, where instead of being homonotonic, which comes with the proportional risk sharing, everybody is going to take a percentage of the risk. If you take distortion risk measures, then Measures, then you may end up with an optimal way of sharing risk, which is all or nothing. Somebody takes all the risk and the others take nothing. And that's what would be optimal in this setting. So I will criticize a bit different setting. And I added this because of a discussion this morning with Professor Joe. So, and this was also linked, in fact, is what if there's a financial market, risk. The financial markets, risk sharing in the presence of financial markets, and you know the budget, or you have an uncertainty now on the budget and not on the distribution of the risk itself. So, first, without ambiguity, the setting is very simple. I'm considering a set of random variables of a probability space. I'm assuming that the variable I want to share is mean-negative. Is min negative and I look at what I call the set of admissible allocation. It's how you share risk between n agents so that the sum is equal to your S, which is your aggregate risk to be shared. Vi is the preference function of each agent, and I'm taking the position of a risk measure. So I'm looking at minimizing the aggregate risk. So the function I'm going to optimize. The function I'm going to optimize is of the form of a sum of this individual risk measured by agent i of his position xi. And you can also cast it as a maximization. If you're thinking of expected utility, then you just put a max here. But I'm taking it in the position of minimizing the risk. If we find an optimal allocation, which is a function of the Which is a function of the aggregate rest to be shared. I'm going to name this Fi the optimal allocation function. And they will play a big role. In particular, we are going to check if this Fi are linked or not to the distribution of S. Because if in some setting this Fi do not depend on the distribution of the width to be shared, then ambiguity doesn't really complicate much the game. Complicate much the game. So the optimization is from a central planner's point of view. Yes, the optimization is from the central planner who's trying to optimize the global position of n agents that each position Xi is valued as Vi Xi. Yes? Is your bus matrix is additive saying that the risk associated to the whole has That the risk associated to the whole position is the sum of the individual risk measures? Not necessarily. But it could be one of the properties of the PI, but not necessarily. It doesn't need to be additive, it's just a representation, like an objective function for this social planner, just adding the different rests. And you discuss also the problem with the CCP that wants to measure the. Be that wants to measure the risk of the entire portfolio and then allocate to the different members? Yeah, could be. Yeah, this is actually a setting in which it's a very generic setting, in fact. It can apply to many sitting and in particular giant households. And so if S is not perfectly known, we're going to still try to look at for the minimum risk, but avoid the worst case scenario, which will be. Over the worst case scenario, which will be the maximum of the value of these risks. So I'm maximized over a set of distributions. So Fs is the distribution of my aggregate risk. It belongs to some set. And I'm trying to solve this problem, which I call this robust risk sharing problem. The first thing we noticed is that without the ambiguity, if you forget about this, and you can solve this problem, and the problem can be expressed. Problem and the problem can be expressed as allocation function of s for some distribution of s given. Then, if you have a set of distribution f, when you solve this problem, the solution will still be of this form. The only thing is that you have to optimize over the soup, the sum. So, you're looking for the distribution which I call the worst case distribution for my. Check on the worst case distribution for my aggregate risk, which is the sum of the VI taken at this optimal allocation function that is calculated without ambiguity. And by doing this, I'm actually interverting the tool. So I'm solving first the inf problem, and then I take the maximum circuit. And you can do that each time the function fi does not depend directly on the distribution of the aggregated ester. I agree to S. Is that a weak assumption? For now, in our example, it's always of this form. It is a weak assumption? It's not always of this form. So there are some conditions, but it's an assumption. It's our assumption. And beyond that, we have. It may not be true, right? It may not be true. Yes. No, no, no. I'm sure there are cases where you cannot interpret it. But so. So, in the case of robust speech sharing, when you look at this, then it looks complicated to talk about the optimal allocation function because the S is actually not known, this aggregate risk, and you only have this. But I will still talk about the allocation function, because once you solve the problem, you can still write the optimum as a function of s in the worst case scenario. Or in other words, you can write it as f. Weighted as Fs in the worst case scenario minus one of some uniforms. So if I can write it this way, then I will still talk about this optimal allocation function. And in the case, the two cases I'm studying here, mean variance portfolio and distortion risk measures, in both cases I'm actually able to write it easily. So these two examples, mean variance preferences, it's in the setting where you minimize risk, so you're actually looking for this minimum expectation. Minimum expectation, minimum variance, and you have this minus to take into account that you're looking at a loss and you want to minimize this risk. Or a distortion risk measures, so this could be a value at risk, an expected shortfall, as discussed this morning by Stefan and Fadina. They were talking about value at risk and expected shortfall, which are special cases of this second setting. Setting. So in the mean variance setting, what happens? It's actually very simple. My talk doesn't involve very difficult math, in fact. So when you solve this inf sup of the mean variance objective, alpha i can be seen as a risk aversion parameter for each of the agent i. The optimal function, if you solve it without the sup, you actually You actually get something like this, where your allocation function only depends on alpha i, and beta i is actually arbitrary because what we want is just that the sum of the beta i is equal to zero, but they are really arbitrary in the optimal solution. And what we see is that the alpha i only depends on the vi to be shared. Like each agent has its risk version. As its risk aversion parameter. That's the only thing that matters when you solve S. And here this S, which one we are going to take, which aggregate risk is going to be shared, is the one that comes from the worst case distribution that is solved by solving this sub problem where you solve the sup of the sum of these objective functions. Subjective function applied at this optimum, and after some simplification, in fact, it comes back to a sup over some condition expected loss and variance of S. But it's a very simple optimization to find within the set, because you're just optimizing and finding the best trade-off between the expected aggregate risk and the variance of the aggregate risk. And that's the At risk, and that's the very simple thing to solve here. How to prove it? I'll just to give you a sense that this is a very simple result to prove. It can be solved by just thinking first by looking without ambiguity, then observing that it does not depend on the width to be shared, and so then you can just put the SHIP in front of it, and that's it. So without That set. So without ambiguity, you can also, yeah, so let's do without ambiguity. Sigma s is the standard deviation of my aggregate risk, sigma i is the standard deviation of my individual risk. And what I have is this is always true. And the idea is if I want to show that at the optimum they are all proportional to S, I need to show they are homogenic, and therefore that's. And therefore, that sigma s is equal to the sum. So, by reformulating this problem, the expectation, I'm just assuming they are all equal to zero, because of the constant here, it's actually not a problem. You can just remove this expectation and focus on optimizing the problem with the variance. And so you can just express this problem as the int for the sum, the square of sigma i. The sum, the square of sigma i, with an extra constraint, that's the variance of their portfolio is fixed so that the sum of the sigma i is equal to constant C. And then it's just a Lagrangian optimization. With some Lagrangian, it depends on C, you optimize and you end up finding that at the optimum, C star is sigma s and therefore that your sum of sigma is Sum of sigma is actually equal to sigma s. In this case, they are homonotonic. And then it's because the sum is equal to s, they must be linearly linked to s. And then this linear coefficient comes from the Lagrangian multiplier. So it's a very simple proof. I go a bit fast, but it's. Are you assuming the interpretance between the There's no assumption here on the independence. So what's nice about this optimal risk sharing is first it's completely exogenous risk sharing. It doesn't depend on the presence of ambiguity, in fact, because these functions are only linked to the risk aversion parameter. It can be done x-on-day, and it's immediate to implement at the end of the period. Implement at the end of the period, if we all decide today that we're taking 20% of the waste, 50% of the waste, and so on, then at the end it's a very easy risk-sharing when you observe as exposed. And it's also strictly cohomotonic. Any risk sharing problem is a very interesting property because it means that everyone, if there's a risk, if there's some loss, everyone is going to be concerned to pay for this loss. And so everyone has incentive to move. And so everyone has incentive to minimize the loss. If you're not strictly kuratonic, then you may actually not care and not take the necessary effort to reduce the possibility of having a loss in the future. So this is actually something that you want when you do a risk sharing. Now what if? And then yes, we have some generalization. You can do it with Paul T. It's even not a concave function, but still find some. But still find some proportional risk sharing as an optimum. So, yes. So, what happens if you are, I mean, if you are in principle comonotonic, right, you are also going to be hit by the climate change, for example, but you don't want to take action or you don't care or you don't understand. And you still have to pay this percentage that you committed at the beginning? Yes, but you can't avoid it, right? That's the whole idea. And you share with others, but the idea that you can be hit and that you have to pay at the end, in any case, makes you more willing to pay something and to try to prevent it to happen. Because you will have a loss in the future. If you if you know that the loss will uh will be on on others, then you have no incentive to actually take action. Somebody else is paying for it. Somebody else is paying for it. So, the second setting in which we worked is the distortion with measures. So, maybe just focus on this expression of the distortion with measure. In some cases, you can write the distortion with measure using x as a distribution g and gamma is your distortion function, and then you can just integrate gamma against the quantile values. The quantile values, and so that's kind of a weighted average of the quantile value where gamma plays the role of the weights. So I'm going to assume that this presentation holds. There are many examples for that. So these are just a few examples, dual power, long transform, the t var, the var, where you can find gamma, but the var actually does not have the representation of 6. So it can be obtained as a. So, it can be obtained as a limit, but you cannot have this representation. Now, what happens when you have distortion risk measure? Then, the first thing is that proportional risk sharing that was optimal for mean variance is never optimal with distortion risk measure. And the only thing that you use to show that is the positive homogeneity of such a risk. Of such a risk measure. So when I take any proportional allocation, so if I take xi being a proportion of S, I can show that there exists at least one all-or-nothing allocation, which means one guy is taking all the risk and the others taking nothing. That is at least as good. And how I do that, I just replace Xi by KiS, which is my proportional. Which is my proportional risk sharing. And what I do for each risk, I look at H GI of S and I take the minimum over all this GI, over all distortion functions. So I take agents that all have possibly different distortion function. And one is minimum. And then you can, using the positive homogeneity, you can go back and get that. And get that the risk that this individual ICO takes the full risk and the others then take nothing is actually always lower than the proportional risk share. So we can improve the risk sharing by giving all the risks to one individual. Sometimes it's actually going to be the optimal risk sharing, but not always. So in the T-bar case, terror value at risk, then it can be shown that the optimal Then it can be shown that the optimal allocation is all-or-nothing. So one guy is taking everything and the others take nothing. At least there's no uniqueness of the optimal risk sharing, but this is a possible way to share risk. So which make TIBA, to me, a very bad risk measure to use in the context of risk sharing. Because that really means that one guy is going to take all the risk, the others, nothing. And if you do that, With the others, nothing. And if you do that, if you know that, then you have no incentive to take any action to prevent the risk from happening, unless you are the person who's concerned by the risk. This is where the Tel Navy at risk is actually really bad. And all distortion risk measures that get this. The proof again is super simple and just rely on the positive homogeneity of Tivar and some common hotening additivity. Need additivity, but at least I don't have time to go through, but it's a few lines and it shows that the tell value at risk is indeed this all or nothing is better for tell value at risk. It's also all or nothing if you have concave distortion with measures and one of the distortion functions G1 is smaller than all the others. One is smaller than all the others. But if you have this situation, then this intimum is also all or nothing. One guy, the guy who has the minimum distortion risk measure, is going to take all the risk, the others take nothing. Observation, if you have concave distortion risk measure, that doesn't make sense in practice because you get all or nothing. It's not reasonable that one person is taking all, like, will pay for all. Taking all, like, will pay for all the risk, and the others take nothing. And in particular, it does not satisfy the stricts of the sabotage condition. So, the idea is really to find a setting in which this would not happen. So, if you want to work beyond the concave function, then you have to look at general distortion with measure where the distortion may not be concave. And then, we wanted to show. Case and then we wanted to show, like in general, how to solve it. But have you looked at like a convex exporting or like A inverse A shape? No, it's not numerically we're we're about to find the way to solve it, but it's not completely done yet. Analytically but no in in approximation. But analytically I don't know how to do it. A concave distortion measure means Distortion measurement is something like so. That's why you have kind of the corner points which all nothing is like corner point. Yeah. Is it? I always mix up the two, but I think you're right. So we started to work on an approximation of the problem when it's Of the problem when it's not concave. And to do that, we observed that optimal risk sharing can be set up as at least after approximating the distribution of the loss that you want to be shared into a discrete distribution, and then you're looking for this discrete allocation among them, then your weights become also discrete weights. Weights, your distortion risk measure is actually a sum of the values observed distorted with this gamma ij. And then you can look for the solution in this problem. If you impose this no sabotage condition, if you impose the increasingness of each risk, so not necessarily strict, but just to impose the this increasingness. Impose this increasingness, then we know how to solve it, and then there's a solution. It's all nice and can be solved. But if you don't impose the no-zapodash assumption, then we think we can still solve this problem by still presenting it as a linear programming problem, but you need to find the right rearrangement of the matrix gamma L J when you work on it. So there's some It so there's some still work in progress on this part. So, in the last few minutes, I just want to present, yeah, so the distortion with ambiguity, so without ambiguity with sure how to solve, and with ambiguity, because this allocation, all or nothing, does not depend on the structure of S, we can still set up the problem as a sup over some set of a distortion disclosure, and this is. Measure and this is solved, in fact, in many cases where you take moment space, for instance, where you fix expectation and variance, where you look at distribution that are symmetric, unimodal distribution, or Weissenstein distance if you are within a set. So if you do take this kind of subset of distribution, you can maximize and minimize distortion with notes. And we've worked in particular with Steve Berlin. And we've worked in particular with Silverna on this. She has a few papers. We have one together, but she's working on it and has a few. So let me just present very quickly what if there's a financial market. So the idea here, and I won't have to go in won't have time to go in the details, just to give you a teasing so that you want to go and read the paper. To go and read the paper. So the idea is exactly the same as before: the inf over the sum of vi xi, but it's not a risk-sharing problem at this step. Because what I share is actually the budget I need to replicate this portfolio in the future. And so, this is more like a portfolio problem in a multivariate portfolio problem. And so, here, possibly, if you have uncertainty, it's on the budget and it's not on. Is on the budget and is not on the distribution to be shared. But you can solve it by linking to what I've done before in a two-step. So one of the steps will involve using quantile approach for portfolio choice, which as Professor Joe has been writing a paper with Schwedunkre in 2011 and has done many extensions. Extension from this paper. So, the idea is in a univariate setting, maximizing a portfolio is the same as searching for a quantile, a univariate quantile. And what we show is that solving the problem that is here, a multivariate portfolio with a budget constraint can be also linked to looking for a univariate contact as long as you know how to solve the risk-sharing problem. So, that's where the link. Sharing problem. So that's where the link is with the first part of the talk. So I'm back to solve for a distribution given S how to share. I minimize, so this is the same problem as before, and I assume I can find a solution. And if I can find a solution, then this problem ends up looking for the quantile to be shared. And this quantile, you can see it appears in the n dimension. See, it appears in the n-dimension, but it is really a univariate problem, whereas we started with a multivariate problem. So it's used the quantile approach in a multivariate setting. So I won't repeat what I've done, but these are my conclusions, and maybe I can just show the references. And thank you for cleaning my talk, and also for keeping it on time. On time. So, we do have time for a couple of questions. What happens in the non-common-toning case? Can we say anything either on computational or what point it would be qualitative? So now we have only a few examples that we can solve. So it's very hard to get non-communotis. So in general, when you get risk sharing, you get a lot of risk. You get risk sharing. You get non-common allocation. When your distortion functions cross each other, then you can sometimes get this non-monotonic. But we haven't done this really too early to make conclusion in this case. I'm working on it. Any other questions? So next on the program is presentation by everyone. So we will go outside and have