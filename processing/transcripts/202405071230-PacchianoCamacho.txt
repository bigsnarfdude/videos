Today we have a paper that is titular de similarity dimension, sharper bounds for optimistic algorithms. Voyamara inglesis en Spanish because much of the terminology in English yamente don't correspondent in Spanish. This is a paper that appears in NERIPS LANO PASA, Neural Information Processing Systems una conferencia, and this lab is a misco autores are Natalie, Miro, and I'm in the institution. The topic: this platica is located. Clatica is what I am adaptive learning. We are going to think in situations where people like a system or Google understanding that with an environment to sequential or in rondas. And the people who are In general, the type of objective in the cup in this case is the maximizar of a reward and that. And that's the scenario. For example, to a robot, we have to do the rope, and the initial node comes. So, the mandates of the entering, and the robot understanding that things exist in this environment, as Europa. And the man who enters this system would be damn like rewards first, if the robot enpies are more sensible, if the target is double robot. And this paradigm encompasses or es. Encompasses or described various types of scenarios, for example, when we utilize machine learning or artificial intelligence methods of two methods to be experimented scientific experiments. For example, a violation where we have models that have predictions about what experiment utilizes to be able to do. Prender the most possible of what we are studying this paradigm between describing the robotic and also there other scenarios that we horse. But technical sonido is platinum, so we have a second.        If we have, and like perfect. Perfecto. Así scenario of adaptive learning tena vara es applications, a for example, the machine learning and artificial intelligence methods to experimentation scientific experiment, other example of robotic example that also many types of algorithms, for example, City of Web, Google. Web, Google, and other social media platforms to understand the users, and content that can be done. In these scenarios, when you have a people who are interacting with the world of sequencing, and this current world, for the action of one of the One of the principles is 2 samples or 2 interactions needed and in the world to understand how actual activity. In supervised learning, which is scenarios where it is a data data, and that wants to learn a function that goes to these data, a prediction. For example, a prediction can meet or the number or characterization, the sample complexity, the number of data that are not dimensions, statistical dimensions, with example visible dimension. So, what we do in this paper, and what we have in this platform, is going to platform as Characterizar sample complexity of the statistics that are the dimension of the dissimilarity and that in particular in focus structure bandits. But significant structure bands, we will first enter the idea, the idea of which is the bandits. So, So, website here in the protocol, we have time steps that are to note. And one, and this is how a temporal case, what we want to do is select an arm in this case. In this case, for example, we understand what the mejor transfer to solution disease and a clinical trial correlated various about different patients to understand what mejoramente para enfirmed. So, the model of this form interaction with these patients in Actually, with these patients, in the second section, that selection is a selection, observas that pass with this, and function that we do in all these scenarios: the people who produce. That I produced with the reward, the gain, financially. In this case, I will introduce formal managers that are the objectives of this aspect in the scientist and positives. But abstract, the idea is the scientists, we will have a conjugate arms. Conjunto de Arms no armas like historic thinking formal of tatamientos or the arms in this case and the mean reward of the mean reward it's going to characterize. The main reward is to characterize a function of the arm that we have. So the tenement of functions that we know, but we are actually. So the idea is that this main reward or this gain. Osa este gain, this reward, is a function of the function, which we are selecting, but we are actually functions that characterize reward of this very reward. So, my interactive sequence with this problem, we understand what this function is, because we are also quite functioning in bio. And so, a little bit more. A little more notation, we can see the arm that maximize the value of this. And that is the model much. See how this forma que tenos accesso este con junto de actions, with arms. The arms and cables that selection is a selection of actions of observing a reward that is a function of the action that was the action, more than expectation zero, valor esperado zero que sel ruido noise. Noise. So, this is the setting that we have structured bandits, in the during the time steps of grandeur. The algorithm selection, an action arm, can use the terminal arm because what is in English and receive a reward that is. Word erote que es de la forma estraya a te ma sero zero min noise ruido de valor es perado ero. This is not that gaussian, the assumption generally is that it is one sub gaussian or something of still. And how else will assume that the valor of The valor espresso de las arms of actions can describe as a function of tradition. It was a conjunto functions that we know in advance, that we know we do not objectively interact with the rewards. With the rewards that the legimos are, we have the flexibility of the corporation that we are. Almost time that we also have the arms that have valorado de la reward tan alto as possible. So, this model of example encounter medical treatment that is exhibited or the scenario of scientific experimentation of the scenario. The scientific experimentation, of the scientific experiment, where experiments allowed the world, at the same time that experiments that are exit. And this model was locations and refined our authors, in these works. And if the model, what we intend in these scenarios, usually. In these scenarios, usually evaluate the performance, of an algorithm, a objective that is regrettable. The regret is defined as the sum of different differences between the maximum of the arm, or the valor of the mejorament, but the valor. Menos, the valor esperado, all these are valor esperados, the valor esperado de la totamento de la arm that the gym and logibos and es que uno quiere lojetives mantene está canidad queam regret the more possible. What is what? Depending on problems that This type of problems that obviously obviously, if the identity of Esther and we actions to do not only understand that, if we do the action that we are rewarding here, it is like possible. How possible. Okay, this type of scenario appears to be the first in this model more simplificated, of the things that we have the multi-armed bandits. In this scenario, what we have is ten discretion of arms or the axions, usually denoted, denoted as much as. And the objective here is interacting with a discrete actions, and we are controlling the action that has the value for more. This problem is inspiring in a paper of Robinson, 15, where we are. Staban intended to understand or tiene a market of these, like Spanish, but a slot machine in English, how can you estimate the value of the payoff, because it is a cos random, so manively, and not and. And then one and because they are arms in this scenario in English, because this is the manive here. And the band, no, the bands that the machina. But in the case, because you like the terminal arms, because you have these machines of puestas, and the terminology for more in English. So that is a puedar, talve in these distinctions, arms, so you are casual. Distintos arms are caso in different various markets and so the payoff. Did not mark a quality of a dad. Parse que una prunta. Valgo. But no vero. Okay, fine. Okay. Um, how usual the mobile que se consider is a cuando uno intent una arm or machinapon, the puestas, the valor respiratory of the reward or the valor that receive aleatory, that has valor respiratory arm that in this case the function class, the class of functions, that contains. That contains these puede understand the space of functions that values the domino, the domain, is one, and the values that can achieve are between. They can identify identify the functions where this live in these types of problems. In these types of problems, how this space of this cubo developed. But this is a model very simple, about the topic in other types of situations, because they don't consider the cases that arms are medical treatments, medical treatments. There is a correlation between a medicine and how they interact with the patient. That can be a form of relationship, how other types of medicine similar, but also with the patient. The problem of a model, like this, to model the type of problem as the medical tests. The medical status where the relationship between the arms, or the tatamentos, is that in this case, and the arm doesn't arm. So, that one Model the problem of nuanced manner, and we are functional approximation that is basically the first thing that the functions in the classes of functions where we are considering the functions of the value paradox has structured. So, for example, y because it is queen. You can use a multi-arm banded problem, where measurement noise are in this case, if we encourage the best arm, the whole arm that is in this case the roja needs to be one of three queries. It has to be the valor of cadaver of these arms, so you can conclude that this mejor because I did not. But But their point is the scenario or this characteristic as a vector in a space of dimension two space, for example, and we experience linear value. So, with two queries, with the valor of two arms, we have the valor of the model, we have exactly the model of the world, and then. Esperado y so treatments that mejor. So, to assume more structure in how valuable experiences of arms or strategies, so the number of queries that need to contrar the model or in contrar the mejor arm is many. In the platica, we are very class of functions that we have the wedge class and that we have the arms to be like identified as points in the recta and the strategy, for example. Fred for example, pass of this form, as a function that has valor, except in this region that is triangular, and then the valor, for example, of this of the arm 3. Let's do the definition of the wage class when When the wedge class, but the first and also that mentioned in the examples that mention the multi-bandits, the number of arms, the number of tatamentos, the number of directions is finite, but not that we can generate a space of actions that infinite. For example, the For example, the action or the arm correspondent and the dossier, which the dossier of this attention the parametrization of the arms paper continuum. Okay, so with a model, this idea of the function approximation. Approximation. Or assumir that there is a class of functions arbitrarily functions that contain a function that is igual. Voyager in a positivas, French van idea is the mental quiete is coming. How is it? We have the capture, the complexity of what is the better action or minimizing the regret in particular to structure bandits that are what is arbitrary. And what we characterized that is indifferent to the optimal action. Action optima to a class of arbitrary functions. For this, if there is a class of functions that are very complicated, so much more difficult, or one can provide many more difficulties, to do optimization or a good action in when. In when the values for dividing a more complicated function. So if the classes of functions are simple, for example, linear function, so that's one of the variables can be contrarized from simple. So we are a characteristic that can class functions and the actions that are disponable. And well, we do first have typed in us the verse. The version of complexity for this type of problem that is describing that can be defined for arbitrary functions. It is also the dimension of the dimension, and what we introduced is a new complexity combinatorial class, which is the dissimilarity, the dimension of the dissimilarity. But to this, the others that first platform, however, the algorithmic principle that we allow solved this problem of it. And that is the principle of optimism. And it is the typical algorithm of the algorithmic principle. What algorithm allows problems the structure bandits? The structure bandits and terminar con the sample complexity of this type of algorithm with introduction of the dimension of the dissimilarity. It's a ambitious plan, because we have a sentence. The algorithmic principle that inventes exist is This exists is ubiquitous in the literature, it is optimism. So, the control of the algorithm that is operating or UCB. It is a more basic album and more common in the literature of bandits. In their pocket of notation, here, we will use this symbol. This notation here for Y paramar to average rewards that we have received when we utilize the arm A. Ten caso del multi-armed bandits mentas ententamos distinctas distinct treatments from sinos quiamos, podemos uh We contar the numeral veces that we have intent on treatment A y we are in A. A. Tamar arm pulls in English. The numeral veces that you are pulled an arm of the first point of confidence intervals, the Chernov, just Chernov bounds, cotas Chernov. Cotash North. What we can do is we have an arm A, for example, ARM 3 in this case, and we're totally injured in the empirical mean, or the promotion of the rewards that we have received from this arm. Recipient of this arm, that cantidad is three. What can we do? Is that if this elimino y les sumas, a cantidad que es roughly of the order, the square root, one between the number of veces que data points that have arm and summaries and construct an interval that. Interval que va de esta quantidad aquí Fat minos dete, Fat more dete que contiene con high probability with probability very alta al valor esperad al valor esperado de verdada arm. So some pueda series construct these are the upper bounds of data the data queues. Los Dados that we have recollected at time of confidence intervals to the valores prominent, which we computed. What we can do is calculate distinct upper bounds for one of the arms, depending on the data that we recollect for a dellas. So the algorithm that is the upper confidence bounds. What is one calculation of these upper bounds and selection to enter in the room? Or time, the arm that has the valor of the upper confidence bound that is more or less in this case the arm three. In the problem in the log, the mejor arm is arm two. But all in All we have intent is sufficiently concluded that this mejor, it is the logic of the algorithm. So, the principle of optimism, what is that if utilizing this regular error, or the arm that will actually the UCV arm, so you can provide the valor of UT. Of the UT of the arm that is going to be por estar, simply major que valor esperado de la mejor arm. That is because for definición el valor of UT of ETO de la arm that we are eligible for this regular, which is more UT of the arm of the arm that is optimal because the arm that we are given. Because the one that is digitized, that valor of the operand, and because the confidence intervals are valid, the valor of this arm is the same, it is more than high probability, that the valor of valor is optimism. So, that is. So, what I can do is regret this algorithm, very super simple, that is face. The order of square root. When the regret is an algorithm, I mean subline, it says that the algorithm is a problem. And what we And what we have the proof of this, the proof, or the demonstration, is how the regret, like ours, the regret is exactly this candidate, which is the sum of the final interaction of the reward value, mejor reward value, but the reward value is perado de la arm that selection. Utilizing the principle of optimism, we know that this alpha star is better that UT or the operand of the arm that is and this UT of AT, but ET is exactly operated by the radio del Chernos radios, or this. The chartnot radius or this confidence interval, so we can have this relation, this operation. The rigor is puede ajotar como esta suma. And what this summary, what you can do, is to demonstrate a little bit that this summer can describe how this otter suma que esugades sumar estobretim. In the summar solo time, first about the distance arms, and to arms, summar about the numeros of the selection, and this summary of the Queen square root, like square root of the number of decisions that selection. And as the number of summa of these NT A is. A is exactly because the regret of this algorithm is create the form square root kt. It is important. Unique imports the first passenger that confusion in this type of proofs, demonstrations for the regret, is the principle of optimism to substitute the mejor el valor. The mejor el valor of Alpha Estrella con algo que dependent del nuestruption. And this difference is exactly the crease or progress to a rate that depends on what we have visited this arm. Okay, and well, there are a lot of papers that utilize this principle and for much. Utilizing this principle and for many algorithms of reinforcement learning, the bandits, utilizing the principle of the optimism. But that in the case in the tenemos functional approximation in the functional approximation, when we are in this simple simple world of the bandits, of the multi-armed bandits, for example. We are going to have an algorithm that will be the same type of idea. And we view the principle of the time because we do, like, actions together, and vista rewards. So, what we can do. So, what we can do is resolve this least squares problem: this problem and a model that explains the rewards of the data. So, some cannot here, but one can see the identity. The strella el verdadero. The verdater model that is producing these rewards recognizes the rewards have no riddle. That is not exactly, we have more riddles. But what can construct a subject of F, of the class of functions, which contain with high probability. That continues with high probability to the model of model. And that with a conjugate queue basically like a volume to read this model FAT. A volume determined by a metric data for the data. That is exactly this. Exactly this. So, we're going to consider a subject of functions, so the prediction, the role in prediction to a quadratic loss, the same quadratic loss here, not much of the predictions of the effects. And this much is characterized by a quick vet that in the case one. In the case of one not rude or noise in the rewards, no sixty rudo noise and the rewards one can telecomma el veté homos and noise and rewards. So can prove and this is not that sufficient for the esteem as order in logarithmo number of classes of functions. Of the class of functions, we are considering a confidence set of functions that contain the model of verdict, which one can construct if created well if tienes access to this effect. The effect is basically a quadratic problem and it is a So, as algorithms are very simple, it's basically principled or what we can do is how this is, how we also construct a upper bound, a upper bound of the valor of the function in what action. And that is implemented. F that live in FT. Here. So it is facilitated as living the valor of UT for A is more than estray of what we also. What we also have, or action we have, in time, the ARC MAC, or the action that maximize the UTEAM. So, optimism also optimism, also satisfaction, is that UT will. Use ATE, basically more grandeur that the mejor reward of all expected report. And here in this case, we consider a model that the optimist model will be the model FTE that satisfies exactly this position. That is the model that for the action that we will consider. Ugar, in time, the ego satisfaction. So, how we have a regret bound, it is very principal. So, what we have is the regret that exactly this is what we are optimism to convert this in a user of AT, and so what we have is substituting the formula of FT formula. Because this is a function of these two functions, living in a arbitrary space of functions. So, how is that? So, how is that characteristic complexity of this type of differentiator? This is how it defines the dimension of the dissimilarity, so it is the idea. So, a class of functions is difficult to understand and one has y data. Actions or queries with them. The conjugate functions in this space of functions that agree with these values that have exactly the same values in these actions. And in mass. And two models in this space in this version of space tales that the valor of equipment in Mason is very distinct for these two questions. Yes, this traction and valores don't predict the valor in this attraction. So, the class fonts are not biennial. Prendido bill valor of the model of this model exists another point in the two functions that have the same values in the queries that the values are very distinct in this point. That is this idea that epsilon independence and confusion is well, connection. Well, the action is epsilon-independent, the actions previous, and exist in two functions in the class of functions, so the role of these two functions in the square error is that for example if the least squares problem is very circumscribed in the historical data, but in two values very distinct when So in this case, this conjugate actions, with this action, we are more than actions independent of these actions. So, to characterize this intuition, when the functions difficult to understand, we are not. So, in the existence of the other dimensions, And also. And also another location generalized linear functions. Well, this notion was for Russo and Van Roy and this paper in 2013. And there are many papers that announce this notion of statistical dimension to progress or introduce distinct algorithms in reinforcement learning, bandits, and things that we And things that are also good. And that the last three slides are the introduction of the dissimilarity, but all the background. So, what downsides have How downside has the definition of the luder. The problem is that what is that the squares that consider in the definition of the dimension are arbitraries. But when these poroso algorithms like optimistic squares, these queries that one are arbitrary, they are queries that are governed by the algorithm. Governed by the algorithm. So all these are optimistic, satisfaction in the principle of optimism. So we can see that in the wedge class that definitely, the dimension of the luder is like one over Epsilon, what is typical of this type of construction, we can see that. Construction, we see that for a class of this class, the dimension that is arbitrarily arbitrary. My entrance que uno can also demonstrate that if one correct optimism in the wage function class, this algorithm will terminate in numerous queries that are other queries. How other queries. So, the idea here is that the algorithm that optimism temporarily, well, I can analyze and see. So, the other dimension is considering all the possible queries, a queries that are only for a parameter to Epsilon. So, what do we say? What our decisions analyze the upper bound, but a optimistic square that we are in the dimension is very useful. What I think is a queer, what we can do with the other dimensions is that it regrets the optimistic least squares of the algorithm that we are for the functions of arbitraries. It's upper bounded by this quantity, which is the idea. Bounded for this quantity that is the dimension of the other dimension, of one sobrete and square root here of the dimension of the other, veto. This is the least square error that mentioned that the logarithm of the class functions and riddles and otherwise. So, in this case, if the dimension of a epsilon, and the solutes, the regret before this for this class, it is. Or this for this class would be. But they don't, because one can see that the rigs of it. So this is falling. So in the sense of three slides, you can terminate. OK, so what do you do is change the definition of eludes to a distinct definition that we have a combination of. A established combinatorial complexity for a class of arbitrary functions. So, what we have to do is decide that a class of functions is difficult to understand or optimize. We have if data in queries all satisfaction in the optimism. And we all And consider all the functions that stand with values that we have in these queries, a difficult point of learning, a point that we concern, but a point that we have these values and these queries. If this point is also optimistic, it is existing a function in the version space that achieves. Achieves an optimistic value. But, result that for the model of verdad, the valor of this new query is much better. Or it is not optimal. This valor is a difficult class of understanding, utilizing an algorithm that uses optimism. Optimism. So, the definition of formal definition is definimos what a dissimilar sequence of functions and actions, the functions. And this sequence of parents, it is dissimilar, and exist a parameter, so that all the queries are optimistic, optimistic, so large self-evaluations. Self-evaluations. Satisfying que la function of the part with the action that is selection, we have alto, but all the functions of the future, the functions that we have, one of the most valuable actions of the past. Actions of the past central todas to reduce a valor that is not and what one can distinguish from combinatorial complex of a class of arbitraries one can be proprietad first to First, that for the lineal class, the 5 dissimilarity also, as a class, as the other for the wedge class, that we are the dissimilarity of constant dissidents, which is one over epsilon, or very small, and for another type of more complicated class, dissimilarity also constantly can be infinite. This is how one can trust. How do we think the dimension of the dissimilarity of algoline is going to be? And finally, what we can do is that the dimension of the dissimilarity is also a lower bound of luder. So, how this dimension is a puedru, which is the algorithm that contexts the optimistic squares, satisfies the regret bound, which is the. Rigaret bound that is the forma dimension of the similarity of a point, but dimension of similarity and the square rootie. This exponents for cases, for example, in the wedge class, this can be much better than the other. The demonstration utilizes the tournament of Turan, and other types of cosas. Look what I decided, is that. Look what I decided, is that what the introduction is what I introduced, what many things definition of the bandit problem, the optimism, how to bound for multi-bandits, how the principle optimism for structured bandits, and to terminate the principle of optimism that are principled algorithms. Optimism that is a simple algorithm as important limitations, for example, but this type of classes of functions, a utilized optimism, can be very suboptimo. And that also can be announced that with the time, the point is that the algorithmic principle that we do is not the end of the story. And so, there are many. And so, there are many directions of investigation in these types of problems, which include our limits to things like sharper bounds, utilizing things like the dissimilarity bound, which is not completely sharp for the exponent, dissimilarity bounds for other types of problems that will be the structure bandits. And also, that is how. That is how optimistic algorithms have neural networks, how we are typing bounds that functions in neural networks, and how we do auto-type algorithms and other types of statistical learning theory with characteristic perfectamentees in arbitrary function classes, the complexity of complexity. But when you ask the impression of reinformed learning, we have. So, if you look at a little bit more differentiator, adaptive learning and reinforcement learning. So, my adaptive learning is the entrepreneurs you see as an umbrella term that contiences like bandits or reinforcement learning, or models that can be done in reinforcement learning or POMDP or partially observed market decision processes. Decision processes. So, when I refer to adaptation, it is implemented the pensar in a sequential interaction between a gentle and world. That is one can cover model, as reinforcement learning agent, if the assumptions of Markovian and Tedan, but can do that there autotipole of assumptions that are to model a problem as well. To model a problem as problem. That van makes solar pension reinforcement learning. Sorry, also another thing that I mentioned is that reinforcement learning problem, bandits, and only what the three objectives maximized a reward, but can be that objective. Osado que non essamente involu maximizar unar reward. One other type. So, what do you say as you have when you are learning, learning not significant maximizing reward, and that typically in reinforcement learning la objective is maximizing reward. If not, no capture an assignment, all the problems that can model in interaction sequential interactions. No sesiña otra preguntar repúblico que la comer. This is a question. We are one algorithm of evolution, evolutionary algorithm to explore a space of configuration discrete. So we have. What we can do is contradict the metro degree, and so I want to ask if the methods of optimism could be this type of situation, for example, a model, or a manera, for example, a method that can be functional Thompson sampling. So, if you are a model value, but. It has a model value, for example, that produced a posterior product, as a distribution of what control of what is there as a score function, which is a fitness, like the evolutionary algorithms, a approach that is more like this optimistic, to see what function. All this depends on. All this depends on how a model of ecuador of what this candidate. If not, like this model, more difficult optimism functions well. So, in the model in the sense of these graphs, if you are apart from what graphic is proprietary, how to have a model of what graphs are not, you can see that, and there is If there is general model, then much. Well, we have to travel for much more.