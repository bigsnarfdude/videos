 Remind you of Tuesday, and we'll start with bringing you as a harmony and full problematic series for having your configuration. Thank you. Elena is my scientific sister. And I think this is not the first time we announced my talk. It's so convenient. Thank you. Thank you very much for the kind invitation. I'm very honored to be part of this gathering for Timo. Let me start with. Downward. Downward. Downward. Oh, okay. So I happen to have a picture of Timo and guess where this place is? That is in Ben. And I think this is Lake Lewis. We went up to Nate Movies. And the one who took this picture is me. And the man in dark is also Timo. So I still remember the taste of that blood. Still remember the taste of that black TV share and the cookie. After two hours of hype, it really tasted good. And I'm hoping we repeated this. So let me start with the motivation. And I think the kind of problem I'm interested in is very much in the spirit of what Timo has done. And basically, my ultimate goal is to study escape. Study escaping limits for many growth problems. And the kind of class of examples I'm interested in, presumably they fall in the KPZ universality class. In fact, one way to model a growth would be that you have an interface separating different phases, and that interface is represented by a graph of a function for simplicity, and that function satisfies the Havitan-Jacouli equation. So ultimately, we have a height function that is denoted by u, depends on position, the position is in Rd, depends on time, and takes values in or and the time derivative of the height function is given by a function of position, time, and the inclination of the height function. So that's how the PD that's how the P D is formulated. That's how the PD is formulated for the growth, and you often have an initial condition. We are also interested in the dynamics of the inclination. That would be the special derivative of the height function. And what I'm writing here as u sub x, this is a vector-value function. x is a vector and it has various components. And rho itself satisfies a differential equation, which is some kind of scalar conservation law, even though this is a vector-value and you. Even though this is a vector value and u is an exact derivative. And I guess the discrete version of this evolution equation is more popular. Some of these variables could be discrete and when they are discrete then many tricks in combinatories becomes available and some of them happen to be completely integrable. That's why we often study a variant of this model. Variant of this model when some of the variables are discrete. In fact, prime examples would be exclusion processes, Hammersiel-Aldis-Diaconus model, and polynuclear growth model. And for the models, we are interested in the Hamiltonian function having to be a random function. In fact, in x and t, you should regard Hamiltonian function as a stationary process. In fact, one example that I had in mind when I was working on this project was a model that I learned from a paper of Yuri, when the Hamiltonian function is a function that depends only on inclination, h zero, minus a potential function that depends on x and t and the potential function is a stationary process. function is a stationary process. And a simple example would be when this potential formally can be expressed in this way. So you have the indicator function x equals xi and you have delta function and the randomness comes from the choice of this discrete set xi and si. Oh by the way, Impressed this. Oh nice. I'm not very good at technology. And this collection, this discrete set, is This discrete set is a some point classes of some intensity. In fact, when H0P is quadratic function, this model was studied with Bachin, Kator, and Hanin. And they established the existence of invariant measures for every inclination. I think was a very interesting development if you're interested in scaling limits for this model. Interested in escalating limits for this model. And in fact, when the Hamiltonian function is just mod p, then this model is equivalent to Hammers, Aldus Diaconus or polynuclear growth model. So this family of examples include an exact dissolvable model and the one for which we know the existence of invariant measures. So that's very convenient. Just, you know, got some. Just, you know, got something, a Google search, and I got this picture. I have no talent whatsoever to draw pictures or anything that is related. Everything is Google. I know, I know, I'm the extreme opposite. So, in this conference, you have the whole spectrum under the other. Okay, so the kind of question we are interested in is as follows. You solve this PD. You solve this PD, that would yield a family of nonlinear operators that correspond with semiconductor. You give me an initial height function, then at later time you have another height function. And or you can kind of express the same thing about the derivative of the height function. Or you have a dual formulation. For our purposes, we would like to choose the height function randomly, so there would be a probability measure that lives on this list of possible profile, possible height functions. Profile, possible high functions. And then when you evolve the high function according to the dynamics, equivalently, the measure is evolving with time. So the dual dynamics would say that you start with some initial measure that says how to select the height function, at length you have another measure. And the goal is to develop some understanding about the evolution of these measures. If I'm lucky, maybe I can find some explicit formulas for these measures, which is the case in the case of completely. Case in the case of completely integrable models. So since most models are not completely integrable, models kind of progress would be you find a suitable nice family of measures that is invariant under the dynamics and you study the dynamics restricted to this family with this hope that you can derive an evolution equation for such measures. So ultimately, Measures. So ultimately, so I'm kind of like giving an overview of several results in this context, but the main motivation came from a conjecture that was formulated by Menon Srinivasan. Then there were two papers establishing this conjecture back in 2016 and 2019. And now there are some recent results that I'm going to share with you today. So there would be So there would be two familiar two uh cases to consider. First, in dimension one, I consider a Hamiltonian which is arbitrary, could depend on x and t. Randomness for now does not play a role here. H is a deterministic function. You can choose it random if you want, but the kind of randomness that you have on the profile would be independent of the randomness on the Hamiltonian for some of the results that I'm going to mention. For some of the results that I'm going to mention. But ultimately, you want to kind of combine these two randomness. But that would be kind of harder to study. But for now, C on H is deterministic. And you're in dimension one. Now, you can talk about fundamental solution in this context. I think in this gathering you may call it a narrow-bedge solution. Solution, narrow veg initial data. What happens is that if you have a Hamiltonian that is convex in P, then you can talk about this Laujan transform. This is a little bit unusual for the Logan transform that I have in, but I did my best to have a model which is last passage percolation, not first passage percolation, to be consistent with other talks in this meeting. So you saw with a convex H. So you start with a convex h, and out of that you produce a Lagrangian which is concave in the velocity variable. And then you can define the corresponding fundamental solution. This would be a special solution to Hamitang Cobi PD. And the way to achieve it is you take a path that at time S starts from Y and at time T arrives at X and you minimize the action over such path. This W for T strictly bigger than S is indeed the solution to the Hamilton-Jacobi T V. So maybe I should write the Hamilton-Jacobi equation here for the reference. And we are also interested in the evolution of the inclination and then it reads like this. So this W would be a fun method solution here, though for if you put some natural condition on it. If you put some natural condition on L, then this solution when t reaches S is often infinite off of some point. So you see the starting point, so maybe I should draw a picture. So here, this is the time S and here, time t. And you fix some Y here, and given for Y, you build a fundamental solution for the equation. So the fundamental solution depends on your choice of Y and choice of S. Of y and choice of S. And that involves path that reaches point X at time t. So this is indeed given Z and Z consists of your choice of Y and choice of S is indeed the solution to this equation. And if you differentiate this W with respect to position, that would yield the corresponding final result to this differential equation. Yeah? Make sense? And with the aid of the fundamental solution, you can talk about general solution. This representation for general solutions. You give me an initial data, I add it to this fundamental solution, then again this is a solution, you maximize. So this is already a maximization problem, you have another maximization on top of that. That would yield a formula for general solutions. For general solutions. Now I'm going to discuss special family of solutions that you get by so here Y varies in R D, but I'm going to restrict Y to a discrete set. So maybe I should give you an example. If H X T rho depends xt rho depends on rho only, then this fundamental solution turns out to be very simple. The fundamental solution you get for given y and s is nothing other, you take the Loujon transform of this guy and then you write this over. That would be your fundamental solution. And you can differentiate it in the corresponding fundamental solution. Oh, I'm sorry, this is T minus S, and you differentiate. t minus s and you differentiate it then you get l prime x minus pi t minus s. But when the Hamiltonian depends on x times t, then this function is not explicit and it may have some non-differentiability point, which means m may have some discontinuity point. So keep in mind, but the kind of profile I'm interested in would be of this four. Namely, you restrict y to discrete sets. So you're dealing with discrete sets. Discrete set. So you're dealing with a discrete collection of fundamentals. So you should think of this as some kind of concatenation of fundamental solutions, just countably many of them. Alternatively, I can differentiate it. And the way to think about it is that you have this discrete set that will tell you where this y lives. Now, what happens is that in this variational problem, problem since I is the script select a y in i and ask yourself for what x the maximum is achieved at that particular y look at that set that would be some interval so basically what you have is that you have a partition so the way it works is that you have some kind of a partition of rear line or and if you have a scenario like Or, and if you have a scenario like this, then y is discrete. So, what happens is you have something like this. So, each piece corresponds to a suitable Y in that discrete set, and you basically have a partition of OR on each of which Y is constant. Alternatively, the way to think about it is that what I have here. What I have here is this fundamental solution that is evaluated, I mean for x and t is evaluated at y. Y depends on x and t. But this process y xg takes values in I. So this is as you vary x. So if I want to kind of plot the corresponding y, so there are different y's associated with different pieces. So it turns out that you have nothing other than, so if this Nothing other than if this is your why, you basically have a jump process. And this is the jump process that shows up here. If I say that these are the regions between the competition interfaces, that's the... That's right. That's right. Absolutely. So now let me say the theorem. Now I'm in a position that make a guess. I want to choose. I want to choose this by random. One way to do that is by choosing this random, because the rest would be a fundamental solution. So now I have this jump process, I want to choose it randomly. And if I'm lucky, the law that I choose for that jump process would be, for example, I'm going to assume that the jump process initially is Markov. And what happens is that at later time, What happens is that at later time, this picture persists. At later time, you still have a similar picture, but your jump process has changed, and you can kind of derive an evolution equation for the dynamics of this jump process. And you see why I'm choosing a jump process? Because a jump process can be described in terms of just one function, and that is the rate function. So let me select a candidate for For the rate of the jump. So here, let's say the initial time is t0. At time t0, I want to give you a jump process. So once in a while, you make a jump. But then when a jump is happening, there would be some y minus that is changes to y plus. So what I'm going to choose. So, what I'm going to choose would be a suitable kernel that says with want rate, at position x, you perform that jump. So given that kernel, I can define this jump process. And the claim is that at later time, you have a similar picture. Though the kernel now would be X would be xt y minus y plus. So there are two parts in this claim. The first claim is that the family of profiles that I'm presenting here is invariant under the dynamics of Hamilton-Jacobi equation. And the second claim is that not only that, I can derive an explicit evolution equation for this rate. Is there some reason to keep drawing at one of them? Yes, because you see here Yes, because you see, here is a viscosity solution, and it turns out that if I don't vary, you see, this profile depends on S and Y. For simplicity, I'm keeping S fixed, but I vary Y. If that is the case, then being viscosity solution is equivalent to say that you always jump up, not down. This is the usual jump condition that you have for driving the core. Yeah, well, I would say convexity. Yes, you're right. The convexity basically says, in fact, you can actually define a metric using that convex function, then it becomes fine on the party. Nice, I think you like to present everything as a metric. This is a good way of seeing that. Yes, thank you very much. All right, so now I have given an evolution equation for this G. The evolution equation looks like this. So. So again, G depends on all these parameters. On the left-hand side, I'm collecting the part of the evolution equation that depends on the changes in position and time. On the right-hand side, all the formulas depends on the nature of the jump you have. So I'm kind of like collecting it on different sides of the equation. This V hat is V, this is a typo. So I have to tell you what V is. So, I have to tell you what v is first, the v that appears on the left-hand side. So, as you can say, this is a kinetic equation, it's as if there are a bunch of particles that traveling with certain speeds. And what those particles are, so what happens is that all I need to do is keep track of the location of these jump discontinuities, meaning you switch from one fundamental solution to another fundamental solution. And then ranking hogoni. And then Rankin-Hagoniet, the analog of Rankine-Hagonier condition would yield this formula. So this is the Hamiltonian function evaluated at fundamental solution. There are two density involves. One of them is My plus and the other one is My minus. This is the Hamiltonian function and this is the speed. And this is the speed for which these guys travel. The speed would depend on position, time, and what the fundamental solution is, the value of fundamental solution. Can I ask you, are you claiming that it preserves the markup structure as you go for anything else? That's the most part of the claim. That's the most part of the claim. I mean, there is no reason whatsoever. Because you lose information. Indeed, you lose information. What happens is that when you see, you have this piece. You see, you have this piece. But when these guys meet, then this piece disappears. So things get simpler and simpler. But getting simpler means in this business the loss of information. Nonetheless, the Markov property is precise. And there is a reason for it, but I have to draw a lot of pictures in 35 minutes. There's no way I achieved that. Okay, so and let me tell you what Q. And let me tell you what Q plus and Q minus are. Let me start with Q plus. So right-hand side has two pieces. These are all quadratic operators. These are bilinear forms on G. So G plus, so for simplicity, I'm not displaying the dependence on X and T because the relevant thing for the calculation right-hand side would be what Y plus and Y minus R. So there is this term, which basically says to produce a scenario involving Y minus. Produce a scenario involving y minus and y plus. So imagine that this corresponds to y minus, this piece corresponds to y plus, and this corresponds to y star. So what happens is that you produce a scenario that involves y minus and y plus with these guys meeting and killing this guy. So this guy becomes irrelevant, this y star. And then for that, the relative speed when these two points meet is exactly this. meets is exactly this difference. That's the relative speed. By convexity, this is of definite sign. This is positive. And this is the scenario that somehow there's a claim here that this scenario you produce it by taking the product of these probabilities and that has to be this Markovian feature of this guy. So that's Q plus. Now, Q minus is just G times some linear operator. So everything is quadratic, so this L should be a linear operator. And this linear operator, Operator. And this linear operator is produced in the following way. So, first, if you give me a kernel G, this kernel depends on y minus and y plus. But this kernel has two information. What information? One information is that how long I have to wait to perform the jump, and the second information is that when I decide to jump, where I'm jumping to. But to calculate the rate, the waiting time, you give me a kernel. I have to average out y plus to figure out. Y plus to figure out the rate of the waiting time, the intensity of the waiting time. So, this operation, when you integrate out y plus, is very relevant for our purposes because we are dealing with this time-continuous Markov check, Markov process, jump process. I mean, when I say time, time here is a position, it's not time. So I'm varying X, and that's a jump process. So that's why this operator is relevant. Is relevant, but you started with a kernel involving y minus and y plus. When you perform this, now it's a function of only one y. But out of that, you build something that depends on y plus and y minus in this manner. There are two relevant kernels here. One of them is the kernel G that is relevant. The other relevant kernel, because of all these speeds, is V times G. This speed times G is another relevant kernel. So what happens is that Kernel. So, what happens is that you take the average of either g or v times g and you build this difference. And that's exactly L that appears here. Yeah, make sense? Now you understand why I decided to prepare the slides. That's not typical of me. The reason I figured that if I want to write this down, that would take 35 minutes. Then the talk is over. Okay, so that's. Okay, so that's dimension one. Now I want to switch to higher dimension. You see, I should mention that many of these works when you plot X and T, there would be some tessellation that emerges. Now, when you go to higher dimension, this tessellation business becomes very relevant. In fact, this you can translate everything to having a tessellation, this tessellation is evolving with time. You want to select this tessellation randomly and you want to keep track of the randomness of that tessellation. And when I go to higher dimension, that would be. And when I go to a higher dimension, that would be very relevant. So now I switch to a scenario when the dimension is bigger than one, but Hamiltonian is independent of xt for simplicity. And even the initial condition I'm going to assume is convex. So h is convex, g is convex. Now, if you give me a convex function g, a convenient way of representing this convex function would be as a supremum of a bunch of linear functions. And in fact, Linear functions. And in fact, you can, if g is convex, I can choose this h to be Logan transform. Now, there's something true about the Hamilton-Jacobi equation when you write it this way. So when this is the case, when you examine this differential equation, there's something true that it says that if you start with G that is convex, then UXT, you can actually. Then UXT you can achieve it in a very simple manner. So this H that is featured here is just a matter of adding this linear factor to it. Just a matter of retracing. However, so it's as if the dynamics is trivial, but there is some non-triviality here that you have to keep in mind. You see, this G is convex by Logan transform, you can represent it this way with this H to be Logan transform of G, which is also convex. However, when you go to this expression, you represent the concept. However, when you go to this expression, you're replacing this H of rho, you're replacing H of rho with H of rho minus T H of rho of the other H, uppercase H. See, this guy is convex, but the difference, since the other H is also convex, the difference is not convex. So when you look at this formula, even though what appears here has a very simple dynamical description, but there's some convex halt operation is going on. Hold operation is going on here. In other words, this is not the Lejeune transform of the function u, because this is not convex. And it is this convex hull that is a non-trivial part of the dynamics. And looks very global. But part of the business here is that to come up with a local description of this, which boils down to the analog of the dynamics of these shock locations, whatever it means in higher dimension. An important observation is that you start with initial condition which is convex. What you get at lead time is still the supremum of a bunch of linear functions. So what you have is indeed a convex function now in x and t. And then, as before, I'm going to focus on a scenario when this supremum is over a discrete set. Put it differently, I'm going to choose G, that is P. I'm going to choose G, that is piecewise linear convex function. That is equivalent to say that this maximization problem, the family of lines that you are maximizing, you have a discrete family of lines. So everything is discrete. Then at later time, the same thing happens. So the set of piecewise linear convex functions is invariant under the dynamics. And then later on, I'm going to put a probability measure on this. Okay, so let me... Okay, so let me. Oh man. Okay, so alternatively, the way to think about it, so let's look at, maybe I draw a picture. I mean, okay, this is another picture. Again, I took it from Google search. This is the result of Google search. Okay, so here is an example, forget about dynamics for now. Forget about dynamics for now. Let's develop some understanding about piecewise linear convex functions. So, this is a piecewise linear convex function, and this is dual, his Legend transform. Both of them are piecewise linear constants. So, what happens is that this will yield a tessellation. Each cell of this tessellation is the one for which the function above it is just a linear function. So, this on the top of this tessellation, you have to take into account this low. You have to take into account the slope of the graph above it. So basically, you have a tessellation, and for each cell in the tessellation, you attach to each cell of the tessellation a vector, which is the slope of this plane. So this is like a decorated tessellation. Every cell is decorated by a vector alone. In the dual formulation, this slope, the whole slope becomes a vertex. And each vertex here becomes the slope above here. So that's the duality. So these two graphs are dual to each other. And, you know, this is not a graph, it's a graph that is also decorated by vectors. But then, you know, and when you decorate it, it's called Laguert isolation. So here, indeed, you have a Lager tessellation. And it turns out, generically, the degree is always D plus 1 if you have dimension D. So the degree is always 3, generically. Is always three generic, which, when you go to dual, it gives you a triangulation. Because the number of adjacent cells here, that would be exactly the number of edges here because of the duality. So this is like a typical picture you have. And for example, to give you an example, if you choose H of rho. If you choose H of rho, this H that I mentioned before, quadratic, then this is the celebrated Voronoid tessellation. In fact, I can kind of plot the graph and its dual, and then the vertices here would be in the middle of the cells. But in general, that would not be the case at all. Now, when you study the dynamics, what happens is that, let me go. Is that let me go here? Let me go to this picture. I don't have to write anything, so I'm going to just play with pictures. So you see, now you start with an initial condition that looks like this. This is the initial condition for your Hamilton-Jacobi equation. And you let it evolve with time. So what happens is that the cells start to move. But the way the dynamics works is that if you have a cell, the angles do not change. So all these edges, they move in a parallel fashion. All these edges they move in a parallel fashion. So the cells stay put for a while, but since the cells stay put, that means these vertices stay put for a while. And what happens is that that means the triangulation stays put for a while locally, but then the triangulation may change to another triangulation without changing these vertices. Vertices are stayed as. Changing these vertices. Vertices stay the same. You switch from one triangulation, once in a while, you switch from one triangulation to the other. So it's important to understand the space of all possible triangulations when all the row i's are fixed here. When the vertices are fixed, what becomes relevant is that how the space of all possible triangulations look like. And it turns out this is a well-studied topic in combinatorics. And this is known as Gelfan. And this is known as Gelfan Kapranov-Selevensky. Hopefully I said it correctly. What happens is that if you give me a bunch of row i's and look at all possible triangulation, there's this huge polytop for which the vertices are exactly the different possible triangulations. And what happens is that when the triangulation changes When the triangulation changes, you have something called the circuit, and the diagonal is you kind of switch from one diagonal to another diagonal. Let me see, what can I say now? Oh, okay. I feel that I am carrying a bottle anymore. Any moment. I kind of explode in my hands. I mean, this is like my life aside. I mean, all the lectures that I gave, all the courses that I thought, graduate courses that I had no clue, but I decided to teach it. Decided to teach it. I force myself to learn it. It's just something to say, oh my god, I have to learn that thing, and that's next week. And then I do nothing, and I say, oh my God, tomorrow, I mean, the bomb is exploding. Then I force myself to learn it. Okay, so this is the dynamics. The diagonals are swapped. Maybe I should go... Okay, let's go to pictures. I'm not going to do anything, but just playing with pictures. But just playing big pictures. Okay, so uh since I don't wanna um take uh someone else's time. So let's look at this picture. So I'm kind of here plotting the the red is the original tessellation. Oh man, I get that. And the black is the dual. So what happens? Let's look at this triangle. So you see the silk. This triangle. So you see, the cells could be a different type, but let's look at this triangle. What happens when you have a triangle under the dynamics, the triangle is going to shrink. And what happens is that eventually this triangle is going to collapse. When the triangle collapse, then the triangulation you have changes. And you can kind of figure out exactly the time of the collapse. So there are kind of like combinatorial calculations that tell you. And that time, the speed of the speed of The speed of this phenomenon, this is the analog of Ranken-Hoganiett condition. You can work it out. So, in terms of the triangulation, what happens is that you have one triangle and then there is a vertex inside and this triangle, you have like three triangles inside one triangle. So, what happens when this triangle collapses, then for the dual lattice, all these guys disappear and this triangulation simplifies with this vertex. Simplifies with this vertex becomes redundant. And again, let me finish by saying that in dimension two, we know of a way of putting a probability measure on the space of all possible triangulation or all possible tessellations, the probability measure that is invariant under the dynamics. And that probability measure involves a kernel that says with what rate you make you cross an edge in this tessellation. And then there is a kinetic. Escalation. And then there's a kinetic equation to derive for that, for the evolution of that rate. So maybe I stop. I managed to finish. Questions? So if you if you're in higher dimensions and you've got something in non-convex, do you have any other practices that you have? Um well, certainly I don't know how to treat that. Well, certainly I don't know how to treat that case if the initial condition is not convex. Not yet, but it's not helpless. You see, the result that I mentioned in dimension one, there is a good chance you can extend it to a higher dimension. The difference is that the tessellations, they are not going to look like that. Everything would be curved. So it's a matter of kind of understanding the dynamics when things are curved. So it's not helpless, but I'm not there yet because this. But I'm not there yet because this already requires a lot of conjecture though. Say the end. Is there a conjecture? I would say what we have in dimension, okay, so in higher dimension, whatever formula we have for this should be true in general. There is no problem with that. The only thing is that all these coefficients become kind of more complicated. So that's a conjecture. In dimension two, I do have a conjecture. But in higher dimension, I don't have that conjecture because it's a solution. Have that conjecture because it's a solution. First, I have a hard time to visualize it. Drawing tissue is much harder. And I think you need to develop some new ideas to derive the formula. But dimension two, yes, there is a package. I was wondering, in the first one, B is one part, where it is G that balls and the derangement. Can you be explicit when each row is less than a half row squared? That's the sample you made? For example, you made you think what's going on there? Is it trivial? Oh, oh, you see, no, this is true for any age. I understand, but in the quadratic case, no, I mean, it's just a matter of the Rankin-Hoganier form, you know, simplifies. So, for me to gain more understanding of what's going on, could you make it explicit in that case what this G would be? Oh, no, no, you mean, do I have an explicit formula? Okay, that's a very good question. That's a very good question. So, in general, there is a kinetic equation. I think I can formulate it differently. Can I solve that kinetic equation explicitly? It boils down to solve that kinetic equation. So, my G satisfies the kinetic equation. Okay, in one case, I know how to solve that equation. And that case, so I think that's a very good question. So, if h of rho is one half of rho squared, so imagine. So imagine that initial data doesn't look like this, but imagine the initial data is white noise. So imagine you have Berger's equation with white noise initial data. It turns out that back derive an explicit formula for that Markov process at random time. So you start with white noise initial data, immediately becomes one of these guys. One of these guys, immediately becomes one of these guys, and he derived a formula. However, one can check that formula satisfies the kinetic equation. In fact, I can reprove a theorem using, by proving that this Markov process, you can establish a central limit theorem that says that this Markov process after scaling goes to white mouse. So it would be classical central limit theorem for Markov processes. So why did you, in what context did you? Why did he? In what context did he do this? So he was interested in a problem that has nothing to do with these things. He was interested in the following problem. Imagine you have a Brownian motion and you add a quadratic function and you take the convex hull of it. That's equivalent, if you use Lag's Hall formula, is equivalent to what we have here. There's also work by virtual analysis, right? When you have. That's different. Initial data is not white noise, the initial data is Brownian motion. Brownian motion. You also get a Smallhofsky equation. You see, that's a little bit different because there's some information coming from infinity. That changes, there would be an extra term in the kinetic equation to take into account some information coming from infinity. Yes. Because Bertoin, what Bertoin has at the time is not piecewise Markovian process. It's a more complicated process. So it would be some kind of legisl process. Let's put it this way. Levy process. Let's put it this way. It's a Levy process. So, and then there are all these small jumps. And it turns out that some jumps coming from infinity because the speed would be somehow infinite. So there would be an additional term in the Kinetic equation. Actually, there is some story behind it. So when I was trying to establish this conjecture of Menon Sei Mibasa, I had a proof, but the proof didn't match with my intuition. didn't match with my intuition because the term was missing. Because what I had in mind was Bertrand's formula, not their formula. It took me a while to realize that these formulas are not the same because there's some information coming from infinity. But in spirit, they're the same. Yes? All of this is on the line, right? So if you do things with boundaries? Okay, so that's a very good question. So you see, boundary here, I haven't. Okay, so that's a very good question. So how do you prove that? So that's a very cool question. So how do you prove that? I cannot prove it in infinite line. That would be very hard. So first I do it in finite interval and I put a suitable boundary condition. What happens is that because of finiteness of speed of propagation, if I'm interested in this interval, if I do it in a large interval with some boundary condition, decent boundary condition, it would be irrelevant. However, there is a suitable boundary condition you can choose when no matter what the length of interval is, all these measures are consistent. These measures are consistent. In fact, that's how we prove theorems in higher dimensions. It's like a Gibbs measure. First, we build our measure in a box, but it turns out when kinetic equation satisfies these measures you construct in these boxes are consistent. The consistencies of these measures is equivalent to that kinetic equation. You don't take the special boundary condition that works? You know, then it's still a good question. Right, you see, there's some subtlety here. This may not work. This may not work. The reason is that if you're not careful with the boundary condition, the information coming from this model, the information coming from the right would not be independent of the information gathered inside. So I choose the boundary condition so that they're independent so I can handle it. Otherwise, I'm not sure this Markovian structure persists. And things may not look like this. Actually, most of the subtlety is choosing. The most subtlety is choosing things in such a way that this Markov process, the boundary condition, is existing. Anybody needs to yeah, and then we'll postpone the talk and start three part. 