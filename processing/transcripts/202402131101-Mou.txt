Okay, so let me start. Hello, everyone. I'm Ven Long. So, today I'm going to present a very simple trick in regression adjustment that actually works. So, usually, even for 30 minutes talk, I won't present the technical detail, but this is a really nice piece of work that I really like. And I'll present, hopefully, I'll let you understand the technical. Understand the technical detail, even with only 10. This don't work with my wonderful collaborators, Bongo, Pon, and Martin. So we work with a very simple and very standard setting where you have a queries collected from the users and you have potential outcomes. So we are in a standard, a potential outcome model for causal inference. And all these things are deterministic, but we cannot observe. But we cannot observe all the potential outcomes. What we can observe is random. And the only randomness in our model is our treatment. So basically, you assign random treatments to our patients or to our users, and they observe one side of the potential outcome. So our goal is also a standard one to estimate the average treatment effect. As the name suggests, average of the treatment effect. So I do have. Effect. So, as you can see, this has a lot of applications. In medical data, you assign treatment to patients. In A-B testing, when you are dealing with digital marketing, you buy this kind of new advertisements to new users. And for these two applications, as you can see, it is very unreasonable to assume that your patient's data are IIT, but it is very reasonable to assume that the treatment. Assume that the treatment gives them our IID because it's under your control, you just randomly assign food. So, we want to do good estimation under this model. A very simple estimator is a difference in mean estimator. Recall that eventually we adjust the average number, so we right only just take the sample average. And it is an unbiased estimator. You can calculate variance. Its variance basically depends on some error, like. Uh, some like error norm of the outcomes. Uh, so basically, the formula is not really important, but basically, it's a uh, it's a like magnitude of the potential outcomes. So, that's it, in the talk. So, if I end the talk now, it's neither trust-worthy nor machine learning, right? So, we need to do something better. And actually, uh, in history, there are people doing something much, much better. So, suppose that, you know, Suppose that in an idealized setting, if someone gives you an oracle, if you dream of a function that approximates your potential outcome well, so then this could use this estimator. You can think of it as an oracle estimator. In general, this X star is unknown, but suppose that you know some F star, you approximate this guy, you basically can take this formula. The formula looks like complicated, but it generally what it does is to But essentially, what it does is to keep unwrittenness while minimizing variance. So it's similar to double machine learning estimator or W robust estimator in the observational study setting. And the important thing is that this oracle estimator has varies depending only on the approximation error of your oracle function instead of the actual magnitude of the outcome. And the approximation error can be much, much smaller than by itself. So, in practice, we don't have articles, but we are statisticians, we are not afraid. And in particular, this data to the very beginning of the statistics feature proposed using this regression adjustment estimate. Basically, you just estimate those functions using our data. You have the data. You feed this oracle function on the treaty side using our treaty data, and you feed the oracle function on the control side using a control data, and then you bug me. Control data, and then you've done it. That actually works at least the agent problem. So, how about non-attempting? Actually, in order to achieve such an improved efficiency bound, people have developed a non-attentive theory for that. And the most annoying fact is that it requires more samples than what you already believe to be the necessary sample size. For example, if you are dealing with like linear regression adjustments, you need dimension square instead of You need dimension square instead of dimension in order to get good results. For sparse, you need I square. And there are also people even with non-permission estimators, and it only work for Docker class. So it's relatively restrictive. And nowadays, people want to use deep learning for regression adjustments. And for deep learning, there's really no guarantee at all. And things can go very well. So what's wrong with regression adjustment? What's wrong with the regression adjustment? So, actually, if you inspect this formula a bit more carefully, you'll see the issue. We use the data for both fitting the functions and taking the average. We use the data twice. And this leads to correlation. So that if you just plug in this formula, this is a bias that's mature. And indeed, it has been observed that this bias can be significant if you are dealing with, if you are using complicated Dealing with if you are using complicated machine learning model, like even for linear regression, if you have a like dimension relatively high, actually your residual term can be dominating because it's still of linear dimension. And people have developed a lot of devising methods to improve that. And sometimes you have a like improve the sample complexity, sometimes you need some stronger assumptions. That is not important. But if you look at deep learning, things are even more complicated and the issue with regression adjustments is even more severe. With regression adjustments is even more severe. It has been observed in fact that deep learning can perfectly treat feature training data. And what if you use an estimator that perfectly fits training data in regressional documents? And immediately we will find that if you use such an interpolation estimator, regressional document becomes outcome regression, just becomes fixed, fixed this fixed function and fixed the average. That did work well. Now we did a simulation study. We did a Now we did a simulation study. We did a we uh we actually simulated with a very simple like interpolating estimator. This is not really for deep uh this is not really using deep learning. We are using a like simple interpolating nonfilmatic estimator that achieves optimal mean-max rate. And as you see, basically the regression admin estimator is risk in this green line is even much, much worse than the difference in the estimator indicated by this blue line. This blue line. But on the other hand, our estimator indicated by this random actually achieves the desired property achievable by the oracle estimate. So what is our estimator? So let me tell you, I'm going to introduce this idea. It's every very, very simple idea. That's a high school math. So what is happening is that you use the same data twice. And when we go to TQer, a very naive idea is that if you A very idea is that if you have IIT data, for example, if you are doing this observational study, what you could do is to sample three. You just use this strong subset to split your data and tweak the average. But this idea does not work in finite population, in this randomized control experiment setup, because this randomness and this randomness are dependent. If you know which part of the data you are using to fit a function, it tells you. Of function, it tells you something about which part of data you are using to take an average because they are mutually excessive. So that doesn't work. But actually, it's easy to see that there are five things that works. You just take two independent subsets. And if you take two independent subsets of this finite population, we know that the cipher basically must overlap. And indeed, what we do is we took. And indeed, what we do is we take two overlapping substance. For example, if you have like one half per weight of getting treated, why don't we take like one minus one by root two data to take a portion of the data to take the average and one minus one by root two portion of the data to see the function. And we just do them independently. And that's why the treaty is that, but we can also do the same thing for true side. And basically that is my already done. And actually in general, you can take with forbidden pi r, like you use the data to see the function, with probability pi m use the data to take every. And importantly, you make the two sequences independent. You use the fortitude side and do the same thing for compute side. And this is our final estimator, the decorrelated workshop for regression adjustment estimate. Related version of the regression adjustment estimator. This estimator has an important property. If you take an expectation, it is unbiased. And this unbiasedness is regardless of the type of function aspect you use. And actually, we can show from theoretical results that basically, if you have a black box estimator for F, you use arbitrary f pet. And if you can show that under If you can show that under a sub-sampling model, if you have this final population and you sub-sample and you use this sub-sample to estimate that function, if that under that model, you have achieved some estimation error guarantee, then automatically it translates to guarantee under this for this regression adjustment problem. So this is a rescale error. This is the square root n times the approximation error of the regression adjustment. Problemator error of the regarding adoption estimator to the order of estimator, which is what we want to achieve. And all these terms are of order a little over, as long as we get like consistent estimator for this endless subsampling model. So this ep n of pi r is basically something going to zero based on consistency. And we can tune this pi r to make the second term smaller as well. And basically, we don't need n larger than b square, we don't need n larger than l square in the sparter details, and we don't need dump per class, and we can even apply this to deep learning as long as you can see that you can get low testing error. And the pi are can be selected based on the trade-off of these two terms. And we also don't have time to discuss inference, but based on this point estimator, we also have an inference. We also have an inference result satisfying similar guarantees. And as I said, it applies to a lot of examples with optimal sample complexity and minimal assumptions. So basically, this is the right regression adjustment estimator that people should use. And hopefully, see this being used more in practice. Thank you.