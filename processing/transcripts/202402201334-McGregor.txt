Try again. So plug it. Plug it back in. Now we're good. Good. So our first talk in the afternoon was given by John Fray McGregor and he's going to talk about conservative commentaries. A conservative commentarium. Thank you very much. I'll start by thanking the organizers for having me and thank you, the chairs, for keeping this running on time so well. I thought yesterday's chairing was particularly spectacular. I've never seen anything like that. And maybe inspires me to change how I do it in the future. It was pretty cool. And thank you for all the speakers. I don't know a lot about this field. It's been really nice to have your talks be somewhat inclusive to everybody and be accessible. To everybody and be accessible. I felt like I've kind of got the big picture for most of these. So, thank you very much for all your effort there. So, I'll be talking today about conservative Hamiltonian Monte Carlo. This is joint work with Andy Wan from the University of California Merced. I'm from the University of Toronto. And let's get started. So, I will be talking about MCMC methods, HMC methods, and an extension that we're making to that that we're calling conservative Hamiltonian Monte Carlo, Johann Maus. Carlo and Johan Maus. And then we'll present some numerical results. So what are Markov chain Martikala methods or MSC-MT methods good for? Well, they let us sample from probability distributions, right? So hopefully this is something that you know a little bit about. If not, maybe this introduction will get you partway there. There are obviously numerous applications: statistical mechanics, simulated annealing, uncertainty quantification, and a big Uncertainty quantification and Bayesian inference is really the main one. And there has been some recent work on score-based generative modeling, which I think I missed a talk about earlier because I was just coming from another conference. So I'm sorry about that. But the main way that this works for MCMC and Bayesian inference is you have your posterior distribution, and this is the object that we want to sample from. This is the object that all the information is stored. And you can use And you can use Bayes' theorem to break this up into like within the prior. And the main things that we're really interested in in the future, and that maybe ties in here as well, is really parameter estimation in your ODE and PDE models. So the way this works, it's actually quite intuitive. Suppose that you have something you're trying to model, maybe a chicken pox, right? As mentioned earlier today. So you have some model that describes chickenpox, but maybe there are some parameters in that model that you Some parameters in that model that you aren't sure how to fit, and you have some data. So, what you do is you make some onsets about the noise. Like, okay, this really is describing how chicken pox evolve, but the data is just noisy. So, you make some onsets about that noise, and then that ends up plugging into your likelihood, basically. And for every choice of parameter, you run your simulation, you miss the data by some amount, that's the Gaussian noise, and it gives you an output. And you repeat this process every time you are generating a sample. Every time you are generating a sample. And then over time, you can use those samples to compute things that you want, like means and variances and so on. And you can even be certain about how accurate this is, because in the Bayesian framework, you're building the entire posterior, so you have this uncertainty quantification. So a little bit more detail about how this works. So again, we're starting with this target distribution. I have a light that we're calling pi. And MCFC algorithms try and generate. Algorithms try and generate samples from this distribution. Of course, if it was easy, just given a distribution to just draw samples from it, then there wouldn't be much to talk about here. But the challenge is it's really hard to do that, right? If we're in 1D and you have a Gaussian, yes, there are direct sampling methods that are really, really efficient. But those generally don't scale very well to high dimensions, and that's really what we're focusing on. So you have to come up with sort of interesting ways to generate these samples, and that's what MCMC does. What MCMC does. And if you've generated your samples properly, as in the way you're bouncing from point to point is done correctly, then you're going to have that the target distribution is your stationary distribution. And so if your transition kernel here, this row, satisfies this integral equation, then you are doing it correctly, right? You are transitioning from sample to sample properly. And then doing this process is like just sampling directly from the distribution. So it means you've done it well. If this equation looks a bit confusing, It well. If this equation looks a bit confusing, I think the finite dimensional case is far more intuitive. So in the finite dimensional case, your row here is a transition matrix, right? And then your stationary distribution is the eigenvector with eigenvalue one. So really what the problem is, is can we come up with the transition matrix that gives us the right stationary or eigenvector? That's kind of what we're doing. And this is just a generalized continuous version of that. So why do we do all this, right? We talked about the modeling reason to. We talked about the modeling reason to fit parameters. We talked about drawing samples from the distribution being hard. But if you can do this, if you can come up with this sequence of samples that are drawn from the distribution, essentially, then we have the Markov chain central limit theorem, which says we can compute these integrals, which are expectations. So that's our mean, that's our variance, by just taking basically averages. So it becomes very easy to get means, very easy to get variances, once you have these samples generated. So the interesting part comes from. So, the interesting part comes for free at the end. The hard part is generating these samples, and that's where the work of MCMC comes in. Okay, so the most basic MCMC algorithm, the Metropolis algorithm or Metropolis Hasting, is a random walk model. It was very effective and it solved a lot of problems back in the day. And I don't know how much it's used now. Maybe in certain situations, it's the only thing that's accessible. But the way I But the way it works is as follows: You start at some point, you're in that space, maybe it's the space of all the parameter values you could have chosen for your model, right? And then you draw a proposal from a normal centered at where you are in the space. So that's easy to do, right? We know how to draw from Gaussians, so we're fine. And then you accept that with probability given by the min of one and the ratio of the PDF, so the density value at the proposed point divided by the density value at where you were. By the density value at where you were. So if you propose a point at a higher value, you always go there. So you can see you're going to tend to go towards the peak, which is what you want to do. And then if it proposes a point below, you only accept it at some probability given by this ratio. So it tends to not want you to go downhill, it tends to want you to go uphill, which is what you want. So of course, if you accept the probability alpha, you reject the probability one minus alpha. So it's a very simple algorithm. You can extend it where you have like, you know, non-symmetric proposals. You have, like, you know, non-symmetric proposals and things. That's the Metropolis-Hastings algorithm. But there are problems with this basic approach and why we need more sophisticated algorithms. So as the dimension increases, you get a lot of rejections, right? So we're going to talk more about this, but when you get to really, really high-dimensional space, most places you look aren't where you want to go. The places you want to look are very narrow, thin strips. And so if you're drawing from a random, you know, Gaussian, a normal distribution center at your point, Gaussian and normal distribution center at your point, most likely you're not going the right way. So that's why these things tend to do worse and worse and worse as the dimension gets high. But as the dimension gets high is really where we need MCMC. So that really we need a more sophisticated approach. There's also this long burn-in period, which is really, it's something that happens for all MCMC methods, is the first chunk of the samples you generate, you tend to throw away because they're kind of converging to the right point. And then once they're in the right regime, then you really start looking at. Regime, then you really start looking at those samples and using them for calculation. So, to overcome these issues, in 87, Duane and Neil in 94 had this idea for Hamiltonian Monte Carlo, and it does overcome many of these issues. And it's actually just a really beautiful, beautiful method that I want to talk to you a little bit about. So, same setup. We want to sample from this distribution. What we do is we take that distribution, pi, we take the negative log of it, and then we add this one half t transpose mm was p. And what we have generated here is a Hamilton, right? We have our kinetic energy, we have our potential energy. So this variable we add is like our momentum. And we can get back to where we start by just marginalizing out by the momentum. You just integrate that out, and boom, you're back where you started. So we're not really changing anything in a damaging way. It's just an extension that we can then work with the Hamiltonian. That we can then work with the Hamiltonian, and maybe we can extract some advantages there. And then we can pull back to the original distribution whenever we like. So, this is the idea. So, how does this algorithm work? So, instead of drawing the point you're at and then doing a draw from a normal, you actually, you know, you are where you are, maybe you have to start somewhere, but you draw momentum, and that momentum is drawn from a normal distribution. And then you traverse the. Traverse the well, two-dimensional or more-dimensional in general Hamiltonian system of differential equations. And then you integrate along that for as long as you see fit based on the parameter choices you choose. You stop at some final time t, and then that's your proposal. So we're not proposing by drawing from a normal, and that's your proposal. We're drawing momentum traversing a level set, and then that end of the level set, wherever we want to stop at, that's the proposal we make. Proposal we make. And so we have choices for how long we integrate for, we have choices for the step size that we use. We also really have choices for the method that you use, even though typically one method is the gold standard here for HMC. But there have been some pretty significant improvements to how you choose these parameters. For example, no U-turn lets you play with that final time to really optimize how you do things. Come back. On that, or not? It did move. It's a good sign. Okay. Maybe I breathed on it too much. Okay. So putting all this together, again, we're integrating all the level sets, we get the algorithm. So this looks a little bit different from the metropolis algorithm, but it's a lot of similarities. There's our momentum, where we start, there's our momentum draw, starting at where you're going. Starting at where you're centered. And then HMC is going to use the leapfrog integrator to traverse a level set. You're going to accept with the same probability, except now, because we took negative log of our distribution, it's the exponential of the negative of the difference in energy. And this is the same thing as the ratio of the energy where you end divided by the energy where you start. You just get this difference here in the exponential. And so you accept with probability. And so you accept with probability alpha. So this is actually really good news, right? Because if we're traversing level sets, hopefully this difference in energy is not too big, right? So hopefully we accept quite a lot. Now, in more detail here, which we're going to revisit, really the acceptance probability has a determinant of the map in it. But because leapfrog is symplectic, it's area preserving, so that actually that becomes a one, so you don't have to worry about that. That becomes a one, so you don't have to worry about that. So, there are probably many reasons why leapfrog is a good choice, but that is a very attractive feature: the fact that you don't have to compute the determinant of your capacity in every step, right? That would really be a painful thing to do. So, there it is, and you can actually do by backward error analysis that the difference in energy here is big O tau squared, so your time step squared. So, you really do have control over the acceptance rate by choosing the right time step. And this is pretty clear by just. And this is pretty clear by just visualizing what's going on, right? So, this is a little picture from this nice article in 2017 where this is where we start. So, we draw momentum, we got to here, we follow a level set, you propose that point. If your time step was small enough, you stayed very close to the level set. The proposal is given. The energy change is very small, so you accept with very high probability. You draw a new point, and you continue. So, you're just traversing these level sets now. So, this looks very different from the picture before, but this makes a lot of sense, right? But this makes a lot of sense, right? Like, you could propose here, and as long as you have good energy error, you could propose all the way down here. And there's really no reason why you should reject it at a high rate. Remember, the problem with Metropolis was you really can't propose points far away because you really have no idea if you're going in the right direction. So it's very likely you're going to reject points that are far away. But here we're able to propose points far away and still maintain a very high acceptance rate. So this is a really, really good feature of traversing level sets of the Hamiltonian system. Sets of the Hamiltonian system. So I've described how we're going to generate these samples, but how do we know we get the right thing? So we talked about stationarity, right? You need stationarity for the samples to be producing the right thing so that we know we're going to get the right answer when we do our expectations and such. So how does stationarity work for this? Well, we have our leapfrog map. We need to define this momentum flip. It's purely to make the proof work. It's purely to make the proof work, even though in reality this really doesn't make any difference, but you need it there for the math to go through. And you define your transition kernel. So this is how you go from one place to the other. And this looks complicated, but it actually makes a ton of sense. So how do you get from Z to Z prime? Well, you need to propose Z prime from your map, right? And then you need to accept it. So that's this first term. Or you reject it. You reject it, and then the momentum flip brings you back to where the z prime is. Those are the two ways to get there. The momentum flip, I didn't really describe in detail, but this is the step you have to do to make the algorithm work. Those are the two ways to go from z to z prime. So this actually makes a ton of sense intuitively. And as long as you use this r reversibility property, you can just basically multiply this by pi z, integrate over all of R2D, and it just pops out essentially with stationarity. Essentially, with stationarity. So you don't need to do any detailed balance calculations. It really can just follow directly from the integral. And even though for this particular example, we do have detailed balance, but the method actually holds more generally, which is very nice. What is R? R is the momentum flip. All right. Yeah. So again, I didn't really describe why you need to do it. And in reality, R doesn't actually really do anything because pi of R is the same as pi. So often you Same as phi. So it's often your way you've defined your distribution, switching the momentum doesn't change the value. So really, it does nothing. It's really just a mathematical requirement for everything to go through. So there is actually this one issue with HMC, which is that as the dimension of the problem increases, the smaller your time step needs to be to maintain a constant acceptance rate. And it scales with the dimension to the negative. And it scales with the dimension to the negative 1 over 4, which kind of makes sense, right? We talked about high dimensions make things worse. And that is what we're observing. So, as you can see, if we took a really, really, really big dimension, we're going to be paying actually quite a lot to do this integrator because our time slip needs to be so small, which is a little bit frustrating. So, this actually is what brings us to the conservative Hamiltonian Monte Carlo idea. So, there's something unintuitive that happens in high dimensions, as I talked about, where the mass really lies. Where the mass really lives. And we're going to look at an example here. This is the p-generalized Gaussian in Rd. And we have this lemma, which looks quite complicated, but there's a nice statement below, that tells us that the high-density regions live on a thin-piece spherical shell in Rd. So this essentially telling you the ratio of things that aren't in this thin strip divided by the ratio of things that are in the thin strip. And as you take the dimension to And as you take the dimension to infinity, or even very large, all of the density lives in this very thin strip of width 2 epsilon. So you can take epsilon to be very, very small, and all of your density kind of squishes into that as you raise your dimension. So this is actually starting to make some sense why HMC was struggling in high dimensions, right? So imagine this is our thin strip, right? At some point, this HMC is going to fall off that strip because it gets Is going to fall off that strip because it gets so thin, right? We showed that the energy change was ordered tau squared. So at some point, that strip is so thin that even if it's tau squared, it's going to fall off. So you've got to make it even smaller to keep staying on that thin strip. So the proposed solution is, what if we use a conservative integrator instead that's able to hug those corners and stay on this thin strip regardless? So an energy-preserving integrator versus a volume-preserving integrator. So again, these are the really the big ideas here. So, again, these are the really the big ideas here. This scaling with d to the negative 1 over 4 is coming from this fact of this thinning of the density strips in high dimensions. Okay, so this is our proposed conservative Hamiltonian algorithm. It looks almost identical. There are just two changes. We propose changing the integrator to something energy-preserving instead. But as I said earlier, there always should have been an. Earlier, there always should have been a determinant there. But when you go energy preserving, you're not really going to get volume preservation as well. So we need to have something here to take the place of the determinant of a Jacobian. So we actually say we're going to have an approximation of that determinant there. So we arrive here at a theorem that Andy and I put together, which says essentially for some map here. Some map here, as long as you're approximating the determinant by some epsilon, so you're close enough that, and then this is your acceptance with the approximate Jacobian, then you get approximate stationary. So really, this should be zero, right? You should have the integral rho pi equal pi, right? But we have this error term here. And I know this is going to make some people uncomfortable who are familiar with this, right? We always have exact stationarity. What do these guys? Have exact stationarity. What are these guys doing? Not getting exact stationarity. And we realize that's a thing, and we have to do our job to make sure that it gives us good results, right? We're not saying this is better by any means, but I think it's worth experimenting and looking at. And we can control this error, right? This epsilon naught, we're going to see, actually, we can make as small as we want. And the rest of these terms here are pretty nice. It's basically proportional to just the probability density and this determinant, which shouldn't be big. So if you actually have an energy-preserving integrator, it simplifies the extreme. Energy-preserving integrator that simplifies the expression a little bit, right? We get the epsilon naught here, which is the bound on our approximate determinant, and we get the distribution, and we get this max of one and the determinant, which really should just be one for the reasonable determinants, for close to one. So I'll give you a very brief discussion of how this proof goes with really very minimal detail. So there's this nice paper by Fang in 2014, and San Cerna, I believe, was on that. And San Cerna, I believe, was on that paper. And it was this really, really great thing. It's the first thing that we found that was anything like what we wanted to be doing. So, what they did is they just took this integral and just wrote it out. And then they actually used the full determinant. So, we're using an approximate determinant. So, there's some subtleties and some differences in the argument. But the idea is pretty straightforward, right? So, the first thing we're going to do is get rid of this one, because this one's just hitting the direct. So, if we use this fact that pi of r is pi, so when That pi of r is pi, so when we do the momentum flip, it doesn't change the distribution at all. This one just comes to the other side, and then here we are, right? We want this to be small. This is the rho z pi minus pi. So if that's zero, then we have exact stationarity. So what we're left with here is just these two integrals, which really don't look that bad. This is our acceptance probability, the distribution, and the Dirac. Move this out of the way again. So it's tempting to say, okay, let's integrate. Let's just take the Dirac. Okay, let's integrate. Let's just take the Dirac. Let's just take it and go from there. But the problem is that because of how this Dirac's defined and this one's defined, we're going to get a bunch of terms that don't mix very well. We're going to have a bunch of like pi or psi inverse z's around and we can't combine that with the other determinant. We don't really have our bounds on the determinant of the inverse of the map. So you need to go through a little bit more simplifying before we can do the actual integral. And it just comes from a change of variables. So you let z be simple. So you let Z be Ïˆ R V and use R reversibility, which we assume that the map has. And then you do a bunch of simplification, a bunch of inequalities, and then the answer pops out here. So you really do need our reversibility. Without that, you do not get the result. And without this change of variable, the right-hand side is going to look very messy, and you won't get this clean result. So we need an actual example now, right? Everything's been a very high level. We've been talking about Been a very high level. We've been talking about energy preservation, our reversibility, but you know, we need an actual map that satisfies this. So, this is the our reversible proposal with energy preservation that we propose. This is equivalent to the Aave discrete scheme, except it's a symmetrized version. We have the second term here. And we started off with actually just the one term when we first started with this, and things looked good, but it turned out it wasn't R-reversible. So, to get R-reversibility, you need to add the second term. To get R-reversibility, you need to add the second term. So that's what we call the symmetrized Ido-Abe scheme. And it's also equivalent to the DMM scheme with a single conserved quantity. This is an implicit scheme, so it needs to be solved by fixed-point iteration or some other means. So it is a little more expensive than leapfrog, but we've still been able to eke out advantages in many examples. So we think, like, the average vector field method and such could also work, right, for energy preservation, but we have to. For energy preservation, but you have to keep in mind you need our reversibility for that proof. So maybe there are lots of other options for energy-preserving schemes, but unless you can get our reversibility, that proof's not going to go through. So that might limit what integrators are possible, but this one certainly satisfies those criteria, and that's what these two lemmas say. So this is energy-preserving if you solve it exactly, and it is our reversible. And it's very easy to do. You literally just do exactly this, and it comes up with it, and it's not hard to show. Comes up with the identity. It's not hard to show. But, you know, like a projection scheme or something, I don't know how you would show a reversibility. You can do symmetric projection. Yeah, maybe. Maybe there's some things you can do, but we haven't explored if you're going to be able to get that or not. But we are certainly open to trying other integrators. And maybe ones that are even faster, right? Speed is obviously of very importance. So the next thing that we need is we need to make sure, let me go back quickly. Let me go back quickly. We want to make sure this epsilon naught term is small. Epsilon naught is how close we were in our Jacobian approximation. If it's not small, we're in trouble. So we need somehow to estimate that, and we actually can't. So you can take the determinant of that math, and you end up with some equation here after quite a lot of work, and you see it's one plus tau squared, right? And actually, this term here really isn't that bad either. Like, these two matrices are quite close to each other. Two matrices are quite close to each other, but it is a big O tau squared. So that actually goes to show that you can control that stationarity, which is your time step squared. So it's pretty easy to control that to be small. Quite nice. So the simplest choice that we could take was approximating the Jacobian with one, determinant with one. And the reason for that is we don't want to be computing this term every time, right? And we have tried doing that, and it actually doesn't give you a term. Try doing that, and it actually doesn't give you a significant advantage. So, it is not worthwhile investing the computation time to compute the second term for our epsilon not to be tau to the four. It just doesn't appear to be worth it. So, we use our approximation of one, which of course makes our approximation of the determinant tau squared. And we end up with this result here that the approximate stationarity is big O tau squared. And we believe that constant c is really not that bad. Not that bad. So, we're going to talk a little bit about some results here. So, we really want to test this idea of, before we go to high dimensions, let's test this idea about does energy preservation work on thin sets? So, we're going to start on a 1D problem. And as you see, this is the p-generalized chi-distribution. And as you raise this parameter d, we get much, much, much thinner. And so, hopefully, we see that energy present. Hopefully, we see that energy preservation, even in 1D, is able to eke out an advantage over the HMC integrator. So, the metrics we're going to use are the Kolmogorov-Smirnov, which is often caused, uses a test, but it also defines a distance. And it's an integral from negative infinity to x of the difference between your distributions. And then we have the 1D Wasserstein, which typically We have the 1D Wasserstein, which typically doesn't look like this, but in 1D you can actually write it down. There's this theorem, or this paper in 74, that as long as you're in 1D, the Wasterstein is actually not too bad to compute. And the F here is the cumulative distribution. So these are quite close, actually, even though they did give us different results. But between the Wasterstein and the Kolmogorov, we feel like we're doing a pretty decent job of testing how well these things are working. So, first thing that we're going to do is we're on. That we're going to do is we're on p is equal to 6. Here's our parameter choice. Let me go back, right? So we're going to choose p is equal to 6, and then we're going to vary the d, and we're going to see how the two methods work. So this is the histogram, of course. This is the PDF. So you can see things are getting thinner as we go from 400D, 800D, 1200D. And green is the energy-preserving Edo-Abe scheme, symmetrize. And blue is the leaf frog. So you can see in this particular example, So, you can see in this particular example, especially looking at the violin plots here, like there are many that leapfrog, it doesn't even converge at all, it's completely blowing up. And here, it's actually saying it's way too thin, so it's really not converging at all very well. But I mean, this is a hard problem, right? This is like finding a needle in a haystack. But as you can see, the energy-preserving integrator does a really good job of sticking to that thin distribution and staying on there. But you know, it's reasonable to ask, maybe these results are. These results are particular to a certain choice of parameters. You know, maybe we chose the right integration time and the right time step. So let's do our due diligence. And well, we're going to get to that. We change the order of one. So this is the same thing as before. We're doing the histograms. And this is just the convergence plot as we do our iterations. So this was the P equals 6 D400, this is the D800, and this is the 1200. The scales changed a little bit, but as you can see, there is just a massive separation here. Just a massive separation here. And the Wasserstein is the dotted line, and the Kolmogorov-Smirnov is the solid line. And these are just wildly apart. The blue is never even going to reach how good the green was even at the start. So very, very, very separate there. So now we're doing our due diligence and we are checking various parameters. So these are heat maps. We have a variety of time steps here from a half to 1/16th, a variety of integration times from 1 to 5, and yellow is bad, and green. And yellow is bad, and green is good. So, HMC with leapfrog is, as you can see, doing a really bad job of converging here in the Kolmogorov-Smirnoff distance. And the CHMC with Edo Abe is doing very, very well. And this is the Wasserstein. Black means it got mansed. So it really just blew up. And again, extremely good results here from the energy preserving over a variety of time steps and a variety of integrations. Variety of time steps and a variety of integration times. This is now we're varying the p and leaving the d constant. So we're going from p to 2, 4, 6. You see actually for the p is equal to 2, it is not as bad. It does a decent job, the HMC with leapfrog. But as you can see, as the p goes up, also it starts to really fall apart. And same thing for the washerstone. So the next big one is. So, the next big one is we're actually going to go to high dimensions. So, we're going to work with the p-generalized Gaussian, and we're going to work on the case that p is equal to 4. So, this is our distribution. And technically, this distribution should be equivalent to the one we just did, right? So, if you make a substitution here, you end up back with that chi-distribution, even though the results are really different. And it's a little bit of a mystery as to why these two distributions, even though they're supposed to be equivalent, Even though they're supposed to be equivalent, sample very differently. Leapfrog performs quite a bit better on these, so we have to go a little higher dimension to see the separation. But there's a little bit of a mystery in terms of why they are so different. Somehow the 1D version seems to be exacerbating the problem even worse than in the high-dimensional problem. But let's look at our convergence. So now we have three metrics. The straight dotted line is the covariance. The dashed line is the Wasserstein, and the solid. Washerstein, and the solid line here is the Kolmogorov-Smirnov. And we are here in D is 1024. You can see they're pretty close together. CHMC seems to have a very minor advantage in all three of the norms, but they're quite close to each other. And then as we start to increase, we double the D 2560, double it again, we're starting to see some separation to 10,240, 20,480, and 40,960. And 40,960, and it's not really slowing down. It just gets kind of annoying to keep computing things. But you can see the separation is getting quite dramatic. So, this is really reinforcing this idea that as we go to those high dimensions and as that density is thinning out, that the energy preserving seems to be doing a better job staying on those sets than the volume preserving integrator does. So, just to kind of wrap up here, a little summary of what we did. A little summary of what we did. So, we introduced this idea of energy preserving, this idea of approximate stationarity, and we've done some testing on it, as you've seen, but there's obviously a lot more testing that we plan on doing because it is a new idea to not have things be exactly stationary. We showed improved convergence on thin, high-density target distributions, both in one-dimension and high-dimensions. We showed robustness as we vary the time step and the integration time. And as we go forward, we And as we go forward, we want to improve the efficiency of the solver. So we are not attached to that solver by any means. This is not an ego abbey scheme that we were stuck to, but we want to use one that's going to be efficient and that is going to get our reversibility so this proof goes through. So I know there's some work being developed on explicit schemes that are energy preserving and so on. Maybe some people in the audience have some ideas as well. What we need to do are check to make sure we can get this irreversibility. To make sure we can get this irreversibility. We are very open to some ideas there to make this a really competitive method for people to use. We want to really investigate why. I mean, we have this good hypothesis and some results that sort of reinforce that idea. But maybe it'd be nice to prove that that constant in front of the 1 over root n is actually better when you have energy preservation. It'd be nice to actually do a proof in the details that we expect improvement on that convergence. Improvement on that convergence. And of course, we would like to combine this with machine learning approaches and Bayesian inference and start solving some real-world problems with this new integrator, a new approach to sampling. And yeah, maybe even some score-based generative modeling as well would be nice. So that's it. Thank you very much for listening and your attention. So I don't know whether this question is off-mark, but let's say that you use, so the reason that you use energy preserving is that so you don't hear off that much to the, I mean, you don't hear off on the energy shell. But what about the resulting distribution of the samples that? The samples that you get on this particular energy. Do you choose some delta t, and could there be some kind of systematic bias? So like, you know, with the fixed delta t, we don't really get, or how far are you away from, you know, the density or the distribution? So, oh, so you mean in the for the stationarity approximation that we have, we're not exactly there. So, you know, but this is something that we expected. We expected that if we ran this simulation long enough, that we would start to see some sort of, we get. We would start to see some sort of, we get close and then we start oscillating, but we've never seen that. Like we've run, we have run some very long ones and we just see sort of constants. So we don't really know why we're not observing that. One idea would be that, yes, it's not exact stationarity, but maybe it kind of averages out as you do all these samples. It ends up being on average correct, right? Maybe that's what's happening behind the scenes. But in terms of every sample we've ever done, where we're just directly sampling the distribution, we have only Sampling the distribution. We have only seen sort of constant convergence. And we've never seen leapfrog sort of catch back up again or anything like that. Honestly, we expected to see that. So this is still very new. We expect to see some problems arising, but we really haven't yet. So it's kind of exciting that maybe there's more to it that we can learn about and use. So I don't I'll talk for us again. I wonder if there's any scenario you also have HSCI's better. Okay, there was one, and this was when we sampled the distribution and then transformed the distribution and looked at the sampling on the transformed space. Leapfrog tended to do better there, so we hypothesized that maybe it's something to do with area preservation. So when you do these transformations, maybe the area preservation is letting it do a better job in the new space. But we're not proposing this as a method for sampling things and then transforming it and then sampling the new space. And then sampling the new space. So that is a scenario where maybe it would be a good idea to stay with energy or volume preservation if you're doing transformations of your distribution. But other than that, we have not really seen anything. We have seen what? We use like a really small time step. Maybe there's some roundoff errors that pop in and stuff like that. But other than that, we've just seen overall very positive results from the method. How hard would it be to make a volume preserving energy preserving? That's an exact integrator, right? If you can do that, it's close. Not necessarily. We've tried. There are certain examples where, for example, POAB8 does give you that, but it's like on not polynomial, but very basic, like quadratic right-hand sides, I think you get very good. But in general, it doesn't work out. But there are no both here. But in 2D, it would be some facting then. Right. Would be at least in the integration in 2D. Exactly. It's okay if it is the type of relativization. It's only that's a fixed time step. With adapted time step, you can get energy preserving. Okay, many suggestions if you have ideas. Many suggested. But I I do believe those are pretty restricted to certain very certain problems, though. They're not going to it's not in general going to give you that for a d arbitrary distribution that perceptible. That'd be great if we could get that. Maybe I don't remember this correctly, but I I have a feeling that San Selna, together with some other Spanish people, uh uh developed some splitting methods. Of splitting methods alternative to the leapfrog for I haven't already met this. Maybe even quite recently. I think I've only looked at the 2014 paper where they proposed this compressible idea. But they were always keeping that determinant in there all the time. They weren't approximating it like we were. I don't think I've brought anything else in. If there was a paper, if that's too high a worker, we may get to that. Yeah, yeah, I have to. Yeah, yeah, I have to check this out. Is that going to be energy preserving though, or is that not? No, no, I wouldn't do so, yes. Yeah, there are other methods like people have used, but the idea would be that even if it's a higher order method than leapfrog, eventually this dimensionality issue would creep up, right? So it just maybe have to go farther down the line to get there. But that's the idea. Okay, no further questions. Thank you again. Thank you very much.