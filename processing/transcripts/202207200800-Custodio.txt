I will start. So, this is the outline of the talk. I will start with some problem definition and then I will present the general structure of the algorithm that will be kind of vague in terms that I'm not going to specify the kind of models that we are using. I will simply say that we are using good quality models, meaning that they satisfy some like Taylor-like bounds. And then after that, I will After that, I will switch to derivative-based optimization. That is quite different from what we are having here in this meeting, but it is because they are the best quality models that I can find. So I will use Taylor models. I will present some results regarding convergence analysis, some numerical results to illustrate the performance of the method, and then I will replace the Taylor models by a The Taylor models by a derivative-free approach. So I will explain how do we build that model, present some numerical results. The convergence analysis is still being worked, so we don't have it yet finished. So we are dealing with multi-objective optimization problems. So we have a function with several components. The components are conflicting between each other, and like everyone else, the And, like everyone else, the goal is to produce a derivative-free approach. So, we have expensive function evaluation, we don't have derivatives, we cannot approximate it. And since we are in multi-objective optimization, we want to use the concept of Pareto dominance. And like I told, the big goal is to develop a trust region algorithm that is able to capture the complete Pareto front of the problem. There are already trust region. There are already trust-region approaches available in the literature, both for derivative-based or derivative-free optimization, but the majority of them, to not say almost all of them, only generate one point in the Pareto front. And what they do after is, well, depends on the method, but sometimes they consider different initializations, run the algorithm, and hopefully they. And hopefully, they expect to have several points in the Pareto front. But there is no reasoning to try to approximate this Pareto front. And in the context of expensive function evaluation, that could be a problem. If we run away from trust regions, of course, in directional direct search and also with generalizations of implicit filtering, we have algorithms that already Algorithms that already try to capture the whole Preto front. So, our goal was to build a type of these strategies, but now framed interest region. So, how are we going to do it? So, like I told, the goal is to use tailor-like models that have good quality for each component of the objective function. And we, in a very similar way to what is done with direct multi-search, we are going to keep a We are going to keep a list of non-dominated points, feasible non-dominated points. And our iterations will alternate between two steps: the extreme point step and the scalarization step. So the goal of the extreme point step will be to try to expand the Pareto front and try to reach the extreme points of it, corresponding to the individual minimizers of each component of the objective function. Objective function. The goal of the scalarization step will be to fulfill the Pareto front by generating points that somehow complete the Pareto front between the extreme points. So let me start to describe the list structure. So we will have the point, the corresponding function value, and two trust region radius. One of them is a scalar. It is associated with the scalarization step. The other one is a vector with high. The other one is a vector with as many components as the components of the objective function because it is used for the extreme point step. And now let me talk about each one of the steps. So the extreme point step has the goal of moving towards the extreme points of the Pareto front. So it starts by selecting for each function component a point that will be the it right center. Uh, the iterate center, and this point is the most promising one that we have in the list according to that component of the objective function. So, it will be the minimizer of the component that we are addressing, considering the points that we have already available in the list. Of course, we need to have a sufficiently large enough trust-region radius associated to that component, so it should be a both. Components, so it should be above the minimum threshold that is allowed. And in case of ties, we select the point corresponding to the largest stress region radius because we want the algorithm to progress. Now, after the selection of this point, what we do is for all the other points in the list, the corresponding trust region radius for that component for the extreme point step is set equal to zero because Is set equal to zero because they are not as promising, so we don't want to care about them when we are in this company in this step. And now, what we are going to do is solve a classical single objective trust region problem. So, we are going to build a good quality model for that component of the objective function. We are going to minimize it, respecting the bounds and respecting the trust region. And after that, we are going to. And after that, we are going like interest region, compute the ratio of agreement between the function value and the model, and update everything in a very classical way. So if the trust region radius is good, we are going to inherit for the new point the trust region radius that we had from the point that was the center of the iteration. If the trust region radius is The trust region radius is indeed very good. Sorry, the ratio of agreement is indeed very good, and the trust region radius is somehow bounding the progress of the algorithm. In that case, we are going to increase the trust region radius corresponding to the new point. And in this case, the trust region radius corresponding to the iterate center is set equal to zero. We are not. Set equal to zero, we are not going to select again this point for this kind of iteration. We are going to add the point to the list, clean everything that is dominated, and in case of failure, meaning that we don't have a good ratio, in that case, we are going to decrease the trust region radius of the current heaterite. And hopefully, next time that this point will be selected, this reduction. Select that this reduction will allow the algorithm to perform better. So, this is a classical single objective trace region approach, and we do it for every component of the objective function. Now, about the scalarization step. So the scalarization step tries to fulfill the gaps in the periodal front. So, we are going to do it for every component of the objective function. We are going to identify the largest of these. The largest of these gaps. So, we are in a given component, we are going to project the points on the component that we are analyzing, and we are going to compute the gaps. And we are going to identify the largest cap. In terms of when we have ties in this cap, we are going to break the ties according to the maximum of the trust region associated to each point that defines the gaps. That defines the gaps. This trust region radius is the one associated with the scalarization step. And if we have a trust region radius for at least one of the points defining the gap that is above the minimum threshold allowed, in that case, and this is a key feature of this algorithm, what we are going to do is not use the two points, but we are going to consider the middle point defined by The middle point defined by them in the variable space. And this will be the candidate to our iterate center. Now, what are we going to do with this middle point? Well, depends. If the middle point is already in the list, because that could be the case, we are going simply there and grab the corresponding trust region radius associated. If the middle point is not in the list and is a non-dominated point, we are going to edit and we are going. Two edits, and we are going to define for trust region radius the initial values considered. And we clean everything that is dominated from the list. Now that we have an iterate point for this colorization step, what we are going to do is build a model for each component of the objective function centered at this point, and we are going to solve this problem. So, what is this problem? So, basically, again, we are respecting. Basically, again, we are respecting the bounds, we are respecting the trust region. And this is like a min-max approach, so like a Chevy Chev approach. And even if it's not totally clear here because I'm formalizing it in terms of models, what these kind of restrictions represent is that we are more or less trying to compute a Newton direction considering the different components of the objective function. Of course, it's not a true, well, it's a true direction. It's not a true well, it's a true direction if you use Haas models, the Taylor models, when you use approximations, is not it's an approximation to the Newton direction. So we solve this problem and now we need, because we are in a trust region approach, somehow to compute ratios of agreements. For that, we define these measures, phi and phi for the model, that take in consideration all the components of the objective function. Components of the objective function. We compute the ratio of agreement between the true function and the model functions. Yes? Yes, yes. And this is the same, but for the model corresponding to each component of the function. So fi, f has q. f has q q components okay and and fi represents each component of the objective function yeah so um after computing this ratio everything goes like more or less like in a trust region approach so the big thing is if the new point is non-dominated because in the scalarization step when we had a ratio of agreement that was positive we were sure That was positive, we were sure that the point was non-dominated. Here, we don't have this kind of guarantee. So, if the point is non-dominated, then the ratio is good. Again, if the ratio is extremely good and the trust region radius is limiting the progress of the algorithm, we increase it. Otherwise, we inherit the trust-region radius from the it-rex center. We add the point to the list. We add the point to the list, delete everything that is dominated. When we have a situation in which the point is dominated or the ratio of agreement is not good, in that case, we are going to decrease the trust-region radius associated to the scalarization step. So, this is basically the general structure of the algorithm. And now, everything relies on the model. So, how to build the model. Models. So, how to build the models? So, when we define the structure, the easiest way to do it, to have good quality models, is to go for the Taylor model. So, this now is not derivative-free, is derivative-based, but I'm not taking too long with it. But even so, I think it is good to see what would be the behavior of the algorithm in the best situation possible, that is, to have good quality models. So, if we consider Taylor. We consider tailwind models, we can establish convergence. So, how do we do it? Well, we use this personality measure, this onge measure, that has very nice properties. So, it's a continuous functions, is always non-negative, and is zero only when the corresponding point is Pareto-critical. And we analyze the behavior of the algorithm using linked sequence. So, this is a concept that is important from other works. That is important from other works. So, linked sequence are sequences in which one point is generated from the other from the algorithm. And what we can establish assumes some conditions. So, the ones that you have here, the first two are classical interest regions. So, we are assuming that the function components are twice continuously differentiable and bounded below. We are assuming also that yesterday of the components of the Of the components of the objective function is bounded. And then we have this additional condition that is like a sufficient decrease condition for the aggregated model. Well, in fact, we stated the convergence using this condition, but for our algorithm, we can establish this inequality that somehow inspires that condition. So it's not an artificial condition for the kind of algorithm that we are developing. Developing. And now, under these three assumptions, so we can establish several results. They are technical, they are using derivatives, so I did not want to detail it here. But basically, if the linked sequence has finitely many successful iterations in the scalarization step, then the linked sequence converges to a Pareto-critical point, which also covers the case of the points being generated in the extreme point step. Extreme point step. When the linked sequence has infinitely many successful iterations in the scalarization step, then we first get the result in terms of linear inf, and then wrapping everything up, we can establish the convergence for the critical measure omega to zero. So, what about numerical performance? Well, we need metrics, we need test problems, and we need something to compare. Problems, and we need something to compare with. Critics can be made to all of them. Okay, so different persons enjoy different metrics. In my case, I enjoy these four and I cannot give up of any of them because I think that a metric only always reviews information. So I will report for purity, spread, and hyperfolium. Just to recall very quickly what is the meaning of each one. So purity represents the So purity represents the percentage of non-dominated points generated in the current approximation to the Pareto front. These two spreads, so gamma measures the largest gap in the Pareto front, delta measures the uniformity of the gaps across the Pareto front. And finally, hypervolume measures the volume of the dominated region by the current approximation to the Pareto front needs to have Pareto front needs to have a reference Pareto front, and that reference Pareto front should not dominate all the approximations to the Pareto front that we are considering. So in terms of test problems, we consider 54 problems for which we knew that the functions were twice continuously differentiable. So these are bi-objective and tri-objective problems. And in terms of compression, And in terms of compression, we had problems because, like I told you, there are not many codes available that compute approximations to the complete Pareto front. There is one in derivative-based optimization, at least that we know, that is MOS-SQP. So MOS-SQP at the time of the release was compared against genetic algorithms and against also scalarization techniques with different whites, and the authors conclude that the code was. Authors conclude that the code was quite good. So we consider all the default settings for the code. This version is the one that the authors reported has been the most successful one in terms of numerical performance. And over here, you have the settings that we have considered for Mo TR that are quite common even for a single objective thrust region. Single objective trust region methods. So, in terms of stopping criterion, what we did was consider a small budget of function evaluations. I have the reports also for larger budgets, but don't change too much. So the behavior is very similar. There is a slight improvement in purity, but nothing more. And for stopping the methods additionally to the 500 function evaluations, see. Function evaluations. Since the default of MOSISQP is to have this tolerance parameter for the step length equal to 10 minus 5, we did the same with the trust region radius. So we allowed a minimum trust region radius of 10 minus 5 for our code. So here you have the results in terms of purity and hypervolume. So MOSIS-QP in blue, MOTR in pink. So these are performance profiles. So these are performance profiles. So for tau equal to one, you have efficiency. For larger values of tau, you have robustness. So we were pleased with the results. So moving now for spread metrics. So let me just recall. So this is about the largest gap in the Pareto front. And this is the uniformity of the gaps. So this means that MoSQP is clearly better in terms of uniformity of the gaps. Uniformity of the gaps, but even so, I think, I personally think that we have something that is promising. Now, the main goal was not derivative bias. So this is like a byproduct of the work. The main goal was derivative free. So we are going to keep exactly the same structure, but we need to replace the Taylor models by something. So, what are we going to do? Well, the natural choice is interpolation models. So, we Interpolation models. So we are going to consider a set of points. I will describe it in a few minutes. And we are going to solve systems of linear equations considering the points for which we have evaluated the function. And from these systems, we are going to define the coefficient of the models. And of course, depending on the number of points available, you can have when you solve these kinds of systems, you can have over-determined. You can have over-determined systems where the systems are solved using least square regression techniques, or you can have determined systems, or you can have under-determined systems. And in this case, the typical approach to follow, at least from other works, is to compute minimum Frobenius norm solutions. Okay, so in this case, I'm paying the price of evaluating points just for building models. So I don't want Building models. So I don't want to use over-determined systems. Okay. So I want to be as economical as possible. So I'm only using under-determined and determined systems. Okay. Probably everyone else knows this, but I'm just going to recall that these models in fact give good bounds, the Taylor-like bounds that we were talking about and that are required for establishing convergence. So these are the bounds that we get. So, these are the bounds that we get when we have the determined case. So, just to recall, these blue constants are related with the smoothness of the objective function. And the red constant is associated with the geometry of the sets of points that needs to be good, and that here is produced using a lambda-poisonous condition. And when we have the under-determined case, well, in Underdetermined case, well, in this case, things are a little bit more tricky because the bound depends on the norm of the action, and that is the most motivation to use minimum Frobenius norm models. Because if you do that, then using different kinds of geometry for the set of points, you can control the norm of this session matrix. And joining everything, you can arrive to this. You can arrive to this kind of bounds that are Taylor-like bounds. So that was our option. How did we do it? Okay, so what we are going to do is to have a sample set associated to each point in the list. And the initial sample set was built like using coordinate directions scaled by a constant. And if in the scalarization step you compute a middle point, you are not, you are. point you are not you are reusing the sets of the points that were used to compute compute the middle point so we are trying to avoid as much as possible to do function evaluations just to compute models we are reusing every time that we can reuse and every time that we new uh that we do a new evaluation of a point being because we solve uh the trust region sub problem at the scalarization step or At the scalarization step or at the extreme point step, we are going to add the point to the corresponding sample set. No matter if it is a dominated or a non-dominated point, we get it, okay? Because it's important for building the model. And we are only, like I told you, we don't use over-determined models, so we are only using under-determined or determined models. And there could be the case. And there could be the case by the end of the iterations in which the number of points is large associated to that particular point. In that case, we select the points as the ones that are closest to the iteration center. If we don't have enough points available to build an underdetermined model, so if we only have less than n plus 2, in that case, we use a similar strategy to the one for the initialization. To the one for the initialization to try to compute the extra points that we need to build the model. So, again, numerical results. The test set will be the same. The question is, which solvers? And again, we don't have a clear view of which solvers to use. We are now in a derivative-free approach. There is one solver that the code is not available for use, but that only addresses by objective. Only address by objective optimization problems. We were dealing with bi-objective three objectives, so that could not be the choice. So we had to make options, not probably the best options, but it's what we have. So what we decided to do was first to compare against Boost DMES. What is Boost DMES? Well, in fact, it's a directional direct search method based on DMES, but for which the search step has quadratic polynomial models. So in fact, Quadratic polynomial models. So, in fact, things are comparable because it's using quadratic polynomial models here in a directional direct search approach, here in a trust region approach. The models are there. So it's more or less fair. So let's see what is going to happen. We consider default settings for codes. And in this case, again, 500 function evaluations, so expensive function evaluations. We want to know what happens in the beginning. Want to know what happens in the beginning. And since the stopping criterion for boost DMES is to have a step size parameter below 10 minus 3, in this case, we increase the trust region radius to 10 minus 3 to try to make things comparable. So here is what you get. So again, MOTR is in pink and in blue you have boost DMES, so purity and hard. Yes, so purity and hyper volume. So nice. In terms of hyper volume, we don't perform too better, but it's competitive, a slight advantage. And in terms of the spread metrics, it's nice. We want to know more. So this is for DFO. So it's not totally fair because now I'm going to compare with other codes that don't use models. Don't use models, but they were available, they were developed to build approximations to the complete perito front. Why not to compare it? So, we compare against D Multimats and also against MOIF. So, D multimaths is a directional direct search method, a recent one from Ludovic and Moif, Ludovic and Sebastian and co-authors, of course. And MOIF is a generalization of implicit filter. Of implicit filter, so made from the Italian group. So we went for the codes again: 500 function evaluations, default for everything. Just let's see. So starting with the multi-mats, this is what you get. So MOTR is always in pink. So purity, hypervolume, gamma, and delta. Nice results. In terms of hypervolume, considering efficiency, BMO. Considering efficiency, D multimuts performs better, okay, but it's nice. I think we have something here. And then we went for MOIF again, the same kind of strategy, leave everything as the authors wanted to do, only cut in the number of function evaluations. And this is what you get. So for now, we think that the numerical results are somehow encouraging, even for How encouraging even for the derivative-free optimization setting. Like I said, Abuzar is working hard back home trying to finish the convergence analysis for the derivative-free optimization. So basically, what we have proposed was a general trust region algorithm for multi-objective optimization that depends on models, but it's able to compute approximations to the complete period of front of the problem. To the complete Pareto front of the problem, convergence was established for the derivative-based case, is still being established. Maybe when I get back home, it's finished for the derivative-free setting. And for any of the two versions, derivative-based or derivative-free, the numerical results are promising considering all that we have available and with all the limitations that we can point to this kind of comparations. of the comparations. So thank you very much for