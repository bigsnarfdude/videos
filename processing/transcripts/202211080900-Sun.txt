Thank the organizers for the kind invitation. I have been enjoying this conference a lot. Yesterday there were many interesting talks. Today I'm going to talk about something slightly different from the flavor of yesterday's talks. So I'm going to talk about some numerical analysis today. And it won't be as sophisticated as the regular traditional PE analysis, but it's interesting to see an interplay of something. To see an interplay of some basic analysis with numerical computation. So, as Taito says, I'm going to look at the multi-scale landing work of Blank, and I will be talking about an asymptotic preserving scheme. And the main topic today is to show that the specific scheme we're looking at will be asthmatic preserving. And this is a joint work with Di Wang, who's going to give the next talk. Okay, so a very short outline. I will briefly introduce what is an AP scheme and let me talk a part I think many people are familiar with. And then I'll show you what the scheme looks like. And then our job is to actually reverse the proof that it is asymptotic preserving. Alright, so let me start with the asymptotic preserving method, AP method. So this method, it has been the It has been there for about four decades, I would say. It has been very popular in doing, especially kinetic computation. And there are many people who have been working in this area. So I listed some names here. In particular, I want to point out Shijing, who is a pioneer in doing kinetic asthmatic preserving methods. And so, what is this one about? So, basically, you have a multi-scale model. So, it doesn't have to be. Model. So it doesn't have to be kinetic, but since this is a kinetic workshop, let's say that this L is a kinetic operator and you have multi-scale epsilon here. Let's say epsilon is a Newton number. It could be other parameters in other scenarios as well. And now in general, if you just go directly to numerically solve this one, you discretize this one by finite difference in time. Let's not worry about other variables. Let's just look at time. And if you don't do anything and then you do Do anything and then you do a direct error estimate, then you would expect that your error will depend on 1 over epsilon. And now, or if you say, I don't want my error to depend on 1 over epsilon, then the compensation is your delta t will be usually of order of epsilon. That is also not what's desired because in the asymptotic limit, your epsilon is approaching zero. And you want to keep your delta t fixed throughout your computation. So, if you see So AP scheme is exactly to deal with this case and one of the main features of an AP scheme is you want a so-called uniform stability in the sense that if you design a proper scheme that is AP then you would have that your error does not depend on epsilon and your error of the discrete solution to the accurate solution only depends on your discretization parameter in this case only delta Parameter in this case only delta t. So the AT schemes are very, very desirable for multi-scale computation. Just think about the case when you have a region where somewhere the gas is very fine, somewhere the gas is very dense. And we all know that in the dense part, fluid can be a very good approximation. So instead of solving the kinetic equation, you just go to solve the fluid equation, which is much cheaper in computation. Now, in the rarefied part, the fluid is not. Part the fluid is not a good approximation, so you have to do the kinetic solver. Now, if you don't do things carefully, you want to solve things that are mixed together. So, how do you do? You cannot use the fluid across because it's not accurate enough. If you use kinetic all across, that will be accurate, but very expensive for the fluid parts. Or if you say I identify where is the fluid part, where is the kinetic part, then I get an interface between these two. Then I get an interface between these two. That's called a domain decomposition method. That also works. But then the difficulty there is you have to match your equations across the interface, which is not an easy job depending on your equation. There is a lot of boundary layer analysis and things involved there. Now, suppose you have an AP scheme in this case, that basically says across this whole domain, I just have one set of schemes to compute, and it's not. Compute and it does it's not affected by whether epsilon is small or epsilon is large. So this is why this would be a very nice thing to do. And now how do we actually realize this? The idea is we're going to borrow the property that if epsilon is small, actually you have a singular limit in general. Let's say for kinetic equations you often go to a macroscopic equations, could be like diffusion equations or fluid equations. Like diffusion equations or fluid equations. So, we're going to use this extra information. The main idea of the AP for uniform stability is in this schematic. So, basically, if we don't do anything, here I have four points at the corners corresponding to four solutions. So, the upper, this guy, this one, is the solution to the discretized, oh, sorry, this one is here. Solution to the discretized. Is here. Solution to the discretized multi-scale PDE. And the bottom one, when delta is zero, that's basically the means continuous PDE. So the bottom one is solution to continuous multi-scale PDE. Now, if you don't do anything, that's basically to say I'm estimating the difference between these two. As I said, you expect the error to depend on 1 over epsilon. So that's the error estimate along the green route. And I put a little error there. A little error there, but we'll talk about that on the next slide. But then, with this extra information that we can actually have a singular limit, then if you want to compare these two, instead of going along the green route, you can go along a detour of the red route to say that I'm going to use my fluid or microscopic division as a bridge to actually compare the two corners on the right. So, in that case, what we're going to do is you're going to compare the two corners. You're going to compare the discretized, let's say, multi-scale equation with the discretized continuous model. You also want to compare the multi-scale with its macroscopic limit. And then in between, you are just connecting using the error estimate on the continuous level. So these three things together gives you a second route to actually compute the error. And then, suppose this is successful. Suppose this is successful, then what you are going to have is you're comparing two the same things, right? You're having two methods to compare, to estimate the error. So you just need to minimize between these two. And if you minimize, now the first one, a direct computation, usually is discretization parameter divided by epsilon to certain powers. The second one, by the triangle inequality, you're going to get all kinds of error estimates. So for the Estimate. So for the top line and the bottom line, which are both to compare the multi-scale equation with the limiting equation, one is on a discrete level, one is on the continuous level. If things are done properly, you would expect that these errors will be depending on epsilon to some positive power. And then the left red line, this is when you are just numerically solving the macroscopic equation. There is no epsilon. Equation, there is no epsilon. So you expect the error to be of the parametrization parameter to some power. So then, if you minimize between these two, you will get an error that's independent of epsilon. So that is the basic idea behind the AP schemes. But I want to point out that it is actually generally hard to rigorously justify the scheme as AP for an obvious reason that we know how hard it is to actually prove It is to actually prove the asymptotic limits from kinetic equations to fluid equations, right? Here, we not only need the convergence, we need the convergence rate as well. So, in general, if you have a nonlinear equation, that's mostly out of hope to actually get a rigorous proof there. So, there are only a handful of works in the literature to do rigorous proof of schemes being AP, and they are all linear equations, and our equation will. On linear equations, and our equation will be linear as well. And the previous results are either on the relaxation equations where you have a fairly simple right-hand side as F minus equilibrium state divided by epsilon, or you have the neutron transport equation again. So it's a fairly simple structure. So here we're going to prove another scheme is AP. Now, numerically, what people often do is what people often do is what people often do to to actually justify their schemes are AP are through numerical observations to say that let's look at the convergence rate and whether it is independent of that. Okay, so this is the background of AP and then for the equation, Levi-Foker Planck. So I think this has been covered from some of yesterday's class as well, fractional diffusion. So Levi-Foker Planck is a fractional diffusion P. And here I put this And here I put these two representations. One is in the real space, one is in the Fourier space. Our equation will be posed on the whole space. Okay, so the equation itself basically is that for usual regular Foucault planck, you have a Laplacian on the right-hand side. Here you replace it by a fractional Laplacian. And now I want to say a few properties of this equation. That is for the equilibrium state, for the fractional Laplacian. For the fraction Laplacian, for the Laffey Foucault-Planck, the equilibrium state has a very slow decay tail. And depending on the strength of the singularity, the rate of decay is d plus 2s. So that does impose some problems here. Especially, for example, for all the range of s, you don't have a finite second moment. And for very small s, you don't even have a finite first moment here. Finite first moment here, which basically says that if you look at the equation itself, if you look at this equation, let's say M itself, this guy is a solution to the equation. And if you just look at term by term, this V times F itself is already not in L1. So this is the slow decay does introduce some difficulties in the analysis. And now let me compare it with the regular Fokker-Planck. For regular Fokker Planck. Foucault-Planck. For regular Foucault-Planck, the equilibrium state has a Gaussian tail, so it decays very fast. It has at least a second moment. Now, why do we emphasize on the second moment? Because this determines what kind of macroscopic limit you get. And here, let me say that if you put in the scale for the regular focal plane, you put in the diffusive scale epsilon for the gradient V and epsilon squared for DT, you can disprove. Just prove quite easily that the asymptotic limit for the density, the macroscopic density, was satisfied by the diffusion equation. And let me briefly explain how this works. It's like Hilbert expansions, I think people are familiar with it. But what's important is we'll see what this C naught, the diffusion coefficient, is. Okay, so one quick slice of Hubert extension. And here we'll Extension. And here what we do is quite simple. You just extend the formula in terms of epsilon. And then you just compare it, like order by order. And then you see what you get at the end. And after three steps, you'll get the equation for rho. First step, leading order is the right-hand side equal to zero, so you get the equilibrium state, rho times. And second step is now you start to have the left-hand side. So the transport term comes in balances with L acting. comes in balances with L acting on F1. So you just invert the L. Now L has no space, so this inversion is pseudo-inverse. And then you continue to do it and you then get a compatibility condition which will give you the diffusion equation for the row. This is a formal calculation, but if you have the regularity is strong enough, then this is actually also reverse. It depends on how much uh regularity you have. Or if you have weak regularity you can go with other ways. Regularity, you can go with other ways to convert it. This is not very difficult, but what I want to point out is this L inverse Vm, it will be, in this particular case, you can solve it and you get it is equal to V times M. So, which basically says this is C0 at the end of the day is actually the second moment of M. So, if you don't have a second moment, you don't have a deviation equation. Okay, so this is why I was emphasizing on the second moment. Now, for The second moment. Now, for the multi-scale Levy Focal plan, first of all, the scaling needs to be changed. We're expecting a fractional diffusion coming out of the equation. And we go from fractional diffusion in V to X. And here the scaling is changed in a compatible way as the limiting equation here. And now let me say a few words about how you actually get this limiting equation. There are various ways that you can do it. Ways that you can do it. One way is you can also try to do Hilbert expansion to say that I'm going to write my F in terms of epsilon order. But there is a tricky thing because it's hard to determine what is the next order. Being order is very clear. Next order, should we put epsilon to the s, epsilon to the 2s, epsilon? Or even there is more trouble of higher orders, right? But it could be done. But in dealing with the fractional things, when you do Hilbert expansion, you actually have to carefully You actually have to carefully pick up all the terms that are balancing out with each other. So it's a bit less straightforward. Yes. There is no coefficient in the limiting. In this particular. When S goes to 1, you don't get what you had in the previous slide. The C0 was 1 there, actually. If you compare to the V squared N, it was 1. Yeah. Okay. That's a good point. And here, what I wanted to say is there. Here, what I wanted to say is there is a way to do Hilbert expansion by actually putting things that seem to be of different orders to be into the same equation and balance them out. For both of them, for the regular or the fractional, the important thing is all this differentiation in x eventually comes from the transporter. So that's the most important information to keep in mind. Even if, let's say, if epsilon is very small, it looks like the transport is. Very small, it looks like the transport is of a very high order, but all the invalid limits really come from no transport. Okay, and let me explain another idea that was in the paper by Sesprona, Malay, and Trivisa, where they used a nice way of doing the test function to actually quickly get the limiting equation. So, in that case, they really built into the information of transport into their test function. Into their test function, and they put the test function in this particular way. The nice thing about it is now you can freely transfer the derivative between x and v. So that's the nice structure of it. And the proof of it is also very simple. When you realize you can do this, so you do a weak formulation of your equation. And then the most important thing is, now, because of the structure of the phi, now for all this differentiation in phi, you can just Differentiation in phi, you can just replace by the x differentiation. And then the middle term, the middle term will be canceled out, the last one will be turned into a fractional in x. And then you see why you get a limiting equation as fractional diffusion equation. And then the numerical scheme is actually built upon this idea. And here, let me just say what the numerical scheme we're looking at. The idea first came in the The idea first came in the paper by Xi and Wan. So they designed this scheme. They did a lot of numerical computation in their paper. And then Li basically came to me to say, is it possible we actually verify it is an AP scheme? Because this computation suggests to be so. So this is the starting point of our project. And let me explain to you what their idea is. Basically, in a classical hydrodynamic limit, let's say, you often do Limit, let's say. You often do the decomposition of F equals rho m plus the perturbation. This is sometimes recalled as micro-macro decomposition. Now, so to guarantee that your d in order rho, that includes the fluid information and the kinetic information are all in the perturbation gene. Here, what they do is they build into the idea of you do a translation. That's the idea coming from the test function. Idea coming from the test function from the previous paper that you don't actually do a complete fluid and kinetic decomposition, but you do this kind of decomposition. And again, this will encodes the nice property that this X derivative and V derivative can be kind of commuted, kind of they can go back and forth. Okay, and all right, so if you do this kind of decomposition, then the next thing is you can Then the next thing is you can decompose your equation. So this is a preparation for setting up the numerical scheme. How do you decompose your equation? Now, this is just what I plugged in the decomposition into the system. And then what you will have here is this guy. This guy will be canceled out with the transport part of this one because, again, differentiation of the V can be turned into differentiation of X because of the A. Differentiation of x because of the eta structure. And this one, part of it will become the fraction diffusion in x for eta. And then you have some remainder terms. And after that, what you do is you basically decompose, you manually decompose the original equation into two. There is no approximation here. This is just an equation splitting to say that I have the freedom to split my one equation into two. This is the way that Into 2. This is the way that was chosen so that you clearly have a fractional diffusion in x, and then you have the rest of the g here with some commutator terms coming from the eta. So this is the first thing. This is not the numerical scheme yet, but this is the starting point of it. As I said, if you add these two up in this format, you get exactly the Lavi Furker plant, but there hasn't been any approximation yet. Approximation yet. Alright, and then the numerical scheme will be done by solving this eta and g. And here is what we're looking at. So the numerical scheme is done by using an operator splitting because the g equation is a little bit too complicated. It has the transport part, it has the L as the level Fokker-Planck operator. So the operator splitting basically said the first equation is very simple. That the first equation is very simple. It's a macroscopic equation, you just do whatever you can do. And then the second equation, you split the transport term and you split it from the LS term so that the middle term becomes space homogeneous and then the last one becomes basically a transport equation. Okay, so both of them are easy to solve. And then the approximate solution here is going to be uh given by this combination here, right? Combination here. So, this is the scheme that we will be looking at. You do notice that there is some gamma appearing here that wasn't in the previous equation. Let me make a comment about this gamma. This is for numerical stability reason. So, if you actually solve this intermediate g m plus 1 half, you can solve it. It's a linear equation. You can just write out the inverse operator here, and then it will be given. Operator here, and then it will be given out in this form. Now, here is a computation of the condition number of discretizing this operator. You can see that, so a sub gamma is 0, 1 half, 1, and 2 are values for gamma. So, you can see that if you don't have the gamma there, when epsilon is very, very small, your condition number is really bad. Okay. But if you start to increase your gamma, then you get better and better condition numbers. This is really for numerical stability. This is really for numerical stability, which I think is not very surprising because your L has a null space. If your epsilon is very small, you are really inverting something that has a null space. All right, and I want to point out one thing. So in the paper by Xiu Yin Wen, in their numerical tests, their gamma was fixed at one. But in our analysis later on, we found that in order to prove the skin is AP, actually the gamma choice seemed to be Choice seems to be we need to choose it dependent on epsilon and delta t. So you have to do some adjustment here. So when you stop condition number, so you said you discretize the operator of there in red, right? Yes. So that's just a matrix. So you mean the condition number with that matrix? Yes, yes. Exactly. The A is exactly the disconnected. Cool. Okay. Alright, so then after we Alright, so then after we set up the numerical scheme, here is a quick computation of all these errors. So error in eta, error in G, error in the full function f. So you don't have to look into the details of this, but I just want to point out, actually it's better to see it in the next slide, that the error for the f, the for density function, here you can see that you do have the main part. This is basically the laminifer plank. Then you have some bunch of errors. Then you have some bunch of errors there. The E1 and E2 are coming from that you are writing partial T into finite differences. So these are just discretization errors. These are very easily controlled as long as your solution is smooth enough. The harder error to control is this one. This is the one that we manually introduced into the system by doing operative splitting. Because if you think about it, your original equation wasn't in this split form. wasn't in this split form of there is you first do transport then sorry you first do the collision then you do the transport okay we work together so this is a this is an error that's harder to control this is an operator splitting error okay in any case what I want to say is at the end of the day what you can prove is if your initial data has certain regularity we were not trying to optimize the regularity here so for numerical computation there Here. So, for numerical computation, very often we're happy with use assume enough regularity, we get the error balance. And here we have all these regularity assumptions for the initial data. Then at the end of the day, we can prove a certain norm, a certain weighted norm, is going to be bounded independent of epsilon. So that's the main result. And let me briefly show you how this is done. How is this done? Very sorry. Sorry. So that instead, so you're saying that, so when the step size goes to zero, then the right-hand side of that goes to zero. Yes. So is it that I don't know? Is this like a stability estimate or a convergence estimate to this analytical solution? Okay, so these two are basically the same. This is the uniform stability estimate and it also proves the convergence. Okay. So for linear equations, there is the lack of. There is the Lax equivalent theorem to say that convergence is equivalent to stability plus consistency. But consistency here is quite straightforward. So if you get stability, you get convergence. Right. But I think what confuses me, sorry, this is very naive, is that when you say that then the solution is going to zero, that normally. Oh, it's the difference. Yeah, F2 is the error term. Oh, sorry, there's a tilde. This is very, very small. I should put the font. I should put the font bigger. The choice of gamma is based in equal zero. Yes, the choice of gamma, I will show you the explicit choice of gamma. What is the source of this initial data that we mentioned over here? The initial data, okay, so because we're not preparing our initial data, which means our initial data can be far away from equilibrium state, right? And then if you think about, you'll see in the next proof that there is one part where you're going Proof that there is one part we're going to compare it with the diffuse the fractional diffusion equation. If you start with something that's far away from equilibrium state, then with very small epsilon, then you have to go through an initial layer to get close to the equilibrium state. You have to make the jump. So that's why this estimate is only valid outside of the initial layer. But the initial layer is bounded by by the norms that come from this. Initial layer in this case will be of order S and to the two S. Of order epsilon to the 2s. And initially, it only plays the part when epsilon is very, very small. So if we look at like epsilon of order 1, then we're in the kinetic region, then we don't have to compare it with the macroscopic equation. Okay, so I want to say something that our analysis slightly generalizes the AP scheme, the AP schematic at the beginning. I will compare that with the regular one in the next slide, but here we One in the next slide. But here, what we're going to do is our analysis will be different in two regimes for these parameters. So we have the epsilon and delta parameters here. We'll do different analysis in region 1 and region 2. So here in region 1, region 1 is epsilon is relatively large compared with delta t. It may not be order 1, it's just compared with delta t, it's relatively large. But still, we call this one as kinetic regime. It's not really. As kinetic regime. It's not really the usually if you think about kinetic regime, you think about epsilon of order one. So this is like generalized. And then if we have epsilon that is relatively small compared with delta t, we call this one as diffusive and intermediate regimes. In these two regimes, the analysis will be done differently. Okay, and this is what I want to say about comparison with classical AP method. For classical AP method. For classical AP method, no matter where your epsilon and delta t is, you just do both estimates. You can go both along the green line and along the red line. So that's the classical way of doing AP. Here what we're saying is we're relaxing that condition a bit. We're saying that if my epsilon is in region one, I'm going to do the green estimate. And if my epsilon is relatively small, I'm going to do the red root. And then Red root, and then you can, because there is no gap between these two regimes, so you can still combine them and show that the fourth in is VP. Okay, so this is a slight generalization of the usual one. Alright, so let me just show you the analysis in these two regimes differently. One is diffusion, one is epsilon is relatively small. And in this regime, we're expecting to compare our kinetic equation with the fraction of equation. The fractional equation macroscopic equation. And so, this is why we need to do a comparison. We need a convergence rate here. If you remember, we do need a convergence rate about f epsilon with the limiting equation. And the previous work by Manette's group, the weak formulation, it does give you convergence, but it doesn't give you convergence rate. So, we really need to know how close these two are. And for this equation, this is an equation. Equation. This is an equation that's posed on the whole space. So at the end of the day, we do a very brute force computation. That is, we solve the both solutions and we compute their differences by using the Fourier Fourier transform. So at the end of the day, you just do actually, it's very rare in PPE analysis that you can actually directly compare to solutions, right? But here we can. So you do a lot of algebraic computation, then you see why. Then you see why their differences are of epsilon to a certain power. Now remember in this regime, epsilon is bounded by delta t. So then epsilon to some certain power means it translates to delta t to some power. Alright, and here are... Yes. Sorry, so there you have a real diffusion in V. Oh, this is a typo. Sorry. Yeah, it should be the fractional. Yes, yes, this was a typo. Yeah, actually, I copied down the wrong equation. It should be the fractional. It should be the fractional. No, this should be the leveling for Koplan. I copied down the classical. So it's epsilon to the power 2s? It's epsilon to the to the epsilon to the power 2s. This is also should be a fractional diffusion ruby. Yeah, sorry about that. And here I want to actually, this is too small, but if you have good eyes, there is epsilon, so let me actually write it out. There is a term. There is a term that is epsilon to the minus 2s times t. This is exactly the term that shows initial layer is epsilon to the 2s. And okay, so then we basically completed one root of the error that is the discontinuous, the f epsilon and the continuous limit are close. And then here is the choice. And then here is the choice of the gamma for this case. So, for this case, what we have is epsilon is, if epsilon is really, really small, you can just pick gamma as order one. This squared of three is of nothing importance. You can choose other numbers. And if epsilon is somewhat comparable with delta t, then you have to choose gamma to be really large. Here, this beta is less than one. And I asked me to actually test it, the choices. Actually, tested the choices of gamma here to say that suppose we just fix gamma as squared of 3, what happens? She does tell me that if you push to the limits here, if you really push this epsilon to the delta in the region, you have very bad convergence if you don't choose the proper gamma. So it seems that the choice of gamma does matter here. And in this case, what we're having here is since we've already got the error from the From the area that is between f epsilon and rho m. The rest of it is just to control the kinetic part, which is the g. So in this case, we don't even need to bother with g n minus g at t n. We just directly control of if these two are. They should be both small. And this was the result. The result tells us that the g, if you directly control them, it will be all border delta t. And here's a very quick slide of how this is. Slide of how this is done. Now, numerical schemes are often estimated using iterations because you do have iterative equations here. And this slide is for the purpose of showing you why we need to choose different regions of gamma here. So you can directly solve and get how your g n goes to g n plus 1. So the iteration you can get directly from the equation. And from there, you estimate the norms of your operators, and then you will get. Operators, and then you will get this kind of iteration here. So the choice of the gamma is really to guarantee the convergence of your geometric series here. And if alpha, because alpha is epsilon to the 2s divided by t, delta t, if alpha is very large, you can choose your gamma to be order 1. If alpha is not so good, then you choose gamma to be large enough to guarantee the convergence of the series. So that's the basic idea here. So this is for the part when the So, this is for the part when the fluid can be, or the microscopic equation can be a good approximation. Now, the harder analysis goes to the part where you don't have that bridge. You have to directly compare these two in the kinetic region. So, in this case, the gamma range that we computed is in this region. And the reason we need a negative weight here is because of this non-integrability of n. You still remember that V times M is not even L1. So if you want to do some auto-type estimate, we'll have to reduce the weight. So that's the idea. And also, oh, I'm going a bit too fast, man. Okay. And alright, so then here's the main steps of how to do the proof. And there will be quite a bit of commutator estimates and so on because of this fractional distribution. On because of this fractional diffusion operator here. And as I said, the reason for the negative weight is to compensate that the M has a tail that goes too slowly. And there is a small delta here. The reason because a small delta here is that when you do a commutator of this kind of weight with the L, the commutator itself doesn't seem to be that small. Usually you would think that once you do the commutator, it would be like lowered, for example, the order. Like, lowered, for example, the order will be lowered, and so on. But here, the fractional diffusion is not really as a pseudo-differential operator, it's not really in that S0S range because it has a similarity at zero. So, as far as we can see, when you do the commutator estimate, the commutator itself actually behaves quite badly. That's why we want the computator to be small. This delta introduced is to get an extra small parameter in the computer. Extra small parameter in the commutator term so that it could be controlled. And this square divided by F M, this is a common structure in kinetic equations. That's because your L S has the coercivity estimate, that's a weighted coercivity estimate with one of the m. So that one is not very surprising. And after we realize this is basically the term to control, then you just do the energy estimate, how to energy estimate. How to energy as unit for the discretized equation. At the end of the day, what you are going to get is the difference between the two steps. You do allow a little bit of growth for Fm plus 1 as long as it is under control. So that's the idea. And there is an A. So all these parameters are fairly complicated, but fortunately they are under control. And there is a delta T, there is an R. You always want something delta T on the right-hand side. Otherwise, On the right-hand side, otherwise, it will diverge because you have to do a summation at the end of the day. So, yeah, so that works, and the delta choice is not arbitrary. Delta needs to be dependent on X1 and Delta. This is how you choose the delta. And yeah, I'm going to show you one example of these parameters just to show that there exists parameters. Show that there exists parameters that work for this analysis. You don't have to see what the formulas are, just that those formulas depend on the dimension and depend on the strength of the singularity as well. And yeah, so at the end, let me show you the numerical test that Lee has done. So the numerical test it was done was for weak singularity before one-half, strong singularity above one-half. And in both cases, the top one. Both cases, the top line is a reference line of slope one. So she was checking the rate of convergence here. And you can see that, at least from a numerical point of view, no matter what kind of S you choose, what kind of delta epsilon that you have, the convergence rate seems to be consistent of first order. Now, our analysis cannot recover first order convergence. We can just say there is some positive order here. Usually it's hard to really match your It's hard to really match your analysis with numerical computation. And in any case, we basically get our convergence. And that's what I want to say. Thank you. Are there any more questions for Weyer? So um so you the the error resin that you the convergence that you obtain is in L2. The convergence you obtain is in L2. Will it be interesting to obtain error estimates and other norms like L infinity? L infinity is actually possible because this L S it does have maximum principle. Right, no thing because the whole equation is a i the unit product one equation, right? Uh it has parts of principle and everything else. I I I well for energy estimate itself, uh energy estimate itself you can get an L infinity estimate. I just don't know whether you can get L infinity in terms of delta T. That one I don't know because that's at the end of what we want. That's what you will or you mean that the rate is yes. Yeah that I'm not so sure. Do you run into problems for S less than a half because then the gradient because then the gradient is higher order than your fractional diffusion operator. Does that pose any problem when you set up a solution concept or so? No, you can do the so what I see from these computation is for fractional passing they did a Fourier transform. What is a solution for you? What is A solution? Well, analytically, of course, it's easy to see. You can set up the weak solution, then there is no problem. In a solar space, like an L2HS or a weak space? In no, no, it it will be uh in weighted. So i if uh we talk about outer based spaces, it will be weighted uh out to Uh L2 one over. So all all our solutions are in L2, one over N d V. So it uh let me actually But how many derivatives are imposed? Let me flip to the one that we had there was yeah there there were uh two derivatives uh so here we put in initial data two derivatives. In initial data, two derivatives, and those irregularities will properly. Where I guess is it known that if the initial data is well prepared, then the initial layer is not there? If the initial data is well prepared, yes, I think so. So, usually, especially if this is a linear equation, I wouldn't expect anything strange to happen. If you prepare your data, then there shouldn't be anything there was this operator splitting with the transport at the kinetic term. Is that something that in general is suitable for kinetic equations? Is suitable for kinetic equations, or is it a feature of this particular one if you try to? This operative splitting is very common in kinetic computation. Like when they do kinetic computation, this is very, very common that they do this operative splitting. The gamma itself, so which terms do you add in to stabilize your system? That might depend on a system. And one has to be careful about how you add in those extra terms to guarantee the consistency. The unstable one was the inverse of L, right? For which you introduced the gamma, right? Yes, well, yes, here we introduce the gamma is to stabilize this L because it has a null space, that's right. Any further questions for Wayron? Oh, let's go ahead and thank her again. 