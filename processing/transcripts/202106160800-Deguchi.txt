So today I would talk about today I would like to talk about so kind of classical result, but anyway, exact evaluation of the mean scale fluctuation of Prosum vector of a cross-link point in the Carlson network. So the Carlson network, there are many cross points and each cross-link point fluctuate and so we Point fluctuate, and so we calculate fluctuation actually rigorously. And this work is in collaboration with Jason Kantarea, University of Georgia, and Kueten Shonku Waider, Kuwait State University, and Erika Uehara, Oceanomison University in Japan. And some relevant preprints are available in the archive. So I just mentioned these two preprints. So. So it is Bert's workshop. Then polymal networks as materials. Actually, polymal networks are many materials are made of polymer networks. In particular, we consider rubbers and gels. And the Gaussian network is an ideal model of positive networks, such as rubbers and gels. And for example, a tight And for example, tires of cars are made of rubbers and they are industrially significant, so commercially very important object. And rubber is often applied another purpose, such as here is an elastomeric seismic protection isolator. Actually, this is put on the basis of a tall building in Japan in Proto- Tall building in Japan, in particular, there are many earthquakes, and so it is very important to use this rubber system. So it's fluctuate, but somehow it's fluctuation damping, damped, so stop motion. And many fruits are indeed made of gels. So for example, pudding is an example of gels. And I say this picture is taken by Erika Vehara, and maybe after. And maybe after taking pictures, she had it made probably. So, anyway, we can enjoy food. There are gels. And today, I would like to propose a novel exact approach to the Gaussian Polymer networks. And in particular, we revise the phantom network theory by making use of the boundary operator in homology or graph theory. And today, I discuss one application as a consequence of. As a consequence of this application, we have an exact evaluation of the mean square flattenation of the position vector of a crossing. So we consider this picture. This is a rectangle cubic lattice and each actually each edges of this one consist of each branch, consists of 50 segments, small segments. And actually, this is a very simple picture. This is a very simple picture, but actually, if we so its confirmation of this lattice is given by this. This is obtained by Erica Wehara through computer simulations. And so colours are creating this part, this part. And so we consider this kind of random conformations of networks. And each point, a crossing point, is fluctuating. So, for example, this is fluctuating, and so we And so we evaluate this fluctuation rigorously. And this is actually a kind of revision of all the theory because many properties of elastics, elasticity, and the rheology of polymer networks are studied by Gaussian networks and actually historically, very old time by James and Goose, 1943, James 1947, and the local Kubo in Japan in And the logo Kubo in Japan in 1947. So they have discussed elasticity properties through Gaussian networks. And today's topic, position of fluctuation, previous studies of fluctuations in the Gaussian networks are given by Eichinger in 1972, Gresley, Flory, this is the most famous paper, 1976, and Pearson and Klockowski, Mark, and Elvis. Mark and Elman, 1989. So actually, this paper is also left out in their book on Lastoma by Mark and Elman. So very famous result. It seems it's very fundamental result. And the main result of today is we present an exact method for evaluating the position fluctuation of each cross-link in a given Gaussian network. Then we have evaluated the positional fluctuation. We have evaluated the position fluctuations rigorously for some typical networks, such as linear chain, square lattice, cubic lattice, n-dimensional hypercubic lattice, binary tree-like graphs, etc. And actually, we exactly evaluate a given physical quantity of the Gaussian network without making any assumption, such as affine deformation of network strands and network deformation. Actually, usually people assume affine deformation. people assume a fine deformation of network strands and if the networks are deformed. However, we don't assume this kind of assumption. Actually, the positional extension of the Gaussian network can be expressed in terms of resistance distances of the corresponding circuit work, a circuit network. So this is in preparation, but anyway, this is our main statement. And so maybe background. I would like also discuss about background. Also, discuss about background so graph La Flacian and the difficulty in the Gaussian network. So, we define actually, we shall define the boundary operator soon, but anyway, maybe I can show you boundary operators first. So, this is a graph, theta graph, and there are two vertices and three edges, one, two, three. And we consider a Eti space, which means one, two, three, three-dimensional, is three here, and vertex space are v v2. And for example, this point one corresponds to vertex vector one, zero and this point corresponds to v2 and given by zero one. And this h corresponds to h vector. Correspond to H vector 100 and this one corresponds to 1012 and this one corresponds to 001. So three dimensional. And then if we multiply boundary operator or boundary matrix to H then we have applying this one so we applying this vector to this matrix we have one minus one and it is given by v1 minus v2. Given by V1 minus V2. So a boundary operator gives the difference between the two edges, two endpoints of the edge. So something like this operator. Then this operator, product of B operator times transpose of B gives the graph Laplacian. And the diagonal part is given by the degree of the vertics and plus adjacency matrix. This shows connection between edges. Between edges, vertices. And if we consider potential function, case constant, elastic constant, and x transpose times L times X, then usually probability distribution function of this configuration. So after we denote by X1, X2, XB the position of coordinates, X coordinates of the A x-coordinates of the operator x position, and we consider a sequence of this vector. And so we and we sandwich this L matrix, Laplacian L by this vector, we have the potential energy. And usually, probability distribution function of this configuration given by px exponential minus phi x over z. This is standard gives ensemble. That gives ensemble. However, the problem in the Gaussian network theory is that we have a difficulty that naive Protestant function Z diverges. If we take integration over this probability or configuration, then it gives infinity. And so James and Gus, they assume that some of the points by exposition are fixed. Are fixed and they somehow get rid of this difficulty. But on the other hand, if you fix some positions, then the calculation becomes very difficult and almost impossible sometimes. However, we have another solution. So actually, we solve all the loop constraints explicitly. So here, this is the graph, and we have two. Is the CD graph, and we have two loops here. And so, uh, the Baltic position one and two has to satisfy this loop condition. And so, thanks to the boundary operator in homology or graph theory, we generate an ensemble conformation to Causal networks where the center of mass is located at origin by simply considering the Confusion space or past space, so which means that the in the 80 space, which which means that we consider this space, so R, so the epsilon and epsilon is two, three here, so three-dimensional vector. And in this vector space, we consider kernel B. So actually, if you consider this loop, this loop Uh, this loop, this loop consists e2 minus e3. And if you multiply boundary operator to e2 minus e3, then all the edges are cancelled out, all the end points of the edge point cancel each other, and so that we have a zero vector as a result. And so, if you multiply loop loops, uh, each vector corresponds to loop to boundary operator, then we To boundary operator, then we have zero. So loops P belongs to the kernel B. And so this is the constraints of loops. And we consider paths which are perpendicular in the perpendicular direction to colour B. So we take, so we generate Gaussian land and walks uniformly in colonial B perpendicular. So we consider perpendicular selection, all the Pipeline digital direction, all the pipelines to kernel B. And then somehow we found that this gives correct to an ensemble. So this is, so, and actually by this method, we automatically generate all the confirmations of Gaussian networks where the center of mass is located at origin. So this is somehow finding this name. And this gives a new kind of And this gives a new kind of new legalization for the Gaussian networks. And through this technique, we calculate exactly the position of fluctuation. And in 1976, Flory argues that positional fluctuation in the Gaussian network or phantom network is probably. network is proportional to the inverse of functionality f 2 over f somehow and here f is the number of edges at each vertex so in the case of this picture we have six edges at the vertex point and so close the link and so we have f equals six and And actually, so we can check this formula rigorously later, soon later. And so we can evaluate the fluctuation of each cross-link position exactly with resistance distances for any thousand networks. And resistant distance is resistance between two points in the network from one point to another point. From one point to another point, I point and J vertex. And this is other, if we view, we consider this network as a certain network. This is a definition of resistance distance. And so somehow, through this quantity, we express this position fluctuation. And we found that this is proportional to this form, actually. Actually, and this is for regular graphs. We consider a regular graph with functionality f, which means that each vertex has f edges and but randomly connected. And this is called regular graphs. And we observe that this is given by this. And actually, we can show this relation analytically for using the spectrum cell. Using the spectrum theorem due to Mach K. And anyway, so in this sense, the flow is result is valid if F goes to very large. So if you consider F is very large, then we have only this part and cancel F1, this one. And so we have this. And furthermore, this expression is also derived by Kokovsky et al. in 1989, but But their argument is mathematically not acceptable. However, the result was correct. Anyway, so and the release is referred to Elman Mark's textbook on rubber elasticity. So this is interesting. Actually, Klopkovsky, Mark, and Elman consider this kind of tetra functional tree-like graph. And so each vertex has four functionality here. And they consider this. And they consult this graph Laplacian. However, this line is okay, but this line, the sum of the elements doesn't vanish. So this is wrong, actually. So their argument is somehow not plausible, but still the result was correct. This is very interesting. Anyway, so something like that. So first result. So we proposed, we found that we have an That we have an exact formula for positional fluctuation. First, the average of positional fluctuation over all voltage states is given by the mean skeletal titanium if the so this means the constraint that the the network under the constraint that the center of mass is fixed at origin. Under this condition we take this average over x squared. Average over xi squared, then we have this relation. So this is a network character radius. And furthermore, the position of flaxation at each platex, I, xi squared, center of mass, then is given by this. Here, Rij denotes the resistant distance. So, which means that I'm vortex and GS vortex, the resistance between two points in the network. In the network. So, if you sum up all i fixed and all the other points, then we have this quantity. So, this is the exact formula. And maybe one comment that the mean squared of the identity is given by the over summation over distances. So, something like this. So, all the quantities on the right-hand side of this formula. Right-hand side of this formula is exhibited by resistant distances. So we can calculate everything correctly. And for example, in the grid lattice, which means that for 3D case, we have this cubic lattice, and 2D case is a square lattice, and 1D case is a linear chain. In this case, the fluctuation is given by this, which means that in one dimensional gain fluctuation is proportional to n. Proportional to n. Here, n is the length of the chain, and in the square lattice, it is given by 1 over 2 pi times log n plus 1 over 6, something like this for n plus 1. So here n is, so the lattice size has n squared for this case. And in the cubic case, we have n cubed sides. And in this case, it is given by constant plus some corrections. So, this is a numerical check for the asymptotic behavior of the two discalators. And this is the log plot and the log log plot, linear and log plot. And we have this fitting very nice. So, this is a very nice number. 10 million, maybe you be half check, yes. And and for so. And for 3D lattice case, this is the log-log plot, and it's almost constant. And if you very precisely, 0.23 and 0.3255, it increases something like this. Here is the 100,000 points, something like this. So this is interesting. So in the 2D case, after 2D case, fluctuation increases with respect to the system size. However, size however larger than 3 decays it is constant doesn't agree it doesn't doesn't increase so this is qualitatively different behavior and position fluctuations for the nth dimensional grid lattices are not favorable to flow this formula which means that if you we assume flow is formula we have this kind of relation and we take that ratio of one The ratio of 1D, 2D, 2D, 3D, 3D, 4D, 4D, 5D, and the number is somehow slightly different. Maybe there are differences, unfortunately. So anyway, so this is not, doesn't work here. So maybe for the grid lattice, it doesn't so much good approximation. And the fluctuation of a vortex with label, so we consider that. Label so we consider the two attitudes, and in this case, we have exact results again. So, and so extra square average is given by this. This L is the level of the vertex point position and level I and T is denotes the height of the binary tree. Binary tree, and we have this result here. V is the number of buttons, and this is given two to the t plus one minus one, so something like this. So, and the correlation does not decay for binary trees. So, exactly, we have this expression. And here, Li denotes the level of the ice vortex, and L V denotes A I D denotes the common ancestor of Ice. The common ancestor of I and J and L A I J denotes the level of common ancestor for I and J. And for example, for I equal 8 and J equal to 15, 8 and 15, and the correlation between this is given by minus one. And so it is fluctuated in different ways and doesn't vanish. Although high system size becomes very large. So it is So it is again quite different behavior from Florida's formula. And if you consider a pair of trees with functionality a plus one, so you have a top products and then you have number a edges, a edges here, children. So in this case, if we talk about x0, we have this fluctuation and the one over f minus two. This is very quite simple. Minus two. This is very quite similar to all these results, very good. But in the left one, we have this exact result. And in this case, if f increases infinity, then fluctuation approaches to one. So the portion fluctuation remains non-zero constant, although the functionality goes to infinity. So something like this, this portion may be balanced and stop, but this portion fluctuated. So, this is the result, an exact result against Florida's formula. And maybe we are short of time, so maybe I can stop in two slides. But so we have a conjecture, Kowski's result should be valid for large irregular graphs. And there are locally tree-like structures in a regular graph. So, for example, this is the So, for example, this is the this point. If you pick up this point and level three, we have this structure, and this is three locally. And so, last regular graph, local structure is given by tree-like structure. And for this network, maybe florid results and the clock cost piece results are valid, maybe probably. This is our conjecture. As analysis has Other analysis doesn't work. So, conclusion discussion. So, Florida's formula of positional fluctuation is valid for the Gaussian networks of regular graphs when the functionality f is very large. However, there exists rigorous conjecture accounterexamples to chlorine's formula, such as those of networks of cherry trees. And so, these results should be valid for large regular graphs. Maybe, and probably I can just mention two. And probably I can just mention future topics that the scattering functions are also calculated for some tree graphs, especially, and it should be interesting to apply them to some scattering data of polymer networks. Maybe we study, re-investigate the results of 1970s, 1980s research results rigorously through this approach. So actually, finally, this based on GST. And finally, this is based on GSD CREST and the Japan Society for Promotion Science, Kakenki. So this research is based on these two grants. So this is my talk. Thank you very much. Thank you very much. It was a great talk. Any questions? I have one. This is Rajiv. Rajif. So I got confused in the beginning in terms of how you compute all these averages. So is there any thermal noise in the system or what is this is a fundamental model of the house and network. But when you compute the partition function, yes. So here. Yes. So what do you do here mathematically? Mathematically? Yes, mathematically, yes. So we take this, yes, yes. But under the constraint that the position, the center of mass position is fixed. And so this corresponds to that peak. So you consider all the direction perpendicular to kernel B. This is equivalent to this. This. So actually, so it's a kind of one regularization method of Gaussian networks. But probably this is the most physical one. This is my our claim, actually. So because the network is very large, so central mass is fixed. So then we calculate everything rigorously. And this possibility. And this possibility may be missed many years, I think. It's quite surprising now. But anyway, this is my statement. So, my question is this: where is temperature showing up in all of this if it's thermal fluctuation, like in Gaussian networks, right? It shows up through the probability distribution function, but I did not see. Yeah, yeah. So, this constant, K. So, if you divide on a temperature K V T and then this appears here. Here. Okay. Yeah. So this is very, very classical calculation. Actually, yes. All right. Thank you.