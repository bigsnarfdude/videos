Mr. from George Yante. He will talk to us about WIC Adversarial Network. Thank you. Thank you for the organizers for giving me the opportunity to come back to this beautiful place and listen to many, many wonderful talks and also a lot of fun activities. I want to start by apologizing a little bit. My talk may end up being five minutes because the mathematics in here is just one slide. Mathematics unier is just one slide. But I try to keep you entertained by sharing some of the experience so that there are a lot of up and downs when you do it. And maybe I can share with you about that. Well, this is a joint work with Professor Gunbao. Many of you probably know him. He was at Michigan State, but now he moved to Jang University and also a professor. So, Professor Xiaojingyi at Druda State University, and Yao Hua Tang was a student at Tejiang University at that time, and was also visiting Druda Tech when we started this work together. Like I said, my talk is like a very simple. I have three items. I have the forward problem, inverse problem, and then a conclusion and outlook. And outlook. I'll spend most of the time on the forward problem because this is about inverse problem, and I will try to make a point at the end so that I just need probably one minute or two about inverse problem. All right. Let me start by introducing why we want to do this thing. And of course, numerous problems, I don't have to, I mean, solving PDEs. Have to, I mean, solving PDEs and the inverse problem, I don't have to moderate it in this group. I'm just giving an example, like say this is the typical elliptic equation. I mean, we take this as an example, but we actually test a lot of different equations. And it's not related to, I mean, restricted to this type. But this is a normally you do it. There are a lot of very well developed methods and well studied. And very well studied as well. And we were thinking about okay, what about if you do this type of things in higher dimension? You may ask, like, what kind of PDE are you in a higher dimension? I always ask myself a lot of times. And I know a few of them, like, you probably have to go to higher dimension to solve it. But I think there are a few of the examples was mentioned earlier in this conference already. But anyway, let's just pretend. Uh but anyway, let's just pretend uh we have a higher dimensional PDE to solve and uh in my mind higher dimension it is usually the five, six up is considered as higher because the traditional method up to three dimension we can handle it. If you go to four dimension it's a little bit scratch me if you go to the fifth seventh uh you probably have to do a lot of pre-processing so that you can actually compute correctly. Right. That is uh Right, that is where we started. Of course, we actually said like this, I mean, view to finite element, finite difference for lower dimensional problem. And there's a great selection. I don't think like this is the point that we want to address here. So when we get to the higher dimension, the most challenging part is actually about oh, sorry, one way. It's about It's about the computational course. And then we try to advocate one strategy called a min-max framework. It's more like a two-player game strategy. Plus, of course, neural network, which has been mentioned quite a few times in this conference already. And I'm assuming that in this audience everybody knows what is neural network. Well, if you've not tried in the past, but you've probably seen it. In the past, but you've probably seen it somewhere. I'm going to just use one slide to introduce the neural network. I use a generic one. We don't really design particular for this operator or for that operator. I mean, they will make differences. It's not saying that they don't have anything. But for us, at this stage, I'm just trying to grab off the shelf. To grab off-the-shelf neural network, you can use it. That's what it works. Just to be briefly, you don't have to read all these formulas. The neural network is you have an input, and you expect to have an output. In our situation, mostly it is you have an Rn input, X is Rn, and output is a number, it's a function value. And then there are how many layers in the neural network, and each layer. In the neural network, and each layer, how many neurons, and how do they actually connect it? What is the structure? There are a lot of very, very detailed study in many, many works. I'm not going to get into any of that kind of discussion here. What I want to say is that even if you're not feeling comfortable dealing with numerical, you can just treat this as a function. It's an input function and it's an output function. Or in other words, Functions. Or, in other words, what I'm actually proposing here in the next few slides has nothing to do with neural network. You can actually use your old traditional discretization. Except that neural network is a little bit fancier or like a convenient for higher dimension. That is the purpose. Fancier is just an excuse, but I think like a classical method still have. Methods still have to face the challenge if you want to do a higher damage. All right. There are a lot of people using neural network for solving PDEs. I think if you search online, you get probably by now thousands or maybe tens thousands of papers on this kind of subject. At least a lot of them, and try to classify them, what they do. Here is my take on these kind of things. Take on these kinds of things. And in the early days, people use neural network. I mean, in the 90s, people already used neural network to improve the classical method performance. So they more likely to use neural network as a post-processor. Say, like, okay, the method is now accurate at a certain place. I'm going to improve it by using neural network. And of course, recent years, probably last five or maybe even seven years. Or maybe even seven years, they start having using neural networks directly to solve differential equations. Of course, most effort has been paid to the higher dimensional problems because I don't think a neural network can compete with the classic method if you have a low dimensional problem. Because we have speed, we have accuracy, we have theory, we have almost everything. And neural network in general, you cannot say anything. In general, you cannot say anything. Like compute, but there's nothing you can say about it. In particular, there's like a very popular one among the different strategies. This is like there's a physics-informed neural network, T-I-N-N, which is quite popular, and I think MATLAB even have a package using it. And also, there's a deep REASNAT. It's kind of used. DebrisNet is kind of using risk formulation, variational form to solve like a please. And also, there's like another popular one, this backward-forward SDE strategies to solve some Hamilton-Jacobi equation type of problems. But each of them is geared towards a certain type of problems. I'm trying to present something that is complementary to It is complementary to all these things, if not like trying to replace any of those well-designed methods. And of course, a lot of people use neural network to do this optimization type of problems. Especially inverse problem, you actually have a few quite a few things available. You may notice that my citation goes to My citation goes to 19, 2019. And because after 19, the paper is just too many. Now I start like lost track about how many. So this is like the early ones. But anyway. So let me try to motivate what is the weak adversary network. We start with the weak formulation of PDEs. That's the starting point. Weak formulation has been used for many, many years. Final difference, you can always, spectral method, you can always derive it from wig form as well, right? So we're going to do this. I'm going to actually say, okay, this is my elliptical operator. I multiply a test function, and then I use this notation. Of course, I do integration by part. The weak PDE solution. PDE solution, there's no need to explain why we want to do it because that's where the solution of PDE usually needs. It's now always have a strong solution. That's the number one reason that we deal with weak solution. The existing method mostly deal with strong solution, like PM. The debris can handle certain type of weak solution, but not every single target. Type. There's another reason is that, well, there are two other reasons why we want to use the weak form. It's actually, weak form, everything is represented in the integral form. Integral format, you can actually use Monte Carlo simulation, or you can use integrals to compute, evaluate everything. And that is one thing found convenient in high-dimensional simulation. If you go to high-dimension, you cannot take derivatives because the derivative. Cannot take derivatives because the derivative is just so messy. But I can compute integrals. You can argue whether your integral is accurate or not. That is an arguable situation. But probably people online cannot see the skies. Okay, alright. Just, I mean, I'll. Move the mouse around, let's see that. I think. Okay. But anyway. Okay. But anyway. Okay, I know. Anyway. But let me let me continue. So most important thing is that in solving PDEs, not like the training neural network in the machine learning community, you need a lot of data, but PDE, you don't have data. We just give an equation boundary conditions. That's it. So this strategy actually provides like Provide like a two-player game strategy, meaning that one neural network is actually trying to poke the other one, generate data at places where they can improve. So that is the most important motivation. In fact, if you go back to look at why people actually define weak solution to begin with, it's exactly from this purpose. Exactly from this purpose, because I cannot really define derivatives at every point for the general PVEs, but I can actually find a nice function, multiply it, and the integration by part, move all the difficult part to my test function. And they can actually, the test function is called test function for a reason because if there's anything you're not satisfied, I'll find it out. So this is the weak solution itself. Start with Itself starts with this kind of game-playing strategy to begin with. That is the main reason why we take this format. Well, with that, this is essentially what I mentioned. That's the slide. I mean, if you kind of like, if I can explain these slides, I think we can actually stop. But I'll entertain a little bit more by showing some of the examples. Basically, the way Basically, the weak solution can be written as a min-max formulation. It's very simple. I define this kind of like an operator, like an operator norm. Essentially, it's very much like the operator norm you define. You have a big solution, you have this integral form, and then I actually divide, normalize the test function just so that. The test function just so that I don't have this strange behavior. Then I take the biggest one and define it as the norm of your operator applied to the function. When this operator will reach to the norm is going to be zero, if you get your weak solution, which is defined by the definition of weak solution. And of course, then you can actually put these things together. I mean, there's only like things together. I mean there's only a unique, if you have a unique weak solution, this is only a unique problem. Any other one will be bigger than zero. Right? So this is just a simple min-max problem for me in that way. And then a very simple way you can actually design a strategy. That's what the next slide is. Planning. It's saying that, okay, I have the weak solution, I parametrized by unusual. I parametrized by a neural network. I mean, you don't have to use neural network. You can use Fourier expression. You can use any other things. Then you take the test function, you also approximate by another neural network. We call the solution as a prime network and the test function as a torso network. And then they start playing games. Because you try to evaluate this operator with Operator with a fixed test function, and then you can actually find out what it is, right? Because fixed test function, you can actually evaluate the operator norm, and then you change your neural network coefficients so that they will actually become smallest with this test function. Once you finish that goal and you say, okay, let me fix this solution, it's not a solution yet, probably. I'm going to change my Probably. I'm going to change my test function to see where this solution is not good yet, or like where they perform the worst. So that's my maximization procedure. So I do this iteratively until the convergence of u is achieved. Or like a in other words, ideally, if I found a zero point tested against any test function, you already got the weak solution. You already got the weak solution. Right? I mean, we're not thinking for convergence in the test function. Test function can be anything. Or, in other words, you can actually prescribe a policy to run your test function instead of actually using this function. I mean, it's okay. We tried that one, actually. It works well, but not as fancy as these min-max things that are automatic. You have to, the other way, you have to actually find a way to prescribe them. Proscript. But in practice, you're not working with H1 or H10. Perfect. That's an absolute excellent question. Once you discretize, replace your solution by neural network, then you are already deviated from the H1 kind of space. Because neural network, so far, unless you use Reg Loo, otherwise everything is smooth. Otherwise, everything is smooth. So, this strategy is essentially trying to identify a solution that is a smooth approximation to it. Not really be able to. But you can follow, for example, kind of this principle that your test function should be smooth. Yeah. The other network can't be relevant because you don't require that the solution to be tested. Yes, yes, actually, indeed, we tried that thing. We actually tried another special. That thing. We actually tried another strategy called the neural network itself is smooth, but its derivative doesn't have to be smooth. You can take the derivative of the neural network as your solution and then do it. Or in other words, I'm actually directly approximating the derivative of the solution. So you can actually, there are a lot of tricks you can play. Sometimes it works for this type of thing, sometimes works for other type of things. There are a lot of like a very A lot of uh like a variability, I would say. And I don't think uh there's a uniform way that you can actually say this is the better. Uh so far we have not found that kind of thing. But anyway, so this is uh just like to illustrate what is the diagram for the procedure. It's basically saying that I have I'm using machine learning language. We have the discriminator, which is the test function. The test function, we have the generator, which is the solution. They kind of like fit back to each other until you don't see anything improving in the solution. That is where the solution is. Of course, this is pretty tricky to define what I consider as not improving because for different problems, it could be very different interpreted. Okay, when you actually do the game training in this like Ford and in this neural network setup, we use package. When the students start writing the code, it is TensorFlow age. Probably many of you probably have no idea what TensorFlow is anymore because it's obsolete. Already, it's PyTorch now. So that's how quick. So that's how quickly these things actually replace itself. So we have to define this trending objective. It's the like they call the loss function. And for us, it's the objective function in the min-max formulation. I mean, we have a formulation in analytical form, but practically you have to evaluate. And how do you evaluate? That comes with a lot of variety. And essentially, same. I have that. Saying that I have that weak solution represented in this operator norm format, and I have to evaluate all the integrals inside. And how do you actually operate that thing? This is basically saying that you have the interior part you have to fit in. This is essentially the solution in the waveform. And you have the boundary satisfaction. And then there's a natural question, then you have to balance it. This becomes a little bit tricky. It this becomes a little bit tricky, and we prefer later we prefer to use design neural network that can actually satisfy the boundary condition accurately or analytically, and because you can actually do that. One of the things, for example, if you have a digital boundary condition zero, just for example, you can say, okay, I design a function which is zero on the boundary and multiply by my neural network, and that guarantees that neural network is always perform zero at the boundary. Zero at the boundary. So I don't have to include that term. I mean, there's different ways to get around if you don't like this kind of balancing thing. I think the inverse community, this is natural, right? I mean, everybody do regularization. There's always a parameter. But all right. I have to be quick, right? I mean, my time is almost up. So let me show you a few examples. So let me show you a few examples. This is a solution. This is just an example to demonstrate the weak solution. When you have weak solution, why this kind of formula is better. This is a weak solution. It's like a roof top. It's an edge. Because the boundary condition we're given is just make it to be a rooftop. And this is, you use the other forms. I forgot, I think. Forms, I forgot, I think this is the PNN. We also try degrees and also give this kind of thing because they try to enforce the function everywhere, like second-order derivative available. And clearly, this function along the rich line, you don't have second-order derivative. But you use the weak form, you get this recovery pretty well. And there's no need to adjust anything automatically. They will actually find. So, that is one thing. So, that is one thing. This is a 2D example just to illustrate that this is actually a complement situation to the existing method in a different way. So, this is another example. Like we have this the true solution. I think this is a dimension of twenty and we don't ask me why this I will write this equation. We just try to make things a little bit complicated. Bit complicated. We'll have an elliptic operator plus a nonlinear term in there. And then our F is selected so that we know what exactly the solution is, so that we can actually compare. And this is the computed solution. We look like, I mean, this is the 20-dimension projected onto a 2D situation. I think this is a 5-10 dimension projection, if I recall correctly. If I recall correctly, this is the error of the difference. And if you look at it, the scale is a little bit small, and it is about like less than 1%. And this is like the decay, if you go on and you look at the rate of decay. I mean, this is the training process. They play each other, the the loss function is getting smaller and smaller. But also not thoroughly, because we use stochastic gradient descent as well, which is non-monopole. Which is not monitor. This is another function on a different domain, just like a because this setup doesn't really care about what is your domain. I mean, it doesn't have to be particular. So we take an L-shaped domain and then compute it and have a similar, pretty good situation. This is a 10-dimensional situation. This is another example, just try to illustrate. You can actually You can actually work on a time-dependent problem because this is something you can actually do very similarly. And here, when you have time involved, you have two probably two different considerations, like do I actually do slice of time in this formulation, or do I actually take time as a gigantic another variable and do it as a whole? I think this is the example uses. We tried both, we will show the example comparison. Example comparison in the paper, and there's not much differences in general. Yeah, I believe so. But I don't ask whether this equation makes sense or not. It was just artificially created to make it could blow up. It could blow up. We compute up to time equal to one. So we just want to see. So, we just want to see how it works. Didn't not pay attention to, I mean, we want to try different types of nonlinearity and different things. This is like another example. So, let me just quickly summarize. This is a slightly different framework to understand, or like using Min-Max framework to solve differential equation, which we usually solve Min-Max problem by come back to differential equation and solve. I come back to differential equation and so forth, which is, I mean, we are advocating going backward in a different way if you have higher dimension. And this is like a sample points in the evaluation. You can do whatever you like. I mean, we tried this important sampling strategies. Sometimes it improves, sometimes it doesn't improve. Actually, it's quite strange. And then there's no mesh, no base in the setup. You can use mesh if you want. You can use Mesh if you like. Only thinking convergence in U now in the test function. It's kind of different than the existing framework. That's what I want to say. Now let me go back to the inverse problem because this is a slice, it's essentially copied from earlier slide. Now I'm having an inverse problem. This is, I mean, you think. Inverse problem, this is, I mean, you think about this is the operator, the classical inverse problem. I call it EIT, but not really EIT. It's just formed in operator form, it's like EIT. But we don't consider Dishland Noin map type of things. We don't need to use that kind of thing. It was just like whatever the boundary condition you give me. Even one pair is okay. Only just one. Not even the map. Just take. Uh just take that I think. You if you ask well what is the reason why I have to do EIT in higher dimension, I have no clue. It was just an example. I mean just to try to demonstrate that this is possible to do it. Because in 2D or lower it doesn't work. I have no idea. I will try 2D actually. I have no idea that. I know that the regularity and also like the lot of theoretical considerations seem lower than. Theoretical considerations in lower dimension. I heard about it, but I'm certainly not an expert to address those kinds of things. So the inverse problem is that you have this parameter. It's also unknown. In addition to you, you have to find that out. That's only purpose. Inverse problem, like use neural network to solve inverse problem, you find much less references, only not too many. Only not too many compared to the full PDE, that's just a huge literature right now. Inverse is not that much. The formulation is almost identical as before because why does gamma as an unknown in that place play any other role different than the solution? Right? It's just a different position. So I'm going to actually treat this in the very same format. This is in the very same format and do it in the very same way. The only thing I did differently is that I use a solution network and I also use a coefficient network. I have two different neural networks to harmonize them. I even use, I mean for simplicity, I even use the same statement to represent them. You can actually, in neural network, you can actually put them together. I mean, it doesn't really matter. But you can do the same strategy. But you can do the same strategy. Or my punch lab here is actually doing inverse problem, doing forward problem using this framework. It's the same. I don't have to search for like a forward problem solver and come back to do the inverse problem solver. I can just do the same thing. Right? That's what I found the most interesting part about this formulation of the inverse problem, is that I don't need to solve a forward problem in order in order to In order in order to you know uh do the universe talk. Alright, you can actually I mean this is a you now something important. My time is up, right? Yeah, so just one second, I'll finish. So you can actually do the announcement saying that how this is a convergent, you can prove it, some of the convergence. And this says like, okay. They say it's like, okay, if you use SDG and it trends, I mean, it will get to a stationary situation, but there's no claim of this is actually the solution you're looking for. It's all of, say, it's critical points, because mean-max problem maybe have many, many critical points. Especially after you discretize, mean, after you replace it by your network, then there might be a lot of problems. I mean, that's one thing. Some of the implementation detail, if you're interested, I can share with you, but I'm going to skip these things and show you some examples. This is one example and just try to show that this is the true coefficient, and this is the difference between the true coefficient and the recovered one. The scale is on the 5% order. This is a five-dimensional situation, no noise. No noise. You can actually do other ones. Like this is what I say, the EIT, but this is not really the EIT, what we usually understand. Except just like giving a boundary condition this way. I don't mean a map in some sense. Having this, you can actually recover. I mean, this one we try to do a comparison so that this is like a Comparison so that this is like getting a little bit straight, like a piecewise constant type of thing. You can actually add noise, 5% noise, I think, 10% and 20% noise. This is pretty robust against the noise in the recovery. The dimension came into play in the evaluation of samples, but not in an exponential fashion. So it is an elaborate. So it's a in our experiment, like we kind of like made it a linearly dependent damage. This is just another example to try to illustrate different type of shapes of the confusion kind of recovery. We tried like one circle with another circle inside and didn't work. I think like probably thing that it's very difficult to make it work. We also try to do some of the inverse of other type involved time. And this is actually the coefficient itself depends on the solution type. And then you can actually recover it pretty well in between. Alright, I should stop because I'm running out of time. We try to advocate a min-max formulation, go against the the normal way of solving PDEs. Way of solving PDEs as well as the immersed problem using neural network for higher situations. You don't have to use it if you don't. A lot of questions that I have say that we keep asking ourselves like this kind of questions, like a convergence, is there a convergence? I have no idea. Pretty much all the experiment. It's not easy to train, as anyone have experienced about advertising. Anyone have experience about adversarial network? The training is a little bit tricky. The min-max problem is not easy to train. But somehow we managed all the tests that we tried it, we managed to make it a convergent in end. I don't know whether it's a coincidence or it's actually, this is actually there's a convergence behind it. I have no idea. The accuracy up to relative error, 1% or so, it seems to be. 1% or so, it seems to be always achievable. But like a better accuracy, I don't know, because it's always getting flat in the end. I don't know whether it's because of the neural network itself or it's the formulation that makes that flat. That is another thing we have no idea. The stability is one of the interesting things. It is quite stable. It's not like it's so sensitive. We have never used any regular. Any regularization in the process. Always find the one that we intend to find, even though with totally different initial conditions. It's kind of like that one is a little bit surprised to us. We were our original plan to see whether there's some regularity needed. I mean regularization needed. Well, the speed is there are a lot of improvement that uh needed. Uh Improvement that needed. And we have some ideas, but not really have time to carry out here. With this, thank you. Thank you, Helmin, for I think three thoughts. Maybe we have time.