Okay, good. All right. Hi, everyone. I'm not going to repeat that long title. I will start with the acknowledgements. First of all, thank you so much for inviting me to this workshop and for giving me the opportunity to give this talk. I'd like to also thank all my collaborators who Thank all my collaborators who participated in one way or the other in the results I'm going to show you. And we recognize Mar here and Georg, and also I would mention Tony from YouTube now, Georgia Tech, Alice, my graduate student, Tucker, my former postdocs, Lekan and Rue, who are now away from New Simerstad, and my collaborative. And my collaborator in Umberto Villa. I also want to mention, he did not touch the button for the recording, right? I did. It didn't. Yeah, you're. Everything will be used against you. Every time I give a talk, I want to make sure that I thank for the funding. Especially the new results have been funded by NSF and I would like to mention my NSF career grant which funded me in the last two, three years. Me in the last two, three years. I would also like to acknowledge that I'm really happy to meet people whose papers I've read in the past, Hirmar and Olga and Matthew and Ellen. So it's really nice to meet you guys and to finally meet you guys and to see you here. It might be worth hitting the knot now just so we're not distracted by that. Thank you. Thanks. So, okay, so I'm an offline mathematician. Okay, so I'm an applied mathematician. I will present, I will focus more on methods, developments, and algorithms, but applied to ice sheet inverse problems. So a couple of slides you have to hang in there are a little bit more generic, more abstract, but eventually I will turn to Stokes and I Schittimer's problems. So in abstract form, I assume that we have a forward problem governed by Forward problem governed by a PD or some differential equation, which we solve for some state or forward variable u, and the unknown parameter is the red m. And then the inf also I will, in the interest of time, I will put a lot of mathematics under the rug. If you want more details, please let me know or we can talk after. I also have lots of citations, so please check out the papers. So the inverse problem is the following. So, the inverse problem is the following. We want to use some available observations to infer some unknown or uncertain parameter in the model. And so, you have this relationship between the forward map or the parameter to observable roadmap, which I denote by F, and the data. And so, obviously, there is noisy measurement and model errors. So, we put all those things under this extra term, which is eta. This eta This eta, typically we model it as a Gaussian with zero mean and some covariance. And that's about that for now. So as you have seen yesterday, one way to invert for these parameters is via deterministic inversion or the so-called OCAMS approach. So one of the issues with these inverse problems is ill-posedness because the observations are usually sparse and the Are usually sparse and the forward operator smoothing. So we essentially lose information. And so what that leads to is that many different parameters could explain or could lead to the same data. So we have to deal with that. We deal with that in the deterministic setting by adding some regularization. Alright, and we have seen Mauro give a really nice description about Description about this, I'm not going to say that. So instead, we take a vision approach, which is a nice framework which will allow us to incorporate uncertainties in the parameter. And it's a more systematic way to add so-called regulation. We have this prior term. And so this, what you see here is just the Bayes formula and infinite dimension. So basically, the posterior distribution is proportional. The posterior distribution is proportional to something like this. The first term is nothing but the negative likelihood. In a deterministic setting, this is just a misfit term. And then you have the prior, negative prior. So what's the target? The target is to characterize this posterior. So this is the general solution of the inverse problem, taking into account the certainties in the inversion. So we want to characterize the posterior, we want to find the mean, the covariance. Posterior, we want to find the mean, the covariance, and so on and so forth. And we want to do this for functions, which means these are high-dimensional parameters due to discretization. We want to be able to solve these problems in a large-scale setting because of the high-dimensional dimension for the design and for expensive to solve forward models, such as the non-linear Stokes in 3D for Antarctica, for example. How do we do that? We exploit connection. That we exploit connection to VD constraint optimization. Alright, so using this Bayesian inference, the first step is to find the most likely or the point that maximizes a posterior. And this is the so-called map point, which is obtained by solving this optimization problem. It's the minimum optimization of a negative log posterior, which can be written exactly like this. The nice thing about this expression is that this is nothing but Expression is that this is nothing but the deterministic inverse problem. So, if you know how to solve this efficiently, you can get your map point. Alright, and then if this parameter to observable map is linear, then it turns out that the posterior is a Gaussian and is completely characterized by the mean, which will be this map point, and the covariance given by the inverse Hessian of this negative log posterior term. And I will show you how to get those. Uh and I will show you how to get those things in a second. But I want to point out that if f is not linear, then we should not expect uh the posterior to be Gaussian. So uh something like sampling is necessary to fully characterize or explore this possibly a non-Gaussian posterior in high dimensions, which is not trivial. Okay, so how do you solve this optimization problem efficiently? How do you get gradients and adjoints? Matthew and Maurice. Matthew and Maureau mentioned yesterday about adjoints. So we do the same thing, we use the Lagrangian. They have lots of equations, but at least I make them colorful so it's not too boring. You appreciate that. I will not mention everything. You can ask me questions if you are interested. But the point is that we use the so-called Lagrangian formalism to get the gradient, which means that we work with adjunct. We work with actual. So, every evaluation, one evaluation of this gradient means that we need to solve the non-linear forward solver and one linearized actual problem. And then to get the hash in apply, you go one step further and you can write two derived second-order adjoints. You can do a little bit more extra and rewrite this Lagrangian in a clever way. Clever way, and sure enough, the Hessian apply comes out in terms of PD solves. So the cost of applying this Hessian to a vector means solving two linearized tokes. So once you have the whole framework, you know, solves and codes, you can actually reuse a lot of those. And you have the Hessian, which is very, very important both for the inverse solver, but also for the posterior. For the posterior. Petra, very quick question. How do you get Haitian? Do you have to compute it in the same way as Jacobian, or do you get it some other cheaper way? I mean, right here, you have, you basically solve, I don't have them here, but you basically solve two PDEs. But if you write the Hessian, I don't know, it's somewhere here, right? So maybe this is. Somewhere here, right? So maybe this is something you are very familiar with. You see something like the prior, and then you have a forward, and this looks very much like the Jacobian, Jacobian Passpose. But Noani, you're not calculating the assumption explicitly. No, no, no. It's applied. Oh, it's applied. Yes. Yes. Sorry. Good. Okay. So now let's turn to the application. So this is the forward problem. And we have seen this many times. This many times during this workshop. Just want to point out that we use the pool stokes, and the parameter of interest is the so we use this sliding law and we use the glass flow law rheology law. And so the parameter of interest is this sliding or friction coefficient. And in addition, I'm also interested in glance flow exponent parameter. I just want to give you a heads up what's coming up. Your heads up, what's coming up. At the end of the day, I'm going to infer for beta and take into account uncertainties in n. So instead of inverting for both at once, I'm going to describe this with some probability distribution and then infer for beta. But before that, I just want to show you what we have been doing in the past. So we have been able to solve the inverse problem at a large scale. Problem at a large scale. So the parameter dimension here was about half a million used for developed in Omar's group by OBISAT. And this has been published already in JCP. So I just want to show you that we were able to solve this inverse problem and get a really nice reconstruction for the Bayes Lighting coefficient. We have been also able to characterize the uncertainty in the reconstruction by using. By using a Gaussian approximation of the posterior. So here I'm showing the variance for the prior distribution. So basically, you don't know anything about the parameter. And then using data, you update the prior and reduce the variance significantly, as you can see. So this has been done in the past, but we also played with the idea of pushing data through inference to prediction, and we To prediction, and we looked at the, maybe it's more proof of concept for you guys, but we were able to actually go from data to prediction. And here I'm showing the gradient and some influential direction in the parameter space. So basically, we were able to compute the mean and standard deviation of the prediction probability distribution for an ice for the ice mass flux. That's what we got. I have to emphasize that we have. But I have to emphasize that we have used steady state SOAC, so this might be not very realistic, but the framework is scalable. It's parameter state and data dimension independent, so this might be useful. And if you are interested, please talk to us. In doing so, we were able to actually, Omar mentioned yesterday and threw it in this slide to show you that we were able to work in this large-scale setting because we took advantage of the structure of the problem, in particular. The problem. In particular, we looked, we made use of the fact that the data is just so much informative. And so, really, the parameter dimension in a one million or half a million problem setting, the effective size of the parameter is really much, much slower. And in this case, it was about just about over 4,000, which really gives you maybe a little bit more room to work with. To work with in this uncertainty quantification setting. And then I show you some eigenvectors just because they can, I guess. Okay, we also did some work in inverting for the glance floor exponent parameter. And these are just some academic examples taken from the ISMEP problem, benchmark problems. And I think really just the idea I want to put through is that you could, in principle, That you could, in principle, invert for N, even though the scary thing is that you have observations at the top, you have to invert for a 3D field. But this is a toy problem, right? So in an Antarctic setting, that might be a little bit more challenging. And also, we have considered the beta field given. So, in principle, or in theory, or ideally, you should do the inversion for both. You should do the inversion for both at the same time. The issue with that is the problem becomes more high-dimensional. First of all, you are adding an inversion parameter which is infinity, and also you add even more ill-posedness into the problem. So we are going to take the route of inverse problems governed by random please. It's exactly what Hilmar was pointing out yesterday: is that effectively, if you invert for both, you can both. Work for both, we can link information from one to the other. So, how certain those fields of parameters will be how yeah, I mean if you do that, then you do also an achievement equal to mission step afterwards, and you can say how certain you are in the reconstruction. So you can do the same thing I've done for the laser sliding, but it's it's more expensive, of course. It's yeah, it's pretty much getting not tracked about. Pretty much getting not tracked about. So then it's really a modeling question. You focus on one primary parameter of interest and then consider the secondary uncertainty and you put it in as a random parameter in your model. And so your forward problem becomes something like that, where u is again the state, m is the primary uncertain parameter, and something else after. So in this, for the I shit problem, let me just say for the I shit Problem, let me just say for the I shit problem, this is beta and this becomes n. So how I tackle this problem, I'm taking, actually I'm borrowing ideas from a work by Yari Kaipio, Somersalo, and this is the so-called Bayesian approximation error. It's a really cute little simple idea to others, but of course there is room for improvement, and I'm interested to push that forward. So really, this is your This is your relationship between the data and model I had before, right? So, the idea of this PAE approach is to approximate the model in some way. So, that's f tilde. So, basically, just say fix n equals 3, because that's what everyone is doing, right? And that's an approximate model. And then you account for the model error. So, you don't put it under the rug of eta anymore, but you explicitly take care. Explicitly take care of it. And so this becomes, the inverse problem becomes like that. And so this is the accurate parameter closed or map, F tilde is the approximation. This guy here, the error is a model error. And we consider it as a Gaussian. And so the issue then is to somehow estimate the mean and the covariance of that. And then the total error will be also. And the total error will be also Gaussian. So the only difference is that now you lose around that's true, yes, exactly. But also the covariance changes, right? So it will be a big change because this gamma noise is typically a diagonal. This becomes a non-diagonal variance matrix. Okay, how do we, so this needs to be taken care of. Needs to be taken care of, and we do that at this stage with Monte Carlo setting. So, basically, we are taking samples from a prior distribution on n and we have to solve the oral non-linear problem, but also the approximate model. So, that's the cost of one sample. This becomes a little bit expensive for the case where you need a high number of samples. But this can be carried off offline and also in parallel, it's really embarrassingly parallel effect. And so, okay. Effect and so, okay, it's fine, but I'm very interested to improve on this. But so far, this has been working quite well. So, now with this new mean and the covariance, as Mauro pointed out, the updated posterior looks like this, where the covariance operator changes, and the mean is different. The priority is the same as before, and the posterior covariance is now taking into account this proximate model, of course, and then the Of course, and then the new covariance sits in there. So far? Okay. And for the results, we are going to compare the ideal situation where you have the truth. So somebody gave you n true. And so you compute, so this would be the likelihood. You compute the posterior covariance. And then we looked at the case, so-called conventional error model, pretty much what we have done in the past. What we have done in the past. So you fix n to some nominal value. For our case, it's n equals n0 equals 3. So that's that. And so you use this approximate model, but this doesn't know about this new covariance. And then this BA approximation error, which is the same as this, but the difference is that you have the corrected covariance. Okay? And so the example I Okay, and so the example I'm going to show you again goes back to the X-MIP benchmark problems. Hopefully one soon we'll test it on more realistic problems. So I look at one, two examples. One example where the model error comes from the fact that instead of working with the non-linear Stokes, I just work with the linear stokes. So that means that I will use the BAE approximation or this approximation method to just use the linear stokes and correct for the non-linear stokes. And correct for the nonlinear part from learning from samples from some prior distribution. Okay, and the second one is a non-linear reality where we just use any Gaussian. And these are the results. So this is just the prior. I did not mention mathematical how we define it, but if you are interested, talk to me. So this is a prior, a Gaussian, just showing the mean and some samples, and 2 sigma, 2 plus plus 2 minus 2 sigma or To sigma or standard deviation. This is the ideal situation. So this is, you don't really have it, but this is where we want to be. And this is with a conventional method, if you don't take into account the model error. So what happens, you're overconfident in your posterior, but also the truth lives outside the posterior. So basically if you sample this the hell out of it, you will never cover your truth. Cover your truth. This is not good, not correct. And this is with the VA approach. You look at the variance compared to what you want to be. It's a little bit higher because you add more uncertainty via this model error. And sure enough, the truth lives within the support of this posterior. So so this is good news. Okay, so this was for the linear reality. This the second example I'm going to show you is for the non-linear reality, but it's pretty much the same. Reality, but it's pretty much the same story. And finally, I just want to show you the structure of the new covariance matrix. This is kind of cool, I think, because we are used to, or I'm used to using a diagonal noise covariance matrix with some constant weights for the observations. And this PA approach really gives you a systematic way to incorporate correlation between observation points. And so, for instance, I'm looking at the blocks, it's a two-dimensional. The blocks. It's a two-dimensional problem. I'm observing the x and y components of the surface velocity field. So the way we ordered the degrees of freedom here is that this is x, x, x, y, y, x, y, x, and this is y, y. So let me focus on this. The diagonal just shows that there is a lot of correlation between the points, nearby points. This is expected because if you have observations and you Because if you have observations and if you use only the noise covariance, right, then the measurements could be independent, and so there is not really correlation. But if you are adding the model into the picture, then suddenly this correlation pops up, which is what it should be. And then what else? I think that's about it. And the magnitude really shows how much uncertainty you are pushing on your observations. That you are pushing on your observations. Yes, welcome. Very quickly, you have a lot of kind of colour or a lot of connectivity on XX version. Is it because your data come from the surface? Yes, but all of them are coming. Well, all of them are coming from the surface. It's just that this is the version. But this XX component that refers to the surface, you don't have any information from Y component. Okay, exactly. Okay. Okay, and this was for linear, this is for non-linear reality, just to show that there is, you know, there are similarities. And to stay, oh, advertisement for, so these model problems, I'm really, you know, I'm kind of proud of our little inverse problem solver tool that we are developing and it's funded via NSF. And this is in collaboration with Omar and others. And so this is a nice tool for. This is a nice tool for research and academic exercises. If you or your students are interested, please check out our website. Our tool is called HIPLIB. And so all the examples I'm showing for the ISMI mental problems are done with this tool. So if you are interested, please let me know. And I will leave you with a list of, it's kind of a wish list and research interest for me. Basically, I'm interested to make these large-scale problems tractable. I focus a lot on approximations for questions to improve the inverse solver, but also to be able to do more meaningful certain quantification. I want to reduce the cost for the PA approach, and I'm thinking to combine it with some tailor expansion approach to make this more flexible for large scale problems. I would be interested in other basic siding laws or reality laws and to accountable models. Loss and to account for model error. I would like to apply this technique, more interesting geometries like the Pine Island glacier to start with, and other physics. Amoru gave a really nice list of interesting physics that you can add to this problem, so I would be interested to pick that out as well. And of course, this came out yesterday. Omar, Georgia and I, we have done a lot of work in optimal experimental design, and this sounds like And this sounds like a nice application for applying all those techniques to get more richer, meaningful data. Thank you very much. Okay, so we have a couple minutes for questions. Maru, I think uh understand how you estimate the and uh And uh it also is that um more expensive than the usual um calibration with an inference? Um so the covariance discovariance you mean, right for the okay. Oh yeah, okay, you have a good expression. Right, so it's this is just a covariance expression, right? And this is done here and you just take samples from the prior. So these are samples from see. So yeah, so you are So, yeah, so you are sampling N, right? So, and for every sample, you have to sort the true model and then the approximate model, and you get the sample. Okay? And how much is that? Typically, well, we have tested this framework on a Poisson problem with rubbing coefficients. We needed about thousand samples. Yes. The BAU work that you introduced, I guess, a little confused by the level of complexity needed, but maybe it's again misunderstood. So this is an example of a parameter that is not independent from the other parameters. So if you had something that is independent, like climate forcing, and you knew from various other means about the uncertainty of the climate forcing by the properties of sort of like By the properties of sort of like Gaussian random, uh, Gaussian multivariate Gaussians, you could simply propagate the uncertainty, the variance from the sort of like independent climate forcing and add that to the uncertainty, the propagated variance from your inverted uncertain variable, right? Yeah, so if I understand correctly your question, I think, I mean, that's what you do here as well, you, but in this case, that would come from somewhere else. It's like a It's like a prior on the secondary and certain parameter. So that you can use it. That would be great. That's the ideal situation. You should use that. Right, I guess my question is, if you had, if your second parameter was completely independent of the one that you inverted for, you wouldn't need to go through this complicated framework test. But this is, we are actually assuming that it's independent. You would have to go through. It's an external forcing, so it's still a stochastic PDE, and you'll Stochastic PDE, and you'll get a distribution of the expectation of the likelihood. You still have to compute all the expectations of the likelihood. But I thought it was sort of independent or additive in a way. The variance propagated from the external force in it. That's another map. So you can't you know you have to you have to say, okay. Yeah, I I like how you build up that covariance measure, which would be exactly my question for it. Would be exactly my question. So that's really, really need. But when you do this, I guess when you did explain where we get the sparse, how sparse is it? And did you model it then afterwards? You are talking about the quantum trips. How sparse it is? Because this tends to show children's object. Because the inverse of a sparse covariance metal is not actually sparse. So did you model this covariance metric? Did you just calculate the way it was? Did you just calculate it the way to describe it and switch that direction? So we actually calculated this, and this lives in the data dimension. So you can actually. These are the values you use. There's no modeling or local areas on it. It's just something that you really built here. Isn't that slow to think about what you would expect? I mean, you are right, you are actually needing for inversion processing, right? I thought you could then model that cobra image matrix so that you get a step. So that you get a sparse matrix rather than the basis. You could do some type of SVD, randomized SVD, and take advantage of some type of low-rank structure for this as well, and you can then just apply it. You can use some type of Sherman or something. Yeah, so there are ways to deal with the apply in a efficient way. Okay, quick question just on your last slide. For the inner end and non-inner ends. Not just like the single slides. For you show the covariance features. Oh, I see. I'm sorry. Yes. Can you just comment a bit on the fact there's quite a discrepancy between the linear and non-internal case? Linear and non- I mean, definitely the the model error is much higher that we know. Um other than that I don't really know how to interpret. Let me just say that this is also current work and it's kind of out of the oven.