Thank you so much. I actually changed my title a little bit just to be provocative a little bit. But yes, my name is Mona Karja. It is such a pleasure to be here. Thank you so much for the invitation. It is such a pleasure to see old friends. I've worked on a lot of different problems throughout my career, but since starting at CMU a few years ago, we've really kept our head down and focused on this idea of shape and structure. Of shape and structure of complex biological systems. How does spatial or population structure shape evolution? And I don't have to, again, sell to this audience that from cells to communities, natural systems exhibit a lot of spatial structure. And similar to some of the questions that Daniel is asking, when is this important? So these questions, how does population structure or spatial structure shape evolutionary dynamics? Shape evolutionary dynamics have had a long history in population genetics. From some of the early papers by Mariyama in the 70s, there's a lot of different models of population structure. Most previous modeling approaches represent population structure as connected communities of patches or deems. You have all kinds of different flavors of models from continent islands, stepping stone. Island stepping stone, lattice-based models, isolation by distance, and so on. And specifically, lately, a lot more work on spatially explicit metapopulation models. And the benefit of a lot of these different models is that they are intuitive and they are analytically tractable. We care about analytical tractability, and I'm going to come back to that a lot over the course of the talk, especially for the students. Analytical tractability can provide so much. Political tractability can provide so much intuition. In a lot of these different models, unless one makes, adds the spice, kind of like Elene was saying, and adds, makes different assumptions on differences in selection between deems or no, and assumptions of periodic extinction and so on. What these models find is that overall, spatial structure changes time specification of new mutations of the plant. To fixation of new mutations of the population, but really doesn't change probabilities of fixation. Now, even though these models are absolutely fantastic to work with, some of the challenges that appear is that their predictions are hard to use for incoming data sets, especially molecular and cellular data sets, with a lot of spatial heterogeneity, a lot of complex patterns of co-localization and interaction. And interaction. Now, the problem is that trying to move towards more complex topologies is much harder to study. So, the challenge lies in finding the right spatial representations from your problem that capture complexity, but also, importantly, allows for mathematical tractability. So, just to give some examples, right, for certain questions, the spatial representation is easy. So, for example, if we want to understand how the population structure How the population structure of a host community shapes rates of mutation accumulation in a virus like COVID, for example, or pathogen. One can use the mathematical proxy of a network to represent at this level organization spatial cartographies that can reflect patterns of contact and human activity. At other scales of organizations, finding the right structure is not always as intuitive. Not always as intuitive. So, I do, a lot of my work is motivated by the fact that we are entering this era and we are already in this era of in molecular and cellular biology where we are starting to have unprecedented windows into their spatial organization. A lot of computational techniques, machine learning techniques, imaging, ability to process large amounts of data at scale gives us this unprecedented windows. And just to give you an example, Windows and just to give you an example, this is data from one of my collaborators. What you're seeing here is a window into the femur of a mouse, the bone of a mouse. And so as you're traveling through this bone, our collaborators are able to map the different cell types, are able to detect using information on the different cell types, where are the stem cell niches in this bone. These are the little blue little round dots. Blue little round dots, and you can get this architecture, you can get this spatial representation of the stem cell niches in the bone marrow, and you can start building these different maps. You also have information on how stem cells travel between the different niches. So, the niches are stationary, the stem cells travel, these are long-lived cells that can accumulate mutations, and so you And so, using this information on where the stem cells are, the migration rates between the stem cells, you can start building these connections between the different nodes and again, start building these networks that represent the architecture of the stem cell niches. And these types of data sets allow us now to ask new questions. How does the topology that The topology, the architecture of the stem cell niches shape mutation accumulation in these long-lived cells. So, back to this question: you know, spatial representations are easy, and in a lot of cases, we can use the mathematical proxies of networks. Turns out that networks are a very versatile way to represent these population structures, and one can use networks, this mathematical proxy of networks, at various scales of our At various scales of organization, right? And one can have these spatial distributions on the left and connect them to a mathematical representation on the right. So the problem then becomes, right, how does the structure of the network, the topology of the network, shape, for example, probabilities of fixations of new mutations, times to fixation, and so on. So what I'm going to talk about in this talk is the simplest possible In this talk, is the simplest possible model, which is a Moran model: a new mutant coming into a random node on this network and spreading through this network. And the evolutionary dynamics, we're going to assume a birth-death dynamics where at each time step we select a node for birth proportional to fitness. We select a neighbor for death. And this is where the comparison to a well-mixed population lies, because in a well-mixed population, Population-wise, because in a well-mixed population, you'd select a node from the entire network. Here, we just select a neighbor for death, and then we replace the node selected for death with the offspring of the original node. And so the effect modeling, this Marin process on networks, the effect of population structure, has been seen or classified in three different groups. So, graphs can be either amplifiers of selection where one can see. Selection where one can see that in these types of topologies, a mutant appearing, an advantageous mutant appearing, has a higher fixation probability on this graph compared to a well-mixed population. And disadvantageous mutants have lower fixation probabilities. Another way to think about it is that the balance tilts towards selections on these graphs. So if you look at selection strengths on the x-axis, you see this crossing right at neutrality. Crossing right at neutrality, and you see the difference in fixation probability between the amplifiers and the well-mixed. Similarly, you can have the opposite. You can have suppressors of selection, which allow for lower fixation probabilities for advantageous mutants. And then in the middle, you have these isothermal graphs that do not change fixation probabilities similar to previous models. And there are many. And there are many previous studies that look at evolution on graphs, but some of the challenges with studying these graph families is that it is very hard to find some kind of way, unified way of putting all the different graphs together. That's why a lot of studies focus on particular graph families, stars, superstars, funnels, bipartites. And there are benefits to studying these particular structures. These particular structures, you know, they're easy to manipulate, allow for more complicated population dynamics, but it makes it hard to understand new graphs from new data that maybe do not belong to a particular family. So how do we build a unified view of how these more heterogeneous graph structures shape evolutionary dynamics, even for these very simple particular models? And again, what makes this problem very difficult is that networks are in. Very difficult is that networks are intrinsically messy, right? They have a ton of properties that can be quantified. If you want to change one property, it actually correlates with all these other properties, and you don't really know which property really drives the dynamic. So, you know, you don't, this is tiny, you don't have to read what it says here, but it just lists a lot of different properties in each graphs can vary, right? So, how do you get to the role of particular graph properties? How do you build intuitive? You build intuitive understanding of what's important for evolutionary dynamics. So, what we show in our work is that while we think that things are very messy and difficult, actually it turns out that things are not as messy as it seemed to be. And we can make a lot of progress if we compute these two evolutionary properties of networks now. And these two evolutionary properties, which I'm going to go. And these two evolutionary properties, which I'm going to go a little bit in detail of, are the amplification and the acceleration factor of a network. And what allows us to do it, and a lot of details in this talk, for purpose of time, are kind of swept under the rug. What allows us to study these networks are also computational advances that actually allow us to tune network properties independent of each other, to tune variance in degree, independent from mean degree, mixing pattern correlation in degree, and this really allows us. And this really allows us to study individual properties of time. So, to start with the amplification factor, amplification factor again quantifies essentially how do we scale a selection coefficient S for the well-mixed model to obtain the same probability of fixation as an allele with coefficient tests on a network population. So, again, if you have this amplification, select a parameter on the x-axis, probability of fixation on the y-axis. You have the well-being. On the y-axis, you have the well-mixed model at exactly one, right? One amplification factor. And then the amplification factor essentially quantifies this, right? By how much does a network amplify or suppress. So now you put all kinds of different networks on this plot. You can see that some networks are suppressors, some networks with amplification factor larger than one are amplifiers. Or larger than one are amplifiers. And here, every dot is a simulation, and this line is our analytical approximation. So we're able to write in a closed form this amplification factor and get analytical approximation over a large, many different types of networks. And also, something else to point out, these networks can also be very large, thousands of individuals. So, just to give you a little hint into how the math works. Into how the math works, right? A lot of different previous approaches to the problem, mostly from Martin Novak, Ben Allen, Arn Charles' group, have managed to build these analytic approaches to networks. But again, in a lot of these different cases, very small population sizes and still very regular graphs. So one numerical type of approach are approaches based on the adjacency matrix, right? Which nodes are connected to which other? Which nodes are connected to which other nodes? The benefit of this approach is that the adjacency matrix uniquely identifies a graph. The problem is that this ends up being that due to the number of nodes Moran process, it becomes very hard to manage very, very fast, right? And so these types of approximations really are not scalable for graphs of much larger sizes and a lot more heterogeneity. Other beautiful You made. Other beautiful approaches by Ben Allen and the limit of neutrality fail to necessarily kind of break down when you start increasing selection, right? When you're trying to move away from this limit of neutrality where analytics just doesn't match simulations anymore. So, our approach is an approach that initially we thought, oh, I don't know if this should work. It shouldn't really work. We use properties. Properties of the network's two main components, the nodes, and the major properties of the nodes are around the degree distribution and the main moments of the degree distribution, mean and variance in degree. And properties of the edges, the mixing pattern, the correlation in degree, how many times nodes of low degree are linked to nodes of high degree. And so at a very big picture, At a very big picture scale, our analytical approach is that instead of using a unique identifier, the adjacency matrix, we kind of take all nodes of the same mean degree, we group them together in the same class, and we actually transform this problem into a finite island population type model where we write the probabilities and then we keep track of the mutant on these different classes. And it works really great. And so this allows you. Great. And so this allows you to both understand how the different network properties affect evolutionary dynamics. So, for example, variance in degree, if you keep mean degree constant, always increases fixation probability. But also, what other properties that we might not expect come into play? All of the different graphs here, every node is a graph. All of the different graphs have the same mean degree, and all of the different graphs have the same mean. And all of the different graphs of the same color, for example, take this graph, these graphs here in green, have the same variance in degree, and yet a huge range for probabilities of fixation. So there's something else. And so because we have closed-form solutions, we can see that our amplification factor really also is correlation in degree explains this. So if you now plot the exact same graphs and look at probability of fixation. And look at the probability of fixation while accounting for this mixing pattern, the variability of degree-edge connection, you capture this lost property. And so, both our computational models, but also our analytics, really allow us you to understand why, because you can rewire one edge, track the change in the amplification factor, and see how that change affects the signs and magnitude. So, the amplification factor, for example, increases when there are more edges. Increases when there are more edges connecting nodes of low degree to nodes of high degree. Now, supplementary side for people who know more about this, we can also definitely do this for death-birth. And it actually ends up that for death-birth, mixing pattern doesn't matter. So it's just a mean and variancy degree. And this allows you to design graphs that kind of connect from minima to maxima of probabilities of fixation that you have. So back to our stem cells. If we use these representations, and a lot, there's a lot Representation and a lot. There's again, there's a lot of work under the rug here, a lot of robustness tests. You find that, regardless of the process, these graphs are suppressors of selection, hinting potentially, maybe we need to validate this, that maybe these architectures have been tuned to suppress mutation accumulation in these tissues. So, a lot of the different projects in the group have this sort of framework of quantifying these complex population structure. These complex population structures, finding these mathematical representations, combining them to model and linking models to data. Now, a lot more briefly, right? The acceleration factor. So it turns out that time subfixation really also matter for rates of information. And previous work has found these trade-offs between fixation probability and fixation time. If you want to increase fixation probability, it comes at a cost of increasing fixation time. But again, I want to point out that this work has been mostly done for graphs. This work has been mostly dactyled graphs. They're still very, very small graphs. So we wanted to ask this question: is there a way to decrease time to fixation while keeping probabilities of fixation constant, to increase or decrease it? And we were very, you know, in vain of being a student of Mark Feldman, we were inspired by a paper from 1965 and decided to study the role of cliques and higher order motifs in these patterns. So if we looked at the lower order motifs, right, these The lower order motifs, right? These matter, the nodes, and the edge properties matter for probabilities of fixation. Higher order motifs are these triangles, right, or connections between multiple nodes. And so again, we build these algorithms that allow us to keep lower level properties constant and really just vary the number of triangles. That's it. That's the only thing changing here. And indeed, triangles do not change fixation probabilities, but they can really affect time station. But that can really affect time specification. So, again, every single graph here has lower properties kept constant. And so we can find this acceleration factor that allows us to quantify the time on a graph compared to the time on a well-mixed population and write it as a function of the number of triangles in the network as well as mean degree or whatever other network properties. And we can go into And we can go into really why triangles, I don't really have time to go into why triangles change times to fixation, but it turns out that they reduce the equilibrium number of the edges that connect to mutants and all type notes. Now, what about multiple mutants, right? A lot of work has been done in this limit of one mutant in beta. What if you want to try to understand how a graph structure helps you cross a fitness valley, right, or the rates of sodacid tunneling? Or the rates of stochastic finally. So it turns out that this complex interplay between probability and time, the fact that the networks affect not just time, but probability, also allows you to see complicated dynamics that you wouldn't see just, let's say, with lattice-based models. So now, instead of having suppressors, having thermal amplifier categories, you see all different kinds of categories of graphs, seven different kinds that shape stochastic tunneling. That shapes stochastic tunneling dynamics. And again, we actually use one of Daniel's papers in this well-mixed regime to really quantify: hey, my two network properties either stretch the time that this intermediate lower fitness mutant can stick around in the population or change its spread, right? Change its effective selection coefficient. So you can really get intuition into the how and the why. The how and the why. And this allows you also to do this systematic analysis across network families. And you see that, for example, lattice graphs are just one knife's edge here, but allows you to put, right, if you now look at amplification factor by acceleration factor, put the different families of graphs together and look at the contour lines of whatever proxy you want. And here it's probability of fitness valley crossing. You can look at this unified. You can look at this unified picture across network families, and it opens the door to all kinds of beautiful other explorations. On this gave us a lot of headache, this problem of clonal interference on graphs. All of the graphs here, again, are graphs where all the nodes have mean degree 8, and so variance in degree 0. And we just play with the number of triangles. And you can already see very different types of patterns emerging, where even Where even for nodes, for graphs, where everyone has the same heat degree. And I'm running out of time here, but I'm going to very quickly zoom. It turns out that as you look at these patterns of clonal interference, graphs also change the genetic variance that you see in the population. And so we can quantify. It turns out that the right genetic variance to measure is obtained by multiplying amplification. Obtained by multiplying, amplification, and acceleration and controlling for that. So, the overview of this talk is that using these types of network representations, we can capture, even under very simple models, we can capture evolutionary dynamics that are simply impossible with Dean-based or more regular types of structures. Again, unless you make other kinds of assumptions in your dynamics. Kinds of assumptions in your dynamical system. And we may think that it's hard and it's messy and we can only study one family at a time, but that is not true. Two main evolutionary parameters, particularly for these types of problems, shape dynamics, and this includes problems where you go beyond single mutation models. And this is just a starting point. We also have work online on eco-evolutionary dynamics and what happens if you have species. Dynamics and what happens if you have species competition. We're interested in looking at tree inference and how that is changed by network structure. I'm in the School of Computer Science, and we think about intelligent systems a lot and how to design swarms that outperform reinforcement learning algorithms. So, kind of a slightly different direction in my work. We're starting to do a lot of data and shape-automated learning, and this has been the bane of my existence this past. This has been the bane of my existence this past year, trying to combine experiments with models. It's very, very hard. And I am always recruiting at every stage. So please reach out to me if these are some of the problems that you'd be interested in working. All of this work has been done in collaboration with my first ever PhD student who just defended this past Friday. And I'm very happy to finally change the picture where we're all masked to. To a more unmasked sort of more recent version of the group. So, thank you very much. When you're next or anything coming from, I was curious. So, you started at this example of stem cells, and cells kind of in this table where you will have each node as like a theme and then network. Each node has like a beam and then networks connecting them. And you move to this evolutionary. And then I was curious when you were applying data, how so, sorry, there are work which has shown that when you have each node being like a population itself, then these sort of amplifiers can turn into suppressors to extra internal dynamics and so on. Did you have that issue occurring from these individual net networks where notes are individuals to data where notes were public? Data where not so public? So that's a great question, right? I kind of zoomed in through the detail here, right? So, what are nodes and what are links, right? You keep mentioning these networks. So, a node can be thought of as an individual, right? An individual spread through this network, and links are these patterns of reproduction and replacement, right? The structure of reproduction and replacement. You can also think of the nodes of subpopulations, but here the assessment. But here, the assumption would have to be that there are homogeneous subpopulations where the time that the mutation takes to spread through the node is much faster than the time that it takes to spread between nodes. So that is the assumption that we make here, that as soon as a mutation reaches that node, it takes over the subpopulation. You had something on the slide that had a one over one minus f in front of it. Yeah. In front of it. Yeah. And I'm just curious about that because that's the kind of factor that could show up for like incorporating relatedness size or something like that. Yes, so I think a lot of the work that we also do in the lab is try to, and I think there needs to be more work on trying to connect this network work to previous models of structure, right? Population structure, kin selection, all kinds of different prior results and maybe. Prior results, and maybe write like a mathematical treaty of how it all sort of comes together. And you're right to notice that, and we're working on that, yes. I guess two slightly unrelated things. So, firstly, you're looking at the MARAN process. You've got lots of nice-looking results from that. Have you tried products with a simple game, like some of the donations? Game, like a sort of donation game? So we are looking at the Moran process here. You're right, there's a lot of other people, including Ben, for example, who use networks to study games, right? Evolutionary, a lot of problems in evolutionary game theory where you have slightly different assumptions. You have patterns of local negative frequency dependence, or so all kinds. Frequency dependence, or so all kinds of different flavors of problems, and we're not capturing them. Okay, so you've not looked at those. No, we have not looked at those, right? One actually thing I was going to say was just about what you were mentioning about local populations and stuff, is that there is a bit you can say on those kind of things that that sort of recently I've done with my own sort of PhD student, I mean sort of rather idealised. sort of rather idealized in the sense of of how the urban population interacts. If the interaction rates are sufficiently strong within the population and weak between, then obviously when something enters the population, then there's a certain probability of it taking over a certain percent. So so so it w it wouldn't take much to to to adapt what you've got to to to to lower sources. I think it's so fun to think of these links because actually, so the paper that I mentioned here on where we add a flavor of ecology, you can also, this is actually a global frequency dependence type of model, but you can turn it, you know, there's all these links, we're also working on local negative frequency dependence, and you can take these links between actually you can frame the model in an ecological framework, you can frame it into an evolutionary game theory framework, and it's so fun to follow. Theory framework, and it's so fun to find the connections and sort of bring the different fields together. And you're absolutely right. What we're also seeing in different papers is that the bottleneckedness between groups, right, like how bottom-necked the population is, really tends to matter. So the algebraic connectivity of the graph ends up being the important parameter there. Oh, one more question. We'll go. This is just to clarify, God, this is enormously impressive. Really cool. Yes, really cool. So, would you say, just in terms of fixation probability, the graph parameters have matter in most power, the mean degree, the variance of degree, the correlation between neighbors, and then for fixation time, the number of triangles or like clustering coefficients or something like that. Is that an accurate summary? I'm going to rephrase the last point a little bit. So, what we really particularly wanted to do for time to fixation. Particularly wanted to do for time to fixation is ask this question of given a probability of fixation, can I adjust the network to play with time? So we're not saying that the other properties don't matter. We're just saying, hey, if I control for fixation probability, how much leeway do I have to play with time? Does it always have to increase, or can I actually work on this idea of trade-off? And we actually use Trade-off, and we actually use these types of models for different types of applications. And it turns out that there's particular optimization problems that are very smooth where you might want to increase the number of triangles because it decreases time to reach solution. But if you're an optimization landscape where it's very rucked with a lot of local optima, it turns out that the populations that have a topology that increase time to fixation reach the global. Reach the global optima more. And so it's kind of an interesting thing to think: well, for some problems, you want to increase times, for some problems, you want to decrease times, give it a certain probability. But it's presumably loopedness, not triangles per se, that increase the time of fixation. How many, what proportion of structures? So, yeah, I sweeped a lot of things under the rug here. But yes, it is loopedness, and you know, you can also see that. That, but I will say the higher order you go. So, if you look at loops at four, they matter like so much less than loops at three. So, the contribution significantly decreases with the higher orders. Thank you. We'll stop there. A good morning to start us off. We have to have lunch from now until one and feedback. And she's back here for the afternoon session.