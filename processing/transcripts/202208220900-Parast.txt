Heterogeneity in the utility. I'm holding that. Utility of a surrogate marker. This is joint work with Liu Tan at Stanford and Tian Chi Kai at Harvard. So obviously I stole some of my own slides for the very first talk I gave on the first day. So I don't need to say this again. And everyone's been saying it. But of course, the whole point of, well, not. point of well not all the time but a lot of times the point of trying to find a surrogate marker is so that it can replace the primary outcome and we can conduct our clinic later clinical trial with less required follow-up time or less cost less burden i gave these examples before so many clinical settings and non-clinical settings where a surrogate marker could be useful and then i don't think we ever actually And then I don't think we ever actually specifically said this, so maybe this would be helpful. But this is one definition in words of a surrogate marker that someone else has proposed, not me. So a physical measurement, such as a biomarker, clinical measurement, or psychological test that can be used in therapeutic trials as a substitute for a clinically meaningful endpoint that's a direct measure of how a patient feels, functions, or survives, and is expected to predict the effect of the therapy. The effect of the therapy. So almost all of us have referenced the Prentice criterion. So in 1989, Ross Prentice proposed this criterion for a valid surrogate marker. You know, when we were organizing this workshop, it was in the beginning, in 2020, Ross was supposed to be here, but he is trying to retire. So I have been trying to get him to come, but I'm respectful of when people are. But I'm respectful of when people are trying to retire. So, but very much a central figure in surrogate markers. And whether you agree with his proposal or not, you probably reference his 1989 paper in your paper if you work on surrogate markers. So he proposes criterion by basically requiring that a test for a treatment effect on the surrogate marker is also a valid test for a treatment effect on the primary outcome of interest, which I think sounds quite nice. Which I think sounds quite nice and reasonable, but actually operationalizing that has been quite difficult, and there's been a lot of disagreement. One of the operational criteria that he proposed in his paper, one of a few, was that the surrogate should be able to capture the dependence of the primary outcome on treatment. So motivated by that, a lot of work has been done on this, you know, trying to define and quantify this. Define and quantify this concept of the proportion of the true treatment effect on the primary outcome that can be captured by the surrogate marker. Again, this is a slide from the first day, but as you have seen from all of these days, many quantities and criteria have been proposed to assess the value of a surrogate marker. Not an exhaustive list in terms of bullet points, not an exhaustive list in terms of references here, but just saying. References here, but just saying there are a lot of quantities out there. There's not 100% agreement on exactly what the right thing to do is, especially if you have just one trial. And which you've seen from the talks this week. I have been partial to the proportion of treatment effect explained quantity, so that's what I'll focus on today. So in general, So, in general, many of the available methods tend to assume no heterogeneity. And by heterogeneity, I mean that the surrogate could be useful for some patients and not useful for others. So that, when you think about it, makes complete, like, of course, that might happen. And as far as I know, although please correct me if I'm wrong, there was no kind of formal test, no method available to test for heterogeneity in the utility of a surrogate marker. Of a surrogate marker. And I think this is especially important to understand if the surrogate is actually going to be used as a replacement of a primary outcome in a future trial. And I shouldn't say I think it's important. It is important. We have seen in simulation. So if there's heterogeneity and you use the surrogate to replace the primary outcome in a future trial and you either don't know about this heterogeneity or you ignore it, things can go wrong. So this is an example. So, this is an example that I'll come back to in the talk, and as my motivating example, so here we consider the use of change in CD4 cell count as a surrogate marker for RNA. And so, this is a case where the surrogate and the primary outcome are measured at the same time, actually, but the surrogate is cheaper to measure. And so, we show, you know, spoiler alert, that the proportion of the treatment effect on RNA that's explained by CD4 count varies. Explained by CD4 count varies significantly by baseline CD4 count. So you have a higher proportion explained for those with a lower baseline CD4 count and a lower proportion explained for those with a higher baseline CD4 count. And so if you use CD4 count to replace RNA, I'm kind of saying this for short, it's always like change in CD4 count to replace change in RNA without taking these differences into account, things can go wrong. Things can go wrong. Okay, so the goal here is to propose an approach and estimation procedures to look at potential heterogeneity in the utility of the surrogate marker with respect to some single baseline covariate W and to propose testing procedures to formally test for heterogeneity. So, luckily, notation very similar to what everyone else has been using. So, why is my primary outcome? So, Y is my primary outcome, not doing time to event in this talk. S is a surrogate marker, Z is my treatment indicator, W is my continuous baseline covariate of interest. We also do discrete, that is a lot easier when it's discrete, so I won't talk about that here. And we use potential outcomes notation. And I'm focusing on this quantity, the proportion of treatment effect explained. So. So, also shouldn't be new information, but I'm still going to go through it because it's integral to my talk. So, Friedman proposed this super simple approach. Dennis talked about it earlier. Others have talked about it. So, you fit two regression models. In the first one, you just have your treatment indicator as your predictor. And in the second one, you just kind of throw in your surrogate. And you basically look at how much the regression coefficient for treatment changed after you throw in the surrogate. The surrogate. So, this has been used a lot. It is still used a lot, even though many people, including myself, have shown that this is not great for multiple reasons, but at a minimum, for this to be well defined and work out, these two models have to hold. And in the survival setting, where you use a Cox proportional hazards model for these two models, Daniel Lin has a paper. Daniel Lin has a paper showing it's actually impossible for both models to hold simultaneously. So not ideal. In 2002, Wang and Taylor defined an alternative, I mean, still getting at the same idea, but defined it in a different way. So they defined a quantity that attempt to capture what the effect of treatment would be if the values of the surrogate in the treatment group were distributed as those in the control group. As those in the control group. So, this is parallel to what Dennis presented, but obviously is starting to sound a little more like causally. So, we have our actual treatment effect on Y, which we denote as delta. That's going to be easy because we're assuming we have randomized treatment. And then we have, or they defined this residual treatment effect, which is like the hypothetical treatment effect when the distribution of the surrogate under treatment. distribution of the surrogate under treatment is the same as the distribution of under the control so it's like the leftover treatment effect after you already account for the distribution sorry for the treatment effect on the surrogate so it looks like this um and this is you know we've there's been discussion of this controversy of conditioning on the surrogate and that is exactly what i'm doing so uh residual treatment effect is literally what i said so it's expected treatment difference given that you like Expected treatment difference given that you like force the surrogates to be the same under treatment versus control, and you got to integrate over some reference distribution for the surrogate. So now this is going to be what's the leftover treatment effect after now I've kind of removed the treatment effect on the surrogate. And so the proportion of treatment effect explained by the surrogate is, you know, so delta minus delta S is now the chunk of treatment effect that's explained by S divided by delta. Explained by S divided by delta is your proportion that's explained. And this is very parallel to the direct and indirect effects of Robbins and Greenland. When those two models on the previous page with Friedman, when those two models hold, that proportion of treatment effect that you explained that you get is the same as this. Okay, but so my goal is to take this idea of the To take this idea of the contrast between the treatment effect and the residual treatment effect and to define and estimate it using as a function of W. So just taking a step back for a minute, in the Wong and Taylor 2002 paper, they propose this, you know, I think very intuitive and more flexible approach to estimate the proportion. But they're But their estimation procedures were still all model-based. So, more flexible models than what Friedman had. Like, you can have interactions and kind of make them as complicated as you want to a certain extent, but still model-based. And Lou and Tainchi and I have previously done work that estimates that quantity totally non-parametrically, so using kernel smoothing. So, you can, forgetting about W, you can estimate that proportion of treatment effect explained without having to. Explained without having to assume any kind of model for the relationship between your primary outcome and the surrogate. So that's all available. That's all out there. You can get a non-parametric estimate. But here we're talking about now trying to condition on W. I want to know what's that R, the proportion of treatment effect explained, as a function of W. So I want to do that, I need my delta as a function of W. All right, let me back up before I show you all that. So this is not, you know. So, this is not a new concept, obviously, at all. This is everyone's doing this with heterogeneous treatment effects. But then my residual treatment effect, I also need to condition on W, which like gets a little messy looking, but we're just taking everything from the previous slide and sticking a like conditional on W in there for everything. So, I have to condition on W for my conditional mean function for the expected value of Y given X. Now, I'm conditioning on W. X, now I'm conditioning on W also. And now, when I integrate with respect to some reference distribution for X, I mean for S, I have to also condition on W. So this is the thing I'm trying to estimate so that at the end I can get my R as a function of W. Okay, so for non-parametric estimation, so this is how we'd estimate delta, of course, with no W, so just the difference in the average. The difference in the averages since we have randomized treatment. And then, as a function of W, this is not new information. We're just going to do kernel smoothing. So this is your, you know, sort of traditional kernel estimator for the conditional mean of y given w or y given x, probably how you're used to seeing it, to get my conditional mean of y given w, and then I can get delta of w. Of W. And then to estimate my residual treatment effect as a function of W, it's essentially taking what we've already done for non-parametric estimation of the residual treatment effect and further smoothing over W. So I am doing two-dimensional smoothing here, you know, which looks a little messy, but it's just two-dimensional smoothing. And so in the end, I get this non-parametric estimate of my proportion of treatment effect explained. Proportion of treatment effect explained as a function of W. So, you know, we show the consistency and asymptote normality, of course, of all of our pieces, including the R. And we derived closed form variance estimates, which are not trivial for the two-dimensional smoothing part, but we have them. And then we also have a procedure to construct a confidence band for R over some interval of W, which I'll show you an illustration of in the application. An illustration of in the application. Okay, throughout, I have a number of assumptions. So, the first three are the assumptions that I need to ensure that I'm protected from the surrogate paradox situation. So, we've heard a lot about these strong assumptions that we need. And there they are. So, there's the top three. They are strong, they're untestable. And I need them, but. I need them, but I things don't, they can be violated and things are okay. So I have actually accidentally violated them in some simulation settings and only realized it after and everything still worked out well. So I, you know, I know, and like I, like I mentioned with the unmeasured confounder assumption, like, you know, of course it's safest. That's what assumptions are, right? It's safest for me to say these as long as I have these. Say these as long as I have these three, I'm protected. But I know that there's some flexibility in there. And what I am working on now with Liu and Tian Chi is, you know, how much can these be violated? First, how can you explore these? And then how much can they be violated for you to still be comfortable with your conclusion you've made about the strength of your surrogate? But I don't have that, those results right now. And C4 and C5 are, well, C4 is. Well, C4 is from my estimation procedure. So, because I use kernel smoothing, and Dan has kind of talked about this, I need the supports to be the same essentially. So, obviously, you know, if I try to build a kernel smoother in one group and apply it to the other group and the support in this group is totally different from this other group, I can't do it. So, I need them to not just kind of overlap, but essentially fully overlap unless I want to do some extrapolation. Unless I want to do some extrapolation, which I'd rather not do. And the last one is needed for identifiability, which I think is reasonable to assume in a randomized trial situation, but is also up for debate. Okay, so hopefully I've convinced you now that this is a procedure. If you had a data set, that you could kind of explore heterogeneity. But now I want to formally test for the presence of heterogeneity. So I'm not just asking you to. So, I'm not just asking you to like look at a plot of your R as a function of W and guess whether you have heterogeneity or not. So, formally, the null hypothesis I'm interested in is basically that this R, the proportion of treatment effect explained, is the same for all of W, right? And then the alternative is that it is not. So, we propose two test statistics, and I'll explain, or two tests, I'll explain why. So, the first is a surprise. I'll explain why. So, the first is a supremum type test statistic, which probably looks quite familiar. But basically, under the null, this part in blue, well, the true part in blue, you can show just with some simple algebra, is equal to zero. So I'm going to calculate my observed test statistic t. And then under the null hypothesis that the r is equal to some tau, you can show that the distribution of that can be approximated by the conditional distribution of the stochastic process, z star. Of the stochastic process Z, which I'm not going to show you the form of because it's messy and unnecessary, but is a function of the observed data and some randomly generated normals. And so I can get this distribution of T stars. Let's say I choose this capital B to be 500. So I take my data, I generate 500 independent normals, and I calculate 500 T stars, and then I use that to get my p-value. And then I use that to get my p-value, which is the proportion of two stars that are more extreme than my observed test statistic. So we show justification for the validity of this proposed testing procedure. The advantage is that it's omnibus, right? So it tests across a broad range of alternatives. The disadvantage is may lack power for detecting a specific alternative. So it's a little too good. I mean, it's just quite strict. Too good. I mean, it's too quite strict. So, we alternatively considered this, what we called a trend test. So, if you're willing to assume that your R as a function of W is monotone, so you're essentially restricting your space for the alternative hypotheses, you can come up with this alternative test statistic that has a bit more power. And I like to describe the intuition. Uh, describe the intuition behind it with this very super simple figure. Um, so if you thought about plotting your R, you know, the proportion as a function of W, if the null is true and R is the same for everyone, you'd expect something like this green line, right? Just a straight horizontal line. Um, and if it's not true, you'd expect something like the blue line. I mean, it could be up, it could be down, doesn't matter, but monotone. Um, so you can imagine if you took your So, you can imagine if you took your support W and you just chopped it in half and you looked at the area under the curve or under the line to the left and to the right. If the null is true, those two pieces are going to be equal. If the null is not true, they're not going to be equal. Obviously, the monotone part is very important here because if it's not monotone, you could have them be equal and it's the null is still not true. So, very important to have the monotone part. So, that was kind of our So, that was kind of our thinking behind trying to come up with this test. In actuality, this test statistic is not exactly what I just said, but that's how we sort of started thinking about it. Basically, under the assumption that the derivative of r takes only one sign, you can show that this s is equal to zero if and only if the derivative of r is equal to zero for all of w. So under the null, you know, kind of same flavor. You know, kind of same flavor as the previous test statistic. Under the null, you can show that S has this distribution, which we can approximate using some S stars that we generate again from the observed data and then some random component. And then we get the empirical variance of these S stars and use that to calculate our p-value. So, oh, that's my, okay. Oh, that's my okay. So, I'm gonna show this how this works in an AIDS clinical trial. I'm not showing you the simulations because I don't have time and I also don't usually like to show simulations, but you know, the usual stuff, things worked out, the bias was small. Our standard error estimates, the closed form standard error estimates were close to the empirical standard error estimates. Coverage was good when there was no heterogeneity. When there was no heterogeneity, you know, we correctly said there was no heterogeneity. Testing-wise, type one error rate was close to what it was supposed to be when there's no heterogeneity. And as expected, when the R was monotone and we used the trend test, we did get more power than using the omnibus test. Okay, so the eighth clinical trial data is a 320 ACTG 320 study, which 320 study, which I mentioned this on some other day, but the ACTG network is really great about providing data. I mean, you have to do like an application and data use agreement and things like that, but they have a lot of really great AIDS data, which has a lot of surrogate markers. So this one was a randomized double-blind placebo-controlled trial. We're going to look at a three-drug regimen compared to a two-drug regimen. And trial results showed better performance. And trial results showed better performance for the three drug regimen with respect to a number of primary and secondary outcomes. So, for this illustration, the primary outcome is change in RNA from baseline to 24 weeks. Surrogate markers change in CD4 count. Like I said, this is an example where they're measured at the same time, but the surrogate is cheaper. And the W of interest is the baseline average CD4 count. So these are the results. So these are the results. So the top picture is showing you delta as a function of W. So delta is on the y-axis. Baseline CD4 count is my W and it's on the X axis. The second panel is showing the residual treatment effect as a function of W. And then the last panel is showing you the proportion of treatment effect as a function of W. So I said this in the earlier slides, but we have a hot, you know, the surrogate is We have a hot, you know, the surrogate is like stronger for those with a lower baseline CD4 count and weaker for those with the higher baseline CD4 count. And the first, you know, the first interval that you're seeing with the dashed line is the pointwise confidence intervals. And then for the last panel, the dotted line is that confidence band. Okay, so hopefully I've convinced you that this is perhaps a reasonable approach if you're willing to. Approach, if you're willing to look at the proportion of treatment effect explained quantity, is a reasonable approach to look at heterogeneity and to formally test for heterogeneity. There is an R package that implements all of this, HETSER. It is actually now on CRAN, so you can find it there if you're interested in using it. So, some limitations. We'll talk about this later in a panel, and we've been talking about it. Panel, and we've been talking about it, so I have those strong assumptions. I also have several bandwidth parameters that I need to estimate. So, there are lots of kernels in there. There's a kernel for my delta of W, and then I had two kernels for the delta of W. Well, actually, I have another one for the reference distribution. So, anyway, there's a lot of bandwidths. So, you know, results can be sensitive to how you choose those bandwidths. And then, obviously, it's all non-parametric, which is great. I don't have to. Parametric, which is great. I don't have to assume any models, but I need a relatively large sample size, especially with two-dimensional smoothing. So we have another AIDS data set that has 30 and 32 in the arms. And obviously, I can't do anything with that, with this, even if I just had one-dimensional smoothing. So certainly something I'm really interested in expanding on. And then implications for a future study. And then implications for a future study. I touched on this in the introduction, but the presence of heterogeneity has important implications for the use of the surrogate marker in a future study. So if you were going to do a future study and you were going to use CD4 count, change in CD4 count to replace change in RNA and you didn't know about this. And like, let's say you decided you were going to use that as a replacement and your next study. And your next study just happens to have a patient population that has people with a baseline CD4 count that's all here, 100 to 200. Well, actually, that's a terrible surrogate marker, right, for those people. So probably shouldn't use it. So we have a follow-up paper that's under review now that basically gives you a testing procedure to test for treatment effect using the surrogate in a future. Using the surrogate in a future study, accounting for this heterogeneity. Okay. And then just a shameless plug for some more R packages in my like one minute left. So many of these are on CRAN. If they're not on CRAN, they're on GitHub, and we're trying to get them all on CRAN. But they're all packages in R. So our surrogate does. So, our surrogate does what I mentioned at the very beginning. So, just non-parametric estimation of your proportion of treatment effect explained. So, really encourage use of that. It works for time to event outcome setting. It works for multiple surrogates, not high-dimensional, but if you just say you have like three or four surrogates and you want to know the proportion of treatment effect that's explained by those four together, it can do that. It can also It can do that. It can also, with Tanya, we did work on how you estimate proportion of treatment effect when your surrogate is mismeasured. And so that reflects what Grace was talking about with the SIMEX. It uses a SIMEX estimator in there, which I think is so neat. Surrogate test provides code for testing for treatment effect using a surrogate marker. I won't go through all these, but there's a lot. Through all these, but there's a lot of them. Long sir down here is implements everything that Dennis talked about with the longitudinal marker. So if you're interested in that, that's all there. Cross sir. Do I have an extra S there? I don't know. Anyway, there might be an extra S right there, but that's right. It's either an extra S or but that's for the high-dimensional surrogate. Also that Dennis. Surrogate also that Dennis talked about. Free bird is the high-dimensional surrogate that Dave talked about. And then HET test is the very last thing I talked about where you can test for treatment effect in your future study, accounting for heterogeneity in your previous study. And that's it. Thank you. Oh, go ahead, Mark. Hi, thanks, Lila. This was quite interesting. Thanks, Laila. This was quite interesting. I think it's an important problem. We've actually never looked at this problem because, in all of the examples that we've analyzed, the confidence intervals on the proportion explained were hopelessly wide. And I mean, in your example, you seem to have reasonably narrow confidence intervals on your PTE. So I wondered if you could comment on that. I mean, I think maybe it has to do with the fact. I think maybe it has to do with the fact that you, in fact, analyze the surrogate for another surrogate, right? So CD4 is a surrogate, RNA is a surrogate. So in a sense, you are one level down with respect to a real clinical variable. And that might explain why you have much less variability and therefore perhaps, you know, smaller confidence intervals. Yeah, I mean, I have definitely experienced the same where I tend to have quite wide confidence intervals for R. For are, I still think in this example, they're wider than I'd like them to be, but they're at least not like the entire zero to one, right? I do have a large sample, you know, it's over a thousand in each treatment group for this AIDS study, so I'm lucky with that. But yes, it could, you know, possibly be due to the fact that RNA is itself a surrogate. What we're doing now, like was doing last night. Like, I was doing last night, late last night, is extending this to the survival setting, which is not exactly trivial, but for diabetes. So, here the outcome is, you know, diabetes diagnosis, and then the surrogate marker is my glucose. And I have various, actually have multiple baseline covariates there. So, I haven't finished running that application, but it's possible that, like you say, maybe my Like you say, maybe my confidence intervals would be quite wide there. I will say that the, you know, the power, I mean, I didn't show the simulations, so maybe this is where I regret not showing the simulations, but the power is not super, you know, great for detecting heterogeneity. It's hard. So even in settings where I had like very clear heterogeneity, the power was like 0.65. 0.65. So there's, you know, it would be great if there were other methods that are proposed that, you know, outside the proportion of treatment effect, because the ratio is, you know, fraught with all kinds, it's very hard to work with. So in these other settings, if something similar could be proposed that has more power, that would be great. I think certainly very useful and room for improvement there. And room for improvement there, yeah. Thanks. Any other questions? Um, yes, can I ask a question? This is Dave online. So can you go back? I think I missed this, but can you go back to the R of W? I guess, so you're trying to test if R of W changes with W, right? I'm sorry, as monotone with W. Right. And you had this really cool test statistic idea. I was just curious. Test statistic idea. I was just curious why. Maybe I, right. Can you not base a test statistic on the estimated derivative of R? Well, that's kind of what this one is doing, right? But can't you like use our kernel method to estimate, directly estimate rhat prime? Possibly. Or is that the same? Possibly, or is that the same thing? I don't know this stuff that well. Um, I don't think I think that this S is perhaps like a simplified version of what you're saying. Um, okay. Yeah, but it is under that assumption that, yeah, the derivative only takes one sign. So, I think I'd have to think more about. Sign. So I think I'd have to think more about how you do that if the derivative does not just take one sign. Okay. And then a related question. I don't know too much about this, but I think in econometrics, there's something called like name and C alpha test for testing homogeneity of a bunch of different like parameters, like theta one equals theta two all the way to theta n. Do you know if this is related to that at all? I don't know. That's a good question. The economists always do. Good question. The economists always do things before we do. So that's possible. Cool. Thank you. Yeah. Thanks, Dave. Yes, we'll do one last question. Thanks for the talk. I thought that was really nice. I've also looked a little bit at stratifying the CEP curve, but we didn't have like formal testing statistics. So I liked that. I was wondering if you've worked at all in the case where you're not pre-specifying what the covariate is and like your ideas. It is and like your ideas for doing that. Yeah, thanks. That's a really good question. Yeah, I sorry, I know we're going over, but I, yeah, when you, you gave a somewhere, I saw you give a talk on like the baseline covariates and I was like, you know, at first, of course, you're always like, oh no, someone's doing what I do. And then I was like, oh no, it's not exactly the same thing. But I was excited to see someone else kind of working in that space because I have heard it. Space because I have heard it a lot from more applied people that, like, obviously this is happening, but I didn't see it in the statistical literature as much. So, yeah, so first of all, we're trying right now to work on the survival setting and then also when you have multiple W. But I think the more interesting and harder question, which we hope to get to someday, but haven't, is identifying the subgroup when you don't know the W. So I'm not really talking about like. So, I'm not really talking about like a high-dimensional, you know, baseline covariate, but even if you just have like 20 baseline covariates, you're not going to go through and like test every single one of them. I mean, just like regular subgroup analysis for clinical trials, people get in trouble all the time for like phishing. So, how do you identify some subgroup defined by your space of baseline covariates? Where, let's say, the surrogate is for everyone, you know, the proportion of treatment effect explained is 80%. Proportion of treatment effect explained is 80% or higher. Like, how do you identify that region? And I don't know how to do that yet, but I think that's a really important question. Yeah. Thanks very much, Leila. All right. So just for the interest of time and perhaps maybe more questions later will come up.