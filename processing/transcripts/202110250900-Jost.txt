And I enjoyed it very, very much. And of course, now I'm there only virtually, but hopefully it will be enjoyable nevertheless. And I'm looking forward to an interesting conference. You can see my slides, can't you? Yes. Good, good. Yeah, so I'm looking forward to an interesting conference bringing together. Conference bringing together mathematicians and people from AI and data science. After some reflection, I'm going to give a talk which is more on the mathematical side, but hopefully it will be understandable and perhaps even inspiring to some of those that want to do data science. If you have questions, or if I'm too fast, or whatever, then please do not hesitate to interrupt me during the talk. To interrupt me during the talk and ask questions, I welcome any feedback. So, I will speak about the geometry and topology of data. And this is works that we have done here in Leipzig, together in particular with Pavane Joharinad, who is a member of my group. And now, this is getting. This is getting gaining greater momentum, and so we are now also involving many other people. So, topological data analysis asks when walls in the metric space intersect. That is a basic principle, and out of that, then you extract from this intersection patterns. These intersection patterns, we extract some topological information. Now, I will look at the question not from this qualitative way, but from a quantitative way, from a geometric instead of a topological perspective. And so we will ask not only when or whether balls intersect, but I will ask how much I have to allow. Ask how much I have to enlarge balls in order to make them intersect. That is, I will turn a qualitative question into a quantitative one. Of course, topological data analysis is also quantitative in the sense that it looks at the intersection patterns in their dependence on the radii of the balls involved. But there is more to say than that, as I will try to. Than that, as I will try to describe to you. And from the geometric perspective, this is captured by the concept of curvature, which may be a little surprising, but I will develop this theme during my talk. And in particular, curvature quantifies convexity. And so I will also talk about convexity properties of distance functions. So now So now some technical details, which many of you will know already. So we consider some set X equipped with a metric D, with the usual properties. And then we look at continuous paths or curves connecting two points. We have point X where the path starts and a point Y where it ends. And then each And then we can define the length of the path as the supremum of the distances over all partitions of the unit interval. That is, we subdivide the path into small pieces and then add the distances between the endpoints of all those pieces and then go to the supremum. That is something that you all know from Euclidean geometry. Now we call the space a length space. If for any two points, the distance is equal to the infimum of the lengths of such curves connecting them. And a length space, when it's called geodesics, is called a geodesic space if for any two points. Space if for any two points they can be connected by a shortest curve, that is a curve realizing the infimum of the length. In general, that infimum need not be realized, but we require that it be. And the distance then is realized by some curve, and this curve is called the shortest geodesic. Of course, I'm talking from your perspective, I may be talking about some idealization here because you will. Here, because you will naturally be interested in discrete metric spaces, because data by the very nature are discrete. But nevertheless, the point is that going to continuous spaces gives you some kind of asymptotic or approximate version of the geometry, some idealized version with which you can then compare the actual data that you may have at hand. So now in the geodesic space, we call a point M a midpoint between two other points if the distance to either of these two points is equal to half of the distance between those two points. And more generally, I call a space totally geodesic. If an error we have two radii, We have two radii whose sum is at least equal to the distance between their centers, then the corresponding balls do intersect. So just remember the last sentence here, two balls that can intersect because the radii satisfies a condition necessary for intersection. In fact, actually do intersect. That is the condition here. Very simple so far. Very simple so far. And just as a convention, all radio I shall be talking about will be positive in the SQL. Now I can make things a little more complicated and formulate it in the following way. So again, I consider two radii, whose sum is equal, is at least equal to the distance between their centers. Between the centers. And then for all points x in the space, I look at the distance between xi and x divided by the corresponding radius. I look whether that is bigger for the first or for the second point, but then I take the infimum over all points x. And then out of this quantity, then I take the supremum over all radius. Then I take the supremum overall radii. Of course, since I'm dividing by the radii, you want to make the radii as small as possible. So ideally, you would have equality R1 plus R2 is equal to the distance. And when X is complete space, then things are realized. And then you just look at the distance between xi and x, take that twice. Take that twice as in the case of a midpoint and divide by the distance between x1 and x2. And this one is achieved. O of x1, x2 is equal to 1 whenever x lies between x1 and x2. Yeah, that is whenever the triangle inequality becomes an equality. That is the best situation. So, in other words, we want to find points that sit between two points, x1 and x2. We may not always be able to do that, for example, in discrete spaces, but then we want to quantify to what extent that can fail. But that is just for two points. Now, I want to extend that to three and in fact, even to even more points, and look at such conditions and see to. Conditions and see to what extent they fail in an actually given space. For three points, I have the following definition that is very important. We call a geodesic length space, that is the space where any two points can be connected by a shortest curve, a tripod space. If for any three points there exists a median, that is a point that sits between any two of them. Between any two of them. So, first we had this condition just for two points, but now we have it for three points. For any pair out of the three points, then the distance from m to xi plus the distance from m to xj has to equal the distance between xi and xj. So, here's also a picture. So, you already see what is happening, and perhaps you also understand why I'm calling such. Also, understand why I'm calling such a space a tripod space because M really is the center of a tripod. You can also reformulate the conditions slightly as written above there, just adding up the conditions for all the three pairs. But most metric spaces are not tripod spaces. For instance, in remaining manifolds. Many manifolds as soon as they are not trivial, that is, they have a dimension at least two, they do not satisfy the tripod property. So, in other words, the tripod property may typically not be satisfied, but the point is to see to what extent in a given metric space the tripod property actually fails, and you want to quantify that. But there do exist some examples that satisfy them. Metric trees, for instance, so the tripod just is a piece of a metric tree, but also L infinity spaces satisfy the tripod property, even though in general geodesics in L infinity spaces are not unique. But you can always find some geodesics so that the tripod property is satisfied. And there will be an important class of space. And there will be an important class of spaces to which I'll come back, the so-called hyperconvex spaces, which satisfy this property and even analog of that property for more than three points. They will be important model spaces. So, our strategy then is to quantify the deviation from the tripod property in order to get some measure. Get some measure about the properties of a given metric space, and to, in some sense, quantify what is checked in topological data analysis. So, but let's again reformulate this condition. So, we have tripods exist if and ever we have three balls. Have three balls such that the sum of any two radii is at least equal to the distance between the corresponding centers, then these three balls do intersect, the common intersection. And so the property then is that three balls that can intersect do intersect. Formerly we had two balls, so it was easy, but now we ask it for three balls. But now we ask it for three balls when it is not satisfied. But as I said, we want to quantify the deviation from that property. So again, I can reformulate it in a somewhat more complicated way, but which will actually be useful. So again, I look for any point x at the distance from x to xi and divide it by the radius ri of the ball centered at xi. Takes a maximum row of. Take the maximum now with respect to all those three points, and then take that point x or some point x that best satisfies this, which has the smallest value of that quotient. Then it takes the supremum again over all radii. And in fact, the radii can then be uniquely found by solving for the so-called Kromov products. So, every radius quantifies to what extent the triangle property fails from the perspective of two points given the thirteen point. By the triangle inequality of matrix, all these quantities are non-negative, but in general, they will be positive, of course. And so, therefore, we can obtain this quantity by optimizing with respect to the radii, by just letting the radii equal to the comm of products. And if we have some point M or X that where the infimus Where the infimum is attained, we call that point a weighted circumcenter. And since we are maximizing distances here, we solve an optimization problem in R3, R3 just because we have points with respect to the L infinity norm. And so therefore, L infinity geometry comes in naturally here. Of course, you can ask when these weighted circumstances exist, that is, when the information is realized. There is one class of spaces to which I'll return a little later. These are the so-called Alexandrov spaces. They generalize remaining manifolds of non-positive sectional curvature. They are also called Katziro spaces, a terminology introduced by Gromov. So now comes an important definition. Namely, we had asked this property for three points, and now I will ask this property for arbitrarily many points. Do we have any family of points and balls surrounding them? Points xi and radii Ri, and close balls centered at xi. Centered at xi with radius ri, and we require the inequality needed for an intersection to be possible, for a pairwise intersection to be possible. But then we require that we not only have a pairwise intersection, but that all the balls have a common point of intersection. That is a strong property. But again, this is something that we can compare. Something that we can compare an actual situation with, and where we can check the deviation from. So the condition is that when balls intersect pairwise, when they're in a convex metric space, and this condition guarantees pairwise intersections, then these balls also have a common intersection, where all of them intersect. All of them intersect. So the slogan is: balls that can intersect by when the triangle inequality necessary for intersection is satisfied, such balls then do intersect. That is a condition of hyperconvexity. And in particular, hyperconvex spaces are tripod spaces, because for tripod spaces, we only had required set condition for three-point. Had required that condition for three balls. Now, here are some examples. Some spaces are hyperconvex and others are not here. First of all, let's take a look at the upper right, where we have a metric tree. There's a hyperconvexity property satisfied not only the tripod condition, but also the hyperconvexity condition. On the lower left, we have We have L1 in the plane, and there we also see the metric balls are these tilted squares or diamonds, and we have three of them that intersect pairwise. Two of them touch each other, and the other two have just one point of intersection, but then we also have a triple intersection. Section on the upper left, we see three balls in Euclidean space, and there we see that the hyperconvexity condition is not satisfied. Not even the tripod condition is not satisfied. We have three balls that intersect pairwise. The closed balls touch, and so they intersect. Each pair of balls intersect, but we don't have a triple intersection. Triple intersection. And on the lower right, you have a circle, and that is the condition where the tripod or hyperconvexity property most badly fails. If we take three balls whose radii are equal to half of the distance between any two points, then of course all these three balls in the Then, of course, all these three balls intersect pairwise, but you have to double the size of the balls in order to get a triple intersection. On the upper left, in Euclidean space, we also need to enlarge the balls somewhat in order to get a triple intersection, but we don't have to double their radii. So, on the lower right, actually, that is the worst possible case. So, hyperconvex spaces have some nice. Hyperconvex spaces have some nice properties. They're complete and contractible to each of their points. They were already introduced many years ago by Aaron Schein and Panich Bhakti. And they satisfy a nice Lipschitz extension property. So whenever we have a Lipschitz map from a subset of some metric space to A. Of some metric space to X, then this map can be extended to the entire space as a map into X with the same Lipschitz constant. And then there is an important result first discovered by Ispel, but then rediscovered in a more general form by Andreas Tres. Namely, every metric space can be isometrically embedded into some hyperconvex space, which is called its hyperconvex. Space which is called its hyperconvex hull. The explicit determination of that space can be quite difficult, but for three points, you would just form the tripod, the corresponding tripod out of these three points. And the hyperconvex hull of a compact space is compact itself, and the hyperconvex hull of a finite space in general is a simplicial complex. Now we come to the relation with topological data analysis with TDA. Of course, you all know for metric family, some distance function and some fixed radius, then TDA always takes the same radius for all points. One defines One defines a check complex through the intersection patterns of the balls with radius r. Whenever q plus one, such balls intersect, then you assign a q-dimensional simplex to this pattern. So we get a simplicial complex. And then, of course, you know, the principle of topological data analysis is the record or the homology of this complex, of this simplicial complex. This complex of the simplest complex formed from the intersection patterns of balls, whereas as a function of the radius. But of course, we already see some more flexibility here. From our geometric perspective, we can take varying radii and we can also ask to what extent actually the intersection fails. But in a hyperconvex space, of course, all such simplicities are filled. Filled, yeah, and so therefore, if there is no local homology, or in terms of the concept used in topological data analysis, you could just say that the check complex equals the Viator-Ribs complex, because the Viatoris-Ribbs complex is the complex where you automatically fill all such simplicities obtained from pairwise intersection patterns. Now, Now, I will look at certain variants because, after all, what I just said is mainly meaningful for continuous space, but not for discrete ones. So, you can relax the conditions a little bit. You can allow to add some delta to all the radii and then ask whether that gives you an intersection of balls, or you can stretch all the radii by a common factor lambda and then. Common factor lambda, and then again ask whether you get non-trivial intersections of balls. The first one is called delta hyperbolic, and the second one is called lambda hyperconvex. Of course, for large radii, delta is quite insignificant, and so that the concept of delta hyperbolicity is good for asymptotic considerations. Whereas the advantage of Lambda hyperconvexity, that is our condition 6, is that this is invariant under scaling the metric D. Both have advantages and it depends on what you want to check or how you want to apply it or what you want to extract from your data. Now, Hilbert spaces including Euclidean spaces. including Euclidean spaces are square root two hyperconvex. That is, if you have pairwise intersection patterns of balls, then if you enlarge all balls by a factor of at most square root of two, by a factor of square root of two, then you are sure to get a common intersection. In general, reflexive and dual Banner spaces are only too hyperconvex, so you need to enlarge them more. Need to enlarge them more, as we already saw at the circle, by the way. And in particular, L2 spaces, LP spaces are two hyperconvex, for L2 it's a little better, but for L infinity, it's even still better because they are one hyperconvex, that is a really hyperconvex. And so, the idea is that we can then use these concepts to compare spaces with each other or with some reference spaces like Euclidean space. So, we can ask if you have two metric spaces, which is lambda hyperconvex with a smaller vector lambda, or which one is delta hyperbolic with a smaller constant delta? And in geometry, this is quantified by the concept of curvature, as I will explain a little more. And our abstract perspective is that curvature relates intersection patterns of balls to convexity properties of distance functions. Again, something to be elaborated a little. So, here I give you a definition. So here I give you a definition, Alexandrov definition, and just look at the picture at the bottom on the page. On the right-hand side, you have a Euclidean triangle. On the left-hand side, you have a triangle in some given metric space. And the bars at the sides indicate that the corresponding geodesics are of the same lengths. In other words, we have three points in our space, x1, x2, x3, and three points, comparison points in Euclidean space, x1 bar, x2 bar, x3 bar, and the mutual distances are the same. Then, non-positive curvature, in the sense of Alexandrov requires that if you take any of these points, let's say x3, and look. And look at the distance of that point x3 to the shortest geodesic connecting x1 and x2. Then this cannot be larger than the corresponding distance in the Euclidean plane. The distance between x3 and c, for instance, the midpoint between x1 and x2, cannot be larger than the Euclidean distance and the Euclidean term. Euclidean distance and the Euclidean triangle between x3 bar and the midpoint between x1 bar, x2 bar on this curve c bar. So that is the geometric content of non-positive curvature in the sense of Alexandrov and for Riemannian manifolds that agrees with the usual condition of non-positive sectional curvature. There is another important condition. Important condition. Boozman convexity. That just means that the distance between two geodesics that start from the same point is a convex function of the length parameter on this geodesics. That is, in a Buzzemann space, geodesics diverge at least as fast as in Euclidean space, because in Euclidean space, this distance just is a linear function of t. Distance just as a linear function of t. And Buzzemann's condition is more general than Alexandrov's condition. Now, our condition of non-positive curvature, now I'm connecting with what I have said earlier, requires that for each triple end point of points, again, it takes a Euclidean comparison triangle, three points. Triangle, three points in the Euclidean plane with the same pairwise distances, then our quotient rho in our space is not larger than the corresponding quotient or infimom in Euclidean space. That is, we need to enlarge three balls not more than we would have to enlarge the three Euclidean comparison balls in order to get triple intersection. Section. So, here I put it again into a formulae, but maybe I skip the details here. But it says that the circumcenter, that is the point that we get when we try to find a triple intersection of enlarged poles, is at least as close to the vertices as in the Euclidean case. That is, poles intersect at least as easily as in Euclidean space, in a space of non-positive curvature. Of course, we could take other comparison spaces, we could take a sphere of some given radius, or we could take hyperbolic space of a given scale or whatever, and then would have other curvature conditions. And in particular, tripod spaces then have no. Particular tripod spaces and have non-positive curvature because there the balls already intersect without having to enlarge them. And also, these Alexandrov spaces have non-positive curvature in our sense, but not conversely, our class of space is more general than Alexandrov's class because we don't require uniqueness of geodesics, as shown, for example, in L-infinity spaces. L infinity spaces. And importantly, an approximate version very naturally applies to discrete spaces. And if you have some background in Riemannian geometry, then I can tell you that for a complete Riemannian manifold, non-positive curvature, in our sense, is the same as the classical case of. Is the same as the classical case of non-positive sectional curvature. Now let's draw some conclusions. I already explained or recalled the check construction. We have a cover, for instance, by balls, and then out of this cover, out of the intersection pattern of that cover, we construct. Of that cover, we construct a simplicial complex by assigning a simplex whenever we have a couple of members of our cover that have a non-empty intersection. And there's a general theorem in topology. When all the intersections are contractible, then the homology of that simplicial complex equals that of the original space X, under some rather general topological conditions into which I don't want to go into here. Go into here. Of course, then for that, the space need not even be a metric space. But when our space is a metric space, of course, we can naturally use covers by distance balls. And then when our space is hyperconvex space, then you always get non-trivial intersections. And so, therefore, as I had already explained earlier, we don't get any local. Earlier, we don't get any local homology groups from that because we don't have unfilled simplicities. Now, when we only have lambda hyperconvexity, that is when we have to enlarge some balls, the balls by some factor, then of course you may get non-trivial homology groups. And so, from that perspective, the hyperconvex spaces are the simples model spaces. Simple model spaces. And homology, now, from our perspective, is a topological measure for the deviation from such a model, this hyperconvex space. And of course, you know that from homology groups, you construct Betty numbers as integer invariants. But the point I want to make here is that geometry can provide more refined real-valued invariance as opposed to simply this topological inter-information. To simply this topological integer invariance. And after Riemann, who was the founder of modern geometry, the fundamental geometric invariance are curvatures. Now we have developed a framework where the essential geometric content of curvature can be extracted for general metric spaces, not just for many manifolds and not just simplicial complexes or Alexandrov spaces. Complexes or Alexandrov spaces, but for any metric space, we have some corresponding notion. And now the basic class of model spaces for curvature is now given by the tripod spaces, which is a special class of spaces that contains the hyperconvex spaces, which are the ultimate models. So, again, from our perspective, the geometric content of curvature. Geometric content of curvature in this abstract setting is a deviation from the tripod property. And now Euclidean space only have a subsidiary role, which is based on the normalization of curvature, traditional normalization of curvature that assigns the value zero to them. But from our perspective, the space that one should really compare a given metric space with a tripod. Given metric space with hyperconvex spaces as opposed to Euclidean ones. Now I end up with a general definition where I now translate all the geometry of a metric space into topology. With a metric space, now we construct a simplicial complex whose vertex set consists of pairs. Of pairs, where x is a point in our space and r is a non-negative radius. And so then if we have a couple of such points, then we can look at the corresponding balls and check whether they intersect. And if they intersect, we assign a simplex to them. So we can, our construction. So we can our construction then allows to do that for all for all radia for all points and all radii that in general depend on the points simultaneously and topological data analysis just evaluates the topology of the slices where the radii are constant and then of course asks how that depends on the radius. But here now we have a more flexible pattern that top of Flexible pattern that topologizes the entire geometry of a metric space in terms of intersection patterns of balls. So there are some questions to explore then. You can ask about new schemes for geometric data analysis that is apply that to data. We are starting to work on that. And we can look at the asymptotic geometry, in particular of networks. It is something that we are collaborating on with Arijit Samal. On with Arijit Samal, who is the head of our partner group in Chennai in India, and who is an expert on the analysis of biological data. Then, of course, there are many mathematical questions which we are exploring in Leipzig about the geometry of hyperconvex and in particular of tripod spaces. Here are our papers. The first one was published two years ago. The second one is still on the archive. Is still on the archive. I want to close this with some advertisement. Namely, we have started a new book series, which is called Mathematics of Data. So the question is, in general, how to find structure in data. And of course, that is a challenge that you're also addressing at your conference here. Traditionally, of course, that was That was attacked by statistics, but as we all know now, that goes beyond traditional statistical methods. And mathematical approaches might come from geometry and topology, like those that I reported about today, but they could also come from algebra, from combinatorics, from stochastics, from analysis, from information theory, or virtually from any mathematical field. And we hope for new interactions. And we hope for new interactions between mathematics, statistics, and computer science, in particular in machine learning. And for this book series, we invite novel contributions at the highest level for finding structure and data. And there is just a sample of disciplines where that could come from: TDA, compressed sensing, algebraic statistics, and information geometry, manifold learning, hierarchical tensors. Learning, hierarchical tensors, support vector machines, the mathematical series of neural networks, information decomposition, or whatever. And this is edited by a distinguished board of editors, including Enya Minges, Eza Harrington, Katrin Hes, Peter Kutinjog, Bernstomfelds, Schmuel Weinberger, and myself. And so, if you have a book project at the highest possible level, then consider submitting it. Consider submitting it and we publish it through a cooperation between my institute and the Springer Nature Company. Okay, so with that advertisement, I've reached the end of my talk in time, and I'll be happy to answer any questions that you may possibly have. Thank you very much, Jürgen. So we had an overview of different approaches. Different approaches and ways to try and derive a topology from a geometry in a space, and how this can lead to notions such as invariants that are not integer, but maybe real valued, and the exciting prospect of applying this to analyze data. So, we have some space for questions. Some space for questions. Um, please feel free to jump in and/ type in your questions in here. Maybe in the meantime, I can ask Jürgen about some of his thoughts on these potential applications, some of which you already mentioned. So maybe you can expand a little bit on that. So some of these concepts, as you presented to us, have a long history. To my understanding, there is a program trying to obtain this synthetic notion. I'm trying to obtain these synthetic notions of geometry and topological information that can extrapolate from the more common spaces, maybe to new spaces, as you mentioned, trying to measure the deviation from some of these properties, which I think is very exciting if we are looking at data that is not presented to us in a traditional way, but maybe with some other structure, like interactions between items. Between items or with different types of metrics among them. So I would be curious to hear your thoughts on that and maybe more specifically how we can think about using hyperconvexity in a practical setting. Yes, there in fact have existed some applications already for a long time. They were pioneered by Andreas Reis. By Andreas Dres, and he was looking at phylogenetic tree reconstruction. So you have sequence data from different species, you look at distance between them, and ideally from the distances between genetic sequences, you should be able to reconstruct a phylogenetic tree. The more distant two sequences are, Two sequences are the more distant the corresponding species should be in evolutionary terms. But practical data usually do not satisfy quite the condition that is required for the data to fit into a tree, to fit into a perfect tree. And then Andreas Des constructed the hyperconvex hulls of these data as the best. These data as the best approximation to a tree, and that gave a lot of insight into the genetic relationships and the branching. And then from that, one could develop schemes to develop the most plausible phylogenetic trees. So that was one application. Another one would be to look at networks. At networks which are naturally not trees, like infrastructural networks, or so, and then look at points that are quite far away, for example, in road nets, road networks, and then look at the corresponding quantities in order to get global qualitative properties, for instance, of transportation networks and see whether, for instance, biological. Whether, for instance, biological networks are different from infrastructural ones or not, or whether they satisfy similar design principles when it comes to asymptotic questions. Not just the local questions, clustering and so on, but really the asymptotic geometry, how three or more points that are all quite far away from each other are related to each other. Particular, how close the shortest connections between any two of them are coming together. Two of them then are coming together near some kind of center of the network. So these are just some applications. Of course, we also want to connect that with other schemes of data analysis, eventually perhaps with information geometry. But there is a lot to be explored. And of course, we could also try to take another look at some of those data. At some of those data that have been well studied by schemes of topological data analysis, whether we can see a lot more, and in particular, also what happens if we adapt local scales, if we don't take a constant radii, but let the radii depend on local densities or so. And so that might, for instance, also connect to manifold loads. Connect to manifold learning, where, of course, also depending on the sampling and the density in some regions, things can be closer together than elsewhere. And instead of just constructing a graph, you might construct a simplicial complex and look at its properties and so on. So, in other words, we are just at the beginning of exploring. Of exploring things, but we hope that we can develop a scheme that can refine topological data analysis and lead to new insight in many empirical data sets. Got it. Thank you. We have a question here in the chat from Martia. It's, well, thank you very much. Is there any way to transfer the idea of persistent homology here as we have different R for the balls? Have different R for the balls. If you have different what? Different R, so different radii. Yes, yes, of course. I mean, that you can easily do. I mean, if you in general, you will take a radius function. So to each point, you associate a radius. For example, according to the local density of... The local density of points around it, yeah. And then you can, of course, do the same as you do in TDA. If you have this collection of balls, you look at the intersection patterns and then look at the corresponding check complex. So, by the way, I usually prefer to work with the check as opposed to the VR Torres-RUPS complex in such circumstances because that gives you the local information. The local information that Vetero Swips complex ignores.