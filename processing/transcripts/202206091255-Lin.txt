the full screen and thank you juliana and thanks um for the organizing committee for inviting me and so i will talk about um some issue related to principal component analysis in jiva study so generally uh in jiva study and we need to perform several pca analysis and in jiva study generally there are hundreds of thousands to millions of individuals and also the number Videos and also the number of SNPs could be 100,000 to million. And so there are two problems I'm going to focus on related to PCA. The first is to control for population structure, and we generally have to decide how many ancestry PC to use. And so instead of saying just use 10 or use 5, whether we can use a data-driven method to estimate the number of PCs. And the second problem is. And the second problem is when we perform the SNP site analysis, and one can also perform genotype PCs. And so if one performs genotype PC, should one use the first genotype PC or the last genotype PC to empower the SNP site association? And in FIWA studies, and so if we have multiple phenotypes and then we want to see whether a SNP is associated with multiple phenotype. Associated with multiple phenotypes, then should we use the first phenotype PC or the last phenotype PC? So, let me start from the first one. So, how can we estimate that number of PCs? And so, we propose this called the Beamer method, and which was published in JASA last year. So, there are a few use cases for estimating the PC. One is to estimate the number of clusters. Estimating the number of clusters, and for example, like in single-cell studies, generally one needs to estimate the number of subtypes, and or in GWAS study, one needs to estimate the number of ancestries, and or in the factor analysis, one needs to estimate the number of factors. So, this is just a figure familiar to everybody. So, if one has 1000 genome data, you can see there if one plot out the PC, one should show definitely. PC one should show definitely the ancestries we want to control for in genetic study. And to present this in a formal statistical framework, and suppose we have already pruned the SNP across the genome, and so this MPP matrix. And then suppose we want to calculate the first KPCs and using the genotype matrix. And then Genotype matrix. And then in the GWAS analysis, one will include the first K PC, for example, first 10 PCs as a covariate to control for population structure. So the natural question is, how can we estimate the number of PCs? And so should we use 10 or 20? So this can be formulated into a spike covariance matrix model. Suppose we have the X is a genotype matrix and it's Is a genotype matrix and its true covariance matrix sigma. It can be written as a spectral decomposition. And the lambda k basically are the first k eigenvalues and the cosine k's are the first eigenvectors. And then the residual take a variance sigma square. And so the result has been generalized to the heterogeneous covariance situation, residual covariance situation with a different sigma. But for now, I will just. But for now, I will just focus on the common sigma. So, our goal is to estimate the K. So, here the sigma is a spike covariance matrix and with several eigenvalues and the low-rank eigenvalues. So, the goal is to estimate the k. So, what is the traditional approach? The traditional approach is basically use the screen plot and so make a guess. And so, in this situation, suppose And so in this situation, suppose that we have plot out the eigenvalues and then to see from the top to the bottom and then to see where we can see the gap. If you use the different cutoff, then you will estimate different case. And so this is pretty much a guess. So can we do something better without guessing? And so that is basically this BMR. So the idea is instead of So the idea is instead of from the top down, it's from bottom up. So basically we estimate the bottom eigenvalue start from the bottom eigenvalues distribution and then fit a parametric curve and then extend the curve to find out where to cut. And then the cutoff is calculated using a statistical criteria. And so what is the eigenvalue distribution? Um, eigenvalue distribution, suppose the distribution is truly ID and there's no low-rug part, and suppose we let the both n and p goes to infinity, and then but the ratio goes to a constant. And so one can show that suppose the one can calculate empirical spectral distribution of the empirical atom values, and then it will follow this kind of a metrical pastor this density. Pastor density distribution. And so this basically corresponds to the bulk. And the bulk basically is suppose the distribution is truly IDs. And then what will be that eigenvalue distribution? And then those spikes basically correspond to the eigenvalues of the low run card. And then you can decide where the cutoff should be based on the statistical properties and then decide how many specs one should have. Decide how many species one should have. Those specs basically correspond to the eigenvalues, the spec eigenvalues were the number PCs. And to do this, it's pretty simple. And so basically what one can do is you first calculate the empirical eigenvalues, and then you calculate the quantiles of standard MP distribution, and then you fit a linear curve of this empirical. Curve of this empirical eigenvalue against the standard eigenvalue from the theoretical MP distribution. And then you calculate the slope. The slope basically is the sigma square. And then from that sigma square, you can decide cutoff. And this is a theoretical cutoff. And then you compare the empirical eigenvalues with this cutoff. And then with the empirical eigenvalue greater than this cutoff, this will provide an estimate of. This will provide an estimate of the eigenvalues or the PCs. And one can show this estimator is consistent. So, therefore, the calculation is pretty straightforward. And one can prove a bunch of theoretical properties. And so, now let's see how that works when applied to the 1000 genome data. And so, suppose this 1000 genome data, there are totally about 2,500 observations. And then we so. We saw totally about 84 million on the SNPs. And then after some LD pruning, so we use about 25,000 SNPs to calculate the PCs. And so in this 1,000 genome data, there are totally 26 athleticity groups. And so therefore, the true ground truth is case 25. Then we can see different methods. Then we can see different methods whether one can recover 25. And so here's the result. So basically, one calculates the empirical eigenvalues and then fit a regression of the empirical eigenvalue against the theoretical eigenvalue under the MP distribution. And then calculate the sigma square, then calculate the theoretical cutoff. And then the value above the theoretical cutoff will be the estimated spikes. Spikes were the estimated PC. So you can see using the Beamer method, it worked quite well and it estimates about 28 very close to the truth and is much better than the other method. And to sum up, so the BIMER provide a convenient random matrix theory-based approach to estimate the number of PCs and the inspect Hobart's model. And so this basically estimates the distribution of the box. Estimate the distribution of the bulk eigenvalue from bottom up. And then the weak assumption has been assumed for the covariance matrix. And also, the method is robust to misspecification of the residual invariance matrix. And the application to 1000 genome data shows this BIMA works well. So let me move on to the second problem and also related to PC analysis. So this is related to if we have Related to if we have the SNPsat analysis or a PHIWAS analysis. And if we perform the PCA and to do the dimension reduction of the genotype or dimension reduction of phenotype, and which PC should we use? The first PC or the last PC? And so basically, how do PC-based tests in multiple phenotype regression and multiple SNP was a SNP set regression? They differ? And which PC should we use? And which PC should we use? Should we use the first PC or the last PCs? And so this work was published in Annuals of Applied Statistics two years ago. So here's a problem we focus on. The traditional GWAS analysis analyzes one SNP and one phenotype at time. And in SNP set analysis, and so this is particularly useful in the rebounds analysis. And so basically, it is one analyze a set of a SNP to look. A set of a SNP to look at their association with a particular phenotype. And so, for example, like 100 SNP in ApoE to see whether they are associated with LDL. And in the fewAS analysis, so one look at if one SNP is associated with multiple phenotypes. And then we will focus on these two problems. So in these two problems, the question is, suppose we do the dimension reduction in this first problem, in SNP set problem. In SNP set problem, I can do the dimension reduction, calculate the genotype PCs. And should I use the first genotype PC to look for the association with the phenotype? Would that have the most power? Or should I use last genotype PC? And then that will have a best power. Similarly, for this multiple phenotype analysis, should I use the first PC of the phenotype? Would that give me the best power for association? Or should I use the last? Or should I use the last phenotype PC? And that will give the best association. So that is the question we want to answer. So let's start from the K to 1 problem. So this is a multiple phenotype problem. So basically, you have one genotype, want to see which particular genotype is associated with set K phenotypes. And so here the G is a genotype and it's a scalar and the beta basically is association between each. Basically, is the association between each SNP and each of the phenotype. And now, suppose you calculate the score statistics of the association between this particular SNP and each of the phenotype. And then we want to see if the problem is we're testing all those k betas equal to zero. And now suppose we calculate the distribution of this statistics. Of these statistics. And so this will follow a multivariate normal with the mean as a beta, and this will be the k-dimensional beta, which are the beta of the association of the SNP and the ish of the phenotype. And the covariance will be the covariance of the phenotype. Now let's look at the SNP stat analysis. And so in this situation, one have one to K setting. So that is one phenotype and the K SNP. And then one look at whether the social. And then one look at whether the association of the LDL is associated with, say, K SNP in Apple E's gene. And so in this situation, one can also calculate the SNP specific score statistics. And then, so here in this notation, and so if we look at the notation P indicate of this is the K to one problem. This is P indicate a phenotype. And then this S. Type and then this s indicates the SNP set setting. And so here we figure out the distribution of the Z. And then turns out the distribution of the Z is the sigma beta. What is the sigma S here? And sigma S basically is L D matrix. So therefore, if you compare these two settings, you can see that this statistic have different distribution. So in the multiple phenotype setting, the COVID the covariance of the phenotype only enter into the covariance of the Z statistics, and the mean is just beta. But in the multiple phenotype setting, this covariance of the genotype and enter into both the mean and also the variance. So you can see that L D enter into the mean as well. And so this will make the behavior of the PC based. PC-based association tests differ. So, because in the multiple phenotype settings, the sigma only enters into the covariance of Z, but in the multiple SNP setting, the LD images also enter into the mean. And let's see how that impacts the performance. And so, in the multiple phenotype setting, this is the K to 1 problem. And suppose we calculate the PCs of the score statistic of the statistic of the um then they basically use eigenvectors multiply the z the phenotype uh phenotype uh statistic association z statistic so this basically is a phenotype of pcs and then it will follow the following distribution then you can see that for the last first pc because first pc phenotype pcs have the largest item value so it will have the largest variance and the last pc Variance and the last PC will have the smallest eigenvalue, we have the smallest variance. And so, what this means is the last few phenotype PCs are often more powerful for multiple phenotype association tests. So, how about the SNP setting? And so in this situation, we look at association between a single phenotype and multiple genotype in a set. So, suppose we perform the PC dimension. We perform the PC dimension reduction of the genotype. And so this basically corresponds to you when use the LD matrix and the calculate the eigenvector, multiply these statistics. And so this is the same as you regress the phenotype on each of the genotype PCs. And now if you look at this distribution, you can see the eigenvalue enter into both the mean and also into the variance. So what they tell us is that because the first eigenvalues and the top eigenvalues, Values and the top eigenvalues generally are larger, and so therefore, what that means is it will have a larger mean. So, what that means is the first few genotype PC are generally more powerful for SNP-side association tests. So, this is completely opposite of the multiple phenotype analysis. So, now let's look at the WALF statistics. So, if one look at the K to 1 setting, this is a multiple phenotype setting. And the WARF statistics. setting. And as a war statistic, you can see that can also be written as the weighted phenotype PC. And the weight is one over the eigenvalue. So what that means is basically the last few PCs are weighted more. But now if you look at the SNP set setting, and so this war statistic can also be written as the genotype PC-based association test statistic. And so the weight is And so the weight is also up with the large later PCs. So what that means is the water test for multiple phenotype and water test for multiple SNP both up with a higher order PC. However, their distributions are different. So if you look at the distribution, if you look at the mean, because the mean affects the power. And so you can see in the multiple phenotype setting and then the last few PCs and they are weighted more. And they are weighted more. And however, in the SNP set setting, and so you can see the first few PCs, the means are weighted more. So what this tells us is the last few phenotype PC influence the power of the multiple phenotype water test. However, the first view PC of the genotype PC influence the power of the SNP setting. So this is very opposite. Very opposite. And now let's look at the various component tests. So, the various component tests, it differs from the world test in the weight instead of in the sigma inverse, you have a sigma inverse times sigma inverse. So this is the multiple phenotype setting. So you can see the multiple phenotype setting, the variance components test, basically weight the last few PC more compared to the water task. And then in the SNP set setting, Then in the SNPSTAT setting, this is also correspond to the SCAD in the rebound test setting, and then it provides equal weighting of the genotype PC-based test. So what this tells us is the multiple phenotype variance component tests upweight the higher order phenotype PCs more. And while in the multiple SNP variance component tests, like a SCATEPS, it provides equal weighting of all the genotype PCs. The genotype PCs. And now let's look at the mean because that affects the power. So, if you look at the various component phenotype tests, you can see that that provides more weight to the higher word PCs. And however, if one look at the genotype PC-based advanced component tests like SCAT tests, you can see that provide more weight to the first few PCs on genotype PCs. And genotype PC. So, what they tell us is the last few phenotype PCs influence the power of the phenotype variance component test. And however, for the SNP side test, the first few genotype PC influence the power of the genotype variance component test. So, the behaviors are different. Now, let's look at the data. And so, this is a lipid analysis. We have three lipid traits. And so, you can see this is multiple phenotype setting. So, generally, the large. Type setting. So, generally, the last using the last few PCs will be more powerful for association tests. You can see if you use the last few PCs, you have more discovery. And also, if you use the various component tests, you have more discovery as well compared to use the first phenotype PC for association test. But now, if you look at the SNP set setting and for the gene level analysis, then you can see if one use the first few PCs, and so you can see the first few first PCs with. Few first PCs, we will have more discovery, and then using the last genome-type PCs. And if one use this variance component test, basically this is like SCAT type test, and then that put more weight in the first few PCs. And so it generally has more correspondence to using the first few PC genotype PC based test. So to wrap up, and so the principal angle, I did not have time to Principal angle: I did not have time to present that provide a geometric perspective on the power of the PC-based test in the multiple phenotype setting and also SNP set testing. So in the multiple phenotype setting, this K21 setting, the balance component test and the wall test favors the last few phenotype PC. So basically, if you use the last few PC, phenotype PC to do the dimension reduction, generally you are going to have more powerful. Generally, you are going to have more power for association test. However, for the SNP setting, if one use the first component test and the world test, they favor the first few genotype PC. So in other words, if you do the dimension reduction, use the first few genotype PCs, and then do the test based on the first few genotype PC, generally those have more power compared to using the last few genome type PCs. So this is just completely opposite. And so the better way. And so, the better way is to do the omnibus test by combining the different types of PCs. And I'll stop here.