Very nice place, very interesting talk. So, I'm also one talk in the series that started with Jan Ruigi on unsourced multiple access. So, it's great that he already prepared the stage. The thing here is that we looked at asynchronicity of the devices when they try to do the unsourced multiple access. Okay, so this is a joint work with a PhD student, Mr. Wu. Mr. Lin is postdoc, another PhD student, Marcel. Another PhD student, Marcel, and myself. And we are in the same project as Gen Riji. So the 6G WIC is mentioned here again as a funding agency, in addition to the DFG, the German Research Foundation. But we also have one project of NPO. There's also one disclaimer. So I think we heard today many disclaimers. I have only one. So we started to work on this topic two years ago in the Information Theory and Physical Air Security Group. Layer security group. The topic is still a little bit outside of my comfort zone, so please excuse me. I have definitely forgotten to mention all references. And I've noticed that when I saw the list of GMEG, that we have definitely missed some papers. This was not done on purpose. If you want to read about it, then there is a treatment on archive of what I present. On archive of what I present, you can access the work here at this later. We start with the introduction, motivation, and state of the art. We heard that before, Internet of Things, sensor networks, and ultimately reliably low latency, massive machine-type communications is currently attracting a lot of interest. And there are many challenges. So, here are at least three challenges we have to. Three challenges. We have to deal with short block length code words because of the latency constraints. We will have a large number of devices that one access point has to serve. And these devices will become active in a very sporadic way. And they will also be asynchronous. And we will try to look at those challenges. If you come from the classical network information theory, then we have. Theory, then we have seen also in the talk by Jan Ricci that that does not so scale very well with a number of devices. And one reason is that in the classical multiple access channel we have individual codebooks for all the devices. And then if you have an increasing number of devices, then this doesn't scale. So one perspective on the massive random axis and with one And with one unifying model that was proposed in the reference over here. And in this, all transmitters share one identical code book, and the amount of data that each transmitter wants to transmit is the same. The decoder needs to estimate the list of the transmitted messages, but it's not interested in the identities of the transmitters. They are already after There are already, after seven years, many several variations and different model assumptions, and I try to summarize some of them in the state of the art. The first order capacity of the system was studied in the reference number three, when the number of users is a specific function of the block length, and users apply individual code books for the identification and an identical codebook for. And an identical codebook for the transmission of the information. Then, next, the second order, the finite block length, thousand totic achievable rates of the grant-free random access system was also analyzed in a couple of papers over here. And users access the channel without any prior request, and radius coding is used as well as a feedback signal from the transmitter to. signal from the transmitter to the from the receiver to the transmitters to inform them about the decoding state then the reference that I already cited they looked at the energy efficiency in terms of the EB to N0 of the synchronous unsourced multiple axis and they had a per user error probability constraint. What has also been What has also been mentioned before is the Tfold Aloha scheme that was proposed together at the same time with a low complexity coding scheme for the ground-free Gaussian random access channel. And there they exploit some type of compute and forward approach. Furthermore, they have analyzed also the EB2N0 of this T-fold Aloha and the low-complexity coherence. Now we think that the asynchronous systems are worth investigating because the large number of users is difficult to synchronize and also they might have different distances to the receiver. So it might be very hard to compensate at the user side, at the device side, for these different delays. It turns out that if you look at the classic It turns out that if you look at the classical multiple access channel and you look at the asynchronous case, then the capacity is the same as the one of the synchronous MAC. That's the older reference from more than 20 years ago, under the assumption that the ratio of the delay to the block length asymptotically vanishes when the block length goes to infinity. Now if you do this for finite block length, then it is of course different. Is of course different. The authors in the reference nine apply a sparse orthogonal frequency division multiple axis scheme and a compressed sensing-based algorithm to reliably identify the asynchronous devices and to decode the messages. Now, for the asynchronous unsourced multiple access channel, there exists two references shown here where the default are local. Where the default Aloha is utilized together with OFVM, and they have transformed the time asynchronicity problem to a frequency shift problem. Then they showed that the capacity region of the non-fading asynchronous multiple access channel is the same as the usual synchronous MAC. However, they have one constraint on the maximum delay. It has to be smaller than the length of the scikit prefix. Okay, so now what is the system model we look at, and what are our contributions? So we consider this asynchronous unsourced multiple access channel with a bounded delay. So the delay is also bounded. We will call the maximum delay dm and we will assume that this fraction dm divided by the block length is a constant. So if this constant is equal to 1, then the maximum delay could be equal to n. Maximum delay could be equal to n. If it's smaller than 1, then the maximum delay is smaller than the block length. All the transmitters send a fixed payload size with the identical finite length n codebook, and we assume that all the delays from user 1 to the active user, to the number of active users is Ka, they are smaller than the maximum delay. And in our model, we have one very strict assumption. We want to Strict assumption: We want to decode the messages of all users that are active within this block of n channel users after these n channel users. And that means that users which start to transmit later than the first user, they will not be, so we will not wait until we have received the complete paywalls of those users. So, basically, for some of the users, we will apply. Basically for some of the users we will apply some type of early decoding. We will not wait until we receive the complete code word but start to decode earlier. We have looked at that for the opposite network model for the broadcast channel where we looked at users which have heterogeneous latency constraints and we applied it to compute the second-order achievable rate region with early decomposition. Achievable rate region with early decoding with both IID codes and also shell codes. These are the two references over here. Now here we want to analyze the period user error probability of the OUMAC where we decode all messages, also those which are incompletely received. And when we do the analysis, we want to do something which is more. We want to do something which is more precise than the typical used very async theorem that is used for finite block length. We want or we applied the saddle point across the image to do so. One challenge if you do this is that due to the different delays of the users the error patterns are not permutation invariant anymore. So basically we have to take a look So basically, we have to take a look at all different combinations of wrong decoded error patterns because all of them have different tail probabilities. And then if you want to analyze this, this would sum up to 2 to the power ka minus 1, different tail probabilities. Therefore we derive a uniform upper bound of the pair user probability error probability for the considered system setup. The considerate system setup. Now it turns out, as we will see, that the delay pattern also has an impact on the performance. And in order to understand what is the worst case and prepare for the worst case, we computed the worst case delay pattern and then analyzed the pair user error probability. Then finally, I will show numerical results that compare the achievable EB to N0 for the proposed. B2N0 for the proposed asynchronous unsourced MEC with a synchronous MAC for calibration. Okay, very small. So the tail probability you are referring to with respect to N. Yes, that's correct. Because we have to decode after N symbols. Okay, so we have a typical setup: white Gaussian noise, only no fading, multiple transitions. Multiple transmitters, the number of active transmitters is a positive integer Ka. They all use the same codebook with the same maximum power constraint. And they all have the same data log M nets. The code words are generated IID from a Gaussian distribution with mean zero and variance p, where we choose the variance p is smaller than the maximum transmit power, we choose power back off. Would use power back off. And the power back off is the reason that, of course, we want to avoid that the maximum power constraint is violated too often. Now we define the asynchronicity pattern by the following vector of time shifts or delays as follows. It's a vector with KA components. Each component corresponds to the delay of the corresponding active users. We will make the assumption without loss of generality that the first user Loss of generality, that the first user has no delay, and we will order the delays of the users in increasing order. So the ith entry represents the delay of the ith received codeword relative to the first received codeword, and dm denotes the maximum delay constraint. We will define this number alpha, which is exactly the fraction that I mentioned before, which is the maximum delay divided by the Maximum delay divided by the block length. This should be constant, and by varying alpha, we can change the level of asynchronicity. In this work, we assume that the receiver has perfect knowledge of the asynchronicity and jointly detects the transmitted messages by the maximum information density decoding. So it means that we assume that we know the Know the delays of the users and we know that there are KA users. Okay, so that's also mentioned here. The receiver is not interested in identifying the and also knowing the delays does not mean that we know which user is associated with each delay. So we are still not trying to identify the user. Not trying to identify the users, you know, have not information about that. Okay, I think I explain this slide better with the figure here. So here you can see the channel uses on the x-axis from 1 to n. And n is also the number of channel uses after which we have to decode all message, all code words that we have, that has started. That has started to start to transmit in this time. And we can see the delay pattern over here. So user 1 has delay 0, user 1 has 1, 3, 5, and so on. All the users have 5. And by controlling this parameter alpha, we can now change the maximum delay of the users. For example, if we say n half. example if we say n half alpha would be equal to one half that means after n over two all users active in this block have to start their transmissions yeah do you know alpha at the transmitter when you pick your codebook can you pick it based on the knowledge of alpha you could do so but in our analysis we choose the IID Gaussian codebook We choose the IID Gaussian codebook generation anyway, so we don't exploit that knowledge. Okay, so the point that I mentioned before was now in the error analysis, you have to take a look at the different activity patterns of the users or the delay patterns. And what really matters is the number of active users at one transmission symbol. So, for example, so therefore we have this vector A. This vector A that gives you the number of active users at that particular symbol, A1, A2, up to AN. So, in the example on the slide that I've shown, you can then see here, so for this delay pattern, we can compute the corresponding number of active users with these corresponding vectors. So, we can see, for example, looking at time point three, we have two. Time point three, we have two active users. Looking at time point six, we will have, for example, in this case, five active users. So these numbers will occur in the error analysis data. Now, to conclude the system model, we introduce the shift function in order to express the delays of the different users. And then we can express the received signal y L as the sum over the active users, the delayed code words. Delayed code words plus additive right Gaussian noise. Yeah, and I think I said that before that we have this power constraint of P prime. Now a code for the OMEC is described as follows. At first we have these parameters, n phot length, n number of messages, epsilon is the error probability, the pube upper bound, number of active users, alpha was Active users, alpha was the parameter that describes how asynchronous the system is, and we have the delay pattern. And message set, encoder function, and the decoder function, where the decoder tries to map from the received signal to the KA different messages. The delay has to fulfill the maximum delay constraint and the pairwise user. The pairwise user, the pair user probability has to satisfy the error probability, where we have the following error events. This is the collision that two users use the same code word for the same message. This is the decoding error, and that's the transmit power constraint violation. We assume that the messages are uniformly generated. Yes. Small question, so I just noticed my So I just noticed one thing. Maybe I think it's probably insignificant. But here you're assuming that they are sending distinct cohorts, right? No, in the error probability, so we account for the errors that occur due to the conditions. That's included in the error event. So whenever, so that's the union over all events where two users which are distinct. Where two users, which are distinct, try to send the same message. That's already considered there. That is included in this error probability and in the analysis. So the first result is this upper bound on the cube. Unfortunately, the result is not very convenient, neither to look at, maybe to look at, nor to simulate. One reason is that you have these functions g1 and g2. They depend on some function e. The function e will be explained in a minute. The point is that all these functions depend on the activity pattern. This is this vector A, which describes how many users are active at the Are active at the different time slots. Here you see the definition of this function, E, A, and T. And we have also some terms which are not very nice, which contain higher order terms. Here you see the error probabilities which comes from the collisions and also from the transmit power constraints violation. Now, one problem is that in order to compute this, we have to take Compute this, we have to take the sum over all different error patterns that can occur. And that's not very convenient. And additionally, we can compute this only for a fixed delay pattern and a fixed activity profile. Therefore, the idea is that we will take a look at the worst case over all different delay patterns, activity. Different delay patterns, activity patterns, and that is reflected by the decoder where this is the, sorry, this is shown here in the, yeah. First of all, we look at the worst case error pattern, this is shown in equation 10, and we take a look at the worst case delay pattern, this is shown in equation eleven. Shown in equation 11. And by this, we get an upper bound on the pube, which is where we can avoid to take the sum over all different arrow patterns and we can become independent of all the different delay patterns. And the result is as follows. So the upper bound on the perusal error probability looks like this. We have only one sum where we go from one to the number of. We go from one to the number of active users, and we also have a specific activity pattern, A0 star, which is the worst case activity pattern that we can characterize completely. And it's very easy, actually. It's very easy. It is basically hidden in the description over here. So, what it tells you is that the worst case that can happen is. The worst case that can happen is that there is one user starting to transmit at one time point zero, and all the other users that become active will wait until their maximum delay. Now from the result, well it might be intuitive because if you let all the KA minus one users transmit at the latest time point, you don't observe their You don't observe their symbols, you lose energy for the decoding. On the other hand, you also have less interference for the first observed. So therefore, we needed to do the computations to come up with that. And you can find the details in the paper. So basically, these sets that occur here, they refer all to the parameter t that we get from That we get from the settle point approximation. So, this parameter T0, T underline one, and T star, capital T star one comes from decentral point analysis and therefore we have also to look at these different sets. Okay, now in order to show that this is the worst case, we have That this is the worst case. We have considered the upper bound and we have shown that it decreases with the number of active users and it increases for any delay pattern because we can take a look at the derivative of this product of these functions g1 and g2 with respect to the number of active users at time point i. So having So having more overlap in the transmission leads to more interference, but a larger number of overlapping symbols has also one positive and one negative effect. It leads to more received energy, but meanwhile also to more interference. In the analysis, we can say that the positive effect is dominant. Okay, then the numerical assessment. Here you can see the number of active users on the x-axis between On the x-axis between 60 and 160, the EB to N0 on the Y axis. We have the yellow, we have the dashed, sorry, the yellow. The yellow curve shows the synchronous case and where we compare it also to the synchronous case from the literature. So we use this synchronous. We used this synchronous case for the calibration of the results to see that they fit. And then we have two curves which show varying asynchronicity variables. 0.2 means that the maximum delay is only 20% of the total block length. And alpha equal to 0.4 means 40% of the total block length is the maximum delay. And we can see that here. Delay, and we can see that here in this model we lose by adding more asynchronicity to the system, and the required EB2N0 gets larger. We also did one simulation with a 16-fold Aloha system with an asynchronicity of 0.2. Of course, in this scheme, the asynchronicity is not taken into account, and therefore, the performance is also shown here. It's basically the worst case. We have to take into account. We have to take into account that in our coding scheme we have assumed that we have to decode after n channel uses. Therefore, this result is different to the one that we have seen in the literature for the synchronous case as well as for the case where the asynchronicity is bounded. Okay, so that brings this is basically described on that slide, so I don't need to read that again. Read that again. So, the conclusions are as follows. We tried to come up with a model for the asynchronous unsourced multiple access channel. We used the subtle point approximations to provide some performance bounds. We developed a uniform upper bound on the error's error probability that simplifies the analysis. The numerical results show the trade-off between the delay constraint or the maximum. Delay constraint or the maximum delay that we have alpha times block length and the EB trend zero. And yeah, so for the comparison to the synchronous case, we encounter some performance degradation due to the asynchronicity. Now, I think what we will do next is most likely we will relax the strict decoding constraint. Maybe look at some sliding window to decode only the user that has been completely received. Completely received, so only and then try to perform some type of successive interference cancellation because we cannot do the joint information density decoder in one step. We should also relax the assumptions on the knowledge of the number of active users and their delays. There are suggestions in the literature that I referenced. We could estimate the active users. We could estimate the active number of users in one time slot and then try to decode if we notice that one code work is complete. Extension to multi-carrier or multi-antena systems might be also interesting. And then finally, the extension from the multiple access channel to the interference channel might be also relevant if you consider that usually you don't have a single access point in some IoT environment, but you might have. IoT environment, but you might have multiple access points that are deployed simultaneously without coordination. Okay, thank you very much for your attention. So, your definition of an OMEC code, you defined it as deterministic encoding. Will there be something