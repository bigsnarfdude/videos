Although, from the looks of the background, maybe is coming from Paris at the moment. And so, Alfred, along with being on the frontier of optimal transport research for some time, has also worked to help popularize optimal transport amongst economists with an excellent book, Optimal Transport Methods in Economics. So, looking forward to hearing the talk. Go ahead, Alfred. Talk. Go ahead, Arthur. Thanks a lot, Aaron. Very nice to be here and very nice to see nice and familiar faces and nice and familiar names. So this is going to be a project which is joint with Pauline Corblais. Pauline Corblais is an excellent student. She's at Sciences Paul. She is really at this intersection between math and economics, although her PhD. Economics, although her PhD is in economics. And she's on the market next year. So it's always something that I like to emphasize. And this is a project with Jeremy Fox at Rice. Jeremy is with us now. So it's good to see him. All right. And we're going to talk to you about dynamic models of matching. And I'm actually glad that Robert is here because one of his papers was an inspiration for this. It was an inspiration for this project. So I'm going to describe how in a minute. By the way, the slides of this presentation or actually a closely related presentation that I gave recently are online. It might be useful if you want to go back a few slides. So I'm going to share this with everyone on the chat so that you can download it and refer to it while I'm speaking. And refer to it while I'm speaking. If you want to go back a couple of slides, I always think it's a useful thing to do. So, what do we want to do here? We want to build a model of matching, which is going to be model optimal transportation. It's going to be a standard model of optimal transportation, apart from the fact that, as it is very often the case in economics, we are going to Case in economics, we are going to leave the people the option to remain unmatched. Okay, so it's going to be, I think it's called partial transportation or something like this in mathematics. But in any case, we're going to have the workers and the firms, the worker on one side of the market and the firms on the other side of the market. And they're going to match at equilibrium. And so we're going to get the usual results that basically equilibrium is going to. Is going to be is going to coincide with the optimal transport, the optimal planners solution. That's the most controversiality is that the social planners solution is going to coincide with the equilibrium. So that's the standard model, in fact. The twist that we are going to impose is that basically we're going to consider a repeated version of this game across time. And basically, And basically, as a worker, I have a type, okay, and this type is going to determine my productivity on the labor market. Now, this type in the matching problem that we, in the dynamic problem that we're going to consider, is not going to be something that is going to be fixed once and for all. It's going to evolve, okay? And it's going to evolve stochastically in a random way, but in a way which is going. But in a way which is going to be affected by who I am matched with. Okay, so basically, this is going to be a problem which is going to have a lot in common with market decision processes. In economics, this is called dynamic discrete choice problems, where basically when you make a choice, you need to anticipate not only the short-term reward, but also the But also the fact that basically you are going to transition in another state. And by the fact that you're going to be in another state, at the later period, you're going to be able to extract a different value from the market. In this case, we think that sometimes it might be worth to be an intern in a position which is very uncomfortable and you're not maybe going to produce that much, but you're going to learn. That much, but you're going to learn a lot. So your type is going to evolve. And same thing for the firm. There are employees that are going to change the structure of the firm quite a lot. So basically, the firm should not only see what is going to be the short-term productivity of this employee, but also it should care about the dynamics and it should care about what the next step is going to be. Okay, so we're going to look at a version of this model. At a version of this model in a stationary equilibrium. And the two main applications that we have in mind are labor economics. So I described this idea where we're going to build up human capital by these types of transitions. And the firm is going to basically also evolve thanks to its employees. The second application that we have in mind is going to be family economics, where you Economics, where you might think if you're very, maybe it's a bit unromantic view of the marriage market, but you might anticipate when you take family-related decisions, you might anticipate your next move, right? So, you know, you might decide whether you're going to do this extra kid or not. And one of the things might be, well, what if we split up? And what if I'm stuck on the marriage market again with this? With this extra kit, right? So, this is the type of decision we're going to be thinking, where you are actually thinking of your value at the future period on the market and your value is going to depend on another matching market. All right, okay. So, let me talk to you about basically, let me talk to you about our contribution to the literature. So, our contributions. Literature. So, our contribution is going to be derived this thing, which is going to be this two-sided analog of the Rust model. So Rust is a landmark paper in economics that deals with dynamic discrete choice. So this is a one-sided problem where you have basically the decision maker on one side of the market choosing alternatives, but there's only one side that is making the decisions. Okay, here we're going to. Okay, here we're going to get a two-sided version of this, and it's going to be for those matching contexts. So there's a big literature on dynamic matching in economics. I'm going to skip most of it. The one paper I'm going to refer to is Robert's couple of papers, where they look at a two-period matching model. And Robert, correct me if I mischaracterize your. If I mischaracterize your papers, but these are papers where basically people are going to match twice in their life. On the first period, they're going to match with a university where they are going to acquire human capital, they're going to require skills. And depending on which university they match with, they're going to require different skills. So that's going to induce a type. So in the second period in their life, in the future period of their life, the universities they were matched with. The universities they were matched with is going to become part of their type. Okay, so it's going to make them more or less productive in the second period when they match with first. Okay, so here we have, you know, it's a two-period version of this idea. So we're going to basically generize this idea and work at the stationary equilibria and embed in the Schoenstroup type of model. Okay, so let me. uh so let me uh let me uh start with the model and uh uh you know my my my notations there's a lot of there's quite a lot of notations because you know there's the current period utilities and and matches and there's a future period and so on and so forth so we have to simplify the notations a little bit and hence my notations are not completely standard so i'm going to spend a little bit of time defining those notations so first of all we are going to have agents So, first of all, we are going to have agents. So, the agents are going to be indifferently workers or firms. Okay, so usually we like to define X as the set of workers, Y as the set of firms. But here, Z is going to be X, unit, and Y. It's going to be all the agents. And obviously, it's going to be a bipartite matching model. So, you know, there's only going to be certain matches that are going to be allowed. Okay, but anyway, so Z are going to be the agents to be matched. Z are going to be the agents to be matched. They might be indifferently workers or folks. Qz is going to be the mass of an agent of type Z. Okay, and this for now we're going to assume that it's fixed. But obviously, at some point, because of those transitions and this population dynamics, it's going to become a part of the equations. It's going to be determined that it will be. Okay, so 2Z is basically the concatenation of this vector. There's a finite set Z, it's all finite dimensional. Z, it's all finite dimensional. It's going to be the concatenation of the vector that stands for the masses of the workers and the masses of the which I usually denote Px and QY. But here it's going to be choosy. Okay, then let's talk about the matches. So the matches, as I said, not all the matches are going to be allowed. It's a two-sided matching problem. So we're only going to allow certain matches. So a match is going to be either a match between a worker To be either a match between a worker and a firm, that's a match xy, but it can also be an unassigned worker, in this case a is equal to x, or an unassigned firm, in this case a equals y. Okay, so basically a match is an element of the Cartesian product x times y, union with the Cartesian product x times zero, zero being, you know, being unmatched, union with the Cartesian product zero times y. Product zero times one. Okay, so these are the matches. Again, we allow people either to match across size of the market or to remain unmatched. There's one notation that is going to be useful. It's the cardinality of a match. So it's going to be two if A is a pair. So if A is of type X, Y, W A is going to be two and otherwise going to be one. Okay, if it's on an on, if it's an unassign agent, W A is going to be one. Okay, that's. A is going to be one. Okay, that's going to be useful in a minute. And finally, we are going to define the transportation surplus, the joint surplus of a match A. So here I'm talking about the static case. The dynamics is going to only arrive later. So S-type A, this is going to be the joint surplus of the match. And if you remember, I mean, if you know this literature, the literature that started with The literature that started with Shou and Shou, that Bernard Seleni and I contributed to, that Robert also contributed to in other papers. Basically, it's an interpretation, it's a micro foundation of the optimal transport problem with entropy priorization, where basically we say, well, it's as if we had a transportation surplus that's basically conditional on the characteristics, so conditional on Z on the characteristics. On z, on the characteristics of the match agents, was equal to something that is constant plus a random term. Okay, so here basically a sum of random terms. So basically, we're going to assume that the surplus of a match, S style A, has a deterministic part, which is S A, which is the focus of our attention, plus the sum of random variables that are going to be IID gumbo. And so these are basic. So these are basically epsilon x plus epsilon y if we're talking about an a which is an xy match. Okay, so basically s style xy is going to be s x y plus epsilon x plus epsilon y. Okay, is this clear? Happy to, you know, I'm happy to, you know, take some time if, you know, because if it's not clear here, you know, we're not going to be able to do things. So I'm happy to take some time. Okay, so this is basically the data of the problem. The data of the problem, of the static problem. What we are going to determine, thanks to Shouenchiou, thanks to Shoen Xiu's model, and thanks to the regularized optimal transport problem, is remind me. Why are we summing the idiosyncrasies on the partners in the match? Okay. It's the sum of the partners in the match, exactly. Z is an element of A. So if A is X Y, this is simply epsilon, epsilon for the man plus epsilon for the woman, epsilon for the worker, plus epsilon. Actually, for the work purpose, example. Thanks. But this also, you know, is going to apply if it's an unassigned agent X, it's going to be, then, then it's going to be a random shot for remaining on. Right. So then we have the equivalent quantities. So the equivalent quantities, they're going to be the payoff that agents are going to be able to extract. So here, as we just said, the surplus is random. Surplus is random. So basically, this is going to be the expected payoff average over a given time. Okay, so this is basically what is called usually little ux and little dx in the show and shoot type of literature. So these are going to be the counter of each potential in the language of optimal transport. And finally, mu A is going to be the equivalent mass of a match A. So in optimal transport, this will be the optimal transport plan. Okay. And again, Plan okay, and again, you know, we are leaving the possibility of people to remain unmatched, so not all the mass to Z is going to be matched. Okay, maybe some part of those Z, they are going to decide to remain unmatched, and that's going to be some new Z for the corresponding for the corresponding Z that remain unmatched. Okay? All right, okay, so now let me present you this paper of show and show. Shoen Xiu. So, Shoenxio, you know, it's almost a Schrodinger system. I saw Christian Leonard a minute ago. This is almost a Schrodinger system, but we need to account for those unmatched individuals. Okay, so if it were a Schrodinger system, you would get the classical basically exponential of the main surplus plus or plus inside the exponential plus the potential. Plus the potential for x plus the potential for y. Okay, so here this is what you've got. This is what you've got. So here, this is the surplus. And here, minus the PZ are minus these potentials, okay, minus those payoffs. Here I have, but here, basically, I also have the possibility that mu is X alone, in which case it has to be, basically, it has to be accounted. basically it has to be accounted for and the result of shuen shu i'm about to you know recall it but it's going to be that mu a is exponential of this thing uh where what do i have in the exponential i have sa which is a systematic joint surplus plus the sum over the partners in the match so there are only either one or two partners but anyway log qz log qz where qz again is the number of individual of type z minus p of z the payoff Minus P of Z, the payoff of Z, okay, and all divided by the condensed potential. So this is mu A, and you plug in mu A in the margin equation in order to determine the payoff vectors. Okay, so this is exactly, you know, if you want synchron algorithm, it's going to be an iteration of those equations. You solve for PZ, you're going to solve for PZ iteratively. Okay, now so you. Okay, so here it's not going to be done exactly linearly as in Syncorn because of the unmatched agents. So, because of the unmatched agents, you're going to have basically sometimes an exponent one half. So, then you need to solve quadratic equations. This is what we do with Seranier, actually. We extend this synchron algorithm to the case with unassigned agent, and we show that it's a bunch of quadratic equations to solve. It works as nicely as in the classical case. In the classical case. Okay, so where does it come from? Well, it comes from economic theory. This result comes from a little bit of economic theory, so a little bit of supply and demand. We need to determine mu A, which is the mass of matches of type A. This basically is subject to this margin constraint that the sum over all the A's that contain Z, so either these are going to be of type Zy or it's going to be Z alone, should be equal to Q. Alone should be equal to Q. Okay. What's going to happen is that agents are going to share the surplus if it's pair XY. S X Y is going to be shared between something that is going to go to the worker and something that is going to go to the firm. And the deterministic part of S, so S is going to be split between two deterministic parts, UXA and UYA. u y a okay so that basically s of x y is equal to u x y that goes to x and u x y that goes to y okay so basically agent z in a match a is going to get this utility u z a plus the random utility term here and that's going to induce a choice probability for an agent a to choose a match of type a A match of type A. And this choice probability is going to be, because this is a logic model, because we've assumed that the epsilons had this Gumbo distribution, this choice probability is going to be the Gibbs distribution. Okay, so I'm going to define a PZ. PZ is going to be the log sum X of the utilities. That's going to be the normalizing constant in the denominator. And I'm going to get at the probability of choosing a match A conditional on being an agent. Conditional on being an agent of type Z, mu A divided by 2Z. This is going to be equal to exponential of UZA minus PZ. Exponential UZA because it's a Gibbs probability and minus PZ because the PZ is here to normalize things. So the beauty of this is that this is going to be the point of view of one Z, but for a match XY, there are going to be two Z's that are going to choose that thing. So basically, Choose that thing. So basically, I'm going to, and this is actually not me, it's show-and-show. What we're going to do is we're going to look, we're going to, well, we're going to take logs of this formula. So the log of mu A over 2Z is equal to UZA minus PZ. And we're going to sum across the Z in the match. And when we do this, basically we substitute out UZA. So this recovers SA, and we will cover Schwoenthal formula. So Schwoential formula is a formula that is going to relate. Formula is a formula that is going to relate to relate basically those payoffs PZ to those mu A's, and then we just need to plug into the margins equation here in order to recover an equation on PZ. Okay, so this is where our contribution with Bernard Salanier comes in this paper that took us 10 years, but has just been accepted in the Review of Economic Studies after 10 years. So, basically, what we do is we Basically, what we do is we say, well, actually, those show and show equations, those margins equation, they are the first order condition associated to an optimization problem. Okay, so basically, this problem is the following problem. It's a regularized version of the standard optimal transport problem of Mojin-Kantorovich. Whereas here, basically, we have the usual dual, the usual expression of the dual. This would be the integral of the Cantorovich. Of the control of this potential. This is the sum over all individuals of the number of these individuals times the payoffs that they get, plus this soft penalization of the constraint. And this soft penalization of the constraint is this function z here. So this function z is quite interesting, right? It's quite interesting. It's going to penalize here basically deviation from the constrainted dual. So it's going to penalize, it's going to allow ux plus dy to be greater, to be less, strictly less than. To be less strictly less than s of xy, but it has a nice and interesting interpretation of this function z. I, you know, we chose to call it z because it's supposed to be zero at equilibrium. Why is it zero at equilibrium? Well, because basically this is counting the number of individuals on the market in two different ways. If I want to count the number of individuals in the market, I can count them at the individual level. This is going to be the sum of a Z of QZ. The sum of a z of qz, but I can also count them at the pair level. Okay, so if I count them at that at the pair level, some pairs are actually pairs, so they're going to have coordinated two, but some pairs with brackets are going to be singleton, and they're going to count with coordinate one. So basically, the sum over A of W A, which is the coordinate of A times mu A, should be equal at equilibrium to choose it. So that basically is going to give us this function Z. And this function Z is going to be the sum. this function z is going to be the sum over a of w a times the candidate expression for mu a minus which is this minus the sum of the z trees and this function has super nice properties basically it's the generating function for everything that we're going to do to do so we need to understand the properties of this function very well and then the dynamic extension is going to be actually pretty simple so let's see what happens let's see what happens when we derive this function z with respect to pz With respect to Pz, well, you see that basically, so this is the deriving this function z with respect to the potentials is going to give us minus the sum of the mu A. So this gives us the margin that is induced by those payloads mu. So if I want to at equilibrium, basically I want to equate this margin to QZ, which is why basically it's going to be the portfolio condition associated with this convex optimization problem. It's going to be the minimum, the minimum. It's going to be the minimization over P of the sum over Z, QZ, PZ plus the regularizing term, just because basically when I take the first order condition with respect to PZ, I'm going to get that QZ is going to be equal to the margin that I need to fit. Okay? All right. Okay. So this is all pretty simple. And this is all the static case. Now let's basically use this tool in order to build a dynamic model. So let's think of this dynamic model. What's going to happen? Well, basically, we are in a large population, so we need to think of some Markov transitions, right? So basically, the idea is that if X and Y are matched together, it's going to induce a probability of transition from X to X prime that is going to depend on X and on Y. Okay, that's the idea of. On white. Okay, that's the idea of saying, okay, whoever the firm I match with, if I'm interning with Volman Sachs, maybe I'm going to acquire a lot of human capital. So basically, maybe I'm going to have probability of transitioning to a high tag that are going to be higher. Okay. And same thing for the firm. So for the firm, okay, maybe an intern is not really going to change the face of the firm, but maybe a CEO will, and maybe even interns have actually an impact on this item. So anyway. So, anyway, so basically, I formalize this idea by saying that basically RZA is going to be the mass of individuals of type Z that is going to be induced forward at the next period by one unit of match A. Okay, so let's be more concrete. In the case where basically A is a match between a worker X and a type and a firm. Worker X and type and firm Y. If, as I said before, this is going to induce a probability of transition from X to X prime given Y. So this is basically represented as this. And for the firm, it's going to induce a probability of transition from Y to Y prime. In that case, basically, RZA is simply going to be this expression, right? It's going to be, I'm going to transition if Z is. I'm going to transition if z is x prime. I'm going to transition to type x prime with probability p of x prime even x y and if z is y prime I'm going to transition to type y prime with probability q of y prime even xy. Okay, is this fine? Any question? How much more time do I have? I give about 15 minutes. 15 minutes. Okay, great. Okay. All right. Okay. So, you know. All right. Okay. So, you know, I refer to Rust because this is the standard in economics, but for, you know, given the audience, I'm going to skip the reference to Rust. So let's see what happens. So given this, you know, if I'm a rational agent, when I choose to match with a given partner, I should not only look at my short-term payoff P, but also my expected future payoff. Now, I don't know which type I'm going to transition to at the next. To transition to at the next stage. So I need to take basically expectations. So I'm going to assume that if P' is the vector of payoffs at the next period, which is also the payoffs that agents will extract on the matching market. It's also going to be wages, basically, wages and profits for the firms. Then my payoff. my uh my payoff uh in addition to the my optic term the short term uh the short term uh payoff phi a i should also get the expected value of the future payoff of the worker and of the future payoff of the firm given uh the likelihood of the various transitions that they are okay so in a matrix form this is phi plus beta r transpose because i'm taking expectations so i need to transpose uh r times times p prime. But this is really the expected value of p prime both for the firm and the worker that I'm that that they're going to get. This is going to be the sum of the expected value of u of x prime plus the expected value of v prime of one. Okay, so that's going to be my payoff. So what am I going to do? And this is why I spend so much time on the static case because once you understand how it works for the static case, you know, the diameter. How it works for the static case, you know, the dynamic case comes almost for free because basically, what I'm going to do is I'm going to insert this expression for s in my functions, okay, in my generating functions. And then I'm just, so it's going to become now a function of q. And remember, q was constant until now, but now it's no longer going to be constant because basically people move and the population distributions are going to move. Distributions are going to move as well. So Z depends on Q, it depends on P, which is the present vector of payoffs, and it depends on P prime, which is the next period vector of payoffs. Okay, so basically what we're going to do is we're going to take the derivatives of Z with respect to the various quantities. So the first derivative is this is something we didn't do, we didn't have to do before, but now we will need to do it. It's the derivative of Z with respect to 2Z. Okay? So big Z with respect to Z. Okay, so big Z with respect to 2. So there's a little bit of a clash of notation. I apologize for that, but you know, I don't think there's much risk of confusion. So derivative of capital Z with respect to 2 little Z is going to be simply, if you look at where Z is, here you've got log Z. So, and here you've got the cognitive of the, so basically when you derive with respect to Z, because here you've got a term which is one half for matched pairs and one otherwise, you simply One otherwise, you're simply going to get basically the sum over a that incorporates z of mu a over qz minus one. So what is this? This is something which should be zero because at zero, if the margin equation is fit, this should be equal to zero. Okay, we saw this already. It's another way to express. Okay. The second thing is the derivative with respect to PZ. So if you take the derivative of this with respect to PZ, Of this with respect to PZ, you're simply going to get the margin, the margin, the sum of the matches that contains, okay? Which is supposed to be equal to 2z. The last thing is we're going to derive with respect to p prime z. So when we derive with respect to p prime z, so what is p prime z? You see that p prime z is here after the Markov matrix R. So there's going to be a beta address going to come. So we need to absorb this beta. We need to absorb this beta. And then it's going to be R times mu, all right? Because here, basically, this term here is my candidate to be mu. So essentially, what it's going to give to you when you derive with respect to p prime and when you divide by beta, it's going to give you basically the mass of z at the next period, which is induced forward by the Markov transition. Okay, so now. Okay, so now the equations, the stationary equations of the model are going to be super simple because the first equation is the margin equation. Supply equals demand. It's simply going to be that the derivative of z with respect to q equals zero. And the second equation, this is the stationarity equation. It's basically the mass at the current period, which is the second term here, the derivative with respect to p, should coincide with the mass that you're going to get at the next period. The mass that you're going to get at the next period induced by your mark of transition, okay. And then the last bit is going to be stationary on utilities, that's rational expectations. We're going to impose that p equals p prime, okay, because you're predicting correctly the future. So I'm able to write down the stationary equilibrium equations. These are p equals p prime, first one. The derivative of z with respect to 2z equals zero, market clearing. And then the last one is that beta, the derivative of zero zero zero One is that beta the derivative of z with respect to pz plus the derivative of z with respect to p prime z equals zero. Okay, so obviously the first question that comes into mind is that is this a variational, is is this set of equations variational? Okay, is this basically are these saddle point equations associated to an optimization problem or a min-max problem? Well, actually, it's pretty easy to convince yourself that the answer is no, unless beta is equal to zero or beta equals one. beta is equal to zero or beta equals one. Okay. Beta equals zero is very interesting. You know, it's basically the static case. Beta equals one, super interesting. Okay, so this is basically the case where we're discounting the future, but in the limit when we have a unit rate of discounting. There's a big literature on that in dynamic programming. Okay, so the infinitely patient case. And here, basically, you see that when beta equals one, we can just basically set p equals p prime as the argument of the function. equals p prime as the argument of the function. And so basically I redefine this function f of 2p as z of evaluated at 2pp. So basically I'm forcing p prime to be equal to p. And I'm just saying that basically those equilibrium conditions are simply saddle point condition associated to a min-max problem. So F, easy to verify that F is concave in Q and convex in P. In Q and convex in P. So basically, these equations, the equilibrium conditions when beta equals one, they are the settlement point conditions for this min-max problem. How do we solve them? Well, we solve them using Champot-Pock. Okay, so Champal, so I'm going to talk a little bit about econometrics later. We will need to take some lesser type of regularization. Chambel-Poch is going to be an algorithm of choice here. Okay. Anyway, so Chambal-Co-Pox, of course, conversions very well. We're not surprised. The surprise here, and The surprise here, and it might interest some of you, is that actually even when beta equals one, when beta equals one, you can still work this scheme, right? It no longer has the min-max interpretation, but you still can write down the Schambel-Bach scheme. So the surprise here is that even for beta is less than one, even when beta is quickly less than one, empirically we observe that this scheme converges, converges very nicely. Now, obviously, we no longer have the proof of Changble-Pohm. Longer have the proof of Chamberlain Point because this is no longer a min-max problem. So we can no longer do their usual trick of bounding the duality gap. But there is something that's going on because it is convergent in all the instances that we call it. How much more time do I have to talk a little bit about egg metrics? Five minutes, probably? Yeah, a little bit more, six or seven minutes. Okay, great, great, great. So let's now talk about egg metrics because we did all this because Because we did all this because we were interested in this function phi, this function phi that is here. Okay, and the idea is that we want to know, you know, sometimes maybe we're going to see lots of matches for positions that apparently don't generate a lot of output, but maybe there is a future value. So maybe the story is that really you're going to learn a lot working on this position. On this position. So let's see what's going on here. So, what we want to do basically is we want to parameterize this function, this production function phi, linearly, and we want to learn the parameter. Okay, so we have a basis of function. We're assuming that phi belongs to this basis of function, and we would like to learn the parameter lambda. So, in order to do that, we are going to remain faithful with the spirit of this work, which is basically try to look for saddle pointing. Basically, try to look for saddle point conditions, try to find a variational conditions. So, the way we're going to do is we're just going to plug in this expression for five in the generating function, okay, in the function z. And now this function z is going to be parameterized not only by q, by p, and by p prime, but also by lambda. Okay, well, lambda is the parameter that we want to learn. And everything that I said remains true, but I said remains true, but the added bit is now that when we derive with respect to lambda k, uh, you know, when we derive with respect to lambda k, you see that the phi k term here goes out of the exponential. And so basically, the derivative of z with respect to lambda k becomes the moments associated with basis function k. So what we want to do, the basis of our estimation, is that we're going to match those moments with the observed moments. Because these are moments we observe, right? So what we're going to do? So, what are we going to do? We're going to define those functions. So, here we could do an energy with thermodynamics. So, I don't know if this would be an enthalpy. Robert, you probably know that if this is an enthalpy or whatever. Anyway, you know. I don't know. Anyway, we define this function h. H might be a misnomer, by the way, because anyway, but anyway, let's define this function h, which is z minus the sum of the observed mu hat here. Of the observed, so mu hats here are the observed occurrences of those matches A. So here I'm summing over A over K, sorry, the type of here over K, and over A of mu hat times phi times lambda. Okay, and you see that the first order condition, so everything that I said still applies. That's going to be the equivalent conditions. But on top of that, this is going to be convex with respect to lambda. And optimality with respect to lambda is going to coincide with. Respect to lambda is going to coincide with moment matching. So basically, the way we're going to estimate this lambda is by basically optimizing, at least in the case beta equals one, in the case the saddle point case. We're going to minimize with respect to P and lambda. We're going to maximize over two. And then the saddle point condition associated with this problem is going to give us basically the right parameters along with the equilibrium predictors. Okay, the equilibrium utility. Predictors, okay, the equivalent utilities, everything that we need to know about this problem. Okay, so here again, it's a bit repetitive. In the case beta equals one, this is a saddle point problem, shambled box converges. When beta is less than one, shambled box still converges. So that's the beauty of it. The nice thing is that, you know, if we want to learn a parameter lambda that is highly dimensional, we can do all sorts of things, less openization, a shamble buck. The very nice thing about Schamblbach is that obviously the proximal Obviously, the proximal gradient embedded in this, so it's going to work nicely with this. Okay, one last slide maybe. So we can, yeah, we have versions of the model with birth and death. And this is just a twist in the function H. You can easily imagine when we, because obviously, you know, in the labor market, people appear, people appear at some point on the labor market, and then at some point they disappear, they return. Point they disappear, they return. Okay, so we need the process of birth, we need basically an inflow and an outflow. So the equation, the population equation here becomes, you know, has a right-hand side basically. So now the equation becomes R mu plus I is equal to two. But obviously, you know, this first order logic that I just showed still applies. We simply need to add a term which is beta times the scatter product between i and p. time the scatter product between pi and p prime and everything that is said uh remains uh remains true okay so what do we have on the agenda we have on the agenda you know understanding deeply you know what are we identifying uh because here you know in optimal transport the constant the issue of constancy is is very simple you add a constant term to a potential and then you subtract it to the other side of the market uh and you and and and you keep solutions there are other cases you know in There are other cases, you know, in matching with imperfectly transferable utility, but it's the case here as well where the normalization issues are not so easy. So what exactly are you assuming when you do a normalization? This is an interesting issue which some economists have studied in the one-sided case. We think it'd be very interesting to study here in the two-sided case as well. On the agenda, we'd like to understand why this thing converges, why this scheme converges. Why this thing converges? Why this scheme converges? We have a bunch of empirical applications that we study. In this paper, we look at human capital accumulation. We have another project where we look at family economics, you know, and this idea of divorce and remarriage and what is going to be my value on the secondary matching market if blah blah. And then, you know, extension to the imperfectly transferred. Imperfectly transferable utility. This is a tougher one because here we lose, you know, convexity, we lose optimization, we lose everything. So I don't know if we'll ever be able to do this test one, but in any case, it's always too, you know, it's always cheap to add things on a to-do list. So anyway. So I'm done. Thank you very much for your attention and I'm happy to take questions if you and my co-authors are here to And my co-authors are here to take questions as well. All right, thank you. Let's thank Alfred for the talk and open it up for questions and discussion. Is the paper available somewhere? Not yet. We're writing it up, Robert. Yeah, hopefully, you know, sometime this summer. Hopefully, sometime. Sometimes it's something that's so Alfred, I have a question. You had that formulation with the regular, not quite the regularization, but you had the Vashestine kind of expression plus some expression. Kind of expression plus some expression. And you're in, is it really an entropic regular? Is there a way to interpret that as an entropy? Is it, or is it something entirely different? You mean in the static case, Sumi, right? Yes, in the static case, that's right. Yeah, so it is an entropy cognization, but here you have the possibility of remaining unmatched. So it's a little twist on the entropy coordination. So essentially, let me skip to the language. Actually, let me skip to the language. Let me switch to the familiar language, right? So, wait. If we switch to the familiar language, it's entropic regularization for the appropriate choice of randomness. Is that not right? Yeah, so you know, those epsilons that I talked about, they need to be gumbo, right? They need to and then it becomes an entropic regularization. That's right. So, if they have, so this is this, you know, this is what we did in the pitpo with Kernan Salenia. Did in the paper with Bernard Selenier, we showed that if you have other distributions, you have other regularizations that are not, you know, the standard entropy. But here, assuming they're global, what you're going to get is, so you're going to get switching to familiar language again. So you're going to get. So the difference between the usual optimal transport with entropic regularization is that you don't. Is that you don't everybody does not need to match. So the margin constraints are inequality constraints. So it's going to be some over X. Oh, I'm sorry. You can't see my screen, I guess. I should share all my screen. Sorry about that. Let me redo this. All right. I don't know if you can see now. Yep. Okay, great. Okay, so that's going to be the problem that we're going to regularize. And obviously, Um and obviously I'm going to uh I'm gonna get so if I had equality constraints right if I had equality constraints I would get this okay and this would give me you know the standard the standard problem I could write down the dual the dual would be the minimum of nx u x Ux plus MY DY subject to so plus the soft penization which is going to be t times the sum over x and y of exponential of phi xy minus ux minus vy and if you like And if you like, okay, so let me put a truth here, two t. And if you want to be very elegant, you're going to put here basically an X and an N Y, right? Which is useless, but it's more elegant somehow. Okay? Let's forget about being elegant. Okay, so that would be the standard entropic radioization. Okay, now what we're doing here is that we're What we're doing here is that we're leaving this possibility open of agents to remain unmatched. So, what does it mean for the primal? It means, you know, if we solve for the first-order condition here, there's going to be no option to remain unmatched. Now, the way we're going to do this is we're going to add here a sum, so t times the sum over x of exponential of minus u x over t plus t times the sum. T times the sum of the y of exponential of minus vy over t and you see why right because if you have uh if you have the first order condition associated with the dual uh the first order condition associated with the dual they're going to tell you that nx here so here i'm deriving the first order condition with respect to ux Ux is going to tell you that nx is going to be okay. I'm deriving here with respect to ux, so I'm going to get a minus sign, so it's going to be on the outside of the equal. I'm going to get 2t here, it's going to go with the 2t. So I'm just going to get this sum here where I'm going to sum over y. Okay, so that's going to be the optimal transport. If I just had this term, I would force everybody to be matched. And I would get a problem, by the way, if the sum over n is not equal to the sum over m. Is not equal to the sum over m, but because I have this term here, you know, by first-order condition, I'm going to get this extra term here, right? And so this is going to be interpreted as the mass of individuals who are going to choose to remain unmatched. Okay, I'm going to get the same thing on the other side of the market. And, you know, if you think in terms of, you know, a synchron algorithm, IPSP, whatever, this is not. This is not much more difficult to solve than synchronous algorithm because synchron algorithm is going to define, you know, you're going to define basically Ax and Ax is going to be equal to this thing. This is going to, Ax is going to be this thing. By is going to be the same thing with V, and then you're going to get a system. And then you're going to get a system of the form nx equals to the sum of kxy axby. So that would be the standard simpler algorithm. Well, here, what you're going to get is you're going to get the same thing, but plus ax squared, right? But plus ax squared, right? So, when you solve for the system, it's a quadratic system. So, you can solve it in close forms. So, it goes very fast and it's going to convert very fast. All right. So, the last thing, I'm sorry, it's probably more than you asked. The last thing is that when we go back to the primal, okay, when you go back to the primal that corresponds to this, you're going to get basically this. You're going to get basically this thing, the sum over x of mu x zero, where mu x zero is the difference between n x and this thing log of mu x zero minus okay anyway sorry that was probably a too long answer but anyway so the so the second part is something like a mutual information Second part is something like a mutual information, or maybe it's a relative entropy for non-sub-probability measures, but something of that sort. You have to add these extra terms to account for the inequality. Yeah, so I guess, you know, this is what you said, but this you're adding the one for the conditional distribution of y given x.