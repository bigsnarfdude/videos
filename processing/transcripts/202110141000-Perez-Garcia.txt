So, okay, I mean, the idea is, I mean, okay, I don't plan to talk about all these papers. I mean, I will focus mainly on the last one. But the idea is kind of a long idea that started, I mean, like even before that, and it's in the context of tensor networks. Okay, and then the idea is that, okay, I would like to argue that, I mean, one of the That I mean, one of the reasons that tensor networks are nice, or at least I like them, is because they have this sort of rigorous bulb boundary correspondence, and from there one can say things that I think are interesting. I will mainly focus on one application to see exactly how these things come into practice. And the application is about self-correcting quantum memories. And the question is whether they exist in two dimensions. I think the general belief, and I would say many people would say that this is a fact. And I would say many people will say that this is a fact, not a belief, is that they do not exist in two dimensions, and our results will go in this direction. So we'll not prove anything strange, we simply align with the belief, but we'll do it in a fully rigorous way. Okay, so if they exist, or if quantum self-correction is possible, it's also believed to be due to the political order. Again, I took from Quantum Marass in the super nice picture about the Tamara seen the super nice picture about the article they have about the classification of different topical orders. Okay, so I think, okay, probably everyone in this conference knows a lot and definitely much more than I do about topological phases, but I don't know if there is a clear definition of what a topological phase is. What I think is more or less clear are properties that they're supposed to have, or and some of these properties, of course, And some of these properties, of course, are related between themselves. But I think these are those properties that somehow come into play here. So one is that there is a degeneracy in the ground state. That depends on the topology. So the torus is different than the sphere and all these things. Second, and also very important, is all ground states are locally indistinguishable, meaning that, I mean, in any contractible patch, they have the same radius. They have the same radius density matrix. Third is that the excitations can be understood as quasi-particles. So, again, this is something that is maybe not true in three dimensions, but okay, anyhow, like quasi-particles with anonymic statistics. I will focus on 2D. And okay, as a consequence of 2 is that to move between different ground states, we need to apply non-local operators. And okay, these properties are exactly those that make these systems candidates to be. Make these systems candidates to be good quantum memories because, okay, we will encode the qubit or qubits in the ground space. And this is protected because, exactly because of property four, to have a to create an error, I mean a logical error, meaning to a change in the ground space, the errors need to accumulate in a non-local pattern. And this is unlikely, okay, in which sense is unlikely is essentially the whole point. The whole point. But okay, this is the intuition, the idea behind that. And this is proving to be true in four dimensions. But of course, the important problem is what happens in 2D and in 3D, because of course, I mean, implementing locality in four dimension is hard because our word is not 4D. And okay, of course, this has, I mean, try to solve this problem is what I guess, okay, Jeng Wang can correct me, but I think what motivated Correct me, but I think what motivated him to introduce the HAACOT and I mean start a whole new area of new type of topological faces, vision two dimensions. But here we will focus just on the 2D case. David, very briefly, what do you mean by here? What exactly is proven in 4D? Okay, that thank you. Good, good. In particular, that okay, I will focus on thermal noise, and what is proven is that. And what is proven is that there is a critical temperature below below that temperature, you have a good self-correcting memory in the sense that the lifetime grows fast, probably polynomially or even more than that, as you increase the system size. Okay, thanks. Okay, good. Exactly. Okay, good. Exactly, I'll focus. I mean, I'll go into that later, but I will focus on thermal noise. Okay, good. Okay, that's more or less the point. And then, okay, we will address this problem by using tensor networks, in particular, what they are called PEPs, projected entangled per states. And okay, these objects are this, I mean, tensor networks in general, PEPS. This, I mean, tens of networks in general, PEPS in particular, are interesting because, first of all, they approximate well ground states of locally interacting Hamiltoni with good spectral properties, like a spectral gap. And if one wants to be rigorous, some other properties, they approximate well, the mixed state versions approximate very thermal state at arbitrary temperature, essentially. And this has been starting, I mean, the first one proving this thing was Matt Hastings, but this was, I mean, improved by many other people. Improved by many other people afterwards. Probably you know very well also the references. Okay, in our case, we will also see that indeed PEPs are also good because they give good descriptions, exact descriptions of particular models, which are essentially those that are randomization fixed points, like okitoric code and all these models. Code and all these models, in which the Hamiltonians are commuting. Okay, that's the idea. But before trying to explain in which sense all these properties that we expect for topological order emerge in a very natural way from this tensor network language, I need to introduce the tensor network language, which is just this diagrammatic notation. Okay, so essentially, okay, the basic way to picture tensor networks is with this. Picture tensor networks with this box-like notation. I mean, a tensor is just a collection of complex numbers with many indices. And I mean, simply, I mean, the box, I will have the label of the tensor, and I will introduce one leg per index. For instance, if you have a vector, which is just one index, I have just a box, V with a label and one index, and this is just simply the tensor with coefficients vi. A matrix, we have two legs, one for rows, one for columns. I will Rows, one for columns. I will, okay, in principle, one wants to be rigorous, one needs to add arrows in order to distinguish between covariant and contravariant indices, but I will neglect all these issues. And then a matrix, you have just two indices, and then, okay, it's just something like that, one box with two legs. And then the only interesting operation is just tensor contraction, which is just that, I mean, you identify the indices and you sum over them. For instance, if you have. And you sum over them. For instance, if you have two vectors, then you identify the indices and sum over them along the leg that you contract, and this is just the scalar product. Okay, again, forget about complex numbers and, I mean, sorry, complex conjugates and these things. I mean, just simply to keep things simple. Matrix multiplication is the same. If I have two matrices and I contract the row index of one matrix with the column index of the other matrix, then this is just matrix multiplication. Or if I have one matrix and I sandwich it between two vectors, but that's simple. Between two vectors, but that's simply just this kind of bilinear form, no? Understanding the matrix as a bilinear form. Okay, with this, I can easily introduce the basic PEPS, which is the one-dimensional one, which is usually called matrix polluted state. And this, of course, was introduced, I mean, by Bruno, I mean, Fannis Nastre and Werner in the finally corrected states paper. I think I cited here. I think I cite it here. Yes, exactly here. And it has played a very important role in numerics of quantum math physics, also because of, I mean, the way to understand the MRG as an optimization over the kind of set of matrix spot states. Okay, so a matrix prototype state is just diagrammatically exactly this picture. And okay, maybe it's instructive to see why this picture has exactly this formula. sure it has exactly this formula. I'm restricting here to the transitional invariant case in which all tensors, I mean, the tensor is independent of the position. So essentially this state is defined by a single tensor with three indices. The one that is vertical here is the physical index, and this corresponds to the local Hilbert space associated to a particular position. And then the other two indices are, I mean, just the row and column of a matrix. Row and column of a matrix. So, in a sense, this three-leg tensor can be understood as just a finite collection of matrices indexed by i. Okay. Then, if I do this, all the row and column indices get contracted in the set that one matrix multiplies the next and then the next and then the next. And then I take the trace, which is just for a final matrix contracting column and row. And this is this product of traces of product of matrices. But of course, I do this for each possible. For each possible choice of matrix for each in its finite set of matrices. So I can choose here the matrix A1, sorry, I1, here I2, IN, and this is just exactly corresponds to this number. But then, of course, these indices are kept open. So in the end, I have a multi-index tensor that I can, of course, just take with the computational basis. And then I get this state. Okay, so in general, a normalized state is just a vector in a tensor product Hilbert space. Hilbert space. Okay, if I normalize it, I get a state, and that's kind of the what is called a matte spot state. Good. Okay, these objects have a very nice property, and is that they, I mean, on the one hand, as I said, they approximate well ground states of gapped Hamiltonians, I mean, local interacting Hamiltonians, but on the other hand, they have their own Hamiltonians called parent Hamiltonians, and this is also the construction on the Fannies-Tracade-Lepel paper. Financial Traper paper, which is kind of easy. So we do the following. So we take, let's say, two sides, for instance. I think we want a two-body, I mean, a nearest neighbor Hamiltonian. And then we take all possible boundary conditions in this degree of freedom. I mean, the row and column degree of freedom, which is usually called the virtual degree of freedom. So I put an arbitrary matrix X here. Could you please use a pointer to see which part of the transparent? To see which part of the transparency you are. Cannot you see my hand, something like that? Moving around the X? Now I can. Okay. Yeah, I think if you move it a little slowly, then we see it. Ah, okay, okay. Sorry. Sorry about it. Can you see a hand moving now? The X in the left hand, in the left part of the. Sorry, I was assuming you were. No, no, we can't. We can. We can. Okay, okay, good. Okay, I will try to. Okay, okay, good. Okay, I will try then to move slowly. Okay, so here we have a hand here. So I have this X here, which acts as a boundary condition, but a virtual boundary condition on these two sites. I mean, it's a box here corresponds to a physical site. So imagine I have two particles here. And then I take this state in which I put an arbitrary boundary condition x. The set of vectors I can get by changing this boundary condition x is just. Get by changing this boundary condition x is just a subspace because this is linear. And then what I take is a Hamiltonian that simply annihilates this subspace. And okay, I can take as a standard choice just the projector onto the orthogonal of this subspace. Okay, that's the right-hand side. That's one possible choice and the canonical one. But in general, any semi-definite positive object with the kernel equal to the linear. Equal to the linear space generated by these possible choices of x. And that's the Palli-Hamilton. And why this is a good choice? We can see it here, because if I now take the state now in many particles, I mean, again, the A is the same everywhere, so it's translation invariant, and I take just two of them, let's say these two, and I apply H. I mean, the rest of the tensors act simply as a particular type of boundary condition. A particular type of boundary condition for these two sites. But since this H annihilates any possible boundary condition, this is zero. And this is true in any kind of consecutive pair of positions, I put this H. So in this sense, if I consider as Hamiltonian just this particular H in which H sub i means the same H by translated by I sides, so it's just the traditional invariant version. So, it's a traditional invariant version. It has these nice properties. This is okay. Each one of these H i's is a projector, so it's semi-definite positive. So, the sum is semi-definite positive, but it annihilates the matrix protein state. So, it's clear then that the MPS is a ground state of H, and even more, this H is frustration-free because this MPS annulates each one of the local terms individually. Okay, and this is the Panic-Hamiltonian construction. Panic-Hamiltonian construction. The same can be done in 2D. Now, in two dimensions, in order to define something on a 2D lattice, now I need like a tensor with five indices. The physical one that here is this red dot that can be, I mean, should be seen as a leg pointing out of the screen is corresponding to this N here. And then there are these other four virtual legs. For spiritual legs that get contracted through this lattice. Okay, I should put also say predicted boundary conditions or other types of boundary conditions. And then the only legs that are kept open are those red ones. And again, then this is a particular vector on the tensor product of all these kind of sites. And therefore, if we normalize it properly, it's just a state living on the Hilbert space of many particles. And okay, we call it PEPS by stop. Call it PEPS by historical reasons. It's called projective entangled per states. I mean, it's a different alternative construction, which is totally analogous to that, and the name comes from that. Okay, so that's the state. And I can construct exactly the same apparent Hamiltonian here. Now I take a patch, let's say in this case, a plaquette, for instance, and then I take in the virtual degrees of freedom, I put an arbitrary tensor. I put an arbitrary tensor, x, I mean, with as many legs as we need in order for this to make sense. And again, if I change x arbitrary here, this is a vector space. And then I take as the Hamiltonian, the projector onto the orthogonal complement of that. And okay, a Hamiltonian is an operator that, therefore, also in this box leg note. Also, in this box, leg notation can be seen then as an object like this, like I mean, it's a box in which I have legs pointing out and legs pointing, I mean, up and legs pointing down, which is the input and the output of the Hamiltonian acting as an operator. If I move this H through the lattice, and now I here is essentially all possible translations, then I get also a semi-definite positive operator, which annihilates the PEPS exactly because of the same reason. Okay, then. Because of the same reason. Okay. The action. So is it possible that H turns out to be zero? Yes. Yes. You are totally right. And it's true. In order to avoid this, you need to take regions that are large enough in the following sense. So the dimension of X grows with the boundary, because you have as many legs as boundaries. And the dimension of the physical dimension. And the dimension of the physical dimension grows with the volume because it's just the bulk. So at some point, this is a proper subspace here, just counting dimensions. One thing grows with the boundary and the with the bulk. So if instead of taking just one placet, one takes a bigger region, at some point this will not be zero anymore. I mean, that's that's, but in principle, it could be zero. You are totally right. But if still there is a finite range for which it's not. There's a finite range for which it's not. And okay, there are properties on the PEPS. I mean, essentially, it's the fact that the map that maps a boundary condition to a bulk is injective as a linear map. If this happens, essentially, one can prove that this construction, in this construction, the PEPS is the unique ground state of H. So it's H is far from being zero, even more, the PEPS is the unique ground state. Ground state and okay, with extra conditions, one can impose that the peps is the unique ground state up to the political order. But for that, for that, we have to understand how to plug intopolycal order into this construction. Okay, but that's a, I will go to that next now. But that is a pretty good point, yes, indeed. In principle, okay, for a single placket, in general, one needs to, this can be more than one placket. But okay, for particular examples, one placet would be enough. Okay, okay, so. Okay, okay, so as we have seen, if we take a patch of a PEPS, say a plaquette, we can see here that indeed this can be seen as a linear map that maps a bulk, which is the boundary condition, sorry, a boundary, which is the boundary condition, to the bulk, which is the red dots, or vice versa. And indeed, this was exactly the key to define the Panic Hamiltonian. If we see this as a map from bulk, sorry, from boundary to bulk, the Hamiltonian is just the orthodox. The Hamiltonian is just the orthogonal of the image of that linear map, for instance. Okay, and that's kind of why in PEPS, there is a natural way to have a power boundary correspondence. Okay, how to include topological order in PEPS? And again, the key thing is something that happens at the boundary, and is that we impose a symmetry in the boundary. So, for instance, we take a finite group, for instance. Finite group, for instance, I mean, to have a concrete example, C2 generated by identity and sigma z. And now we ask that in, let's say, one single tensor is invariant under the action of sigma z in the 20 degrees of freedom. So I mean, doing this is doing nothing. Okay, so this type of condition will be exactly the one that will guarantee topological order. So, first of all, this condition is easy to see that this It's easy to see that this is something really stable under blocking. So it's a property of the boundary itself, not of a particular region, but of any region. So, I mean, this is easily seen if we block just two sides. And the reason is clear. I mean, C squared is the identity. So I can plug in this leg C and then another C, and then I use. He froze? Yes, aha. So it's it's so he's frozen, not me. Yeah, we'll see. Well, hopefully, if he can see on his side, he will. Yeah, he's frozen. He'll figure it out. Figure it out. You were cut before, so there was this slide before where you contracted two tensors and the sets disappeared. That's where you got you got stuck. Okay, okay, okay. Here? Yes, exactly. Okay, thank you. Thank you. Okay, good. So, okay, so the point was exactly that this property is not just a property of a single tensor, but it's a property that is stable under blocking. That is stable under blocking. This is a property of a boundary versus a bulk. And it's very easy to see it if we block two tensors. And now I have two tensors. And then I want that if I put sigma c's in the boundary, this just vanish. And the argument is trivial. I mean, in this link, I introduce two sigma c's because, of course, I mean, this is c2, sigma c square is identity. And then I simply apply this equality in each one of the two sides, and I get this. And exactly the same argument works. And exactly the same argument works in any contractible loop, exactly the same argument. Any contractible loop of this, each one of these green dots is one of these sigma c's. And then, okay, if I have this, any contractible loop simply vanish. Okay, what happens with non-contractible loops? Meaning loops around, imagine that, okay, I'm always assuming like this is a torus, so I mean, all these legs are contracted with period boundary conditions, so this is a loop around. So, this is a loop around one of the directions of the torus. And then it's easy to see that by using the symmetry of each one of these local tensors, I can deform arbitrarily these loops. I mean, as I want, like this way. But they will never vanish. I can move them, deform them, but they will never vanish. I have a quick question. So, the action that you draw on the left with all these green dots, is that the Green dots. Does that correspond to a physical action of the group on the physical sites? It's a very good question. So far, I don't care. So you're just making an operation on the tensor map. Exactly, exactly. And see what happens. Indeed, yeah, I mean, if we are in the randomization fixed point, like in the toric code, yes. I mean, we can implement this by acting on a single leg. The nice thing of this view, but I will not enter into that, is that this will allow also. Enter into that is that this will allow also to go to work a way of the randomization fixed point. And there are, of course, very important cases that are a resonating balance boundary state, which is a C2 spin liquid, but is a way of analogy fixed point. And the arguments why there is a topological order and all these things will be exactly the same because you can argue here. But in those cases, in order to implement this, of course, you have to act on something wider, like beyond the correlation length. Something wider, like beyond the correlation length or something. But that's but so far, yeah, I will not care about this. Okay, so so okay, so it's clear that because I can deform this loop, the Hamiltonian will not see that loop in the sense that, okay, I take a term in the Hamiltonian acting here. Okay, there is no loop there, so okay, the term in the Hamiltonian vanishes. But they can take a term here, and in principle, there are And in principle, there are these green dots that could do that H is no longer annihilated here. But that's not the case because, okay, this is equal to a deformed loop, like this one, where this is outside of the action of the Hamiltonian. And therefore, again, the Hamiltonian animates this part. So in the end, all these objects are also ground states. In principle, okay, they could be the same ground state. There is no argument why they should be orthogonal. Okay, but okay. Why they should be orthogonal. Okay, of course, again, in the particular cases of interest, in which we are in the randomization fixed point, and this is not just a particular tensor with a symmetry, but it's exactly the projector onto the symmetric subspace. One can prove easily that these things are orthogonal to each other. But that's okay. If not, in principle, there could be an angle between them, or even being equal at some point. And exactly. Okay, this is part of understanding this topological free transition. Okay. Now, again, openness. Now, again, open strings, they can be the form arbitrary set at the endpoints. I mean, for in this placket, this green dot can be moved here, here, or here, but we can never leave the placket. And the same with the other one. So in the end, this corresponds to excitations with energy equal to two. I mean, because again, all the Hamiltonian terms, exter those in the extreme placettes, will not see the loop and therefore will be zero. I mean, the action on the particular peps. On the particular PEPs, and these are the excitations, and they do have weird statistics, at least for gene on abelian. Okay, also for G abelian, but I mean, it's easy to see for gene on abelian, easier to see in the following. So, I will try to do is the following. I create a pair of excitations A1, A2, B1, B2, as below, and then just do this sort of move one around the other. And if we do this at the level of the PEPs by just Of the PEPs by just deforming the loops. Then one sees that when we pass one excitation through the other one, these objects, these green dots, get conjugated by blue dots. And this is a non-trivial action that corresponds to moving one flux around another flux in the non-abelian case. Okay, so with this, we have seen that just asking for this particular symmetry. This particular symmetry at the level of the local tensor, one recovers, I mean, a kind of easily pictorial way, all these nice four properties that we were looking for in topological models. In particular, those models that I described when the particular tensor is just a projector onto the symmetric subspace, they're exactly the same as Kitai's quantum double models. And in particular, for GC2, this is exactly the trick code. But again, with this picture, we can go beyond the normation of fixed point, and for instance, we can also describe very easily the exactly the resonating balance one state, for instance. I mean, also as an exact peps with the same type of symmetry. Okay, good. So in this way, I have a question. Yes, sir. Yeah, I have a question. So you have this group in the game. So does it mean that every anion that you have that the fusion The diffusion rules are abelian or not? No, no, doesn't need to be because if I take G non-abelian, then I have non-abelian protein statistics. Of course, in this case, all I can get with this picture of a group is they are just quantum doubles of a group. But in principle, the quasi-particles are just the Trinfeld double of a group. I don't know. If the group is not abelian, this is not abelian. Yes. With the same picture. Yes. With the same picture, one can get also, in principle, all stringent models. So, in particular, yeah, every double fusion category or extra properties. But in that case, of course, then the symmetry is no longer a group symmetry. I mean, we need some kind of the symmetry coming from a matrix plot algebra here. But again, the philosophy is the same. The maths are more complicated, but yeah, okay. More complicated, but yeah, okay. In principle, with this picture, you can get all known non-chiral two-dimensional two-dimensional topological models with essentially the same circle of ideas. But okay, for the group case, at least the maths are easier because, okay, representation theory of groups is at least for me much easier than for, I mean, generally, we hope algebras or things like that. But okay, that's but definitely if the group is yes, sure. Go on first. No, no, I simply said that it. No, no, I simply said that if the group is non-abelian, okay, we get non-abelian, yes. I have a basic question about moving the non-contractible loops. So, once you move the loop away from some Hamiltonian term, how do you see that the reduced density matrix on the term is not affected by a loop that is far away since it's acting on the bombs? Okay, you mean when you move the this is the cartoon you were looking for, right? The cartoons you were looking for, right? I mean, just on a previous slide, maybe previous, okay, yeah, okay, yes. I thought you were suggesting, say, on the right picture, that once you move this string away from this group of placettes, that the Hamiltonian has this, it doesn't change the reduced density matrix on the group of four placetes. Was that the suggestion? No, no, what they're simply saying is that if I take this state, which is an excited state, and I would like to see that. And I would like to see that all terms in the Hamiltonian are zero when they act on this state, except those that act on the excited placets. So, for that, I take one which is not in an excited placet, like this one, and I would like to see that the action of this Hamiltonian term is zero on the peps. And this is simply because I can deform this to put it out. And therefore, essentially, the energy is just equal to two. I mean, it's associated to each one of. I mean, it's associated to each one of the two excited placets, this one and this one, because the rest of the Hamiltonian terms are just simply vanish. This is what I wanted to say. And once you know that this state has the same zero energy, how do you see that it has the same local reduced sensing matrices? Okay, this state is not really an excited state, so this is not a ground state. So So, I mean, those that okay, you okay, yeah, yeah, good. Okay, you just say in how do I see in this picture that they do have the same radiocity matrix? No? So actually, so what happens here is that this doesn't need to be the Hamiltonian. I mean, I mean, maybe it's better to do this for the, for really the ground things in the ground state. So I take any big operator in a non-contractible loop, let's say. In a non-contractible loop, let's say essentially this big operator, an arbitrary one. And then the action of this on this state with this loop and without this loop is the same, because I can move this loop outside of this action. So you have two states that have the same effect on every operator on a region. Okay, by duality, they must have the same relativeity matrix on that region. That that's that's the same happens here in the citations. A set, of course, is you touch these things here. So everything that you can move the loops outside of that, because again, any observable acting there will be exactly the same. They must have the same residuity matrix. That's okay, that's the argument. Maybe I'll just ask one more question. So, when you were saying that you draw this big region, then you move the loop away from. This big region, then you move the loop away from it, and it has the same reduced density matrix with or without that loop. How did I see that fact? If the loop had acted on the physical dimension, on the physical bonds, I would have seen it. I'm sorry, on the physical sites, I would have seen it, but on the virtual bonds, I'm not sure. Okay, okay, good point. Yes, yes, you are, in a sense, right. You are totally right in this respect. And indeed, probably that's true. I mean, indeed, it's true. Indeed, it's true that the radioity matrix is the same, exactly the same for exactly the case in which really these things can be mapped to the physical degree of freedom, which is the randomization fixed point. You are totally right. In this case, because the correlation length is zero, you can create these loops by acting on the physical side next to it. But you are totally right. Yes. Yes. For this, we need to be on the RG fix point. Yes. Okay. So you're sort of using the assumption that when I act on the bonds, The assumption that when I act on the bonds, it's not going to affect far away. Yes, exactly. Yes. Okay, thank you. Yes. More questions? Yeah. Does your Z have to be a linear representation or can it also be a projective representation? It's a very good question. In our case, okay, again, I mean, usually in Z2, it doesn't matter, of course. Exactly. Usually we take a linear. Usually, we take linear representations, and even more, usually, we take even the left-regular representation. Um, indeed, if you take the left-regular representation, and this is exactly the projector onto the symmetric subspace, this is exactly the total code or the quantum double. We want really to have at least a representation that has a copy of each irrep because otherwise, if not, I mean, that's kind of, but if you want to have really all the good properties, like commuting Hamiltonians and all this, indeed. Indeed, then you take here the left regular or the right regular, a regular representation so that you have each year with the corresponding multiplicities. And then you can guarantee that really the parent Hamiltonians are all at terms commute between themselves and all these things. And indeed, you can see that this is exactly the toric code or the quantum double law, whatever. But yeah, in principle, you can take also projective representations, but I mean, in our case, we restrict to just even the left-regular representation. Thank you. Okay, good. Okay, so okay, as I said, there is much more to say about how this approach, how general is this to study topical phases. And it will have kind of several results showing that this seems to be the most general thing one can do if one wants to cover at least normalization fixed points. Fixed points. So things with a zero correlation length in a somehow well-defined way. And how, if one imposes these, then one see emerges all these, one see how emerge all these sort of stringent models like Fusion categories and these things. But okay, this is not something I would like to go into because I would like to focus on topical quantum memories and their lifetime. And their lifetime. So, okay, so let's go in this direction and then let's take a two-dimensional topological model with some Hamiltonian. And again, I will take just the ramization fixed points. So Hamiltonians with our frustration-free and commuting, like for instance the Tori code, which is exactly the previous construction for the panel Hamiltonian I constructed already for the case in which I take G equal to C2 and the left regular representation or NEG and the left regular representation. And the left-label representation. And then we assume that there is thermal noise in the weak coupling limit, and we'll take this construction of Davies, in which the infinitesimal generator is the Davies generator. And then we take the evolution given by this Limbladian. Okay, it's a Limbladder evolution. And then we'd like to see how long does it take to reach the fixed point of the evolution, which is the thermal state, okay, that I put here. Thermal state, okay, that I put here and normalized, but the normalized keep state. Because here the information is lost, because at the, I mean, in the contribution from the ground state, all ground states have the same weight. Okay, so I would like to see, because this is the belief, that these objects have, I mean, the very short memory time. And therefore, in order to address this, we'll focus on the Address this, we'll focus on the spectral gap of this Lyme Bladian and would like to see that this is lower bound uniformly independent of the system size for all beta. Okay, the bound of course will depend on beta, will depend on beta badly, I mean exponentially, but the bound will not depend on the system size. So it's true for all beta and for all system, independent of the system size. That's the goal. Okay. Okay. Okay, the first result, the particular case of the Torik code, was proven already in 2007 in a seminar result by Aliki Fannessando Rodecki. And this was extended in 2016 to all abelian models by Comar Lando, Cardinal, and Teme. And then what, okay, there was nothing known about the non-abelian case. And this what we proved. So we proved that indeed for all quantum double models, abelian or non-abelian. All quantum double models, abelian or non-abelian, the same is true. Okay, and indeed, the bound on the spectral gap is the same as for a total code, essentially. I mean, a constant and an exponential on beta. Okay, so that's the result. So, how the proof goes? So, okay, we consider the fixed point, so the thermal state, and then we purify it. So, at each side, we do a partial transposition to make it a pure state, which is usually called, I think, the thermal field double. Which is usually called, I think, the thermal field double state. Because the Hamiltonian is commuting, this object is exactly a peps. And then one can see that indeed the gap of the Lynn-Blood evolution of the Limbladian generator is exactly, okay, or essentially proportional to the gap of the parent Hamiltonian of this PEPS. So then the problem boils down to estimate the gap of a PEPS parent Hamiltonian. Okay, that's the thing. Okay, that's the thing. Okay, what's the problem? The problem is that this problem in general is undecidable. So, we commented on that at the beginning of the talk: that the spectrograph is undecidable, but it's undecidable even for Panis-Hamiltonian of PEPS. So, okay, that's bad news, but okay, this is a general statement. This is meaning that worst case is undecidable, but okay, this is a very particular case. So, the hope is that for this very particular case, okay, the undecidable doesn't. Okay, the undecidable doesn't apply, and we can redecide and even estimate the gap of this Hamiltonian. Okay, and this is what we will do. And the solution comes from, again, ball boundary correspondence. So we would like to characterize in the boundary the existence of a spectral gap in the parent Hermiton of the PEPS. Okay, so for that, we'll go back to this picture in which the PEPS is seen as a map between the boundary and the bulk. And then we'll construct from this a one-dimensional object. This is a one-dimensional object, which is the boundary state. This was done by Thirac company in 2011. And essentially, what they do is say plug another copy of this kind of big tensor, okay, conjugate it on top of it. So that the physical indices are contracted and only the virtual indices in the boundary are left open. So this is a one-dimensional state, okay, because this has a clear one-dimensional picture. This has a clear one-dimensional picture, it's a state, okay, at least semi-definite object and doesn't need to be normalized that lives in the boundary of some region A. Okay, essentially by mapping to this picture all we have seen before, it's easy to see that this object, this one-dimensional object, mediates the correlation in the system, defines the panhermetry of the state, and its symmetry is characteristic to polical order, because again, well, all. Because again, well, all I said before for this object can be mapped to this object. That's the same. But we want to see how to characterize in this boundary state the spectral gap of the bulk Hamiltonian. Okay, there was a conjecture with some numerical evidence saying that the Panache Hamiltonian of a PEPS has a gap if and only if the boundary state is the give state of a short-range Hamiltonian. So that the bulk, the gap in the bulk corresponds. The gap in the bulk corresponds to locality in the interactions in the boundary. Well, one sees the boundary as a Gibbs state. Okay, there is some intuition behind this via Araki's theorem that the Gibbs state of any finite range, one-dimensional Hamiltonian, have exponential decaying correlations. And the reason is that this boundary state mediates the correlations in the system. There is some sort of belief that the spectral gap in the bulk corresponds to DKF correlation. To DKF correlations, exponential DKF correlations. And therefore, okay, this is kind of an intuition why maybe this is true, and probably what motivated them to do some numerics in order to check this. Okay, so our goal is to really prove this formally. And we do this in two theorems. For the quantum memories, only the first theorem will be important, but I will comment on the second one. So the first theorem is the following. If the boundary state is what we call approximately factorizable, Is what we call approximately factorizable, then the value Hamiltonian is gapped. And okay, I want the state is called approximately factorizable if I can write it as a product of two objects. One, you have a region ABC. One object acts only on AB, an identity on C, and the other on B C, an identity on A, and this is just a normal product. And of course, this approximate symbol means that the approximation, I mean, goes exponentially or super polynomially to one. Exponentially or super polynomially to one with the length of B. So the farther the B, the more product this is. Why this is a natural condition? So if this is exact, then one can see that this implies that the Hamiltonian terms indeed commute with each other. So in a sense, this is something related to almost commuting. Also, one can see that this condition is essentially a way to see the Essentially, it's a way to see the Martingale condition of Bruno in the boundary, which is known to be equivalent to gap. So, in the end, this condition looks very similar to Martingale condition and therefore equal to gap. Okay, so that's, but that's a nice condition, this condition on the boundary. Okay, and then our second theorem shows that give states of Hamiltonians with fast-decaying interactions are approximately factorizing. And the intuition is somehow okay. Is somehow okay. Intuition is easy. The proof is not that easy, but the intuition is imagine that instead of a thermal state, I have really imaginary, I mean, instead of thermal state, which is imaginary evolution, I have normal time evolution. Then, because of the locality of H and Librovinson bounds, this can be well approximated by a finite depth circuit. But if I have a finite depth circuit, there is a clear product structure here. I mean, lambda is a Lambda is the blue, and omega is the red. Okay, thing is that we don't have a real evolution, we have imaginary evolution, and we need that Lieb-Robinson bounds also hold in this case. And this was proven by Araki for the finite range case, and we could extend it to sufficiently fast decaying interactions. That is indeed at least to the speed that matters for our problem of total code or quantum doubles. Okay. quantum doubles okay so let's finish with the going and finishing the proof of our result about um lifetime of quantum memories uh so in the end we wanted to estimate the gap of the panel hamiltonian of a particular peps which is the thermal field double associated to the give state of a topological hamiltonian coming from a group and then what we do And then, what we do in the end is: okay, we simply go, compute the boundary state of this object, and prove that it's approximately factorized. And that's it. That's what we do. And that's the end of the talk. Thank you very much.