All right. Thanks to the organizers. I'm very sorry to not be there in person with you all. I visited Oaxaca for the first time a few months ago, and it really is a beautiful place to be doing mathematics. So I'm talking today about braiding groups of homeomorphisms of canner sets. So everything that I'll talk about today is. So everything that I'll talk about today is joint work and various papers with Matt Zaremsky at the University of Albany and Shalae Wu at Fudan. Right, so yes, this audience obviously is familiar with canner sets, but the perspective I'll take today is to be studying groups which are acting on trees as either automorphisms. Trees as either automorphisms of trees or almost automorphisms of trees. So, to do that, let's set up just some initial notation to unify throughout the talk. So, the first family of groups I want to talk about are self-similar groups, which are groups that act actually on a tree and hence act on the boundary of the tree, which is where a counterset arise. So, we'll fix x to be an alphabet zero up through d minus one. So, you know, this implies obviously here that what this implies obviously here that what we'll be talking about is D array canner sets more generally. And then I can take x star to be the set of finite words over x and x omega to be the set of infinite words over the alphabet. With this setup, right, this is where our tree comes up. So x star has the structure of the vertex set of a regular rooted tree. So for instance, our standard binary case, right? We have the empty set for the root, 0 and We have the empty set for the root, zero and one, zero, zero, zero, one, one, zero, and one, one, and we can keep going. And of course, then the boundary of this tree, right, is our x omega, which is the counter set. So then when I'm talking about automorphisms of this object, I just mean automorphisms as a graph. So the automorphisms of the tree is the set of biomass. Of the tree is the set of bijections from the vertex set to the vertex set that preserve whenever two vertices share an edge. Okay, so yeah, so as I said, obviously any automorphism of the tree extends to an action on the canner set. So we want to be able to describe these automorphisms of the tree. So given any automorphism, the way we can start looking The way we can start looking at it is by observing a few things about automorphisms. So, first of all, if I'm thinking about this as graph automorphisms, what I can see here is that the root has degree two, every other vertex has, I sorry, it has degree three. And so, what that means is the root is fixed under any automorphism. Since the root is fixed here, right, since the root is fixed, that means any automorphism must be. means any automorphism must either permute these two vertices or leave them fixed. So the notation that we can use here to describe whether we want to permute or keep them fixed is I can label my tree with a permutation here. And then I can keep making decisions going down the tree. So once I decide whether I'm going to permute these two vertices or keep them fixed, this determines also whether or not I move this entire subtree, right? So if I permute them, then it naturally takes the full Then it naturally takes the full left subtree to the full right subtree. But then after that, I have to make the next decision on the next level of the tree, and I can decide now, maybe I want to permute this one, maybe I want to leave these two alone. And we make these decisions down the tree, deciding what to do at each step. And at the end, we fully label this tree by automorphisms and so by permutations, and this fully describes the automorphism. So what we're really So, what we're really seeing here, if you notice, that I can zoom in on one of my subtrees rooted at some vertex here. And what I see here is I see another infinite regular rooted tree that's been labeled by permutations. So what I see is I see a full other automorphism of a tree here that's isomorphic to the original tree we started with. And so this says then that when I take my That when I take my automorphism, I can decompose it as a permutation, where this permutation here is this permutation at the top. So, this is some element in the symmetric group on D letters. Followed by some new automorphisms. So, in this case, I'm looking at the binary tree. And so, here I have a left automorphism and a right automorphism. But in general, on the D area tree, I will have I will have D new automorphisms. So each one of these is in ot T. All right, so now we can define what we mean by self-similar. So we say a group G is self-similar if for every element in the group. So if I take element in the group. So if I take an element in the group and I do this decomposition as the permutation at the top and the states left to right, then for each i, I have that the states GI are back in the original group. So I'm using a word out loud that I didn't actually write down. So let me just say here that I call these new elements the states of G. All right, so the idea here is when I look locally on my tree, when I look at some subtree here, what I'm seeing. Some subtree here. What I'm seeing is I'm seeing an automorphism that also shows up somewhere on the whole tree. Great. Right, so everybody's favorite example of a self-similar group, the Garuchit group. So this is the most well-studied example of a self-similar group. This one really acts on a binary tree. So 0 and 1 is our alphabet. And I'll take sigma to be the non-trivial permutation of the alphabet. Alphabet. And then the Gorgic group has four generators defined recursively. So A has this non-trivial permutation at the root, and then it has as its two states just the identity automorphism. B here has a trivial permutation at the top, and then on the left subtree, axis A, and on the right subtree, axis C. C has a trivial permutation. C has a trivial permutation at the top and then acts as A on the left subtree and D on the right. And D has a trivial permutation at the top and acts as the identity and as D. So yeah, so perhaps maybe this audience is more familiar with these types of constructions than the average audience, but just in case you're not, right, sometimes the first time you see this definition, it's a little bit confusing because we're defining things in terms of themselves, right? But in reality, this Right. But in reality, this does make sense. And we can see this by tracing out what the generator B does on the binary tree. So we start with the top of my binary tree. And I see that B, right, if I look at my list here, B says that we have no permutation at the top, and then we act as A on the left subtree and C on the right. So what that means is I can add in the next level of my tree, and then I can see that what I should do. Can see that what I should do is replace B by an A on the left subtree and a C on the right. And then I keep going through this procedure. So now I look at what A says to do. So A says I should do a permutation on the first level and nothing more. So what that means is that I can replace A with just this permutation label and then I'm done on the left side of the tree. Whereas C, on the other hand, if I look at my list, C says I do no permutation. C says I do no permutation at first, and then I do A on the left and D on the right. So again, we fill in the next level of our tree. We replace C with A on the left and D on the right. We know what A says to do, right? A says I do a permutation and then I'm done. Whereas D, on the other hand, right, we go to our list. D says no initial permutation and then the identity automorphism and B. Morphism and B. So adding in one more level of our tree, I can replace D here by the identity on the left, so nothing on the left and B on the right. Now we're back where we started, right? We started with the automorphism B. We're back to seeing the label of B again. And so now we just keep iterating this procedure. And inductively, we can fully define B using this permutation labeling. So then the Gorojic group here is the group generated by these four automorphisms. Right, so the Gorogic group is one of our many examples of interesting and surprising groups that we can find by studying homeomorphisms of the Canner set. So in particular, it was introduced by. Particular, it was introduced by Gorczyk in the early 80s, and he proved many things about it. So he proved that it's the first amenable, but not elementary amenable group. So if you don't know what these things mean, right? So roughly amenability is about putting a type of Bonach-Tarski paradox on a group, okay? So there's a way of defining this on the Cayley graph. And roughly, what this says is that this And roughly, what this says is that this group fails, fails the Bonach-Tarski paradox. That's what amenable means. But not elementary amenable means that it doesn't fail for the obvious reasons. So for instance, finite groups, you can't subdivide and double, but also abelian groups, you cannot subdivide and double. And there's various operations that amenability is closed under. And the geruptic group cannot be built using these finite and abelian groups in this way. It also turns out to be the first group of intermediate word growth. This is another property established by Slava. And so what this means, right, is you can count the number. So if you have a finitely generated group, which we do here, you can count how many elements of the group can be written as a word of length n in the generating set. That gives you a function on n, and you can consider how that function grows. And you can consider how that function grows. So it can grow like a polynomial, like in the case of nil-potent groups. It can grow exponentially, like in the case of free groups. And it was open for a really long time whether those were the only two options. And indeed, this is a group where the growth function is faster than any polynomial, but strictly slower than any exponential function. And indeed, that property is how we get amenability. We get amenability. So, intermediate word growth implies amendability. And even more than that, it's also a finitely generated infinite torsion group. And although we have other examples of finitely generated infinite torsion groups, these are still the most really accessible examples as the ones built in similar constructions to that of the Gorc group. You know, there are early examples before Growjek's construction, going back to Golasz and Shafarevich, but these are still. And Shafarevich, but these are still very difficult to understand as actual groups, unlike this group where we have now really fully defined it, right? We have the description. All right. Yeah. So a second example that I want to talk about of self-similar groups is what we call self-identical groups. So these groups are far less interesting on their own right compared to the Goruchic group, but they're sort of relevant in some later constructions when we start doing. Constructions when we start doing this braiding operation that I'll talk about. So these are groups where all the elements have the form that if I take the element and I break it apart as its permutation and as its set of states, what I see is that the set of states are exactly the original element I started with. So what, yeah, so on every single subtree, I see the exact same G that I started with. The reason this is not so interesting. The reason this is not so interesting on its own, right, is you can see pretty quickly what this implies. So if tau is some non-trivial permutation here, then what this says is that, you know, this is the top permutation of G, but then I have G on this subtree and I have G on that subtree. So that means that it has to be the top permutation here and it has to be the top permutation there as well. So that says I have to put this permutation everywhere down the tree, right? I have the what. Tree, right? I have the whatever permutation I put at the top that determines the permutation everywhere. And so, what this is saying, really, right, is that these self-identical groups, these elements with self-identical elements, these are just finite symmetric groups. Yeah. So they're just embeddings of finite symmetric groups or subgroups of finite symmetric groups into the automorphism group of the tree in a way where the action is global. Where the action is global. Again, we can see that this group is self-similar, right, in the same way we can see that the Gorogic group was self-similar. So if you go back to the description of the Gorodic group, right, what self-similar means is that when I look at these states, it's back in the original group. And for the Gorodic group, right, here what we have is these states are in fact back in my generating set. So indeed, we have something similar here. So every element here, when I look at So, every element here, when I look at its states, these states are back in the original group because they are the original element. So, yeah, so these give you some embeddings of these finite symmetric groups. Right. All right. So, that's all I plan to say about self-similar groups. And I'm going to move now to the almost and the word almost automorphisms. And this is where Hickman-Thompson groups come up. Feel free to. Feel free to stop me if anyone has any questions. I'm happy to pause at any point. Okay, so for the Higman-Thomson groups, so these also are defined using trees often, but indeed these are groups which only act on the Canter set and do not have an action on the tree itself, only an almost action. So how we define the Hickman-Thomps groups is first we need to talk about cones. So for every Cones. So for a vertex V in the tree, we define the cone at V to be the set of infinite words. So V W, where W is an X omega. So it's the set of infinite words that have V as a prefix. So this is basically our standard flop and basis for the Canner set. So if we think about the Canner set again as being the boundary of the tree, then what this says, the cone, is all the infinite rays. It is all the infinite rays and my tree that pass through this vertex. And it's the same as saying, right, that I've subdivided my Cantor set in half and then in half again. And then I've picked like this fourth of the Cantor set. So yeah, so this is very much our standard bovin basis. And now we can see that we can do that. And now we can define certain types of homeomorphisms of the canner set. So, in particular, what we'll do is we'll consider subdivisions of the canter set into the basic clop and pieces. So, here I'm going to take u1 through ut and v1 through vt to be two partitions of the canter set into cones. And then from that, I can define a map psi, which goes from the canner set to the canner set. Goes from the canner set to the canner set. And all it does is it takes any infinite sequence that starts with ui and replaces that infinite sequence with a sequence that begins with vi. So we keep the tail and we just replace the prefix. And so for that reason, maps like this are called prefix replacement maps. And then we define the set of all such mappings to be the Higman-Thompson group V sub D, where again, where you see this D showing up, that's just talking about, you know, if we're considering a DRE canner set here. On the Cantor set, what this looks like is something like this, right? So we consider this subdivision of the Cantor set, so we divide it in half, and then we divide the right half in half again. Write half and half again. And then we pick some other subdivision that has the same number of basic cloven pieces. So, and then we just choose some mapping that permutes them. So, I map this red piece to this red piece, the green piece to the green piece, and the purple piece to the purple piece. All right, so the picture here to keep in mind is that this is essentially like permuting the cones, right? The cones, right? We're taking permutation, we're taking two subdivisions and we're permuting the chunks. And the reason I use this word permuting is because, of course, we know the canner set has this very self-similar structure to it, that if I take half of a canner set, it's still a canner set. So that's what makes this well-defined, first of all, right? And so what that means is, right, that even, for instance, here, where the red piece got smaller, it's still being mapped to a piece that's homeomorphic to itself, right? A piece that's homeomorphic to itself, right? It's being mapped to another canner set. So, using the word permuting is, of course, a little bit inaccurate at the same time because there is some stretching and compressing going on here. But permutations is often like the guiding philosophy when you're thinking about the Higman-Thomps groups. If you're trying to figure out like what properties should be true, we often tend to think about the Higman-Thompson group as being like this infinite permutation group and having somewhat similar properties to this. Somewhat similar properties to this. The reason I'm kind of emphasizing this is because it's important again when we start doing this grading operation to realize that both families of groups I've defined so far are essentially defined by permutations. And so what's important for us later is that braids and permutations are closely related to each other. All right. So yeah, of course, these are some other really nice examples and, you know, good examples. You know, good examples for why, in my opinion, studying homeomorphisms of cannercy are important is this is you know a very different type of group than these self-similar groups, but also groups with really surprising properties that we really don't know how to find otherwise. So V2, the case where we're looking at the binary tree. So this is the group that's usually just called V in the literature. Sometimes you'll see Thompson's group V. So this was introduced by Thompson in the This was introduced by Thompson in the 60s and it gave the first finitely presented infinite simple groups. So, you know, it's not so hard to get infinite simple groups that are not finitely generated. Getting finitely generated ones are a little bit harder. I believe it was Higman. I want to know. Anyway, yeah. So you can get finitely generated ones with slightly more effort. Once slightly with slightly more effort, but it's still surprisingly hard for us to find finitely presented infinite simple groups. And a lot of them really come up via these dynamics on the Canner set. And I think maybe you saw some of these yesterday or today, later today, I think. But anyway, so the point is, yeah, canner sets are really useful for finding these types of groups using similar types of constructions. So what are going on here? Going on here. Yeah, so this gave the first finitely presented infinite simple groups. Right. And that's, yeah, the main draw of Thomson's group V, is it gives you this very concrete infinite simple group that you can work with? What I want to define now is a second definition for Thomson's group, which is relevant to us today, and that's via something called strand diagrams. So to do these strand diagrams, To do these strand diagrams, I'm not going to give the formal definition, instead, I'll do a definition by example. Yeah, um, so let's take some prefix replacement map. So, let's say we work on the binary tree and we take the prefix zero, the cone zero to the cone zero, one. Let's say we take the cone one zero and we take it to zero zero. And we take the cone one one and One and we take it to the cone one. So then the way one builds a strand diagram that represents this element that we've defined as a prefix replacement map is to make first a finite binary tree. So the finite binary tree should have as its leaves the codomain cones. So here my tree will look like this because what I have here is 0, 1, 0, and 1. zero, one, zero, and one, one as the leaves here. And then I draw a similar tree, but I draw it upside down for my, yeah, for my for my outputs. So here I have a tree that looks like this. So I have zero, one, zero, zero, zero, one, and one as my cones here. And now I just divide, I just map them according to what our previous. map them according to what our prefix replacement map says. So our prefix replacement map says I should be mapping 0 to 0, 1. So I draw a connector there. It says I should map 1, 0 to 0, 0. So I draw a connector there. And it says I should map 11 to 1. And so I draw a connector there. All right, so this is the strand diagram that represents the same prefix replacement map. Yes. All right. Yes, all right, uh, but one has to be a bit careful here because this is not the only prefix replacement map, or this is not sorry, the only strand diagram that represents this element in the Thompson group. So in particular, as we said, you can divide the Cantor set in half. So I can divide, say, this rightmost cone, for example, into 110 and 111. And I can divide the other cone here into 10 and 11. Here, and the one, zero, and one, one. And if I map the left half to the left half and the right half to the right half, then indeed this defines the exact same map on the Cantor set, but it gives a strand diagram that looks a bit different, right? So the strand diagram corresponds to adding this extra carrot here at the bottom of my tree, an extra carrot here, and then connecting the left side to the left side and the right side to the right side. So, what that means is if I wanted to. So what that means is if I want to define the Higman-Thompson group in terms of these strand diagrams, I really have to define it as the group of equivalence classes of strand diagrams, where the equivalence relation is exactly the relation generated by this here, this expansion and this adding in of carrots here. Right, but you can take this to be the definition of the Thompson group and then this by Thompson group, and then this bypasses acting on the Canner set. And this gives you a second model for looking at this, which is a bit useful when we try and move these to a map and class group setting, which is what we're headed towards. All right, so that's all I plan to say about Thompson groups for the time being. And I have a third family of groups I'm going to define. So this is one of these talks where we spend most of the talk just defining the groups in question. But the third family of groups, we're going to spend a bit. The third family of groups we're going to spend a bit less time on because essentially all they are: so these are these rover neck or shavish groups. So all they are is groups that we get by recognizing that both families of groups we've been talking about so far act on the canner set. So one can put them together. So for a fixed self-similar group G, the Rover-Nekroshavich group, which we denote by V D of G, has as elements, so again. So, again, these are going to be homeomorphisms of the Canner set. And the elements here are going to be found by first applying an element from the Higman-Confin group. And then, again, recognizing that these subdivisions are, again, canter sets. And so thus we can apply elements from the self-similar group to the individual pieces that we got from the subdivision from this first bit. So the picture here. So, the picture here, right? Let's put our picture of our Hignan-Thompson group element up again. So, again, the picture here, the thing is, is that what I have here is I have a whole counter set, right? It's a counter set on its own. I have a counter set here and I have a counter set there. And so what that means is since my self-similar groups also act on counter sets, I can choose G1 and the self-similar group G2 and G3 and let each one of those. G3 and let each one of those act on these individual pieces. And this is what we need to define the Robert Nekrushevich group. All right. And again, that's all I'm going to say about Robert Nekrushevich groups. But now we want to move to some big mapping class groups. Again, if people do have questions, please let me know. So, I think if you attended the talks yesterday, you probably definitely heard some things about mapping class groups. But just to remind you, the mapping class group, the mapping class group is defined on surfaces. So, or at least for us, we'll focus on the surface case. The mapping class group of a surface S, which we denote by map S today, is the Today is the set of orientation-preserving homeomorphisms of the surface taken up to isotopy, which pointwise fix the boundary. Right, so that means, yeah, what we're trying to understand here is symmetries of surfaces, and we make the restriction that we only consider homeomorphisms up to isotopy, right? If two homeomorphisms only differ by an isotopy, we'll think about them as being the same in the mapping class group. Okay, everybody's first example, right? Everybody's first example is if you take, for instance, the surface to be a disk with a set of punctures. So here we identify punctures as being different from boundary components. And so what that means then is if I want to look at the mapping class group, what I'm going to get here is I'm going to get a braid group on four strands. So what that looks like, right, is I think about these four points as being moved around in the surface. When I'm getting the braid group, I'm I'm getting the break group. I'm keeping track of which one's moving in front and which one's moving in back over time. And at the end of the procedure, this is the starting situation. This is how things end. And I have this brave that describes how these points moved around each other. So as I'm sure yesterday, you saw the word big here. Big just means that pi one of the surface is. One of the surface is not finitely generated. So, in this case, right, the brain group, this is not a big mapping class group. But in order for us to make it into a big mapping class group, we can, you know, we need to put some sort of infinite geometry going on here. There's been a lot of study of big mapping class groups, but particularly in the last nine or so years, nine to ten years, and this really got set off with this blog post by Danny Caligari. Blog post by Danny Caligari. All right, so yeah, so how do we make a service into a big service? So the example that's obviously relevant to us today is we replace these finite punctures, right? And instead of having four punctures, we take, for instance, a canner set worth of punctures. So you can take your favorite finite type surface, you can take, say, you know, a torus here, and then you just add a canner set worth of punctures to it. Just add a canner set worth of punctures to it. There's a lot less known about big mapping class groups, but there's been, as I said, it's been a prolific area of research in the last few years. But one way that I argue that we can maybe begin to study some of these big mapping class groups and even to understand small mapping class groups better is to take these well-studied groups of homeomorphisms of the Canter set that have been studied since the 80s. That have been studied since the 80s or since the 60s in the case of Thompson groups, where there's endless research that's been done, essentially, and try and lift some of these results to the big map and class group set in. And the way we can do this, the way we can import these groups and try and see which properties lift is to do what I've said out loud several times, but without writing it, is break. It is braid them. And what I mean by that is to again recall that braid groups and symmetric groups are really closely related, right? For every braid group, you have a corresponding symmetric group. And the symmetric group that you have just comes from tracking the final location of these points, right? So here we see that the first point is in the second location, second is in the first, right? And we have this swapping around. So we have this permutation that comes from the So we have this permutation that comes from the braid group, but we can kind of go backwards, right? We can take any symmetric group and we can look at whatever, you know, whatever braid group matches up with that. So what that means in our case, right, is that we have, for instance, in the Thompson group, it means that we're going to replace. So let me write a couple of words here. We're going to replace symmetric groups with braids. Groups, liberator groups, so here is where this combinatorial model for these Thompson groups is kind of more useful because it gives you a concrete picture here, right? So remember, we had this picture before with these two finite trees, and we just permuted the pieces of the leaves of these cones. So what's happening now, right, is we want to braid them. So we want to now, instead of just permuting, So, we want to now, instead of just permuting them, we want to keep track of which one moves in front and which one moves in back, for instance, right? So, we're replacing the symmetric group in between the two trees with a braid. Yeah. But what's nice about this sort of construction, which is very combinatorial, is it does have a topological translation to these big surfaces. So, topologically, what's happening here, so if you what I So, if you, what I have here is the disc function by the Canter set, but topologically, what's happening here, so this surface, this disc punctured by the canter set, what's happening here is it is homeomorphic. In fact, this surface here is homeomorphic to taking a pair of pants and then adding a pair of pants to each leg and then repeating. And then repeating this forever and ever, right? And so, what I have here is I have these two different descriptions of the same surface, the same disk punctured by the Cantor set. But the benefit of the left picture here is it's giving me a bunch of induced, simple, closed curves in my surface. And a big thing in studying mapping class groups is tracking curves, arcs, these sorts of things. This gives you a lot of information for what's going on in a mapping class group. Group. And so, in particular, what these curves look like over here is: I have a curve here and a curve here, and then I have one here, and here, here, and here. And then, you know, just going all the way down, what you're getting here is you have a bunch of nested simple closed curves, each one containing one of our basic cloven pieces. And so, what's happening then when we're braiding these, so the braided self-similar groups. the braided self-similar groups the braided higman thompson groups the braided rubber nekrishevich groups what they're what's really happening here what each one of these doing are doing is when they're being braided is they're rigidly braiding these simple closed curves on the surface so the word rigid has to be made a bit precise here but we won't go too far into that today but you can kind of picture it means that you know we're not really messing up anything that's inside the symbol close curve Inside the symbol closed curve, we want to think about the symbol closed curve as something that's fixed that we can then move within the surface. And as we move it and as we track it over time, you know, if there's some stretching and compressing going on in the symbol closed curve, then we have some Higman-Thompson things happening. If all the curves remain of, you know, exactly the same size, then what we have here is these self-similar groups happening. And so what we're getting here is this action then of this break. This action then of this braided version of these groups on this disc punctured by the canner set. Yeah, so the braided, so some of these groups have been around for a little while. So braided Higman-Thompson groups were introduced independently by Bren and the Hornois around 2007, 2006. And it turns out that, you know, this braided Gerudgit group, for instance, where it first Group, for instance, where it first kind of pops its head into the literature, is shows up in a paper of Alcock's from 2020, where Alcock was showing that most big mapping class groups fail the TIPS alternative. So he used this as one of his main counterexamples of a subgroup that fails the TIPS alternative. But what's interesting to me about this group is that, in fact, if you look closely at this braided group that Alcock is studying, right? Group that Alcock is studying, right? It turns out that it's isomorphic to one of Gorchik's early groups. So Gorchik gave these torsion groups of intermediate growth, but he also gave some torsion-free examples. So he gave a torsion-free example that acts on the real line. And Alcock totally independently, you know, comes up with this group acting on the surface. And it's exactly this group that was studied 40 years ago as a group of intermediate growth acting on the real life. Group of intermediate growth acting on the real line, but it's, you know, but Gorczyk's definition is in terms of a presentation, and Alcock's definition is in terms of surfaces. And it's a little bit subtle to pick up that these are exactly the same thing. But if you look at them closely and you analyze that presentation, you can see that indeed Alcock's group is exactly this group that was studied 40 years ago. And so I really, I think my goal with this talk is to emphasize like all the groups that everyone here at this conference studies. Here at this conference studies may be useful for trying to say some things about big mapping class groups. Right, so the some other places these have shown up. So the braided Rover Nekrashevich groups in the self-identical setting. So these were introduced by Aroca and Completo in 2020. And then with Serensky, we talked about braided self-similar and more general. Similar and more general river neck or shavage groups. I want to give an argument for why these are actually really natural subgroups of the mapping class groups. You know, obviously you can define this, but you know, but it turns out that these are natural if you're interested in map and class groups. And the example to have in here is to take, for instance, the Dane twist, the half-Dane twist around a boundary curve. Around a boundary curve. So, yeah, what I want to argue here is why we don't want to just talk about the Higman-Thompson group, but why we also want, for instance, these self-identical elements. So, the self-identical elements really pop up here, right? So if I think about what a half vein twist around this curve is going to look like, so what's happening here is I can draw a line through my canner's head. A line through my canner set. Yeah, top and bottom. And then if I do a half-gain twist around this boundary curve in this nice rigid way, what happens is this side ends up here and this side ends up here. And for a slightly better picture here, we can see that I can think about this like a ribbon. I can think about this as a ribbon once I've done this straight thing, and the ribbon is twisting as I do this homeo. As I do this homeomorphism. So it's a bit like a braid, but now we have a front and a back to our ribbon, whereas the strands of the braid don't have this front and back. But of course, Dane twists are, again, things that show up all the time when you're studying math and class groups. And so you probably want to include your Dane twists. And the reason these self-identical elements capture the Dane twist is because, again, we remember that what I have here, the Canter set at the top. The counter set at the top. I have this counter set here. So that means it can be divided in half, right? And if I divide my counter set in half that I've done this half-dane twist on, what I'll see is I'll see these two ribbons that both twist around each other and twist individually. And this is precisely what the permutations of the self-identical elements did, right? You remember whatever permutation we saw at the top, when I divided it in half, I should see the same permutation on the left. I should see the same permutation on the left half and the right half. And so, self-identical elements are really the necessary thing to be included with the Higman-Thompson group if I want to be able to capture things like Dane twists and half-dane twists. So, because of that, when we include these self-identical elements with the Higman-Thompson group, sometimes this is what's called the ribbon-Higman-Thompson group. So, again, you have this kind of combinatorial model where Have this kind of combinatorial model where instead of braiding the individual pieces, you have these ribbons that are allowed to twist. So, yeah, so the first theorem now finally, so with Chalet Wu, what we proved is that the oriented ribbon-Higman-Thompson groups are isomorphic to a family of subgroups that Funar and Capujian studied, which they called the asymptotically rigid mapping class groups. I don't have time in today's. I don't have time in today's talk to really define what asymptotically rigid map and class groups are, but the point is, what they are is they were defined on these tree surfaces, right? That's where Funar and Kapujian were studying these groups. And they proved that one, they're dense in the topology on the big mapping class group. So big mapping class groups have a Polish topology and these groups are dense. Two, they're finitely generated or finitely presented. In fact, they get Or finally presented. In fact, they get a presentation for these groups. But also, they contain every finite type mapping class group of genus zero with no punctures. And so the idea here is that if you look at this tree-like surface, you know, what you can do is you can kind of restrict to what's happening somewhere, somewhere. So if you want to, you know, get the mapping class group of, say, you know, a disk with four functions. Say, you know, a disk with four punctures, then you kind of restrict what's happening here. And yeah, so anyway, so I'm being a bit imprecise here. I'm not really defining these asymptotically rigid mapping class groups. But to me, they're kind of these, you know, very sort of magical subgroups of the big mapping class group in that they let you study all finite type mapping class groups all at the same time. They're somehow very big. They're dense in this mapping class group, but somehow they're also finitely presented. But somehow they're also finitely presented. And now we have this combinatorial model in terms of the ribbon, Higman, Thompson groups. So one of the things that then lets you prove about these groups once you have this mapping between these subgroups of big mapping class groups and these Thompson-like groups is you can prove things like topological finiteness properties. So there's a lot of tools for proving things like finiteness properties in the world of Finiteness properties in the world of Thomson groups. So, what are finiteness properties? So, we say a group G is of type Fn if it emits a classifying space with a finite n skeleton. So, just to remind you what this all means. So, if we have a group with a presentation, then one way you can build a classifying space is you start with a single vertex and you add a loop for each generator. And then you And then you glue in a disk for each relator where the boundary of the disk wraps around corresponding to the relation. At this point, you've built this object whose chi1 is exactly the group you care about. But what you want is you want a group that captures the information that you capture the information of the group, but you don't capture anything else. Yeah, okay. So, Slava, I see you're. Yeah, okay. So, Slava, I see your question, and I will answer that question at the end of the talk. Yes, um, right, so uh, yeah, so you want to, after this, you add in higher dimensional cells to kill the higher homotopy groups. All right, so yeah, in the higher dimensional cells, you kill the higher homotopy groups. Right. And so then what these various properties say, so type F0, F0, so is every group. So every group has type F0 because F0 said I only needed finitely many zero cells. And indeed, I only have one version. Indeed, I only have one vertex necessary in my construction, no matter what group I work with. Type F1 is equivalent to saying the group is finitely generated because it said I could do this construction with only finitely many loops. And type F2 is equivalent to finitely presented. And after that, this becomes a property of topology a lot more than it becomes a property of the algebra of the group. So, this is saying then type Fn means you only needed finitely many N cells. All right, so what I was able to prove with Chalet then is we proved that if we take any subgroup of the brain group and then we take G to be its braided self-identical group, so that means. Braided self-identical group. So that means I have a braid group acting, you know, on D pieces of my counter set, but then when I subdivide them, I see the exact same braid acting on the next level and the exact same braid acting on the next level. And then I look at this braided Rover-Necker-Shavich group, then it will be of type Fn if and only if H's. And so in the case, so as a corollary, what this says, for instance, is that the asymptotically rigid mapping class group of type F infinity, which just infinity, which just means type F n for all n. Type F n for all n. And so the reason this is is because remember the asymptotically rigid mapping class group we said is really the same as adding in the Dane twist. So that's the same as taking a copy of Z, right? A Dane. And so here it's just the single twist braid is the self-identical thing. And so Z has type. And so Z has type F infinity, and so this says the asymptotically rigid mapping class group has type F infinity. More than that, it turns out Zerensky showed that, in fact, there exists a subgroup of the Bray group on D strands of type F and Tight f n, but not f n plus one for all zero less than or equal to n less than or equal to d minus three. So if you choose these sufficiently large, you can find essentially any subgroups with finiteness properties that you want. And so what this tells us also then is that now we have these subgroups of these big mapping class groups with a wide range of finiteness properties. Groups with a wide range of finiteness properties. On the other hand, with Zerensky, we showed that the Brady-Gorchic group is not finitely presented, although I should say that this first part also goes back to previous work of Boroƒçik. So we give a proof in the paper, but indeed it follows from some other work. And so it's not finally presented, but the second half of this. second half of this okay sorry but the second half of this is that we showed then that the braided Gurarchic group and the braided rover necrochet group for the Guruji group has type F infinity so unlike the theorem with Chalet Wu this says that if you take more complicated self-similar groups and put into this construction you maybe can get lots of different finiteness properties uh Proofs of these types of theorems, just to give you some ideas of what goes into these things. So, these proofs usually follow from an application of Brown's criterion combined with Bethvina-Brady discrete Moore's theory. So, I'll state the main ideas here. So, Brown's criterion with Bethvina-Brady discrete Moore's theory essentially says the following. So, let gamma be a group acting cellularly on an n minus one connected. On an N minus one connected CW complex. Suppose that the stabilizer of every P cell is of type Fn minus P. And then on this complex, what you do is you add a height function. So you take a function H from the complex to the real numbers. It needs to be invariant under the group action. And it needs to be what's called a Morse function, which I'll explain in a second what that means. And what you need is And what you need is that the sublevel complexes. So, if you take all the complex that's of height at most m, then you get a co-compact action of the group. So, just to clarify what this Morse function is. So, Morse function just means it's, you can think about it being a height function. In other words, it needs to be discrete on the vertex. On the vertex set and affine on cells. Right, and so what this is saying is we have this complex, we know that it's n minus one connected, we have a group action on it, so this the stabilizer of the p cells have nice, finite nice properties, and then we have a filtration by height, where at each height we have a co-compact action of the group. Of the group. And then the next part of Brown's criterion says that if there exists some number, some t such that for all x in the vertex set of height greater than t, we have that the descending link here is n minus one connected, then gamma is the conclusion of all of this, if we are able to prove all these things, is that gamma is of type F n. Type ethan. So the descending link here, what the descending link means. If you don't know, this is just the subcomplex of the link spanned by vertices of lower height. All right, right. So, this is complicated in general, right? There are several things to check here if you're trying to check Brown's criterion and Bespina-Brady discrete Morse theory. But usually, if you have some kind of Thompson-y setup, the first several steps are quite straightforward. You have kind of a standard complex that you can work with. What ends up tricky in individual proofs is usually trying to study this descending link. So, I'm just going to spend the last few minutes of the talk. Going to spend the last few minutes of the talk talking about what happens in each of these cases for the descending link and how we can understand these things. So, again, I'm not really defining the complex, but all I'm going to tell you is what the descending links in the complex look like. So, for the braided self-identical case, so if we're looking at the Rober-Nekrchevich group, then if we take a vertex of height m, then we can find a map from the descending link to something. From the descending link to something that we call the D disk complex on the disk with M marked points. So yeah, so in this case, I should have M marked points here. And then what the D disk complex is, right, is we look at this disk with With these marked points. So here I have M equals 8 and I have D equals 3. So if I have these three disks, then we say a set of disks will span a simplex if they are disjoint of the isotopy. So in this case, what I will end up with is, if this is my descending link, if I was looking at these three disks, then I see the blue and the green are linked, and so I can't disconnect them. So this gives me. I can't disconnect them. So, this gives me two vertices, but there's no edge between them because they intersect each other. But the red vertex is disjoint from both the blue and the green, and so I get these two edges here. And so then what we prove in order to prove the finiteness properties is that as n goes to infinity, so does the connectivity of the d-disc complex. And then, you know, this map, so this is an example. And then, you know, this map. So, this isn't exactly what the links look like, but as I said, there's a map from the link here. But the map has certain nice properties, which allow us to lift that connectivity to the descending link. And so, what this says is the descending link has the same property. All right, and the Brady-Gorogic group case. For the Brady-Gorgiant group case, we consider something that we call the D25 halves complex. And so, what this looks like is again, I'm going to have these disks, but this time I allow two different types of disks inside. So, I have this red disk, which is what a five halves disk because it encloses two points and half of another point. And then I also have some two disks, which are these disks that enclose exactly two marked points. And then we allow two of these curves are going to form a These curves are going to form a simplex if they're either disjoint or embedded. So, in this case, we get this two-simplex here because all of the curves that I have here are either disjoint or embedded in each other. All right, and then with Zeremsky, we prove something similar. So we prove that, in fact, there is a map from the D2 five halves complex to the D2 complex. And indeed, you can lift again this connectivity through this map. And this connectivity through this map. And so this tells us that the D to five-halves complex also has better and better connectivity properties as you add more and more marked points. All right. And so this is all I plan to say. And so it's a great time to mention the answer to Slava's question in the chat, which is, what about the case of the oriented surface with infinite genus and Cantor set of ends? So indeed, a lot of these things can. Indeed, a lot of these things can go through if you allow genus. So, I at the beginning, you know, I was working with a disc punctured by a canner set. But indeed, you can also do the same type of surface where, you know, you have this pair of pants, but instead of just a pair of pants, it has a genus, right? And you can keep doing this all the way down. And indeed, you can define really similar groups here, right? Really similar groups here, right? You can define something that's very similar to these asymptotically rigid mapping class groups. Where, more precisely, what that says is you choose some finite portion of the surface and you're allowed to do essentially anything you want there. And then you require some rigidity outside. So the self-identical thing, what that's saying is instead of requiring rigidity outside, you're allowed to do something, but you have to do the same thing on each piece going outside. thing on each piece going outside. So if I did a twist here, I need to do a twist at the next level as well. Right. So if I, if, you know, let's draw some little, so for the asymptotically rigid mapping class group, I can map this, for instance. I can map this surface to this surface. This surface, to this surface. And then outside, I want to preserve some rigidity. That's what I was saying. Yeah. All right. And then, yeah, the self-identical thing says if I twist these two pieces, I need to twist these two and these two and all the way down. So you can do the same thing here, and you can get very similar types of theorems, right? You get theorems about the finiteness properties depending on. Properties depending on what's happening out here. Indeed, you have to work with a little bit different complexes. Indeed, you do lose the exact analogy between a braided Thompson group and or a braided self-similar group because the genus allows a lot more to be happening on this part, right? The mapping class group of a surface with genus is very different than the mapping class group of a disk with some puncture or with some. Of a disk with some puncture or with some boundary components. And so, what happens here is you can still prove many of the same theorems. You get lots of finite nice type property theorems, but you have to change your complex a little bit. You can no longer work with kind of the standard Thompson complex, and instead you manipulate that complex into a more surface-style complex that you work with. But indeed, yeah, many of the same theorems go through in this case. And with that, let me just say thanks and let me. Me to say thanks and let me know if you have questions. Thank you, Mark. Thank you very much, Rachel, for the talk. Very nice. So you already answered the question, right, from the audience? I did, yes. It was right, yeah. Very good. Thanks. Are there any other questions from the audience here in presence? Yeah, here we go. So, thank you for the talk. So, thank you for the talk. I have a vague question. So, is it true that braiding cannot increase the finiteness properties, but only this Hickman-Thompson construction can do that? I don't know. Yeah, that's so I think one sort of general good question that one can ask, and that we don't have the answer to is what properties are preserved under Brayden? So, for the self-similar group. So, for the self-similar group case, right, we use a lot of stuff that's very specific to the Garagic group to show that it's not finitely presented there. Again, like I said, it follows from also some earlier papers about the algebraic properties of the Garagic group and groups that surject onto the Gargetic group and this sort of thing. But the question remains, right? Take some other self-similar group of type Fn minus one, but not Fn. When you braid it, When you braid it, does it still have that property? I don't know. It's not clear. So, yeah, I mean, we have theorems in some pretty specific cases, but they use specific things about those specific cases, our theorems. So, but yeah, I think there is, so other things that are preserved, like I said, since this braided Gurarchic group is isomorphic to one of Slava's earlier groups, it means that intermediate growth is also preserved in this case when you take the In this case, when you take the garridge group and you braid it, it maintains intermediate growth and amenability and this sort of thing. But I don't know about other groups, right? Like take some other, you know, some other group of intermediate growth and braid it. And is it still intermediate growth? I don't know. I think it's a good philosophical question to say, you know, what are properties that you can say in general are preserved. And yeah, I think things like this would be interesting. This would be interesting, yes. Thanks. Thank you. Any other questions? Yeah, in presence. Yes, one second. Hi, I have a question on the definition of the Rova-Nekashevich variant of self-similar groups. You said something at the beginning. So is it you describe the elements as first applying an element of V and then applying an element of the self-similar group? Of the self-similar group. Is it the same as considering the subgroup of the homomorphism group of the cantoset that is generated by V in the self-similar group? It is not. It is not. It is a little bit subtle. Most of the time, the answer is yes. In general, the answer is no. And so the sort of key feature is you don't know that every element in the group actually appears as a state somewhere lower down. So if you apply Lower down. So, if you apply the self-similar group at the top first, then there are certain elements that may or may not show up. And so, yeah, that's the big difference, right? So, this group is generated by Thompson's group and putting self-similar group on any proper piece. If you put the self-similar group on any proper piece instead of on the whole thing, then it's the same. Then it's the same. It's the group generated by Thompson's group with the self-summar thing on the proper piece. Because Thompson group lets you move any proper piece to any other proper piece, but it doesn't let you move the whole canter set to something smaller. That's the idea. Okay, I see. Nope. Thank you. Thanks. Okay, so if there are no further questions, I propose to thank Rachel again for the very nice talk. Thank Rachel again for the very nice talk. Thank you. Thank you very much. And see you next time in Ojaka, hopefully, in person. Yes. Yeah. Bye. Bye. Bye.