So I'm happy to introduce Benjamin Schroeder, who's going to talk about split maintroides and major invariance. Thank you very much. Thank you for having me. It's a great place, great people, great math. So thank you. So I want to talk about split metros. These are specific metroids that I think it's worth to look at. I will tell you what they are and how you can use them, even if Jacob already mentioned some tricks, and then I will talk about the Some tricks, and then I will talk about major invariance. So, the combination actually is a way to solve this. Okay, so I will take the perspective of polytopes here. I've mentioned that before, but so if you have a matroid, you can turn that into a polytope. How do you do this? So, one easy way to do it is just take the characteristic vectors of all the bases, take the convex L, you have a polytope. And that's the point I want to study. So, if you do that for To study. So, if you do that for all the k-element subsets of an n-element set, you get the hyper simplex. It's also an interesting polytope for itself. So, this is a slice to a cube with the hyper plane all cornered sum to k. There we are, the matriarch polytope of rank k on n elements. It's a sub-polytope. And how do you get that? Of course, you can still just take the convex all of the characteristic vectors, or you take the hypersimplex and you cut away something. And you cut away something, and how do you cut this away? You take a cyclic flat. So, this is the union of circuits, which is closed, so which is a flat, and you just sum over all the coordinates which appear in that cyclic flat. You ask for, is that, or you want that, this is smaller than the rank of your cyclic flat. So, this gives you the description, auto-description of a popular. So, here's a toy example where Here is a toy example, very small. So let's say we take the columns of this matrix. This is a 2x4 matrix. Potentially, you can have six different bases. But in this case, you don't. Why? I mean, column 3 and 4 are dependent. Everyone can see this. So there are only 5 bases. One is missing. Geometrically, what happens there is you have the octahedral, which is the hypersimplex 2,4, but you cut this with a But you cut this with an additional inequality or half space, which says, I mean, the coordinate sum of 3 and 4 should be smaller than 1, because the rank of 3 and 4 is 1. I also drew the letters of flats that also appeared in talks before, and I marked the cyclic flats in red, so the empty set, the entire set, and 3, 4. You see, 3, 4. And you see, 3-4 is what will do the job for you. Okay, so this is the picture. So, this is true if you do this for all flats, but you can get away with just the cyclic ones? Yes, that's true. And put more inequalities there. You can also take the circuits, and then this will be not even an integral polytope, but if you take the integer half, then this will be final get math. Okay. So, what is a split? So, I want to talk about split matrix. So, all the splits come from this polyhedral point of view. A split is just a cut of your polyfill into two pieces. What a split is. And I call two splits compatible if so every cut into two pieces comes with a hyperplane. If hyperplanes do not intersect in the interior, Do not intersect in interior, then I think we can call them compatible. And I mean, this is what I want. I want that all these facets, right? So every half space comes with a hyperplane. If my polytope, my matriarch polytope is really nice, meaning these hyperplanes do not intersect in the interior, then whatever you get, I will call a split matrix. So that's the property. And here are two examples. So on the right, it's cutting the octahedron. Cutting the octahedron into two pieces. Both of them we already saw are matroid polytopes. This will be a split for both pieces and the entire thing too will be split matroids. But you can do more complicated things like here on the left. This is actually, if I look at this polytope, it's a five-dimensional polytope, so I have to project it. That's why it might look a little bit skew, but so the outer part that you see. The outer part that you see is the hypersimplex two six. But if you project it, it looks like this, and you can cut with two hyperplanes to obtain this lightly gray shaded major polytope. And this is again a split polytope, but a major split polytope. And the hyperplanes are 1, 2 is, so x1 plus x2 is smaller than 1, and x4 plus x5 plus x6 is smaller. X5 plus X6 is smaller than 1. Yes? What about your definition of split matrix? Because the fastness of a polytop or diagonal intersecting interior, are you saying the intersecting interior of the hypersimplex? Of the hypersimplex, yes. It's always with respect to the hypersimplex. But I give you an alternative definition soon, which is maybe easier to pass. So now I want to describe this not in a geometric way, I want to describe this in a more I want to describe this in a more combinatorial way. And to do this, I need two definitions. So, one is a cusp of a given set. So, you have given a matriarch and a set. And I want to call the cusp of this set. What is that? That's all elements, which are all subsets of the size K of my ground set, such that the intersection with this given set A. Intersection with this given set A is too large. And what does too large mean? That it's larger than the rank of A. So if A would be a cyclic flat, then you already see the cusp or all elements in the cusp can't be basises. This is the idea. And the other term I need is a stressed set. So you mentioned it but didn't define it. So what's a stressed set? So a set is stressed with respect to the nature. With respect to that nature, if both the restriction to that set and the contraction are both uniform nature. Okay, so this is all you need. So here is my example from earlier. So if I take, for example, 3, 4 as my sub A, then can see immediately that this is stressed. Why is it stressed? Because I mean, restriction, contraction are uniform matrix of rank 1 with two elements. And the cusp of 3,4 would be just 3,4 itself. Okay, on the right I drew more interesting letters of flats, and I marked again the cyclic flats, and there I see things which are not stressed, so not all the cyclic flats are stressed. So cyclic flat 3, 5, 6 would be a stressed set. Why? Because, I mean, if I look at the bottom, this looks like a uniform edge chord. This looks like a uniform atrophy, so that's the restriction. If I look at the top, this is also a uniform atrophy, so this would work. But either 1, 2, 3, 4 wouldn't be a stressed set, because if I look at the restriction, there's something parallel, can't be stressed. Or if I look at 1, 2, then the contraction contains 1, 2, 3, 4, and again, 3, 4 then, because I contracted 1, 2, but um Attractive one too, but isn't stressed either. Okay, so these are the terms I need. So, what can I do with them? I can do something that you already probably guessed. I can add to my set of bases. So, given a matrix M and its basis and some stressed set A, then I can look at B and I add just everything which is the cusp of B. And this is again a mage point. And this is again a matriarch, which I call the relaxation of m by A. Okay, so this is pretty nice. And here's almost the example from before. So if I start with the direct sum, or geometrically just a product of two intervals, then I get this nice square, or the major polytope of u12 plus u12. If I now relax, If I now relax, let's say 1, 2, then I add the cusp, which is just 1, 2, and I get the Egyptian pyramid, or the matriarch polytope that we saw before. Now I can go on, and I can relax 3, 4, and then I get the hypersonics 4, the uniform matriarch. And I'm happy. And this also doesn't depend on the order. So everything is nice here. And there's a nice theorem or an alternative definition. Theorem or an alternative definition of the elementary split. So the matrix elementary split, if after we have relaxed all the stressed flats or subsets, you obtain a uniform matrix. So everything we saw here is actually elementary split matrix. So for example, this direct sum is a elementary split matrix because you can relax. Because you can relax the set of 1,2 pyramid. What's the definition of it? Ah, the elementary. This means, okay, so this is a little bit more technical, but for if you say your matrix is connected, it's the same as before. Yes. So this is a technical reason why I put elementary here, but let's ignore this for the moment. So for connected matroids, elementary split matroids and split matroids are the same. Matrix are the same. If you're disconnected, then the question is: with respect of which polytope do you don't want intersections and the subtlety. Is this sort of implicitly saying that if I have a set where I can do a relaxation, that it, if I have multiple sets where I can do a relaxation, the order doesn't matter. So it's completely sitting with a skull commute, that if I have something that I can do a relaxation of, I don't like getting new things. I don't like hit new things that I could potentially relax. With this type of relaxation, yes. Yep. Yes. What should we call the reverse operation of collection? I don't know. Stressing. Stressing. It's very stressing. Okay. I already showed you some examples. This is somehow the easiest kind of example, right? So let's take a direct sum of two uniform matrix. Sum of two uniform matrials and take the relaxation with respect to the ground set of one of these. So in this case, I take the later one. And then what you get is a new matroid. This is now a connected matroid, which I call caspet.matroid. Basically, everything that you saw in the casp, plus another layer. So why is this interesting? Why are split metroids interesting? Split matroids interesting. One perspective is you maybe have heard about paving and sparse paving matroids. So the matriarch is paving if each circuit is large, either of size k, which is the rank of your matriarch, or even k plus 1. And it's sparse paving if this is also true for the dual. And there's a famous conjecture that almost all matrix are paving or sparse paving. And I think Rudy knows more about that than everyone else in this movie. A nice proposition. And a nice proposition is if you have a sparse paving matroid, you can do the relaxation of all the rank k minus 1 flats, and you obtain the uniform matroid, and this also works the other way around. And this definition or this proposition gives you immediately that paving matroids and sparse paving matroids are also split. At least you have that many elements there, and we believe this graph. We believe this class of split matrons to be much larger in the sense of even if you remove all the non-paving matrons, well, all the paving matrons, if you remove them, most of them are again split or eliminate. Okay, so this is the setup. And now I want to turn to the second part of my title, valuations. They appeared already. What's the valuation? So this is a map from geometry, from polytopes, or in general. From polytopes, or in general, convex bodies, into a group. What's the property? How do you transfer polytopes and geometry into a group? By this nice assumption, so you want that the union of your two polytopes. You evaluate that, and the intersection is the same as just evaluating your original polytopes. And this only makes sense, of course, if the union and the intersection are both. Union and the intersection are also polytopes in your pre-described family. For this talk, the only thing we have to consider is major base polytopes either with a fixed crown set or sometimes I don't even care about the crown set, I just recall them. And this is a trick that Federico mentioned, right? So there's an easy way to evaluate my matroid. By a matroid, by knowing just few things. Few things means, for example, if I know what all the Schubert metroid or nested matrix with a different name do for my valuation, I can express every matriroid. Or alternatively, I can also do this. If I know what happens for series parallel matriarchs, which are even graphic and also realizable, then it's also enough. Yeah, this is a spanning set. Yeah, this is the spanning set, this is the basis. Okay, so what does that mean for split matroids or elementary split matroids? This formula, how to express this with these simple-minded matroids, becomes really nice. So if I have some elementary split matroid, then I can express evaluation just by knowing what happens on uniform matroids, these caspital matroids, which are. These caspital matroids, which are as simple as possible, which are also Schubert matroids, and direct sums of uniformity. I know what happens there. I know what happens for all these elementary split matroids, which are many. So I need to know a few things to learn something about many. And that's, I think, a really nice theory. And then the rest of my time, I will give you some examples. Give you some examples how I can use this formula to say something. Something meaningful, hopefully. Are there questions so far? Okay. Then let's jump in the first example. This is from a polyhedral application, so this is Erhard theory. So what can I do? I mean, I can just count in my matrix-based polytope how many letters points are there. This is just the number of bases. But now I can scale my. But now I can scale my polytope by a factor t and ask again how many lattice points are there. This function is a polynomial function. That's why the name. So I can assign to my matriarch just the Erhard polynomial. And it turns out this is a relative invariant. That's even actually not hard to see because I just count letters on it. Okay. Now I can apply my theorem. Now I can apply my theorem and there was a famous conjecture from 2009 that asked what are these coefficients of these Erhab polynomials. And they claim for all matriarch polytopes, they should be just positive numbers, which is wrong. But it's not so easy to see that this isn't true. And how does the counterexample work? It works exactly with the method or the theorem I just With the method or the theorem I just showed you, one needs a formula for the uniform matroid. If I have a formula for the uniform matriarch, for the R polynomial, I also have something for the direct sum because it's just a product of uniform matrix. And then I need a formula for the caspetal matrix. And to find a counterexample, I can even make a very special caspal matrix. I cut away just single vertices for my polyto. So I look at For my polytole. So I look at sparse paving matrix. And the hard part is to figure out what is this number lambda in my theorem. So my theorem here depends on numbers lambda, and I wonder what are they. I can find a lower bound by using a very old and nice result of Graham and Sloan, which gives me this bound, and I plug in large enough numbers, and then I figure out. And then I figure out the drastic term of some of them will be negative. This is what my co-wisfermoni did. For other ranks, we proved actually they are non-negative, but for this is how all the context samples we do work. I think it's a neat method, and it's again, you can easily check with a computer that you have these formulas, you don't need to express the matriarch itself, so you don't enumerate all these crazily many matrix. All these crazily many matroids, but you can check very many. Okay, so this is the first example. So the second one is, I mean, how do you prove, how do you come up that something is a matriarch invariant, which is valuative? This is a really, really nice method by Federico and Mario. You can, if I know that I have two valuations, I can just get on a new one. Just get out a new one by doing this convolution trick. So, how does this convolution work? I go over all the subsets, I look at the restrictions and evaluate them on my first evaluation, and then I do the same for the restriction on the other one, so it's not symmetric, but this always gives me a new valuation. Here's a very small example of this trick. So let's take matrix and prime. Let's take matro xm prime, which is just a constant, at least if you fix the size of the crown set at the rank. And this is either 1 or minus 1. So this is a valuation trivially. Or even if you take something like minus t to the power of something constant, okay, that's also trivially evaluation. So this is easy to see. And now I can just take the trick, take the convolution, and what I get is. Convolution, and what I get is the characteristic polynomial. So for up to sine, which is pretty nice, right? So this is a nice proof once you have this theorem to get the new valuation. Okay, so this is how most of the proofs work, find the right input. Another thing that appeared in many talks, probably will in others, is the chowring. What's the role of the chowring with all these, I mean, I mean, with valuations, where's the link between these? So, let's say we have this description of the charing that Ferruko gave us in the first lecture by Brian, then I can somehow say something about homomorphisms. It's charging to any group. If I have such a homomorphism, then I can, of course, concatenate that with some variation, and I get a new variation. So, that's not so interesting. They get a new valuation. So that's not so interesting. But the other way around is the interesting part, right? So if I have any value addition, then I can here, I have any valuation, and I have this fixed valuation which goes from the matroids into this chow ring, which should be the chow ring of the free matroid, then I can find a unique homomorphism which factors. Homomorphism, which factors through the non-empty property CHAP. Yes, that's true. Okay, so I think time is almost up, so let me skip the last application and go to the summary directly. So what we saw is sprit matrix are really nice. They are many and well structured. And well structured. And I mean, I gave you the counterexample of the L'Oreal-Horst Campus conjecture, but there are others which do not rely on valuations. But also, comes even more interesting if you combine them with valuations. And there are very, very many things which are valuations, many variants, or invariants, very, many major invariants that people cared about before they knew that they are valuations. But it turned out they are all valuations. But it turned out they are all valuations, and you can combine and test your conjectures with split matroids and see what happens here and there. And of course, there's a lot we have done, most of you have done, but there's also many open questions. Much I know, I want to do. So talk to me if you're looking for problems and want to discuss split metroids or value issues. Thank you. Questions, Mika? Does that formula you had for valuative invariance simplify at all in the case of paving matroids or sparse paving matroids? Or is this really kind of Yes. So the part that gets better is this part, right? So I mean, and the others are not so hard anyways, because this is just a uniform matrix. I guess you're wondering what that is for these solid matrix. I mean, the way I think about these caspital matrix is you have your hypersonplex, now you cut with a single hyperplane, you shop it into two parts, right? And one of these two parts is exactly this. And if you do this for a sparse paving matriarch, then this will be the minimal matriarch. So just the vertex and its neighbors. Like with the Egyptian pyramid that you saw. Always a pyramid over a product of hydros that you see. So this is what happens in the sparse paving case. In the paving case, this polytope is well this uh matroid is known as penhandle matroid. Headhandle matrix. So this is the lattice path matrix, which is also nice and easier to understand than general case. They are all lattice path matroids, but I mean it's getting a little just easier. That's why some of the results hope, I mean, we could prove for spast paving, some of them for paving, and of course all the wood, but really are we lucky things that got nice, we could prove that for all speeds. Okay, with that. Okay, with that, maybe we can save the rest of the questions for coffee time, which is just