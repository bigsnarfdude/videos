Okay, maybe we can start. And the next talk is from Professor Zapozets Dumpty, if I pronounce it right. And I think the title or something is the show is on the screen. And also, okay, now please. Now, please, yeah, thank you, Cha Chu, for the introduction, and also, I would like to thank the organizers for organizing this workshop and also for inviting me to give a talk here. And yes, as I said in my abstract, it is based on our joint work with Gilles Bonnet, Anna Gusakov, and Christophe Telle. And okay, let me start. Actually, the result will be about it. Will be about it results will be in Rd for any dimension, but for simplicity, let me start with the plane. So let me start with R2, some kind of motivation. And very famous, very famous Sylvester question asks follows. Imagine that we have. Imagine that we have some convex figure. I assume that it has non-empty interior and consider convex k in the plane. And let us assume that we choose independently and uniformly in this figure four points: x1, x2, x. X2, X3, and X4, the IID and distributed uniformly over our figure K. One, two, three, four. And Sylvester asks, what is the probability that the convex hull okay? Let me just conf of X one, X two. One, X two, X three, X four is a triangle. Triangle. What is this probability? Of course, it's not, it's a little bit incorrect, this question, because of course, this probability depends on the shape of our figure. And so, Blaskevsky, in In ninety sevent seventy answered these questions in the following sense. He considered he proved, okay, let us denote this probability by alpha probability, and he proves that this probability probability lies between the following numbers. It is greater than 35 over 12 pi square, not less than alpha, and it is not greater than one third, one third. And also this both bounds are optimal. It means that It means that alpha equals the lower bound if and only if our figure is sorry, is ellipse. Of course, this probability is invariant and affine transformation. So if it is true for one ellipse, it true for all ellipses, of course. All ellipses, of course, so it doesn't matter which ellipse. So if it is ellipse and the upper bounds bound holds if and only if our thing is a triangle, again, any triangle, because it is a fine invariant, this probability. Okay, and Okay, and let me do the following elementary observation. If you would like to somehow calculate this probability alpha, so when this event happens, it happens if you have one of four cases. First one is that X4 lies. Four is lies inside the convex hull of x1, x2, x3. It means okay, probability that x4 lies inside convex hull of x1, x2, x3. And also, we have to consider other three cases when x3 lies inside the convex half of others, and so on. Of others and so on, and of course, because they are identically distributed, all these probabilities are the same. So, it's just we have just have to multiply the first probability by four. So, we have this equation. And also, to calculate this probability, let us first condition to the points x1, x2, x3. So let us. To x3, so let us first assume that they are fixed. And if points x1, x2, x3 are fixed points, non-random, then of course, this probability just by geometric probability, it is just the relation, ratio of the area of convex hull of x1, x2, x3. So area of convex hull x1. X1, X2, X3 divided by the area of the whole figure, area of K. That is when the points are fixed, but since they are not fixed by the formula of probability, we have to take expectation and also, of course, factor four. Okay, so we have this. We have this relation, and so if we apply this relation to the result of Blaske, then we will obtain that the result of Blaski is equivalent to the following. We just replace alpha by this probability, no, sorry, by this ratio. So we have to get. Ratio, so we have to divide by four, and so the result of Blasky is equivalent to 35 because divided by 4 is at most the expected area of the convex hull of three points. Now we have only three points. Area of K. So it's okay, and at most now we have to divide one third by four, so one twelve. And actually, we have the following very natural result. If we consider three points inside a convex figure, uniformly and identically distributed inside it. Identically distributed inside it. Consider the expected area of the economic hull, and if you normalize by the area of the whole figure K, then we obtain optimal bounds for this ratio. Again, the lower bound is for ellipse and the upper bound is for triangle, even only if the case a triangle. And later. Again, it is, of course, due to Blashka's result. And later, it was generalized for any dimension, the lower bound, the lower bound for any D and now it is known as Blaschke Gromer inequality. And any dimension D. And of course, in lower bound, it is just this ratio for the ball for any ellipsoid. And concerning the upper bound, actually, surprisingly, for d greater than two, it is still an open question and Open question. And of course, it is conjectured that the upper bounds holds for simplices. And but nobody can prove it for starting from dimension three. And it is so-called famous simplex conjecture. And actually, it is very Actually, it is a very important conjecture, particularly in now famous asymptotic geometric analysis. And particularly, this conjecture would imply so-called hyperplane conjecture. But okay, I don't have time to go into details. And okay, and now let me let me formulate the question which The question which we are interested in. The question is the following: What happens if we replace area by perimeter? So, we would like to consider the following quantity: expected perimeter of convex hull. Half of three points x1, x2, x3 divided by the now perimeter, of course, perimeter of the figure k. And we would like to find the bounds, the optimal bounds for this ratio. And of course, very simple observation: if that expected perimeter, expected period. Expected perimeter of our convex hull x1, x2, x3. It is a triangle, and so it is the sum of three lenses. So it is expected length of the first edge, x1 minus x2. And two others have, of course, have the same distribution. Of course, we have the same distribution, so we have just to put three here. So, actually, our problem turns to the following one. We would like to let me introduce the notation. Delta of k it is just the expected, this expected number of x1 minus x2. So, since we have this. uh since we have since we have this option since we have this uh very simple relation now we deal not with three points but we deal only with two points and so we introduce the notation for the quantity of our interest delta of k it is just the average distance between two points chosen uniformly and independent Chosen uniformly and independently inside our figure K. And so now we would like to find the optimal bounds for this delta K divided by perimeter K. That is our goal in dimension two and in higher dimensions. But before formulating the main result, let me start. The main result, let me start with some historical remarks. By the way, is the connection is good? Everybody hears me? Yes. Okay, great. Fine, it's fine, it's fine. Okay, thanks. Just check. Maybe I'm off the internet. Okay, historical remarks. Okay, historical remarks. Concerning first, concerning this delta of k. Actually, it is a very popular quantity, delta of k. And maybe first who considered it, it was Crofton. It was Crofton in 8085. He considered K to be a regular triangle and he calculated, and actually. And actually, there are few examples when this delta of figures or of bodies in any dimension, when delta of k is calculated explicitly. And most of these examples are in the plane. And in higher dimension, actually, very few examples when it is calculated, and I will talk about it a little bit. So, Crovton. So Crofton Crofton calculated it for the regular triangle regular triangle and he showed that it is A where A side side of the triangle one over five plus Plus three over twenty log three later, much later. I'm not sure that it is actually the first who did it, but we didn't manage to find earlier reference. So let it be Fairhorn who considered actually in my Actually, in my opinion, easier case. He considered a unit disk, not unit disk, just disk, and he proved that delta for this disk is radius of this disk and 128 over 35 pi and later, oh, actually, no. Later, oh, actually, not later, sorry, but before this, uh, Gauss in 1951 Gauss considered a square and proved that for square it is the following a a again the eight. Colon a, a again is the h of square over 15 and square root of 2 plus 2 plus log 5, log 5, 1 plus square root of 2. It is outside of log. Okay, and maybe enough formulas, just let me say that later in 1985, Shen Shen found explicit formulas for arbitrary triangle, ellipse, ellipse, and parallelogram. Let me know that contrary to the to the first to the first First problem with three points. This problem with two points is not a fine invariant because neither perimeter nor this quantity, nor this quantity, they are not a fine invariant, of course. So the answers different for different ellipses, for different triangles, and so on. Okay. Okay, and relatively recently in 2012, Aharonian Aharonian a mathematician from year one, he found an explicit formula for the irregular hexagon. Regular hexagon and in 2014 Basil considered a regular n-gon for any n and he found explicit formula for the distribution function actually distribution for function Distribution function of the distance between x1 and x2. So, not average, but distribution function. But the formula was very complicated. And as a corollary, he managed to obtain the formula for data of K only when K is a triangle, a regular triangle. And in our first preprint, And in our first preprint, we cited this work and mentioned that as a corollary from this general formula was only for the triangle. And actually, very recently in 2021, he put another paper to archive where he Where he derived explicit formula for delta of n-gon. And actually, not even for average distance, but actually he derived the formulas for all moments, for all moments of this quantity, for all moments of this quantity. And actually, he also found that he also found that in this result of a In this result of Haronian for regular hexagon, actually, it was a mistake. So, and he from his general formulas for all and gons, it followed that it was a mistake in the paper of Haronia. Okay, it is concerning the two-dimensional case. And for, as I said, for higher dimensions, very few results. Mentions very few results, and let me just mention them for first one if okay, arbitrary n d first one is when k is d-dimensional unit cube and in And in 1979, when these three Robbins found an exact formula for this quantity, delta of null zero one three and actually it is it looks very similar, it looks very similar to this one. Similar to this one, but more complicated. Again, it contains square roots, logs, and also it contains pi and nothing more. So it's elementary expression. And what is interesting that for higher dimension, this quantity, first of all, it is called, it has its own name, it is called box integral. called box integral integral and for d greater than three no formula no elementary formula of course you can express it as d dimensional integral but no more for this box integral and this uh this guy is called uh robin's constant it's famous well enough this constant it is called Famous enough, this constant. It is called Robin's constant. And another example is when, okay, it was in 19 actually 71, very famous work of Miles. And he can see that K to be a unit ball, and he proved that it is just some not, okay, let me. Just some not okay, let me show it to you to d plus two gamma square of d plus one over two and divided by d plus one double factorial d plus one pi okay and let me say a couple of words about the what is known about that is what actually literally known Literally known about the exact values of delta of k and what is known about the bounds for delta of k actually very little in 1918 blaske proved for d equals one he obtained the lower bound for in our case we normalize it by the perimeter of k and he normalized it by the square And he normalized it by the square root of area of k. And he proved that it is at most, or at least 128 over 35 pi to the power 3 over 2. And again, it is optimal, optimal and holds when k is disk. Is disk. And okay, and I have a question for you. What do you think about the upper bound? The upper bound actually is infinity because we have, if you take very narrow, very narrow rectangle. Reno rectangle, this one is epsilon, this one is one, then the area goes to zero, and delta of k actually is bounded from below. So it goes when epsilon goes to zero, this quantity goes to infinity. Okay, and later in 1989, 89 This result was the lower bound was generalized by Fithir for any dimension. And again, low bounds achieves on both. Okay, and another bound, another bound it is obtained by Was obtained by relatively recently by Burg Stahler and Felix Heimer. They normalize delta of k by the diameter of k and they obtain some again. And they obtain some again some constant in dimension D C D, but this constant is not optimal because in particular if you take K is unit ball then okay okay let me miss it, but uh C D is is not optimal. But C D is not optimal. Okay, and this is literally all what is known about delta K: some bounds and some exact values. And let me now formulate our main result. Theorem. The following relation holds. If we consider again our delta of k, let me again. Delta of k, let me again write what it is: the mean distance between two random points inside k and normalize it by the perimeter of k. Then we have the following bounds: the lower bound is 7 over 16, and the upper bound is 1 over 6, which is actually 10. Actually, 10 over 16. So the lower bound and upper bounds, surprisingly, are not far from each other. And also they are optimal. We prove that these bounds are optimal. Because if we consider in the left, if we consider the following figure, we consider the triangle with two equal edges. Equal edges. And this guy is epsilon. And this edge is one. Then when epsilon goes to infinity, oh sorry, to zero, then this ratio, this ratio for this triangle goes to the lower bound. So asymptotically, this lower bound is achievable. And concerning the upper bound. And concerning the upper bound, the maximizer is asymptotic maximizer in the following family. Here we have to consider the rectangle. This H is one and this H is epsilon. And it goes for this one. And okay, in the beginning, I said that we consider the figures with non-empty interior, but if we consider just convex. Consider just convex compacts, then this bound would achieve at the unit segment, not unit, but any segment. So inside of class of compact, of compact sets, we have actually this inequality, non-strict inequality. But this inequality, the lower bound is not achievable. Is not achievable even in the class of convex compacts without assumption about non-empty interior. Actually, it is achievable on so-called measure on the unit, a non-uniform measure of the unit segment. Okay, and okay, I still have six minutes. Since I said this. Since I said these two bounds are not far from here, it means that the perimeter of k actually is a good approximator of this quantity. In some sense, we have that this quantity is just 17 over 120 multiplied by perimeter of k and the error is plus minus 17 percent. So it's good enough. So perimeter with this coefficient is. Coefficient is a good enough approximator for this quantity, actually. That is what our theorem shows. Okay, and concerning any dimension D, any dimension D, actually in the plane, the perimeter due to the Cashy formula, the perimeter is equivalent up to some factor to the mean width, mean width. The mean width, mean width. Mean width, it's you take direction, project your figure on this direction, and you obtain a width with respect to this direction. And then you take average over all directions. So it is mean width, which in the plane proportional to the perimeter. So in the multi-dimensional case, we have to divide not by the perimeter because this quantity. Because this quantity have degree one, and perimeter in the d-dimensional case have degree d minus one. So we have to normalize by mean width, but it's more comfortable to normalize by the first intrinsic volume of k. If you do not know what it is, just consider it like mean width with some factor. And for this case, we obtain that here we have the same boundary. The same bound actually one over third because first intrinsic volume is just one half of the perimeter. But the lower bound, it depends on the dimension. Now, 3d plus 1, 3d plus 1, 2d plus 1, 2d plus 1. And again, this all are optimal. Optimal and actually, it is surprisingly because for as I said for the problem with these three points, these three points, actually the upper bounds is unknown in higher dimension. It is still a conjecture. But for two points, actually, it's not a conjecture, and we prove that it is the same, like in the plane. And the last thing which I would like to which I would like to mention, it is corrosive. Which I would like to mention, it is corollary from our result because we have that the diameter diameter of K is at most the first intrinsic volume of K. Okay, who does not know what it is? Just believing that it's very easy. Then we have that from our result that if we normalize this x1 minus x2. This x1 minus x2, not by the first intrinsic volume, by the diameter of k. Then we have the same lower bound d plus 1 to d plus 1. And also, it is bound as optimal because on the extremizer for the extremizer, for this bound diameter and the Diameter and the first intrinsic volumes actually are the same. So it means that this bound is optimal also. So we have the optimal bound when we normalize by the diameter. That is exactly which Gustaler and Felix Meicher do. But concerning the upper bound, concerning the upper bound, as I said, the bound is not optimal, but we believe it is our conjecture, Mai and Gusakova. Gusakovan. We believe that the optimal bound is for when k is ball, when k is ball. So it is delta of unit ball divided by the diameter of the unit ball, which is two. So it is optimal and it is a conjecture. Which we didn't manage to prove, even in the plane, actually. Okay, I think I have to stop here. Thank you very much for your attention. Thank you. Any questions? I have a question, so I'll prefer to talk. Can you? Can you place the perimeter by relative perimeter? But then you will get an affine. Relative perimeter, you mean a fine perimeter? Yeah, so every phase of the pandemic file, you consider it in its linear span, in its define span, and then it sits inside some node space. Some node space at the unit voltage of the space with your convex body, and then it defines some measure, say through the Busman or Paul-Thomson definition. Sorry, you're talking about the case when our body is not of full dimension or wood? No, so you want to study the perimeter. The perimeter, let's talk about the point. You want to study the perimeter of the convex hull of some points, right? Yes, yes. So, you did it using the Euclidean metric. If you consider not Euclidean metric, yes, instead you can consider the method defined by your quantum spot. The metric Generated by our convex body, but in actually, what is what Montek? I don't understand. If you have a convex body inside Euclidean space, what is the metric inside this body? Ah, maybe if our body is in the sphere, say yes, or some remaining. Your body is the unit body. Uh, the unit ball of your normal face. Ah, okay, okay, I see. Yes, but actually, actually, I think our methods which we used will not work in this setup, so maybe it's a complicated question. Okay, thank you. Okay. Okay, thanks. Any question? Comment? How about change the diameter or mean width to the volume? How about what? Sorry? Volume. Volume if you normalize by the volume. Yeah. Yeah, but as I said, okay, if you have. Okay, if you have this setup with three points on the plane, or if we have D plus one point in R D, then the lower bound, it is Glasgow Grammar equality, it achieves four ellipsoids, and the upper bound is simply conjecture. It is when we normalize by the volume in dimension ID. So it's area. Okay. No, no, it's area for in the plane, and when in any dimension, it's. And in any dimension, it's of course volume. Yes, we have d plus one point, d plus one point, the convex hull is simplex, and we normalize by the volume, yes. How many other we? I mean, this is vy is the mean width, and how are others? Yeah, and actually nothing is known about other vy, only for v1. And we have a conjecture if you take k plus one point and normalize by vk. and normalized by Vk, then actually we have we have similar similar normalizers and in this case in this case it would be just it would be just segment and we take we take some disk and take convex hull. Oh, I see. And in the And in the from the right, from the right, it would be again a segment, a segment, and we know the idea how to prove it, but it would follow again from the simplex conjecture, actually. Oh, I see. Okay, thank you. Thank you for the question. I just a little curious. Why is the up boundaries? Why is the up boundary nothing to do with a dimension T? That is because when we project our body to some V1, it is the integral. As I said, it's mean-with. When we project to some direction, to some direction, actually, we take an optimal bound, an optimal bound. Optimal bound and optimal bound, it turns out that for our maximizer for the segment, it's not maximizer in average. Actually, it is maximizer for every direction. And our segment is maximizer for every direction. And then we integrate this one-dimensional estimate over all direction. And so the estimator is the same like for one-dimensional. That is the answer. That is the answer. Okay, just uh you know all right all right okay uh any other question or comment okay uh then let's uh thank speak and thank you for interesting talk