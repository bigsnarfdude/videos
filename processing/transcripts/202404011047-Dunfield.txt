Thank you, Joe, for a very kind introduction and the invitation to be here. I think I was, my first workshop at Manff was either the first or second year. It was 20 years ago. I've been back many times and really love this place. My slides are posted here if you want to follow along on your own device. I know these people go live kind of fast. So, everything I'm going to tell you today, joint work with Julio Tiozzo. And since I know this is a broad audience, please just interrupt me with questions. So today's topic is very concrete. So I'm going to be interested in three strand grades. So as a group, it's generated by two elements, sigma one and sigma two, with some relation. All that's important is that a word in these sigma ones and sigma twos describes a way to braid three strands of string. So the way it works is you read this from left to right picture. So a sigma one means you take the bottom two strands here and you braid the top one. And you braid the top one over the bottom one. And then the next thing is a sigma two, so you braid the top thing over the bottom thing. And then if you take negative powers like this, that means you braid them but the other way. So these two things, this is my sigma 1 to the minus 2, I'm braiding the bottom over the top. And so we just have a simple word like this. You can imagine generating this by picking these four things you can do. SQL 1, SQL 2, and their inverses at random, and then get some law. At random, and then get some long. So, this conference is about knots. So, let's go ahead and give it a braid, W like this. We can talk about its braid closure. So, this is the original braid. I'm just taking all the strands at the left and bringing them around to the right to get, in this case, a knot. And one of the most basic invariants of a knot is its Alexander polynomial. So, this is just a polynomial. So, this is just a polynomial in a single variable. Defined up to multiplication by a power of t and maybe a sign. This particular knot, for example, has this Alexander polynomial. So the Alexander polynomial encodes something about the action of the group of covering transformations on the infinite cycle of cover. For now, let's just think about it as a polynomial associated to this not, and it doesn't depend on how we draw the non-eri device for other questions. Other questions? Okay, so about 10 years ago, Denois observed that if you look at positive braids, so positive braids means that I only use sigma 1 and sigma 2. I don't use their inverses. So this is not a positive braid. If I wanted to make this a positive braid, I would need to change these three crossings. So he noticed that if you take a positive break, That if you take a positive braid and look at the braid closure and you look at the roots of the Alexander polynomial, you get a highly structured picture. So, this is a braid of length about 750, which is generated by switching between sigma 1 and sigma 2 at random, a point. And so then you plot the degree, sorry, you plot the roots of that Alexander polynomial. So it's a polynomial of degree roughly 700 and 760, and you get this picture. So, I mean, one thing you notice, there's a huge number of roots here on that, those are exactly on the unit circle. There are then, now it's entered polynomial symmetric. So, if you interchange T with T inverse, you get the same thing. That means the roots always have a symmetry in inversion in the unit circle. So, like these roots here, they correspond to these roots here. So, what you see is you see a whole bunch of things on. So, what you see is you see a whole bunch of things on the unit circle up to about minus a half up to the third roots of unity. You see a whole bunch along kind of path. You see a few on the unit circle, a few sporadic ones off it. And this picture is very typical for if you look at a positive, positive braid. And I should say, positive braids are very natural to look at. They fight over the circle. They show up a lot in sort of, you know, like contact or symplectic stories about braids. Stories about brains, and so it's a natural class, although for us, it's just a bunch of brains. Only twist, always twist in the same direction. So, this picture is sort of just to make sure I'm not just making this up. Here is a, this is the picture from before. Here's a random grade where I just randomly chose each of our generators. And the polynomial has basically the same. And the polynomial has basically the same degree, 750-ish. And you see here, you know, there are some roots on the unit circle. So I didn't mention, but in this picture, about 69.3% of the roots are on the unit circle. Here, only about 10% are. And there's tons of them off the unit circle, right? You have a bunch of ones on the positive real line out here, away from the unit circle. It just looks like this kind of, well, it has this kind of bendy structure. That's kind of interesting. I'm not sure what's going on with that. That's kind of interesting, not sure what's going on with that. But in any event, it does not look like this. So, okay, so we're doing experiments. So, let's look at many braids. So, we took 2,500 positive braids. The mean number of the length of the word, the mean number of twists, was 500, chosen, so the standard deviation is about 170. And these words are chosen. And these words are chosen, these braids are chosen just by randomly switching between sigma 1 and sigma 2 by flipping coins. And so you take these 2,500 positive grades and you plot all of their roots. And you get this picture. And so what does the color represent? So the color represents darker colors correspond to shorter words. So maybe let me see. Let me zoom in. Yes, you are. So, darker colors correspond to shorter polynomials. So, like there's, okay, this is okay. So, you see this red, these are all part of the roots of one of the polynomials. It's probably about the median length. The yellow corresponds to the logger words. You sort of see the yellow is kind of concentrating in the middle. So, And then this is all yellow just because yellow ones are plotted last. So you see, again, this huge number of roots on the unit circle, a few roots on this part of the unit circle, and for each knot you see like one band kind of goes like that. And as you do longer words, the sort of where that band occurs seems to be getting kind of converging in some sense. Yes? Are those like equations? Are there like equations for those very? Yeah, so well, yes. There are these curves, they do lie on some kind of thing which is determined by an equation. This, though, is just plotted by, you write down the Alexander polynomial, you plot the roots. But there is some kind of structure here. Other questions? How does this compare if you just take a certain If you just take surface bundles of the circle or monochrome use. Right, so these are fibered. The fiber genus is very, very large. So this won't look like, does not look like that. So these all, their ciphered surface is surface in a vibration over the circle, and the genus of the ciphered surface is the length of the line. Sorry, the vibration. Divider. Yes. Oh, so these were computed with something called the Boreal representation, but any method would do. The Alexander polynomial is polynomial time and the complexity of the diagram. So this is not, but in this case, these are 2,500 cross-sects. That's not a problem. I see, so it's end. Is there a simpler way to so because these are closed braids, you can use the Borau representation? I'll show that in just a minute. Yeah, no, no. Good question. This would still be in the range that you could do just by some good methods. Okay, so again, experimental mathematics, right? This works back title. So we can go ahead and now we have this data. Now we have this data. There's clearly something going on with the unit circle, right? So let's look at the distribution of roots on the unit circle. Again, about 69, a little more of the roots are on the unit circle. And so let's just plot the density of those in terms of the angle. So starting here at angle 0 and then going all the way to angle pi. And so if you do that, here's your histogram again to do these things. Get to do these things. So it's basically uniform constant until you get to here, the third root of unity, and then it drops off, and then it decays. And it's a pretty pretty marked pattern. Okay. Okay, so now we have a bunch of data, and I'd like to propose some conjectures based on this data, and then we will prove a subset of them. And maybe you can help prove the others. So here's the way I want to think about trying to understand this is basically a limiting picture of the distribution of the roots. And so the way I'm going to think about this is: given one of these breaks, then let's look at the probability measure, which is, well, just on the plane, which is supported at the roots. So in other words, you're just taking the delta mass of each root and then weighting that by one over the degree. You're just taking the mass supported on the roots, just as your finitely supported measure. Finally supported manager. And then let's think about a random walk in these generators, sigma 1 and sigma 2, right? I'm just choosing them at random, and they're equally liquid. So, you know, in fancy language, I'm thinking about this infinite product space as a natural measure, and I'm choosing a point in that. And having chosen a point in this, we get a sequence of random blocks. We'll get A, sorry, we get A random block, where Wn is the product. Where wn is the product of the first n things in our sequence of flips. And so then our conjecture by zoomed in bar. There's a little zoom bar. There's a zoom bar. Here, maybe I'll just do this. Okay. Okay, great. So this is the setting. So we're doing this random off where we just generate the n plus first letter by picking sigma 1 or sigma 2 equally. So the conjecture is that there is a limiting measure. There is a limiting measure, infinity, which is compactly supported. This is a picture of the support of this measure, such that for almost every sequence, almost every random lock thing here, we would have that these measures, in other words, the points, the roots of these units, the roots of the Alexander polynomial, they converge, their distribution converges to this measure. By any open set, the proportion of the roots of the Alexander polynomial. The proportion of the roots of the Alexander polynomials in that open set is this given by the measure infinity of that open set. And we conjecture, moreover, that the support of this measure looks like this. So it's a unit circle plus a pair of continuous arcs that connect the third roots of unity to each other. We conjecture that two-thirds of the mass of the measure is on Measure is on this blue circle. I'll call that AR. And there are just a multiple of a little bag measure, perfectly uniform. There is some, the mass here is positive. We conjecture it's exactly this number. And then it's not, it's like absolutely continuous with the spectral bag measure, but it's not like uniform. And then, yeah, you have something going on here, maybe a little more mysterious, but. Maybe a little more mysterious, but still some kind of multiple, absolutely continuous package. Joseph? What happens if you don't get uniform measure? So Joseph's question is, what happens if we don't do the uniform measure? So, I mean, so I think the fact that the limit exists should definitely still be true. Definitely still be true. Having not thought about it, I'm not sure if we expect the limiting picture to change. Yeah, so when I get to the section, like the last slide, you'll see some things that definitely are insensitive to the choice of initial questions? So you're in the picture, it looked like the two gray arcs, arc and the gray hero have thickness. No, that's because that was like as you, I was plotting 25. Like as you, I was plotting 2,500 different knots. So each knot was contributing one arc. And we've conjectured that in the limit, there's only one. And that it crosses, you know, like the point where it crosses the real axis is about minus 0.78 or something like this. Yeah, yeah, so that's part of the conjecture. So as you look at the data, as the words get longer, they sort of, where those arcs cross the real axis, they're going to. Cross the real axis, they're getting sort of closer together. That's what this is our conjecture. We don't prove this, though. I mean, that might not be the case, but yeah, that's definitely something we're asserting. The arcs are converging from the inside of the blob to the gray, is that right? No, so well, so like, you know, to go back, this is a typical picture, right? So, so this is the unit circle. For each one of these, we get. Circle. For each one of these, we get. Oh, I was wondering, can you go back to the color picture? Yeah. So, where does the limit lie in terms of the colored picture? Is it like right outside? No, no, it'll be in the middle. Okay, so there are things that are on both sides. Yes. Yes, exactly. Exactly. So I probably can't see if in fact, it's kind of hard to see up close, but like the outliers here are sort of, their colors indicate they were relatively short. They were relatively short. And so, as the things get you, I kind of see like this more sort of yellow in the middle, that's indicative of. So, our conjectured gray line runs through the middle of this. Hi, you have a question? Yeah, so also in the picture, we could see points in constant interval of each other, which is maybe a bit stronger. Yes, no, so that's the yeah, so they're sort of close to equally spaced, and that sort of equidistribution. Spaced and that sort of equidistribution property is also part of our conjecture. Absolutely. And it's especially like here, we actually believe it should just be a multiple. It should, you know, you scale the arc length on this so it has mass two thirds. So it's very rigid. We could actually go to kind of zero in the middle. I mean, if you go back to this picture, right? This picture, right? So, this should be an approximation to what Î¼ infinity looks like on the unit circle. So, it's just multiple of the bay, and then it does something. Other questions? Was there any significance to the three? So, these pictures originally were on two-strand braids, correct? Three-strand braids, yes, yes. On three strand, that's right. Oh, so I should have said, yeah, so what Devin Watt observed is that actually, so you. Observed is that actually, so for larger n, you get a similar picture. You don't just have a single strand here, actually, a single arc of roots here. You have n minus two of them. And where they hit the unit circle moves kind of back towards this as n increases. So there's definitely a similar picture, probably similar conjectures. We focused on the three-strand case because. On the three-strand case, because, well, we couldn't even prove it in that case. But yes, there's definitely a similar story. Other questions? You could grandma pause almost just coming from anywhere with some restrictions on coefficients. So, can you simulate some of the types of measurements? So, that is something that people have looked at quite. That is something that people have looked at quite a bit. And the various sometimes you look at, say, polynomials with 0, 1 coefficients, and they look nothing like this. I don't have a slide on it, but this is like Thurston's bot kind of thing. So I mean, it's, yeah, they're very, there are lots of cool things, but this is very non-generic. Extremely non-generic. Do you expect the green arcs to also be parts of circles? So that's a good question. So that's a good question. I don't think we, I mean, so didn't think about that. I'm not sure we have good enough data to sort of see. So I think we generally don't have any conjecture about what these is. They could well be circles. But we have no reason to think that. We just, yeah. There's some continuous arc, by the way. Other questions? Other questions? Yes? Kind of a strange question. How do you know this is? Why are you? I mean, the Jones polynomial and the Alexander polynomial, the three grains are very cross-free. You can say what you want. Is this a property? How do you see this? Is this if I wanted to look at this kind of behavior for higher indices, should I look at the jobs or the alexander? Oh, so I don't actually know. That'd be a reasonable. Yeah, I mean, like, yeah, yeah, right. You make this kind of pipe for all sorts of polynomials, and I actually have no idea which. Okay, so let's get a little bit into why, or some of the features we were able to prove about roots. And these go back to the Borough representation. So I believe Borau actually introduced. So, I believe Brow actually introduced this in order to understand Alexander Kalinoma's positive, closures of positive braids. So, we're just in a three-strand case. So, this is a representation from the three-strand braid group, the two-by-two matrices with sort of Laurent polynomial entries. And it's just sigma one goes to this two by two matrix, and sigma two goes to this two by two matrix. And so if we have a big word in sigma one and sigma two, we just get a two by two matrix whose entries are polynomials. Entries are polynomials. And the key property is that the Alexander polynomial can be computed from that 2x2 matrix by this formula. So you subtract the identity matrix, you take the determinant, and there's a little, it's not quite the Alexander polynomial, you have to divide by 2. No worries. So that's how, to answer Chase's question, that's how we compute the Alexander problem. The Alexander polynomial. Just multiply these matrices. Now you've got matrices, the polynomials might have entries like 25 degree 2500, and then you take the determinant, the 2x2 matrix. That's actually. Okay, so one thing we do have is kind of an explanation for why these roots tend to lie on these curves. So let's look at the closed unit disk. And I'm going to find this function, which depends on the element. Which depends on the element. So I picked a w as a particular grade. So this is a function, pick real values, it's the spectral radius of the matrix. So if I pick a particular point in the disk, I have some particular matrix. And I just look at the eigenvalues, they're two eigenvalues of that matrix. And I look at the larger of them, an absolute value. And I define that to be this. So for example, So, for example, if I'm on the, anywhere on this disk and my w is just sigma 1, then the spectral radius would always be 1. Because this eigenvalue here has absolute value at most 1, and this one has 1. These would have, omega would just be the constant function of the plot. Not so interesting. But anyway, so this is a nice function describing these. Describing these matrices. And the key observation is that this function is one at any root of the Alexander polynomial. And the reason is, if the Alexander polynomial is 0, that means that this determinant is 0. And that means, I teach my linear algebra students, that 1 is an eigenvalue for this matrix. So that's So that's certainly consistent with this, right? But I'm also saying then here that the other eigenvalue must be smaller than 1, the absolute value. And that's just because the determinant, right? The determinant of this matrix is minus t, and so is this one. So if you look at the determinant of this, it's just going to be some power of t, in particular, it's less than or equal to 1. So if one of the eigenvalues is 1, their product is less than or equal to 1, the spectral radius is 0. Yeah, that's literally the only thing I've been approved is talks. Okay, so let's now look at some plots of this. Okay, so here is some relatively simple, I think it is like 10 or something, brave. So these big dots, these are the roots of the Alexander polynomial. And then this curve here, this is this set. Here, this is this set of places where the spectral radius is one. So, as per the observation, they have to, the roots have to lie on this curve. And so, you might wonder what's going on in here. If you zoom in, you see this picture. Zoomed in. So, here now, here's the locus where the spectral radius is one. Here is one of the roots. One of the roots, and then it's like a contour plot. So it turns out what happens here is that the function does this is where it's one, it decreases as you go this way, and it increases as you go this way. Maybe to connect back to some other things, I mean, it turns out the value of the spectral radius at minus one, this is going to be the stretch factor of the pseudonozo monochrome that the break induces. So the spectral radius is going to be very large here in general. So what is it that we can actually prove about this process or this limiting measure? So the first two theorems are just about any positive brains. There's no randomness here. So as long as we just exclude taking powers of just sigma 1 or sigma 2, these have Alexander. Sigma 1 or sigma 2, these have Alexander polynomial 0, so it's just a special case you want to exclude. Then what we prove is that the set where the spectral radius is 1 contains the arc that goes from the third root of unity back around here. So it always contains that, and again, this is the set which contains all of the roots. So at least you see a lot of roots there, and that set always contains it. A lot of roots there, and that set always contains it. We also show that Rw is disjoint from this particular set T. And in particular, that means there are never any roots in here. So that's also very compatible with our picture. And in fact, I mean, you actually never see any roots past the imaginary axis that are inside the circle. We're unable to prove that. So, anyway, the roots, they missed this thing. The roots, they miss this thing. And then there's a potential for a lot of them here. And, you know, one of the features of the limit, which you also saw in this picture, is there should be something that kind of crosses from one side to the other. This is the thing that's going to limit those gray lines. And so we prove that this set Rw meets the real axis in a single point, and that point actually. In a single point, and that point actually has to be somewhere over here. So that also is kind of compatible with this picture. And we also proved the volume. So for any positive braid, at least two-thirds, fletch factor, of the roots occur on this arc. Oh, this arc is AR. So there's this half of the. So there's this half of the half, two-thirds of the unit circle here, and the conjecture was we're supposed to get Lebesgue measure there with sort of mass two-thirds, and we can show that at least two-thirds of the roots are there. There might be more. That's why we haven't proved that part of the conjecture, but there definitely are a ton of roots there. And then the other two things that we managed to prove are about this random walk process. Process. So we can look at the other arc, AL. So this is the arc that goes from the third root here. And here we show that for almost every random walk, asymptotically the portion of the roots, they're on this other portion of the unit circle. It's like two-thirds of them on AL, sorry, on AR. On AL, there's at least this portion, 2.4%. 2.4% of the roots of the half-line. And so these are kind of our, these three things, I'll get to this in a second. These three things are kind of our main parts of the conjecture that we confirm. Yes, sorry, question. You say that the proportion is at least that. Yes. How close is. Oh, then this is then, and our conjecture is it's exactly that. Yeah, so both of these things, what we're showing. What we're showing is that there are at least this many roots as we expect, and the conjecture is there are no more. Just have to prove the upper bound. Just have to prove the upper bound. The conjecture is a zyptotic. Sorry? The theorem is absolute and the conjecture is a zip dotic, yeah? Yes. No, I mean, for this too, there also seems to be, this really should be equal up to, I mean, up to plus or minus one, and I know what the plus or minus one is. Yeah. Other questions? Other other questions. Okay, let me say a little bit just about where some of this connects with people with backgrounds in knot theory. So there's a very important function associated to a knot called the signature function. So this is a function, it's a function on the unit circle, it's integer-valued. So in particular, it's some kind of step function. And it only has discontinuities at roots of the Alexander Point. Discontinuities at roots of the Alexander polynomials. And so, in particular, if you understand the signature function, it can give you lower bounds on the number of roots on the unit circle. This goes back to an old observation. And so, work of Gambordo and Gies from 2005-ish, I think, tells you a lot about this. A lot about this signature function for a positive grade. So, in particular, they tell you the signature function is basically linear up to the third root of unity. Of course, it's a step function, so you have to be a little careful what I mean by basically linear. But anyway, that's what they show. It's basically linear. And so that gives you this statement, more or less immediately. And in fact, it tells you more. It's not just that this many of the roots. It's not just that this many of the roots occur on this arc. If I take any sub-interval here, the number of roots in this sub-interval is at least as many as roots. To get it compatible with the uniform limit that we propose. So the signature function then tells you a lot. And in fact, our conjecture implies, oh no, I mean, our conjecture doesn't imply this, but it seems to be true that for a positive. To be true, that for a positive grade, at least the three-strand one, then on this first portion of the unit circle, the signature function only ever jumps in one direction. So in general, if you take the two points on the unit circle and you look at the difference of the signature functions, that bounds the number of loops inside. On that portion, it seems to be exact. And that seems to be like something maybe if I understood positive grades, topology, or something, that one could try to, and maybe that's just not. That one could try to, and maybe that's just something one could prove. Positive brains, they have this property. And so, okay, so great. So, we have this signature function, and we understand it up to here, and that gives you this. Then, what you want to understand is, well, what's the value of the signature function at this point? So we think that there are more roots in here. We know the value of the signature function here. We'd like to know it's bigger here. It's bigger here. And the value there, that's the signature of minus one, the classical MERS E signature. It's a number very closely related to the topology of naught. And what we show is actually that this signature obeys a central limit theorem with respect to this random walk. And it's not just, so again, this, I think this goes back to Campo and Keys. This goes back to Camp Order-Hau-Guise. If you think about this as a function of your word, this is actually a quasi-morphism. And there's work of Jorklund and Harlem that says that sort of do a random walk, if you apply a quasi-morphism to a random walk, it has to obey a central limit there. And the tricky bit is that, well, we actually characterize what the drift is. Characterize what the drift is of this thing. It's exactly this number, and that's what eventually translates into the thing. Questions? So we also have kind of a conjecture, well, we do have a conjecture for what the limiting measure is. So let me talk a little bit about the Lyop and off next moment. About the Lyop and Optics moment. So, okay, so what's the deal here? So, I look at words in the Bray group of length n, let's say. And I just look at a word of length n. There's lots of these things, positive words. And for each one, I compute their Barrel representations. So that's some matrix. And then I take a, you know, I'm fixing T as a plus. Take a, you know, I'm fixing t as a point in the complex plane, it's fixed. So we evaluate the Borough representation on this work at T, so that's a matrix. And we take some norm of that matrix, like let's say the L2 operator norm, or the size of the biggest entry, doesn't matter. And so what will typically happen is as we do longer and longer words, those matrices are going to become more and more complicated. Or if someone has one thing that could happen, they could also become sort of simpler. Are simpler. And so if you take this norm, maybe it grows exponentially. So you take the log. So this is just that, this is an integral, but this is just the average of this quantity over all words of length. And then we're normalizing it, like we're looking for an exponential growth rate, and we define this function. So this is a exponent. This is a Well-studied kind of thing in dynamical systems. It is continuous and subharmonic in this setting, so it's a nice function. So I plotted the function. That's what this is. And so, you know, for example, well, this function has a pole at zero because the matrices at zero, they're singular. And on the unit circle, And on the unit circle, it's one up to this point, and then it's bigger than one. And then these other curves I've drawn, these are the locus where, let's just focus on the one inside the disk. This is where the Lyapunov exponent is one. But this looks like the curve that we think is the limit. And there's kind of a general, the motivation for this comes from the work. The motivation for this comes from the work of Teran and Tujardin studying kind of the opponent of exponents of families of representations like this. Their results are into SL2. These are not determinate one matrices, so slightly different things that curve. So anyway, you have to look at this function. I'm sure this is making no sense, but we talk about x opponent, the logs of value and zero. So this is a function which is actually zero and equal. So, this is a function which is actually zero in here, and then it's sort of interesting. Anyway, the conjecture is that this is some nice, probably continuous function, and you take the Laplacian of this, just this derivative, and in a sense, it distributions, and then you get what's called the bifurcation measure. So they were motivated here in the work of DeMarco and Variable. One variable complex dynamics denote this, define this bifurcation measure. So, anyway, this is something that you get, and the conjecture is that that's the limiting measure. And yeah, so this is like a numerical approximation of the Avmunov exponent. But we have some partial results. I think they're too technical to state in this context about. In this context, about places where this does converge, but we don't really characterize the limit. So the approach to these conjectures, but not really. Not a get component. Our questions. Okay. So let me end with. End with some open questions. Well, okay, prove the conjecture. Someone also asked about n-strand braids, and the answer is there should be a similar, there are similar pictures. No one has done the kind of more detailed experiments like we have in the n-strand case, but it would be straightforward to do that. And I would suspect you would get very similar pictures. We could also ask about non-positive praise. What are the roots of non-positive praise look like? Phrase look like. So, this is actually the same picture I was showing you before, except with a change of coordinates, right? So, that Alexander polynomial is symmetric and t goes to T inverse. So, maybe you should really look at T plus T inverse and plot those points. And then that's you get this. So, the unit circle has collapsed in the interval from minus 2 to 2. And then that arc, instead of being doubled, is now this. So, that's your positive break. This. So that's your positive brains. So now do that same picture, but for arbitrary brains. Again, three strands. You get this. I got no idea what this means. I mean, there seems to be some kind of maybe interesting fractal leaping going on. Hard to know. Don't have a huge amount of data here. We didn't, yeah. A plan, of course, was to do positive braids and then understand this, but you see, we didn't do positive braids. And how did you try? And have you tried quasi-positive? Yeah, so like the positive is, as you say, is like one of a many family of quasi-positive. And we haven't done experiments with that. The original work of Demero was looking at, I think there's like Lorenz knots, which I believe are kind of quasi-positive knots. Don't quote me on that. So, no, I have not looked at that. And yeah, quasi-positive is very. At that, and yeah, quasi-positive is very, you know, lots of these theories, that's really the natural kind of thing you want to look at. Great question. So, for you are again thinking about the Alexander polynomial. Is there a, maybe you said this, is there a reason why the Alexander? Oh no, the reason why was that uh Denois observed this weird half. Uh I'm I'm just uh wondering because as I said it was restricts. For three strands, the Alexander polynomial and the George polynomial are like T plus T inverse plus the Alexander polynomial. So I wonder, actually, I'm continuously wondering about this. Yes, well, it's a great opportunity for someone to do some experiments. You won what's called More Strings Expression. Yeah, yeah. Exactly. Other questions? Oh, well, those sorts of random matrices, I don't know. This is what the relevant random matrix is. I mean, people have studied these kind of families of representations on like a complex variety and their sort of dynamics. This is the theory we were trying to. But you were thinking about like random orthogonal matrices. So, I mean, I should have said, well, I probably should have said many things, but So, on this unit circle, the Boreal representation, right? So, it's a representation of 2 by 2 matrices once you plug in the value for t. It's actually unitary. It's actually in U2 here. So you're in a compact group. Here, you're not in a compact group anymore. It turns out you're in U11, which is roughly the SL2R or something like that. And one of the strangest, from the dynamics point of view, maybe the most remarkable thing we've observed here. Observed here is that so here, when you're doing your random walk in these matrices, you know, you're basically in the hyperbolic setting. So, you know, one should not be an eigenvalue very often. The eigenvalues should grow rapidly and so on. But yet we still see roots here. And we prove that there are roots. So somehow that convergence to no roots, or no eigenvalues of one, like it oscillates somehow here in a way that's very, I don't, I don't understand. I don't understand. Yeah, and I think from the dynamics point of view, that's the most interesting phenomenon. Because you have here, you have these developed random walks, but you're still seeing eigenvalues of one as the parameter varies. That's kind of weird. Plus, I mean discrete indiscreet mass. Do you know anything about the Do you know anything about the factorization of the Alexander polymer work? Yeah, so generally speaking, these are irreducible or close to. So there aren't, say. There are sometimes small singletomic factors, but not enough to sort of... They don't contribute to the left-hand side? No, they don't. Not to any... Like, you know, so you're getting a polynomial that might have degree 500 or 1,000. And maybe there's some cyclotomic factors of size 10. Sorry, I had a Sorry, I had a second question. Very bad. Did you explore how any height measure of a polynomial might correspond to some of your other gadgets? No, we did not. That's a good idea. So, here we've mostly been talking about random words. If you start to put more structure into those words in some fashion, I go. In some fashion, I don't quite know what I mean by that. Computer disappears at some point. You start to see examples that are sort of maximally distant from this limit. I mean, so certainly if you're careful, for example, you can make the Alexander polynomial just be the nth cyclotomic polynomial and you get them uniformly distributed by that. But it's always there some correlation. Yeah, though, it's how structured. Yes, I mean, because the gray group, there's this. You know, the breaker, there's this, you can solve the word problem using kind of the Gar side theory. But of course, this breaker is basically SL2Z. So we use those kind of structures in some of our theorems. And yes, they sort of give you parameters. So the last thing I wanted to say, not that, I don't know how to push the right button, is the talk I almost gave. You can ask me about this at coffee or something. So as Ben mentioned, there are three. Or something. So, as Ben mentioned, there are 352 million knots. Joint work with Sheridan, we've proved that 1.6 million of them are slice, 350.4 million of them are not slice, and we're down in the gritty 13,000 of them unknown, which is a very small percentage of 352. In our defense, this property being sliced is not known to be algorithmically computed. I'll stop there. I'll stop there. Thank you for your attention. Okay, so next up is the two o'clock.