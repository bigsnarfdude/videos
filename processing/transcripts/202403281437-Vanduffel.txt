Thanks a lot for having me. It was always a dream with me to come at least once in my academic life to Balf. I almost made it, but then COVID popped up. And so thanks again for the organizers for having me. It's wonderful. So I talk about robots of distortion risk mesh. This is a paper joint with Carol and Silvana. Actually, the paper kicked off five years ago when Silvana was visiting us. So we make progress, Carol, because the paper that you presented kicked off ten years ago. Presented kick off 10 years ago. So this is good. So I'm from Frei University Brussels, a small university. English translation is Free University of Brussels. So there are three, just to give a little story, three famous export products, I think of UB, which are Freddy Dobar and Joe Bourguer and Ingrid Bobishi. Ingrid Dobishy, the lady from the Wavelets, Fredi Dobar, financial mathematics and insurance mathematics, with a famous coherent paper. And Jean Bourguer has done incredible things. He has done incredible things in non-linear partial differential equations, function analysis, ergodic theory, member theory, and all that. He also got the Fields Medal. Jean-Bourguin was the first PhD student of Fredi. Unfortunately, he passed away. So the intersection between me and these amazing people is very, very small. So one piece in the intersection is Freie University Brussels. That's one thing. I could think. It's one thing. I could think about one other thing. Actually, my last name, Van Duffel, means from Duffel in English. Duffel is a small town in Belgium. It turns out that Frede Delbahn was born in Duffel. So that's one piece. Ingrid Toby, it turns out that she spent the first 12 years of her life in the same village I was where I spent twenty years of my life. So that's also an intersection. And Jean Bouguerre does a little bit more sad, he passed away in a hospital nearby. In the hospital near Burfin. So, yeah. So, okay, robust distortion dismisses. So, let me try now to introduce the problem. Some of you have already seen the first couple of slides, but sorry for that, but for the others, maybe it's full. On the right side. So, this problem was already highlighted by Richard. Highlighted by Richard yesterday. So, this is a classic problem in the area of model risk assessment. So, we could be interested in figuring out what's the worst case value at risk for a portfolio sum in case in which the components have known partial distributions. So, this problem has been studied for over four decades. For example, in the case n equal to, there are explicit results in the paper of Makarov and in the pandemic by Peter Russendorov. You can also see You can also solve this when n is very big, so there are symptomatic results available, and so on and so forth. There's also an algorithm that allows you to approximate the supremum quite the so-called rearrangement algorithm, so very powerful. So the message here I want to give is that, of course, this supremum is big, typically a very big number, right? In particular, the supremum is bigger than the sum of the value faces, right? Because the connotonic dependence is included. Commodonic dependence is included, of course. And so, on the commodicity, here that the value at risk of the sum of the sum of the valued risks, and so the supreme is bigger than that number. So, for practitioners, yeah, this is not really useful. So, we should include dependence information. And so, some of these problems have been discussed by Lucia, so I'll not repeat that. I will just focus on this third problem. So, where we include dependence information by saying that we may have information coming from observed data. Information coming from observed data, which gives us an estimate about the variance of the portfolio sum. And we add that on top of the marginal distribution information. And so this should, of course, lead to Sharp about. And the contribution in this paper is mainly, I think, that we've figured out an algorithm that could help us, or that helps us to approximate the supreme, quite powerful algorithm based on the original rearrangement algorithm of the Czech motion. So, the point I want to make here is that, of course, the bonds get better, but the practical examples. So, if you apply this algorithm, you try to estimate this thing, right, which still denotes the upper bound of the value at risk, but now also including this variance information, that this thing on the left-hand side is close to this quantity on the right-hand side. And this quantity on the right-hand side is the maximum possible value at risk, given that you would only use. At risk, given that you would only use the portfolio sum as the novice portfolio sum, its mean value is variance. So, this thing, of course, is strictly bigger than this thing, but it turns out that in practical examples, it is often the same. So, this is not the mathematical truth that you can prove, basically. The thing is that if you can create a dependence among the variables such that your sum behaves as a quantum function, so that quantum function of the sum is concentrated on two values, right? Greater than two values, right? Then basically you have strict equality. This can happen, of course. In practice, this is what you can often achieve. There's always a way to think of dependence that's close to this extreme dependence that way. So what this is learns us, well, this learns us that this problem is, of course, very simple as such, right? You can prove this in two, three lines if you want. But it has these problems where you can also include. Has these problems where you also include marginal information, so where you include the distributional information on each of the components, that makes it much harder. So that gives rise then to the following kind of problem, where we want to focus on the sum directly, using maybe some moment information and maybe using some other information. And we are not going to focus only on the value at risk, but we are going to focus on more general risk measures. To focus on more general risk measures, and these are the so-called distortion risk models. So, what are the distortion risk measures? So, this is the noted with this thing. So, if the g me is the identity function, then you of course you observe immediately that you just have the mean of the distribution f. So, g is really distorting the survival function, and hence we call it a distorted expectation. And under some smoothness assumption, we can also write the distorted expectation as a weighted average of one, where gamma. Of one path, where gamma is the weighting function. And gamma will play an important role in what for us. Now, this is a very broad class of risk measures. I think Kutik also mentioned this. So it includes, for example, the value at risk in general, the rate value at risk, gala value at risk. It also includes the so-called concave distortion risk measures. So these are the distortion risk measures that have the nice properties, they are coherence in particular. So in that case, if And in that case, if G is concave, then the gamma will be increasing. That will also be important, not false. So, what is now one of the basic problems we considered in that paper? So, we want to maximize distortion risk measure, given that we have the first and the second moments, so we know the mean and the variance, and we know that the distribution must lift the Waskerstein ball around the reference distribution LC. So that's the very basic problem. So let's try to solve that. Let's first get rid of this Wasserstein distance constraint just to give you the intuition of how this works. So we first ignore the Wasserstein distance constraint, so we only use the first and second moment information. There are some technical assumptions, but nothing really important. So of course, this is a structure this measure. So, of course, this is a structure risk measure. You can just, you know, it's completely obvious, this is just an inner product, right? And so, this then gives rise to the following simple result. So, let's say that G is concave. I will tell in a minute why that's important. If you want to maximize this inner product, given that G has a given mean and a given variance, gamma is of course fixed, then of course g minus 1 must be linear than the gamma. Positively linear than the gamma with A. Positively linear than the gamma with the A and the B such that the mean and the variance constraint are satisfied. How can you see this? Well, this follows immediately from the Cauchy-Schwansli point. That's one way to see it. Another way to see that that's also related to the talk of Carol, we can also interpret this thing as the expected value of a product of two combatotonic random variables. The first one has quantum function gamma. Note that she is concave, hence gamma is increasing hence the real quantum function. And the other quantum function is to be determined, but we know the mean of the variance. Be determined, but we don't demand the variables. So, when is this thing going to be maximum? Maximizing this expectation of a product of two random variables is like maximizing the correlation between these two variables. Because the mean and the values are given. That was also a point that Carol made. So, and the correlation can only be one, that's the maximum value, so we make the second variable such that its quantum function is linear linear. So, nothing very complicated, I would say. Complicated, I would say. So now we add the Wassenstein distance constraint, because that was the basic problem we considered. So we want to control the Wassenstein distance constraint, because the G doesn't live well with radius epsilon. So controlling the squared Wassenstein distance constraint is controlling this inner product, because the other things are fixed. Again, so how do you do that then? If you want to maximize this under this constraint, well, it basically means. Well, it basically means that for all lambda, the solution must come, must satisfy, also, must also be a solution of this problem. We just lift the side constraint, plus the standard constraint, in the objective, if you want. So, very straightforward. And we already know how to solve this problem, right? Because we have seen that just before. We know that for each lambda, if you want to solve this problem, the g minus one, so quantum for x mod g, must be linear in this thing. Before we had only gamma, now we have gamma plus lambda times quantum. Now we have gamma plus former times the quantum fraction of f0. So the solution to our problem that we started with must be of this form. So that's completely obvious now. With the A and the B, they depend of course on lambda and they must be such that the mean and the variance constraint are satisfied. Alright, so. Alright, so we know that the solution must be of that form, and just the only question is then: how do we figure out what is the correct lambda? Because for now we have solved for all lambdas, but of course we need to figure out the best lambda. So let's first say that lambda is zero. Let's just say what would happen if lambda is zero. First, try to go back to this. If lambda is zero, then of course we have g0 minus. Then, of course, we have g0 minus one, but that was the solution to the unconstrained problem. With unconstrained, I refer to the case in which we only had the mean and the variance fixed, and not the Wassenstein distance constraint. Of course, if the unconstrained solution happens to be in the Wassenstein ball, then it's also the solution to our constraint problem. So, and that means that if the unconstrained solution is in the Wassestein ball, then we know the solution. In this case where lambda is zero, of course, if the unconstrained solution is not in the wall, Constraint solution is not in the ball, then we need to increase lambda. Because by increasing lambda, we put more weight on F0, so we go closer to the center of the ball, and at the same time, we decrease the distorted expectation. Because the extra constraint will make the maximum lower. So we increase lambda and lambda lambda goes until we hit the boundary of the losses time, and then we stop. There's no point in going further, because the distorted expectation will just decrease. Started expectation will just decrease. That's, I think, is not so difficult. So, just one point here: that the case without the wasterstein, this constraint was also proved. Well, I find it amazing that it was only proved in 2018, or at least as far as I know, in the paper in operations research. I prove it quite complicated. There is more that is done in that paper, but proof is. That is done in that paper, but improve effects could be made more simpler, as I think I've just shown. Okay, so that was one big thing. Well, one big thing, that was one thing in the paper. Now we want to consider the general case where G is not concave. Because when G is not concave, the gamma is not increasing, right? You still have this Kaushi-Schwarz inequality, but it's not a legitimate quantile function that you obtain. So you need to do something. And what you need to do is. And what you need to do is basically. What is the motivation for now you can eight genes? For example, range-valued risk, the distortion function, that's a non-concave distortion estimator. And it's quite popular these days. As you do now, it's estimation of the tail value which is complicated. You know what range value trips because it just frog up? Okay. So the solution must be, it's easy to show, the solution must again be of the following form, just like before, but now we project. Just like before, but now we project the function, which in the case in which g was concave and hence gamma increasing. We did not have to do anything more, but now we have to make this thing increasing. So we project this function on the set of square increval increasing functions. And that's still the solution. So we can work this out um in general. Uh we have the maximizing content function and we also know the bounds. And we also know the boundary. So now a few remarks. We can extend this result for the case in which we only assume that the distribution must be in the Wassenstein ball around the reference distribution, and we do not fix its mean and its variance, which I think makes a lot of sense as a problem. So that, of course, can be done because if you fix the mean and the variance, well, if you fix Because if you fix the mean and the variance, well if you fix, no, sorry for that. If you fix the Wasserstein goal, that of course imposes constraints on the admissible means and variance. So you just have to optimize. First you optimize, you have to optimize for every given mean and variance, and then you just have to optimize in the second step across the set of all admissible means and variances. And that's what we did. So we get the results in the paper. For the case of range value at risk, that's indeed an example of a non-point case G. We have explicit results. G, you have explicit results. That's quite useful because when G is not concave, you have to project. And basically, when you want to work out the optimal solution, you have to do it for every lambda. So this is quite time-consuming, I would say, because computing is a projection in general, it's not analytical. But for the range values, we could do it. We have worked out how to project it. And since we could also do it for range value at risk, the value at risk, we could guess from the solution of the range value risk what the solution should be in the case of value at risk. Because then we go outside the setting, right? Because the G is then no longer absolutely continuous, so we cannot write it as a weighted average of quants, basically. But you could guess the solution for this case by taking limits, and then we prove it that way. How long do we have? Ten minutes? I will skip this. Lucien mentioned yesterday that we have written a book together. Yeah, that was something else that could now be removed from my bucket list. The way to writing the book was very pleasant at some occasions, but also the usual trouble. But I still remember, Richard and Carroll, that we had this wonderful Greek parallel on the Greek island, where we took the opportunity to figure out a few problems. You know, to figure out a few problems and so on, and to settle the final details of the book. An application of the previous results. We are interested in finding a portfolio, optimal portfolio static setting. So it's buy and hold. So you have n assets. You know their joint return of the asset returns. The joint distribution is not known. You only know the mean vector and the covariance matrix. And the covariance matrix, which is maybe already heroic in some sense, but you can say that this is no. I want to find the maximal, the best portfolio. So for each portfolio we denote by gx, it's unknown. Distribution, well, distribution function we denote by gx. We don't know what gx is, but at least we know that it has a certain mean and a certain variance, right? The loss function. And we know also for each portfolio there is a kind of For each portfolio, there is a kind of idea of how the distribution of the portfolio loss should look like, and that's the benchmark distribution fx. And we assume that this distribution function fx is in a location scale family. So, for example, fx, it's a normal distribution. We have a given mean and a given sigma, which come from the mean vectors and the covariance matrix of the asset returns. The problem we solve, we try to solve is the problem. The problem we solve, we try to solve is the following. We want to figure out the portfolio that performs best under the worst case scenario. I have a very naive question. So for the returns, how is it that you know the mean and the variance, but you don't know the higher moments of the distribution? Well, estimating higher order moments is of course more complicated statistically than lower moments. Than a lot of points. That's basically. So often you may have an idea about mean invariance. I'm not saying that this is always, yeah, you know. Yeah, it's an assumption, but it's maybe not completely idiotic. Correlations are easier to estimate in general than corporates, right? So we want to look for the portfolio that performs best under the worst case scenario. What do we mean by that? Well, we know that the joint distribution of the asset. We know that the joint distribution of the asset returns lives in this moment space. So we have the mean vector given and the covariance matrix given. And we assume, or we know, that the loss distribution must be in the neighborhood, the Lossenstein wall around the reference distribution FX. With radio epsilon X, the epsilon X is also input. Maybe we can estimate from data, but as such, it is just input. So the epsilon X depend on the portfolio rate X, maybe in the Depend on the portfolio weights X, maybe in a very complicated way. I don't know. It's just given. So, how to solve this? Well, the first step we can reduce this to this problem using the projection property of Kopescu, which was already mentioned in another talk. And then you have still a min-max problem, but now the GR is gone, and you just have to optimize over the set of distribution factor GX in this space. And this thing we have already dealt with. We have already dealt with. That's exactly the problem we have dealt with before. So, this we can work out for each vector x, right? And then we just need to minimize over the maximum value for each x. So, this gives rise to the following theorem. Problem two, so the equivalent problem is equivalent then to minimization of this thing, because this is just the upper bound of this distortion distribution over this information for every x. This has this. For every x. This has this form. So note that we have now epsilon x underscore. Epsilon x underscore depends on epsilon x. It depends also on this thing. This thing is basically the Wasserstein distance of the unconstrained solution for every x. And that could, of course, be binding, right? So if that's in the ball, then you have the epsilon x basically becomes this p. So it also depends on the v. V is driven. V. V is driven by the distortion function, because of the rating function, and the distortion function plays also a role in this coefficient C0. Alright, so now what is the good news? This depends on mean and on sigma variance, right? So that looks already quadratic. But the epsilon x are of course the problem, right? Because these can depend on the x jacked up in a complicated way. So we are going to make an assumption. And there are some reasons to believe that epsilon x Epsilon x, because the distance between two distributions is driven by their variances a lot. So there are reasons to believe that epsilon x could be of this form, right? Where there's a parameter A, which maybe could be estimated from historical data on the asset returns. We talk a little bit about that in the paper. And yeah, and A will be between 0 and 1, because it also upper bounds on the possible distance between gx and fx, actually. Gx and Fx actually. So if A is equal to zero, then of course there's no ambiguity, right? So there is no Wasserstein role that plays a role. And then of course we just do basically nothing new. That is just the classic no-concerted problem where we try to work out the problem that minimizes basically the mean variance problem, right? That we solve and that is bucket. By contrast, if A, so that's one extreme case, by contrast, if A is very big, is very big. Very big means that A is bigger than 1 minus E0. So basically means that the unconstrained solution can never be acceptable for every X. That's basically what this means. Then we have the problem that was also considered in Li. From the paper of Li. Go back to this. He did this problem, exactly this problem, but then without this constraint. Then we are in that case. And then the third case was. And then the third case is, of course, we are in between. So we can interpolate by varying A. We can interpolate between the two extreme cases, and it is in a smooth way. So note that if A is zero, you put less weight on the sigma. If A is very big, then you put more weight on the sigma, right? Because here you have C0, which is smaller than one, here you have just one, and here you have something between C0 and which. We have five minutes or five minutes. Okay, can still make it, I think. So I considered the same setting as Carol in the talk. So we considered the set of path-independent payoffs. There is a pricing measure, what could be applied from the availability of causal good options, as Carol explained. Options, as Carol explained. And we know then that the price of any payoff in this set is given by this thing. So we can express it as an expectation of psi times x, where x, where psi, is the Habernig derivative. So it's one over the likelihood that Carol was using in her talk. So now, one basic problem that was already discussed by Carol. Deepwick showed that the solution to the problem where we want to minimize the cost of a payoff. The cost of a payoff given that the fixed distribution of the payoff is obtained by the payoff which is anti-monotonic weak psi. That was Carol explained, so I will not repeat the argument, because this is of course a uniform, it's anti-monotonic with Peak Psi, and it has the right quantum functions or the right distribution functions. Now, what is maybe of interest is that the cost itself of a cost-efficient payoff can be represented if you just, you know. Presented, if you just plug it in, basically, you get this kind of form. And this looks like a distortion history. This just really looks like a distortion history, where the gamma is this function. It's increasing, it's not positive, but it's not really a big problem. At least we have this weighting function. Now we consider this problem. We want to minimize the cost, given that we do not fix the distribution of the payoff, which we just want it to be in this set. We fix the mean and the variance. Right? You fix the mean and the variance, and there is a loss of significance if radius, the radius is epsilon. So to solve that, well, it's obvious that the solution must be cost-efficient, so the payoff must be decreasing in xi, and hence we only have to consider this kind of problems, but that we have already done before, actually. So, really, the solutions to the problems we considered before can also be used here. Now, I have to say that this actually is not in the original debate with Carol and Original in the paper with Carol and Silvana, but well in subsequent work with Silvana. Last part was also inspired a lot by Silvana, who got her inspiration, I think, from Caleb and Lennett. Kayden, I have to say, right? So now we are going basically just to replace the Wassenstein distance constraint by the Wassenstein-Brechman divergence. Time Breckman divergence. So that's the main idea. So Breckman divergence, so we're going to plug the Breckman divergence as a cost function in the Mons-Patolkovich optimal transport column, the associated cost of transport. We call it the Breckman-Wasserstein divergence. It is trivial to see that optimal coupling, or almost trivial to see the optimal coupling is the homo-atomic coupling, and hence the Breckman-Wasserstein divergence in the one-dimensional case has this. One-dimensional case has this kind of nice formula. But phi is, of course, the squared function, then you cover the squared Boss stein distance. Okay, so let's now deal with balls that are not driven by the Woss-Stein distance, but by the Directman Wosserstein divergence. So we're going to consider this problem. We maximize the distortion estimator, given that the distribution function must be in a ball. The center of zero, I would say, and distance is now becoming Bregman-Losselstein divergence. Here we have one, I think we find this very cute result. So we restick to a distortion function that is concave. Then the optimal quantum function, to the optimization problem we consider, so maximization of distortion response, given that the distribution needs to be in a ball described by Rossenstein Breckman. By Wassenstein-Bregman, or Bregman-Wassenstein divergence is of this form. And the solution is unique. So, maybe just to conclude, to give a clue about why this is still not too difficult to show. This is basically, so if a solution must have some divergence epsilon zero, right? So the solution to the problem equals, so this is the objective, must it also be a solution. So, this is the objective, must also be a solution for each lambda of this thing. And this thing is basically the Brechma-Musselstein divergence, but we got rid of the arguments that do not depend on the decision variable lambda function of G. So, we focus on these things, like vector and optimization. So, that basically means that for all Lambda, we need to solve this problem, right? But this thing in the random is just convex in the context. Just convex in the contour function g, and so hence, by direct optimization, you have that for each lambda solution must be of this form, and then there's a little argument to show how you can obtain the right lambda. And the right lambda is such that we are at the boundary again of the ball. We have some reference, and I thank you very much for your presence. Okay, quick question. We want to move to In the non-concave case, in the result where you said yeah one needs a projection on the ink. Does one see this directly from the projection? Yes. Yeah. The fact that uh that the the solution for each bundle is of the form that I gave, so that we're just each project, follows immediately from the from the definition of the of the outcome projection. Of the outcome projection. I must say that it was Silicon who found that the ice crop. It's almost immediate. But it goes back to the talk. Is this related somehow to taking the compact summary or the integral of that? Okay, that's uh six with two thirty. So Charlotte Chow something else where