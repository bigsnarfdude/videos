So let's get started. So I'm very happy to be here. So very thanks a lot to the organizers for the invitation. So I work in a French company called Biomarieux who develops in vitro diagnostic systems for clinical microbiology mostly and today I will present And today, I will present you some work we've been doing with my colleague Magali, who is on the phone as well, aiming to improve the interpretability of Kmer-based prediction models of antibiotic resistance. Okay, so really our main motivation is to predict the antibiotic resistance profile of bacteria from the genome. And for this purpose, we build upon our previous work in this area, which considered a kind of a Which considered a kind of a related setting of genome-wide association studies based on debris graphs. And most precisely, we relied on a software called DBGOS that Magali developed during her PhD together with another PhD student called Leontro, which is described in this paper shown on the right-hand side. So in short, DBGWAS takes as input a panel of assembled genomes and associated phenotypic data and proceeds in three steps. In three steps. In the first step, we build a compacted Dublin graph to represent the overall genomic variability of the assembled panels. So to make things short, each node of this graph will correspond to a k-mer, as John just mentioned in his previous talk. These k-mers can have a variable length. And from this graph, we build a variant matrix or feature matrix X here to X here to encode the presence of or absence of each unitig in the various assemblies. Okay, so we have the strength in rows, we have the unitigs in columns of the various k-mers, and we set zeros and ones to say which k-mer is observed in which genome. From this variant matrix, then Edbisuas applies standard genome-wide association. Wide association methods based on the linear mixed models that I won't describe here to really test each of these units for association with the phenotypes. And finally, the significant heats can be visualized within their overall genomic environment thanks to the use of this overall Dublin graph built in the first place. And as extensively described by Magali in this paper, this post-processing really helps to have a better understanding of the nature of A better understanding of the nature of the phenotypic associated genetic events, where, for example, a SNP will typically translate as a kind of a branching pattern in the graph, okay, with susceptible strain taking one path and the resistant strains another, while the acquisition of a gene will typically translate as along a chain of nodes, which are all associated with the phenotype of instrument. So, to address the issue from the predictive perspective, we basically simply traded this association model for Traded this association model for a supervised classification model. At this, we are really interested in building some models that we can interpret. We focus on sparsity promoting machine learning algorithms to achieve some kind of a feature selection within this matrix X. And this quite naturally led us to work within the framework of Las Openized logistic regression. So there are several advantages, at least we see several advantages in working. In working within this framework of last-openalization. The first one being, of course, that it remains a linear model, a generalized linear model, meaning that in the end we have a prediction rule which is defined as a linear function with weight associated to the various features that we can interpret in terms of predictive power. The second very interesting point is that we have some very efficient implementations that scale quite nicely to the relatively Quite nicely to the relatively large data set that we end up working with in this context. They can involve several thousand strains and hundreds of thousands, or even maybe a couple of million features. But on the other hand, the LASSO is subject to a well-known limitation, namely that it is unstable. I mean, the solution it provides is relatively unstable when features are strongly correlated to each other, which is obviously the case with CAM. Is the case with Kamber base representation? And this instability manifests itself in the so-called regularization path of the LASSO. So for those of you who have already experienced with this LASSO penalty, this figure will look familiar. For those who haven't, well, this figure basically represents the evolution of the coefficient of the models as we vary the penalty, the regularization penalty. So each of these curves here. So each of this curves here corresponds to one feature, so one unitic in our case, and represents its evolution when we decrease the penalty, hence allow more and more features to enter the model. And what is really striking in this example, which is an actual example involving cambridge and bacterial genome, is this kind of irregular or maybe erratic behavior that you observe in some cases. Like, for example, this curve here, this coefficient starts to steadily increase. And at some point, To steadily increase and at some point starts to decrease suddenly to start increasing again. And when we dig a little bit more in the data, it's fairly easy to understand that this kind of erratic behavior is precisely a consequence of this notion of correlation between features. Because in this graph, I've highlighted two groups of strongly correlated features, I mean, correlation above 0.9 or something. And we see that, so the group of green features and the orange features, of course. Of green features and the orange features, of course. And we see that, for example, when this coefficient here starts suddenly to decrease, it corresponds to the addition in the model of a novel features to which it is strongly correlated, which basically means that at this point, the LASSO decided to share the weight on these two features. And what is interesting to notice is that on this actual real-life example, we observe a situation which has been A situation which has been reproduced by simulation in a very well-known textbook example by Trevor and Steve of Robert Tushino. And our main point here is while this kind of instability will not really necessarily be an issue in terms of prediction, I mean, whatever the LASO has picked one of these green or one of these orange features, it will probably be able to predict correctly the phenotype. This will have a very important impact in terms of Have a very important impact in terms of model interpretability. Because first, it means that somehow this kind of feature selection ability of the LASSO is a bit a bit high. Whenever you are on this path, you won't get the same kind of feature selected. And also, although these green or orange features are strongly correlated, meaning that basically they share the similar level of information with respect to the outcome we want to predict, well, their weights can be. Want to predict? Well, their weights can be very different. The coefficients they have in the model can be very different. And this will not reflect the fact that they are relatively equivalent with respect to the phenotype. So several strategies, of course, I mean, this issue is well known, and several strategies have been proposed over the last decade or so to cope with correlations in such Lassea-based models, like for instance the elastic neck penalty or the group Lasseau penalty. Penalty or the group lasso penalty, but for reasons I won't have time to detail today, but I will be happy to discuss later on. We believe they are either not easily applicable in our context or not fully satisfactory. And this led us to proposing a method that we call the cluster LSO, which proceeds in three steps. So, in the first step, we screen a relevant or informative feature. For this purpose, we start by building We start by building by fitting a standard Lasso penalized model on the original feature matrix to extract all the features which are selected at some point by the Lasseau. So we build a regularization path as before, and we extract all the features for which the coefficient at some point is different than zero. So this defines a set of IFT features, and we extract also all the features from the entire feature matrix which are sufficiently correct. Are sufficiently correlated, let's say, to one to at least one of these active features. Okay, so this defines a pool of active and correlated features that we, in the second step, use to build clusters. Okay, so we build clusters of screen features using very standard procedure. For example, we rely on hierarchical clustering to build a dendogram that we cut at some point. And once we have built those clusters, we saw. And once we have built those clusters, we summarize identified these clusters. We summarize each cluster into a single composite variable that we define as the average value taken by the features of a given cluster in a given string. And since our case, those features correspond to, or they are binary variables indicating the presence of absence of k-mers. So each cluster basically corresponds to. So each cluster basically corresponds to the fraction of k-mers of the clusters which are actually observed in the given strain. And finally, so we build our final model, which is also a LASOP analyzed logistic regression model, but built at the cluster level using this kind of composite variables we have here. Okay, so in the end, we obtain a prediction rule, which is still defined as in our function, so with weight reflecting the predictive power. Reflecting the predictive power of the various components, but where each variable corresponds to a cluster that we hope to be able to interpret better thanks to the help of this Jubilee graph built in the first place. So the method is fairly simple. I won't delve too much more into technical details. I just want quickly to mention that we have three parameters basically to optimize in this approach. So we have two thresholds to control the level of correlation we impose when we screen and when we screen. We impose when we screen and when we cluster features. So, for the moment, we have set them in quite arbitrary fashion. So, we make some preliminary experiments and we observe that they did not seem to have a very strong influence on the predictive performance as long as they were sufficiently high. So, we set them, we fixed them once and for all. And the third parameter. Third parameter is the usual regularization parameter we have in such a less openalized model, which controls the trader between the sparsity of the model, the number of features it would involve, and its predictive performance. And we rely on very standard cross-validation procedure to tune this regularization or a long-term parameter. Okay, so now I will present you some experimental results to try to illustrate the interest of. Illustrates the interest of this approach. So, we mostly based our evaluation on a parallel of Klipsy-Lap pneumonia genomes that we took from a paper from 2018. So, this data set involves something like 1600 genomes, and we focused on 10 drugs. So, this table here summarizes the cross-validation performance we obtain upon model selection. So, I don't want to spend too much time. Spend too much time detailing all of these numbers, but the main important message is that we obtain quite similar performance, predictive performance between the LASSON shown on the left-hand side and the cluster LASSO strategy. And this predictive performance is measured both in terms of the AUC, the error under the rock curve, and the balanced accuracy, which is the average between the sensitivity and specificity of the motor. And this is something which is Something which is totally expected, I mean, because we do not expect this kind of a clustering operation to bring some additional information with respect to the outcome we want to predict. We really expect it to bring some additional information to interpret the feature which are selected. So, this is perfectly natural to have this kind of a comparable performance. We also know that the support of the model is relatively. Of the model is relatively comparable, the support referring to the number of features involved. So, these features correspond to uniting for the LASSO and to clusters option for the cluster LASO. We note maybe a slight tendency of having smaller support with the cluster LASO, which suggests that it indeed leads to merging within a single cluster some features that were selected independently by the LASSO, but it is not systematic. Not systematic. And finally, we also note that with the cluster also, we sometimes identify large clusters of units, which are given by the number shown between brackets on the right side. Okay. Okay, but now we have two strategies that lead to comparable predictive performance. Now I want to discuss a bit about the key differences between the nature of these signatures that we identify. And for this purpose, I have two. And for this purpose, I have two figures. So, this first one provides an illustration for ceftazidema, which is one of the drugs that we have considered. So, this figure here represents the correlation matrix measured on our training data set of all the units involved in the Lasso and Plastor-Lasso models. Okay, so we have on top of the correlation matrix, we have two color bars showing. Color bars shown in blue and in orange, which allow to identify which unitig is involved in which model. Okay, so all unitigs for which we have a blue mark belong to the cluster LASO signature, and all the unitigs for which we have an orange mark belong to the LASO signature. Okay, so we see that most of them belong to the cluster LASO, and some of them also belong to the standard LASSO signature. So we observe we have So, we observe we have strong blocks of correlated features here, which is perfectly expected, and which is a direct consequence of the cluster lasso strategy. But if we take a closer look, for example, to this cluster number seven, shown in pink here, which corresponds to this large block of highly correlated features. So we know that in this case, the LASSO only picked one feature out of this group of strongly correlated features. And of course, we cannot blame it for it, because And of course, we cannot blame it for it because the job of the LASSO is to build sparse models. So, whenever it picks one feature among this group of strongly correlated features, which basically are equivalent with respect to the outcome to predict, well, it will be able to predict properly the outcome. But the important thing to understand is that when we will want in the processing analysis to analyze Analysis to analyze the nature of the genetic features which are captured by the model, well, probably we will have lost a great deal of information working with only one unitig out of this group of strongly correlated units. And this second example aims to illustrate that on the concrete case also of Meropenem. So we focused on Meropenm because it's the simplest model we obtain on this list of drugs, and we have only eight features. Drags and we have only eight features involved in the LASSO model and three features involved in the cluster LASO model. So, for the LASSO, we have the eight coefficients shown on the top here. Each of these features corresponds to a single unitig as expected. And when we try to understand and visualize the sequences of the unitigs within the entire Debrungraft, we note we have three features, features which have color in. With features which have colored in red to purple here, which fall in a similar region, which is labeled as Blake EPC. Okay, and Blakey PC is a well-known gene involved in the resistance of tumoropen. But since the surrounding nodes, which are shown in grey here, are also labeled as Blake PC but are not involved in the model, well, this visualization would suggest that these three very specific positions within the genes. Specific positions within the genes are important for the prediction, hence for the resistance. And therefore, it would suggest that the CAPT corresponds to point mutation like SNP or something like that. With the cluster LASO, the story is a bit different. First, we have only three features, and one is clearly prominent with respect to the two others. And these prominent features is made of 159 unitics. And when we try to visualize the And when we try to visualize them, these clusters, these clusters of 150 kinetics within the Dublin graphs, and we observe a long chain of nodes, which are all labeled as blake APC, and which basically capture the consensus sequence of the gene. Okay, and with this, and we argue that with this cluster LASO model, we are able to obtain a more faithful characterization of the nature of the genetic determinant, because in this case, it clearly highlights. Because in this case, it clearly highlights that it is really the presence of the gene and not these specific parts of the gene which is responsible for the resistance. Okay, so that's about it. I just wanted to add a final slide to discuss briefly the computational costs. So on the left-hand side, we have the time taken to build a regularization pass for the LASSO and cluster LASO. For the lasso and cluster lasso. So, really, a collection of solutions indexed by the regularization parameters that from which we can choose afterwards to control the trader between sparsity and prediction. So, of course, the cluster LASSO is longer than the LASSO because it started by treating the LASO model and then had some post-processing operation. It's actually something like three times longer than the LASO, but yet But yet it remains relatively manageable on the decent computer. And for example, it took something like five hours to achieve the entire model selection strategy, which involves repetition of a tenfold consolidation process. Okay, and this is, I mean, this is relatively feasible. You can run it overnight and get a Run it overnight and get the results in the morning. And this is really for a data set that we found to be quite challenging. I mean, this Clapshield AppliModia dataset involved, as I said before, 1600 strains, but 1.2 million features. And it was much challenging that other data sets involving similar number of strains for Staphylococcus or Mycobacterium, for example. And regarding the memory footprint, so o o we of course we also have a slight overhead with the Plus Toleso, but this is a relatively marginal. But this is relatively marginal. Okay, so to conclude, so it's not rocket science, but we propose a simple and computational efficient procedure to leverage to some extent at least the K-Moss correlation in sparse machine learning models. So all our work was done with logistic regression, but also penalized logistic regression. But while the principle is itself relatively generic and could probably also Also, a transpose to alternative models like the Digiboost or Setcover machine or things like that, which are quite popular in this context. We really think that when it is paired with DBGOS, it really helps to get a better interpretability of the models for genomic application. And I should emphasize that it is especially relevant in the situation when you have a very high number of features, like one, one million. A number of features like one million or something. Because if you have relatively small data sets, and you can turn to standard strategies based on GroupLasso or things like that to carry out your clustering in the first place and then leverage them to start with. Joint practice, as I mentioned, we have three parameters to optimize, which can be seen as a limitation. So the regularization parameter involved in the final model, while quite naturally I think be shown by I think be chunked by cross-validation in any case. But we have in mind several ideas to maybe optimize automatically the two threshold that controls the level of correlation we reinforce within the clusters. I mean, somebody yesterday mentioned bootstrapping or things like that to get stable clusters. This is clearly something that we can imagine to apply in this context as well. So, this method was very recently published in the Giga Science paper. So, you are very welcome to have a look if you are interested and want to get more details. And we also have a public implementation available on GitLab. And this implementation takes the form of a generic R package, which implements this kind of three-step storeless method that you can use to any kind of problem, and not necessarily genomics, not necessarily. Necessarily genomics, not necessarily resistance. And we have some dedicated script to show how to interface it with DBGUAS. And that's it for me. I don't know how I went on time, but I'll be happy to take any questions if time permits. Yeah, so I think what we'll do is try to get back on track with starting the next session. With starting the next session at 20 after. But if people want to stay, we'll take John Lee's question and then Leonid, as the organizer, I might have you discuss with Pierre in the session afterward. So from John Lee's, he asks, did you consider using the Elastic Net with some mixing between lasso and ridge rather than lasso alone to try and get more of the correlated features? Sure, I actually have some backup slides specifically for this. Specifically for this? I might say, yeah, just given the time, a quick answer would be great, and then perhaps for a greater time. Okay, quick answer, yeah. And quick answer, we see three limitations to the elastic net. So the first one is that we did not find a good criterion, an objective criterion to tune this trade-off between LASO. Okay, because if you vary it and you will get the same level of predictive performance. Our second limitation, Our second limitation we saw is that, yes, indeed, the Liastic Net leads to a grouping mechanism, but the groups are not explicitly defined, so you have to reconstruct them afterwards. And the third limitation is that we empirically observed that the asticnet seems to lead to a partial reconstruction of these large clusters of correlated features, and there is still some level of heterogeneity of the weight within the groups. Okay, and so really we can. Okay, and so really I will be very happy to discuss that further, but we have many results and further details in the paper if you want to have a look.