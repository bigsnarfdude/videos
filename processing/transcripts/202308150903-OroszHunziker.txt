From Hansinker, Oliver Oras Hansinker, and she will give a talk about credit traces, modularity, and pseudo-trace. Thank you. Well, thank you so much, everyone, for being here. Thank you to the online participants for being here. Before I start, let me just thank the maybe original two organizers, Mishnah and Anna, for all your work to make this happen. I'm good friends with Anna. I know of the tremendous amount of work. I know of the tremendous amount of work that has been put into making this happen. So we're very grateful and we're very grateful. I'm very grateful to Katrina and Gail for joining the organizing committee and being here also on the drug to make sure that things work smoothly. I'm very grateful to my collaborators. They pushed this and our other project forward. While I was on maternity leave, they were very nice, accommodating when I came back and was able to contribute to the work of the group. Able to contribute to the work of the group, so I'm extremely, extremely grateful for that. It was like a first experience for me, and it was just wonderful to be part of this group. I'm really grateful. And I'm very grateful to Beer's staff member Jacob. He was extremely kind, professional, caring, and helped me make sure that I can be here with my family participating in the conference. I'm really grateful for that. Okay, great, let's get started after all this acknowledgement. So, I'm going to be talking about joint work that's in progress with Katrina. Joint work that's in progress with Katrina, Gail, Kari, and Gail. Sorry, and then I'm going to give an overview of our future work that we'll do with our one for woman or two team. And let's start. Oops. Ah. Not. Almost. Just a second. Sorry. That's my bad. Okay, Carrie. Wait. There we go. There's a wonderful team. Katrina, Caddy, Justine. Katrina, Katie, Justine, myself, Veronica, and Gail. And here's the plan for the talk. So, first, I hope to give you some motivation about why one should see through a talk about vertex algebra. Vertex algebras are the algebraic structures behind our work. I hope to give a few reasons why one should put up with its definition. I'll give an example, the free bossons or the Heisenberg-Vertex algebra, then I'll talk a little bit about modularity and graded dimensions. Finally, I'll describe graded Finally, I'll describe predicate traces and introduce pseudo traces, which are the functions that we have computed and that we're interested in computing even in more cases. And finally, I'll give you an overview of our results and what we hope will be our future work. Great, so let's start with why should one consider this interesting algebraic structures called vertex algebra. Well, they play an important role in string theory. The algebra of symmetries of a conformal field theory is a vertex algebra. If you're interested in a finite simple group, If you're interested in finite simple groups, the monster is the automorphism group of an interesting module called the Munchen module, and that thing has a vertex algebra structure. Also, vertex algebra, these modules for rational vertex algebra of special type that we'll discuss later, are examples of modular tensor categories. And finally, there's very interesting connections between vertex algebra and number theory. So there are connections between vertex algebra as the end, modular forms, and modular forms. And the reason why this is in purple today is because we And the reason why this is in purple today is because we hope to kind of explore a little more of this last stuff. Great, so what is a VOA? I won't give the full details of the definition, don't worry. But maybe we'll try to get a good idea of what it is. So it'll be an integer-graded vector space V, such that the dimension of each graded component is finite. And we have some lower bound limits. So Vn is 0 for n sufficiently small. And it comes together with a linear map that 8. It comes together with a linear map that 8s an element in V and speeds out a power series with coefficients and endomorphisms of V. And you may notice that we have a weird shift here. The reason why we do this in vertex algebra theory is because we like to take residue of c to the n times our power series and get back the coefficient a sub n, the coefficient that we call a sub n. So this is why we use this fear shift, and you'll see it all over our papers. And we ask that this map be not too crazy in the sense that when you evaluate it in another element, Sense that when you evaluate it in another element of the vector space, now this is a power series with coefficients in V, because it was an endomorphism at each coordinate and you evaluate it. But we ask that there will be only finitely many powers of z that are negative. So there's going to be poles, there's going to be complex analysis on the background, but it's not going to be insane. To make sure things converge, we'll ask that there only be, once we evaluate an element, finitely many powers of z that are negative. So for instance, just to be more concrete, this would be an acceptable operation. After, so before you After, so before evaluating this blue element B, it can really be an infinite sum of endomorphisms, but we do ask that after I evaluate it, I end up with only finitely many powers of C that are negative. So it's infinite on the side, but it is truncated. This will make sure that complex analysis-wise, number theory-wise, things make sense. Converge. Okay, great. So there's a bunch of axioms that we're going to ignore, but maybe we'll cover a few. But maybe we'll cover a few that will need to make sense of our results. So we'll ask that there be some sort of unit vector, we call it the vacuum vector. It's at degree zero, so it's in the zero component. And there's another special vector that we call the conformal vector. It's a degree two. You'll see that I say degree, conformal weight. Those are all equivalent terms. I'm sorry if I mix them, but by degree I mean you have degree n if you belong to v sub n, the nth grading component. And we asked that when Component. And we asked that when you grab this conformal vector and you jam it into this machine, that vector and spit out a power series, you end up with a power series that we expanded in an utter different way. But that gives you the following relations. And this is just saying that we have an action of the Virasoro algebra on. Here's Virasoro. I was recently in a conference, and no one knew that Virasoro was Argentinian, so I just wanted. And he passed me, so I thought he was. And he passed me, so I thought it was nice to mention it. Well, anyways, and we will ask also that L0, but not the mode that goes right here next to z to the minus 2, gives you the grading. How? Well, Fv is in Vn, then L0V is NV. So it turns out that the grading is by eigenvalues of L0. Great. Okay, and of course, there's going to be a ton of action. Okay, and of course there's going to be a ton of axioms that we're going to not focus on today. What's some examples of the OAs? Well, we're going to discuss two. The free bottoms are the FAC representation pi or the high-speed vertex algebra. We'll have tons of meanings for this. And VSRO vertex operator algebra M. Great, so let's start with the free bottoms. We're going to start with just a Lie algebra, is an infinite-dimensional Lie algebra H that has generators X and N, one for each integer, and a central element C. And a central element C, such that almost everyone commutes with each other except when n and m are opposite. In that case, we get some non-trivial commutators. So for instance, if you take x1, x1, 2, oh yeah, I'm sorry, and c is central commutator. If you take this, you get 0, because minus 2 is not the opposite of 1. But if you take this bracket, you don't get 0. Instead, you get 2 times 0. NC can be. NC commutes with everyone. Great, and we're going to grab just the maximum. Well, we're going to fix the triangular decomposition, so this is pretty standard if you're trying to induce a representation. We're going to say the positive part of H is this vector space, the zero part of H is this one, and the negative part of H is this one. We're going to grab a maximal Solgebind there, H greater than, and we're going to build a one-dimensional representation. I just called the basis vector for this one-dimensional thing. The basis vector for this one-dimensional thing, one here. And we're going to give it an h greater than module structure by declaring that xn kills this vector for all n greater equal than 0, and that c acts by the identity of this vector. Great, so now we can induce, we define this module pi to the induced module. So now we extend the action of that subaltern that's one-dimensional to the whole space. And remember that we said, we declared xm kills this vector and C. xn kills this vector and cx by 1. So linearly one can see that this is a nice representation of phi and I claim this is actually a basis for pi. So isomorphic as vector spaces is isomorphic to polynomials in these variables. And let's make sure that this is true. It's a Poincar√© of Bit argument. If you are wondering why aren't there any elements of this form, well we can commute x1 and x minus 2. x minus 2, we can take a move here. We can rewrite it in this way, and now we use that x1 kills 1. So this is, we don't need to worry about this elements. And on the other hand, if we have this expression, we can not commute x minus 2 and x2, but we can carefully use the commutative relations to rewrite it in this way. And now we know that x2 equals 1 and c squared 1. So this is really two terms of vacuum. So it's someone that shows up as a linear combination of these people. And finally, the same is true for such an element. thing is true for such an element. This element is really not listed here because we like order to be x minus 2 goes to the left of x minus 1, but that's okay. We can use our computation relations to prove that. Yes, it's just... Should I go back? Or I can write it on the board. So H0 is the scan of X0 and the central level. And the central college. Yeah, yeah, great. Okay, so you can see from this computations we did over here that the x minus i for i greater than 0 really create new elements. We call them the creation operators. They don't kill one, they don't kill any element you act on. But on the other hand, if you look at this one, x2 is behaving here. x2 is behaving here as just taking a derivative with respect to x minus 2 and multiplying by a scale. So maybe let me write the expression so it's a little clearer. But I claim that if i is greater than 0, these are annihilating operators, or annihilation operators, and they behave in this form. You multiply by scalar, and they basically kill whatever variable was there by 1. Any element in pi, In pi, the free bossin, can be written as a linear combination of the people who show up here. And this is maybe the general form of an expression here. Does that make sense? Okay, great. Okay, so we have our vertex algebra, and we can order the indices in this way. And now what's the DOA structure on the free bosons? Well, the vacuum is the C, this vector over here that we start with. We started with a one-dimensional representation. Well, that vector, now it's image and induced. Vector, now it's imaging in this module as the vacuum. The conformal vector can be chosen to be this element, a half times this person that we see at degree 2. We know that it should be someone at degree 2 from the axis. It can be chosen to be this. And the map y is defined in this form. We just define y of this element to be the power series that has all of the high significant generators in here. And then we can extend this map to a vertex algebra map. Send this map to a vertex out of a map in a unique way by using normal order product. And if you've never seen this before, you can ignore it. But normal order product is an artificial mechanism to make sure that things converge in which you put annihilating operators to the right and creation operators to the left. Great, and this is the general formula for y of an element in pi is just the normal order product of a bunch of scale derivatives of this field x that we define as the power series that has all of the Heisenberg generators in there. That has all of the high symbol generated. Okay, cool. Maybe I should mention that there's actually a whole family of conformal vectors in the three pluses. And changing the conformal vector is something that we call conformal flow in vertex algebra theory. And Veronica will tell you, we will be telling you more about conformal flow in the bio vertex algebraic work that we also did with our woman. For today, we could consider this conformal structure for any complex number A, and we would. A. And we would call the free buttons with that conformal structure pi sub A, but for today, we're just going to focus on pi, which is pi squared. Our results hold for any complex number of A, and I'll mention that later. Okay, great. So we said the conformal vector for today at least will be this one. And we know that y does this to such an element. So we can try to find what L0 is. It was the mode that goes right next to z to the minus 2 here, and so on. Right next to z to the minus 2 here, and so on. And using the number order product definition, one can see that this is what Dal zero is. If we translate it into this annihilating creating operator language, it becomes, oh, I reordered them, I'm sorry here, first, re-index things so that it's a little easier to read, and now we translate it, and it looks like this. It looks like a sum of multiplying by L, multiplying by X minus L, and taking derivative with respect to X. And taking the derivative with respect to x minus L plus a half x 0 squared, the stays there, that's all. Okay, so if we try to see what L0 is in an element, for instance, what's L0 of the vacuum, we can actually use this formula. We evaluated in this vacuum element, which was 1. And we know that taking the derivative of 1 is 0. So that will die. And we also know that x0 outspace is 0. So this is 0. 0 upspace 0. So this is 0. The number 0, but I'm writing it as 0 times the dot. That's because also they're equal. But what happens if I do L0 of this element over here? I'm hoping it will give me 3 times that element, right? Because I want my space to be graded by L0 eigenvalues. And let's check that that's the case. Since I'm at degree 3 in my module, that's what I expect. I evaluate. Expect. I evaluate this in x minus 3, and you can see that this expression will not contribute because I can commute x0 and x minus 3 from the Lie algebra relations. And then I also know that x0 kills a battery. So this will die. And here, almost everything will die, except when I take the derivative with respect to x minus 3. That term will survive. So I end up with exactly L equals to 3, which is 3 times x minus 3, the same, which I can simplify to just 3 times x minus 3. Simplified to just three times. So L0 is actually giving us the gradient that we want. And more generally, L0 on an element of this form really gives you the sum of the ji's times the element. Okay, wonderful. So we do have a decomposition into L0 eigenspaces. I'm going to call each variant component pi sub n. And pi sub n is just the span of elements of this form that sum to n. And in particular, let's look at pi 1 and try to figure Let's look at pi 1 and try to figure out what the dimension is. Well, that one's quite easy, it just has dimension 1. Let's look at pi 2, so the elements of degree 2. That one has dimension 2, and I can index the basis elements by 1 plus 1, which corresponds to this element here on the left, x minus 1 squared, and 2 by 3, as I mentioned 3. And I can index its elements by 1 cubed, or 1 plus 1 plus 1. cubed or 1 plus 1 plus 1. x minus 2 x minus 1 corresponds to 2 plus 1. x minus 3 corresponds to just the thing. So we see that the dimension of pi 1 is 1. The dimension of pi 2 is 2. The dimension of pi 3 is 3. One may want to conjecture that the dimension of p n is n, but fortunately we don't have to look much further to see that that's not the case. So if we look at degree 4, we have this out. So we have x minus 1 to the 4. So we have x minus 1 to the 4, x minus 2x minus 1 squared, x minus 2 squared, x minus 3x minus 1, and x minus 4. So my previous conjecture was false. And we get five elements. We get 1 to the fourth, 2 plus 1 plus 1, 2, 2, 3, 1, and 4. However, one can see from the way that we are enumerating the basis elements that the correct formula would be the number of partitions. Formula would be the number of partitions of n. That's what we're getting at each degree. And that's exactly what happens. So, what we have is that the dimension of pi sub n is pn. And now we build the graded dimension of pi by taking a generating function, a shifted generating function. We're now going to focus on this. Q is a q to the minus central charge we're 24. That plays an important role in terms of number theory, but for today we're going to think. Of number theory, but for today we're going to think of the gradient dimension as the generating function of the grade, the dimensions of each gradient component. So we're putting dimension of pi n times q to the m. And this ends up being the sum of basically partitions of n q to the m, which is the inverse of the derivative eta function, which has this pretty cool product extension. And it's a modular function, so it's compatible with the National SL2C. We'll discuss this more. If Q is equal. discuss this more if q is e to the 2 pi i tau with tau in the upper half of course. Great. Maybe I'll say that this, this fact that the greater dimension of a vertex algebra gave us a cool number theory object is not a coincidence. It's been widely studied and it's the reason why we're looking at connections between vertex algebras and graded traces as zero traces. We expect interesting behavior for such Behavior for such generating functions typologies. Okay, great. So, what is the modular group? The modular group is SL2C and it acts on the upper half plane. It's of course two or two matrices within straight positions in the terminal one, but also it's generated by these two elements. Oh, you can see that, yes, as well. It's moved. Oh, there. It's moving. There we go. It's generated by two transformations. Generated by two transformations of the upper half plane onto the upper half plane, T and S. One is a shift and one is some sort of inversion. And more completely, it adds as a matrices onto out in this form. And if you do this, if you fix this more algebraic approach, then this would be the matrix of T and this would be the matrix of S. It's generated by these two elements. It's a discrete group, right? It's a discrete subgroup of S. Group, right, is a discrete subgroup of a sub-taurus, and it's also a discrete group of symmetries of the torus. And this is why it's reasonable to expect to have a coherent action of this group in the representation theory of a nice number such. So modular forms. A modular form is a holomorphic function, and we're going to say it has weight k if it satisfies this. So it's not invariant under the action of SL2C. And then the action of SL2C. But it's kind of, I mean, it's almost there. It gives you this multiple times f tau after you act with SL2C on an element, and then apply F. And then also we'll ask that F is bounded as tau goes to I, tau means infinity. If you remember our free Boston number here, it had great dimension the inverse of the eta function, and the eta function is a modular form I said, and I'll just notice that this. And I'll just notice that it's a modular form of weight one-half. Wait, what is a module for a VOA? It's a vector space, W, now it's complex created, together with a math that now eats elements in the vertex algebra and spits out a power series with coefficients and endomorphisms of w. Just like with other algebraic structures, we hope that we can kind of grab something that eats something in V, something in W, and speeds up something. In V, something in W, and speeds up something in W. And this is what our map is doing. And again, we're going to ask that this power series be nice and not have infinitely many powers of C that are negative after you evaluate an element W and a bunch of axioms. And for a second, we're going to focus on modules that are graded by positive real numbers, and we're going to call those positive energy modules. Great! What are nice vertex algebras? What are nice vertex algebras? Well, a vertex operator algebra is called rational if you have semi-simple representation theory. So every nice enough module is the sum of irreducible ones, the rect sum of irreducible ones. And we're going to say that a VOA is C2 cofinite if the dimension of V mod sum vector space is finite. And what that vector space looks like is the minus two products. Ooh, this should be a baby medium, sorry about that. They need them, sort of about that. The minus two products of elements u, or maybe let me just write what the C2 spay is, is this the span of things of this form over the composite. Where this minus two comes from thinking There is each stage. Okay, and why are they, oh sorry, there it was. Why are they this, why do we call these people nice vertex algebra? Well, it turns out that if you have both conditions, rational and c to cofinate, the vertex algebra has only finitely many irreducible motors. In particular, if you're interested in In particular, if you're interested in finite categories, finite tensor categories, or modular tensor categories, you definitely want to have a finite category. It haven't finally many non-isomorphic reducible modules. This really can't be. So we have some simplicity, we have finally many reducible modules for this nice vertical saturnis. Okay, and now I'm going to tell you, this is a bit long, but I wanted to give the complete and correct statement. So Jus proved. Incorrect statements. So Zhu proved the following. We casually say the space of graded traces for simple modules for nice VOAs, so C2 rational VOAs, is modular invariant. And I'll try to unpack that casual phrase. So we grab a rational C2 cosine i VOA that's positively graded in this way. We grab positive number k, or positive integer k, an element u that's in the kth radius. Element u that's in the kth rated piece. We grab an irreducible positive energy module, so r plus rated, and we look at its trace function. So this is a trace function restricted to w of some grade preserving, a degree preserving operator associated to u that I'll describe in an element, times q to some shift of L0. That trace could That trace converges to a holomorphic function, where this degree preserving operator is defined as the k minus 1 load of u acting on w. And moreover, the space spanned by all the straces as you fix u but move the irreducibles w1 for wm is a finite-dimensional representation of SOC. In particular, if you fix u to be this unit we had, If you fix u to be this unit we had, the vacuum vector, you get that the greatest dimensions span a finite dimensional representation of a solution. Because the degree preserving operator associated to the vacuum is always the density. So you really end up with a graded dimension. So we could casually say the space of graded dimensions for simple modules of nice DOAs is modular. Is modular in there. Okay, other vertex algebra is modular. So unfortunately, not all vertex algebra are nice. Or fortunately, this is also very interesting. But many interesting vertex algebra, such as the three bottoms, the highest over vertex algebra, are not rational. Meaning they admit indecomposable, non-inreducible modules. And in 2004, Miyamoto defined graded pseudo traces for indecomposable modules and proved their modularity. Composable modules and prove their modularity. So the gradient pseudo-trace is a notion that constant plays the role of traces once we have in the composable non-irreducible modules. And this applies to irrational but still C2 cofinite vertex of periodological. So we can lose the rationality we can admit in the composable non-irreducible modules. But in Miyamoto's work, C2 co-fininess is still a condition that's needed, or that's asked for. Asked for, etc. Informally, once we have indicable modules, the degree-preserving operators are not diagonal anymore, and pseudo-traces capture some of this off-diagonal. Okay. Sorry. Okay. Yeah. Of course. The difference between indecomposable versus irreducible. Ah, yes. Maybe. Yeah, of course, of course. So an indecomposable Yeah, of course, of course. So, an indecomposable is someone that admits a sub module. So, they're not irreducible because they have a sub module living inside it. But you can decompose as a direct sum of simple things. Make sense? When you're in the stem-simple setting, every time you find a sub-module, you know that there's a sub-module complement to that one. And you can keep going to get a direct sum of irreducible modules. So, everything is really, really nice. By knowing the simple components, you know all the modules, because you know all of them are sums of simples, fine sums of simples. Find something. But in this case, we'll have things that have submodules but are not subs. Okay, so what are graded serial traces? Well, more formally, we grab an interlock module, which is a nice enough module, and now we're in the logarithmic setting, in the setting in which we have indecomposable modules. So these are generalized eigenvectors. For us, we are not eigenvectors anymore. For else, we are not eigovectors anymore. And we can choose a nice enough basis, call a miomodo basis, such that the matrix of any degree-preserving operator looks like this with some symmetries. And we're going to define the pseudo-trace of such a matrix to be the trace of this upper right corner. So pretty nice, friendly, algebraic definition. However, we're going to call that the Cedar trace a degree lambda because we're looking at the generalized eigenspace. Generalized eigenspace associated to lambda, a complex number lambda. But we are going to actually mix things up a little bit. We want to take into account that L0 is not semi-simple anymore. L0 has a semi-simple piece and a nil 10 piece because as I mentioned, L0 doesn't add that in a nice simple anymore on our module W. So we're going to define the modified pseudo trace to be the zenotrace of the matrix that you get after you put the degree preserved. After you put the degree-preserving operator right next to Q to the null-putin part. So we're incorporating the nil-putin part of L0 in the definition of pseudo-trace. And this Q to the null putin part should be interpreted as e to the L0 block. So if you do that and you explain this, you end up with this expression, which looks a little bit more complicated. All we did was just really evaluate this exponential. There's a Nilton matrix, so this. There's a Nilton matrix, so this will actually converge, right? Eventually, you'll get a zero. And we're going to call this the modified pseudo-trace at Greek lambda. These are going to be the things that we put in a generating function, and that's the thing we're going to call a pseudo trace. The modified pseudo-trace of degree lambda is going to be the degree lambda piece of our pseudo-trace. Great, so the pseudo-trace of an element v, which depends on the parameter tau, is defined exactly as Is defined exactly as the sum of the multiplied pseudo traces at each degree lambda times a shift of Q to the L0 sensor. I'll give you an example in a second, but we end up with this complicated expression because we're really summing each modified pseudo trace and multiply it by Q to the L0 summon simple minus C L T. Okay, great. So here's a concrete example of what a pseudo trace looks like. We're going to grab an indecomposable module for the free bosson that's really A model for the free bosson that's really, really friendly. It's graded in this way, and the top space, the depreciated space, is spanned by k vectors, u1 through uk, that satisfy that u1 is an eigenvector for x0 with the eigenvalue lambda, but u2, u3, so 4 are not. They're not eigenvectors, but they're generalized eigenvectors, so this way. So you can kind of see that you can go from uk to uk minus 1. From uk to uk minus 1 by applying x0 minus Œª and so forth for the weight. Great, so in particular, this is what the Jordan block looks like for that operator. And as I said, it's non-diagonal, right? There's some off-diagonal component. Where x0, let me just recall, is the degree-preserving endomorphism associated to this element, at degree one. And we're looking at its action on our module W, and we're looking at this. At the zero mode of the atom. That's how we get x. Okay, great. Now, on the other hand, L0, of course, we had this expression for L0. It's also non-diagonal. So we get a semi-simple piece for L0. And we can use carefully this expression to compute what it does to each of this u1, u2, uk, plus this piece. So we get a semi-simple part. And it nope. The one semi-simple dot. Out here. Oh, here, because yeah, there's so many simples, but so many simples should be here. Ah, ah, yes, sorry. This one shouldn't be here, obviously. Yeah, I apologize. Yes, thank you, thank you, yes. One, one for zero. Yes, this is same as simple should be same as this one, sorry about that. Yes, so maybe I apologize, I'm not sure what you have in there, but I should notice. This ones, this ones should not be here, and that should be zero. So we only have, let me square over two tens of densities in this piece. Go over two tensio identities in space, plus some interesting, kind of unusual new milketing part. And if we fix k equals 2, so now we have u1 and u2, and u1 is an eigenvalue for x0, and u2 is not, but close, x0 minus lambda square, u2 is rough. Then this is what the matrix for L0 looks like. And the sum of some of R is lambda square over 2, which is the identity, and 0, 1, 0, square is the null depart. So, oh. So, oh, never mind. Cool. This should be a 0, I apologize. And then we have this lambda here. Yeah, I have no idea what happened, but I'm sorry. Ignore this one. It should be lambda squared over 2. And then this means that q to the l0 looks exactly like this. It's just really nice and multiple. And we can now build the modified pseudo trace for the vacuum vector at degree zero by taking the Degree zero by taking the pseudo-trace of this matrix. The degree-preserving operator times the matrix q to the elza. Then I can just ask I don't know. Or any relationship. I'm not familiar with that. Okay, so I'm ignored this one, so all the things that say semi-simple should be semi-simple. And we end up taking the pseudo-trace of this nice friendly matrix, and this is just the trace of lambda, a number, so it's just number. So interestingly, you can, after you compute carefully the modified cedar trace at each degree, you can put them in a generic function and you get some very, very Function and you get some very, very interesting functions. And we computed some pseudo traces. Maybe I should mention a few things about this. Here are the pseudo traces we computed. We computed the pseudo trace associated for any indecomposable module, the pseudo trace for the vacuum vector, the pseudo trace for x minus 1, the vacuum vector, and the pseudo trace for the conformal vector omega n for any a complex number, as I mentioned earlier. Complex number, as I mentioned earlier. We can study this problem for any conformal structure of the free classes. But I should mention that first, before we completed pseudo traces, we had to carefully work on making sure that all modules were suitable for such structure, because as I mentioned in Miyamoto's work, he asked that his vertex address be C to confine and the three bosons are not C to confine. So the first thing we did was we showed that all indecomposable modules for the three bosons for any conformal structure are interlocked. Any conformal structure are interductive in the sense of miomodes. So it makes sense to go and find pseudo traces. We also found pseudo traces. So if we grab this indicum possible module and now I'm allowing for A to be any complex number, because we're thinking of the three buttons with any complex structure, omega A. We have it in the composable module. Its top space is k-dimensional, and this Is k-dimensional and these vectors behave in this way. So they're in general generalized stagnant vectors for x0. Then we proved, we explicitly gave formulas for the pseudo trace associated to the back constant in any decomposable. And I didn't put the formula here because it's a little long and technical, but I'm happy to share it with anyone who's interested in that. But it actually is just a function depending on log q times the graded dimension of w. The graded dimension of this index. The greater dimension of this index of this book model. And we explicitly describe this function. So, for instance, if k is 1, the function is just 1. If k is 2, the function is lambda minus a times log q. We saw it in a few previous slides. When a was 0, we got lambda times log q. If k is 3, we get this slightly more complicated expression. Okay. Example 2. Example two, and this will be much shorter, the Virasoro vertex algebra. So we start again with an infinite dimensional Lie algebra in a central element, generated by this infinite generator, from sorry, in a central element, with the following commutation relations. And we're going to again fix a triangular decomposition. So we call Bir plus this whole space. We grab a one-dimensional vector space, and we make it a module for this BirPlus by declaring that L. By declaring that n kills this vector for n greater than zero and L0 acts by a scalar h that we call the informal weight. The central element acts by another scalar little c that we call the central charge. And we're going to say, we're going to call the Fermi module the space induced from this action on this one-dimensional vector space to all of the Pearson algebra. And now we're going to fix h equal to zero. This is a nice representation of what the permanent module would be. A nice representation of what the perma module looks like for any CH. But, and again, we have a PBW basis in the same discussion we had for the free boss and holds here. And this is a basis for the Vermont module. And now we fix H equal to 0 for any central charge key. We fix H equal to 0, and we kill the submodule generated by L minus 1. So we're going to kill all those elements. Franklin Ju proved that that is a VOA. That is a vertex operator. That is a vertex operator that we're going to call NC. It's a Verma module for H equals 0, mod out by the submodule generated by L minus 1 on the bat. And the VAA structure and the Virasoro vertex operator algebra, here's an updated picture. We have killed L minus 1, 1, L minus 1, 4, 1, etc. Has the vacuum, which is this vector that we started with. The conformal element is L minus 2, 1. The only thing that you see if The only thing that you see are the V2. And the vertex angel map is defined as the power series that has all of the VR0 generators for L minus 2, 1. And more generally, one can use, again, normal order products of derivatives of this field to describe the general vertex algebra. 3. This vertex algebra is irrational for all central charges. It admits in the composable modules, and we describe the gradient traces. We describe the gradient traces for certain indecomposable modules. We also show that in this case, unlike the three bosons, there are modules that are not interlocked. We're again in a non-rational, non-C22-finite algebra, so we have to be careful and make sure that we can actually go and look for pseudo traces in there. So for the VR server tech side, we've proved that there are indecomposers that are not nice in the sense of Miya model, unlike in the high-speed case, in which all In the high single case, in which all indecompose levels were interlocked. And we described which in the composed levels are interlocked and computed their speed atrialization. So, last slide. I don't know if we're a little behind in quote mode. Both the Virasoro VOA and the Heisenberg VOA are neither rational or significant finite. They both have interlocked. They both have interlocked modules, and maybe more precisely, all indecomposables are interlocked for the Heisenberg vertex algebra. Only some of the indecomposables are interlocked for the Virasoro algebra. But both of them have interlocked modules and interesting graded pseudo traces. And this pseudo traces satisfy an important logarithmic derivative property, which is promising if we hope to find modularity properties for the pseudotraces, which is Which is, this was the key ingredient for Miyamoto to prove that you still get some modularity even though you're dealing with irrational DOA representations. And we computed this heater trace associated to the vacuum and to this degree 1, or x minus 1, 1, and all the conformal vectors for the free bosons. And we computed these two traces, the one associated to the vacuum, and the conformal vector for the Virasorov VOAs. And with our And with our wonderful team, we hope to explore the following question: find signotraces for other elements V and V. In particular, we're interested in finding signotraces for other elements in the free bosons, and we hope to study their modular behavior. I just I turn it down. All right.