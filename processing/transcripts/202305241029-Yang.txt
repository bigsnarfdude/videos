Rodney and Jan, can you speak about the projectile train spectrum and so-called discussion? In the first talk, I basically covered the finite-dimensional case. There are interesting phenomenas here. So today, we'll do infinite-dimensional case. And as I promised to Selma, I will start with a very simple example. But before doing that, But before doing that, I want to introduce, recall the definition of projectic joint spectrum, and maybe say a few words about its philosophy. So suppose you have a NAT algebra, commuting or non-commuting, and you have several elements and And seeing from Rauspak that there are several different constructions of joint spectrum when they are commuting. And the construction is based on basically tuples of this kind where the lambda one and named n are complex lambda. So this is the i. Is that I was used as a base point for the definition of joint spectrum for the previous notions. For the projective spectrum, we do away with this identity. So it is defined in the following way. So we consider the linear pencil and then the P of A will be just Will be just a collection of elements in a complex projective space where AZ not invertible. So this is a naive and probably very, you know, cute definition and and it's symmetric and it's simple. And clearly you don't require the operators to be commuting. The operators to be commuting. But what is the philosophy behind this definition? This is something I almost never told anyone except maybe very close friends. So in this definition, the eye is used as a base point, meaning that there's a so-called privileged observer. So you're observing things from a fixed base point. In this definition, we do. In this definition, we do away with that base point. So, all the perceptions from different observers are treated in an equal footing. So, this is the philosophy. There is some physical meaning, right? From physics, Kami, like I said? Oh, yes, definitely. So, this is a linear pencil. It has been studied very well in many parts of the world. So, why do you call it a pencil? Not very character. Your pencil is a one-dimensional. Not the right geometry. A pencil is a one-dimensional linear space. I don't know. Because the pencil is one-dimensional. That's right. So some people call it multi-parameter pencil. Several pencils. Okay, so now let me get back to examples. And for the experts here, I'm sorry, this is very elementary since the consensus. Since the consensus was that we're talking to graduate students, so let's start with a very simple example. So consider the hydro group. This is probably the simplest non-computing group. And but it's important. It's been used in the construction of sophisticated groups like Griggerjuk group and so on. Kruggerjuk group and so on. Now, what are the irreducible representations of this simple group? Well, if you take a theta and you do the following representation E metaphi theta E magazine E meta passment and roll say the T just one here and this induces a representation okay and you will see the following facts and those facts actually are proved by Carmos in the fifties. In the fifties. When theta is zero for pi, this is commuting. So rho theta a rho theta t is equal to rho theta t rho theta a. So it's basically a direct sum of two one-dimensional representations. Second, when theta, let's just look at the domain from zero to pi. Okay? Because otherwise it'll be just duplicating self, other parts. So this is irreuseful. And the strange thing about this group is that every irreducible representation is either Is either one-dimensional or of this type. Okay, so representation of T infinity either one being more. Do you mean two by two unitary representation or anything? Yeah, two by two unit two representations. Whatsoever. Okay, so all right, so then you have an irreducible representation when theta is in this range. Okay? So let's compute its characteristic one out. Yes? Should the definition of Renata T mention? Verna T mentioned T is here. I mean on the right. There's no, this is just one. This is a. Okay, so let's calculate this characteristic polynomial. Okay, so let's consider the determinant of Z0 identity plus Z1 Rholls K plus Z2 Rhohn C. And it's pretty easy to calculate. It turns out to be z0 squared minus z1 squared minus z2 squared minus 2 times z1 z2 cosine z. So you see the characteristic polynomial contains information about this irreducible representation, which is contained. Representation, which is contained in the coefficient here. So, meaning that if you have two different irreducible two-dimensional representations, then they are unitarily equivalent if and only if they have the same characteristic polynomial. So, the characteristic really tells you something about the representation. And why it is a quadratic thing, why it's always a square, but it has something to do with. Squared, but it has something to do with the way the group is constructed. All right, so this is a two-dimensional case. So what happens if I consider a left-right representation of this group position? So Romway, I'm sorry for more questions, but I'm a student. Go ahead. So if you were to represent into Un, N by N unitary matrices, your polynomial would be degree N, right? But you're saying that we have some linear factors? Well, if you represent the UN, it can be decomposed as some of irreducible representations. So the characteristic polynomial will be a product of something like this. So the irreducible factors. Right, and this is irreducible if and only if when Seta is not. One reason you see it as polylow dimensional representations is it contains. Dimensional representations is it contains the cyclic group and that decomposes the sum of the unhindencies which you see. Okay, so let's take a look at the regular representation. So, and which is from d infinity to say u of L2 must be infinity. Okay. Uh but L two of D infinity, this thing here, can be identified with L2 on the unit circle direct sum. So then the representation can be represented on this direct sum spaces and the analyst will be happy to see what's happening there. I'll be happy to see what's happening there. So it turns out that lambda A is simply in block matrix term T is identity where T is the unilateral shift, or is the bilateral shift where T acting on maps? T. Carrie F, E to the P Zeta is E to the Plus theta F E to the power theta. Okay, so this is called the bilateral shift. It's a term that every analyst, every person in orbit theory loved to hear. It's a shift. Now, the shift is a unitary operator, so it has spectral decomposition in terms of Spectral decomposition in terms of projection-valued spectral measure. Okay, so let me write that down. So here, the t can be written as an integral over the circle of e to the i theta d e of theta, where this is the projection-valued measure. Now, what is this measure? I'll tell you what it is. So, the measure is defined in the following way. So, this is a unit circle. And if you have a subset, say S here, then E of this subset acting on function is just a characteristic function of this subset times. This is the projection. So, this is clearly written. Written, very well understood decomposition. So let me try to use this spectral decomposition in here. Do that. So A is equal to integral P equal to theta from here. And here, when you take the conjugate, you will have a minus sign here. Say that this 0, 0. And of course, identity can be written similarly. So 01. One the say like one right, so like that. Okay, so how about I take the integral sign out? Okay, so let's see what happens. So keep this in mind, and then we have a very interesting phenomenon. Very interesting phenomenon. Okay, so then this is so-called matrix-valued integration. Matrix-valued integration. And the good thing about this is that this is the spectral measure. Now I know that the irreducible, I know that for amenable groups. That for amenable groups, the left or regular representation can be written as a direct integral of irreducible representations. But in that integral, they are not using the spectral measure. So here, we're represented using the spectral measure. And I believe something more general can be said here. So, what happens with other groups? So, the question here so can we write it using the spectral measure, you ask? The direct sum with respect to the spectral measures? Okay. Yes, sorry to slow you down, but it's not completely clear to me how T acts on. It's not completely clear to me how t acts on f using this directed integral. Well, it's an integral operator. Right, but if you wanted to, one line below. So if you hear, okay, yeah. So it will be the following. So if you have t acting on f and then you say inner product with the function g, that will be okay. So let's take a finish. We have to say that say a projection acting on f in z inner power is g. So it's defining the weak operator that the power just sets. Okay, so so far so good. Any questions? Okay, so then if we consider your question, Pierre said that the surprising fact is that you get spectral measures. Yeah. Yeah, this is the point. Yes, yeah. So we need to make sense of this integral first. It's not often seen, okay? I believe I have made sense of it. I'm at peace with it now. But whether it happens, But whether it happens for other groups, I don't know. Is it something that is special about this Dahedral group? What is your I don't know? I don't think it's unique to the Hedral group because anytime when you have a unitary representation, the unit has special decomposition. So lambda of A is a measure on the real line or what? Which anatomy? At the top there, you've got this integral. Oh, no, this is the. You've got this integral. Oh, no, this is the left irregular representation. Okay, okay. Where is the spectral measure? Oh, it's here. Okay, this is the spectral measure. But the dihedral group is special in the sense that you found the unitary sitting inside the infinite dimensional representation, right? Yes. And in general, if you are looking at a unitary representation of a group, then you can get hold of the Can get hold of the matrix elements or what are called matrix elements, but recognizing it as some kind of a block operator with unitaries in them, I haven't really seen too many instances. For example, even if you look at SU11, linear groups, the general unitary representation. Right, right. So, yeah, it's a good start to start. It's good. It's a good start to start to consider this question for some very simple groups. We know for the cyclic group, this is always true. The one that I was talking about, L2 of the disk, and you look at just that weighted composition operator, as they call it. I mean, how are you going to sort of break it up in this way? Of course, it's a unitary operator, so it has a direct integral representation of the whole operator. Representation of the whole operator. But in terms of irreducible components, which are very, very difficult to understand. So let's talk about it in the talk while we work on it. Maybe your final question for students. Now, notice we have a two-generated group. And then one of the generators is sent to a matrix that involves the identity operator. This is what makes this kind of unlock a little bit, because now you can use the spectral measure for like a commutative spectral measure that comes from the element A. The spectral measure that comes from the element A. Correct. So the minute you start messing around with going somewhere else. Can you ask this question for two generated groups to begin with? Is that essential? Otherwise, I don't know what to do with the spectrum measure unless you're doing stuff that Rolo was doing earlier. Okay, so let me just continue. And from here, let's look at the projected spectrum. Okay, so here, let's consider P of Ai, which is the collection. Which is the collection of say that's quite nice. This is Z inside P2, where plus Z1 lambda A plus Z2 lambda T is not important. Okay. Let's consider that. Oh, this is a rule. So let's put this representation into the linear sum. So this linear sum so I have a so the linear combination will be the linear combination inside the integral. So that would be here A So A rho sub Seta of Z D E of D of Seta. So then I can make a claim, which I have proof, but let me just forget the proof. It's claim that A and Z not invertible If and only if A row say that Z not invertible for every say that just almost everywhere? No, for every sale. Okay. And the spectrum of this is computed, right? We just did it. So then we have the following. So then we have the following theorem, and this theorem is the joint work with Slava. It says that the joint spectrum, the project spectrum is the union of quadratic pieces. Where z0 squared minus z1 squared minus 2 times z1, z2 cosine theta equal to 0. For theta is between 0 and 2 part. So in this way we calculate the joint. We calculate the joint spectrum without going through the finite stage. And that is possible because we use the spectral decomposition for the bilateral shift. So do you mean for all theta or for some theta? For all. This is a union. For all theta in the thesis. No, no, no, no, I mean above there in your equivalence. It's not a verbal, if only A rho theta is not verbal. For all theta. For all, for all. I think there exists a theta. For all, yeah. No. For all, yeah. No, for for any, for any. Yeah, this is okay. It's not invertible for any. If it fails to be invertible for one, that's enough for the vertical. That's right. That's what he's asking. Oh, I see. I see. I see. I see the excess of theoretical. Right, right. But you have the answer version though. You have a spectral mapping theater right there in these guys. Oh, really? Yeah. We can talk. We can talk. Okay, so. Okay, so I would like to keep in mind of this thing because later I'm going to use this fact when I do the study on the Julia site. So this is the things we discovered in our joint work in 2015 and published in 2017. And there's a very interesting consequence of this fact. That is, if you consider If you consider the C-style algebra, the reduced C-style algebra of T infinity, then there are two very unique projections in it. One is lambda A plus identity divided by 2, and the other one is Nambda T plus identity divided by 2. If you call it P and Q, so these are the projections. Projections in generic position. And this is a subject that's been studied by many people. And using this theorem, and because this P here and Q here are linear combinations of lambda L and lambda T, you can actually write down. You can actually write down the projective spectrum for the PMQ. So again, the projective spectrum for, let's say, this pencil, say AZ is Z0 plus Z1P plus Z2Q. Okay, and it's just a change of variables. And it's just a change of variables here. If some graduate students are interested, just go ahead and use this theorem to compute the joint spectrum. It's fun to do. Okay, so now let me just jump over to the connections with self-similarity. So the self-similarity has been defined in several talks in this workshop and they refer they define the self-similarity through the actions on a tree or on a shape. So for our future theorists, we would like to see things through Huber space. So here is a definition of self-similarity. Of self-similarity without using the group action. So suppose you have a, you started with a group representation, U of H. And if you have a unitary map from H to H D, as that type of unitary map always exists. That type of unitary map always exists when H is infinite-dimensional. You can compose and get a new group representation. So that is a group representation from G to U, H to D. Okay? So then for each element, So then, for each element, I call it pi hat of g. So, then the pi hat of g can be written as a block matrix, a d by d block matrix, where you have elements here, elements here, and elements here. Definition, this chi is said to be To be self-similar if all the elements here, so let's just call it x ij if x i j is of the form pi of x for sine x and sine g or Or x minus n is zero. So this is a self-similar group representation. And well, because this is a unitary operator, right? This is a unitary. And each entry, it is either zero or unitary. So what it comes down from this definition is that in each row and in each column, there's a And in each column, there's precisely one non-zero unit tree. Right? So this is a fact, you know, very clearly. And then once you have that, you have the following, this representation here induces a homomorphism from the group algebra. So let's say group algebra into Into let's call pi act here into D of H E. So this is the same we discussed in the morning. So I guess Slava's question is: what is unique about this homomorphism? So this homomorphism can be extended to be a homomorphism. To be a homomorphism from a C-star algebra to this, right? So it can be scaled into a, so this is included in the C-star algebra of G. So this is an interesting question. So what is unique about this map? This is not an ordinary homomorphism, right? Because this is not just a map. Not just map every element to every element. Right, I mean, what I'm going to say is that some things that can be, must be said, I mean, that relates itself similarity to the representation of cis algebra. This is a per sum w or per sum w? The w map going from h to h. Map going from H to H B. Yeah, yeah, yeah, yeah, yeah. So I call it the pi hat. So there just a W so that that happens. So the question basically is how can you describe self-similarity using the C-star algebra language? Holomorphisms of C-star algebra. Could you define the C-star algebra for representation principles? Oh, does that just extend to the Cister algebra? Extend to the sister algebra. Just the definition of the sister algebra itself. You just take the closure to specifically. Yeah, take the dorm closure, take the norm closure, and the hydro space. That's it. Right. That's all it is. Okay, so let me continue. This is a question. Or maybe I should state it clearly so then the question is clear, right? We don't want any ambiguities. The questions. Okay, so the question here is that Is that well I mean the image here is in a very interesting sub-algebra it's like a like a read product or something but that's that's it's and at least when you're talking about like like represent like permutation permutations of groups those are called in primitive representations. So how do we Right. So, how do we interpret self-similarity by C-star algebra of homomorphism? And as Frank just mentioned, I mean, this the I mean this the image here has some unique properties. It's not just a tensor product with a matrix algebra. It's the analog of an impermanent permutation group, but in the operator sense. Okay, so keep thinking, all right, keep thinking. So let me move on to the self-serve. You the self-similarity of tahedron sorry, but again, like for the sake of clarity, so what you would like to interpret the like the self-similarity or what? Of groups of algebras of actions the self-similarity comes. The self-similarity comes from this definition. And that self-similarity. Yeah, from representations. So that self-similar representation induces a system algebra representation. So how do we read this self-similarity from this homomorphism, the system algebra? So without necessarily any knowledge of Java, you've just seen. Correct, correct, yeah. So JK, the observer without knowing what's going on behind the curtain. Yes. Without knowing what's going on in the anti-current. Yes, that's the question. I'm asking one question ahead. Why is this not just the silly thing saying that you've got a star representation? Sorry, a C-served algebra is self-similar. If you have a star representation for which there exists a W that does the same thing, but now the entries are from the C-square algebra. Why isn't it that W? But the exists of W is the problem. You'd like to identify it. So, for instance, there's an analog in geometry where you have what's called a branched cover. Cover. And it's like a covering space, but a little brancher. And when that branch cover factors, the monodermic group of the covers is imprimitive. And that's equivalent. Even though producing the elevator period. When you have an imprimitive permutation group, it's imprimitive if and only if it preserves a non-trivial partition of the set. And so these are things you observe at the level of the original object, not knowing what the decomposition is. What is characterized by the same thing? Yeah, I think that's what his question is. He wants the operating analyt of these things that you're saying. So for true. Sorry, I'm going to let us give a speaker possibility to continue. Sorry. He is a speaker. Sorry about that. I like the fact that I motivated some discussions. Okay, so let me continue, 'cause uh I thought he had to. I will show you that instead uh mountain strip there can be discussions. Alright, so for the self-similar representation of the dihedral group, people can construct one using the action on the binary tree. But I will not do the action first. Instead, I will use this definition to write down that property and then I can show you how to translate it into. Translated into the action on the binary tree. So using the W now, so you have the following. So pi hat of, say, A is I believe it is identity identity here. It's on the Kubernetes, it's a Kupmer representation. Okay, so this is no longer on the LT. On the on the L2, okay? And then pi t is pi a 0 0 pi t. So this is the self-similarity. Self-similarity. And now, how do you see its action on the binary tree? Well, the binary tree, if you look at the boundary of binary tree, If you look at the boundary of binary tree, that is basically a sequence of zeros and ones. So you can write a sequence, say W is a sequence of zeros and ones. Then the action of A is the following. It acts on, it changes 0 W to 1 W and it acts on acts on one w to zero w. It changed the flips. And the second T zero del P it doesn't change the index here. It's still zero. But now you have A acting on delta and then T 1 W 1 W is still 1, but then it is T W F. So once you see the definition from this site, you can also read its action on the binary tree. Now, let's again take a look at that linear pencil. So then this linear pencil, A pi of Z. Of Z, which is Z0 plus Z1 pi of A plus Z2 pi of T is now unitarily equivalent through this W to the following. So it's a Z0, Z0. Z1 pi A, well, the Z1 here identity, this Z1 here. This is a scalar times identity. And then you have Z2 pi A plus Z2 pi T. So you have that. So the linear combination Combination is represented by a 2 by 2 block matrix. And then the invertibility can be tested using the Short complement. So in the case, so when Z0 squared is not equal to Z2 squared, this is Z0 plus Z2A. Plus z to A is invertible. Now, why is that? Well, because A is an involution. So pi of A is a self-adjoint unitry. So its eigenvalues are either 1 or negative 1. So when Z0 squared is not equal to Z2 squared, this is invertible. And when this is invertible, this is invertible, this linear panel here, Z pi. Hasso here, dÏ€ of z is invertible if and only if z zero plus z two pi of t minus z one square and the inverse I is invertible. So this is a simple linear algebra technique. And the inverse of this can be written. So the inverse here is simply z0 squared minus z2 square one over it then times z0 times Z0 minus Z2 pi a because that is it's English and you can easily read it okay so then we can rearrange terms to write it again as a linear combination of pi A and pi T, right? So let's do that. So let's rewrite this term somehow and so constant term comes this hashtag. This has uh let's uh let's be patient, okay? I'm I'm slow at reading these things here. So the constant term is Z0 minus this times this, right? So that is Z0 minus Z0 divided by Divided by C1 squared, C0. Oh, C1 squared, yes. C1 squared. Yeah. So this is the identity part plus the pi A part. Pi A part is minus Z two over Z zero. And it's also a Z one squared pi. And Z one squared. Yes. Squared. Yes. Okay, and then the IT party is DTI. Correct, correct. I think it looks more symmetric. You can play your map like this. Exactly. This is exactly what we did. Okay, so then we want a polynomial map to start with the discussion. Okay, so we multiply the button throughout the terms. So we have the following thing. So then we have a map. So then we have to map f of z0 z1 z2 this z0 z0 square and then middle term is zero z two z zero z two z two z two z zero z two square. So we have a very nice polynomial. And you have the following effect that it maps the projective spectrum back to the projected spectrum. We can consider it in the C3 case, or we consider it in the P2. It in the T2. Okay, so it doesn't matter much. So the maps A pi back to this is where my PhD student, Brian Gouldberg, and I began to investigate the dynamics of this path. So the question here is that So the question here is that can you calculate its Julia set? Calculates Julia set. So this is a, at the start, it seems like a very daunting task because Julia setting several variables for non-trivial maps is extremely difficult to compute. So it's very daunting in the beginning. Okay, so, but so far, Uh okay, so but so far I have not told you about this set. We only said that the projective spectrum with respect to the regular representation has a clear description, right? And it turns out that these two maps, two projections are so-called a week weekly equivalent. This is a weekly equivalent. And a nice thing about projective spectrum is that if you have two weakly equivalent representations, their projective spectrum is the same. So this equal to P and T. So we have a clear understanding of what this set is. The union of quadratic surfaces. It's a union of quadratic surfaces. Okay, so the question, let me state it here: what is Julia set? Bruno, why should invariance imply that it's the Julia set? Because it matches the uh set facts to yourself, so you can just iterate. But but so it should be uh forward invariant. But so it should be forward invariant. Right, I mean, you can do the iteration. So once you have this effect, then you have iteration. So I call this just the iteration n times. So you'll map this thing back to itself. Right? Yeah. So initially, we were thinking of calculating the projective spectrum on this set, but it turns out. But it turns out that we're just limiting ourselves too much. So, in the end, we consider the map from P2 to P2. But then, we have to deal with the indeterminacy points. I would say a few words about, make some definitions and then maybe say a few words about indeterminacies. So, definition is that Is that the P2 has no origin, right? So you can have a situation where you map all these components to zero. So those are called indeterminacy points. And so if you call this for simplicity, have one, have two, have three. You have indeterminacy set to be the point. To be the point in P2 where F1Z equals F2Z equals F3Z equals 0. And it turns out to be finite set. It's easy to compute. But when you go to the second level, say I N, which is the Z Which is the z where the iterations here is denoted by n this is zero. So this is the end indeterminacy set of this map F. And you can see that because this is a homogeneous. Because this is a homogeneous map, once it belongs to i n, it belongs to i sub n plus 1. So it's an increasing net of sets. But these are subsets of the p2, so that you have the so-called extended indeterminacy set, which is the union of i n, n goes from 1 to infinity, and you take a closure in the projective space. In the projected space. So, this is called the extended indeterminacy set. So, what is the definition of a Julian set in the Fatu set? So you consider a map from P2 to P2. Maybe minus its indeterminacy set. A point near inside let's say P is all It is called a tune point if there exists a neighborhood u of p such that this family h to n is normal. It's a normal family. Normal. It's a normal family. A normal family is a family of functions where every sequence from this family contains a normally convergent subsequence. That is P. That was enabled. So an FH is the collection of two points and the Julia set of H is the conduct. Alright, so I noticed that there were different definitions, but the turns out to be equivalent. So some use acricontinuity to define, so instead of using normal families, you use acrylic continuous family as a chapter. So the handling that is part of the Jupiter set now? Say it one more time. Yes, they uh E is a part of the S. Yes, we consider, yeah, so let's say convention. You always regard E as a part of the Julius convention. But there are maps where the Julius There are maps where the Julia set or where the E is the entire P2. That can happen. And when you are given a very concrete map, just like this, it takes a huge amount of work to determine whether the extended indeterminacy set coincides with P2. Because if it is equal to P2, then that's hopeless. There's nothing useful you can say about Julia's quantity. Actually, there was a good amount of work on this in my students' thesis. Okay, so let me just write down this theorem. Well, it says Well, it says that uh the Julia set of F is the project spectrum union with E. So this is the connection with the Julia set. Well, it looks good, but there is an unsatisfactory part. That is the part E. And we don't know. And we don't know, we don't have a clear picture of what E is, right? So even though he's a good student and get him a PhD degree, but we don't know exactly what E looks like. So this is a little bit unsatisfactory fact. So then let's revisit this map. So to make a better statement, consider the following map. We consider the following math. So we consider the math high, which does the following. It maps when z0 squared minus z1 squared minus z2 squared 0 and otherwise Two. Well, this is other. Now, why do we define such a thing? That comes from the knowledge of the projected spectrum. So let me just write down one more time here, and then I'll keep it till the end. This is the union of these zeros where Z0 square minus 2x2Z1 d2x0 for the union here. So this is the spectrum. So you can see that this quotient here, when you restrict your your points in the spectrum, then this is real. And it's a number between that is one and one. That is one and one. So, using this map, we can rewrite this thing here. So, then f02 can be written as let's see. So, this part is tau z0 and then tau. Uh z zero and then tau of z times two z one z two and this part is z one z two squared and this part can also be written as these two so these zero squared So z0 squared minus z2 square would be z2 tau of z times q z1 z2 and then plus z1 squared. Okay? And then once it is And then once it is written in this way, you notice that it has a common factor Z1, Z2. So I can factor the Z1, Z2 out. I got Z02Z0 tau Z and Z one and Z two tau Z Times Q, and then plus Z1. So I give a name to it. I call this map half time. Now, by doing so, I come up with a simpler map. And I excluded many indeterminacies points, because those points are mostly contributed by the spectrum. Contributed by this factor. So this factor kills many, many points. So let's take out this factor and left with a simpler map. So then what is the indeterminacy set of this and what is its true mass? And this set has this map is interesting because It's interesting because it has the relation with the so-called Chebyshev polynomial. So here x is on extended on x character and the relation is that f of d and then tau And then tau is equal to f of tau of t of tau okay, meaning that the map f pi is semiconduct to the Chebyshev map. And the Chebyshev map is well. And the Chef Bishop map is well studied, and we know it's, Julia said, very well, and using the techniques here, we can improve the farmers here. Can I make a small correction? The F pi on the right side shouldn't be there, I believe. Yes, you're right. Thanks. Okay, so the serum here is that Julia said hi. Is actually exactly equal to the projectile. So this is the end of this journey. Well, let me just say a few words to a few more. Not only we calculate the Julia set, but also we can determine the limit of this thing. Limit of this thing is to our maps, let's say star, which is bear with me maybe two more minutes zero z two plus z one half z where is l z minus squared have a clear understanding of what's happening at the limit all right so to conclude Alright, so to conclude this discussion, I want to mention a connection with John Buna. Well, first, we read the question about group of intermediate books. And then Slala solved the problem and introduced the notion of self-similarity. And then through the joint spectrum We made a connection with the Julia set. And Milner is waiting here. Okay, thank you. Questions? Comments? Yes. When you were talking about scale similarity, When you were talking about cell similarity and in the context of sister access and so on, that kind of links developed in terms of the work of Donald Hadwin with Eric Norgren and also Yeeby Ken and Bonnet Hadwin in terms of how do you use the sister algebra structure that you have to look at similarity. The similarity and unitary equivalence are different notions. So the first application Notions. So the first attempt, which doesn't go very far, is you look at the invertible operator that implements a similarity and you break it into a quality composition. Unitary and positive operator that is invertible. The unitary you can do a little bit, but then there is an issue with the positive operator. It's just a thought because I I I think that maybe there are what they do in terms of the text value. Okay, are questions, comments? Yes. I wanted to ask a general question about the projective spectrum. So you pointed out that the operators don't have to commute, right? It still makes sense. But if they do commute, I mean, is there a connection to the Taylor spectrum? Oh, yeah, yeah, absolutely. Yes. This is something that I did not mention because I want to start with a simple example. So very good questions. Very good questions. So when you have a tuple, commuting tuple, say and this is basically a linear map plus Z and A. Plus Z and En. So it's a map from two poles to just single operators. So you can use the spectrum mapping theorem. It's the simple operation there. So you can use the spectrum mapping theory. So in the end, you have the following effect. So P A of Z is the Z in the Netherlands. I think it's the union where the Z is inside the Taylor spectrum of these hyperplanes, which is W1 W n inside C N minus 1 where C one Where I C1, W1 plus C, and W0. So this is a connection there to the Taylor space. And even more, I can say, because there is a spectral mapping theory in this case too, right? Well, if you have a holomorphic map, say F from C N to C and holomorphic, then the P Then um P of so then each one of them you have it replaced by so let's just say P of F of A is going to be equal to the union here where this Z again is still inside sigma t A and then this part is H F of Half of C. This is like a spectromatic theory by using the projective space in between. Yes, sir. And then we want to go to lunch, but let me ask you a question. It might be relevant. For all of the examples that I've seen, where you have this renormalization theory, the joint spectrum is always the support of a closed positive one, one current. So that is a very good exercise on the leave to anyone who's interested. To anyone who's interested. But let me finish my question. Is it always, or maybe not the self-similar situations, if you have a joint spectrum in a more general setting, should it be the support of a close positive 1,1 current? Does it have a kind of co-homological property underneath it? That stud I didn't study that part, but instead we studied the so-called Mara Katamfo. The so-called model-kadam flow on the complement of the spectrum. Yeah. And that plays an important role and tells a lot about the topology of this set. But as I said, there's a very good exercise here. Maybe you're interested, and maybe some others can work on it. That is given this very concrete map. What is the green colour? What is the green current? Anyone can pick the green current on this map? Is the green current supported on the Julia set? Right, so, okay, I was okay. I think we are under pressure of time. We didn't promote the discussion sessions, so let us find to speak not to start. 