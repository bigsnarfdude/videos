All right, let me continue with the last talk of the conference. Stanley Zhao is going to speak to us about prime values of FAB squared and FAP squared for F, a binary organic form. Thank you very much for the introduction, and thank you to all the organizers. So we have Samir, Mike, with us, Bianca, who's not with us. With us, Bianca, who's not with us as far as I know, and of course, Nils opening up such a nice meeting. And it's my second in-person meeting after the pandemic. And the first one set a very high watermark, but I think this one easily meets that standard. So I pretty much appreciate it. And of course, a lot of the speakers, I've already thanked the organizers and thank everybody, all the attendees for such a great meeting. But I think for me, I also want to put a shout out for all the staff that's working at the facility. Working at the facility. Especially, you know, I brought my family with me. I have two young kids, so they have a lot of demands, and the staff are really accommodating and really nice to the kids. So I really appreciate that on top. So thank you very much. Okay, and for me personally, one more person. And for me personally, one more person I have to thank. Okay, there we go. Okay. So this paper, so I put it on the archive last year, so John is turning 81 this year. This talk is a little anachronistic in that sense, but this talk and this paper is in honor of John Friedlander's 80th birthday. And I say this without any sense of flattery. Sense of flattery or just, and that this work certainly would not have been possible without his influence and support. So, John, if you're watching this now or sometime later, thank you very much. I hope that you enjoyed the work that comes as a consequence of this. Okay, so another thing is a disclaimer. This talk is a bit fish out of water for a conference called Modern Breakthroughs in Diaphene Problems because really. Throughs and diaffecting problems, because it really is a prime number theory investigation, but I hope that it's entertaining and if not useful for everyone in the audience. So this is Dr. Seuss, right? Why should there be three fish in a tree? I'm really confused. Okay, so in this conference, we saw many examples of interesting families of equations with the Council of Integer or rational solutions, right? That's kind of what we do. Rational solutions, right? That's kind of what we do in number theory. Or to show that there are none, right? So that's kind of the general theme of this conference. But let's look at a really basic equation that probably we all know how to solve, in any reasonable sense of the word solve, in integers or rationals. x minus y equals 2. Right? So if you care about only integers or rationals, then yeah, sure, right? Like, okay, if you just I'll give you any x, you can solve, you can find the y. You can solve, you can find the y, right? If there's like a bijection to just z and q, if there's nothing going on here. So, why care about this particular solution, this equation, right? This is completely trivial if your domain is z or q. But, you know, maybe there's, maybe I'm the only one in that tribe in this room right now, but there's a different, slightly masochistic tribe of number theorists who like to ask how to solve this equation when one removes such very When one removes such very basic and nice algebraic structures, the question is: Can one find infinitely many solutions to this equation if one restricts x and y to some proper subset of natural numbers without a semi-group structure? So you basically lose the additive structure. It's no longer closed under addition in any reasonable way. Okay, so okay, well, why would you do that? Well, it's really just boils back down to an old question. I think this is like. Old question. I think this is like twin prime conjecture is much newer than a lot of people think. I think the earliest record of it is actually only goes back to Landau, who's no longer with us, but he's not ancient. If you let x and y be prime numbers, can you find infinitely many solutions? And this is, of course, known as the twin prime conjecture, and it is still open. Okay, so one of the fundamental breakthroughs in prime number theory in the last decade. Prime number theory in the last decade, Yi Tang Zhang and James Mader, plus polymath, I should have wrote that, but I forgot, is the following assertion. There exists a positive integer n0, such that the equation x minus y equals 2n0 has infinitely many solutions for prime variables x and y. So this is perhaps not the way that you usually see their theorem stated, because usually their theorem is stated in terms of prime gaps, but really is an existence result. We don't know for any particular We don't know for any particular even number whether there are infinitely many solutions. We could boil it down to okay, in this list of, I think the record is like 242 or something, that one of them has to have infinitely many solutions, but we don't know which. And figuring out exactly which one actually has infinitely many solutions is somehow beyond the scope of Civ theory. And maybe I'll talk about that if I have time. But that's a picture of But that's a picture of Yitang Zhang and James Maynard. I think this picture of Yitang Zhang is close to what he looked like at the time, but this picture is much more recent. But he probably still looks like that. Probably looked exactly like that at the time when he worked on this. Maybe a little younger. And I'm very proud to say that I actually have had dinner, or at least we're in the same room during dinner for everybody who appeared in the slides. Okay. So I met everyone who's So, I met everyone whose picture you will see in this talk. So, this goes to show that even the simplest equations could become almost impossible to solve if you force things to be prime. So, prime number theory, of course, is at the heart of modern number theory. So, throughout this conference, we've heard, actually, in the very last talk, there was a reference to GRH. So, that just says that, well, how to use GRH, right? It really is. It really is a slap. Usually, the applications of GRH to things that are not prime number theory come from Chipotero's density theorem. So, one of the deeper applications, as far as I know, is one of the initial conditional proofs of the Andre-Word conjecture, which has now very recently been completely unconditionally proved. But it's safe to say that this theorem is not just for the masochists, it's for everyone. And of course, the prime number theorem itself, right, and of course Dirichlet's theorem, these are classic results that all number theorists will appreciate. But in terms of applications, this one has a huge number of applications. Okay? So it's not just like a novel to you, like solving x minus y equals 2 in primes, just because. So of course, the proof of the prime theorem was due to two independent works of Hademard and, okay, I'm going to. Hadamard and, okay, I'm going to embarrass myself by trying to say his name. Charles de la Valley de Poisson, I think. So again, I tried to find pictures. Okay, sorry. I never had dinner with either of you. Okay. But yeah, like I tried to find pictures of what they looked like approximately when they did the work because if you look at a typical picture of Hadamard or Elvadi Kharsan, when they were older and more distinguished, but they were relatively young. But they were relatively young when they did this work. Okay, so just as the proof of the prime number theorem by Hanamard and the Lavali-Person capped off an exciting century of research in primes in the 19th century, I'm going to argue that the seminal work of John Freelander and Honor Gabonietz capped off an absolutely exciting century of research on prime numbers in the 20th century. And it's one of the things that kind of One of the things that kind of supports my claim is that the date of the publication, right? It's 1998 and 1899. Okay, so yeah, I really think this is like the capstone for the 20th century in terms of prime labor theory. Okay, so this is a picture of John. I think he's older in this picture than when he did the work. Maybe Yvonne's was approach. I think it might be approximately correct. I'd be approximately correct. I don't know what dates these pictures were taken. Okay. So in 1998, Friedlander Voniitz changed the landscape of animal number theory forever by proving the following theorem. So I'm going to, as a support, I'm going to refer to a quote of my advisor, Cam Stewart, when we were talking about this theorem. He said to me in Zachary, You know, he said to me, in fact words, this was a revelation for me. He didn't think it was ever going to be possible to do something like that. And Freelander Lanez went ahead and did it. So you have this theorem. So for n number theorists, right, sort of something that looks like this is like the gold standard. You have like an asymptotic formula that's very, very precise. Okay? So, Okay, so you know what is this thing? So maybe in this audience, this requires some explanation. So this is the Bonmengo function. Okay, so maybe even explaining, this is a name Bonmengo function might not be enough. So this function, you can roughly think that it's equal to log p if n is equal to p to the k and it's zero otherwise. Okay, and of course this kappa is some definite real constant, right? So it just comes from n litigate n. Constant, right, so it just comes from an elliptic integral. So this is one of those nice elliptic integrals that actually boils down to a gamma factor. Yeah, and sort of for any of the end-living limit theorists who's going to watch this now or in the future, of course, this error term here is of significance. It's like y is at log log x over log x. So you know it's an end-limgular theory zone when you see more than one log, right? But this is actually like fundamental. This comes from the sieve itself. So in order to improve this, So, in order to improve this, you actually have to make some sort of fundamental breakthrough on the construction of the SIP, which I believe is very, very difficult. Okay, so there's, so I've lavished all the praise on this theorem, so let me try to justify it. Okay, so first of all, prior to this, there was no example of any polynomial of degree exceeding 2 that represents infinitely many primes. In the many primes. Okay, so this is. So if you have just degree one, that's basically just Dirichlet's theorem. If you have degree two, if it's homogeneous, it's finite quadratic forms, and this is just a norm form for ideal classes of a quadratic number field, then of course you're going to get infinitely many primes. You can think of it as a special case, like a very special case of Chevoterov. And of course, Ivaniets himself did, there's a very There's a very difficult work by Vanietz where he generalizes it to arbitrary quadratic polynomials, modulo congruence conditions that are not necessarily homogeneous, but the Greek beyond two was impossible for most parts of the 20th century. Okay, and in particular, this is a very sparse sequence of primes. Okay, so it has log density less than one. So log density is a very particular Log density is a very precarious measure of the difficulty level of a prime problem. So, for example, twin primes, we expect the log density to be one, but we can't prove it. And this is an example where you can actually do, you can detect a much thinner sequence. Okay, so that's perhaps another measure of the difficulty of this problem. So, what is the log density? So, it's basically the smallest exponent you can attach so that this asymptotic bound holds. That this asymptotic bound holds. And it could be zero. If your sequence is super sparse, like powers of two or something, then the log density will actually be zero. Okay, so the primes themselves have log density one. You cannot, like, the primes are not fewer than x to the 0.99, for example, right? So x over log x. And any primes in the fixed arithmetic progression is also log density one. And the sequence considered by three magnetic. And the sequence considered by a 300 audience would have log density equal to 3 quarters. So the important thing is that this is less than 1. So shortly after Freelander Vonietz's groundbreaking work, Keith Brown proved the following theorem. And I've worked with Keith Brown as well at Oxford. And in conversations about this theorem, it was very clear that he was, even in writing, it was clear that Keith Brown was inspired by Ferguson Blanche. Inspired by Bernard Lanyens, although in principle their methods are sufficiently disjoint that it's conceivable that Heathcliff could have proved it before them, but he didn't. He didn't think it was possible. Okay, so I'm going to state the theorem in a slightly different way. So this binary cubic form, x cubed plus 2y cubed, represents infinite many primes with x, y, and z. In particular, the infinitely many primes which are sums of three cubes. Okay? So, in particular, Okay, so in particular, Heath Brown's theorem answers an old question of Hardy, which is: while Hardy's conjecture was actually a little bit more precise, he conjectured an asymptotic formula for the number of primes and interval that's representable as the sum of three cubes. And of course, Heath-Brown's theorem doesn't answer that at all. You get a very thin subsequence. But it's kind of remarkable that this is the only proof that we have that there are infinitely many primes that are subs of three cubes. Because if you actually looked at x cubed plus y cubed plus z cube, that. x cube plus y cube plus x cube, that function is not nice enough to apply some of these techniques. But you could do it with this one. So Keith Brown also gets an asymptotic formula, but it's not nice in terms of the gold standard because he has to restrict the variables x and y in some unnatural way. Okay, and that's really just caused by the fact that Freeland Devonius polynomial is positive definite, but x cubed plus 2y cubed certainly is not positive definite. Certainly is not positive definite. Okay, so yeah, this is just like the remark I mentioned earlier. This is the only proof that we have that there are infinitely many primes, which are sums of three cubes. So it's really impossible to put the second grade cubed. Sorry? It's impossible to put the stress cube plus minimum IQ. Okay, we'll get to that. Okay. So that's a good segue. Because very quickly, right, if you look at the date, If you look at the date, this is 2001, and this is 2002. And this is a published date. It's not even like, yeah, like this work could have been done like a month after the previous one. I don't actually know. But suffice to say, it was really quickly generalized to cover every binary cubic form where it could possibly apply. Obviously, you need it to be irreducible, and you also need this congruence restriction. Because if it's actually congruent xy times x plus y mod 2, then it's always going to be even. Then it's always going to be even. And even numbers don't like to be prime. Okay? So, yeah. That's the generalization. And the reason why I mentioned this result is actually this is this created a point of friction between John and Robert. Well, not between John and Roger, but between John and somebody else, I should say. And they never told me who it was. But at least some members of the community believe that Keith Brown's theorem is strictly better. Brown's theorem is strictly better because it can be generalized immediately. It took basically no time to generalize. It took basically every binary cubic form. And I'm talking about the corresponding generalization today in 2022, 24 years after the Friedland derivatives result. So there's a bit of a time difference. Okay, so for some time there was no progress until 2015. And then Keith Brown and Chen Nan Li proved the Brown and Chennan Li proved the following. So, if you squint, okay, well, what is the difference between this thing and the thing that we just saw? It's actually this variable. Okay, so of course, p always means a prime in number theory. So, before, I think we used the letter b, b was allowed to be any integer, but here I insist that p has to be prime. So, this corresponds to, you get an extra log factor here. And if you look at this error term, it's slightly worse because instead of a log log. Because instead of log log x, you have like log x p epsilon. Yes? Sorry, what is this? Lambda? Oh, this is the same, it's a small angle function as before. What is it? So it's equal to log p if n is equal to p to the k for some k. It's zero otherwise. So kappa is, yeah. Kappa is the same as if the integral for the four. So really the only difference is this log, right? That's exactly the factor you expect because that's the relative density. Factor you expect because that's the relative density of X. Okay, so the Heath-Brown-Lee theorem is an amalgam of the Friedlander-Welt-Wagnetist theorem and an earlier theorem due to Fury of Audience, which says that, oh, sorry, that should be a P. Yeah, that should be P. It's right here, but that should be a P. Yeah, these two should be the same. They should both be P. And if you, it's easier, right? Instead of having this to be like a prime square, you just make it a prime. Like a prime squared, you just make it a prime, then you get this kind of asymptotic formula. And kappa prime is some other positive constant related to the area, like a real density, if you will. Okay, so that's a picture of Fouvry and Shenyan Li. Actually, it met Fouvri for the first time just last month. Okay, so despite the passage over two decades, as of 2021, which is last year, the 21, which is last year, the analogous generalization to the original Friedman-Derbonius theorem, akin to the generalization obtained by Heathrow and Lorenz, has not yet materialized. So this is what I want to talk about today. So during this time period, maybe the first time I seriously thought about this problem was 2017, I've heard different things about possible reasons why the Freelander of Arnietz theorem. Why the Freelander of Arniette's theorem is more resistant to generalization than Keith Brown's theorem. Okay, so these are some of the reasons that have been brought up to me by various people over the years. So first, the lack of unique factorization, right, because the Friedman-Revanius theorem works over the Gaussian integers, which does have unique factorization. Makes some of the multiple identities troublesome, right? Because they really needed some really clean and nice identity. Really clean and nice identities to start a process. So maybe you just lose right out of the gate, right, and you can't get it started. And the harmonic analysis seems to require positive definiteness, right? Because if there's a section in free line of volume, I think section six, it's all about counting points in like an ellipse. Well, that's got to be positive definite. So if you lose positive definiteness, maybe things get out of hand, right? Because now once you have these cusps, Because now, once you have these cusps, maybe things aren't doable anymore. Okay, the third one is just kind of like a cop-out. Maybe all arguments are so delicate that it seems impossible to discuss them in a general setting. So what I mean by that is that whenever you read an algorithm theory paper, there's usually no road sign. You just keep going forward, you read one lemma at a time, one proof at a time, and it all seems okay, it works. You have no idea why it should all fit together. Why it should all fit together. And at the end of the theorem is proved. Okay, and if you want to try to generalize, it's like, okay, if I tinker with one thing here, is it all going to fall apart? Probably not, but it could happen. So that was a real barrier. So what do you think is the most pressing issue? Like, do we have, out of one, two, three, do we have like Okay, we don't have to do a poll or anything. You can answer the question for yourself. Is none of the above also an answer? So the answer is none of the above. Okay? And the reason is, and it's none of the above in a subtle way. I don't think anybody, I think everybody thought it was one of the three, but they didn't see that it's really hard to see what the true difficulty actually is. Because I don't think anybody actually tried. Actually, because I don't think anybody actually tried to seriously do it, except for me. And to be fair, I also missed it until the proof fell apart and I had to fix it. Okay? So yeah, I think this is out that the arithmetic structure of the Gaussian integers is used in an essential way by Fregon Monians. It's such an essential way that I don't think even they. I don't think even they fully understood how subtle this part is. I mean, obviously, they made it work, but they don't perhaps fully appreciate just how much every single piece was relevant. Okay, and this subtle piece seems to be missed by the vast majority of people who read the paper. At this point, I've never come up with anything. Yeah, I've never had any conversations with anyone prior to me writing this paper that discussed the point that I think is the most subtle. So, these are the properties that they needed to use of the Gaussian integers. Okay, so you need to have class number one, because that's how you get the identities in the beginning. And this is the one that's really special. The norm4 of the ring is the same as the norm 1c. Okay, that means that it has to be just the Gaussian integers and nothing else. And this one also says it just has to be the Gaussian integers and nothing else. Because, especially this one is like, why would you need this? Well, it turns out that. Well, it turns out that in the Gaussian integers, you have perfect quadratic reciprocity. You can always flip up and down without introducing the twist factor. And that was using their proof. Like, it's buried in some lemma somewhere. Like, it didn't emphasize it, but it's there, and they really needed it. Okay, so their artists really were tailor-made just for this one ring. Okay, so in a way that's Pete Brown. Way that Pete Brown's argument was not just made for Z adjoint cube root of 2. So that's kind of the difference. So this is the theorem that I proved. I didn't say it in terms of asymptotic formulas because, unfortunately, I also didn't get something that I will consider to be the gold standard, like the Free Hunter Vanius theorem. So I just say it in simple terms. So let F be an introduce binary quadratic form, satisfying this congruence condition. This is just to remove trivia. This is just to remove trivialities. Otherwise, if this happens, then if your second variable is odd, then it's always even. And even numbers don't like to be prime very often. Okay, then there are implemented primes of the form f of AB squared or f of AP squared, where p is a prime variable. Okay, so this is a simultaneous generalization of Levant Lanietz and Heath-Brown-Lee to arbitrary white prime forms as far as you can expect the theorem to be. Forms as far as you can expect the theorem to be true. So, first, the positive definitive assumption is not required. It turns out to be nothing, like that, it's actually not even relevant, not really relevant. Yeah, and the class number turns out to be, it's annoying, but you could easily make it work. So, neither of those issues turned out to be difficult at all. Okay, so I didn't state the asymptotic formula. I didn't state the asymptotic formula, but I because one thing that I was able to do was that I let me just see if I can go back to the Kief Brown-Lee result. So remember, Kiefrown-Lee had this slightly worse error term. I kind of just got it to work so that it's log x over log x. So if you're not an analog theorist, this point could not matter less to you. But for the analog theorist in the audience, this turns out to be like a point of pride almost. I'm sure that Keith Brown and Lee could have done it if they thought about it harder. They probably didn't care at that point. So basically, the proof kind of breaks down into three components. So you need to do some algebraic number theory to understand the structure between classes of ideal numbers. This is a substitute for having class number one, which is, you know, the situation is more complicated, but not so complicated that we can't understand it. We can't understand it. And you do analytic number theory, right? Because the whole reason why this polynomial, you can actually prove such a theorem is because it's not geometrically irreducible. It's basically like a specialization of x squared plus y squared with splits over c. And it has some sort of multiplicative structure. And multiplicative structure, roughly speaking, is how we do prime number theory. Like, if we don't have Number theory. If we don't have any semblance of alternative structure, then we're just kind of dead in the water. If you have some ideas, make it work, that would definitely tell me, because that would be a big breakthrough. The third one is the one that people didn't think about before, is that there's actually a linchpin, right? And the linchpin is kind of small, right? It just kind of ties two pieces together. It's not very flashy. But you need it, because if it's not there, everything falls apart. Okay, so let me just say that in the Heathbrown Moreau's case, the algebraic structure and analytic structure are almost independent. Once you set up the algebra, the analytic machinery doesn't even see the algebraic structure, so everything just pushes through. But so they didn't really have an essential linchpin. They're kind of like two independent pieces. But for us, there really is a linchpin that needs to be set up. That needs to be set up. Okay, in particular, like the Heath Brown, in Heath Brown's X2 plus 2YQ paper, the analytic machinery really only depends on the Z module structure. It doesn't see any of the arithmetic, really, with the ring of integers. Okay, so really it's this linchpin that, you know, that where I did anything. You can think of numbers of that. Okay, so this is this project builds on some ideas from my earlier. Project builds on some ideas from my earlier work with Peter Lamb and the Mars Schindler, where we did the analysis. Basically, we generalized proofread of audience instead of freelander of audience. And in that paper, we still needed the positive definite assumption. So at that time, I didn't think that you could do it for indefinite forms. But once I dug a little deeper, I think maybe it was actually Peter who suggested that the positive definiteness wasn't essential. But yeah, it turned out he was right. Okay, so let me. Okay, so let me very quickly blast through sort of the structure of the proof. So I'm very glad that the one talk that talked about CIFs in this conference other than mine was right before. So we're going to talk about CIF theory. CIF theory is the only way to do prime number theory asterisks, right? Because every time we want to detect crimes, we have to rely on some sort of CIF. Okay, so Bomberi. Okay, so Bomberi came up with what's called an asymptotic sieve, but he initially devised it to detect semi-primes. So, you know, numbers having a bounded number of prime factors. And so obviously that was very influential, especially on John and Avoniets, who also collaborated quite a bit with Pomberi. So eventually, John and Avoniets realized that they could Bonniets realized that they could refine the asymptotic sieve, right? And to detect primes of this shape. So here is another reason why I think John and Ivanza's work can be thought of as a capstone for 20th century prime number theory. Is that, yes, this is their main results, but in a companion paper, which was published in the same issue of The Annals, they actually wrote down like a theoretical Down, like a theoretical framework for a prime-detecting SIF that actually will pump out an asymptotic formula, provided the pieces are in place. And as far as I know, that is like the first time somebody wrote down like a recipe for giving you primes. Because analog theory papers tend to be very ad hoc. Like I said, they just state the theorem, you know, lemma, lemma, lemma, lemma, proposition, lemma, lemma, lemma. And all of, they seem to have nothing to do with each other. And okay, theorem is true. I'm like, okay. Yeah. Okay. Yes. All right, but how do I do it the next time? Well, it's hard to say. But they really gave a very general framework. Of course, verifying the assumptions of the CIV are, in practice, extremely difficult, and you have to do something, you have to get really lucky for any of it to work. Okay? So the output of the Bonberry sort of 300 Bonians type sieve is an asymptotic formula for this sum, right, where you take an arithmetic sequence. Where you take an arithmetic sequence, you take the support to be on the primes, and then you have this weighted sum. Okay, so one thing that any prime number theory talk will talk about is the so-called type 1 and type 2 estimates, which is English germany. When I say English, I mean like England, like not English the language. Okay, or level of distribution and bilinear sum estimates, which I think is from North America. I think maybe that's due to Bonberry. Maybe it's not fair to say Bonberi is from North America, but. To say bomb varies from North America, but that is sort of the difference. So, in order to get type 1, you think about a sequence that's defined like this, right? You basically sum, you think of this a n being supported on this interval, and you take the sum. And you want to say that if you restrict your variables to the convergent to be divisible by d, that the behavior should be controlled like this, where this r d of x is supposed to be small. Rd of x is supposed to be small. And importantly, like a type 1 estimate is saying that it's very small on average. Or it's small enough on average. So as is common in prime number theory, a type 1 estimate is never going to give you primes. It's never good enough. You need a type 2 estimate, which comes from an estimate of a sum that looks like this. Importantly, your beta n has to be like that. You cannot really impose any restrictions on your beta n. You basically take any complex sequence. You basically take any complex sequence. Okay, so the asymptotic sieve tells you that if you have these two estimates, you're going to get primes. Usually the type 1 estimate is either already there or it's easy, and it's not already there or easy, you just give up. If you can't do type 1, there's no way you're going to do type 2. And so usually the difficult part is type 2. Okay, so like I said, the type 2 estimate in Teeth Rounds paper. The type 2 estimate in Teeth Round's paper is basically independently of the great input, but it's not the case in freeboundary models. So, this is the identity that I mentioned. Whoops, where did I go? Yeah. You need some multiplicative structure out of something like this. And that really depends on the factorization properties of your polynomial. Okay? So this is identity. You could break this up into a sum over, so this is like the norm on the Gaussian integer. Is like the norm on the Gaussian integers, and this is the square indicator function. So this is zero if it's not a square, and it's one otherwise. And this is like the real part of w times z, or w bar times z. Okay, so this, like I said, this is the identity you needed to get started with. Okay, but it's actually not that hard to generalize because, actually, because it's already written down in heat-branded rows, right? If you have, in general, class number h, then you have h. Then you have H sets of ideal class numbers, and each of them are isomorphic OK at Z modules whose elements correspond to integral ideals OK in a given class. So as long as you fix the classes, the multiplication behaves in a completely controlled and understood manner. So the multiplication between elements of the ideal classes preserves the class. So like if you have an element in class J and that element in class. You have an element in class J and that element in class K, their product would be in the class JK. So you can also choose your basis for these ideal class numbers as you please. So in the Gaussian integers, one thing that's very subtle is that there is only one basis for the Gaussian integers. It will be insane to use any other basis. But in general, you can choose your basis. And there are various criteria for being a nice basis, and you just follow those. Okay, and keep in mind that we won't have to deal with a pair of ideal classes at a time, because we don't have to care, we'd have to think about multiplication between every pair of ideal classes, but we can divide and conquer one pair at a time. So this is basically the appropriate algebraic framework, and the analytic machinery is basically almost all done. Most of the stuff that I needed to use was directly importable from either Freedom Drive Audience or Free Front. From either Freedom of Audience or Free Front Lee. And yeah, when I told Roger about this, he was shocked that I was able to recover salvage so much without changing basically anything. So that's a testament to the robustness of their methods. Okay, so the treatment of bilinear sums requires some ideas that goes back to Selberg. You basically start with harmonic analysis. Okay, and you basically do this really. And you basically do this really difficult thing of trying to detect squares, and you flip it to talk about congruences of quadratic forms. And that's a much easier problem, but they're actually equivalent. But it can't be that easy, right? Because then, you know, my talk will be really short if that's the case. It turns out that these quadratic congruences, like the moduli, are moving in such a way that it requires a lot of work to even set them up. So, another thing about analytical methods. So, another thing about analytical theory is that, you know, at some point you introduce small, medium, and large, and they never mean the same thing from talk to talk. So, you always have to ask, what do you mean by small, what do you mean by medium, what do you mean by large? So, I will tell you. So, the treatment of small moduli is usually the easiest case. In this case, what do I mean by small? Well, it's when Sega well fish works, right? So, your moduli only log power. And here, you can actually get very precise. And here you can actually get very precise bounds because you actually get asymptotic formula for individual sums. You don't have to average. Okay, so this middle range is huge. You get from log powers to just a little, you shave a log power off the main term. Like this is a massive range. Keep in mind, we're thinking multiplicatively, not additively. So you should think of like this is more than x to the one minus epsilon. So this is zero, and this is like one minus epsilon. Okay, this is the line share of the work. And because this theorem is so... And because this theorem is so robust that I think, well, I don't want to speak for them, but at least in their treatment, they just kind of, oh yeah, they just kind of slammed it in there and didn't mention much more. But I think this theorem is like just magnificent. Like, this is the estimate. I'm really running low on time, so I don't have time to... But the point is, you get some complicated estimate like this, but it's always big O of D. As long as your D is at most Rx. As long as your d is at most rx. Okay, and very importantly, I should emphasize that this result, there's no hint of the Gaussian integers here. This is just depending on the Z module structure. This is very important. Okay? So the final range is you have to go up to actually X. Okay, so this is the bulk of the work. They devoted about 10 sections in their 96-page paper to just this range. Okay, so to kind of like To kind of like motivate the ideas here, you basically think about the duration hyperbola method. So, summing over a long variable is really bad, summing over two short variables whose lengths add up to the original length is really good. So, if you try to estimate this naively using calculus, you would just get x over log x log x, but you wouldn't get the secondary terms. Okay, and the reason is that you traded your log. And the reason is that you traded your long variable for a short one. Okay? So I'm going to do some self-promotion here. So a recent application, this hyperbola method, is in this paper of mine, where I use it to count monitoring abelian cubics. And this bound is, I think, very surprising. I don't think it was after we were predicted that it's basically the same as the, like that one family gives you almost everything. Okay? So, Okay, so you want to do multiple canonical theory, right? You want to break up your main term somehow, and they needed to do this. So, this is the thing that I want to ask the algebraic people in the audience. It's like, what would motivate you to come up with this? Okay, what is this? You take a Gaussian integers. Well, why not just compute the Jacobi symbol of the components? You could do it. It's well defined, but why? Like, that just seems like it doesn't have anything to do with anything else. To do with anything else, but that's exactly what they needed. Okay, and importantly, it has this twist factor. This is a pseudo-multiplicity formula, right? If this epsilon and this CWZ wasn't there, this would just be straight-up multiplicativity. But you need this extra factor here. And let me just, and I know my time is up, so basically figuring out what the CWZ should be in general when it's not the Jacobi symbol is basically the point of the paper. It's an ugly. It's an ugly object, but at the very end, all the cables get plugged in properly and the machine works and outputs the theorem. Thanks for listening. Any questions for the speaker? I have a question about the definiteness situation. So in Heathcrown, This situation. So in Heath prime result, you have an influencer prime to form xq plus 2y. Is the assumption here, like the assumption here that x and y are both positive, or can you have like... Yeah, he did assume they were positive, but I think that assumption can be removed. It's just that... In fact, I believe if one works a little harder using modern technology, one can get the natural asymptotic formula. But it's one of those things. But it's one of those things that the amount of work that you have to put in and the result that you get might not be in proportion. But I believe it's entirely possible to do. So in your result, you can prove that like f of a, b squared is a positive prime number under the assumption that you stated. Even if f is negative definite. Well, not negative definite. It has to be positive definite or indefinite. Okay. Yeah, I think there was maybe a question on Zoom. It's not quite different. On Zoom, like to ask. I saw a hand raised on the chariot. Maybe that was a clap. Okay. Any other questions in the room? So just asking about this Yakobe Kubota symbol. If you could flip back to the slides. Oh, wait. Forward a little bit. One more? One more? Oh, sorry, forward. I mean, you have this formula with this weird property of the thing. Is that reminiscent of something like a one-co-cycle condition? Well, I don't know. I mean, in their case, this CWZ is just this thing. It's just a Jacobi symbol extended the Gaussian integers. So in this case, very, very concrete. And yeah, off the top of my head, I don't know. Okay, that's why. Okay, that's why. What do these classes represent? I guess. So this is not a class. This is, I defined the previous slide. Oh, simply. Okay. Gotcha. Okay, thanks. No problem. Any other questions? Well, before we close the proceedings, I would just like to thank I would just like to thank all the speakers who have contributed so much to this event over the last week, our last speaking day. It's actually kind of awesome. I hope everyone has a safe trip and see you again sometime soon. 