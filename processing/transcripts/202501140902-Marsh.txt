Oh sorry. Oh no, that's not perfect. I just want that data. I feel like that is. Okay, welcome everyone to day two. Hope you are enjoying your work so far. One quick announcement before we get started with the talk. Small change in schedule for the remainder of the workshop. So yesterday we did two hours of full group discussion and then two hours of precaut session. We're going to modify it a little bit. So we're going to do an hour and a half of full discussion. Then we'll have some free time. Discussion, then we'll have some free time for people to just, you know, chat or do whatever they want to do or whatever. And then we'll start the breakout sessions a little later and do them for an hour. And obviously, you know, if you're having a good time discussing, please continue. But just wanted to modify that to allow for more like free form discussion. And I'll update that on the website. Okay, so for our first talk of the day, we're very happy to have Dottie Marsh take away. Yeah. Yeah, hi. So I'm going to talk about fuzzy dark matter of observables. I'm not going to talk anything about the connection to string theory here. That will be covered by Nicole in the later talk. So just keep in mind if you have string theory related questions, they're going to come later. I'm not going to talk about them at all. I'm going to have a completely observational bit of a change from the theory focus of yesterday. Yeah, I'll just get. Yeah, I'll just get started straight away. We've already talked about different end-universe scenarios. I'm going to be thinking here entirely in the pre-inflation scenario, for the closed string axions that we talked about mostly yesterday. So the axion initial angle theta has just some homogeneous value throughout the observable universe at the initial time, which is a free breath thing. The equation that you need to solve to compute the relic density is just. To compute the relic density, it's just the Klein-Gordon equation for a homogeneous field and an expanding background with whole parameter h, and that's just a dapharmonic oscillator with a time-dependent friction. And you can solve that exactly, it's a Bessel function, or you can solve it numerically. Next infield looks like this, it starts with some value, and then it undergoes dampened oscillations. At the damped oscillations, we need the energy density scales like cold dark matter, like eight to the power minus three. At late times, but at early times, the energy density is a constant. So you have a transformation. Density is a constant. So you have a transition in the behaviour from dark energy, like to dark matter, like. And that occurs at this time here when the field becomes dynamical and when the mass is avoiding the Hubble parameter. We'll call that the Hubble parameter is falling over time. And I'm going to be considering in this talk exclusively cases where the mass is a constant as a function of time. Won't say that. Okay, and a useful approximation for the relic density. Approximation for the relic density and to give you a sense of the scales that are going on is that the energy density at the time when the oscillations begin is approximately given by the energy density at the initial time, which is just, for this approximation of the potential, is harmonic, just the half m squared phi initial squared. There's a transition when roughly three times the Hubble parameter is equal to the mass. So early times, any time before, A is the scale factor for me, by the way, I'm a cosmologist. Factor for me, by the way, I'm a cosmologist. For any scale factors smaller than the scale factor when oscillation happens, the energy density is constant, we behave like dark energy, equation of state approximately minus one. And at late times, once the oscillations begin, the equation of state is approximately zero, and we behave like that matter. And using that approximation, you can work out left and out density as a function of the two parameters, the initial field value, so roughly the symmetry breaking scale. So, roughly the symmetry breaking scale, and you have to show the k constant f and the mass. And there's two free parameters: one thing that you want to match, the dark matter density. So if you want to get all the dark matter, you're restricted to a parallel relationship between these two parameters. But you can also, if you have smaller values of the initial field, you will have smaller contributions of the belt matter density. And for the sorts of masses that I'm interested in in this talk, In this talk, all the way from, I'll talk about some physics towards the end, around 10 to the minus 12 EV, all the way down to or below 10 to the minus 24 EV, you get the right, the full dark matter abundance for initial displacements at or around the gut scale, but some sort of significant one percentage fraction for decay constants, you know, in the sort of things 10 to the 14 to 10 to the 17. Okay, so that's all the introduction. I'm not going to dive into the physics. I'm going to start with cosmic structure formation. I'm going to start with an estimation of whether we can estimate facts of ultra-like bosons. And the estimation starts by thinking about when does that transition from behaving like a cosmological constant to behaving like dark matter happen. So let's look at how the Hubble parameter evolves as a function of. Evolves as a function of temperature and compare that to known cosmological scales. So here's a nice figure that Sam Hoof made from a review that he and I wrote. So here I've looked at the scale factor, which increases from left to right, along with cosmic time, and the temperature, which decreases from left to right, and is also a measure of cosmic time. And the Hubble parameter, if I go from temperatures of a GeV down to temperatures of 3 Kelvin, today the Hubble parameters are. 3 Kelvin today, the Hubble parameter falls and goes from 10 to the minus 5 eV in the early universe down to 10 to the minus 33 EV today. And I can relate that to the co-moving size of the Hubble horizon. So what sizes of objects are in causal contact with each other, and the co-moving horizon grows, and it goes 50 days. The co-moving horizon is a few gigaparsecs, size of the observable universe. Whereas if I go back to, as I go back. As I go back in time, the co-of-coupled horizon is smaller and smaller, and some relevant scale would be megaparsec, the size of the horizon. And when galaxies are formed, the typical distance between galaxies, distance between the Andromeda, as you go further back in time, it corresponds to smaller and smaller structures being formed. So, the first bit of estimation I'm going to draw on the next slide, I want to point out to you the Hubble scale. The Hubble scale at matter radiation equality, roughly 10 to the minus 28 electron volts, and the Hubble scale today, roughly 10 to the minus 33 electron volts. So also bosons transition to behaving like dark matter when the field begins to oscillate, when H is avoided at M. We know that the dark matter is behaving like dark matter today. It's pressure which is the current universe in its following structures. So the dark matter had better be heavier than tech than the whole parameter today, ten to the power of seventy three occurring volts. 10 to the power of 73 a half volts. That's equivalent to saying the Compton wavelength of dark matter should be smaller than the size of the observing universe to localize it. That's your roughest bound, and that's going to define the lowest mass that I'm interested in for anything that forms structure in the universe. We also know that dark matter was present at mass-radiation equality. It's the thing that defines mass-radiation equality. There aren't enough baryons to do that. So, by writing down the Friedman equation in the right way, saying, Equation in the right way, saying that I know the temperature of mass radiation equality is about an electron volt, the redshift of matter radiation equality is about 3400. We know that the mass has to be larger than the Hubble parameter of matter radiation equality, 10 to the minus 28 electron watts. And they're two things that you could know without knowing anything about cosmic production. Dark matter definitely has to be heavier than this value. To go one further than that, To go one further than that, we have to actually ask how does structure form in a model where we only have ultra-light scalars. And the relevant thing to think about here is something called the mean scale. So if I perturb the Klein-Gordon equation at linear order, and you'll also perturb the metric at linear order, and work out the coupled equations of motion, and take some limits, this is the relevance equation that you end up with, where delta is the overdensity parameter of dark matter. That dark matter is something that's very small in the universe and grows to become large when non-native structure formation begins. And it takes the form of a damped harmonic oscillator, as everything does in cosmological preservation theory. But now the effective mass term of my damped harmonic oscillator has a positive piece and a negative piece. A negative piece comes from Pottshond's equation, 4Ï€g rho, times the over density. So that's the part that's driving the growth. So that's the part that's driving the growth of structures. It leads to power law growth of structures because of the damping term. But you have a positive term in the effective mass squared, which arises from the field equations, from the gradients of the, from the gradients in Klein-Gordon equation when you go to Fourier space. And it looks like an effective sound speed in terms of this parameter for the overdensity. So these two terms. So these two terms fight against each other, and if k is large, we're talking about small-scale structures, the pressure term wins, if k is small, then the gravity term wins and you get growth of structure. So large structures can grow and small structures cannot. So the effective sound speed is given by this expression here in some particular limit. And so you can work out the scale k for which wave numbers smaller than this, structures large. Numbers smaller than this, structures larger than this, form, and wave numbers larger than this, structures smaller than this cannot form, and his chain genes. And the relevant thing to consider is the gene scale equality, which is roughly going to be a megaparsec for this reference mass. Some intuition for this, which I find useful, if you're not used to seeing fluid equations, is to just consider, and this is very much a model, an observer. An observer moving away from considered an observer and an axion moving away from you on the Hubble flow. So here's Hubble, and it's the axion, and they're moving away from each other, and they're separated by some distance part. As they move further away, the Hubble flow, the Hubble velocity increases. The velocity is h times distance. And the axion that's moving away from us, I can't localize this axion, I can't say that it's inside any. I can't say that it's inside any bound structure if the separation between me and the axion is smaller than the Brogley wavelength. I can only localize it when the separation is larger than the Brogley wavelength. So let's just plug in this velocity here. And this intuition gives you an intuition for why the GM scale happens. If the action is moving away from you with the humble velocity, the Broadway wavelength. The Brody wavelength has to be small enough that you can actually localize it, which actually gives parametrically and to an order one value the value of the June scale from full cosmological perturbation theory. Tonian cosmology, surely. Okay, so to go one step better than that, I'm going to have to actually solve Solve equations of motion with this equation of state that comes from the homogeneous pressure. This appears in the Friedman equation and means that ultra-light axial dark matter affects the expansion of the universe in a way that's different from cold dark matter. Cold dark matter is equation of state zero for all time, light dark matter is equation of state minus one early time, zero late times. The effect of this sound speed means also the density perturbations in ultra-light dark matter don't cluster in the same way. Light dark matter don't cluster in the same way as cold dark matter, which has zero sounds to be efficient. And so the growth of structure and the background expansion are both going to be different in fuzzy dark matter than they are in cold dark matter. So let's just compare these two parameters to the two node quantities in the universe. So CDM equation of state zero, sound speed zero. Baryons equation of state zero. Sound speed changes from a third when they're coupled to the photons to a zero and late band. Photons equation of state zero zero zero Photons, equation of state on sound speed one-third. Cosmons are constant, equation of state minus one. And sound speed, it doesn't cluster, there are no perturbations. You can arrive by that right sign of sound speed of minus one, but it doesn't really make sense. And our axions are ultra-like that matter. It doesn't look like any of these things. And that's why we can tell the difference between a cosmology that has all sorts of axes and components of ultra-like axions in to standard lambda CDM, which only has this stuff in it. Which only has this stuff in. It doesn't look like anything in ordinary lambda speaker. There it is. It will try to put it in dark matter, equation state minus one at early times, so at late times, sound speed effectively minus one at early times when it can't cost that, and this effective sound speed that I rub that area at late times. So to get precision constraints using this, we need to, so cosmologists measure two-point functions and Measure two-point functions on the sky in Fourier space, and we compare to theoretical predictions and use Bayesian parameter estimation. Typically, Markov Chain, Monte Carlo, Britain's parameter. The cosmic magnetic background, which I'm going to start with, measures, is sensitive to the expansion rate via the Sax-Wolf effect at late times, so the time dependence of gravitational potential wells, and the sloped. And the silk damping effect at early times, so the size of the sound horizon through which baryon cooes cosmos. Whereas late-time observables, the galaxy power spectrum, for example, or I'm going to talk about the abundance of high-register galaxies, are sensitive to the late time expansion rate and the growth of structure. So, late time observables are more sensitive to this thing for sound speed, whereas the CMB is more sensitive to this transition. So, let's go back to our estimation. So, let's try let's let's put these scales on onto onto a graph. So you see axial mass on a log scale, what physics is going on and what the value of the Hubble parameter is. What the value of the Hubble parameter is, we're going to compare the mass to the Hubble parameter. So BBN occurs for a Hubble parameter somewhere around 10 to the minus 15 EV, maybe slightly smaller if you think BBN doesn't actually finish until 0.1 MeV. But roughly an MeV temperature is over 10 to the minus 15 EV. Anything with a mass larger than that, the abundance of this action and all of its physics, And all and all of its physics can be changed by unknown UV physics. We don't know anything about the universe prior to me yet. And this is something that will come up in Nicole's talk. Bubble parameter today, as I've said, is 10 to the minus 33 EV. Matter radiation quality, 10 to the minus 28 EV. Stuff lighter than this are going to show up in sort of like dark energy or neutrino light. They're going to affect very large-scale structure formation and late time energy. Very large-scale structure formation and late-time expansion of the universe, whereas things heavier than the public scale of matter radiation quality are really going to form structures in the way that dark matter does. The nonlinear scale, the Hubble parameter corresponding to non-linear structure, the horizon size of nonlinear structure formation is roughly 10 to the minus 24 eV. So things in this range, 10 to the minus 44. Things in this range, 10 to the minus 24, 10 to the minus 53 electron volts are going to affect linear cosmological scales. And that's good because linear theory is easy and precise. And then everything in the window below here, below 10 to the minus 20, sorry, higher than 10 to the minus 24 EV, I have to worry about non-linear physics, that might affect galaxy formation, for which I can use the halo model, look sort of warm dark matter-like, and then you know, this sort of true fuzzy dark matter regime. True fuzzy dark matter regime, if you like, where you know you can be a really large fraction, maybe all of the dark matter is roughly a mass that gives you a broad wavelength that's larger than the size of a dwarf cereal galaxy. I'll come back to this point at the very end. And I'll also come to this point about solid heads as well. Okay, so precision cosmology. Precision cosmology and CMB. So here's the CMB. What's going on? First acoustic peak, angular size of the sound horizon. This is the two-point function of the temperature in spherical coordinates. So what's going on? Here's the angular size of the effect of the first accretive peak. The large angular scales are sensitive to the distance to the CMB and to the late time expanding. And to the late-time expansion. So, my very lightest axions of affecting the late time expansion rate are going to change this bit of the CMB. Whereas the higher acoustic peaks damp away, and that's silk damping, diffusion damping, and that's sensitive to the expansion rate during the radiation endpoint. So, this is the silk damping scale. It's given by some integral of the toxin scattering, and it is sensitive to the expansion rate, the change of the scale factor. Expansion rate, the change of the scale factor. So all of this part of the CMB probes the early time expansion rate of the universe. The height of the acoustic beaks probe what matter content there is in the early universe. Let's have an estimate and then talk about how the precision constraints are arrived at. So consistency with the lambda CDM expansion rate, the same thing as consistent with the lambda CDM expansion rate up to a redshift of 10 to the 5. So dark matter must have been behaving like dark matter. Have been behaving like dark matter, at region of 10 to the 5 precisely. That gives you that you should expect a rough lower bound on dark matter mass B of about 10 to the minus 25 electron volts. To do this in a precise way, you have to solve the Boltzmann equations with these perturbed equations of motion and effective sound speeds and so on. You should lock up J. Monte Carlo with some parameters and compare it to the flight light machine. And to do this in this part of the talk, In this part of the talk, I'm going to be using Cosmosis, which is a parameter estimation code, and Axiom CAP, which is the bottom of the regression plot. So, CMB. So, as I mentioned, the entire is heavier, they're at 10 to the minus 27 EV, reflecting the overtime expansion rate. So, here's just some models where I'm varying the mass of the entier, and you can see, as advertised, they change the early time expansion rate, and so they change the height of the acoustic beams away from the line. Of the acoustic beaks away from the CDN value, and such that you can no longer match the data points with very small error bars that you can barely make out on the scale of the sugar. So putting in too much dark matter that's very, very light, wrong acoustic picture of the CMB, excluded. On the other hand, if you're lighter than the Hubble parameter at the time when the CMB was formed, 10 to the power of 27 UV, don't change the silk damping scale, because that's Don't change the silk damping scale, because that stuff's already frozen in, but you change the distance, the size of the size of the sound horizon, the distance to the first acoustic peak, and your scale of the first acoustic peak, and this sex wolf affects time evolution of the gravitational potential at both times. So I can now constrain the density in axioms, omega ih squared. This is the thing that should be 0.12 if you're all looking for quantum dark matter. 2 if you're all over the cold dark matter, and I can constrain it in bins for the mass. So at sufficiently high mass, where sufficiently high in terms of the CV is 10 to minus 25 EV, the data points here are samples from that block of chain Monte Carlo. And at sufficiently high mass, you can get the cold dark matter density, omega ch squared, down to zero, and the axiom density up to 0.12, the observed value. But at low mass, there's no degeneracy with cold dark matter. The cold dark matter has to be basically 0.12 everywhere for low mass. On the other hand, if I now colour my points by the value of omega lambda, you see that at high mass, I can't change omega lambda, there's no degeneracy with dark energy. But at very low mass, around 10 to the minus 82, 10 to the minus 33 eV, I can start having very large omega AH squared by. Large omega ah squared by reducing omega lambda into this one. So at the lowest masses, you're degenerate with dark energy. And that's why you get this sort of characteristic shape of constraints where you're strongly constrained in the middle, you generate with dark matter on one side, you generate the dark energy on the other. And this is now, if I put that on a scale of mass versus cosmic density, the Planck CMB excludes some regions. CMB excludes some region like this. If I fix my decay constant to be at the gut scale, I expect to be in some sort of region like this. And future CMB will do a little bit better. And this is just from the primary analysis object. Ollie, last question. How sensitive is that height exclusion to the assumption by making that mass is a hard UV mass, which is not very dream? Um I don't know how it would change if I if I check if I change if I change. I can certainly cop some models where it does change. Yeah. I don't make a complaint about how. As long as the masses become constant before you start oscillating, you won't care about that. No, no, clearly. No, it's during oscillation. I can get to anything from that. So I agree, this is a fine tube model, but nevertheless. Yeah, I don't know how the construction changes in that case at all. It's a good question. Okay, another thing that you can do with these very light. Can do with these very light fields is cosic biofringence. If a very light field is coupled to photons, then it can cause cosmic biofringence. So what's cosmic birefringence? Cosic biofringence is the rotation of the CMB polarization angle between C and B, and when we observe it today. So we write the CMB polarizations in terms of E and B modes, where E is divergence and B is curl type. And if you rotate. B is KL type, and if you rotate the angle of polarization by some angle beta, then you mix up these divergence and KL polarizations. And apparently, this is something that we might have observed from the Paxium B. And such an isotropic birefringence can be caused by an ultra-light axiom, which is coupled to photons. And the value of the rotation angle is given by the coupling constant times the change in the value of the field between the C and B and today. The field has a constant value. The field has a constant value and then it changes and oscillates. So you can cause this uniform rotation if this drop happens between when the CMB was formed and when it rotated. And that fixes very, very, very well the range of masses that can give rise to uniform biofringings. Roughly between the Hubble primitive today and the Hubble primitive C and B. And you naturally get the right value. So if the coupling constant is alpha over 2 pi times. If the coupling constant is alpha over 2Ï€ times the k constant, the field value is the k constant times the angle, then the rotation angle is just the fine structure constant basically times the initial field value. The initial field value radian should be something of order one. So you basically get the observed value from a fundamental constant that we know, the fine structure constant. So this may be a hint that will A hint that ultralight axions are actually around, but notice that the effect is independent of the decay constant and thus independent of actually how much dark matter you seem to make up. Also, can I make a comment about that? Because this estimate was in the paper with the time for a group surgery. If you have multiple axons, of course, you can get a routine enhancement of this thing. So if you're trying, it's very interesting, if you're trying to get the right partner to be in the consistent constraints, I believe that it's better to split it. I believe that it's better to split it up into different pieces. You know, it could be that there's more than one axion moving and doing this thing at the same time, and that's an interesting thing. And that needs to be different flows, you know, for Wikipedia. Yeah, if you had random feature angles in the plane, it would be like root angle, like the random walk. But you can also gain pretty fair alignments. Reading is sort of default value, but you can get you better on the tackle. Okay, so going beyond the CMB, trying to constrain heavier masses, I'm going to start talking about the cosmic structure formation, clustering of galaxies. So you said it had to be higher than 10 to the minus 28 before, right? If you're all the dark matter. But in this regime, the effect is independent of the decay constant F. And it's independent of where. And it's independent of whether it is called a dark matter. It's completely independent of the dark matter. Because the dark matter abundance depends on the actual value of phi squared in physical units. So it depends on F, the dark matter abundance. But F cancels out in the biorefringent rotation because it only depends on on the feeder angle. I guess I'm not going on this. Obviously this is very important given the data is there and it's probably about these feeds of my hair. Uh So we have, one issue is Teak and collaborators were claiming you wouldn't have that coupled. In any scenario that is unified, you know, as you know, it was coupling to electromagnetism, so rather than something you want or something else like this doesn't exist, it's applying axioms, right? So one major issue... You can't do it for guts. Yeah, you can't do viable guts, right? I can think of Grace if it's true, it's telling us that the electric sector is in a different part of the gauge group than QCD. That's really. So, yeah, that's a very important point. That distinction between guts and non-guts was something that came up in Jakub's talk yesterday. So, we can say the first point. Okay, so moving on from the CMP to try and constrain heavier matters of light axions, I'm going to think in terms of this thing, the massive power spectrum. So, the mass of power spectrum P of K is the Fourier transform. P of k is the Fourier transform of the two-point correlation function of galaxies or anything, any structure. And so here it is, this is what it looks like in Lambda CDN. And we can measure it with lots of different things. So the CMB gives us an inference on it, but we can also try and measure it directly with, for example, the Solar Digital Sky Survey, or the Barrier Volcanism Spectroscopic Survey, Limar Forest, or the Dark Energy Survey, Cosmic Shield. And so the CMB is only sent. And so the CMB is only sensitive to measures large scales. So Planck lensing, for example, Phi Phi can't give us any measurement on wave numbers anywhere near close to an inverse megaparsec. So if we want to get better constraints than we got from the CMB, we need to think about things that are sensitive to the power spectrum on larger and larger wave numbers, corresponding to smaller and smaller scales, corresponding to larger and larger axiom masses. CMB probes large scales, galaxies probes smaller scales, and larger matters. Great. Consist the observed structure is consistent with the Lambda CDM model. Now, the way the data points are pulled onto here is not, you shouldn't just compute this thing and compare to these data points. It's really a bit of a heuristic visualization, however. And it drives the point home quite well that the Lambda CDM model, the black line. So, under the CBM model, the black line is consistent with observables, so we shouldn't mess with it too much. We shouldn't have too much dark matter around with an equation of state or effective sound speed that is non-zero. We shouldn't have too much fuzzy dark matter, or clearly this would go wrong in some way. How does it go wrong? It goes wrong like this. So, now I'm taking, instead of the power spectrum, I'm taking the cluster invariance delta squared, which is just k cubed times time. Squared which is just k cubed times times power spectrum. So I'm just tilting it up like this. And the cluster invariance, when it crosses one, it corresponds to nonlinear scales. So non-linear scales are roughly tens of megaparsecs separation here. And here I'm showing the effect of introducing some fraction of ultralight actions. So here I'm taking the mass to be 10 times 22 electron volts, the decay constant to be 2 times 10 to 2. The k constant to be 2 times 10 to the 16 gev, and I'm changing the initial theta angle. And as I change the theta angle, I have more and more density in these fields. And so, as I have like fields, I have this thing called the gene scale that means I can't form structure. So, that means that the fluctuation variance gets smaller and smaller. Up the theta angle, up the density of dark matter, increase the amount by which you suppress structure formation, decrease the fluctuation variance. That's the physics. Fluctuation variance. That's the physics. And here I'm showing just to guide the eye: the grey region is the range of models of this type that are consistent with the Lyman alpha forest as determined by Kashi-Kobayashian and collaborated here, which constrain at this particular mass should be less than 10% of the dark matter of. Have the dark matter above it. So when I increase ether too much, I get too much dark matter, and my coloured lines go outside the grey region, and that's inconsistent with the data. It's sort of heuristic way. So I'm not going to use Lyman off first to place a limit. I'm now going to use high-registered galaxy formation instead. So high-range galaxy form, so galaxies form. So, galaxies form from the growth of linear structures into non-linear structures. If your fluctuation variance is suppressed compared to length CDM, you have fewer galaxies than we have at once. And you can use this thing, the power spectrum, to try and compute how many galaxies you expect there to be using something called the halo model. And that's what I'm going to do right now. So this suppressed clustering of dark matter. Suppressed clustering of dark matter caused by light fields means that you will have fewer galaxies, and in particular, you'll have fewer galaxies at high redshifts. Structure formation is hierarchical, galaxies form first at high redshift, and then hierarchically plus state, and give us more galaxies that we've found. So, putting that onto scales, as I have been elsewhere in this talk, is a nice figure from this recent paper by Harrison Winch and myself. And Harrison Winch and myself and others. So here's his redshift on the y-axis. So this is going from today back in time as you go up and the scale, the wave number on the x-axis. So large scales at small k, small scales at large k. And you can see all of these different observables bottom here. So galaxy clustering, the two-point function of galaxies in, for example, Spanish digital sky survey, is only essentially Sky survey is only sensitive to low redshifts and relatively linear scales. The CMB lens, gravitational lensing of the CMV, is sensitive to deeper redshifts. The kernel for lensing extends to higher redshifts, that's because the CMV is the backlight and it gets lensed by everything coming forward, but also only to linear scales. Samely, primary anisotropies is a probe of very high redshift. Pieces of probe at very high redshift, but also in linear scales. Now, all of these other observables that are shown here probe larger wave numbers at smaller scales. So, weak lensing of galaxies is sensitive into the mildly non-linear regime. Structure formations in the Milky Way itself, how many sub-halos are in the Milky Way, sensitive to the deeply non-linear regime. But obviously, these are redshift. The Lyman alpha forest, which I mentioned briefly on the previous slide, On the previous slide, is sensitive to non-linear scales and intermediate high-related shifts. So, Lymanoff forest is the two-point function of the observed Lyman offer absorption feature in hydrogen. And the observable I'm going to use now is high redshift galvanity. So, high redshift, by definition, this is something with large redshift, and it's sensitive to the mouthy non-linear region. The Maudy nonlinear region. Mildly nonlinear is nice because I can get away with approximations of the Halo model. But you've got an additional lever arm that goes further out to higher redshift. And at higher redshifts, things are more and more linear, so you can trust this even more. Ultraviolet luminosity function. So the ultraviolet, so it means that luminosity function is like how many sources do I have omitting in the universe? Methink you reuse it. So these are the titaniums regarding an ultraviolet and the narcissist function is how many sources that you have. So I'm going to use Hubble. We used JWST data in this paper, but JWST does not have very many high-regular galaxies at the moment, and so you don't gain anything by using JWST at this stage. But in the future, JWST will improve the boundaries I'm about to show you because it measures, in principle, to higher education. Because it measures, in principle, to higher edge shift. But at the moment, it doesn't have anything to do with it. This is what the observable looks like. This is what the UV luminosity function looks like. So it has units of per cubic megaparsec, it's a density measure, per magnitude. So the x-axis, which has been cut, which I forgot and cut off, is the magnitude of the galaxies. So the fainter ones are here, and the brighter ones are here. And so the data of the And so the data, the whole data set, are the black points here. And the theoretical model, which comes from fluctuation variance power spectrum, pipe it through some standard procedure and work out how many galaxies there are of the coloured light. And so here I'm fixing an axion fraction of dark matter of 10%. The observable is at redshift 6, which is roughly the FOC of reionisation. And the column lines correspond to change. Correspond to changing the mass of the fuzzy dark matter. So if you're 10 to the minus 21 eV at 10%, you're consistent with these data. But if you go significantly below 10 to the minus 21 EV, say 10 to the minus 23 or so EV at 10%, this observable drops out of the domain that you know. And the observable, the luminosity function gets smaller when you have. Smaller when you have fuzzier dark matter because you're suppressing galaxy structure formation. Fewer galaxies, that's why this thing moves down. Fewer galaxies are redshift six. So you can use Bayesian parameter estimation, vary these parameters, and ask what the allowed range of parameters of dark matter fraction versus mass are from this observable here. And it looks like this. And it looks like this. So now I've got a sort of almost complete picture of constraints on the relative abundance of fuzzy dark matter versus mass. So the CMV constraints I talked about earlier are very precise. It's linear theory and the CMV is very well measured. So the constraints go down to a percent of the observed dark matter. And I showed earlier how this extends further to lower matters. Limar Forest, the COVID-19 results that I showed before, probe the smaller non-linear regime, matches up to 10 to the minus 21 EV, but at a sensitivity of about 10%. And these two regions are joined up by considering the ultraviolet luminosity function. The ultraviolet luminosity function is sensitive to masses that suppress structure in the Maori nonlinear regime and has a roughly 10% sensitivity to the dark matter fraction of such a dark matter. Fractions that you're not making. And here is a region that I won't say any more about, but we can discuss it in discussion or maybe in a breakout session, is a reported preference for ultricaxions from somewhere by one of my collaborators, Kieran Rogers and Vivian Poulam. Again, using Lyman alpha forest, but a different Lyman alpha forest measurement than this one on slightly larger scales. On slightly larger scales, there's a discrepancy between the amplitude of the CMV fluctuations and the amplitude of the Lyman alpha forest fluctuations that can be explained if the power spectrum occurs in a stable. It has a particular amplitude on large scales and a smaller amplitude on small scales. And that can be explained by looking at the spectral index in inflation, but it can also be explained if you have about 1% of the dark matter in. Have about 1% of the dark matter in, and ultralights actually have mass about 10 to the minus 14. So that's maybe a hint for some ultralight dark matter. And we can discuss. What is preference mean, Argentina? Preference means, well, like this is a closed cop, yeah, statistical preference. This is a 95% preferred region. I don't think Kia and Vivium competed the base factor for this one. And Vivian computed the base factor for this model over lambda CDM. So I don't know how much it's preferred over lambda CDM, but there is a preferred region in the context of the model. What is the darker shaded yellow squares? It's shaded by the value of the posterior, so that would be the maximum posterior. Why is it a disconnected region? Can can they not solve it's a con it's a connected region. It's a connected region. It's just a funny shape, circus sort of. Oh, yeah. Because you can only explain this Lyman alpha effect with 1%. If you're more than 1%, you can't explain it. You have too much suppression. But why is you still consistent with data? Why doesn't it turn into an exclusive? Because you're so this does. So you are consistent with the data. The exclusion's up here. So you're far from the exclusion. So, you're far from the exclusion. That was one of the aims of this work was to see whether the preferred region from bottom, Lyme, and alpha is consistent with HSTU VLF, but these data sets have not been analyzed together. Because we don't have the pipeline, the tools to at the same time analyze Hubble and Lima First. So, it's not a that so that it's it's not um a um it's not a global fit sorry if i put those yellow that yellow region and then i look at um milky way uh dwarf galaxies it has no it's a small enough change and it's increasing the effect of the milky way yeah so milky way dwarf galaxy it's um milky satellite galaxy exclude 100 percent of the dark matter being fuzzy 100% of the dark matter being fuzzy at about 10 to the minus 20 months. No one has done the Milky Way substructure analysis with varying fraction. I suspect, because errors on galaxy can probably all commensurate, I would be surprised if Milky Way satellites was more statistically powerful than Hubble UVRF. So I suspect if you did the Milky Way satellite analysis varying the fraction, you'd get something similar to the value. Varying the fraction, you get something similar to the value. But I don't know, no one's right. One more question. So, if you take into account the C and B by refringence, does it have any overlap or is it only at smaller masses? Birefringence, only at smaller masses. It's only 10 to the minus 20. 20 is smaller. You can't do both. I mean, maybe you could do some sort of with yeah, maybe you could have that both funny. Yeah, maybe you could have like multi well you need multiple fields anyway, but maybe there is some non-trivial interaction between the two. But I don't know. That's an interesting phrase. So what exactly is assumed from our own power standard? I know FlimAlpha also has what we might end at like 0.95. So like compatibility of Planck and Flime Alpha is continuous. That's exactly it. That's exactly the thing. So that's what Kia showed. He said, Plank. He said, Planck is incompatible with EBOS, Lyme, and Alpha unless you introduce either strong running of the spectral index, exactly what you said, the spectral index is not consistent between the two, or you have a normal spectral index and a suppression of the power section. So they're assuming, like, okay, so they're not using weird power power effects, and it's just the axe house suppressing power. A normal power spectrum plus. A normal power spectrum plus axions suppressing it makes the two data sets consistent. Or I'm running with the spectral index with on the CDM. For exactly the reason that we said it. Okay, so in the last part of my talk, I want to try and say three different things. We'll see how far I get. A little bit about what fuzzy dump matter looks like inside galaxies, a little bit about maximum stars. Actually, stars, and then if I have time at the end, two exciting-ish new results. Okay, so inside galaxies. Inside galaxies, that function is described by this equation, the Schrodinger-Poisson equation. It's just the non-necessary limit of Klein-Gordon. Of course, it gives you a Schrodinger-like equation. The pressure effect that I talked about earlier, the sound speed, arises from these gradients in the Schrodinger-Parton equation. It's a bit of a nasty equation because it's non-existent. It's a bit of a nasty equation because it's non-linear and non-local, but we can top it numerically. And the fuzzy dark matter physics, the fact that this is waves and there is interference, means it's fundamentally different than cold dark matter or warm dark matter inside viralized structures. And so this is what a simulation of that equation looks like. This is a figure by Philip Munch. So this is a filament. Is a filament, a cosmic filament, and here's a dark matter halo. And in the dark matter halo, you have this sort of turbulent environment that looks like this in the insect with a soliton in the middle. And in cosmic filaments, you have interference fringes. I'm going to talk in detail about both of these things. But here's just a nice Rhodes gallery of simulations of these equations. The very first cosmic simulations of these equations were done by Shive Etal and By Shive et al. who pioneering paper in 2014. This is from a paper by Zemeyer and his former PhD Jan Veltmatt, showing again the cosmic structure formation and the zoom in inside the galaxies. These simulations cover scales of dwarf galaxies and masses of about 10 to the minus 22. The physics here, yeah. Do you think if we're changing the mass of the axon, that is something we use 10 to the minus 18? Yeah, yeah, if you change the mass of the axon, all the features. Mass of the X-ray, all the features, all the wavelengths are controlled by the mass, so all of the features will get closer and closer together. Interestingly, I think this is a nice play. There's nothing special about galaxy formation scales and so on here. So, this is then another screenshot from a paper by Jens. You can apply exactly the same thing to talk about non-linear structure formation during the heating of the infoton, and you can form infoton halos and infoton filaments with interference fringes and infoton stars in the middle. Interference fringes and photon stars in the middle. So, yeah, the physics can be applied on many different scales. It doesn't have to be the large corporate scales that are. ASCII ends up that. And one more, this is from a paper that I wrote with Alex. This is showing that we can do simulations also with mixed, with some cold components and some fuzzy components. So here you can see that the fuzzy component, this is in two halves of the same box, and the cold component. The same box and the cold component at the same time. So, this was like, I forget the exact number in this, it's probably like 10% of 10% minus 24 EV, something like that. 10 to the 8th, 25. So, you can do mixed dark matter simulations, but they're somewhat in their infinity compared to all of the dark matters of simulations. And inside the halo, the halo is not static, it's dynamic on the On the crotching time. This is a movie from the paper by Jan and Jens, showing that the halo is sort of turbulent and this action star sloshes around. The camera is going to start spinning around in a minute. But this dynamics, this turbulence inside halons, works to our advantage because we have to look for its effects. So there's a coherence length and coherence time, and you can understand. And you can understand how this interference arises by taking the square of the wave function and noticing that there are cross terms from different energy and different energetic values. We'll come back to this. The effect of this turbulence means that anything that's living in this environment will get heated up. So you can compute a two-body relaxation time, using Bini and Tremaine. This was first pointed out by Humi et al. And ask whether this would heat any population of stars. Whether this would heat any population of stars. So Jens and I considered the old star cluster in Aerodynamus II, it has some particular mass and velocity dispersion. And you can work out whether this relaxation time, the presence of this fluctuating halo, will disrupt your star cluster. And this is showing in an approximate model how the radius of the star cluster in parsecs changes over time for different values of the fuzzy dark matter plastic. And if the radius If the radius of the star cluster grows too quickly above the observed value, that would clearly be inconsistent with your observation that there is a small star cluster. And this leads to constraints and the fuzzy dark matter mass that you exclude matches of roughly a few times 10 to the minus 10 to the analysis by Darrell and Kravsov looked at a different system and arrived at a similar rate. This is assuming 100%. Yes. Gens and I looked at varying the fraction, but I'm not sure how much I'm going to. But I'm not sure how much I would trust it at very small fractions. But you can constrain the fraction. And Neil is working on that for segue. I'm going to contrast this to another limit at the very end. This is a very powerful limit on the maths, but it relies on knowing about the, you know, saying that I know the history of my star cluster of giga year time scales. So it's not local in time. So I'll return to that. So I'll return to that. Okay, last bit of physics. Compact structures. So we've gone from cosmic scales and cosmic linear scales to quasi-linear structures and galaxies and virialized objects. Fuzzy Delmather can also form very compact structures, things called axian stars and solitons. So the so the shrodict they're not true solitons. With they're not true solitons. They're time-dependent. The example doesn't apply. So you can look for ground-state solutions to the Schrodinger-Poisson equations. It's just a boundary value problem. And you can find them. So this is a ground state, stable solution of the Schrodinger-Poisson equations. You can get a fit for the density control. It's a one-parameter family of solutions. So you can change the mass and make these things heavier or lighter. Things heavier or lighter, and as you increase the mass, they get more compact. And there's a maximum mass beyond which they will become unstable, either due to gravity collapsing to a black hole, or if there are any kind of interactions, unstable due to the interactions. So either to quartic interactions, exploding interactions, or to, if there's an action-photon interaction, and some ambiguity photons, unstable to explosions of photons. And these things are observed to form in simulation, so they can form from coffee. So, they can form from condensation in a random environment in the kinetic regime. And they can also form in the sensitive dark matter halo. So, this is a halo condensing in a simulation box. And these things are observed in those cosmological simulations that I showed earlier. So, we see them in simulations of structure formation. Can we use them to our advantage and get some phenomenology? Well, you need to know how many there are. There are. If you want to get a rough estimate for how many solitons there are, you can use this thing called the core halo mass relation. So, in sufficiently relaxed systems, the mass of the soliton is observed to scale with the mass of the host halo that it lives in with a particular power, although there's some statistical, significant statistical scattering in this relation, probably due to major histories, due to the work of Simon and others. But if I assume that such a relationship holds, I can take. Relationship holds, I can take the number of halos, which I know, and from the power spectrum that we've already talked about, and work out how many solitons there are, assuming that there's one in each halo. And this is what the soliton mass function looks like. So this is the number of solitons per cubic megaparsec is large, 10 to the 11 solitons per cubic megaparsec, and their mass spreads over a wide range because halo mass is spread over a wide range. So there could be lots of them around and spanning very wide. And spanning a very wide range of masses. So, physics of these solitons. So, these solitons can grow and become unstable. How do solitons grow? Well, how do halos grow? Halos merge. So, if I know the halo merger rate, I can compute from that the solitone merger rate. And this is again just some turn-the-crank halo model calculation. But what happens? But what happens when two solitons merge? Well, if they merge and they go above a critical mass threshold, then they can collapse and give off radiation. And so this is results from a simulation by my graduate student, Ima Chonjako. And this is a simulation in full numerical relativity. We took two solitons, we merged them head-on. Binary merge, these binary mergers are difficult. And when they merge, they give off some small amount of gravitational waves. Small amount of gravitational waves. These things aren't as dense as black holes. So when they merge, you get a little bit of gravitational waves. But then, when they merge, they gone above a critical mass threshold. After some time, they'll decay. The star collapses under its self-interactions and decays. And when that happens, you get a burst of gravitational waves, which is very different from any inspiral and ring-bound type of significant tissue. This would be very distinct in LIGO. In this case, the In LIGO. In this case, the axion star is unstable due to an axion-photon interaction, so you get a burst of electromagnetic radiation as well. And you also get axion emission throughout this whole process. So because the star is sort of oscillating around rather than giving off scalar waves. So this is potentially a way to see mergers of axion stars in gravitational waves and electromagnetic radiation, and even if those mergers are going around, they might produce axions because it's a methodology. That production of electromagnetic waves heats the intergalactic medium. You can work out how much it heats the intergalactic medium. And so, this is the from the halo model. This is the energy injection in ergs per cubic megaparsec per giga year as a function of redshift for solitons. So now the actual mass is actually much bigger that I'm looking at. Tens of mass ten, eleven, twelve EV, assuming you're all the dark matter. Assuming you're all the dark matter, the energy injection rate for action frozen co-plus 10 to the minus 11 inverse GeV is big. And by big here, I mean larger than the energy injection rate due to population 3 co-collapse supernova 2, which we think are significant in reionising in reionizing the universe. So you can try and work out how this gives you constraints on axion-like particles, and the red region is excluded by patterns. Is excluded by matter. So you produce some photons, you heat the intergalactic medium, if you heat it too much, you're excluded. And the exclusion on out is in an interesting range, lower than the fuzzy dark matter range, 10 to the minus 12, 10 to the minus 8 electron volts, stronger if you're all of the dark matter than constraints from X-rays and gamma rays, and could be even stronger with future observables like the 2110 power spectrum. So I think this is a promising observable to look into. Observable to look into going forward, like modelling these solaton measure rates better, for example, in simulation, and working out the effect on the 21cm power spectrum, you might be able to leverage two orders of magnitude more on outs that we've curved. So th so this could be promising, but a l a lot of work needs to be done to to get to understanding the signal enough for this twenty one sentiments there. Of this 21 cents, it's there. Very, very rough forecast that I've done here. Right, I'm going to flash in my last minute two things because they're really cool. Self-consistent payloads. So, both of these things I'm going to flush up by a really, really good graduate student in Oslo called Tim Zingerman, who I record. So A classic thing that people say about contents and fuzzy dark matter is 10 to the minus 22 V is your rough lower bound of mass. Why? Because the Brody wavelength must be smaller than a dwarf galaxy. Okay, that's the bosonic Tremaine-Gunn bound, if you like. You can do the Tremaine Gunn bound for fermions precisely. Solve the Boltzmann equation, give it some potential for the galaxy, and work it out. No one's ever done the analogous thing for Fermi. The analogous thing for fuzzy black method precisely. I'm till now. And the reason it's difficult is because you have to reconstruct a self-consistent wave function in a potential of a dwarf galaxy. And this is what Tim developed the tools to do in a computationally efficient manner. No one had done it before, because if you tried to do it by brute force, you don't have, like, you can't do this with battery computers. And Tim worked very, very hard to make this possible. So this is showing the self-consistent wave function of fuzzy. This is showing the self-consistent wave function of fuzzy dark matter in LiO2, given some estimate for the potential of LiO2 from genes analysis in Crassphere. This is what the wave function looks like if you're at 10 to the minus 22 eV. Very, very spread out and fluffy on the scale of ZO2, which is about one kiloparsec. If you up the mass 10 to the minus 21 EV, the structure becomes much, much smaller on the scale of ZO2. And so we use this to place a lower bound on Bound on Donald Particle Mass from Leo 2. I won't go into how we did the statistics. But the very nice thing about this is the band is an order of magnitude better than the back of the envelope estimates, which you would not expect, normally you do a back of the envelope estimates, and then you go do things properly and you get a worse bound once you come to the errors. In this case, we got a lower bound of 10 to the minus 21 Ething if you're all of the dark. If you're all of the dark matter, this is something that we're working on trying to adapt to multi-fili or trying to vary refraction, but that's working progress. I won't mention filaments, but I can talk about my questions. And I will leave you with my closing slide, which just says that fuzzy dark matter is a collection of phenomena where wavelength effects might. Where wave-like effects manifest in astrophysics. And so it's a lamppost that we can use to look for ultralight particles. If ultralight particles exist and they make up anything around a percent or so of the dark matter, we can train up for their effects in cosmic observables, inside galaxies, on the growth of galaxies in the universe, and all kinds of other things. Things. The question of whether or not these things are really predicted by that event will be answered in the next one by a couple of them. Thank you. I had a lot of questions during the talk, but any more for John? I shouldn't ask you for that. Oh, that way I have. Oh, but when I have two field points of dark matter, you can train them. I've been confused for a little while about how the effect of field matters. I take the non-alternatistic limit of both of these fields. So usually in place of effective matter here, if you take non-analysis limit, it's sort of like a pick reduction, where I have the slowest oscillating state, and I have a tower of fast modes, and I'm going to reduce fast modes, so like three kilometers. I have a second field, which is A second field, which is a little bit heavier, the mode that's going to excite the first one are the ones you've integrated out. So there's been a small amount of work mainly numerical to