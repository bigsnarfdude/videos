So we continue with the second talk of this first session. So we're very happy to have Maria Piavaldan from the University of Texas hosting and she will talk about regularity estimates for the Landauer equation the energy. Another question here at the beginning. So, the seconds. Thank you, thank you for the introduction, and thank you to the organizer Kerry, who is not here, Michaela, Mateo, Marco, for the very kind invitation. It's wonderful to be here and to see many friends after a long time. So, today I would like to present some recent results related to the Lambda equation and regularity estimates in the spirit of what Fran√ßois In the spirit of what Francois was talking about, but I will actually look in a different setting, so near equilibrium. So I will skip a little bit the introduction because this was just done. So the Landau equation was introduced by Lev Landau in 1936. The expression then you see at the top of The expression then you see at the top of the slide is how it looks like in the original paper. It's the transport equation. The function f is the particle density. It's a probability function that describes the probability of fine particles at position x with velocity v at the time t. And the collision operator only acts in the velocity. Operator only acts in the velocity variable, so the physical variable x somehow plays a role, at least in the way it looks, this one only from in the transport part. And as you have seen from the previous talk, the collision operator is basically an elliptic operator. Operator. It's a diffusion operator. Let me put it that way. So it first appears, as I said, in 1936. Landau derived it from the Boltzmann equation with the intent of modeling collision in plasma when particles collide under the Coulomb force. But it also appeared in a very different derivation in the series of books by Lifshis and Pita. Books by Lifzis and Pitaevsky as a Nolinia Foker Planck describing collisions when a particle collides under smooth potentials actually and particles barely deviate after the collision. So, anyway, this is a model that has been studied very intensively in the last 20 years and Years and today I will focus on the homogeneous problem. So, the same setting as in the previous talk, we assume that the particle density is constant with respect to the space. So, now the problem, if I click, okay, so the problem as you see here basically becomes a parabolic problem, so a diffusion problem. Let me use this terminology for. Me use this terminology for the um following the title of this workshop: is a diffusion process. And let me show you why this is. So, the assuming that the function f is smooth, okay, so and so I can do all the manipulations that I want. So, if I look at this operator, now I'm going to abandon the subscript V because now it's subscript v because now it's clear v is the only variable that we have here beside the time so i will write it and i consider three dimension in this talk everything can be translated to higher dimension so three is not binding here and then we have the f of w the gradient W the gradient with respect to V times the gradient with respect to W. I forget the T, but the T is in here, right? So F is a function of V and T, W and T. Okay, so now you see that assume that F is very regular and I can do the manipulation, those terms are independent of W. So I can take them outside the integral, and what I get is something. Is something that can be written in this way. So, this is the first term here. The capital A is what is defined. Actually, here we have a constant. Let me write it. Pi in three dimensions is the integral of this projection matrix over the kernel. Over the kernel, B minus W, and then F of W dw. And so then in the second term, once I take the F of B outside, you see I have a convolution with a gradient, I put it outside, so it becomes F of B, the divergence of the matrix A of F. And now, actually, this matrix here. Actually, this matrix here, once you take the divergence, you see, not very fast, but if you do a couple of computations, you see that actually can be rewritten as the gradient of a scalar function. The gradient of a small as a scalar function, little A, little A is the trace of capital A. So, little A. capital A. So the dot A is one over four pi because the trace of the projection matrix in three dimension is two. So we get one over four pi, the integral in F3 of the convolution of F with respect to the kernel. And this one is the twist potential of the Laplace. Equation. So from here you see that the Laplacian of A is actually negative F. And this is somehow the reason why now if you say, okay, I can distribute the W gen inside, I get what we saw in trans towards the non-so the divergence for. The non-so the divergence form, non-divergence form, and then once we apply the divergence form in this term, we get the f square. So, this comes from the fact that the Laplacian, so the divergence of this collating is exactly negative f. So, I get here the quadratic nonlinearity. So, if f is smooth, the three formulations are equivalent. Are equivalent. So one can choose. And so Francois previously worked on the first one. So I will use mainly the second one today. And the third one at the very end. So what are the most important facts? The one that I will use today. So there is a There is a unique equilibrium, the Maxwellian, and we have conservation of mass, conservation of force momentum, and the second momentum, the decay of the Boltzmann entropy. And the second and the third fact imply that this diffusion matrix capital A, this one here, is uniformly bounded from, I mean, uniformly bounded from below. So this is the somehow. From below. So, this is somehow the ellipticity of the operator. The bound degenerates for large V, it's approximately going like B cube. And this bound is sharp when F is the Maxwellian. So this is somehow the optimal bound. Okay, so the most important question is: do solution to the Landa equation stay bounded? And once we know. Bounded. And once we know they are bounded, they are smooth by standard elliptic theory. So in this talk, I will use more or less sometimes bounded, sometimes regular, smooth. They all mean the same thing. Bounded, hence smooth classical solution. Okay, this is an open question. And what existence results? And we have seen some already. So we have an existence of a solution. This is known. Of weak solution. This is known, several types of weak solutions. Long time asymptotic is also known. The solution, any weak solution, converges to the steady state, to this Maxwellian in L1 norm. This is clear, it's done in several papers. Global velposin is close to equilibrium. This is also known for smooth initial data. And today, Initial data. And today I will actually present a result of global well-poseness where initial data are not smooth but in LPP small. So then uniqueness. Uniqueness is partially known because it is known for various type of smooth solutions. So somehow it has a conditional uniqueness. If the solution is smooth in various definitions, in various sense, then it is smooth. Then it's smooth regularity. Regularity, so boundless, regularity, the same issue. This is also partially known, right? So what is known? It's non-conditional regularity. So what do I mean by that? We have so sorry. So So there are several results, but so the conclusion is basically the following. If we know then our F is something that uniformly in time belongs to, say, an L P space when P is greater than D over 2 in R D, so in three dimensions three over two. Dimension 3 over 2, slightly slightly bigger than 3 over 2, then f is bound and F4 is not. So it's conditional because at this point, this one we don't know, right? So, but the question is now if the function blows up in finite time, so becomes unbounded. Time so becomes unbounded defining time, then all the norms up to three over two in three dimensions become also unbounded. Okay, so then we have the partial regularity results. This is what we have heard just now from Francois. Okay, so if there is blow-up, this blow-up is confined in a certain time interval and in a certain region. Region, if there is. And then we have what I have called eventual regularity. And Laurent can object the name, but this is his result. It's very important. Two years ago, the Villette, he and Jan showed that if there is blow-up, this blow-up happens in finite time. And whatever happens, any solution can go through whatever, but after, eventually, Eventually, they become smooth and they will live forever smooth. So, the blow-up is not at infinity, the blow-up is at some point, right? And then the solution becomes smooth again. So, eventual regularity. And today, in this topic, I will comment. This will be just a comment or a reflection about the role of diffusion in the Land equation. So, given that we cannot rule out Blow. Then we cannot rule out blow-up yet, or we cannot prove global well poseness. Can we rule out blow-up or certain types of blow-up? So, yes, so until so, for example, we could rule certain type of self-similar type 1 blow-up, a la semi-linear fit equation. Those types of blow-ups do not happen for lambda. Obviously, there are many other types of pathology that could happen in the That could happen, and that's we don't know. Okay, so this is actually a very open question. Many things need to be done. So, the big conjecture is if they are bounded or not. Okay, so what are the obstacles to overcome? And the main obstacles, in my opinion. So, first, the lack of comparison principle, right? Which we know many things are nice because there is a comparison principle here, there is no comparison. Comparison principle. Here there is no comparison principle. And the reason is that one cannot have a comparison principle due to this non-local diffusion coefficient, right? That one breaks the. So the only Lyapunov function that we know is the Boltzmann entropy, plus and minus some adjustment. And the third one, which is In my opinion, the hardest to what makes things hard to decide if blow up or not is the fact that the diffusion, so this the diffusion and the reaction have the same strength, the balance. And this can be seen in many ways. The easiest is by scaling. If you rescale the F, you see that the reaction, so sorry, the diffusion. Reaction, sorry, the diffusion doesn't scale like the Laplacian. There is fusion scale of order one because the coefficient capital A balances exactly the second derivative. So this term over here and this term over here have exactly the same strength. So there is a fine balance there. Another way how to see that is by a new weighted Poincare inequality that was proven by Gressman. Proven by Gressman, Krieger, and Strain in 2012. It says that actually, yes, so the reaction is kind of the same order as the diffusion. And another point is that at the equilibrium, the two terms, they exactly balance out, right? Because it's the equilibrium, the collision is zero. And so if you do some type of LP estimates for the Maxwell, and you see that those two, the exact, the And you see that those two balance out. So today, this is the first main theorem. And now I'm focusing on the situation when the initial data is near the equilibrium, M is the Maxwellian. So let us fix a P strictly greater than 3 over 2. Okay, and in D dimension could be D over 2. In d dimension could be d over two. Then I consider initial data, then they are bounded in, so they have finite mass and moments. So this bracket here is just a smooth version of the absolute value of V. So I have L1 and L1 with moments bounded, and And will be bounded and closeness to the equilibrium in LP, P33 greater than 3 over 2. Then for such initial data, the problem is globally well posed. So there are classical solutions. This solution is unique and satisfies this. Unique and satisfies this regularity estimates that instantaneously, so as soon as the clock starts, the function f becomes bounded in L infinity with a rate that is one over t to the gamma. And gamma is a coefficient which is less than one and is between three over two p and one. Okay, so I have an LPL infinity regularization in time. So this is a short-time estimate. It's not a long time estimate. Long time estimate. So it's a smoothing effect. So, what does this theorem show? Well, first one, a uniformly smoothing effect and pointwise bounds for the function if the initial data are in L P, P arbitrarily close to 3 over 2, then this estimates actually is strong enough, you will see strong enough to extend short time exactly. Short-time existence to global wealth bosses. And so the condition P greater than 3 over 2 is actually essential in our argument, because our argument hinges upon short-time smoothing estimates that hold when the diffusion dominates the reaction. Okay, and this is done when. done when in subcritical norms. So for the Lamber question, subcritical norms are all norms that or LP norms p greater than 3 over 2. And this is not by chance that the same 3 over 2 happens here, but also happens here in the conditional regularity. The proofs have nothing to do with it. And in fact, the proof of this one, there are a couple of different proofs, one with energy S. Roofs: one with energy estimates, and one, for example, one with Sylvester using three loss sofon of barrier arguments. So, two different things arriving exactly at the same conclusion to this experiment. And the same is there. So, this three over two seems like the threshold, and after which I believe that we need a new approach. Okay, and in this new approach, I don't know what it is, and we haven't found it yet, but with It yet, but with the somehow with this point of view, this seems to be the wall against which we always bump. We really need something new after that. Okay, so, but for sure, in those sub-critical norms, then it's clear that the diffusion takes over, controls the reaction, and then one has global welposiness. So, before I go into the The details, let me go a simple exercise. Okay, so now let's take the equation and let's what is the divergence hole here exactly. So I'm going to assume that this function, this coefficient here is the identity matrix. Okay, so now what I'm going to do is let's Going to do is let's multiply everything by u. Let's do two estimates. So I multiply by u. So the first term gives me the gradient u square, right? And then I have the reaction term, u cubed. So now let's focus on the reaction. So u cube, I do, we do holder or interpolation L6, L3 half. And then I bound, I use, we are in three dimensions, so this L6 norm can be bound, can be, can be bounded by the H1 dot norm square. And then I interpolate L3 half with L2 and L1. I want this L2 because it is on the left-hand side. And now, if we take the integral of gradient squared as common factor, I have Common factor. I have a negative sign, the gradient of the integral of gradient u square. And then I have one coming from here minus a constant, which is the term coming from the L1 norm. The L1 norm is consolved, times the L2 norm to some power. So from here we see that if initially the L2 norm is below a certain constant, then the L2 norm keep is bounded. Is bounded, keeps decreasing in this case, but is bounded. Okay, so this is, I think many of you know this type of computation. Okay, so, but what is the reality here? Now, what is my u? Now, my u now will be the distance of f and the Maxwellian. And my u now solves something that is not quite. That is not quite what we just showed, right? But kind of similar, right? And some lower order terms. Now, this A of F is a diffusion which is non-linear. So I'm going to do, I'm doing the same estimates as I did before, not with L2, but with LP. And because this is a non-linear problem, we This is a non-linear problem, will give me some, say, sub-linear terms, which are kind of not very nice. So I can show that if my initial data is less than delta, then at a certain time capital T, and the capital T is of order delta, my LP norm is still smaller. Okay, less than two delta, for example. And the same will be some. For example, and the same will be some weighted H1 norm. And now, here you see the appearance of this denominator. This comes from the bound from below of the A, capital A, right? It's not a pure diffusion, yes. There is a U. Thank you. There is a you. Okay, very good. So Okay, very good. So now I have, so for a short time, zero capital T, I have propagation of smallness of L P norm. So now I do a de Georgia iteration, L P L infinity. So for a short time in this time interval, zero capital T, my function u becomes instantaneously L infinity with a decay to zero of the order one of a T. To zero of the order one over t to the gamma. So this one is the regularization that you saw in the theorem. Okay, but I don't want to focus now on that one. I want to show, well, if I take my capital T to be something like half of this one, of delta to the one minus alpha, then actually my L infinity norm becomes small. Okay, becomes small, very small of order delta. Very small of order delta, and now I can do higher regularity as needed. I keep iterating, so at some point, some norms a subolef norm hk is also small. Why do I want to do that? Because so now I have a solution, started with Lp, becomes instantaneously regular at some point in my existing interval. I know them as small in L infinity and in all sobolic. In L infinity and in all suball f naught, then I need. Okay, but now I use the existing result of, I use this one to be my initial data to a new solution. Now, this one is small and smooth. It's as smooth as you wish and small as you wish. So I take this my initial data of a new problem and I know by existing results, for example, David Letti and Jango, Capara, Fastosso, Michel. Jang, or Capar, Patroclus, Micheler, that there exists, if your initial data is small, smooth, and small, you have a global in-time solution. So now uniqueness, which is new, so which is known, allows me to patch my solution to the one that I build, and this gives me globally time solutions for a small. For small data, okay, but P is as close as you wish to d over 2. So, one comment about, couple of comments about this theorem. So, this is a, even if we are close to equilibrium, this is a fundamentally non-linear approach. We are not linearizing, we are not taking a linear operator, and the remainder study, the linear operator. The remainder studied the linear operator anything, so it was a non-linear problem, right? And for because of that one, or thanks to that one, for example, I'm not worried, I don't need to assume smallness in the moments. Usually, the moments or smallness in the moments are used to, once we have the linear operator, to push away the continuum spectrum and have a spectral gap. I don't need to do that now. Okay, so my To do that now, okay. So, my method is non-linear, I don't care about spectrum and anything, and the smoothing effects that we get are actually kind of sharp because they approach as much as you want, they approach the decay of the heat equation. So, LPL infinity regulation heat equation is one over d to the three over two p. To the 3 over 2p, and this gamma then you saw before was as close to this rate as you want. Okay, so the next, I still have I think 10 minutes, right? So in the remaining part, I would like to actually make a comment on the role of diffusion. So if you remember, so for example, even in my So, for example, even in my proof, at some point, there is this lower bound, one over V cube. And I said, well, this is because this matrix here, this A of V, has this lower bound, which is kind of shuttered in a max way. And then also in Francois's talk, at some point, there is this polynomial which is at the bottom, right? And it seems that this is what we can use. Okay, so, but the question is. But so the question is: Are we losing something by losing the lower bound? And I understand that it is sharp around the Maxwellian. But what about if we are not close to the Maxwellian? Somehow the lower bound puts my equation, which is a quasi-linear problem, into the semi-linear setting, and I'm losing something. I'm losing something by doing that. Okay. So, and interestingly, actually, all the sharpest results that we know in this field, and when I mean sharp, I mean global well-poseness, not close to equilibrium, not small data, but global well-posedness, flat, I mean, case, are the ones that do not use this lower bound. Use this lower bound. So, for example, let me those are the three. So, the first one is by Gressman, Krieger, and Stray in 2012. So, they said, okay, they propose actually the isotropic, what is called now the isotropic Lando. So, what they did is that, okay, I'm going to consider this problem here or this problem here, but I'm going to Of this problem here, but I'm going to remove the projection matrix. And this projection matrix, some, yeah, is I know that it's something that is bounded nicely, but creates some problems in the analysis. So what about if we remove this? We remove it and observe it. And so then they damp down somehow. Damp down somehow the reaction by adding this coefficient alpha. And so they could show that if they damp down the coefficient alpha and they somehow make the diffusion isotropic, right, by removing this matrix, then this equation here, alpha, can be anything between 0 and 74 over 75. There is a reason why they get at that threshold, but then this problem has global. problem has global doesn't blow up solutions are smooth bounded and they live forever clear okay and the reason why they can get that one is because they can show they can use a new weighted point inequality you see the diffusion is there the capital a is there is not remote this This, the alpha and the description of the alpha is because the constant in front is too big to push to alpha to one. But that is the first one. So second result came myself and my collaborator Nestor Guyan four years later. We could push it to alpha to one, but we abandoned the energy methods. We worked on the mass. Methods. We worked on the mass function and do barrier arguments. So there we didn't even see the diffusion. So it was a black box somehow. And the third one is one that considers still isotropic, so still the projection metric is not there. We cannot put it back. I don't understand why. But if I remove a And if I remove, if I we make the integral, sorry, the kernel less singular, and then we have if gamma is between negative 2.5 and negative 2, then this equation has global well-possible, is globally well posed for general solution. And we use Hardy inequalities. So the diffusion as it is, that's it. So I don't know. So, beside those works, I don't know how to use the diffusion as it is, honestly. But how much do we lose if we use the lower bound? It's very handy, the lower bound. It's very tempting to use it, but are we losing something, at least in the short time? Time okay, maybe in the long time, no, because we are approaching the Maxwellian, but in the short time, are we losing something? So, a way how to one way how to see how much I lose is by analyzing this diffusion equation. So, I'm taking considering this operator, divergence of gradient U times this capital A of U. This capital A of U. And now, if you look at this equation here, simple, actually very simple computations show that the L1 L infinity regularization is much faster than the one given by the heat equation. So, if you consider the heat equation in three dimensions or in the dimension substitute by one, so So the L1 L infinity has a regularization power one over t to the three half shard, right? But this one, L1 L infinity is a power one over t to the one plus epsilon, epsilon as small as you wish. So it is much faster, right, for short time. So this is, in my opinion, a way how to see that we are losing something. See that we are losing something if we rely on the bound from below. Okay, so this estimate here is actually very easy to prove. It's actually an interpolation between the Gress Bank region strain and at the Georgia iteration to go from Lp to L infinity. So, first we can do L1 LP using the Gressman-Krigarin strain and gives this type of the This type of the smoothing effect, so from initial L and L1, then the solution becomes a stentaneous CLP with this rate 1 over 1 over 1 minus P, which is already much faster than the heat equation, if you remember that. I don't remember what is for the heat equation by hand, but this is faster. And then now, if I now perform a DeGeorge iteration from a perform at the George iteration from Lp to L infinity and then I combine the two. At the end you see that by doing some numerology over here you arrive at a decay which is one plus some numbers epsilon that depends on P and so now you can you cannot push P to infinity right this was from the previous one as well. You cannot say here I'm taking P to infinity. This coefficient will blow up. That's why we do the Georgia. We blow up. That's why we do the Georgia to go from Lp to L infinity. But now, after you do that, now you can P finite, but as big as you want, and you can lower this coefficient as much as you want to approach one. So this is just a comment to highlight that actually the diffusion of the Lambda is much stronger than the standard Laplacian, than the one given by Laplacian. Than the one given by Laplace. And how to go from here? I don't know, honestly. So, how to use this information at this point, I don't know. But I thought this was something that we should keep in mind because this is the quasi-ellipticity of the problem. So, this reflects the quasi-ellipticity nature of. Nature of the operator versus the semi-linearity of the setting that we kind of always rely on. Anyway, thank you very much. Thank you very much, Maria. Other questions? So in this model where you remove this projection operator at the moment, what are the because I'm not an expert of course, what are the implications on the model in terms of preservation of this form of like the second one? Oh very good. So yes. What do we modify if we remove a lot? So for example So, for example, the Maxwellian is not a steady state anymore. So, the steady state is zero. There is still conservation of mass, first momentum, but the second momentum becomes like an integration that will grow. So, for a long time, it's different. I don't know if this could be a an idea I should like. You let the the model evolve in this free way without this uh constraint. Way without this constraint, and then try to reproject it on a manifold bits for a set of moments. This is something that, yes. I'll show there are some communicators in between. I don't know. Yeah, somehow all what we have, so what we have so far is very rigid to that particular setting. It is, yeah, it. Yeah, the intuition is there, right, as you said, but there is the theory and there is the practice. So this argument with Netflix, you really use the homogeneity of this uh kernel very much? Or would would there be s removing the anisotropy, but taking a slightly different kernel with the same similarity at zero, but maybe a different one at infinity? So the barrier argument works because the constants match. In the radial symmetry case, once you remove this one, you get a Newtonian potential. And once you write it in symmetric coordinate, you get some coefficients. And then they match with what you have. With what you have. If you take a different one, I don't know because you will have to write it in pora coordinates, so it's in spherical coordinates, and then do the numerology. So, you really someone using the data the inverse of that? Yes, yes. Yes, yeah. So, I have a question? Yeah, by the way, on this as you saw it now to actually see. regularity in the um access and access uh uh in the uh regulatory symmetric case decreasing solutions for that is everything special on the access and application for the uh for the as we shortly have to be on the for colomba for culombe yeah i mean it's this uh as we short thinking or dt u equals the minus of plastic minus Equals a minus per plus minus 0.2 times per plus mu percent squared. Yeah. I mean, I think that you do it back with you looked in the video case. Have you tried the issue symmetric case? No, we haven't tried. So the the the no we haven't tried because uh maybe we should after your work yeah but no we haven't tried because the better argument works very well because we concentrate on a point and then we build the Concentrate on a point and then we build the data barrier. And so, um so you have no uh but now that we know since now we know that the blow-up happens at the axis uh maybe could be extended because you can control the tail maybe in another way and then perhaps yes we have a Perhaps, yes. We have any yes, after your work, maybe this is something that one could do, absolutely. Thanks, Maria, again.