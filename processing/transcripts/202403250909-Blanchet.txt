Thanks so much. Well, thanks very much for the invitation. I'm glad to be here. And yesterday I was told, I'm sorry about what happened, the incident. I was worried because I arrived very late. I was worried I might not be able to make it my own talk because it was late, but I'm happy to be here. And I'm going to talk. And I'm gonna talk about recent work with several collaborators at Stanford. My postdoc, who is now joining UBC in Vancouver, Jia Yen Lee, a Suri PhD student at Stanford, Marcus Felger is a colleague also at Stanford, and his student Greg is on the job market now, a former student who is now working for a hedge fund. So let me just Let me just give you a bit of the big picture story. So, this works is about optimal transport and distributional robustness. And I used to give talks on distributional robust optimization and connections to statistics. And you will see in this talk, and I think in other talks, perhaps judging by the titles, that there are intimate connections between distribution and robustness. Connection between distributionary robust estimation and statistics, and you can get estimators that have interesting statistical properties. And the formulation of distributionary robust optimization, distributionary robust decision making, it makes a lot of sense that the word robust is attached to the formulation. These are min-max games and they have well-studied economics, they have a tradition, they are well formulated. They have a tradition, they are well formulated, and they have a good decision-theoretic foundation to it. And there is this very classical area in statistics called robust statistics. And you know, statistics is used, sorry, the distribution of robust estimation is used to build statistical estimators with properties. On the other hand, the statisticians have been doing robust estimation for many, many years, and then the question. And then the question often was asked: what's the connection between these two things? How are they related? And this was partly the motivation of what I'm going to present. So I'm going to argue in this talk that try to kind of formulate, think about statistical robustness with the same lens as we think in terms of distribution and robust optimization, and then argue that the optimal policies that are The optimal policies that are robust from a statistical standpoint are completely different than policies that are considered distributionally robust, the way we think about them. So they are going to be the formulation, so the formulation can be done with optimal transport. It makes a lot of sense, but the type of estimators you get are just very, very different. In fact, from a standpoint of what you are going to see, Of what you are going to see, distribution and robust estimators are not robust from a statistical standpoint. And you will see that it's going to be pretty obvious. So that's kind of the big picture. So let me tell you what I, you know, a success story in the context, not the statistical context, it's in a context that is much more, I think, clear what the intuition is of why standard distribution and robust. Distribute standard distribution and robust optimization works. So, this is very, very quick primer on portfolio selection. I'm going to show you an experiment. I'm building from this because I'm going to show you an experiment where the use of distribution and robust estimation works very well. So, in this, you know, let me remind you here, I'm showing in this picture an efficient frontier. So, I'm showing the simplest model. Simplest model, portfolio selection model. This parameter is called the risk aversion parameter. So you are minimizing variance. This alpha is just an optimization trick so that you can write the variance as an expectation. So you just insert another variable. Here, and you're minimizing variance subject to a return constraint. You want to maximize return, so that's what they got to assign. And if you know the distribution of the returns, as you change this parameter, Change this parameter, the risk aversion coefficient, you draw this paradox frontier. That typically is increasing concave. The more risk demand, you should expect more return, but with a diminishing, decreasing return, so force. Now, the data-driven version of this, of course, is, you know, you collect data, this is an empirical measure, and then you try to solve this problem. I'm not going to talk about whether this is a good idea in finance or not. There are lots of ways you have to do it, right? You have to do it, right? You have to keep a window of time because of non-stationarities and other sort of sophistication that you need to have. But just to simplify, at the end of the day, you collect data, you form a problem like this. Now, I'm going to tell you what the experiment was. The experiment was as follows. So there are too many things to read here, so I Many things to read here, so I'll walk you through them. So, on the left-hand side, you see empirical versions of things that empirical versions of something like that. So, this is in-sample performance, and you see three curves. So, the top curve is the more preferable, right? The more given the standard deviation, you are getting higher return, right? Then you have another overlay another curve, and then another curve. So Curve and then another curve. So these are different parameters of the risk aversion coefficient. As you move, this higher curve corresponds to a delta very close to zero, delta equals zero. I'm going to explain what this delta is. But as you increase this parameter, delta, that is going to play a significant role in this talk, uh you can see that you get worse and worse curves. Now these are in sample performance. So how did how did I build this uh in sample curves, or how did the student build this today? How the student view this sample curves. So the way we did it is: okay, we collect the data from 2000 to 2019, and these curves are produced by looking at 10 years of data and moving the window monthly by selecting monthly returns. So from 2000 to 2010, we compute means and variances of the returns of 20 stocks that were sampled. Of 20 stocks that were sampled at random from the SP 500. So we picked 20 stocks at random from the SP 500. We look at 10 years of data study from 2000 and from 2000 to 2010. In January of 2010, we solve this portfolio selection problem and then we compute the optimal allocation. We have a predicted return and a predicted standard deviation. We implement, then we get a realized return and the next moment we get another. And the next moment we get another realized return, and so on, and so forth. So, we have two statistics: one that is the predicted returns and predicted standard deviations, and the other one involves the two returns that are realized after you roll over these 20 stocks from 2010-2019. Then you can compute the realized average return and the realized standard deviation. We repeat this 100 times for different stocks, the S ‚Åá P 500, never looking into the SP 500, never looking into the future. And if at one point in time one stock left SP 500, we just grab another one and then we continue from that point onwards. So this is the in-sample. So this is what we predict is going to happen month by month. And in the right-hand side, here I showed the out-of-sample versions. So what actually happened, right, in the experiments. You can see that the curves get flipped. You can see that the curves get flipped. The delta equal to zero is the worst one, and you have better performance as the increases. You have this, this was something surprising to me, but I'm showing just the point estimation of the means. There is a huge variability, so it really, the slope pattern thing can be predicted, but the layers, that's correct. So if you, I mean. So if you I'm plotting here as a function of the risk as measured by you know statistical quantity which is the standard deviation and you h you have other two curves here. So I'm going to summarize fixed I'm going to fix a risk aversion coefficient and instead I'm going to plot according to the model risk. So as a function of the model risk which is this delta then it kind of looks like okay and this is a this method is exactly what I This method is exactly what I described, the blue one, just based on the data as you move this parameter that is the model risk, amount of model, model mispecification that we inject in these formulations. And this red one involves a slightly better calibration of the optimal transportation cost function that is used to model, to inject modeling specifications. So, this one, this red one, is obtained by looking at implicit By looking at implied volatilities and information that the market contains now about expectations about the future. So, in this type formulation, an optimal transport cost function that is convex has been calibrated to the expectations of the market and then you can get a little bit more performance about the future. So, this is kind of the way in which I've seen the success of distribution and robust optimization in tasks that are not fully as statistical. Tasks that are not fully statistical. It's also known that these estimators are, from a statistical standpoint, they involve, you know, they can be seen as a regularization, you know, variance regularization or a non-regularization that's part of a distribution and robust optimization, and you can make it part of optimal advanced work as well. So, on the other hand, what do statisticians often think about What the statisticians often think about what is robust are situations of this form. You know, you have a nice sort of like a predictive curve, right? But you don't want that curve to be highly affected by points that are really out of the ordinary. Maybe you think that they are contaminated, there was measurement error or something like that, and you want to make sure that the inference is not too affected by points like that. So, you know, median and these types of testing, right? And there are many model contamination models that are studied. Contamination models that are studied for which you know, given that contamination model, you do you know, to design this estimator, and this estimator has nice properties, like it's not too sensitive to outliers and things like this. But how these two things are related, that's the point of the talk now. So, the method that I'm going to describe today, that is built on optimal transport, was applied to this industrial application. Industrial applications. So, in fact, this project started in collaboration with Morgan Stanley. And one of the problems they have is they sell data. So, this is an implied relativity perfect. I'm not going to talk about it, but I don't have time. But they should be smooth. Yeah, this is what they want. And things like this, you can see maybe that there are these points that just go outside of what should happen. So that means the gradient change. So that means the gradient changed a lot here. You can see the jumps here. So those, in terms of the gradient, those are the extreme things or points that are outliers. When we apply, well, it's a surface, so they were interested in kind of like finding a way to automatically remove this for different tasks. This is just one task. They sell different types of information. So the employable activity is one of them. Is one of them. When we apply this method that I'm going to describe, you get clean pictures like this, and then they were able to increase 25% of the information they can put out in the market. So that's an example of what we're going to see here. So in the first example, in portfolio optimization, we can see that we see an instance of a changing environment, non-stationarity. Changing environment, non-stationarity. The second example shows an instance of data contaminations and what we have typically the formulations that we see under DRO, distribution and robust optimization with optimal transport, they tend to hedge against global shifts, so the whole environment changes by a relatively small amount. In the other case, what is happening is that you want almost the whole environment to stay in tactical. Almost the whole environment to stay intact, that's one difference, and only very few points should change. So, these are qualitatively what you see, but there is also a very important difference that I'm going to highlight. And these are two papers that describe connections to statistics and how to solve these problems in optimization. So, there is a more fundamental difference, not only about qualitatively, okay, you just see a few points moving, it's a difference that has to do with how. It's a difference that has to do with how you sort of frame the problem, how you frame the contamination or the modeling specification problem. So a typical sort of a decision-making cycle, on the data-driven decision-making cycle, just takes this shape. You have data you assume that was generated according to some distribution. You get samples from the data, you either build the model or use the pyrita version of the data. Whatever it is, it's just this model. Is just a dismal. Then you make a decision, and then you have, according to some optimization problem, and then you have a number of sample distribution where you deploy your decision. And in statistics, what you assume is that as the sample size increases, you are going to recover the data-generating distribution. And in an ideal world, the outer sample distribution coincides with the data-generating distribution. So that's the case where there is no model mispecification. Model mispecification. Now, model mispecification can enter in two ways. It can enter here at the beginning, can enter here after you make the decision, can enter in both places, of course. But in statistics, for the statistician, the statistician kind of thinks that the deployment distribution, the environment distribution when you're going to deploy, coincides with the distribution that generated the data. To the data, and it's just what happened is that you are observing something that has been quantum. In distributional and robust optimization, at least the example that I showed you before, what is happening or what we think and the way we inject the modeling is a situation where the environment is different from either the distribution you collected, right? This is what I described. This is why this red curve, and informing the model with the market expectations. With the market expectations, they actually have an improvement. Or if you are a statistician, you say, well, look, I mean, maybe this is the same, but maybe the dimension is so high, and relative to the complexity of the problem, you have a nil-posed statistical problem, and the P hat N is significantly different from P star, and then you can, you know, this can be a helpful regularization technique. In either case, the In either case, the misspecification happens not at the beginning, but after you make your decision. That's the order in which the misspecification happens plays an important role. Now, there are many ways of dealing with model misspecification or model ambiguity. One way is to take an adversarial approach. So, you take an adversarial approach that is, I was saying, rooted in the Rooted in decision-theoretic fundamentals. In the statistical case, you formulate a game and the game will take this form, an adversary chooses first, and then the statistician follows. The statistician thinks that the data, the true is hidden in the data. The adversary has moved. In distribution and robust optimization, you make your decision, then the nature chooses. The nature chooses. So the order matters. Now, then I'm going to highlight. So typically the formulation is an expectation, it's a linear function of the probability distribution. So something like this. And you can think for the rest of the talk that this is just a function of linear function of the risk factor x. So it's theta transport sense like the portfolio selection exam. So you have a maximum problem. You have a maximum problem in robust statistics, or at least my formulation of what I'm trying to kind of go to what is a good policy in robust statistics. And in the arrow, you have this min-max. So let me highlight two points. So this B is going to be an optimal transport ball. This class of policies for the statistician, this class of policies actually are free. He's free to do whatever. Are free. He's free to do whatever he wants. He just wants to achieve some minimax statistical risk. And in DRO, typically we have a simple class of policies linear because for ease of implementation and so that you can, you know, typically this for complicational difficulty. Okay, so most of the for the talk is going to concentrate in Talk is going to concentrate in the rest of the talk about this case. I'm going to argue that by natural modeling choices for the statistician of the policies and for the policies, these ones will make this problem such that max-min is not min-max. These are completely different problems. And the choice of the geometry, of the perturbation, is also. The geometry of the perturbation is also going to be, both are going to be related to optimal transport, but they have to be different if you really want to capture what we want to do here. So I don't have to explain to this crowd. In the bank collaboration example you gave us, you were rearranging the intellectual chiefs movement. Yes. Where does that fit in? Where does that fit in? The gradients, the gradients are, if you look at the gradients for a curve like this, you are going to see like a huge gradients compared to something like this. So the outlier would be the norm of the gradient. That procedure would be a distribution robust optimization procedure? No, it's going to be a robust statistics procedure. At the end of the talk, you will see what the procedure is. It's because it's smooth. Because a global shape is a bit more efficient. Because a global shape is a little bit different. Yes, yes, it's a global shape. Yes, exactly. It's they they don't they the the reason they are not actually presenting this is because everything looks great here. Most of the things, just these little things, right? They have to, these are outliers. Okay, so this is, you know, this slide. Sorry, I didn't have channel if I wanted to change the slides that are more appropriate for this crowd. Everybody knows. Are more appropriate for this crowd. Everybody knows in this crowd what is optimal transport, but you know, okay, what is useful, I guess, is the notation. Something that is also well known here is that there is a dynamic view of optimal transport. So this is the part of the talk where I kind of explain why optimal transport. And in an audience that is a general audience, I say, well, you have this dynamic view, and this allows you to visualize as you change. To visualize as you change the modeling specification, you can visualize what the points are doing in the Nash equilibrium, right? And you can see what the adversary is doing, what are the more damaging points, and that gives you a lot of intuition also of what are the dangerous scenarios, right? So that's one of the reasons. It also gives me a chance to show a nice picture. Another reason for why you want to do optimal transport, at least in the distributionary robust optimization case, Optimization case, well, it makes a lot of sense. Like, there are two ways in which you can really have an incorrect model. You can have the likelihoods are incorrect. You know, you think that such and such event has such and such likelihood, and that's wrong. Or the other possibility is that the outcome was incorrect, right? There was a modeling error. These both things can be, in fact, are part of optimal transfer. So that might be surprising to you, but for in from But from the standpoint of distribution and robust optimization in your formulation, you can reduce a phi divergence problem or KL divergence DRO problem into an optimal transport problem. All what you need to do is you include the likelihood ratio as a part of your randomness, you lift, and then you assign a cost of transportation for the likelihood ratio. And that's something that. So it's very, very, it basically covers, you know. It basically covers the ways naturally that you can model fundamentally, but it's flexible. So that's why we use optimal transfer. Okay, so now I am going to explain to you what a statistician would consider a good estimate. So the statistician would think that I'm going to go back to the case of just estimating empirical mean. So very simple problem, you estimate empirical mean. simple problem you estimate it peak admit the statistician thinks that the data that in the data that is contaminated therein lies the truth okay he needs to extract the truth out of it so he is going to design an estimator theta as creative as he can be based on data that has been contaminated with p-bar and he his figure of merit is still the truth somewhere that is there inside okay and so he wants to get the best possible estimate to this problem Possible estimator to this problem, and then he wants to take the expected value under the distribution that has been contaminated because that's the model of randomness in this p-value, this IID, and then he wants to minimize that. So, he's going to select the best possible algorithm for the worst-case situation. So, an adversary is going to select the worst case P-bar that is inside some contamination ball. I'm going to select total variation, and over all. And over all possible data generating distributions that will be contaminated. So that's the mean here over theta and the max. So it goes like that. That's the mean, and then the max over all models that generate the data and all contaminations around that model. Okay? Because statisticians want a lower bound, then you want to do this m you know, mean max and this expectation because but because you want a no lower bound, it suffices to do with isolate an event with some with a correct rate. Event with some with a correct ratio. Okay, so that's what this minimum, this min-max is what is called mean-max in statistics, and that's the figure of merit. So we want an estimator that achieves that. So as a proxy for that estimator, I'm going to think that the adversary has made its move, that's a max, and I'm going to do this here. I'm going to take a mean mean. So I'm going to correct what the adversary has done. That's my policy. That's what I argue makes sense. Policy. That's what I argue makes sense. If he has contaminated, then I'm going to correct what he has done. Okay, so now this is the problem I'm going to solve, a mean-min problem. Statisticians like something that is the Hoover contamination model. That's a weaker version of this optimal transport total variation contamination. So that's also something studied in statistics. Study in statistics, so that is the case where CXY is an indicator function, x different from y. So, because I want to do something that can be computed and apply gradient descent and so on, I'm going to realize this and I'm going to use a concave function. But the estimator is this one. Now, this thing that I'm going to do, this min-min, is the proxy for this, and then I need to check that it actually achieves the rate, the optimal mini-max rate. That's a good idea. Optim and minimax rate. That's a good estimate. Okay? This is the result. So if you have enough separation, the heavy lifting in the result is in this paper by the annals of statistics. That's the lower bound, right? So if you have a, for this mean estimation problem, if your contaminated distribution is sufficiently light tail and you use Light-tailed, and you use an epsilon total variation neighborhood for contamination. This is the size move. You clean the data with this estimator, the mean, mean estimator, this one, right? You match the delta chosen like this. Then this estimator is minimax optimal, and this is the minimum max rate. So this is optimal in all of the parameters. Okay, so the Okay, so the key message then is that something that is distributionally robust, but when the adversary plays first, in this case, is of the form min-min, not min-max. So that's one thing. So in robust statistics, I think of this as, you know, this is a harder game to play, and the reason this is a harder game to play, to This is a harder game to play. To play this game well, you need to solve this problem. And this problem, because you have this minimum here, this function is convex, you have the minimum of convex functions, this is nasty code. So it's a harder game to play well. They are all, I call it a harder game to win because the adversary moves after you. So you are at the mercy of the adversary. But on the other hand, this game typically for Hand, this game typically for these types of problems is easier to play because you really are solving a complex optimization problem. So, these mean-mean formulations are recently investigated in operations research on this form. They have also a tradition as a regularization to approximate some problems for the procaflera regularization. But yeah, so that's, I think, that's the message of the talk. This is what is robust. Of the talk, this is what is robust, a mean mean, not a min-max. Now, because I'm interested in, you know, I want to approximate the total variation distance, I'm going to choose this type of concave function, so norm to the power r, r between 0 and 1. And this also will, as you will see in the pictures, it will have exactly the desired characteristics. When you do this, then the rectifier, the transporter that rectifies, that helps you. Transporter that rectifies, that helps you, actually moves points that are far away. So the structure of the optimal transport plan of the distributional, the robust, the statistically robust optimal transport corrector has this characteristic that it takes graphs from far away and moves here. This might not come as a surprise if you are familiar with these classical papers of Angol Macran and Fegom Kisoli and Sarcambroy. Broadly. So, this is a picture. So, again, mean estimation problem. This is the data. Let's say I want to compute the mean. These are the outliers. I introduce this mean-mean problem. And this is what this thing is doing. So, you can see as I increase my budget, my correction budget, I'm starting grabbing from, start from what is. Grabbing from a start from what is far, and I move it here to the center, right? So I'm kind of removing the outliers one by one as the body increases, and that's what this program is doing. So it has the effect that we want to have. Now, if I instead use a convex cost function, do this. Do this. So here I'm doing mean max or min-min turns out to be very similar. If I did the mean max with a convex function or a mean mean, it would look like this. You know, very global changes. With the mean max, you know, they are trying to put it apart globally. With the mean mean, they are trying to put, you know, bring them together, but this is not typically a good model of kind of robust Robust decision policy, robust decision. So, the key difference between optimal transport distribution and robust optimization and optimal transport statistical robustness is this formulation in which you are not doing min-max, you are doing min-mean, and second thing, you should be using a cost function that is concave, not convex. Not convex. So here is another picture in the case of linear regression. So once again here, now you can see that you don't need to remove a lot of the data to get the stuff that aligns to the uncontaminated distribution. At some point, everything collapses, you are too greedy. But if you even just start removing a small fraction of data, of course, the delta has to be calibrated. Everything is relative. Delta is absolute value. So there is a factor here. It depends on the theory right here. But you can see that you can, you know, the same effect happens. I think this is the case. Let me see. Yeah, this is again, you know, if you. Yeah, this is again, you know, if you do a convex formulation, and similarly, this is min-max or mixed-min will will be similar, and you don't really, you know, get anything that is very helpful. Okay, so I hope at this point I have given you a good motivation, you know, why this estimator is good in principle, at least I did it for the empirical mean, whereas, you know, why optimal transport. Why optimal transport makes a lot of sense. I don't need to convince this crowd about that. Why a concrete function also makes a lot of sense. And now, here, the ugly part, I need to talk about the ugly part. So the ugly part has to do with the fact that I hinted to this issue that in this problem, if the uncontaminated version of the problem was convex, a convex optimization problem, the minute I introduced this mean formulation, this will result in a non-convex. Result and non-convex and non-smooth optimization problem. And we need to address that problem. And statistical thinking is going to come to the rescue and help us address this problem. That's what I'm going to explain now. So this is an example. This is the case of a mean estimation problem. Linear regression is very similar. The DRO version of the problem is well known here. You have this, in the linear regression case, it would be the square root lasso. Case it would be the square root lasso penalty, right? In the robust statistics case, with a convex cost, you subtract a constant here. So, this actually is a nice problem if it was convex. So, if convex, if you were able to pick convex and convex made sense, this would be a beautiful problem on screen. So, this is something that is tractable and nice, but unfortunately, it just doesn't work. So, this is the one that we are interested in. For this problem, For this problem, the profile, this one you can see is nice, it will be convex. This one is not. That's the problem. And so this is the case where delta is 0.5. This is the case where delta is 0.05. The hard parts, the hard the the the hard uh features of this problem um i is not not that much the shape, the problem are the cusps. Shape, the problem are the cusps. These things you don't see it, but these are cusps, inverted cusps. And those are problems for algorithms like gradient descent, but that's not nice. It doesn't play nice with those algorithms. So you hear the cusps are still there, you just don't see them. Now, it's very evident when you look at the problem like this with data, disk data. Data, discrete data. So the solution, you know, it's not smooth. You have this index. Basically, you start counting until you accumulate enough budget, and then you split the last atom, and then you move it as much as you can. It's just the picture, right? You start kind of moving as many points as you can, and then the last one you move it as much as you can. So this is not even differential, that's the problem. So the discrete So, the discrete is differentiable but not continuously differentiable. So, how to smooth the problem without changing the statistical guarantees? That's what I'm aiming at now. So, this is going to tell us, this result is a little cleaner in terms of explaining what's the structure of the optimal transport. And it's also going to help me build an argument. An argument that will allow me to smooth the data and argue that the smoothing can be large enough in application so that you basically you have a smoothed version of the program that has the same statistical properties. And to do that, I'm going to, you know, kind of first I need to present this. This has been simplified for the ease of presentation. I'm going to give you a quick sort of argument in the next slide about why. In the next slide, about why this result is true in a very simplified case. And I'm going to walk you through these assumptions. And as I explained to you in the next slide, how the assumptions are used, you can see that how the assumptions can be relaxed, and the result will be analogous. It's just going to be more complicated to state this kind of thing. So if you assume that the function is convex and Lipschitz continuous, and those are things that are important. Those are things that are important. You can relax this, but you need to have some sort of polynomial growth, quadratic or something like that. L of 0 is equal to 0, that's something that you will see later, that is not as important. Symmetric is definitely not important, but let's say symmetric, that this thing can be estimated easily. Suppose that x has a positive density, that is important, and you have one plus epsilon moments. And you have one plus epsilon moments on this contaminated distribution. Okay, so basically you have finite mean. And this is not as important, but it's happens in every statistical model in practice. So this limit could even be zero if you want. That's okay. So really, what is important is the convexity, the Lipschitz for this exact result. That's really the Side result, that's really the essential part, and the density. The density is important. Okay, so what this thing is saying is that this provides an asymptotic expansion of this optimization problem. So this optimization problem is equal to, you know, as delta goes to zero, you didn't do anything, and you correct this amount. So basically, you remove all of these points that are larger than some threshold, and the threshold is computed so that this cost. That this cost condition holds. Okay, so let's see. There is a Lagrange multiplier, which is the shadow cost that is hidden in this B, and in the next slide you will see what's the shape of it. Okay, so how this, so that you can see what's intuition, this is precisely what you remove here. And the concavity plays a key role. So, you know, we start with the optimization problem. So you want to find the minimum over all random variables delta. Over all random variables delta that have the cost constraint such that when you correct this x by this amount delta, when x follows this contaminated distribution, you want to solve this optimization problem, finding all possible random variables that couple with x, of course. So this has a dual formulation. There are a couple of results. There are many results now that show this duality at the level of generality that is needed for. At the level of generality that is needed for here. So you need to solve this inner optimization problem. Here you can see that if L is slip shoot, if L is linear with the slopes that do not match left and right, so if it's non-symmetric, well what you would need to do is you need to intersect with the case where peta x is positive or negative, and you deal with the positive or negative case separately. So that's something that can be done. In this case, the slope is the same, so that's why the C. Case the slope is the same, so that's why the symmetry. And here you just simply use duality, so this theta star is the dual norm associated to whatever norm you use to define the body constraint of the transportation. This becomes a concave optimization, the minimum of a concave function, and so we know that this is achieved at the extreme points. And this is the extreme point of interest when you solve for delta, so precisely. Solve for delta, so precisely this value is the value of the transportation. So, this is the optimal transport cost when you apply it, right? So, when this is better than just moving zero. So, this is why the optimal policy ends up being precisely this. Just move an amount, and this is this B, and this is the Lagrange multiplier. So, in this formulation, asymptotically, you can get everything, the Lagrange multiply as a function of. Multiply as a function of p. If you have a density, there is a unique solution for this problem as delta goes to zero, and that's what will play a role in selecting the smoothing. So, this is in the case where the data is smooth. Of course, in practice, you have discrete data. So, what is it that we are going to do? You give me the data, I apply some kernel smoothing, some kernel. Kernel smoothing, so Gaussian smoothing, right, with this parameter sigma. Gaussian is not the optimal thing to do, but it serves well for this top. So, Gaussian smoothing, one important thing is that this Gaussian has light tails. So, this becomes automatically differentiable under very mild assumptions, if I'm continuously differentiable. If the B, if the B, this B, unfortunately, Unfortunately, it will depend on theta here. If it didn't depend on theta, then this would be, in fact, C infinity, but continuous differentiability is enough to apply a standard resourcing optimization that allows you to enforce guarantees with the optimal convergence and interactability for these problems. So, how to choose sigma so that we don't flow. So, how to choose sigma so that we don't fundamentally change the statistical guarantees? So, here is the thing. This is the optimization problem we want to solve, right? So, we want to minimize over, say, some compact set over a space of decisions data. We know this is still the gap that we have. So, I described to you that the case of the minute. The case of the mean estimation. And for linear regressions, you still, if you ignore theta, just the minimax rate in total relation, just as a function of contamination and sample size is still correct, but not in terms of the dimension with theta. So that is still not, that we still don't have yet. Also, the thing that we still don't have yet is, I told you the minimal statistical error with total radiation contamination, but I'm here doing But I'm here doing R strictly positive, so that result we still don't have yet. We believe it's going to be true, but assuming that's correct, correct, that we do have the error of this one, then the smooth problem, the difference between this, which is a hard thing to solve, and this, which is an easier thing to solve, in fact this one is easy for delta small, this will have a global optimizer and you can reach the global optimizer. Optimizer and you can reach the global optimizer. So this problem is much easier to solve, and what we want to do is choose sigma so that this problem becomes essentially the same as this problem from a statistical standpoint. That's the point. So how do I choose sigma so that the error doesn't start to compete with this error? So the way in which I'm going to do it is I will not I will not describe this, but I'm going to provide an intuition. So, if this under the contaminated distribution, this p-bar is regularly varying. So, what regularly varying means is basically like the tails are decreased like a polynomial. And this tail-bar means that you can add logs, polylogs, and any slowly varying function. If the contamination model is larger than 1 over root n, big constant times 1 over root. Big constant times 1 over root 10, which makes a lot of sense because otherwise you really have a purely statistical problem. So I would say, I'll argue, okay, this is a natural assumption to make. If you select r between 0 and 1 half, then 1 half is valid, which is great, because that facilitates a lot. Many of these problems can be reduced to semi-definite programs when you have piecewise linear convex functions. When you have piecewise linear convex functions. Then this problem, which is the one you want to solve, and the problem that you that you this is the one that you want to solve because it's easier and the problem that you should be solving because it's statistically optimal, these two things differ by sigma. So now I need to motivate why this distribution contaminated being regularly varying makes sense. The motivation The motivation is that if you look at the hard cases in the minimax result that I showed from this Analyst of Statistics 2022, you realize that the hard instances, the thing that you are really worried about, are situations where you have a very heavy tail contamination. So you want to make sure that you project to something that has finite variance, from something that potentially could have infinite variance, and yet you retain the epsilon error contamination. Then, when you move there, then you can. There, then you can do your estimation with means and variances, you get the 1 over root n statistical error, and the contamination is always there. So that's why it's epsilon contamination or delta contamination plus 1 over root n, assuming you can do this sort of projection. So that suggests that an adversary is going to have potentially infinite variance, and this accommodates that, so finite mean, but infinite variance, and that's the motivation of why we are doing the analysis in this environment. In this environment. So, when you do that, then this B, the optimal choice, actually is independent of sigma, asymptotically. And the reason is also very simple. When you give me a distribution that is heavy-tailed, if I add light-tailed smoothing, then the distribution is still regularly varying and the asymptotics are largely unchanged. It doesn't depend on C. Now, this thing. Dependency. Now, this thing, what this thing requires is that this is also true even if you don't have the two contaminated distribution, only if you have samples, right? So if you have samples and I send delta to zero as n goes to infinity, I will have enough samples sort of to if if this doesn't degrade to zero too fast, then I'm going to be estimating the budget constraint with a good statistical precision basis. Good statistical precision, basically. So that's basically the intuition. You don't, you know, this B ends up being exactly the same as this Bn that depends on sigma in principle is the same as this Bn. And now you can do, you can, you know, from there you can get this error for the sigma. So you could replace it here by B, then you do this expansion, you get this signal. So the key message of the talk, at the end of this discussion about This discussion about the optimization is that if we are able to show, right, if this little gap is closed, where the even when R is positive, you still have minimax optimality, then the prescription is choose sigma as a function of delta n. And typically in applications, this delta m is going to be strictly positive, you know, or something that is consistent with. Consistent with something like going to zero very, very slowly here. So, in other words, the message is that you can basically pick sigma constant, small but constant, and that will make the program, the optimization problem, at least for a small contamination, tractable. Even if you have this, if it's still non-convex, but still a global optimizer, and you don't have these cusps, you can write through the cusps nicely. So, this is So, this is, we are building all of this theory. There are, at this point, I think we have a nice picture to complete, right? A sort of like machinery to construct optimal transport robust estimation in an environment that is practical. So, I mentioned, you know, these problems, mean, mean, are problems that are of wide interest in operations research. They are studied under the name of local field. They are studied under the name of Lochefellian relaxations. Typically, they involve non-smooth, non-convex optimization. The beauty of these problems when you inject the statistics aspect of it is that you can inject the smoothness, you can do it in such a way that for the task at hand, which is fine, a good statistical estimator, you don't really interfere with that task, and then that makes the problem much, much easier from a computational A computational standpoint. I'm going to show you now something that I hope we are also doing. So one problem of interest is kind of generate extreme events, generation of extreme event distributions for tasks related to pricing insurance contracts with not a lot of data and whether. Weather, climate change, and things like that, motivated by applications of this sort. And so, what we are studying is informing this generation by looking at this transportation map and inverting the map. So, you know, getting examples where you kind of remove storms to do pricing, the impact of the storms, feed data, feed the inverse of the transporter, because you can. Of the transporter, because you can show the formula, you can take the inverse of it, informed by the statistic, by a specific task, like pricing, an insurance contract. And for that task, the natural sort of generation of events, of extreme events for that task, will be inverting this transportation. So now you send data that typically storms back boom to things that are extreme storms that are damaging for that task to come. So that's kind of like something. So that's kind of like something we're exploring. So, messages, just to summarize. So, if you take the point of view of modeling robust or distributional robustness, right, but from the standpoint of the statistical robustness via optimal transport, well, two things. You the the optimization problem should be set up as a min-min problem, not a min-max problem. Problem, not a min-max problem. Because this solution is actually the solution of the max mean. It's a max mean that the adversary has played. Given that choice, you do mean-min, and you are implicitly solving that problem. So there is a game there. It's just that as far as your move is concerned, you need to do this min-min. The second message is that once you do this formulation, it makes sense to use now, if you want to latch on to optimal transport, which again is very flexible. Again, it's very flexible, it makes a lot of sense, you can visualize, you should be using concave optimal transport costs. That promotes precisely what you want to see in applications. Yeah, I say that robust statistics is a max-min game, DRO is a min-max game, and I think this area of optimal transport to statistical robustness opens new opportunities in statistics, operational. Opportunities in statistics, operations research, and applications to extremes. We are doing that as well. Fairness, and it has very rich geometric intuition. And I think I will just finish with this. These are the QR codes for some of the papers. I hinted in the talk that there are many things under construction, so we're still kind of doing, but you can see a couple of things already up there. Maybe up there. Maybe you can stop recording because we can skip the question. I have to hit it once.