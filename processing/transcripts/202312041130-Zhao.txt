Today I'd like to talk about the kinetic search continuum in 3D order fields. And this has been our joint work with Bartis. And let me first introduce the equations we're studying. We're studying the 3D order equations on the periodic domain. By periodic domain, I mean the unit 2. And here the first equation is just a time evolution equation of the velocity field 3D velocity field. And P is the scalar pressure, and we're interested in compressible flows. So, the divergence of the velocity field is equal to zero. And here, eta is the initial condition of the velocity field. And we'll mention this eta later again. The local well-confident results of the radio infrastructure have been established a long time ago for development in cellular science HM for MADNA fibrosis. For M is less than 5 over 2. The solution is local process, and this was proved by Ketchoff. And in contrary to the local wealth profiting result, the global well-profit result is still an open problem. And this problem can be equivalent to the formal linkage and the finite time blow-up problem, and we'll find that blow-up. So the certain norm of the velocity field will go to infinity and the final. Local fields will go to infinity and a finite time. And in the context of solar space, this means that whether there exists a smooth initial condition in the solar space Hn for n less than 5 over 2, such that the Hm norm of the corresponding time evolution will go to infinity at not finite time. And this is closely related to the well-known problem about another skill sequence. Here we are setting the older equations so we don't have the misfortune separation. Okay. And for this fine-tuned block problem, there have been many studies. And on the theoretical side, I'd like to mention one of the most well-known results, which is the BKM criterion. And for the BKM criterion, they say that, okay, the smooth solution develops a singularity at a fine time if and only if the time integral of this L infinity norm of the vertic field goes to infinity at a fine time. And um and for this VKM criterion, uh I'd like to mention something here. I'll just use the board. Okay. So for this one, like if we take the curve of the equation, both sides, and we can obtain the allotted equation of the vorticity field. Okay, so here for the 2D planes, then you can see the right side because the vorticity field is orthogonal to the plane, so the right side are just steady. And in this way, we just get a transportation equation, transport equation of the vorticity field. So the efficiency norm of the vorticity will always be preserved, so there will be no co-hop for the 2D case. However, for the 3D case, this is more complex. However, for the 3D case, this is more complicated because of this vertex matching term and you can apply the vertical field. This is why the analysis of this 3D problem is more complicated. And for the 2D case, it's a direct application of the different criteria. Okay. And we're doing like numerics. So on the numerical side, uh, can we make this first one? Okay, thank you. And on the numerical side, many like point configurations have been proposed as a possible candidate for the fine translator model. And among the results, I'd like to mention two things. The first result is a thing with Kirk initial condition, which features two anti-parallel vertex tubes and that's climbing balls of some here. And that's kind of from here. I just took the picture from Harlow and Lee's paper, where they use like a quite different initial condition from cursed initial condition on the periodic domain. And as time evolves, the center of the two or three cubes will get light turned and they'll get closer to closer to each other, which will lead to the final blow up. And another thing I want to mention is the host initial condition, which features an axisymmetric flow on an infinite cylinder. I finished doing that. Okay, and different from the previous studies, where they kind of focused on specific type of configuration, and this is based on the author's PRI knowledge and self-centered configurations. We adopted a fundamentally different approach where we try to systematically search for the initial conditions that might lead to the fine-time blue-up. By search, I mean we are trying to formulate this problem as the optimization problem. As a coalization problem. And this approach has also been used by Kahn and Purchase in the study of potential singularity of 3D number stop separations. And let's go back to the formulation of our problem. So for us, we're not really using the PKM criterion. We go back to the subway space because for our solving of the implementation problem, we want to use a joint method. So we want to make use of the inner product structure of the subject space. This space. And here you can, here, we to fix discussion, we just choose the m to be 3, which is an integer larger than 5 over 2. And we also assume that the integral of the velocity field is equal to 0 over the whole domain. In this case, the H3 norm and H3 semi-norm are equivalent, so we just use the H3 semi-norm. And here, like, for block problems, we say the normal approach. Problem, we say the norm will go to infinity. For our optimization problem, we want to optimize that norm. And now, let me introduce the optimization problem we are studying. We are studying this objective functional, which is the squares of the H squared semi-norm of the time evolution corresponding to an initial condition eta. So, here, this objective functional depends on the initial condition eta and also the final time t. And after this, I want to also mention the initial conditions we are interested in. As I've mentioned before, we are interested in smooth initial conditions. And so we cannot just use a smooth space H3. Instead, we consider this Doubt space endowed with Dubie norm. So for every function in the Doubt space, it has a finite Dubie norm. And I'd like to point out for this Rouver space, you can see that there is an exponential term. This promises that. Exponential term. This promises that the coefficients of the corresponding function will decay faster than exponential. And also, as the parameter sigma decreases, we will have a larger and larger space. And when sigma is equal to zero, we just recover the sublime space H3. And another thing I want to mention about the initial condition is that due to the scaling symmetry of the other equations, we just consider the initial condition with 0 and H374. After this preparation, I can finally introduce the optimization problem we are studying. We are just studying this, we are trying to given a finite time t, we are trying to find the initial condition belonging to the mixed plus and one, such that the corresponding objective functional will be maximized by this initial condition. And we denote this optimal initial condition by two data. And And okay, now how do we solve this optimization problem? Numerically, we use an adjoint gradient, sorry, conjugate gradient method. And for this method, one of the most important things is to compute the gradient. And how do we compute the gradient? So if we compute the delta differential of this objective functional, we'll obtain this inner product between u and u prime, where u prime is the solution of the linear Rise Euler equations. Notion of the linearized Euler equations. And on the other hand, we can wheel this as a, for a fixed initial condition eta, we can wheel this as a bounded linear operator on eta point. So using the Greece representation theorem, we can define the gradient as its read representation using this inner product structure. But here is a problem. You can see that for the gradient, we want it to act on the initial preponderation in the To act on the initial condition e define. However, what we have here is an inner product between the n states, and the initial condition is hidden behind the n state. Now we need to do something to transform this inner product of n states to the inner product of initial state. How do we do this? We just introduce the adjoint states use the red and t-star and also the following duality relation. And by introducing the adjoint states, we can By introducing the adjoint states, we can express the gradient as an expression of the initial state of the adjoint of the solution of the adjoint system. And here, I'd like to mention two things. The first thing is that this button flyer is actually something like a molecular, and it goes smoother than the U star because, as I mentioned, before very interesting smooth in neutral conditions, and we want our gradient to be the And we want our gradient to be in the same reverse space too. And another thing I want to mention is about the adjoint system. So you can see, like, different from the previous order equations where you evolve equations converting time. Here, for the adjoint system, the end state is given in terms of the n state of the order equations. And we evolve the adjoint system backward in time to obtain the new start at 0.0. Okay, now our numerical method, our numerical algorithm, is just the conjugate gradient method. And for this method, I'll just mention one thing, which is about the conjugate gradient part. So the search direction depends on two things. The first thing is the gradient at the current step, and also the search direction from the previous job. And also, when we get a search direction, we will perform a line search to find the optimal step size along the search direction dn. And this is actually the most expensive part of our numerical computation because we need to evolve the forward Euler system multiple times for different values of tort to find the optimal torque. And okay, the last thing I want to mention about the numerical algorithm part is the numerical method we're using. We're using the pseudo-spectrum numerical method and we're using a uniform mesh with n field gradient third time. So here's the thing. Like theoretically, you can replace the normal equal to infinity. But numerically, you can never compute infinite things. And how do we like this seem very And how do we like distinguish the different behaviors of blue up or non-blue up? We achieve this by performing a max refinement study. So for example, for a short time window T, as we refine the special resolution, we will solve the optimization problem again and again for different special resolutions. And if the objective functional converges to something finite, we say that, okay, the Euler equations are well closed instead of this short-time integral. Short time interval. However, for a long time interval, and as we refine the resolution, you can see the optimal objective functional goes to infinity. And this indicates that there might be a possible singularity inside of this long time interval. And how do we understand this? Because as I mentioned before, we cannot really compute like blowing up things. As we refine the resolution, we just get a better and better. We just get a better and better numerical approximation of the potentially singular flow. And in numerical computation, we use special resolution ranging from 128 cube to 1024 cube. So one thing I want to mention about our optimization problem is that it is not convex. This means that we will see something like the local maximum. And this is indeed the case. In this case, we solve our optimization problem for different initial guesses and we use a Taylor brain context and we use random initial condition. We also use curse initial condition to show you which features two anti-parallel vertex tubes and house initial condition which is an axis symmetrical. And here the plot is the dependence of the optimal objective functional on the iterations. And you can see Iterations and you can see like except curse condition, all the other three initial guesses will give us almost the same optimal objective function value. And we also check the state and these flow configurations are almost the same up to certain translation and outage. And why is the current initial condition doesn't give us a better optimal value? Better optimal value, and we think this is because Chris' initial condition is designed to produce significant growth of the norm for a fairly long time window. And the further problem, we re-normalize the initial condition, and to see that significant growth, we actually need the time window which is something like 100k. And okay. As I mentioned before, like for we have a sort of window and So we have short-term window and long-term window, and we have different behaviors of the objective functional. And the short-time window we use is 25, long-time window we use as 75. And we obtain these two values just based on our numerical experiments. And here, this is the different behavior of the blow-up and non-blow-up situations. So, for example, okay, so here this plot is a dependence of So here this plot is the dependence of the objective functional on different spatial resolutions. And you can see for the short-term window, as you increase the resolution, the objective functional converges to something finite. And as I mentioned before, this indicates that this evolution is well posed over this short-term. However, the behavior is totally different from the long-term Windows 75, and you can see that the increased resolution in the objective functional is not converting. Is not converting to anything finite. And most importantly, you can see the slope is increasing more and more rapidly. And here I show you some pictures of, sorry, yeah, I show you some pictures of the objective function. I think the main question you will ask me is like, so what does the flow look like? And now I'd like to show you how the flow looks like corresponding to this point, which is the optimal initial condition obtained with the longest average. Obtained with the longest tor window and largest resolution, 1024 cubits. Okay, so these are the three rotistic components corresponding to the initial condition. And you can see like these three, this is omega 1, omega 2, and omega 3. And they look almost the same up to certain functions. And this indicates that our optimal initial condition possesses certain symmetries. And this is indicative. And this is in the case. So here, I'd like to show you the vorticity field corresponding to the end state. And for the picture on the left-hand side, the red color denotes the magnitude of the mortgage field, and the yellow color is the point lines, objective functional, and the green lines are the string lines. And how do we understand this picture? You can see like actually this features two anti-profits. Actually, this features two anti-this features two vertex rings that rotate in opposite directions. And also for the string lines, actually, they will first move towards the center of these two rings and then diverge. And this is the mechanism that draws these two vertex rings moving closer and closer to each other. And I want to show you something about the structure. The structure, like so I can show it, sort of show different angles. And as you can see, like this looks like a red donut. And here you can see like we have these two vertex frames. And one symmetry I want to point out is you can see that this structure has this kind of rotation symmetry around the body diagonal of the tube. And this is the coincidence with Hoh's axisymmetric initial. Axisymmetric and initial condition. But for us, we're working on this periodic domain. So, this kind of discrete symmetry, you rotate the configuration around the body diagonal by 120 degrees. It's the best discrete symmetry we can get. And due to the symmetry of the vertices field, we just try to plot the vertices component that is orthogonal to the symmetric point. Is orthogonal to the symmetric point x is equal to y. And you can see that this features two components of different signs and the value of the vertici, this orthogonal vertical component changes over this narrow gap. And in the end, let me just show you some time evolution. So this is the time evolution of the vertices of field. Okay, you can see the time evolves. We will have these two rings, and they are moving closer and closer to each other, and the potential singularity might develop in the center of these two rings. And process. And this is the time evolution of the vertical component orthogonal to the plane. So you can see that they will concentrate. They will concentrate near this narrow gap. Okay. And if you're interested in our work, feel free to check out the paper. And one last thing I want to mention about the future direction of our work is something related to the finite resolution. So here we are using the pseudo-spectral method, which means that our solution is cursed by the resolution. Is cursed by the resolution. Here you can see that this flows have certain like small stable features. And for the pseudo-spectrum method, we want to add more grid points over this small gap. We need to add grid points everywhere in the canonic box. And this is quite expensive. So in the future, like we want to use something like a, for example, like adaptive mesh method. So we can just have finer meshes over there and maybe coarse meshes. Over there, and maybe force meshes at other places, which is more cost cost-efficiently for numerical simulations. And that's our STEMQ.