complexity. Um because I think that's part of what's fun in the standard protocol. So um let me tell you a little bit about distributed certification. So the setup here is that we have some distributed network and the network is folks um sorry, I think we are seeing the wrong screen here. Um for some reason. Okay, maybe now we get it, but uh the speaker view is looking at the audience. The speaker here is looking at the audience. Can you see now? Because it's still messed up. My speaker view is a random person. On Zoom, I won't disclose the name. Just pin. Just pin the right view in Zoom. Just go to it and pin it. Yeah, but before it just worked. Thanks. Thanks. All good. Is everybody online able to see? Okay. Cool. Okay. Fortunately, we are still on the first line of the first slide, so not much lost here. Okay, so we have a distributed network, and this is represented by graph G, which is the topology of the network, who can talk to whom. And some input assignments. And some input assignments, every node in the network might have some input, and we would like to say something about the combination of the network with these inputs. And what we would like to do is to verify that this network has some desired property. Because maybe we set it up, for example, to have some desired infrastructure. Like in this example, every node has a pointer to a neighbor, and together these pointers form a spanning tree. Form a spanning tree that we can then use to communicate over. Or maybe we've set up routing tables, or maybe we want the network to be a good expander. There's many kinds of properties that you might be interested in. Maybe when you designed this network, you had that property, but later on, due to some faults and changes in a network, maybe it stopped holding. So we'd like to be able to very quickly and efficiently check that the network still has the property that we're interested in. That we're interested in. And what we would like to do is, in order to help that, we'd like the algorithm that computed this infrastructure or whoever designed this network to leave us a certificate to store at every node of the network some small label, a proof, a piece of a proof, that we can quickly verify to make sure that the property really has. So we're looking for some notion of a distributed proof here. Some notion of a distributed proof here that the network that we have satisfies a particular property that we're interested in. So, the first to kind of formalize this notion were Corman, Kuten, and Pelleg in 2010. This was already implicit in a lot of prior work on self-stabilizing and fault-tolerant distributed algorithms, but they were the ones to kind of pull it out and give it a name. And they called it proof labeling schemes. And the formalism that they come. And the formalism that they come up with is the following. So, every node in the network knows already some stuff about the network. It initially knows who its neighbors are, and it knows its own input. And it might also have some additional information, like maybe the nodes have unique identifiers in this network, like an IP address or MAC address. Maybe they know the size of the network, the diameter, the maximum degree, some auxiliary information that they might or might not have. And the proof is a labeling that assigns to every node of the network some certificate or label. And now, what we're going to do in order to verify the proof is just have every node look at, first of all, its own local view, the things that it knows, its input, its neighbors, and so on. And also look at its own label and the labels of its neighbors. And based on this, it has to decide if it's happy or not, if it accepts or rejects. It accepts or rejects. Okay, so this is a local decision that every node is going to make. And what we would like is that if everybody accepted, nobody raised the alarm, then the property should hold. Soundness, like with NP, except that here when we say accept, it means everybody accepted. And also completeness. So if the property holds, there should be a labeling that makes everybody accept. Okay, and you can see here the reason that these are called proof labeling schemes is that they're kind of inherited from a line of research called labeling schemes, where you have some graph, you want to place labels on all the nodes, and you need to be able to deduce some property from just these labels alone. For example, like an ancestry labeling scheme, you have a name. You need to design labels for all of the nodes such that if I take two nodes and I only show you their labels, you can tell whether. Their labels, you can tell whether or not one note is the ancestor of another. So, this is how they came up with this formalism. It is a labeling scheme, but it's also a proof labeling scheme because it has these elements of soundness and completeness, which are not present in plain labeling schemes. Questions about this basic model? Is there any restriction of how the labeling is computed? No, the prover is all-knowing. Yeah. The assumption here is that I as the designer. Here is that I, as the designer of the network, placed these certificates, or maybe there was some difficult distributed algorithm that ran in the past and it's just leaving us traces. But it's a very interesting question also, like if the prover needs to be a distributed algorithm as well, how much really, how much power does it have? I'll touch on that a little bit. Other questions? Yeah. So for a spanning tree, if my label would Planning tree, my label would be, say, my distance from like some root or something. Yeah, so I'm going to do exactly this in two slides. Exactly. Yeah. So let me just say before this example, what is the complexity measure here? It's just the length of these labels. This is the only thing we can hope to minimize here. This is what we want to minimize. Okay, and here is a Yahoo example. If I want to certify that these current pointers really do form a spelling tree, then it's enough. Then it's enough to. So, first of all, the problem statement is that every node is given the name of some neighbor, and I would like to verify that these together form a spanning tree. And what I'm going to tell every node is, here is the ID of the root of the tree. This is your own distance from the root. And then what you can verify is that all of your neighbors agree on the root. And also, the node indicated that kind of is you're told this is your parent, it should have one. Told this is your parent, it should have one less distance from the work. And this means that it's cycle-free and it is spanning, so it's a spanning tree. Okay. What can we say about the kind of complexity measures that we can encounter here? So first of all, anything that you want to certify, you can certify by just giving all the nodes everything. So if you describe the entire So, if you describe the entire graph and the entire input assignment, that kind of solves everything. Just tell every node the entire network. And then the nodes make sure that the prover told everybody the same thing, and also that the prover accurately described their own local view. And if you do these two things, and everybody has the correct network, and you just locally check the properties that we want. There do exist properties that you can verify with a single bit, right? I'm off with an example. Come up with an example? By far thickness? Yeah, exactly. Bipart thickness. You just tell every node this is the site that you're on, and you look at the sides of your neighbors, and they should be different thicknesses. So by far thickness is like a one-width property. So we see that the playground here is like between 1 and n squared plus the size of the input. Can you say the the round is assumed to be connected? It can or it uh it might or might not be, but I am gonna assume connectivity generally. Yeah, there's many variants of this. Of this. If the graph is not connected, there's some things that you cannot certify without prior information. There might be a partition, if you don't know the size of the network, you just cannot overcome that. Okay. And we do know that some properties are like maximally hard, and I'm hoping that this is a bit of mika here who proved this. For example, if you want to prove a property like non-three colorability, this is On three colorability, this is maximally hard. And I'll show you another example in a second. And we also have some kind of structural understanding of what is easy to certify. It's not perfect, but here is a really nice result from the past year. Every graph property that you can define in monadic second order logic, talking about the edges and the notes, you can certify this very efficiently in graph. Efficiently in graphs that are sparse, that have bounded tree. So I won't get into this, but it shows you that there is some structural understanding here of what can and cannot be done. And interestingly, this goes back to techniques from model checking, from formal verification, which should turn out to be useful here. Verification step, the nodes can communicate with each other? Can we count that cost? So, in the model, the way it's defined right now, In the model, the way it's defined right now, you take your label, you send it to your neighbors. That's all you can do. And of course, what I want to talk about is what if we don't want to do that? What if we want to do something more general? But this is the model as it was originally presented. There are many exchanges. Okay, let me show you an example of the lower bound, and this is from Lika's paper. So the property that we can show is hard here is graph symmetry to prove. Graph symmetry to prove that the graph has some automorphism, which is not the identity function. So I claim that this is as hard as it possibly can be. It requires n squared bits of certificate of label. And how can we show this? So let's look at graphs that have this form. They're going to be this barbell kind of graph. And we have to kind of place some small restriction here. Abstriction here. I don't want there to be a non-trivial automorphism from this part to itself or from this part to itself. So I'll just pick like a canonical representative under this equivalence relation. It still leaves us with 2 to the roughly n squared possibilities. And now this graph is symmetric if and only if I can map this part onto this part. And this is basically like a And this is basically like equality. It's like two-party equality, and essentially this lower bound is a reduction from non-deterministic two-party equality. So if there exists a good labeling scheme for this problem, I can take just the labels of this note here and this note here and use them to come up with a good two-party protocol for equality. And what I want to emphasize here is the cut. What I want to emphasize here is the cut. So, this lower bound is by reduction from two-party communication complexity. It only works because of this very sparse cut. In Mika's paper, there are more interesting complicated lower bounds as well that do not work for the deduction, by the communication complexity. But they are also kind of sparse-cut-based. Require average size of the colours. Average certificates are still old, so do you know what size will go about? We don't really know. So I believe that you can prove existential lower bounds. You can certainly come up with a problem where the average certificate size will be n squared, but I don't know of a natural problem that has this property. Okay, so let's talk about this model for distributed proofs. Usually, in complexity, when we talk about proofs, we have a verifier that is computationally bounded, we have a prover that is computationally unbounded, the prover produces some sort of proof and gives it to the verifier, and then the verifier has to accept or reject, right? In our case, the verifier is a distributed algorithm. And so, what does it mean for it to be computationally bounded? If we want to go beyond this very basic formalism of proof labeling schemes, what should we be looking at? So, generally, when we talk about distributed algorithms, we care about mostly two things. Communication, the number of bits that the nodes need to send each other, and the time, the number of rounds of synchronous rounds that the algorithm executes in. So, more generally, you could think of a model where a verifier is any distribution. Verifier is any distributed algorithm that runs for some number of RANs, sends some number of bits on every edge. You can come up with kind of a more general model that way. And when you look at it this way, these proof labeling schemes, they are what you get when you restrict to one round algorithms because you're just sending your label to your direct numbers. They're deterministic. You're not using any sort of algorithms. And you force the message to actually be the label. Actually, be the label. So it's interesting to ask what happens more generally when you allow any sort of efficient distributed algorithm to be the verify. And here are extensions that people have looked at, kind of pushing proof-labeling schemes in various directions. So you can try to let nodes see further away, not just their immediate neighbors, maybe beyond that. You can let them see more information. For example, in Mika's paper, the nodes are allowed to know a little bit for free, like the names of their neighbors. The names of their neighbors got sent to them. And you can let them send different messages to different neighbors, kind of very natural things to do. You can add randomization. Unsurprisingly, that helps a lot in this kind of setting. You can weaken your requirements the same way that we have, for example, proofs of proximity. You can have a distributed proof of proximity, which is not exactly proving the property that you want, but it's proving closeness to that. But it's proving closeness to that property. And you can add interaction with the prover. And recently, we also looked at zero knowledge, and I want to tell you about that today. So I really wanted to tell you more concretely about our recent work on zero knowledge distributed proofs. And if there's time, I'll tell you a little bit about what happens when you increase the radius of the proof of the case more distantly than that one. Okay, any questions so far? So far. Okay, so let's talk about zero knowledge. Let's say that I would like to certify that the property that I'm interested in holds, but maybe the participants in the network care about their privacy. And when they're verifying this property, they don't want everybody to know their business. They don't want everybody to know who they're connected to, what their private input is. You want to certify the property without sacrificing too much information. Much information. Ah, before that, here's like a philosophical outline for this line of research. Generally, kind of these two lines of research have been developing in parallel without a whole lot of crossing between them. And part of what I've been trying to do is take the sparrow and kind of move it up this way. They go down. They go down. They go down. This is this is, yeah, you you're saying they should go up. Okay, so let me tell you a little bit about this work on zero knowledge. So what is zero knowledge classically? I'm sure you all know this, but I kind of want to review it because when we come up with a distributed definition, it's not obvious what it should be. So let's think about the classical definition first. We would like Definition first. We would like a proof where the verifier learns nothing from the prover other than the fact that the instance is in the language. And what does it mean to learn from the prover? What does nothing mean? What does it mean that I learn nothing? So the brilliant answer here of Wadium is that four instances that are in the language. For instances that are in the language, when the prover is being honest, the verifier can actually generate all of its interaction with the prover just by itself in its own head. This means that it learned nothing because it was already able to generate this interaction by itself. And nothing has many definitions, but it should mean something like you're generating the right conversation, either exactly the right conversation or close in some sense to the right conversation. That is what Bauffeng means. What about thing is. So, more formally, a zero-knowledge proof system is a pair of, sorry, a triplet of verifier, prover and simulator, where we want, first of all, the usual things, completeness and soundness. And in addition, the zero-knowledge property says if my input is in the language, then the simulator should be able to produce a view of this proof, a transcript, which is close in. Which is close in distribution to what the verifier gets when it interacts with the actual proof. And you can define this information theoretically, it's exactly the same distribution. You can define this as statistical zero knowledge, it's close to the right distribution. Or you can define this computationally. It's hard to distinguish the simulator's output from the actual interaction with the cook. Okay, so what should distributed zero knowledge mean? When this distributed network interacts with the prover, what does it mean that they don't learn anything? How should we think of that? Remember that in this distributed model, there weren't any computational restrictions. All that we were bounding was the communication and the number of frames. So in proof labeling schemes, the verifier, we said, The verifier we said is the distributed algorithm, it's a network. We don't have any computational assumptions, so what is the advantage that the prover has? What are we trying to protect? In the classical case, the prover was computationally unbounded, and that's the advantage that we were trying to protect in a zero-knowledge proof. Here, the advantage that the prover has is it is the global view, it knows everything about the network. So this is what we're trying to protect. The knowledge here is this knowledge of the entire network. This knowledge of the entire network. And because of that, zero knowledge should mean that I don't get this global information about the network. Maybe I'm able to learn a little bit, but only local information that I could have efficiently computed using an efficient distributed algorithm. Okay, so here's our definition. First of all, you need to tell me what you consider efficient, because in the Efficient because, in the distributed computing community, there's like a whole lot of possibilities for what is an efficient distributed algorithm. For example, you might say I only allow it to run for three rounds, and congest is a model where you can send log in bits on every edge. Okay, so fix this to be your favorite definition for efficiency in distributed curve language. And a proof system for this class of distributed algorithm and a language consists of a verifier in this class and a prover. The prover is unbounded, so it's not necessarily in this class. When you interact with this prover, what you do is, first of all, you talk to the prover and the prover talks to you. Maybe you want to interact with the prover also. Maybe you want to interact with the prover also, which we haven't seen so far. But maybe you don't. Maybe it's only that the prover gives you the proof. And then you execute the verifier, which is a general distributed algorithm from this class. A verifier produces a view at every node, which consists of what was my input, who are my neighbors, what did the prover tell me, what messages did I exchange with my neighbors? Did I exchange with my neighbors? That's also part of the view. And then the node decides if it's going to accept or reject. And in order to measure the knowledge that was leaked by this proof, we're going to introduce a simulator. And the simulator is also going to be a distributed algorithm. And it's going to need to produce the same view that we had when we were interacting with the proof. So, this is our definition for distributed knowledge. So, this is our definition for distributed knowledge. If you gave me a proof system, I'm going to look at the distribution of views that were produced by all the nodes when they're actually running the proof system with the proof. And I'm going to ask for the existence of a simulator. Generally, you can define some other class B and say that the type of knowledge that you gained is of this class B. If there's a simulator in the class B, If there's a simulator in the class B that exactly matches the distribution of use. Okay, so here I'm not yet saying zero knowledge, I'm just saying knowledge. For example, maybe my verifier runs for five rounds, but I can simulate it by a distributed algorithm that runs for three rounds. So the knowledge is kind of restricted to three hops away from me, even though what the actual verify. Though what the actual verifier does is maybe communicates for a further way. Maybe this is the kind of guarantee that I want to give. Okay, and zero knowledge just means that the verifier and the simulator are exactly in the same class. This is the classical definition for zero knowledge, right? You have an efficient simulator from the same class as your verified one. But you could also have defined it this way. I don't know if anybody has, maybe you guys know. For classical zero. For classical zero knowledge, okay, maybe the verifier is polytime, but the simulator is, I don't know, at least run in linear time. In that case, really, the kind of knowledge that you got is more restricted. Okay. If you're unhappy with this definition, yeah. So you would expect like B to be weaker than A? Yes, hopefully. Exactly. It's less interesting. It's less interesting, but still not trivial when B is not contained in A. I mean, the prover knows everything, so it's not even trivial that the distributed algorithm that doesn't learn the entire network can simulate the prover. It's not trivial even when B is very strong. And the stronger B is, the easier it would be to show. Yes. Yes, the more knowledge this proof is leaking, and so the easier it is to. So the easier it is to imagine like, okay, so maybe it's like five rounds of three, but that's still like fairly moderately dish. Yeah, agreed. Absolutely. So generally, the way we think of it is like, okay, A wouldn't be three rounds. It would be order of one rounds. All the algorithms that run in constant time, that doesn't grow with the network. This is the ideal. Okay, let me say one word about. Let me say one word about an alternative definition that you can have here. The definition that we have so far does leak information about the network because the simulator is a distributed algorithm. So whatever you can learn from this class A or B here, you can learn that stuff, right? The same way that in classical zero knowledge, the verifier, it has the graph, it can compute things about the graph that it didn't know initially, but it can compute them by itself. If you're not happy with this, if you If you're not happy with this, if you want even more privacy, you can go to a definition that is like secure MPC, like secure multi-party computation. And you can get that by just taking this class B to be algorithms that don't say anything to anybody. They just look at the local view of the node, and from this they produce the view. Also, it's under the same kind of definition. Okay, I want to show you an example just to give you the flavor of how this works. So let's go back to bipartite nest. And remember, the way we can certify bipartiteness is tell every node which side it's on, and then you talk to your neighbors and you make sure they're on the other side from you. So I claim that this proof is actually zero knowledge already. In fact, even strong zero knowledge. All the prover needs to do, it needs to randomly permute the sides, just to make sure, as usual. As usual. And so I need to convince you that there is a simulator that doesn't send anything to anybody and produces the view of the interaction here with the prover. But it's pretty obvious what it should do, right? You just sample a uniformly random bit and you pretend that you received from all of your neighbors the opposite bit. And this is your view of your interaction with the prover and with your neighbors. With your neighbors. So you can, without talking to anybody, completely simulate this proof. No knowledge was leaked here. Let's go one step up to recallability. You can prove this in a very similar manner. You just tell every node, the prover tells every node its color, and then you make sure that for each neighbor, they got a different color. Neighbor, they got a different color. This is zero knowledge. So, obviously, since I'm asking, the answer is no. But here, something interesting happens. It's in fact completely not zero knowledge. And in fact, it's easy to see that this proof leaks information from the complete other side of the network. So here are two network graphs where under any coloring that you want. Under any coloring that you have here, the green node here, V, by just comparing the two colors of its neighbors, remember in this proof, the neighbors send you their colors so that you can compare and make sure that the edge is properly colored. Now I can compare these two colors and I can ask you, did I learn anything from just the fact that these colors are equal or they're not equal? So under any valid coloring in this graph, Coloring in this graph, these two neighbors must receive the same color. And in any coloring of this graph, they must receive different colors. And the only difference between these two graphs occurs at distance data of n from the green node. So by just this thing, the node can gain very non-local information. Okay, so let me show you proof for Let me show you a proof for three-colorability that is zero-knowledge. And I think there's an interesting question here. That's why I wanted to show you this. So here's a zero-knowledge proof for three-colorability. I'm still going to stay in this framework where the prover gives every node a color, but of course now the prover will randomly permute the coloring as usual. And I'm still going to tell every node its color, but we know that. But we know that we cannot afford for the nodes to send these colors to their neighbors. That will immediately kill the zero knowledge quality. So instead, we would like to come up with some comparison algorithm or protocol that will check if the neighbors have the same color without actually telling what the colors are. And it turns out you can do this pretty easily. So this protocol is inspired by Graph Nonisomorphism. By graph non-isomorphism, what I'm going to do is, me and my neighbor will both toss a coin. If it's heads, we're going to agree on the same random color, and both of us will send this color to the prover. But if it's tails, each will agree on a random permutation of the colors and will send separately our permuted colours. Separately, our permuted colors up to the prover. So if the prover gave us the same color, here we're going to be sending it the same color, and also here. But if it gave us different colors, here it receives different colors, and here it gets the same colour. Now we'll ask the prover to tell us what the value of the coin was. And it can only succeed with probability half if it was cheating. So this is a claim that this is zero. So, this is a claim that this is zero knowledge. It's pretty easy to see, right? I can simulate all of this interaction by myself. The simulator assigns to me a random color, and then we can do this just without interacting with a neighbor, just pretend that we're doing it. And then the bit that we receive is just whichever coin value we choose. Okay, so it is strong zero knowledge. So it is a strong zero knowledge. And how many bits did I actually need to send? So this cost us a constant number of bits per edge, though, because I had to verify for every edge that I received a different color. So actually the total communication that went back and forth with the prover and with my neighbors is the number of edges. And if you think about the naive proof that was not zero knowledge, it was better than this, because the prover just had to tell me the color. The prover just had to tell me the colors. That's only order of n bits of information. So we're paying here for the zero-knowledge property. If you're not happy with this back and forth with the prover, you can actually get rid of it. I won't get into that. So there is a zero-knowledge proof where just the prover gives you the certificate, you talk to your neighbors, and that's it. But the open problem that I wanted to discuss here is this question, is there in fact overhead forgetting? Overhead for getting zero knowledge. And like we said, this scheme gets you a total communication, which is the number of edges, instead of the number of nodes. And the reason I think it's interesting is that a similar phenomenon happens in classical zero-knowledge. Because how do you do the classical zero-knowledge proof for three colourability? First, the prover chooses this randomly permuted three-coloring and sends you a commitment to this colour. Commitment to the sign. And now the verifier chooses a random edge and it sends the edge to the prover. And the prover responds by opening only the encrypted values of the two nodes that the verifier chose. And then the verifier can check if they're equal or not, then they look uniformly random. It's like a uniformly random pair of distinct colors. But the soundness of this is only one over the number of edges, because maybe there's a coloring that colors everything properly except for. That colors everything properly except for one edge. And so my chances of finding that one edge is just one over. So if you want constant size, you're going to need to repeat this a lot. Okay, so we see here the same phenomenon. NP for three colorability, it's only telling you the colors, it's only ordering. But zero knowledge, at least as far as I know, we don't know how to do it without this overhead, going up to the number of edges instead of the number of rules. In the distributed version, In the distributed version, there's actually a hope to prove this. There's a very concrete question here. Prove that any protocol where the nodes exchange with the prover. Let's not have interaction because that makes it very hard. Let's just have the prover send a certificate. What does the total length of the certificate need to be? Does it need to be purchased or the number? Okay, I did promise to finish quickly, so let me just. Okay, I did promise to finish quickly, so let me just tell you what else we can do. This is the part of the talk where I throw fancy words at you just to convince you that there's interest. So we can verify specific properties. For example, going back to this question of spanning trees, it turns out that you can actually verify a spanning tree in zero knowledge with no overhead. You can do it in one round by sending login bits to your neighbors. bits to your neighbors and also the labels will be of length log n. It matches the proof that we saw initially, Jakob's proof, where it was just telling you log n, it's kernel. And we also have a general compiler that can take any proof labeling scheme and make it into a zero-knowledge proof labeling scheme. And the way that you can do this is instead of telling nodes their labels, take the label and you split it The label and you split it into shares. And instead of giving the node the color, for example, you just take secret shares of this color and you spread them around in the vicinity of the node. You also ask the prover for a proof that this node would accept this label when all of its neighbors have their neighbors. Okay, I'm not going into any detail here. And this can be kind of checked securely. Secure. And just to point out what I'm sparing you here, the actual heavy lifting here is this part: deciding who is going to get rich shares without disclosing information about the network. Because I need to choose some friends to help me here, but I don't want to tell them who my neighbors are, and I certainly don't want to tell them who my neighbors' neighbors are. So it's kind of the tricky one. Okay. Some questions that I think are interesting here. I think really the most interesting one is the overhead of zero knowledge. But more generally, this thing that I told you, it uses fully linear PCPs. We know how to construct them, but the construction depends on the size of the circuit that tells every node whether it should accept or reject. So all of a sudden we have computational considerations here. Even though nothing is computationally bounded about this problem, Nothing is computationally bounded about this problem. This particular compiler, if you give me an inefficient verifier computationally, then I'll produce a proof which is not efficient in bits. That's kind of unsatisfactory. I think it's generally interesting to ask about privacy preserving distributed computing. Okay, so we forget about this question of certification. If I'm participating in a network and I would like my local And I would like my local information not to spread very far away from me in the network. The basic definitions that we gave you, I think, can capture this type of knowledge, leakage. And then you can ask, all right, what can we do? Can we compute spanning tree without leaking non-local information? And I want to point out that there is some work in this direction. It's called topology hiding computation. Topology hiding confrontation, but it's all or nothing. Either you've revealed nothing or you fail this criterion and you're not topology hiding. So I think there's interesting band in the middle. Okay, so let me end here and I'm very happy to take any questions, discuss offline, or eat lunch, whatever you guys prefer. Remember late, but quick question. Can I ask about this? So for three colour applications, it's somehow important that this verifier is not allowed to look very far in this neighborhood. Yeah, this is true. So if you wanted resilience to coalitions, you can't even afford to give the color to the note. Right, so let's say you wanted to be secure against coalitions of two nodes. Then these two neighbors could compare their colors and then everything falls apart. But you can use this compiler with the sequence sharing to spread it across enough neighbors that no small coalition can recover the legal. Okay, so I don't have a nice recoverability protocol that's resilient even to two. Another thing I don't Another thing I don't have is one that's risen into malicious players. Everything here was honest so far. Yeah. Does it make sense at all to think of zero knowledge for other kind of labeling schemes like distance labeling schemes, for example? Does your knowledge make any sense there? It's a very good question. Well, but I think generally. But I think generally it's kind of opposite to the purpose there. What labeling schemes do is they encode all of this non-local information in a very efficient way. I doubt you would be able to do anything non-trivial just by a labeling scheme that looks at the two labels. I really think having a distributed algorithm that verifies it is functional. Thank you. Surprised that the decent work is because let me discuss. I don't think. I know that you have done something, but from my point, it seems like recent stage. Yeah, that's also a team I said. See myself seeing them outside of the side. For example, tree tree. Yeah, how much people have that problem? Maybe I don't know. I'm enjoying it. Yeah. I like the ask for updates and uh yeah. Yeah, it's my friend how Ah is really interesting in his old college and how a few years ago they had a special paper. I think that I mean now it's I think somewhere in the middle. Yeah. I think somewhere in between like April and October like the the summer half of the year is by any swimming, I guess. It's like I mean it's hard to say this, but it might even be slightly less a problem. I was going to say actually that are you committed to that or no I mean I you are I mean actually I'm trying to see if only the DPS is Yeah, no, this is a strange ship. Yes. I mean, believe me, I'm struggling to be so exciting. Like I've been traveling the computer making it so it's a weak break, but I always describe it for computer free.