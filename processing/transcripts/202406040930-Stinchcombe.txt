I'll begin. So, I'm Lucas Tinchkel. I'm working with Matt Amy at Simon Fraser University doing a master's. And this work is not particularly sophisticated, but at least it's an example of how we have a benchmark that is efficiently simulable in one gate set, but may not be in another one. So the title is Polynomial Time Classical Simulation, a Rottler Shifted Bent Function Algorithm, which you probably know as the hidden shift. You probably know as the hidden shift algorithm. So, some background. The hidden shift algorithm was originally devised as an Oracle algorithm with the form we'll also see later. And it's been used to benchmark classical simulators by giving the Oracle an actual implementation. And then, due to some empirical evidence of running this benchmark on classical simulators, it's been conjectured to be polynomial time simulable. Polynomial time simulable or simulatable, whichever one is correct. So, in this talk, we'll show that this is indeed the case: that the algorithm does admit a polynomial time simulation. The method we'll do this by is to first cast the circuit as a sum over Pod's expression, and then give a rewrite system that is confluent for the corresponding expressions. And then this will lead to a natural simulation. So, just some background on the actual problem. So, the space of functions that take real values over Boolean inputs are called pseudo-Boolean functions. And you can consider amongst others, this is a vector space, and we can consider potentially two different bases for this. So, we have like a direct delta type basis where the coefficients are the values on the input and. The input and a parity basis where the coefficients are called Fourier coefficients, and this is just a Fourier transform of the original function. And so functions in this space that take values in negative one and one, we'll call Boolean functions. And we'll say that a Boolean function is bent if the Fourier transform is also a Boolean function, up to a scaling here. So correcting for the scaling. Correcting for the scaling, we'll get that the Fourier transform takes values in negative one and one, and this will be our dual function. And so taking a dual is like an involution where if you take a dual and you take a dual again, you get back the original function when you when you are bent. So when the function is bent. So for the purposes of benchmarking, um clarify on the previous slide, what is slide what is f hat f hat is the fourier transform of the function f okay so it's like if you define an inner product where you have like expected value or something the coefficients of those yeah okay and then correcting this because it has the wrong sort of absolute values correcting this will give you an actual boolean function down hello oh you don't see my mouse Oh, you don't see my mouse. So, for benchmarking, what's commonly used is the Mariana-McFarlane bench functions, which are just a particular construction. This is nice because it's an actual construction. So, you take an arbitrary Boolean function on like half the inputs and an arbitrary permutation and you feed it into this construction. And this guarantees that it's a ben function with the dual that's closely related. And so we'll. And so we'll denote these by capital M and so now finally we can define the problem. So given a shift and a bent function f, we let g be the shifted function, which is just applying a shift and running f. And then the hidden shift problem is given oracle access to some collection of functions that hide the shift. We want to determine what s is in the least number of queries. What is S is in the least number of queries. So, Rotler gave two different settings for this problem. One is where you have access to the function and the shifted function. Classically, you need exponentially many queries, but in the quantum case, you can do linearly many. And so this gives us an oracle separation between P and BQP, and that's nice. For our benchmarking talk, we'll be focusing on the second one here. Second one here, this one in the blue, where you have access to both the original function and the shifted function, as well as the dual. And so, here, classically, you need linearly many queries, but in the quantum case, you can do constant. And so, here using this setting and actually giving these oracles an implementation where the oracles are implemented, running, like executing and applying to. Like executing and applying to the phase. We've seen that in all previous works when we can, they've been constructed over this gate set G, where we have X swap Z and control Z up to some M controls. This fixed M is kind of important because this determines the bounds and the degree of the polynomial of the bent function. So, in particular, in all previous works, M hasn't has. Works, m has been equal to 2, which corresponds to bent functions of degree at most 3. And then it's been conjectured to be polynomial time simulatable by Julian Coddesy in 2022 in his master's thesis. And so, just like a quick thing, just quickly correctness, we can just observe that if you apply these each step here, we get an expression that. Here, we get an expression that takes, it takes a zero state to this state here. We know the structure of F, we know the structure of G, so we apply that structure. And then the rest is just noticing some constructive and destructive interference. So here, X2 has to be equal to y one, and so we plug that in, and then we're kind of working over when we're over negative one here. It's like characteristic two polynomials, so uh, we get. So we get the same thing, and then we have a destructive interference, constructive interference. So we get our shift. And in this case, it was zero bit string. And so what we just did is like informal mathematics to prove correctness, but we can formalize this into expressions that live in algebraic polynomial rings. So we would take what we just did and say, okay, let's apply a formal. And say, okay, let's apply a formal expression, which is called the sum of our paths, where we have a scalar s, we have a set of indeterminates, and then Boolean polynomials, which are just polynomials over F2, where variable squared are just the actual variable itself. And then a quick proposition that these sum overpass expressions over the gate set that we were considering can be computed in polynomial time and polynomial size. And polynomial size. This is basically just due to the fact that the degree, the number of controls m bounds the degree of the polynomial. So if you have a bounded degree, the number of terms is polynomial and the number of indeterminates, and then everything stays polynomial after this. So a quick example of how you would do this. Well, you would just, for a Bell state circuit, you would just deconstruct it into its component gates, apply tensor product rules and composition rules. Rules and composition rules, and then you would get a final expression, which is a sum of a class expression for this circuit. And then another super trivial, simple example is if you have two Hadamards, you do the same, and crucially, you find that you don't have the identity for completeness results, like this sort of thing would matter. But for us, we don't actually care. We care about simplification for the purpose of simulation. So, however, However, even though we don't care about completeness, we're going to take this as the motivating example for our rewrite system. So, in particular, we're going to allow the HH rule if you're aware of this rule, and we're going to apply a restriction. Well, you can kind of see them. Anyway, a restriction where whenever we substitute in a variable for another expression here, so y would get q, we're going to limit the number of variables. Q, we're going to limit the number of variables of q to be at most one. So this will be called the simple HH rule. And fixing vocabulary will say that this is an application of the simple H rule with respect to X. So just to recap what we have so far, we have that we had the original circuit in polynomial time. We're going to turn this into a sum over paths expression. And then just as a simplifying lemma, we're going to Just as a simplifying lemma, we're going to notice that because these expressions live in polynomial rings, the naming of these indeterminates doesn't matter. So we can just relabel the name so that we can basically undo this permutation. We find that this permutation moves to the state, but we have no rules that care about the order of the variables in the state. And then naively, what we could do here is just a strong simulation. Just a strong simulation if we wanted. So we would like project onto, say, a computational basis state and then apply rewrites until we no longer can, and then finally do an evaluation of the sum over paths. So that would mean actually doing the sum over paths by, you know, every single assignment of these variables. And so we have kind of two problems and a kind of zeroth problem. The zero-width problem is that the rewrites could perhaps never terminate. Could perhaps never terminate. So we don't have this problem because our rewrite system is noetherian, which just means that we have normal forms not necessarily unique, but all rewrites terminate. And then our first problem is that this evaluation has cost exponential in the number of variables. So we want to decrease the number of variables in our expression as most as the most number of variables possible so that our final evaluation. Variables possible so that our final evaluation is cheap. And then the second question is: well, what if an expression allows for multiple rewrites? Which one should we choose? And so the reason why I gave that correctness proof calculation is that actually that correctness proof is a sequence of simple ch rewrites. So that in turn means that there exists some sequence of rewrites for original expression that gives us. That gives us the shift. And crucially, the shift has no variables involved. So the evaluation is just trivial. You just unpack it and return the shift itself. And so the second question was about the freedom of, you know, what choices, doesn't matter what choice of rewrite you apply to each expression. And so here, intuitively, this is just the property of confluence that if any order of If any order of rewrites results in the same expression, then it's a confluent rewrite system. And so, just to fix some vocabulary, we'll just say A rewrites to B confluently. If whenever A rewrites to C and A rewrites to D, then C and D both rewrite to B. And so we get this diamond property, which is desirable because you never have to backdraw. So here's like a simple, simple hidden shift. A simple hit and shift circuit just to explain what sort of things can happen. So, let's say we apply the simple HH rule with respect to X. We would have here, well, two possible scenarios where you would rewrite Y to be W plus one or W with Y plus one, which both capture the same equality. And so, the question is: does this even matter? And the answer is no, because there's And the answer is no, because there's a one-to-one correspondence between every rewrite sequence starting from this side and every rewrite sequence starting from this side. So if you're confluent with respect to one of them, you're confluent with respect to the other. And then now at this point, we don't even need to develop anything more. We'll just do a case analysis, and this will kind of be enough to prove confluence. So I think it's best shown as an example. So at the outset, if we Example. So at the outset, if we have an expression that looks like this, we'll consider like the linear relationships that they induce. So with respect to x, we get this expression, and with respect to z, we get this expression. We'll notice that we can't apply this linear relationship because it has too many variables. And so we apply that rule with respect to x and track how this linear relationship changes. And so with respect to z now, we have that. With respect to Z, now we have that this is a valid seven point change rule, and so we can apply that. And what that means is that the ith index of our state is replaced with the shift, which is what we want. And what we also learn from this is that we have a dependence of rules. So on the rule with respect to Z depends on the rule with respect to X. And similarly, it seems like a lot, like extending this sort of reasoning to the rest of the experiment. This sort of reasoning to the rest of the expression, but actually, there's so much structure here that we can just group terms that behave identically and extend this reasoning to the rest of the expression. And we find that we get slightly more complicated dependencies, but not that much more help. And then using this kind of proof sketch sort of reasoning, we can prove the claim that every valid read write sequence must satisfy the dependencies generated and every Is generated, and every rewrite sequence that does terminates with the state S. And so that's exactly what we wanted. And so that leads to a natural algorithm that if you have a hidden shift circuit C, by casting it to the sum over paths, we apply simple HH rewrites until we no longer can. And then at the end, we're guaranteed to just have the shift itself. And so we return that result with a trivial evaluation. G and the theorem is, of course, that algorithm one simulates the hidden shift circuit over gate set G in polynomial time. And just like an additional thing, this is because this really, the important thing is that this number of controls M is bounded. So at every point, we only have polynomial-sized expressions. And so finding some rule that matches a precondition is just a scan of. Condition is just a scan of polynomial time. And that's basically it. I may have gone a little quickly. I have some like current directions, but I don't know. Oh, I'm very early. Sure, I'll just talk about this. Okay, so on the previous slide, so I could see you argued that scanning. Scanning the expression can take place in polynomial time. But how do you know that there's only going to be a polynomial number of these rewrite rules to apply? So it doesn't matter if there could be many more, but you just have to identify one. Right, but in order to reduce it to the shift. Yeah, yeah. So that's because the number of variables is bounded by the number of gates and times the multiple. And times the multiple, times the number of qubits. And so each rewrite removes two variables. And so you can have, in this case, like if you have two n inputs, you halt in basically three n steps. So yeah. And that's actually a property that's stronger than Ethereum. This is like called bounded rewrite system. So all rewrites are bounded by some fixed length of rewrites. A rewrite blank that rewrites sequence. So, um, yeah, so maybe just I didn't know how long I would take, so I'm just going to continue. Um, so the kind of good news with this result is that, okay, or the bad news, depending on how you look at it, is that the hidden shift circuit is efficiently simulatable. Um, we had some discussion yesterday about like these benchmarks, so it's kind of topical. Benchmarks, so it's kind of topical, and I think maybe the moral of this story is that depending on the gate set that you choose, a benchmark can, at least as far as we know, it could be efficiently simulatable in one case without being the case in the other. In particular, here, if you replace the CCZ gates or CCZ gates, depending on where you're from, if you replace these with T gates, this is not known to be efficiently simulated. Like, so maybe there is, even though, like, according to Solovy Kitayev, these things in the quantum realm should give us equivalent sort of polynomial time circuits. This doesn't necessarily transfer over to a classical simulation given a description in one gate set versus another gate set, even if they compute the same algorithm or same circuit. So perhaps that's of interest. Perhaps that's of interest, and then maybe current directions. So, I said the good news, which we decided is good news. So, now we have bad news here that these rewrites are generic. They just capture H2 Hadamart's being equal to the identity, but they're very weak. So, there's a lot of expressions that you cannot simplify, even though you should be able to. Be able to. And confluence here is with respect to these specific objects, these specific expressions generated from a specific class of circuits. So it would be desirable if this property of confluence was not a property of the combined set of specific expressions with our choice of rewrites, but instead a property of the rewrite system itself. And obviously, over some set of objects. And obviously, over some set of objects, but a natural class of objects, in particular, maybe what I'm considering calling the Boolean autom. So the current work is, okay, let's allow instead of the simple HH, let's allow the affine HH, where the degree of this polynomial that we substitute is the only thing we restrict is that this degree is at most one. And then from the theory of rewrite systems, we can. The theory of rewrite systems, we can begin to consider a case where we don't have confluence as like the objects themselves, but we have confluence up to an equivalence class, which is which our equivalence class here will be an affine transformation, which you might think of as like a degree-preserving polynomial isomorphism between these that is simultaneously acting on all of these polynomials that are involved in our expression. Our expression. And so quickly, you can notice: like, if you do this, you'll find that this alpha property does indeed hold. So, maybe I didn't say what these alpha property and beta property is. The alpha property is, well, together, an Oetherian rewrite system is confluent, modulo, and equivalence class if and only if the alpha property and the beta property hold. And so, we can, our current work shows that, okay, the alpha property does indeed hold. So, the question is: what about this beta property? Is what about this beta property? And it's turning out that we need to introduce a new rule here in order for the beta property to be satisfied, which involves sort of presentations of polynomials. So for example, if I had a polynomial that's written as, let's say, x plus y brackets times x plus y times z, let's say. This involves three. This involves three variables, but in its most minimal presentation, you could apply a linear transformation where you replace x with x plus y, let's say, and you would find that you would just need two variables to present this polynomial. And so the minimal presentation of a polynomial seems to be necessary in order for two affinely equivalent expressions to be rewritten to the same thing. Written to the same thing. So this is kind of the direction that we're going in. It's kind of motivated by the fact that these are, in fact, algebraic expressions, not syntactics, purely syntactic expressions. And so we're kind of pursuing this. And maybe I'll just leave it there. And and if you so you said if you write your circuit over paper ST, then it's it's it's no longer so easy to do the simulation. At least it's not known to be. So like the original construction was, so you construct your hidden shift circuit using this gate set, but then the way it's been previously used is by taking your CCZ gate and then replacing it with some gadget. Replacing with some gadget with some sub-circuit implemented over Clifford plus T, and then the way you would simulate is with stabilizer rank style simulation. And this is, it seems to be difficult. But we don't know. Could you not also do the pantheon stuff with like a PST and try to? Yeah, so this particular construction is for the CCZ. Perhaps it works. I'm not saying that it. Perhaps it works. I'm not saying that it cannot work, but we don't know whether it works over Clifford plus T, but we do know that it works over CCZ. So that's still like an open question. Thank you. So if just to add to that, if you were to restrict yourself to just C naught T to actually implement the Boolean function of the phase, then it would still be polynomial times in removal. Time is in the movable. It's when you start doing the basis change between the Z and the X basis. So if you, if you add on topelies, like if you replace the CCZ with the topology instead, then it becomes not similar. If you're actually implementing the Oracle in the phase, like if you're doing the qualification and state and then make the Oracle in the phase, then it becomes an AFC all the time. Yes. I guess this is a comment, but it might be kind of relevant to this question. So when we were doing this with physics and physics, sort of doing this rewriting technique, the thing that I initially found is if you use the 40 gig decomposition of CCZ with Bitcilla, it did not work. Work so so it so it didn't it didn't give efficient simulations, right? When you use the seven T gauge decomposition, even though now you've got a lot more t's and it's doing some stabilizer ring stuff, the simplifiers do a lot more, which could it could be this reason that there weren't padmark gates sort of obstructing the um the the this the simplifier kind of figuring out that this is actually a CCZ gate. Right. So, okay, interesting. Okay, interesting. Maybe. Yeah. Yeah, I mean, basically, I think if the simplifier could figure out that the 4T gate implementation is a CCZ gate, kind of before it works. If it kind of does that rewrite instead of like pushes the rewrite out, then it would still kind of work. Like if it pushes the rewrite in towards CCZ instead of out propagating the borders of the circuit. Not kind of stay at the borders of the circuit in a sense, which is not into where the CZ. Because I'm thinking about that, that Hadmart's like, I mean, you're pushing the Padmarts in to normalize into like a CCZ kind of thing. Yeah, yeah, I question about propagating pattern marks outwards towards the end and start to maybe get some fears of the other things happening. Yeah. So I have both of them. Part two. Like I have two parts. So just now, Matt said. So just now Matt said the things become difficult when you change from the X basis to the Z basis. Is this the reason that you only need the rule for two headmart reverent? Like in the talk, like you mentioned that you only use one rewrite, which is two heavy marks. Is this somehow related to the problem become difficult when you change from X basis to Z basis? Well, these are two different comments. I don't know if it transfers over specifically to any. Transfers over specifically to any reason why this is efficient and assume that one. So I was wondering. Right. So, okay. Then if you're not doing hidden shift circuit, if you do something more general, then do you need more rules to do the rewrite than just to have more head? Yeah, so this is like super specific to the hidden shift circuit. Super specific to this particular gate set and set of circuits that the hidden, the symbol HH is sufficient. HH is sufficient to simplify completely. So if you give it something else, like there's no guarantees of simplifying even one step. And how do we find out this true HH rule is sufficient? So that comes from the fact that the proof of the correctness of the hidden shift algorithm is just secretly a sequence of simple HH rewrites. So we know that you can simplify it with these just this rule. And then it turns out that. And then turns out that every possible order that you would apply these simple ch rewrites would give you the same thing. So, yeah. I'm going to suggest we go for coffee. We have an online talk in the next session.