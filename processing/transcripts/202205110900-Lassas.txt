So, I'm going to speak about the geometric inverse problems for functional diffusion equations. And the main results that are presented, they are done in collaboration with Tapio Helin from La Peranta University, Finland, my graduate student, Laurie Udinen, and Jidong Chang from San Yet Sen University. So the main topic that I will go a little bit around is that I'm going to consider fractional diffusion problems with manifolds. And there are so many ways to define fractional diffusion that I want to specify that we are going to consider a spectral calculus to define fractional operators. So the specific problem that I'm now concentrating is that we have manifold. Is that we have a manifold that is compact and has no boundary, but the general results also generalize, for instance, to results in bounded domain in Rn, when you put, for instance, dlyn the boundary condition. And the estimate of the dimension of the manifold is at least two. So we consider a fractional diffusion equation when time fractional derivative alpha is Alpha is between zero and n1, may also be strict one. And then the spatial derivatives are given by powers of Laplacian, where the power is also between zero and n1. And we are asking that we do measurements in some small open subset B of the manifold, like here in this picture. There is a source F. F depends both on space and time. And then this source causes a reference. And then the source causes the diffusion to happen. The diffusion process starts to go around the whole manifold. And we do measurements only on the set V. So the sources are supported in V, or actually they are compactly supported functions on open set V times time axis. And then the measurements are that for any given source, we measure the solution restricted to V times time axis. So here you are. The sources. So here you are, the sources in V across time, and also the observations are in V. And this define a source-to-solution operator that maps the source on V to a solution on V. And emphasize that this data is given as a form of a linear map. This is the general setting that I aim into. But let me first recall some definitions, how this different How these different fractional derivatives are defined and the problem in general. So, in this talk, we are going to use the caputo fractional derivative in time variable. And I recall that when alpha is one, then this is just a regular derivative. When alpha is between zero and one, like in this talk, then it is given by we take one derivative of function y. So, we take a standard derivative. Y so we take standard derivative and then we operate to it with this singular integral weekly weekly singular integral of vector. Why we do this if we just consider just an antiderivative so integral of a function and we denote that by j then the higher order derivatives can be computed by using integration by paths with these integral operators. And these are not similar at Similar at when n is large. And we are interested of functional derivatives and therefore also antiderivatives. So if gamma is larger than zero, we define the derivative of order minus gamma, so anti-derivative of order gamma, with this integral equation that is singular, basically singular when gamma is between zero and one. And one and these antiderivatives have the semiconductor property that j to power alpha, actually alpha times j beta is this j alpha plus beta. So they are semi-group. So they are continuous interpolation between identity operator and derivative. And that's why it is natural to define the derivative by using this anti- this kind of these integral operators. And the computer derivative is defined in this way that Is defined in this way that we first differentiate the function and then operate with the antiderivative. There are different alternatives, but this I'm following actually Barbara's and Bill's recommendation that this is most natural functional time derivative. So this is the time derivative that we are using. Then on fractional spatial derivatives, there are different alternatives for that. And on manifolds, And on manifolds, the most natural thing is to consider powers of self-agent operators. So we are starting from one self-agent operator. We take the Laplace Beltram operator on a manifold. That is just a Laplacian on a Riemannian manifold. And in local coordinates, it has this form where there appears a metric G, that is the matrix with lower indices, depends on X. And by using this metric, And by using this metric G, the Riemannian metric, we denote the determinant of this matrix G by absolute value of G that appears here and here. And the inverse matrix of G is denoted by J with upper indices. So here we have the inverse matrix. And if you consider just like Euclidean Laplacian, given by here, Laplacian given by here with the Euclidometric, and you write it in different coordinates. This is the format how the Laplacian looks in different coordinates. And this is generalized to Riemannian money. First, when you have a Riemannian metric, then you imitate the rule of change of coordinates in the Euclidean space, and you define that the Laplace operator is this here. And this is standardly can be used to also model of. Be used to also model heat flow in anisotropic medium that is not homogeneous. Also, this appears in other physical applications. For instance, if you consider a wave equation, so here we have a second time derivative and Laplacian to power one. This is the wave operator. So this could correspond to the metric correspond to the speed of sound. And you can also consider testoharmonic functions in three and a half Functions in three and higher dimensions. This is actually equivalent to the conductivity equation. So, G10 corresponds to electric conductivity or wave speed, like here, or some kind of diffusion in the case of fractional, like in the case of diffusion equations. So, let me use this operator to define the fractional space derivatives as follows. We use a spectral theory or spectral calculus. The ideal values of The algebra values of minus Laplacian, they are increasing sequence that goes to infinity when the index of algebra value goes to infinity. And on a compact manifold with no boundary, there are a complete orctonormal sequence of eigenfunctions united by phi j that correspond to these eigenvalues. Then the spectral definition of fractional Laplacian is. Is no fractional Laplacian is here. So if beta would be one, this is just the way how we write operator by using eigenvalues and eigenfunctions. We take the function u, project it to eigenvector. So here is inner product of u and eigenvector. We multiply it with eigenvector. And then if we beat as one, we would multiply it with eigenvalue. The fractional derivatives are defined in the same way that here the power of the fractional Here, the power of the fractional Laplacian is that we have here a power of the ideal value. So, in practice, this would be very much like single-value decomposition and how you compute the powers of matrices. But this works for self-aggant operators in Hilbert spaces. And the domain of this operator consists of those functions, so that the coefficients of the function in this eigenfunction space, I often call this just Fourier coefficients when I refer to eigen. Coefficients when I refer to eigenfunctions of Laplacian. So these Fourier coefficients have to be square summable with these weights. So this is the way how we define the fractional space derivatives. And here is the domain where the fractional space derivatives are defined. There are many different ways to actually define fractional space derivatives. In Rn, I think the most common way is that you I think the most common way is that you consider that you consider use fully transformed. So the fractional space derivative, Laplacian here is just a usual Laplacian in Rn. We operate in Rn here now. We take a Fourier transform. Laplacian to power alpha over 2 is that we multiply the Fourier transform function with absolute value of the Fourier variable to power alpha and take inverse Fourier transform. And you see that this when alpha is equal to oops, let's yeah, when alpha is equal to two, this coincides with the usual definition of Laplacian in Fourier variables. This Fourier transform definition can be written also in terms of singular integral as a principal value integral. So we take this ux minus uy divided by this power of x minus y and integrate over ball minus And integrate over ball minus some integrate over R R n minus ball center at x with radius epsilon and let epsilon go to zero so this limit can be called also principal value integral. So this is other way to define this functional powers of Laplacian and these are equivalent also in in Rn we can use this this spectral calculus to write To write the Laplacian as integral of a projector-valued measure. Here, this projector-valued measure EÎ» is such that if I integrate this measure over interval A to B, then this is computed by taking the Fourier transform of u multiply it with the indicator function that the absolute value of psi squared is an interval a b, and then we take Fourier transform. transform and here we can define also the fractional derivatives by just like changing this this this power of the spectral parameter and in Rn all these different definitions they coincide when we go to bounded domains or or manifolds then these definitions are either different or they are not even somehow like easy to easy to Easy to define. But there are lots of results for similar integral Laplacians, namely for this, especially for the, I would recommend the paper of Ghosh, Runan, Salo, and Urman. They also have other papers in different combinations of authors. And also, Giovanni Covi has very interesting results recently for inverse problems for fractional Laplacians where he connects the fractional Laplacian. The fractional Laplacian to non-standard random walk. Anyway, these are the definitions. Let me give some properties of the direct problem next. And I recall that we now consider a closure Riemannian manifold, which means that it is compact and has no boundary. And alpha and beta, the fractional indices are in these intervals 0, 1, 1 include. 0, 1, 1 included. The direct problem has quite well developed theory. This formulation is from our paper, but the techniques follow the methods that Barbara and Kian and Bill, and especially Sakamoto, Yamamoto, has used. So, here, maybe the main interest is that what smoothness is we interest is that what smoothness is we choose. And for inertial problems, we don't need to go to extreme non-smoothness. It's often to just have some smoothness and show that we can then define the source social maps with some relatively nice smoothness classes. So if we have sources F that are compactly supported in time, twice have two derivatives in time variable and have values in L2, then there exactly one function u. Exactly, one function, uf, that solves the fractional diffusion equation in strong cells, where the solution has one time derivative in that is L2 valued. And it also has, if we consider fixed values of t, then the values of the solution are in the domain of fractional applications. So all objects are defined here in the domain. Objects are defined here in structures. And also, the wave vanishes at time t is equal to zero. So, this is relatively standard theorem, but I want need one independent from the proof. So, let me somehow indicate main steps. So, if you would have a solution of this fractional diffusion equation, then we could just take inner products with eigenfunctions. Take inner products with eigenfunctions and show that the differentiations, like in time variable, for instance, just commute with this operation and obtain that this coefficients of the solution u in eigenfunction basis, I call this Fourier coefficients, this Fourier coefficients here can satisfy an ordinary differential equation. So here we have fractional time derivative, here the Laplace n to power bit has changed to lambda j to power bet. Next change to lambda j to the power beta, and here we have just short steps. And this can be this ordinary differential equation can be written explicitly, that this can be solved by using the mid-tagles function. So here in this bracket, square brackets, there is a formula that gives this coefficients in the eigenfunction basis. And this is something. Basis. And this is something that we are going to use later. Actually, to prove these properties of the Director problem, one thinks that one takes F, considers this formula as unsuch, and then just shows by using the definition of a strong solution that this U actually is indeed a solution. And the uniqueness needs different considerations. But anyway, we are going to, in this talk, we are going to use this formula, which says that we can every Formula which says that we can compute the coefficients of the solution using the source term in diffusion equation. So I return later to this form. Okay, let me now formulate the inverse problem that we want to concentrate here. So I recall that we have a So, I recall that we have a manifold M that is compact, has no boundary, and there is an open non-empty subset V where we do measurements. We consider sources that are, now we can think that they are twice differentiable, completely supported in time and has values in L2 of V. And we coordinate by UF the solution of the fractional diffusion equation with source F. With source F. And we have well-defined a local source, the solution operator that maps a source to restriction of the solution. We call this local because everything is defined here in V. Sources are supported in this open set V and waves are observed also in V. And we consider it as an operator that maps these function spaces to here. So we have Spaces to here. So we have a like smooth, gravity, smooth function in time in L2R map to C1 functions in time. And the question is that we study is the following inverse problem. Let's assume that this manifold M is unknown. We don't know for the topology of the manifold. We only know this set V. It would be for like diffeomorphic to Euclidean ball. And then we know this. And then we know this sort of solution operator, and we ask: can we determine the manifold, the topology of the manifold? And one has to also define, determine the differentiable structure, that is the local coordinates on this manifold, and the metric. Also, one question: what it means to determine a Riemannian manifold? It is an abstract object. So, in practice, determination of a Riemannian manifold means a construction of other manifold. Of other manifold that is isometric to the manifold where the measurements are done. So we construct isometric copy or isometric model of the object where the measurements come from. Okay. So with Helen, Ulinen and Chan, this also proved a little bit more. It is not necessary to actually measure the whole source-to-solution operator. Operator. But surprisingly, it is we can consider we constructed source H source such that when we measure the solution in V times some arbitrary small time interval, then this determines the whole source-to-source operator. So, in other words, In other words, all information that can be obtained on Z V times whole time interval zero to infinity is obtained from a single measurement on a short time interval. And the trick here is, of course, that we have to construct in special way this source H. And I actually want to somehow make this construction relatively detailed through because I hope that it would be interesting because it can be applied to several. Because it can be applied to several many other like fractional problems too. How to basically pack many measurements to a single measure. Okay, so let us, we actually want to pack many measurements into one measurement. And let's consider example first that we have want to pack two measurements into one. And I recall that we considered this fractional diffusion. Recall that we consider this functional diffusion equation. And let's first consider a single source that is product of a function A that depends on time variable. It is like in this picture. And then xi of x, where x depends on on, psi depends only on x variable. xi is supported in v okay so we measure on on on time interval zero to t one um the sort of The source resolution map for this particle source f and get this blue curve. Now we want to use the fact that, like in this picture, if the function a of t one is on here on some short time interval, from some the time interval from t one minus epsilon to t one, so it is zero here, then the solution of the fractional diffusion equation is actually analytic in time variable. Is actually analytic in time variable. So close to t1, there's an interval where the solution is analytic, real analytic in time variable. And the real analytic function is defined, is determined if you know it on an arbitrary small open interval. So indeed, we can do unit continuation and find out how the measurements would be if you would measure those from t1 to infinity. So this book. So, this blue curve here contains information that makes it possible to determine, maybe unstable, but still determine uniquely how the solution would look on later time moments. And now we can think that we put here other bump function and we then measure this blue curve that appears here. Let me do this in detail. We actually going to. Do this in detail. We're actually going to put there many this kind of bump functions, use analytic continuation, and then we repeat this adding one more bump and analytic continuation many times. So here are a little bit more detailed explanation. We consider two bumps that are sums of bump A1, A capital Y A1 and capital A2, where A1 is just this bump function and A2 is a function. And A2 is some other small function, small case A2 that is delayed. And let me recall what we somehow obtained from the measurements from 0 to T1. So in the time interval 0 to T1, A2 is 0. So we actually are only measuring things related to source A1. So we measure this function. We measure this function the response on the interval zero to T1. There is a small time interval before T1, but the solution is analytic, real analytic, and we apply analytic continuation to obtain what the solution would be if we would measure only with source A1 times xi. So we will use analytic continuation to get information what this source, what the source. With a bit of what the solution would be with source A1 times xi. So we get this dashed line here. And now we measure, actually, physical measurement was done with two pumps. So actually, we know like this sum of these two pumps, times side. This is what we measure. And it is enough to measure this from some time interval. From some time interval, something like from zero to two t, because we can again use analytic continuation there to see how this continues. Now we know these dashed lines. So we can just subtract two things that we have now determined. We subtract the physical measurement and then the information that was obtained by using analytic contribution. So we have here the response to source A1 plus A. To source A1 plus A2, that is measured, and we subtract the response to source A1 that was obtained by unique continuation or analytic continuation. And this gives us the source to solution operator with source A2 times psi2. So now we have a separately obtained information that the source is A1 times Xi or A2 times Psi. Now we have packed two measurements together. Measurements together. Now we can continue this: that we actually take infinitely many bumps that get smaller and also shorter in time interval. And now we measure, consider what would happen if we would measure this function, the sum of these a's, a1, a2, a3, times xi. And we want to approximate. To approximate a source-to-source map evaluated with a smooth function f of t times psi here and and how we can do it. We could now think that okay, we can measure separately what would be the response to a1, what would be response to a2, and so on. So, if we use, for instance, a2 here, then we could, and that means that we actually take some index p, and p is now here too in this picture. We want to. We want to represent, approximately this f of t with the sums of a twos that are delayed and combined together with some coefficients. So here are all these bumps that we combine together, delays of A2. And then the sum of these bumps give us a function that goes with this gray line that here was the function that we wanted to approximate: sums of delayed AJ's. Sums of delayed AJ's will somehow give this type of like a little bit oscillating function that is here, this light gray line. And when we go, when we use this index A2, then we had a bump that has relatively long in time interval. If we go very far here, the bumps are very, very short, so we can make better and better approximations. So we can actually, by variating P We can actually approximate this source resolution operator, evaluating f times xi as a sum of this type of de-day bumps, with bump AP, with arbitrary precision. And because the source solution operator is continuous, we can go limit to the limit and obtain the source solution operator to f times xi. f times xi so now we have arbitrary function f here arbitrary smooth function times times xi so this is expressed here so i recall that we used this a that was was sum of of this type of of many small bumps and by measuring um short resolution operator with a times xi we can determine short resolution operator to any function f that is smooth in time times xi. But we want to actually consider also freedom in this x variable. So we would like to determine all the functions f of f x and t. And how we do this? We are going to modify these psi functions. This is a little bit more complicated. Let us consider functions psi j's that are that are That are that span linear, that span density in L2 of V. And then we define a little bit more complicated function where we have these bound functions a1, a2, a3, and so on. So we have this type of bumps. But we multiply each of these time bound functions. Here we multiply with psi one. Here we multiply psi two, psi three. And in this way, we sum these together. And the idea here is that this psi one and psi. That this xi1 and xi2, and so on, each of these xij appear here infinitely many times when we go to the further and further in this chap. Of course, numerically, this would be very difficult, but now we are considering just unique results. Well, if we know now, this is the source that actually will define, that give enough information to determine the whole source resolution map. solution map namely if it we can isolate what would be the responses what is the source resolution map for for uh like each term separately so for each term separately we can see what is the source resolution map responses for this when we keep psi one the same and let a j's to be smaller and smaller jumps this determine uh short source termine shows the source map to arbitrary function f times xi1. Then these next terms here, the blue terms here, they determine sort of map to f of t times psi 2 for arbitrary f and so on. So we can determine short social maps for this functions, some functions f of f j. f of f j f j of t times psi j of t and and any reasonable smooth function can be approximated with this type of sum and because again by using continuity and linearity of the short resource map we can then uh go to the limit and and determine the short resource map to arbitrary say smooth uh complexly supported source source f so this now means that this one function h when we do measurements with it it contains When we do measurements with it, it contains enough information, at least in theory, to reconstruct values of the source-to-source operator to arbitrary functions f. Okay, so now it's cool. We actually have reduced this single measurement problem that we want to solve. It is reduced to the problem when we assume that we are given the whole source-to-solution map. Source to solution map. Okay, so this is now, we can go forward to in our goal. And let me now, this is actually our main result, which says that, so if you have this closed compact Fiemanni manifold and open on and receptive measurements, then for any time t, there can one can construct a source h. One can construct a source H that is supported on this time interval zero t and this determines the whole source to solution map then we can ask does the source to solution map determine the manifold and the metric up to Riemannian isometric so instead of saying that that there is one source H because of the earlier considerations we can somehow put here that we say that just to set V That we say that just the set V and the whole source to solution map is operator determine three money manifest, and this I'm going to concentrate next. Okay, so what is the here the strategy? The strategy is actually to I would say that we change from fractional equations, we go to more standard equations. More standard equations, and we want to consider actually the Bay equations. Oops, sorry. And to consider the relation of fractional diffusion equations and wave equations, we are going to consider so-called interior spectral data. It consists of eigenvalues, lambda j's, and restrictions of And the restrictions of eigenfunctions phi j restricted in v. This is spectral data because it contains information about all eigenvalues and we call it interior because we do measurement inside a manifold. We have an open set V, where we measure the eigenfunctions. So, this is the data that we connect together fractional distribution equations and diffusion equations and various questions. And the strategy is the following. He saw that for the functional diffusion equation, the source-to-solution map, it determines this interior spectral data on set opposite V. Then we show that this interior spectral data determines the hydrobolic source to solution operator that maps the source F to restriction of the solution in V. Of the solution in V, and that then this map determines Manifold and the metric. Let me now concentrate like how we use this fractional short resource operator to get this integral spectral data. And we are going to take a Laplace transform of the short resolution operator. So the script L here is the Laplace transform. The Laplace transform in time variable, and S is the Laplace variable. So, and so the source-to-solution operator actually is the source, sorry, it is the solution when X is in B. So, we actually are computing the Laplace transform of the solution. Let me now go back some slides. So, here was the So here was the idea of the proof for the Diego problem. And what we said there is that there's an explicit formula based on Mitla-Leslier functions that gives what are the coefficients of the solution into eigenfunction spaces. So here are the coefficients and those depend on time. This is independent of time. This is independent of time, this phi j. So, when we take Laplace transform of the solution, then we have just take Laplace transform of this integral. Fortunately, this was already done by Randall and Chang, and they considered like Laplace transform of these integrals. And what is the answer is that when we take Laplace transform of the short solution operator, or if we take the Laplace transform of the stressed solution, Just the solution. There's expirit formula. Here are Laplace transform of the source function f times eigenfunction. So here this f depends on time variable. So we take Laplace transform with this, multiply with this, take in a branch with eigenfunct. And then because this is solution of fractional diffusion equation, we get this type of terms that look a little bit like analytic or minimum functions. So here is the S. Functions. So here is the S with representation how things look like. Let's now consider this as a function of S. And we consider S as a complex variable. Now, this function here, this actually is a complex analytic function in a neighborhood of the positive real axis. And again, we use. And again, we use analytic continuation. Now we continue this function, z, to maps to the Laplace transform of the source-to-source operator evaluated at fixed point x in observations at V. And then the Laplace parameter is z to power one over alpha. This function is actually a meromorphic function. A Meromorphic function in the complex plane minus the slit of this positive imaginary axis. So theoretically, the Laplace transformed this real analytic in this neighborhood of positive real axis. It determines the meromorphic continuation and the metamorphic continuation has some poles. Let's see. So the poles. Let's see. So, the poles are actually the values where s to the power alpha plus this lambda j to the power beta gets value zero. So, when we analyze this Meromatic continuation, then the poles of this function determine the locations where the eigenfunctions are. So, we obtain this minus lambda j to the power beta. So the So, the points where this function blows up the poles, they determine the eigenvalues. And then we can consider what are the residues. The residues are actually, one can read from here. The residues will be some kind of products of this phi j times phi j itself. So, more precisely, they are this type of sums of phi l at y, phi l of x, where the sum run over all eigen. Over all eigenvalues that correspond to, all eigenfunct correspond to the same eigenvalue. If all eigenvalues are such that they have multiplicity one, so the eigen space would be one dimensional, then the sum could be removed and we would have just this product of eigenfunction with itself. And now the residues, they determine the eigenfunctions, phi j's. functions phi j's when x lies in in is lies in in z v or actually more precise they when we have multiple multiplicity of eigenvalues they define the equivalence classes of eigenfunctions where the equivalence equivalence now means that when we have uh for instance like mod dimensional eigen space then we can rotate the eigenfunctions with the orthogonal matrix or with some rotate orthogonal basis but anyway But anyway, for simply assuming that eigenvalues are one-dimensional, so the poles determine the locations of eigenvalues and residues determine the eigenfunctions restricted to v and using this we can we can go to vary equation i recall that we had a nice formula based on mid-tach leftler functions That left functions for this fractional diffusion that looks very complicated. One can do just the same analysis to wave equation and get much, much simpler result. One gets that the hyperbolic shorter solution map. Short solution map that maps the source supported in V to restriction of the wave at V times R. This is given by this expression that where the mid-dogless functions are replaced by sinc functions, that are like sin lambda over lambda type of type of functions. And now I recall that we knew what the eigenvalues are, so we know what these lambda j's are here, and we also And we also got the equivalence class of these eigenfunctions. And by using those, we actually see that the integer spectral data determines this hyperbolic source to source of matter. Let's go back to the strategy. So in this book, when we have the sort of social operator by taking Laplace transform, we get a function that can be modified to be meromorphic. Then this meromorphic functions poles give eigenvalues lambda j's, and the residues give this phi j's restricted to v. Then we have the ex-grid formula of how to hyperbolic or vague. How the hyperbolic or wavy equation-based short-term solution map can be written in these terms. So here is the form. And then we can apply results for wave equation. Namely, when we know the local source operator for the wave equation, then we can Can we can unitly determine the manifold and the metric g on it? Let me shortly explain what are the, because here we actually construct a manifold. Let me explain what are the basic ideas here. And to draw actually better pictures, I don't consider now manifolds that has no boundary. I will change slightly this setting. I will consider a compact manifold with a boundary. So it's easy to draw. So it's easy to draw a picture of manifold with boundary. And there we consider a wave operator, wave equation, where we specify what is the Neumann derivative, what is the normal derivative of the wave, that is F, and we measure what is the boundary value of the wave. So if we consider that F here is actually a boundary source, here we ask that we measure the Neumann to be dilemma. The Neumann to D relay map that maps to Neumann data to DRLA data. This can be considered that we have a boundary source that is mapped to solution values of solution. So it is a kind of source to solution map. And we can ask, if we are given the boundary and the Neumann Bridge map, do this data determine the manifold antimetric unit? There is some problems with the this zoom interface. Yeah. Idea is that and that comes in a bit from very somehow surprising direction. There are these time reversal methods that Matthias Fink, Dion Ball, Borse, and Papa Nicolau have studied. And to explain what these time reversal methods could be, that this Time reversal methods could be that we could consider a situation where we have some scatterer, red scatterer here, that is an unknown location. And we would have here points that can send waves and can also record waves around them. So we could consider that we have here these sources, like microphones, and then they send a wave that hits to the stretch scatter. That hits to this wave scatterer. So we measure the data scatterer when the waves hit to the scatterer. Huyen's principle says that the scatterer becomes a source. Oops. Sorry, I have to try to remember to do this differently. Okay, so we have here we send a wave from these sources. They hit to a scatterer and the scatterer becomes a point source. So the waves that hit to the point scatterer. Waves that hit to the point scatter becomes a source, it sends a wave that we measure at these points. So we measure the signals, SJs, that are the scattered wave recorded at these sensors. Then we time reverse the signals. This is where the method has its name, time reversal. We reverse the signals in time and inject those two sources like microphones that change the time. Like microphones that send the time-reversed signals. And because the time equation, the wave equation is time-reversed, the waves sent from these point sources, they focus approximately to this point square. This idea of this time reversal methods, time reversal methods that you reverse the time somehow, and then you obtain waves that. And then you obtain waves that focus to a single point. And this requires that you have a point scatterer, but now we want to somehow do considerations without any scatterers. We want to focus waves in empty space. Maybe I say a few basic ingredients. When we have this Neumann-to-digital map, then we can connect Neumann. Can connect norms of the waves in the interior of the medium, these L2 norms of the waves at time t capital, something that is computed on the boundary. And on the boundary, we have an operator k that is a combination of our measurement operator, Neumann-Degrill operator lambda, and then some very simple operators that are some kind of low-pass filtering and time reversal operators. Lambda here is this mapping that maps the Neumann data to TDLA data on the boundary. So we can connect norms of waves inside the manifold at any given time to boundary data. So we can compute these L2 norms. Maybe I okay. Then we can use the fact that the Bayes probably Then we can use the fact that the waves propagate with finite speed. And now the distance of the money between two points X and Y, the Riemannian distance, the distance in the Sri Manny manifold Mg, is physically corresponds to the travel time of waves from point X to Y. And we have the sets that are called domains of influences, when we have an open set gamma of the boundary. We have open set gamma of the boundary, we specify distance s. Then, the domain of the influence consists of all points here inside the manifold that has distance that is less or equal to s to gamma. And this has the name domain of the influence because if you have this is the picture where time is up and space is horizontal, if we have sources on gamma times time interval, the waves propagate inside. Interval, the waves propagate inside light cones. So the waves at time s when we have produced them by sources on gamma, they must be in supporting this dominant inference. And there is status unique continuous results, which says that we can approximately control, reach all possible states here. So this actually implies that we can solve so-called blind control problems. Also called blind control problems. So, first, what is the control problem here? We would like to say that let's we want to produce a find of source if such that at time s, the wave would be as close to a value one here in the domain of the influence and zero elsewhere. Elsewhere. So, we want to find sources for which the wave is as close as the target value one in the domain of the influence. And S is considered as control, so we want to somehow find some control that makes the system to be as close as this ideal state as possible. And to solve this problem, so one more thing: why this is blind? Blind is. Why is this blind? Blind here is that because we don't know what is the medium. The medium inside is unknown. We only can do boundary versions. So we want to control the waves inside unknown medium by using boundary observations. This control problem can be solved with a small error by minimizing the function that is. And that we minimize the difference of the value of the wave at time s minus one. So because when f here is a sort that is supported on gamma times time interval. Anyway, this wave is zero outside the domain of the influence. So there we can't do anything. If we minimize this quantity, the wave will be as close to one in the domain of the influence as possible. And then we add there. As possible, and then we add there some small regularization there, and actually, by using Tata's unique continuation, it means that if you solve this minimization problem, then the waves actually approach to this indicator function of the domain of the reference. Now, the question is: how are we going to solve this meaningless level? Now, the quantity here, the L2 norms of waves, they can be computed by using an Be computed by using this our boundary operator. So, this is a quantity that we can compute from boundary data. This is just quantity on boundary. So, everything here can be computed on the boundary or boundary data. And then we can just minimize a function that we can, which point values you can compute. And you can use your favorite method to minimize this function. What this means is. This means. This means that using boundary data, it is possible to find sources that are identical to one in the domain of the influence and zero elsewhere. So we can focus the wave in this domain of the influence. We can make also this set smaller. Actually, here is a result that we say that we can approach delta distribution. But let me show you the picture. This is very But let me show you the picture. This is very nice numerics by Martin de Hoop, Paul Keple, and Laurie Oxen. It says that using boundary data, it is possible to find sources that produce waves that at given time look like this, also waves that look like this. And when you subtract these two waves, we obtain a wave that is focused in a small area. Oops, I pressed again the wrong button. So we can produce waves that at that given time focus to single area. This was only for the value of the wave, but we can actually do this can focus in both for the wave and its time derivative. We can produce, we can minimize some functionals that can be computed directly from Neumann and the Bridian map so that the waves and the time derivatives of waves go to zero and delta distribution. zero and delta distribution. This actually means that if you look at later time moments, so if at time t capital the wave focuses so that wave is zero and time derivative is delta distribution, this actually means that when we look any later time moment, the wave will be equal to the prince function. Let's find this equation. So here we have a delta source and here we have a we use delta source to solve the equation. Wave equation. So we can focus waves to arbitrary points of the manifold. Oops, I again press the button, sorry. What we can do, we can any point here inside the manifold, we can construct waves that are focused here. And so we basically construct here artificial delta distribution. And when we wait a little bit, we ask that when we observe the wave coming from this. When we observe the wave coming from this single, when we have a so here we have a one possible point point source, it produces the focus of the wave there and wait how long it takes that the wave is observed at the boundary. Can we are measuring from the interior point travel time to boundary points? And these are just Riemann distances from the interior points. From the interior points to boundary points. And it can be shown that this determines the isometry type of the Riemannian manifold. And this is actually this kind of construction that originates from Belly Shaven, Berry Sheav Curie, so we're boundary control method. It was developed then further for geometrical setting for by Belly Sham Curie 11 later with Binham Curie 11 and Children. So Verique. So I recall that finally, we reconstructed from the fractional, we've reconstructed from fractional diffusion data, we reconstructed data for wave equation. Using data for wave equation, we can focus waves to a single point. And when we have focusing waves, then we can see that how much it takes time from some integer point to send waves to the boundary. And this gives a collection of functions. Collection of functions for any point x inside the manifold with no distance function dx that give the distances from the integer points to boundary points. And finally, the reconstruction of the manifact. Assume that we have the correlation of all functions dx, where dx is the function that gives for boundary point z distance from x to z. So we have reconstructed the correlation. So, we have reconstructed a collection of all these boundary distance functions. How to construct a manifold? Now, the answer is that actually you don't have to do anything in a simple case. If the manifold is simple, which implies that all geodesics inside the manifold are distance minimizing, so they are globally distance minimizing. Then it turns out that the norm of two distance functions dx and dy is the difference. Y, the difference and its supernormal is equal to the distance of points x and y. Now we can say, in a very fancy way, that we have a mapping H that maps a point X to the corresponding distance function. This maps the manifold to continuous functions on the boundary of the manifold. And the inverse problem data give us the range of this map. It gives the collection of The collection of all these distance functions. Now, this inequality is equality here. It says that if we just have constructed this set, this is isometric to the original manifold. So we constructed an unknown Riemannian manifold by constructing distance functions. And this family of all distance functions itself, it is a manifold that is isometric copy of the physical structure. Copy of the physical structure where the measurements came from. And everything is done. We have constructed the copy of the manifold that we wanted to find. Thank you very much.