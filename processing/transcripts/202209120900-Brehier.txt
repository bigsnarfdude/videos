Good afternoon, everybody. Thanks for the introduction. Thanks for inviting me to give this talk. So today I will indeed talk about some numerical methods for SPDs. So the plan of the talk, I don't know if I will be able to speak about everything. So I will present some motivation, basically about the standard Euler method. Then I will present the new method. Present the new method I have proposed, which is modify your archaeology and the main results about the qualitative and quantitative behavior of this method. And depending on time, I will discuss either an application to multi-scale systems or discuss the proof of the main results. And if you have some questions, don't hesitate to stop me. So, first, just present the settings. Just present the setting and the kind of equations I want to consider. So, I want to consider parabolic semi-interstochistic PDs, which are driven by additive noise. So, here I will consider only equations in special dimension one and on a bounded domain with homogeneous Diracle boundary conditions. Okay, the noise will be spaced type point with noise. We have a parabolic equation, so we have a time derivative. Equation: So we have a time derivative of x on the left, and on the right, we have a single order operator, a linear operator. Okay, and if you want, you can consider that the function a is constant, and we also have some non-linearity f applied to the solution. And in this talk, it will be assumed to be globally Lipsy-continuous. Okay, and this was just for the presentation of the model, but in the sequel I will consider this. The sequel, I will consider this in the framework of stochastic evolution equations, like in Daprato and SAPSIG book. So the unknown will be a stochastic process depending on time t and with values in an inverse space, okay, capital H, which will be L2 for our for our problem. The noise will be a cylindrical linear process. We have some non-linearity still, and the linear operator, I call it Meinus London. It minus lambda. Why not? Okay, this is a setting, and for this audience, I think I don't have to give too many information about SPDs and the mild solutions and things like that. So I just recall very briefly the notation. So our linear operator lambda is unbounded, but it can be decomposed in eigenvalues and eigenvectors. So eigenvalues are lambda j. So eigenvalues are lambda j, they go to infinity. Lambda j is like a constant time j squared. And Ej is a complete, gives a complete orthonormal system of the Hilbert space. And to give solutions, I consider the semi-group generated by this operator minus lambda. I will write it e to the power minus t lambda. So it's defined in a very classical way. I don't insist all. I don't insist a lot on this, but I insist on the spoofing property, which plays a very important role in this talk. So we can consider fractional powers of the operator lambda, lambda alpha, and we have this moving property. The solution at time t of this linear equation belongs to the domain of this operator for all times t positive and all alpha. And we have this estimate. And in the sequel, I can reconsider solutions. Sequel, I can reconsider solutions in the sense of milder formulations. And what is important is to give meaning to the stochastic convolution. So it's in red because just I gave this talk last week to non-specialists, but it's just something basic for us, I think, today. So the cylindrical Wiener process is just a W of T, which is a sum of beta J of T E J, where beta J are independent Boolean motion. Where BJ are independent Brownian motions, standard real-value Bronyen motions. There is an issue that W of T does not take values in the space V space H where we look at the solutions, but using the smoothing property of the noise, we can give a meaning to the stochastic convolution because we are in dimension one, so the series of the inverses of the lambda j converges. I go very fast on this. Stop me. very fast on this stop me if you have some questions but here nothing is really nothing is really tricky and nothing difficult in terms of solutions of the SPD so the main solution is well defined for all times we have nice bounds and I insist that we have regularity in time which is given by the parameter one over four and in space one over two and mostly in the sequel I will use a Sobolev type regularity estimates in terms of this kind of t estimates in terms of this kind of moments. So the expectation of a square of the norm of lambda alpha x of t for positive t is finite only if alpha is less than one over four. Okay, I think that's all for the setting. And now I'm ready to introduce the standard Euler scheme, which has been studied a lot. So sorry, I didn't write any precise references to the literature, but there are many special. The literature, but there are many specialists in this audience about this question. Okay, so it's a numerical scheme. I only discuss time discretization. So I consider time step size 2, which I consider to be a time capital T divided by an integer of capital N, and I have times of Tn, which are N2. So how we define the standard scheme, we write the My formulation between two times, Tn and Tn plus one. Between two times tn and tn plus one, so we have three terms, and we make some approximations. And the nice one is to approximate this the exponential operator by this operator eto, which is the inverse of the identity plus two lambda. So if f was zero and if w was zero, this would be just the standard implicit Euler scheme for the for the for the for the linear. The linear equation. Okay, so this is the basis of the scheme. So this operator A tau. For the nonlinearity, we just replaced the exponential in the integral by A tau. We assume we freeze the value of X of L at the left point, and we get this term, TO A2 F of X L. And for the noise, we do something. And for the noise, we do something like a noise archive. So, what we use is a similar argument, and we freeze the value of exponential, it gives AO, and we have increments of the cylindrical Wiener process. And I will call gamma n these variables, okay, in the sequel, and for why not calling them cylindrical Gaussian random variables. I don't know if it's classical notation or not. And for this, we have a literature contains many, many results. Literature contains many, many results on the strong and weak convergence and with rates. Okay, so the parameter alpha between zero and four, one over four is very important. It gives corresponds to regularity and we get strong order of convergence, alpha, and weak order of convergence to alpha. And I see it on something, which is that the test functions phi in the weaker estimate, meaning that I take the solution, I apply phi and then I I apply phi and then attack expectation. These functions phi need to be at least of class C2 with bounded derivatives. If we remove this assumption, we decrease the order of convergence. Okay, just to say this in a few words, if we assume that they are only of class C1 with bounded derivative, we get order alpha. And if we do not assume that they are C1. C1 or C2, we get something, we do not get convergence for generic test function file. I will come back to this after. Okay, and to illustrate this numerical method, this standard numerical method, let's just see some numerical experiments. So I consider the discretization using this time step size 2 and the Size two and in space its finite differences method with a very smaller a reverse smaller mesh size on the left you see the evolution in terms as a function of time and position time tn and position z so from left to right it is the z variable and on the right something which is just the value at the final time so it's just the evolution At the final time, so it's just the evolution, so it's just the process at the final time. So it's just a function of z, the special variable. We see that on the left and on the right, it is zero because of direct homogeneous Dirac A boundary conditions. Okay, and based on what I have said before, this should have a regularity order one-half, like one-hand motion. But this is, as you can see, this does not look like a brown-hand motion. Look like a Bonham motion. This is too smooth. So, the observation is that the numerical solution is smoother than the exact solution. And this is due only to the discretization in time, in fact. When you choose a positive toe, you have this issue for positive toe. And one of the objectives of the scheme I want to present now is to ask a question. Of course. Yes. Of course. Yes. So, what kind of f did you choose for this one? I don't remember, but it's very possible that I chose f equal to zero. I don't remember. I don't remember the initial value. And you have this additive noise, right? Yes. In fact, everything is due. Only the issues are only the discretization of the noise. Even for f equals to zero, I have issues. Issues, but yeah, non-linearity plays essentially no role here. Yeah, I would expect the solution to look more like a perturbation of the heat equation in that case. But yeah, but it's added here, so I think I started from zero. Okay, I think it's just the stochastic convolution. Okay, so it's like But it's forced, so it's not exactly the it equation. It could be, could be. So it's Gauchan, just one realization, yeah. Yeah, no, I would just expect to see a little bit more of the initial heat equation shape, right? I think it was zero, but maybe on the left, not clear. Okay. I will check after. Okay, fine. But you will see after with a new method, it's completely different. With a new method, it's completely different, anyway. So, okay, so this is basically, I think, just a stochastic convolution discretized by the standard method, which has been studied by dozens of people in the last 20 or 25 years. Okay, so the objective of the new method I propose, and I will try to explain why I call it a modified method, was to propose a scheme which preserves the regularity of the solution. Preserve the regularity of the solution. For any choice of the time step size, I want the numerical solution to have in space the same regularity as the exact solution. That was an objective. Okay, and then we can study whether we can prove better quantitative results based on this. And the answer is yes. And this is one of the main results of this work, which is an approximation of the invariant distribution. Of an invariant distribution in a specific situation where we know that it's a Gibbs distribution in total variation stands, something which is completely wrong if we take the standard Euler scheme. So, I will explain more to detail this result. And then we can also exhibit other situations where we can use the modified Euler scheme, whereas we could not use the standard scheme. So, this is, for instance, the multi-scale problem. Maybe I will have. Scale problem, maybe I will have time to describe the markup chain Monte Carlo method in infinite dimension. Before presenting this scheme, I should mention that there is an alternative which is the accelerated exponential hierarchy. So here you should recall that for the standard hierarchy, we have just one formula here, simple one, we have three terms, and we have one operator, A2. One operator, A2, which is linked to the implicit approximation of an approximation of a semi-group. In this alternative scheme, we can use the exact solution. We can assume that we can use the exact solution of the semi-group. We have to compute the exponential of minus 2 lambda. We can also modify the other two terms. So, for the second one, we have this expression, lambda. For the second one, we have this expression, lambda minus one times this quantity. In fact, it's just something that should be, well, that would be exact if f was constant. It's an integral between tn and tn plus one of the exponential. And we can do something similar for the noise. In fact, this is chosen such that if we take f equal to zero, in distribution, this is exact. This is exact. Okay, so this is exactly the covariance we have to choose to make this happen. Okay, so for this scheme, there are many good results too. In fact, it's even better for probably than the modified learner scheme I propose. But for the method I propose, there is no need to compute the exponential. That can be an advantage in practice. So, Charledor, can I ask a quick question? Edward, can I ask a quick question? Of course. Here, do you need to have this approximation of the non-linear term, or do you can you take the standard one? I'm not sure. I mean, at this point, it's not more. Is it more difficult to compute? No, no, it was just a curiosity question. I don't say that it is better. No, no, but at some point it's better, I think. I think. Okay. Thank you. We'll see. I'm sure that at some point it's used, but I don't know if we can prove. Okay, no, okay. Thank you. So, and in fact, in the sequel, if I have time to present the proof, I will have to come back to the accelerated exponential earlier scheme. Okay, last slide for this part. So For this part, so I have to define now the modified alert scheme. So, the idea is that this scheme is just a modified version of a standard alert scheme. I will make a very kind of small modification of the scheme, but it will be much better. So, I just recall the SPDE or stochastic evolution equation and the standard OER scheme. And the modified Euler scheme is almost the same, but there are But there are two major differences. Okay, so there are one more term, in fact. One more, yes, one more term. Okay, so the parenthesis is almost the same as the standard RA scheme. We have A2, still the same A2, but what we are instead of square root of gamma n, we have a square root of two divided by two times a random variable gamma n1. Variable gamma n1. And we need another Gaussian random variable with the same distribution, which is independent. Okay, a gamma n2. And we need another operator, beta. So maybe to explain this, imagine that beta is equal to eta. And in fact, because of the properties of Gaussian random variables, in distribution, we would recover the standard LSK. We would recover the standard Role scheme. Exactly. Okay, if beta is equal to A2. But here we impose another constraint, another condition on B2, which is the one here. So B2 times its transpose is equal to A2. This is the condition we impose. And the news is that this can be computed I don't I do not need to assume that B two is separate joint or things like that. I don't do not need to diagonalize any operator. Diagonal has any operator that we can use a Cholesky decomposition. And I insist, for instance, to compare simulations here in practice. You can think that square root of 2 gamma n is the sum of gamma n1 and gamma n2. Okay, it will be consistent, in fact, and it will be better, as we will see after. So, is the definition clear? So, in practice, the only difference is we need this operator B. We need this operator beto, and we need two random variables for this implementation. Okay, and now I can show you that it's very different. So here it's using the same noise, same two, same final difference, same initial condition, and same F, even if it was probably zero. Okay, so same noise, I mean vitreation. Square root of two gamma n is equal to this. Of 2 gamma n is equal to this. So I see I sample gamma n1 and gamma n2. Okay, so on the left is the standard Euler scheme, and on the right is the modified Euler scheme as a function of time and position. And maybe I go directly to the final value. So it's at the final time as a function of position z. So it's very different. Quickly interrupt you. Yes. What was the dimension of the noise? Yes. What was the dimension of the noise you used on the left? Did you use space the the same dimension for the noise as you took points for your finite differences? Exactly, yes. I sampled it like that, yeah. And here in the right, it's the same, yes. Yeah, double so many or so here, we just just because of this beto, we completely change the regularity of the. Yeah, yeah, I'm not surprised. The left one is, I think, known that you have to take a lot more noise points. You have to take a lot more noise points than this for white noise. Yes, but in fact, it's just not just a question of finite differences. Because in fact, you can see this at the level of semi-discrete discretization, only discretization in time. Thank you. It's not a question of finite difference. Of finite differences which are not refined enough. Other questions? Yeah, Shalidoa, sorry to interrupt. So in some sense, the standard OLA method could be thinking like it has a regularization effect, right? It has a regularization effect, yes. Yeah, but you. Yeah, but it's modified is more is close to the exam solution, right? In fact, there is a regularization effect, which is too strong for the standard scheme. In fact, it comes from the V can be seen here on this condition on B2. Do you have some county? Uh, quantity quantify proof, do some uh proof for this, yes. I mean, uh, what that depends uh which result, but uh yes, I can show you. Um oh yes, I don't know it's not written in this slide, but uh okay, uh let me show you something. Okay, here I have this property in terms of soball spaces for fractional powers. Fractional powers, I can show that for the modified hierarchy, if I fix two and I the moments of the exact solution and of the numerical solutions are finite for all the same values of alpha. And for the standard DNA scheme, for fixed, we can allow higher values of alpha. I don't remember exactly, maybe one to one alpha or something like that. For something like that, I see. Thank you. Yeah, it's not difficult to. This can be proved easily. So it's a first result, about the qualitative behavior. So the special regularity is preserved by the modified Euler scheme for any two. And I can go on with one of the other results, in fact, which explains why I have to choose Bito this way and Which is the fact that the Gaussian invariant distribution, when f is equal to zero, which is in fact for our problem, the law of a Brunian bridge, it is preserved by the modifier team for any two. So we have a North China led back process in infinite dimension, which is Gaussian. Its invariant measure is Gaussian, and it's the same. It does not depend on two. Something which is completely false for the standard yellow scheme. Okay, now first quantitative result, which is not the best one, so I will go first. In fact, we in a general situation, we have exactly the same result as for the standard LA scheme. In fact, I'm stupid because I want it for the standard ULA scheme, but I wanted it to be for the new scheme. So maybe now I go to the more interesting results. Go to the more interesting results. So, as I said, one of the motivations is to remove regularity conditions on phi. And for this, I introduce the notion of a total variation distance between two distributions mu1 and mu2. So, we take the integral of phi d mu1 minus phi d mu2 and we look at the supremum for functions which are bounded only and continuous or measurable. And I start with two results. So on appropriate technical conditions on F, but I don't want to detail. For the standard LSK, there is no approximation. So the total variation distance between the distribution of X of T and its approximation by the standard scheme, it does not converge to zero. It is a constant for all two. It's because, in fact, the distributions of these two are. In fact, the distributions of these two random variables are similar, and the proof is somehow something like that. It's just because they do not have the same space regularity. And for the exponential Euler Kim, the accelerated version, I mean, we can prove that with good conditions on F that the error goes to zero with some rate which is two alpha. And I think I will try to prove you this result after. Prove you this result after, but I will skip some parts. Okay, and now there is something in between for the modified alier key. At this stage, I don't know if I can prove the same result as for the exponential alier key, which is in any situation at any time, the total variation distance goes to zero with some rate of convergence, positive rate. But in fact, for the modified Euler scheme, there is a if we look at the invariant. If we look at the invariant distribution, so we take the limit t goes to infinity, we assume that, for instance, that the Lipschitz constant of f is small, smaller than the first eigenvalue of lambda. Okay, something happens in this setting. We have to assume something more. We have to assume that the nonlinearity is a gradient, so minus a gradient of u, or some function v. In this case, there is a nice property that the invariant distribution. Property that the invariant distribution of the equation we are looking at is a Gibbs distribution. What do I mean by this? I mean that we have this expression, so I call it mu star. So mu star is absolutely continuous with respect to the Gaussian invariant distribution nu when f is equal to zero, and the Radon equilibrium derivative is the exponential of minus two d. So we have some expression in this case. In this case, it's not a new result, something also well known in a finite dimension. And the result is that in this setting, so with these two assumptions, and the most important one is the one in red, is that the modified IRC has an unified brain distribution, which depends on toe, and that the total variation distance between U infinity toe and mu star goes to. And mu star goes to zero at the same rate to alpha. And this is, I think, I think something remarkable, something new, interesting, and so on. And I think I can give you the main idea of the proof. Okay, so this is. I will come back. I have some slides after to explain this again. So the idea is to observe. So, the idea is to observe that the new scheme can be written as the accelerated exponential air scheme applied to another stochastic evolution equation. So, maybe we can go from below. So, we have this modified equation, so a calligraphic x depending on toe, and we have operators in red and blue, okay, lambda to and q to. Blue okay, lambda two and q ta. So some new linear operators. So lambda two is not equal to lambda, and it's an approximation in some sense of lambda, and q2 is an approximation of lambda of identity. Okay, if we apply the accelerated exponential Euler scheme for this method, we get the equation in the middle. And we can define lambda tau such that exponential of minus tau lambda tau is equal to A tau. And we can define Q tau such that A tau is equal to. That eto is equal to what it needs to be. Okay, and there is a kind of algebraic miracle that we have for the noise. So, okay, we have freedom only for two operators, lambda and qto. And for the noise, we get the square root of qto. And the good news is that if we assume that f is minus gradient of V, then this modified equation has also mu star as a unique inverne distribution. Star as a unique van distribution. Okay, so this is a key observation and something nice. Okay, and I will skip a few slides to explain why it is interesting. Maybe I will come back later to a multi-scale setting. So to explain why it is interesting, I will prove the result I give uh the give idea of the proof of the result for uh the total vari variation approximation. Total variation approximation for the exponential error scheme at any time. If I am able to do this, I will be able to use similar techniques maybe for the modified equation on the modified Euler key. And at some point, I will use the fact that, in fact, the Winvari distribution of the modified Euler scheme, in fact, it does not depend on two. So I get a result for the Winvari distribution I wanted to approximate the Gibbs measure. That's the strategy. That's the strategy. So we have this. So I consider now the accelerated exponential error scheme during two slides, I think, something like that. I recall the definition. So something we have exponential. The coefficient in front of f is just the integral between tn and tn plus one of the exponential of what it the exponential of something we f. And we have again this theorem because given. It was given before, so under appropriate technicians conditions on F, but I do not want to write. So, any time, and we have this total variation approximation result, and the order is 2 alpha. And I want to explain the proof. I think one slide will be enough. So, we take a function phi, which is say bounded and continuous, and in fact, we use a And in fact, we use the standard method for weak error analysis. One parenthesis is missing, we care. So we write the weak error in terms of the solution of the Kolmogorov equation associated with the SPD. So u is the solution of dtu equal lu, look at the bottom, and with initial condition phi. And we have the usual arguments. Usual arguments. We can use this representation: a telescoping sum argument, an auxiliary continuous time process, which has the good values, the same values as the numerical scheme at times. And what happens, because we have chosen the accelerated exponential hierarchy, is that we only have one term. So if we consider the standard hierarchy, we would have al already a three terms at this stage. Already a free term at this stage. But here, what happens is that it's not so it's possible to understand that this should be like that, because if f is constant, this term vanishes. Okay, but if f is constant, by construction of the scheme, the scheme is exactly distribution. So we have something nice. This is why we have many constellations. Okay, so we'll Okay, so here we are happy because we only have one term. Very nice. And no second order derivative, for instance, of view. And here to continue, the nice thing is that we have a nice regularity result for the derivatives of view at positive times. So maybe look only at the part in blue first. In fact, to have an estimate on the derivative, Estimate on the derivative in space with respect to x. I mean, we don't do not need to assume that phi is c one, we can assume that it is c zero, but we have some singularity. We have some singularity when t goes to zero, t to the power minus one alpha. Okay, so imagine first that alpha is equal to zero at this stage. If we have this, we are happy and we get some positive rate of convergence because f is ellipsoid continuous. F is ellipsis continuous, and we use the regularity in time of trajectories, which is alpha, okay, the parameter alpha. And if we do this, we get the result not exactly what I've written. Instead of two alpha, we get alpha. So D is the derivative with respect to X or with respect to W? Sorry, I mean D, the D, the capital D, the derivative? Ah, this is derivative. Ah the v is derivative with respect to x which is in infinite dimension but yes this is a sorry okay so here uh it's this operator here just uh this is it o form here if we apply this with alpha equal to zero in this equality below we get order alpha and in fact because uh we impose some nice regularity properties on f we can go to order two alpha because Alpha because this the process has higher older regularity in a negative solar explanation. Okay, so for the main result, I think this slide is exactly the same as before. The modified Euler scheme is the accelerated exponential Euler scheme for the modified equation. And as I said, we now understand how to deal with exponential accelerated exponential Euler scheme. Exponential acceleration, exponential key. Here, maybe it's time to show you the expression of lambda toe and q to. So I just give expressions of eigenvalues. The eigenvectors are the same. And maybe I should emphasize. So when to goes to zero, lambda toe j should go to lambda j and q to j should go to one. But that for fixed toe, when j goes to infinity, it's completely different from a parabolic equation. parabolic equation because this goes only a logarithmic like a logarithm logarithm of uh of j at infinity for lambda j to j so we have very different uh properties for this uh of these equations okay and um what happens then no i decompose the error i decompose it into two terms so i have the x of t and of Of t and of so I take the weak error and phi is again some some function. So x of t and I have the solution of a modified equation. So what I put is the solution of a modified equation at time t. And in general, so we have this is like the standard Euler scheme. For the first term, we need to assume that phi is of class C2. For the moment, this is what I want to, I don't know. What I want to, I don't know how to remove this condition for this, and we get order of convergence to alpha. But with the condition, the gradient condition, if we take the limit t going to infinity, this vanishes. So it's equal to zero. Something equal to zero will be easy to control. And for the second error term, we do something like for the analysis of the accelerated exponential. Accelerated exponential Euler scale. But what is different is now that we need to look at the solution of the Kolmogorov equation, which is associated with a modified equation. So it's not U anymore, it's U2. Okay? And we have a similar regularity result, but here are now the technical things and funny things, maybe. Maybe I show again the result for you first. U first. So we have two things. On the right, we have some constant phi, only bounded, okay. And we have powers t, which are minus one alpha and minus alpha because of this regularization effect. I didn't mention that this comes from the smoothing property of the summit. It's very important. But for the modified equation, for this U2, sorry there are u SUD power here. So we get something an exponential because we want something to go. We want to look at the Large time behavior, nothing important. Here for the part in blue, we have a power one alpha and we have something more. We cannot, we do not have t, but t minus two, two. And for the alpha part, it's the same. In fact, it's not exactly the same because we have an additional term square root of two alpha. Additional term square root of two alpha, square root of two. So we do not have a this rig smoothing effect here, but we have a square root of two. Square root of two is nice. This is very similar to the result for you, but more technical to prove. How to prove is it's a combination of some kind of Markov properties, summing group properties. So we prove inequalities independently first. First of all alpha equals zero, but whose text phi smooth text phi of plus C1 or alpha equal to zero, but phi of plus C0. And in fact, the result comes from the fact that the smoothing property for the modified semi-group, so I have lambda alpha here, an exponential of minus t lambda two, I get something with t minus two. Between times zero and two, it's not good enough. So that's Enough. So that's the idea of the. So there are many. It's not so difficult, not so technical. It's when you have this like the accelerated exponential scheme, but with additional terms, things like that. So I go back since I have five more minutes, which will not be enough, but I will try to explain this. So another application of a modified alert scheme, so also to have some. So, something I like, and I have been working on in recent years which are asymptotic preserving schemes for some stochastic equations with multiple time scale. So, here I consider a system with two components, capital X epsilon and Y epsilon. And there is this parameter epsilon, which is small. It will go to zero. For the equation on Y. For the equation on y, we have an Australian back process here, exactly. So you should think that y epsilon in this notation is what I have studied before as called by x. Here dt is missing in the equation for x, but it's an equation and we have some coupling between x and y. x epsilon depends on y, the evolution. The evolution, okay, through some non-linear term g. And there is a result when epsilon goes to zero, it's a kind of law of large numbers. x epsilon at time t converges in some sense when epsilon goes to zero to the solution of a deterministic evolution equation where the variable y has disappeared. We replace g of x y by g bar of x okay and g bar of x okay and g bar of x is the average of g of x y d nu y where nu is the invariant distribution of the first process which depends on the epsilon so this is a well-known result theoretical results at this stage okay it's a low graph numbers and the idea the question is can we do something which is can we get an approximation of a slow component with a With a choice of a time step and maybe error estimates, which are uniform with respect to epsilon. And this is the notion of asymptotic preserving scheme. I will consider a scheme for the system and I will pass to the, I will take the limit epsilon goes to zero in the system and I get a scheme which is which will be consistent with the scheme with the limit equation, the average equation before. Okay? Average equation before. Okay? So the scheme, the idea is to use the modified alert scheme for the fast component. So this is for the second equation. So we see again the B appearing, the operators A and B. Okay, and for the first part, it's a time step, delta T divided by epsilon. And there are some computations, but when epsilon goes to zero, we can replace it. We can replace, in fact, the y epsilon delta t n plus one in the equation here by some Gaussian random variable, which is distributed with exactly a new. The distribution of this Gaussian random variable is new. And for each n, we have a new one, okay, gamma n. If we had the standard linear scheme, we would get zero instead of something, and in fact, this is not consistent. Something. And in fact, this is not consistent with a good equation. It will be consistent with this scheme, it will be consistent with the equation with g of x, zero, instead of g bar of x. So if this is just another illustration that the modified Euler scheme can outperform the standard Euler method. In fact, we could also use the accelerated exponential Euler scheme, of course, here. Course, here. So, this is an absent total t-preserving scheme. In fact, we can take the limit delta t go to zero or epsilon going to zero in different orders and we get the same approximation. We can change the order of taking the limits. This is the first, I don't know, yes, these are the two properties. Not what I wanted to discuss, and the most. Discuss and the most interesting stuff is to prove some error estimates, weak error estimates. So, here I need some real IT conditions on phi, C3, why not. But what is important is that I consider the error for fixed epsilon here, and I take the supremum over epsilon, and we get that V converges to zero when delta t goes to zero. And with order, which is something between zero and one-third, and I don't know if it's. And one-third, and I don't know if it's optimal or not. Maybe I have time to discuss just the ideas of the proof. We have four limits to take in this diagram. The one on the right is not about the numerical scheme, and it's a weak error in the averaging principle. Okay, we know it's order size epsilon, essentially. At the bottom, it's deterministic. At the bottom it's deterministic, more or less deterministic. Basically it's uh size uh delta t. It's not difficult. The one on the left uh it's more technical and for the one at the bottom we use the fact that it was before because it was the modified earlier thing. We have a nice limp. It's about the limiting scheme. The one on the left is j it's a modification of the proof for the right, but it's much proof for the right but it's much more technical because we are in discrete time and we so we get epsilon plus delta t plus epsilon basically so this is one way to control the error what we control is the top top left and top right what we want to control so we can go below we have epsilon plus delta t and we have another term and i think it's like square root of delta t divided by epsilon because in fact it's a standard recur estimate we know that Standard recur estimate. We know that it goes to zero when z that t goes to zero, but at first we are not able to prove that it's not dependent of epsilon. So we have to be careful not to have some exponential growth or something like that of a constant. So I think it was there. Square root of delta t divided by epsilon. And we optimize the two estimates and we obtain the one at the top. And I go to the conclusion, which is that I propose some. I proposed some new scheme. I hope it was convincing that this could be useful. The results are in two preprints, which have been submitted on archive. So the first one is about the modified Euler scheme, although the results with the accelerated Euler scheme, other results. And the second one is about the last result for multi-scale systems. Okay, and I think I will stop here. Sorry for being one minute late. Thanks for your attention. One minute later, thanks for your attention. Thank you very much, Alidua. And you don't have to be sorry for one minute. It's very good that you stayed to the schedule that much. Other questions, comments? Please unmute yourself or use the chat or raise your hand. So can you do this non-linear noise? Non-linear noise, for example, noise is not additive. Is there some difficulty? I mean, in the definition, sorry. Yeah, so the scheme, so you can just so I can take this. Yes, I can take this and put X sigma of X L to for both. I mean, I can define the scheme. But for the analysis, probably I think it will also increase, it will also improve regularity in the sense of decreasing. Improve the regularity in the sense of decreasing the regularity of a numerical solution compared with the standard other scheme. But for the analysis, I mean, the only result I get is for the moment is about this inverse distribution. Okay, and in the case where f is a gradient. If I put a sigma, I completely destroy this and uh I don't know. And for the exponential linear scheme, I don't uh I don't know to I don't know if I put a sigma in this result. For example, this theorem: can you let alpha equal to one-fourth? Sorry, can r by equal to one-fourth? Equal to one-fourth? I don't know. For example, if f equals zero, can alpha equal to f equal to zero, it is for this one, it is. F equal to zero, it is for this one, it is zero. But it's kind of related to regularity and so it's really close to one-fourth, but before I don't know. Okay, maybe. Usually, it's difficult to prove such results, actually. I don't know any results like that for WikiRoll or Can we go to page 24 about the error estimate? So you have derived the order in terms of delta t, or maybe the previous about the weakened convergence. I see there is a theorem about the major theorem about the convergence order. Yeah. Yeah. Right, right. That's the theorem. So you have the order in terms of delta t and then the constant. terms of delta t and then the constants the constant for the c depends on the capital t do you have like a more explicit dependence on the capital t well it i mean uh what kind of on the behavior of the c so yeah i i assume just that g is a kind of leap sheet continuous and uh continuous and maybe uh i don't remember the regularity probably c free but uh but he But the constant depends on moment bounds, and usually moment bounds are exponential in T, like because they come from Granois spaces. So it's not uniform for this T. Because this is for Y, not for Y. Everything for Y in some sense is uniform. Okay. So you're saying that the dependence of the C on T would be an exponential, right? Exponential in T on X zero, it's it's uh X zero, it's a polynomial in some good norm. I don't remember. I need the paper. I wrote something hopeful to explain this. Yeah, I probably missed something about this. A triple norm, the three is that in H3 or something. Oh, yes, triple norm. Okay. Triple norm. Three means I need three derivatives. So I use this notation everywhere. Sorry. So for uh if it's zero, I mean only the it's uh only a bound on five. It's only a bound on phi. In fact, it's an infinity norm. Yeah, I don't know. It's more classical. Okay, so it's a phi zero. A triple norm, it's a supremum of phi. If I had a one, it would be v phi zero plus the supremum of the derivative of the norm of the derivative. With a two, I had a normal, bound on the second order derivative and three, a bound on the third order derivative. All right, okay. All right. Okay. Thank you. Other questions? Maybe I can ask one. Yeah, so I haven't. I'm not sure I've seen something about the strong convergence in finite time, but not for this. Yeah. No. Yeah. Hello. I did not discuss strong convergence, so I'm not sure about this. We have to be careful. Sorry, I have to show you. I have tried at some point to look at this, but it's because of this condition in some sense. I think it's probably true, but I was not able to do a complete proof. But here, Vito, I do not assume that. But here, V two, I do not assume that uh it commutes with A two, for instance. I I do not assume that it is a self-adjoint. I do not assume that it's diagonal in the basis. The same basis as the others operate, those as the other operators. You see what I mean? And in fact, what happened is that I only have some simulation of the Gaussian random variable, which is good in distribution. I'm only interested in the distribution of the Gaussian random variable. Quotient on the variable I adding. All right, but this is taken from a discretization of your W, right? Yeah, and but I don't care. But for all my results, I don't care that it's coming from the W. Okay. For the weak convergence issues. I don't care. And in fact, I j for this uh it's it's like saying that the uh Yes, if I have a Q DWT, the distribution only depends on the Q Q transpose for a gamma or Q gamma, things like that. Here, I mean, this it depends only on beto, which satisfies there are many possible choices for beto. And maybe because of this, we don't have strong convergence. I'm not sure. Because you would also expect that. Because you would also expect that the weak convergence is better than the strong convergence, right? I mean, I would expect, yes, but I have to show first that it's only convergent. But I think, yes, I think we have some for a standard Euda scheme, it's true. So the picture is this. For standard Euda scheme, we have alpha for the strong and two alpha for weak. But I say for the new. That's what I say for the new scheme, the modified scheme, I only have weak with two alpha. But the Charlé Drois. Yes. If you have the same regularity as the exact solution, don't you expect to have a rate for the strong convergent? It will be strange to not have a rate. I mean, it's possible to propose schemes which are only too good in. In appropriate in distribution, but not strongly. Yeah, but but here you have even the gosh, but I'm not sure. Maybe I can that's a question that needs to be uh looked more carefully the strong convergence of this scheme. Yeah, I had a more maybe even more naive question. Uh, would it make sense to have such a modified Euler scheme for five? Scheme for finite-dimensional systems like SDE? The question is this operator minus lambda. So if you have a finite dimensional SDE, I'd sum set anyway. This is what I do in practice. So I'm going to go somewhere. I want to show you something. Here, if I imagine that everything is about Everything is about finite-dimensional operators and solutions. I also have A2, I can also have some exponential and things like that. And probably, yes, we can have with this modified equation, we can preserve a Gaussian invariant distribution, for instance. And we have also this property that if f is a gradient, in fact, we have a preservation of. In fact, we have a preservation of this. In fact, it's a everything is like infinite dimension to approximations. We have to prove that everything is uniform in some sense. Yeah, but would you improve something by doing that in finite dimensions? For a given dimension, I'm not sure, but maybe if we have some problem depending on dimension, maybe we can have a better boundary. Bounds because, in some sense, some sense, probably, I am not sure, but we can probably prove that the false standard Euler scheme, if we look at the finite dimensional approximation, it will go to zero when tau goes to zero, but the constant is not uniform with respect to dimension. I think this is correct. The thing is that for the modify Euler scheme, it is uniform with respect to dimension. Okay, so this is the Okay. So this is a way of interpreting my results. We have to think that we are considering finite differences or any finite element approximations and that anything we are writing is uniform with respect to dimension for this modified scheme. I guess that you have improvement in case of stiff problems. Yeah, stiff four lambda, you mean? Yes, in finite dimension. Maybe you can get estimates which are uniform in stiffness. Probably, yes. And this result on AP schemes. Oh, probably, yes. And you even in finite dimension this result? But for yes, for AP schemes for For AP schemes for finite dimension, we did this in the paper with my students. We did this only for one-dimensional of tail-enback process. So lambda was a diagonal and the identity. Yes. So I think we for more general lambda, I don't know. Yes, I think we need yes, probably, maybe, probably. Maybe there is something to do. Yeah, there is, of course, I use a lot of the smoothing properties and things like that, but something else. But in terms of dimension, you don't care about scrolling. No, I agree, yes. Except if you want to be careful with respect to dimension or or it depends on lambda or maybe probably the that could be a good setting too, yeah. Uh that could be a good setting too, yes. But but the thing is that if we are in finite dimension or small dimension, uh we could we just diagonalize and and we can use an exponential scheme. So my point more or less is to say that the modified scheme is the one you do not want to diagonalize. But but here it's a 1D homogeneous Dirichlet arguation. It's not a big deal to compute the exponential, no? Yes, even for non-homogeneous. Okay, this I have forgotten this term. Yes, for the if A is constant, I agree. And what else? Yes. Yes. Maybe we can also apply this to higher-dimensional problems. Although, if we put some good correlations of the noise, I don't know exactly what happens. It's more difficult to get precise results, probably. Depending if uh noise commutes or not with operator. Oops, sorry. Okay. Okay. I think it's time to close today's session. If there are no further urgent questions, then I would like to thank Charlé Doua, Raluca, and Kirsten for their very nice presentation. And I hope to see most of you, or all of you, tomorrow. And I wish you a nice