If people stick around and are interested, also breakout rooms. So, with that, it's a pleasure to have the third talk by Gaddy Cosma. And Gaddy, will you share your screen and we will get started. Okay, anyone everyone can hear me fine? Yes, hear me. Yes. Okay. So welcome everybody. Thanks for staying for the last and I'm afraid most demanding talk of this mini course. So first talk was about things that went on since the 80s. The second talk was about these results from 2015. And the last talk, which will be about results which are not yet published. Results which are not yet published of Hugo, Vansan, and myself. It's just a lemma, it's not a very important result, but it's an interesting application of this theorem of self, and therefore it somehow will, I hope it will demonstrate why I believe that this is an important theorem and a breakthrough in understanding of critical percolation. But again, there are no references. There are no references, so the only reference is actually the slides which are on the site. So try to hang on and don't hesitate to ask questions because there is no more detailed versions where you can get the details. Okay, so let's start. So this is where we left off last time. We stated this theorem of surf. Let me remind you the notation. remind you the notation again lambda is a box so lambda n is a box from minus n to n in all dimensions we are in say dimension three or an arbitrary dimension bigger than one and this is a smaller box but not that small it's n to some constant that value of the constant would not interest us oh well it interests but not at not the precision of Not the precision of the numbers here. And this notation, which is the most, which is not a standard notation, but it's especially for this talk, means that there are two clusters from the smaller box to the boundary of the bigger box, which are clusters in the bigger box and disjoint different clusters in the bigger box. In the bigger box. And as people already asked in the first time, they are allowed to extend outside the box and intersect there, but not inside the box. And the theorem says that this probability is decaying in n in a polynomial rate. Okay, so in order to not carry around this one over n. Carry around this one over a let's eta be some number smaller than this, so I won't have to carry this number around. Okay, I'm going to start with a lemma which is which looks a bit strange, but I will need it. But this is really a lemma, so I'm not going to motivate it beyond how it appears in the proof of a layer later, but it's Of a later later, but it demonstrates an interesting and important principle which I think that people who are not experts in percolation should certainly be aware of. So let's see what the lemma states. So you look at cubes of side length n to eta. Remember, eta was from just some number smaller than this. Smaller than this in gamma n. Okay, so I don't mean all cubes. Let's just imagine that this divides n, these kind of divisions are not important, and just take a collection of points which form like a lattice, which are disjoint and you know touch each other. Okay, so I I'm interested in these boxes which are basically form a like a renormalized lattice. Renormalized lattice inside the gamma n of n to some small part. And I couldn't, I'm bothered with clusters which touch too many boxes. So the number of boxes is n2d times one minus eta. And if a cluster intersects seven over eight, the exact number is not so important, but uh this lemma can be proved with any positive constant. With any positive constant, but but let's for but I seven over eight four just for to be explicit, then the probability then it cannot exist with too bigger too the probability that exists cannot be too large. It's bounded by some absolute some okay, some constant which depends only on the dimension. Okay, so think 0.99. It might be 0.9, but it cannot be 0.99999. Be 0.99999, it cannot go to one as f goes to infinity. And again, I repeat that this is definitely critical phenomena. I mean, at P bigger than P C, such as large clusters exist with probability very close to one. Okay, so let's just repeat. So, again, the probability of a cluster which intersects too many signs. Cluster which intersects too many sub-boxes is not too close to one. No, it's all the boxes. Look. Yes, I see this question. Yes, yes, I have the chart open. So, but I'm looking at all. Take the cube. It's a pity I can't draw. I'm missing a board. Take the cube, the larger cube, which has size length, side n, and divide it into n. Into n, maybe this number is written somewhere. No, divide it into n to power d times one minus eta smaller boxes. Okay? And I'm bothered, I'm largely intersects the majority, a seven over eight of the boxes of all translates of the box of size and eta. The box of size n eta by numbers which are multiples of n eta. Okay, so let's let's let's let's see how this is okay so let's note this event by e. This is just notation and let's assume that e happened for two boxes look at this number n half. So I'm looking at the box lambda n I'm translating it by half. I'm translating it by half. So the new box, the translated box, somehow overlaps the existing box by half. And I'm asking that, and I'm denoting by E prime the event that the translated box also satisfy the same property. So let's understand what do I mean here. So there is a cluster in the original box. Okay, we intercept. K, which intersects seven eighths of the smaller boxes. And E prime is that there is a cluster in the translators box which intersects some boxes of a big proportion of the smaller boxes of lambda prime, but it doesn't have to be the same cluster a priori. We will soon see that it does, but it doesn't have to be. Okay, so let's see. So So let's assume that both E and E prime occurred. What does it mean? There is one cluster which intersects everything but one eighth of the cubes of gamma n and another cluster, or possibly another, which intersects all but one eighth. So if you add those descending cubes, you get no more than one fourth. So it there are There are at least one fourth cubes that intersect both, okay, right? Because the intersection of gamma and gamma prime is only half, contains only half of the boxes, and there is a quarter that we threw out because which came from two eighths. So the conclusion is that at least a quarter of the cubes in the intersection, look at this quantity, this intersection is like a half. This intersection is like a half cube, right? Because we have the cube and the cube translated by and half, so the intersection is a half cube. It contains half of the small cubes, and a quarter of the small cubes in the intersection intersect both C and C prime. I really should have drawn a picture here. Sorry about that. So what happens if these clusters are not the same? Here, this is a the point. Here this is the point. This means that each of these cubes satisfies the two disjoint clusters event. This is the point because they have each of these small cubes has the cluster C coming to them. Each of these small cubes have the cluster C prime coming to them. If the cluster of these If the clusters are disjoint, then this means that this is that they have two disjoint clusters going quite far. And we know that by serf's theorem that the probability for that is small. If we use also Markov's inequality, we see that the probability that there are many of them is quite small. So let's understand exactly what is written here. The probability that E happened, that is, such a That is, such a large cluster exists. If prime happen, such a large cluster exists in the translation, and their difference is smaller than n to minus 4, because it implies too many boxes where self-theorem does not work. Questions about this inequality: this is the cultural inequality. This inequality. This is the crucial inequality. If you understand that, the rest of the proof is pretty standard. No, no, the union is an arbitrary union of boxes. I'm not interested in the shape of the union. Okay, we have many small, I'm just interested in their number, right? There is some, we know that for every Some we know that for every cube, small cube, the probability of two disjoint clusters is small. So the expected number is smaller than n times minus 4 times the number. So by Markov's inequality, the probability that there are many of them is small. But I'm not interested in the shape of the union. This is probably not. And this is probably not okay. So let's okay, the slide will now disappear except for this formula. Oh, okay, no, I'm sorry, just was just compacted. Okay, so we have most of the text of the previous, and the self's theorem disappeared because we already used it, and we have this crucial formula here where you can still read it. Okay. Okay, but this means that what? Let's see that the probability if the probability oh there is one difference from the previous slide. I gave this C a number. I replaced C with C1 because I want to use it. So what is the probability that these clusters are equal? Well, we have the probability of E, which is 1 minus C1, and the probability of E prime, which is also 1 minus C1. Also, one minus C1. So if we assume the opposite, then the probability that both E and E prime happens is at least one minus two C1. And we have this bad event, which we also subtract. So with this probability, these big clusters are one and the same. Okay, this is just a reformulation. Now, here is our favorite. Our favorite, remember, how do we prove things about PC? We change P a little and get a contradiction. So, this property, okay, sorry, I won't try to select things. This inequality is an equality which holds in a restricted volume. It holds in a box of size, okay, n times n times n times three halves n. Okay, it's some property of finite space. So, if we take p. So, if we take p slightly smaller, can depend on n, that we are proving this lemma. So, I'm assuming by contradiction that this is bigger than 1 minus c1. So, so if this holds, so our contradictory assumption implies that this inequality holds. By continuity, if we take a slight If we take a slightly, slightly smaller p, certainly this smaller p can depend on n, no problem. This will also hold, maybe with a slightly bigger constant. And here is the crucial point. There is a theorem of Likert, Schoenman, and Stacey that says that if you have that if this number is too big, then you will have an infinite class. This is an extremely extremely An extremely, extremely useful trick in calculation. And if people understand that, they certainly learn something. So let's understand. Maybe I will show the statement of this theorem of Liggett-Schönmann and Stacy. Okay, so here is a statement. For every d, d is the dimension as usual, and k, there exists some epsilon such that if you have any dependent... you have any dependent percolation so some bits which are could depend could be dependent but a they all happen with big probability and they are independent if you look at distance larger than k then you have an infinite cluster with probability one what will our bits be our bits okay now let's Our bits, okay. Now let's let's close and I'll show you again if it's necessary. So let's understand how this theorem of Liggett, Schulman, and Stacey helps us. If I'm claiming that if this probability is big, then the theorem of Lagot-Schmann and because this probability, if you look at boxes which are now I'm dividing the whole space into The whole space into boxes of size n, not of size n to the lambda, of size n. Okay? And I've shown you that with probability quite large in two boxes. Let me take questions after I finish the explanation. So I'm dividing the whole space into boxes of size. Into boxes of size n, and I want to show to construct an infinite cluster. I want to jump really from box to box while keeping the connectedness. What allows me to keep the connectedness? This fact, which is written here. So what I'm saying here, I'm starting with our first label. I know by this line here. By this line here, that with quite a large probability, there will be a big cluster neighbor, which is the same. And I'm going to enable a big probability that this cluster will be the same. So if I find the infinite paths of such n boxes, such that all the clusters are the same, then I will construct an infinite cluster. An infinite cluster. And the theorem of Licke, Schoman, and Stacey tells me that it's enough that this probability be bigger than some constant smaller than one, 0.99, say, for this to happen. Okay. So again, what is the contradiction? We assume that we took piece slightly smaller, found an infinite class. Slightly smaller, found an infinite cluster. So it's a contradiction because we know that for any P smaller than P C, all clusters are finite. Okay, so this is the proof of dilemma. So let me now just see if there are any questions. So I see that there's a question: why is the continuity in P? Okay, this is certainly something it's it's a Something it's it's let's explain that that's easy to explain. This event is an event that depends on only finitely many edges because it's all contained in a in two boxes of size n which are neighbors which are like one is translation by n half of the other here this half is still written okay so it's an event that depends only on finitely many Only on finitely many edges. Events like that, the probability is a polynomial in P. And this is something completely generic. So if you have an event that depends on, I don't know, 10 x, then the probability as a function of p is a polynomial of degree 10 in p. Or it could be the degree could be smaller. So this is the continuity that is explained. Continuity that is explained, that is written here. It's continuous because you see that this argument is not somewhat delicate and an extremely useful trick to realize. We find, we do the reduction on P for this event which is local. Even though this event is local, it implies the existence of an infinite cluster. It's quite confusing. So we find something. So we find something, some global, some local property, which implies an infinite cluster. And this immediately leads to contradiction in PC, because in PC, such an object cannot exist because of this argument that is written here. You can reduce P because of continuity and then get an infinite cluster where you shouldn't get one. Okay, I see that it was already answered in the chat, but still, I think. Already answered in the chat, but still, I think this point was sufficiently important to actually answer it even in the talk. Okay, okay, so the constant, oh, I see another question. Why doesn't the constant depend on n? Because uh the constant in Ligerchon and Stacey doesn't depend on n. It just uh okay, let's let's uh let's move on and maybe take more questions. Let's move on and maybe take more questions. Okay, and to use this lemma, okay, let's skip that. We don't have so much time. This was we skipped the technical point. Let's not bother about that. Okay, so here's what I want the lemma for. Okay, so let's see what this now that I've stated that you will immediately feel a little. I feel a little bit why we never published this because this result is really a little bit disappointing. Let's see what the result says. Suppose for any D, okay, we will actually use D is bigger than three. It's not a big deal, but we will actually use that. You will see how. So if D is bigger than three, there exists some number, okay, such that the probability Such that the probability that the box of size, again, a small mesoscopic box of size n to some small power, is not connected, is bigger than some constant n to minus d. So look how disappointing this result is. We actually think that this probability is going to one as n goes to infinity for a new sufficiently small, not for any new. But for new sufficiently small small small. For any new. But for news sufficiently small, we certainly think that this probability is going to one because we are at PC by the standard conjecture connection probability decay x polynomially. So what happened here? Okay, so by the standard conjectures on critical percolation, if you take you don't have You don't have large smaller boxes should not be con uh connected too far away. They are even uh quantitative uh estimates or conjectured estimates. So this probability for nu sufficiently small and going to infinity should go to one. It should be typical. This unknown connectedness event should be typical. And the only thing we can prove is that the probability doesn't decay exponentially. Okay, so. Decay exponentially. Okay, so is bounded below by some polynomial by a polynomial. So this is why we never published it. And I am not claiming that this is an important... Yeah, these are dimension always. I'm not claiming that this result is so important. I'm just saying that it's a nice application of it's a nice application of self-steering. We already see. Theorem, we already seen one application of surf theorem in the lemma, and there will be another application of surf theorem in the theorem itself. So let's go to the proof. Okay, so assume by contradiction that this probability is in fact, okay, so the probability of the complement, the probability that the box is connected is bigger than one minus n to minus t. n to minus t. What does it mean? It means that with very large probability, all the boxes are connected. So again, when I'm saying each here, okay, or all, when I say each box, I mean again, like we did in the lemma, I'm taking boxes of size n to the nu. I'm taking a lattice of them so that they are touching, but they're disjoint. And so they are something like n to power one minus nu times d. One minus nu times d such boxes. And just by some, because we know that the probability of connection is so, so close to one, then oh, the probability of disconnection is so small, then even if you sum them over all boxes, it's still small. So we will have that all the boxes are connected to the boundary. Now, this doesn't say anything about clusters. They could be connected with one cluster or with many clusters or maybe one large cluster. Or maybe one large cluster, and maybe many small clusters. All we say is that all the boxes are connected. Okay. So let's denote this event by A. And okay, there is some issue here with, yeah, it in particular it means that this part, because if the boxes, if our smaller boxes, our boxes of size n to the new, are inside n to the fourth and connected. Inside n to the fourth and connected to a shifted box, and it will also connect. Okay, this is not important, this all this playing around with clusters, with fractions. Okay, okay, so this is just it's a stress because it's an notation, it's a convention that will be used throughout the proof, but it's but it's but it's not but it's not so important. So, any all the clusters are clusters. So, any all the clusters are clusters that go from the fourth to n fourth to n half. Okay, so the whole of the previous slide is now summed up in this little claim. Our event A, which I remind you has very large probability, probability very close to one, implies that all the boxes are connected. So, I'm taking a union boundary. All the boxes are connected. Taking a union boundary, all the boxes are connected, and this happens with big probability. Okay, so let's maybe it's not a good time for a break yet. Okay, so let's continue a little bit more before having a break now. Let's end for any cluster, what are this proof is about? This proof is about is about understanding how many boxes various clusters have. We know that all the boxes belong to some clusters, but we don't know how many clusters there are and what's the distribution of the sizes. We are working here with some partial knowledge and we somehow have to accommodate that. So, for every cluster, let n be the number of n to lambda sub-boxes, again, of this, probably to be quarter. Probably to be quarter that intersect the cluster. Maybe it should be half as written. Okay, so as under A, we have that, in fact, this sum is at least n2d to 1 minus nu. Nu, because this now, we know that all the boxes belong to some cluster. So, and of course, one box might belong to more than one cluster. There could be many clusters that get to a box. That's not the problem. Get to a box, that's not the problem. So, this is certainly an inequality, not an equality. Okay, so let's understand again. We sum over all clusters which go from n quarter to n half. For each one, we count how many small boxes it reaches. And this sum should be at least the volume because of our assumption. Because we are working under this variable, under this event that states that all the boxes belong to one. The boxes belong to one such, at least one such cluster. Now we use concavity. Look, that there is a word here that appeared. Now we use concavity. Concavity of this function, x to power d minus 1 over d tells us that this is smaller than this. If you don't know this fact, you know, prove it as an exercise, it's simple. Okay. And now we are going to use the lemma. Now we are going to use the lemma. It's a bit tricky, so be careful. Not really tricky, okay. I want to, what is the difference? The difference is only that I'm added the condition, the condition that the cluster is small. Okay, here I summed over all clusters, and here I want to sum only on small clusters. Where small is, of course, the opposite of large. No, this is written correctly. Check this. The number of clusters and okay, so small here is the opposite of large. So let's understand just this inequality and then take a break. Ah, Russ saves me. Ah, Russ saves me. So, this inequality is called Bernoulli inequality. Okay, good. Thanks, Lus. That was helpful. Okay, so why am I allowed to write this inequality? Okay, let's see. We know that under A and A, remember, I remind you for I remind you for yet another time. It happens with probability going to one. It happens with probability very close to one. And under, in this case, this sum is bigger than, okay, you have to replace here D with D minus one. But we know that with probability at least 0.99, there is no large cluster. So with probability at least 0.01, there is no large cluster. There is no large cluster. So there is a part which has zero point, which has a probability at least 0.01 where both things hold. You don't have large cluster, and this sum is bigger than this. And therefore, you get an estimate for the expectation. So I hope I explained this. Let's take a five minutes break and then I will take a question. And then I will take questions up to this point. Okay, so five minutes break. Okay, so if there are questions, you can raise your hand or post in the chat. And when Gaddy comes back, we'll address them.  Okay, let's see what's uh going on here. We didn't use uh a dig bigger than two yet. We will, but we haven't used it yet. It yet. And they certainly didn't explain yet why do I choose your d minus one over d. All this will become clear. So, why do you need also this point 0.1 event that there is no large cluster for this inequality? Hello, I will need it. I will need it later when I use Leopardic inequality. All this will become later. Maybe it wasn't the best point for Proof because everything is still quite mysterious. Maybe it wasn't the best time for Berg because everything is still quite mysterious. It's not clear why I want here the small clusters. It's not clear whether this, why I'm interested in this. Whether this is why I'm interested in this number. Maybe it will. Okay, I hope it will be clearer later. And just to be sure, so this is all under the assumption that the event in the theorem with Hugo and Versant has a high probability. This is all under the contradiction. This is all under the contradictory event that actually no, this is under the contradictory event that this has it has probability small that the non-connectedness event has probability small. So small that in fact all boxes are connected. That's right. Okay, let's continue. I think the five minutes are more or less past. Okay, so so I guess there were not so many questions in the chat. So I guess so far at least the argument is clear, even if the motivation is The motivation is still in the dark. Okay, so let's go. Okay, so we won't be using this lemma about large clusters, so I hid it. But here is the last thing that we concluded: that this expectation is large. Now, to continue, let's remember this argument of Mendelfig remittance. There is one more question. There is one more question just in the chat about the union bond. There should be a factor of n to the d minus nu. Yes. Leo is asking if I didn't make a calculation mistake when I put the union down. No, the probabilities are n to minus d, and I'm summing over n to d times one. To D times 1 minus and there are n to the power, open parenthesis, d times 1 minus nu, close parenthesis, boxes. So after the summing, I still have left over L2 minus d nu. Okay, so but let's let's go back to this Gandalfig-Rimet-Rousseau argument. Argument that we covered the last hour. What did it tell us? It told us that the probability that you have two disjoint clusters going to distance n to the quarter is. I want to focus your attention for the for yet another time. We already discussed very shortly. This very shortly that the crucial quantity that you get there is the sum of the square root of the sizes of the clusters. Okay, I'm not going to use the result, but the result, the eventual result, but I'm going to use this intermediate claim that it's the sum of the square root of the sizes of the cluster that really calls the shots. Okay, I hope you remember that. Now, okay, here there is again more technicalities with n quarter and n half. Trust me that it's okay. This part is written a bit more detailed than a normal presentation would be written simply because it's the first time that I've written this book. So it's also a bit of a paper. But so there are some businesses. But so there are some businesses here with n over quarter and n over half that we don't want to know about and I'm going to skip now I again this is a part of the argument which unfortunately I didn't have time to show yesterday yesterday and I also don't have time to show it today but so you will have to trust me here but but but but part of the argument that is in search papers you could read That is in self-paper, so you could read it there if you needed to. That says that from the probability that a okay, this should be two neighboring points, I'm sorry, and also here. From the probability that two neighboring points have two disjoint clusters going to distance and to the quarter, you can get to the probability that a small box has two disjoint clusters going to distance and quarter and pay a N to some power of the size of the box. This is the same argument which I didn't show in Serf's theorem last hour. I'm going to use it again. It just says that there is a connection between these two probabilities, which again is some kind of parting algorithm. Now let's put this estimate here. So you get, you see, just I just put it here. There is no problem. There is nothing. There's nothing interesting in this line. So you get n to minus d half plus some constant. These terms are not important. Don't bother about them. This is the important term. You get n to minus d plus something which can be made small if nu is taken small enough times the sum of the squared of the cluster. So I just copied. Okay, I'm doing this calculation in details because this is the Calculation in details because this is the core of the argument. Okay? But still, it's just a calculation. Let's go. So, this is just the conclusion of the previous transparency. Okay, it's written exactly, you see the same n minus d half plus constant mu, and the same n minus d plus constant mu, and the same crucial, crucial, crucial sum of the square roots of. Square roots of the clusters. And here's the second point of the argument. Let's remember what is the isoperimetric inequality. Okay, what is the isoperimetric inequality? It says that any set has boundary at least the size of the set times to power. times to power d minus one over d. Okay? Now we are going to use the isoperimetric inequality after you know restricting to boxes. So it's a boxed version, but this is but it's the same inequality. And what it shows, it shows that if you have a cluster, then the Then there should be many. Remember what this notation, this notation is still around. It's the number of n new sub-boxes that intersect this cluster. There should be this number of boxes which intersect the clusters, but have a neighboring box that does not intersect the cluster. Okay? And this is some kind of local isoperimeter. Some kind of local isoperimetric inequality. And here it's very important that the cluster be small. I remind you the definition of small. Small means that the cluster does not reach more than seven over eight or some constant, it's not important, of the boxes. There are still many boxes which the cluster doesn't reach. So the point is, so this is here is very important because if the cluster reaches all boxes, Because if the cluster reaches all boxes, then this set would be empty. And so this is clearly false. Okay? So it's important that the cluster is not large. And then we know that there will be many boxes which intersect the clusters, but have a neighboring box that does not intersect it. We're almost there. Hang on for a few more minutes. Let Q be such a box. Let Q be such a box. Again, we are talking about an end to the new sub-box. And let's q prime be its neighbor that does not intersect. Remember that our event A, that all the boxes are connected. This implies that the union of these two boxes is connected to distance n quarter by two disjoint clusters. Right? Because all boxes are connected, and we know that Q is connected to C and Q prime. connected to C and Q prime that C reaches Q but not Q prime but and Q prime has some therefore whatever the cluster that reaches Q prime it must be different than C and you we get a lot of disjoint clusters therefore you have this many boxes of size two new and new which are connected by two disjoint clusters okay Okay, I'm taking the sum over all small clusters, and for each one, I'm looking at this boundary, this number of boxes which have this neighboring box, which are this property, and I can just sum them. Okay, so here it is written again. Okay, now there is some overcounting in this argument. When I did, when I summed over When I summed over the clusters, there was a little bit of overcounting because one box may appear in various places, but this overcounting is no more than n to the nu, which I don't care about. So what did we get? We get that the number of what, what does it mean such boxes, it should be written here. Okay, here it is, boxes of size. Boxes of size 2nu, which are connected to distance n quarter by two disjoint clusters. So this number is bigger than some factor that comes from overcounting times this sum that we explained came from the isoperimetric inequality. And this is it. We take expectations. And we get essentially a contradiction. So let's understand. The difference between here and here is just taking expectation. This was under A, and this is exactly the same thing, but I took expectation and used the fact that A has probability going to one. So the expectation of this would still be larger than the expectation of this. You see, it just copied. And this last inequality, I took this guy and put instead our estimate from a few transparencies back, which is still written here, basically by the Eisenman-Kestin-Newman self-argument. So I get, so you see. So you see, it's just a formal. I took what is written here and copied it. And this is the end. Let's see what we got. Okay, we still have to bother with this smallness, but this is not a problem. We can discuss this later. And let's see what we got eventually. We got something that cannot be. Be we got that the sum of the square roots it should be bigger or equal to equal is bigger than the sum of the powers d minus one over d there is some factor here but it doesn't break the argument so why doesn't it break the argument because it's everything is multiplied by By nu. Okay? So let's let's and for if nu is sufficiently small, this is a contradiction. Okay, so maybe I will just show you the proof in a nutshell and then and then actually I don't have much time and I didn't plan to show anything else. So let's let's understand let's understand the proof, the overall structure of the proof. Okay. Okay, on the one hand, we got that from the Eisenman, Kest and Newman self-argument, we got that the probability that n to the new is connected, that the box of size n to the new is connected to lambda n is smaller than some sum of all clusters of the square root of the sizes. On the other hand, our contradictory assumption, the isoparimetric inequality, and the fact that there are no large clusters, we used all three. Clusters, we used all three, gave a bound which had powers d minus one over d of the same quantity. Okay, so let's remember again why did we use all three? Why did we use all three? The contradictory assumption that this probability is very small meant that all boxes are connected, which allowed me to use the isoperometric inequality, which meant that the sum of the boundaries covers everything, that the clusters cover everything, so that gave me some bound on the cluster. And I needed the fact that there are no larger clusters to use this optimic inequality. Use isopiometric inequality. Because if there are no large clusters, then I can use this operatic inequality for each cluster. And these two things contradict. So I don't have much time left, and anyway, I don't have too many things to say. So please feel free to ask any questions about. to ask any questions about about the about the proof because i'm basically done okay i see that there was a question in the at some point in the chat where did i use d bigger than two now you can see why i need that did at least three because at d equal to two this is square root and there is no contradiction contradiction Contradictions come because in 3D the boundary is bigger than the square root of the volume. Of course, the result holds also in 2D, but using a different argument. Okay, any other questions about this proof? And Omar, at some point, asked. And Omer at some point asked why do I need this fact about small clusters? I hope this became clear to use the isoprimieric inequality. Okay, so if there are no questions, let me make just a few remarks and we'll finish. First of all, if you go through the calculation, you can get an explicit number, for example, one over sixty. Example one over sixty okay, certainly like everything else, improving it should be useful, but I can't you know give any particular reason or you know magical value where at this point it would be must be true. By the way, new cannot be improved beyond half at At no, sorry, maybe even one over 2d in high dimension. So, so it's not too, you know, people who think too much about two dimensions might think that mu can be, should be improvable up to one. This is not true. Okay, I should have written it, but I didn't. Okay, and let's finish with dependencies diagram for this entire mini course. Tells us Tells us just ignore these two, which we didn't have time for, but we did have time for a slightly sketchy proof of all these six. So we actually did cover quite a lot of ground. So let's remember what we had. We had that we started with the fact that the expectation at criticality is infinite. We got from that the sum of the probabilities of connection. Sum of the probabilities of connection to the boundary of the box is at least one. From that, we got Surf's lemma, which says that if you have two points in a box of size N, then they are connected in a slightly bigger box with a probability which is not too small. From that, we got Serf's theorem that says that the probability of, and of course, here came the argument of Eisen-Man Kesten and Newman. And Newman, that the probability that if you have the probability of two disjoint clusters from a small box to the boundary of a larger box is quite small. From this, we got the lemma that we saw today: that the probability of a large cluster is bounded away from one, and both things. One and both things together, because we used a self's argument here during the proof of that, gave us our final result of the final result of this course. And I've highlighted two of the claims in a bolder frame. These are the places where used criticality. The places where you used criticality explicitly rather than implicitly, you know, these are all conclusions. So, certainly, if you use criticality in one, then it will fall, then you will need it in everything that follows. But here and here, we use criticality explicitly. Here, I remind you, this is the expected size of the cluster. How did we use criticality? We, again, assume the contradiction that the expectation is finite. Expectation is finite, increased P slightly, and so that even after increasing, there is still no infinite cluster, which contradicts that you are at least at PC. Yes, yes, yes, this is a, sorry, this should be smaller than, sorry, thanks, thanks, Gabo. And here, we use the criticality explicitly by, again, assuming the contradiction. Assuming the contradictory assumption, assuming the opposite, assuming that this is bigger than 0.999, reducing p slightly and constructing an infinite cluster. So, so you see how, okay, you can think about it as the same trick or not, I don't know, but it demonstrates that basically two kind of dual or similar, if you like, ways to use criticality to get to learn. To get to the point of the case, okay. That's it. Okay, so I will unmute everyone to thank Gaddi. 