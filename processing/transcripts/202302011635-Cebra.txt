Who worked at the University of Chicago? I'm sorry, who's an undergraduate at the University of Chicago and is now a PhD student at UIUC. All right, well, thank you to the conference for having me out here. Today I'm going to be presenting sort of a summary of some of the research I did with Alec, specifically Similarity Promotes Transitivity in Generic Competitive Systems. So, all right, we'll start with some definitions. So, our competitive system is going to take So, our competitive system is going to take the form of a directed graph. Edge flows for this directed graph are going to be some metric of performance of one competitor against another. That can be wild gods of victory, that can be chaot in a zero-sum game, that can be normalized win probability. The only important concept is that the flow in one direction is equal to the negative of the flow in the other direction. So that's why it has to be normalized. You can create a competitive system in a biological system. Competitive system in a biological network, you can create one in social choice, you can create one in like sports context, pretty much various applications. But, okay, so the competitive networks are going to have some properties, and the main one we're going to talk about here is transitivity and simplicity. So, a network is going to be defined to be transitive if there are no advantaged cycles. So, if you had A beats B, B beats C, C beats A, that's a cycle. So, if there's no such cycles, the network is transitive. Cycles, the network is transitive, and the network would be cyclic if it's favorite-free. That is, no individual in the system has a net advantage over or a net average advantage respecting their neighbors. Okay, so a stronger notion of transitivity is strong transitivity. That says that if you have A, or if you have two agents, I and J, they're connected in a path where, let's say, I is stronger than J and it continues down some transformation. Than J and it continues down some transitive path, and there's two other agents in the middle of that path, H and K, then I has to beat J by more than H beats K. So it can't be like I beats J 60%, J beats K 60%, but I only beats K 51% of the time. And the strongest possible notion of transitivity here, perfect transitivity says, okay, we have some rating function, and we can determine the when probability. The win probability solely as a function of the ratings of the various competitors. All perfectly transitive networks are also strongly transitive, and all strongly transitive networks are also transitive. So here, this is an example of a perfectly transitive network on the left. These are the ratings of each of the competitors and the directions of the edge flow. And then the other one is a perfectly cyclic network. There's three cycles that the competitors find themselves in, and that one, the one on the right, is favorite free. Is favorite free. Okay, so what's the fundamental problem that we're trying to ask here? So the dimension of transitive competitive networks compared to the dimension of all networks is very small. However, in the literature, it's widely observed that competitive networks are more abundant than they would be expected from solely a dimensional argument. So we're trying to introduce some mechanism for why this transitivity is promoted, and we want to introduce it. And we want to introduce it regardless of the domain. So, our proposal is that across evolution, the competitors might concentrate towards a set of optimal strategies within the trait distribution. And if they do so, that local concentration is a mechanism to promote transit in the system. And this is a Hodge theory lecture. So, how are we going to use the Helmholtz-Hodge decomposition here? So, we want at any step to So, we want at any step to measure the degree of transitivity of the network at some point in time. And the way that we do that is you can decompose the network. Of course, we've seen the conservative component being the range of the gradient, cyclic component being the null space of the divergence. But specifically in this context, we can decompose any network into a perfectly transitive network and a perfectly cyclic network. And we can measure the sizes of those two networks. Sizes of those two networks to calculate a proportion of transitivity at any specific time. Okay, so this is the networks we saw before. This is a combination of the two, but it can be decomposed into its perfectly transitive component and its perfectly cyclic component. And that is through the network HHD. Okay, so now moving on to some theoretical findings. So we're going to use performance functions to measure. Performance functions to measure how well the competitors do against each other. Performance function is a function that takes in the traits of the two competitors and it outputs this when probability, log odds, et cetera. The most simple performance function you can think of is just a linear function of the traits. Like, okay, you have maybe one competitor as a trait three, one competitor as trait one, your value is two. Those linear performance functions are pretty clearly transitive, but they're obviously a very simple example. A very simple example. Slightly more complicated, a quadratic performance function would take a form similar to this. A quadratic performance function is also probably a simplification of what most performance functions for a real world game is going to be like, but it will allow us to get some interesting mathematical results. So yeah, this is our basic form of a quadratic performance function, and then we'll try to generalize those results to more complicated performance functions later. Okay, so one of So, one of the fundamental results, a theorem on trait performance. So, if we have some arbitrary competitive network G with vertices V and edges V, and we assume that the traits of each competitor are independently drawn from the trait distribution, and the edge flow is defined according to the performance function, then we can say that the covariance of the edge flow has the form equal to sigma squared, which is the variance in the performance. The variance in the performance times I plus rho times some function, the edge incidence matrix. And rho here is the correlation between, if you randomly sample three competitors, x, y, and w, it's a correlation between x and y and x and w. So the closer that that row is to one half, the closer you are to perfectly transitive. That means like you can tell a whole lot about how one competitor will do against any. One competitor will do against any random one by just seeing how it does against one. And that would be more common in a perfectly transitive network because a lot of it is about the ratings. It's not about who you play, it's about how strong you are overall. And so this correlation coefficient rho is a useful way of measuring how close we are to perfect transitivity because we know that at 1/2 we get perfect transitivity. But if we want a component that goes towards zero as we get closer to perfect transitivity rather than going towards one half, we're going to Rather than going towards one half, we're going to introduce this additional coefficient called epsilon. It's going to control sort of how far rho is away from one half. And with how we set it up, we've defined that rho is greater than or equal to one half times one over one plus epsilon. Okay? So previously, we had an inequality in terms of epsilon, but it actually is true that. But it actually is true that if the performance function is quadratic, then rho is just equal to one-half over one plus epsilon. So we can simply interchange rho and epsilon for a quadratic performance function. And also a lot of the messier terms in our definition of epsilon go away. And it's just a function of the expected value of the higher order terms of performance divided by the variance of the linearization of the performance. Okay, and then also from a trade. Okay, and then also from our trait performance result, we can say that for these quadratic performance functions, the value of the expected size of the network and the expected size of the transitive component of the network are just O of 1, but the cyclic component of the network is O of epsilon. So the cyclic component, the size of the cyclic component will change with epsilon. So as epsilon shrinks, the size of the cyclic component would be expected to shrink as well. But we said in our mechanism, But we said in our mechanism that we would be talking about a concentration as a mechanism for this transitivity to develop. So for concentration, and specifically because we want to see how quickly we converge towards transitivity. And so we're going to introduce some parameter kappa that corresponds to the concentration. It's like a way of measuring how quickly the trait distribution concentrates. And I guess a simple And I guess a simple toy example of a concentration result would just be a normal distribution with covariance equal to kappa. So as kappa goes to zero, this distribution will shrink to its centroid. And we're going to define a few rate of convergence sort of notational things that as if we have some ratio of g of kappa over h of kappa, which is if we go back to the definitions of rho and epsilon, there are. The definitions of rho and epsilon, they're all going to be a bunch of components that will go towards zero as kappa goes to zero. Then we'll say that something converges in order less than or equal to h of kappa if the limit of g of kappa over h of kappa is finite. We'll say that it converges strictly less than h of kappa if that limit goes to zero. And we'll say it converges equal to h of kappa if we can define some finite but non-zero term that this limit goes to. That goes to. So, okay, so for our quadratic performance function, and also if we assume concentration, so we assume that the trait distribution, the distribution of the traits, so we can sample our individuals from pi, so x of kappa, depends on kappa and has a covariance that is going to zero at order O equal to kappa squared, and also that the higher order moments of our trait distribution are. Trait distribution are and the higher order moments of our trait distribution are going to zero faster than kappa squared. So the higher order moments are going to zero faster than the covariance of the distribution. And that our gradient at our centroid that we're considering is non-zero. Then we can say that epsilon is also going to zero faster than our covariance is going to zero. And that the ratio of the expected size of the cyclic component to the overall expected size. Component to the overall expected size of our trait distribution is going to go to zero at a rate that is less than or equal to kappa squared and is only equal to kappa squared if the xy component of the Hessian is non-zero. So a little bit of background for why that might be relevant. So a big reason that systems are going to be cyclic is if one competitor has say three traits and their trait A and someone else's traits. Trait A and someone else's trait B can compete, like maybe say there's a predation scenario, and like one competitor is really fast but doesn't have a lot of endurance, and someone else is really slow but they do have a lot of endurance. Those two traits might create some cyclicity in the system because they kind of, you know, there are different scenarios in which different ones might be helpful. So for a higher order system, we would expect that this X sub Y Hessian being zero promotes more transitivity and being non-zero promotes And being non-zero promotes more intransitivity in the system. And as I mentioned, as a toy example, a normal trait distribution with vanishing covariance is an example of a distribution that will satisfy these conditions, so we can say those results about it. In a secondary lemma, under the same assumptions, we can also say that the variance is going to also go to zero at order less than or equal to capital squared, so the same speed as the curve. Speed as the covariance, or I guess it's fat, it may be faster than the covariance, and also that the expected size of our transitive component and our overall distribution, or our overall competitive system, are going to be going to zero at order equal to kappa squared, but the sigma component is going to zero clearly faster because it's less than or equal to kappa to the fourth. And again, we have our equality result only if the Hessian xy component is non-zero. Okay, so we've Okay, so we've said all these things about a quadratic performance function, but as we said previously, we aren't sure, and actually, generally, performance functions are not going to be quadratic. So we are going to try to approximate our higher order performance function with a quadratic performance function locally. And so we need a couple more conditions this time. We need that the second order Taylor approximation of our performance function needs to have errors. Function needs to have errors with respect to the actual performance function we're considering that are bounded by a power series with cubic terms or higher. And we need that the support of our trait distribution is going to also go to zero. It doesn't have to go to zero as fast as the covariance, but it does have to go to zero because we're worried that the tails of our error, like the Taylor approximation, might blow up as we get. Taylor approximation might blow up as we get pretty far away. So, this support is also going to have to vanish over time with kappa and then our concentration parameter as before. And if we have these assumptions and we have that either the gradient or the Hessian, the xx Hessian at the final centroid is not zero, then we can say that both our epsilon and our variance parameters converge to the quadratic approximations we found earlier, and so that gives us. Earlier, and so that gives us our sort of pleasant results about how the cyclic component is going to zero faster than the transient component, and so on. And this all leads into the overall theorem about trait concentration. So if we have basically the above assumptions and this concentration assumption, so we have that over time our support is vanishing and also our covariance is vanishing. Then we can say again that we converge towards the quadratic approximations, and to go over those again, that the transitive and the overall component are going to zero at order equal to kappa squared, while the cyclic component is going to zero faster at order less than or equal to kappa the fourth if the gradient is non-zero. And if the gradient is zero, then both the transitive and the overall component are going to zero faster. So you'd expect. Zero faster. So you'd expect the gradient to go to a non-zero value at the end of evolution if you're converging onto the boundary. Because potentially you would, like, it would be better to have a higher value of this trait. You just can't because you hit a physiological orientation. Whereas if you converge to, or if the gradient is zero, that means you've reached a local maximum that's on the inside of your trait distribution. And so in those cases, you might see the transitive component also going to zero faster. Going to zero faster. So, this is all sort of summarized in this table. Because it's a fraction of some terms going to zero in a numerator and a denominator and potentially a bunch of, well, I guess theoretically you could have a bunch of zero derivatives and Hessians in a row. But in actuality, you're generally going to find yourself in one of these three boxes. So this one is the most simple case. It just says, okay, well, we converge to we have a non-zero gradient. We have a non-zero gradient and also a non-zero xy Hessian, so that corresponds to we have a high-dimensional performance and also we converge on the boundary, then we'd expect quadratic convergence. If we have a one-dimensional performance function, we're not going to have an x, y, Hessian. So we expect to converge faster if we only have one dimension. But then maybe in one dimension, we're going to end up on the interior, and so we would go back to quadratic. So this is kind of our predictions. We're going to test those later. Predictions. We're going to test those later, so this is just a good thing to keep in mind regarding what we'll expect. Okay, so our final major theoretical result says that, I guess previously we showed that the network converges in expectation to perfect transitivity. So it's also true that we can trade out our strong assumption about transitivity and drop it from perfect transitivity to simply transitivity in exchange for strengthening our convergence. For strengthening a convergence statement from convergence and expectation to convergence and probability. And that's listed in this theorem. The probability that the network is transitive goes to one if we have the same assumptions as before. So this is just another interesting result, and it allows us to strengthen our assumption about convergence. Okay, so we have sort of all of this, all of this developed theory. So we're going to demonstrate now some of our rate of convergence and also a few. Some of our rate of convergence, and also a few examples that show that this convergence towards transitivity is something we can reasonably expect. So, our first example are some bimatrix games from game theory. They're nice because they're well-studied examples. They also, we can estimate a performance function by like, okay, so you have one trait in a bimatrix game, and it's just your probability of doing one strategy. So, like, for a prisoner's dilemma, maybe your one trait is your probability of defecting. Probability of defecting. And we can estimate a performance function by basically taking all of the possible strategies and having them play a bunch of games to see how effective each of them are and then interpolating it into a real performance function. So it's a performance function we can develop pretty easily for our game as well. So these are the three bimatrix games we use. We think they each have different characteristics, and in fact they they all do, so they can lend slightly different cases for some of our convergence results. Some of our convergence results. And the way we did our numerical demonstration is we started out by randomly sampling a bunch of competitors from all across the trait distribution, and then we had each of them play another 100 randomly selected competitors. And we measured how well each of them did in the game by using our performance function. The ones that were most successful, we selected to reproduce. We gave them some genetic drift to induce some difference. And then at that Difference and then at that step, we calculated the size of the cyclic and the transitive component. And then we basically saw: did the competitors move a lot, or do we think that they found their optimal strategy and that evolution has stopped? If we think it's still going, then we would repeat playing games with our new agents until evolution stopped. So for our three bimatrix games, this is our proportion of transitivity by step of evolution. So for prisoner's dilemma, it's pretty clear that the evolution stops very quickly. The competitors Evolution stops very quickly. The competitors find the best strategy. They go to zero transitivity very quickly, or sorry, zero intransitivity very quickly, and they stay there. For a stag, it seems like transitivity is increasing over time, but it looks like it's probably reached about a point where it converges. And that's obviously, as you can see from the y-axis on this graph, a very low portion intransitivity, only 1% intransitive. With chicken, on the other hand, there's initially the And initially, the network becomes much less transitive, but then at the end of evolution, it seems like it becomes more transitive than it starts. So these three games have three very different results. So why might we expect that? So Prisoner's Dilemma, the best overall payout occurs on the boundary. So we would expect the competitors to converge very quickly towards the boundary. With STAG, we're going to have convergence to an interior maximum. Convergence to an interior maximum. And then with chicken, our performance function kind of goes crazy at the edges because the payouts are so like, the payouts are so massive in the event that you crash, you lose a ton. So in that case, it's possible that some of the higher order terms and the higher order derivatives are maybe not dominating the expression, but at least having some effect. So that's why we have more intensity. And so, as we said before. So, as we said, because we have a one-dimensional performance function and we have convergence on the boundary, we'd expect quartic convergence with Prism's dilemma, and that is, in fact, basically what we observe all the time. With stag hunt, quadratic convergence is probably the most likely prediction because we're converging on the interior, and that is, in fact, largely what happens. The ones on the bottom, they're probably still spread out a little bit, or potentially they still have a secondary cluster. And then with chicken, it's a little noisy. And then with chicken, it's a little noisier. It looks like it's mostly coordinate because it is a boundary maxim that it largely converges to. Although it is possible if there's this big cluster that always swerves, it is advantageous to not swerve some of the time. So sometimes you can keep two clusters. And that's also the reason why it's a little bit more intransigent. But again, it seems mostly on the cortic line. And then, so these are all one-dimensional examples. We also developed. We also developed some arbitrary higher-dimensional performance functions where we basically just define them as a random sum of a linear component and a trigonometric component. The linear component is going to create strong transitivity at the beginning because, again, you have sort of one very clear local maximum, and those competitors that are closer to that are gonna be way stronger. Whereas the trigonometric component, you're gonna have a bunch of peaks and valleys. Going to have a bunch of peaks and valleys. And in that case, it's pretty likely that some, at least at the beginning of the evolution, you're going to see some high intransitivity. So in fact, this blue one, which is the performance function we defined that was solely trigonometric, at the beginning it's nearly perfectly intransitive. But if we allow our evolutionary mechanism to go for even 15 steps, it becomes only about 0.05 Port intransitive. Portion of intransitivity. And then for the other networks, they seem to also converge to a very low level of intransitivity. And because this is a higher dimensional performance function with more traits, we'd expect quadratic convergence because we have crossover interactions between traits built into the function. And in fact, we do see these points lie on a line of quadratic convergence. This middle graph shows that our concentration. Shows that our concentration result does, in fact, hold as the covariance goes to zero very quickly, but about as quickly as the intransitivity, the intransitivity also goes to zero. So yeah, so this is our sort of, both of these are kind of contrived examples, although they do sort of allow us to explore all of the, or at least a large number of the potential cases that we can rely on for our evolutionary results. So, yeah, thanks for. So, yeah, thanks for it. And let me know if you have any questions. Okay. Questions? A simple one. On the previous slide, what gives rise to the horizontal lines that you see there? So we... Okay, so we stopped our evolution if the centroid stopped moving. And so what I think probably happened in those cases was that, like, Happened in those cases was that we still had two clusters, and those two clusters didn't move, so the centroid didn't move, so it stopped evolution early by accident. I think most likely. Because they're equal, right? I don't know. Yeah, it's supported in the covariance because you also have the same two lines of elevated, right? If you look in the covariance, there's two cases which retain. So those are the two clusters. Yeah. Yeah, but I think that we actually were supposed to flag those, and I think it somehow thought it was one. And I think it somehow thought it was one cluster as well. I don't know. But I think those, I mean, they're marked as outliers on MATLAB. I assume there's probably one beam each. So does this apply to the case where things are converging to a single dominant strategy? Apply to, I guess. I guess cases where there were multiple strat equally good strategies. So it is possible that, like, even if there are multiple equally good strategies, our evolution will just pick one of them and then by randomness it will end up staying there at which point you would have that transitivity result. If there are like two long-term clusters, you can't say the things about like everything converging inside of a shrinking ball or whatever, because obviously they're going to be converging. They're going to be converging to separate points. So it is some of these ones, it's like they do have two clusters or multiple clusters for a while, and then eventually one of the clusters will just have like a bad set of results and it will get sort of killed off in the next step. 