So this is joint work with Alexiev Yaroslav, Dima Grigoryev, and Eduard Hirsch, who is sitting here. And this is basically a work on algebraic proof systems and semi-algebraic proof systems. And I'm going to start by asking the following question. Can a natural number be negative? A pun made by Edward, I think. And it's not just a pun. The answer is yes. In our computational model, our proof complexity model, we see that it's actually See that it's actually possible that the computation, the proof complexity model, does not refute the fact that efficiently that a natural number is non-negative. Now, I'll start, I'll have two parts for this talk in some sense. One is the conceptual framework, in which I will be very abstract and not go into much detail. Detail, but I will give the basic ideas behind the work, and then I will give some of the details for those who are more interested in seeing what is going on, and I will hopefully sketch the lower bound, some lower bound, conditional lower bound proof and the relation to semi-algebraic proofs. So, the conceptual framework is this, as I said, we have this binary value principle, which is an encoding, simple encoding. Is an encoding, simple encoding of the fact that a natural number is negative. So hopefully over 0, 1, right? This is unsatisfiable. Hopefully we know it is unsatisfiable. But we are going to show that something about this. Now, as you see, this is just a simple linear form in n variables, which are all Booleans, and they have quite big uh coefficients. Quite big coefficients. And as I said, this is what we call the binary value principle, which says that a natural number, because this is the value of a natural number encoded in binary, is minus one. Now we are going to show that in some sense connected to algebraic and semi-algebraic proofs, this principle, and also to circuit complexity of our algebraic circuit complexity, more Complexity. More concretely, actually, I would say the following: so the algebraic segment complexity or some hardness assumption there are going to yield something about algebraic, the relation between algebraic and semi-algebraic proofs. And all based on this simple linear equation. Now, let's see the motivation. So the motivation number one is this. Are semi-algebraic proofs stronger than algebra? Proofs stronger than algebraic ones. So that's what I want to ask first. I want to understand. And in order to understand this, first we need to understand what is, at the high-level scheme of things, what is algebraic proofs, and what are algebraic and semi-algebraic proofs. So algebraic proofs are simply proof systems that operate in the ideal. So the ideal here, inference is in the polynomial. Inference is in the polynomial ideal of any field. And I have these polynomials, and I want to consider the ideal of these polynomials. So inference there in algebraic reasoning or algebraic proofs is if I have P and Q in this ideal, then I can multiply P here, if it's in the ideal, I can multiply it by any polynomial H, and it's still in the ideal. That's quite definition. And if I have two polynomials, P and H. And if I have two polynomials, P and Q, then I can add them together and still get the polynomial in the equilibrium. So that is algebraic reasoning. Algebraic proofs are doing operation like this. And as you observe, this preserves equalities with zero. So if I have, if I have in this sense, if I have for A some field assignment, I have these f, these polynomials are equal to zero, then all this inference preserves zeros, right? Preserve zeros, right? So all inference polynomials are under the assignment are also zeros. So algebraic proofs is working in the ideal and it preserves zeros. And what happens in semi-algebraic proofs? In this case, we work not over the ideal, we work over the cone. So what is the cone? You can think about a cone as like a polynomial ideal, only that it's a polynomial ideal that preserves non-negativeness. So it's like Right? So it's like uh polynomial ideal, but it preserves no negative values. So let's look what it what see what it means. So cone actually is kind of it's not completely standard when we search the literature. Some people call the cone only if you product by a coefficient. Some people call what we are doing here as sum of square cones. I think this definition appeared originally maybe in Grigoryev and Voroboyev. Grigoryev and Voroboyov. And this is our, it's quite generic definition. So I start with this cone of these polynomials, and if P and Q is in the cone, then also P times Q is in the cone. So remember, I'm going to cone, preserves no negativeness. So this means that if these are greater or equal to zero, then P times Q is also greater or equal to zero. And the addition, like in the ideal, is also greater or equal to zero. Also, greater or equal to zero. And the second thing here is in the code we can have for free sum of squares like this. So this is a polynomial. Or this means for any polynomial s here with variables x and over the reals, I have the power, the square of s is in the code. And also I have if c is a constant from the reals, which is not. From the reals, which is non-negative, then it is also in the column. And then, by induction here, I can multiply by the sum of squares and so forth. So, semi-algebraic reasoning is reasoning in the column. Doesn't 3 follow from 2? Um not necessarily. Depends uh are here, yes, but uh maybe if we work over uh uh uh uh ordering, I'm not sure it ev any ordering, it might not. I'm not sure it has any ordering, it might not. Right. So, yes, so this preserve, as I said, preserves inequalities. If it is greater or equal to zero, if we start with things which are greater or equal to zero in A is a field assignment, then of course all inferences are greater or equal to zero. Now, what happens here is, remember, we are in the motivation, so motivation is to understand what is stronger, algebraic or semi-algebraic. What is stronger, algebraic or semi-algebraic proofs? So, for us, at least in our setting, and the setting in proof complexity, it is usual the case that semi-algebraic proofs are stronger for free, or at least as strong as polynomial, as algebraic proofs. Why? Because of two reasons, I mean two independent reasons in some sense. The first one is that as Grigorier defined it and others. Grigorier defined it and others. They defined the proof system, semi-algebraic proof system as first working in the ideal. So again, the inputs that we want to refute are equations, polynomial equations, and inequalities. So in semi-algebraic proofs, S is defined by Grigorier. And further on, you take the equalities and work over the ideal, and you take the inequalities and work over the code. So for free, we have. So for free we have algebraic reasoning, sorry, working in the ideal in semi-algebraic proofs. Because I will start with my equations and develop new, infer new polynomials over the ideal. And also, if I have inequalities, I develop them in the code. So this means that for free, semi-algebraic proofs simulates algebraic proofs. Now otherwise, you can actually Now, otherwise, you can actually do it like this. If you don't want to work over, which if you don't want to, if you start with polynomial equalities, inequalities, you don't want to work with equalities, so what we do is the following. We still work over the colon, but we add to the set of inequalities, we add the following. So, I treat inequality in my input that I want to refute, p equal to zero, as a pair of inequalities. As a pair of inequalities, p is greater or equal to 0, and minus p is greater or equal to 0. So I have p and minus p, and so I can simulate working in the ideal with these two polynomials, with these two inequalities. How? Because the cone of p and minus p subsumes the ideal, I think. This, right? And how do I derive h times p in the cone of this for any h? Of this for any h, not just non-negative, even a negative h or even negative constant, I just say h times p is equal to negative monomials of h times minus p plus non-negative monomials of h times p. Right? So that's how I simulate in the ideal of polynomial equations. Because I just take p and minus p. So this was. I do have negative monomers. Sorry? Sorry? How do you get negative parallel numbers? Yes. Oh, right. First question is what is your question? And the second, I think if your question is how do you represent the polynomials, if I represent a polynomial as some of monomials, then I will have minus monomial and positive monomials. So minus monomial will be minus minus monomer. Minus 3x1. This is my polynomial. So this is a negative monomial, and this is a non-negative. But in a cone, you can multiply by not every polynomial, but on a polynomial from the column. You have to negate them first. So there's a minus sign missing. Oh, maybe I made them, yeah, I changed it up. No, it's not. No, no, negative monomers of age. I think it's the issue is that how do you know that? issue is that how do you know that you have a 3x1 in the cone and x2 in the cone for example if this is the polynomial if that's h let's say that that's h then you want to know that you have a 3x1 in the colon you don't need that you get to multiple oh 3x1 is not a square so well h is this one and we want to have And we want to have P here. You want to multiply it by P. So, right. So you break P into the minus parts. Sorry, this should be P. Sorry. This is P. And then. No, no, that's H. And that's H. It's 3x1 times. It's 3x1 times minus p plus x2 times p. You take 3x1 times minus p plus x2 times minus 3x1. No, you don't put the minus there, put it on the minus p. I put it here. Well, I don't know how to do it now. But it's just in the Boolean setting or something. Okay, that's an eponomially positive, right? Oh, positive, right? Right, so how do you how do you have uh x? Yes, so we actually have these x's for free. Because I'm uh x, I will have the the x chose uh this and this. Maybe this was the case. But the point is, this is simple in the sum of uh monomials. Actually, we show this idea works also for circuits. So you can do it uh by structural induction on the size of the circuit, the same idea, and it will work. The same idea, and it will work. But this was too detailed for this conceptual part. So let's go for motivation two. So, motivation two is we want to have conditional lower bounds or lower bounds which are conditional even on strong proof systems. And this is unknown, for example, for Frege. Example for Frege and beyond, we don't have lower bounds and we don't even have conditional lower bounds. Condition based on something that is not co-NP equal to NP. Some interesting condition, computational hardness condition, and we want to have this lower bounds on some strong proof system. Now, we are going to show this, but it's not going, because it's going to be for the binary value print. It's going to be for the binary value principle, which is a linear equation. It's not going to spill over to the Boolean setting, so it's not a CNF, so it will not give us a conditional low bound fragment. But still, it's going to be a conditional low bound, a very strong proof system. So here are our results. Right. So our results are the following. We have We have three parts for this result. So, algebraic proofs weaker than semi-algebraic ones under complexity assumptions. So, we, in some sense, separate algebraic proofs from semi-algebraic proofs for strong enough proof systems that we show this. For this goal, we do the following. We formulate a very, very strong proof system. A very, very strong proof system which we call the cone proof system, which is an analog of the ideal proof system. So, like you work in the ideal, we work in the cone and we do the same. What is the gist of the ideal proof system by Grocio and Pitasi? It is working over the ideal, but representing a proof as a single circuit. So, we are going to represent a proof also over the colon. Of the cone with a single circuit. In order to preserve non-negativity, it will be a specific circuit that we call conic circuit. But it is just a circuit with some specific property. But it's also not a cook-reca, it's probabilistically verifiable proof system. Of course. Of course. So because it's over circuit, it's not Cupreko, it's probability it's uh the verification process is in Co-RP. Right. But this for lower bounds just gives you more edge because, of course, we can do it also cook record by adding syntactic rules, rewriting rules. Now, so we are going to call it the CPS, the cone-proof system. CPS, the Cohen-proof system, and we are going to show that under this some complexity assumption it is strictly stronger than IPS. And what we are going to show also is that even the strongest algebraic proof system, namely IPS that we know of, cannot simulate the weakest semi-algebraic proof system like sum of square. So based on this assumption from complexity theory, Shabbat-Smith, we are not going to be able to simulate algebraic proofs, cannot simulate Algebraic proofs cannot simulate semi-algebraic proofs, even if they are very weak. Although it is, I must say that it is open if for CNF encoding it can be, but for the general case, it is not possible assuming this complexity assumption. So, in this sense, we separate the algebraic and non-algebraic reasoning. Now, and so I put this nice, oh, it's quite small, nice diagram, and this is the diagram that we are going to That we are going to study. Sorry? Sorry? I hope you read it for us. Yes. Okay, so I'll read it. So what we have here is a graph, supposed graph, an area of proof systems, in which we have two axes. One is axis from proof complexity strength, so it goes from weak to medium strength system. So weak is resolution. System. So weak is resolution, all this proof system that we know how to lower bound, but actually we understand quite good because we have interpolation and a lot of result on them. Medium strength is those system that we call like constant depths, Fregep. It is not strong because we know how to prove lower bounds, but I think it is slightly less understood. There's no interpolation and so forth. So this is, I call, weak and medium strength, and we have the following resolution. Resolution and yeah, and now we go in this axis from X to expressivity. So we have these systems for CMF or Boolean formulas, right? So we have system for propositional logic, but if we go to the left here, we have algebraic proofs. So algebraic proofs, they prove also CNF by simple encoding, but they can also prove more things like a linear equation or system of linear non-unsolvable linear equations. Unsolvable linear equations and so forth. So, this is the system works for a slightly bigger language, and here it works even for a bigger language. We take the Boolean formulas and code it as polynomial, and also we have any polynomial equation here, and we add inequality. So, this is the most expressive. This is, so let's read it: system for propositional logic. Positional logic, this algebraic proof system for sets of polynomial equations over a field with 0, 1 variables. So all are with 01 variables. And semi-algebraic proof systems for sets of polynomial equations and inequalities over a field with 0, 1 variables. Right, so uh and what do we sh see here? So here the the strong systems, and this is how uh they are usually called, so Frege, extended Frege, we don't know how to know about them. We don't know how to know about them. And here, dynamic positive Stellensat. I don't remember precisely the definition, but it's a line-by-line positive Stellensat proof, which we don't know how to lower bound. And here I put Grigory Evan here, PC over formulas, which is a Cook record proof system over algebraic formulas, and the non-commutative IPS, which is basically equivalent to Freddy. Equivalent to Frege. So these two are more or less equivalent to Frege, but they are more expressive. They can prove propositional tautologies, but also equations over the field. So these are the strong parts. And our work is going to concentrate on this part, the red one. So here is the IPS. This is the Grocero Pitasi proof system that is very strong. And it's very strong because it is also, I call it very strong because it's not a Kuro. Call it very strong because it's not a cook record, it is probabilistically verifiable. This is IPS. And here we define the strongest possible that we know of concrete proof system, CPCOM proof system. So it simulates everything here. And we don't know anything that can outperform it, I think, concretely. And this is also more expressive, it is for similar. This is also more expressive. It is for semi-algebraic inequalities, sets of equations and inequalities. And what we show is the following. So this CPS simulates, of course, all the semi-algebraic proofs below it. It also simulates IPS. It is not extremely trivial to show it simulates IPS. It is with this trick. And we show the following. It actually is stronger based on Chaben's. Is stronger based on Chaben-Smale hypothesis. So CPS is stronger than IPS based on this complexity assumption. Now, so that's when I put S here, it means stronger, strictly stronger. Now, actually, because of the linear size refutation of the binary value principle in SOS and beyond, then actually we have all these separations in some sense. So this cannot seem, IPS cannot. IPS cannot simulate SOS over this inequalities based on this Sharp and Smith, and it goes after also this separation. So this is our result. Now, yeah, the second one, of course, in order to get this separation or conditional one, we need to prove a lower bound, a conditional lower bound. Conditional bound against strong group system, and remember this was one of the motivations. So the binary value principle. So, the binary value principle, this linear equation, is hard for IPS under complexity hardness assumption. I talked about this. And the hardness assumption is the following. So it's Chaban's main hypothesis, which is related to the tau function. And we have something called tau function. So Hannah's assumption is the following. I cannot compute factorials with constant free. With constant-free algebraic circuits. So I cannot compute this. This is m factorial. Km is any set of non-negative, of integers, any set of integers. For any sequence like this, Schaben-Smale presume or assume or hypothesize that there is no polylogarithmic in M operations that can. Operations that can build this constant. So there is no operation that works over with zero and one and build it like this. So there's no uh polylogarithmic number of operations starting with coefficients zero, one and minus one that can build the coefficient of these numbers and factorials. M factorials. So it is not known if this is true or not, but there are some consequences for if it is not true, so if it is true, then there are consequences like NP is different than P in the Sharp's main model. Did you say w what is the complexity or necessity in the first case, the with the binary first case? Oh, what is it? Super polynomial. It's super polynomial. Yeah, that is a good question. I think it is super polynomial. I don't think it is exponential. What is this? The assumption? The assumption is this one. If I cannot do this, I'm not going to have a polynomial size circuit. I think it's super polynomial. I don't think it's exponential. Yeah, so if you replace the file against any dialogue, presumably get explained. I cannot hear. If you replace the file log n in something else, presumably you get explained. Yeah, maybe it will. Yes. Right, so the PVP is very easy. It has linear size refutation. It has linear size refutation in the cone-proof system, or actually any semi-algebra. So, even sum of squares, I will try to show you this. So, is that does the hardness of PVP imply anything in algebraic complexity? Any hardness result in algebraic complexity? Sir? No, no, no. No, no. So that's why I flipped the arrow. Because it doesn't have implication, the error score. But maybe there is. I don't think we thought about this. Because we'll see an absolute implies honestly. Oh, VP is only going to. Oh, VP is a big one. Oh, yes, yes. So I I tried to prove this. I remember now. We tried to prove this, but I remember we talked about this, and the answer is we don't know. Correct. That is a good question. Now, our results, second one is conditional load bounds against strong proof systems. So we talked about this. This would be the IPS. Now, what is the IPS? I'll show you. It's a big circuit that is algebraic. That is an algebraic, that actually is a Lushter, is a circular representation of the Luch telescope. Now, one thing that is nice here is that a lower bound extends for Spilker, myself, and Windelson, the approach for lower bounds. So the approach there took subset sound instances, something like this, equal n plus 1. n plus 1. So this is an instance of subset sum. These are Boolean variables and this is unsatisfiable. We need to take some variance of these and we lower bound with IPS this refutation of these subset cells. And what we do is something that is very resemble this approach, but we get it not for subsystems like I like this. Subsystems like this work which got unconditional all bounds, but for subsystem quite not weak but not very strong subsystem of IPS. We get it for full IPS, but of course conditional. We cannot go beyond conditional unless we prove VP is unequal to VNP. So we can obviously hope for better. So that's what we show. And another thing that is very interesting, that's Another thing that is very interesting, that's the third result, which is all related to each other, is that actually the binary value principle, this linear form, is not only necessary in order to simulate semi-algebraic proofs, it's also sufficient. So every proof system, and that's what we show here, so if I take IPS plus this linear form, I can simulate all semi-algebraic proofs. Proofs. So it's also sufficient, this one. Based on some conditions over rationals and some conditions on the bit length of numbers, but these are very mild conditions. What is this strong enough to do a question? Correct. So what the correct, well, there's no question which is correct, but a good question. IPS plus PVP is equal to CPS, and Rahul asks, what is strong enough, strong enough? What is strong enough? Strong enough is any proof system that can do bit arithmetic. There is a subtlety there. You sometimes can do bit arithmetic, but it doesn't mean something that I will tell you. It doesn't mean, even if you can do bit arithmetic, you cannot go to the algebraic side of things and you cannot actually refute BVP. So it's quite interesting. So anything that can do bit arithmetic, and I think this is a result. And I think this is a result of Impagliazzo, Moli and Pitassi. Independent of R, they also thought about bit arithmetic in algebraic proof systems and they did it for constant depth circuits, a proof system operating with constant depth algebraic circuits. And there they show that it's possible to do BW. But there, but it is impossible to go, it is still impossible to prove the BVP. It is still impossible to prove the BVP. Right, so that is the essence here. The BVP plus algebraic system is equivalent to semi-algebraic proofs. Right, and this is the thing that answers you what did I mean by this? So here is an example of a thing that cannot be done in algebraic reasoning. You cannot do in algebraic reasoning the following. x, this sum is equal to 0 and these are Booleans. Equal to zero, and these are Booleans, you still cannot prove that the ith bit of this number is equal to zero. So this bit R is a big circuit that we do, we develop in our paper. We show carry safe header and all this, and the IPS can do this, can actually define this bit I, but bit i but from this you cannot go to you cannot prove this. So you can define the bits and you can do the arithmetic but you cannot really prove things about their values. It's quite subtle and it's written in the paper. Some observation about this. Now this is the proof ID of IPS plus the BVP, the binary value principle equals the scomp system. The proof ID is Is this binary value principle allows you to go from a polynomial equation to saying things about the properties of the values of the bits? And then what we use is a sort of a big reflection principle that we take the CPS refutation and we evaluate it based on the binary bits of the vector. bits of the vector, the binary vectors that represent the bits of the computation of this big polynomial, big set. And we get the refutation. So that is our these are our results. And what is the moral of the story? So one thing is one can do interesting things with a relatively large coefficients. R coefficients. So we get this conditional lower bounds because we use large coefficients. So we use this in a work with Fedora Part for Res-Lim lower bounds, also large coefficients. The second one, this is slightly more subtle, I don't know if it's possible to explain it precisely, but algebraic proofs can do efficiently bit arithmetic, as I just said, in our work and in Pagliazza and all. They can do this, but But the absolute not they can do this, but they cannot go from the hardness is to going from the equa equations to saying something properties of the values of these bits. Yeah, so I actually said this and so let's skip this. So now any question? Well, I didn't give any details, so it's not really no much question, and the only detail that I gave. The the only detail that I gave raised a lot of questions. Correct questions. Sorry? So when you say large coefficient, in control slides, large means not polynomial in value, but sorry, yes, you're right. The value is exponential. Of course, the bit complexity is polynomial. Everything will be polynomial, but the value is exponential. So it's kind of a weird mesh between a Boolean compared. The Boolean complexity and algebraic complexity, it's hard for these proof systems to talk about bits. Yeah, so the technical part is this. Let's see what I can do. So algebraic circuits, so let's see, what is an algebraic circuit? It's a circuit like this that computes formal polynomials, a vector of coefficients. So I start with these leaves and these coefficients. With these leaves and these coefficients, and I add them and I multiply them, and this is the output. And the output of this circuit is the following formal polynomial. Right? It's a vector of polynomials. And I fix, usually I fix a field. Right. So these are algebraic circuits. And what is Schabsman hypothesis? So I already say this actually in detail. So I have a constant free circuit. So I have a constant free circuit which starts with 0, 1 and minus 1 as the only constant available. This is the constant free model. And for integer m, I define the tau of m as the circuit complexity of the, which computes the m. So it's the smallest constant free circuit that computes m. Actually, it also generalizes to universal Generalizes to univariate polynomial, but for us it's a coefficient, it's an integer. So for integer, this is the smallest constant free circuit like this that can compute the integer. So that's the size of the smallest? Yeah, is the size of the smallest. Sorry. Sorry. No. Yes. The smallest is the size of the smallest. It's implicit in the English language. So this is Tau, and the shape. So, this is tau, and the Schultzmith said the following. We show this: no constant free circuit of size at most log M, poly log F computes these factorials because these are too big for any constant integer, for any sequence of integers. This is the assumption, and as I said, it implies NP versus P in the Sharpsmail Blue model, BSS model, and it also. And it also implied by a result of a Burgess actually VP versus VNP over constant free circuit, I think. Yes. Constant integers Kn. So they are. Yeah, sorry, this is not very good maybe phrasing, so maybe not constant integer. Integer, any integer. Forget about the constant integer. Non-zero, probably. Non-zero. Yes. Yes? For any non-zero integers Km, you cannot. That is, we cannot compute numbers that are divisible by m for zero of this. Well, zero is, of course, two. No, not non-zero. Sorry. Yes, so this is the very interesting hypothesis. Now, let's remind us what is or understand what is ideal proof system, IPS. So this is This is basically new standards written as a big circuit. And a refutation there is quite a subtle definition for those who see it at first. So the refutation, you want to refute these polynomial equations because it's algebraic system, Fi X in the field in the ring of polynomials. And for us, it will be a constant free algebraic circuit C X Y Z such that the following. X, Y, Z such that the following two things occur. If we plug in zeros, so these we call the placeholder variables, because they are variables for which we plug in the axioms. So if we put instead of the axiom zero, we compute zero, because this circuit computes a polynomial in the ideal of the axioms, like polynomial calculus and so forth, like Nursten does. Like Nursten does. It's a product of the axioms. And it is a refutation because if we plug in the axioms plus these Boolean axioms, then we get one. So it's really like Lucik. This equality is in the middle of the comma. Sorry, this is a table. So it's a comma. So here it should be a comma. And we plug in the axioms, we get one. The axioms we get one, and this is equality as a formal polynomial. The size of this IPS is the size of the circuit C. So this is constant free circuit, so you just count the number of nodes. And this is our result: conditional or bound on IPS. Assuming Schapsmal hypothesis, this is the binary value principle, does not have smaller. Does not have small refutation, polyencized refutation, constant free IPS refutation over rationals. Right? And let's see the proof. How do we prove this? It's not extremely hard. It is reminiscent of the Forbes and all approach, but it's slightly different. So what we do is the following. First, we recall from Forbes and all that IPS is the general one is the same as Neusterzats of the circuit. The same as Luftensatz of a circuit. So I'm going to write the contradiction like this. And this is like Luft-Senzatz, for those who remember. This is my axiom, and I multiply it by some polynomial plus some polynomials times the Boolean axioms. And this all big sum equals one. So this is the refutation of Q of the binary value principle. Binary value principle, and this is the IPS refutation, because I can write it as follows. With G of polynomial algebraic circuit by way of contradiction, we assume it is small. What we can do now is the following. Step two is show that it is enough to prove this low bound over Z. How do we do this? Well, I don't show you the detail, but it's just structural induction by multiplying enough. Reduction by multiplying enough times to get the denominators out. So if you have over q, we're now going over z by multiplying enough times. The only thing that we need to care for here is that, of course, the size of all this is small, it's still polynomial when we multiply enough time to cancel denominators, but also that this m, sorry, that this one, because we multiply enough, this one become m. Become m maybe bigger, but we need to preserve the fact that the tau of this m is polynomial in n. So the algebraic circuit computing this m is small, and this is done routinely. So this is not hard. So we have this over the integers with this of tau complexity, of circuit complexity, of constant free circuit complexity polynomial in n. And this is g. Now, what we are going to do now is What we are going to do now is the third step. I'm going to consider refutation over z of this. This is the same. And I'm going to do a restriction. Now, the restriction is not random, it's basic. For every number b in 0 to 2 to the n minus 1, with, so this is b, with bit vector b i to b n, I'm going to restrict this proof, which is of Boulevard size, and get the following. So I get G restricted. And get the following. So I get g restricted to this bit vector of p. Of course, these are the bits corresponding to x1 to xn. And I get b1 plus this. So here I instantiate the binary value principle. And I restrict m to b also. Now m is a constant, so m is the same. So m stays the same. g is some polynomial with integers, and I replaced in the inlaid. And I replaced in the in the 0, 1, so this is also some integer. So everything here is an integer, right, and this depends on B, on the number. Now what happens here? I still get this, and this is quantified for all B's. Now, what is the corollary here? It's the following. Because I can do it for all B's, D's change, and this change, but this stays the same. This is always M. So because I can do it for all B's, So, because I can do it for all B's, and this M stays the same, it means that M is an, and this is an integer. So, M is an integer of small size, circuit size, which is divisible by every number between 1 and 2 to the n here, because I added 1, so it become 1 to the 8 here. So that doesn't mean that it's m factorial, because you might have different power, like it's the L C M of 1 through M. M of 1 through n, 1 through 2 to the n, at least, not necessarily 2 to the n factorial. I didn't say anything about factorials in this proof. Okay. Yeah, no, no, I just, yeah. Okay. Right. So that's what we have. We have m is an integer of small size which is divisible oh, you're right. That's the next step. Which is divisible by every number in this. Correct. This this is not the end of the proof. This is not the end of the proof, but it's quite close. So it's divisible, it is not factorial, what we do is step four, the lemma, if m is an integer of tau m and is divisible by every number, then Schabz-May hypothesis is false. Now how do we do this? So as hinted by Paul, we cannot take the m. We have to do repeated squaring n times, which gets us to m to the power of 2 to the 2. gets us to m to the power of 2 to the n and then we get the result. Now what we do is we show that there exists a polyn size constant free circuit that computes 2 to the n factorial and then so this is 2 to the n factorial and thus the tau of m factorial here m is 2 to the n is logarithmic because this is polynomial in n. Polynomial, right? Yeah. Polynomial. Uh polynomial, sorry. So logarithm yeah, polynomial. Yes, probably. For M, a power of 2. So I'm not going to do the rest of the other case. It's almost similar. This will only show us Chaben-Smail as false for powers of 2. We need to have to say some word about everything, but this is easy. So we're going to do this. We show that there exists a small circuit, a constant-free circuit that computes 2 to the n factorial in Pole and size. And what we do is, as I said, by repeated squaring, I get m to the n. I get m to the 2 to the n, and this is still polynomial because it's just a chain of self-square repeated squaring. So I get this, it's a big number. And now I'm just noting the following. P R is a powered prime factored of 2 to the n factorial, then p is at most 2 to the n. So it's a factor of m right? It's a factor of m because. Right, it's a factor of n because uh um and the second uh uh fact is that r, the power of this, is at most 2 to dl. So this you can show by a simple claim. So p r is a power prime factor of this prime factorization of this, and it is at most 2 to the n, and it's a factor of m because of how we construct. Of m because of how we constructed m because every it is divisible by every number until up to 2 to the n, and also its power is 2 to the n. So now we finish because every powered factor P R of 2 to the n appears in here. So we finished the ref the proof. So that's a lower bound based on shadow state. Down based on Chabensmith. So you can read it, I hope it is written clearly if you want all the details. So that is one very interesting, hopefully IPS condition on lower bounds. Now we have something in the tau conjecture. I'm not going to cover this. We can establish IPS lower bounds over this field over rational functions. Now let's go quickly over the cone-proof system, how it is defined. How it is defined. So the comprehensive system, and this is the semi-I already showed you why semi-why IPS plus binary value principle using some reflection principle simulates semi-algebraic proofs. I'm not going to show you the detail how we define it precisely. So we just take, like in IPS, a big circuit, but we call it conic circuit. So conic circuit is almost the same as circuits, only that if you have something, y-conic means Yconic means that if you have anything that is x1, supposedly it can be, it's y conic, so every variable that is not in the y variables or every minus or every negative coefficient, you need to square it sometime. So x1 might be negative here, so I need to square it. So I will get a positive value here, and minus three also you need to square it above. So, you need to square it above. So, this is a conic circuit, why conic circuit? It means that y variables are assumed to be non-negative, and the x-variables or non-negative constant must be squared sometime. So, under this assumption, every value, the value of this circuit is always non-negative, right? Because y is non-negative and the x and minus coefficients are squared. So that's good. So, a y-conic circuit is just. Circuit is just a circuit that preserves non-negativity when the y's are non-negativity. Now, this is the control system. So, you see, it's very similar to the IPS, but it's supposedly under this conjecture hypothesis, it is stronger than IPS. So, this is the CPS. So, C, X, and Y, this is the placeholder. It's a y conic circuit. Here, it just says that it's y conic instead of equal zero. Y conic instead of equals zero, and when we plug in the axioms, it gets minus one, not one like not here. So that's it. Now, CPS refutation, as I said, I want to refute both equalities and inequalities. And what I do is the following trick that we started with. We take the equalities and add The equalities and add inequalities, add both the positive part and the negative uh ver uh version of them. And for inequalities, we just take the inequalities and we take the Boolean axiom. So the Boolean axiom also has negative and positive versions, and we have, as we said here, we have xj and mm one minus xj. It's also uh Boolean axioms. So when we plug in these axioms, we get minus one. These axioms we get minus one. Now, the size of the IPS proof is the size of the circuit C, and just let me just finish almost. So theorem says the following. Cohn-proof system simulates all known, at least to us, semi-algebraic proof system. SOS for this challenge. Let's just see the upper bound if you want. This is kind of hard to read, but this is. Read, but this is the upper bound. This is a very simple upper bound. This is the cone proof system refutation of the binary value principle. You just plug in the placeholder here and yn plus 1 corresponding to this axiom, which is precisely the minus of the binary value of the value principle, and it sums up to minus 1. So it's a linear refutation of binary value principle. The Kohn-proof system. The co-proof system quite easily simulates SOS, a positive stereozet, and so forth. I think that's it. And as I already described this, CPS is equal to IPS plus the binary value principle by this reflection principle. And I have here a crew, but we don't have time. And that's it. Questions? So low values only uh of the rationals? Over Z and the rational, yes. Oh No, it's for constant free circuits. So how do you write the real with constant free IPS proofs, refutations? So this is like in group reputation, they define it or in algebraic, for algebraic proofs, you define it as a constant free, so you only have minus one and one. Right, so if I have, maybe if I have big, probably it will not work. If I have big. Will not work if I have big for three bigger weights. If you compare so many algebraic proof systems with algebraic proof systems of finite fields, so oh, does it work for algebraic proof systems of a finite field? I don't know. Is it? I think. I don't think we've done it. Could you do a translation of the finite fields or something like that and do the simulation that way? Oh, sorry. Sorry? Actually, no. I don't know. If it works for finite fields. Well, I don't know the answer to the answer to this. If you said that you can use add the binary principle to an algebraic system, but what happens if you add it to a very weak algebraic system like polynomial calculus? I don't think it will work because maybe it will. But polynomial calculus, so I said if it is strong enough to do bit arithmetic, it is possible. So if you add it, and this is why I cited Impagliatso, Mullien Pitansky, if you add it to a polynomial calculus over To a polynomial calculus of a constant depth algebraic circuits, it is okay. They will simulate CPS. They will not simulate CPS, they will simulate the corresponding class of CPS. But standard PC, I don't know. It's not even strong enough to do the basic, no. No, the of course the degree will be high. More questions? IPLs. I think the Yeah. The only thing I kind of wanted to mention, which was already mentioned in the webpage, is the pixel design. Yeah, and maybe it was also like this to do the survey, but then I was already thinking the defining way of surveying this exorification would be like a first example. The best example is the easiest to prove. Just like a political example in front of you, I'm expecting to be complexity and then. I was planning to most do but not But no, but it's no ball. But just reports. Mostly about the reaction. How do you use it? Yeah, something particular. There's everything, I mean with this button part of this. Yeah, which were wrong about just simulation and talking about the number of alternation doesn't matter. We were going to since that year we have this formula. So here we have the same. I suspect that there are another problem there. So this is the part where I was talking about defining about one of the tasks that you can face that or you could Okay, by the way, so how long was this original talk in India? Yeah. Yeah, I mean, of course he has his own Microsoft. So they make So this is all I would do, but I mean I don't think that's the same thing. No, wait, oh, you want to take a look at the microphone. 