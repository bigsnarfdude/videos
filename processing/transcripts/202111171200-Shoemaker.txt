Still, what you're seeing on the slide right now is a single time snapshot from a numerical relativity simulation. Although the black stars are artistic license, but the contours you're looking at in this blue-purple are the emission of gravitational waves as a solution of Einstein's equations from two black holes merging. And if you look very deep. And if you look very deep into the well in the center where it's a bit turquoise color, you'll see a very tiny black dot. And that's actually the black holes having merged and now settling down to the final Kerr black hole, just to give you some fun scale for this image. And this was a GW190521, which was one of the exciting detections to come out recently, as we already talked about about a year ago, for the intermediate mass buckhole. So that was just for beauty, but I'll talk about this event again. But I'll talk about this event again later. So, my point here today, and there is a movie, it's going to be a little bit hard for people to see in the audience, but those online probably can see it better. This is the same GW 190521 where you saw this still, but now playing out for the full numeric relativity simulation. And really, here, I'm looking at the future prospects of ground and space gravitational wave detectors and seeing what opportunities there are for us. Like, yes, obviously. For us, like, yes, obviously, what we're after is the big science picture, and then I'm going to be a little bit narrow-minded and say, What does this do? How does this place new demands on the theory that predicts these waveforms, which is, from my perspective, numeric relativity. And the two big takeaways, if you wanted to go to sleep right now or go read your email, is that we really need to broaden the range of parameters that we cover in numerical activity such that the modelers and all the other people engaged in the endeavor have. People engaged in the depth endeavor have those things on hand, and we have to prepare for very loud signals. So, that means high signal-to-noise ratio because that puts a different demand on the prediction of the waveforms. In other words, it adds accuracy and length of signals. So all those things are really tough to do well in numerical equity. So, what are the science drivers? This is just to remind maybe me what the science is at the end of the day. At the end of the day, um, can we prove Einstein wrong? Sometimes it's unlikely we'll prove him right because that's challenging. Do you, you know, I've actually, one of the things I've enjoyed watching over the last, you know, five, six years, you're not getting the audio. I'm probably going too far away from the mic. I apologize. I like to pace. It's very hard to stand still and get with that. I enjoy watching all these black holes be detected with larger masses than the people. With larger masses than the people who sort of predict stellar evolution have expected. And I'm hopeful that this will keep happening as the detectors increase in their sensitivity and also change in their frequency bands. So we'll see more really massive intermediate mass buckholes and obviously supermassive. I'm not going to talk about what is the equation of the state of neutron stars, but clearly we're all interested in that and many other aspects of matter. We're also, I think, very interested in understanding the formation history of these. Interested in understanding the formation history of these black holes and galaxies and how everything has come to be the way it is today, probes of the early universe. We've heard a couple of really interesting talks about dark matter. And so it's just a wealth of information we're all looking for. And my perspective right now is what does this make, what kind of demands does this put on the theory so that we can. I'm easily distracted so that we can make sure we're ready to gather the wealth of information that will be available to us in the coming decade or so. I had to put up this picture mostly because I think I have a really pretty image of illustration of COGRA. So I wanted to add that to our pictures today and the last few days of the current gravitational wave landscape. We're fortunate to have soon four detectors, not including GEO, taking gravitational wave data. So the first three images. Data. So the first three images, Livingston, Hamford, and Virgo are pictures. Calgar is an illustration because Calgar is underground. So you have to imagine a little bit better. Let's also think, so we have that in hand now. What are we looking towards for the future landscape of gravitational detectors? Right, we've got advanced LIGO plus, A plus, which is an incremental upgrade to LIGO. Then we are seeing a lot of excitement about the Einstein telescope in Europe. The Einstein Telescope in Europe, Cosmic Explorer in the United States. These are proposed future gravitational wave detectors on the ground that really challenge things. The Einstein Telescope and Cosmic Explorer are very, really linking the arms of the detector, increased sensitivity. And of course, we have LISA, the European Space Agency-led space mission, where NASA is a junior partner, which would do the amazing experiment of having 2.5 million kilometer arms. Having 2.5 million kilometer arms under three satellites, which have a hanging free mass in them, orbiting the sun rather than the earth. So, the images you see before you are artist illustrations of all three of those last missions up on the slide. So, I'm looking at those two and I'm thinking, what are they demanding of us, and what can we prepare for? This one's for Adam. So, as I talk about So, as I talk about some of the things that are available, I tend to think in terms of a single detector at a time. So, usually I'm asking, what do we need to do to make sure LIGO has got everything it needs? What about Cosmetic Explorer? What about LISA? But the truth is, we can also do multi-band gravitational wave astronomy, and we shouldn't lose sight of that. So, this image before you is from a paper Paranjani wrote a couple years ago, where we studied how you can look at binaries, and we weren't the first people. Look at binaries, and we weren't the first people to look at multiband gravitational detection. This one was just pointing out the fact that intermediate mass plot holes binaries are ideally suited to look across the ground and space-based band. So you see here in three different colors, in blue, a comparable mass IMDH of 3000 plus 1000 in spiraling for a long time. And Lisa merging sort of in between. merging sort of in between the two all the detectors and ringing down in the potential enzyme telescope then you see in red a much more unequal mass black hole with 1200 plus 80 spending some time in lisa and then again you can see a lot of higher harmonics come in because of the unequalness of the binary which we could hope to detect and we heard a very interesting talk by Lorena about how to By Lorena about how to get a good hand on that ring down, which is looking at the very end state of the very bumpy red signal. And you can see here in this plot, we're plotting a lot of higher modes. That's why it looks like there's so much information available. There's so much dynamics happening in that signal. And then the green is a 1100, a 100 plus 200. So a much smaller signal, highly, ideally suited for something like. Something like advanced LIGO, and you see that it could, as now I'm forgetting his name, Salvo mentioned in a paper a few years ago, be a nice system where you could actually start to see it in Lisa before LIGO detects it. So how do we detect these things? Other people talked about this much better than I will, but just to be complete, I wanted to remind people that I'm thinking of these things from match filtering. Of these things from match filtering, and I often think of it, it really shows you my age because I don't know how many people know Shazam anymore. That app where you could figure out what song was playing off the radio, if people remember what radios are. So it always reminds me of match filtering because it's comparing to the full library of songs available in their database. You forgot what song you're listening to, which is similar to what people do when they detect gravitational waves. Gravitational waves. So, this is a cartoon of match filtering where you have a template and data in blue. And you can see there where we hit the best correlation in the signal to figure out what the template is best suited to the data is. So, I'm thinking about how we produce these templates rather than how we actually measure them in the data, but I thought that was a fun reminder of what MASH filtering does. Of what match filtering does. So, if we look at what those templates are under the hood, I think of this as just the theoretical landscape of waveforms. So, before people model waveforms, they're using this kind of information to create waveform models, which then become templates and these detectors. So, we can break the theoretical landscape, and this is true whether you're talking about binary black holes or neutron star, neutron star, neutron star black hole, any column. Nature star black hole on any compact binary. So, when the black holes, or I'll continue to call them black holes, I can't call myself when they're pretty far apart and their speeds are not too, too relativistic, we use post-Newtonian theory. When one of the black holes is significantly smaller than the other, we would use self-force, often called perturbation theory. And basically, it means that you can ignore the gravitational interaction of that second tiny black hole and treat it as a. Second tiny black hole and treat it as a perturbation on the space-time of a Kerr or Schwartzhield bigger black hole. That is particularly interesting when we start talking about LISA sources, because Emory's intermediate mass ratio in spirals are governed by this type of theory. And then we have numeric relativity, which goes the full general relativity solution to Einstein's equation where you can't ignore anything. This is basically the point. So, this image in the bottom is a plot of the compactness, M over R, versus the mass ratio, M2 over M1, where M1 is the bigger black hole. In this case, that will change as I talk sometimes. And what you're looking at is that numeric relativity's sort of sphere of influence, what we can do right now, is in blue, self-force in red, Primetonian in green. And this is for a particular case. And this is for a particular case. I think this was the equal mass non-spinning scenario, where the region is white and right is what we're concerned about, that we don't have a theory that can quite encompass that area and produce a prediction of what Einstein would say is correct for the coalescence of a compact binary. So, typically, we're worried about mass ratios. I'll call it getting too high. In this case, it would be too low. Too high, in this case would be too low, but when we're treated to separate between the two masses, we don't have a good handle on the situation. So that's where you're seeing a lot of new work happen in numeric relativity, but also in self-force, people try to meet in the middle. So all three communities try to cover that part. The gap depends on the parameters of the system. So if we go towards eccentricity, the Post-Tonium maybe isn't as good more than numerical relativity. You go to high spins. So the gap does depend on what the parameters are that we're talking about. The parameters are that we're talking about. So, should you trust numerical relativity? I think the answer has been very much yes, the last six years of gravitational wave detection. And as we move forward, we will continue to make numerical relativity hopefully more trustworthy in its solutions. So the top part of that is just a nod to the famous breakthrough work by Pretorius and then by the group Star IT and NASA for the first merger of black holes. First merger of black holes. So, right, so numerical activity just basically solves the Einstein's equations to the best of our abilities. And we have to remember it's computationally done. So, if Einstein is correct, so if general relativity is the real theory and there's no matter here in principle, we don't have any missing physics for the binary buffalo, but we are solving it computationally. So, we do have errors coming in numerically. So, this does take weeks. So it does take weeks to run one of these simulations, longer if you want more cycles. So this famous one here came out of the SS group and I actually talked to them at the time and it was a mistake. Somehow they forgot to shut the simulation off. So they have an incredible number of cycles in this one waveform, but that's not typical. You find most of the cycles are about 20 to 30 gravitational wave cycles in all the groups. And it takes a long time. The problem is we don't scale if you're Is we don't scale well if you're a computer person, right? So, none of our um codes that handle the mesh refinement are very efficient right now. There's a lot of work being done in this area. So, throwing processes at us at this moment with the current codes wouldn't be that helpful, but people are working hard to recreate new mass refinement and new ways to do parallelization so that we can get beyond this problem so that we can solve longer cycles more accurate, et cetera. So, why you should trust us is that there are more than one formulation, more than one code, more than one way of handling almost every aspect of solving Einstein's equations. And we all agree with each other and with, you know, the events that we've been seeing have been consistent with our results at current gravitational wave sensitivity. I keep saying that because I think we're noticing now that we can do better as we look at our gauge conditions, as we look at our average. At our gauge conditions, as we look at our accuracy, and many things. So, as the detectors get more sensitive, it may reveal inconsistencies between the way we solve these equations and choose our gauges, et cetera, that we're paying attention to so that we can get there before the detectors reveal these differences. And there are three catalogs available for the public, one by our group. That wave site is no longer correct because we just moved to UTS. Because we just moved to UT Austin, so we had to move our catalog. And then the SSX and the RIT catalog. So, one of the ways, so how does NR contribute to all this gravitational wave detection? One of the biggest ways is the models, right? So there are two most commonly referred to models used in the LIGO Virgo Not collaborations. One is Collaborations. One is on the left is based on the effect on body NR formulation, and the one on the right is called phenomenological, where they do things. They're all fitting to numeric relativity at some point, but they're using different inspiration for the model. But it's some combination of Potentonian theory and perturbation theory with NR. There's also direct comparison to the gravitational wave data. We do take numeric relative waveforms directly. forms directly. Most of that is done with a data called Rift, which was written by Richard O'Shaughnessy and Jacob Lang. And we do things like if you look at testing GR and you wonder how those tests happen, a lot of those tests happen by using the fact that you can look at the inspiral of the black holes, calculate their parameters, and then use numerical relativity fits to predict what the final parameters are. What the final parameters would be based on those initial parameters, and then go detect what you think the final black hole is using the data and look for consistency. And those fits have been mostly produced by Lusto et al. Rizolo et al. And of course, there's all the fun things of matter, which I continue to ignore. I'll let Miguel and Pablo deal with that. So, what are these famous demands that I keep? Are these famous demands that I keep talking about? Um, so here's a plot of kind of many of the detectors. There's no Cosmic Explorer and ISIN toolkit in this one, but this one includes PTA, Pulsar Time Uray, LISA, and the current ground-based detectors. And then the little insert in the top includes Einstein Telescope Composite Explorer. So, as I said before, if you look at this plot and you think about how all these gravitational wave detectors kind of Kind of span the frequency space, you see that we really will start not only getting more sensitive as the ground-based detectors get better, and as we build space-based detectors, you're also covering different frequency bands, and that puts a different demand on waveform production. And of course, the high signals to noise ratios that we can imagine having, certainly with Lisa, with the supermassive black hole binaries merging, but also. Binaries merging, but also with ETCE. And another question that I'm not really going to address, but which probably is of interest to some people in the audience, is the fact that when you right now, I mean, even though we have 90 events from the collection of all Ligo and Virgo's work, we're seeing them get more and more every time the detector comes on. When you start looking at something like Lisa, the expectation is. Something like Lisa, the expectation is you're not only going to have more events, you could have a supermassive black hole binary live for years in band with all the other gravitational wave signals also happening at the same time, potentially. So you have to be prepared to detect multiple signals at once. And that also puts a different emphasis on the quality of the waveforms we produce. So here's my summary of that. So, here's my summary of that. Right, I kind of already said this, but broader or different frequency bands adds new sources. So, right now we see the mergers of stellar mass, binary black holes, black neutron stars, and binary neutron stars. We will now see extreme mass ratio in spirals, galactic white dwarf binaries, supermassive black hole binaries, other sources. We can also see. We can also see a longer length of the signal in band as we get better at signal frequencies. And of course, I mean, I completely ignore observing the early universe, but I like to remind maybe myself of that every now and then because I think it's really interesting, but I had no real insight on that part of the space. As I mentioned before, we can expect higher signal-to-noise ratios, louder signals, which is kind of a game changer for precision tests of general relativity. For precision tests of general relativity, it's exciting if you want to test Einstein's theory. And at the same time, again, we have to get really good at numerical relativity to produce those waveforms so that you don't have any numerical errors left over that are sitting above the detector noise ruler. And all these things about increasing accuracy and the length is hard for us. You know, it puts a big demand on the numerical two. New microscope. So here's another list about a little more specific for you guys about where are we right now in the minor black hole world of numeric relativity. So if you want to say what can we do, and probably what we'd all agree that we could do more, you know, with sufficient accuracy for quite a while would be non-spinning equal mass or anything with a mass ratio less than 1 to 15 is. Mass ratio less than 1 to 15 is pretty well in hand. It depends on how accurate we really need to be. But there aren't many numerical relativity simulations hanging out above Q equals 15. There's one, one to the 128, but you know, it wasn't very accurate or long. So you're not going to get really long simulations with these high mass ratios because we just don't have computer codes that can handle it yet. We're also very good at doing moderate spins, processing our knots. Spins processing or not for mass ratio less than about q equals eight. Very good at line spins. But when you start doing processing spins with highly spinning black holes and mass ratio, we just don't have enough of those waveforms on the ground. And every time you increase the spin of the black hole, there's some issues with initial data. But also, it also needs more resolutions. When you have the highly spinning and a high mass ratio, you're making the problem. Mass ratio, you're making the problem harder. We're also a big push for doing eccentricity now. I'll talk about a little bit in a second why. Why had we before, because the expectation is eccentricity creates away very quickly. So by the time these binaries merge in band, our expectation was for a low eccentricity, but there's been a lot of work questioning that, especially as you look towards Lisa signals. So that's being a big push to create more eccentric numerical relativity waves. To create more eccentric numerical relativity waveforms, um, we'd like to we can do about tens of orbits, not hundreds, not thousands. So, depending on the accuracy of post-Newtonian, that's going to dictate how many orbits we need from numeric relativity because we would like to meet comfortably so that you can build these really long waveforms that combine post-tsonomy and numerical relativity. Um, so that's a big challenge. And the higher modes are always important because a lot of Are always important because a lot of the biases in the parameter space, so what's spinning, what's unequal mass, it's an eccentric signal, clear up a little bit and you have the higher harmonics, not just the dominant 2-2 mode in your waveform. So that's sort of where we're at in the world. We want faster, more efficient codes to achieve hundreds to thousands of cycles, whatever we need at high mass ratios. We need accuracy. Accuracy and preparation for loud signals, and also lots of harmonics accurately extracted from the codes. Actually, right now, we need a better way of setting those accuracy requirements. Believe it or not, we don't have a really super good handle on that. What I mean by that is we don't, I could tell you what accuracy in a very conservative way, which I'll mention in a minute, but I don't, you really want to understand what the accuracy means when you do parameter estimation or when you do global. Estimation, or when you do global fit. Otherwise, we can be too conservative in our demands for the waveforms. Of course, you know, we also begin to go beyond GR, so it's a tough thing. I'm not going to talk about it. And this talk, just to be complete, we heard a talk about how people are testing GR on the first day by Leila, and you saw a lot of use of phenomenological approach to figure out what parameters could we could introduce. figure out what parameters could we could introduce to see if we see a smoking gun for going beyond GR. Another approach is to actually solve alternate theories of gravity as a numeric relativity solution. Of course, that's hard. Probably the person I know best who does that is Hobby Wittak. So there's definitely work being done there. It's just that you can imagine pick a theory that's not ruled out yet, make a well-posed initial data problem, solve it, fix the waveforms, and do it again. Waveforms and do it again. I mean, it's just a challenging problem. Eccentricity, as I mentioned, and better gauge and extraction. And the reason for this is just to anticipate places where there'll be errors that will basically turn into waveform systematics if we're not careful. So, what are all these new challenges? This I stole from a, see, we hadn't heard a talk in person in so long. And when someone gave us a talk last week, Pavel and I got really. Use a talk last week. Paul and I got really excited, so we keep talking about it. So I hadn't heard a person give a talk and so long, apparently. But this is for this one thing that we keep hearing about GW190521. And the reason why we keep hearing about it, it was a very large solar mass system, the first intermediate mass left hole that was detected. And it was super short because the higher the mass, the higher the frequency. So you start hitting the detector's frequency beyond limitation. There's frequency band limitations. And any, almost anything would fit this signal. And so if you, I didn't write down all these papers. I ran out of time because I just threw this together this morning. But if you look through the literature, if you go to the archive and put GW190521, you'll find head-on collisions, which is what Juan did, eccentric collisions, which is what Florida and IT did. Like, you know, just like you could probably put, who knows, an alternate theory on there. There's a lot of things that's going to match a signal because it's super short. Because it's super short and it's frequency. So, the only way we're probably going to get out from under this is having enough waveforms that cover the potential GR space to be able to rule out what it isn't rather than guessing what it is, which it looks like everything. So, this is the challenge of short signals. So, anytime we're going to have, as we increase our frequencies, you know, this particular signal we would know this particular signal we would probably see more in spiral if we have if the detector you know as the detector gets better but we always will probably always see if black hole binaries scale uh the mass range well we'll always run into this type of signal as we continue to improve so here's my nod to this what this conference is all about which is the fact that um we're supposed to be doing machine learning or something Supposed to be doing machine learning or something. I don't do it. But my postdoc Deborah Ferguson has been working on one of my requests that I've had for years, which is that if you ask me right now, what are our next numerical relativity runs going to be, we have a tendency, I think, in every group in the world, just lay down a uniform grid in parameter space. So if I'm going to go do my new eccentric run, say, I'm probably going to go from eccentricity to zero to 0.4 and equals steps. 0.4 in equals steps and i'm probably going to just choose some mass ratio and spins and just form a grid that way well it it's uh computationally expensive to do these runs and it gets more expensive wherever you challenge sort of the edges of those parameter spaces and probably not every run is as useful as another so i would like to have an optimal way of picking where my next parameter run should be what parameters i should choose Run should be what premise I should choose for my next run, and there's a lot of different ways you could do this. Adam was mentioning that I could use Bayesian, but this approach is to use machine learning and the way, which is using a neural network. And the way it's done is by taking all the, not all of them, because you have to have training sets. I know all this stuff, but taking some subset of all of our simulations and those available in the world and asking ourselves, you know, training it so that it. Now, training it so that it uses the match between waveforms to say: if I put a new waveform down at this parameter space, what would be, machine learning tells you what that match would be. And if that matches 0.99, don't bother. If that matches 0.6, then you need it. So if it matches one between two waveforms, it means they're basically identical in that detector. If it's much, much less than one, less than 0.98, we might say we need a new waveform in that. Say we need a new waveform, and that's why so that's this idea. Um, it's working slowly basically because of all the it's sort of our side project to do, but I think it could be fun to have a better way of deciding where to choose our numeric relative runs in the future. So that's not published. This one is another challenge is I keep saying accuracy. Why do I keep saying that? Because it comes up a lot in the Lisa world. Up a lot in the Lisa world, but there's a lot of concern. It was even mentioned in the Astra Decadal in the online speech they were giving about it, that waveforms need to be accurate enough. So that was interesting to hear. And it's what we want, this indistinguishability. So we want the fact that I've created a numerical relativity solution for that waveform. I don't want my numerics to To actually be distinguishable in the noise. So, here, this little plot example is of a low-resolution template in black, I mean, a high and a low in blue. And if you subtracted those two, they have the same parameters, only difference is how many points we put in the grid. We don't want the light blue, which is the residual left over, to be so loud. Because that would mean we've left physics in the signal. In the signal, you can imagine it one hurting tests and general relativity, but two, leaving junk behind that will contaminate other signals when you do a global fit. So there's been some work on this. Well, there's been one other piece of work on 3G by Pure and Carl. And they saw that for just the third generation of ground-based detectors, and they did it for the waveform models, they needed to reduce their error by three orders of magnitude. We found for just numerical. We found for just numeric relative error, just resolution. That as we just created a measure on how your resolution needs change as you increase your signal-to-noise ratio, showing that we were okay for current LIGO and Virgo, but as the SNR increases, we need more, a lot more resolution. So, this is all a very conservative error that we're all doing. And as I mentioned before, we'd like to do it a little bit. And as I mentioned before, we'd like to do it a little more practically by actually watching how this would play out in a real, a real fake detector, you know, get do this with noise and seeing what the ramifications really are. So we're not asking too much of people without having good costs. So this is probably too detailed. I was toying with whether or not to keep it in or not, but I won't spend too much time on it. This is how we did it. This is how we did it. So, if you look at that little cartoon up on the left, that's kind of what a numerical relativity grid might look like. This is for finite differencing methods. This won't hold true to the same way in spectral methods. So, you know, we have these black holes. Everything in vacuum GR is discussed by M, the mass of the black hole. That's our scale. So, what we care about is how many points go across that black hole. That's the whole name of the game. And then, to result, to extract for everything. And then to result to extract gravitational waves, you reduce your resolution as you march out, but you have to make sure you have enough points to extract the gravitational waves well. And that's the tension in numerical relativity. It's not as easy to do mesh refine as it might be in a fluid code because we don't have, we have to maintain enough resolution to get that gravitational wave out. And that gravitational radiation needs to be as far away from the source as possible. possible. So we there's a criteria well known to use between to make two waveforms indistinguishable delta H with delta H and we just found a measure based on that indistinguishability requirement where we could directly put in that number of points across the grid delta with the signal to noise ratio rho. So here in this case it's ground-based detectors. It tells you how many points you have to put across the black hole. Put across the black hole, depending on the total mass of the system. Why? Because that depends on the frequency. And so this line of row equals 33 tells you that's a high SNR for current ground-based detectors and where we sit. So we can easily have enough points to the left of this line. As we go to the right of that line, you can see that we start meeting. You know, if we need over a few hundred points across the black pole, it gets very challenging. Across a public disparate challenge. And then these other parameters are details of the numerical method. The same thing happens with mass ratio. The higher the mass ratio, the more resolution we need to capture it. So you can see that if you have an equal mass black hole, it's not so challenging to resolve it, but as we get to To resolve it, but as we get to these higher mass ratios, more inclined, we quickly won't have enough resolution to do this well. The good news after all this is that there's an incredible amount of work happening in the community to produce the next generation code. So this is an unpublished table that I'm still creating. So every time I do this, I get Mac relative is mad at me because I haven't included their code yet, which is why I do it. So they send me an email. Yet, which is why I do it, so they send me an email with the code details. It's been very effective so far. So, this is the code, some of them aren't there yet, they're in progress, whether they're open source, whether they've created a way from catalog, and some other details. So let's take the example of SPAC Inspector. That's it SACS Collaboration is writing a new code that's going to be now open source, and they're working on a new mesh refinement. Likewise, Diane Sign Toolkit is doing the same. The Dionysine Toolkit is doing the same, working on a new mesh refinement to increase the efficiency of the codes. There's also codes like Dendro, which are taking a different approach to mesh refinement totally. So there's a lot of exciting things potentially happening over the next few years. And you'll also see that a lot of the new codes are going to be open source, which means the whole community is going to benefit. So, in summary, it's super. It's super exciting that the gravitational wave detectors are steadily improving, and that we are looking for. I actually ignore PTA. The pulsar timing is already operational since the pulsars already in space. We don't have to launch them. I tend to ignore PTA because the supermassive black holes that they're looking at are so far apart that you don't need numeric relativity or really, you don't need Post-Tonian is overkill for producing those waveforms, so I don't worry about it. Those waveforms, so I don't worry about it so much. But as these detectors improve, we're going to do a lot of great science, but it also increases the requirements in our waveforms. And this is not exactly sexy work, right, to do a better job with the atrocity waveform, but I think the science payout makes it worth it to do what is almost a service pact, getting all these things ready. And when we first, you know, back in 2008, when people could solve the first binder black hole problem, People could solve the first binary black hole problem. There was this huge feeling of numerical relativity dead, you've done it, you have the solution, let's move on. And it's been fascinating to kind of watch how not true that's become. So I think numerical relativity still has a pivotal role to play in the future. There's a lot of work happening in getting these codes to be able to do these high mass ratios, high spins, lots of gravitational cycles, tons of accuracy, really demands new codes. They're in progress, whether they'll be good enough. They're in progress, whether it'll be good enough, we don't know yet. We have to achieve both high accuracy and complete coverage parameter space, and then we can worry about beyond GR. So I just think it's a really exciting time for both numeric relativity and gravitational space. Thank you. So, do we have? I think we have a couple of questions online. Online, so can you go to meet this? I think so. Does anyone in the audience have a question online first or here? No question. This happens to me a lot. I must be born. Yeah. So you had a slide that would solve the problems and challenge. Yes. Can you rank challenges for me? In terms of what? Hardness or perhaps whatever you want. I mean, in terms of which. You want. I mean, in terms of which of those will go to the left first, or in terms of partners, or so. In my role as co-chair of the Waveform Working Group and LISA, I have learned from everybody else in the community that they want parameters before accuracy. Because if you have the parameter space, you can at least get the first sense of where you're sitting. Where you're sitting. And if it's not accurate enough, okay, it won't be the best science, but you can at least say, okay, we know what that parameters of that binary probably are. So if we had to prioritize, it would be parameters before accuracy in that sense. The problem with that is that that doesn't negate the need for better codes because the parameters people are often thinking of are higher mass ratios. And to do that effectively, we really struggle with doing mass ratios of like one to 100, one to 200 hours. To 200. So I don't think anyone would be able to make enough waveforms to cover that space well without some better codes. So that's what makes it sort of hard to rank all the different problems. Essentially, relatively easy. We're going to get that out. No problem. I mean, it's hard when the centrality gets too high because it just plunges. But anyway, you know, that's not so hard. But to get the high masses, high mass ratios, it's kind of It's kind of a tie with faster codes. But faster codes means just to be at faster machines, or they're more efficient, like better mesh refinement. Yeah, if it was just machines, it'd be okay. We need better mesh refinement. We can't take advantage of the best machines right now is the problem. Okay, I get very upset because we're sitting on Frontera, which is one of the good machines in Texas, and I can't use, they have special time where you can use the machine. Using the whole machine doesn't do anything for us because I could run 100 runs. Because I could run 100 runs, but I can't run one run with much more processors. We just don't, it doesn't, we don't scale well enough. So, but the changes would be fundamental or they would be refinements of what there is. So, for example, the puncture method and so on, but those are they don't change. What changes is it's a not a change in right now the formulation and even the gate. The formulation, even the gauges, all that will make improvements, but not this level I'm talking about. There's changes in actually the numerics, the nitty-gritty numerics. Exactly. Are you so right now, if you look at the way we do parallelization, we do it based on the way we distribute the spatial grid? So a processor gets this chunk of the grid, another processor gets the next chunk of the grid, and they have to communicate between themselves. Some people Teen themselves. Some people in spec are exploring with doing a different way to do a task-based parallelization instead to see if that's more efficient. Einstein Toolkit is keeping that kind of parallelization, but changing out the mesh refinement. So there's different approaches happening from different groups that I think is good. Other people are figuring out what we swap out. Spectral methods isn't that much better than finite differencing in this case. Is there, you know, another way? There's lots of other ways to be doing. There's lots of other ways to be doing the numerics, GPUs. Is that helpful? Is it not? So, all of this is being explored by different groups. GPUs are hard because we're so communication bound. So, you know, you have to then string GPUs together. So, we have to use GPUs smartly for some tasks, but maybe not in all tasks. But it's all, this is all pumpy. There's no fundamental physics. There's so many screens to look at, it gets confusing. So I stopping you. Should we go to lunch? Do we have another question? Questions? There's one. Oh, sorry. Do you want us? The little magic. For those of you online, we passed this little box around. Okay, thanks. So I was wondering then if numerical relativity has not Numerical relativity has not produced yet any kind of simulation of extreme mass relative in spirals, because I have seen images or videos of this supermassive black hole and a small black hole, but then these are those are done completely when we okay. Yeah, so there's there's no, I mean, so the highest mass ratio to date in numerical is one to one for quasi-circular orbits, okay. For quasi-circular orbits. Okay. I don't know if head-on I've done anything wild. I made that lower, but and that one, you know, it was a merger. It wasn't cycles. Like you're picturing. So when you look at extreme masturbation and spirals, you see these black holes go around forever. That's completely self-profit. They have their own set of issues to get ready for. But that's because if you're going to do one to a million, one to ten thousand, you want to use that, not the medical technology. And then we'll try to join each other in the middle one too. Then we'll try to join each other in the middle when we get to like one to five hundred. We'll try to meet each other a little bit. So, so what happens? The code of flow or sorry, the code. Oh, when you put a high rate to do it, it would just take you know 10 years or something. Accuracy, every step that you take in a numerical code, you're summing up the errors. So eventually it just will be slow and worthless. How many resident years do you want to spend? Years you want to spend. I think that one gala is saying it took two years to do the 128 and they didn't they didn't like produce good waveforms, right? That was just a brute force. This is the one that they forgot to do. No, that's different. That's cycles. It was an equal mass almost, but they did like 100 cycles or something like that. But no one could do that same thing of 100 cycles and Same thing of 100 cycles and a high mass ratio? Sure. Not because. Like, at what number of cycles with this numerical relativity places would you can you can actually do after how many cycles the error is used to be usually so we routinely do in uh finite differencing we can do 30 cycles no problem We can do 30 cycles, no problem. In spectrum methods, they can do more. So they do the inspiral super, super well. So they could do a ton of those, maybe like 50 cycles. Maybe not routinely. It depends on the mass ratio and the spin. But 100 more than that, we start putting on the parameters. Maybe we could do an equal mass-on spinning with more, but not one of the highly spinning, precessing, unequal. Tons of cycles would be hard. Sylvia also means the. Style days also means the post-Newtonian had to be good at that too. So that's why the gaps between all the theories, perturbation, post-toniumeric relativity, changes with parameter space, because where is every individual theory, how far have they pushed to full time? Does that make sense? Yeah. Yeah, I always wondered in that diagram, how do you draw those lines, right? So there's another, that Van De Mint paper is out, and they also have one where they actually do it in detail. One where they actually do it in detail with all the different choices of theory, so it's a really nice. If I show it, it's too complicated, okay, but it's really interesting. So it's van de mint and Pfeiffer. It's a nice one. So for the for Lisa, which one would you think is more important to be done quickly, eccentric binary or the processing binaries? And which one is harder from numerical relativity point of view? Eccentricity is easy, except we don't even have it. Is easy, except we don't even have a definition of eccentricity, right? Like, eccentricity is one of these funny things that every signal is eccentric in general relativity, right? We don't want close to it. So, that's the problem with it. So, if people want eccentricity, so the typical binary Steven Massive black hole binary for LISA has a centricity between 0 and 0.1. Mass ratios between 1 and 4. Let me just pick things. But any spin, Any spin, then it's the any spin that we should work at. We can do it, but we're not good at like 0.999999. Then the problem will be: can we do all that accurate enough? But if you talk to the astrophysicists, they always want. So if you look at a table of what the eccentricity should be, it's like the expected eccentricity is 0.01. Oh, but we could have 0.9. Are you ready? And it's like, so that's, it's really the outliers that people that work, we need to cover. Yeah. I call them dreams. Need to cover, yeah. I call them dream parameters. So, in my mind, get everything done. I thought the most appropriate should be: get all the stuff you expect them first, build your accuracy, do your dream parameters, but they came back and said, actually, we think you should fill in the parameters based first. I don't know. Who are those people? Leo or Barak. Aminas want the magic box now. Okay. So if there are no more questions. If there are no more questions, I don't see any in the chat or online, so we can finish for today, right? Marco? Yeah. And we will come back tomorrow. Tomorrow, yes, today is free time. Yeah, today is free time. So we will come back.