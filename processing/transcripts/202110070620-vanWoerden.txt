Good morning. This Wesel van Berden from Amsterdam, who will speak about perfect poetic forms and upper bound and challenge in enumeration. Yeah, thank you. And welcome, everybody. And thank you for the invitation here. So, indeed, I will be talking about perfect quadratic forms, and I will discuss an upper bound on the number of them and some challenges in enumerating them in dimension line. Enumerating them in dimension line. So, but first I start at the sphere packing problem. Most of you already know it probably. It's like given some identical balls, the question is how can we pack them such that their density is maximized in real space? And this problem has only been solved in dimensions 2, 3, 8, and 24. And these are the solutions in dimension 2 and 3. So one is the Tree. So one is the hexagonal backing, and the other you could see like as a triangular pyramid backing. So why has this problem not been solved, for example, in low dimension as four? Well, you could say that just the problem statement itself lacks a lot of structure. While on the other side, we see that the solutions do have a lot of structure. So a natural way to make this problem. A natural way to make this problem a bit simpler is to restrict it to so-called lattice speckings. And here we have the extra constraint that the centers of each of these balls must form a lattice. And this indeed makes the problem a lot easier and has been solved up to dimension eight and again 24. So suppose we look at all these lattices or like lattice bases, like a lettuce given by a basis. Like a lettuce given by a basis B1, B2, or maybe more in higher dimensions. And if we look at all these lattice bases up to some orthonormal transformation, so we ignore rotations and stuff like that. Those don't change the lattice packing. Then the solution space in which you're working can be represented by the cone of positive definite quadratic forms. And this is a cone because you can always scale these lattice backings up by a positive constant without. By a positive constant without changing the tense. And now, suppose we only consider those lattice packings which have swiggers of or balls of radius at least one. So if we do that, then we get the so-called Ryskov polyhedron inside of this solution space. And the nice thing is, if we have lower bounded the radius of these spheres, to optimize the density, we only need to minimize. Density: We only need to minimize the surrounding space, and actually, this surrounding space gives us a concave function, and so it becomes a concave minimization problem over this risk of polyhedron. And so, to find the optimal lattice backing, we have to look at the vertices of this risk of polyhedron. And well, this risk of polyhedron is infinite, like it has an infinite number of assets, infinite number of verticals. Infinite number of vertices, so that seems like a bit of a problem. But a lot of these lattice bases actually give the same letters. And if we look up to this similarity, then there's only a finite number of non-similar vertices. And well, one question that you could have is like, how many of these non-similar vertices do we have? So what does Voronoi's algorithm do? So, what does Fournoise algorithm do? Well, it solves the let's back problem in any fixed dimension. And in essence, it's very simple. You enumerate all these non-similar vertices, and then you pick the best one that corresponds to the best LED spec. And then you're done. So later I will explain how this algorithm actually works, but this is in essence how it solves the LED spec problem. Okay, so those were some pictures, but now let's get to the real. Some pictures, but now let's get to the real definitions. So, the space that we are working in is the space of real symmetric matrices. So, d is in this case the dimension of our lattice packing. But the dimension of this space is equal to n, which is given by half times d times d plus one, which is just a number of coefficients you can change on a symmetric matrix, a number of free equations. And on this space, we can also define some numerical. Also, define some geometry by the following inner product, which is just the regular trace inner product. But you can also see it as if you would just collapse these matrices into a big vector, then it's just the regular Euclidean inner product. And statistic matrix defines a quadratic form by saying that given some d-dimensional vector, it x-value x. Vector, it takes value X transpose Qx on this vector. And the beautiful thing about this inner product is that this becomes a geometric notion. Because the value that X takes at Q is just the same as Q inner product with the rank one matrix X transpose. And as a result, if you take a fixed vector X and you look, for example, Fixed vector x, and you look, for example, at all credit forms that take a value, say, 2, at this x, then these all lie on a single hyperplane side of this space. And now for a positive Dafin quadratic form, these are the ones that lie inside of this cone. We can define some extra notions, namely the airmedical minimum, which is just the minimum value it takes on all non-zero integer vectors, and the vectors at which it takes this value. The vectors at which it takes this value, we call them the minimum vectors of the quadratic form. Okay, so how does this relate to lattice packings? Well, given a lattice with some basis B, we can look at the Grom metrics, so the metrics of all parallelized inner products of this basis. And this gives us a positive democratic form. And now, if we look at this lattice packing, because it's At this lattice packing because it's repeating, we can only just look at locally at one of these parts. And actually, the size of these balls is proportional to this first minimum, which you could see as like the minimum distance between any two lattice points, also. And this foreign noise cell that we have is proportional to the determinant. And so the density. And so the density is somewhat proportional to this value, which you call the Hermite invariant of a credit form. And thus, the lattice packing problem is just equivalent to solving, to determining Hermite's constant, which is just a supreme over all these ratios. And now let's get back to this risk of polyhera. So for any lambda, we Any lambda, we only consider those positive democratic forms that have arithmetical minimum at least lambda. So these are only the lead speckings that have spheres of a certain radius. And note that another way to look at this is as an infinite intersection, where for each non-zero interfactor, we look at the half space of all quadratic forms that take value at least lambda on this x. And so each of these things gives you a facet of this risk coefficient. So each facet corresponds to some primitive non-zero interfactor. And note that plus or minus x give you the same, correspond to the same vessel. Okay, so what does this help us? Well, because we have lower bounded aromatical minimum, to find this Hermite constant, we only need to minimize the turbine. Only need to minimize the determinant or some power of the determinant over this risk volume. And in fact, Minkowski already showed that this function is strictly concave inside of this cone. And so the local optima lie at the vertices. So what are these vertices? Well, these are exactly the perfect forms. So Q is called perfect if and only if it's a vertex of this such a risk of codahedron. And note that this immediately implies that such a perfect form. That such a perfect form must have quite a few minimal vectors. Because if you look at a perfect format, for example, this vertex, then the minimal vectors are exactly given by the facets that lie next to it. And because we're working in an n-dimensional space, the number of these facets at the vertex must be at least n. And because we also have like plus minus x, we get at least two n minimum factors. So, now a small notion about this similarity. So, if you have a basis B of a lattice and you have a basis B times U, where U is a unimolar transformation, then these generate exactly the same lattice. It's just a basis transformation. And if we now translate this to the setting of positive quadratic forms, then we get the notion of arithmetical equivalence where Q prime and Q are. Q' and Q are nitrogen equivalent if and only if there exists such a unimolar U, such that Q' is U transpose QU. You just get this if you take the gram matrix of these things. And note that this indeed preserves these properties, like the aromatical minimum and the determinant. And we can look at a slightly broader notion, namely that of similarity, which is just arithmetic equivalence up to scaling or to positive scaling, because we Or do positive scaling because we again for the density we don't care about positive scaling. Okay, so that were a lot of definitions. And now I want to discuss like how many of these perfect forms do we actually have? Well, the exact set of perfect forms is known up to dimension eight. And we see that, for example, in dimension two, we're only one. That corresponds to the hexagonal packing. But in dimension, But in dimension eight, we have almost 11,000 of them. And it was finally solved only in 2005 by Mateo Tour, Archer Schurmann, and Frank Valentin. And in dimension 9, it's still an open problem. Also, the LED specing problem is still open in this dimension. But there they also render algorithms, and they found more than half a million of these perfect forms. And during my master's thesis, I Master thesis, I also worked on this a bit and optimized some parts, and then I was able to find 23 million of these forms. But I will promise you there are many more, and I will, at the end of this talk, give some more details. But what we see is that the number of them grows dramatically. You could say, like, okay, this is more than exponential, maybe even. Oh, it's maybe even going to be more. So, what do we know theoretically about this? May I just ask a question? Sure. So, of these 23 million, how many of them are eutactic? Oh, I did compute that for a bunch of them, but it's not. Like, it becomes less and less. Yeah, I think in dimension eight, most of them are not eutactic. And then, yeah. Yeah, yeah, it only becomes less. But yeah, it's quite a computation for this. It's quite a computation for this many. Yeah, so what do we know about the number of these perfect forms? So let's denote by PD the number of these things or the number of similarity classes. Then what do we know? Well, in 1998, Christopher Soulet already proved an upper bound that's exponential in d to the fourth log d. And he uses to say something about the Van Dewey conjecture. To say something about the Van Deve conjecture. And in 2017, quite recently, Royal and Bashi proved a constructive lower bound of the single exponential and a upper bound that's exponential in D cube log D. And in one of my works, I showed that actually this you can give an upper bound that's exponential in d squared log d. And I mean, we don't know if this is tight, but given that the space is already Given that the space is already as dimension d squared, or like, well, of the order d squared, it might as well be that this is close to what you could get as a little thing. So now I will try to give a very short sketch of the, well, not very short, but a very short proof of this. For this, we need the definition of a Vorner domain. So a Vorner domain is just the cone spent by all the Spanned by all the minimum vectors of a form. And in this case, like you look at the span of the xx transpose of these minimum vectors. And this is in some sense dual to the whole Ryskov polyhedron setting that we discussed before. And in this case, a credit form is perfect if and only if this foreign domain is full-dimensional. And additionally, And additionally, which is very important, is that these perfect forms, if we only look at the perfect forms up to scaling, then these form a disjoint packing inside of this cone of positive semi-definite forms. So each of these perfect forms gives you a foreigner domain, but they are all, they fit nicely inside of this cone, but they don't overlap. And so now let's talk about the strategy of this proof is. The strategy of this proof is so. This is the case for two-dimensional lattices. And so you have this three-dimensional cone, and I've taken just a slice of it by looking at only the credit forms where the trace is one. And each of these triangles here corresponds to one of these foreigner domains. However, we have also seen that in dimension two, we have essentially only one perfect form, namely that corresponding to the axiomal lattice. So each of these foreigner domains So, each of these foreign domains corresponds to, like, they all lie in the same similarity class. But some of them are pretty large, and some of them are pretty small, and they get smaller and smaller. So, the idea of the proof is that, first, we can't fit that many of these large foreigner domains inside of this cone. Secondly, suppose for each similarity class we can find at least one large representative. Well, then we can conclude that we can't have. Well, then we can conclude that we can't have that many similarity plus. So, how does this? So, what large representative do we have? Well, for this, we have the following technical lemma that says that we can always find a representative for which the minimum vectors, just like as insert vectors themselves, are polynomially bounded in their norm. And so, what does this give us about the volume of this? Give us about the volume of this furniture domain. Well, to talk about volume, we first need to put some cap on it. So we only look at the bound the trace by one. And what we then get is these foreign domains that are that are just spanned by zero and then all these normalized minimum factors. And because these minimum factors are integral, we can We can lower bound the volume of this thing. So, if you first ignore these scalings, then all of these things are integral. And because they also only try to find a lower bound for the volume, we can just assume it's a simplex. And then we know that the volume is at least one over n factorial. And now, if we include the scaling, we need to add an extra product of all these norms of the minimum vectors. And those are all. And those are all polynomi bounded, and so we get a lower bound that's exponential in minus d squared log d by using the fact that this n is also of order d squared. Well, now we're essentially done because the volume of this cone of Poisson-definite semi-definite forms, if you also capitalize race one, and the volume of this even goes to zero. And well, we have this lower bound on each. And well, we have this lower bound on each, we have a complete set of representatives for which this volume is lower bounded. And so we get the exponential and d square flock d bound on the number of perfect forms. Any questions about this? Okay, then let's continue to a more practical part. So I will discuss Fourier's algorithm. So, I will discuss Vounier's algorithm and some challenges and solutions for running it in dimension 9. So, the Vourench algorithm, what it does, it enumerates all these pertforms. So, how does it work? Well, it starts at a single vertex of this risk-of-pollusion, and then it just determines all the neighboring perfect forms. For example, we started this one and we determine all the neighboring ones. Then we only keep those that are new up to the Up to the similarity. And we repeat this for each of the new forms that we found. And once we have explored every of these of these vertices, then all the neighbors are also known already. Then we know that we have found all of them and we're done. So how does this work algorithmically? So, how does this work algorithmically? Well, determining all the neighboring perk forms, this gives us a, for this, we need to solve a dual description problem. Namely, if we have one of these vertices, what we do know is the facets, because those correspond to the minimum factors of this form, and that is something we can easily compute in these dimensions. But then, given the facets, we need to compute these extreme rates that lie on the that point towards the next perfect form. Towards the next perfect form, and this is exactly the dual description problem, namely the conversion of these facets to the extreme race. Now, to see if a perfect form that we find is known already or not, we have to be able to test for equivalence. So, suppose during the algorithm at some point, you have a large database of all the perfect forms you have found already. And if you find a new one, you need to check, okay, do we already have an equivalent one? Do we already have an equivalent one in our set or not? And lastly, we have to repeat this for each form. So if the number of perfect forms grows, then well, we also have to explore a lot more of these things. So what's the first problem? Well, let PQ be this local pointed cone at Q, so this local cone here. Then, for example, in dimension 8, if you look at the product form that If you look at the product form that corresponds to the E8 lattice, then it has 120 facets because this E8 lattice has two times 120 minimum factors. And this leads to, well, this staggering amount of extreme rays. And of course, this is way beyond what we can enumerate or check. However, many of these rays point to similar forms. And what we want to do is use some local symmetry to only Symmetry to only explore a few of these neighbors. So, what's the symmetry that we need? Well, this is the automorphism group of Q, which are just all the Unimote transformations that map Q to Q. And we only actually need to enumerate these extreme arrays up to this symmetry. And why is this the case? Well, if you have such a This is the case? Well, if you have such a automorphism and you look at the array R, then the form Q plus R is similar to the form Q plus U transpose R U. And that's precisely the action of U on this ray. And so what we need to do is we need to enumerate these extreme rays up to some symmetry. And for this, you can, for example, use the SJSC decomposition method. Use the SJC decomposition methods. And Mateo will talk about this, J. Dutch will talk about this tomorrow a bit more. But in essence, it's very similar to the Foreigner's algorithm itself. You start with a single extreme ray and you try to find all the neighboring extreme rays, and you only keep those like one representative per orbit. And you repeat this until all the neighbors are known. And so using. And so, using these methods, so much workman and von Valentin were able to finally solve the eight-dimensional R1 in dimension eight, and thereby showing that all the eight-dimensional earth forms are known. And they show that it only has like about 83,000 orbits, which is a really feasible number. But in dimension 9, of course, things become. In dimension nine, of course, things become a bit harder. In dimension nine, we have a case corresponding to the nine-dimensional laminated lattice, and this one has 136 facets in a 45-dimensional space. And basically, the bigger the gap is between the number of facets and the dimension of the space, the more it's possible that you get this big explosion in this combinatory. Big explosion in the this combinatorial explosion in the number of extreme rays. But still, we think this is going to be feasible. And yeah, so Macheo is working on a lot of improvements in implementations to get this working. Okay, secondly, we have to check for a metrical equivalence. So we have to, given some Q prime and Q, we have to check. Prime and q, we have to check if there exists a unimolar transformation that maps one to the other. And if you work it out, then actually this transformation u gives an isometry between the set of minimum vectors of u prime and the set of minimum vectors of q. And of course, this is an isometry where in this case, the vectors are like the inner products are computed with respect. the inner products are computed with respect to q prime and here the inner products are computed with respect to q but these sets are finite so what we could do we could do a backtrack search over all possible isometries from one set to the other and in fact if this these sets also span C to the D over Z then every such asymmetry induces immediately a Ulimar transformation so we have like a one-to-one correspondence between them To one correspondence between them. But in general, you could use like a larger set. Instead of looking at the minimum factors, you could look at all the vectors up to some value lambda such that, and then you take lambda minimum, such that they actually span C to the D. And but I mean, you don't necessarily have to do that, you can also maybe use projections to like if you just project. If you, if you just project away from or yeah, you project away from the first minimum factors, and then you can also reduce to a lower dimension problem. Okay, but however, this pairwise checking of arithmetical equivalents is way too expensive. If you have a database with a million performs or tens of million or hundreds of million, and if you find a new perfect form, you can't just check this for like Just check this for, like, you can't do the pairwise check with every perf from your database. Of course, you have some invariants like the determinant or the size of the optimism group, stuff like that. And that indeed reduces the number of candidates you have to check. But still, for this number of forms, this could still amount to like hundreds or thousands of checks. And that's just way too expensive. So, what we need is a So, what we need is a canonical function. And it must be canonical in the sense that two chronic forms, or post-that's sent to the same value if and only if they are similar, or maybe let's say a metric different. So, how do we construct such a thing? Well, if you take a complete graph where the verts are given by this minimum spanning set of q and then on the And then on the edges, we put the weights x transpose qy, which are just the inner products between x and y with respect to q. Then what we have is that two of these forms are equivalent if and only if these graphs are isomorphic. And the nice thing about graphs is that we know how to canonically label them. So we have such a canonical function for graphs. Such a canonical function for graphs. And we can actually construct, we can lift this canonical labeling back to the form itself and thereby construct such a canonical function. And for more details, you can look in this joint work with Matur Anna Einstein and John Voigt and myself. But this was an essential part of, well, Of well, running foreigners already, we're starting to run foreigners already in dimension 9. Okay, so to finalize what's the progress that we have in dimension 9 using all these solutions. So, what we did, we made an ongoing work on Material Tour. And what we did is we made an MPI implementation which can run on supercomputers for NAS algorithm. And then what we did is we ran it for about 60,000 core hours on the national supercomputer. And we explored all but a few thousand of the tough cases. So these tough cases are, for example, the one corresponding to this lambda 9, but also other perfect forms that have quite a few minimum factors. So, how many of these perfect forms did we find? Well, like at some point, Well, like at some point, you just don't find any new ones anymore, which is to be expected. And given that we have only a few thousand left, we can be fairly confident that, well, maybe we find a few more, but it could be the case that we have already found all of them. So we didn't find like tens of million or hundreds of million. No, we found more than two billion of these pearl forms. Of forms. And so, a well, a conjecture, maybe not with too many much confidence, but a valid conjecture would be that the number of non-similar dynames performs equals this 2 billion, 237 million, a bit more. And that's where I would like to leave my talk. So, yeah, these are some sort of discussions. These are some of the citations. If you want to know more about these perfect forms, I heavily recommend the book by Acha Schurman. And here's some more citations. Thank you for listening. Okay, thank you. So, any questions or Any questions or comments? How much time was spent in the computation? Sequential time? Sequential time? Not that much actually, because I think I I run it in batches on like four hundred and eighty cores. So you if you divide it uh by that, then uh By definition. Okay. And how much would you need to finish the computation? Say a few thousand tough cases. Yeah, so that's the big question. So in dimension eight, it was really the only problem was this tough case. I mean, you had about 11,000 forms, and just enumerating all these easy cases was easy. And then you had only one tough case, which was the E8. Only one tough case, which was the E8 letters. But you already found all the perfect forms without exploring the E8 letters. Yeah? Yeah, yeah. He knew them before. Yeah. Yeah. Yeah, yeah, but you have no proof that you found all of them. No proof, yeah. But the tough case was not necessary. That's why your conjecture might be true. So actually, in this case, the tough case is necessary because there is one lattice that's only connected to lambda 9. only connected to to lambda 9 but i already added that so actually we found uh only 30 like uh well 32 here but i actually know of one that's only connected to lambda 9 so yeah we do need it officially in dimension but i i don't really expect to find uh any more one more like for the for the last uh Like for the last, let's say, billion perfect forms I explored, we found no new ones. But yeah, and so in dimension 9, there were basically two big problems. One, just the sheer amount of these somewhat easy cases. And then secondly, we still have the problem of these tough cases. But yeah, Mache will talk a bit more about that tomorrow. Other questions or comments? So I do have one. Putting aside the running time, is the method scalable? Or how much? So for instance, can you grasp some information on Some information on dimension 10, 11, 12, for instance. Not necessarily all of it, but at least a part of it. So you mean computation scalable or yeah, I need if it's scalable and I mean there's no there's no problem between, yeah. I mean please. Yeah, so in these like the easy cases are easy. Easy to explore even in the higher dimensions. Like, I think you can, like, then it should be no problem, but in theory, you could even do it like in dimension 20 if you only consider the very easy forms where the minimum vectors is just the minimum amount you have. But I don't think we will be able to even enumerate like a small fraction of all these perfect form fields. If you see how fast it grows. If you see how fast it grows, I already in dimension 10, maybe sometime in my lifetime, but probably not. But yeah, I mean, if you just want to find good packings, then you can, of course, just run this. And I mean, the nice thing is that these nice packings, the good packings are also often have a lot of minimum factors. And as a result, they are pretty well connected in this. They are pretty well connected in this graph. So, if you just do a random exploration, then you are much more likely to find these good backings than arbitrary backings. Okay, and just to be again to be back to a question which was asked by Gabby during the talk. So, if, for instance, we were looking only at autatic Only at autatic lattices, will it be possible to adapt the algorithm only to this target? I mean, if someone knows how to do that, then it would be nice, but I don't know. I mean, you would need to prove that these are all connected. Okay, I see, yes, yes. Yeah. But there's no yeah, there's no reason a priori why that should be the case. Why should that be the case and why you don't miss anything? And about the lattice, where am I the perfect form that you find in dimension nine? Is there, I mean, the large parts are, let's say, simplicial perfect forms. Yeah, the minimal vector of the perfect form is equal to the m minimal acceptable size. Minimal acceptable size, yeah. So, most of them, like about a billion of them, uh, have like exactly two times 45 minimum vectors, and then after that, it kind of decreases exponentially fast. So, for the next one, you have like two times okay, so it looks looks in fact similar, taking into account the dimensional, it looks similar to the dimension eight situation. Okay, yeah, okay. Okay. Thank you very much, and thank you for this very interesting talk. Okay, then Uh oh. I for