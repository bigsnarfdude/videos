Thank you very much for the introduction, and thank you to the organizers for the opportunity and everybody here for coming to this talk. So this is a job that we did with Sergio Zapeto. He was my master's students at CMAP, graduated last year, and now he's at Minnesota. And actually, he should be giving this talk. Actually, he should be giving this talk, but he's preparing for qualifying. So I hope you enjoy. And he has a story that is connected with, I would say, the same community. So Sergio came, well, went a couple of years to this event organized also by a non-trivial intersection of the group here and was very excited about this topic of optimal transport and mid-field games and told me what. Told me, well, probably we should do our thesis on this subject. So I gave him to read Kennock's favorite book, which is also mine. So, and we got stuck in a problem. Eventually, Ryan Heim came to the rescue and we completed this program. So, let me tell you, it's going to have a lot of intersections with the René's talk. René's talk. And to make life easier for us, we are going always to go in the discrete settings. So I don't care about, well, there is not too much analysis in that sense. Many of the challenges are under the rack. So let me explain the setting. So the problem is, as in many transport problems, you want to move from one location to the other, but everybody wants to do the same at the same time. So there are some restrictions, there are some costs that depends on. Restriction. There are some costs that depend on what everybody else is doing around. So I'm going to spend some time setting up the notation. So we have a directed graph, G, with nodes given by N and edges given by E. We're going to be considering path, which I'm going to denote with the lower omega, which are, well, adjacent nodes. And usually I'm going to use this super. This super square with minus and plus to the node initial and finite points, similar for the edges. Okay? So the length of a path is going to be given by some function, some weight or some metric, as you want to call it, and it's just add up all the weights along the path. And the distance is just a path that minimizes the length between some initial and final point. And a path that relies. No? And a path that realizes the distance is called a geodesic. So we are familiar with that, and now we go to the stochastic setting. So a stochastic geodesic is going to be a path profile, I'm going to call it, which is just a probability measure in the set of paths, as the P pies that were being considered by Rene. What is a geodesic profile? Well, if we Well, if we get inspired by this identity, I just want that the expected length of my path is equal to the expected distance between the nodes. So here I have another probability measure, which is called the transport plant, and it's just measuring under Q, what is the probability that my path starts at X and then stops at Y. Okay? So notice that in this identity, there is a In this identity, there is an inequality that comes for free, which is this is always going to be bigger or equal than this one, just by definition. So, in order to have this equality, it would be equivalent to say that this probability measure is supported on geodesics of this metric. Okay, I only see the geodesics. An efficient geodesic, well, now we have some, I would say, boundary conditions so you can. I would say boundary conditions. So you have a set capital Gamma in the probabilities of n times n, and you want to find a geodesic profile, such that it also minimizes the cantorobic potential. Okay, so here is one of the connections with ultimate transport. In other words, you not only want to have that the expected length is equal to the expected value of the distance, but that you minimize. Of the distance, but that it minimizes that functional over all the gammas on this set capital gamma. Okay, and in optimal transport, we are very familiar with the problem of moving one mass to the other. So if you have mu and u, so our probabilities on the set of nodes, so the constraints capital P of mu nu are just the transport plans such that the marginals are given by mu and Given by muani. Okay, so this is uh, let's say what they call in the book the long-term problem. Okay, so let's move towards conjecture. So there is this concept that was studied around the 50s by Wardrobe, Nosso Beckman and collaborators. It's called Wardrobe equilibrium. So what I want to do now is to say that my metric C is actually determined by Is actually determined by the path profile that I choose. Okay? So in a congestion problem, the metric is determined by how many people are using the roads. Okay? So in order to do that, I need to talk first about the edge flow. The edge flow is exactly that. How much mass is being moved through a given edge? In other words, what is the probability under Q that I'm using the Q that I'm using the S E by a generic path. Okay? Now, this is a function that takes for every edge, it gives me a positive number. Now, my cost is going to be for every edge, I'm going to look at this profile and I'm going to assign a number. No? Usually, the cost that you see in the book of Santa Mbras are local, meaning that the actual cost depends on the value. The actual cost depends on the value of this vector on the HE. But as René, I'm going to allow this function to be non-local, because, well, it's going to play a role in the dynamic problem. And I will abuse the notation a little bit when you see L sub Q for the path profile Q, that means that this is the L, the length that you compute for the metric or for the weight. Weight that is generated by Q. Okay, and the same for the distance. So, what is going to happen now is that award-drop equilibrium is a probability, is a path profile for which you get the following identity. So that means that the paths in the support of Q are geodesic of the own metric that Q generates. Okay, and moreover, we say: so this is a condition that is local. Each one of the agents that is using the graph, the roads, this is what they would like to do. The efficiency is, let's say, like the global planner condition. It's just saying that for a given boundary condition gamma, I not only want to have this equality, but I also want to have that this expected. Have that this expected length minimizes the cantorobish potential, the cantorobi functional. No? Okay, so what are the problems? Why is this a difficult problem to tackle? Well, this is not a problem in optimization. This is a problem in game theory. No, so you can see it as a system of optimization problems. In other words, you have a path profile queue that give rise to generative. That gives rise, generates a metric G, and the metric gives you a set of efficient geodesics. And the question that you want to answer is: does Q belong to this set of efficient geodesics? This is non-trivial and it doesn't necessarily have an existence here. And the second problem is that the problem is too big. Santa Bro, you would call these two ledgers of infinity. First, you have. Two layers of infinity. First, you have the set of paths, which is extremely large, and then you have probability over the set of paths. So, this is something that two things that you would like to deal with. Like the difference between taking the optimal one versus the one that you are taking the again, you you mentioned the Again, you you mentioned the paradox that if you add a row yeah if you subtract a row then you get uh more efficient yeah they this is this is study but uh I'm not going to talk about that here was like taking the optimal path versus the one that you are optimizing compared to what the other I don't know if you go back like uh so I guess it is the buler so you have the picture to the other volume with the the logo. Equilibrium is that a local? No, I mean, an efficient equilibrium is an equilibrium that is also the an efficient equilibrium has to satisfy this and also this. Yeah? Yes, yes. And usually there is no uniqueness for this problem. Okay? So it's not even clear that we have existence. So actually, when we were trying Actually, when we were trying to solve this problem with Sergio, we were looking at a mean field game approach. And we were trying actually to look at a dynamic programming equation. And this is where we got stuck and we failed. So eventually, Ryan came with the following suggestion that we should look at the particular set of costs that arise from a potential. So this is what are called potential cases. No? So a potential. No? So potential gain only means that my remember this d is a g for every h. Okay? Now this g is going to rise as the gradient of a function h, no? A function that is defined over the float, the edge flow. Okay? So h is a function in r to the edges. Okay. And what I'm saying is that when you take the gradient of this function, so you have as many coordinates as ages in your graph, you get the cost function g. Examples of how you can get this cost, for example, if you have a constant cost, then the edge is just a linear function. If you have a linear cost, all these are locals, then you get a Are locals, no? Then you get a quadratic potential, okay? And let's say that my graph is undirected, no, for every edge e, I also have the edge coming in the opposite direction, no? A non-local cost could be, well, I have to pay a price for going along the direction of B and a different price going in the opposite direction. Yeah? And this can also be written in terms of a quadratic potential. Okay? Okay, so just a few examples. And the theorem that was proved 70 years ago is that actually the problem of finding efficient wardrobe equilibrium is equivalent to an optimization problem. Okay, so this is an optimization problem that takes place on gamma. Yeah, and what you want to minimize. Yeah, and what you want to minimize is the composition of H and I of Q. So, this is, I would say, this is the connection with Renes talk. No, it is essentially, correct me if I'm wrong, you are reducing the problem to studying this optimization problem, I would say. This is then a move renier, in other words. Okay? But still, we face the size problem. Still, our configuration space is a probability. Space is probability measures over the sets of path. So this is way too big. So, what should we do? Well, in some particular cases, we know how to deal with this. So, this is why I was talking since the beginning about this particular gamma, which are the transport plans that go from mu to nu. And what we observe is that if a path profile gamma q has a transport plant that transfers to μ, then the divergence of the edge flow is determined by mu minus u. And what is the divergence? So remember, I is a function over the edges. The divergence is going to be a function over the nodes. And what it's going to be measuring is that at a given node, I add up all the edges that come out of it, and I subtract all the edges. It and I subtract all the edges that come inside. So it's the net production of matter. Okay, so this shows this relates the previous problem with the following one. So I will say that before explaining this slide that we were minimizing, no h of i. H of i of q under the constraint that gamma of q belongs to pi of mu, mu. Then there is a different problem that is more advantageous for us because it's not going to, the variable is not going to be probability measures over the set of paths, but are going to be edge flows, which is called the Beckman problem. problem which is we want to minimize h of i under the restriction that the divergence of i is equal to mu minus mu so what is clear is that this minima this minimum is going to be smaller than this one that just said a moment ago yeah but they are actually equivalent and this is a consequence of a lemma due to smirnov no Due to a smirnov, no? It essentially said that for each one of these edge flows, you can always find a path profile that realizes this I as an edge flow. Okay? And this is one of the lemmas that also appears in Santa Mborgio's book, but in the continuous set, you can also get the proof in the discrete set. Okay. Okay, so now that we have now we are in good shape, no, because now we are in calculus of variation, no? So this is a problem that we have nice tools to solve, no? So what we are going to do next is to compute the critical equations. So I come from PDE, so I essentially am directing myself to figure out what are the PDEs of this problem. So these are what I'm going to call the constitutive law. To call the constitutive law. Okay? So the lemma is the following. So the minimizers of this problem, the critical equations, is essentially this one. No? So for every edge, I look at the minimum between I and the gradient of H minus a discrete gradient of U. So this U is a multiplier, it's a Lagrange multiplier. We have two restrictions over here. No, I have to be bigger or equal than zero. Or equal than zero, and the divergence of i has to e is already predetermined. Yeah, so this is just the transpose minus the transpose of the divergence. And to compute this is essentially what René did a moment ago. You do the compute the extended Lagrangian and deduce the KKT conditions. And what you get is exactly this, well, together with the conservation of mass. With the conservation of mass, no? And just to remember, so the divergence takes functions over the edges to functions over the nodes. It's a linear function. It's transpose, which is going to be minus the gradient, has to take functions over the nodes to function over the edges. And it's just compute the difference for every edge, you just compute the difference between the end point and the initial point. Okay? Initial quantity. Okay? So something very nice is that if H is strictly convex, this just means, so this equation that I wrote here where C was the gradient of U, is equivalent to say that I, the H flow, is the gradient of the Legendre transform of H. So that's what I should call this constitutive relation, no? Constitutive relation, no? Out of u and its blading, I can compute what is the edge flow. Okay, so if I put these two things together, if I put the constitutive relation together with the conservation of mass, I get a very nice equation of this structure, which in the simplest case, if this is the identity, this is just the Poisson equation. Okay, but But oh this uh well I I guess we we I don't have uh too much time either. So so notice that okay this seems to be an analytic equation because H star is convex, but it has a few more interesting properties. It's not local because the gradient of H is not only looking The gradient of edge is not only looking at the gradient of u, at the discrete gradient of u at a given edge, but it's looking at the whole profile. Okay, and it's going to, in many cases, is going to be at the generic equation. So let me give examples to see why this is the case. No? So the first example, this H is not strictly convex, so I won't even care about writing what is the Legendre transform. But it's interesting, no? So I have a con. No? So I have a constant cos. As I said before, this arrives from a linear potential H, and you get this type of equation. Okay? There are something that we can say about those equations in Serge's thesis. This one is more interesting, because it's already giving us a degenerate problem, no? A degenerate problem, no? So, the linear problem we have that the cost for each edge is just the edge flow at that given edge. So, this is still a local cost. The potential is quadratic, and then you get this type of equation. So, you see the gradient of U whenever it's positive. If the gradient is equal to zero, you don't see what's going on with that gradient. This is going to be zero. Okay, something interesting. Okay, something interesting is that if you also assume that the graph is undirected, no, for every edge going in one direction, you get also the opposite edge, h, I'm sorry, you can simplify this equation just to the linear equation. So symmetries give you better structure. No? And let me talk now about this affine problem. No? Now, the previous one with this constant being zero. With this constant being zero, it's not very natural because it says that to cross an edge, you're only going to pay a price that is proportional to the mass of their population that you're sending through that road. But even if the road is empty, there should be a base cost for me to pay, no? So I would say that this other constant is the base cost, okay? And this arise from a quadratic, another quadratic potential. Okay? When you compute the Compute the Legendre transform of this, what you are going to get is this equation. Okay? So you are considering the gradient of U whenever it's larger than that constant. Okay? And if you try to do something similar to the previous one, if you consider, for example, the symmetric graph, they have every edge coming in, have the edge coming back, what you get is a very degenerate type of elliptic equation, which says that essentially you have the Laplace. Says that essentially you have the Laplacian equal to mu minus mu whenever the gradient of u is larger than c. Okay, so this is related with some problems that have been treated in 2016 by Inbert and Silvestre. This actually was also studied a few years before that, this particular one by Pigali and Colombo, also for the pila plasma, so a more even more general set. Okay, and there are And there are irregularity results in the continuous case. Okay. So the last few minutes, what I want to discuss is what Sergio was studying, so what's new. And what we want to understand is a dynamic model. So far, what we have been discussing here is a static model. So, for example, you have your measure mu, you have your measure new, and you want to set a vector field that. A vector field that transports the measure that constantly transports the measure mu to nu. Or now you want to add a time component and say that initially you have your measure nu, you want to fulfill this task of transporting mu to nu. It could be end at any time, no? And well, how do you model that? So the idea is that you're going to, yeah. Yeah, with the previous problem, could you do that as a limited time for this problem? Or no, it's a static problem. It's like if in fluid you're understanding that the velocity field doesn't depend on time. Now, here, the velocity field, the vector field, is going to vary with time. So, in order to model this problem, so we have our original graph G with nodes n and With nodes n and e, and we give and we give us a time horizon which is a positive integer. And the natural thing is to consider extended configuration space, which means just take p plus one copies of n so let me so here is my base graph g, no? So you have So you have from t equals zero to t equals capital T copies of n, no? And you're going to connect the edges in this new graph. Let's say from time t to t plus one by the following rule, no, if x and y If X and Y are connected in the original S G, then you connect X comma T with Y comma T plus one. Okay? Now, what about the constraint? Three minutes? Okay. What about the constraint? Okay, what about the constraint? Well, if you give me a set capital gamma in this probability measures of n times n, I'm going to construct this extended version of gamma, which means our probability on this new graph, such that the initial condition falls in n, zero, okay, and the projection in time, yeah, has to agree with gamma, okay. Gamma. Okay. So for example, if my gamma is, can I have in the next slide? Okay, if my original gamma is mu, nu, no, it's pi of mu, nu, what I need to have is that in at the initial time, I see the measure mu, no? But then I need to transport this measure mu in a measure mu that can be. In a measure, new that can be spread out all along the all possible times. No, I'm allowed to finish my job at any time. I think one of the difference with the Rene's work is that what they are considering is that the final measure have to finish at time one. Yeah? So, and something that happens is that this station doesn't necessarily have the same structure as. Don't necessarily have the same structure as before. Okay, so it's not clear that I can transform the Wardot problem in this setting to the Beckman problem, to the calculus of variation problem that I had before. But the good news is that you can figure it out, you can go around it, and you can do it. So, ah, I forgot something, a little more piece of information is that you have a cost now that is given. cost now that is given now now your edge flow leaves are functions that live from e to e super t to the reals no and to compute my cost i'm just going to say that the flow at time t at the edge e is given by this this formula no so this is going to give me a flow for every time no so this would be the instantaneous flow and to compute the potential i'm just going to use Potential, I'm just going to use the sum of my given potential at isot at time. Okay, this will be like integrating in time, no? So, what is Sergio's result is that you can still figure this out as a problem in calculus of variation. You can model this as a problem of calculus of variation. And the trick is very simple. Sorry, it's a scene is very clever, no, but the clever scenes are simple, no? So, what he figured out is that, okay, I have this problem and this constraint, gamma extended, doesn't necessarily look like a pi of mu prime mu prime. But if I add a new copy of my graph here on top, I'm going to call it, I don't know, gamma omega, okay, which is going to be a deposit. Okay, which is going to be a deposit, no? And I add for every node in my extended graph, an edge from x to here. These are not. This is x, omega. The dynamic problem is going to be equivalent to transfer mu, mu n times zero to nu in my deposit. Yeah? So essentially, you can apply. So essentially, you can apply again the, you can find a variational formulation, and when you compute the critical equations of the Beckman problem, you get exactly this one. So this we saw before. So either the flow is positive, and if it's a strictly positive, you have equality between these two quantities. This is a concern. This, this is the conservation of mass that we should expect, and this is the one that is new. This is telling you that the divergence is always negative, no? Or if there is mass, if there is a non-trivial divergence, it should be that the edge flow is consuming the mass at that point. And this has to happen at points where this gradient of U is strictly. Is a strictly negative. So, what is this gradient of u? This gradient of u is just, let me say, gradient omega of u is just u at x comma omega. So, at this node, minus u at x comma t. Okay? So, something that you will observe is that at all those points where you are consuming. Where you are consuming mass, where this divergence is strictly negative, the values of u has to be the same. Yeah? So if this is strictly negative, this part has to be zero. And if you have two things here where you're zero here and zero here, no, this is equal to this and this is equal to that. So the multiplier is equal at these two points. Okay? Yeah. So you could see. So to finish, we also had an estimate on the support of the edge flow. And we have many other results, so I will let it for questions at the end. And just an invitation to Juana Juato, this is a nice picture from Francis Matthien. There is no traffic. Thank you. For the nice talk, so I was wondering regarding the back map problem, so if you would consider the continuous phase, this is equivalent to the one was metric. So you can rewrite the one was between the metrics. And this does be in the measures. Yes, yes, yes. Yeah, I have to think about it, but so be careful here. This is a static problem, no? So you're just thinking about the static problems? I think this is no, I may be wrong, but I think it's in the book of. Is in the in the book of Philippe. I know in the case of the continents, if you do not see it. Yes. Okay. I don't see why not. Yeah, maybe. Okay, okay. Like if you study, for instance, Ben and Ugrenier, it will not correspond to the static automatic. Okay. I think. 