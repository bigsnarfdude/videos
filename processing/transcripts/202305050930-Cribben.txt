See you later. This is probably the choice of audience that I would pick. So I'm kind of fascinated to hear your feedback on this. I hope that many of you have not seen the paper. Don't go looking for it now. Please look at it on your ops. But I'm really fascinated to hear your feedback on this because it includes most of you. Most of you. It even includes myself. Okay. So, what is reproducibility and replicability? So, these are often cited as the cornerstones of reliable science. Studies that we can't reproduce or where we can't cannot be replicated by the community, they're treated with caution. There's a little bit of kickback against that as well. The ideas of reproducibility and rep. Of reproducibility and replicability, and there are benefits and the importance. So, for authors, what are the benefits? So, you know, if you're thinking of writing papers, what are the benefits to you? Well, the benefits are that people greater impact. People will hopefully compare their methods to yours. That might lead to more citations. But in terms of your group, in terms of work efficiency, communication, teamwork, if you have. Teamwork, if you have this sort of reproducible mindset, it means that work, when work is transferring from one student to another, it should be more efficient. We have all been in the case where we're trying to read or use somebody else's code, whatever hasn't been made in this reproducible mindset, and it's really difficult. For readers, so that's from the author's perspective. From the reader perspective, what are the importance and benefits? Well, there's this perceived trustworthiness. There's this perceived trustworthiness that you're being upfront saying that this is my data, this is my code, I'm open about it. There's hopefully will reduce fraud and scandals. I mean, it doesn't happen too much in statistics, but in other fields. And then giving your data might lead to sort of meta-analytic sort of studies as well. So there was this study by Nature a few years ago, and this is for science, this isn't for statistics. This isn't for statistics. This wasn't us. Is there a reproducibility crisis? Okay, so 52% said yes, a significant crisis. 38% yes, a slight crisis. And 3%, no, there's no crisis at all. Now, I probably should have done this first, but people often confuse reproducibility and replicability. So the sort of perceived definitions. The sort of perceived definitions now are reproducibility: I can take your code, your data, and without too much work, I can reproduce the results in your and my papers. Replicability is the ability that we go and collect data on new subjects and we can verify the results that you found in your study. I will not be doing this, I will be concentrating on the first. The first. So both terms facilitate the ongoing self-correcting nature of science. So if you think about Hanneman and salary and happiness, you know, a few years ago, Hanneman published an article saying that once you read a certain salary after that, you sort of plateau in terms of your happiness. This has sort of been revised recently that your happiness and your salary under certain conditions grow linearly together. So I use. So I used to think this was great being an academic, that there's no point in working for that extra money, but it's changed now. So, this sort of ongoing retesting, you know, extensive confirmation, looking for how robust the result is, this is what science is. In statistics now. So, anecdotally, from my experience, and I hope it's the same from your experience, statisticians are very responsive to sharing code. Responsive to sharing code and data. Assuming that it's not proprietary, that they're very, you send them an email. And in general, in my experience, people are pretty good, especially code. Data, that's something else. However, with this, there is no quality control. So I've in the past received code and data, and I've tried to use that code and data, and I've failed. Okay, so by using this sort of model, there's no quality control on it. There's no quality control on so this led me and my students down this road of well there's you know many reproducible reproducibility studies in other computational fields, there hasn't been any yet in statistics. So that was our motivation. So all of you are keen to get to the results. I know you're like, what is the result? So what did we do? So the reason I think you are the perfect audience is we focused on, I mean, Is we focused on, I mean, we didn't pick all application areas because we didn't feel as though we were experts in all those areas. So we selected 93 papers that study fMRI only, so not EG, not ECOG, not LFP, et cetera. We focused on fMRI. And we took seven high-level statistics journals. So you can see them listed here from the years 2010 to 2021. So So, invariably, the people in the audience, you are in this sample. This is you. I'm in this sample too. This is me. This is all of us. So, it was population. So, we feel as though we got every single fMRI paper in these seven journals that are focused that have fMRI papers in them over these years. It ended in 2021. These years, it ended in 2021. Obviously, I would like to keep this ongoing, see how things change after the paper comes out. After I present it to you, after we might get a journal, the journal, I feel as though I might be asked to do this sort of study, this new journal. But here we go. But before I get there, I think the most important thing was each journal specifies requirements for data. It's probably quite hard to see here, and requirements. To see here and requirements for codes. So we got this directly from the journal web pages. And I'll point it out to you: there's just certain words that we should focus on. So there's strongly encouraged, okay, strongly encouraged to make data used in papers published in AOAS available for others to analyze. Authors are encouraged to use web-based supplementary files to include software code for carrying out the analysis presented in a paper. Biometrics encourages and then strongly encourages. So each journal is quite unique in what it says. Biostatistics, there is an opportunity to present extensive analysis of data on the journal's webpage as supplementary material. Requirements for code: authors are strongly encouraged, not must, not expected, just strongly encouraged to submit codes reporting their To submit code supporting their publications, authors should submit a link to a GitHub repository and to a specific example of code archiving service such as Figshare or Zenoda. So, yeah, this is correct. That's very important to know. This is the current are when we collected it. Very important. Yes. Jason, it's going to be. Jason, it's going to be important for a couple of reasons. So, you would expect that given JAS in particular, let's focus in on JASA, as it changed in September 2021. September 2021 changed. So you'd expect from then on things to go really well. They were actually pretty strict even before that. They were, yeah. So, JCS, which is important, and I'll explain later. So, authors are expected. Later, so authors are expected to submit their code and data sets as on supplementary material and JASA. So, all I'm going to read it because I think this is really important. JASA, I'm going to focus in on JASA and statistics and medicine. Okay, you'll realize later why I do that. So, all invited revisions to JASA, both apps and case studies and TNM for manuscripts whose initial submission was on or after september first, twenty twenty one must include both data and the workflow. Data and the workflow, and I'll point to Mandy as a good example of this. We particularly highlighted Mandy. Okay, but it's good that they made you do. To reproduce the work presented, published papers will include a link to reviewed reproducibility materials, including the York contributions checklist. The materials will be posted to the JAZA GitHub repository. That is the most extensive out of everybody. Most extensive out of everybody. I believe JASA even has an AE for reproducibility. Statistics and medicine. So statistics and medicine expects that the data supporting the results will be archived in appropriate public repository. And the journal requires, and then in terms of code, the journal requires author to supply any supporting computer code or simulations that allow readers to institute any new methodological. Any new methodology for the published article. So, for those of you who've not read the paper, I don't know how many of you that is, how many were reproducible? Now, don't say zero. So, I presented this to my students. Everyone says zero. Yeah, so the new marker is going to say zero. It's not zero. No. June? Half. Half 60% five Armin 10% 20% one yard Okay 14 So 14 out of the 93 we could reproduce Now let's look into this because that's the advertisement. The advertisement that's to catch you. Now we look into the statistics a little bit more. Okay, 93 pages. We divided, I mean, sometimes it was quite hard. I'll discuss later. FMRI data is quite unique, and that's one of the limitations, obviously, of this study. But let's look in. So, this 14 here is we could take your real data and your code, and we could reproduce your results with some. Results with some or minimal work. We did take a very liberal view of this. We wanted you and I to do well. Okay. I'm now part of a management. Do people know management science journal? So this is a big journal in the business school and operations management. I contacted them to see if they want to do something like this. And they said, we were already doing this. Doing this, and they're doing it in-house. So they're, I'm a part of this team that are doing this house, and they're looking for reproducing 300 papers from their past 10 years. And my first question to them, obviously, was, but what if they were, because they're publishing, I didn't publish this in any of the journals I cited, obviously, but they're going to publish it themselves. And so I asked the editor, what if the results are really poor? Are you still going to publish it? To report, are you still going to publish it in management science? And they said yes. So it's good that people are changing attitudes towards this. Do you have a quick question, Mikhail? So if we, okay, so these are the 14. The one in, I'll get to that in a minute. That one in parentheses was anything in parentheses is our software provided. Software provided. Okay. So we highly encourage our packages, our software, but that does not mean that I can reproduce your work. You have to provide the script that you use in the paper in your R package for reproducibility. So don't get me wrong, these are great. R packages are great, but you need to provide the script too. So in terms of, so if we look here. So if we look here, so code provided, yeah. Absolutely. Version control is, yeah, yeah. And this goes back to Claudia's point. That's why I wanted to present this first because there were so many things yesterday. I was like biting my tongue saying, no, don't say anything yet. Because Claudia was mentioning, you know, hiring during the track session yesterday. She was mentioning, you know, instead of us keeping up to date on this, can we hire? Keeping up to date on this, can we hire a team that keeps packages up to date? I mean, how many of these packages or these things failed because they didn't specify what version of R they were using, their packages out of date, et cetera, et cetera. Okay. And so the number of papers out of the 93 where code was provided was 47. So about half where code was provided, not provided. In terms of data, so data not provided, 47. Data not provided, 42, so slightly more. So, data provided was 51. Okay, and in this data, we break it down into real, simulated data, and raw data. Okay, raw data is specific to fMRI. So, ideally, real data would be provided. If that is not possible, simulated data is, you know, it's a good start. And then, raw data. So, this is very specific to fMRA. So, this is very specific to fMRI. So, raw data is okay, in our opinion, assuming you give us the pre-processing steps, the log, the workflow, et cetera. As we all know, if you pre-process the data in a different manner or in a random variation of your steps, we'll get different answers. So, raw data is So, raw data is good, but you need to give us the steps to get your data that you use in the paper. This is the total, yeah, yeah, this is the total number. Yeah, yeah, that's the population. That's the population, yes. Yeah, yeah. So, this means that for every single paper, you guys sat down, read the paper, try to get the code, and you just. People try to get the code, they just go through the whole thing, and multiple people, multiple people, yeah. But it's still subjective to how much you try. So, so what do you stop? So, so if we fix, so we had to put a limit on it because otherwise it would so management science are giving a paper to each individual and they're giving them a month. We didn't do that. If we can't figure it out in a day, we move on. And I think that's quite fair. Normally, people would not give it a day, they'd move on after an hour or two in my. On after an hour or two, in my opinion. And so, we again, our goal was to give the benefit of the doubt to people. But in general, you know, code failed or there was missing functions or the data wasn't pre-processed. There was no way we could do it. Again, I'll get to the limitations later, okay, of the study. So, this is our summary table. We also have journal-specific table. Journal-specific tables as well, if you're interested in specific journals. But as I, I'm going to run out of time. But as I said before, JASA had the most restrictive with statistics and medicine, and they performed the worst in terms of reproducibility. Actually, from the last two years, they've got to do that. That's this graph here. Yeah. So we looked at that, and even then. You know, even then, the performance was poor. The best performer was JCGS, which was very surprising to us. But this was possibly due to the low sample size. We only had five papers from JCGS and they got 40%. So it could be low sample size. We don't know. This was very surprising to us. So here we again, it's quite hard to see this. This is just sort of descriptive plots of. Of plots of trajectories of the numbers of papers over time. So here you can see, it's quite hard. It's not good at all. Here you can see trajectories from, I think this is JASA, and this is data provided, and this is code provided. So if you're taking the optimistic view of this, data and code being provided, there is an increasing trajectory. Increasing trajectory, which points to Claudia. So if we're taking the optimistic look on this, things are getting better. Okay, let's not go back down again. I won't go to the last two pictures in the interest of time. So, oh, yeah, I knew I'd run out of time. Okay. So, suggestions for authors. So, some of the authors. So, some of the authors' things that you should consider from now on. So, step-by-step workflow for computer codes. As I've mentioned before, paper scripts in your R package. We highly encourage R packages, but provide a script. Pre-process data, if it's possible, or raw data with detailed steps, code, logs, as much information as you can give. Okay. Now, I know some of you are going to say, but my data is proprietary. You're going to say, but my data is proprietary, I'm collaborating. I understand that, okay? But a lot of us are beginning to use data sets that are freely available, like Open Euro. People are also worried about the size of the data sets. If you're worried about that, you can upload your data sets to openeuro.org. There's a growing number of data sets on this website. Suggestions for journals. We, again, this is our belief, and I'm interested to hear what you think, probably not during my talk now, because I've got. Probably not during my talk now because I've got so few time left, but after my talk. We think that this needs to be driven by the journals. I mean, we will do what they say. Okay. So the journals should clarify the access to materials. They should assign a DOI. So this is something that we discussed, you know, things that we discussed yesterday to the computer code and data. So you can cite it even. Material availability statement. So people are doing this now. So at the end of your. Doing this now. So, at the end of your papers, you have to make your materials make a statement on what's available, but perhaps have that in a different location, maybe at the start of your paper, so it's up front. Reproducibility check. So, some journals are where they have a big R on papers that have been reproduced. Okay, so we think that this is good. It gives more trust, more confidence in the results. And then our last sort of suggestion. Then, our last sort of suggestion for journals is rewards. Okay, so we don't really do this in statistics. I'm aware that in other fields that they do, rewards for authors who take that extra step. Give an annual award for the paper, the best reproducibility paper. And rewards for referees. If you take that extra step as well as a referee, have an annual referee reward. Again, other fields do this. Perhaps we should, I'm looking at McCall. This perhaps we should. I'm looking at Michaeli. Perhaps this we should do this in our field, too. Okay, and so we believe that while we're in a good field, we share, we're very open to sharing, we can do a lot better. Those statistics are quite poor, in my opinion. The limitations of this study, obviously, we don't think that they, it's very specific to FM. They it's very specific to fMRI, the fMRI application. We're aware of that, and it might not generalize to every application, and but we wanted to focus on fMRI because that's what was interesting to us. And we did not contact the authors because you know it's a quality control thing. You know, we understand that some people, some authors are willing to engage with you and go through the code. And if you grab errors or if you have errors, they'll help you out. But we think we could get rid of it. But we think we could get rid of all those problems if the journals just take over. You did not did not contact you. Because I got an email like a couple of weeks ago. I thought it was maybe you can. No, no, no, no, no. But I was in the Asia. I didn't have to call. And I don't know if John answered or not. Okay. You're eating into my time. Stop. Yeah, yeah. I'm joking. I'm joking. FMRI. So do we believe? Um fMRI, so we believe that you know fMRI lies between data that is very open, you know, Yahoo finance data, and data that is truly proprietary. Some fMRI data truly is proprietary, but there are some data sets that you can get online and you can pre-process yourself. So here's the paper. It was published late last year. If you have had a chance to take a look, please do. Comments are welcome. Any feedback, right? Okay, so with that, I've got. Okay, so with that, I've got minutes to do my actual talk. Okay, so I'm again, this is, I can go through this pretty quickly. So functional connectivity, you know, we had, we've talked about this before during several talks. So it's the undirected association between two or more fMRI time series. So there's several ways to estimate it, correlation, precision, inverse covariance matrix, undirected graph, one-to-one relationship between the undirected graph. Relationship between the undirected graph. Dynamic functional connectivity. One way to ask this dynamic functional connectivity, which we discussed in our high-dimensional track yesterday. One way to do it is the sliding window technique. So you take a window of a certain number of time points. You estimate the functional connectivity within those time points. And then you simply shift your window in time. So you might have overlap or non-overlapping windows. Overlap or non-overlapping windows until you get to the end of your time course. And this gives us a sort of simple idea of how the connectivity is changing over the experiment. Obviously, the choice of windows is very important. Another way to do it is estimating dynamic functional connectivity with change points. So, first of all, finding the change points, and then estimating the functional connectivity between each pair of change points. So, there's several people in the room that have contributed towards this work. Contributed towards this work. I am one of them. So I kind of hammered this area to some extent with different methods, changes in the spectral clustering, so changes in the community network structure, changes in the graph summary statistics, changes in the clustering structure with packages, changes in the second order structure with isolate detect that allows us to find change points that are pretty close to one another, uses wavelets, and for a manual. Uses wavelets and for Emmanuel. I just thought Emmanuel deserves it. Changes in the vine copula structure. I thought that given our discussion yesterday in the high-dimensional track, Emmanuel was so passionate about it that I want to include it. So here we get beyond the sort of linear Gaussian dependence and we find changes in the, yeah, non-linear non-Gaussian. And this gives evidence that there is, you know, dependence beyond that linear and Gaussianity. That linear and Gaussianity. But we've lost the battle. I'm afraid to say the moving or sliding window has won the battle. Unfortunately, neuroscientists predominantly use the sliding window technique because it's simple, as we discussed yesterday. But can we win the war? Okay, they are currently. Okay, they are currently winning, and this goes to Yara because we were talking about Game of Thrones last night at dinner. So, I'm trying to touch on all the conversations that I had throughout the week. So, can we win the war? So, for me, I'm kind of trying to justify the work that I've put in. Can I tell a neuroscientist of the importance of change points? And is it better than a sliding window technique, a more data-driven, you know. Or data-driven technique where it tells you where the window is. And so I thought about this from different perspectives and trying to justify work. And so two questions that I was thinking about. The first one has kind of been looked at before, but does dynamic functional connectivity provide more information than static functional connectivity? And what does more information mean? So we have all these great tech. So, we have all these great techniques, but what are we doing with that information? What's the next step? We know that dynamic functional connectivity exists, but what are we doing with that information? I know it's ultimately for the definition of biomarkers, but I think we're a long way off that. And sorry, the second question was, for me, the most more important is, does window-based dynamic functional connectivity provide more information than changepoint-based? Information than change point-based dynamic functional connectivity. And I was hoping not. Okay, I was hoping that change point-based dynamic functional connectivity provides more. So this is the sort of idea for static functional connectivity. So the importance I took from a classification point of view. So here we've got static networks. We want to see and we vectorize this network. This network, and then we put it into our favorite statistical learning model to see if it can predict disease or non-disease. And so we have this setup. I'm only going to show you one example in the interest of time, but we've got lots of different data sets, lots of different examples. So the idea is we have a, we took the ADNI data. So we've got controls on people with EMCI, so early mild cognitive impairments. We pre-process it. We pre-process it, we extract the ROIs, and then we have three different options: static functional connectivity as the input in our machine learning, our statistical learning algorithm. Window-based, so where we specify a different number of steps and different number of window sizes. And then finally, change points. Okay, so specifying that you can find one change point or two change points. Obviously, we can't have. Change points. Obviously, we can't have a different number of change points across subjects. Okay, so we fix the number of change points. So I'm interested in time, I'm just going to, the method is, I'm just going to skip through that and just get to the results. So in terms of change points, the change point methods, you know, we can switch in and switch out, which we have done. In terms of change point locations across the 67 subjects for the controls and the EMCI, the number of And the EMCI, the number of change points and the location are roughly similar. There's not clear evidence that the number or location is different between these two groups. But when we put it into a classifier, and again, this is just one resource just to whet your appetite, we find, so we've got different statistics here. So we've got F1 accuracies, sensitivity, and specificity. So green here represents the static. Here represents the static classification. The first red bar here represents the one change point classification performance. All the blue lines represent the windows for different steps, different window sizes. And then the red bar here represents classification performance for the two change points. So, in summary, Mandy's saying that I'm in negative time. So, in summary, Time. So, in summary, I'll say that we found that the change points outperformed the window-based or sliding-based methods. Now, obviously, there is, yeah, Rebecca, Claudia, and I can be happy. You know, there's just so much variation in terms of performance for the step size and window size across experiments. How do people decide this? All the steps that go into the window-based methods, it's an issue, I think, in terms of internet. It's an issue, I think, in terms of interpretability, in terms of the number of unique features found is less. For all of these reasons, I think that change points is better. If you'll permit me 30 seconds, my last topic is chat. This is from Moo. We have a paper where we looked at the benefits and limitations of chat GPT in data analytics. So we looked at So we looked at it from the perspective of the professors and students, and we found that in terms of benefits, code writing, debugging code, grading, TAs might be out of a job, it can grade your exams for you. There are a huge number of benefits for faculty in terms of GPT. There's a large number of limitations in terms of proofs. Number of limitations in terms of proofs, you need to know the domain knowledge, et cetera, et cetera. So, again, I'll refer you to the paper for details. Thank you for your time and patience. So, Ivar, thank you for a fascinating and very impressive talk. I think we will just take one question at the same time because I think we have a lot of questions for you while all the articles that I got. Mark, you provide your query for the plan. Pardon? You provide your query. Can you wait for the right? So, I asked it to write the paper for me. I asked it to write the paper. Lots of examples of exams, syllabi, presentations, all these sort of things. Yeah, so I can tell you the query that it asks. Yeah, so or rather I'm frame and display. I might have probably started here. So, would we be able to reproduce your chat if you didn't? No, because every time you use it, it'll give you a different. Because every time you use it, it'll give you a different answer. Yeah. We probably have time for another question during that. So I'm really biased here, but I think what is the why you couldn't use sliding windows and shapes different. I mean, I could not, I obviously know what I have to say, given that you can use sliding windows. Human labor can use twice the name of things, but maybe this is how you can add it to that. Perhaps, yeah. And I didn't tell you the results here, but actual ensemble methods where you use all of them together. Because they're each providing different information. That was actually the best of our but on their own, change points working back. That's yeah, that's a really good idea. We all have to plan it together. Of course, yes, yeah. Okay, so I think we'll say, oh, is this a question? So, I think we'll save. Oh, is this a question for the coffee break? I think a lot of a lot of questions, very fascinating. Uh, very fascinating work, you are. So, but thank you for one more time. And thank you, everybody, who stuck around for the last talk. Okay, so it is my pleasure to introduce my colleague, Yare Arzlak, who's going to be talking about biflusrig multivariate longitudinal data with application to a EPI study. So, Yare, the floor is yours. So, we are the floor is yours. I think it's the next one. Oh, this one is that very difficult. I didn't mind all these years. So that's okay, I can change from that. It doesn't work. It doesn't work. No, but you can use it to switch forward. You just the pointer doesn't work because I don't know, nobody has installed the software apparently. You have to do it. Oh, that's work. Okay. Cool. Okay. Well, thank you for staying for the last talk of the last session. Thank you for scheduling people for the last. We had this conversation yesterday. So again, this was, I have to say, one of the best conferences I had.