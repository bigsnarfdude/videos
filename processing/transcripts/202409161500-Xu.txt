The theoretical results on the optimal fair learning and the paratole frontier, and eventually the fair data representation at the paratof frontier. After that, I will show some numerical results based on the theoretical result. So start with the motivation. So fairness is now an important topic because unbiased algorithms can actually inherit the bias presenting. The bias presenting the data. And then, due to the increasing popularity of decision-making and information sharing based on machine learning, it's like reinforced the bias. So, our goal here is trying to remove that bias directly from data. Okay, there are two perspectives on fairness now. One is group fairness, which focuses on like affirmative action and long-term structural. Long-term structural bias between different groups, and another is individual fairness, which focuses on the different learning outcomes due to the individual difference. So, in this talk, we will focus on group fairness. In particular, we'll work on this definition, which is called the statistical parity. It requires the learning outcome, which is our y-hat, is a random. Which is our y-hat is a random variable to be independent of z, which is our sensitive variable, for example, gender or race or the combination of those. Okay, yeah, yeah, it's the independence. So Z is the sensitive variable, which, yeah, so male group or female group or male Asian male. So those different, you can consider of the index. Actually, any arbitrary, I will explain later, but any arbitrary index that can be considered as sensitive. Yes. So, for example, if we look at the learning outcome and then Learning outcome, and then for example, z is zero and one. We want to achieve the conditional distribution of y hat, condition on z equal to zero to be equal to the distribution of y hat, condition on z equal to one. Great example, the law says you cannot discriminate against race, gender, age, sexual orientation, and a whole other thing. This could, for example, be oh, yes, it could be all of those. So it couldn't make up your own trusted, you know, uh burning classes and not that sort of thing. So we started this project several years ago, and we realized along the way, we realized it's um Realize it's very closely related to other research area. For example, covariance balancing in partition samples into different subgroups, and also machine-on learning or features, because it also focuses on how to get rid of some undesirable information from your data or learning outcome. So, to do optimization with the social parity definition is not a trivial problem because the data. Problem because the data can be highly correlated to the sensitive variable. And also, we don't really know what is the necessary utility loss due to that additional independence constraint. And before our work, there are two remarkable works, one by Jean, one by Le Guique. The simultaneous proof that the on one-dimensional regression, the optimal fair regression result, can be characterized by. Result can be characterized by Was assigned to bare center. And however, their work does not generalize to a trade-off, which if a practitioner wants some flexibility of disparity to remain in the data and still want the lowest utility loss. And also on the pre-processing, which also known as fair synthetic data generation, there's still a lack of theoretical. There's still a lack of a theoretical foundation of how to design provably a fair data representation at lowest utility. So that is the two open problems we target. Yeah, those are actually open problems listed in the 2022 New York awareness workshop. Okay, so we will solve actually three optimization problems with different independence constraints. So the first one is this. Is this assume we have a machine learning task that we want to use x and z to generate some prediction of y. X is our independent variable, z is sensitive, and y is dependent. And then we are optimizing over, I use the cell tool because we want uniqueness result rather than almost everywhere uniqueness, but it's actually for any measurable function. So we are optimizing over those. So, we are optimizing over those functions and also require this fx equal to our y-hat to be independent of our sensitive variable. f is the function we are trying to optimize. We choose this f to optimize to minimize our L2 loss while satisfying the status of parity constraint. Yeah, so our first result is actually a generalization of the previous result I mentioned in 2020. So it's just to finite dimensionality. So we show that the optimal solution can be, if we look at the optimal space, then can be characterized actually. Characterized actually explicitly constructed in the following way. So, first, we find the conditional expectation of y given xz, which is the L2 projection operator. And then after that, we look at this conditional expectation, find the distribution of those sensitive groups now conditioned on each realization of my sensitive variable. So, the distribution of those. So, the distribution of those is denoted by this mu Z. And then from this mu z, what we call the marginals, center of marginals, we find the Waza-sen-barycenter of this musi, which is the rachet main on the Wasassine-2 space. It's an analog of like the Euclidean average of different data points on the Euclidean space. And after finding that barycenter, we construct those optimal transport maps now parametrized by my realization of my sensitive variable. So for each realization, I create this optimal transport map to push forward this mu Z to my barycenter. And then applying those optimal transport maps on those conditional expectation marginals to construct my unique solution, which is Unique solution, which is denoted by the conditional expectation R. And we also show that if we denote this in FIMA by this V squared, then this V squared can be decomposed nicely into two parts. One part is the orthogonal projection loss on the L2 space. Another second term is the independence projection loss on the Wassenstein II space. So this is due to the conditional expectation. So, this is due to the conditional expectation operator. And this is due to the, we are trying to find the Washington barrier center. And to provide an intuition of why Washington barrier center help us with fairness, we use this toy model. So, if we have three sensitive groups, negative, positive, and cross, and then on the upper right, On the upper right, we estimate the Washington barycenter and then perform k-mings on that barycenter. And look at the pre-images of my k-ming labels on the original sensitive distributions. We see that the data share relatively similar locations are sharing the same barycenter k-ming label, which means that the barycenter is grouping data points that share the similar. That share the similar location within their own sensitive group together. In fact, how one constructs a barycenter is first to find that matching and then remove the disparity of the matched points by their Euclidean average. So that's how barycenter is connected to fairness. Okay, so now we obtain the optimal fair solution. Thereafter, we want to move on to extend that result to the parallel frontier, which is the optimal trade-off. So to that end, we need to define what we mean by the remaining stato disparity in the learning outcome or in the data. So we use the pairwise was assigned. The pairwise was assigned to squared was assigned to distance averaged to define the was assigned disparity, which is a quantification of the statute disparity remained on my learning outcome. So this is the so we use this quantification due to the following two properties. One is that this is a non-negative quantity. Quantity. And it is equal to zero if and only if the statobarity constraint is satisfied. So it characterizes the independence constraint or statistical parity constraint. Another is that this quantity due to its definition using Wallestine 2 distance can be interpreted as the expected minimum amount of work to move one randomly selected sensitive group on my learning outcome to another. Learning outcome to another randomly select group. So we are using this to quantify our disparity. So now we use this quantification to replace the original strict independence constraint by this relaxation. And due to the characterization property, we can see that if we choose this tolerance level D to be zero, this problem reduces to problem one. This problem reduces to problem one. So that if we, and you might want to ask: so for every threshold D, I have to solve this optimization problem. That's a lot of work. But our second result shows that if we solve problem one, we actually get all the solutions for problem two for free. Because one can show that in our construction, Construction of the solution to problem one. We generate those optimal transform maps, T parametrized by Z, by the realization of Z, right? Now, for each of the arbitrary D we chosen from zero to infinity, if we replace this optimal transport map by the linear interpolation between identity map and the optimal transport map, and choosing on this And choosing this interpolation parameter t to be equal to 1 minus d divided by square root of v, whereas v is the is the infimum we found in problem 1. Yeah, it's here. Then this is the optimal solution for every D for problem two. It's this. So we're replacing the original strict independence constraints by this relaxation using the disparity quantification we define. Yeah. And I'll show later why. Yes. Yes. So for any, so by the definition, if we want to lower this minimum loss, we need a higher tolerance level. If we want to, if we need level. If we want to, if we need lower tolerance level, we will have a higher minimum loss. That's the definition of a protofun here. And to show the intuition behind our second result, we will just look at three points. Instead of looking at Vaseless and Tutorial space, we look at three Euclidean points, data points on the Euclidean space. Now, if we quantify Now, if we quantify their difference by those dotted lines, here dotted is defined as this, the average pairwise squared Euclidean distance between them. And then if we quantify the two loss by the solid line, which is the distance one point traveled away from its original location, then one can show that the solid plus one divided by square root. Plus one divided by square root of two n dotted is lower bounded by the standard deviation. Now we show on Wasosan 2 space the same thing is happening. So if we replace the solid by the L2 loss, replace the dotted by the Wazzheim disparity we defined, and then replace the standard deviation by the V, which is the quantity we found in problem one. Then this equality is also then this equality is also achieved, is also valid, and this inequality is also satisfied. And the equality is achieved if and only if those points is traveling towards at constant speed towards their Euclidean average. So on the Western Seinus base, we just replace this Euclidean average. time space, we just replace this Euclidean average by the Western barycenter and replace those Euclidean geodesics, which is the straight line by the Euclidean, by the Western geodesics, which is the linear interpolation between the identity map and the optimal transform map, which is known as the Makan interpolation. So that is the intuition behind our theorem too. And finally, we moved to how to design the fair data representation. You might ask why we have those two nice results, but why we need fair data representation is because those two results have practical disadvantages. For example, if we assume We assume we can obtain the conditional expectation in result one and result two, and perform the post-processing step using optimal transport to enforce the conditional to enforce the independence constraint, which is a post-processing step after we obtain the conditional expectation. So if in practice, if we want to really use those post-processing steps. Really, use those post-processing steps to enforce sensitivity. Then, for any model we select to estimate that conditional expectation, we need to do, like a practitioner would have to do model selection, parameter tuning, hypertuning. And for every repetition of those steps, he needs to do that post-processing step to compare the fair model obtained. So our goal is to design a fair data representation such that a broad family of machine learning models trained on this fair data representation can automatically give me a fair learning outcome. So we try to design the following objective and constraint. So only objective So on the objective part, we look at the assumed from the practitioner perspective. If he's given the x tilde, y tilde, which is the assumed better representation he's given, he would train a model to obtain the y hat based on this x tilde and y tilde, which is denoted by f y tilde and x tilde. Now, so the total utility loss. So, the total utility loss by using this model is the L2 distance between the true dependent variable and the model we obtain. Now, we upper bound not total utility loss by this L2 distance between y and the perfect model he would get based on x tilde and y tilde, plus the distance between the perfect model and the model he actually got. And the assumption. And the assumption here is that the practitioner would try himself to optimize this learning utility loss because this is his task based on the given XL and Y delta. So our goal to design XL Y delta would to minimize the first term so that combined the effort of two, we can actually achieve a low total utility loss. So this is our objective and for the constraint. And for the constraint, we require x tilde to be independent of z such that any measurable function take x as the argument would satisfy the conditional expectation, the parity constraint. Z is a random variable. Yeah, it's a fixed random variable. It's a given random variable. Sorry, repeat. Yes. Yes. So this is a simplified version. So this is a simplified version of our problem three put in the original paper, but for the time reason I'll stick with this problem setting. So this is the objective we got, and this is the constraint we got. And this admissible set is just we require the x tilde and y tilde to be some measurable function. Some measurable function map on x and z, and respectively y and z to formulate this x delta, y delta. The reason is that we want some roots based on the original data rather than some artificial information. Now, so our result shows that how to obtain the optimal x tilde is X tilde is to pick the Wases and Barry Center. This is because we can show that the Washington-Bary center actually generates the finished sigma algebra among all of those random variables or admissible X tildes satisfies the independence constraint. And one can show this by a tower property that the Finner sigma algebra. The thinner sigma algebra, the lower the L to loss. And we don't have to touch y delta here because we can because this is a just a measurable function of x tilde. So it will accept, as long as x tilde satisfies the independence constraint, my measurable function of x will satisfy the independence constraint. So we don't have to do anything for y tilde. for y tilde and um based on those we design our algorithm based on those uh theoretical results we we design our algorithm it's um the actual algorithm is a little bit more complicated than um than um the results we present here because we also did something for y and to put more constraints on y on y tilde but um But let me jump into the numerical experiments. So we tested our algorithm on the baseline real-world data sets. We did classification on adults and compass and a regression test on LSAC and crime. So this is the numerical result I got. We got. Results I got. We got. And on the horizontal axis, it's the discrimination measure. This is the popular discrimination measure used in fairness study. And on the horizontal, on the vertical axis, we have area on the curve. So the higher area on the curve, the more accurate our model is. And we choose those two to show that our, even though our part of frontier Even though our parallel frontier is designed on the Wisdom Science base, but we have a good estimation for other quantifications of discrimination and utility. So this light blue one is the original test result. So we do nothing but perform random forest and logistic regression on the data and look at the AUC. Uh, look at the AUC and this discrimination are those light blue ones. And the dotted line is the parallel frontier we generated using our algorithm. And in comparison, the orange one and the light gray ones are the state-of-arts methods. So our algorithm actually achieved higher accuracy. Higher accuracy at the same discrimination level. And we also tested the regression on crime and LSDC. So here we use the Washington Due disparity and as the quantification of CSO disparity. And for utility loss, we use L2 loss. And we compared with the The exact barycenter method, which is proposed by Jean in 2020. And he used the inverse of the CDF method to find the exact matching and therefore the barycenter. So our method actually achieved a very similar, very similar performance to his, but our computational time is significantly. Computational time is significantly lower because our estimation only uses a fine estimation to generate those optimal transform maps. For example, you can see that our method cost, so the entire machine learning task cost 1.1 second comparing to the brutal force variable center matching method. Okay, and then we also plot our method to show the particle frontier for multi-dimensional regression. So because our estimation is based on affine, the affine maps has a limited power to reduce further this disparity. That's why in the ongoing work, we're now instead of using We're now, instead of using affine maps, we're actually using neural networks, actually gain structured neural networks to mimic the true optimal transport and then the true bare center. So in this preliminary result, we got. So the first row is the, so we are testing our method on the salabay data set. The first row is the female group. And then we train the, we use the gamma structure. We use the GANA structure neural net to train an estimation of the optimal transform map from the female sensitive group on that Select A data set to the male. So the first row is the true images on that select A data set. And the third row is the push forward. So it's the synthetic. It's not true. It does not exist in the original data set. And then this middle row is the barycenter because it's a two-marginal. because it's a two marginal problem. So we pick the time in Markar interpolation equal to 0.5 to get this bare center. And one can see that indeed this optimal transport is trying to get rid of the gender feature on that data set while containing other information on the faces. Faces. So that is a visualization of our fair data representation theoretical results. So, but we are still working on this and hope to share more results thereafter. To summarize, we provide a provable and concrete way to characterize the partial frontier between utility loss and satellite disparity. And also, we provide a provable way.  Are you guys looking at extending these ideas to conditional distributions of fairness? So, for example, sometimes with the when the prevalence is very different among groups of the response that you're going to predict, you can refer instance with things like equalize odds. Yeah, we did work on equalized odds and we proved the optimality results based on some assumptions. But we have to put measurability of we To put measurability off, we have to assume we can obtain the accurate result to use conditional optimal transport to solve the implies problem. So why are we using the David Hilbert loss when there are other more fancy losses? I mean, L2 loss. Sorry? Yeah, sorry. L2 loss. Yeah. Sorry? Yeah, sorry, L2 loss. Yeah. The primitive chimpanzee loss. Yes, for sure. So our goal is to, it goes back to this design of objective. So we want our fair representation to work for all the regression and classification methods. So we look at, so we optimize when designing x delta y delta, we optimize this potential utility loss. And any method that Loss. And any method that aims to estimate the conditional expectation would work on our very data representation because we minimize this utility potential utility loss. Yeah, this is just triangle inequality. Yes. But since the classification can be also considered as a conditional expectation, right? Yeah. And regression is, of course, intuitive to L2. So that means our That means our if you try to if you try to achieve the conditional expectation using the given x tilde and y tilde, you would obtain a good result based on our design objective. Otherwise, you have to assume a specific loss, right? But that loss function would be very specific for different machine learning models. Different machine learning models. Does that answer the question?