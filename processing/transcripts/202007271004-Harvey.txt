Together and inviting me. I was really looking forward to meeting people in person in Banff, but today I'm just going to give an overview of the paper that my co-author and mentor, Shivilahiri, and I put on archive just before the shutdown in California, which is on non-equilibrium sensing. And we'll hopefully get at some of those ideas that we were talking about in like the very end of the last QA about like when is it advantageous to use a non-equilibrium sensor. use a non-equilibrium sensor. Okay, so vaguely this project is motivated by the motivation for this project comes from the quite fascinating ability of these simple organisms to sense their environment in order to survive and grow. And one particularly well-studied example of this is chemotaxis or the attraction or repulsion of modal bacteria to substances diffusing in their medium. So this video on the Is diffusing in their medium. So, this video on the right is from the Howard Berg lab a long time ago, and it shows bacteria displaying their swimming mechanism using their flagellar motors. And so, if you watch closely, they're executing this run and tumble model. And they're able to adjust the frequency of the tumbling based on input from their receptors in order to execute a biased random walk towards the And walk towards the substances that they like. And so the frame on the right is showing that from a paper in the 60s from Julius Adler, who did a lot of really early studies on chemotaxis. And you can see the bacteria, which are the black speckles, have migrated towards the source of an attractant in a capillary tube. So we're interested in how this was accomplished by single-celled organisms that we don't really usually associate with it. We don't really usually associate with advanced decision-making ability. So, in a very physicist's hand-wavy cartoon picture of this, they do this using a collection of the membrane-bound receptor proteins that bind and unbind certain molecules, which causes the conformational activity change in the receptor and generates a signal, which is in the form of a phosphorylated protein that diffuses across the cell. And this allows the And this allows the receptors to control the direction of the rotation of the flagellar motors based on activity, the binding and unbinding activity. And they also have the ability to adapt to longer time scale changes in concentration, so they're not easily saturated. So, this is a fairly complicated and well-studied system, but for our purposes, we're interested in just an abstract or toy picture of this process, which is almost Your toy picture of this process, which is almost certainly incorrect, but maybe will be useful or just maybe interesting. So we're just interested in. Yep. Apologize to interrupt. So some of the people on chat are saying that they're not able to see the shared screen. So I just wanted to just briefly interrupt and make sure that we can resolve any technical difficulties. So I am sharing my screen. Can anybody else see it? I can just see Sarah's face. I can just see Sarah's face. Some people can't face. Am I pinned? Maybe if someone has pinned my video, then you can't see my screen. I don't know what to do. You could try unsharing and then try sharing again. Okay. Stop share. Share screen. It seems like most. It seems like most people were able to see. Yeah, I mean, if it's just most people were able to see, that's weird. Only a couple had trouble. We're not sure. Okay. Okay, can you see my desktop? Yeah, I can see it now. Okay, where's my presentation? Sorry. Oh, no. Okay, can you see? Can you see? Oh, okay. This is weird. Yes, I can see that. Sorry, I'll try one more thing. Keynotes. Get out of this. Share. Okay, anything now? Looks good. You can see some cartoons. Okay. Right, cool. So, we're kind of interested in this abstract picture of the cell performing an internal representation of an external concentration over some time scale and such that it can measure new changes in concentration with respect to that. So, an interesting question might be: with the information that's available to the cell, how accurate can the cell's estimate of the concentration be? And is this limited by these thermodynamic ideas? By these thermodynamic ideas that Professor Stafford was talking about? And is this an area where we can study the relationship between thermodynamics and information processing in biological systems? So this system has a long history of study by physicists, starting notably with Berg and Purcell, who were interested in the fundamental limits of this system when they wrote the paper called The Physics of Chemo Reception in 1970. Paper called The Physics of Chemoreception in 1977. And they're interested in studying this phenomenon given that cells inhabit an environment that's really different from our macroscopic world. And under these conditions, what is the smallest change in concentration that a cell could hopefully ideally respond to in a given time? So there's all sorts of interesting calculations in their paper, starting with really idealized models of chemosensation, such as a perfect integrating sphere. Such as a perfect integrating sphere that counts the number of molecules in a volume over time, as well as the perfect absorbing sphere that counts and releases particles that collide with its surface. But for our purposes for this talk, the relevant result in their paper is the analysis of the single receptor, where they thought about the uncertainty defined as the variance of the concentration. Defined as the variance of the concentration estimate divided by its mean squared. For a receptor model, it's a two-state Markov chain with the binding rate proportional to the concentration linearly and the constant probability per unit time of release. And it assumed that there's some sort of estimation based on the average time spent in the bound state. And they found what is known as the Berg per cell limit: that the variance over the mean squared is limited by 2 over n bar, where n bar is the n-bar where n-bar is the expected number of binding events in some integration period and they express this in terms of like more physical quantities broken down into the diffusion constant and the like effective capture radius of the receptor so this result kind of kind of stood for a little while as the the bird or as the single receptor limit um But we can pretty obviously change the bound and the uncertainty is by violating the assumptions that went into this calculation. So, is it possible to write down another model that does better? And is that maybe useful or interesting to do? And so, people have thought about this in the intervening years, starting. Oh, God. Okay. I'm not that familiar with giving a Not that familiar with giving a virtual presentation. Okay, starting notably with Andres and Windgreen in 2009, where they applied this maximum likelihood estimation to a two-state receptor model as a continuous time Markov chain and applied maximum likelihood estimation to the trajectory time series. And what they found is that the maximum likelihood estimator is proportional is basically related to the Is basically related to the time spent unbound. And the uncertainty from the Kramer-Rau bound is smaller than the Burke-Russell element by exactly a factor of two, which can be intuitively seen as coming from the fact that only the, in the case that you have access to this entire time series, only the unbound time intervals actually contain information about the concentration. So that's kind of interesting, but you can. So that's kind of interesting, but you could also imagine violating the Berg-Purcell assumptions by expanding the Markov chain used to model the receptor to something less trivial than a two-state network or a two-state Markov chain, which invites the possibility that the process can be driven out of equilibrium and have asymmetric fluxes between states. And so we'll be more precise about what that means. And so we'll be more precise about what that means later, but it's later in the talk. But this was studied in a paper by Lang in the Meta group in 2014. And they considered continuous time Markov networks divided into two sets of states, the signaling states and the non-signaling states, the signaling states being the ones that produce some continuous signal when activated. And this is kind of an extension of the Berg-Purcell assumptions. And they found. And they found for networks with one non-signaling state and constrained to be ring topologies. They found an expression relating the uncertainty, the variance of the observations associated, or the variance of the concentration estimate associated with observations of this network has a relationship, there's a relationship between that and the There's a relationship between that and the entropy production. So, suggesting there's this trade-off that reducing the uncertainty for observations of this network requires below the Berg-Purcell bound for just two states requires networks that are out of equilibrium. So, kind of jumping off from those previous to and other studies, there's been a lot of work in To in other studies, there's been a lot of work in this area. We're kind of generally interested in studying the apparent dependence of the estimation uncertainty on the observability of the Markov process that's used to model this sensor. And then we'd like to study analytically the apparent trade-off between the energy required to maintain a network in non-equilibrium steady state and its estimation accuracy. And when is that an advantage? And under what circumstances does it help to add more states? States. Okay, so just for the rest of this talk, I'll just go through a little bit of mathematical setup, which I'm sure people are familiar with, and then just sketch the two main calculations in our paper. Namely, the uncertainty for detailed trajectory observations, which we call the ideal observer. Basically, the observer has access to the entire trajectory. For more general multi-state networks, by writing down a Kramer rau bound. And then we'll address a more coarse-grained observer, which we call a simple observer, where it only has access to the time spent in some subset of states and bound that in terms of the entropy production using some ideas from stochastic thermodynamics and large deviation theory. And then I'll just conclude with some numerical figures. So So, just to review, the entire basis of this line of inquiry for us is that we're modeling a sensor, which is maybe a good model for a cell's receptor, as a continuous time Markup chain, and then making observations of realizations of that Markov chain in order to do inference. And so, right, so this is a discrete state system, which we represent graphically as nodes on a graph, and then the allowing. Graph and then the allowed transitions in my cartoons. The allowed transitions are represented by edges on the graph. And there's some transition rate that describes or a transition from state I to state J, which we matrix Q. And this, of course, the density over states evolves according to the master equation dynamics, which tells us that the derivative of the density is related to the sum of the currents in general out of the. The sum of the currents into and out of the node and has some steady-state distribution, which we call pi. And this bracketed quantity is obviously the expected current from node I to node J to under density P. And then we can identify those terms in the current, the two subtracted terms in the current, as the flux between states and the expected number of transitions per time over that edge in that direction. So in steady state, we find So, in steady state, we find indicate that with a superscript pi, the expected number of transitions under the steady state distribution, and then we can write the current in terms of the fluxes. Okay, so that should be it for the notation. So back to that general sensing problem where which a signal is transmitted through a physical channel modeled as a continuous time markup process whose transition rates are modulated by some signal, which we're calling C. Signal, which we're calling C. And so the idea is that the observer records the entire trajectory and transition times for some fixed time interval, and then is able to use this information to construct an estimate of the signal C hat. And the challenge is now to find the best possible, you know, ask the question, what's the best possible estimate the observer can make, the signal C with what uncertainty. So I won't go through this calculation, it's pretty straightforward, but we can get at this by The basic we can get at this by writing down the Fisher information for the observed trajectory with respect to the signal C, which is modulating its transition rates. And then the Kramer route bound will give us a nice, a fundamental limit on the precision with which the signal can be estimated based on trajectory observations. So the outline for this is pretty much to write the probability of a trajectory in discrete time, write down what the Fisher information. Discrete time, write down what the Fisher information matrix is, and then take the continuous time limit. So the probability of a trajectory can be written in terms of its, you know, in discrete time, in terms of its transition matrices M, or its discrete time transition matrices, which are related to the continuous time generator. And then we can write down this expression for the Fisher information after we make some. After we make some substitutions, like the expansion of the discrete time transition probability matrix and taking the time steps to zero, you'll find a lot of terms collapse. And we end up with this kind of simple expression, which might look familiar for the Fisher information. Where this first term is just like a single shot Fischer information of an observation of the state of the network drawn from the steady state distribution. Network drawn from the steady state distribution. Oh, Sarah interrupted. There's a question from Peter Thomas. So to clarify, is C a fixed constant or is here and for the rest of the talk, C is some fixed signal that we're trying to estimate based on like the dynamics of the Markov chain. Right. Okay. So this Fisher information tells us. So, this Fisher information tells us essentially how informative is the observation of some trajectory of the signal, which is related to its transition rates. And so you can see there's one term that's constant and then one term that grows linearly with the length of the observation time as you increase the length of your trajectory. Okay, so kind of So, kind of cool, but we can make some assumptions that are maybe more well-suited to our self-sensing motivation. That maybe the states are divided into two states, two groups, the signaling and non-signaling states, which is I'm trying to indicate in this upper right-hand figure here. And that the binding transitions, the ones that go from non-signaling to signaling, are the ones that are linearly related to the concentration. And in that case, And in that case, the Fisher information simplifies nicely to just something, you know, that the constant term is just constant. And then the second term would explain what you mean by signaling versus non-signaling, because you were talking about the whole trajectory before. Yeah, we were talking about the whole trajectory before. So now we're dividing them into non-signaling or signaling states, but that identification effectively only means in this case that the This case that the trans we're identifying a subset of transitions that are related to the concentration. And so what ends up being, sorry? Does it mean that we see only these transitions or what does it mean when it doesn't mean that you see only those transitions, but those are the only ones that are informative. So, right. Right, so in that case, the Fisher information collapses to just a term that, you know, in the long time limit, this thing dominates. The term that's related to time dominates. And we just end up with a term that's related, that's just the binding rate. So you can identify this as the sum of the fluxes over those transitions that are related to C. And so in the case And so, in the case that those transitions are like moving from one set of states to another set of states, as opposed to some other weird combination of transitions, the Fisher information is just proportional to the average binding rate from that one set of states to the other set of states. Hope that makes sense. So, it's like identifying a set of transitions that may or may not be, or that are related to the concentration. The concentration that moves you from one set of states to another set of states. So, yeah, there's a question from Henry Manningly. Does it mean a subset of the transitions don't depend on C? Yeah, so some transitions like transitions within signaling states don't depend on, or transitions between non-signaling and transitions between signaling states don't depend on the concentration. We're just Depend on the concentration. We're just identifying the kind of by definition, the states that depend on the concentration as the binding transitions as kind of an extension of the, you know, the Unras and Windgreen paper from 2009, where they had this two-state system where the binding transition was what was proportional to the concentration. They looked at the trajectory of that two-state system. We're saying you can observe the entire trajectory, and there's an arbitrary number of binding. Number of binding transitions, like the structure of the binding transitions from the non-signaling to the signaling can be arbitrarily complicated, but those are the ones that are related to the concentration. And we can observe that trajectory. And that's what's being calculated is the or that's the reduction. And so in that case, the Fisher information simplifies to just the binding rate over those transitions. Over those transitions. Right, and so then the Kramer outbound gives us the variance of an unbiased estimator of C is just related to the inverse of the Fisher information. So that implies that our uncertainty, our variance or the mean squared of some estimator, is bounded by one over m bar, where m bar is the expected number of binding events in the trajectory. So this is a, you might remember that this is exactly that maximum likelihood result. So this is kind of a generalization of the previous Unres and Windgreen result, but also kind of tells us that there's in this under these assumptions, there's actually no advantage to adding more states because I can saturate the Kramer route bound with a two-state Markham process, which is under the assumption that I can. Under the assumption that I can observe details of this trajectory. And then you might have noticed we didn't really discuss anything about detailed balance or non-equilibrium or entropy production because I can saturate this bound with a two-state network, which is trivially in detail balance under this assumption of like a steady transition rate. So there's a question from Pur Shotam Dixed. Rate Qij depends on C. QIJ depends on C, then I is a non-signaling state and J is a signaling state. Is this the definition? Yeah, that's the definition. Yeah, yeah, yeah. Yeah, they go in that direction. Yeah, so that comes back to like diffusion-limited binding from the Bird-Purcell paper, where the binding transitions are, or the binding transition in that case, is the thing that is linearly proportional to the average concentration in the area. To the average concentration in the extracellular medium. And then the proportionality constant is something to do with the diffusion coefficient and the like capture radius of the effective capture radius of the receptor and so on. This is kind of just kind of trying to generalize it. Okay. So this is kind of switching to a new topic. So that, you know, the fisher information is kind of interesting, but maybe. It's kind of interesting, but maybe that assumption that you have access to the detailed information of the transitions and the transition times is kind of optimistic. And maybe we can make more realistic assumptions about some observability of a Markov process. So, this is kind of jumping off from the 2014 Lange and Meta paper where they observed. Met a paper where they observed that for larger networks where we're now restricting the observability to the non-signaling or the signaling states, they can approach the Kramer rau bound or violate the Berg-Purcell kind of two-state limit only when driven out of equilibrium in a non-equilibrium statistic. Okay, so the scenario that we're describing here. Scenario that we're describing here is that the cell no longer keeps track, or cell or observer or whatever, no longer keeps track of the microscopic transitions, but the estimation is based on some fraction of time that the receptor spends in a subset of states, which is the Berg per self assumptions, but for an arbitrary, like a larger network. And so, right, so assume arbitrary structure. So, right, so assume arbitrary structure, we just divide into two groups, and now the estimate is based on some density in the signaling states. So, we call that Q is the sum over the, you know, the probabilities of being in the signaling states. And we want to know if there's an advantage to, since this is no longer a two-state system, is there an advantage to driving the sensor out of equilibrium? Okay. It's okay. So I should probably at this point be a little bit more precise about what I mean by, you know, non-equilibrium and entropy production. But luckily, this was covered for me basically in Professor Zayford's lecture. But really fast, I'll just go over a neurotic Markov chain. Under some assumptions of ergodicy, the Markov chain relaxes to a steady state distribution in the long time limit. Distribution in the long time limit, which by the master equation tells us that the sum of the currents into a node is equal to zero. So for more than two states, there's two ways to have the steady state not changing. And one is detailed balance, which implies the currents are zero everywhere in the everywhere. Everywhere in the network. And or we could imagine all of the terms in the sum kind of conspire to be equal to zero. And this implies the existence of non-zero current loops, which sum to zero or asymmetric fluxes along edges. So intuitively, you might be able to imagine that the non-equilibrium steady state case breaks this time reversal symmetry in the sense that now that there's a very obvious difference between the videos of these two processes. Between the videos of these two processes played backwards and forwards in time. And you also might imagine that maintaining non-zero currents should require energy dissipation, but to provide that physical interpretation, you need to associate the Markov chain model with thermodynamics, which is precisely what Professor Zeifert did in his lecture and the subject of the stochastic thermodynamics. So I'm not going to repeat a lot of this, but Repeat a lot of this, but it's basically a framework for describing stochastics, driven stochastic systems that are coupled to the thermodynamic reservoir at some temperature. So we relate the, you know, we require this local detail balance condition where we relate the ratio of the transition rates to the, you know, the change in total change in free energy along these transitions. And there, where this thing can be driven out of equilibrium by some Equilibrium by some thermodynamic potential that maintains it out of detailed balance. And so this identification allows us, which is kind of what Professor Zaford was talking about, this identification allows us to be precise about the expected entropy production rate of the system in the environment. And so there's kind of some subtleties here, but the point is, which we can write down a consistent expression. That we can write down a consistent expression for the entropy production associated with a non-equilibrium steady state in a Markov process, assuming that the transition rates are related to the thermodynamic quantities by this local detail balance condition. And if you look at this expression, it might be intuitive in that you can see that it's always greater than or equal to zero. It's zero in detail balance when the flux is along each edge, you know, the pi. fluxes along each edge you know the pi i q i j term is the flux from i to j when those terms are equal to each other this thing is zero so it's zero in detail balance and so you can think of this as like kind of a quantitative measure of the time asymmetry of the process okay so for our purposes I think everybody's probably comfortable with this concept of entry production rate as existing but our question is is there is is there a really can we find a relationship between the entropy production and the precision of measurements based under our you know previous assumptions and the answer is yes but it requires a little bit of large deviation theory it's kind of been done it's been done before in this related scenario that Professor Zaford talked about at length is just this the thermodynamic uncertainty This is the thermodynamic uncertainty relation, which was conjectured and then proved by the Gingrich et al. in 2016. And they showed it using large deviation theory for Markov process currents to relate the fluctuations in a generalized current to the dissipation rate, or that fluctuations in reducing the fluctuations in the currents costs them. Fluctuations in the currents cost of minimal dissipation, basically. And so the question is: can we follow the same sort of program for our concentration estimation problem that's kind of motivated by cell sensing and bound the uncertainty in the concentration estimate? And so the answer is yes, but we need to start with a little bit of large deviation theory, which I'll just try briefly to motivate. So, if you imagine in observing the time evolution of a continuous time markup process for some large observation time t, we could write down an empirical estimate for the steady state density by just summing up the time intervals that the process spent in each state and dividing by the total time. And the vector of those quantities we'll call the empirical density. And then, similarly, you could find the empirical current. You could find the empirical current by writing down the net number of transitions along each edge in the total time. And as the time goes to infinity, these, you know, the empirical densities and currents converge to their mean values, the steady state probabilities, the steady state densities, pi, and the steady state currents, which is J pi. And but for large with finite t, they'll fluctuate around their steady state. Finite t, they'll fluctuate around their steady state values. You know, you won't exactly measure the steady state value. So it turns out these two observables jointly obey a large deviation principle, which just, there we go, which describes the probability assigned to a particular pair of density and current vectors and as the observation time that you kind of integrate over to generate your estimate. As that time becomes large, the fluctuating. As that time becomes large, the fluctuations of these vectors from their steady state values are exponentially suppressed according to the large deviation rate function, which is i of p comma j, which is some function that has its minimum at the steady state values of pi and j pi. And so I'm not, this is really not a rigorous introduction to Legation theory, but you can use this rate function to study fluctuations. Rate function to study fluctuations of these observables, even when the fluctuations are large and they're not well described by the central limit theorem. So, okay, so what is this rate function? It seems like something we need. So it turns out it exists and it is part of a larger theory of large deviation theory for Markov chains, which identifies these different levels of observables and rate functions for general observables that can be. General observables that can be obtained from other rate functions. And in this case, we are what's interesting, we're interested in what is called level 2.5, which I'd encourage you to see the references below to find out why it's called that. But basically, there's various ways of deriving this rate function with different degrees of mathematical rigor. In our supplemental, we describe a method called the tilting method. A method called the tilting method. But there's other methods found in more mathematical papers, like spectral methods and contraction. But the details are not that important for the purposes of just this talk, except for the kind of remarkable fact that this rate function exists in closed form. To me, it seems remarkable. And that we can now use it to study the fluctuations of these empirical densities and currents for Markup processes. Concurrence for markup processes. Okay, so if we just accept that, that's exactly what we can do. We can study the, we want to study the density in the signaling states, Q. That was kind of the quantity that we thought would be interesting from the sensing perspective. But that's an additive combination, you know, it's just the sum of the densities and signaling states. So it's an additive combination of densities P. So we can. So, we can find the rate function for Q using the principle of contraction from large deviation theory, which allows us to bound or allows us to find one rate function from another rate function by taking the infimum of that, of the known rate function over its arguments that are consistent with our desired value of the observable. The intuition behind that being that the probability of Q occurring should be approximated by the most probability. Should be approximated by the most probable fluctuation in the P's and the J's that would lead to. Is that an effectively the Legendre transformation or something else? Yeah, it's, oh, is it effectively the Legendre transformation? It's effectively. It comes from Laplace's approximation. I think it's effectively. Okay, never mind. I was just asking whether there's a connection to. Whether there's a connection to something that's known from the rest of the thermodynamics. There are definitely a lot of theory. Okay, I'm not sure if it comes into this exact, but I'm probably just blanking. But yeah, so this intuition that you can find a rate function for observables from a rate function, it's a function. From a rate function, that's a function of from a known rate function. You can find another rate function for an observable that's like a function of the known rate function observables, which can be kind of many to one. Like the intuition of using the infimum comes from like bounding it by the like the most probable fluctuations that are consistent with your desired observable, which comes With your desired observable, which comes from is basically an application of Laplace's approximation. If you integrate the exponential, like this distribution that goes exponentially in time or some parameter with a rate function, you integrate over the values that are consistent with like Q or whatever variable you want to contract to. Comes down to an application of Laplace's approximation. Anyway, we can. Anyway, we can talk more about that later. And then the variance of Q is just related to the inverse of the second derivative as the steady, as the expected value, which is the minimum. So the infimums of this kind are generally hard to find exactly, but you can bound them pretty easily using educated guesses from. Educated guesses from for the densities and currents. And that allows us to bound the rate function as well as its second derivative in terms. And if you choose wisely, we can bound the rate function and second derivative in terms of the entropy production and the flux from the non-signaling to the, or the binding rate from the non-signaling to the signaling states. And this implies a relation. And this implies a relationship between the or inequality, which states that the variability in the empirical density in some subgroup of states is bounded by these quantities, the entropy production and the average binding rate, which is kind of cool because they're more aggregate quantities that don't really depend on the details of the network. We didn't really make any assumptions on that. We didn't really make any assumptions on that, except for the division into one group or two groups. Okay, so the last kind of bit is to just apply this relationship to our, to say something about our self-sensing problem by relating the density and the signaling states to the concentration estimates, or sorry, to the concentrations, which are. Concentrations, which are related to the steady-state densities in some complicated way because the concentrations are modulating the transition rates. So, right, so that comes down to asking the question, given some empirical observation of the signaling density, for what value of C of concentration would, or arbitrary signal, would this value of the Value of the steady state density be the expected one, be the steady state value. That allows us to relate the two using your typical error propagation techniques. You can relate the variance in C hat to the variance in the density Q, provided you have this Jacobian term between the two. It relates the steady state density in the signaling state. Steady state density in the signaling states to the concentration. And so we need to figure out what that is. And so, okay, this is the last kind of thing, but you can write down an expression detailing like the sensitivity of the equilibrium distribution to changes in its transition rates using first passage time, the theory of first passage times for Markov chains. Markov chains. And so this is this formula here that is in red. So this relates the derivative of the elements of the equilibrium distribution or the steady state distribution to changes in its transition rates and the mean first passage times, which I think is a pretty interesting formula in my opinion, just because it seems simpler than it should be to me. But anyway, this allows us to find a function that relates. To find a function that relates the steady state density signaling density to the signal C, which takes a particularly simple form. It's kind of messy for completely arbitrary networks, but it takes a particular simple form for networks that have only one unsignaling state. And so we can write down this nonlinear relationship between the concentration that's modulating the transition rates and the binding rates in some way. Transition rates and the binding rates in some way, and the steady state density in the signaling states. Okay, so the takeaway is just you can write down what that Jacobian is. And then using that and using the relationship between the variances of these two things and our bound for the variance of the density in some subset. Combining those three formulas leads us just to a bound on the signal estimation in terms of the Estimation in terms of the total entropy production and the number of binding events in the time, the observation time. So, right, so that's this formula in blue here. So that this tells us that, so there's a nice cancellation, and this turns out to be kind of remarkably simple. And you can see that it agrees nicely with the Berg per cell limit in the detailed balance case, where the sigma pi, the entry production rate, is zero in detailed balance. Is zero in detailed balance. So you'll just end up with eight over four times the expect times m bar, which is two over n bar. Okay, so to transition. Okay, so just to recap, I know it's kind of difficult to follow all of the notation, but we just saw two theoretical bounds on the uncertainty of a sensor. Certainty of a sensor modeled as a continuous time markup process in different limits of what's observable about the process. And then the first was a, so the first was a Kramer-Raubound based on observations of its trajectory. And the second was a coarse-grained observer whose measurement can be is based on the fraction of time spent in some subsidist states, not the details of the trajectory. There's some other, There's some other, we did some other, you know, interesting, there's some other interesting results in the paper, including an exact expression for the coarse-grained simple observer uncertainty by solving the contraction exactly to leading order. And so, you know, I don't, you know, nobody should understand this formula, but it's basically just relates the, you know, the uncertainty to, you know, it's 2 over m bar times some complicated term. Complicated term. But the important part is this is an equality. So we can optimize this expression to find the optimal networks at some entropy production constraint. And then we can also, this actually turns out it simplifies in the case of uniform ring networks that have the same transition rate backwards and forwards, or they have the same transition rate in. Rate in one direction and a different transition rate in the other direction, but all of the transition rates between states are uniform. And you can write down an analytic expression for that, the uncertainty for networks of that form as a function of the entry production rate. Okay, this is the last uh this is the last section. So just we wouldn't Just, we wanted to. We can compare these bounds with numerical studies and ask which networks most closely approach the bounds. What do they look like? And we can get at this through direct simulation of Markov processes and then optimization of that exact expression that was on the previous slide. Oh, which is valid for arbitrary numbers of states in either group, by the way. By the way. Okay, so you can plot the bounds as a function of the entropy dissipation or the entropy production rate divided by the binding rate, which is we could stylize as the energy consumed per binding event, the energy dissipated per binding event. And basically, we were just multiplying both sides of our inequalities by the expected number of binding events, which is Which is basically scaling out this common dependence on the expected number of binding events. And this puts the Berg per cell limit at two. And I tried to indicate it in yellow. And then our Kramer-Rau bound here at one. And the coarse grain bound kind of interpolates between two and eventually becomes zero. I have a question. Yes, please. The coarse grain bound cannot be beaten because it's not clear whether it's just a property of the coarse grain. Whether it's just a property of the coast graining, or is it simply that it's really not beatable by any means? Right. So it's a property. Okay, not beatable by any. So this is infeasible. So my question is, is it just infeasible as coarse-grained or universally infeasible? Okay, yes, great point. So this is all really highly dependent on, you know, so the observation. On the observation, the degree of observability you're assuming about the Markov chain. So what's plotted on this graph is the feasible and infeasible regimes for networks that are basing our estimation on the density of the time spent in the signaling states, the coarse grain. Signaling states, the coarse grain. The Kramer route bound is on there because it's kind of the idealized case and the limit that you have access to all of the transitions in the network. And so you should never expect like a coarse-grained network to outperform the Kramer-Rau bound. But yeah, it's not a function of the entropy production rate there. That makes sense. It might make more sense if I show If I show like the data on here, so or the simulations on here. So basically, you can. There's a kind of follow-up question from John Beckhofer. Is there an intuition as to why the core screen bound can go below the Krameral? Yeah, it becomes not tight in the large energy consumption limit. As I think my intuition for this is as this will become more clear in just a second when I play this movie, but as you increase the entropy production rate like budget of this network, the optimal network becomes more and more unidirectional, like becomes a ring basically using all of the states. And observations of the time spent in the steady state. In the steady state, the time spent in the steady state becomes more predictable under the large entropy production limit, and observations of this becomes more and more like the Kramer rau bound, or it becomes more and more like informative of the entire trajectory. So, right, so in the large energy production limit, you shouldn't expect networks that are restricted. Networks that are restricted to coarse grain to violate the kind of idealized case where you had access to all of the transitions. But our coarse grain bound becomes loose in that limit. There was a question from Peter Thomas. How is the result for the ring system? So, kind of two slides back, Zeifert's thermal clock precision result? Clock precision result? Yeah, the result for the, sorry, I'm like looking into space. So it's not an application of the thermodynamic uncertainty relation for currents, which is, I believe, what was going on in that paper, but correct me if I'm wrong. So, what the result about the uniform directional rings. Result about the uniform directional rings, it's actually okay. So, it's this dotted line here on this plot here. So, I'll just explain this plot real fast. So, this plot is showing the optimizations of the exact expression on that previous slide to find the networks that do best. And those are the solid blue circles, and then for a fully connected or can be fully connected five-state process. Be fully connected five-state process. Then the open circles represent like the direct simulations, which are obviously all for random processes, which are all above the optimal processes. And so this dotted line here is the analytic expression for those unidirectional ring networks. So, what you're seeing here is that the ring networks, we're still working under the assumption that this is a scenario where we're trying to estimate. A scenario where we're trying to estimate a signal which is modulating the transition rates from the non-signaling to the signaling states, the blue states to the red states, which in this so we're not trying to necessarily try to optimize the first passage time, but it turns out that what am I trying to say? Trying to say in the high energy limit, the optimal processes agree with the unidirectional ring processes. So, kind of what you're seeing is the emergence of a reliable oscillator in the sense that the first passage time through the process becomes less variable. So, it's probably related, but we're dealing with the time spent in the signaling states instead of the In the signaling states instead of the. I'd have to think about it a little bit more. I think the connection is reasonably. I mean, like the maths you've got to the result with is not the same, but there is a connection, right? Which is that basically Udo's result says that if you want something to take a reliable amount of time, you have to put loads and loads of effort into it. Right. And like you get a really horribly divergent A really horribly divergent energy expenditure for being really accurate about that. And your optimal sensors, in the ones that manage to get as close as bottom to the lowest variance, what they're doing is having as little as possible variance in the occupation time of the bound state. Exactly. Precisely. Yeah, that's well said. And those turn out to be exactly those, the ring. The ring networks. So, as this movie is attempting to show, we can kind of just jump onto the last slide. You can ask what do the optimal networks look like as a function of the entropy production rate for this is just for a whole bunch of different numbers of states. And so, as you play this movie, you'll see that they migrate from in the like close to detailed balance case, everything is balanced. Case everything is balanced, they're basically fully connected to the unidirectional ring network in the large energy consumption or energy dissipation limit. For time precision, what do you optimize for? So here we're optimizing for the uncertainty in the concentration estimate based on the time spent in signaling states. So basically, it's So, the basically it's the uncertainty based on the empirical density and the signaling states. And so, this like the literal expression that we're optimizing is this thing for some fixed value of entropy production is some nonlinear constraint for this. For the case that the estimate of the signal C is based on the empirical density in the signaling state. Empirical density and the signaling states by this coarse-grained observer. And then the empirical density and the concentrations are related through that Jacobian I talked about earlier. I mean, the halobacterium, I think, has this mechanism where the timing is actually achieved by a cascade of reactions. So basically, the signal is sent. It's like a domino kind of. It's like a domino, kind of a set of dominoes just falling down, and something like 50 steps. And this seems to be something that happens to make time more accurate. Doesn't mean that if you want to keep time accurate and you have many, many such steps, I would expect that the entropy production should go up with a number of steps and the time accuracy. And the time accuracy goes is probably not growing more than the square root of the number of steps, doesn't it? My question is: does it make sense what I'm talking here, or does it fit together with what you know? Where like the end, I mean, the total entropy production does scale with the number of links in the network. So, as you add, but we're what we're plotting here is kind of a scaled version of that, the energy per term. Uh term finding event. Okay. Like, so this plot is not a variable, it does not show a variability in the number of states. This, what these are showing is the, um, is how this relationship changes as you add more non-signal or signaling states. And basically, what this is telling us is that the The variance in the time spent in the non-signaling or in the signaling states is minimized when you drive it in a ring or you drive it to be a unidirectional ring and you add more states. If that makes sense. And the accuracy will grow with what factor? The courtesy will be. The courtesy. Sorry. So the accuracy always grows with the like you can increase the, it's a little bit distracting. Let's go to the summary slide. You can increase the accuracy arbitrarily by measuring for a longer time or increasing the flux from the non-signaling to the signaling states, which you can do even in detailed balance. Right. But if you want to drive the at kind of a fixed binding rate or at a scaled binding rate, you can increase the or decrease the uncertainty by decreasing the uncertainty in the time spent in the signaling states, which is achieved. States, which is achieved by in the low energy limit, you can't. The best thing to do is actually make this lumpable to a two-state, lumpable in the Kimenian Snell sense. And then in the large energy limit, the best thing to do is kind of just make this more as ring-like as possible at that intribute production level. So you can see that kind of goes through like an intermediate phase where it's trying to be a ring but can't can't. Can't be a ring under that entropy production constraint. Does that make sense? Yeah, more or less. I probably wouldn't read the paper. If you're really into the behavior as a function of the number of states, I know Andre Barrato and perhaps with Udo. Perhaps with Udo, wrote some papers which were like how much more accurate do clocks get as you increase the number of states in the clock and how much more energy does it cost you? If Udo's still in the chat, he assumed he can confirm that. It's not exactly the same system, but the physics has got to be very similar, right? Because yeah, I would love to look into the relationship between these two things because what you see here is like we're trying. Two things because what you see here is like we're trying to optimize the like the estimation precision of some like signal that's modulating some transition rates. And what you see is you know, kind of the best thing is this reliable clock. I think yeah, Tom, I can support this. Yes, so the larger the number of states, the more precise it gets. And it's also our experience that the more uniform the rank That the more uniform the rates, the better this ratio typically is. And adding links through the circle or adding epicycles doesn't really help. So in a sense, the asymmetric random walk is typically the best and it saturates the bound. If you use the bound which still depends on the affinity with this hyperbolic cotant function. Right. Yeah, so that's consistent with. Yeah, so that's consistent with. I mean, this is a slightly different scenario, but it's consistent with like the intuition here: is that the, you know, the uniform rates in one direction is the best and adding links makes this sub-optimal. But at a given entropy production rate, you know, there's these intermediate stages where it has to kind of migrate from having these intermediate links to a more ring-like system. I mean, I think the I mean, I think the, yeah, I think that's almost certainly true. The, the, I mean, it is true. Sorry, it is true. Sorry. What I meant to say. What I think the connection between, or the difference between your paper and Andre's paper with the clock is that in their paper, every state is, in principle, adjustable. In your case, in practice, some of the transitions are you're kind of constrained, right? Constrained, right? When the molecule is out and not bound to your receptor, you kind of have to wait for it to turn up and bind to you. And so you're kind of doing this optimization under the constraint that there's that step that you can't really improve. And so you end up making the states, like you can't really reduce the error rate associated with the amount of time. Associated with the amount of time the molecule spends bound to your receptor by doing exactly this: like going into a circle, driving around the circle, right? Exactly, you can't just sit there and you can't, at least in your model, you can't sort of hold out a magnet and attract molecules from the solution to sort of increase the reliability with which you find them. And so, probably the differences that you will find with respect to. That you will find with respect to Andre's results will be that you have that constraint and that he doesn't. Yeah, and there is this further constraint of having two different types of sites. Yeah. I mean, in our case, you know, in a sense, in the optimal case, all sites are equivalent. Yeah, so I think also the difference is we weren't trying to optimize. Differences, we weren't trying to optimize for reliability in the like, um uh right, but that's your Kramer-Rau bound, right? The Kramer-Rau bound that you get is one over n bar, yeah, right? Yes, that and that is the bound where you have no uncertainty in the bound time and the standard exponentially distributed arrival times for the stuff coming out of sort. For the stuff coming out of solution. Right, exactly. So, so you're what although in principle you didn't impose that upon the system, that is the result that is falling out of your system. I think. Yes, yes, I agree with that. And so, and then, and so, therefore, that's what's giving you the thing that kind of looks like a bit like Andre's result, but with the fact that you can't play the game with these transitions. The game with these transitions where the stuff is coming out at solution because you're kind of just waiting for it to turn up, right? Um, I mean, I think the result, like this formula you have on this page, I think it's really, it shows that perfectly. The two results you have on this page show that perfectly. They really, you know, they make the story really clear. That's the point I'm trying to make. So I think they're really nice. Yeah, I think I agree with that. Yeah, thank you. Yeah, thank you. Oh, sorry. I guess I should probably, before we talk a little bit more, I should probably acknowledge my collaborators. So Shubi Lahiri is my project partner on this and he's a mentor and he's a staff scientist in the Ganglu Lab. I think he's here as well. So if he has anything to input. Guess anything to input. And then our PI is Suri Ginkule, and our paper is on the archive, obviously. And thank you for organizing the conference. But we can now talk. Thank you. All right. Yeah. Thank you, Sarah, for that really interesting presentation as well. I should also mention, I forgot to thank Udo for the talk in the morning. But yeah, but we can now kind of open up the, you know, for this. Yeah, for general discussion. Okay, so yeah, general discussion if there's any more questions or so I've talked a lot, but I have more things to say. Oh, that's great. I'll let other people go first if they want to. If not. Okay. Too late. So it's not very effective, right? It's not very effective, right? As a method of reducing the uncertainty of this process, you can burn infinite amounts of free energy and you're getting a factor of two in your error, basically. Yeah, I mean, from a biological perspective, this is maybe not a super useful result. Sorry. I was going to go on and say I think it could be more useful in the idea of kinetic. The idea of kinetic proofreading, right? So, fundamentally, when you're kinetic proofreading, you've got two different things that's binding to maybe not a receptor, but somehow we can treat model it as a receptor. So, you've got two different ligands binding to a receptor, and you need to distinguish between them. And there's a really big penalty for occasionally getting the wrong one, right? And if you're And if you're just relying on the lifetimes being exponentially distributed and one of them is longer than the other, then it's really difficult to only pick one and not pick the other one. Right? Right. Yeah. But if you're able to have much sharper distributions in the amount of time the thing spends bound, then you can it'd be much easier to pick A rather than B. Rather than B, perhaps. And you really do get a benefit in that case for going from, let's say, you're correct 99% of the time to being correct 99.9% of the time. That is a real sort of like biological benefit. Whereas in this case, going from like pushing that limit doesn't really get you much more back, if you feel what I mean. So I wonder if you can basically apply. So, I wonder if you can basically apply the same maths to those sort of questions and then get more obviously functional uses of the free energy. Definitely. Yeah, that would be really interesting to look into. Yeah, because it does seem like this is probably a minute improvement from the cell's perspective or from like a cell sensing perspective. I think the more interesting, like the take. The takeaway from this is not anything all that fundamental about cell sensing, I don't think. It's just more like an application of ideas from stochastic thermodynamics and large deviation theory. So it'd be really cool to apply it to kinetic proofreading ideas where, like, under some entribute, you know, some entry production or like dissipation budget, there's a Budget. There's a limit to the variant, like the how distinguishable you could make the occupation time of two different two different things you're trying to distinguish. Yeah, you're getting it. Yeah, yeah, it's exactly what I'm saying. I mean, people have looked at the thermodynamics of kinetic proofreading since Hopfield, right? But I don't think they've looked at it with this kind of general formalism. I mean, I'd look up people like Like I've now forgotten is Murrigan and Leibler and people like that. But yeah, I don't think they've looked at it in this general setting. And you might be able to say some similar, you know, derive some similar results that just perhaps apply more directly to biology. I don't know. Right. The results are really nice. It'll be really cool. Okay. Yeah, I'll think about it. Okay, yeah, I'll think about that. About that more. Yeah, I'm not super familiar with like the kinetic group reading literature. Anything else? Does anybody have any like general questions for Professor Sister for me? Could I maybe ask a question? Could I maybe ask a question? So I'm Peter Einstealda. For some logistic reasons, I jumped in sort of halfway your talk. My apologies for that. But if I remember the paper by Lang and co-workers, right? So they also make the connection with maximum likelihood estimation, right? So they precisely make the point that by putting in more energy and by driving your system then through a cycle, you can make the bounce. You can make the bound state more deterministic. So, the only uncertainty that remains is the uncertainty that you cannot control, namely the diffusion-limited arrival of the ligands to the receptor. And then you arrive at basically this result that was derived by NGRES and Wingreen, which they then framed as maximum likelihood estimation. So, is this also your perspective on? Is this also your perspective on this? Yeah, that's. I'm not sure where you came in, but that was basically the intro of the talk. Can you see the slide right now is the figures reproduced from that language. And they studied this in the particular case. It's basically just a less general case of our result. They studied it in the case of networks that are constrained to be ring topologies. And what our result kind of shows is that in the low entropy production limit, it's actually not. Limit, it's actually not optimal to have a ring topology, but it becomes optimal as you have more, as you drive this entropy production to be large. And right, so they wrote down an exact expression for the uncertainty based on the lifetimes and the signaling states for ring networks, and then looked at this, like, did what I was describing for our numerical figures, is what I understand, anyways, they opt. I understand, anyways, they optimized at some fiction reproduction level and got this relation, this interesting relationship between the uncertainty and the dissipation. And so what we were trying to do is study that at a theoretical level, which is this bound, I guess this bound here on the right-hand side for the coarse-grained observers, kind of like an extension of their. Of, like, an extension of their situation, but for an arbitrary network of signaling states. And we found a bound in terms of the entropy production rate. So we can more theoretically think about that relationship, which is kind of interesting. So, yeah, that was, this is great. Thank you for those are great points. Yeah, and that was kind of the motivation of this. Um, that's kind of the motivation of this whole, yes, thank you. Very clear. Um, another question is perhaps that, right? So, one of the big challenges in biophysics is to connect these more abstract ideas to actually concrete biological systems that implement some of these ideas. So, have you found any examples, perhaps? Yeah. Yeah, so are you talking about like, is there any reason to suspect that like receptors in nature go through multiple states and are out of equilibrium? I think there is like there's evidence that receptors in biology are highly variable and some of them do execute multiple states. But yeah, this is not at the level of comparing anything with data or observations. anything with data or observations. This is kind of just more of an abstract. It'd be really interesting to think, especially if somebody with more biological background knows a lot about this, I'd love to talk more about that. I really recommend it at these to look at these timing cycles in bacteria. I know that halobacterium must have it. I do think E. coli has it too, but I'm not sure. I think E. Pola has it too, but I'm not sure. Timing cycles in halo bacteria. The halobacterium basically is a bacterium that lives in very saline solutions, let's say Dead Sea or something like that. And it is basically navigating by, if I remember correctly, by differences in ultraviolet light intensity. Light intensity. So because it's it's small to to navigate through um basically spatial gradients, it uses a temporal gradient of its movement to decide whether to tumble or to go straight. I mean, similar to your example. Okay, so it's not chemosensation at all. It's phototaxis. It's phototaxis, but it's temporarily distinguished. So basically, it can't measure. Distinguished though. So basically, it can't measure along its body length. It doesn't see a gradient difference along the body length. The difference is between how much it travels. So it sees differences in the intensity of ultraviolet light during its travel. And this temporal difference is essentially measured by a cascade of cascade of basically, I think, identical, identical. identical identical networks okay yeah so a question might be why why bother having a cascade of identical identical elements and yeah it's timing I think the timing is is uh it stabilizes the timing right yeah right so we might have something to say about that in terms of like if you have some energy constraint well it's hard to say I mean it's a very small book term and I Small bacterium, and I just think that it's I when I saw your cycles, I thought immediately that this, um, that why would you not build a clock? Okay, why wouldn't you build um a multi-hierarchical clock? So one cycle, the next cycle, and maybe there's a reason for doing that, and that's that's your thermodynamic reason. When you're far far from the thermodynamic limit, uh, perhaps the clock is much better because then you can. Is much better because then you can really very flexibly choose your resolution over many scales. But if you're close to thermodynamics, then perhaps it doesn't make sense. Right. Yeah, that's a great idea. Just a guess that I'm making. And we're talking here about 50, 52 or something steps. So it's not that large. If it were a thousand, it probably wouldn't make sense. Or it would be the effort to build up this mechanism is probably. Up this mechanism is probably energetically or entropically so high that it makes sense to actually decompose it to modularize it. This would be my guess here. Very interesting. Yeah, thank you. Okay, I'll think about that a little bit more. So we're coming kind of to the end of the discussion section if there's any last-minute questions. If there's any last-minute questions. All right. So, yeah, I'd like to thank the speakers again and hopefully see everyone tomorrow.