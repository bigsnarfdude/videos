I would like to offend the invitations from the organizers. So, I'm Hen Chen. I'm currently a PhD student at the University of Calgary under the supervision of Bertha Chiu and Professor Alex Peterski. So, today the thing I'm going to talk about is something that I discovered during my first project. And I'm going to talk about some historic solutions of a class of second-order HP equations in the host science phase. So, actually, it is quite lucky for me to present after Professor. For me to present after Professor Perator's talks because I will be using a lot of his materials, and it is actually something I discovered after reading his papers. So let's see. So before I go into the problem settings, I will first of all just quickly give an overview of what the water science space and what will be the notion of derivative that I will be using. So the water science space is So, the Mosesine space is actually the space of probability measures with the so-called Mosesine distance. And the notion of derivative I'll be using is the so-called Lyons derivative. So, the main idea of Lyons derivative is that for some functions acting on the measures, what we do is that we leave it to the space of random variables. And the space of random variables is a Hubert space. And on that space, A Hilbert space, and on that space, we can talk about the notion of derivative in the sense of like persuasive derivative. And if that admits a continuous percentage derivative, then we say it is L-dependential. And for so just like it's quite technical, right? But just remember, we'll be using like partial mu f to denote the first order derivative and partial mu squared f for the second order derivative. And the control problem we'll be looking at is some standard. Two problems we'll be looking at is some standard like standard dynamics. Just remember, we'll be using B for the drift and using sigma for the volatility respective to the syncretic noise. And here we will have a red turn, which is the common noise. So we're using like the sigma zero to denote the volatility with respect to the common noise. So I'm here, just keep in mind that our common noise can only take the time into our input. Time into our inputs. So, and we are subject to the cross-functional where the f stands for the running cross and the g is the terminal cross. And finally, we define the value function v to be as usual. So we are taking random variables as the arguments. But there's one thing that's nice about this is that actually this value function is low invariance in the sense that if two random variables have the same law, then the value functions. Same law, then the value functions give you the same results. And therefore, you can actually think of like this value function is actually acting on the Wolserstein space instead of the space of random variables. So now let me quickly overview what's the notion of restorative solutions. So the notion of restorative solutions dates back to Bangladesh. Show these solutions dates back to like Randall's and Leons back in the 1980s. And just like in the past decades, the mean field theory has developed really rapidly. And this is really natural to consider the restorative solution theory of HIV equations on the water science space. So there are mainly two approaches to do this. And the water science space is well known for its lack of local companies, which is crucial in theories. Um, soil solution theories. So, there are mainly two approaches to deal with this. The first approach is the so-called lifting to the Hilbert space approach. So, it's just like what we asked for the derivative. So, they just lift the whole equations to the space of random variables and where on the space of random variables, it is a Hilbert space, and the theory of our solution has already been established. So, and the other approach is the so-called intrinsic. approach is the so-called intrinsic approach. So in this approach, so they just deal with like, they will deal with the equations on the Watson sign space directly. So, and in the paper of Wu and Zhang, they use they require the maximum to be taken on some compact subsets of the Watsonstein space. And in the paper of Crosswell and Feng, they make use of the verbational principle together with some finite dimensional approximations to tackle the problem of life. To tackle the problem by lack of local components. And in the paper of Beretta, Elkin, and John, so which is like Professor Beretta has already talked about it. So they made use of some generalized Ishi lemma in order to establish the Risori solution theories on the Mozilla space. And for more, you may consider looking at the paper by Samuel Zhou and Benjamin, and the paper by Tu Zi, Zhang, and Zhou. Um, by Zuzi, Zhang, and Zhou. So, our work is a generalization of Crosswater and Flam. So, um, so what we did is like we will be so in the paper considered by Proser and Fan, they are mainly considering about the dynamics without this red term. So, our paper is that we will show we can actually incorporate this red term into their method. And well, um, it's quite a technical one, so I mean, both. Technical ones. So, I mean, both of our papers are quite technical ones. So, but I don't have enough time. So, I hope that I will convey the main message to you. So, now let's look at some standard assumptions. So, what we assume is quite mild, to be honest. Like, we are only assuming the B, sigma, sigma 0, F, and G, they are just like leafless, continuous, and also bounded. I think despite standards. I think it's quite standard in the literature of lab restorative solutions in the water science space. And on top of this, we have to assume something more. So here we are assuming that we should also have some W1 Watsonstein literature instead of the W2 literacy. So you will see why is it in a minute. So the main purpose is because it is required to erase some estimates of some finite dimensional. Of some finite dimensional approximations. And it is standard that we have the following dynamic programming principles. And these dynamic programming principles actually leads us to the HJV equations. So, well, it is quite standard, but just like as the red turn. So the return here is actually coming from the common noise. So, and well, and that's why I say I'm lucky to have like Professor Bireta presenting before me. Professor Parrett presenting before me because I will be exactly using his operator H here. So, so yeah, it is of like some something like finite dimensional point of view. And also, in my interpretation, I would just think of it some of some sense of like second order derivative in the weak sense. In the sense that if your function u is, if it is actually smooth enough, then actually you can just have the below relation. Have the below relation, which, and you can see that there is a section derivative of the with respect to the measure here. Okay, so our goal is quite simple. So our goal is just to show that the value function v is a unique restriction solution to a restricted solution to the above HGV. This is our goal. Okay, so whenever we talk about withdrawal solutions, so Solutions. So we have to think about what our test functions to be. So in our case, we choose our test functions to be like PC112. So which consists of all the things in one and two. So for the definition in one, it's quite standard for the first four steps. But for the wireless stuff, I'm requiring it to be like HF differentiable and continuous. And for the second step, for the second definition, I'm here. I'm requiring it to be like it has a more section moment bar. So, in the standard literature, we usually use this set of test functions where we require it to be like section order differentiable. And also we have the pollen wise bound here. So it is obvious that this set is stronger than this set, right? And usually the solution of The restorative solution theory is, I think, it's a balance about how do you choose test functions such that you have both the existence and the uniqueness. If you choose too much functions in the set of test functions, then it is hard for you to get existence. But if you choose too little, then it is hard for you to get the uniqueness. So here, in our case here, In our case, here we have to exactly choose this test in order to guarantee us both the existence and uniqueness. So here, so let's look at our definition of restorative solutions. So luckily, we are able to use the almost typical Grand Dog-Leon's definition of restorative solution theories. And here we are requiring our site to be licensing this set of test functions. Realizing this set of test functions. And we say it's a something like, well, it's standard in the literature of restorative solutions. So let me just quickly go through it. So now it comes to the existence, because I've chosen something that is not usual in the literature. So it creates a little bit difficulty for me to show the existence. However, the statute of truth is like this. I mean, it's always examined this. always examine this it's always to examine these um difference quotients and then we make use of the dynamic dynamic programming principle and a relaxed eto lemma so here a relaxed eta lemma is needed because um you kind of imagine that we need a near eta lemma for um for the things that that is hf differentiable instead of like having the second order derivative and that's why we need to uh relax the tolerant and Less detolent. And because if you remember the form of the HJB equations on the mossotized base, it is non-local. So at some point, you expect that you have to have some like dominator chromogenic theorem in order to pass the limit. But here, if you look at this one, we don't have the dominators, but we only have this. But luckily, we have the second order bound. So we can just simply make use of the retirement conversion. The retarded convergent theorems because the second moment bound gives us the uniform interpretability for us to pass the linear into the integral, and then we can get the existence. And now let's look at the uniqueness. So uniqueness is, I think for the solution of resolutive solution, the uniqueness is always the hardest part. So what we'll be proving is a comparison theorem, which states as follows. States as follows: say, let u1 and u2 to be some bounded functions such that they are restorted, um, subsolution and supersolution, um, respectively. That it holds that u1 is smaller or equal to u2 on the space, and hence, um, the result solution of the HJB equation is unique. So, um, how do we prove it? So, we what we prove is that we shall prove that u1 is more than or equal to v and v is more than or equal to u2, where v is our value functions of the. V is our value functions of the HTV, so of our control problems. So we start with some standard contradictions. We assume there exists some point such that u1 minus v is greater than zero. So here we replied that u1 minus v, the maximum of u1 minus v could be achieved, so that we could use the definition of restorative solutions to draw the contradictions. And on top of that, we also require our v to be nice enough. our v to be nice enough because if we if you remember um in our definition we um in our definition here so we require say if you want to make use of definition we replied our v to lies in this space but but sadly it is hard to like i mean the maximum is hardly is hardly attainable on what's a size phase and the v is like i mean we we never know whether it is that nice or not so the way how how do we do So, how do we deal with it? The way we deal with it is like this. So, we will adopt the approach as in Parson and Ven. So, where they make use of the variational principle, which the variational principle, which says that a bounded troll-distance function can attain its maximum or minimum after the perturbation of something of a metric lie function, which we try to be a gauge function. And in this way, we can attain the maximum. We can attain the maximum or minimum. And in order to make the function v to be smooth, they make use of some smooth finite dimensional approximation to v, which we shall see in a minute. So first of all, let's look at like what is a gauge function. So a gauge function, if you look at the definition, is quite complicated, but just remember, it is something, it's something that S line metric, but without a Like a metric, but without the triangle inequalities, and we usually choose it to be smooth because the waste size distance is not smooth. And if we choose it to be smooth, then we can kind of like put it into our test functions. And so a dauge function is basically a metric-like function that dominates the original metric in the first sense. So, in our case, we will choose our data function to be the one. Digital function to be the one introduced by Roberta, Akron, and John. So, what we'll be using is that we'll be using the Gaussian regularized slice was a stein distance. So, the main idea of this metrics like this. So, let's say we are living on Rd, right? And then we can project our stuff into our along the ball. And then we do the same thing. And then we do the simply sum up all the cogressions around the ball. And then we do the Gaussian regular rise. This is the so-called Gaussian regularized Wasa sign distance. So you may wonder why do we have to project into R1, right? So the reason of this is like that there is a specific formula if it is in R1. So if you are familiar with the literature of the worst time distance, Of the waterside distance, in R1, we can explicitly write down the optimal transform map. And with this written-down transform map, we are able to derive the continuity of the derivative of this row sigma if we choose the row sigma to be our gauge function. And on top of that, we are able to show that the H row sigma is actually bounded, which means that we can actually put this. Which means that we can actually put this thing into our test function. And you may wonder why doesn't TOSO and FEM do so? It's because, like, the gauge function, they choose, it simply blows up if it is added by H. Oh, okay. Okay, yeah, here, let me put the principle here. It's just simply saying that if you perturb your function by the dish function, then you can get your maximum point. Then you can get your maximum point. And here is a conclusion of the boundary that we derive. Okay, so for the finite dimensional approximation, this was simply the n-player games approximation, which is by standard, because like for this term, it's by standard. And we have the modification for the Y. The reason we do the modification is because we want to make things, we want to make sure that it is moved in a sense. It is moved in the sense that we can put it into the test function. And then we should simply define the value function of these MP approximations. So be careful that here we are on the space of measures. But actually, it could be shown that there is some function v bar such that we have the following representation. So, and I mean, it's expected that when we take the v inverse, it gives us back to the value function. Give us back to the value function itself. So under the assumption A star, we are able to show that we have this estimate and the following estimate. So actually, assumption A star is to guarantee this one. And this one follows from some standard parabolic literatures. So now let's go back to the proof of linear. What we shall prove is like u1 is smaller than v and v is smaller u2. And then by point prediction, we assume that there is some point. We assume that there exists some point such that this is greater than zero. And then we just simply make use of like approximations. We approximate v by v epsilon n. And then if we choose the delta small enough, this thing could actually be guaranteed to be greater zero. And then we make use of the variational principle, this thing is maximum at some point. And then we just simply make use of like, we take this to be our test function. And from the definition of resolved solution theory, it's Of resolution solution theory, it satisfies the PDE at some points, just like replacing the equality to inequality. And from the regularity, we have derived. So after plugging into the PDE, it is still bounded. And then because it is still bounded, so we can control the magnitude by just by just taking the delta to zero. And then we take all the things to infinity and zero, respectively, and we are finally able to conclude the contradictions. With the point fictions. Yeah. So, this is how we establish some theory on the second order stuff. Thank you very much for contemporary.