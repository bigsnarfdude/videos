It's my privilege to introduce Sammy Natur, who is at Veritech, VeriCast. And gosh, Max Point, Velassis, VeriCast, things have changed. But thank you so much for speaking to us today. Are you able to make your slides full screen, Sammy? Excellent. Great. Great. So please, Sammy, why don't you begin? Sure, no problem. I just want to make sure that you guys can't see it full screen, right? We can. Okay, okay, great. So good morning or good afternoon for those now on the East Coast. My name is Sami Natour. I am the Vice President of Engineering at Veracast. As David mentioned, we previously were known as Velassis and then also previously known as Max Point Interaction. And then, also previously known as Max Point Interactive, there's for those in the North Carolina area, we have a very large presence in the triangle. So, so yeah, so what I wanted to talk briefly about today is how we have built our platform with research and development in mind, but also being able to make use of all the resources that we have in order to scale well. In order to scale well, to do things as efficiently as possible, and then ultimately, right, deliver success for our advertisers. So, what I briefly like to talk about is who Bericast is, really just kind of level set on what programmatic advertising is, and then talk about the various execution methods that we have on our platform and the different types of data or models that use each of those execution. Those execution models. And then at the very end, just talk about why that matters. So, you know, my experience on the engineering side is I work in tandem with our data science team that are doing all of the hard calculations and data analysis and building models to help us better optimize our campaigns. Where engineering comes involved is how do we take what our scientists have created? Scientists have created and be able to scale it to the needs of hundreds of different types of campaigns, each with very specific targeting criteria and other benchmarks that we're attempting to meet for our clients. So, first, who's Vericast? I think it's important to know what's in a name. So, very, the Latin definition means true or true. Definition means true or truth. And then the standard definition of caste, right? To shine a light on and to move forward. So, what we do is we're a marketing solution company that connects consumers to businesses. In a nutshell, that's what we do. And we like to do it in the most ethical manner possible. We try to differentiate ourselves from your traditional advertising companies that folks may think of in that, you know, we do things in a manner that is. In a manner that is safe with people's data, and that we are keeping user privacy in mind in everything that we do. VeriCast does advertising across the spectrum with the exception of earthly radio and broadcast TV. So print-related products, digital advertising, right? Banners, video, connected TV, all of that. We do that. Social, search, you name it, except for those two things. That's what we do. We want to do it, though. We want to do it, though, in a meaningful way, right? We actually want to engage consumers and connect them with a business for whatever it is that that business is attempting to sell, whether it's a product or whether it's a service. And then what we want to do ultimately is fuel commerce, right? We view ourselves as a mechanism to help the economy move forward. So what is programmatic advertising? At Vericast, put simply, At Veracast, put simply, our digital marketing institute folks put together a very simple definition is to use the software to buy digital advertising, right? That's what it is in its most simplistic form. How do we do that? We do that through the use of APIs, most notably the IAB OpenRTB specification. When do we do it? We do it all the time. Like this stuff never shuts down, if you will, right? The internet is always on. Is always on. People are connecting and doing things. And with e-commerce, right, shopping really never stops. Where does this happen? This happens on all sorts of connected devices from computers to phones and tablets, smart TVs, set-top boxes, smart displays and speakers. And then something that I like to point out to people that they may. I like to point out to people that they may not realize, but you know, if you go to your typical pharmacy, like a Walgreens or Rite Aid or CVS, you'll see those blood pressure monitor machines, you know, the ones you sit in, you put your arm in, and it has like a display. Believe it or not, you can programmatically buy advertisements on those type of screens. And that's what we define as digital out of home. So not many people know that, but I always find it's a little interesting tidbit to throw out. It's a little interesting tidbit to throw out there because it really does get the mind thinking: wow, what are the other mechanisms that exist? Another thing that I will point out are the digital billboards that you see in New York City or San Francisco that are by bus stops or major areas of transit. You can also programmatically buy advertisements to show up on those screens as well. So, Tammy, before you leave this slide, could you say a little bit about why IAB opened? About why IAB open real-time bidding API is your preferred choice? So that's a good question. It is our preferred choice only because the overwhelming majority of supply-side platforms or ad exchanges make their supply available through that specification. So Google also supports it, but they traditionally lean on their proprietary protocol that they call their protobuf. Protocol that they call their protobuf. We do use that at Vericast as well, but we're in the process actually of moving off of it to OpenRTV, just because from an engineering standpoint, it really reduces complexity in our bidding logic. Okay, thank you. Yep. All right, high-level overview of real-time bidding. So everything that we do at Veracast across all the different media types, we do through real-time bidding. We do through real-time bidding, and what that is, is you have ad exchanges that have connections to publishers. Publishers are owners of content, so you can think of them as ESPN, MSN, CNN, right? Fill in the blank, just your traditional websites or your mobile apps or games, those are considered publishers. They make placements on their web pages or mobile apps available via the OpenRTV protocol through an exchange. Through an exchange, and the exchange will broadcast out that opportunity to all buyers that are integrated with them. And through that integration, an auction takes place where buyers will determine if this request is valuable or appropriate for them to buy for a campaign they're running. And then they will bid whatever price they deem to be appropriate for that specific opportunity in the hopes that they win that auction, meaning they can display their ad. Auction, meaning they can display their ad for that opportunity. And then subsequently, right, the exchanges will let you know, hey, you won that auction. And in some cases, not shown here, you lost, right? And maybe why you lost. So what information is available to you at the time you decide to make a bid or not? A lot. A lot of information is available. So in general, there's over 250 signals, we call them, or attributes of that operation. Attributes of that opportunity that are made available to all the buyers. And it can be a wide variety of things. It could be information about the device in which the advertisement is going to be displayed on, right? Is it a phone? Is it a computer? What operating system is it? What browser is being used? All the way to information about the user. Is there a cookie ID? Is there a device ID or IDFA? Approximately where that user is located. Sometimes we'll get. User is located. Sometimes we'll get high-level location information, like a zip code or a digital marketing area DMA. Sometimes we'll even get GPS coordinates as well. It really just depends. A probability about gender or age or income? Some of that information may be provided, but I will say with all of the different privacy regulations that have been coming about and maturing over time, we are seeing some of those signals. We are seeing some of those signals actually fall off. Thank you. Yep, sure. And then, on average, depending on the opportunity, you know, we see about 150 signals just because there are certain attributes only available if the opportunity is a video ad versus a display ad, right? So, not everything is available in 100% of the requests. But the one thing I will say to keep in mind is that publishers and exchanges can And exchanges can provide custom information or custom data in those requests through an extension. So, something unique, maybe they want to enrich the data to make their opportunity more valuable to buyers. They can do that via an extension. At VeriCast, we handle on average about 1.8 million requests per second. Second. And 100% of those requests is analyzed by our bidders to determine whether we are going to bid or if we're just going to say we're not interested. During that process, we're also logging the information that comes through those bid requests as well to help accomplish a few things. First and foremost, we actually mine that data. So we actually have algorithms and models that are building interest related segments based on. Segments based on who they're seeing navigate certain websites or what apps they're using. But we do all of this and we make a decision to spend money in 6.8 milliseconds. Just as a comparison, the average time it takes for a financial transaction to occur is 10 milliseconds. So we are deciding when to spend our money faster than large sums of money are being sent between parties. Sent between parties. All right, execution models at Veracast. So we have three different ones. First and foremost is what we call the real-time path, right? The real-time path is the bidder. What does the bidder need to know at the time a request is made for whether we're going to bid or not bid? And we need to get that done. Our benchmark internally is we have to be able to make a decision under 10 milliseconds. And 10 milliseconds. And if we decide to bid, we have five seconds to let every other bidder in our infrastructure know that we bid on this opportunity and who the user was, where the user was, what website or app they're using. And we do this for governance, right? To make sure we're capping frequency or if we're doing day parting where you only run your campaign at specific times of the day for days. Specific times of the day or days of the week. That's done here. The next model we have is what we call a short-term offline model, where we're using our clusters to process data. A model typically is run, and there is some output that is produced. And that output will be produced and sent to our bidders in under two hours. So there's a specific cluster that handles this type of short-term path. And typically, this path. And typically, this path is used where the information we get in BIG requests could be useful for that model, but it does not require any other data source other than what we have available natively in the platform. And then the last one is what we call long-term offline, which is essentially the same as short-term, but it requires the use of somebody else's data to make something happen, right? And the reason why I thought this was interesting to present. Why I thought this was interesting to present here is because as you guys look at how to create different models that achieve a different thing or how you would conduct AB processing, it is important to understand what your capabilities are in how you build that model. Knowing those things will allow you to leverage different resources in the most efficient manner possible, but it could also be a lot more efficient. Efficient manner possible, but it could also open up doors to how you construct your model or how you conduct A-B-related testing. And so we're going to get into that in these next few slides. So before you go there, if I can ask another question, do you have third-party verification of transactions in your ad buy stuff? Yes, absolutely we do. And is it one third party or are there multiple third parties that are involved? Or are there multiple third parties that are involved? We use up to, sorry, with the blurb. We use up to four. And I will say, some of that is more client driven where they may have a preferred third party that they use. And then in some cases, we will leverage a third party based on what the campaign is trying to do. Thank you. Sure. So what gets stored in the real-time path? Typically, it's Stored in the real-time path, typically it's attributes that are not predicted to change frequently throughout the campaign. So, what does that mean? Typically, it's the configuration of the campaign. What's the targeting criteria, right? Is there a specific audience or segment that we're going after? Ideally, those don't change too much, but they always need to be made available so that the bidder knows what it is doing. So, people always ask: well, if your audience segments are at the bidder, Audience segments are at the bidder. How do you adjust to what's considered a valuable user, right? Because someone may all of a sudden express interest in purchasing a specific product, you know, five seconds later. We have a process to do that that I'm going to get in a couple of slides, but we do have a process for that. And then A-B testing. In working with our data science group, one of the things that we've built into our bidder is what we call online experiments, where you're able to Experiments where you're able to construct a specific profile that you can run against the same campaign, where you can allocate a number of impressions or a specific amount of the budget to test different strategies in execution. And then, you know, they'll get their results back in near real time to understand what is performing better. But we have the ability to construct a strategy and push it out just so that they can get a more real-time. A more real-time idea of what their updated strategy or model is doing and how it's performing. The reason why we have very limited data in the real-time path is because we want to be the fastest in an auction in responding, but we also want to be accurate because those bid requests have criteria from publishers that say, I'm ESPN. I don't want to show advertisement. I don't want to show advertisements for Fox Sorts, right? Or I don't want to show advertisements for TNT basketball, for example. So we also have to honor all of those different things as well from those publishers. So the most simplistic way we can make the real-time path, the better. Another quick question. If you do not mind, Sammy, I'm asking a lot of questions, but I find this stuff fascinating. Okay. If you have two contracts to show ads, how do you decide which user is going to see which ad? That is a good question. There's a variety of variables that make that determination. Some of it's going to be based on a historical performance of a campaign. So if we know that a specific user isn't seen as frequently as someone else, we may prioritize. As someone else, we may prioritize that user higher than the other. In addition, some of these signals that we get during a campaign could signify that this user, while we believe may be interested in this thing, has not demonstrated to us that they are as interested in this thing. So we may try to either push more in front of that user or really back off, right? Or really back off, right, as a result. Really just depends on what the goal is. There's also pricing implications as well, right? We have a concept at Vericast called expensive users. And it could be those users that we don't see as frequent, or it could be those users that convert on an action, but the action is what is deemed to be an expensive action, right? So if we're trying to do a campaign for, let's say, a A campaign for, let's say, an automobile dealership, and we're trying to drive people to their website to sign up for a test drive. That is an expensive action to do because, man, you have to really hone in on that user and drive them through to the website and to fill out the form to say, I'm going to test drive this thing. Right. So, there's those variables that are considered. Thank you. Yep. Short-term processing is really. Processing is really getting data specifically about attributes of performance for a campaign. So, clicks, placements, whether they're viewable or not. If we're trying to conduct some type of retargeting activity, that's done here. And then how we pace. How we pace a campaign is based on how we're performing, right? How often are we bidding? How often are we winning? And when we win, do those turn into actual impressions? And again, this has to have a quick turnaround because it's we're optimizing for performance of the campaign, but we need to do it in a way that we're not adding latency to the real-time path. And then the long-term model, right, again, is if you have to use someone else's data that's not our own. And so at VeriCast, we tend to not demonstrate. Demonstrate our performance based on our own data to a client because I can tell you that I'm the best vice president of engineering in the entire world, right? But unless you have somebody else that's saying the same thing, then it becomes a lot more believable. And so what we do is any type of attribution of an action, any type of impression. You know, impression record is what we get to with discrepancy. We may say we served 100 impressions, but the ad server may say actually only 90 took place. We adjust for those, but we want to bring in that third party, David, as you alluded to, the verification aspect, to really dictate how well we are doing from a non-biased third party. The other thing that takes place for a lot of the longer-term processing jobs really. Term processing jobs really relate to our graph in determining sentiment and interest about a specific thing, short-term, long-term, purchase history, how we map IP addresses to geographical locations. We also comb through every single GPS-derived coordinate that we've received and we validate them. Because believe it or not, sometimes you will get some corrupt data. Some corrupt data from a publisher where the point of interest is in the middle of the Atlantic Ocean. And that actually has happened, which is why I have that example ready to go, because it's funny, but at the same time, it's, you know, you have to build out your platform and your models to account for those edge cases as well, right? And then what I call our special sauce, which is how we hone devices, how we determine what devices are in the same. We determine what devices are in the same household, how we construct neighborhoods, right? Because that all aids in our targeting and helping identify users that would be interested in a particular product or services. The one thing I want to call out, because I think it's important for folks to know doing R ‚Åá D, is that most third parties will certify their data once a day. So we typically, you know, run up to a 24-hour delay from when we run an impression. Delay from when we run an impression at you know 12:01 a.m. to when we actually get a third-party interpretation of that impression, right, that we can use. So going back to, well, how do you easily account for changes in user behavior and who's interested and who's not or who would be considered a user that would be valuable for a particular campaign? We do this in a very unique way. Very unique way. Some may believe it's overkill, but we believe it actually provides capabilities to our data scientists to be able to really produce models and tests and get a very quick perspective on how that model is performing or which test is proven to provide better results. And we do that through a custom-built key value store. And we have Value store. And we have many of these in our environment, but they're essentially a computer that has 384 gigabytes of high-speed RAM. And so every user we know about in the entire United States is loaded into this key value store. And so every few seconds, right, depends on changes that are happening, but those messages get pushed out to this key value store as they happen. Right, as they happen. If a model requires that there be a test group, if you will, those groups can be dynamically created and pushed out to this storage unit as well. Our bidders connect to these key value stores over a high-speed, low-balanced network to where the responses only add one. Only add one millisecond round trip, right, to our overall performance time. Yes. So this is why I thought this presentation would be helpful is I know every place doesn't have this, but I know that there are a lot larger organizations, like you can pick on Google, for example, that have much more resources and more capital where they can do fancy things. But really knowing what you have at your fingertips to work with can drastically change. To work with can drastically change how it is you tackle a problem or how it is you try to validate a solution right to a problem. And then lastly, I do want to talk a little bit about why it matters. And we have these models, these execution models in place because processing takes time and time equates to money. And that money that we're spending or not spending will impact the performance. Will impact the performance that we deliver for our clients, right? We want to give them the biggest bang for their dollar. And so props to the team that handles this, but our core clusters are very large. And mind you, I know the Facebooks out there have a couple hundred petabytes, but they're also dealing with rich media, images and video and things that are heavy. We're really talking about. Are heavy? We're really talking about text. So we've got 11 petabytes of storage, over 13 and a half thousand cores, and a total of 48 terabytes of RAM that power these clusters. And what's impressive is that we have 40,000 daily jobs that are executing over 3,100 core jobs that are doing all the work. And what are these jobs? Some of these jobs are maintenance related, right, that engineering uses, but the Right, that engineering uses, but the overwhelming majority are jobs that came from data science through their research, through their testing, that engineering then extrapolated and built into a more scalable solution that we perform on. And so that was it. Just a high-level overview of kind of what we do and how we tackle dividing up our resources. It's amazing. I've watched you all grow for years now, and it's astonishing to me. Let me ask a little bit about the data scientists that you refer to. What types of things do they address in their sort of daily work? The type of things they address. So I'll pick on viewability, for example. So viewability, right, is, you know, was the advertisement viewable by a The advertisement viewable by a human being, right? Plain and simple. And you would think that something as simple to communicate as that, right? The definition, would translate into some form of unanimous way in terms of how that is determined. But all of these verification vendors that are out there will determine viewability in their own unique way. And sometimes they And sometimes they don't agree on whether the exact same impression was viewable by a human or not. And so, one of the things that our data scientists do on a daily basis is as they're getting this information from those verification partners, as they're getting information from our own systems that we're producing, they build predictability models on is this placement gonna be viewable? This placement going to be viewable the next time we buy it, right? Because ultimately, we get credit on not just if we won an auction and that it turned into an impression. We don't make an advertiser pay for it unless someone actually saw it, right? And so those are the type of problems that they're tackling. And they also tackle much larger problems as it relates to generating short-term and long-term interest overall. Short-term and long-term interest over a variety of different categories, right? Someone interested in pets versus someone not, someone interested in stock trading versus someone not. So they are the proverbial brains, if you will, that are building these models and then tuning them as they go. Some of them are self-learning, right? We try our best to build as much AI as possible. As much AI as possible. But again, you know, with contextual targeting, that's the big thing now. Contextual targeting with all the privacy initiatives going on and the loss of cookies and potentially the loss of location, right, with Apple's iOS and Safari changes. How do you build a contextual product that's not just relevant to the ad, but is seen in a positive way by the user, right? How do you get. Way by the user, right? How do you get that emotional sentiment involved? So that's one of the things that they're working on heavily right now is because we want to try to differentiate our contextual offering, not based on, you know, Pepsi is running a campaign. They want to sell more Pepsi zero sugar to football fans. So we don't want to serve it to an ad that says, hey, this football player was arrested for this. We don't want to do that, right? So those are the other things that we're working on, but that team does that type of stuff. But that team does that type of stuff. Yeah, you don't want to show McDonald's on a PETA site. Yes. Makes perfect sense. Does anybody else have any questions or comments on Sammy's presentation?