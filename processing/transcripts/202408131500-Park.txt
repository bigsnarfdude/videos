Thank you very much for the introduction. And I want to thank start by appreciating gratitude to the organizers for organizing this fantastic workshop. And of course, the NSF grant, the number of which I definitely remember. But I want to say because this is a short talk, so I don't have that much time. So yeah, this is a short talk. So I'm going to keep things simple. So just like the kind of motivation and ideas. And I was really, really happy when I heard about this workshop because optimal. Heard about this workshop because optimal transparent dynamics is exactly the kind of perspective that gave rise to this project. Okay, so let us first start by kind of recapping the Fokker-Planck equation and its interpretation as a gradient flow. So just going to fix notation, I'm going to write Fokker-Planck equation like this. So there's a Laplacian. And for me, all the subscripts in T are just, it's not derivatives, it's just an index. So let's say V is some kind of scalar potential, so often confined. Some kind of scalar potential, so often confining, then the component equation takes a form of this type. So we just assume everything's normalized to be probably to measure. And so if you're more comfortable with SDs, then this is the corresponding stochastic dynamics is the Langevin dynamics, which is sometimes called the overdamped Langevin dynamics, where at each time you go in the negative gradient direction of the potential, and then there's some Brownian motion. With, I think, this is the correct constant, although I can never remember. So I'm going to use this. So just to kind of emphasize. So, just to kind of emphasize this ODE point of view, I'm going to use this notation μ dot equals to vt to denote that the mu dot and vt solve the continuity equation of this form. So v dot is kind of like a tangent vector, if you like. So the direction in which your curve mu t is proceeding at each time. So it was noted by Jordan, Kindle, and Otto, and subsequent, it was made more rigorous later, that Foker-Planck equation has a gradient flow formulation in the P2. So P2 is the two-positive space. p2 so p2 is the two basic channel space for me um where at each time you're you're going your direction you're going in the negative w2 gradient of an energy functional so i'm just going to write the gradient of the first variation of uh to denote the w2 gradient or the vast magn gradient and so of course in terms of continuity equation you have you have this form so the relevant energy for the poker plan equation is the kolbic libelary divergence or the relative entropy with respect to Or the relative entropy with respect to e to the minus v, so the kind of Gibbs distribution with suitable normalizing constants, so it's a probability measure. And you can also write this as a sum of the potential energy of this type and the internal energy u, where in this case, this is entropy, right? And the solution of mu t, solution of the Fokker-Plan equation converges to the minimizer of this functional, which is just e to the minus t. The kinetic Fokker-Plan equation is similar, but a bit more complex. equation is similar but a bit more complicated because now we're working in the phase space. So let I'm going to use z to denote a point in R2D. The first d coordinates are x denoting the position and p is used to denote the velocity. So I apologize for somewhat non-standard kind of using x and p, but I think it's for this purpose of this talk. I think it's easier to distinguish. So x is the position and p is the velocity, right? So we're in the phase space. I'm going to introduce a friction parameter, alpha, that is strictly positive. Parameter alpha that is strictly positive. And so the kinetic Pokémon equation is of this form. So you definitely don't, if you are familiar with this, it's great. But if you're not, you don't need to worry because we don't really need to look at this PD really that much. So I'm going to use this color scheme. So the blue part is really kind of corresponding to the conservative with the Hamiltonian part. And the red part, this kind of degenerate diffusion in the velocity variable or dissipation that is as productive dissipation. So the corresponding SD again is the underdam Langevin dynamics. Is the underdam Langevin dynamics. So at each time you're going in the position is moving in the velocity direction and the velocity is moving in the negative gradient direction, and then there's some kind of dampening that ultimately kills all the all the momentum or velocity. So you can see that it's kind of like you're accelerating in the negative gradient direction. So the solution converges to the unique minimizer, which I'll denote mu infinity. So this is the product measure of this form. So in x, it's e to the minus v, just like the overdam-focke-ball equation. The overdam-focusabal equation, and in p, the velocity variable is just a Gaussian, right? So, and again, there's a pseudo-normalizing constant, and so independent of alpha, as long as alpha is positive, the solution converges to this unique minimizer. And this, so mu infinity, of course, is the unique minimizer of KL divergence or relative entropy with respect to itself, which again can be written as a sum of potential energy, where in the potential energy, you have the scalar potential for the position, but also the scalar potential for the position, but also the kinetic energy, so the quadratic and p. And then you have the entropy where now entropy is joint in X and P. So the kind of point of view we'll take is this. So the kinetic equation formally can be written as of this form. So at each point, at each time, your tangent vector, you're going in the direction of the Wasserstein gradient of H with respect to in the whole like Z coordinate, the Wasserstein gradient of H, and then you're multiplying by these two matrices. And then you're multiplying by these two matrices, so the sum of the two matrices. So J is the anti-symmetric matrix, which takes care of the kind of Hamiltonian part, the blue, and S is the degenerate dissipative part, though it has dissipation and just the velocity variable. So when S is just zero, so as in alpha is zero, this was first, to my knowledge, rigorously studied by Ambrosi and Gangbo, the kind of paper of the name Hamiltonian ODEs in the space of probability measures. Probably two measures. Yeah. No, because it's well, so it's like a choice, but I think alpha will show up in the kind of scheme there. So this is just, yeah, it's fine. Okay, so why are we interested in the dissipative Hamiltonian formalism? So this is certainly goes way back. I mean, this is in the Delani's book, and I think early 2000s, and I'm sure it was noticed before by other people. It was noticed before by other people. But so, why are we interested in this geometric structure? Because, so, firstly, we want to kind of leverage this geometric structure to establish something like unified existence theory. So the for T D's of this type, which include kinetic Pocompline equation. So when you have the, when you incorporate the interaction potential in X, this is called the velocity of Pokémon equation, where for the Coulomb potential, which we can't really deal with, this is the Potential, which we can't really deal with. This is the kind of known as the Poisson Foker-Plan equation, which is of interest in plasma physics. And you can also consider variance with non-linear diffusion. So you can replace the interaction, so the internal energy entropy with porous medium type energies, either in the X variable or on the P variable. Okay, so this is kind of interesting. So this is quite similar to granular flow, but there is the, so this is not directly related to this talk, but I think. To this talk, but I think it's very interesting, and I think it gives, I think it explains. Well, there's it just says that there's a really gap of understanding and understanding the asymptotic convergence rate. So this is, so assume that V is strictly convex with parameter lambda. Then the gradient flow, so in the Euclidean space, where if you're just taking x dot is equal to minus gradient of v, this, I mean, it's easy to show that this converges at this rate, e to the minus lambda t, right? And in the Wasserstein case, where we're thinking of And in the Wasserstein case, where we're thinking of kind of Focke-Plan equation, the KL divergence with respect to invariant distribution converges at the same rate. So there's some kind of analogy there. And so if you look at the dissipative Hamiltonian flow with the critical damping, so alpha is being chosen to be square root of lambda, then it's now understood that in the Euclidean case, you have this convergence rate e to the minus square root of lambda t with some universal constant c. And typically the kind of difficult cases are when lambda is small, right? And this is much, much faster. Is much much faster in these hard cases. And now, the kind of conjecture that I think a lot of people believe in is that in the KL divergence, the solution of the kinetic fork applying equation does it converge to the invariant distribution at this rate? So, of course, this table is a gross simplification of what's kind of known and why people suspect this is true. And this is already true in some sense, well, at least for the chi-square divergence. And this was shown by Chaolu and Wang recently. And then it's a barrel. Eberle and Lure show that this actually cannot be improved in terms of lambda. And why do we care about this? Is this not just like, well, obviously, it's like a very kind of mathematically natural question to ask, but this sharp convergence rate is really of practical interest to people who do, like in statistics or machine learning, because this, the corresponding SD, the underdam Launchband dynamics, is used for MCMC sampling. So people who are really interested in the kind of hardcore complexity and like how fast you can sample from the invariant Fascinating sample from the invariant distribution is really interested in established rates of this type. Okay, now we're going to really try to focus on the discretization or the discrete formulation. So again, so gradient flows, I just kind of rewrote this pointwise formulation. So this can be in a certainly relaxed sense as a limit of the minimizing movement scheme. So we saw this in kind of Will's talk yesterday. So here I'm taking, so we have the energy, and then you have, you choose a metric, and you have. And then you choose a metric and you have a time step h, you just iteratively solve this variational problem. And then, among suitable interpolation, you can find a subsequential limit, which I will call minimizing movements. So minimizing movements, yeah, the continuous time limit. And this kind of philosophically gives you some kind of characterization of gradient flows in some rigorous sense, right? Because in generalized metric spaces where these kind of Riemannian or pseudo-Riemannian structures don't make sense, this gives the justification for gradient flows. This gives a justification for gradient flows. So, we want what we want is basically this: something like this for the dissipative Hamiltonian flow. Okay, so why does this dissipate formulation matter? So, the first point is, okay, so just again to take the example of the gradient flows, first point is that it's more philosophical, right? It's just like a rigorous, more rigorous justification of the geometric formalism, which is which you just write point-wise, but then it's kind of understood in some robust sense because you're just taking the implicit or Taking the implicit Euler scheme for gradient flow, and that's what minimizing movement scheme does. And the second reason is kind of existence theory. So, this minimizing movement scheme firstly kind of gives very kind of robust way to show established existence, especially in the presence of non-linearity, right? So, like porous, okay, maybe heat equation, it's kind of, I mean, you learn in evidence through expertization that you can show existence, but like in the presence of non-linearities, for instance, force medium equation, or like in the presence of interaction potentials, Of interaction potentials, it becomes much, much easier to prove existence, especially with the measure-valued initial data and using this type of arguments. And this is something like this, if you want the full picture, this is the kind of content of the chapter four of Ambrosio, Gigli, and Sabaret. So if you have sufficient convexity, which is in the Vassaten case, convexity along generalized geodesics, then you can get like basically everything you want. You generate a Lambda contractive semigroup where Lambda is the convexity parameter. Where Lambda is the convexity parameter. And then you get existence for measure value initial data, which means you can actually consider the fundamental solutions in a very rigorous way, convergence rate to like optimal convergence rate to continuous solution, all these things that are. So basically anything you ever want to know are kind of known for gradient flows because of this type of minimizing movements and characterization. So this kind of guides you what kind of algorithm you want for the displacement Hamiltonian flow. So we want an algorithm that is the first two, or at the first point, consistent. You're at the first point, consistent with a geometric structure. You want kind of philosophically, so this is where the consistent with the geometric structure that is dissipative Hamiltonian. And if you ever want to go, so this is something I haven't done yet, but if you ever want to go the full distance, right, if you want to get a really satisfying theory, your algorithm better be convex. That's where you get all the contractive estimates. So this kind of gives you some, so the, especially the second part, or the first part, especially the second part, really gives you some kind of reduces the degree of freedom because you're choosing for the minimizing movement. Of freedom because you're choosing for the minimizing movement scheme, you're really choosing the energy and the distance, so you have kind of two degrees of freedom, but then you get you need to get the correct Euler-Lagrange equations that reduces by one. But then if you want the energy to be convex or GD is convex, which is the metric, that really reduces the degree of freedom by one. So, okay. Again, if I'm speaking too fast or anything's not clear, or if I'm speaking out loud enough, please let me know and stop me because I really don't have that many slides. Because I really don't have that many slides. Like, I think only 12 are the ones I need to go through. Okay, so this is kind of the philosophically very similar to Caroline's talk yesterday. So what I'm going to do is look at what makes sense in the Euclidean space and then lift it to the Vashanian space, try to implement it there. So if you have, let's say, so now you have a dissipative Hamiltonian OD in the Euclidean space with kind of straight base H, XP, this is just the sum of the potential energy and the kinetic energy. You can write it down in this form. You can write it down in this form. Again, the color scheme, the blue for the conservative and red for the dissipative. So when alpha is zero, so this is purely Hamiltonian, this can be approximated by something called the complexic Euler scheme, where you first freeze X and then update P according to the time step. And then you update X, freezing the new P. So it's kind of like if you're doing. So it's kind of like if you're doing, as opposed to doing, I don't think I need a light because, as opposing to go, going directly, let's say this like phase space. So X and P, maybe I should go more like out of the axes. Instead of going from this point to this point directly, what you're doing is you're moving in P first. Doing is you're moving in peak first and then you're moving next, right? So you're moving in something like a grid. And so this is, I mean, there's a deep theory behind this called, like, it goes under the name of geometric integration or geometric numerical integration. So this is something that I certainly don't have time to explain. But let's for now accept that this is a canonical or up to some variation, the canonical like first order scheme for Hamiltonian equation or DE, right? The Euclidean establishments. Okay. So you can rewrite this in a quite, I would say, like nice. In a quite, I would say, like naive, well, pointless way, like this. So, you just update the p first by solving this variational problem. And the functional here is linear, linear in the appropriate variable because you're fixing x, you're just updating q. And this functional is a function is linear in q. And your distance is just the distance in the velocity. And then you're updating this, and then you have to kind of take care of the sign because you want to get in the Euler-Lagrange equation. You want to get in the Euler-Lagrange equation, you need you want to get the plus sign, right? So, this is pretty simple to do this. But why do we do this? Because it's not really in the at least in the purely Hamiltonian case, it's not really helpful at all. What you can do is you can incorporate easily the dissipative effect, like the generate dissipative effect just in the velocity variable, right? So if you just add the Hamiltonian, it's alpha, like alpha, as you mentioned, like if you can just like incorporate alpha here, so you just add the alpha of the full Hamiltonian, then you get the Euler Grange equation that kind of at least in the continuum. Equation that kind of at least in the continuum corresponds to this, right? So it's kind of mixing the oh wow, I feel like everyone. Okay, that's kind of scary. Okay, so yeah, so this kind of is a way to mix this dimplectic Euler scheme with the basically gradient flow, right, or the minimizing movements. So now I want to implement this in the Wasserstein space, and where the point is that, okay, so you want to separate the velocity and the position. And the position. So now I have to introduce some notation, unfortunately. I'll write the, yeah, I'll go through the important ones and I'll just write them so you can remember them. So little px is just projection, so where the superscript is noting the kind of relevant variable. And the uppercase pi x is basically the marginal. So let me just write here. X marginal. And same for P, right? And unfortunately, you have to write disintegration. So we're almost always going to be disintegrating with respect to one of the marginals, and then you have the superscript. And this will be the velocity, and this will be the probability distribution over Rd, which is probability distribution over the velocity. And okay, so the last one, this is probably the worst one, but it's just going to. One, but it's just a notation. So to d sigma, this is just the subspace of the Vaster 2 Vasterstein space, where your X marginal is fixed as given sigma. So fixed marginal. I mean, I don't think you really need to remember this because I think it won't come up that much, but just in case. Okay, now I'm going to define the Basserstein distance along fixed marginal. So, I mean, it's symmetric in P and X, so I'm just going to define for the P, because that's where more interesting things happen. So W2P, let me just define as, so in the case, well, when the marginals of mu and nu, x marginals of mu and nu do not coincide, and let's just say by convention, it's plus infinity. When they do coincide, okay, so you're disintegrating with respect to the marginal, which is common. With respect to the marginal, which is common, right? And then you just integrate over the x-marginal the Wasserstein distance of the kind of conditional distributions, if you would like. So these are probably to distribute as an Rd, so on velocity, just integrate this. So just there's a kind of very simple pictorial example. So let's say mu is a blue, so every point is of equal weight, and mu is the. Weight and new is the red. The W2 coupling will basically just couple the closest points, but then the W2P coupling, so now you have to stay in the fixed marginal subspace. So you cannot move horizontally. You're going to have to move vertically, even if that distance is farther. So in general, I mean, it's very, very easy to show. I mean, there are other ways of defining this, that W2 is majorized by these two. P-dependent. P dependence. Oh, sorry. So for p is just the velocity. So I'm not, yeah, yeah, sorry. This is my bad notation causing troubles. But yeah, everything, p is equal to two. Oh, not that the velocity is equal to two, but yeah, and we're in the kind of nice reminder space. Okay, so I just rewrote the definition. Okay, so you might think, well, is this some kind of random, well, arbitrary distance, but. Well, arbitrary distance, but I mean, it has some geometric meaning, as in, so W2P is the length metric induced by the W2 on the specs marginal subspace, right? So, if you're not familiar with the kind of what length metric means, it really means that it's just the kind of shortest distance, it's the shortest, the length of the shortest curve connecting these two points, mu and nu, given that the path stays in this fixed marginal subspace. And the length is measured by the classical Vasashenk. The classical Vasescheng, right? So, if you like the metric derivatives, this is the formulation to say in here. If you like the Benamou-Rainier formulation, so it's exactly the same thing, besides that, you cannot move in the x variables. So, the first d components of your velocity field is going to be zero. And okay, so I think if you are kind of nitpicky and you like kind of analysis in the technical parts of calculus of variations, you should be suspicious because narrow convergence or weak convergence does not behave nicely. Does not behave nicely with respect to disintegration, right? This is a well-known phenomenon. But then, this dynamic formulation is actually where you can show the lower semi-continuity. So, this kind of can be resolved. Okay, now we have this algorithm. So, I have this same problem with Brene earlier. So, for lack of a better idea, I've named this coordinate-wise minimizing movement scheme. So, if you have a better idea, please tell me and I'll acknowledge you. And I'll generally appreciate it. So, this is a symplectic. Appreciate it. So, this is a symplectic Euler scheme in the Euclidean space. So, I've separated the green just to kind of separate the two. So, now you want to do this in the Wassein space. So, I'm just going to generalize or kind of lift this green part into the space of probabilities to measures, where you're just integrating over the measure. So this is a functional of the measure, and it's really linear. I mean, I call them linear because it's linear in the relevant variable that is denoted in the subscript. Okay, so this is, so I just integrate the green part, and then I just integrate the blue part over the measure. And then I just integrate the blue part over the measures. And then our scheme is really, it goes like this. So you have the sum of the linear functional and the full energy with constant alpha. And you descend, you do the kind of JKO scheme, if you like, in the W2P distance first. So this is the velocity update corresponding to the first part. So you can think of this mu bar as the kind of intermediate form where you have updated the velocity, but not the position. And then you go from the intermediate one and descend. From the intermediate one and descend in the W2x metric. So, I mean, you might wonder if this is like some kind of, I mean, this looks similar, but how do you justify this? But I don't have time to go into this, but if you kind of accept this formal Poisson bracket on this structures, that again, has all kind of consistent work by John Lott or Gang Bokeh and Puccini, and I think it goes way back to Marston and Einstein. So there is a more direct analysis. So, there is a more direct analogy of these two algorithms at that level if you use if you accept that kind of formal Poisson structure. Okay, this I should mention that this is somewhat similar to the flow and descent scheme of Carlin and Gangwell. So it's kind of the interesting thing because I started from their paper in 08. It was a motivation. And then I kind of tried to do this. And then I arrived in 2004. So I've traveled back in time. So, but the difference is, so what they do is essentially. But the difference is, so what they do is essentially, I don't have enough time to explain everything, but they just kind of take the descent and the velocity of the conditional distribution. So, without this kind of integrating back in the marginals. But the difference really is that, so which means that the energy instead of the, so this is a different kind of Fokkerplan equation. So it's hard to directly compare. But the difference is that there you need to use this conditional entropy with respect to the kind of local max volume. Respect to the kind of local max volume, but here I can use the like actual joint entropy, which is kind of more satisfying because this is, I mean, at least for this case, I'm not saying, because that's what the flow is, the Hamiltonian flow of this beta flow. Okay, so the main result, I think five, six minutes should be really enough. Okay, main result kind of informally stated is this. So we're assuming the gradient of V is Lipschitz. And I mean, it's better, it's confining, but it doesn't really matter. So H, the Hamilton, so the energy functional. So, the energy functional is positive at is not in is finite at the initial time. Then, essentially, this scheme converges to the distributional solution of the kinetic Fokker-Plan equation as the time step goes to zero. So, where you're really looking at is the kind of interpolation, and I'm using constant, piecewise constant interpolation. So, the idea behind the, I mean, the kind of rough ideas behind the scheme. So, it's split into three parts. So, you use some kind of compactness arguments to show existence of a minimizing movement, right? And you have just Right, and you have just analyzed the Euler-Lagrange equation just past the limit, and this you show that the minimizing movements should be a distributional solution of the kinetic point equation. And then I'm just so the only place I'm really using anything from the standard theory of the KFP is that I'm just using uniqueness so I can claim that the whole sequence actually goes to the uh to the solution. So, okay, there are again this kind of uh parallel with the gradient flow. So, nonlinear extensions, the preprint is out. The preprint is out is on archive since two months ago, roughly, and that actually talks about velocity for complying where you incorporate the interaction energy in X with the gradient, where the potential has the Lipped gradient. So that analysis goes through very, very similarly. And of course, you can also consider other W2Gesically convex internal energies like of the porous medium type. And so for this, I can do the first step without any change. Because the nice thing is that. Because so the nice thing is that W2P, or these kind of boss sign distance along fixed marginals, because it's the kind of geodesic distance along this nice space, it basically inherits like all the convexity properties translate, like it with appropriate modifications of whatever is in a browse geoducleian subarray. So, and it's not really a fundamental instruction in being able to do two and three, because it's just like distributional solution is a bit harder to find. But if you're willing to accept, for instance, this kind of formulation, then Ambrosian gangboard. This kind of formulation in Ambrosian Gangbo, then I think this should really be doable without that much change. So that's just for technical reasons. Okay, so I just want to mention a few things. But any questions? Okay, so the convexity of the discrete problem. So this is the kind of my selling point. So this is just the algorithm here. And so my point is that each step of the variational scheme is geodesically convex, meaning that the meaning that the sum of these two functionals is W2P geodesically convex. So this is geodesically convex problem. So you get nice kind of estimates. And the second one is geodesically convex with respect to W2x geodes. And the reason is because the linear, the blue parts, the LP and LX are just linear in the relevant variable. And alpha of H. So if you kind of remember the relative entropy formulation, I mean, entropy is just geodesically convex. And there's the kinetic energy like p squared over. And there's the kinetic energy like p squared over 2. So that's this one geodesically convex with the alpha. You just get this. So, I mean, this trivia, I mean, this easily gives a unique existence of the variational problem. But so, I guess what the real question is, can we really leverage this to go like the full distance? More refined theory. And actually, this is the kind of worst slide that I put all the junk in the. So the point is this. So, the point is this: you definitely do not need to read everything. The point is that, okay, so the Lipschitz continuity of these potentials allows the basically means that you don't need to worry about anything besides the entropy functional. Like the potential energy or the linear functional, these are kind of very easily controlled. So the velocity update dissipates the energy because that's the minimizing movement scheme. And then the position update, if you just analyze what it actually is, it can be explicitly just written as the push forward under this map feed. As the push forward under this map ph. If you look at the gradient of that, which is the matrix, so I d is a d by d um identity matrix. Then the point is that this matrix is upper triangular and on the diagonal, you just have id. So this is determinant one. So if you look at the push forward density formulation, it's easy to see that the entropy actually does not change at all. So with that, you can just easily do the analysis then and show some kind of equal continuity, which using this kind of refined scolio. kind of refined uh scoli or zelle uh theorem from ambrosia jiggling and stuff where you can show the existence of the unique of some kind of convergence the limiting curve right over some sub okay so yeah i think i'm basically i mean there are some appendix things in page that are questions but so there are some future directions that you know i'm actually not actually working on any of these things because i'm interested in the asymptotic convergence rates um and if you're in case you're ever interested in this i can talk to you about at any I can talk to you about at any given length of time from two minutes to two up. It's really a fascinating problem. But I mean, so, of course, the kind of first thing is: can you really refine the existence theory? So, generation of a contractive semigroup or relaxation of assumptions on this kind of Lipschitz continuity of the gradients is something that's kind of interesting. And I guess the kind of another interesting thing is like identification of an intermediate formulation. So, in the case of gradient flows, there is this curve is maximal. Yeah, curve is maximal slope, which is use metric derivatives and metric slope. Can you actually identify something in the kind of continuous time that is the connecting bridge between these two? Because this will allow showing this existence, passing to the limits in the presence of non-linearity much easier, which is actually also kind of partly the point of Perris maximal slope in the case of Ambrosio Devon and Steve, right? But also, you could think of things like, you know, there's this, well, of course, the Alper's talk was somewhat. Talk was somewhat in the sense of the convergence of gradient flows, right? But and there's some more, well, somewhat kind of non-quantitative theory of old theory of Sandier Sefati, where you can look at convergence of gradient flows under the convergence of relevant structures. So if you can identify this kind of intermediate formation that just depends on the relevant structure, so you can't just be metric in energy because I think the Poisson structure is really kind of relevant here. But if under somehow suitable convergence of these things, can you actually? Somehow, suitable convergence of these things, can you actually show the convergence of the Hamiltonian quotes, like these types of things? So, these are the interesting direction. And just because I think there are some experts in connect theory, I'm going to talk about something I do not understand at all. So, okay, so the point of, so what nice thing about separating X and P is that you can put different local metrics. So, if you are, so there are kind of works on the spatially homogeneous, like gradient flow interpretation of spatially homogeneous kinetic equations, collisional especially. Means kinetic equations, collisional, especially, is the different case where I guess Landau equation is one example of some members of the crowd here, and also Boltzmann equation by my TSR bar. So, like, whether you can do this, like you can use a scheme to apply that specifically in homogeneous equations, I think is also an interesting problem. But I really am learning basic things about kinetic theory. So, this is something that I don't really have a good answer right now. I think I'll end my talk here, and I'll take any questions. Hi, thanks for the talk. So, in kinetic equations, usually, although I'm your kinetic Poker point equation has a lot of terms, usually with kinetic equations, there's this notion of a velocity. There's this notion of a velocity averaging. So I guess you integrate in P, then the thing that you get, although these equations, right, there's only a Laplacian in the momentum variable. So you only think that it only smooths out the V thing. Anyway, what I wanted to ask is, could you derive the velocity averaging gain of regularity just from this structure, do you think? Right. So this is an interesting question. Right, so this is an interesting question that is, I short answer is I don't know. But if you look at the, so I think I mentioned this paper. Okay, so it's a paper by Carlin and Gangbo about kind of model Boltzmann equations. This is actually kind of very close to, I think, what you're asking. So there is a bit that I did not read yet, but there is certainly a part that does. So at someone has this kind of similarities of kind of this kind of discrete scheme. So that's what they're showing existence through this. And there's, I think, a section about. Existence through this, then there's, I think, a section about velocity averaging that I was planning to look at, but I did not get the time to. So I think, so it's hard to say because I don't know the full theory, but I think there are some kind of, it could be, is the answer. Thanks for the really nice talk. I guess like the place where I've been the most familiar with these handled money inflows or Dissipative Hamiltonian flows or like accelerations of gradient descent. Yes. And I've seen some things where, like, to do it in Bosser-Stein space, they get rid of the momentum variable. And then you just have some kind of like extrapolation where you have like a W2 term that with a positive weight from your past iterate and then the negative weight with like the iterate from basically like two steps before and somehow. Like two steps before, and somehow this like does the momentum part of it. I don't know if so, I so I think I have a partial, like very small partial. So, so in the Euclidean case, right? So, this is so basically the dissipative Hamiltonian flow with the discretization is called, I think, heavy, um, polyux heavy ball OD, right? So, you can just, because you can just write the whole thing as a second derivative equation. So, and of course, in the Vasser Street space, it's kind of not easy to do that. And it's also unclear if that's the better idea because, like, looking at The better idea because, like, looking at second derivatives in Basavna is not the most beautiful thing from my past experience. But there really is. So, let me just kind of just because you triggered me, I'll rise to the bait. So, there is this beautiful, really paper. So, okay, so I think the short answer is the discretization is actually harder, right? So, you first have to understand whether you can get accelerated rate at the continuous level. And then you might want to describe this algorithm and. You might want to describe this algorithm and see if this is preserved in the end. And there's this. So, Chao Lu and Wang. So, they're basically kind of refining the estimates of this paper by Al Britson, Armstrong, Murat, and one of M. Novaks. That you get some kind of space-time averaged space-time point-carry inequality. So, under what is essentially the Polyak-Luis-Shevich type condition in the suitable L2 space, you get this conversion. Like L2 space, you get this convergence of chi-squared or the weighted L2 norm at this accelerated rate. And this is like an absolutely beautiful thing. I mean, their statements are very geometric. Their proof is just PD. And it's really, because it's using a lot of the linear structure, it's hard to generalize that to the Watsonstein space, where the relevant Polyagloshevitz inequality is the Logzopola. And the problem with this, like, why does this not translate to good results in the kind of sampling? So this is exactly like in direct comparison with the Euclidean case. In direct comparison with the Euclidean case, because you're accelerating at the level of probability distributions, right? It's like sampling can be seen as optimization. And why is this not sufficient? So this is actually coming from one of the authors who's a postdoc at CMU, is because typical distance in L2 grows exponentially large in the dimension. And typically you're interested in high dimensions, but KL only grows linearly. So that's why that actually makes a difference. And nobody knows how to generalize each other. I don't know if that answers. No, no, so yeah, so that's a good question. So it's exactly the same continuum equation. And last summer I was like looking into this, and you can also get like exactly the dissipative Hamiltonian structure in, I would say, a weighted H minus one space, where you're weighting in the invariant measure. So and the energy, I think the relevant energy. So, and the energy, I think the relevant energy is there, is probably some kind of like just the something like L2, right? And so, there's a very natural thing. And in terms of this energy and the gradient, like the gradient in that space, the statements of the kind of key results of this paper are very geometric. It's some kind of time average, yeah. And so, there is a suspected analog in the Vasterstein space that I would bet like $50 that it would hold. Because I don't have that much money still. Because that's, I don't have that much money still. But it's just, I'm trying to understand this better than this, the kind of hard problem with the long-term goal. Yeah. Thanks a lot, Poopa. I have a complete beginner question, but it's important. You compared the episode with this. Where? Right, right, right. So right, right. So I will, so this again, there's this paper of Gangbokem and Puccini that really kind of studies this type of Poisson structures quite rigorously that I would like to understand, but my maturity in symplectic geometry is not sufficient. But yeah, so, but there's this kind of agreed upon form. Um, kind of, you know, agreed-upon formal Poisson structure on this Basserstein space that is like this. I mean, it's just the bracket is H or V if you know one of them, it's like the time derivative where you're doing the Hamiltonian flow of the other, right? And the thing is, okay, so this L P minus L, these are the linear functionals that come up in the algorithm. L P minus L ' is exactly the Poisson bracket of H with the second moment, right? And this is really, this has to do with how at the level of purely Hamiltonian. How, at the level of purely Hamiltonian case, like the internal energies do not matter. Things cancel out, so like it doesn't. So, really, the kind of the entropy part goes away. You just get exactly this. And this is in direct analogy with how in the Euclidean case, if you just use the kind of variational formulation, it's the Poisson, Euclidean Poisson bracket. This is like completely rigorous. So, the bracket of H and the, I guess, the quadratic in the. So, I is just the X plus P, right? That is the. That is the linear functions that pop up. So that's the kind of direct analogy I was talking about. And thanks for asking this. I could flash my appendix slides. Does that answer your question? Okay, so I'm going to use the stuff you need.