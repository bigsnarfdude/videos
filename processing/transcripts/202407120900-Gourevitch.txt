Today end is by admitting Ripich about the hypergolder for the agreement. Please. Thank you very much. And thank you and all the organizers for inviting me here. I'm really enjoying this conference. Okay, so I apologize for telling you something not about branching problems, but the advantage is that it's fresh from the Oval, recently put it on the Aachen. And it's about orthogonal polynomials. So, a couple of orthogonal polynomials appeared in this lecture. And there are several special sequences or families of orthogonal polynomials. And actually, there is Askin-Wilson scheme with 44 families. Most families go there because they're just useful. Got there because they're just useful. They proved useful sometimes in mathematics, sometimes in physics or electrical engineering to solve some differential equations. So basically, most of them are family of polynomials that is first orthogonal and second eigenvalues of some second-order differential operator. So, of course, just like for a series, it really helps to solve the equation. You can decompose the solution in these cases. And ASCII and Wilson have. And ASCII and Wilson have a classification result proving that these are all the families that satisfy some kind of second-order differential equation. And what we present now is a different classification result that has nothing to do with differentiation. So in fact, we have an ambitious project of classifying the whole ASCII-Wilson scheme. We are not there yet. So far we managed to classify. So far, we managed to classify part of it. But we have two more ongoing projects on which I will not yet talk that, but they're in the same spirit, in which we got already half of it. So we hope to eventually get all of it in some purely algebraic classification without the differentiation. Right, so let me continue to do some definitions. Okay, so let me end. So let Pn be a family of orthogonal polynomials, so just family of polynomials, one for each degree. So the degree of Pn is n. And now we call this family quasi-orthogonal if there exists a linear function on just the space of all polynomials, in one variable with complex coefficients that defines the scalar product. So how do we define scalar products from a function for two polynomials? Product from a function for polynomials, just multiply them, apply the function. So, if this basis is orthogonal with respect to the scalar product, so it is called quasi-orthogonal. Why quasi? Because best case is when this function is just given by integration with respect to some measure. Well, this measure has to have finite moments so that the integral will be defined at all for each polynomial. So then they're called orthogonal. Otherwise, they're called quasi-orthogonal. Otherwise, I call quasarthal. Quasarthon is more algebraic condition, there's not positivity condition on the measure. But there are lots of Portagon prenominals. I mean, you can write any meaningless measure, take standard basis, do Gramschmid, get a family of Portagon prenominals. Surely we don't want to classify all these. So we want a second condition. A second condition satisfied by all the ASCII schemes is that the polynomial. Ask you, ask you is that the polynomial. So, second condition is that the polynomials are hypergeometric. So, what's hypergeometric? Geometric series are series with a constant ratio of consequent members. Hypergeometric is a series in which the ratio of consequent members is a rational function in the index. So, in our case, we have two indices. So, we take the family Pn and we write its coefficients. So, coefficient is its coefficients. So coefficient is a function of two integer variables n and k, then the number of predominant family and the power of x. We have the cmk and if the ratio of next coefficient cm k plus one divided by the current coefficient cmk. If this is a rational function and n and k, we call a family of rational type. And if this rational function, the denominator depends only on k and not on n, then we call this family of Japanese. Then we call this family of Jacobi type. So, Jacobi type is quasi-orthogonal and this condition on ratio predictions. So, as you can guess, this is satisfied by Jacobi polynomials, but also formal polynomials. And our result is classification of all polynomials of all families of polynomials of Jacobi with time. So, oh, sorry. So, it's So, it's classification up to equivalence. Of course, you can rescale the wave. You can also re-normalize polynomials, or you can fix the normalization by demanding that they are all monic, for example. I think monica will agree. So, up to this equivalence, there are only five families of Jacobi type. Actually, when we started to prove, we thought we will prove there are only three families. We thought we will prove there are only three families, the classically known ones, Giaconi, Laguerre, and Basori. But in a special case of one of the lemmas, we saw that there are two more families possible. We don't have a good notation for them or name, so far we call them EN and FN. Then we are very happy. We contacted Kornwinder, who is a specialist. List of the things, and he said, okay, they are not completely new, they can be defined through Lomelle polynomials that are classical from the 19th century. But Lomelle polynomials are not hypergeometric. And if you kind of separate the Lomelle into two different families, each of the families En and Fn will be hypergeometric. So that's kind of the new discovery, the new practical discovery. The theoretical one is this. Theoretical one is this classification. So, I do not expect any prior knowledge, so I will now define all those polynomials. I'm glad that on the second slide, I can formulate something. So, what are the definitions of the polynomials? Maybe let me ask if there is any question about the result, except that I will. Result, except that I owe you a definition of those families. Okay, so let me define. So the families are defined using hypergeometric functions. What's a hypergeometric function? So it's a series, it's a power series where the coefficients are defined using Pohammer series. Such a thing is called Pohammer symbol. Such a thing is called Poham symbol. It's also called raising factorial. So in factorial, we go by step one down. In this thing, we go by step one up. So C set tells us where to start. And K is an integer, non-negative integer that tells us how many steps to go. Steps one. So just this product. So for example, one k is k factorial. Factorial. We see one factorial here. So, and then the coefficient is defined to be product of Pohama symbols, case with the same k, some a i's. And then we divide by another product of any number of Pohama symbols, but always in the denominator, we also put k factorial. And times x to the k, this series may be convergent, maybe not convergent. So, of course, if x is at Course, if x is at most one and absolute value, it will be convergent. So, but we don't actually use series, we truncate them by putting k1 to be minus n. And then for k equals n, this is zero. So, it becomes a polynomial of degree at most n. So, any collection of a i's and b i's where a1 is a minus n. A1 is minus n gives us a family of polynomials so we allow a i's to depend on them for example the first is minus n the p i's we do not allow to depend on them and then it is easy to read the t's from the series so jacobi polynomials are 2f1 which means we have two a's and one b but there is another hidden b this k for just This K for Kodel, just not reading. The first A is minus one, the second A is n plus A, where A is a parameter, a complex number, and B is another parameter, there's only one B. The variable is X, the variable is a period. This gives the classical Jacobi family. And since, by this definition, Ck plus one divided by C k is just C plus K. Is just C plus K, it will satisfy the condition from the previous slide. The ratio of Token Security coefficients is P divided by Q, where you can read the P and the Q from here. The P is product of S plus A. So minus N is gives S minus U. So U is a variable of polynomial P since for the condition we plug in integers, but in general, it's polynomial. In integers, but in general, it's polynomial and two variables. So, I mean, u is n turned upside down. Let me just plug in n for u and k for s. So, s minus u. Here, n plus a gives s plus u plus a, and then b gives s plus b, and this hidden k factorial gives s plus 1. So, we will always have s minus u in the p and s plus 1 in the q. At s plus one in the q because s minus u is what truncates for other polynomials at degree n, and s plus one is what truncates for other polynomials to be polynomials. So this ratio of coefficients being constant, it continues if we if we say we have infinitely many coefficients, but most of them are zeros. So we still have coefficients of degree more than n, but there are zeros, and less than zero, but they are zeros. Than zero, but they're zeros. And this s minus u and s plus one allows this. Now, how to recover the measure from the formula is not easy at all. It was just done by the classics for these Jacobi polynomials. And this happens to be the measure. It's some continuous measure on 0, 1. Now, the measure only works when B are positive, and A minus B, I think, is also positive. Otherwise, the family is only quite. Otherwise, the family is only quasi-orthogonal. And for some particular values of A and B, I think negative integers, it's not even that. Sometimes it's not defined, we will be dividing by zero. But outside the negative integers, it is quasi-orthodox. So that's Jacobi. Now, Bessel is the same thing, but without the V, so just no V parameter. And Bessel is never orthogonal, so I don't write the measure, but it is quasi-orthogonal. The measure, but it is quasi-orthogonal again, but a is not a negative integer, so I will not write the p and the q for besides because it's the same idea. So p is same and q is just as plus one. You can read it from the function. And Laguerre is like Jacobi, but without the A, so the function is one at one. And the measure is on half interpretable, infinite interval. Infinite interval from zero to infinity, such a merger. Musokotskin, and then we found two more families that are more elaborate. So it's En is four of one of the sort also type of and n is also four of one. So slight change in parameters, big hypergeometric functions. Hypergeometric functions. Now, every hypergeometric function satisfies a differential equation. You can also just read it from the function. The first three are simple-minded, and indeed the differential equation will be second-order. Here, it will be fourth-old differential equation. And so they are not eigenfunctions, so not even fourth-order operator, but satisfy some equation. Ah, so here are the equations. So here are the equations, quite long. Well, here d is the Euler operator, xd by dx. So these two come from bottom, it's the one, and the other one, which is always there, the k factorial. These four come from upstairs, and there is an x here. That's the way to write differential equations for any kind. To write differential equations for any hypergeometric function, and now I would like to tell you how to define this for Lomel and what are Lomel. So the Lomelle polynomials are given by recursion. The minus first is zero, the zeros is one, and then the next one is given by, take the previous one, this should be x, sorry, that's the tip of the variant. Be x, sorry, that's the tip of the variable. So multiplied by the variable, multiplied by c parameter, c plus the index, and by two, and subtract the previous one. So this two-term recursion. These are my polynomials, and you can see from this that they are alternatively even and odd. So they cannot be hypergeometric. No rational function can. Domo-rational function can arrange for us infinitely many zeros and poles. So, but if we separate them to separate families, what I again accidentally call the variable z, so we separate just the even once, then they are polynomials in x squared, right? So, say that e n of x squared is this. So, then so that dn has degree n and not. One and separate just the odd ones, and this will be the ENs and the FNs. So that's what we discovered. And our next question is, what if we allow the sorry what if we allow the Q to depend on U as well? So I said. On u as well. So I said rational function, but I had a peculiar condition. The denominator doesn't depend on n. We had some complicated reason, but actually the real reason was that just classical polynomials satisfied. So if we remove it, we can still say something. We can say the following. So if P and is quasi-orthogonal, we see. Relation group, any relational function, then there exists a polynomial in two variables and another family, qn, such that our family is obtained from qn by the following differential operator. We take this polynomial g in two variables for the first variable, plug in n, but for the second variable, plug in the order operator, x dx. The point is that it multiplies x to the k by k. By k. So actually, what this does is takes a coefficient cnk and multiplies it by g n k but what q n satisfies? Well, qn, I would like to say that qn is of Jacobi type. This may be true, but I cannot prove it yet. And what we can prove is Is that it is either Jacovi, Olager, or Bessel, or 4F1 with some parameters. So for En we have N plus C here, and then A, D, and B are linear functions in C. For this QN, we cannot prove it. Could be some parameters, but we don't have any example when it's not PN and not F. Yes, and I'm all the time saying here. Uh, yes, and I'm all the time saying here I forgot to say it's joint work with Joseph Banachstein and Sidhar Sahi. All right, can you say the problem? So, if you give it G and Q, then P satisfy the so yes, so for any P, there exists G and Q. Vice versa, if you choose a Q, even If you choose a Q even of Jacobita, it's not clear at all whether there exists any non-trivial gene that will give you a PN of this type. It's quite, it's still open of what can be obtained in this way. We do have some non-trivial examples. One example is this nice family, which is to me. Which is to me is nicer than NOFN. It's 3F2 minus n and plus 1, Cn plus C plus 3 over 2, 3 halves, and Cn plus C plus 1 over 2, where C is any complex number. Again, call the variable Z. Hope it's not a problem. And it is obtained from Jacobi. So this is a very special Jacobi. Jacobi, so one and three halves. So, and another polynomial, which is given by a hypergeometric function, and it's not classical as far as I know, it's new. Probably not as nice because we have in the denominator, we have something dependent on them. I don't know if it's useful for anything, but it's what's the g in this case? You did this explicitly? Yes. Yeah, so I don't. We have some explicit G, I don't remember, maybe even Dina. Q doesn't depend on C? Ah, on C, right. On the parameter C, right, doesn't depend. The G depends on C. Yes? And Yes, and one can also obtain fermilies not of this type, not hypergeometric. Probably non-hypergeometric are less useful, but I just wanted to say that in the formulation of the theorem, not this one, not the previous one, we didn't require hypergeometry. We required something related, this ratio, but the p doesn't, and the q, they don't have to factorize. They are polynomials in two variables. Somehow we got that. Somehow, we got that in the previous theorem that it always factorizes. Now, in this theorem, it not always factorizes. We have examples in which the G doesn't factorize, and as a result, the P and the Q do not factorize. So, it made us appreciate the previous theory more things, automatically factorizing. But we still don't know. Don't know first for which what could be QN? Can we restrict QN to be just of Jacobi type? And second, given a QN, do they exist non-trivial G? And if they do, what is the classification of all non-trivial G? So these are the two open questions. Is QNOS objectophytite? And given QN of Jacobi type, what Pn are possible prevalently, what G's are possible. So we are doing good on time. So if there are any question at this point, I can have to because you you are. And f are related to by this kind of a gene. That's correct. Yes. Yes. E and F are also related by this kind of gene. So in this way, you can obtain from F a different G, vice versa. That's absolutely correct. And that's the reason that we managed to define new families using E and F. So basically, when you F. So basically, when you have the same case with Jacobis, there were two different Jacobis related by a gene, and thus, from them together, we could define something third which was not already not Jacobi. So, yes, I just want you to have a characterization of P of n in terms of coefficient, but in terms of Q of n, you have a sort of So Q of N, you have sort of, it seems like QN is sort of a bit more restricted. Is this Q of N sat by sort of easy to catalyze kind of criteria? Yes, so what really matters is a certain module defined using the coefficient. So let me tell a couple of words about the proof. So the first ingredient in our proof. The first ingredient in our proof is a very classical statement, I think, from the 19th century. It's called Pavard's theorem, but actually part of it is due to Gauss. There is a completely algebraic characterization of what does it mean to be quasi-orthogonal. So let's normalize it to be monic. Then quasi-orthogonal is equivalent to the existence of two sequences of complex numbers such that x times pn is pn. x times p n is p n plus one plus alpha n p n plus beta n p n minus one. So this is called three term recursive relation. It's usually written this way, but actually it allows to define pn plus one using pn and p n minus one in this way. So rather than defining coefficients, you can just define recursive law. Then Then we define the following algebra, which plays a key role in our probe. We take rational functions into variables and extend them by two operators, which are just shift in every variable. Shift back and forth, and shift just the u or you shift just the s. So, as a result, we get a non-commutative algebra. And the little rule. And we draw the following key layman. If the family is of Jacobi type, and the same for this more general rational type, then first of all, those alpha n and beta n are almost rational functions. So there exists rational function in one variable such that when you plug in n, you get the alpha n for almost all n. So it can deviate infinitely many points from the rational function. Finally, many points for a narration function. And second, we can generate from the CNK and A module in the following way. First, we generate a module over polynomials just by multiplication. The CNK is a function of two variables. We can look at all functions into integer variables. Any function can be multiplied by a polynomial. Yeah, take a polynomial restricted to integers. Restricted to integers. Now it's a function, it's plyblane. But we can also shift, of course, every one of the variables of this module of functions and take this particular function, n k go to the n k's coefficient, generate a module by it, and do extension of scalars to rational functions. This generates a module, and apparently, this module is Apparently, this module is one dimensional over this field. So the fact that a coefficients, ratio coefficients is a rational function, says that when you take C and K, shift it by S, it just gets multiplied by this rational function. But what happens if you shift it by U? Shifting by U is changing from 1 to N plus 1. So we can see. So, we can see that it depends on C and K and on the shift in the other direction, multiplied by rational functions. So, the module, we thought, is two-dimensional. But then we wrote this relation in the language of this module, it's easy translation from here. And we applied u and s, u and s, commu, the shifts in different variables, and we got from this relation two different linear relations. Different linear relations, and we thought we reached contradiction in mathematics. Then we realized, no, the module is just one dimension. So if it's at most two-dimensional with a relation, then it's one dimension. And if it's one dimensional, it means there is one more rational function. What happens when you shift not the k index, but the u index? It also gets multiplied by some rational function. So one rational function was there by definition, and the other came from three terms. And the other came from the terminal action. One-dimensional modules are much easier to work with, and actually, they were classified by an Ore in 1930s. And they each has a very explicit model. So you can construct a Meromorphic function that generates a module over A, which is one dimension of the ring of rational functions. functions and every module is obtained in this way. So the functions are products of gamma functions where gamma of k u plus n s where k and s are integers. So since when you shift gamma function by one you get your multiply by x. Here it will be shifting u will result in shift not by one but by k which means some polynomial x times x plus one for Hamas information. In one direction, multiply by Pochama signal direction. You divide, and as it's different, Pohama signal. As a result, you can get any polymer. And another thing you can do is exponential of AU plus BS. This here, when you shift, you get multiplied just by the scales, XA and XB. And this way, you can compose anything. This way, you can compose anything. Now, a priori, it's not obvious because rational functions and two variables don't factorize. But apparently, if the module is one-dimensional, then the rational functions factorize and have very restricted factors. Ku plus LS where K and there are integers. That's a classical theorem from almost 100 years ago. And now we are in business because we can. Business because we can replace this relation. So, what is this relation? That's a relation on some element of a one-dimensional module. But we can assume this element is almost of this form, product of gamma functions and exponentials, but also multiplied by a rational function, because Aura showed that every module has such an element. Possibly, our relation is on a different element. So, we have to multiply. So, we have to multiply by a rational function. We write this relation in this form, and then we just ask about poles. So, gamma functions have poles along lines, and their shifts have poles, different lines. So, it's always the same family of lines, but it starts at a different place. So, here it's one kind of shift, here the other kind of shift, here a third kind of shift. Of shift, and but each shift has to be covered by something, every pole has to appear in at least two terms of the formula. This gives serious restrictions on what the case and the s could be. So there are only five possibilities for the pairs. Now, each pair can appear any number of times with different constants here. Constants here, these CI's complex numbers. So there's still some variety, but already quite restricted. And then for each phi of this form, we exactly know what is the ratio function. So the ratio of phi US plus one, phi US, has to be P U S has to be some polynomial in S minus U, so that's one variable polynomial, times some polynomial in S plus U divided by some polynomial in S. And also then this G, it gives it S G divided by G. G could be arbitrary and it gives this kind of shift. But if you have Jacobi type, then Then the denominator cannot depend on u. So g cannot depend on u. Then if g depends just on s, then s g is g, so it cancels out. So it's one proof for two theorems, one for Jacobi type seconds more complicated, and which g exists. Okay, then after we have all those restrictions, We have all those restrictions, we have to classify all triples P R W. We can again rewrite this formula now in terms of P R and W and bring to common denominator, we get some identity in which we have unknown polynomials, but in one variable. But into them, we plug into one of them. Difference in the other sum in the third. One variable in alphas and betas, another variable u. Another variable u, and we can show that it's very hard for this to be consistent because some is s plus u, some is s minus u. And we have a precise argument that I don't want to show. It's just some computation, you can see it from Darker. But we quite fast prove that the maximum degree of P, R, and W is two. And then you can go over all the cases: two, one, one, two, one, zero. There we go. Okay, so it seems that there are only five combinations. What are now our plans in the future? First, paranormals of Wilson type. So they are hypergeometric functions in which you put the variable, for the variable, you plug in one or just Variable you plug in one or just some parameter, and the x appears in the parameters of the hypergeometric functions. And we have a way to characterize them also, but not by what I just said, what I just said is construction, but to axiomatize this. And I mean, I was not sure what I want to show and don't want to show. And my Siddhartha said don't yet show because maybe they are new. Show because maybe there are new ones. So maybe if we check again, so far to prove there are no new ones of Wilson type, but we will have to check again, maybe in some lemma, in some corner, still find new ones. And then there's Q Jacobi. So actually, what all everything I was talking up to now is part of Wilson scheme. The ASCII Wilson scheme means you do everything Q. There's Q Pohama scheme. There is Quhama single Q hypergeometric functions, it's called basic hypergeometric function. There is this Q calculus, Q factorial, Kubernetes coefficients of everything Q. How to characterize this? Actually, there is exist similar characterization, except that you have to allow the Q in those rational functions. They should also depend on Q. And it's also in progress. It seems that Seems that this machinery of one-dimensional A modules is the thing to do everything here. But then what we did not yet have chance to check is whether these two combine to classify the whole ASCII-Wilson scheme or not. We just did one step in the Wilson direction, one step in the Q direction. We still have to, we have to finish that first of all. We have to finish that first cycle and then go back. Finally, I wanted to quote the last sentence from the ASCII Wilson paper. It says a characterization theorem that leads to new orthogonal polynomials is usually interesting. One that says the classical polynomials are the only polynomials with a given property is usually much less interesting. And if it keeps Interesting, and if it keeps people from voting for new polynomials, it is harmful. So, fortunately, ours discovered some new families. And also, there's some open questions I showed in the middle. So, please don't be discouraged from looking for new polynomials. I hope it's not harmless. Thank you very much for your attention. Thank you very much, Dima. Very interesting talks. Are there any questions? Yeah, so you classify up to an equivalence multiple E and can you normalize that constant multiple E and so constant multiple EM so that your PM looks beautiful. Yes. Yes. There are actually two ways to normalize. One is to require the leading coefficient to be one, just to make it monique. Then the formulas will be similar to what I showed, but you, I mean, it's easy to find what is this leading coefficient, you just have to divide by. Or you Or you can normalize for the free coefficient, for the constant term to be one, because we can show that it is never zero. Our conditions imply that the constant term is not zero. And then you can normalize the constant term to be one, and then it's just the hypergeometric functions. So hypergeometric function, by definition, when k is zero, it's empty. Ratio of empty products, which is one. So generating functional point of view. So generating functional point of view, it is correct. Yes, I think so. But then the three-term relation is slightly more complicated. So here this is homonic. Otherwise, you put here a third thing, but you don't really have three sequences because the condition for the other normalization is that the sum is zero. You see it by concealing that constant job. Let me ask you questions. So it reminds me that I introduced some special polynomials that satisfies the first order differential equation. All the differential equations that appear naturally from the minimum representations. And we think it's also your new polynomials, En and Fn connect with some representations. Possibly that your framework also may cover the jam. Maybe I don't know of any connection to representation. Don't know of any connection to representation theory for the new feminists. In general, Sidhart Sahin has a representation theoretic characterization of the Wilson polynomial. So the Wilson polynomial is the most complicated polynomial in the Wilson scheme. And then from it, one can obtain others by substituting something, taking limits. But so that's all I know. I don't know. Okay, but it's not a false differential second order. False order differential based also naturally appear in uh minimal representations. I'm very glad to learn about this. Please send me your screens if you have time. Any other questions? If not, let's thank again.