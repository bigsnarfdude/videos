Present my work. I just finished my PhD study two months ago at the University of Chongqu. But today, rather than presenting my thesis work, which is Bayesian Computations Hierarchical Modeling, I would like to present these works that I completed as a Cancy Ontario State Trainee under the mentorship of Dr. Jerry Dollis, Dr. Andrew Carlson, Dr. Lacer. So I know. Okay. Uh so first of all I'd like to start with a bit uh brief motivations as well as the locations. Uh in this work we consider this classical GRM which has been used in various kinds of GWAS or various kinds of treats. So the tree beer denoted as y and we mainly focus on the value case and g here is a link function which in typical g was going to be a profit or a logistic A profit or a logistic link function that converts this linear predictor to 0 and 1. We follow the practice of current GWAS to use these acid codings for the main effect of the genetic variant. So basically, the genetic variants JA here is some 0, 1, 2 denoting the number of minor new copies, and here denotes the interacting in. knows the interacting environmental variables. So environmental is really good on the quotation mark because this could essentially be any interacting variables. It can be composite like the sum of many interacting variables including the genetic pyrosnakes. In this work we are interested in studying if this E part, the variable that is interacting with the SNP of interest is latent, then can we still Is latent, then can we still test the hypothesis of this G interaction beta G. So, first of all, for the continuous case, based on all these previous talks given by previous speakers, either implicitly or explicitly, I think most of the audience already know the answer is yes. So, we can make use of the variant heteroscedastity to interact with hacking interactions, even without having any. So, basically, the idea is simple. So basically, the idea is simple. Start with this classical linear regression model typically used for continuous 3 GUS. If you don't have any information of E, of course, those two components got absorbed into the random arrow. So you end up having an arrow term that depends on both E and G. And if you compute the variance of these terms, conditional different components of manual yields, then you will have these quadratic functions. And this is going to be. And this is going to give you a variance heteroscalasticity as illustrated by this figure here, unless if you have this beta G equals zero. Otherwise, the variance becomes a function of G. So there have been methods, existing method, leveraging this phenomenon to indirectly cast the interaction effect for conjugate traits. So the question we try to answer is whether we can do something similar for binary tricks. For binary trees. And since there's already well-established literature on continuous case, the naive questions to ask is: can we use this variance argument for binary case directly? And the answer to think about this is no, because the variance of binary random variable or moody is completely characterized by the mean. So the variance won't provide any additional information that are already covered by the on top. Already covered by the, on top of what already covered by the mean function. And for similar arguments, you cannot add over-dispersion terms and identify over-dispersion parameters in this binary GLM. So it may seem like there's almost no way to do it at all, and the only way perhaps is to collect all those possible interactive terms. But actually, in this work, we show for battery trait analysis, the dominance effect plays analogous roles of the heteroscath. Analogous laws of the hydroscal statistics for continuous traits is time for binary trees. So, just to better appreciate what's happening behind the latent interacting variables for the binary case, I'm going to show some boring slides with a few equations, just basically to better clarify what will happen, capture the consequence of the latent stuff. So, rather than using these classical formulations, I really Using these classical formulations everyone used to express a GLM through the link functions and also the linear predictors, I'm going to take an equivalent approach by specifying a latent variable, a latent liability score approach. So basically I assume the value tree y is the dichotomization of the continuous latent score y star, which is basically having this generating mechanism exactly same to the linear regression case. To the linear regression case, where there is a continuous random arrow epsilon. But one thing that is different from traditional linear regression case is this epsilon has a completely specified distribution, which I denoted CDF as F. So basically, unlike in the linear regression case, we got to estimate the variance of these random arrows here. This term says completely determined. So for probate regression, this So for probable question, it's standard normal variance one, and for logistic question, standard logistic distributions. So here I assume it's some symmetry and a distribution around zero. Okay, so with this way, it's not hard to show the probability of observing one as your outcomes is exactly the probability of these error terms less than or equal to the linear predictors. So you plug in the CDF, you see. So, you plug in the CDF, you see this way and this way, they are exactly equivalent. It's just a matter of whether you specify in linear predictor and the link functions, or you choose the linear predictor and the CDF of your arrow functions. But why do we use this new way to formulate the GLM? It's because it's much easier to study what's going to happen when you have latent variables in your model. So, still start with these true models with both many factors. Models with both main effect and also an interaction effect. But this time, assuming everything involving E cannot be observed, so we have to put them into left-hand side of the probability statement. So basically, instead of having epsilon here, we have a new arrow terms, epsilon subtract this property. Okay, so we make one simplifying assumption without loss of generality that these terms on the left-hand side. These terms on the left-hand side is forcing to a scale family for each value of G. Then that means we can standardize it by the conditional standard deviations of these terms at each value of g. So we divided this function C on both sides. We have a new standardized arrow epsilon star, which again, because we assume this scale family has a well-defined CDF functions. So we can plot CDF functions, so we can plug in the new right-hand side into this. So we end up with this being the working model when the variable E is statent. So just to summarize what we have saw here, we start with the model that has a main effect and also the interaction effect, but the main effect is completely linear additive. Once we miss the interaction terms, it actually becomes nonlinear in terms of G instead of these in functions. Inside of these ink functions. So the nice part of G is because it's simple. So the genotypes can only be three possibilities, depending on the number of mental copies we receive. So we can drag this one, these models, using these three parameter genotypic coding, these three parameter genotypic models. And each of these genotypic effects, gamma 0, gamma 2, can be computed exactly in terms of the original regression parameters, beta g, beta g. So if there is no beta JE in the true model, then you see this function in the denominator is actually constant over G. So when you compute their difference, you eventually get the linear result. So this off-linear RT, which in genetic we call it some dominance effect, is capturing the latent G interactions here. So we can effectively use this gamma D dominance effect to test indirectly whether Effect to test indirectly whether beta G is zero or not. So just to give you a few figures for illustrations, this is the simplest case when you have no interaction effect on your models. You'll see, of course, you can just follow the practice, fetal additive models, additive coded SNPs, and everything is nice linear additives. So the genetic variation 100% is planned by the variances by the additive. By the active part, so there's no dominance effect in worrying about it. But when you start to mess up with non-zero interaction effect, it's really easy to come up with a scenario where this dominance effect introduced by the latent gene interactions actually maps over the original main effect of the osynic. So, in this case, although I start with the model with both main effects and interaction effects, if I go ahead and theta try to Go ahead and fit a traditional advert model to it, it won't have, first of all, it omits all those latent interactions, but also it won't have too much power identifying the main effect because the additive main effect is kind of masked by the dominance created of those latent interactions. So, leveraging this approach, we proposed an indirect test for this beta GE of binary trees using. The GE of binary traits using dominance test. And we illustrate this through a GWAS UK Dow Bank with the trait being the self-reported high cholesterol. So we did QC to select those number of autoformal snakes. And also we select those white British participants phetologistic regressions with covariance including age sex and genetic pieces. So here you link the default, the defect model, the default The default model, the default encodings, if you choose to fit a genotype model, is like this way. So it's contains a additive JA, but also defines a JD, which is kind of like the over-dominance encoding. So it kind of looks not the same as the genotypic model I showed in the previous slides. But in the paper, we showed there is nothing to worry about what kind of encoding, what kind of coding you use. Coding you use to the note-dest phenotypic models because this beta d is going to be proportional to the gamma d we have in previous slides. If you are interested in testing that it's zero or not, you can test beta d equal to zero or not. It's equivalent. So this is the JWAS result using the dominance test. Obviously, there's something interesting going on here on chromatography 19. So there are some, there are four slips flagged with genome-wise significance. With genome-wise significance. And we take a look at the leading one, it's the RS7412 from the April meeting. And this result is kind of consistent with the existing literature on this topic because there have been well-established evidence on how this leading SNP RSM12 here, together with another SNP on nearby regions, form the three haploid calves of A4E. A4E. And when, in the context of those lipid types of treat, it has been well suggested that those haplopath have a haplopath effect, which has been shown to be just equivalent to, say, as GG interactions between SNPs nearby regions. So, is this really the reason of the dominance effect we saw in the GIWAS? We carry out these confirmations. Out these confirmations by picking 65 SNPs near the dominant leading RS7412 and selected, those are based on the B prime and physical distance. Then we test those selected SNPs with, in terms of the GG interactions with the leading SNPs, RS7412. So those are the, this is the histogram of p-value of the GG interaction test. So we found 11 SNPs significant. So we found 11 SNPs significantly interact with this leading one, leading SNP after barflonic corrections. And also this particular SNP with a very significant interaction effect is shown to have a D prime one with this other defining snake report. So this evidence indeed suggests the dominance effect is likely explained by the Explained by the interactions, the missing interactions with the RS7412. But to further confirm this, we then carry out another dominance effect, another dominance testing on the slatted snakes, this time adjusting the interactions with the linear snake. So, if this missing interaction is indeed contributing to the dominance effect we observe, then by explaining it, we should. By explaining it, we should really see a dilution of the dominance effect. And here, this figure shows you the comparison. The figure shows the connected log 10 p-values. X here is the original results. Y here is the new results after adjusting the interactions. So you see, before you do the adjustment, there are 10 SNPs with the p-value of dominance effect less than 0.25. Last density of 0.05, and three of them here have generally significant dominance effect. But after adjusting for these interactions, the dominance effect shrunk for eight of the detentes. So this red line is the 45-degree line. So you see, most of those SNPs, they lie below this line. The result got strong after adjusting the interactions. And none of those SNPs have genome-wide significant p-value after adjusting the line. Just a quick conclusion. Just a quick conclusion. So in this work, we consider for binary trait how to do this latent interaction passing. And we show that heteroscalasticity has an analogy of dominance effect in the context of binary trait analysis. So we propose this approach to indirectly pass interactions based on dominance effect for binary tree. And we use this EOP Delband applications to find interesting SNPs with consistent evidence from existing detritus. So there are some details. So there are some details I need to kind of jump through due to the time constraint, but if you are really interested, please take a look at this preprint available on Dell Archive. That's all for my presentations. My quick question was super interesting talk. So for the A4E example, it has been known for, for example, it also has the stock. So it also has this perhaps a probable dominance effect on higher species as a real dominance effect for I think that's a really good question. So to answer that question very precisely I think it's really hard because just like tetral's elasticity for quantitative trade, right? If you observe it, like the mathematical derivation shows you it is possible to be contributed because of the latent interaction. But is it the only reason causing the Only reason causing the hydroscatosity is hard to say. I think a similar story here. Definitely, this dominance effect is really significant. But in this case, after considering the GG interaction, that would take note. This is like an evidence saying it plays, the latent interaction plays an important role in the dominance effect, but may not be, I think, the only factor. So definitely cannot rule out the Definitely cannot rule out the possibility that it has a biological content disruption. Yeah, yeah, so that's another good question. So here, this coding is using the overdominance coding just because that's the default in implementations. But in principle, you can change these terms to recessive, dominant, or feature codings, whatever, and we show in the pre-processing. Whatever, and we show in the preprint that it just kind of corresponds to a different proportion of the gamma E. So it's still proportional to gamma E. Eventually, you are still testing the dominance effect defining this slide. That should be equivalent. And if you're testing for departures from additivity, whether it's recessive or dominant, overdominance coding will pick it up. Or overdue. Yeah, yeah, exactly. It's just like if you are tasked with Like if you are testing whether it's zero or not, that proportionality doesn't really matter. And I wish I had the same thought. So it's really clever math showing that you can actually do something binary tray. But you're left with the tested balance, and then you don't know, is it because of the balance effect? Is it because it was G by G or is it because it's G by E? Yeah, exactly, exactly. I think that's like a natural. I think that's like a natural disadvantage of any indirect test, right? Just like for Leven test for quantitative trade, well, you see the heterostatistic table. And even if you show by accounting some interactions, you reduce it, you dilute it by some levels. But it really doesn't mean there couldn't be heteroscedacity just in the true mechanism. So that's some unavoidable confounding. C by sleep, couldn't that all be interpreted as a habitab chart or some exactly it's it's a haploid help effect in this case. So the haplotype effect is basically um for those um yeah for those you haploid has defined validity to uh those were working on the handling there is any biological interpretation of habitat or there's a Or there's another sort of people saying you have input errors. I think there's no other snippet that can really capture kappa type or yeah, I think for that one, actually I'm not super sure because like this is kind of some evidence found in existing APOD studies. So people found like depending on like those three Kabul capital kind of interacting in a very complicated Interact in a very complicated way in terms of risk. So, uh the biological interpretation of actually thoughts occur at all. Okay, well, you can see. Although you can still graphicate so you know like a piece of paper when you find things in the material but like the way they interact with your magic after a different equal image. So I think we have between five inch minutes.