So it's okay. Okay, so this is a joint work with Chong Liu and David Prumo. And if you're looking at the title and thinking rough paths and reflected differential equations, this sounds quite familiar. Indeed, it should because Paul Gassier gave a talk on the very similar subject on Tuesday. And indeed, hopefully this talk will somehow complement his. And there may be a little bit of overlap, but I won't assume that everyone. Um, but but I won't assume that everyone watching this has already seen his talk, so uh, so I will give a proper introduction. Um, okay, so yes, so this topic is about reflective differential equations. So that is, we have some differential equation. So if you ignore this k term here, then this is just, you know, just a standard differential equation driven by some signal x. But then we have a reflecting lower barrier, which I'll call L. So the idea being that. L. So the idea being that the solution is constrained to always lie above the barrier L. And the way it does so is with this term K, which we call the reflector term. So the idea is that whenever the solution gets too close to the barrier, then K, this reflector term, gives the solution the sort of minimal push that it needs to keep it at all times above the barrier. So to sort of write it a bit more precisely, so More precisely. So the input of the problem is the signal, the driving signal X and the barrier L. So the barrier in particular itself can be a time-dependent function. And then our goal is to find the pair of, so Y, which obviously is the solution of the equation, and then also the reflector term K is then also to be found as part of the solution. So Y should satisfy the equation in the usual sort of integral. The equation in the usual sort of integral sense. And then, as I say, so y is constrained to at all times being above the barrier L. And then K is the reflected term. So this is non-decreasing in all of its components, starts at zero and satisfies this relation here, which captures the sort of the minimality property of the reflection. So it essentially says that K can only move when Can only move when y is on the barrier, so in each of its components. So, obviously, if so, so for this integral to always be zero, if k has a jump, then y minus l must be zero, right? So k can only give the minimal jump at each time. It can only move the minimal amount in order to keep you above above the bar. Okay, so what does this look like? Okay, so what does this look like? So let's have a little picture. So here's just an example. So here, so the green line is then the solution. The blue line is the barrier. So you can think of y as satisfying this reflected equation. And so whenever it hits the barrier, it gets given a push by the reflected term K, which then looks like this. So you can see that whenever the solution lies away from the barrier, like here, then the reflected term doesn't do anything, it's just constant. Anything. It's just constant. But whenever the solution hits the barrier, then K gives it the minimal push in order to make sure it stays above the barrier. Okay, so that's the basic idea of the equation. Okay, so firstly, I'm going to talk about two different cases. So the first one is the easier one. So there's sort of the Young differential equation case. Okay, and so one of the themes of the talk is that everything can be with jumps. So we're going to look at everything's going to be catalytic paths. So, okay, so I'm going to write for shorthand. So, okay, so I'm going to write for shorthand dp, this is the space of cadillac paths with finite p variation. So we first consider the reflected Young differential equation, which then looks like this. And okay, so then we have the usual minimality condition for the reflector term. And okay, so the point is we have two driving signals, A and X. So A has finite Q variation. Now Q is just between one and two. Between one and two. So it doesn't, you know, it's not necessarily bounded variation, but it's not too rough. And in particular, it's called a young differential equation because this integral can be understood in the young sense. So it's a limit of left-point Riemann sums. And then, okay, so then we have the second signal, x. So x is then allowed to be, so more rough. So the p can be any p provided that we have this relation between p and q. That we have this relation between p and q. So, if in particular, if q is very close to one, then actually p can be arbitrarily large. So, it can be very, very rough. But, of course, it only really appears in the equation in quite a trivial way. So, in order to have a more general integral against x, that's of course where we need the actual rough paths that will come afterwards. And just a small remark about the minimality condition. So, although, as I say, here we interpret this integral in the Young sense. As a in the Young sense, so it's really a Riemann-Stiltsches type integral. So it's defined as a limit of Riemann sums. Actually, that is not the correct interpretation for this integral, for the minimality condition, in the presence of jumps. You should actually interpret this as a Lebesgue type integral. Because if whenever k has a jump, then we need to evaluate the integrand at the jump time. Whereas if you take sort of a left-wing Riemann type integral, then it would be evaluated in. Type integral, then it would be evaluated immediately before the jump, and that would not give you the correct interpretation. So this integral is interpreted as a vague sense, and this one as a sort of Riemann type. Okay, so one thing that Paul mentioned in his talk on Tuesday was the Skorah problem associated with these reflected equations. So the Skorahod problem associated with a path. Problem associated with a path Y and a lower barrier L gives you the pair Z and K. And simply, so there's no differential equation here, it just simply tells you the reflector term, which is the minimal push that you have to give Y to make sure that the resulting path Z stays above the barrier. So, this is actually quite a simple object. So, the scorer problem has a unique solution. Solution. And so then we can write the associated score holder map denoted by s. So, in order to construct a solution to the reflected equation, a simple way of doing that is to combine your usual sort of fixed point arguments with the solution of the scorehold problem. So, the reflection itself is done by the scorehold problem. And in particular, so then there's a result by Falkowski and Sliminsky, which says that the Scorahalt map is Which says that this Korahot map is Lipschitz continuous with respect to the p-variation norm. It is not, as a remark, it is not Lipschitz with respect to the Huilder norm, which is why even for continuous paths, you really want to be using p-variation, or in particular, you do not want to be using Huilder norms here. But then, as I say, so by combining your usual sort of, so we construct a Banach fixed point argument using the scorehot map to deal with the reflection. And then, so, I mean, there's, you know, technical detail to deal with. I mean, there's technical detail to deal with the jumps, etc. But it works the way you would hope. And so you get a unique solution to the reflected Young differential equation. And moreover, the solution is literally continuous with respect to both the p-variation norm and also the scorehold J1 type p-variation distance. Okay, so in the Young setting, the theory works very nicely. There's nothing too controversial, and we get a nice coherent. And we get a nice, nice, coherent theory. But okay, but that now we want to look at the more interesting case where we really look at the rough path case. Instead, this is CAD-like rough paths because we want to deal with the jumps. So we look at standard sort of level two rough paths. So I'm sure everyone here is familiar with the definition. So X is finite p variation. And then this enhancement is then as p over 2 variation. As p over two variation, satisfying the usual gens relation. And then we use the notion of control path, which again, I'm sure everyone is familiar with or has seen in other talks. So the solutions will actually be pairs y prime. So y prime is then the Kubernetes derivative. And then the idea, of course, being increments of y are some linear transformation of increments of x plus some remainder term, which we denote by r y, which is then. Which we denote by Ry, which is then of finite p over two variation. So it's somehow more regular. Okay, and then we can consider the reflected rough differential equation. So we have a rough integral here, and then we have our reflector term, satisfying the usual conditions. So again, we want the solution to remain above the barrier at all times, and then to have, but then K is the minimal push in order to ensure this property. Which, in particular, then the solution to the reflected RDE is then a triple. So it's the solution along with its Kubernetes derivative and also its reflected. But just as in the case of standard RDEs, it's obvious sort of what the natural Kubernetes derivative should be. So again, in order to impose uniqueness, we impose that the Kubernetes derivative should be sort of the natural choice. So F of Y. Okay, so obviously, you know, one hopes to be able to construct a fixed So, one hopes to be able to construct a fixed point argument again. That would be nice. So, let's look at the control path structure of the equation. So, okay, so we know that y, if I look at the increments of y, then I get my usual sort of Kubernetes decomposition here. And then, so for the integral, well, we know again, we know it's Kubernetes derivative and then its remainder term. So now we have the input of k, the reflector. But of course, it doesn't fit into this term here, right? So it has to fit into this term. So it has to fit into this term here. So, in particular, when you try and do your calculations, you really have to consider the k in its p over 2 variation. So, okay, so we need to estimate its p over 2 variation. So, okay, you're trying to do a contraction, so we take two solutions, k and k tilde, and we want to try and estimate its difference in p over 2. But the score hot map only allows us to estimate its p variation. us to estimate its p variation, not its p over 2. So what we would need is to estimate the p over 2 by the p variation. But of course this is just not possible in general, right? Because I mean the p variation norm is decreasing in p, whereas for this we would need to be increasing. So in general this does not hold. Okay so one little trick you can do is to say well since k is increasing it must have finite one variation. Finite one variation. So by interpolation, we can write the following. And then, okay, so since k and k tilde have finite one variation, we can get a bound, we can do some invariance and get a bound on this term. And then you do get essentially the bound that you want. I can bound the p over the two variation by the p variation, but to some power, which is less than one. So you don't get Lipschitz continuity of this map, but you do get continuity, right? You get Hulze continuity. Continuity. Okay, and then combining with that, we can also identify a suitable subset of bounded and equiregulated paths. So equiregulated, if you're not familiar, it's essentially like saying equi-continuous, but for processes with jumps. So our regulated path has both right and left limits existing at every point, and then we want them to be equiregulated. Be equiregulated so that those right and left limits are somehow uniform in all of the paths that you're considering. And then by combining the boundedness and the equiregulatedness, we can get compactness. And then combining that with the continuity we had above, we get existence of a solution by Schauder's fixed point. Okay, cool. So then we proved existence. And then obviously, we want to then consider uniqueness. So there we were. Uniqueness. So there we were, we were working away, thinking, okay, how do we prove uniqueness? This doesn't seem so easy. And then Paul comes along with this preprint saying non-uniqueness for reflected rough differential equations. And we thought, ah, oh no, we can't prove it. But on the one hand, we can't prove it. But on the other hand, it shows how interesting these equations are. Because the rough differential equation, we know this is well posed, this really makes sense. This really makes sense and standard reflected equations also are perfectly well posed. These are perfectly sensible equations, but it turns out when you put the roughness and the reflection together, you actually suddenly lose well-poseness in general, which makes it particularly interesting equations, at least to us. So, and obviously, you know, not to repeat his talk. So, for full details, recall Paul's talk from Tuesday, where he details his solution or his example of a two-dimensional linear RDE. Of a two-dimensional linear RDE reflected at zero, which has infinitely many solutions. So, for full details, I refer you to the other talk. Okay, so obviously you can't get uniqueness in general, but in the one-dimensional case, of course, you can. And so we were quite happy with this result, particularly as its proof is very relatively short and transparent. So, in the one-dimensional case, okay, I take a catalogue-braft path. Then there exists at most one solution to the one-dimensional reflected rough differential equation. So, just to clarify, the driving rough path can still be multi-dimensional, but the solution process y must be one-dimensional. So to point out, again, and again, Paul also mentioned these papers in his talk. So, uniqueness in one dimensions for continuous paths were obtained in both of these papers, but under slightly more These papers, but under slightly more restrictive assumptions. So, our result here is slightly more general, even in the continuous paths. But as I say, everything here is for jumps as well. So, we also have a Cadillac path in our set. Can I ask how much time I have left? Good question. Maybe eight minutes. Okay, perfect. Then I have plenty of time. You know, the hard limit is eight minutes. minutes um so uh so i'll just quickly so the proof of this theorem um so for uniqueness in one dimension um uh the proof is actually quite short and actually i can describe it to you in one slide so since i still have a bit of time i'll just quickly do that um okay so we do a proof by contradiction so take uh two suppose we had two solutions for the reflective rough differential equation and look for the last Equation and look for the last time when they are equal, which without loss of generality we can just suppose is time zero. So we assume that immediately after time zero, the solution split and that they never meet again. Okay, so the first thing you say, okay, either there exists a time such that if I look at the difference of the reflector terms, then this function is monotone on the interval from zero to t, or there does not exist such a time. Right? Okay, so firstly, this is. Right, okay. So, firstly, let's assume that there does exist such a time. Well, okay, so we have some time interval on which the difference of these reflected terms is monotone. But if I have a monotone function, then actually its p variation is independent of p. So its p over 2 variation is actually equal to its p variation. But of course, this is precisely what we needed. You know, we needed an inequality here in order to get the contraction argument. So this is precisely what we need. So, this is precisely what we need. And so, in this case, we can proceed with a usual contraction argument, and then you can get the contradiction. Okay, so that's fine. So, then we look at the other case. So, okay, what about if not? What if there does not exist any time, however small, on which this function here is monotone? Okay, well, that means if it's never monotone, then that means both k and k tilde must keep increasing. Must keep increasing. There must be times, as close to time zero as you like, you must be able to find times at which both k and k tilde increase. But of course, the reflective terms by their minimality can only increase when the solution hits the barrier. Therefore, both of the solutions, y and y tilde, must hit the barrier infinitely many times immediately after time zero. Now, if the path were continuous, then If the path were continuous, then you could immediately deduce that they must meet each other. But of course, if they meet, and that gives us the contradiction we want. And then you're done, the proof is over. But of course, we also have jumps. So the solutions must either meet, but of course, if you have jumps, they don't have to meet because at least in principle, they could jump over each other infinitely many times and therefore they never meet because they keep jumping, so jumping over each other. But then again, you can still obtain a contradiction. Again, you can still obtain a contradiction. So, essentially, you do it by proving an estimate on the amount at which on the size of the jumps of the solutions. And what you can show that is that in order for the solutions to keep jumping over each other, the driving rough path X itself, I mean, X is what's inducing the jumps. And in order for this to happen, you can show that X itself would actually have to have infinite p-variation in order for this to happen. Variation in order for this to happen. And again, that would then be a contradiction since it is a P-rough path. So, in all cases, you get a contradiction, and thus the proof is done. So, the proof is done on one slide. And then, okay, just on the last slide, just to point out that the contraction argument that we talked about here, this works perfectly well in multi-dimensions. So, it follows that even in the multi-dimensional case, if you The multi-dimensional case, if you have non-uniqueness, then this part of the argument is still true. So the solutions must therefore hit the barrier infinitely many times immediately after uniqueness is lost. And indeed, this is exactly what happened. So in Poole's talk on Tuesday, he actually showed a picture of, if you remember, of the solution and how it did indeed hit the barrier infinitely many times immediately after uniqueness was lost. After uniqueness was lost, and what we can actually show from this argument is that this behavior is not just a characteristic of that example, but actually that must happen in all examples of non-uniqueness. So we can actually give a sort of a qualitative description of what actually happens whenever uniqueness is lost. Okay, I think, yeah, that's all I wanted to say. So thank you very much, Velisna. All right. Thank you, Lasa. Are there any questions? 