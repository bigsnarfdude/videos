Second speaker is Er Shan Chu, who is going to talk about quantifying distributional model risks. Okay, so I'm glad to give you the presentation here. This is joint work with my advisor, Yanti, and another UDA graduate. The name of this paper is Qualified Distributional Model Risk in Relax Model Risk. Risk in relaxed marginal problems with all team. So, first, let me give you a quick introduction of what is the distributional model risk. So, in the paper written by Blanchard and Murphy, they define the Worstein distributional model risk as the worst associated with our loss function f as the worst case expectation of f. Of F, where the distribution Q is running over a Watson standball centered as a reference metric with radius delta. Here, the Watson standball is defined by an OT distance. O T distance is the minimum transportation cost between two probability measures, mu and gamma. Here, the cost function C satisfy our very weak conditions. Are very conditions, only the positivities. And next I'm going to introduce the WDRO. WDRO is defined based on the model risk. So give a loss function f theta. is in our parameter space and the And the WDRO is going to find the minimizer that the Watson stand model risk is minimized. So this is our minima experiments. So WDLO is a very powerful tool in many disciplines, including the machine learning and finance, because it has a functionality of hedging against the misspecification of The misspecification of the model and also the distribution shift. The empirical access of WDLO is largely credited to the strong duality. So the primary problem is infinite dimensional problem. However, with strong duality, this hard problem can be converted to univariacate reformulation optimizations. However, the dependency of the Watson sample on the reference measure mu limits the scope of application of WTRO. Especially in the econometrics applications, the reference measure Î¼ is not point identified. We only know a partial knowledge about the reference measure. About the rubber spectrum. Let me give you an example in causal inference to illustrate this point. So, first let me introduce the standard framework of potential outcome. So, here we have a binary treatment status. So, when D equals to zero, this means the individual gets this treatment. So, when D equals to zero, the individual doesn't. To zero, the individual don't receive the treatment, and when the D equals to one, this means the individual receives the treatment. So suppose we have a random sample, Y, X, X is the covariance, D is the treatment status, because the Y1 and Y0 cannot be observed in four individuals, so we can only observe. We can only observe one outcome. Moreover, we also assume the standard selection are observables. So, the first part of this assumption is conditional independency. This means given the coval rate, whether this individual gets the treatment is independent of the potential outcomes. The second part of this assumption is the common support. This means the propensity score is greater than zero and Greater than 0 and smaller than 1. So these two, with these two assumptions, we can identify the distribution of y0 and x and y1 and x, mainly due to the conditional independence assumptions. So we can identify. So, we can identify these two modulate distributions. However, the joint distribution of y1, y0, and x is not identified. So, think about a scenario. We are interested in some causal parameters. ATE is an example. However, the difficulty is the treatment. Is the treatment, the distributional treatment effect. Here, the function is an indicative function. This is not additive separable. So without more information about the joint distribution y1, y0, and x, we can not point identify these parameters. Under some weak conditions, some papers show Some papers show the identified set of this parameter is a closed integral. So the upper bound and the lower bound is just an OT, is just a modular problem studied by Ruchindoff 1991. And to be more specific, the upper bound is a integral where the measure, probability measure, is running over a for share cost. Over Fauchier class. Fauchier class is the probability measure mu with overlapping marginals mu13 and mu23. Mu13 and mu23 means you can think about the example in the causal inference, the covariate part have the same distribution. But yeah, however, we are interested in the case when there are some missed specifications. Some misspecification of the reference measure, or especially when there is a distribution shift, or the identification assumptions, especially the selection of the raw assumptions is invalid. So now we are ready to give you the framework of our methodology to get model risk. Get model risk against the reference measure misspecification and also the partial identification. Think about we have two data sets, S1 and S2. S1 is a product space of Y1 and the covariates X. S2 is another data set, and this is a product space of Y2 and the X. So, for simplicity, we suppose there are For simplicity, we suppose they are both polished space. And we are given two reference measures. Maybe they are misspecified. And these two reference measures have the colouring support on X, on X part. For notational simplicity, for any measure on space S, we let gamma L3 denote the projection of this. The projection of this measure gamma on the space YLN times X. So now we are ready to define what is WMDR in marginal properties. So this model risk is defined as the maximization of integral where the measure is running over a Wolfson state ambiguity. Watson stand ambiguity. So, this Watsonstein ambiguity is defined as the projection of this measure centered at Watsonstan ball, centered at reference measure mu13 and with radius delta 1. And another part of the projection also we see in the Watson's table, another Watson table. So, we don't impose. Watson stand function. So we don't impose the restrictions on the joint measure because we only have the knowledge on the marginal distributions. So the Watson stand distance is imposed on these two marginal distributions. But when the delta equals to zero, our problems is reduced to the routing of 1991. So, before giving you the most important result in our paper, the strong duality, let me give you some notation. So, first define the space B as a product space, and a function psi B is defined for each lambda. Lambda is in R two. So this is definition of psi lambda. definition of psi lambda and for each lambda in R2 plus this means they are non-negative. We define lambda F lambda V, F lambda V is a maximization and we also define F lambda 1 and F lambda 2. So the difference here is just the F lambda minus I'm sorry F minus lambda 1 C one and C1 and F minus lambda 2C2. So now we are ready to give you our results. So this result is very general because we only assume the cost function is measurable and satisfies the possibility conditions. Also, the loss function f is measurable. F is measurable and the expectation or the integral of F is bounded above from minus infinity for some measured in the Fauchi course. So for positive radius, our model risk can be reformulated to bivarricade optimization, where the production is consisting of Is consisting of the linear part. So this is the inner product of lambda and the radius. And another part is marginal properties. So f is defined in the previous slide. And the expectation is taken, is minimum is maximized over a coupling set. So this is for This is for the case when the radius are both positive. So another interesting case is one radius is zero and another one is positive. So this is due. So when the one radius is zero, it can be written as univaricate formulation. And the inner And the inner part is still linear part and marginal problems. So because this is when the F lambda satisfies some weak conditions like semi-continuous, this part can be sought out by Cantor which dualities. So some computational algorithm developed for OT. algorithm developed for OT can be applied to compute the model risk. This slide is discussing the example I reached in the previous slides. When the loss function is an indicative function where the y two part is greater than y one, this is not additive separable. separable. So when delta equals when the radius above zero, this recovers, this is reduced to famous Markov bound as the upper bound and the border risk can be written in this form. However, if we are interested in some model specification of the reference measure and the distance is The distance is the transportation cost is written as a quadratic form. So the model risk can be reformulated in these two, this univaricate, this bivaricate reformulation. So this strong duality for the positive radius implies this model risk is continuous in the radius. And when And when the radius is going to the zero, the optimal value can be convergence to the marginal probability. So I just want to stop here and Any I'm welcome to comment and