Is it is it okay? Okay. So I'm coming out of an embaystic black hole, which is in theory impossible, but maybe there are some quantum physics effects. And so it's really a true pleasure to be able to chat with you and to talk about these topics. And when I evaded the black hole, so I moved of computer science. I moved from computer science to physics and to work with this guy on these topics that are exciting. I'm unable to think about anything else. I will tell you why. So first I asked AI, as everybody, to create some slides for this presentation. And so there is a real one. This is the only AI side, the rest of this presentation is free of any AI. So this slide is just the beginning. You watch at the stars and then you start wondering why is it like that? Was it always like that? There are some mysteries in the sky. And so the mysteries that there are in the sky, first thing is Vera Rubil in the 60s, she was measuring the speed of rotation of the stars around galaxies. Around galaxies. And so she did this type of graphics. So the x-axis is the distance to the center of the galaxy, as symbolized here. And the y-axis is the velocity, the speed. And so this is the theoretical curve, and this is the observed curve. And so there is a big mystery that talks about flats, rotation curve. Here it's even more than flat, accelerating, but most. Than flat, it's accelerating, but most of the time it's rather flat, and so there is something weird because normally, if there was only the matter that we can observe here, it couldn't stay stable. Correct me if I say stupid things in physics. So it should spread out in the cosmos. So another scientist, Zwicky, by exploiting the CRM, the virial CRM, made an estimate of the mass. He made an estimate of the mass that should be there. And there should be a lot of more mass, like a blob of matter around the galaxy. And so he started to seek for this matter in all the possible wavelengths, infrared, radio, all the possible wavelengths, everywhere, nothing, nada. We couldn't observe anything. So they called it black matter because we don't know what it is. But there is a lot of black matter is required to explain this. Required to explain this rotation curve. And more than that, I think that most of you know this picture. Do you recognize this picture? And the James Webb telescope, the first image from the space James Webb telescope. If you look at it, it looks like somebody did punch the screen over there. Do you see it? If you look at the galaxies, they look deformed around here. Around here, around this big diffuse spot. And in fact, if you look, if we could look at that in 3D, the big diffuse spot is a super massive galaxy cluster that deforms the space. And this is Einstein general relativity. And so the light that comes from the galaxies behind is deformed. And there is what they call the gravitational. And there is what they call the gravitational mirror effect. And so by estimating the deformation, you can estimate the mass that is here. And the same problem, a lot of mass is missing. It was already observed before James Webman. Well before James Webb, I took this image because it's a more recent one. So this is for one of the problems. And also, if you look at the nuggets in the Look at the nuggets in the cosmological background that Nikhil has shown right before, you can do statistics on them and estimate also the mass. And always the same, the same quantity of mass is missing. So this is why we believe that there is this dark matter or that we should modify the law of gravity, not super clear. This is where this story of dark matter comes from. Then something else. So, Nikhil, right at the end of the presentation, Right at the end of the presentation, talk about standard candles, standard light bulbs. So these are stars that explode burn away. When they explode, you can estimate their actual luminosity. By estimating their luminosity, you can estimate the distance. And in the end of the years 2000, Perlmutter and Rees did that possible supernova, and they were really supernova. Over, and they were really surprised because they were much further away than they thought, and uh, so it was really a big surprise. And uh, so, in fact, uh, in my own words, that are huge, I will say that the big bong is big bonging faster than we thought, but much faster. And so, it means that there is some energy and they still use the same terminology. Things that we don't know are dark things, this is dark energy, so there's dark matter. Dark energy, so there's dark matter. There is dark energy. Uh, okay, so uh, this one you have seen that already. So, there are these two things: dark matter, but we don't know what it is, dark energy, we don't know what it is. So, uh, we need to do uh to do physics and physics. This is uh creating models and uh doing observation, uh, then trying to constrain the model by the observation. If they don't match, you throw your models away, they are longer. Throw your models away, they are longer. It's not like mass. We can study the equation that we want. If the universe tells us it's wrong, you need to throw the equation away. So, what the equation looks like? Well, first, you will see it's in fact it's much simpler than I thought cosmology, because everything starts by Newton equation, and you get this modeling. I will elaborate a bit on that. F equals ma. And if you don't do anything, everything grows in straight. Don't do anything, everything goes in straight line, like the ZWitch model. In fact, and you got also general relativity, which is a simplified Newton, because Newton, there is first law, everything moves along straight line. Second law, acceleration equals force divided by mass. And in general relativity, there is only first law, but you change the definition of going along a straight line. Going along a straight line, okay. So, there is this equation. So, mass. So, the right-hand term is the content of mass and energy in the universe, and the left-hand term is the geometry. It's a Riemannian tensor. And in fact, Einstein was thinking that the universe was static and the equation couldn't work with a static universe. So, he added a term like that to make the universe static. To make the universe, and after that, there was the discovery of the big bang. Then he said it was the complete balloony, it's completely wrong. He removed the term, look, the equation is nicer, like that. But when they discovered the story of dark energy, they revived this term with an opposite side to make the equation match the observation. Okay, so you got different models. Got different models. There are the observations, kind of observation that Nikhil showed, and that Farmik will be showing 3D map of the universe. And you can do also numerical simulation. We are in a very good situation because we got a lot of data that is coming, and that is incredibly precise. I wouldn't have thought that I would have done something like that in my living. When I see the Daisy Bat. I see the Daisy bat, just crazy. We got computer power to do this kind of cosmological simulation. I will elaborate a little bit on the model. And if you look at them, it looks like caustics. It looks like optics. Christopher has modeled a lot of optics load in transport. In the universe, you see exactly the same type of patterns that you can observe. That you can observe in a swimming pool in a sunny day. And so we elaborate on that. The farming will show a computer animation to explain that in this plantation. Okay, so there is a microwave background. And then the question is, can we create borders, program them, and try to reconcile observation that corresponds to now, in fact, not exactly. Correspond to now. In fact, not exactly now, because as you move further away, you move also in the path. And reconcile them with what we observe in the cosmic microwave background. So now what the models look like. So the type of models that are manipulated in cosmology, I will start with a super simple model. I've got a mass capital M at the origin, mass small m, r is its origin. M, R is its coordinate, and so it's subjected to gravitational forces. So it moves like that. The force, this is just a Newtonian gravitational force. And then this force derives from a potential phi that writes easily. So super simple. Now I am doing that for a large number of particles, so n-body stimulation. So you just sum for each particle. So, you just sum for each particle the influence of all the other particles. You get something like that. But we work at the scale of the universe. So, modeling individual particles, it may be not really when you do fluid dynamics, you do not model individual molecules, right? And at our scale, the galaxies, even the galaxy clusters, are like atoms. So, maybe it would make sense to model to model. To model that with a density field that evolves with respect to time. So, how can we write the equation of this density field? So, this is just the same, F equals MA. So, you are going to derive the acceleration. And also, about the potential, potential at a given point, you need to integrate the influence of all the other points in. Of all the other points in the entire space. So you get an equation, it doesn't look like a local. In physics, we like to relate time derivative with space derivatives. And this one, it does not look like a physics equation. But if you look at this equation, you can recognize the green function, the kernel of the Poisson equation. And in fact, the kernel of the Poisson equation. And in fact, the kernel of the Poisson equation allows you to express the solution of the Poisson equation as a convolution with the kernel. And so you reverse engineer this equation. You say, oh, okay, I see. There is k here, one over x minus y times for pi. And then you deduce that the potential obeys a Poisson equation like that. And then it's very nice because Very nice because then you can write the equation. So you got f equals ma, so you write it in Eulerian coordinates, and there is a convective term here to take into account the fact that you are in Eulerian coordinates. And there is the Poisson equation for the potential. But of course, any potential and any density. And any density field won't be compatible, and you need an additional equation that is mass conservation, which is the continuity equation. So you get this type of systems, the Newton Poisson system, which is just Newton gravitational law, but written for a density and in Eulerian coordinates. This is equation for a self-gravitating cloud of matter. Of matter, but then there is something else. There is the expansion of the universe. There is this A parameter that depends on time, or you can also say that A is a time. We love to change the time parameter in this equation. And this square becomes very large, very fast, in fact, to cube mines. And so A of T grows very quickly in function of T. So it's interesting to interesting to to to freeze this square and to uh to look in what happens in this square to do a change of coordinate and to see i don't care about the the size of the square i just want to to look at the movement of matter inside the square by fixing its size so these are called co-moving coordinates because they grow uh with the expansion of the universe and if you look at a of t uh then in fact what you are doing you are In fact, what you are doing, you are pushing all what depends on relativity at a certain scale. You are smoothing out the effect of relativity. And so A obeys an equation, this Friedmann equation, and that you can deduce A of T in a certain set. And once you do all the change of coordinates, and also you replace rho with density control. With density contrast instead of absolute density, you end up with this equation that is very similar to the initial Newton-Poisson equation. There are some differences that are circled here. Differences is that there is two, so it's no longer A or T is two. Two is the cross of the structure. It's very convenient to use it as a time parameter. It appears at the denominator. Parameter that appears at the denominator here, and in the initial condition, two equals zero. And so, so this is interesting. And in fact, this has two consequences. For this ga to be non-singular, rho should be equal to one at the initial condition. So, it means that the initial density field should be uniform, else we are dividing by zero. The universe doesn't care about us dividing by zero. The good news. Earth dividing by zero. The good news is that the universe agrees because the cosmic microwave background is very, very uniform. The variation you can see in the images are 0.001%, I think, incorrectly if I'm wrong. So this is good news. And what about this guy? This guy says that for two equals zero, but there are these two terms. So the force, there is the gradient of the gravitational potential, okay? And there is another. control okay and there is another part which is the which is the you can if you think about the big bang at the initial pick and then uh then everybody will want to continue uh with the same uh velocity and so so this is this is an expansion so it it tends to make things grow and you got uh you got now the gravitational force they act in uh the in the reverse direction they tend to make things collapse To make things collapse, so there is nearly a balance between them. So, this one is called a purple drag. When you are in the, it acts like a drag that slows down gravitational persistence. And in fact, these two guys, they nearly balance, which means the same doubt check approximation would say there was just a kick. And then after that, we don't do anything else. Everybody continues in a rectifiliar uniform motion. It means. Uniform motion, it means we consider that gravitational potential and Hubble drag exactly interbalance, which is an approximation. But we are not obliged to do that. This approximation makes sense because at 2 equals zero, grat phi and v should correspond, else this guy would be singular. And in 1D, they always correspond through the entire time regulation. But in 3D, it's no longer true, but it's. No longer true, but it explains a bit why this approximation is not too stupid and why we observe rather rectangular linear motion in the n-body simulation. Okay, so now what about the inverse problem? The inverse problem, so we take a 3D map of the universe like that, and we would like to reconstruct the entire machine. So it seems super under constraint to do that. Under constraint to do that. So, how can we do that? Well, the idea is to take, or there is this Newton-Poisson equation, there is another format, there is the principle of least action. And you can say that the motion of the system minimizes an action integral, something that depends on the position and velocities integrated over space, integrated over time. And the action that corresponds to the previous. And the action that corresponds to the previous Newton-Poisson system is this one. With the boundary condition, that the density should correspond to what we have, and the density at the initial condition should be the Z Lebesgue measure, because we suppose it to be uniform. And then, well, you can, if you look at the equation, well, these three other two terms, they are a bit annoying. They are a bit annoying, so I will score them away. So, you forgive me, I am a physicist or a computer scientist. So, sinus x equals x, pi equals three. So, three over two, I say it's three alpha over two, and I make alpha tend to zero and take, and I've got kinetic energy. And kinetic energy, you all know where I'm going and with kinetic energy. This is a Benamou Brunier. This is exactly a Bename Bronier. Brunier is exactly a Benu Brunier problem about the boundary condition, minimize kinetic energy. Everybody moves along so why here, in fact, I won't get rid of it because I would say that the influence gravity plus dark term, maybe it happens. Back there. Maybe it happens like before. What I'm computing here is what I call the picked equivalent motion, which is you integrate over the whole period of time the influence of the dark term and the gravity. You obtain the whole motion. I will elaborate a little bit on that. So you've got, it can be any motion like that. But what we are interested is just the starting point and the end point. Point and the end point. We want to know who went where, and we don't really care about the actual trajectories. And can we reconstruct this information? So here I am making too many assumptions. I am making an assumption that corresponds to Zeldovich. And one may think that it is embedded in my assumption, but in fact, it's not. I will elaborate on that. I don't do that. Roya, who is listening, will kill me because she's struggling to say, no, it's not. She's struggling to say no, it's not the bitch, much more general than that, and she's right. And uh, but um, uh, okay, so uh, we get that, and so we want to know which point corresponds to which point. And so, there is uh this Bonnet Mounier theorem that says that minimizes this action, kinetic energy, is equivalent to finding the optimal transport method. But in fact, small. Map. But in fact, it's more than that because if I say, okay, I've got my trajectories. I don't. And suppose that I know who went where. So now, and suppose now that I am only interested in Q and X equals T of Q. I'm only interested in that. And with the transport problem, we solve for a potential, the Monjean-Pair equation. This is a phi, and our mapping is... Our mapping is the gradient of this potential. And here I didn't make any assumption about Zelda Rich or whatever. The only assumption I make is that the displacement is a gradient of this potential. And now, if this potential is convex, then we got the uniqueness of the decomposition of the mapping as a gratite composed with identity in R. With identity in our presence. So there is this Brunier decomposition theorem, and that if grad if phi is convex, then the only decomposition of T is grad phi composed with identity. So in fact, small, more general. It's an intuition to give only a physical intuition of what happens, but it's just an effective motion that we compute. And it's not the physics, the modelling of the physics. Modeling of the physics. Okay, so if you think about it in a discrete way, you can map discrete points to discrete points and use discrete algorithms. And in fact, we are going to go much faster than that because there is a semi-discrete setting. So here I've got an introduction on optimal transport that I will skip because I see that everybody. Skip because I think that everybody knows that. So there is general optimal transport like the counter of each problem up and the optimal transport plan. I'm just stopping on this side because this is a slide I made for computer scientists. And I explained to them that the optimal transport map, the idea is to solve for a pixel image, and computer scientists like pixels, and your unknowns. And your unknowns are just the brain level values of this pixel image, which is the graph of T in a certain set. And then I've got, okay, countervisuality. This one for computer scientists, I do it in a discrete way. And so you write marginal constraints, and everything should stem over the rows and the columns. Check. And so then it gives rise. So then this gives rise to an intuition to the sinkhorn iteration because sinkhorn iteration in this space you you just sweep a little bit, sweep a little bit, sweep a little bit, try to convert you into regular eyes with roll or grow, else you get stuck in the constraint in a certain sense. But this is not what we are we are doing. Then we you can move to the to the dual. I do it with vector and matrices because it's easier for And matrices, it was easier for a computer scientist. It was quite easy to see that in the end you got the dual problem, you do a little bit of algebra, trivial algebra manipulation, and you got the counter of each dual, which is this problem with a new constraint. Okay, and then if you go back to continuous, transform vector into functions and matrices into linear vectors. Into linear operators, you got this formulation. I got the two Lagrange multipliers. There are the U and V's of Nickel. And there is, in addition, this story of the C conjugate. You can replace one by the C conjugate of the other one. But you guys already know all that, so I won't spend too much time on that. So now so I move to the semi-discrete story. this semi-discrete uh story semi-discrete i was really uh amazed puzzle because for now we we had a rather continuous story starting from the physics to optimal transport and now we need to program it and uh what happens usually when you program maths you need to torture the math and to to shape the equation into grids or project them onto function basis and what send up you And what send up you? It's like a caricature of the mask, but here it's not the case. It's nearly no detail lost in translation. Let me explain you why. So, okay. Hi, yeah. So, on my webpage, you can find all the software that I will be demonstrating. If you want to play with it, it's accessible. So, there is the continuous transport. There is a discrete to discrete transport, a semi-discrete. So, you transport. Discrete, so you transport a density to a sum of direct masses like that. So now what we are going to do, we just write the equation. So this is a general counter-ovidual, but now the right term becomes just a weighted sum of Lagrange multiplier. The Lagrange multiplier style is just a vector in a certain sense. And then the leftist. And then the left one term, you need to replace the Legend transform of psi with its equation. Look like that. So you've got the integration of the domain of the Legend transform of Psi. And then there is an F here. At each point of X, you need to find the dot that minimizes this quantity. But then this is where the computer science enters the scene because we could free But we could freely decompose the domain into the zones where the term is achieved for a given height. This is great, a partition of this space. And then you got this formula, the sum over each of these regions of the integration of this function. Okay, so this is defined called the Laguerre diagram, defined like that. Fine like that. And so it can give you an impression of wedding vision. Like here. So I think that you already know about the Voronoi diagram. I think Voronoi diagram is for each dot here, I'm going to skip into the points that are nearer to the dot than to the other other dots. And so in fact, this diagram, I cheated you because, in fact, it's in three DV. In fact, it's in 3D. Chuck in 3D. I put the parabola on each of the points. And if you look at it from above, you can see the lowest parabola, the minimization diagram of the family of square distance to each of the blue dots. And when we look at it from above, the intersection between two paraboloids is a parabola that lives in a plane that is orthogonal to the screen. That is orthogonal to the screen. And so we can see a straight line. And so now we can play a bit with it. And imagine if I take one of the parabolas and I shift it or I pull it. I don't know what it will do. Let me discover. Okay, so I pull it towards me like that, or I push it. Okay. And so let us see now what happens when I look at it, remove the lighting and do the same. And do the same. You see, it changes the area of this cell. I can even swallow some other cells. If I'm too greedy, I will eat up all the space. You don't want this to happen. But so it's interesting because I've got a Voronoi diagram with tuning buttons, actually. And the tuning buttons, if we go back to the formula here, actually, Actually, we know that there exists a value of the tuning buttons, of the size, the amount of shifting along the axis, that achieves exactly the measure I wanted for the Lager cells. And the second thing, the Lager, what is this Lager diagram? Actually, this is a description of the optimal transport map because the Lager cells corresponds to the region of space that is mapped to one of the weighted derivatives. One of the weighted direct masses. This is all the story about this semi-discrete optimal transport. Just take the general counter-of-digitual, write it when the right-hand side is a weighted sum of the arcs, and then you see Laguerre diagrams appearing. So I'm super excited as a computer scientist because Laguerre diagram, I can compute them. And then also the counter-ovid dual, it's easy to. The counter of HDUL, it's easy to prove that it's smooth, C2 in function of the P side, and it's concave. Of course, you all know that there is a unique solution to the problem. So you can program a Newton method to do that. So here. So I've got some problems. Okay, so here I'm taking a number of points. So in the first step, I am playing with one of the Lagrange multipliers. This is the same demo as before. Change the weight to the Step three. Hi, there's also something interesting about the weight. So people usually think about the Laguerre diagram as a Voronoi diagram that will slightly change the shape of the circle. In fact, you can do much more than that. You can, by just changing the weights, you can completely translate a Translate a Voronoi diagram. And this is quite surprising because, but the cells do not necessarily contain the points. And it's good news. We are doing cosmology, we compute the transport of matter. So as Nikhil was saying, it's not traveling a lot, but it's traveling. There is no reason for constraining the except to contain the point. It's left as an exercise. You can find the value of the weights that achieve an arbitrary. That achieve an arbitrary translation. Chuck? Okay, and then where I advanced if I do this one. Okay. And then if you can do an iterative algorithm, a Newton algorithm that will that will update the the weights in order to uh to maximize the front power of each. To maximize the turn power of each gap, and so here the constraint is the same area for all the cells, and you see that the diagram will evolve in such a way that the cells have the same area. Something important in the Newton algorithm is steppelands control. And we got a wonderful CRM by June, Contamia and Boris there that tells us how to do steplance control. Steplen's control, and there is a proof that we will reach the optical. And this CRM, so the math work, but it works for real. When I'm saying that, excuse me, I am a computer scientist. Sometimes you got a CRM. It tells you that it will converge one day after a finite number of iterations, finite amount of time, but it can be longer than your left time. Here, it's not the case. It's really a few, a few iterations. This is fantastic news because Is fantastic news because here we are really integrating the influence over special regions. We are manipulating smooth functions, computing gradients and SEN, and we are doing numerical optimization. It's much, much faster than doing combinatorial optimization. Okay, so back to the presentation. Okay, so one way of thinking about that, I like starting from I like starting from a Voronoi diagram and lifting it. And you see the shadow moves a little bit. I like this basic optics. And so how do you relate that? Well, you can translate that into a geometry. Think about the Laguerre diagram as a sectional Borneo diagram, intersection between a here a 3D Bornois diagram to be 4D cosmology with the plane or with a 3D space. Plane or in the space, and then how to do a translation. This is the solution to the exercise. It's a square root of translate like that. Okay, and then you can do different things. I've been playing with splitting and merging things. Then you got the Newton algorithm and with the Titegawa, Merigo, Tiber algorithm to find the alpha telescope. To find the alpha tells you how much is reasonable to move forward in a direction. Okay, and so another example here, something that looks like posology in 2D with wide variation of areas. And now, starting from the Voronoi diagram, the areas of the cells are very different. And then you do the Newton iteration. It's a bit explosive, right? It's like a big bomb. A bit explosive, right? It's like a big bomb. And after that, convert the shape of the circuits can be very elongated, can be a lot of anisotropy. It's normal, the solution to a Mangent-Paire equation, they can have a lot of anisotropy. So what I can show you before can show you what we did with that. What we did with that. What we did with that, we did a computer simulation, big end-body simulation, because doing a simulation, you got the starting point, so you can cheat. And so these guys, they gave me the final condition, kept the starting point so that I couldn't cheat. And they said, can you reconstruct the initial condition? And then we compare. So it was quite interesting. It's challenging, cosmology, because Cospology because we're here. This is a cube, 300 megaparsec, the length of the edge, 300 megaparsec, and there are like 100 million points in this cube. So it's challenging because of the size of the data, and it's also challenging because there are wide variation of density. If you if you look, there are zones, normal and gravity, everything uh collapses. Everything collapses. And so it's terrible because when you compute the Laguerre diagram, sometimes you nearly divide by zero. You need to be very, very careful with the representation of the numbers in the computer. And so here it's a part of the Laguerre diagram. I cannot display the entire Laguerre diagram because it has one hundred million cells. Because it has 100 million cells, but if I do a zoom in a tiny region in the center of the cube, you look at the Lager cells, and then all the computer science story, I won't dive too much into the details, is about how can you compute a Laguer diagram very efficiently. And we developed different parallel algorithms. And now the next one will be a distributed algorithm that runs on a PC cluster. That runs on the PC cluster. So, I would like to go beyond one gig article. It'd be great if we could have that. So, I go back here. And here I've got another example. This example, it looks less challenging because much smaller. It's 60 megaparsecs. So, it's maybe 100 times smaller in terms of volume. In fact, it's more challenging. Volume. In fact, it's more challenging because at this scale, the variation of density are crazy. I've got variations of lenses with five to six orders of magnitude. And then here, if I zoom over a blob, there are many, many, many points turned on the blob, and so it's challenging to solve the problem. Okay, so. Okay, so this was for the inverse problem. And then I will also say a few words. How much time do I have? 10 minutes. Okay, perfect. I will say a few words about the diad problem. How can we compute forward dynamics with optimal transfer? So where? So, well, so there is the Newton law. This one we have already seen them. Here, slightly different. There is a density contrast rule minus average. It was already in Nickel slides. And so there was Jan Brunier's idea. Jan Brunier's idea on Mon Jean-Père is based on the development of the determinist. The development of the determinant around the identity matrix. There is this formula. And if you say that epsilon A corresponds to the Hessian matrix of pi, and then epsilon trace of A corresponds to the trace of the Hessian, that is the Laplaceian, then you got this equation that relates. That relates the Mangent-Pere operator with the Laplace. So I write it like a double triangle, say slight Laplace, but slightly more complicated. And then if you look at our Newton Troissance system, you can play a little bit with the equation. The constants are a little bit discussion about the constants, but you end up with a But you end up with a Newton Poisson system that is not a Newton Poisson system, a Newton Montgomery Montjeum-Père system with the Montjeon-Père operator instead of the La Pess operator. So it's funny. Okay, so then here there is another slide about the relation between the determinant of the HN, that's the Montchamp operator, and the That's the Montchampere operator and optimum transfer. So it's an explanation, I think, the initial intuition of Jan Brunier. So if you take this equation, so I will write it like that. So and you take the optimal transport problem, that is finding T that minimizes the transport cost under the constraint that rule That rho should be the push-forward of rubber for each bore set T minus one of B contains the same amount of mass as B. So you write it like that. And intuitively, if you think about that, I say instead of B and T minus of B, I will use a G function. You can think of G as the indicator function of B and minus one of. function of b and minus one of b so you got this constraint easier to write because now i only got functions and for for all functions then you can write uh write it as a lagrange multiplayer formulation with psi uh associated to the mass conservation constraint and uh then if you look at the optimality conditions of this lagrange optimization problem first order Problem. First order optimality condition gives you that R equals gradi of T of R. Unfortunately, this is the other way around that interests us, but Ayatollah will elaborate on that. And second order optimity condition tells you that Psi is a convex function. And to go the other way around, you need to use the Legendre part. You insert that into the constraint. Into the constraint, and you look at that pointwise, and you obtain the Monjam-Paire equation. This makes you the relation between both problems. Okay, so now you can relate that with a discrete transport map, point to points, and where sigma is a permutation that minimizes the transport test. And then, in fact, our course in the Newton press. In the Newton Poisson system, when we replaced the Poisson operator with the Montgomery-Per operator, the force means that you are repelled by your mates through the optimal transport. Each point is repelled by a single point, which is its mate in the optimal transport. Okay, so and then you can program that. I will show you a couple of That I will show a couple of images, but before forming that, so the initial intuition, I think the initial intuition of Yen was I can replace the Laplace with Montgomery-Père, and interesting things will occur. But can we find a physical motivation to do that, a physical principle that leads to that? Yes, there is a way of deriving that. We wrote an article about the large deviation principle. So, how it works? So, how it works? Okay, can we deduce this formula from something else? And so, the idea is very similar to the principle of east action. You know, principle of east action. You suppose initial and final conditions are fixed, you minimize the action, you deduce from the stationarity of the action a differential relation between the position and the velocity, and then you can transform that. And then you can transform that into a Cushy problem and have the evolution look. Yes, it's different. It's more something based on statistics. So we are going to suppose that we got a number of indistinguishable particles. Very important that they are indistinguishable. They move according to Bronyan motion and they do not interact, except there is Brunian motion, but Except there is Bronyan motion, but put differently, all the interaction is captured in the Bronian motion. And we suppose that we observe the cloud of particles at time T0 and at time T1. We observe them. And then the question is, what is the most probable motion of these particles accounting from their indistinguishability and that satisfies this observation? This observation. And so, if you write the probability to observe up to permutation, the point cloud at a certain position after a time t, so you have this type of formula and you look at it. This is how people doing artificial intelligence. Each time there is an arc in artificial intelligence, you want to differentiate, so you replace it with a smooth nerf, which is an exponential with the. An x, an exponential with the different terms like that. So it's a smooth term, in fact. And it's also the same thing that happens in Dirac integral or fine-line integrals. Only one term takes all the influence is enormous as compared to all the other ones. And so if you look at the term that remains corresponds to the optimal transport. And so if you make temperature And so if you make temperature epsilon ten to zero, this half becomes enough, and you get the optimal spar. Then the trajectories become geodesics. And so this relation is valid at the final point, but it's also valid at any point of the geodesic, you get the acceleration that you are repaired by your friend in the optimal transport. The optimum transport. So, okay, so now how to simulate that? Simulate that, we can reuse our semi-dispute setting saying that instead of having two different times, we got three different times. There is an initial time where there was a uniform cloud of particles, but modeled by the Lebesgue measure. And there was a time T1 where the structure were formed. We suppose that the We suppose that the particles clustered, lumped into a set of structures. And then these structures start moving until time T2. And so if you write the equation, you will see that a red point here, instead of being repelled by a single particle, it's repelled by the center of mass of its pre-image through the... It's pre-imagined through the semi-displayed optimal transform. Okay, so then you can program that. And so we did some cosmological simulation with 300 million cells. And then if you compare what it looks like, so it's interesting because the overall look is the same, but with Montgomery-Père, you got less. You got a larger number of filaments, you got more anisotropic structure, and they are more diffused at the same time. So it's interesting. This is confirmed by measuring the power spectrum in the simulation at different times. The left part of the graphic corresponds to the large scale structure and the right part to the small scale structure. And the small scale structure, of course, they differ and as time passes. They differ, and as time passes, they differ more and more because they are more fuzzy with this rabbit. So, I did also simulation at 60 megaparsec, a zoom simulation, and then you can see in the end these structures are really much more fuzzy than with the standard gravitation. And here we can see also that the filaments are, you got a larger number of filaments. And here, if you look at this, this produce looks like. This produce looks like a pointiest painting. You got rather circular amounts of matter, and here the structure are more anisotropic. So is it interesting for describing the laws of nature? I don't know. But what is no, I know it won't work because if you take this equation as a scale of the solar system, it would support the It would for the expansion of the determinant around the identity to be correct, the term should be an epsilon, it should be smaller than the identity. And for it to be true, you would need a huge density of matter in the solar system, which is not the case. But this is still interesting for other models of gravity where the Montgomery-Per force does not replace gravity, but acts as an additional force. This is Roya and This is Roya and Albert Bonnefoux have been and Jan have been studying that. This is something we plan to simulate. Okay, so I will reach the end. So what we'll be doing next with the plan for exploring the shape of the universe at different scales using optimal transport. So first, large-scale structure of the universe is what we have been talking. Talking. What will be interesting if I am taking my most challenging simulation of today, which is 60 megaparsec, 100 million points. Looks like that, if you do a slice on it. I would like to do 300 megaparsec with the same resolution in order to capture the fine-scale dynamics. So it means that by 60 megaparsec cube, By 60 megaparsec cube, it's it's here, so it's 125 larger. And uh, you know, my computer nearly died to do that. And so, here I'm going to kill 125 computers instead of a single one. It's not trivial because you need to make this guy communicate and exchange points and do things like that. But we've got an algorithm, this is good news, and I've got a new postdoc who will start working on transformation. Start working on transforming the algorithm into a program. It will take some time, but I think we will be able to do that. This is 1.7 billion once here. So it's probably the largest instance of an optimal transport that somebody ever dreamt of solving. But we will see what we get. And then there are other things that maybe Farnik will be talking about that. I don't know about Galax. about galactic dynamics, relativity also crazy project about Telabu manifolds that are a structure used in string theory. There are CRMs that say that they exist, but nobody ever computed them. And to compute them, you need to solve a Montreal-Père equation. It's a complex Montreal-Père equation. Maybe we can do that. So, okay. So I think I will stop there. I think I will stop there. Here are a few references, including some mass references. And if you want to learn more about relation between optimal transport and cosmology, I recommend this one, second reference, because it's a super long paper, but it's really a good fresh course on cosmology. This is where I started to learn about this concept time ago. So, thank you very much for your attention. Attention Thanks for the really nice thoughts. So I was just, I just find it really fascinating of the module pair variant being more diffused and fuzzy. Do you have any high-level explanation of why this like why you can't discord? I've got some interesting. So, first, why is it more anisotropic than the Poisson equation? Because Poisson equation is invariant with respect to a rotation. And Moujam-Père equation, there is some invariance with respect to a shearing, a volume, conserving transport. And this is optimal transport. This is mass conservation. And you got additional degrees of freedom. Degrees of freedom. So, these additional degrees of freedom you can create elongated structure. And now, about the diffuse aspect, if you look at the Newtonian gravity, there is a singularity when we go to points at the same place. And you don't have an en-body simulation with Newton gravity. You are not guaranteed to stay bounded and become a bonded. It's no longer the case with. Abundant. It's no longer the case with smaller paragraphs. There are tools in Jan Bronier's article about that. So, this model is tractable. There is a Donemu Brunier version that works for this model, but it's super difficult to program. But at least mathematically, there is complexity, existence, uniqueness. It may be slightly different, but there are still. Still, there is still this space-time formulation with the same duality and Lagrange multiplier. There are more constraints. The equation is much more complicated. It's less symmetric, but in the end, they could prove, I think, maybe Réguire Le Pair proved it. I am not sure. There is a reference to the other paper, I think. Yes, I would say yes and no, because in fact, when we solve the optimal transport problem, we are not obliged to say that we are doing the Lubitch. We say we solve for the potential that matches mu to nu. And then we could completely imagine that our trajectories, the physics, were completely different in between as compared to As compared to the Lovitch chance, this is because the potential for which we solve is like an effective potential, an average potential over the whole time evolution. But we need first that this potential exists, because displacement, if it's potential, then it wouldn't work, but in practice it's nearly the case. And we need this potential for the decomposition to be unique. The decomposition to be unique, we need this potential to be convex to get Z1. I would say it's not exactly the same because there are some regions where particles collide. This is where all the filaments are formed. But the potential looks like big zones where it's exactly convex and some small zones, maybe at five megaparsec or a little bit less than that, forming the filament. Bit less than that, forming the filaments where there can be uncertainties in the upper section. The important fact is that we get the overall trend of the reconstruction, and that's interesting. So, for the point of condition, I'm using like the actual operation. So, I guess you mentioned that if the The spatial scale is large, then there's actually a time in the observation. So as you go further out, it's actually not current. So is this just like at a scale that's so small it doesn't matter? Or do we do something to kind of account for that? We need to do something. We had a long discussion with Bernick, Ikil, and Sebastian yesterday. There are several strategies. One strategy would be to change the cost in the multiple. Change the cost in the optimal transport problem. But then, if I take my computer scientist hat, I will say, hey, guys, you are crazy. I'm unable to compute the Lagier diagram. But this is something, if this is the only solution, we will suffer like crazy, but we will do that. And there is another solution, which is in the famous article with everybody, that is an interactive algorithm to pretend that the Red Schistos is a physical. Position in the physical position. So then move the particle at its correct position because you get the average velocity. So it's like a Newton algorithm, I would say, in a certain sense. We are not sure it can work, but we got some hints that maybe this is the next step. The next step will be trying to do this algorithm on very simple scenarios and see what. Scenarios and see what happens because this would be the best scenario, the easiest one for us. We could do that. And there is also another scenario. This is in an article that we published where if you consider not too wide a portion of the scale, then you can say the triangular sector becomes like a cylinder. And if the distance scale is not too far away, this is basically. Far away, this is basically just an anisotropy that you add, and it's constant for the whole volume, so it does not change the transport problem. This is what we did up the now. Thank you.