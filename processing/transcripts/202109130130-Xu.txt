Okay, okay, I'm gonna today I'm gonna talk about how possible and also I will mention some application in optimization. Okay, so let me start with the definition of helper. Now I want to To begin with with here, down here, here okay let's let's consider a hub space H okay now in hub space H you have an inner product, you have a norm. I use this notation for the product and for the norm. Now I want to introduce I want to introduce the mapping down here the definition. Okay, the mapping T from H to H is said to be non-expensive if T does not increase distances. Okay, that's the definition here. Okay, giving any two point X and Y, the distance from TX to Ty is no more bigger than distance from X to Y for all X and Y. This is a very, very important. This is a very, very important class of non-linear mappings. Okay, now let's recall the definition of fixed point. Okay, a point x is a fixed point if t of x equals x, then the x is a fixed point. Now, fixed of s denotes the set of all fixed points. A more specific class of mappings are called alpha. Alpha averaged. Okay, I just said alpha A V for short. If T can be written as a convex combination of I and V, now the combination coefficient alpha is strictly between 0 and 1. V again, so such a mapping is called alpha A V. Okay, and this is a very important class of knowledge. This is a very important class of non-linear mappings. Now, obviously, okay, we have the two facts: okay, the fixed point set of P and the fixed point of V coincide. This is number one. Number two, okay. T has a fixed point if and only if T has a bound trajectory. That means for some x, t to the nx, it bonded. Okay, that's a consequence in the cube space. I just mentioned these two fundamental things. Excuse me, what is I in the decomposition of T? So in the definition of alpha A D you T is alpha A V y T can be written. T is R A V if T can be written in this form. What is I? I identity. Sorry. Oh, I see. Yeah. Yeah. Identity map. Okay. Now let me show you some A V's. Okay. Some A V's. For example, the first, most, actually, the most important instance is here, down here, GC. Okay, if you have a non-empty curved convex substance. empty curved convex subset of H, then you have a projection, projection defined by this minimizing problem. Okay, giving X in H, the P C X is the only point which assumes the shortest distance from the point X to set C. Okay, that's the definition of P C projection. projections are important also projection has nice very nice they have okay they are actually one over two a v that means that means okay p C satisfies this inequality this inequality this is the example of A V Of AVs, okay, a particular example which is one over two AV. Okay, now let me mention the PGN, the projection gradient. Okay, what we want to minimize a function, phi, over a set C. Now, what is phi? What is C? C, again, is a non-empty closed. Is a non-empty closed convex subset of a Hubble space. Now, phi. Phi is a proper lower semi-continuous convex function. Now, in notation, we write phi belongs to gamma zero of h. So that means gamma zero of h denotes all such functions. But in our case, we assume phi is continuously differentiable. Okay, then the minimizing problem 1.1. Problem 1.1 can be solved by so-called PGM projection gradient. Now, this method PGM generates a sequence Xn by the following algorithm, 1.2. Okay, the left here, the most left in PC. Now, here, this is a gradient of phi. Okay, so this is a call, this is a projection. This will be called the projection, okay? Gradient method. Now you have operator P C composite with I minus lambda greater than phi. Lambda is any positive constant. Now, this operator will have nice property if we assume. We assume more on phi. Okay, the condition is this: the gradient of f L Lipschitz. The colladience of phi is L Lipschitz continuous. Now, this means this Lipschitz continued the condition. Under this condition, we can prove that the generating operator in the PGM is actually Is actually A V if lambda, the step size is selected between zero and two over L, then this operator is actually A V. Okay, this is another very good thing for minimal land problem. Okay, now if we move to Now, if we move to the more complex, so-called complete optimizing problem, if we want to minimize over the whole Hib space the sum of two functions, f plus g. Now, here f and g are both in gamma zero h. Now, this composite minimum mining problem can be solved by a very well-known, now quite well-known. know now quite well know a very powerful algorithm which called prox gm okay prox gm prox proximal gradient that we write prox prox gm now prox gm generates a sequence according to the formula down in the formula 1.4 okay so from the formula you can see we still need a gradient of f so we need to assume that f So we need to assume that f is continuous differential. Now in the front, we have prox lambda g. Now what is prox lambda g? Prox lambda g is called proximal mapping of g, which is defined by the formula 1.5. Okay, for x in h, proxy limit of f is the only solution to the minimizing problem on the right-hand side of 1.5. Okay, you can prove, you can prove, okay. Okay, you can prove, you can prove, okay? You can prove the right-hand side minimum margin problem has a unique solution, which is used to define the proxy energy. Now, again, if we assume the gradient of F is Lipschitz and the stable size lambda is select in this. Is select in this range. This range. Then the defined operator prox lambda g composite i minus lambda greater than f is a v. Okay, if lambda is strict between zero and two over l if lambda equals two over l, then you have non-expansion. You have non-expensive mapping. Now, if you want to make applications, now let me just mention Rasu. Okay. This is the Rasu problem. Raso problem actually can be stated as minimizing problem, which is special case of the composite of the you see, it minimizes the sum of two functions. The sum of two functions. Okay, the first component here is the L2 norm, the squared L2 norm. Now, the second part is L1 norm. So the first part is continuously differentiable. The second part is not differentiable, but both are convex. Okay, because now this Russo is stated in finite dimensional. So A is M by Matrix B is belong to R. B is belong to I. Now, under certain conditions, we can prove. We can prove, okay, this Lascelle problem is equivalent to the sparse recovery optimization problem, which is minimize a zero norm of X subject to X equals V actually. Now, E is the noise. Now, this is a special case. Now, this is a special case of the composite minimizing problem, which can be solved by prox GM. So the prox GM now become to the algorithm 1.8. Okay, now this T A T means transpose of A. Now prox lambda L one, this is the L one. the L1 L1 norm L1 norm the proximal mapping of L1 norm can be computed in a formula so this is a concrete sample of of the composite optimization so so we need we need the average wrappings wrappings okay now how to find how to solve how to solve this then we need we need down here how can we need how can iteration how iteration now what is happening what is happening okay let me now let me now state a bit more details about hyper okay giving a non-empty closed common Non-empty closed convex substance of a banana space. Okay, also giving a mapping T from C to C here, the mapping norms expansive fixed point set, norm, T has a fixed point. Okay, then hyper introduced, introduce this algorithm. Okay, take another. Okay, take another point u, another point u, which is called anchor. Take x0 as a starting point. Then take a sequence alpha n in the interval 0, 1. And then starting from x0, you iterate again, again through the formula 1.9. This is called happen. Now you get a sequence. Okay, you get a sequence. Okay, you get a sequence. Now we want to ask what is the behavior of this sequence. Now, actually, Harpon introduced this in the year 1967 for a special case. In a huge space, the set C is the unit closed ball. The anchor is not. Okay, so the first. Okay, so the first term disappears. There is no alpha u. It's simply the second part. Also in Hubert space on the closed unit wall, and then he proved convergence. Okay, he proved convergence. This is his paper published in the bulletin of MMS in 1967. It's a quite short paper, okay. Quite short paper, okay, six, seven pages. Now, in order to guarantee convergence of this algorithm, you need to put some condition on alpha. Okay, now Harper find the following conditions. He showed, he noticed that the following two conditions, C1, C2, he noticed of muscle. He notice of must satisfy C1C2 if you want to if you want to guarantee now but these conditions are not quite sufficient you need to assume another condition what condition okay now let me let me show you this table okay let me show you this table uh hypothesis mentioned c1 c2 Mentioned C1, C2 conditions, and which are not sufficient. So there's one more condition in order to guarantee to be sufficient conditions. So now what else conditions? Let me show you this table. In order to help for convergent, to be convergent, you need condition C1 and C2 plus one more condition. To plus one more condition. Okay, so I put the question mark here. Now, what is the question mark? In Harper's paper, he introduced condition C3. Now, what is this condition? This is C3 here. P3 satisfying this condition. Okay, there is a subsequence. Subsequent satisfying the three conditions: one, two, three. Okay, this is how. Okay, this is a hypothesis condition. Now, 10 years later, in the year 1977, Pierre Johns introduced condition C4. This is his condition C4. Okay, so then you have sufficient conditions. So C1 plus C2 and plus C4. C2 and processive. Okay. And in the year 1992, Wuterman introduced condition C5. This is the condition C5. Okay, this CR is prudent. And then you also have sufficient conditions. And then in the year 1994, Schumann Reich. 1994, Schumann Reich introduced this condition. Alpha n is decreasing. Now, actually, this condition is a special case of C5. Because if R5N is decreasing, then of course the cell is commuted. So C6 is a special case of C5. And then in the year 2002, myself introduced this condition, C7. Okay, C7. And I also myself studied in one of the space case. one space case okay now my condition and genuinely improved condition c4 because i removed the square in the bottom okay and uh and and the leon's condition only covers this choice okay r n to the r for alpha strictly less than one now both with return and mind condition can include mind condition can be included can include this the choice and alpha alpha can be equal to one okay but there are other conditions but the mainly mainly to guarantee convergence of hypothes we use these conditions okay the most commonly used condition c5 and probably also my condition c7 okay Now, this is a summary of high points condition. And then people also want to speed up the convergence. So then they consider the so-called judicial case. Okay, because high-point Because high points method, how method is just one step, one step. Now, the technique of inertial has been studied widely. So people also introduce initial technique to PyPon. Okay, so then a student of mine and I myself consider this case. this case you can find you can find many other papers about you about this okay inertial hypo produce a sequence in the following way okay 1.10 two steps okay that's the first step you have a yn is a con is a linear combination of xn and xn minus one and then use yn replace then use yn replace that xn in hyper you define xn plus one so then you have two sequences the step size alpha n and the sequence beta n now we can prove okay i i can prove okay i can prove i can prove under some conditions and some conditions okay conditions and Conditions and this condition on alpha. I can prove: okay, if alpha n satisfy condition C1, C2, and C7, and then I require beta n to satisfy the condition two. Okay, and then we can prove, can prove, okay, we can prove this inertial hyper converges in norm to a point. In normal to a point, which is the projection of u over to the fixed point set of t. This is, I just proved with my student. And actually, I, with my co-author, Ginardo Sorves and Victoria Martin, okay, we wrote a short silver. short survey paper which published in the journal of contemporary mathematics in the year 2010. So this survey is up to the year 2010. Now since then, not more than 10 years passed. Since 2010, of course, there are a lot of new consequence, new new papers published on Harper method. On Harper method. Okay, so my survey is up to 2010. Let me also mention that, okay, in Harpo's algorithm, this is a very simple exploration. Now expansion mapping T. Okay, T is only. Then you need three conditions. Then you need three conditions, as I show you in the table, okay? C1 plus C2 and plus one of the conditions from P3 to C7. Then you have sufficient to guarantee convergence. Now, I want to point out that if for average mappings, for average T you don't need other Need other conditions, you just need condition C1 and C2. Okay, then you have convergence. C1 and C2 are sufficient to guarantee convergence. Now, why Hypom proposed proposed his Proposed his way. Okay. I think he was inspired by Browder's regularization technique. Okay. Browder was the first. I think Browder was the first, probably in the year 1963, four or seven, 65. But I quote here, his paper in 1967. He used contractions to approximate. To approximate okay, t, the difficulty constant of t is one, okay. Now, one can be approached by a number smaller than one. This is a idea to use contractions. So, for each t between zero and one, strictly less than one, t okay, you define a map t sub t sub t now is. T sub t now is a contraction on C. C is a closed convex set. So then T has a unique fixed point. Okay. Let's use X T to denote this unique fixed point. And then Browder proved that in Hubble space, this unique fixed point of the contraction T sub T converges in all. Converges enormous to the fixed point of T, which is actually closest to the set of fixed point of T. So that means the projection of U onto the fixed point set of T. This is browse regularization. Regularization. Now, if you describe, if you discretize browsers. highest browsers implicit regularization method then you then you just get hyper okay so hyper can be viewed as discretization of providers regularization regularization okay now let me also tell you okay here Here, U, which is called anchor, is fixed. Okay, it's a fixed point in the space. Actually, we can do something more about this. So, this is the idea of VAM, viscosity approximation. Contraction, we use contraction. We use contraction. We can do slightly more to replace U by another contraction. For example, F is loot contraction. Okay, we take a loop contraction F and replace the U by loop and define this map. We simply replace U by F by the contraction. Now this is again a contraction. Now, this is again a contraction. The contracting coefficient is one less one minus lo T. This is smaller, still less than one. So this is again a contraction. Okay, so this contraction still has a unique fixed point. Let's again denote this unique fixed point by Xt. And then we have the following result. Of course, the first time proved by Modafi in 2000 and later on I Modafi did the Hubble space case. I did the Banner space case in the year 2004. Okay, we proved that the limit, the strong limit of Xt is the unique solution to this Vi. To this VI variation inequality. So, this result extends parallels to a more general case, which is called VAM, viscous field. No plus-main method. I just point out this. I'm not going to detail for this. Okay. Now, let me. Now let me move on. Let me just also mention another iteration, which is called cross-nossel man. Because it looks, it looks KM, cross-nosetsky man, which I just write the KM shot. Okay. KM looks, seems to be more popular. It's a more popular fixed point algorithm. Okay, you take, okay, that's the Km. Km produce a sequence Xn in this way. Xn plus one is a convex combination of Xn and TXN. If you compare this to hypo, high point here, this Xn is U, fixed. fixed fixed point but but Km takes the nth iterate Xn and then make combination with TXN this is called Km. The Km was first introduced by man in the year 1953 on the new line and two years later and first Marcelsky did the case the KM in the year 1955 in infinite 1955 infinite infinite balance space on compact convex set. So nowadays we call this KM. But today I'm not going to talk about in detail about KM. It looks KM is more popular. Okay, I just briefly mentioned the definition of I briefly mentioned the definition of hypnot. Okay, hypo, and I just show you a table about the convergence. Another important thing is rate of convergence. So now let me just mention it, briefly mention rate of convergence. I mentioned here KM is looks more popular because KM looks more popular because it's a bit easier to discuss the rate of conversion for KM. Okay, not for Hyphen. Okay, so KM looks more popular. Let me now turn to rate of convergence. Let me mention a great work done by Professor Colin Bach and his group. Okay, I just mentioned some names here including. I just mentioned some names here, including Inela Rope, Acedo, Andreana, Nicole, and Lucien, Frix Reader, Pedro, Pinto, and so on. I don't have a full list of names. Okay, I just made them. Using proof of mining, made significant contributions to study the later convergence of hyper in qubit space, in minus. In cubic space, in Mana space, and in nonlinear space, such as cat zero space, in serial papers. I just mentioned a very small, a few. Of course, I don't have time to discuss the details. They publish a lot of papers in speech journals, like this advances in math. This advances in math. Okay, user-real math journal mathematics and numerical functional analysis and application and many other journals very impressed. And I just mentioned this. But I do want to mention readers' recent rate of convergence. It's a remarkable result. Of result, he proved capital O of NO1 rate of hyper. He proved, okay, in the Hibo space, non-expansion mapping T with fixed point set, non-MT, and then consider the sequence generated by Harper, by Harper method. For this particular choice, the step size alpha n is one over n plus two. n is one over n plus two now the anchor and initial point coincide so u equals x z n then he proved he proved the rate of convergence okay now for our high points or even for km we always use we when we we mention about rate of conversion we always mention mean that mean mean that conversion to zero of this displacement the norm or the displacement Okay, the norm or the distance from xn to t xn okay okay the norm xn minus txn the norm go to zero how fast it go to zero we mean this then reader and then leader reader proved this very very nice very nice rate of convergence it's very simple look at okay the distance from x to t x and go The distance from x to tx and go to zero at the rate of capital O of one of n, you get the exact bound. Get the top is twice the norm of x zero min x star x star n fixed point of t. The bottom n plus one. And the tight, the boundary, this boundary is also tight. He showed this tight. So this is the best possible. Very impressive. Very impressed. He proved a few years back, but published just this year. Okay, by the way, let me also mention the vector convergence of KM. Leave a few space for hyphen. Now, how about KM? I just mentioned this. What Km? I just mentioned this. This is Km. This is KM. Okay, the KM, the rate of convergence has been obtained recently by Lovedo Caminetti and his students. They published the results in a couple of papers. For example, they obtained this estimate of rate convergence in a general Banach space. In a general Banach space. Okay, X is a general Banana space. C is non-empty, closed convex bound subset with the boundedness of C. And then the prove this inequality. This is a very, very nice inequality. Okay, the top is just diameter of C. The bottom is square root of pi multiplied by this summation. The alpha is the step size. Step size. Okay, they published this result in two articles. The first article published in the year 2014 in the Real Journal of Mathematics. And the second paper in the year 2019 in the Journal of Math programming. Okay, they also prove the square, down the bottom, you have the constant square root of pi. This is exactly the best constant. Exactly the best constant in the proof in general about our space. Okay. Okay, this is the show. Okay, this result, again, they published also in the 20s, 1518 level general mathematics. They show, okay, this is also, you know, general final space, this is the best possible inequality because they construct an example to show. example to show you this bigger than inequality if k is smaller than square one over square root of pi so that that constant one over square root of pi is the best but they did in a general hiber space but actually they did they did it in general general balance space but actually in the field space actually you can get more more because the rate of convergence the rate of convergence is not big o this you look at you go back go back go back here this inequality this means you can you can also you can you can conclude that the rate of convergence is capital o capital o of the right hand side okay in general balance space but in human space But in general, one space, but in human space, actually, this is little O little O. That means actually, you have some null sequence here. Actually, you do have some sequence, which is now, but I don't know how to find it. Okay, I don't know how to find it. I just mentioned, I just mentioned, okay, because I mentioned. I just mentioned okay, because I mentioned the rate of conversion for Python. So then I want to mention rate of conversion for KM. I just mentioned. Okay, now let's move down applications. Okay, I want to show you some applications of Hyper. The first application I want to show you is 2 VI validation inequality. I variation inequality. Okay, and I will consider in Hubble space setting. Okay, so we have a non-empty closed convex subset C of Hubble space H and a mono monotone. The monotone operator F from C to H. Now, the very thing you call it Vi is that to find one that you start, which satisfies the following property. Okay, the inequality 3.1. This is called Vi. Okay, VI. Okay, Vi. Now, why we can use fixed point to Vi because Vi is equivalent to fixed point problem. So you start your solution to Vi 3.1 if and only if it is a fixed point of this equation for any positive value. So if the monotone operates F The monotone operate F is strongly monotone and Lipschitz. Then, for sufficiently small gamma, this mapping I minus gamma F will be a contraction. And then computer with non-expensive projection is still a contraction. So then we can use the Banach contraction principle to get the Picard iterates Xn convert. Xn converge to the unique solution. Okay, this is a very beginning point of view of fixed points algorithm applied to VIs. But how about the case if F is not strong monotone or F is not Lipschitz? But anyway, we still have the equivalent. But anyway, we still have the equivalence between VI and the fixed control. Okay, many non-monoto-modiform operators are not strong monotone, but in most strong monotone or cocursive. Okay, now we say we say we said that F is in most F is inverse strong monotone. I just write RSM. Okay. So F is RSM if you have a constant gamma, which satisfy this inequality. Okay, right-hand side is gamma multiplied by the norm squared of fx minus fy, not x minus y. If the right-hand side is the squared norm of x minus y, The square norm of x minus y, then you call this astronomic comics. But now on the right-hand side, there is norm, the squared norm of fx minus fy. So this is called inverse triangle monitor, I think. Now, in many cases, we needed to emphasize the constant gamma. So then we say gamma RSA. Now, let me tell you, let me tell me, okay, many interesting mappings are SA. For example, projection. Projection, proximal mappings of convex functions are one RSA. In the meanwhile, there are also one over two AV. So projections at approximate mapping. Projections and proximal mappings are both RSM and AV. I don't know what kind of operators can enjoy both, can enjoy both. Okay, non-expensive mapping categorized as one over two, calculate as the complement. Complement I minus T is one over two RSM. So for RSM, Y S M the coefficient gamma if the coefficient gamma equals one over two one over two is not good not not good no one should be bigger than one over two that's much better I like projection one I say now let me let me show you this proposition the relationship The relationship between Av and RSF. Giving a mapping T from H to H. Now, T is alpha A V for some alpha between 0 and 1. If and only if the complement I minus T, I call I minus the complement of T. Okay, complement I minus T is 1 over 2 alpha RSA. Please note here the coefficient 1 over 2 alpha bigger than. To alpha bigger than one over two because alpha is smaller than one. Okay. So in in in the proofs, okay, in proof, we quite often convert, convert from AV to RSM and from ISM to AV by using this proposition. Now we also, okay, unfortunately, I have to use condition. We consider minimaling problems. We assume continuously differentiable, differentiable a convex function. Then we have the gradient. We often assume the gradient phi is L Lipschitz. Is L Lipschitz. This is L L okay. Why? Because if greater than phi is L L, then greater than phi is monotone and actually is one over L I S F. This is why, okay, in optimizing problem, we often use this condition, okay, L Lipschitz for gradient. Now let me show you how to apply high problem to minimizing problem. We want to minimize this, the function phi over C. Okay, assuming the solution set S is non-empty. And then we know the solution set S is just the fixed point set of this mapping for any lambda positive. Now, if graduated phi is L L then this map will be A V. I can identify the coefficient of A V here. Okay, so this is non-expensive mapping. So we can simply apply high pulse method to this map. Then we can define a sequence. Then we can define a sequence Xn according to hyper. Then we do have convergence. We have convergence, strong convergence to a solution, which is the projection of the anchor U onto the set of solutions. Okay. If we assume the step size satisfies the conditions C1 and C2, if lambda is triggered. If lambda is strictly less than 2 over L, then this generating mapping is average. So we don't need anything else. We just need a C1, C2. If we want to get fast convergence, then we can apply leaders rate of convergence by taking the coefficient alpha n to be 1 over n plus 2. So down here, this So down here, this algorithm converges to a solution at the rate of capital O of one over n. This is a very straightforward application of hyper to minimization. Now, the same technique can be applied to this composite minimizing problem. If you go back to the definition of proximal mapping operator, I will go back to what I have talked previously, the proximal gradient algorithm. Okay, then the difference from the gradient projection, you just in front of here you have flux for the projection average here. You have projection. Projection. Okay, but projection and process have many identical properties, like one over two, half, half a V, like one ISM. So simply replace the projection by proxy lambda G. You will get the same result as here, this result. Okay, let me just. Out okay. Let me just mention this. I'm not going to give you the details. Okay, so this is the algorithm. On here, now you have the proxy lambda G. Previously, you have P sub C. Then if lambda is still between zero and one to over L not inclusive, then you just need the condition C1 C2 to guarantee the condition. C1C to guarantee the convergence of this algorithm to a solution of this minimizing problem. Okay, that's again a straightforward application of high problems to this composite minimizing problem. Now, of course, you can apply leaders rate of convergence. Okay. Okay, I just mean this. Now let me move down here. If you want to solve this equation. If you want to solve this equation, fx equals zero. Okay, now P and F is one over L is F. And then you can apply. You can apply, you can apply hyper to get this iterates sequence in 3.4. Okay, then you still have convergence. You have convergence, you can, then your parallel result, you get the rate of convergence. If you want just the epsilon approximate solution, that means the norm of fx and little more bigger than epsilon, then you just need so many, okay, fit relations after. Okay, iterations. After this number of iterations, you get x, which is the absolute solution. Okay. Okay, this is the zero. Now, in a recent paper in a recent paper by by Dear Coli Curls, okay. She's from computer science, but they apply hyper. They apply hyper to study study convergence for solving for solving monitor increasing problem. monitor increasing problem and minimal heating problem also varying copper problems they prove prove near optimal solution and so on so my here my work is actually expired by first okay uh we can see this this is the variation inequality and now f is And now F is one over L R S M and the solution set is non-empty and then we have the solution set is equal to the fixed point set this standard. Okay, now we introduce another map, G sub ed by this formula down here. Now why we need we introduce this map because because that's truth a giant optimal A giant in optimization theory. Okay. He first introduced the map when f is a gradient of phi. Then he called g eta a gradient mapping. Okay, now obviously if we replace the gradient of five by a general monotone operator, you can still define G. Okay. Now the good thing is that, okay. Now the good thing is that okay g and f in enjoy the same set of zeros so to find a zero of f or okay or to find okay even to find the zero of f even to find the solution to explain five you just need to find a solution uh to find a solution of model inequality with with with g not f g eta Not f g eta f sorry g eta now why then we consider the limiting case here a does big strictly bigger than l over two now we take it equals l over two then we get expense non-expansion map okay so when when the equation is yeah when eta equals l over two you we have a non-expensive map in g l over two okay of course you need time two of l this is non-expensive this map is not expensive then we apply hypom we get this then we get we get we get this estimate if we choose alpha n. If we choose alpha n to be one of m plus two, we just use leaders without okay now now the work I show you show here is slightly slightly extends the work by yeah Connie Collis. Okay, if you're interested you can you can read her paper Okay, now I want to mention to extend extend high point method two to the case to the case of finding a zero of the sum of two maximum model operators. Okay, to find a zero of A plus B. Now, this is a very important problem. It has been investigated widely. If you search, search google then you can find a very good number of articles okay investigating this problem now we have to monitor operate a and b maximum monitor sometimes we need some a plus b is also maximum tone okay now of course we assume the set of zero of a plus b is not empty now we often use s to denote Now we often use s to denote the solution set. Now, for monitor operators, we have the solution, the concept of resolvent. The resolvent of A with coefficient lambda is denoted by J sub lambda upper soup A. And this is the generalization of approximate mapping of convex functions. Okay, now let's, let's, we have a lemma. Let's let's we have a lemma. A z low of 3.6 can be converted to fixed point of some mappings. Okay, we have this V is the fixed point of this map or this map to different maps, but equivalent if and only if If and only if you apply the resolvent of V to U, to V, you get a solution of 2.6. Okay, so in order to find a solution of 3.6, you just need to find a fixed point of any one map of these two maps. Once you find the fixed point of these two maps, then you apply a Then you apply the resolvent of B to that fixed point, then you get a solution to fixed point to get this solution. So, in this sense, we say that the inclusion and the fixed point here are equivalent. Okay, now what properties of these two mappings have? You find this down here. This is down here. The first operator is non-expensive, but not heavy. Now, it can be a rotation on plane. The second map has better profit. It's one over two, maybe. So we should apply the second map. Now, there is a very third. Now there is a very famous famous splitting method. It's called two maps actually. If we use we use the second map, which is 1 over 2 AV, and use that as a generating operator to define this iterates. Iterates, the big success of iterates. Then we call, we call, we call, we can call it DR. We call it DR, Douglas, Ratchford. If we use the first mapping, then actually we call PR. Actually, we call PR. Peaceman, Redford. But we can combine. But we can combine them. We can introduce the so-called generalized diagram. Okay. By taking a convex combination of the identity I and the map, this map. Now this map, here we introduce a new notation. Okay, lambda RA equals twice the resolvent minus R. The resolvent minus i a similar for b okay now this is this is called deflection okay if we introduce this generalized the dr mapping then actually cover both both dr and and and pr okay if if we select the beta equals one then we get pr if we we take a beta equals one over two one half beta equals one over two, one half, then we get GR. Okay, this is to this V beta, V beta is more general. Now these are taken from Pierre Leonz. Peer Leonz and his colleague Mercier article published in the year 1979 because they were the first persons to extend splitting algorithm for some to For some of our non-linear operators from linear to non-linear. The first one. Okay. Now, what's the result? We can apply hyper to the generalized DR mapping. Now we call this, I call this DRH Douglas Ratchet hyper DRH. Okay, we have. Dih. Okay, we we have convergence, so we have rate of convergence. Okay, okay, we we we simply we have this and finally let me let me apply hypo to minimax a minimax problem is is very popular now okay minima minimax problem also called minimax game is an option Math scheme is an optimization problem of the form. Okay, you have an objective function L of XY. First, you maximize in Y and then minimize in X. Okay, I consider the general case, okay, and H1, H2 are human spaces. And then L, of course, in mapping from the product space. Mapping from the product space to the real line, it's called loss function. Okay, how we define the product space with equipped with the standard in the product and all. The minimax, minimax problem has recently been paid significant attention due to its important application. It's important application in machine learning. In particular, in the so-called area of generative adversarial nets, GN short. So if you search, you will find many articles recently, very recently. Recently, very recently, contributed to the study of this minima, minimax problem. I read a couple of papers, recent papers, using anchor technique, anchor technique, including Hyper technique to provide algorithm for solving 3.7. Okay, uh, a special case. The general case of 3.7 is very hard. So, we focus on a general special case. It's called the convex concave case. That means the objective function is convex in x, concave in y. So, this is why here you maximize in y. Okay, minimize in x. Okay, we maximize a concave function, minimize a convex function. Can minimize a convex function. So we will consider this convex concave case. Then we have the concept of a saddle point or a solution. A solution to the minimizing problem 3.7, which is also called a saddle point, if the point x star, y star satisfies the two inequalities in equation 3.8. You can see, okay, minimize in X, maximize in Y. But how can we use convexity to study this minimax problem? Okay, for convex functioning, we have gradient for For concur function, of course, we can define a gradient, of course. But here we do something different. Okay, for x, we use gradient, but for y, we use negative gradient. So that means the gradient of negative f in y. Okay, f is convex, concave. F is convex, concave in y. Negative f is convex in y. So 3.9, we use L prime. Okay. So L prime is actually the gradient of some comic function. So this. And also, and also a saddle point, okay, x star y star. Okay, x star, y star is a saddle point if and only if the coordinate is zero. So that means that means z is a saddle point of L if and only if the coadiant here L prime equals zero. So to solve the saddle point problem, to solve the minimax problem, we just need to solve the zero problem of this monotone operate. Okay. So solving minimax problem in the convex concave case is equivalently transferred to the problem of finding zero or maximum monotone update, which in turn can be solved by a fixed point, such as hypho. Hyper if we assume a suitable condition for okay. So, what's a suitable condition? The suitable condition is L is R smooth. R smooth means the derivative L prime is R Lipschitz. Okay, the maximum month operator L prime is R Lipschitz. is R Lipschitz. In this case, we can let the straightforwardly applied typon and then we get to this. Okay, now we put X and Yn as coordinate in the form Z n, okay, Zn equals X and Yn. So we can apply high point to the product space, then we get this algorithm. Then we get this algorithm. This is the components. Then we do have convergence. We do have convergence, okay? And we also have rate of convergence. Okay, finally, let's mention this result. It's called EG, extra ankle gradient. Egg. Eg was introduced very recently. Down here, you see the citing, I cited this paper. This conference. It's a conference paper. Okay, just this year, 2021. Okay, they introduced this code, they introduced this method E, they call E, okay, as an speed up accelerated algorithm for solving the convex context of minimizing problem 3.7. They introduce this algorithm. This is a two-step. This is two-step, two-step, and it and it contains also two sequences, beta and rfn. Rfn still called step size. Now beta n, they call they call anchoring coefficients. Okay, this is the they are they call EAG. They call EG. Now they study two cases. We have to, in order to allow for some questions. Okay, okay, okay. Okay, they consider two cases. Okay, the first case, a constant step size, alpha k equals alpha for all k. And then alpha is called the varying step size. But both cases take beta n is equal to one over k plus two. To one over k plus two now I observed okay I can rewrite I can rewrite the algorithm into into into into a standard hyper but of course two steps okay their E can be written down here 3.13 not 113. Now you can see this is very equal, very similar to hyper. Okay, that's ZZLO, the anchor, and here the operator, but still two steps. Now, what's the connection between the gamma and the coefficient in egg alpha, alpha and beta n? Simple. gamma k is equal to alpha k over one minus beta k now what's the convergence they they they did not study convergence they just study the rate of convergence they they study estimate the square of this norm okay they have to touch the convergence of the algorithm now i'll prove this i'll prove this okay if I prove this okay if I assume I take gamma n to satisfy this condition the beta n satisfies c1 c2 then the sequence I can prove the sequence defined by e converges even in infinite dimensional space converges to the solution okay this I've just proved this okay I think I have finished my I think I have finishing my time. And then finally, references. Okay. Thank you for your attention. Thank you very much. Yeah, thank you so much for your exciting talk with a lot of, I think, problems to consider. So this is very amazing how this alpine iteration has been also recently applied in the context of machine learning. I just want to add one. Yes, yes, that's the most important thing. Yes. That's the most important thing. Yes, yes. I actually see, I finished my survey in 2010. I actually stopped. I actually stopped iPod. But recently, machine learning told me I have to do it once more. Once again. Yeah. Yeah, I just want to make one remark. This result, this Felix leader you mentioned, he's not a member of my group, so he's not in optimization in. From optimization in Disseldorf. However, this result, of course, is only in Hilbert space. Yes, instead of one over n, one has one over square root of n in arbitrary Bano spaces and even in hyperbolic spaces. So that is a result due to proof mining. So is there any situation, even let's say L P space other than L two where one has improvements due to leader? Due to leader, or is it just tied to the Hilbert space case? Yes, yes, yes. Normally, it's one of the Skalutoven. But he had a joint article with you, so I thought he was a member of your group. Sorry for that. And also, of course, in proof mining, we are very much interested in analyzing the convergence of Xn itself. I mean, when you say rate of convergence. And when you said rate of convergence, you mean rate of asymptotic regularity. So the distance between xn and txn goes to zero, but not the convergence of xn towards the metric projection. For that, one can show by methods of logic there is no computable rate of convergence. So one has only what we call rates of meter stability in the sense of tau. Ah, okay, okay, okay, thank you. Ah, okay, okay, okay. Thank you. Thank you for letting me know this. Thank you. So, but are there any other questions or comments? Let me just see whether. Okay. But Pinto, also you are a student? Pinto? Well, he is a student of Fernando Ferreira, who is also attending this workshop. He is now currently working with me as a postdoc. Currently working with me as a postdoc here. Ah, because he also published a paper in this field. We are currently working together. Actually, we have a paper on the viscosity method. This is a very nice result of Suzuki showing that the viscosity method can be concluded, can be inferred from the original Halper method. And so we gave an analysis of that, how to convert. Analysis of that, how to convert rates from Halpan into rates of viscosity Halpan using the of Suzuki. So have you published that paper? Sorry? Have you published that paper? This is currently submitted. I mean, it's on the archive. There's a pre-printed version. Oh, can you send a copy? Thank you. Thank you. Oh, sorry. I'm sorry, I used too much time. No, no, no, no problem. The last results, I didn't know, they are very interesting to us, obviously. Now, I have a question. I mean, you mentioned that the Kasnoselsky man declaration is or was for a long time more popular than Halpan, although it is not strongly convergent. Yeah, yeah, yeah, because people like that, you know, I like more. That's not like him. More, I mean, I, um, in my view, uh, is the following correct? I mean, it seems to me that the benefit of Krasnosellsky Man is that it's Ferré monotone, whereas the Halpan is not. And if it's Ferré monotone, then one can use conditions of metric regularity to get rates of convergence, rates of convergence for the actual XN rather than just for asymptotic regularity. Just for asymptotic regularity, and that doesn't seem to be possible for the Halpern methods. So, is there any use metric regularity in the context of Halpern methods? Okay, because probably because you see the limit of hyper is identified as the projection onto solution set, probably your application people think it's not easy to find such a projection. Yeah. Yeah, yeah. And in, I mean, and in a Banner space case, it's even not even the projection. Yeah, yeah. That's also probably more non-constructive in a sense. Okay, so then I'd like to thank you again very much for your great survey and the recent results. And the recent results are definitely, I mean, many of us will be eager to look into many, many things again.