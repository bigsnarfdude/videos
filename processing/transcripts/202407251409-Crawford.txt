So far, honor you for all in telling me to do this talk facility. You're welcome. So I was trying to figure out what I was going to talk about all throughout this week, listening to everyone else's talks. And one question I kept getting is like, what do you do at Microsoft? So I figured I'd get a little bit of an overview of my research program in general. I think a lot about this idea of interpretability on the AI, ML spectrum across different methods, right? Spectrum across different methods, right? And you can think about interpretability here as things being super interpretable in terms of like linear regression or like PCA, and then you might backtrack all the way across the spectrum, things are more black box. What I try to do in my research program is think about how to develop, you know, utilize our knowledge about biology in order to kind of make black box methods a little bit more interpretable. So, like utilizing, you know, conditioning on our knowledge or things that we can know about biological structure to kind of leverage both. To kind of leverage both the utility that we use in ML methods and still get the interpretability that we get in more linear regression type approaches. So, to that end, I think about how to manipulate both architectures of models and also the way that models are also tracked. And you can think about the benefit of both of these. This is what we call a fully connected neural network. I like to show this is fairly simple. For those who may not know what fully connected means, all that really means is that all of my inputs here, think about each of these X's being like different. Each of these X's being like different SNPs. I might have a phenotype of interest that I'm trying to predict why. And fully connected just means that every single node in a previous layer is connected to a hidden layer node here. There are two really important things about this slide. The first is that this is what we call non-interpretable because each variable here has many different weights, and it's hard to know which weight corresponds to a given variable's effect. And the other thing, too, is that these hidden layer nodes are just kind of hidden neurons. Just kind of painted neurons. And so they also don't have an implicit or natural interpretation. The second reason I showed the slide is because machine learning models are just fancy linear algebra. You can write any neural network as a non-linear model, where any kind of prediction here is just a linear combination of my hidden neuron weights and hidden neuron layers and also the weights that correspond to them. I'm from Duke, so I'm going to be inherently Bayesian in this. So you put priors on all of my weights, and I can. Priors on all of my weights, and I can do categorical sampling just like I do in any kind of therapy. So, you know, some of the methods that I kind of think about is how do I take the hierarchical nature that one might see in genetic and genomic studies and implement them to kind of manipulate machine learning architectures in order to get more targetability out of them. So, here's a famous Manhattan plot, right? You can imagine each point here is a given SNP, a given genomic location. What I can do then is annotate this, right? So, I kind of Annotate this, right? So I kind of have this natural hierarchical structure where I know how which SNPs are kind of annotated for a given genomic, a given gene, or a given region. And so with all of our studies, we get this nice natural combination where I know I have these natural groupings across different genomic positions. And also I have these kind of windows where I know different features kind of sit in this. So I kind of have this natural group structure across all of the SNPs. So some of the stuff that like Zoe and I have worked on is. Stuff that, like, Zeng and I have worked on is thinking about: well, if I take this natural predefined gene or pathway annotation list, can I use that to inform neural network architectures? Right? So, you know, very briefly, I have this idea of like individual features being fed into groups here, right? Like this kind of natural illustration. What I can kind of do from an illustrator perspective is like kind of flip this onto its side. This kind of looks like a natural neural network, right? But one that's kind of just partially connected. So here I have a bunch of different genotypes, and there's I have a bunch of different genotypes and their SNPs. And this we call partially connected because every single input variable here only has a connection layer if it's been annotated for a given group. And now we have the natural interpretation. Now each variable has its own particular weight, and these neurons are not just hated neurons anymore. Now they've been annotated such that they have a meaning of tens, right? Or pathways, or what we can say. So we call these things biologically annotated neural networks. And you can, you know, they kind of extend in any sort of way that you want them to, right? You can apply this in many different areas. You know, let's stick to the whole GWAS for our mind here. So I have a set of SNP sets. I have a SNP set that I know corresponds to a given chromosome, certain impositions, and I might know SNPs kind of fall within these. What I can do is I can naturally take this list and naturally create an architecture that corresponds to it, right? Where I have SNPs feeding into genes. If I want to be, again, I can be very statistical about the way I think about this. That's statistical about the way I think about this. And so I have this nice, like hierarchical integrative architecture, right? Where my full model specification is some phenotype that's given by a linear combination of both my hidden neurons and their weights and a tendency biases. But again, I could be really Bayesian about things and put special priors of how I think maybe effects are distributed on a given genomic weight. So if I think genes might be distributed differently than SNPs, I might have a more complicated prior structure for my SNP effects, and I might have the most extensive SNP. And I might have a little standstill. You can do this with both individual-level data, I can do this with summary statistics, and you can also do this with multiple phenotypes. If you imagine that phenotypes also serve as kind of a structure, I can model multiple phenotypes at them. So this is the kind of stuff that we kind of think about a lot. We kind of get this kind of clientable multi-scale view on genetic data all at once. So if you run a model like bands, what you might get is both the idea of like understanding what SNPs might be enriched for a given trade of interest, but then you Might be enriched for human trait adventurous, but then you also get this idea of what genes or sets of gene sets are also enriched for human trait, right? And the really cool thing is that the way the models fit, and I won't go too many details, each layer kind of informs itself in the model training process, right? If I understand which SNPs are enriched in the model training, I also inform which SNP sets are enriched. And then if you do back propagation, you'll have that information for the flow values. Now, the really important thing about machine learning. Important thing about machine learning models in this context are two things. One is that they work really well when I have a ton of data. So in the biobank era, they really are kind of well suited for this task. When n is very large, I should be able to learn really cool sets of information about that. The other nice thing is that we talked a lot about nonlinearity structure here. Machine learning models naturally learn all parts of different types of effects. They get this nonlinear structure for free based on how you define whatever that. On how you define whatever that hidden neuron function is. The problem is, we do so much on the left-hand side for a lot of reasons. One is I think people think about this atom structure as defining most of the heritability or variance indicative trait, but also you have interpretability here, right? The effect size that I might get in a linear mixed model goes a long way in terms of my ability to understand hypothesis testing systems and things like that. So, we're going to try to, what I try to do a lot in my everyday life is try to close these. For my everyday life, is trying to close this gap. In this talk, though, I'm going to focus a little bit on this idea of how do I make the identification of these nonlinear models easier, right? And how do I facilitate that a lot? And so I also think about that question, right? How do I lessen the burden if someone wants to test for these nonlinear interactions? How do I do that in a well-grand way? So, you know, Sriram introduced my method, probably better than I will. So, if you weren't here, I'll give a So, if you weren't here, I'll give a worse version of MapIt to you for my own work. Let's think about this generative model. So, let's imagine we have some trait of interest, and we think about this generative model for a complex trait, just for notation purposes, because I think there was scolding about that, about not defining the variables earlier. So, I'm going to do that here. Y is going to be just some n-dimensional vector of traits. X will be some high-dimensional vector of genotypes. Let's let W be an interaction matrix. Let W be an interaction matrix of, let's just think about pairwise interactions between some sets of causal SNPs. Beta would be the added effect sizes and what they would be the highest effect size. Now, what MapIt effectively is doing is thinking about this from a combinatorial perspective and trying to lessen this burden on this combinatorial problem. So if I think about all pairwise interactions, I have this like J choose two possible pairs that I might search over if I think about it from an exhaustive perspective, right? And so what the marginal epistasis test was supposed to do, and I'm sorry, you think epistasis. Test was supposed to do, and I'm sorry if you think empathasis is a bad word. I know for immunogeneticism, sometimes not a word supposed to say it out loud. But what it's supposed to do is think about how do I think about the combined interaction effect between the Jth variant and all the variants as a way to do like a pre-filtering of SNPs that might be involved in this interaction before you do four things. And so, what MAP is supposed to do is give you this kind of reduced search space. That's how it's performed. And the test is actually quite simple, and I won't go over this too much anymore. Simple, and I won't go over this too much. We've kind of heard this already, but you know, the main idea here is to take each SNP in turn. So, let's say that's like little XJ here. I separate that out from the rest of the SNPs. So, MJ is going to kind of define this background without this XJ term. And what you really want to test for is this CJ. So, CJ is going to be this random effect with this variance term here. And this capital G is going to be your Is going to be your interaction where basically what we do is we take this X matrix here and multiply it on the background of this K. And so the hypothesis test is: can you do this for every single SNP in your data set? And so what you're really doing is you're basically testing for marginal epistemic effects. We fit this MQS algorithm from Jung, and then we get this nice null distribution test for which we can test this. So I won't spend too much time on this because I don't have a lot of time, but the real important cool thing about MapId is that MapId's power. That MAPIT's power is not based on the pairwise interactions of everything, it's based on how strong or how much variance the given SNP explains for that non-additive piece. So here's a cool simulation that shows that, like, well, if my group one SNPs here have a high contribution to that non-additive effect, that non-additive piece, and I slowly decrease the power of at least group two SNPs, it doesn't matter. I still should have the same consistent power for those group one SNPs over and over. Consistent power for those we want steps over and over again. So that's the cool benefit of this Marginal approach. And so you get these cool things, you can do these really nice Manhattan plots here. The only difference here is that these are marginal epistemic effects where instead I would say that this SNP in particular has a high likelihood of interacting with some other SNP. So what you could do in practice is you could take all the SNPs above this red line here and then say I'll look for interactions across all of those, or I'll look for all interactions that involve these SNPs as kind of hug. Interactions that involve these SNPs is like kind of hub SNPs in my interaction with. And that'll greatly reduce your multiple testing. You can manipulate different architectural differences you want. All that really depends on if you want to test cis interactions or whatever the case might be. That just means you need to just change whatever you look at in terms of these covariance matrices. And then you can look at multiple phenotypes all at once. Now, the crux of what I really wanted to talk about was: you know, this is great. You know, this is great. This is what we do on individual level data, but I've always had this kind of nagging question in my head, which is: oh, and then Matt is probably out of water already. Yeah. What I've always tried to ask myself is, can you actually identify non-additive effects using additive summary statistics? And I've had this in my head for a while, this idea of like, effectively, do additive summary statistics that basically tag non-additive effects, which I can then take additive summary statistics and tease that apart. Statistics and tease that apart, or actually look for evidence of non-added effects that were tagged from these summary sites after energy losses has been implemented. So, let's kind of revisit our generative model here. The key thing that we're going to focus on are really these two components here. We're really going to manipulate this in a little bit. The key concept of how you can do this is this idea of what linear independence means versus correlation horse. means versus correlation versus a dog analogy. I'm sorry if you haven't read these words since I think. The key thing that is really important is a lot of people assume this kind of independent normal distribution on the effect sizes in that generative model. Now that's really important because what it means is that there's orthogonality between your additive effects and your non-added effects in that generative model. The covariance between these things ends up being the same. The interesting part, though, is that if, let's say, most people assume that this W takes on this kind of pairwise Hadamard type of form, X and W are correlated, but they're not actually linearly, they're not linearly dependent, or they're linearly independent, right? Because this W term can be formed from, it's not just a natural form where I can choose some function C or some scalar C and just. Or some scalar C, and just automatically recapitulate them. And so, since this holds, the really important thing is that the cross product between X and W is actually not zero. And that's a really important thing when I think about how the summary statistics were actually used. So let me just walk you through a very basic example of what I mean by this. And we're going to use this fact as a really important key here. So let's take the traditional view on summary statistics. You have my regular way of how I compute a summary stat. You select those other quick things. A summary stat, using like those other quick linear least squares, right? I get this, I can take the expectation of this on both sides. If I assume that x and w are completely independent of each other, I get this really nice relationship that I think everyone kind of uses in all areas of each other. Now let's take this idea that like that X and W are actually not independent from each other, but I still fit my model as if they were. We have this idea of GWAS and resistance being tagged with interactions, right? Is being tagged with interactions, right? Let's go through the same process. I'm going to fit my LLS here. If I take the expectation of both sides, right, this W kind of exists, right, this W theta in the context of their mean interactions. And actually, because this X transpose times W is not actually zero, what ends up happening is if I look at the expectation of my beta hats here, I'll kind of have this additional term from this concept of omitted variable bias, where I actually have this additional term that. Where I actually have this additional term that basically measures the tagged effect between my genotypes and their interactions. So, what this effectively means is that, in theory, I should be able to squeeze a little bit more in terms of like variance explained out of these summary statistics than what I'm doing just using the regular GWAS stats along. And so, the way that we kind of poke at this problem a little bit is we do this via L V score regression. And it's a little bit of an extension of L V score. So, you know, So, you know, I want to explain those were a little bit earlier, but you know, I can take the expectation of my GWAS summary stats, right? I get this really nice model to estimate heritability here. What we're doing is like this interaction LD score, which is effectively just saying, well, if I have this extra tag term, then I have just one extra term in this expectation, which also gives me like a little bit of an extra term, what we call these interaction LD scores in this framework. And what effective did. In this framework. And what effective this should do is it should give me a little bit of a bump in terms of variance explained from my summary statistics than if I just use the regular LD scores. Like if you're familiar with stratified LD, like an additional category. So think about additional categories, it's not added things. And so this is actually not like new of a concept, actually. So people have kind of shown before that the theoretical added genetic variance for like some jake SNP, let's say that I ignored Say that I ignored environmental environmental effects, and let's assume that dominance plays a minimal role here. Actually, it takes on this nice form where there are additional nonlinear terms, but if I assume that as I go up in polynomial order, those effects go down. You have this really nice term that people have reported on in multiple papers. In the regular statistical genetics generative model, I was trying to show you have a nice outline to that. So the theoretical. So, the theoretical additive variance for a new kitchen SNP should be both a combination of this additive effect and then some term that encodes this non-additive or this tagged non-additive function. And so, what we do in this IODSC paper that came out recently is we think about this, we test for tag interaction effects, right? So, here I have this effect size, I say, Effect size, let's say r theta. What I'm going to do is I'm going to fit all these using like wavelength squares, just like it's done in regular LD score regression. And the idea here is that because I know what this theoretical piece actually is, the original variance component from LD score regression plus this new ILDSD score should always be less than or equal to whatever that theoretical alpha limit is. I should never be able to explain more variance than what's actually explained from this theoretical piece. Than what's actually explained from this theoretical piece with these new interaction scores. So, I guess there's a nice upper bound from a lot of them. And so, we did a lot of simulations, and I was trying to figure out which results to show because that paper is getting pretty long. But the key things there are that ILDSC is actually well calibrated. So, in the context where there are no additive effects, the ILDSC model and LD score regression model are actually exactly the same empirically. Empirically, when we do have interaction scores or interaction effects in our generative model, and these are just different scenarios, you see this additional added boost that ends up happening when you add this additional score. And here are the really interesting things that I'm still kind of thinking through, and I would love that other people have thoughts. You know, so we try this across 25 different traits in both the UK Biobank and Biobank Japan. This dotted line. And this dotted line here, so here's the LD score PVE estimate or the variance explained estimate that comes from COVID-score regression. Here's one coming from ILDSC. This dotted line is effectively what would be the same for both of these, right? And then 25 of the 20, all 25 traits for the UK Biobank and 23 out of 25 for Biobank Japan, you actually get a statistically significant increase that happens across these traits when I think about adding that interaction LD score tag term. LD score tag term. What becomes really interesting in about a few minutes on Sasha's posts on some of this stuff, Sasha PJS posts on some of this stuff. When you do that, you can also think about running ILDSC with other annotation categories. And so what you could do is you can add like 27 or something like many annotations and ask what happens to that interaction term when I think about all these other annotations. Well, interestingly, the statistical significance piece of these interaction scores goes away. Of these interaction scores goes away, even though each of these have a positive contribution. And what I still need to figure out doing is figure out how to implement ILDSC without this block jackknife thing that has relatively conservative in terms of estimating standard errors. But what you see is still a positive increase across all traits for the UK BioBank, but we have this idea of how we can make these standard errors a little bit more calibrated in the model that we have to try again. In the model that we had to try again. So that's another interesting piece: you still see this positive increase, even with all these out of place. So, with that, we have some ongoing work. We've been thinking about this as an overall framework strategy. So, you can imagine doing this also with TYE effects. I think Pong Lou's group has thought about this a little bit recently. You can also think about exploring this with other annotation things. We've been thinking about how to incorporate other modalities. Other modalities, so things like high-C data. Can I limit where I search for interaction effects with respect to like high-C and maps? And then also think about how to extend IOVSE with multiple chips. So with that, a lot of people have acknowledged. John, I didn't put your face on here, but you're here, so you can see his face there. And people have been nice enough to work with us at this point. So yeah, with that, I'll leave these up. Thanks so much for coming. 