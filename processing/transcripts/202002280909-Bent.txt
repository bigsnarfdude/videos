My name is Renee Bent. I'm a PhD candidate at Duke University. I'm working on a thesis in digital biomarker development for pre-diabetes, but I'm not going to talk to you about my thesis today. I talk a lot about my thesis, and I'd rather share something that I think all of you will find a little bit more interesting. So I don't have to tell this crowd that digital biomarker research is expanding quite rapidly. Quite rapidly. In PubMed, the number of digital biomarker articles in the last decade has increased 325%. Something interesting about this graph is that there were articles on digital biomarkers being published in the 80s, which is kind of crazy. Even with this rapid growth of research, still only 13% of all research articles available are available open access, and even fewer provide access. And even fewer provide access to the code and data that makes the research reproducible. Additionally, there are many barriers to entry into digital biomarker development. A lot of them we've discussed here this week. First, it requires computational skills, statistical methodology. You have to have a knowledge of these things in order to accurately develop these digital biomarkers. But it also requires. But it also requires domain or clinical knowledge. It requires people that know the physiology behind the disease state. It's expensive. Computationally, it's very expensive. Also, to run these studies, it's financially expensive. Other issues are it's not standardized. So, and like we talked about many times this week, there's a real lack of validation across studies, algorithms, and devices, which is a huge problem. In our lab, In our lab, we do digital biomarker development. I don't have to go through this process because this is something that you all do every day. But this process here in the middle is something that we do over and over and over again in our lab, and we do it for various different devices, and we do a host of digital biomarkers. There's about 10 projects in the lab right now that are focused on different digital biomarkers, and we're going through this same process. So, we're taking big or big little data. Big or big little data, combining that with medical domain knowledge and using EDA, statistical analysis, machine learning, and deep learning in order to discover these digital biomarkers that may be inherent in the data. But what we found is that we're doing this over and over and over again. And we're repeating the same methodologies, but we're repeating them in different languages, and different students are repeating them. And we went out into Broader Duke and other. Out into broader Duke, and other people are doing the exact same methods we're doing, but reinventing the wheel every single time. So, what we came up with is the digital biomarker discovery pipeline. And Jesse Lynn, who spoke on Monday, Jesse Lynn Dunn and I came up with this in order to provide an open source framework, a platform for digital biomarker development using mHealth and wearables. Health and wearables. So, we wanted to do something that was modular and provided this framework for improved interoperability because of the challenges in this field. And this is the basic process of the DBDP. And so when you enter the DBDP, you're going to have some sort of goal. And this goal usually has something to do with digital biomarkers, either monitoring or an intervention, monitoring some kind of health outcome. You have some kind of sensor data, and you might have some sort of Sensor data, and you might have some sort of other data, so electronic health record data, surveys, omics, imaging data. And this is the real meat of the digital biomarker discovery pipeline, the DDDP, over here. We have a modular framework for different pre-processing for various devices. We have about 15 right now different devices for pre-processing. This involves data cleaning, quality control, date time, which is a huge problem, because we work with a variety of different Because we work with a variety of different sensors and so aligning time. Exploratory data analysis, so exploring relationships between data and outcomes prior to actually looking at the feature engineering and selection. So we have a variety of modulars focused on summary statistics, inference statistical modeling, machine learning, temporal analysis. We have multimodal integration and deep learning. And all of this is available in the DVDP. So these are our current modules in the DBDP. Like I said, there's about 10 projects currently working on this. And these ones are the ones that actually have algorithms in place that are well documented in the DBDP. And I'm going to walk you through three of them today that I think could be useful for you all given the talks that have gone on this week. And so I'll start with sleep detection. So, I'll start with sleep detection. So, this is work done by a student in our lab, Will Wong, and the problem he was coming up with, so he is studying a group of people that are on a clock shift. So they're police cadets who are sleeping in different periods throughout the day. And he has a Garmin device, and the on-board Garmin device monitors. Garmin device monitors sleep, and the way it does this is by general sleep times. So, while it does look at accelerometry and it does look at your heart rate data, it mostly only does that between approximately 9 p.m. at night and 7 a.m. in the morning. And that's consistent. And so what he developed is actually an algorithm that can detect sleep just based on your heart rate. And you can see the results here. So the salmon color is the traditional, so this is what the Garmin says. Traditional, so this is what the Garmin says should they be asleep during this time. And then you can see the red up at the top. This was his algorithm that says when they were sleeping throughout the day, and that one is accurate to the observational study. So this has been validated in a group of people that have clock shift and have normal sleep so that you're actually able to detect when people are sleeping. And this is pretty obvious when we look at it. And this is pretty obvious when we look at it too, right? I mean, just if we just did exploratory data analysis on this, we'd probably be like, there's something going on in these valleys. And that's exactly what his algorithm is doing. And this algorithm is available, well documented in the DBDP for other people to use. Another module within the DBDP is Resting Heart Rate. This was worked on by Chen Tian Jang, another student in our lab. Student in our lab, and what she was looking at was trying to estimate resting heart rate. There's not a lot of good metrics for measuring resting heart rate, especially during daily activity. And she really wanted to look at if you could extract resting heart rate from your day activity. Many of us wear wearable devices at home, and a lot of us probably don't sleep in those wearable devices. I know that mine is really bulky. I don't like to sleep in it. The Apple Watch, you actually have to plug in at night. watch you actually have to plug in at night so you usually don't sleep with it. So people who are relying on resting heart rate algorithms derived during sleep might not be getting the whole picture. So she validated her estimated resting heart rate against clinical resting heart rate and she provided all of these methods in the DVDP as well. So you can go in there and look at all of the functions that she worked with and adapt them to your own needs. Lastly, this is word Lastly, this is work that I have done for as part of my thesis, which is glycemic variability. This is actually a Python package that's available called CGM Quantify, and we have 40 different metrics of different glucose variability metrics and glucose summary metrics, and then we also provide some ways to do visualizations easily. Now, the visualizations aren't necessarily for researchers, but we're doing this in partnership with OpenAP. Doing this in partnership with OpenAPS, which are patients that actually use their own CGM data to make insights about their health and to create feedback loops with insulin pumps. So we wanted to give them a way to visualize their data easily in a nice Python package. And this one is available in Python, but there also is code in R for it. We're trying to make it agnostic between R and Python because these are two of the programming languages. These are two of the programming languages that are most ubiquitous in the field of digital biomarker development. So in addition to our actual digital biomarker modules where you see our full steps, we also have exploratory data analysis modules, including a lot of visualizations like missing data. I've seen some incredible visualizations and I'm like jotting notes down throughout this process because I really want to figure out how you all Because I really want to figure out how you all did a lot of your visualizations. So, if you have really cool visualizations, we would love for you to put them up on this because I want to use your really cool visualizations. They're awesome and it'll help me get better talks too. We also have a variety of resampling methods. We have to do a lot of resampling, downsampling and upsampling, for a variety of reasons, especially in our lab because we've worked. Especially in our lab, because we work with so many different sensors. So, we're looking at sensors that go from 4 hertz all the way to 64 hertz. So, we have to do some resampling. So, we have our methodologies that have been published also available in the DVDP. Additionally, like I said, we have a lot of pre-processing modules that do all of that data cleaning. We also provide a lot of our signal alignment packages, including some of our novel dynamic time morphing algorithms that we've developed so that you That we've developed so that you all can use them to align signals. We also have multivariate sequence generation for deep learning. So, this was also a part of my thesis. In my thesis, I'm working in deep learning with multivariate sensors. And so, we've actually developed a sequence generator that's also available within the DVDP. We're also doing a lot of educational and outreach within the DVDP. And outreach within the DBDP. So, through the Rhodes Information Initiative at Duke University, we're hosting a Data Plus project this summer, and there's going to be a team of undergraduate and master's students, and their end goal is to do some activity recognition as a module for the DBDP. This is also being used in Duke classes, including intro to biomedical data science in the Pratt School of Engineering at Duke. At Duke. We also have a workshop in the Women in Data Science Conference that's coming in April to Duke. And so we have a workshop on the DBDP to encourage collaboration. So by 2022, our goal is to have 100 or more digital biomarkers within the GBDP, and we need your help with that. I've seen some really amazing things while I've been here. It's truly been an incredible experience because I had no idea there was so much cool No idea. There was so much cool research being done in this area. I feel very siloed sometimes working in it, but it's been amazing. And you all have some really incredible methods that I want to try out, and I'm sure a lot of other people here would like to try out. So you can actually contribute your digital biomarker module here, or just visualization functions, links to functions, links to your packages. And we have contribution guidelines, a validation process. A validation process. It does require some testing data. This can be totally de-identified just to make sure that your package works properly. So here's my slide for discussion points because I know that is part of this process. And even though we're on the last day, hopefully we can take this offline and continue this discussion. So I'd really like to know a little bit more about how we can make open source code. We can make open source code a requirement or a high recommendation in digital biomarker development. I think it's really important to include that for reproducibility of our models. And then I'd really like to create a culture of collaboration in this space. This is something that we've started to do while here, and I hope we can continue that offline. And then this is my call to action at the end. I'm giving you the challenge to open source the code for your projects. Open source the code for your projects, whether that's part of the DBDP or something else. Please provide your code, well-commented code, so we can all try your methods and make sure that we're validating these digital biomarkers, especially before they're being used clinically. So, the last thing I'll say is that if we were able to go and summit this mountain, Sulphur Mountain, together, I think that we can together create a really awesome. Create a really awesome open source collaborative environment within digital biomarker research. I'd like to thank the Duke University Big Ideas Lab, BIRS, DukeForge for all of their amazing support. And then my contact information is here. Please reach out to me if you want to continue this discussion because I would really love to. Thank you. Any questions or comments for Rubina? Yeah, this is a really nice. Yeah, this is a really nice idea. I was wondering, first off, is there any kind of quality control check in place for people who submit their own modules? And also, are the modules, can they be sort of linked up with different languages? Say I submit something in R and have something downstream that's in Python. Is there some sort of interface that is built in? Yeah, absolutely. So, as long as it's very well documented and you provide like a small piece of test data that we can actually test your function on. So, I think you said yesterday you. On. So I think you said yesterday you submitted to the Journal of Open Source Software. So it's similar to that, is that you provide some testing data for them to be able to validate it. Do you do continuous integration? Pardon? Do you do CI? Continuous integration? Oh, yes. Yeah. So that's a portion of it as well. And we have the entire team at the Big Ideas Lab working on that. So I had a quick question also about validation. So, like, you know, if I want You know, biomarkers that are ultimately going to be used in the field, the validation is obviously challenging because you want to make sure that the behavior you're measuring, their behavioral biomarkers, is really one that's happening in the field. Are there any, I don't know, is there any sort of practices or framework for that people have come up with? Like, is there a way to sort of do that validation and be confident you're following best practices or really kind of problem and domain specific that you know for physical activity we do this and for smoking we do this? Yeah, absolutely. Yeah, absolutely. So that is a great point. And we actually, through the Dime Society, the Digital Medicine Society, we wrote a paper that hopefully will be out soon. It's in preprint now and should be out soon in Nature Digital Medicine that goes through a standard framework for the verification and validation of these sensors, the data, and the algorithms. So I'll send you the framework. And what about the computer? Yeah, yeah. And what about the conditions for use of the biomarkers? So, if they're put out there as open source, what are the terms of use? Yeah, so that's a great point. And so, we're working within the MIT license. So, as long as it follows all of those, usually in our documentation process, if you put something to cite, then they will cite that. So, for a lot of our modules, we actually have papers that we just ask you to cite this paper. Papers that we just asked you to cite this paper if you use our module. What about like commercial use? So, MIT license does allow for some commercial use, but it does require those citations to back it up. But I would imagine people might be willing to share biomarkers for use by the research community, you know, but then they want to reserve the right to commercialize that biomarker in some fashion. Commercialize that biomarker in some fashion, then they wouldn't want it to be shared in a way that allows anyone to use it for commercial purposes without getting a license. Absolutely, and so what somebody doing that might do is they might provide some of their code open source and more of their proprietary algorithms, they keep those not open source. We recommend for everybody to do as much as they can open source, but understand the financial limitations of some of that. In the academic community, though, definitely. In the academic community, though, definitely trying to be as open source as possible because I think it's really important to be able to do validation across these studies. Quick question. About your glucose package, are you using those metrics, like the 40 ones that you selected from Rodbart 2009 paper? So we went through a very large lit search and just like grabbed all of the different glucose variability metrics that are being used across fields, including the newer ones. We also have a few. Newer ones. We also have a few in there that we came up with as a lab. Yeah, because we have an R package for 41s that are in Roarbart 1000, and maybe some more 60 lines. Yeah, absolutely. So that would be a perfect addition to our module because then we would have the package I developed in Python and the package you developed in R, and then people can use either one and know that these are validated metrics. So right now, if you go to DBD, So, right now, if you go to dbdp.org, that's our website that is still very under development, but we'll have a link to the GitHub on there. Any more questions? All right, thank you all so much.