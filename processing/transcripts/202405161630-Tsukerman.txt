Well, thank you very much. Thank you very much for being here. Okay, I appreciate it. We're approaching the end of the conference, sadly. And I think that at this time it's probably fair to say that the organizers have done a fantastic job and deserve a big thumbs up. May I ask for a quick show of thumbs? Who thinks it's a thumbs up? One, two, three, four, four, five, six, seven. Four, four, five, six, seven, eight, nine, ten, eleven, twelve, thirteen, fourteen. Thumbs down. No one, zero abstentions, abstentions. Okay, the organizers themselves are very humble, so they think they abstained. But otherwise, I think the motion passes. Thank you, thank you, thank you very much. And I cannot, on a personal note, Keyanote on the personal note, I uh I could not have thought of a better start of my uh sabbatical year. It's just it's lovely, it's very nice. All right, so let us let us move on. So as a preamble, I would like to talk about the style and content of my talk. So, first of all, I am an electrical engineer by training, so that means that I have a fairly high level of tolerance. Fairly high level of tolerance for hand-waving arguments, but that tolerance is not infinite. So, for example, I do not like circular arguments, and I'll give an example of some major circular argument in the physical literature toward the end and ways to kind of get out of that circle. Okay, so I thought about the kind of balancing breadth and depth, and I already confessed the other way to Peter. Well, that I have no breadth. I have no depth. I have no breadth. I have no depth rather, but only depth. So I decided in favor of breadth because also I'm hoping that maybe some bits and pieces you will pick up and maybe you will like. And there is lots of good mathematics to be done still, I think, in some of those areas that they will highlight. And there are some mysteries there that they will also highlight that still remain to be solved. To be solved. Okay, so I decided to split it up into two parts. In part one, I will talk about numerical applications of traffic functions. And in the second part, I will talk about physical applications of trust functions. So in the first part, trust functions will play a major role, the dominant role. And in the second part, trust functions will be important, but they will kind of play second fiddle. I promise that there will be not a word about the finite element method, because if you About finite element method, because you've heard enough about that. And the project that I happen to be on on DG drafts, there I played a very, very minor role, and the main role was played by my collaborators. Okay, so in the part one, I will talk about some simple examples of finite difference draft schemes. I call them FLAME for a flexible local approximation method. Then I will give some less simple examples of those. I will give some less simple examples of those schemes. I'll talk about radiation boundary conditions as another application of Treft's ideas, Traft's approximations. As another example, Treft's different schemes for waves in disordered structures. And Traft's different schemes for the computational block bands and periodic structures. In part two, I will talk about the mysteries. There are real mysteries, there are fake mysteries, and how they're related to trust functions and how trust functions can help us. Functions and how thrust functions can help us solve those mysteries. So, one, the first one is non-magnetic magnets. You may have heard about it, maybe not. I will explain what that is and what it has to do with trust functions. And the other is so-called topologically protected boundary modes, also related to some mysteries of block bands. And I emphasize that those are real mysteries. That is something that is very hard to explain and very counterintuitive. As opposed to some fake mysteries, and I could not resist, and I included my favorite. Resist and included my favorite kind of fake mystery from the adventure of Sherlock Holmes. Here is this quote. So, Holmes says to Dr. Watson, and he figured out that Dr. Watson's bedroom window is on the right side. And why? Because, well, this is a full quote, because Dr. Watson is shaped better. Shaving is better on the right side than on the left side. I think the first time I read it was maybe I would have been maybe 10, 11 years old. Since then, I've been trying to figure out what side of my... Figure out on what side of my bedroom the window is, and I still kind of cannot quite figure that out. Sometimes it seems to be on the left, sometimes on the right, I don't know. So that's an example of a thick mystery. I would like to talk about kind of real ones. All right, so my students, the ones who worked on trafts, not all of them, but the ones who contributed to traffic. And embarrassingly, to my chagrin, I'm not a good photographer, so I do not have pictures of frantic children. Pictures of Francia Shikcheika, who was a very those of Franceschek and Jean Howard Io were very good students. This Alexander Plax was a very talented, bright one who is now working in Google. And Leonid Proak, another very good student who is now at Intel. And Sharia Hussain is now finishing his PhD at Case Western. And then co-authors on the Trafts papers. Okay, lots of credit goes to them. Them. I probably do not have time to talk about all of them, but Dean Markle is my longtime collaborator for more than 10 years. And then we have several papers with Yidong Chung and Seo Yang Seong, Li Junjiang from Hong Kong University previously, and now they're different places, and the German group, and they are the ones who are really experts on DG TREFS. Particularly, of course, of course, you know Herbert Egger in this community. In this community. Okay, and some co-authors, some other co-authors, I could not resist again, include Sergei Boživoni, even though we had just one paper with him, but I'm very proud that he is the man who makes the magic happen. It's not his webpage, but it is the university webpage where he appears. All right. So the first big subject is flame schemes. I call them flexible local approximation methods, so find a difference to have schemes. Draft schemes. In the classical finite difference schemes, as we all know very well, the problem with them, one of the problems with them, is that Taylor approximations on which the schemes are based break down at material interfaces. And so it's difficult to construct high-order schemes at those interfaces that slanted the curved in particular boundaries. There are staircase features. But this is a matter of approximation, I would argue, not a matter of geometry. Anyway, if we have the better approximation of the boundaries, then... If we have the better approximation of the boundaries, then we would not be dependent on whether or not the measures are regular. Okay, so the idea is a pretty straightforward one. So replace the tail expansions of standard finite difference schemes with local trust approximations. Okay, and then we'll build finite difference schemes on that basis. So, examples of such functions well in this community that is very well known, but I will. That is very well known, but I will give less, these are simple examples. I will give less simple examples later on. And that improves accuracy dramatically in many cases because, well, TREFS functions have this feature in many cases. As again, I do not need to explain that to this audience. Okay, so how does that work for in the final difference context? So imagine that we have a regular mesh. It doesn't have to be regular, but it's the easiest setup. And suppose we have The user setup, and suppose we have a patch. I'm borrowing that terminology from a generalized M. And so that patch the shape of it doesn't matter, I call it omega sub i. So that's a domain that contains several nodes. Okay, and we are interested in building a different scheme on those nodes based on Taylor expansions as opposed to Taylor approximations or Taylor series. Okay, so we'll look at a set of stress functions, suitable. set of stress functions, it's a suitable choice of a set of stress functions. I call them size with some coefficients. And naturally, the nodal values, the nodal values of this expansion are linearly related to the coefficients with some matrix N, which is very easy to visualize. And if you stare at it for a minute, you will see what this matrix is. And I'll have it on the second on the next page. Okay. Okay, so schematically the idea is very, very, very straightforward. So imagine, well, this blob represents very, very schematically a functional space that is spanned by the set of thresh functions in this patch, this local set of thres functions. And so if we have the ability to build an exact scheme, to construct an exact finite difference scheme, and the solution happens to be in that functional space, then of course we're done because we have an exact scheme where the solution satisfies that exactly. Solution satisfies that exactly. If the solution is close, so if the approximation properties of the finite difference, oh, I'm sorry, of this functional space are good, and the exact solution is pretty close, schematically, I showed it as some small epsilon, then the scheme is not going to be exact, but it's going to have a low consistency area of high order. Okay, and so one example, one example, one trivial example of that, suppose we have a three-point scheme in one dimension, and we want to build. In one dimension, and I want to build a scheme for Laplace equation in 1D. We've got two tress functions, oops, I'm sorry, one, one, and x, one, one, and x, and there are three nodal values, and therefore, those nodal values have to be linearly dependent, and therefore that is the different scheme that we're looking for. How to construct it? Well, we just need to do a tiny bit of linear algebra. It's so it's almost embarrassingly simple. And we end up, I'm not going to go through that because anybody can do that. Through that, because anybody can do that in just a few minutes, I think, in this audience. So, what we end up with is the coefficients of the scheme are the null space, and I will always assume that null space is of dimension one, so we'll construct this as the null space of this matrix that contains the nodal values of the basis function. So, a very simple matrix. We take the first basis function and evaluate it at the nodes, and we take the second basis function and evaluate it at the nodes, and so on. And then we take the null space of this matrix. Of course, it has to be judiciously constructed. Yes. Yes, I mentioned that, so we always try to make it this dimension one. Yes, so I say the inclusion here, but really in most cases, the actual non-practical. In most cases, actually, in all practical cases, it's going to be quality. Okay, so it's embarrassingly simple, but it has very nice, kind of rich consequences. So, let's start with trivial examples. So, again, let's start with the plus equation of one dimension. So, then we have, well, the transpose matrix is the first, the first basis function is just one, and so evaluated, but not that gives us the row of ones, and the second basis function is x, assuming that the origin is in the middle, so it gives us and the Is in the middle, so it gives us, and the mesh is uniform, doesn't have to be, but for simplicity, let's say minus h, 0, h. And we get the standard up to, of course, an obituary factor if it's a homogeneous equation. So we get 1 minus 2 and 1. Nothing surprising there, except for the fact that we get it automatically. Okay, next, more interestingly, we've got, let's say, the Helmholtz equation. Okay, again, again, uniform, so kappa is constant. Okay, we do the same thing. Okay, we do the same thing. We construct the n matrix, plug in the well, the trusts, the trust functions are obviously the exponentials, and we plug them into this matrix, take the null space, and that's what we're getting as compared to the standard scheme that we would be getting from tail expansions. They, of course, agree to second order, but this scheme is exact, meaning that, well, we can have, we can step through that equation with an arbitrary step size, and we can step over. Arbitrary step size, and we can step over several periods, even, and we're getting the exact solution. Okay, so that's an exact scheme. Another example, again, in one dimension, is the heat conduction equation. Maybe I'll skip that because all of those things are pretty obvious. In three dimensions, we have a seven-point stencil-laplace equation. Again, similar thing. We take harmonic polynomials up to certain order, up to second order in this case. In this case, and then plug them, plug the nodal values of those harmonic polynomials into this end matrix, take the null space, and we get the standard, we get the standard stencil, the standard difference scheme. Again, not surprisingly, you cannot get anything else out of this set of nodes. Okay, slightly more interestingly, if we look at the nine-point scheme, again, take the first set of harmonic polynomials up to, well, I guess also second, second-order. Well, I guess also second, second order. Well, it's going to be fourth order, I guess. Yeah, up to fourth or fourth order. And then again, construct the n-matrix, take the null space, we get this scheme, which is a null scheme. It appears, let's say, in the Collatz book, for example. He calls it the Merch Stellen scheme, pardon my German pronunciation. Okay, and that's a scheme of order six on the regular, if the mesh size is uniform. Okay, so again, nothing new here, except for the fact. Nothing, nothing new here, except for the fact that we get it automatically. Collatz spends a couple of pages deriving that scheme, and we get it automatically from that null space formula. Similarly, for in three dimensions, we have this, I split it up into three levels of the set of knowns, first layer, and the second layer, and the third layer. And we've got the set of coefficients again that is known, and we can find it in the Collette's book, but again, he spent several pages on that. He spent several pages on that, and it comes out automatically from the null space formula, which is nice. The Helmholtz equation in two dimensions, again, it is more cumbersome, but with the symbolic algebra, it's very straightforward, and you get that set of coefficients. Next, in one dimension, just for fun. Just for fun, the super high order schemes on the three points ten cell. The intuition is if you have three points ten cell, well, the highest order you can get is second order. That's not true. In fact, the order of the scheme is not limited. If you can construct Trump's functions to any order, then you get the scheme of the commensurate order. And here I illustrated that. So this is a Schrodinger equation, the four-harmonic oscillator. for a harmonic oscillator with some potential. And as an example, I took this quadratic potential for harmonic oscillator. And you get oops and you get high order convergence until you hit the stability or ill poseness, yield conditioning. All right. And the next again, mostly for the fun of it, I came across this paper with an example of a single equation. I decided to apply this finite difference trust method. This takes a little bit more analytical work. You need an expansion. You need an expansion. Oh, I didn't mention how I found the trust functions in that instance. Let's say I didn't know at the time. This goes back years, so I didn't know at the time that this was supposed to be quasi-threft. That this was supposed to be quasi-trefts. So I just called them, I just called them troughs, but not exact troughs. And so the local expansion of the potential into a Taylor series will be in the quadratic case, of course, it's trivial. You already have it as a quadratic polynomial, and then you expand U and then you collect the coefficients, exactly what Lismarie did. But I didn't know it was classy traffic. Sorry. And similarly here, so except that the tail expansion, not the tail expansion, but you need to add a singular term there because it's a single equation that has a singularity, square root of singularity, I believe. So you need to add that term to construct trust functions. And you get to get very accurate solutions, almost up to arbitrary accuracy. You do hit some pill poseness there, but you get if you want to play that game, you can get much better. If you want to play that game, you can get much many more digits than in the papers by the Red and Shoemaker. Okay, so what is the general idea of Lami already? I think I made it clear already, so we want to use any functions, not necessarily harmonic polynomials, not necessarily plane waves, but something that may be more complicated than that. There are typical features, and I say the special behavior of solutions of different practical problems. Solutions of different practical problems. Through behavior is actually typical and not special. There are often peaks, there are boundary layers like here. In the problems that I have been interested in, there are dipole local dipole behavior like that. If you have, let's say, particle, then the field around it will look like this approximately. And so it would be nice to be able to incorporate those special functions there into, let's say, find a difference scheme. Find a different scheme. Okay, in high dimensions, of course, you're not as lucky as in 1D. Well, the reason we could do magic, as I showed to you, and construct schemes of arbitrary order in one dimension is because the functional space of solutions is two-dimensional, if you have a second-order equation, of course. Similarly, for higher order equations, the solution space is finite-dimensional. And therefore, if you have a set of trust functions, a finite set of trough functions, then you can do magic with that. Can do magic with that. In high dimensions, you're not so lucky, and that will play actually a major role in several instances that I'm going to talk about. But we can do our best. And so that's the general motivation. So I would like to use kind of arbitrary approximative functions, arbitrary trust functions, more complicated than just, let's say, harmonic polynomials. But I had some personal motivations for doing this. My motivation one was the statement by Tom. Was the statement by Thomas Weiland that he made when we had a short discussion at the conference a long time ago in 2002? And he said that FIT, which stands for finite integration schemes, and for our purposes we can view that as just finite difference time domain schemes. And so when I asked him, you know, why wouldn't you do finite element analysis when they had complex geometries? And he said, well, we can do with finite difference schemes everything that finite element method can do and more and better. And more and better. Okay, that's of course the bold statement. But on the other hand, well, first of all, Thomas Weiland is not a random person in the street. He's certainly the founder of a very successful finite difference. Well, they wouldn't call it finite difference. They call it FIT, Financial Migration technique. But he's the founder of a very successful company, major commercial software. So it should be taken fairly seriously. Be taken fairly seriously. And what I thought as a result of this short conversation is: you know, what is really the best, and that's a legitimate question to ask: what's the best that kind of difference methods can do on a regular grid? The best, of course, is in quotes, because it depends on your measure and your goals, but it's kind of an open-ended question that is fair to ask. Okay, so my motivation number two came from a project that I had with Gary Friedman and his collaborators and And they invented this method of particle assembly that is controllable by magnetic fields. Okay, I don't want to get into details of how this is done, but the most interesting point is, from my at least perspective and from my perspective as numerical analysts, is that there's a bunch of particles in the solvent in generally, in some electrolyte, a bunch of colloidal particles, let's say, floating around. So Gary invented the method with So, Gary invented the method with his very capable graduate student to control that behavior using magnetic fields. But the question is: if you have just pure electrostatic problem, and maybe with some magnetic attacks as well added to that, how can you describe or how can you model the behavior of those particles? And several approaches come to mind. So, of course, the finite element method comes to mind, but if you think about, well, I kind of promised not to mention the finite element method, so I'll keep my mind. Mentioned the final method, so I'll keep my promise. I already did it, okay. Well, it's my promise, so I can take it back. It's my promise. I gave it, I can take it back every once in a while. Generalized FAM, again, I will not mention that either. One, okay, but you can imagine what it would take to construct if those particles move and you want to solve it in the time domain. Solve it in the time domain. Just constructing the meshes is a bit of a problem. Okay, of course, you can think about multiple multipole methods combined with fast multipole. And that will be legitimate. But if, in addition to the particles, you have a substrate, then Green's functions will be difficult, and it will be quite complicated, cumbersome to do that. But in any case, I thought, well, what is the best that we can do? What is the best that we can do on the regular grids? Okay, and so I try to, that was my second motivation for thinking about that. Okay, that I can skip because everybody knows this. Trust functions have very excellent approximation properties in many cases. So this is a citation from one of the Babushka's, I think, papers, approximation of Laplace solution using harmonic polynomials that's exponential behavior. Using harmonic polynomials, that's exponential behavior, versus using all polynomials up to a certain order, and that is going to be algebraic behavior for the approximation error. Okay, and another example, well, everybody here in this audience can cite this. You can cite it in your sleep of those results from Ralph Gitmeyer and others. But again, that shows exponential convergence for plane wave approximation. Okay, so how do we construct, let's say, So, how do we construct? Let's say, getting back to the particle problem, how can we construct those special functions? And the answer is pretty simple. If we're just talking about pure electrostatics, then we have a spherical particle, then there is a Laplace equation. There's the solution in terms of spherical or cylindrical harmonics in the 3D case is for spherical harmonics. There is a solution inside, there is a solution outside in terms of harmonics. We match them at the boundary using the boundary conditions. Using the boundary conditions, and there we go, we get, as a result, we get those basis functions that we can then use to construct Trev schemes. Okay, if we have a solvent with colloidal particles, I need to say first of all a few words about the physics of that. The importance of colloidal systems is great, so many systems have that property, and that is paints, milk, et cetera. Ice cream even is a colloidal system, believe it or not. System to leave, but they're not. And so the physics of that is just in a nutshell. Those particles are charged, typically charged because of electrochemical reactions with their surfaces. And so they repel each other. And that is what keeps the system stable. But if they come too close, then van der Waals forces of attraction take over, and then the particles collapse, and the system can coagulate, as we know with MILC, let's say. And so we just need to model those. So we just need to model those electrostatic interactions in the solvent. And the equation there is different, of course, because of the presence of the solvent and the presence of ions in the solvent. The model is different from just from a pure Laplace equation. And the physics of it, again, very, very quickly, is this. Suppose you have an electrode that is negatively charged and the colloidal particles around it that are floating around that are positively charged. So they would want to collapse on the electrode. Would want to collapse on the electrode because of the opposite charges, but they do not because of the thermal motion. So there is a dynamic equilibrium, there is this Boltzmann distribution of the density of particles away from the electrode. And that is, of course, well known in the physics of collides. So there is, as a result of that, there is the Poisson-Boltzmann equation. So this is nothing other than the Poisson equation, where the charge density happens to have the Boltzmann distribution. And then you can linearize that under certain conditions and the other. Under certain conditions, under other conditions, you cannot, but under certain assumptions, if the charges are not too high, then you can linearize that and end up with a linearized Poisson-Boltzmann equation, which is really the Helmholtz equation, but with the right, I don't if I can call it the right side of the coefficient there. So you have, instead of waves, you've got exponential decay. And that's clear why, because the particles screen the yield of the electrode. Screen the field of the electrode, and so it does decay as opposed to exhibiting a wave-like behavior. Okay, so this looks cumbersome, but you can easily put it in the computer. So those are the functions that the construct, Trev's functions constructed by just looking at this Laplace equation inside the particle and then the analytical solution outside the particle, matching them at the boundary, and you get the trash function of that. And you get the trust functions that way. And then you can put it into the different scheme, compare it with some existing solutions, and you get fairly good results. So I will skip some of the, we do not have time kind of to delve into the details of all of those simulations. I don't think we need to do that. Well, it worked pretty well. Next example is, let me see how I do with the time. Well, five hours was my initial plan, but they trimmed it down to two hours, sadly. So, okay. So, another example is scattering from a cylinder. I think you probably are guessing where this is going, right? So, then you can construct press functions there fairly easily. Again, uses cylindrical harmonics in this case. It's, of course, well known in scattering problems. And scattering problems. And then you simulate that. If you do not impose any absorbing conditions, then of course you get stuck at a certain point. But if you impose some absorbing conditions about which I'll talk a little bit later, then well the convergence is good and consistent with the order of the schema. In this case, this dashed reference dashed line is the H to is six order convergence. H six-order conversions. Here's an example of what is known as a photonic crystal. Okay, so it's really a bunch of cylinders, the electric cylinders on a regular grid, but there is a waveguide carved out of it. And under certain conditions about which I'm going to talk a little bit later also, the wave cannot propagate through the crystal, but it can propagate through the waveguide. So even though this waveguide has no walls, the wave can propagate without... The wave can propagate without any dissipation or scattering into the crystal itself. That, of course, is also well known. It was a very, very popular direction of research, particularly in the 1990s. Then there is less activity in that area because it got saturated at some point. But I decided to model it using the finite difference scheme. And that's a comparison. So, if you get the stimuli accuracy, level of accuracy, comparable level of accuracy, this is the finite element mesh. Element mesh you need to have. I forget whether that was probably first-order elements in this case, or maybe second-order, I have to check. And this is just a regular 50 by 50 of Flame scheme or trafts by a different scheme. Again, it does not honor in any way the boundaries, so it crosses the boundaries at random points, and that doesn't really matter because the boundaries are taken care of by Are taken care of by the approximation properties of the curve spaces as opposed to any geometric approximation. Okay, and so this is actually the wave behavior inside the crystal. Again, it doesn't matter to us the details of that. What matters is, well, we get fairly accurate results in comparison between finite element and finite difference analysis. Okay, next that was joint work with John Webb and his graduate student, Helder Pinher. Graduate student, Helder Pehero from McGill. And so, similar but more complicated geometry, waveguide modes, and in photonic waveguides. So two coupled waveguides. And again, the principle is the same. Have a regular mesh, construct a different scheme, and we'll compare the results with other methods. And of course, the finding different threft scheme compares favorably. Otherwise, it would not. Scheme compares favorably, otherwise, it would not have published that. Okay, and then the next, and that's an important problem related to the ones that I described before. This is so-called band structure computation. So many, of course, will know that if you've taken any physics courses, you would have encountered that in your physics courses. But if you haven't, let me say a few words about that. So, in one dimension, I'm using the first simplicity, and then it generalizes to multiple dimensions. It generalizes to multiple dimensions. So we've got this wave equation, have a slightly different system of units here with the μ0 in there, but that's the Helmholtz equation, but with a variable parameter there with the dielectric permittivity there as a variable parameter. And then eigenmodes of that in general have this form. They're known as block waves. There is a periodic factor there, the lattice periodic factor, times the plane wave. Okay, where case. A plane wave. Okay, where K sub B and some other instances I will call it Q. It will be the same thing. Sorry about kind of this little mismatch of notation. It's just historical mismatch. So if you're seeing this for the first time, then a couple of ways of interpreting this, this expression for the block wave, which is an eigenmode of this count quality equation with periodic coefficients. One way of looking at it is. One way of looking at it is: well, particularly if this periodic factor is just constant, then we're falling back on the plane waves. So we can view this as a generalized plane wave where there is a pre-factor that is slightest periodic. Another way of looking at it, slightly different and maybe more physical, is that if you have a periodic equation, a periodic problem, and a periodic lattice, then naively you might expect that, well, there's going to be a periodic solution. That, well, there's going to be a periodic solution, just that. But no, there is this additional factor that characterizes if K is real, then it characterizes just the phase shift. So if you go from one Lyttosault to the other, you get, well, pretty much the same solution, but with the phase shift. Okay, so that is the intuition behind that. And much of solid state physics, condensed matter physics, is based on block modes. If not, yes, yeah, that's right. Yes. Yeah, I should I should have said that. Sorry about that. So, yes, it is a periodic function. And there may also be magnetic properties where mu would also be a periodic function and block modes would have the same form. Okay, so those are fundamental on the question of calculating and computing block modes. It's not trivial, particularly three-dimensional is not trivial at all. Not trivial at all, and that's one of the central questions in condensed matter physics. And there are numerical issues there that, and I think there are some open questions there as well. I know that Peter worked on that, a problem, particularly in 3D, when you've got maybe I have something like that on one of the next slides, but when epsilon also depends on the frequency, in addition to being dependent on coordinates, that becomes nonlinear with respect. non-linear with respect with respect to the eigenparameter omega, and therefore that becomes even more complicated. So in 3D, this really is, to my knowledge, you can call it an unsolved problem in terms of numerics of it, or partly solved maybe. All right, so these are typical block diagrams. So for those of you who know this, I don't need to explain anything. For those of you who do not know, let me just say a few words. Let me just say a few words, kind of to give you a general impression of what it is, to give you a flavor of what it is without getting into too much detail. And this is, of course, you can find it in any physics, the book on condensed matter. So on the horizontal axis, you can view this as just the wave number, go in different directions, though. Okay, so this is the block wave number. And on the vertical axis, that is the frequency. And what's important there is that there are bands, okay, so where Case of where waves can propagate, so there is a certain wave number, and I should emphasize that those are real wave numbers. Okay, so we're not talking about in the band area, we're not talking about evanescent waves. Those are propagating waves with a certain wave number on the horizontal axis and a certain frequency on the vertical axis. And then, even more importantly, maybe equally importantly, there are gaps. There are band gaps where waves cannot propagate. There are band gaps where waves cannot propagate, or more precisely, there are just evanescent waves in those frequency ranges, which are highlighted here in gray. Okay, so this is one gap, and this is another gap. Oops, I'm sorry. Wrong button again. Okay, so we did this calculation using finite different TREF schemes. I'm sure you understand how this was done. So, this is a lattice cell with a cylinder in it. Okay, so that's very typical. Okay, so that's very typical for botanic crystals, just a cylindrical inclusion inside a lattice cell. Okay, and you can have a very coarse grid, which I will illustrate later, and construct again the Trev spaces functions in the same kind of very simple way as I described before, matching cylindrical harmonics inside and outside. And off you go, you solve that problem, and because the mesh is coarse, it is not expensive to solve it. It is not expensive to solve it. And then another example, this is a more complicated example of so-called plasmonic crystals. Well, plasmonics is a kind of a fancy word that physicists use for our intensive purposes. It's just metal crystals. And there you really have frequency dispersion. So you've got the parameter that I mentioned before, the epsilon, that depends not just on coordinates, but also depends on the frequency. And that problem with spectra omega. Problem with spect omega, if I go back to it, this problem becomes nonlinear with the spectrum if epsilon, if epsilon also depends on omega. However, there are two eigenparameters there. There's one eigenparameter is the frequency, and the other one is the block wave number. And so if you fix the block wave number and solve for the frequency, then the problem is nonlinear. But if you go the other way around, if you fix the frequency, which If you fix a frequency, which then therefore fixes the epsilon as a function of position, then you have a linear, or in some cases, a quadratic eigenpro, which can be reduced to linear with respect to the block wave number. Okay, so in many cases, when you have frequency dispersion of frequency dependence of parameters, it's better to go that route and avoid nonlinearity in the eigenproblem. And so that's another comparison, that's another example of that kind. And that's another example of that kind. We compared our results with the ones published by some of the experts in botanics, the group of Gennady Schvetz. Negative refraction, that was very, very fashionable in the early 2000s. So we tried to do that as well. It worked pretty well. I don't want to. It was very, very popular for like five, six, maybe even seven years. And then five, six, seven years later, and a few hundred. Five, six, seven years later, and a few hundred million dollars later, it fizzled. But what did not fizzle is fine and different strap schemes applied to that. They still are strong. All right, so we had good results in that case as well. There are some funny features that if you look at how the wave behaves, that when the one the refraction of the wave is kind of opposite to what it is, what normally is, then it looks a little funny. But as far as our subject is concerned, as far as As far as our subject is concerned, as far as thrift's methods, there was little difference. There are some stability issues and so on when you've got negative refraction. But again, those are details that are not important to us. Okay, and then one generalization that I can partly speculate about, because there is only one paper that I published on that, and with just one, I guess, one application example. If you were to replace the null space formula with the SVD formula, And with the SVD formula, we take instead of the null vector, the minimum, the vector corresponding to the minimum singular value. You can have the same or similar consistency errors, kind of modulo the value of the minimum of the minimum singular value. If the minimum singular value is small, then you can get the same estimates for the approximation error of the scheme. Any questions, by the way? Scheme. Any questions, by the way? So feel free to kind of interrupt me at any point. All right, so instead of the null space formula, we can try the S V D decomposition. Of course, those metrics are very, very small, so computational cost is absolutely not an issue. Those are small kind of grid molecules, and that's not an issue. The advantage of that approach is that then you're not. That then you're not limited strictly to one-dimensional null space, and you do not need to match the number of trust functions to the number of nodes in any way. You can have kind of random, you can have a meshless setup, you can have a random nodes distributed anywhere, and you can have a bunch of we can have a bunch of thrust functions as well. So, okay, this can still be, even though it is published, I didn't have enough time or, I guess, motivation, enough motivation to develop it further, but I think it could be done. All right, and then another example that is fairly recent, okay, that comes from our joint work with the group of Yu Dong Chung and his graduate student Shampi Manshe in Singapore at Nanyang Technical University. Yu Dong Chung, I will have an occasion to mention. Yu Dong Chung, I will have an occasion to mention him later. He is a very, very good theoretical physicist who knows also a lot about numerical analysis. And he was one of the pioneers of topological photonics, which I will mention later in the second part of this presentation. Okay, so the problem is this. They are interested, and by the way, I should mention, I did mention that in the previous slide, so the credit for the next The credit for the next bunch of slides goes to Champion Mansion, his work, his simulations. So, the problem that they have is: suppose that you have not a periodic structure, but you have the kind of a quasi-random structure. And I don't want to get into the reasons why they're interested in that. So, they're interested in so-called random lasers and similar things. Okay, so suppose that you have a structure that is disordered and Disordered and you need to calculate the electromagnetic fields around it or in it. And then again, it's clear that standard methods, which I will not mention, keeping my promise, in 2D will not be difficult, but in 3D they will face problems. But even in 2D, yeah, in 2D you can do pre pretty much anything, I think. But but in 3D that is But in 3D, that is difficult. And so we wanted to see how far we can really stretch the finite difference draft schemes. I'm not claiming that this is the best method by any means. It is just interesting to see what can be done. And well, Shampi Mansh actually succeeded in doing that. So here is, but this was still admittedly in the two-dimensional setting that we did it. So suppose that we've got some quasi-random structure that consists. Quasi-random structure that consists typically of a substrate and then some pillars, and the pillars are distributed in some random or quasi-random manner using some physical considerations or design considerations. Okay, and so we would like to solve this on a regular finite difference grid and construct the finite difference trust scheme, even though this is a complicated structure. Okay, so the question is: how to construct thrust functions? And again, I did not know that they. And again, I did not know that they were supposed to be called Poison traffic in this case. So we have some grid molecules of different types, six, nine points at the boundaries. There are different combination of fields. Those are details that do not really matter to us. This is a typical kind of an example structure that Champé simulated, and he had several kind of example structures that he simulated. That you simulated. And the way the basic functions are constructed is by interrogating this structure with some external excitation at different angles. Okay, and also having different separation distances. So this is a pillar. Suppose we assume that it's separated sufficiently from other pillars. Let's say, and so there's some typical length L, where no other pillars exist. And then we can also double that length and double L doesn't. Double that length and double L doesn't assume doesn't contain other pillars as well. So we can, as a first approximation, say that this pillar is a standalone one, and then we can interrogate it with different plane waves coming from different directions and solve this small problem numerically, imposing some artificial kind of periodic conditions on the boundaries. And we hope that this will represent give well a good enough representation on physical grounds. On physical grounds, okay, without any, certainly mathematical proofs would be very difficult or maybe impossible. But on the physical grounds, we assume that, well, if we have a representative set of excitations and a representative piece of geometry, then we can construct functions that are at least physical. And so that's the main idea. And Champi actually succeeded in the structures that we calculated. Of course, you can defeat this, but within reasonable frequency ranges and with reasonable... Ranges and with reasonable structures, reasonable meaning that you do not have two pillars too close to one another, so they do not break the assumption that we made to begin with, and then so on, and the frequencies are not too high, then you get very, very good results with that. Okay, and the advantage, of course, I didn't mention that, but it almost goes without saying that you solve those auxiliary problems once. Okay, and then you apply throughout the structure. All right, and that's those are Shampi as the results. Here's the results. Now, the elephant in the flame room, not just in the flame room, in the Tref's room, and the elephant you know very well, that is the ability, well, first of all, little conditioning. And as a result of that, partly a result of that, and partly as a result of those being kind of different schemes, the convergence proofs are lacking, and I think they're very difficult. That would be very difficult, except for special cases where, say, the matrix has. Cases where, say, the matrix has some special properties, let's say diagonal dominance, and so on. So, in some sense, I will say that trust messes hoist and they want to turn. That is, well, the accuracy is so good that if you add another trust function, then it's almost a linear combination of the existing ones. And that is, well, obviously, that gives rise, as all of you know, to almost linear dependence or ill-conditioning of the basis. Of the basis. And for finite difference methods, unlike, let's say, DG, well, it's very difficult, also, as I mentioned already, to come up with convergence proofs in general. So what do you do? Well, as an engineer, I'm happy with that. So I don't have a problem with that. So rely on numerical evidence. So you run multiple examples and see if there are any problems. And if there are any problems, you try to find out what the source of those problems is. And maybe if you're lucky enough, you can fix that. And well, after a while, you kind of get. And well, after a while, you can get some level of confidence that these methods work. Okay, but at the same time, I should say that anything that is done along those lines has to be taken with a grain of salt since there are no general proofs of convergence. You have to kind of double-check the results and then do what you can to verify them. Okay, so next, my my next item, and I hope you're still awake, and I still have one more hour to go, a little bit less. So non-reflecting boundary conditions. Of course, this is a subject that's been studied for several decades, starting in the 70s, I think, probably 50 years, maybe even more. Okay, so it's very difficult to get invented. It's very difficult to get to invent something new there, but at least we can, out of curiosity, if nothing else, we can see if we can at least replicate the existing results. Yes? V-square, because we're talking about non-reflecting conditions, this is all happening in free space. Oh, yes, yes. Yes, yes, yes. Yes, yes, yes. It it it is just uh it is just free space a free space uh property of this just phase velocity waves in free space so so this of course is again as I said a well-known problem so uh you have to you have to impose uh any anything else that the Bruna is something else that's not clear okay well I do not need I do not know if I Well, I do not know if I, to this audience, I need to describe what the problem is, but just in case if you haven't come across it. So for wave problems, radiation problems, you have to impose a boundary condition on some exterior boundary of the domain. And that boundary condition has to be ideally complete non-reflective. So the waves can go out but do not get reflected back into the domain. That's the physics of the problem. The difficulty is that those conditions, of course, analytically are well known at infinity, but you do not have it. Well, known at infinity, but you do not have infinity in practice, right? You have a finite domain, and therefore, if you impose those conditions exactly, then they become non-local, and that's, of course, a problem. This becomes kind of a dirty denominator, something like that, and that is non-local. Local boundary conditions, on the other hand, are relatively easy to impose, but they're not exact. So that is a dilemma, and there have been tons and tons of publications in that area. That area. Okay, so this is somebody that I already mentioned to you. Okay, so there are several classical approaches. One is by Enquist and MIDA. They use, was their basic analysis, pseudo-differential operators. And then there is the Bayless, the Turkel asymptotic boundary conditions, and many, many more. Okay? Okay? And so I was curious where we can replicate at least part of that using Tref's ideas. And, well, extensions of really ideas of finite difference truff schemes. So what we would like to have is a set of trust functions. And that is fairly obvious. Those are different variations of outgoing waves. So we can construct different types of outgoing waves. So that is fairly clear. Of course, there's this free. Of course, there's this freedom of choice of what outgoing waves we will take. And then we need degrees of freedom. So, previously, in finite difference schemes, typically those degrees of freedom are nodal values, but in general, we're talking about any linear functionals, right? Nodal values are just an example of linear functionals. So, I call those degrees of freedom L yet to be defined, and we're looking for kind of what used to be a different scheme, but now it is this generalized. But now it is this generalized combination of degrees of freedom, and we want it to be equal to zero. And we're going to be looking for those coefficients. And not surprisingly, we can try the same formula. And again, assuming that in the space of dimension one, so this is really going to be an equality sign there. Okay, and the matrix is going to be the same as it was, or similar to what it was. It's going to be all the degrees of freedom evaluated on the basis functions. Okay, so let's see what we can get. So let's see what we can get. So I call it kind of a Tref's machine. So we plug into it the basic functions and we plug into it the degrees of freedom. And it gives us the scheme. It gives us the coefficients. I call them those coefficients S. So it gives us the boundary, synthetic boundary condition. There's an element of art in there. So not every combination will give you a good result, right? So you have to, but maybe half of them will. You have, again, apply some common sense and see what you're getting. sense and see what you're getting. So it turns out that the Bay List Turkey conditions are, well, a particular, we can call them a particular case of those Treft's conditions. When you choose outgoing either cylindrical or spherical harmonics, in this case, cylindrical harmonics have those Henkel functions there. Cylindrical harmonics has the basic functions. And then the degrees of freedom are derivatives, radial derivatives. Are derivatives, radial derivatives of the field. Zero, the derivative is the field itself, and then first and second derivatives. And if you plug it into that machine, so you construct this matrix that I call matrix N by simply evaluating those degrees of freedom on the basis functions, then take the null space of that, and you get the Bayless Terkel conditions, at least one of them. There is a hierarchy of those conditions, but you can get some of them using this approach. This approach. Okay, I'll skip that, the algebra of that. I'm not sure you get the idea. Then there is the end-quest-miner conditions, and there you use different outgoing waves. So you take a plane wave, okay, which is in xyt coordinates, looks like this, propagating at an angle to the normal, to some direction. And then you differentiate that with respect to the angle, the small angle. Okay, and obviously if you differentiate. Okay, and obviously, if you differentiate with respect to the parameter, then you still get trust functions, right? You start with the trust function, you differentiate with respect to the angle. And if you differentiate it several times, then you get multiple trust functions, as many as you wish. And they are supposed to approximate the solution next to a particular direction. Okay, and in practice, we're lucky, it turns out that really the good approximation extends to really a pretty wide range of angles, not just small range of angles. Just a small range of angles next to the normal direction. And so those are the outgoing functions, and these are the degrees of freedom. Well, it should be partial derivatives there. So some derivatives with respect to x, y, and time in this case. Okay, and there has to be some judicious choice of, well, the order of those derivatives versus the number of derivatives that they care for, the number of basis functions to get some meaningful results out of this. And it turns out that you can replicate. That you can replicate the NQ smart conditions. And then maybe I should skip the rest of it. So there are interesting games that you can play with this, what they call the Trefs machine. It is on the archive. I never got to publish the full version of it, but we did publish with Ralph Gitmeyer's group and his students. We published a shorter version of it. I'll skip the rest of it. Version of it. I'll skip the rest of it. There are some nice error plots there, mostly for artistic reasons. What matters is really the rate of convergence, and it is, as expected, pretty, it is consistent with what you would expect. And this is an example that Ralph's students did, and this is the shorter version that we published in AAA Transactions in 2016, where we have a test example of five scattering cylinders, elliptic cylinders. Cylinders, elliptic cylinders, and there is software out there that does this type of problem up to Roundoff. And so we compare that with the finite difference threft results, and we got the very good agreement. And what matters is not, in this case, not just finite difference threfts, but also the outgoing non-reflecting boundary conditions, some of the versions that I highlighted in the previous slide. So, this is a summary of. So, this is a summary of the different combinations that I examined. Of course, I don't want to go over all of them. You can find it on the archive, or we can talk about that later if anybody is interested in this. Okay, so let me move on to part number two, and that is physical mysteries. And I really mean the word mysteries, I really mean seriously. Seriously. Okay, and I will explain why what those mysteries are and why they're really difficult to understand, at least at first glance, and maybe at second glance as well. So the first one, the first physical mystery that I'm going to be talking about is non-magnetic magnets. So you take non-magnetic materials, put put them together and you get magnetic properties out of that. You take silicon oxide and you shape it in a particular way and they get all of a sudden magnetic properties. Magnetic properties. And another mystery, which is even deeper, I think, is what is known as topologically protected boundary modes. So, in the balance of the time, I would like to at least give you some idea what those things are and what the explanation of those mysteries might be. And my hope is that some of you might be really interested in that, maybe as mystified as I am. And there is lots of work to be done, I think, in those areas by good mathematicians like Olaf. Mathematicians like all of you. Okay, so first, I'm going to be talking about electromagnetic metamaterials and their magnetic properties. And we're talking about homogenization, that is representing some microstructure with some equivalent effective parameters on the macro scale. So going from the micro to macro scale. Okay, so this quick, quick introduction for those of you who haven't maybe living, either living. haven't maybe living either living in cave or just focusing on your phd work and haven't heard about about metamaterials uh so there was um a great deal of interest still is i think but the peak was in the early 2000s because of the discovery of negative refraction where the wave refracts in the opposite way to what it normally does and this was done by um the um by the smith group in the year 2000 an experimental demonstration this is an artist rendition This is an artist's tradition of what a straw would look like if it were to be put in the glass of some fictitious negative refracting fluid. Okay, so the idea is that you can construct periodic structures, and this is a prototypical example of that. I don't want to get into what it exactly is, and those of you who know that, you don't need an explanation. Those of you who don't, maybe you don't need an explanation either. Okay, but but the idea is that oops you can you can by constructing periodic structures like that you can shape the wave propagation you can control the propagation of waves by some judicial design and by engineering those structures so that can achieve effects that are not accessible in nature. One example, one example of course is negative refraction that I already mentioned. Of course, is negative refraction that I already mentioned. Another one is cloaking. Again, it became very popular in about the year 2005-6 for like another five, six years. It was very, very popular. Actually, there are some serious mathematical issues there. But as far as applications, I think it also, to my knowledge, it kind of also fizzled, unfortunately, after getting a few hundred million dollars invested into that. So if you have, let's say, a shell, maybe I shouldn't be talking about that. To be talking about that. Anyone who is curious about that can look it up. Either in the popular literature, you can talk to me. I think I need to save time for something that is maybe more, a little bit deeper than this. Okay, the intuitive explanation for those magnetic effects that arise is that all of those structures have some resonating elements. The typical one is a split ring. So it's a metallic ring with the gap in it. So those of you The gap in it. So, those of you who know a little bit of electromagnetic analysis, they will realize that this acts as a capacitor and an inductor. So, the spring behaves as an inductor. The currents can be induced in it, and the gap acts as a capacitance, little capacitance. And so, a naive point of view is that there is an L C circuit there that can resonate. And at the resonance, the currents can be pretty high, and the currents give rise to magnetic effects. So, that is in a nutshell. Effects. So that is in a nutshell for kind of electrical engineers or physicists. That is an intuitive explanation of what is going on and why magnetic effects can be, can appear, even though each of the constituents, each of those materials is itself non-magnetic. But that, of course, is an intuitive way. It's not very rigorous. So what can you do in a more rigorous fashion? I would like to go back for those of you who do not know, or for those of you who have taken your physics courses. For those of you who have taken your physics courses a long time ago, I should mention the predecessors, a number of geniuses who developed very kind of accurate homogenization theories in the 19th century. Okay, so very quickly, so there is the Clausius-Masati model, and then there is the Lorentz model. There are two Lorentzes, as probably most of you know. One is with the T, the other one is without the T. It's without the T. The famous Lorenz gauge is without the T, actually. Okay, and so they developed surprisingly very accurate homogenization models for systems containing particles, containing mixtures of different materials, using for what we would today, at least I recognize that as a hand-waving argument, even to my taste, I think it's too hand-wavy. But nevertheless, they did get very accurate results that are actually hard to. That are actually hard to beat, even using more sophisticated methods. How did they manage to do that? That is Maxwell-Garnett, the Maxwell-Garnett model. This is actually one person, in case you wondered. Hey, named after Maxwell, after the Maxwell, because his parents were quite fond of Maxwell, of them Maxwell, and he named their son Maxwell after Maxwell. Okay, so there is this little. Okay, so there is this also famous Maxwell-Garnett expression for equivalent properties, effective parameters of the mixtures of materials. All right, and so I also mentioned Erica Fermi, even though as far as I know, he didn't work in homogenization, but I would like to mention his name in connection with a story that I heard, and it's probably apocryphal, but it's a good story, so why not tell it? Casey was he was apparently He was apparently swimming in the liquid in the sea with his assistant, and the assistant approached him and said, Dr. Fermi, you are a genius physicist. So you managed to solve problems that nobody else was able to solve. I think Swimming there. How did you manage to do that? And Fermi apparently says, well, you've got to simplify the model to the point where you can solve it. I think we had this discussion with somebody over lunch. With somebody over lunch a few days ago, right? You have to find the right model, you have to simplify it. I think Lego, right? Simplify it, but then he thinks about it a little bit more and says, but you must not oversimplify the problem, because then you kind of throw the baby with the bathwater. Then, of course, the assistant asks, you know, how do you know how to simplify the problem, but not oversimplify the problem? And then probably firmly says, well, for that, you need to be a genius physicist as I am. Okay, so this. Okay, so these guys that I mentioned before in the 19th century, they were able to really find a good model. Okay, and there I have another quote here from another expert in the field. A good model can advance fashion by 10 years. So good models are important. Okay, I think I'm at the risk of running out of time. What I would like to mention in connection with the homogenization problem for meta-feminaterials is For metamaterials, is that boundary effects are extremely important, actually critical. And one of the reasons for it is this. If you look at one of Maxwell's equations, the curl-H equation, if I assume that, for the argument's sake, that the B and E fields are fundamental, and the H and D fields are, well, instance, auxiliary fields. And we fix the B and D fields because they're. The B and D fields because they're responsible for electric and magnetic forces. We notice that this equation is, of course, is invariant with respect to rescaling by any factor. So what that means is that if you rescale H and D simultaneously, this equation remains the same, but then you're changing, by doing that, by rescaling this, you're changing the electric and magnetic parameters so that it's easy to see that, well, epsilon times mu is. times mu is uniquely defined, it does not depend on that rescaling, it remains invariant, whereas the ratio mu over epsilon changes and the parameters themselves therefore must change. And what that implies, among other things that I don't have time to talk about, is that if you really look only in the bulk, you assume an infinite medium, because this equation is invariant with respect to rescaling, you With respect to rescaling, you cannot, as a matter of principle, determine the electromagnetic parameters uniquely. The best you can do is determine the product, which really characterizes the phase velocity of the wave. And the ratio of mu over epsilon in the electrical engineering or physics jargon is called impedance. And so you cannot determine the impedance, and nor can you determine those parameters separately. Okay, and so the mystery that So the mystery that is associated with that is what I call the insanity pitfall. So suppose that to start with the fine scale fields, the fields that vary on the microstructure scale. And I'm talking about magnetic fields, and there's an H field and the B field. Well, some people will say, who read a lot of, let's say, Landau Lirch's books and other books, they say there's no such thing as the H field. But there are good reasons to have the Reasons to have the four-field model, so have H, P, E, and D, okay, as opposed to just three fields without the H. So I'm working through from that four-field model. There are certain differential geometric reasons for doing that, et cetera. Okay, so on the final scale, you've got H equals to B. I'm saying I'm assuming that mu naught is equal to normalized to one. And then you average whatever procedure you use. You average whatever procedure you use, you average, you start with well, two equal things. No matter how you average them, you get the same result on the core scale, but somehow you're supposed to get different results. And well, according to a quote attributed to Einstein, if you do the same thing twice and get different results, that's the definition of insanity. When I googled that quote, by the way, it turned out that it's not Einstein's, but that's really believe it or not, and I kid you not, it's narcotics anonymous. They have that in their brain. Anonymous, they have that in their brochure. I don't know why they have it, but that's the source. And by the way, just as a side note, the other phrase attributed or statement attributed to Einstein, his biggest blunder, everybody knows that, right? Turns out that apparently he didn't say that ever. There's a big article in the Atlantic that you can quote it here that kind of digs into that. And apparently, by interviewing different people and looking at into kind of And looking at more closely into Einstein's letters and publication and all that, there's no evidence that he ever said it, but his biggest blunder. Anyway. So why does the boundary matter? Well, because of the boundary conditions. Okay, so in free space, if there's a boundary, let's say between some fancy material and free space, in free space, of course, we assume. Space in free space, of course, we assume that B is equal to H. Well, apart from maybe μ naught is there. Okay, and that fixes this relationship, or fixes the impedance, if you will, at the boundary. And so you can no longer arbitrarily rescale the D and H fields simultaneously. The Maxwell equation remains invariant, but not the boundary condition. Well, of course, you can rescale the fields across the whole space, right? But that would be very, very silly to do in free space. Okay, so in other words, Okay, so in other words, free space and our assumption that B is equal to H and free space fixes in some sense the boundary condition, fixes the scaling. That is the intuition behind that. So what we did is, let me skip some of the slides here in the interest of time. So what we did is first we need to give a, at least at the physical level of accuracy, we need to give a definition of what effective parameters are. And surprisingly in the physics literature, there's no such definition. Physics literature, there's no such definition. Oftentimes, they just simply write down a particular procedure without defining what those effective parameters are to begin with. And so our definition is this. Suppose that you've got a periodic structure, a slab of periodic structure. For simplicity, just an infinite slab, semi-infinite slab in two dimensions and finite thickness. And you want to replace it with some homogeneous slab with. Homogeneous lab with an effective tensor, μ script m, in such a way that the reflection and transmission coefficients through those slabs are as close as possible. I will borrow the expression from Andrea Maiola's presentation, In Your Favorite Norm. Okay, so you interrogate the structure with certain, let's say, plane waves at different angles, and you look at the reflection and transmission coefficients, and you want to replicate. And transmission coefficients, and you want to replicate that as accurately as possible with a homogeneous structure. And then this tensor M is going to be, by definition, by our definition, the equivalent tensor or the effective tensor. And of course, in principle, that is a non-linear inverse problem. So it can be solved using fancy optimization techniques. But then you kind of lose the physics of it and you lose the insight into what is really going on. So, and also, of course, it is numerically, computationally, very costly. Numerically, computationally, very costly to do that. So, we decided to look at it in a different way. So, we used what I call now Treft's homogenization. So, on the fine scale, we've got block waves. And remember, going back a couple of dozen slides, we talked about block waves, eigenmodes in periodic structures. So, we're looking at the size here, the trust functions there, block waves going in different directions. So, in practice, So, in practice, that is a finite set. And it's in principle very, very similar to what is done in, let's say, DG drafts or some other methods using plane wave decomposition, except that instead of plane waves, we've got block modes in periodic structures. Whereas in the homogenized one, we have generalized plane waves. There is no periodicity anymore, so those are really capital size. They correspond to the homogenized structure, and these are plane. Noise structure, and these are plane waves. Okay, and so what we want is two things. We want to, as accurately as possible, represent the boundary conditions. That's number one. And number two, we would like to represent the dispersion relations in the bulk inside the material. The Maxwell equations, if you will, in the bulk. And both are equally important. So boundary conditions and Maxwell's equations in the bulk. So to represent the boundary conditions, The boundary conditions, let me skip that and get to the final result. So we have a bunch of modes, and they put it into a matrix. So there's mode one, mode two, mode n, which are block modes going in different directions. Okay, let's say in two dimensions, that would be, let's say, eight, as an example, eight directions at 45 degree angles. Okay, and with And we find their tangential components on the boundary, because that's what determines tangential components of the E field and the H field, because that is what Maxwell's boundary conditions are all about. Okay, and so that fixes the, I'm sorry, we should look at this matrix first, that fixes the components of the E and H fields for For the block modes. Okay, and then so that takes care of the boundary conditions. Then we apply Maxwell's equations to them, the curl equations, and then from the E and H components, we can find the D and B components for the same modes. So again, the E and H components are determined from the boundary conditions, whereas the B and D components are determined from applying Maxwell's equations to those waves. To those waves. And as a result of that, you've got an optimization problem, at least worse problem, with this matrix on the left-hand side, and that makes it in the right-hand side. And in between them, this is the tensor that we would like to find. Yes, go ahead. Right, right, right, right. Right, so the tangential components of the end edge fields will be determined from the boundary conditions from matching the respective block modes. Okay, I'm unfortunately quite short of time, so I just want to kind of highlight those. To kind of highlight those kind of main things, and if anybody has any interest in this, we can discuss this at length. Okay, so then you find kind of the optimal tensor using leg squares approximation. So we've got several papers, of course, where the technical details of that described in the Royal Society proceedings and in the physics letters and physical review. This I will have to skip because you can also. This I will have to skip because you can also extend it in a locality. And I will skip also the results because those are very nice curves that always match what you expect to find. No matter what you do, you always get good results sometimes. One couple of things that are not intuitive that I'd like to mention on the physics side. So, homogenization of spatial symmetry breaking, that is fairly recent work with Yu Dong Chong. Diudong Cheong and my graduate student, Sharia Hussain. So, the essence of that problem is this: if you have a structure that lacks symmetry, so let's say you've got two layers per cell, okay, parallelitis cell. So, those two colors represent two different material layers per cell. That's just a layer structure. And then there is, and then if the incident wave comes from the left in this case, so it comes. From the left, in this case, so it comes on one of those layers versus the incident wave coming from the other end. Most things are the same, but the angle of the reflection coefficient is different. Okay, and those are the plots. So this is the phase of the angle of the reflection coefficient from one side and from the other. And you might think that this effect cannot be replicated in a homogenized structure because the homogenized structure is by definition. The homogenous structure is by definition homogeneous, right? So it doesn't have this asymmetry. But it turns out when I applied our method, it takes care of that. And the way this lack of symmetry is represented ultimately is by an effective tensor that has those off-diagonal terms. So this effective tensor represents to the first line, the first row, represents to the one component electrical field. Component electrical field, and the rest of it corresponds to the electromagnetic coupling. I have to leave it at that and again leave the details for any future discussion. So that's one interesting, one interesting example where kind of our method gives a result that may not even have been expected, because you would have thought that if there's a lack of geometrical symmetry once you commogenize the structure, there's no way you can represent that lack of symmetry. On that, that lack of symmetry. Okay, and that okay, so let me go to the most mysterious of all the mysteries that I've encountered in my kind of research career. That's the mysteries of block bands and what is known in the literature as the bulk page correspondence. I can only scratch the surface. We started a little bit. Well, wait a second. So wait a second. No, we still have time. I think I, yeah, we still have time. So, well, that's good. So, we have more time than I thought. Well, I have more time. I don't know if you have more time. But I hope that you're still, some of you are still awake. And if you're still awake, maybe you'll be interested in this. Okay, so let me, yeah, so it turns out that I have enough time to talk about that, but maybe even leave some time for discussion and getting back. Some time for discussion and getting back to some of the things that I had to skip. Okay, so here's the problem. Suppose, and I'm starting with one dimension. Although the most interesting case actually is in two dimensions, not in the one and not in three. Well, in three, also interesting, but actually the most interesting is in two dimensions. But I will start with one. So suppose that you have two periodic structures. Okay, I'm not specifying their parameters and what they are, but they have a common name. But they may have a common interface. And then, under certain conditions about which we're going to be talking, they may exist in interface mode, in evanescent interface mode, evanescent in both directions. Okay, and so the question is, under what conditions does this mode exist? Does it exist or does it not? Okay, and then there's one straightforward way to find out. You just write down the boundary value problem. Well, it may not be completely. Well, it may not be completely trivial because this is a periodic structure, so conditions with affinity are not so easy to write down. But suppose you do that, and of course, the interface conditions are very, very well known. Those are Maxwell's boundary conditions. So you write down this problem and you see whether or not it has a nigga mode, right? With the real frequency as opposed to some complex frequency or some okay, and so that is one way of doing that. One way of doing that, kind of a direct way of doing that. But the mystery comes from a different direction. It turns out that there is a very, very different way of looking at this. And to understand what that way is, we need to go back to block diagrams. So let me remind you what they are. So there is the block, let me start with again with the definition of a block eigenmode, the block function. So it has a periodic factor and it has then a plane wave. And it has then a plane wave factor. And again, just to repeat what I said before, since that was about an hour ago, you can interpret that as a plane wave with, in the simplest case, if the periodic factor is equal to one, that would be in a homogeneous medium, then that would be just a plane wave. So you can view this as a generalization of a plane wave for a periodic structure. Or you can view this. Or you can view this as a periodic solution that gets shifted by a particular phase, assuming that the Q block parameter block parameter Q is real, then it is just this exponential effect is just a phase shift from one cell to another as the wave propagates. And of course, if Q is imaginary, then it is an evanescent block wave. Okay, and then there's a typical block diagram that I represented from one. From one of the simulations for particular parameters which do not really matter. This is just some dielectrics, layered dielectric structure in both of those media. One of those media, I should say. Yes, yes. Oh, no, no, no, not at all. Well, because I'm focusing on one material and the other one is yes, yes, yes, I'm focusing on good questions. So I should have said that. I should have said many other things, but which I forgot. My advice to kind of graduate students here, do not get old. Then you will mention everything you need to mention. All right, so here, so this is again. So, here, so this is again, for those of you who know this and counted that in your physics courses or in your research, this doesn't need any explanation. But for those of you who are seeing it for the first time, so this is the block, this is the block number. Okay, and because it's one-dimensional, so Q is, even though I showed it in bold, in general, it's a vector, but in one dimension, of course, it is just a scalar parameter, and so I'm showing this on this axis. One thing that I didn't mention before, and that is absolutely needs to be mentioned, and should have been mentioned before. And should have been mentioned before is that because of this complex exponential factor, Q is defined modular 2. Well, if the unit cell size is 1, then modulate 2 pi. Okay, so therefore, it makes sense to restrict the Q to what is known as the first brilliant zone. And well, if you normalize that by pi and also by the cell size, I call the cell size A, so then it would go from minus one to one, but in this case, it is symmetric, so I just truncated the. This symmetric, so I just truncated the first Brilliant zone from zero to one. So that is the range of variation of Q. Okay, and so that's the horizontal axis. The vertical axis is frequency normalized in any convenient way. Okay, so again, the important features of that, what is known as the block diagram, is that there are bands where waves can propagate, so where Q is real. And then there are gaps. This is one example of gap. Then there's a very narrow gap there, and there's another gap. Narrow gap there, and there's another gap, and so on. So, there's a sequence of gaps in the sequence of bands as you go to high and high frequencies. Okay, and so, well, first of all, we notice, and that's obvious, that this phenomenon can only exist in a gap, not just in a single gap, but in a common gap. If there is an overlap between the gaps in the first medium, and that goes to the question that Bruno asked, and the second one, if there is a common frequency for which. If there is a common frequency for which waves cannot propagate, or only evanescent waves can exist in both structures, then that is certainly a necessary condition, but not a sufficient one. But not a sufficient one. Okay, so that's the kind of preamble. That's the basics, what the block diagram is. And then suppose that we're interested in whether or not this wave exists in a particular gap. Exists in a particular gap. I did not mention why that is maybe, why that may have important applications. So those modes, those boundary modes, they can be used for information transfer. At least that's the idea. Certainly not in the one-dimensional case, but in two-dimensional case, if there's a common boundary, and I will get to that. And then the wave, if it exists at the surface, at an interface, it can propagate along that boundary. Can propagate along that boundary, and that propagation can be robust. Okay, that is the idea. In other applications, you can create those robust surface modes, boundary modes in a cavity, and that is, well, people have explored so-called topological lasers. Where I don't have pictures of that, but if you can create those modes in In the boundary that encloses the cavity, then that may give rise to topological lasers. Why topological that? That's what I'm going to explain next, what is topological about that. So suppose that you're interested in whether or not such a mode, such an evanescent mode, exists in a particular gap. Let's say, let's take this gap, that's on top here. This is little gap here. Gap here. Okay, and suppose that the necessary condition is satisfied. So there is an overlap, at least a partial overlap, between the gap of one material and the other one, which I'm not showing, but has a similar structure. It may, of course, have different parameters and different gaps, but for one reason or other, let's suppose that we're lucky enough and the gaps overlap. And so there is a frequency there where this, such a mode, such an interface mode, could exist. Such an interface mode could exist. Okay, and of course, the keyword is could. So whether it does exist or not, that's the next question. And then, well, it turns out that to each of those bands, you can put at the correspondence at the popological invariant. I didn't write it down because the expressions are difficult to explain in a short interval of time. In the short interval of time. So that's something again that we can talk about to anybody who is interested. Let's just take it for granted that there is some way of associating any particular band with a discrete, discrete number. Okay, and moreover, this discrete number, it is just binary, 0, 0, 1. Under certain conditions, actually, under certain conditions, there is a way to associate each of the bands. As a way to associate each of the bands with this invariant that is either 0 or 1. I will say a little bit more about that, what the physical meaning of that invariant is. There is an integral formula for it that I didn't write down because, again, it will take some time to explain it. Okay, and then so this band, let's say, has zero, and this band has one, and this band has one, and this band has zero, et cetera. So we've got a bunch of zeros and ones. Etc. So we've got a bunch of zeros and ones corresponding to each of those bands below the gap. So the frequency is lower than the frequency of interest to us. And then we sum up all of those zeros and ones in binary arithmetic. Okay? And we do it for both materials, for the first one, for the second one. And if we get the same result, then the mode does not exist. If we get different results, then the mode does exist. Okay, and to appreciate why this is so mysterious and why I do call it a mystery is that we're talking about modes existing at a very high local, very high, maybe some high frequency here. And so the field kind of varies very, very rapidly. And somehow the existence of this interface mode at this very high frequency, let's just exaggerate and say we're looking at an optical frequency in 10 to the power of 14 hertz. In 10 to the power of 14 hertz, right? And we're asking whether or not the mode exists at 10 to the power of 14 hertz. Okay? And to determine whether or not that's the case, we're looking at the behavior of all the other modes below that frequency, including zero frequency. We're looking at modes with one hertz and two hertz and three hertz and ten hertz and one thousand hertz all the way up to ten to the power fourteen. And of course, those low frequency modes have a completely different behavior, nothing related. Completely different behavior, nothing related to what we have at the very high frequency. So the mystery is: how is that? So, how Dr. Watson put it, how on earth is that possible? And so, I could not figure that out for a long time. Okay, and so there is another yes, yes, yes. Okay. Oh, yes, in this case, there's just one. In two dimensions, there may be multiple. Maybe I should just elaborate on that and just to mention some terminology. So, in one dimension, this invariant that I mentioned, and I didn't give you the explicit formula for it, but I will talk a little bit more about. Formula for it, but I will talk a little bit more about it. It's called the Zach phase, ZAK. Zach was a physicist who published this now famous paper in 1982, I think, 1981, on that. And now it's called the Zach phase. In two dimensions, the respective invariant is something that many of you certainly not just heard of, but maybe passed your exams when you took your topology courses, algebraic topology, and so on. That's called the churn number. That's called the churn number in two dimensions. And then, if you have two structures, I'm going a little bit ahead, kind of answering Bruno's question. So, if you have two structures and they're two-dimensional in the same situation, asking the question whether or not the mode exists. So, if they have, well, the same churn number, then the mode does not exist. If they have different churn numbers, then there is one or more modes, and the number of modes is the difference of the churn numbers. And so in this case, because Zach phase can be the 0, 1, with the particular normalization by pi, Zach calls it 0, pi, but if you divide it by pi, 0, 1, there's only one possibility. Well, actually, two possibilities. Either it exists or it doesn't. There is another part of that. And that is the circle argument that I mentioned to you in the beginning in the preamble to my talk. And that is the circle argument. And that is that the circle argument that is you find in the physics literature and I could not get the straight answer from any of the physicists that I know of how to break that argument. And it is this. This block diagram is valid for infinite structures when full translation variants, when block waves propagate in the bulk. This structure, this band diagram knows nothing about. This band diagram knows nothing about boundaries. Okay. And so, and yet, somehow by analyzing this diagram, you're supposed to deduce what happens at the boundary. Okay, so in other words, you ignore the boundary to begin with, because block diagrams do ignore the boundaries. Ignore boundaries to begin with and draw conclusions about boundaries in the end. Draw conclusions about boundaries in the end. So that is a circle argument that I mentioned. And it is in one dimension explainable for the same reason that I talked about in the part on finite difference drafts, because the solution space is finite-dimensional, two-dimensional. As a matter of fact, there are two waves going back and forth. And therefore, once you know those two solutions, you know everything. You know everything. So it doesn't matter whether it's a bulk or boundary. So in one dimension, this kind of circle argument really can be broken fairly easily because bulk and boundary are not really potentially different. But in multiple dimensions, there is a significant principal difference. So the solution space is infinite dimensional, and what happens at the boundary is not necessarily the same as what happens in the bulk. And I just illustrated that with that. And I just illustrated that with that yolk shell example. So if you know what happens inside an egg, you do not necessarily know what happens on the shell. Okay, that's kind of an extreme and certainly maybe an extravagant example, but it kind of illustrates the point that I'm making. And so that is the mystery that I do not know an answer to right now. I have some guesses, and my best guess is that. My best guess is that apparently the main kind of assertion, the main statement does not really hold. Or at least there are some exceptions to that and some counterexamples. But I have not been able to find any counterexamples. But my best guess is that it probably doesn't hold always. It's not kind of a mathematical theorem. The one that I just mentioned, that those topological invariants of the block bands really determine what happens at the boundary. There's something more complicated that might go on at the boundary. But I might be wrong. Boundary, but I might be wrong. All right. And then so I already mentioned to you of the biggest mystery, and I only mentioned part of it, actually one half of it, that, well, the high frequency behavior somehow is related to the behavior at all lower frequencies, including even zero frequency. But the other part of that mystery is that in the gap, we're looking for those evanescent modes that decay. Looking for those evanescent modes that decay away from the boundary. Whereas the topological invariants of that I mentioned to you, the Zach phase of the Schur number, are related to the band. So we are analyzing those evanescent modes in terms of propagating modes at lower frequencies. So that's double the mystery. All right, so in one dimension, we do have a full analysis now and the answers to those questions. Okay, so this is a setup, and that's a standard setup. So we got the periodic structure with epsilon and mu in general. The electric and magnetic property is periodic with respect to the coordinate x. One important thing that I didn't mention before, but without it, things do not hold. So this is the periodicity. But another thing that I didn't mention before, but it is important, is the symmetry of the cell. Is the symmetry of the cell. Okay, so A is the cell size, so epsilon of A minus X equals epsilon of X, and the same for the same for mu. So assume that the cell has mirror symmetry. And then there are block boundary conditions. So at the bottom here. So that is the phase shift that I mentioned to you before. So if we look at the field at one side of the cell, at one boundary of the cell, At one boundary of the cell at point A, it's related to the value of the field at point zero via this exponential phase factor that contains the block parameter. Okay, so if the block parameter is zero, and in physics this is known, or in crystallography, even this is known as the gamma point, when q is zero, then it's a particular case where the solution is just periodic. If q is not zero, then well, there's a phase shift between the values. If q is real, there is a phase shift between the value. Q is real, there is a fatio between the values on the two sides of the cell. If q is imaginary, of course, then there is an evanescent behavior of the field. Okay, so that's just a one-dimensional problem. And there is only this dependence on the normal. Well, I call it normal, it's kind of normal to the interface boundary, it's just one dimension. Then, important are the definitions of block impedance and admittance. They're kind of reciprocals to one another. They're kind of reciprocals to one another, so we divide the electrical field by the magnetic field, and it's almost equivalent, not completely, but up to a factor to just dividing the field by its derivative, because while they're curl equations, curl-maxwell equations in one dimension, they become just derivative equations. So the magnetic field up to a factor is just the derivative of the electrical field and vice versa. Okay, so instead of those electromagnetic impedances, we can just look at, let's say, the E-field divided by its impedance. Let's say the E field divided by its derivative with respect to X. Okay, especially important are the boundary values. The impedance at zero is equal to the impedance of A just because of this block periodicity. And particular cases where one of the fields is zero, and the appendix either has a null or a pole, depending on which of the fields is zero, what you're dividing by what. Fields is zero, what you're dividing by what. Okay, so those poles and zeros and nulls of the boundary values, well, the gamma point is the physics term for periodicity, so Q is equal to zero. The X point is the physicist's term for antiperiodicity, so Q is equal to pi. So then we have anti-periodic conditions on the two sides of the cell. Okay, so that is what I call mathematical impedance if we just divide the E field by its derivative, maybe multiplied by the material parameter. Okay, and so that is the behavior, that's the numerically calculated behavior of impedance as a function of frequency. So on the horizontal axis, we've got the frequency, normalized frequency in some way, natural. In some way, natural normalization, of course, is the wave number. That's not the block wave number, that is the actual wave number in free space. So that's really the frequency multiplied by the cell size, so that becomes dimensionless. And on the vertical axis, we have the real and imaginary parts. I can plot the mathematical impedance, I can plot the electromagnetic impedance, it almost does not matter. But what we know, well, and then the green lines represent correspond to bands, so waves can propagate, so kind of green light for the waves. Propagates a kind of green light for the waves. And this was supposed to be red, it's not, didn't come out quite as red. But the red parts, quasi, if I borrow the term, quasi-red parts, represent stop bands, so band gaps, where only vanescent waves can propagate. And so what we notice is that, well, within the bands, the green lines, well, some of them are monotonic, but let's say this one isn't. But let's say this one isn't. Whereas the red ones are all monotonic. Okay, and that's not an accident that can be proved, and I will not go through the proof, but it can be proved that indeed, in the gaps, the impedance decreases monotonically with frequency. And that will play an important role in the analysis. That will explain part of the mystery, at least in one dimension. Okay, and then another important Okay, and then another important fact is maybe I'll see how much time is left, if any, I will explain why that is. But at those gamma and x points, when I have periodic and anti-periodic conditions, there are only two possibilities. Either the mode is symmetric or it is anti-symmetric. So that means that the impedance either has a pole or it has a zero. Okay, and if I go back one slide and look at the If we go back one slide and look at this plot, that is what indeed we observe when we look at those red lines, right? So each of them, some of them start, some of them start with a null or zero and go to a pole. Again, there is a monotonic decrease. So that's one possibility of behavior, another possibility of behavior going from a pole at plus infinity to a null. Okay, and because of monotonicity, there are only two possibilities. And also because of the fact that it has to go from a pole to... Go from a pool from a pole to a zero, then only two types of behavior. Okay, and so I decided for the fun of it to introduce this terminology borrowed from semiconductor, even though it has nothing to do with semiconductors. And the reviewers pointed this out and had to explain, well, no, it is just borrowing the terminology and not the essence of it. So if a gap starts with the pole and goes to... Then and goes to null, as far as the impedance is concerned, we call it the p-type gap. And if the opposite, if the gap starts with the null and goes to a pole, we call it the n-type. And here comes the most critical part. In order for Maxwell's boundary condition, interface boundary condition to be satisfied, we have to have this condition. So the sum of impedances has to be equal to zero. So that's this impedance match at the boundary. So that's this impedance match at the boundary. Okay, and well, the reason why we have a plus sign as well as a minus sign is because the normal directions point opposite ways on the boundary. So that's what we've got to have. And so that then is a key to explaining part of the mystery. Because now, if we see that on one side of the interface, the impedance goes from, let's say, from a pole to a zero, so that is from plus infinity to zero, and on the other side, it goes from zero. And on the other side, it goes from zero to the minus infinity. By continuity, there's got to be a point in the overlap between those two frequencies, between those two gaps, where this condition has to be satisfied. Okay, so that is the critical, that's the critical observation. And those of you who are still awake, I wonder maybe I should pause for a few seconds and see if that makes sense. So, in one material, you have this type of behavior in a particular Behavior in a particular gap, so the impedance goes down this way. And another material in the same gap will have the opposite type of behavior. So then at some point, the impedance will have to be opposite and equal. Okay? Before I go to uh some practical advice what you can do with your bank account, uh Do with your bank account. Let me then summarize what I just explained. And that is, the mode will exist if and only if the gaps on the two sides of the synchrophase are of different type. Okay, so one is in my terminology p-type and the other one is an n-type. So one impedance starts with the pole and the other one starts with the null. Well, that still does. Well, that still does not explain how all of that is related to those Zach phase and topological invariance of the bands. Okay, so now when we're armed with this knowledge, we can go back to the band diagram and see what is actually going on. So, suppose that again we're interested in this particular gap. Okay? And we need to figure out the critical. Need to figure out the critical thing, as we just discussed, is to figure out whether what type of the gap that is, whether that's a PM gap. So, in this case, let's say P is green in my here. So, this over here, we've got the pole of impedance, and at the top, we've got a new of the impedance. So, this particular gap in my terminology is an NP gap. I'm sorry, it's an N gap because it starts with, I'm sorry, it starts with the pole. So, it is a P gap. Starts with the pole, so it is a p gap. Whereas this gap starts with a new at the bottom of this black dot, so that is an m gap, and this is also an m gap, and this is a p gap, and so on. Okay, so for each of the materials, well, we need to figure out what gap, what kind of gap it is, and if they are opposite types, then there will be an interface mode. If they are of the same type, they will not be an interface mode. Okay, so how can we find that out? Well, as Well, as I already kind of mentioned in the beginning, we just can calculate those modes directly, look at the particular frequency and see, kind of look at that mode, plot it, figure out what type of mode it is. Okay, but the fancy way of looking at it is to go down the frequency lane and see what happens with the impedance. And one important property that I did not yet mention, but it plays a key role, is that across any gap. Role is that across any gap, the I actually did mention that, but across any gap, the impedance always changes from a pole to zero, vice versa. Okay, so that means in my scheme that any gap has opposite colors at its end points. Okay, so as we go down the frequency lane from this point and we trace the bands and the gaps. We trace the bands and the gaps, so we go over this whole block diagram. And we track down the change of impedance along that block diagram. So we know that as we cross any gap, the impedance, the type of impedance always changes from a null to a pole or vice versa. Okay? And then, but what happens across the band? So if we go from here to there, So, if we go from here to there, that's emphasized that's kind of a virtual procedure. So, this is not that physically happens, this is a mathematical procedure. So, we go down the frequency lane and see and trace those bands and gaps and see what happens with the impedance. And as we cross any gap, the type of impedance changes from zero to a pole or from pole to zero. So, that's fixed. What happens in the band, how impedance changes across the How impressed changes across the band is not fixed. So it can either, in this case, it goes from green to black. Okay, in this case, it goes from black to green, but in this case, it goes from black again to black. So the type of impedance may change or may not change. How do we know? And the answer is the Zach phase. So it turns out that Zach phase tells us whether or not impedance changes from a pole to zero or not across a band. So if we summarize the whole process, then whether or not we go down. The whole process, and we assume that we go down the frequency line again. As we cross any gap, the impedance always changes. As we go across the band, it may or may not change depending on the ZAC phase. Okay, so therefore, what happens in the gap can be deduced from by tracking down this whole thing and summing up all of those changes, looking how many of those changes have occurred in that virtual process. I hope that at least the gist of it is clear. Okay, and that is. Okay, and that is that is the bank analogy that I make on my one of my last slides. And after that, if we have time remaining, then I will be happy to answer any questions. I'll be even happier if somebody is interested in any of the things that I, any of the topics that I raised. So here's my analogy that I give in connection with that. So, and that's kind of if you want to know your account balance, well, one way. Balance. Well, one way is just to look it up. You go online, you call up your bank, and you say, Well, it's my account balance, and you will find out easily. But another way of doing the same thing is to sum up all the contributions over, well, all the deposits or withdrawals that you've made over the history of the account. Right, and that's exactly what we're doing here. So if you want to know what happens in this gap in terms of the character of the mode, the character of this impedance, we can just calculate the mode. Can just calculate the mode. Okay, so that will be analogous to looking up your balance. Or you can do it the hard way. Well, I'm not sure which is harder, but no, I am sure which is harder. So tracking it down and calculating the whole thing is harder than calculating just a single frequency. And yet, if you sum up all the changes, all the kind of contributions over, well, all those frequencies below a given one. Is below a given one, then you get the same result. Okay, so if you sum up all the contributions to the bank account, you get the same result as your account balance. Okay, so that's so in one dimension, I think the mystery is by and large solved. There's still some minor, I guess, issues related to that, but by and large, I think it has become clear why the behavior of modes at high frequency in the gap and evanescent modes for that matter is related to the behavior. Modes for that matter is related to the behavior of propagating modes at low frequencies. I did not mention maybe one important thing. Why is it called topological? And that is because if you imagine any continuous deformation, any continuous change of parameters, that does not affect the band, doesn't close any gaps in the process. So the band structure remains kind of topological equivalent to itself. So no gaps close. So, no gaps close and no bands get broken, then this analysis and the results fold. Okay, so it's invariant with respect to continuous changes, let's say, in material or geometric parameters. Okay, that's why it is topology. So, what about generalizing that? So, what I've been able to do so far, kind of maybe 80-90% complete now is. To 90% complete now is what I call 1.5D analysis. And so that is the same kind of one-dimensional problem, but now waves can propagate, and that's the most interesting case in practice, they can propagate an angle. Case of the fields, at least one of the fields has two components. Okay, those are kind of S and P modes in physics. So one of the fields can one component perpendicular just to the plane, and the other field has two components in the plane. So the fields can, one of the fields at least can two components, but the problem still reduces to the one-dimensional, one-dimensional problem. So it's kind of physically two-dimensional, but mathematically one-dimensional. And then you have another parameter, which is the wave number in this tangential direction along the boundary. Okay, so that's a little bit more complicated, but I've been able to repeat that analysis, and I'm getting so there's a different. So, the difference is that we can have now traveling waves as opposed to just a standing wave in the previous setup. So, now there is a component of the wave number that is along the boundary, so the wave can now travel while also being evanescent in the perpendicular, in the normal direction. And I also include the frequency-dependent material parameters, which is an important, which is important physics, because, in principle, all material parameters exhibit frequency dispersion. And And then the result is pretty much the same as long as the frequency dispersion is what is known as normal dispersion. So the derivative of epsilon is positive, as long as the derivative of epsilon is positive with respect to frequency, the previous analysis calls. It becomes a little bit more cumbersome, but the end result turns out to be the same. So this 1.5 D case is kind of about 80% clear, I would say, at this point to me. But I may be wrong. Okay, now two dimensions. So, that is the most interesting case, and that's where the main complications arise. I'm pretty sure that the analysis that I kind of outlined to you is the only kind of game in town, in a sense, because that's the only feasible possible explanation of this mystery of why the behavior modes are high frequency and evanescent modes, for that matter, depends on lower frequencies and propaganda modes. So, this kind of bank account analogy is, I think, the only possible. Analogy is, I think, the only possibility for the explanation. But in 2D, there are serious complications that are not kind of a direct extension of what we've done in 1D. For one thing, impedance now becomes a Dirichlet-Neumann operator. It's no longer a scalar parameter as it was in 1D. And it's not exactly clear what to do about that. However, at least preliminarily, I was able to show that its frequency derivative of this Dirichlet-Neumann operator. Of this Dirchlich-Noman operator is negatively definite. So it is certainly analogous to what we have for this monotonicity of scalar impedance. So this is kind of encouraging. It doesn't really solve the problem, but I think it shows that maybe we're on the right track with that. Okay. And then, so there are many, many other challenges. One I already mentioned, maybe another, well, this is a major one, the Dirschlit and Lehman operator. the Dirsch and Lemana operator. And directly related to that fact is another fact that if the space of solutions now is infinite dimensional, and the Dirichlet-Naman operator itself is infinite dimensional. And so again, as a matter of principle, we cannot necessarily capture the behavior of fields at the boundary by just looking at block diagrams, by looking at what happens in the bulk. We can do that. Happens in the bulk. We can do that in one dimension because the solution space is really two-dimensional only, but in the physical-dimensional space, this is no longer true. So that would be a very, very interesting, in my view, result. And that's where there are many things that, well, first of all, I do not understand, and I'm not even sure how to go about that. And also, my suspicion is that they might be kind. And also, my suspicion is that they might be counterexamples of that. I think that's pretty much close to what I wanted to tell you. My conclusion is a very simple one. You do not need to be convinced of that, but I still wanted to put it down explicitly. Okay, so again, my biggest hope is that some of you might be interested in some of the things that I presented to you in a very, very superficial way. In a very, very superficial way, admittedly, because of the time constraints. I prepared, as already mentioned to Andreas, a five-hour talk, but unfortunately, they just trimmed it down to just two hours. And so it had to be pretty sketchy in many cases, in many places. Thank you for your patience and almost an infinite amount of patience that you exhibited. Thank you. We will give the priority to our online system. Is anybody still awake online? Yes. Is there some questions? We had already some during the talk. Somewhere in the first third of your tale, you mentioned that there's an R. Tale, you mentioned that there's an art to constructing these drafts, spaces, spaces. Is it clear what the difficulties are there that cannot be done, let's say, algorithmically? What is the magic source? I think that is a $64,000 question, I would say, right? Different situations, I guess, very, very different situations. The general thing is that I do not have convergence and stability proofs in many. Proofs in many cases. So, one thing, kind of one negative result that we observed in practice is that the null space is of dimension more than one. So, you've got two possible kind of most two possible, let's say, schemes of more than two. Then the results are not good. And that's just been a practical observation. So, that's a negative result. So, that's one thing. The second thing is in connection with different. With different schemes, I think the more redundancy you have in the least squares methods, let's say, I think they generally the better. So that might be, if you know what I'm talking about, right? So in the example that I showed where you have multiple nodes and much fewer basis functions, right, then the least squares approach is more stable, right, as everybody knows, right? So if it's overdetermined as opposed to the underdetermined. So I think that in that sense, In that sense, the SVD version that hasn't really been explored that much maybe is worth looking at. Okay, in the case of observing boundary conditions, I do not know if you're referring to that or something else. In the case of observing boundary conditions, I think it's, in my case, it was kind of intelligent trial and error. I suppose it was intelligent, maybe to. I suppose it was intelligent, maybe to some extent. Okay, if you want to replicate the existing conditions, then it's easy. You either do it or not. And in the case of existing conditions, they have been, to some extent, to a large extent, they have been proven. Many results have been proven. Many results have been experimentally verified. So you are on a solid ground in that case. But I also play it with multiple other combinations of basis functions, let's say, and degrees. Functions, let's say, and degrees of freedom in the case of outgoing boundary conditions. And then I just tested them experimentally. If you have a code where you can just plug in various boundary conditions, then it's relatively easy to do that. And by doing kind of those numerical experiments, you see whether or not, of course, if it's a negative result, if something doesn't make sense, then pretty quickly you'll see that things will fall apart, right? There's instability. When the results, if the scheme The results are, well, if the scheme, let's say, if the condition is good, then of course it's more difficult because you have to kind of keep trying, right? And if it keeps going well, then at some point you say, well, at least as an engineer, I'm satisfied, right? But mathematically, that's a big challenge. Okay, okay. Thank you all very much again. Those of you who have the patience to stay, I'll be happy to do so.