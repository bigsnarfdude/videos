In probability, computer science and theoretical physics. I'll just take a few minutes to remind you of how things work in terms of questions. So for the questions, you should ask them directly in the chat. And our expert in the room today is Max. And he's going to answer as many questions as possible. And if needed, he'll Possible, and if needed, he'll interrupt Amin so that he can answer the question more broadly. Apart from the chat, we'll also have a short break after half an hour where Amin will answer directly your questions. And at the end of the talk, so in one hour, we'll have a longer period where you'll be able to unmute yourselves and ask the questions directly. So, just to remind you that this is recorded and streamed live on YouTube. So, if you don't want your face on the internet, please turn off your camera. Now, I'll take just a few seconds to tell you about the schedule. So, Amin Haskell agreed to give three lectures. So, there's the one today. There'll be one tomorrow at 1:30 p.m., not 12 p.m., and then on Friday. And then on Friday, the last lecture at 12 p.m. Eastern Time once again. And on top of this, tomorrow we'll have a lecture by Eli Ran Subag at 12 p.m. Eastern Time. So with this in mind, I think I will give it up to Amin so that I'd like to thank you very much for agreeing to give. I'd like to thank you very much for agreeing to give this lectures. I'm looking forward to hearing about all this. So I'll give it up to you. Okay, thank you. So let me see if I can. Can you see my slides actually? Not yet. You have to share your own screen again. Okay. Is it working now? Yeah, perfect. Very good. Okay, so yeah, welcome everybody. One of the most, maybe the most exciting development in probabilistic combinatorics in the last 10 or 20 years or so has been the discovery that there's a close connection between a lot of questions about. Of questions about discrete random objects, like, for example, random graphs and random matrices, and the statistical mechanics of disordered systems. And as a result, what has happened is that new proof methods in Venn graphs have been developed that are strongly influenced by ideas such as replica symmetry breaking, for example, an idea from the theory of disordered systems that you already heard a bit. Systems that you already heard a bit about in Aukash's lecture. So, in this lecture, what I'm going to do is I'm going to give you a brief overview of this connection between these two different areas. And in particular, in lecture one, I'm going to give you an overview a little bit about random graphs and the phase transitions that we expect in them in light of the In light of the ideas from statistical mechanics, I'm going to give you an overview of the way, if you like, the lens through which physicists look at random graphs and their main tool that they wield, something called the cavity method. The cavity method is an analytic but mathematically non-rigorous tool, and it has led to mathematical methods. And it has led to, mathematically speaking, quite a number of intriguing conjectures, some of which have by now been proved rigorously. And at the same time, it has also guided us in finding mathematical proofs, even though the method itself is non-rigorous. It has inspired new proof techniques. I'm going to tell you a little bit about the connection to classical proof techniques such as the first and the second mode. Such as the first and the second moment method, and about things like belief propagation and density evolution, which are tools that play a prominent role in the physics calculations and by now also in modern rigorous results about random graphs. In the second lecture, I'm going to give you a rigorous proof of a rather non-trivial prediction based on Prediction based on physics ideas, namely in the case of the random two-sub model. So, I believe or I hope that in the second lecture I'm going to be in a position to more or less give you a back-to-back proof of the physics prediction about the main quantity in the random two-sub problem. I'm going to obviously have to omit some of the technical calculations, but conceptually. Calculations, but conceptually, I think it will be more or less a complete proof outline. The details are written up in a paper, of course, but you will get hopefully a very good idea of how we can turn physics intuition into mathematical proofs in this lecture. In the example of a non-trivial mathematical problem, and then in the third lecture, we are going. Third lecture: We are going to look at a different type of problem that has nonetheless been influenced recently by these same physics ideas. Namely, we are going to look at an inference problem called group testing. In this context, I'm going to tell you a little bit about the basics of Bayesian inference on random graphs and about the analysis of combinatorial algorithms on random structures. And we are going to see a new. And we are going to see a new paradigm, a new technique called spatial coupling that can be used and is particularly useful in the context of inference problems. So, I mean, just to explain group testing a little bit. I mean, imagine it seems completely outlandish just a few months back. Imagine there's a pandemic spreading across the planet, and you want to identify people that are infected with this. People that are infected with this rare disease, so that you can either guarantee them, or maybe cure them, or otherwise, maybe trace their contacts. And to this end, you want to use your test capacity, your capacity for conducting tests for the pathogen as effectively as possible. And group testing is a strategy for testing a big number. Testing a big number of patients for a rare disease with the smallest possible number of individual test kits. So, we are going to look at this and it will emerge that actually these ideas, like, for example, belief propagation hold the key to the precise answer to this problem. So, let me briefly begin by explaining a little bit what disordered systems have to do with random. Disordered systems have to do with random graphs and what disordered systems are in the first place. Of course, those of you who attended Aukush's lecture already know quite a bit about this, but for the others, a good example of a disordered system is just a piece of glass. I mean, either the window pane that you're looking through or maybe a glass bottle on your table. And the reason this is a disordered physical object. Physical object is because the glass was produced by annealing, by cooling down material at a sufficiently fast pace so that there wasn't enough time for the individual atoms to arrange themselves in a crystalline structure. As a result, because of this relatively fast annealing process, we have a quenched We have a quenched disorder. We have not a perfectly regular lattice-like structure like in a crystal, but we have a topology of oxygen and silicon atoms, for example, that is random, that is disordered, it is not perfectly regular. So that's an example of a disordered system. And this is what physicists would call a structural class. Is what called a structural glass, a glass where the disorder, a disordered system where the disorder is in the geometric arrangement of the individual atoms. There's a different kind of disordered system called a spin glass, and that is, for example, what you get by rapidly cooling down a magnetic alloy. For example, I think iron and gold would work. And this rapidly And this rapidly cooled-down metallic alloy is going to evince a very peculiar disordered behavior when it comes to magnetism, to ferromagnetism. And that is what we call spin glasses. So maybe for the start, maybe for intuition, a good way of thinking about disordered systems is this picture here of a structural class. Of a structural glass. Now, of course, this annealing process takes place in three-dimensional space, and our atoms live in three-dimensional space. So, ideally, from a physics viewpoint, we would like to analyze such models in a three-dimensional, or anyway, finite-dimensional geometry. And of course, there actually are lattice models of glasses, of structural glasses, or of spin glasses. Or of spin glasses, or could for example mention the Edwards-Enderson model. And these are intriguing models, but unfortunately, they are notoriously difficult to get a handle on, even non-rigorously. And so these models exist, but they are essentially, at this point in time, as far as I'm aware, pretty much out of reach for us. And so my metaphor for science. My metaphor for science is always that science is a bit like getting home after a night at the pub. And so you are pretty drunk and maybe somewhere halfway you realize that you lost your key. So you start searching for your key and maybe you start searching under a lantern. Now imagine a policeman coming by and a policeman asks you, Well, what are you doing there? And of course you answer, well, There and of course, you answer, Well, officer, I'm looking for my key. And the answer back from the policeman might be, Well, okay, where did you lose your key? And maybe our drunkard might at that point point, might at that time point at a dark corner somewhere on the other end of the street, and might say, well, I lost it somewhere over there. And the obvious question from the policeman, of course, would be: well, if you lost your key over there in that dark corner, then why are you looking? There, in that dark corner, then why are you looking here? To which the answer is: I'm looking here because the light is a lot better. And so, this is more or less how science works. So, there's this model that might be awfully realistic in some sense, might be a very accurate model of what's actually happening in reality. But unfortunately, we can say precious little about it. It's somewhere in a dark corner. So, instead, what we might want to do is we might want Instead, what we might want to do is we might want to look for our key under the lantern. And so we might look at a model, we might want to study a model that is easier to get a handle on. And one family of models that share that characteristic is classical mean field models, like for example the model that you heard about in the previous lecture, the Sherrington-Kirkpatrick model. Patrick model. And that is a type of model that completely gets rid of any kind of underlying geometry. So, in that model, you have complete interactions between all the atoms effectively in your system. But of course, to make up for the huge number of potential, the huge number of interactions in your system, what you do is you introduce this one over square root n factor that you might remember from. root n factor that you might remember from the SK model to make these interactions very very weak so you you have complete interaction but you have very weak interactions and that's that's one type of model to look at and you can potentially maybe in many ways learn quite a lot by studying this type of model but a different type of model that is maybe a bit closer to a geometric To a geometric model is what is called a diluted mean field model. And these are models of such disordered systems where the underlying geometry on which your atoms live is not given by a geometric structure like a lattice, but it is given by the topology of a sparse random graph. Now, by comparison to these complete interaction mean field models, Interaction mean field models. The intuitive advantage of a sparse random graph from a physics angle is, of course, that you have at least some kind of a geometry. It is not a three-dimensional geometry, but you have at least something like a notion of distance and you actually have strong interactions between individual neighbors. So, for example, in a sparse random graph, you might have a real topology. You might have a real topology where every atom, every vertex in your graph has a bounded expected number of neighbors. So you actually get locally at least some kind of a geometric structure. And also, because you get rid of this complete interaction, you can actually realistically mirror short-range interactions by saying that interactions take place between a vertex. Take place between a vertex and its neighbors. And these interactions are just as intense, just as direct and strong as they would have been in the lattice model. So in other words, these models on a random graph are halfway houses, halfway points between classical mean field models like the SK model and lattice models. So that's the physical motivation for studying such models. And by coincidence, it so happens. Coincidence, it so happens that the physical intuition about these models also sheds light on quite a number of questions that arise classically in probabilistic combinatorics, for example, in the theory of random graphs. So as a specific example of a type of random graph that we might look at, think of the binomial, sometimes so-called Erdogeny random graph, G and P. We have n vertices x1, up. We have n vertices x1 up to xn. And we have an edge probability p that is defined as some real parameter d divided by n. And that means that on the average, every vertex in your graph has d neighbors. To be more precise, the number of neighbors of a given vertex is going to be Poisson D distributed approximately. Distributed approximately. And so locally, the structure of this random graph resembles a Poisson D Goldman-Watson tree. So if you start exploring your random graph from some particular vertex, what you're going to see for a long time looks like a Golden-Watson tree. So we recover this physical notion of one site, one One side, one atom in your system having a bounded number of immediate neighbors. And so we can try to maybe study physical models on this type of a geometry. Two more words about this, the local geometry of a random graph. Because you get a Poisson-Degaud and Watson tree locally. Locally. This means that locally your graph is acyclic. So if you look at any bounded distance from a given vertex, for example, you explore your random graph up to distance 100 about vertex x1, then you're not likely to see any cycles. So the first cycles you're going to see likely emerge once you move by distance something like log n away from the root vertical. From the root vertex. So locally, up to any bounded distance, your random graph is going to be acyclic with high probability, or more or less acyclic with high probability. Okay, so here's an example of a physical model that we might want to study on such a random graph. It's the random graph version of a classic. Random graph version of a classical model from statistical mechanics, something called the POTS antiferromagnet that some of you might have heard about. And so here's how it works. You fix a d greater than zero, the average number of neighbors that a given vertex in your graph is likely to have. You fix a number q of colors, at least two, and you fix a parameter beta, a positive parameter beta, that we call the Parameter beta that we call the inverse temperature in your system. So this means that higher beta corresponds physically to lower temperatures. And in terms of these parameters and the random graph G that ensues, we can define a probability distribution called the Boltzmann distribution on color assignments. So these sigmas here are Here are assignments of colors to the vertices of the graph. Every vertex gets one of Q possible colors. And the probability mass under the Spoltzmann distribution of one particular coloring is given by this expression here. So we are going to come to this normalizing term in a bit. Before that, what stands here is What stands here is the product over all the edges of the graph, e to the minus beta times the indicator that the two end vertices of this edge receive the same color. In other words, e to the minus beta times the indicator that the edge is monochromatic. For example, this edge here would be monochromatic. And whenever you see a monochromatic edge, you add an Add an e to the minus beta penalty factor to the probability of that particular calorie. And if the edge is bichromatic, you simply have a factor of one here. So bichromatic edges are not penalized or rewarded in any way. It's just that monochromatic edges receive an e to the minus beta penalty factor. And in order to turn this To turn this probability measure here, this Boltzmann, this mu here, into a probability measure, we of course have to normalize so that the overall probability mass sums to one. And that is why we divide by this expression z here. This is something called the partition function, and that's simply the sum of all these individual Boltzmann weights of all the possible color. All the possible color rings. So the intuition behind this is that, of course, μgβ is a probability mass on all possible color assignments. And the larger you choose beta, the greater the penalty that you impose on monochromatic edges. So for larger beta, you have a stronger preference for For good colorings that leave few edges monochromatic. And of course, like always in statistical physics, there's a trade-off here between entropy and probability. There's going to be a huge number of potential coloring sigma that leave a lot of edges monochromatic. And if you make beta quite small, then presumably because just Presumably, because just of the sheer number of possible poor quality color rings, these are going to dominate your measure. By contrast, if you make beta larger, you have an eye for quality. You have a strong preference for very good quality colorings that leave few edges monochromatic. Okay, so that much for the Boltzmann distribution. Boltzmann distribution. Now, as you might remember from the previous lectures, the key quantity for any such model is the partition function. If we understand, if you get a handle on the partition function, then we already make good progress towards actually understanding the probabilistic and combinatorial nature of the model. So that's certainly going to be a key quantity of interest for us. Another important remark at this point. Another important remark at this point is that both the partition function and the Boltzmann distribution are random objects, namely, they both depend on the random graph G on which the system lives. So in physics language, we are going to be interested in the quenched version of this model, where we first take a random graph G, then keep and fix this graph. We effectively carve the We effectively carve the graph in stone. And then on this fixed random graph, we are going to be interested in studying these objects, the Boltzmann distribution and the partition function. Okay, now, according to our very good friends from physics, what happens in models like the Pots anti-ferromagnet and like very many others is that various phase transitions take place. Phase transitions take place as you tune the model parameters. In this case, we might fix Q, so for example, fix Q to be 10, some fixed number of colors. And we might also fix D to be some large number, maybe 1,000. And now there's one parameter left that we can play with that we might want to tune, and that is this inverse temperature parameter beta. inverse temperature parameter beta. So we are going to look at increasing beta, which means effectively that we are going to look at decreasing the temperature. And like I said on the previous slide, this means that we are going to look at higher quality colorings, colorings with fewer monochromatic edges as we increase beta. Now a good way to look at this kind of model is that you think of the The space of configurations, the set of all possible colorings, like a plane. And on this plane, you have a function that tells you the number of monochromatic edges for each of the colorings. So, for every coloring, you have a height, which is effectively. Which is effectively the number of monochromatic edges. And now there's going to be a lot of colorings, a huge number of colorings that sit at the plateau level of this picture, that are at the top of this picture, that have a huge number of monochromatic entries. So, simply, there's going to be a lot of entropy there. There's going to be a lot of possible colorings. Going to be a lot of possible colorings at that level, and but there's also going to be a number of colorings that are better, that leave fewer edges monochromatic. So this means in this picture, you have a good number of troughs that come down from below up to some level. And these troughs correspond to local bubbles, to local clusters. Clusters local accumulations of higher quality colorings, to colorings that simply leave a smaller number of edges monochromatic. And so the way to think of this model is that you, by tuning beta, you take cross sections of this landscape, and the larger you make beta, the lower the level at which you cut this landscape. For very large Landscape. For very large beta, you cut at a high level, and for lower beta, you cut this stalagmite landscape at a lower level. And so, according to physicists, what we will observe as we cut at lower and lower levels is a bunch of phase transitions. In the first phase, we are going to see something called replica symmetry. So, the cross-section is going to look more or less like a convex set. As like a convex set, like one big bubble. And this in particular is deemed to imply that, for example, Markov chains are going to be rapidly mixing on the model. So a Markov chain is going, at this particular value of beta, a Markov chain is going to have an easy time navigating the landscape and producing samples from the Boltzmann distribution. And in particular, there's not going to be any long-range correlation. Any long-range correlations. So if you look at two vertices x1 and x2 that are far apart from each other in the random graph topology, then the colors assigned to them are essentially stochastically independent. So the probability of seeing one particular color at x1 and one particular color at x2 is approximately equal to 2q to the minus 2, number of colors to the minus 2. Another feature. Another feature of this is that there are some certain spatial mixing properties, something called non-reconstruction. So for large temperatures, for small values of beta, the model is quite simple. Now, what happens if you make beta just a little bit smaller? What happens is that there's going to be a phase transition that goes under the catchy name of dynamic. Catchy name of dynamic replica symmetry breaking in statistical physics. And so at this point, you are going to cut a lot of these troughs. You are still going to cut a huge number of these troughs in your landscape. But the picture is now going to be disconnected. As you cut through, there's going to be different separated bubbles in your cross-section. And this means there'll be. And this means that we don't expect Markov chains to be rapidly mixing anymore. So, if you launch a Markov chain, it's bound to get trapped in one of these bubbles. On the other hand, because there's still such a large number of bubbles, we do still expect to see the absence of long-range correlations simply because correlations between these different bubbles effectively cancel out. So, if you look at too far away, You look at two faraway vertices, then the colors assigned to them are still going to be essentially stochastically independent. And finally, there's a phase called static replica symmetry breaking. And at this point, in your cross-section, there's only going to be a small number of dominant troughs. So there's not that many troughs anymore that go as Go as far down as the point where you are cutting. So, this means that your Boltzmann distribution effectively looks like a mixture of a small number of relatively narrow troughs in this picture. And as a result, we now do expect to see long-range correlations, namely the colors of x1 and x2 are going to be correlated through another hidden random variable. Another hidden random variable. And this hidden random variable is, if you like, the address or the number of the trough where the coloring comes from. And so these troughs are called, these few troughs that dominate the picture are called in statistical physics lingo pure states. And these also play a big role in the context of the Sherrington-Kirkpatrick model. Sherrington-Kirkpatrick model. Now, just before we take the break, let me make one more point: namely, one thing that you can ask is whether you can effectively turn this OMELET on the other side. So in the previously, what we did was we first created a random graph and then chose a coloring. And so maybe we can actually put the omelette on the other side and first choose a coloring and then just color the color. A coloring and then generate a random graph that goes with it. And this is actually something that can be done. This leads to an inference problem, and this is exactly the connection between random graphs and disordered systems and statistical inference problems. So in this particular example, the inference problem that you end up with is something called the stochastic block model. There's an amazing amount of literature on this, actually. And this is simply the flipped omelette version. The flipped omelette version of the POTS anti-ferromagnet. Namely, what you do is you first generate a random coloring uniformly, and then you choose a random graph from this distribution here. Namely, the probability of hitting some particular graph, capital G, is simply proportional to the Boltzmann probability that sigma star would have under this random graph. Random graph. And so, from an inference viewpoint, the question would be: given this random graph G star, can we at least partially infer sigma star? And because of the connection between this inference problem and the Potts anti-ferromagnet, these ideas like replicas symmetry breaking and so on are actually useful to answer this sort of question. So, let's maybe take a five. Maybe take a five-minute break, and then I'm going to proceed with some more detail with the random TUSA problem. And I'm going to give you some more details and fill in some of the blank spots in this high-level picture. Okay, thank you. So, if you have any questions, feel free. So if you have any questions, feel free to ask them in the chat. So there's already one. I don't know if you have access to it. It's good. I can describe again how the landscape is constructed or defined. Yeah. Okay. Right. So this landscape is actually something called the Hamiltonian in physics language. Language and so this Hamiltonian is simply a map and it's a map from the space of all possible color assignments to the non-negative numbers. And what it simply does is it simply maps a given Maps a given coloring to the number of monochromatic edges. And physicists really, from a physics viewpoint, the Hamiltonian is a very important object and plays a pivotal role in the definition of many such models. So in this picture that I showed, think of the two-dimensional plane, the x and y-axis, as it were, as the cube 1 up to q to the n. One up to q to the n. Of course, that's not really a plane, it's a very high-dimensional combinatorial cube. Nonetheless, at least metaphorically, let's think of it as a plane. And the Hamiltonian is simply a function that sits on this plane, effectively a three-dimensional function that defines this landscape. And what I showed you was actually not the Hamiltonian itself, but the flipped Hamiltonian, the Hamiltonian with the minus in front. The Hamiltonian with the minus in front, basically. Right, so yeah, the questions. Can you explain the last slide once more? You can share the screen again. So, right, so the POTS model has an inference problem. So, previously, what we did was we said, well, you take a random graph and then subsequently you define, subsequently, you choose a configuration from this random graph. Now, what we do here is we turn the tables. We basically say, you know what, just first. Just first choose a coloring uniformly at random. Take a random coloring uniformly without looking at any graphs, without asking anybody at all. Just go to your room and secretly generate your random coloring, then come back and generate a random graph to go with it. And this random graph is defined so that it tends to fit. So that it tends to fit your coloring. So, roughly speaking, you say, well, for a given specific graph, I look at the probability mass that this particular coloring would have under the Boltzmann distribution of this graph. So e to the minus beta times the number of monochromatic edges. And this expression, e to the minus beta times the number of monochromatic edges, is roughly how much I like this graph. Like this graph. So I'm going to like graphs better that have fewer monochromatic edges under this coloring, that happen to have fewer edges that link vertices of the same color under this particular coloring. And I'm going to dislike graphs that have a lot of edges that fall inside the color classes of this particular coloring. Now, in the case of an added rainy model, you could alternatively say you choose every Alternatively, say you choose every edge independently so that you have this e to the minus beta penalty factor for a monochromatic edge, and you have and you don't have this penalty factor for bichromatic edge. And so, what you end up with is a random graph with supposed to be conditional the number of edges with some specific number of edges. Of edges. And you can ask yourself, for example, is this random graph that you get this way going to be distinguishable in any way from the purely random Erdogini-like random graph. And if the answer is no, then unfortunately, it's not going to be possible for you to reconstruct the coloring from which I started to generate this random graph. And if the answer is yes, then maybe you have a chance. And it turns And it turns out that this static replica symmetry breaking phase transition is precisely the point from where on it's going to be possible for you to get back at the coloring sigma star that you started from. And so this stochastic block model, which has been studied since the 80s out of independent interest in various communities, actually can be solved. Actually, it can be solved indirectly by way of understanding the POTS model on the random graph. So that's the connection between inference and the random graph. So the next question is small, right? So what is a small value of beta? What is a large value of beta? So this is not quite so easy. So the precise formulas are a bit tricky. Are a bit tricky. I didn't put them on the slides, but I can easily put, I could maybe add a reference where these values are worked out to some extent. So let me do that at the end of the lecture. I'm going to put in a reference what small and large beta mean. It's not as easy as one smaller than one or greater than one, like it would be in the Curie Weiss model, for example. A query vice model, for example. Okay. Yeah. Max, are you still there? Yeah, he's still there. Yes, sure, I am. Okay, good. Yeah, so you can also ask Max any questions while I'm rumbling on. So don't hesitate to ask Max. So, any other questions? He's asking if there's an intuitive way to um picture full RSB uh solutions, uh solution geometry of full RSB. The solution geometry for RSV. Yeah. Yes and no. I mean, so the best intuitive way of describing full RSB, or let's say, okay, so the best way of describing this is, I suppose, in terms of the asymptotic Gibbs measures. Gibbs measures that you can describe. So let's look at the one RSB picture first. I didn't actually discriminate between one RSB and full RSB in the slides that I showed. So the one RSB picture would basically be that you have, if you look at these different Different contributions, these different little bubbles that remain in the static replica symmetry breaking phase, that these bubbles are kind of almost isomorphic from one another, and that they are distributed more or less uniformly over this landscape. So, you have bubbles that carry different Boltzmann weights, but these weights are different only by a few. Weights are different only by a fairly small amount. So, they, I mean, there's only a constant factor weight between them, so they don't differ a whole lot. And what we would expect is that if you zoom in onto any one of these bubbles, you would effectively see a very similar picture locally. And these bubbles are more or less uniformly spread all over this place. You can think of them kind of like a basis. Like a basis in an L2 Hilbert space. They are essentially orthogonal. In the full RSB picture, it's different. You get a hierarchical decomposition. So these, I mean, if you like, there's a hierarchy of bubbles. So each of these bubbles would in turn again decompose into bubbles, which would again decompose into bubbles and so on and so forth. So that's the So that's the, I guess that's the only intuitive picture that I can give. But I think it's not such, I mean, from a combinatorial viewpoint, it's not such a big mystery, I would say, as it's always or sometimes made out to be. So thanks for the detailed explanation. I think we'll cut this exercise this question. This exercise, this question part for now, and we can ask more questions at the end of the talk if you want, because these are more general questions. So, I'll let you continue, and we can go over time a little bit if you need. Okay, I'll rubble on them. Okay, so now let's try to make this to some extent a bit more concrete. A bit more concrete. So, I mean, we have this intuitive picture maybe in mind to some extent about replica symmetry breaking and about these different phase transitions. So let's look at a concrete example, a concrete installment of a problem that these methods can be, these physics methods at first can be put to work. And let's inspect a little bit the Let's inspect a little bit the proof techniques that we have in our arsenals to maybe verify some of these statistical physics predictions. So there's of course a bunch of classical Wendel Graaff techniques that are time honored and that still have their place in the context of these disordered systems. So, one example of this is the method of moments. It's great if it works. But it doesn't always work, or well, maybe it works, but with an extreme amount of complication in some cases. There's of course the concept of branching processes that play a big role in order to understand the local geometry of random graphs. And there's large deviations techniques, things like understanding rate functions or large deviations. Or large deviations, inequalities that you might find handy in some places. So these are kind of classical random graph techniques that you find in the book, literally. But more recently, there have been some very successful mathematical physics-inspired techniques or statistical physics-inspired techniques. And these are things like coupling arguments. We are going to see the Isenman-Sim stars. The Eisenman-Sim star scheme, for example, in the next lecture. There's the idea of exchangeable arrays and something called the cup metric, which is a way of connecting high-dimensional discrete probability distributions, like, for example, the Boltzmann distributions of our various disordered systems with analytic methods. There's the belief propagation message passing scheme. Propagation message passing scheme and something called the contraction method from probability theory. And of course, one very important technique in the context of disordered systems is the interpolation method first developed by Guerra for the study of the SK model, but by now in widespread use also in the theory of venue graphs. And there have been quite a few success stories, this connection between Stories where this connection between disordered systems and random graphs has been used to great effect. For example, there's some work on the geometry of solution spaces. For example, Michael Loy's beautiful paper on the freezing phase transitions in random constraint satisfaction problems. There's the random K-SAT problem where there's been a line of work that culminated in the article by Dings Lyons. The article by Dingslei and Sun on the KSAT transition. There's been very beautiful and outstanding work on low-density parity check codes, where these ideas from disordered systems have been used in order to develop new error-correcting codes. And low-density parity check codes actually are a very successful class of codes that are part of communication standards. So you actually carry them around. So, you actually carry them around with you in your pockets because they are built into your smartphones. The stochastic block model is a nice benchmark of a clustering problem that has been receiving quite a bit of attention. And of course, I'm going to speak about group testing. So, what I want to say is that this connection between disordered systems and random graphs and inference problems has been quite a success story with some. Success story with some real-world applications as well, like these low-density parity check codes or, like I said, group testing. So to give you one example of a theory, what a typical rigorous theorem in this area looks like without going into any details. This is a result from a paper that we had in 2017 about the POTS model on a random graph and what this Graph. And what this theorem tells you is the static replica symmetry breaking transition in your random graph model. So the characteristic feature of this theorem is that the result comes out in terms of a variational problem. So an optimization problem on a space of probability measures. In this case, all probability measures measure. probability measures, in this case, all probability measures pi on the standard simplex in RQ, whose very center is the uniform distribution. And the function that you're supposed to maximize is something that is called in physics jargon the beta-free energy. And that is a function that looks a bit like this. So it talks about a lot of independent samples from this distribution pi that you're optimizing over. And your phase to And your phase transition is characterized by an equation that tells you: well, look for the optimal solution to your variational problem. If it hits a particular value, that is where your phase transition is. And so the point about this is that, and I think this inf should actually be a soup. And so the point about this is that. Point about this is that we may not end up with a formula that is quite as explicit as some formulas that you get in combatorics. So you don't get something that you can punch into maple and get a solution right away. But what you do get is you get a characterization that tells you that these physics ideas, these ideas about replicosymmetry breaking and belief propagation, actually get to the bottom. Actually, get to the bottom of the problem. So, even though you might not be able to punch this into a computer algebra system as it stands, the punchline of this result, the upshot of this theorem is that the cavity method, the physics ideas can be taken as they are. You can put rigorous tracks beneath them and run the calculations on them. And there's no gap, it leaves nothing on the table. This physics intuition actually hits the This physics intuition actually hits the nail on the head. And so, even though it looks maybe a bit frightening at first glance, this is the kind of theorem that we typically aim for. So what I'm now going to do is I'm now going to tell you a little bit about how the two-sub problem from comulatorics looks through the lens of the cavity method and what kind of ideas you would bring. What kind of ideas we would bring to bear and what predictions we would make. So the two-side problem is a classical problem from combinatorics, from logic, if you like. You have Boolean variables x1 up to xm. So these are variables that can take the values true or false, which we represent by plus 1 and minus 1 by easing spins. And we are going to use these Boolean values. And we are going to use these Boolean variables to construct propositional formulas. And these formulas will be composed of such OS, such disjunctions of literals. And the disjunctions that are possible are, well, such positive disjunctions, where you just take two variables and put an OR between them, or disjunctions that might involve negations. So this would be X. So, this would be xi or not xj. So, if xi is set to true, this expression would evaluate to true. And if xj is set to false, it would also evaluate to true, and so on. And now a two-side formula is simply a big and of many such clauses, of many such ors. So, a two-side formula is a big AND of many ors, and each of these. Of many ores, and each of these ores has two literals, as two separate literals. And of course, we are going to be interested in satisfying assignments. So we are going to be interested in assignments that simultaneously satisfy all of these M clauses. And in particular, we would like to count such assignments. We would like to know how many there are. And so Z of phi out. And so z of phi, our partition function in this case, is simply just the number of satisfying assignments. Here's an example of a two-sat formula. So we have three clauses in this case. The first clause is not x1 or x2, and so on. And of course, you can represent this two-sat formula by a graph with these little boxes representing the clauses and the circles representing the Boolean variables. The Boolean variables, and the color of the edge indicates whether the variable appears positively or negatively in the clause. And in this specific example, you see that there's two satisfying assignments. One is where all the x1 and x2 are set to true, and x3 is set to false, and the other one is in this case, interesting. In this case, interesting enough, the binary inverse of the first. And so, in a way, you could say that this two-sub problem is glassy. It's a disordered problem because the variables appear in the clauses with different signs. So, for example, this variable here is dragged into two different directions. Dragged into two different directions by this clause and by that clause. So, this clause would rather have x2 take the value false, and this one would rather have x2 be set to true. So, x2 is kind of dragged into two different directions, like in a disordered system, where we don't really have a crystalline structure, but a structure that is somewhat disordered. There's not a perfect solution maybe. A perfect solution, maybe in every case. Of course, we are looking for a satisfying assignment, but there's not a way to, let's say, in this case, make all the edges get what they want. Okay, so that's an example of a two-sat instance. And of course, you may have heard that the K-SAT problem plays a big role in computer science. Now, fortunately, it has been known for quite a long time that 2-SAT can actually be solved in polynomials. Can actually be solved in polynomial time. So there's an efficient algorithm that will tell you whether a given two-sat formula has a satisfying assignment. In fact, also find a satisfying assignment if there is one. However, counting the number of satisfying assignments is a different cattle of fish. That's actually a hard computational problem. And in fact, Valian showed in 1979 that this problem is not just. That this problem is not just np-hart, but it's a problem that belongs to an even worse complexity class, namely this class number p. And it's number p-hart, which means that in particular, if you could solve this problem in polynomial time, you would collapse p and np. Okay, so counting satisfying assignments is still a hard problem. And so maybe it's not surprising, therefore, that even on random Therefore, that even on random two-sat formulas, the problem is still rather non-trivial. So, how do we generate such a random two-side formula? Well, we fix some, like in the random graph case, we fix some degree d between zero and infinity, some finite number. And now we include Poisson DNO2 clauses in our random formula. And these clauses are simply drawn. Clauses are simply drawn independently and uniformly at random. So we simply put down m uniformly random independent clauses and connect them with our variables. Also, the colors of the edges, the signs with which the literals appear in the clauses are, of course, chosen randomly. And if I look at this picture from the variable side, then I'm in a similar situation like in the POTS model that I described. Like in the POTS model that I described earlier. Namely, I'm going to see that the degree distribution of the variables is Poisson D. And of course, what we are going to be interested in, like I said, is the partition function. In particular, we would like to know, first of all, of course, is the partition function positive? Do we have satisfying assignments? And assuming that we do, And assuming that we do, what is the limit in probability of the number of satisfying assignments? Or to be more precise, as it will turn out, we should really be looking at one-on-one n log of the number of satisfying assignments because it will turn out that there's exponentially many of them. So, to get a reasonable finite limit, we have to normalize by mod on n log. Okay, so Okay, so there has been quite a bit of prior work on this. Let me run you through that quickly. The threshold for the partition function being non-zero is actually known and has been known for a long time. This is a result that was independently obtained by Cottal and Reed and by Gert. And in 1996, actually, Moulasson and Zekina also used the cavity method to The cavity method to derive a prediction of the typical number of satisfying assignments via the cavity method. And the goal is going to be for us to prove that prediction. First, we are going to look at how they derived this prediction, and then we are going to try and prove it. And there have been some partial results towards this result already. So, for example, most importantly, there was this. Most importantly, there was this paper by Abiy and Montanari from 2014 that proved the existence of a deterministic limit for the number of satisfying assignments, or more precisely, the suitably normalized number of satisfying assignments. So they proved that this function phi of d exists so that your number of satisfying assignments suitably normalized. Assignments suitably normalized converges in probability to phi of d, but failed to actually compute phi of d or to prove that phi of d matches the result of predicted by Monasson and Zikina. So let's briefly speak about the satisfiability threshold and about the way we can bring random graphs into this game. So one thing you can observe. So, one thing you can observe is that a clause, an or of two literals, is logically equivalent to two implications. Namely, the or is equivalent to not L implying L prime and vice versa. And so this means that your formula is going to be satisfiable unless there is an unlucky chain of implications that starts at xi. That starts at xi. I mean, once I put down these, once I transform the clauses into implications, there's an unlucky chain of implications, namely one that takes xi to not xi through some intermediate steps, and then takes xi and not xi back to xi. And of course, such a chain of implications cannot be satisfied. And such chains are called bicycles in two-sat. In Tusat jargon. So here's an example of a bicycle. Here's your variable xi. And if you re-translate the colors into signs of literals, what you see is that this bicycle here, this structure, precisely encodes such an unlucky double chain of implications. And of course, we can try to use percolation. Can try to use percolation arguments, arguments that you may know from the study of the giant component in random graphs, in order to compute the threshold for the emergence of such bicycles. So effectively, this means that we have to check whether a certain branching process is supercritical or not, and that is precisely the gist of the work. The gist of the work by Crattal and Reed and by Gert. So they effectively compute the threshold for the emergence of bicycles and discover that if your average degree is less than two, then your formula is unlikely to contain bicycles. And for d greater than two, bicycles abound, there's a lot of them actually. And so what's the intuition between this? Where does this number two come from? Number two comes from? Well, suppose you start exploring your random two-sat formula from some variable, and suppose you set that variable to a specific value. Let's say you set it to true. Then the effect will be that you satisfy all the clauses where that variable appears positively. But unfortunately, you fail to satisfy all the clauses. Unfortunately, you fail to satisfy all the clauses where your variable appears negatively. So, in this example, the two clauses, these two black clauses, are unfortunately not satisfied by the parent variable. So, these variables will have to ask their child variables to please satisfy them. So, this means that they have to, they are going to force their children to take specific truth values that will. Specific truth values that will satisfy them. So, this child here, for example, is connected to its parent clause by a blue edge. So, in order to satisfy its parent clause, it has to take the value blue. And this one here similarly has to take the value red. And so, unfortunately, this variable here that has been forced to take the value true will fail to satisfy one of its children, which will therefore have. Of its children, which will therefore have to propagate the good word down to its children, that they will have to satisfy the clause, and so this will continue. And now you can imagine that you get yourself into trouble if this propagation process here, this forcing process, is supercritical, if it will, with some positive probability, actually continue for an unbounded amount of time. For an unbounded amount of time. Because in that case, there's a good chance that you will run into a loop and thereby close a bicycle. And that is precisely the kind of argument that you find in these papers. It's encoded a bit differently in these two contributions, but this is basically the gist of it. Okay, so that was our first classical method, our first class. First classical method, our first classical random graph technique, the theory of branching processes and this kind of propagation argument. And now let's try to see whether we can also use our other classical tricks, like, for example, the second moment method. So can we actually try and use the second moment method easily to compute the partition function, the number of satisfying assignments? So one observation is, of course. So, one observation is, of course, that we can always get an upper bound on log z, on the logarithm of the number of satisfying assignments, by using Jensen's inequality. So we can certainly say that if I probability with probability tending to one in the limit as n goes to infinity, log z, the log of the number of satisfying assignments, is upper bounded by Is upper bounded by the log of the expectation of Z, okay, given the number of clauses. So we can certainly upper bound Z by its expectation plus a little over term. And this is basically just using Jensen's inequality, or if you prefer, Markov's inequality. And so now we could say, well, maybe. Could say, well, maybe we are in luck, and maybe this inequality sign is actually an equality sign. And maybe we are really, really lucky, and we can prove that this inequality is an equality by simply using the second moment method, by simply computing the second moment of the number of satisfying assignments. The number of satisfying assignments. So, yeah, let's try and carry this program out. First, computing the first moment is easy. So simply by linearity of expectation, we can write the first moment as the sum over all possible assignments, probability that a particular assignment is satisfying. Now, fortunately for us, once we Fortunately for us, once we condition on the number of clauses, the probability that a particular assignment happens to be satisfying is precisely three quarters. And that is because if you fix an assignment and an assignment of two variables, and now you drop a random two clause on these two variables, in three cases out of four, your clause is going to be. Your clause is going to be satisfied. And the reason is that, so for example, suppose I set them both to true, I set both the variables to true, but there's precisely one way of choosing the signs of the literals that will unfortunately leave the clause unsatisfied. And in the case where I set the two literals to true, that one unlucky case is if I put negations in front of both my variables. So for any one So, for any one assignment, the probability of being satisfying is three-quarters to the number of clauses, and there's two to the n possible assignments. So my expectation, my expectation of z is simply two to the n times three quarters to the m. And so, if I take logs i and write and recall that m is Poisson dn on two. Poisson dn on 2, I end up with this tiny little expression down here. Okay, so the first moment was easy. That's encouraging. Let's go for the second moment. So maybe, like I said, we are really lucky and our second moment turns out to be not a whole lot bigger than the square of the first moment. So let's get cracking. Let's get cracking. We write down the second moment, and we can think combinatorially of the second moment as the number of pairs of satisfying assignments. So that means we need to look at any two truth assignments and we need to calculate the probability that both of them happen to be satisfying our random formula. Random formula. So we sum on any pair of truth assignments and we calculate the probability that they both happen to satisfy.