Does this look okay? Yeah, it looks great. Okay. Important fair. Okay. Okay, let's take a look at the game. So the next equation is critical button, focus on. Yeah, and she's going to talk about the phase and aversion contract imaging using entity methods. It's your turn. Hello, everyone. I would like to thank the organizers for the invitation. I think I'm jealous of you being at Pears. It's a very nice place to be. Unfortunately, I had to teach. I'm teaching a big class, and it was difficult to get away. But I hope to see you all real pretty soon. Okay, so this is joint work with my collaborators, Mikel Moskoso, Alexei Novikov and Jospa Panikolau, and I would like to acknowledge support by Air Force. So this is an inverse problem and I think most of you will know what this slide is about. We'll know what this slide is about, but let me go through it quickly. So, in inverse problem, what we aim to reconstruct is a medium characteristics from knowledge of the response of the medium to a known incident field. And here, we will consider that we are trying to reconstruct the transmissivity by recording the medium's response to one or more known excitations. So, the incident field is known, then it interacts with this plan. Interacts with this plane where there is the object that we would like to reconstruct, and we collect the response on some receivers. So in my talk, I will consider that the unknown is sparse. This is important for this talk. It may be true in applications if the object that we wish to image occupies a small part of the imaging window, but more generally, often. But more generally, often we can assume that the object that we seek to recover admits has a low structure and therefore admits a sparse representation in a base basis that we know, maybe carefully, but we have determined in advance. So, in this talk, we will have Talk: We will have measurements that are just the intensity, and this will play an important role. Why intensities measurements? Because at high frequencies, only intensities can be recorded, and this has important applications in optics, in digital microscopy, and X-ray crystallography, to name a few. And the approach that I'm going to present is To present is based on an algorithm, so it's a computational imaging approach that allows us to recover both phase and absorption contrast from intensity-only measurements. And we will be using multiple illuminations as it is usual in phase retrieval. For example, instead of multiple illuminations, some other approaches may be using masks. Masks and the keystone for the efficiency of this method is, as we will see, a dimensionality reduction strategy, which allow us to reduce the number of unknowns for the problem, accounting both for the incoherent and the coherent contributions in the data. So, in this sketch, I want to illustrate how important phases are. Maybe all of you know that. Maybe all of you know that, but in the far field, which is the case that I will consider today, we know that we can use the Fraunhofer representation for the waves. And then imagine that the anonymity I'm seeking to recover is this image, right? And it's a black and white image. So I have a variable that takes a value between 0 and 1. And then the data that I have. And the data that I have is the Fourier transform of this image. And here on the bottom, I have on the left the amplitude and on the right the phase of the Fourier transform for two quite different images. And then what I will do is that I will mix the phases. So I will interchange, I will put the phase of this image here and of that one here, and then I will reconstruct. So you will see what happens is that basically the image is Basically, the image is literally flip, which means that most of the information that we seek if we want to characterize an object is encoded in the phase, right? So if we only measure amplitudes, we lose a lot of information. So the problem, the inverse problem with intensity only is much harder than the classical one when we measure both amplitude and phases. Okay, so let me now present my mathematical model for My mathematical model for the problem that I will be solving. So, as I said, we seek to reconstruct a transmissivity vector. So, it's a vector that lives in this imaging window plane that we discretize and that we have capital K pixels in this imaging plane. And the unknown is a complex function, so we seek to reconstruct both the amplitude and the phase of T and our. And our intensity measurements are described here. So, what is it? So, we send an illumination from the source plane, and this illumination that I call W UI. So, I is the index of the illumination. When it arrives on the imaging plane, at its pixel K, it takes a value Wik. So, I assume I know W U I K, both the amplitude and the phase of the illumination, because I assume. Of the illumination because I assume I know the propagation medium between my source plane and my imagined plane. And then locally at its pixel, this illumination will be multiplied by TK, which is the my anode. And then this field will propagate with a propagator that I call FSK from the caved picture in the imaging plane to the S receiver. Receiver. So, my S receiver will receive contributions from all the pixels in the imaging plane. So, the field at the S receiver will be equal to that. And I record the intensity. So, this is the absolute value squared of this field. And this is what I wrote here. So, by expanding this sum, I have for k equals k prime, we get this term. equals k prime, we get this term. I assume here that the absolute value of fs k is equal to one, like if it is a Fourier transform, this is the case. But even for the wave equation, if we are far, the amplitude is almost constant here. So this is a good, we could have an amplitude factor that doesn't change anything. And then we have this term for different than k prime. So we'll call this contribution. So I will call these contributions here, the first one, the incoherent one, because there is no phase, right? Everything is an absolute value. And I will call these contributions to the data the coherent one. So this is our model. And now we want from this data to recover both the amplitude and the phase of the unknown pK. So So okay, so this problem can be written in the following matrix form: W U incoherent times X D plus W coherent times X cross is equal to the data. And our data is what I described in the previous slide. And X D and X cross are the two components of the anode. So this is the The ankle. So, this is the incoherent component, and this is the coherent component that contains all the cross-correlations. So, another way to think about it is if we know t, t is a vector, we form the Rankuan matrix T T star. And then the diagonal of this matrix, that's why I call this X T, the diagonal of this matrix is the absolute value squared of Ti, and then all the And then all the other terms of the matrix are the cross-correlation terms. And now we know, so we could try to solve this problem. The difficulty is that the dimensionality is huge, right? If we have an image with k unknowns, then the unknowns for these problems are k squared. And for example, an image with a thousand by a thousand pixels results to billions of unknowns, which is not Of unknowns, which is not really a problem that we can solve. So, this problem is non-linear in T, and there is much interest in finding algorithms that can give a true global solution in an efficient way. And I will divide the solutions that we have for this problem in two categories. So, there are iterative projection methods. For example, the approach by Girtsberg and Saxton, which was Per and Saxton, which was popularized by the algorithm by Finab, which is, I mean, there are many, many, I should say that this reference look old, but there are many newer reference on this area. Well, we basically use non-convex approaches in order to solve this problem. And these approaches are simply to implement and flexible in practice, but because they are non-convex, they do not always converge. Convex, they do not always converge to the true solution unless we have prior information about the object that we wish to recover. And then the second type of approach that I want to mention is convex approaches. So in this case, one such approach is when we look for the unknown TT star. So as I said, this is a rank one matrix. So we can use nuclear norm minimization for this matrix and try to find the solution to the problem. Find the solution to the problem. But as mentioned already, the difficulty in this case is dimensionality, right? We still have a matrix unknown, bless you, which has a very big dimension. So the advantage of these approaches, and again, my list is not exclusive, is that we have a convex problem. So we know that we are going to find the true solution, but the computation. Solution, but the computational complexity of the algorithm makes it not really scalable, so we cannot use it for large images. So, what is the approach that we will follow? As I said, it relies on a robust dimensionality reduction strategy. So, the idea is to get rid of this huge size of our problem, which is equal to k squared. And so, what we will do is that we will fix. What we will do is that we will fix every time a smaller part of the unknown, as the one that is of interest to us, and the rest of the contributions in the data will be considered as noise. And we will use a noise collector to deal with this noise. So basically, we will solve linear system of this form, but every time our anonyms will be linear in k and never quadratic. Never quadratic. And C eta will be here a noise collector, which I will explain in the next couple of slides what the noise collector idea is. Okay, so the noise collector idea is something that we introduce to solve a linear problem with very noisy data. So imagine that we have to solve this linear problem A times chi equals D. chi equals d and our data the clean data are d zero and then we have this vector e that represents the noise and let's assume that our noise is quite high and also our data are incomplete meaning that the number of data is smaller than the number of the unknowns and they are also as i said noisy but we know that what we are seeking to recover is sparse so the sparsity of chi So, the sparsity of chi is important. And the main result is the following. So, we can recover exactly the support of chi by solving this minimization problem. So, instead of solving A chi equals d, we solve a chi plus c eta equals d. And then, among all solutions that verify this linear problem, we choose the one with a minimal age. We choose the one with a minimal LU1 norm, where here we have this linear combination of the norm of chi and the norm of eta with this weight tau that we call the non-quantum of eta. And the matrix C here is what we call the noise collector matrix. And eta is a fictitious unknown that we have introduced into the problem and is here to select, if you want, the columns of the matrix. Columns of the matrix C that will provide a good approximation to our noise vector E. So C times eta is here to absorb E so that A times chi approximates D zero. So as I said, the result is that the support of chi tau is exact when the noise is not too large. So a few So, a few words on the noise collector and how it is constructed. So, the columns of C are chosen independently and at random on the unit sphere so that we can approximate well a typical noise vector. And this weight tau is an order one weight that can be chosen in advance. So, the way that we call it a non-fandom weight, and typically the Quantum weight. And typically, the way that we choose it is that if we try to solve the problem A chi equals E, so there is no D0, we only fit the problem with noise, then we would like our solution to be zero, right? So tau is chosen as the smaller weight that gives the zero solution chi when there is no signal. Okay, and And so it cannot be too large because then we lose some of the signal that gets absorbed in our noise collector. And I didn't give any assumptions. So the main result, the fact that we can recover the support exactly, is obtained under a condition of incoherence in the columns of the matrix A. And also, I said the noise is not too large. So here the scaling for So, here the scaling for the noise is basically square root of n, meaning that as we increase the number of data, of course, the noise can increase as the scaling is square root of n, which is quite typical for these problems. So, let me now just illustrate how this noise collector idea works. And here we will see images like that. So, this is a two-dimensional image. Let's look at the bottom one where it might. The bottom one, where my solution is mainly zero everywhere, except for a few pixels where I have a non-zero solution. And I'm trying to recover the location and the value of the solution by solving a linear problem A x equals data, which are very noisy here. So I have 100% of noise in my data. And when I know that my solution is passed, but because my noise is very high, when I try... My noise is very high when I try to use the classical L1 method, I fail, and this is the result that I get. So it's a very bad reconstruction. And now, when I use this idea of the noise collector, we see that eta, which is, so we have two types of images. This is a two-dimensional image. And on the right, I have a one-dimensional where I vectorize the pixels of the image into this vector unknown. Vector unknown, and I plot the true solution in green and the recovered solution in red. And here we have eta, this auxiliary unknown that we augmented, that we added to the problem that absorbs the noise so that our true solution basically has an exact support. And this is what is very important for me, the exact support of the found solution. Of the found solution. Okay, so how do we use now this noise collector idea for our problem? So, in the first step, we will seek to recover absorbing objects. So, we set as A the incoherent part of the matrix, and we solve A times chi plus C eta equals D. So, recall that in my data, I have both the incoherent contributions and the coherent contributions. The coherent contributions, but we neglect the coherent contributions and focus only in the incoherent in the first part. And these contributions by X cross will be considered noise, and I hope that my noise collector will absorb them. Okay, so looking at my data, which were written here, so this is what we consider signal basically, and all these contributions we consider. And all these contributions we consider noise. We remark that this is independent of S, so we can average the data with respect to the receivers and then obtain the total intensity in this first step. So now just to add an epsilon to the talk. So let's consider that we have M strong absorbers that have amplitude one and n weak absorbers that have And weak absorbers that have amplitude epsilon. So, this is what we call the absorption contrast. And during the first step, we only recover only the strong absorbers, right? Because the strong absorbers will have an order one contribution, and the weak absorbers will have an order epsilon squared contribution. So, we cannot hope to recover the weak. Cannot hope to recover the weak ones during the first step. They will be lost in noise. Okay, so but we assume that in the first step we have recovered the strong absorbers, their support exactly. So in the second step, we will remove the contributions from the data of the strong absorbers that we have already found. And what remains in our data is written here. So this is the incoherent control. Is the incoherent contributions of the weak absorbers. These are coherent contributions of the strong absorbers. So both TK and TK star are strong. That's why it's order one. And then when we have interactions between weak and strong, this will be an order epsilon term. And when we have the current contributions of the weak absorbers, this will be epsilon squared. So in the sense. Epsilon square. So in the second step, we hope to recover the order one and the order epsilon contributions and not the epsilon squared. So what we do in the second step is we fix the strong absorbers that we have already found and we seek its contributions with every other pixel in the image. And that's how we find these two terms. So now assuming that we have found both Now, assuming that we have found both the strong and the weak absorbers, we are done. Or if we want to have a more quantitative reconstruction, we can go into a third step, which is once we know the support of both the weak and the strongs, we can solve, in fact, the full problem now, but only on the support. So instead of having a complexity of k squared, we have a complexity of m plus n squared. Plus n squared, so a complexity that is proportional to the sparsity of our problem square. Okay, so let me show how this works. So this is my setup. I have the source plane, this is my imaging plane where the unknown leaves, and my measurement plane. These are single frequency measurements here corresponding to this wavelength, and I will use many illuminations. Illuminations. So the number of illuminations will be 300, and I obtain them by just sending random illumination patterns from this source plane. And my data are measured here on five times five receivers that measure intensity. Okay, so the first step of the approach, right, recovers the strong absorption. Right, recovers the strong absorbers. So here we have two strong absorbers and two weak ones. So the weak ones are not visible in this two-dimensional version of my unknown. And if you look at this is the one-dimensional version. So the true solution is the green one, the green circle. So you can see that too strong, and if you look carefully, I'm not sure you can see them, but there are too weak in the true solution that can be seen. In the true solution that can be seen. Of course, these are, as I said, the contributions are epsilon squared, so here the ratio is 0, 1. So I think this is 0, 0, 1. We don't really hope to recover the weak absorbers. But we do recover the strong ones. The support is exact, and the amplitude is not exact, but it's quite good. So this is data with no noise, and this is data with 30 dB SNR. So now we recover the strong absorbers and we want to recover, to go to the second step that will allow us to find the coupling of the strong absorbers with every other pixel. So here it is. So we fix the two strong absorbers that we have found and we seek for their coupling with everybody else. So in this picture on the left, I have fixed this absorber. Fix this absorber and I look for its interactions with every other pixel. And that's what I find. And then in this picture, I fix this guy and I look for its interactions with everybody else. So the true number of unknowns is two, which is my strong, times k minus one. And this is what I illustrate here. So with this number of unknowns, which is still linear in k, we recover. Okay, we recover the, you know, we had the strong, and here we recovered the position of the weak anonym. And this is without noise, and this is with a noisy data. And if we look at both the amplitude and the phase of the solution, in this case we have done a pretty good job, so we don't really need to go to the third step. Go to the third step. But this is not always the case. So, here again is a way to look at the results. This is what we call the phase distribution, so the phase of the unknown in the imaging windows. This is something that can be relevant in the applications. And here is a more challenging, let's say, setup for this method where we have. For this method, where we have one strong reflector and nine weak. So 10, the sparsity is equal to 10 in this case. And there is no difficulty in the first step in recovering this strong unknown. You see that even the amplitude seems to be quite well reconstructed. And in the second step, where we fix this unknown, right, we fix a strong one and we seek for its interaction. And we seek for its interactions with everybody else, we do recover the nine-wheel reflectors, but the amplitude is not good. And so, this is an example where it is important to go to the third step where we go on the support and we solve the full problem. And then we recover both the amplitude and the phase of our unknown, which has here a dimension of 100, right? dimension of 100 right is m um 10 square and well the results are are very good okay so let me present my conclusions so we presented a two or three step algorithm for phase retrieval based on a robust dimensionality reduction strategy that we carry out in two steps where we account both for the incoherent the absolute Both for the incoherent, the absorption contrast, and the coherent contribution, the phase contrast in the data. Our algorithm is efficient because its cost is always linear in the number of pixels, and it guarantees the exact recovery if the image is parsed with respect to a given basis. And it may be used, I didn't show the results here, for partially coherent data. And this is important, for example, in phase contrast X. Phase contrast X-ray imaging because, in that case, fully coherent sources are not really available. And here are some references on this work. So, thank you very much for your attention. There is a question for us in the audience? Hi, Melena. Hi, Erisona. This is Melena Espanol. Thanks for watching. This is Melena Espanol. Thanks for a nice talk. I wonder this idea of the noise collector, is it related to that the data is in the frequency domain or can we apply or have you seen it applied to other contexts for problems? I think it's quite general. It doesn't have to be in the frequency domain. It can be used in other contexts. I think it can be used for the noisy or for Noisy, or for independently of where your data live. We haven't used it in the time domain, but I have used it for multi-frequency data. Another question from the audience. And let's take the speaker again. Yes, and let's take the scripture again.