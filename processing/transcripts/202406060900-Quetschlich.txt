So, for those who I haven't really talked yet in this conference, I'm Niels. I'm a PhD student in Munich with Robert Willer, and I'm also currently visiting Olivia School at UBC in Vancouver. And today, I'd like to give you a broad overview about the research efforts we do in Munich for quantum computing. And probably this talk will be a bit different to the talk you have heard before because we are coming from a less theoretical perspective. And also, I try to cover a broad range of topics to show you what we are doing and also maybe to trigger some interest in you. Maybe we can. Trigger some interest in you. Maybe we can apply some of those things also for your problems. So it's rather a broad talk than a deep talk. And I'm happy to have more detailed discussions afterwards if you're interested in that. And also some of our research efforts are more towards the fault tolerant error. Some are also more towards the NISC error. Some of the NIST works can probably also be somehow applied to the fault adjusted to the fault tolerant error, but some probably are also not adjustable to that. Also, not adjustable to that, but I hope that you still find some things of it interesting. So, as a quick motivation, where we are coming from, so our background is more or comes originally from the classical domain. We have many different, very complex classical systems like cars, smartphones, and all of that. And to design those different systems, many design automation workflows have been developed, and many software tools to aid those design flows have been developed. To aid those design tools have been developed because, as you're all aware, like the machines we are using on a daily basis are quite complex, have a lot of components, and we can use them without knowing each and every detail about that. And this was possible partly because of sophisticated design automation methods and software that enabled that. And we think that in the quantum computing realm, we actually have similarities here because we also need to simulate, we also have compilers and all of that. Compilers and all of that, and of course, there have been already initial solutions to basically do the same thing we did for classic or similar things we did in classical notes in the quantum realm. But we think that the full design automation expertise from the classical systems has not fully exploited yet in quantum. And our main motivation is to not end up in a situation where we have powerful devices, but no really means and tools to use or design respective systems for them. And also to, yeah. And also to use them actually. And what we try is now in our group to utilize these design automation techniques and apply them through certain problems in quantum computing and along different layers of the quantum computing stack. And all these research activities are covered under the umbrella of the so-called Munich Quantum Toolkit. And as I said, I want to give you some examples. What we did in the past before, I will give you the whole picture, what levels we were. The whole picture, what levels we are working on. And these are actually starting on the kind of application side where we try to develop workflows. Can you remove that high bar? Oh, good. So I'm not sure what that means. Is it this in the... Ah, this one, maybe? Yeah. Is it better now? Do we get some feedback? If there is anything, I will let you know. Sorry. No worries. Thank you. Thank you. Okay. So, yeah, application application will try to develop some tools to make it easier for people to use quantum computers because we think that in the future, not everyone who uses quantum computers should be necessarily a quantum computing expert because other people should be able to use it as well without knowing all details similar as it is for classical devices and things. But we also worked on simulation, compilation, verification, and as I said, also error correction. And as I said, also error correction, and also have some initial works on hardware design and all of that. It's based on efficient data structures and what we call core methods, which are the same diagrams, which I also will be explaining soon in this talk, Tensor Networks, but also ZX calculus, sub-servers. And we do not only want to publish our, of course, our research work, we also want to provide all our tools open source, available, and also as easy to use software tools. And this is what. To use software tools, and this is what we usually do as Python packages. I will show you some examples for that later on. And wherever it is very important that the efficiency is, wherever the efficiency is very important, we implement our software in C ‚Åá  and then provide Python bindings to make it accessible to also get some better performance out of it. Okay, so let's start with the application side. So, in a very simplistic way, I will show you how currently problems. I will show you how currently problems are solved on quantum computers. Very sure you all know this. Let's start with whatever problem we have. This specific example doesn't really matter what it is. We first usually have to select some kind of algorithm that is in general capable of solving that problem. Then we need to take the problem and the algorithm and derive some kind of quantum circuit out of it. We need to execute this quantum circuit, getting a histogram, and then decode the histogram to get the actual solution. To get the actual solution, and I know this is a very simplistic view, but it roughly covers what is necessary. But actually, these steps are quite tedious and error-prone, and I'm very sure many of you have also experienced that. You can make easily some mistakes and get garbage results out of it. And this is why we think that in the future, not every user should do these steps by themselves, but there should be some automation support because we think that many of those steps can actually be automated, and the long-term wish. And the long-term vision is that we, at some point, have some kind of black box approach where you can insert for a specific kind of problem using classical interfaces as they are used right now. All those quantum parts highlighted here in red are automated and implemented by quantum software tools developers like us. And then again, a classical solution is returned such that people can use this quantum solver in a black. Use this quantum solver in a black box fashion. You have a classical input as classical solvers currently provide. You have a classical output, and then you can just use it as a drop-in replacement. And of course, we are not there yet. We all know that, but this is what we are aiming for on the application side. And one step is why we are not there yet, of course, is the execution part, because currently we have the NIST devices, we have simulators, and these do not really fit to the error correction realm. Error correction realm. But one alternative, even to do something right now from the application side, is to extend this workflow using resource estimation. And this obviously does not give us any kind of results so far, but it already gives us some kind of resource estimate, what would be necessary to run a certain application concerning a certain error correction scheme and certain hardware characteristics. And this can then be used to get at least some kind of temporal perspective: how many qubits I will need and how. How many qubits I will need, and whether it's more realistic, like in one to five, ten or twenty years. Furthermore, the resource estimation allows us to create some kind of feedback loop because you can already try around with different encoding parameters, because usually one problem cannot only solve in one way, but in different ways. And using resource estimation, we can already explore how this will propagate to the estimates and aim for a lower bound or lower number of resources necessary. And lastly, we can also incorporate some prognosis about how the hardware might develop. Prognosis about how the hardware might develop and see: well, if our error rate like improves by 10%, how does it affect the overall result? How does it propagate? Because it's often due to the fault tolerant compilation steps, not one-to-one as you would expect. So, this is one example of what we do on the application side. As I said, I want to cover different things. So, it gives you a good overview. Next thing I would like to talk about is simulation, and we do quantum simulation using precision diagram. Simulation using decision diagrams. And probably many of you haven't really heard or know what decision diagrams are. So I want to give you a quick overview of what decision diagrams are. They are a data structure to represent quantum states and quantum operations. And how does it look like? It's a graph structure where the nodes are the respective quantum qubits. And to create such a structure for this three-qubit example, you can see here all different amplitude values. Different amplitude values. And you first start, sorry, with the create a node in this graph structure for leftmost qubit. And this leftmost qubit, let's call it Q2 here, can then be either zero, as you can see here, all remaining four entries, this leftmost qubit is zero, or one on the other side. And you can do this over and over again until you end up with one specific amplitude value at the leaf node. Value at the leaf node. And if you want to get out, for example, now, or want to check now the amplitude of this alpha 010 state, you have to go to the left, left apps always the zero, indicates the zero, right, the one, and left again for the zero. And here we do not see any benefit yet because we have still the exponential structure space, but what we're aiming for is a less than exponential structure space. And how do we do that? We try to. And how do we do that? We try to use certain effects or certain characteristics of this structure. So let's have a look at a concrete example here. If we want to represent this quantum state, we can already see that in this case, many entries lead to zero amplitude. So we can use the sparsity here and reduce our structure. Then we can see on the right side that the two sub-structures below the Q0 are the same, so we can also. Zero are the same, so we can also reduce those to one node, to one path. Basically, here you can see that it's not the same value, same amplitude value, but the same factor. So, we can use those factors as edge rates and also reduce it further. And also, lastly, we need to normalize our data structure because we want it to be canonically such that each and every condom state results in the same decision diagram structure, independent, for example, what kind. Diagram structure independent, for example, what kind of quantum circuit led to this quantum state. So we want to have it canonically. So, can you see this as a generalized matrix product state in the sense? So, I must say this is not my rec process, so I cannot give you too much details, but there are correlations to the matrix product state simulation. But I cannot really tell you how it relates. But if you're interested, I can send you a link to the paper later on. And what we now do with this structure is that we can use it also to represent matrices. That we can use it also to represent matrices, and then since we can represent matrices and the quantum states, we can use it to apply these quantum operators on the state to get some kind of quantum simulator. And we can also sample from this. And this quantum simulator is what we call MQTDDSIM. And I want to show you, since I said that we also want to make our software accessible, how you could actually use it right now. So when you have some kind of circuit that you want to simulate, you can just You want to simulate, you can just import our software package and provide it in this case the VSIM also as a Qiskit backend, you can just replace whatever simulator you were using before by the DSM simulator and run it in the same fashion as before. Okay, this was the simulation part and the decision diagram part. And yeah, we did many things with the decision diagrams, applied in many different cases, also approximate simulation, for example, Hamiltonian simulation, and yeah, got. And yeah, got some results over there. The next thing I would like to talk about is compilation. And this is something we did now for NISC devices. But I think this is also what we talked two days earlier, where this might be adjustable, that it also fits back to the fault-tolerant population. Yeah, when I say compilation, what do I mean by that? From a user's perspective, again, we have some kind of logical quantum circuit and want to choose a quantum device and execute it on it in the best way possible. It in the best way possible to get the best results out of it. And we consider this a two-step approach. First, we need to select some kind of device. And currently, already there are many different devices available. It will only increase in the future. And then, whenever we have selected some kind of device, we need to compile it accordingly such that all constraints are. Such that all constraints are considered. So, for example, or not, for example, so the native gates are considered. So, the circuit only contains native gates of that quantum device, and also connectivity constraints should be considered. And this minds are trivial, but actually is more complicated than it at first appears, because we've modeled as a multi-step process. We're starting on the left side, the right quantum circuit does not satisfy the native gates constraints and the topology, so the connectivity. So, the connectivity, we can apply some synthesis compilation passes to make sure that we only have native gates that we need to map it to the topology that also that is fulfilled whenever our quantum circuit is in this kind of state, but it's executable. But also, we have many different optimalization actions that might preserve the current state, but might also not consider related gains of topology that has been already considered so far. And when connecting. And when connecting those two, this is what the user has to basically decide when to compile a quantum circuit. And I would like to give you some details about the, especially compilation part, because I think this is something that could be translated to the fault tolerant domain as well. So what is actually the problem? Why we are not happy with the current, or we are not happy with the current state. So currently, whenever someone wants to compile a quantum circuit, they usually use whatever. They usually use whatever compiler they like, run Qiski.transpile or whatever compiler they use, and get some result out of it. But actually, from a user's perspective, the compiler use is usually not what people are, from an application point of view, not interested in. What they're interested in is to get the best result outcome. And the hypothesis is that some compilers might be better at synthesizing, some compilers might be better at mapping. So it would be nice to combine those compilers in an easy fashion that you're synthesizing. Those compilers in an easy fashion that you're synthesized with compiler A, map with compiler B, and each compiler does what it is best at. And by considering the compilation on this kind of level, on the compilation path level, we can combine compilation passes from different compilers and using, and then we're using reinforcement learning to learn when what compilation path should be applied and is most promising. And for that, we need three things. We need some training circuits, we need some kind of device. We need some kind of device information, what we are compiling for, and we need some figure of merit. And figure of merit is our optimization criterion in this case. So, this is what the reinforcement learning agent is trained for to optimize. And in this case, we use something called expected fidelity, which is some kind of, let's say, proxy for the actual fidelity without executing it based on a rather simple noise model of the device. But it could be anything, could be some kind of gate con functionality, could be death, could be anything. And this is also why it does. Anything. And this is also why it does not really matter in this case what it is, but the important thing is that you can configure it to whatever you want it to optimize for. And what we get out of it is then a trait reinforcement learning model that can take a quantum circuit and can compile it for that specific figure of merit on that specifically chosen device. And this is what we embedded in the overall workflow. Has yeah, for the compilation part, we did something similar for the device selection, but I won't go into detail here because I think it's not so. Go into detail here because I think it's not so interesting for you, probably. And yeah, what you get out of that is like a black box too for people who can just throw in the logical quantum circuit and get some recommendation what device to use and how and a compiled, optimized, compiled circuit for that based on the reinforcement learning model. And yeah, okay. It's also easy to use. I will just skip that. It's also just like one Python line. Yes, please. I'm just curious, how many different How many different compilers and compilation passes are you considering that you need in order to compilate? Currently, we consider compilation passes from Qiskit, Tickit, and Biskit. And the overall all number was something, I think it was around 20 roughly. We also did some other compilation works, for example, also synthesis optimization for Clifford circuits and also compilation for qubits, and some more things here. Here. One big last point I want to area I want to mention is verification. We also did some work there, but verification is in our case a bit different than the formal verification approaches we have seen in the last days. What we call verification, or what we consider verification, is to compare whether two quantum circuits are actually still representing the same functionality, for example, after a compilation process to make sure that your compilation did what it was supposed to do and didn't introduce any kind of mistake. Introduce any kind of mistakes or anything like that. And conceptually, it is rather easy to compare whether two quantum circuits are equivalent because you can just build the unitary for the circuit and compare those. But as you know, the exponential size here is a large problem. So this might not be a scalable approach. Something else you could do is creating the decision diagrams for both quantum circuits. And since it's canonical representation, if those decision diagrams are equal, those Decision diagrams are equal, those circuits are equal. This works, but it's also not really optimal because the decision diagrams in the worst case are still exponential in size, only in certain cases it reduces to a better structure, or to a smaller structure in that case. So worst case, this is still ugly. But you could do it. Second thing you could do is, yeah, so if they're equal, it means those sectors are equivalent. Meets the both sex are equivalent. Another thing you could do is inverting one circuit and multiplying it or applying the other one to get the identity matrix out of it. Well, still unfortunate because you still need to construct a complete decision diagram for at least one circuit. And another approach that we also have explored is starting with the decision diagram of the yeah, for the initial. The initial identity matrix, and then apply operations from the right side and from the left side from both circuits in an alternating padding. So you take the C not gate from the right side, take it from the left side, and since those circuits should ideally be somehow related, the idea is that you always increase complexity and size of the system diagram, but then reduce it immediately because you apply the operation from the other side. And you do this in an alternative. You do, yeah, you do this in an alternating fashion, one from the right side, mainly from the left side, in this case, because you can also consider some or you can utilize some background knowledge of the compilation process. And then hopefully you end up with a decision tree that again represents the identity matrix. And then, if it works out, you know that your circuits are equivalent. And also, this is a tool that's provided as a software package that's easy to use. That's provided as a software package, easy to use. Won't go into details again, one line of code. Yes, please. Do you have any make statements about the speed at which that one by one reduction happens? Yes. And how that compares to this transaction? Yeah, we do. So again, also, this is not what I personally work on, but it can give you some repetition. So we have all those numbers, of course, in our papers there. But also, in many, many cases, it's really, really fast, like below one second. Really, really fast, like below one second. In some cases, it is also takes some time, like a few seconds, some cases also doesn't really work well. But it's also not a direct correlation with the size of the quantum circuit. It's more about the structure of the quantum circuit, whether it works very fast or not so fast. So it's hard to say whether now it scales up to like, I don't know, 80 qubits or 100 qubits or 20 qubits, but it's more about the structure itself and the specific examples you investigate. Yeah. So when you say structure, do you mean like recursive structure? Recursive structure, yeah, redundancy basically, whether you have like similar, similar gates, similar structures, similar amplitudes there. Maybe you said this already. Does that the thing that you showed on the previous slide? Does that work for cases in which you have an LED C circuit as well? Yep. And we often use it to verify that compilation processes still do what we intended them to do. And as a method to also find bugs in quantum source code. Last year, I want to, yeah, we did. Last year, I want to, yeah, we did various approaches also using ZX, of course. And two last short things I want to mention is that we also have some initial works in the quantum error correction domain. So colleagues of mine implemented some decoding algorithms for QLDPC codes, also work on state preparation, and also on some kind of automated tools to apply error correction schemes to quantum circuits. And the very last thing I'd like to mention is our efforts in the terms of benchmarking, since this was also a topic. Of benchmarking, since this was also a topic a few days earlier, and we also provide a software tool here-a benchmark library called MTT Bench. But the goal for us is not to benchmark any kind of devices to give any kind of performance indicators. Our goal is to provide some benchmark circuits for people who develop quantum software tools that they can benchmark their software tools to make it easier to get comparable evaluations, get good circuits to use to evaluate quantum software tools. And for that, Tools and for that, we have um it's it also comes with a Python package, but also as a website where you can just click and collect your benchmarks you want to download. So in this case, it's right as CASM files from the website. You can specify the number of qubits you want to have for your benchmarks, and it supplies many of the currently used algorithms. And the idea was also to have the same benchmarks on different levels of abstraction since we were. Levels of abstraction since we work a lot on compilation tasks. We like to have them also on a hardware-dependent level where it may be mapped to a certain architecture, but we provide them as well on a target-independent level and also using or compiled with different compilers and different devices and optimization levels, depending on what user might find interesting to benchmark their software tools. So, again, it is meant as a tool to support other people developing software tools doing their actual benchmarks by deriving some kind of current. By deriving some kind of performance metrics, we just want to provide an easy fashion or easy means to download suitable test cases for that. And this brings me already to the summary of my presentation today. I hope you found some of that interesting. So, trying to cover different aspects here. As I said, some are more nisky than others. And with that, I'd like to end my presentation. Thanks a lot.