Yeah, so thanks for organizing this nice workshop. I wish I could see you all in person, but this is better than not seeing anyone. Yeah, so I'll be talking about this joint work with Felipe Rencan and Cynthia Vinzen. It's already a couple of years old, but it fits well with the topics of this workshop. So you already heard from Cynthia yesterday, and Felipe is in London. Is in London. So let me remind you quickly what our hyperbolic and stable polynomials are. They've already shown it a few times at the workshop, but so that everyone is on the same page. So a homogeneous polynomial is called hyperbolic with respect to a point. If it doesn't vanish at the point and every line through the point meet the hypersurface defined by your polynomial only at real points. Yeah, so in other words, algebraically, you know, you can think of it as you sort of parametrize the line and then you get a univariate polynomial, and the polynomial has only a root. So in this picture, you know, this is a, so on the left, this is a hypersurface of a hyperbolic polynomial. So if you take a point E, like in the middle, in the middle region, right? And then you put a line through it, then it intersects my hypersurface only at real point. Points that you can see in the picture. A real point, points that you can see in the picture, right? Because we're not drawing the complex points, right? So the same here. So if I put E inside, and then if you put a line through it, it's going to pierce through all these layers, right? So say something that is not hyperbolic would be like if a degree four curve looks something like this, right? So something like four plus, right, one of the four equals zero to four, I think, right? So if a degree four curve looks something like this, and then if you pick some E in here, right, it will. E in here, right, it will intersect my hypersurface only at two points instead of four points in the rear picture. So this is not hyperbolic. Say, yeah. Okay, so a bunch of examples that you have seen them. So, you know, it's easy to check the product of variables, it's hyperbolic with respect to one vector or any point in the positive orthodox. And then taking directional derivatives in In direction E preserve hyperbolicity. So it's essentially the mean value theorem because between every two points, you know, that must be the derivative must have a root. So using this, by taking this and taking derivatives, you get the elementary symmetric functions hyperbolic. And so more generalization. So this shows up earlier in the workshop as well. So if you have a symmetric matrix of variable, then the determinant is hyperbolic with respect to the item. Determinant is hyperbolic with respect to the identity matrix because this polynomial, right? So, this is whose roots are negatives of the eigenvalues, is real-rooted because symmetric polynomials are real eigenvalues. And then, so I think maybe this one is a very important one. If you have a symmetric matrix and then you take, then this is a matrix, symmetric matrix whose entries are linear forms, then its determinant is hyperbolic. So, similar is related to the third example. Example and also by the matrix tree theorem, the spanning tree or spanning forest generating function of a graph is hyperbolic. So some quick examples. So a related set of polynomials is stable polynomial. So the definition looks a little bit different if you have never seen it before. A polynomial with complex coefficient is called stable if you take any root, if you take any root of the polynomial. So z is. So Z is C has n components. So Z is a vector in C to be n. So if you take any root, any zero of the polynomial, the imaginary part is not in the positive of them. So this is defined in terms of imaginary projection, right? So as in Torsten's talk. Imaginary projection. So stable polynomial is defined in terms of imaginary projection and this hyperbolicity. So this hyperbolic. And this hyperbolic city, so this hyperbolic polynomials are defined in terms of this like PSN with a with a cutting with a linear space, right? So, right here, what you should think of it is the hyperbolic polynomials come in layers, right? The real part comes in layers, and then stable polynomials are defined in terms of the imaginary projection. So, you can check that if f is univariate with real coefficients, then you know not having roots in the upper half plane also means not having roots in the lower half plane because roots come in. Hot flames because roots come in complex conjugate pairs, so stable means rearbooted, and and also one can show by sort of you can you can sort of rewrite this as um rewrite this algebraically, this condition algebraically, and it is easy to see that homogeneous real polynomial is stable if and only if it is hyperbolic with respect to every point in the positive process. So, so being stable is a very, very special type of hyperbolicity. Hyperbolicity. Okay, and then stable polynomials are also Lorentzian or strongly log concave, as you saw in Petra and Cynthia's talks. Okay. So yeah, this, you have seen this in Petra's talk as well. So the stable polynomials are very special Newton polytopes. They are not Newton polytope is a convex hull of the exponents that show up in a polynomial, right? Newton polytope of some. Of so a theorem of Cho, Oxley, Salka, and Wagner from 2004 says a Newton polytope of a homogeneous multi-affine. Multi-affine means the exponents are just zeros and ones. You don't have two or higher. So homogeneous multi-affine stable polynomial is a matrix based polytope. So another characterization of matrix-based polytope is that it is a zero, one polytope whose vertices have coordinate zeros and ones, and then the edges are in direction Ci minus. Then the edges are in direction Ci minus EJ. So edges are parallel to the edges of the standard simplex. Okay, so this is a matrix-based polytope. And then Brendan generalized this to drop the word multi-alphine, right? So if you drop the worm multi-alphine, you've got a polytope of a homogeneous stable polynomial. It's a generalized permutahedra. So it is then, if you drop the word multi-alphine, you just drop 0, 1. Okay, so these are polytopes whose edges I Are polytopes whose edges are in directions En minus Ej. So these are generalized permutohedrons. So on the right, I have a picture of a permutohedron. A permutohedron is a polytope obtained by you take the factor 1, 2, 3, 4, 1, 2, 3, up to n, and then you look at all the n factorial permutations and take the complex form that is a permutohedron. So it is called a generalized permutohedron because these are precisely the polynomials that you get by taking. That you get by taking starting from the permutohedron and then moving the facets in and out without changing the edge directions. So, that is the work of Posnikov. So, the point is that these stable polynomials have very, very special Newton polytopes. They're extremely special Newton polytopes. And then, FATA also give them even more generally, if your polynomial. If your polynomial has coefficients with valuations, then the valuations of the coefficients form an M-convex function on its support, on its monomial support. So what does it mean to be M-convex? It means that it is convex, meaning that it can be extended to a convex function, and it induces a subdivision that has edges in direction EI minus EJ. So it is equivalent to M convexity. And then you saw in Petra's talk that we also get. That we also get jump systems if f is not homogeneous. Systems are a little more complicated, so we will not get into we'll get back to m complexity later, right? So, maybe just to understand and digest it a little bit more, you know, just going back to this example, right? Here, Newton polytope is just a point, so it's not interesting, right? But elementary symmetric function, right, the Newton polytopes are these Newton, let me write it. Newton, let me write it. So for the elementary symmetric function, right? New term polytopes. What is called the blanking on the word? The hypersimplices. So these are called hypersymplices. Okay, so these are, you know, delta Kn is the convex hull of all the zero, one vectors with exactly k ones, and the rest are zeros. And these are exactly a matrix base. Matri-based polytopes of a uniform matrix ukn. So this you also saw in Mario's talk yesterday. And then maybe let me just point out this last example, you know, spending tree spending forest generating function of a graph. So in this case, by essentially by definition, right, Newton polytope is equal to the Newton. Is equal to the natri-base polytope of a graphene natrix. Sorry, what do you mean when you say hyperbolic without any direction? Oh, okay. Yeah, no, no, it's respect to something. Yeah, that's right. I am missing. Yes. Okay, thank you. It should be, yeah, respect to all one vectors, I think. All one back to us, I think. Thank you. Yeah, even the positive authentic. Sorry, because it is in fact stable with respect to every point in the positive. Yeah, thanks for asking. So, okay, so far, this is our review so far. Any questions? Any other questions? Um, any questions? Any other questions? I don't know if I can see the chat. If anybody has a question in the chat, maybe I will let you know if there are questions. Yeah, I don't know what the chat want. Okay. All right. So far, I hope you know these are something that you have seen earlier in this workshop. So right now, this is somewhat new. So the point of this talk is we want to go from polynomials to varieties or. From polynomials to varieties or ideals, right? So instead of looking at one polynomial and one hypersurface, we want to look at variety, meaning like higher co-dimensional geometric object, or you want to look at ideas. So this is not something that we invented. So it was introduced by Shamovich and Vinnikov in 2014. Okay, so let me read this. Let X be an equidimensional algebraic variety. Dimensional algebraic variety. So, equidimensional means all the irreducible components have the same dimension, right? And then it has a coordination C in the complex projective space. And then let V be a linear subspace whose dimension is C minus one. If this were not minus one, if this was C, right, then that means that they will intersect. So, you know, coordination C variety and dimension C linear space will intersect. And dimensions in linear space will intersect, but we're looking at linear spaces one dimension lower, so it does not intersect x. I mean, it could, but we choose one that does not intersect x. So in the previous case, so for the stable polynomial case, like before, we're looking at the case when c is equal to one, right? We're looking at one polynomial at a time. So when x is a hypersurface, so only c is equal to one. Okay, so the shamovich and Vinnikov. So, the Shamovich and Vinnikov define a hyperbolic variety. So, we say that a variety is hyperbolic with respect to this linear space. Before we had respect to a point, but now we have respect to a linear space. If every C-dimensional linear space, the intersection consists only of real points. So, for example, if I take my X as a twisted qubit, so I can take my V, right. V, right, maybe the line like that. Okay, so to check for hyperbolicity, you know, you look at all the planes that contain my fixed line, right? So you look at all the planes that contain my fixed line. All these planes should intersect my curve only at real points. So another way to check this is Way to check this is another way to check this is after linearly projecting V to a point, the image is hyperbolic with respect to the image of V. So another way to look at this is you take this picture and then you project it so that my V right here becomes a point, right? So this is the image of V, and then my image of X go around like this. Like this, and then you can see that you know it is hyperbolic because this is a degree three curve, and then if I put any line through image of V, right, I have I intersect my curve in three points. Yeah, so this is sort of a natural generalization of hyperbolicity from hypersurface to higher coordination. Any questions? Josephine, the set of Vs. The set of V's from which you can be hyperbolic, does that have an extra structure like the analog of being convex? Oh, yeah, so they proves, yeah, that is an excellent question. So, I think Mauricio, yeah, so the question says, you know, so do the set of V such that X is hyperbolic with respect to V, right? So, is it convex or something like that? So, there is some kind of convexity, but I think that is a Of complexity, but I think there is a lot of open, um, open questions. So, this is um, I think not much is known. So, there is some kind of very weak convexity. So, Shamovich and Vinnikov's there exists some pretty weak convexity. So, so over there, I mean, what does it even mean to be convex, right? So, you, you know, because Vs live in a subtle linear spaces, so you know, they live in a Setolinear spaces, so you know, they live in a Grassmannian. So, what does it mean for a subset of Grassmannian to become vexed? So, I think maybe people are saying things in the chat as well, right? So, yeah. I think not too much is known, I think. So, it can be bad. I think Chris said that it can be disconnected and Mario said yes. I think yes, to convex, like, oh no, or yes, to disconnect it. I don't know. Yeah. Disconnected. I don't know. Yeah. So it can be bad, but there exists some with convexity. I think something like, you know, because you're looking at linear spaces, I think you use maybe like fix if you if you have a two linear space, if you, well, okay, if you fix if you fix a spanning set of the linear space and if you just move one of the vectors, I think, like if you just take if you if you have two two such matrices, if I'm thinking of two such matrices and If I'm thinking of two such matrices and they're all the same, but only one row is off, and then you take the convex hole, I think that is okay. So, convex in this very weak sense. Yeah. So, so I think in general, I think structure of this subset of the Grassmannian is, I think, not too much. Some things are not. So, yeah, so please read Mario's comment. Okay, let me just read. Okay, let me just read it. So, yes to both. I think yes. So, there is some kind of convexity and it can be disconnected. So, Maria said if X is a curve, then the stat is the intersection of the Grassmannian with the convex cone. So, I think, yeah, so whether this is true for higher dimensional X, I think is an open question. Thank you, Josephine. Thanks for the question. Okay, so these are hyperbolic with respect to a linear space. And as you recall, you know, stable polynomials are those with hyperbolic with respect to the positive orthan. And what is the analog of the positive orthan? So we're going to take analog of a positive orthan as positive linear spaces. So yeah, so let's recall that a polynomial is stable, right? If it is, well, okay, we can define. We can define it two ways. One way is that it is hyperbolic with respect to positive lines. And then another way is that it's imaginary through imaginary projection. It's imaginary projection of the roots is not in the positive, in the positive directions. So we're going to define a variety of core dimensions C to be positively hyperbolic by looking at imaginary projection. So if you take any points in your variety and if you look at the imaginary In your variety, and if you look at the imaginary projection, the imaginary projection is not in any positive linear space of dimension c, unless it is zero. Zero is okay, but imaginary projection can be zero. So, what is a positive linear space? A positive linear space is one span by a row span of a matrix, right? Where the span is a matrix and all such that all maximal All maximal minors of A are positive. Similarly, one can define non-negative linear spaces as a Rose-Manner matrix whose maximum minus are non-negative. So yeah, so recall that for hypersurfaces, positive hyperbolic means defined by a stable polynomial. For projective variety, positive hyperbolic, so the Hyperbolic. So, so this was proven by Mario and Cynthia. Positively hyperbolic means that it is hyperbolic with respect to every positive linear space of dimension C, C minus one. So it's a slightly like two different ways to define it, right? So, you know, our definition is that you look at the one way is you can look at imaginary projection, right? And another way is hyperbolic with respect to a linear space as in Shaman. To a linear space, as in Shaman Pitch and Vinny Coffee. They're equivalent. It's not too hard to show that they're equivalent. Like in the stable polynomial, that's sort of two slightly different ways to define it. Any questions about the definition? So we have two definitions. One way is we look at imaginary projection. Another way is you sort of, you know, with respect to positive linear spaces, you stick in a positive linear spaces and you sort of look at sort of this like oscillating lane sort of thing. Okay, so over here, you know, if you it becomes, you know, what we wanted to, it becomes necessary for us to get a handle on, you know, how to characterize points in a positive linear spaces of dimension C. So, if you want to do any examples or anything like that, so how do we characterize points in a positive linear space of dimensions C? So, like See, so luckily for us, this has been known since the 1950s. And this was also, we learned this from Lauren Williams and her student, Stephen Kirk. Okay, so this is a very nice theorem that tells us exactly when a point is in a positive linear space. So you look at a real vector, and then you look at a C, and then there exists a positive linear space of dimension C containing the point, if and only if this sign variable. This sign variation thing var bar is less than c. Well, okay, let's see what a var bar is. So, sign variation means that it's the number of sign changes where zeros are assigned signs that maximize the number of sign changes. So, what you do is you read from left to right and you see how many sign changes are there. You go from minus to plus and here, plus to minus. And then, whenever you see zero, you try to assign on, you try to assign signs, right? So that you know that. Right, so that you know they are to maximize the number of sign changes. So, right here, you can see that no matter what you do, right, you cannot get more than two sign changes in between. So, for example, you can assign minus plus or minus minus or plus minus. No matter what you do, you pick up two more sign changes. So, that means the vol bar is four. Yes, so that is a very easy and useful criterion to test. For criterion to test whether a point is in a positive linear space of dimension C. And there is a similar, um, similar characterization for non-negative linear space. In that case, it's even easier. Instead of var bar, you look at the sign variation bar. So this is one, whenever you have the zero, you just ignore it, like you just pretend like they don't even exist. So that means that here the number of sign changes is just two. So from here, you can see that. So, from here, you can see that an immediate corollary is that a variety of coordination C is positively hyperbolic if and only if, if you look at all the points in your variety, the sign variation var bar of the imaginary part is at least C. So, positive hyperbolicity is determined by the imaginary projection. I mean, we already knew that, but here in particular, positive hyperbolicity means that imaginary projection is. It means that imaginary projection is contained in a union of authents, union of special authents corresponding to high enough sign variations. So using this, we can characterize the very first case of higher coordination of varieties are linear spaces. So we can say that a linear subspace is positively hyperblock. linear subspace is positively hyperbolic if and only if it is defined over r and its orthogonal complement is non-negative right so positively hyperbolic linear spaces are exactly orthogonal complements of non-negative linear spaces right so let me introduce some a metric so a metrite terminology so a positrite is a special a special type of meat right a positrite is a is a mate positri is a is a matri who's represented by rows of a matrix, rows of a matrix A I'm sorry, columns of a matrix A okay I guess it doesn't matter okay I think of I think of columns okay so it is uh represented by columns of a matrix A whose maximal Maximal minus or non-negative. That is a positive. It's a representation as a columns of a non-negative matrix. So we know that there is a theorem of Dila Williams and Rain Kahn that says the dual of a positron is a positrite. That is not obvious at all, actually, right? So if a matrix is represented by a non-negative matrix, you know, so. Matrix, you know, so if you if you just take the Gale dual, you don't get a non-negative matrix, but they tell you that there is a different representation, not with the Gale dual, a different representation that is non-negative. So using this, right, so we see that we see the matrix of a positively hyperbolic linear space, matrix of a positively hyperbolic linear space is a part of, right, using the fact that dual of a positive track is a part of. Okay, so you can think of like, so Okay, so you can think of like sort of you can think of positively hyperbolic variety as a common generalization of a stable polynomials and orthogonal complements of non-negative linear space. So they're pretty nice, right? So in the po-dimension one case, right, you get stable polynomials, and then in the linear space, you get orthogonal complements of non-negative linear spaces. So these are things that people are interested in. So our goal was to. So, our goal was to, this is our starting point of our collaboration: we want to answer this vague question: do positively hyperbolic varieties have a nice combinatorial structure? We know that in the hypersurface case, hyper surface case, you get a single polynomial. So, combinatorial structure of a single polynomial is given by a Newton polytope. And we know that the Newton polytope is a generalized permutaphi. So, it has a So it has a very nice combinatorial structure. In a linear case, what is the combinatorial of a linear space? You know, one way to get combinatories of a linear space is its matrix. What I mean is that if your linear space is row space of a matrix A, then the matri of the linear space is given by columns of A. You have a linear independence among the columns of A. That doesn't depend on the choice of A. So you can think of L as the, you can think of, yeah, you can think of the orthogonal complements of L as the, as the, as the dependencies among the matrix. So in linear case, the matrix opposite, right? So which is a very nice combinatorial structure. And then also you combining. Also, combining these, we also know that the algebraic matrix of an irreducible positively hyperbolic variety is again a positri, because a tangent space, a real smooth point of a positively hyperbolic variety is again positively hyperbolic. So what is an algebraic matrix? So an algebraic matrix is a matrix whose rank. So if you have a variety, if it is a variety x, you can define a rank of a matrix by Rank of a matrix by rank of a subset of coordinates is equal to the dimension of the projection of my variety onto these coordinates. So whenever you have an irreducible variety, you can define something called an algebraic matrix. In this positively hyperbolic case, the algebraic matrix is also a positric. So you can see that we already see your nice combinatorial structure. On one hand, we have this generalized dametohedron, sort of matrix-like thing. On the other hand, Like thing. On the other hand, we have these positrites, right? So it should have a nice combinatorial structure that combine both of these, both of these stories. So how do we see a combinatorial structure of a variety? So one way to find combinatorial structure of a variety is to look at the tropicalization. So tropicalization is a process that takes an algebraic variety and turns it into a polyhedral complex. turns it into a polyhedral complex. So one way to do this is you have an algebraic variety and then you take the log limit set. So what you do is you take points in your variety, you take the complex absolute value, you take the log base t, and you send t goes to infinity. And then so another way to do that, this equal is not obvious at all, is in terms of our Gravna theory. So it's the same as all the weight vectors W. Or the weight factors w such that the initial ideal of the idea defined in x does not contain a number. So let me quickly draw a picture. So if x is given by, given by a polynomial, one plus x plus y to zero, right, so this is my x. And then if you take the, if you take the absolute value, right, you get some things like this. This is absolute value. Things like this. This is absolute value, and you take the log. Okay, so then you get the amoeba. And then if you take the limit, you end up with a polyhedral complex. And then in this case, if you look at the Newton polytope, Newton polytope of this polynomial is one. This polynomial is 1 plus x plus y, and then you see that these relationship between the neutron polytope and the tropical hypersurface. So very important cases, if you have a hypersurface, then tropical variety is the normal count to the edges of the neutron polytope, like in this case, right? So these are normal vectors to the edges. They give you the tropical variety. And then if you have a linear space, And then, if you have a linear space, tropicalization is something called the background span of the matrix. So, in other words, tropicalization finds the matrix for you, find the combinatorial structure of the linear space for you. If you tropicalize a tori variety of a matrix A, sort of Stonfalzian Torre variety, right, parameterized by monomials in A, then you get raw space of A. And then, if you tropical like positively hyperbolic variety, we should get a polyhedral complex where. A polyhedral complex with some kind of matrixal structure. This is what we wanted to prove. Okay, so here's the main theorem. I think, for the interest of time, I'm going to zoom into the homogeneous case. So maybe ignore the first point. Okay, so if x is a homogeneous positively hyperbolic variety, so defined by homogeneous polynomial, then the linear space parallel to any maximal phase of a tropical variety is spanned by 0, 1 vectors whose supports are disjoint. Who supports a disjoint and non-crossing? So this disjoint, in other words, locally, tropical variety is a subfan of the type A arrangement given by Xi equal Xj. So with the extra condition of non-crossing, non-crossing means if you look at, you know, say like, say the set one, two, three, four, let's say three, four, five. Four, let's say three, four, five, and non-crossing. Because if you put things around a cyclic order, here is one, two, and here is three, four, five, they don't cross. So this is non-crossing. But say one, three and two, four, five is not non-crossing because you have one, three with the set right here, and two, four, five like this. So this. So, this is not non-crossing. Okay, so the non-crossing depends on the cyclic order of your coordinates, and which is expected in the theory of positrites. The cyclic order is very important. So, we always fix an ordering of the variables. Yeah, so any questions about the main theorem? So, this tells you locally what the tropical variety looks like. Okay, so this is about local. So, this is about the local structure of a tropical variety. So, locally, tropical variety has to be subfan of the type A arrangement, and it has to have this non-crossing property. So, this, yeah, so this, so some corollaries, right? For the, for the case of a, you know, for the case of a homogeneous multi-affine stable polynomial, right? So, if you look at the So, if you look at the pipeless surface, then we know that the sub of the type A arrangement xi equals xj, that means that because these hyperplanes are perpendicular to edges of a neutron polytro, that means that we've got the theorem, the edges are in minus each. So we recover the results of our socket into. In 2004, similarly, you know, there's any multi-finance recover the results of Blenden about Newton polytope being generalized on hetohedron for any homogeneous stable polymer. Right. And moreover, yeah, so this is a new, so Bagman fan of a positron. So we've got this like non-crossing condition about the Bachmann fan. So this is a new result. And in fact, we show that this, this in fact, characterized the Bagman fan apositrise. Characterize the Burgland fan of positron. So this is an if and only if. And then also follow that using the work of Alex Fink, so it follows that the child polytope of a positively hyperbolic variety is also a genomized magnitude, right? So this is not so hard to prove using Alex's characterization of child polytope from the tropical variety. Yeah, so these are immediate corollaries of our main theorem. So we have some, we cover some new old results and some new Some new old results and some new results about positric and child positives. And then we also give a new proof of an old result that of PETA: the tropicalization of stable polynomials are M-convex functions. And in fact, the new proof also extends to strongly log concave or Lorentzian polynomials as well. Any questions about the main theorems in the following? Okay, so I will go over the main ideas very quickly because we don't have much time. So, what we want to do is we want to study tropical variety locally, right? So, but tropical variety locally is actually tropicalization of an initial idea. So, this is always true. If you want to study tropicalization locally, you should take initial ideas. And we can show that positive hyperbolicity is preserved. Positive hyperbolicity is preserved under taking initial ideals. So, you can think of one way to think of this as taking initial ideas as like doing some kind of a tori degeneration, degeneration of the varieties. And then these degenerations preserve the sign variations. That's one way to look at it. And then if you look at, if you zoom in to a point in the maximum phase of a tropical variety, then locally the tropical variety looks flat, right? Tropical variety looks like linear spaces. That means that a looks like linear spaces. That means the associated primes of my initial ideals are toric ideals. So toric ideals are prime ideals generated by binomials. So then we reduce ourselves to a binomial case and then we sort of like just do that brute force. We analyze the case of one binomial, show the result for one binomial, and then we yeah, and then we just look at the monomial parameterization and analyze sign variations carefully. Variations carefully, and we get the result. And sort of, and I'm proving the M convexity that doesn't quite follow from this theorem. So this theorem is about, you know, locally at tropical variety, right? But you can have like, you know, many different polynomials that give you the same tropical variety, right? So this convexity of the coefficient is something stronger. So yeah, so I guess this is just for experts. This is just for experts. I'll just take one minute. So, again, proving the initial forms, we can reduce to the case with trivia evaluations. And then from the main theorem, we already know that the Newton polytope of a stable polynomial is a generalized ambition. So to be convex, you need two things. You need to be convex and you need the Newton polytope to be, you need the cells of the subdivisions to be. The cells of the subdivisions to be generalized polynitorhedrum. We already have the generalized polynitorhedrum part from our main theorem. What we need is this convex, right? So then it's the same as saying that this, you know, in a trivial evaluation case, we have to show that the support of a stable polynomial is whole-free. This is also a very old result that has been proven multiple times, but we're going to give a new self-contained proof, right? And then, well, so suppose not, suppose it is not whole-free, right? If the hole is the boundary. If the hole is the boundary, then we can take the initial form to zoom into the face, right? To restrict the face so that it becomes a relative interior. So we don't have to worry about the case when the hole is on the boundary. If the hole is in the relative interior, then we can take partial derivatives to sort of shave off slices of mutant polytope to expose the hole. It's a little subtle, you have to be careful that, you know, when you shave off, you do expose the hole. And there are some things that you have to do. There are some things that you have to check, but that is the main idea, I think, pretty straightforward. And yeah, so using this, we can reduce to the binomial case, which we already proved using careful analysis of the sign variations. And then the same proof works. A nice thing about this proof is that, yeah, it proves for any family of polynomials, such as the Lorentzian onstone Law Conquer polynomials, is close undertaking initial forms, close undertaking partial derivatives with respect to the Derivatives with respect to the variables, and then the binomials have the right form. So, so, yeah. So, if you discover a new family of polynomials that fit, you know, these conditions, then you know that you know, you know that M complexity. Okay. So, how about the converse of the main theorem? So, the main theorem says that if X is a positively hyperbolic variety, then tropicalization is very special. Then, tropicalization is very special. The converse is: well, if we know the tropicalization is special, does it come from the positively hyperbolic variety? So, the answer is no. So, yes, so these are related to hyperbolic matrix, also somewhat related to Mario's HPP matrix. Yeah, and also these super abundant tropical literature curves also give a counter example. So, the converse is not true. That means that there is more structure to the positive. There is more structure to the positively hyperbolic varieties that we haven't discovered. We haven't completely characterized it yet. But the answer is yes, the converse is true for usual linear spaces or tropicalizations or tropical variety. It is true for curves, not curves, but like fan curves. So that curves are fans. And that is also true for blood and fans. So in summary, right, so positive hyperbolic variety have a nice combining. Hyperbole variety have a nice combinatorial structure related to type A bra arrangement, non-crossing partitions, and positive threads. So that is the point. And then, yeah, so I'm going to stop here and I'll just pull it here so people. Thank you. Thank you. Very nice. Thank you very much. Very nice talk. Do we have questions for Josephine? Very nice. So, yeah, so Josephine, so what are the main examples of positively hyperbolic varieties? Are we people that have conjectured on, you know, maybe this kind of varieties has that? Because I think of your theorem as an obstruction, something that if you topicalize and it's wrong, then you for sure know that that is not. That's right. Yeah, so we don't know. I think, like, I don't even know how to decide, you know, if like, yeah, if some. If, like, yeah, if somebody gave me a variety to check if it is positively hyperbolic, I mean, we have extraction, obstruction, as you say, we can look at the tropical variety and you know, has to satisfy this condition. But I don't know how to decide that. So, right now, we don't have many examples. So, sort of, I think maybe Mario or Cynthia can chime in on that. So, yeah, so originally our work was inspired by Mario and Cynthia's work. By Marian Cynthia's work, where they look at the reciprocals of linear spaces. In that case, they look at which reciprocal linear spaces are possibly hyperbolic, and they call them stable polynomials. I think Mario also has looked at, for example, which curves, right? Or elliptic curves. I don't know if he's here, but yeah. Or positively hyperbolic. I think in general, you can take fiber products of positively hyperbolic variety. Positively hyperbolic varieties to get another positively hyperbolic variety, and like this, you can build from hypersurfaces, you can get some more of higher co-dimension. So, yeah, and I think we do need, yeah, I think we could use a lot more examples. Yeah, we don't know many. And then I think this item will be very interesting to be able to. To be able to do that. So we don't know. Embarrassingly, we don't know how to decide. Yeah. Yeah. And then I think this was brought up yesterday in Cynthia's talk about, you know, can we sort of generalize this strongly low concavity to varieties that we don't know. I mean, whatever the, like, I think Cynthia mentioned this, but you know, whatever the generalization is, like, it's tropical, it's tropical. Its tropicalization should satisfy these nice conditions. It's tropicalization should be substantial type A grade arrangement. It should have this non-crossing condition. What is missing though is that we don't know how things fit together. So tropical variety is a polyhedral complex, a polyhedral fan, right? So a bunch, you fit together a bunch of cones. We only know what each single cone, what the direction looks like. We don't know how they fit together. Josephine, there is a question by Chris Shaw in the chat. Should I read it or can you read it yourself? Yeah, can you say anything about the real tropicalization and the positive behavior of all of our arti or the real phase structures? Yeah, we don't know. We hope that, let me see. So I have one picture. So we hope we don't have it, but we hope to say something to the effect of, you know, look. To the effect of, you know, recall in our very first slide that these hyperbolivariati come in layers, right? Layers around a point. So we also want to say that, you know, these positive hyperbolivariates also come in layers. And then hopefully these kind of coming in layers can be seen in the tropical world. So right here, this is a picture of on the right, you can see these layers. Okay, so this is a tropicalization of a tropicalization of a A tropicalization of a stable polynomial, and then you can see that the real tropicalization has this like layer structure. So, we want to say that, yeah, they also come in layers that you can see this tropically, but we don't really have that theorem. But yeah, this is this is, yeah, so this is this is why, yeah, we don't know so.