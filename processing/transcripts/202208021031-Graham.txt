I'm grateful to organizers, but this is my first time at CAMP, and so this time I am especially grateful to the organizers. This place is grateful at PAM. So, the subject of my talk is the uniqueness of steady states for a KDP reaction diffusion equation in some general domain in Euclidean space. And everything I have to say will be joint with Henri Veristiki, who may be joining us remotely. Unfortunately, can't be here in person. I can't be here in person. So, the general motivation for our investigation is to understand the effect of inhomogeneity on propagation in reaction diffusion equations. So, it's a very broad question. Many of us have worked on different aspects of this. And the most common way to tackle that question would be to study an inhomogeneous equation. So, make your reaction or your diffusion coefficient depend on space. But another way you could But another way you could model this would be to add some sort of boundary and consider the effect of, say, an absorbing Dirichlet condition on propagation in some subset of Euclidean space. And that'll be the perspective I'll take here. So if I'd like to understand the propagation in a general domain, that generally implies that you have one steady state that's invading another. That's invading another. And so, really, a prerequisite for understanding propagation is to have some feel for what the steady states of your system are. And when I first came to this problem, I figured we would knock out a quick classification of the steady states and then get on to the real math. And several years later, we're still answering questions about steady states. So that's what I'll be discussing today. So everything will be elliptic rather than parabolic. So the equation will be very simple. I'll just consider a constant LaBlauschin diffusion with some reaction F, which will be ABP type. This will hold into the domain. And then I'll impose Dirichlet boundary conditions. We can treat Robin conditions or even Neumann conditions, although that case. Or even neumann conditions, although that case is a little simpler. But just for the sake of a 25-minute talk, let me stick with Dier Schlei. And actually, I'll go ahead and add one extra condition, which is that I want to study states that are strictly between 0 and 1. So generally, we're not really interested in unbounded, say, population densities. It doesn't really make sense. And I want to forbid the trivial zero steady state here. Zero steady state here. So the question will be: when do solutions exist? And when they do, when are they unique? And so here we should think of omega as being potentially unbounded. And my reaction F will be KPP. And actually, I want it to be of the strong KPP. I want it to be of the strong KPP type that Luca mentioned yesterday. So by that I mean that the function f of s over s is strictly decreasing. So we could think of this as a kind of convexity. Convexity hypothesis. So for instance, if I draw the graph of f, it's positive between 0 to 1. And this condition is saying that all the secant lines that come out of 0 are monotonically decreasing as I go along the path. So in particular, this So, in particular, this forbids other reactions that satisfy the more traditional KPP hypothesis. Something like this will lie underneath its tangent line at the origin, but certainly it has this non-monogenicity going on. And it turns out that this assumption is actually quite important for uniqueness. So, before discussing So, before discussing uniqueness, let me say a few words about existence. So, like is often the case with KDP reactions, the whole story for existence really boils down to the linear theory. And so everything is kind of linearly determined here. And so, I can express everything in terms of the principal eigenvalue of the linearization of this operator. So, let me define that. So, really, it's a generalized principal eigenvalue. So really it's a generalized principal eigenvalue because omega might be unbounded. And there are many formulations of it, but the one we found to be the most useful was just the classic variational characterization of this thing. And there's nothing unusual with the definition. I'll want to take the infimum of the usual Rayleigh quotient. overall test functions that are in H1 and vanish on the boundary. So that's very familiar. I say that it's a generalized eigenvalue. Some familiar properties of eigenvalues can go wrong when you're in an unbounded setting, but that won't come up too much during the talk. So we can just think of this as We can just think of this as a familiar principal eigenvalue. And broadly speaking, this number will govern the stability of the state zero in our system. So there's a couple of alternatives. So if this eigenvalue is large, oh, and let me say that this is just to choose a sign, this is an eigenvalue of minus the quotient. Of minus the quotient. So it's positive, right? We're non-negative. So if this thing is strictly greater than f prime of zero, then heuristically that's saying that the absorption from the boundary is stronger than the growth you feel in the interior. And so that's going to tend to really kill any solutions you have, drive them towards the stable, steady state, which is zero in this case. So here, zero is stable. Zero is stable. And among other things, you have a maximum principle. And so we can see that that implies there's no positive solutions to this equation. And then in the other alternative, zero is unstable, and that means you can construct a positive subsolution for Can construct a positive sub-solution, for instance, and then from there you can drive yourself up towards a steady state. So zero is unstable, and now you have positive sub and even true solutions. Okay, so this is nearly a short classification of existence for this problem. The only question is. The only question is: what happens at the critical value? And we don't know in general. And I think that's a fun, open question that I would like to see solved. So, on bounded domains, we can show that there's no solution at the critical value. And that's a consequence of this strict, strong KDP property. Basically, it says that your reaction is always strictly less than its linearization at zero, and that extra, or that gap between Extra, or that gap between your true nonlinearity and your linear function ends up giving a bit of extra absorption that forbids the existence of the solution. We expect that to hold in general. We don't expect solutions at the critical eigenvalue, but we're not able to show that at the moment. So, with that, I'd like to get on to uniqueness. So, this was a pretty simple story, and I expected the same for uniqueness. Same for uniqueness, and I've been surprised. So, first, let me share a result for bounded domains, where we really do have a good feel on what's going on in this problem. So, this is a classical result due to my collaborator, Henri. I'll use the word classical to mean any result that predates my own birth. And so, Henri showed that. And so Henri showed that when omega is bounded, the strong KDP hypothesis is good enough to imply uniqueness. And so I won't go through the whole proof, although it's not long, but I want to give you the idea of how this works because it influences. Because it influences where I'll go in the rest of the talk. And so, as many such proofs do, you would start by considering two solutions, u and v, which are not necessarily distinct. And ultimately, you'd like to show that these are equal to each other. And so, the general idea is to say: well, you're on a bounded domain, so you know that. So, you know that these two solutions are comparable to each other in the sense that one always lies underneath a large multiple of the other. That's just a consequence of compactness and the hop lemma on the boundary where things can get a little bit tricky. So. That's coming for the strong KPP laws? That would come for a much more general reaction. Yeah, I think as long as Yeah, I think as long as you have a positive solution in the interior, you would have a positive slope at the boundary. And that would be enough to. Well, here, let me finish writing this out. So what I mean is that u will be less than some large multiple of v, and that just needs positive slope of value. And so now the idea is let's look at the optimal choice of k. So let's bring this large multiple down and down and down until we just touch, and then see what happens. And this is where the strong KPP hypothesis comes in. So I'll call that optimal value k star. And okay, it's not true in actuality, but morally, I just said it. Morally, K star V should touch U somewhere. Maybe they have the same slope at some point on the boundary, but let me not worry about that. Let's just think that they touch somewhere in the interior. So, this is kind of setting off alarm bells. We would like to draw a contradiction from the strong maximum principle at this point. But, like Peter was getting at. But, like Peter was getting at, a priori there's no really reason to have such a contradiction because kv doesn't have to satisfy the same equation of the V. And actually, yeah. But if I assume that K star, let's suppose for the sake of contradiction that it's strictly larger than one. Then I can deploy the strong KDP program. I can deploy the strong KDP property to compare the value of f at this multiple with the value of f at v itself. So then I'll find, let's see, k star times the value of f at v will be strictly greater than moving k inside. And now we can look at an equation for a difference and derive a contradiction. Difference and derive a contradiction to the strong maximum principle. Certainly. So this theorem has been known for many decades and started first. This is 1981, I believe. 19. 81. So around that time, many people have selled these. There is some peak on site entity, right? You can use peak on site entity. Picon side entity. But there is an early earlier result, which is not the same as this, in 1968 by Fuji. We showed that for convex F nut is Not this. If there is more uh uh steady state which is ordered triple. Here zero is that zero is the idea is similar. So but under this particular condition uh probably the desired uh the first Okay, yes, thank you for that. Yeah. Yeah, it's very good to keep in mind. And I think, okay, so I'll pretend that I finished the proof here from a little box. The thing I want to emphasize is that this result is false if you relax this condition too far, which is something that surprised me when I heard it. Which is something that surprised me when I heard it. But I could take a reaction of this type and make it a little more extreme. So I could have a very large first hump that almost goes down to zero and then goes back up. And maybe it's not too hard to believe that you could have a solution that is more or less supported in this first hump, if that makes sense. If that makes sense. On a bounded domain, at least. You could have something here, and then another solution that really sees the entire reaction actually comes close to one. And the point being that if my reaction truly touched zero, then certainly you would have such a thing. And you just need to use a perturbation argument which works in a bounded domain to get such an injury. So, really, you can't relax this too far. So, for the rest of the talk, I'll So, for the rest of the talk, I'll stick with the strong PPP assumption. And now I'd like to turn to what's going on in the more novel case of unbounded domains. So, when we look at an unbounded domain, we can We can see a place where this proof has a problem. It's no longer clear that any pair of solutions will be comparable to each other. So for instance, what if v vanishes at infinity somewhere and u doesn't? Then there's no hope of a bound of this type, and proof is down. So this suggests that if you really want to proceed with this argument, you want to get some grip on the behavior of solutions that include. Grip on the behavior of solutions that you think. And so that gives me some motivation to study some solution that's been translated by some sequence that's going to infinity, my domain. And this is a solution that's now proposed on a shifted domain so that my sequence of points xn gets translated back to the version. And so I'd like to take. And so I'd like to take some limit as n goes to infinity. And as long as I have some sort of uniform smoothness on my domain, I can extract a subsequential limit. So I'll get some limit u star on something that for the moment I'll just write very loosely as the limit of this domain. We can think of this as holding kind of locally uniformly, so I look at some large ball. So, I look at some large ball and I get convergence of my domain there that I diagonalize. There's kind of a problem here, which is that although I am assuming that my initial domain omega is connected, there's no reason that this limit should be connected. So, for instance, if I have some sort of funny u band domain, and I start looking at a sequence of points that's tending out to infinity. Tending out to infinity in this direction, then the limit I'm going to get will be a disjoint pair of cylinders here. And that's pretty unpleasant for all kinds of reasons. If I want to apply the strong maximum principle, I'll get positivity in some components and not others. So I want to discard that component, basically, because it didn't contain the sequence of points that I was interested in. So I'll give some terminology to this. So I'll say that omega star is the connected limit of my original domain omega along this sequence of points. Whenever It's the connected component of the limit that contains, well, contains the origin after I've shifted everything back. Connected component of this thing, which may be kind of nasty, contains zero. I should add that I'm always thinking of these points as being insidable. Citing. Okay, so that's kind of a bookkeeping thing, but it'll really be the building block of the rest of what I have to say. So motivated by this linear determination, I'm really interested in the eigenvalue of my operator on this limit. This is telling me whether zero is stable at infinity in this particular direction. And so more generally, And so, more generally, I'm interested in the set of all eigenvalues at a thing. So, I'll denote this by sigma of omega. I'll call it the limit spectrum. And it's the set of all these limit eigenvalues when I go in all possible different directions along all possible sequences. And so we're able to. So we're able to prove uniqueness subject to a certain non-degeneracy condition on this limit spectrum. So as our existence results suggested, we have difficulty dealing with the critical case when an eigenvalue is exactly equal to And eigenvalue is exactly equal to f prime of zero. And that's true for uniqueness as well. So if that SP critical value does not lie in the closure of this limit spectrum, then we can show the difference. And in fact, okay, we've conjectured. And in fact, okay, we've conjectured that in general a uniqueness holds. But for the time being, we don't have the right technical tools to treat critical limit eigenvalues. So So in my remaining time, let me mention a little bit about how we go about showing such a thing. So the main technical tool we use is a kind of decomposition of our domain according to whether a limit eigenvalue is above or below this critical value. So So we prove a kind of geometric result, which is that your domain is non-critical in this sense, if and only if it admits a kind of decomposition. So if and only if I can write this open set omega as a union of two nice open sets, which turn out to be connected, I'll mention. Which don't have to be connected, I'll mention omega minus and omega plus, so that all the limit eigenvalues of omega minus are less than this critical value, and all the limit values of omega plus are greater than. So it's sort of like we looked in all different directions, and depending on whether you have a supercritical or a subcritical eigenvalue, we put that chunk of the domain into omega minus or omega plus. And it took us a while to understand how to actually go about constructing this decomposition concretely. But once we have But once we have it, let me say why such a thing would be useful. So in omega minus, all your limit eigenvalues are strictly less than f prime. So that says that zero is unstable everywhere in omega minus. Is that the stop val or the five minute val? It is, but we asked you some questions. Okay, all right. I'll wrap up quickly. So in this domain, zero So, in this domain, zero is unstable, and you can construct a positive subsolution that prevents general solutions from vanishing at infinity. So on this domain, the previous proof works just fine. And on this domain, zero is stable, but we also have a maximum principle. So, with that extra tool, we can basically transfer all the useful inequalities from this part. The useful inequalities from this part over they still hold in this part. And so this will show that solutions are comparable to each other and you end up getting uniqueness by the same way. So in some sense, we've just taken the previous proof and added this extra maximum principle tool. And I think I'll just wrap up by kind of providing one example of what this decomposition might look like. I think it's a try. I think it's a strategy if I finish without drawing a pretty picture. So let's imagine that my domain has a whole bunch of teeth running off to infinity, varying widths. So this is my domain. It has these things running away. Running away and the lengths of these or the widths of these teeth. Maybe I can call L1, L2, L3. And so the question is whether one of these teeth is subcritical or supercritical. When the tooth is very narrow, the boundary effect is very strong, the limit eigenvalue in that direction is large, and you end up being supercritical. End up being supercritical, so that part should end up being in omega plus. Maybe this part is too. Depends exactly on the value of your f prime, of course. And at all the wider widths, you throw all of this into omega minus. So all along here, you can't vanish at infinity in every. Here, you can't vanish at infinity, and everything works. So it happens that whenever I try to write down some funny general domain, I almost always find that there's some way of squinting at it to decompose it in this form, unless I've designed it specifically to break that. So I'll stop there. Thank you. So you mentioned at the beginning that you can handle also other boundary conditions, like Neumann or Prohibit. And it's the same kind of in case of Neumann you have that you are just at the omega minus, right? Th then this condition is always satisfied. Yeah. Eigenvalue is always zero. So you have that one is the unique uh solution. Solution because I have this result and um is it the domain is only from this position? Right. Do you think that is it I think it's a technical position, right? Or you think it's it could it could be multiplicity if uh this for instance if this L's there are thinner and thinner, you think that some uniqueness Some uniqueness? Yeah, probably not in that situation. It is hard for me to imagine a non-uniqueness scenario in any case. Certainly, I've thought about that question a lot for Noinmine, because it seems like you should just be able to prove it, even if you're not uniformly smooth. And every time I try to do it, I get baffled right at the end. But yeah. I think that uniqueness should hold in a pretty general sense. general sense. Do you have a conjugate example with f prime zero being the correlation? No, no, and we conjecture that there are no counterexamples. Yeah, and we've tried. Actually, we do have one case in which we can prove that although there is a critical limit, you do have uniqueness. Sort of a case like this, if you just have a cylinder of critical width going off to infinity. Cylinder of critical width going off to infinity with some bulb attached to it, then you can explicitly analyze the behavior at infinity by ODE methods, and you can prove uniqueness. When you have a solution that should be stable, such as if you take a parabolic flow, conditions with compact support, if they are small, they should converge to the Small, they should converge to that solution. Yes. Now, the solution is stable, and you have the other stable solution constant, one well, it wouldn't satisfy the boundary conditions. So we think this should be solution. Yeah, it should be stable in a pretty strong sense, from above and below. About the black. So you rotate the solution, for example, you get the same type of. Any other question? So if the domain disconnected, solution pass? But even though it it is Yeah, I I guess I would you could have multiple solutions Well, so if I restrict all solutions to be positive everywhere in your domain, then you could treat each component individually and you would get a unique solution on each one and then there'd only be one On each one, and then there'll only be one positive solution. Yeah, you could have a positive solution here and zero there. Yeah, and I agree. Then you could consider the kind of non-uniformly smooth limit when you disconnect the two. I think that that wouldn't really happen. I think that if you can support a positive solution on both domains and you take a kind of pinching process, you should pinch off to just be left with the positive thing on both sides. I can't imagine you would end up with zero. I can't imagine you would end up with zero on one when it could support a positive solution. This then is still under the strong PPP. Indeed, yes. Okay. So then even if the domain is bounded, you cannot recover the bounded domain. Yeah, you're missing the critical value. Now, there's kind of a Now, there's kind of a I guess there's a caveat that we can also show that in the critical bounded case, there's no solution. So it's sort of abandonable. Yes, when you augment it with that other result, then you can recover everything. But yes, you're right. There's a small gap there. Another one. Who do you construct a very strange ova so that sigma ova is anti-communication? Um uh well I guess so it it kind of depends on let's see so I glossed over one point which we use in a preprint which is that I just want to interpret sigma omega as being the set of eigenvalues along all kinds of sequences but I want to allow bounded sequences as well and if the sequence is bounded then you're just shifting your domain around and you end up just seeing the eigenvalue of the domain And you end up just seeing the eigenvalue of the domain. So, in that scenario, kind of when I expand the definition, it will always be non-empty. It will include the principal eigenvalue of your original. If you change the definition to kind of go to infinity, if you have a uniformly smooth condition, then you'll always get limits at infinity because they can't kind of narrow down to nothing, for instance. But if you relax that uniform smoothness, That uniform smoothness, things could go wrong. I should say that when I use uniform smoothness, I'm including kind of an interior ball condition. The only way it can be empty is that the limits of the domains are empty. If you don't require x and to be unbounded, you can choose x and the fixed point. And you get only get yourself in single model. But you could have. So if you require If you reply, yeah. As long as you get some domain interlimitability. Yeah. So I think the worry would be that you end up with some narrowing form that vanishes in the limit. Then I think that's kind of interesting too, but outside our scope. Looks like we are done. Thank you again.