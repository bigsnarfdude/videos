So, um, you might still be muted. I'm not sure. How about now? Ah, I can hear you now. I can hear you now. Yeah, I don't know how it was muted again. Sorry. So, thanks for accepting the proposal to talk here. This is about monotony interaction laws coalgebraically, as I said while I was muted, and it's joint work in sort of temporal order with Shinya Katsumata, Executive Rivas, Niels Fornefeldt, and Dylan McDermott. I'm trying to summarize some things in a very compressed way. Compressed way. So, what is this about? This is computer science. We are following Moji's monad-based approach to effects in mathematical semantics of programming. Effects being things that are non-purely functional, like manipulation of mutable state or input-output or exceptions, or non-deterministic choice, or probabilistic choice, for example. So, the nice paradigm is to think of effects as a purely functional program. As a purely functional program that doesn't want to dirty its hands, requests to the outside world for certain services that are then considered impure. So then to be able to run such a program, abstracted mathematically into a computation, which is basically just a term representing how these requests occur, has to meet a state machine or an environment more abstractly that is able to serve these requests. So for example, Serve these requests. So, for example, if you want to put something into a store, then there has to be some store service that accepts it so that the next time when you want to ask what was the value I put there, it will actually give you back the same value and doesn't cheat. So then these two, a program and its environment or a computation and its environment, they have to understand each other. And monad common interaction laws are just a piece of mathematics where you can also leave out the computer science altogether that then mathematize the communication protocols. Mathematize the communication protocols between these computations and environments. That's something that we came up with with Shina Katsumata and Executive Rivas, but that also has some prehistory. I mean, some ideas were present in Plotkin and Power's work some while ago, and then they've been gradually explicated by other people or made more explicit. Just to the matter. So, this is the game. So, we work with a Cartesian or perhaps. With a Cartesian or perhaps symmetric monadic category, and there is some given monad R. And then you talk about monad common at interaction laws. So, apart from a monad r, you are supposed to have a monad t, a common at d, and then a natural transformation typed like here. So, tx times dy to r of x times y, such that certain diagrams commute. And there is some sort of legend of Some sort of legend of how you should read it that is known in mathematical programming semantics, part of it at least. So, think of the given monad t as some sort of a notion of computation. So, for example, you can model state manipulation with a certain monad. Then whenever I've got a schematic variable x, this is about the values that computations return. That's useful to keep in mind. D is a common, but it works here as a notion of n mind of. works here as a notion of a mind of an environment so so different flavors of computation are abstracted into monads different notions of environment environment are abstracted into co-monads and and again this schematic variable y here an object of of c whenever i use y this intuitively is a state of a state machine and r is also a monad that's um for another notion of computation residual computation so there may be some So, there may be some effects that the environment will never be able to meet. Like, if I throw an exception, the environment gives me no way to go on from there unless there is some exception handling mechanism, but that is not covered here. So, this is literally it. You can just read it like Tx times dy 2r of x times y, compatible in some way with the unit of the two unit. Of the two unit multiplication, co-unit co-multiplication of the two monads and the monad. So, similar to how monads are monoids in an end in the endofunctor category over the base category, monad-commonad interaction laws are monoids in some right place, which perhaps we could see here. So, to define this, we should say what first of all an R-residual functor functor. An R-residual functor-functor interaction law is this is like a monad-comonad interaction law, except two functors, two end-of-functors, are given, and just a natural transformation subject to no equational conditions. Then monad conode interaction laws are going to be monoid objects in the category of functor-functor interaction law. So, therefore, I need a category, I need a notion of map between two functor-functor interaction laws, and there has to be a monoidal structure there in order for me to talk about monoids. Talk about monoids. An interaction law map between two interaction laws, like this, between two functors, two pairs of functors, is given by forward natural transformations between these first functors, the f's, and the backward natural transformation between the g prime and g, satisfying this pentagon, or rather a square. And then these functor-functor interaction laws form a category with a composition-based monoidal structure. The fact that r is a Monoidal structure: the fact that R is a monad plays an important role for you to write down the structure. Here is only one example of a real interaction law that I give. So this is called the state monad, given a fixed object S of the base category, which here I assume to be Cartesian closed. Double arrow is for exponents. This is the monad. Here is a commonad defined like this on objects. S and S here are some fixed objects. S and S here are some fixed objects connected in some way that is called the lens. The residual monad is actually identity. Then, to really have an interaction law between these two things, I need to define a natural transformation like this. So on components X and Y, it should have this type. And the idea is not complicated. So a stateful computation is something that reads a state at the beginning of the day, at the end of the day, it writes something to the state. The day it writes something to the state, there may be intermediate stages, but these are extracted out. The co-state common is something that can provide you a data state so that you can start to work and then at the end is able to consume it. So given a computation, given an environment like this, you can just use the infrastructure of a Cartesian closed category to manufacture a pair of X and Y. And the legend is here: X are values that you return, Y is the states that you work over. One is the states that you work over, control states. Capital S is sort of views of stores from the point of view of computation. S0 is stores from the point of view of the owner of the store, so to say. Why is the residual monad R sometimes needed? The reason is why don't we just always have nothing here? Why don't we have identity here? The reason is in many cases, you do. In many cases, you do not get reasonable examples anymore, or you cannot conceptually describe what you want. So, while needed, the residual, the monad for residual computations, assume C is extensive, so with well-behaved co-products. If a functor f comes with a nullary operation or a commutative binary operation and interacts with G, G can only be constant zero. So, only completely uninteresting interaction is possible. So, you can only talk to a state. So, you can only talk to a state machine whose state set is the empty set, so that's not fun. Similarly, for example, if a monad comes with an associative binary operation and interacts with a commonad, then the commonad cannot be very interesting in a certain technical sense. So, therefore, it is often useful to use the residual, a non-trivial residual monad where when the given monad T has an Allery operation or a commutative binary operation. Operation or a commutative binary operation, or so. So, a commute or even an associative binary operation. So, things like exceptions and non-determinism are not interacted with well. So, these effects are often left over in an interaction. So, even after the interaction, you still see these things in residual computation. So, therefore, like finite multiset, a finite non-empty multiset, or just blank plus one are good examples. Now, then, theoretically, it's interesting. Now then, theoretically, it's interesting given a monad to find the universal, given a monad R, to find the universal monad T interacting with a given common at D, or maybe the other way around. R is fixed. You want to find the universal common D interacting with a given monad T. Why is that? Suppose you want to talk generically about all possible types of environment that are good for your notion of computation. Notion of computation. You could be interested in particular common ads that satisfy your needs, but there is going to be hopefully one universal one, which in some sense is the minimal type of environment with which your computations can interact. Like in the case of your computations being stateful only, you really don't need any other service than storage, right? You don't need non-deterministic choice then, somebody that would cast dice for you. Okay, and the other way around. Okay, and the other way around. There are some alternative formulations, of course. If the category is Cartesian closed, you can play your Yoneda and transposition games, and there are different ways to state exactly the same concept of a monad-commonad interaction law. Why I mention this is that one of these views, namely this, to talk about an interaction law as a natural transformation type like this, natural in Y and Z, subject to two equations. Z subject to two equations, sort of suitable rewrites of the two conditions I had before, gives us actually quite an insight on what these monad common interactions do. Namely, there is a co-algebraic view on these things. Namely, a monad-common interaction law, which is just nothing else than a fixed T and D together with a natural transformation like this, naturality in Y and Z subject to equations, turns out to be exact the same thing as functors taking coalitions of D. Taking co-algebras of D and algebras of R into algebras of T, but not arbitrarily, but such that on the level of carriers, the carriers are exponentiated or hummed. And actually, these functors necessarily are already determined on what they do on three algebras and three co-algebras. So, therefore, equivalently, you could talk about functors from cochleislia d up time. Kleisli of D up times Klaisdy of R to Alembert more of T. So, this is a useful view that in some ways explains quite a bit about these things. There is a programming story about it, namely you can see algebras of the monads involved as handlers of effects. This is very popular currently in mathematical programming semantics, and co-algebras of co-monads that. Co-algebras of common ads then are cohandlers. So these are like a carrier, a state space, and then a co-algebra structure on it that explains how from any given initial state in the state space the behavior evolves in a way where you do not need to see the machine concretely but just this abstraction into the behavior and then And then interaction laws basically tell you: if you can handle residual effects in some way, if you can co-handle the environment, if you can generate the environment from an initial state, then you can actually handle the original effects. So there is this construction is very simple and very trivial when you think about it. So let me not delve into this. Let me not delve into this. There are also intermediate views. So, on one hand, we can talk about monad-commonad interaction laws that we saw. We can talk about this carrier exponentiating functors between co-algebras and algebras of the co-monads and monads. But there are also intermediate use. You can also talk about, for example, that these things are the same as carrier-preserving functors from algebra. preserving functors from algebras of R to something that are called continuation-based runners of T, fueled by D, or co-algebras of D to stateful runners, residual stateful runners of the monad T. So there is lots of variation here. I can't go into the details, but for example, a residual runner for a given monad R and the monad T with a carrier Y is a natural transformation like this with certain equations. With certain equations. The difference from an interaction law is there is no dy here, but y. So instead of being given a whole environment, you're just given an initial state of it. And a runner then is a natural transformation that sort of implicitly knows how the machine behaves from the given initial state. These are the same by occurring, of course, as natural transformations like this, but the equations here. But the equations here become actually those of a monad morphism from T to the R transform state monad for state object Y. This monad is defined here on the level of objects. So then interaction laws you could also see as functors from coalgebrases of D to stateful runners, for example, and you can also see them as functors from As functors from algebras of R to these d-fuel continuation-based runners of T. Okay, but now to something more abstract. This was actually a complicated way of telling the story, but on the level of algebras, you have to to a degree. But let's go more abstract. Actually, let's forget about, if we can, monads and commonads altogether and see if we can talk about the same thing for monoids and commonoids for perhaps an arbitrary monoidal category or perhaps a richer category with some. Richer category with some further structure, but we're still talking about monoids with respect to at least some monoidal structure that is there. So, restrict the end of functor category to accessible functors, or just don't worry about the existence of certain ends and coens. Then the end-of-functor category has this day-convolution symmetric monoidal structure. And now, an R residual functor-functor interaction law, if you Law, if you think in terms of date convolution, is really nothing else than a choose base. And R-residual functor-functor interaction law is a pair of two functors, f and g, and then a map from f star g to r, where star is take convolution, via this bijection here that only again just uses Yoneda, the universal property of Coupal. So, this characterizes functor-functor interaction laws, but where are monad-commonad interaction laws? We do not immediately get another characterization of R-residual monad-commonad interaction laws. The category of two spaces has a monoidal structure, but that's wrong for our purposes, because in interaction laws, the monoidal structure on the category of endofunctors with respect to which we get. Which we get that interaction laws, then, or that gives us the monoidal structure with respect to which interaction laws are monoids, is not based on date convolution, is based on functor composition. So we actually have to use that endo functors come with a dodel structure. On one hand, a monoidal structure given by endofunctors, on the other, given by day convolution, interacting in a certain way, the most important part there being a middle-four interchange law. For interchange law. And then it is true that given this toodal structure, these two things being the most important ingredients, you always get a monoidal structure on two spaces with vertice R, and the two spaces are with respect to the star monoidal structure based on the dot monoidal structure. So on the two spaces, which are two spaces with respect to star, we will have a monoidal structure. We will have a monolith structure, and that monoal structure is constructed from C. And then our residual monad common interaction laws are monodal objects with respect to this monoidal structure. So, therefore, you can talk about general monoid commonoid interaction laws in any dweidle category in principle. So, if you are given some monoid object with respect to one of these monoidal structures, we get a monoidal structure. A monoidal structure on 2R and an R residual monoid commonoid interaction law is then nothing else than a monoid object in this 2R. Explicitly, it is literally a map like this, subject to these two conditions, which are the general forms of the conditions I had originally. Now I had this concern about the universal D for given T and the universal T for given D. How we can For given D. How we can talk about this game, we have to go a bit more specific. And actually, this has been done in the context of Swiel theory for dual categories by Gnacio Lopez-Franco and Christina Vasil-Copoulou, who then generalized Swiela theory from symmetric monoid categories to dual categories. We have to assume only a tiny bit more than we already have, a duodel category, but we be better closed with respect to With respect to, and this is now wrong, with respect to J and star. So I want that star has a right adjoint like this for every G. So for endo functors, it's no problem other than size problems. So the right adjoint to date convolution for a fixed G is defined like this by an end. And then there is standard three layers. And then there is standard Swillier theory things that follow. This monoidal closed structure, symmetric monoidal closed structure that we have on D, it actually induces certain things. So star lifts to commonoids. So a pair of commonoids gives us a commonoid again. Whereas lollistar lifts to a mixed thing, which I call power here. So it's an operation that takes So, it's an operation that takes a commonoid and a monoid and produces a monoid. Then, what are monoid-commonoid interaction laws? In this context, they are known as measuring maps, and they are defined exactly via this power. So, they are, for a given T dr, they are maps between UT times star UD to UR such that the transpose The transpose is a monoid map. I mean, this thing is nothing, it's not the map in monoids or commonoids, it's just on the level of D. And here's a mistake, the D and C should be the same thing. But then the equations you could read off from what is a monoid morphism between T and D lowly star R, which is a monoid. Then you don't always have the following things, but if appropriate adjoint. Things, but if appropriate adjoints exist, and you typically produce them by special adjoint functor theorems, you will have these further functors. I mean, with luck, you already lifted star, in our case, convolution to commonoids. Then with luck, this will have a right adjoint. And then we had this thing that is always there easily, power. It's just a lifting from. It's just a lifting from the underlying category to the category of, you know, to the mixture then of these categories of commonoids and monoids. Yes, so power gives us what these measurings are or mono-common interaction laws, but then you could require different adjoints to exist. You could require now this is in mono. Require now, this is in monoids. You could require, or this is actually a mixture. But yeah, the map is in monoids. D is a commonoid, R is a monoid, the result is a monoid. This is in monoids. You could require an adjunction, a left adjoint to Lollistar, this thing, that would then be called the Sweder co-power. And then you could, in turn, require a right adjoint for this thing, and that would be called the Swede HOM. And that would be called the Swede Hom. If all of these things exist, you get a very nice picture. You get that the category of commonoids is symmetric monoidal closed, and that the category of monoids then is enriched, co-powered, and powered over the category of commonoids. On this level, many things become very easy to calculate about these desired operations that we want. So the That we want. So I talked about given R and R and D, what is the universal T? This is just the power that is always there. It is a lifting of Lolly star on the underlying category. So now we know how for a given commonoid and the monoid to produce this monoid T. Produce this monoid T. But then other things are more complicated, like the universal D for given T and R is then this thing that is called the Swileham. And this is not obvious at all why it should exist, for example, in our monad-comonad case, or under what conditions it exists, etc. What should be some concrete ways of constructing it? Whereas this one is trivial to construct because we know what Lolly star is on functors, namely. star is on functors namely it's this um uh and this is always carries uh a monad structure if if g is a commonad and h is a monad okay so to tweet uh i've got two more slides to illustrate for example um exploiting the swielder theory perspective some things about monad common interaction Some things about monad-common interaction become very, very easy to calculate. So, for example, I might be interested in having a nice condition: when does a free monad interact residually with a commonad, with some given commonad? And this is very, very easy to calculate. So, if t here is a monoid, which is the free monoid on a given object, or we could think of the free monad on a given functor. Given functor, then just a simple chain of bijections tells us that our residual monoic common interaction laws of T with a given D are just object-object interaction laws. This is to say, just plane maps between what? F, the object, the underlying object of D to the underlying object of R because Because, yeah, what is happening here? So, this is just the transpose. Lolly star is right-adjunctor star. This is using that lolly star on lolly star lifts. So, lolly and use, the forgetful commutes. So, this is the adjunction between free and forgetful for monoids. And finally, we And finally, we know by definition that these measuring maps or interaction laws are nothing else than monoid maps to lollies. And therefore, we've calculated that interaction laws between F star, D, and R are exactly the same as just maps from F star underline of D to underline of R. In a similar vein, for example, In a similar vein, for example, one could calculate with ease the Swedler Hum for the free monoid on some given object and some arbitrary monoid. And it turns out that this is a certain co-free monoid. So what you have to do is forget about the structure, the monoid structure of art, take the underlying object. This is Loli star on the level of these objects. And then this gives you an object in the base category. And then you just take the first. Base category, and then you just take the co-free commonoid on it. Co is missing here. And that is again a very simple calculation. Sorry about that. I just wanted to mention that we just have a few minutes before the next talk. So we'll just need to wrap up in the next minute or so. Sorry about that. This is the last slide, actually. So then I wanted to say that there is a lot that one can do on the level of Sweden theory alone. Maybe worrying about some existence questions, but the rest is straightforward calculations. But for other things, one really needs to use the algebra-co-algebra perspective. So, here, for example, how do I calculate the Sweden-Holm for a general monad? Of course, I won't give a recipe, but I just give you the hint of how it goes. So, it really goes by combining the perspective of the Swieler theory with this quadratic perspective. So, for example, it turns out that the quadric perspective... Turns out that the Kohalberg perspective characterizes a certain category of runners as a pullback in cat. And then the Swedler theory says the same pullback is the Kohalenberg-Moore category of the Swedel-Hom TR. So by sort of accident or actually by good luck, two things are described as the pullback of the same Yeah, are described as the same bullback, and from there, then we can extract this concrete characterization. So we cannot construct the common as such, but we can talk about the co-algebras of the Sweden home with carrier y, they're exactly R-residual stateful runners of T with the same carrier, which by the definition were monad maps from T to the R transform state monad for state space. For state space y. So similarly, you can also calculate the Sweda co-power, for example. Sorry for going over time. Thank you. No problem. Thank you. Let's thank the speaker.