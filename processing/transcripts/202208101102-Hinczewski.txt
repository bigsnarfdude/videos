Who's an oncologist and also studies theoretical evolution? Is in some sense that in many disease contexts, evolution can be a major impediment. The most famous example of this is bacteria evolving resistance to antibiotics. But you can also have, even in cancer therapies, development of resistance of tumors to cancer drugs, right? And there's this been this idea in the past decade or so that perhaps we will never be able to turn off evolution, but perhaps there are. Off evolution, but perhaps there are ways of biasing it, severeing it in directions that are somehow more easily treatable. So imagine taking a population and moving it toward a set of genetic variants that we know are susceptible to a particular drug. So we have to have the methodology to basically kind of push it in that direction, and that might involve a whole other type of drug protocol just to do the pushing. And this whole field is known as kind of adaptive or evolutionary therapy. So we're kind of trying to build up the theoretical framework So, we're kind of trying to build up the theoretical framework to support these kinds of ideas and to basically get evolutionary systems or other types of biological systems from point A to point B along a certain track. All right, so in an evolutionary case, what are we talking about? So let's give a concrete example. So we have some kind of cell population. There's going to be some kind of set of genetic variants or genotypes. Here, in this simple example, there are three of them. This population does the stuff that populations do. So the cells can give birth here. Here is the simple. Cells can give birth here. Here is the simple division process. There's going to be a rate at which that occurs. We're going to call that the fitness FI of type I. Cells can die, cells can mutate between different types. And there are parameters controlling all of these different things. So how would you bias this type of the evolution that's going on in this population? Well, we're going to have some control knobs. So the fitnesses in our system are going to be dependent on something, right? The most common thing is you can imagine a single drug concentration, you can imagine a cocktail. Drug concentration, you can imagine a cocktail of drugs. There could be nutrients, right, or other kinds of environmental parameters, but we're going to have some ways of basically tweaking these fitnesses. And the idea is going to be, okay, can we then use these control knobs to guide the system in some desired direction? Now, if you have a population like this with different types, you can imagine describing it in terms of this instantaneous state of the system as just basically the fraction of the population, each individual type. And mathematically, And mathematically, if you know, this is a three-variant system, so you can actually imagine that as a point on a triangle. So, one axis of the triangle is the fraction of the first type, one axis is the fraction of the second type. You don't need the third axis because all three types sum up to, you know, the fractions sum up to one. And a single population would be a point on this triangle. Now, if you consider now an ensemble of populations, which is a description you need because it's a stochastic system, that's going to form some distribution of genotype. Of genotypes in the space. And the idea is, and then the main question that we're going to try to ask is: can we basically drive the system to a certain, rather the ensemble of populations, through a certain sequence of probabilities? And of course, underlying this is we've made a kind of continuum assumption. So we're assuming populations here are large enough that this fraction we can think of as a continuous variable in each direction between 0 and 1. Between 0 and 1. And so we have underlying this, I'm not going to go into the, you know, for a shortage of time, not going to go into mathematical details, but we have basically a description like a Pako-Planck equation that describes how a probability would change over time in this type of space. Now, here I'm showing three different probabilities, and these actually correspond to the equilibrium probabilities that you would get under three different, let's say, for example, drug concentrations. So you can actually imagine tweaking these sort of parameters and having different probability distributions as a function. Probability distributions as a function of that control now. And the goal is going to be, in some sense, to figure out: okay, if we have a sequence of such distributions, can we actually enforce that and make sure the system follows that particular sequence of distributions? Now, for a lot of the talk, we're going to concentrate on distributions that are essentially these equilibrium distributions, and I'll explain why because of this analogy. But later on, we'll actually generalize this to totally arbitrary distributions. But that's kind of the, if you want to think about what the control. Kind of the, if you want to think about what the control problem here is, is kind of choosing a path in this probability space, forcing the system to go along that path. Now, because we have this underlying Fokker-Planck description of the dynamics, it turns out that there is this really beautiful analogy between Fokker-Planck equations and the Schrodinger equation. So you can actually take some of the results that people have developed in quantum mechanics and kind of translate them back into the classical world. That's not a perfect analogy, but there's enough kind of pieces. There's enough kind of pieces of it that you can actually take a lot of quantum manipulation techniques and look at their classical analogs. And our inspiration comes from, in particular, quantum adiabatic computation. So what is that? I'm going to give kind of a very high-level description of it. So in that type of, you have some kind of like quantum system. Typically, people imagine like a series of interacting spins. And the idea is, here I'm showing a very simple configuration of this. Very simple configuration of this, but in principle, you can actually achieve very complicated configurations because you could have control of the local magnetic fields at each spin site. And the idea here is you want to achieve a certain ground state of a very complicated configuration of magnetic fields. And if you achieve that ground state, that actually encodes the answer to a particular computational problem. And if you can achieve that ground state, you can read off the answer, and you've just done a single quantum computation. Now, how would you actually achieve that ground state? Well, you would first start off with a very simple configuration of local fields. For example, all magnetic fields pointing up, all the spins align up in the ground state. And then there's a theorem in quantum mechanics that says if I now infinitesimally slowly change my local fields, I will always guarantee to remain in the corresponding ground state at all times. So eventually I change my local fields to the final configuration that encodes the problem. I'm guaranteed that I have the ground state. I guarantee that I have the ground state. I'm still in the ground state if I start in the ground state, and I get the answer. Now, the problem with this paradigm is you've just taken an infinite amount of time to do a single calculation, which is kind of not such a great computer. So, of course, in practice, you have to do this in finite time. Now, if you were to do this naively and just, okay, I'm going to speed everything up, the problem is that you are not always guaranteed to remain in the ground state. You might get excitations, and then if you get excitations, And then, if you get excitations, so you have your final state is superposition or some excited state synchronous state, there's a chance when you read it off, you will get the wrong answer. So, to actually fix this, people have come up with kind of a clever strategy. There's a variety of different things. They go now under a whole field called shortcuts to adiabaticity, but there's one particular method which attracted our attention, and that was essentially what's known as the counter-diabetic approach. And this is from a series of papers in the early 2000s, where what you're essentially doing is you're Where, what you're essentially doing is you're adding a term to your Hamiltonian. So you can think of this as modifying the local fields at each individual site in just the precise way so that you're always guaranteed to cancel excitations. So you can still remain in the ground state at all times. And then you're guaranteed, even if you do a finite time process, that you'll get the correct answer at the very end. The attractiveness of this method is that it's completely closed form. So you can write down the solution, you know, you can. It's a three-line basically proof. You can actually teach it to another graduate, a quantum student. And so you get this necessary perturbation that you need to basically cancel out the expectations. So this kind of attracted our attention. And the idea was, can we actually then take this and make an analogy in the classical setting? So, what's the analogy going to, how it's going to work with the evolutionary system? So, in our quantum case, we have a sequence of ground states for each. Of ground states for each field configuration. And in the evolutionary case, it's actually going to turn out that the ground state in the Schroder equation is going to correspond to the equilibrium distribution of the corresponding upper plane. So you can think of this as a sequence of equilibrium genotype distributions that are defined by each drug concentration will have its own equilibrium distribution. And then if you want to hit the target in the quantum case, you're going to modify the local fields. And in the evolutionary case, Fields, and in the evolutionary case, you're actually going to be modifying the drug concentrations over time in order to basically guarantee that your system follows the sequence of distributions. That's the basic idea. So, what's the attractive part again? You can write down a closed-form analytical solution to this. The details, the mathematical details are in this reference, but I just want to show you kind of a concrete numerical example of how this works in practice. For really, what was the simplest case you could imagine? Yeah, oh, yes, you mean that we're. Are we assuming that the response to drugs continuous response to drug? Typically, I mean, the drug responses are modeled kind of like hill functions, right? So, yeah, if you have kind of, if it's not differentiable, you'll run into problems, at least with this methodology. There's probably other ways of going around that kind of road. But yeah, in this original methodology, you assume continuous responsive road. Yeah. Quick question. In the quantum case, you have to kind of engineer a counter-diagnostic. Contra engineer a contra diabetic Hermatopian term. I wonder in this case, is that something in addition to the control over lambda that you have to yeah you're gonna be engineering essentially another term that term basically takes the form of a modified drug concentration right yeah so it worked I mean if you had to engineer a term which was impossible to actually implement biologically then we'd be stuck happily for many of the examples we've looked at that extra term that you engineer can be actually you know either exactly or approximated by just basically changing the drug concentration. By just basically changing the drug concentration. Yeah. So, in the case of the one case, you have the local perturbations that are happening at all basically, right? With the drugs, do you think all the gene expression levels have to be changed or specific ones have to be changed? Yeah, so generally speaking, the drug will affect every one of your genetic variants. And so, you're basically having, you know, you're changing everything at once. Now, you can add, if you have, if you want more fine-bate control, perhaps you might want to choose additional control points because I'm more than. Additional control panels because I'm more than one truck. And we're actually exploring that as well. Just something which I wanted to add in from my about is in single cell RNA genomics data sets, what we are seeing is when cells start taking different states, not all the gene expression levels are changing. And interestingly, the ones which change between two states are not the ones which affect the change. So there are other genes which small perturbations of that actually take. Of that actually takes you through the visualization. So it's a bit interesting here that the difficult thing is to find out where you would add the local perturbations. That's the difficult part. Yeah, so there are a lot of questions like that. In such a examples that we've started with are cases where we have a completely understood kind of fitness landscape, right? We're looking at a particular gene, and I'll show you an example right now where we have essentially a single gene that we're looking at with a finite set of mutations. Mutations. But you're right, that there's going to be mutations that are not accounted for. And so we're looking at, in some sense, the single-cell RNA sequencing data, or even bulk RNA sequencing data, something that we're actually actively thinking about. In that case, you're getting a more kind of global perspective on the system. You're not sure about this equation, so I'm a little bit confused about linearity, because uh even like a simple logistic row to have a finite capacity will be a nonlinear term and Will be a non-linear term. And if you did you do you linearize somewhere or no, there's no linearization here because effectively it's uh you know you have an equation which tells you you know the time derivative of your probability distribution is then an operator acting on your probability distribution. That worked, you know, that's you know that's the same for the you know time-dependent Schrodinger equation or for the Focker plane equation. That's essentially the structure. Why is it linear? Because if there's too many of my Newtons while time, But the Newton's while type the relationship should be smaller because it's a finite it's crucially I mean you you can have non-linearities in the interactions and etc. all the you know complicated biology but it's crucially linear in the probability distribution that's what that's what allows the the whole thing to work yeah um yeah um so you're basically writing down imaginary plans for the equation for all the functions right so getting rid of all the So getting rid of all the you know using quasi-mechanics is that you have I and so you when you write at indigenous things work and things fix and stuff like that. For Fokker-Planck equation, I mean there's not too much, right? So you basically end up dealing with the problems that you can you can write down a path integral for Fokker-Planck equation, but it's not gonna sort of simplify the problem. Yes. So here you actually do not need to import the entire kind of pathogical formalism. The analogy is in some sense simpler than that. All you have to do is basically look at, for example, express a solution in terms of eigenfunctions. In the quantum case, each eigenfunction is going to be multiplied in time-dependent case by e to the i energy times t. In the Fogger-Planck case, times t. In the Fokker-Planck case, basically you get e to the minus lambda times t, where lambda has a positive real component. And once you make that analogy, everything that you do in the counter-diabetic case for quantum, you can then import directly into the classical case. So it's actually, it it's really not that that difficult. So uh the other thing that's maybe relevant for the nonlinear case is when you actually write down you know Actually, write down control problems. So, evolution of population, stochastic evolution, you know, right for the font, you can do packets, they go all of this, and you go all kind of well-established, it's great. But then, once you add a control, like external control, and you want to maybe look at optimal controls, let's say, then all of a sudden all your stochastic processes become non-linear in your probabilistic distribution. So, what you're doing is kind of in between, if I understand correctly. There is already built in nonlinearity. So for example, all the response to drug is entirely non-linear. So you want to have a non-linearity. So the derivative, the partial derivative of both distribution should have cured. So for a forward dynamics population, that's fine. You can write a few transpired equations. If you transfer equations and everything is linear and good. But then once you add optimal control or semi-optimal control, then you actually get, you know, if you're trying to optimize something long term, right, then because you have to solve the problem backward in time, then things become non-linear in probability. So, yeah, so I will get back to the optimal control problem, I mean, get here a little bit later. But so there's trade-offs. Optimal control allows you to optimize. So optimal control allows you to optimize a particular objective function, but you end up with these extremely complicated equations that typically you have to do numerically. You have to solve numerically. Here, you specify which path you want to go along from the beginning. And once you do that, you only need the forward equation, and you can basically solve it, you know, the control protocol in closed form. Now, whether that particular path is the optimal path is not clear, right? But there may be cases from the practical perspective where you want to drive the system. Practical perspective, where you want to drive the system, you know the beginning and end point, you want to avoid certain regions in the parameter space, so you choose a path and say, How am I going to drive the system along that particular path? So I'm not trying to optimize anything at this point, but there is an interesting question of how these pantry diabetic problems, you know, how they relate to it. You know, do they in some sense approximately optimize particular measures of dissipations in the abstract sense? There are optimal problems that they can't really answer practical, but so. But so your objective function here is really remain your quality of your asset. Yes, at least in this initial example, yeah. Okay. Okay, great. Okay, so just numerical examples. This is a case of an experimental system where they put a yeast, where they took a gene from the malarial DHFR gene, they plugged it into yeast. They introduced mutations at one of four positions, so you could actually write all the mutants as a kind of bit string. Zero means no, no. bit string, zero means no mutation at the position, one means there's a mutation at the position. And you can actually then measure, it's kind of a laborious laboratory experiment, you can measure the growth rate as a function of drug concentration. And each particular drug concentration will have a certain equilibrium distribution of genotypes because, you know, certain genotypes will be winners, have high growth rates, certain will be losers, have low growth rates at any given drug concentration. For example, here at low drug concentrations, the 1110 genotype has the highest growth rate, so it has the Highest growth rate, so it has the largest distribution of the largest. Choose a particular drug dosage protocol, so I'm increasing from low drug to high drug, and I was to look at the way this population evolved, each individual drug concentration would have a certain equilibrium distribution. For the top four genotypes, I'm showing that equilibrium distribution, the frequency here on a log scale as a function of time as a dashed line. Of time as a dashed line. But if you were actually to just implement this directly, what you would see in reality, this is from a single vector, would be that your system would typically lag behind your equilibrium distribution. This is the exact analog of the, you know, if you're doing this in finite time, you will get, you know, expectations of the quantum system. In the case of the classical Fogg of Klan, you actually get lagging behind your instantaneous equilibrium distribution. If I was to do this infinitely slowly, of course, the solid lines would match the dashed lines. The dashed lines. But using this kind of prescription to calculate these additional fields that you need, you can actually get the system to directly follow those dashed lines. So the prescription gives you a modified drug concentration, which in this particular case includes kind of a spike to speed things up in the middle. You can impose kind of like, you know, constraints. You can put maximum drug cutoffs here. And you essentially can get the system to basically follow your. You can get the system to basically follow the chosen path very nicely. And this is a case where, because this is an experimental system that people have already characterized in the past, we're actually now working with a collaborator, Kerry Samarath at Arizona State, to directly test this kind. These are all simulation results, but we're working to directly test this and validate it in a laboratory setting. Now, this kind of methodology, though, to kind of add this perturbative field and to kind of try to steer your population, it's not. Population, it's not just limited to evolution, it's not just limited to continuum systems, right? There's a whole set of biophysical models, for example, that can be described as kind of biochemical reaction networks, where you might have, for example, a discrete state, and your system transitioning between those discrete states with some kind of rates. Now, because those rates can be controlled, in some cases, certain of those rates can be controlled by external concentrations of chemical species, you have then some control knobs, right, to tweak your system. Control knobs, right, to tweak your system. And again, you can ask the same question: can we then drive the system to a certain sequence of probability distributions? And we can actually even generalize this question, right? So we can ask, for example, the problem that I described to you before was essentially, okay, I specify a target path, a curve of probability for each state, and that curve of probability happens to be the instantaneous equilibrium probability for each concentration. For each concentration, but I could generalize this. What if it was a totally arbitrary path that I chose? Or maybe I'm only interested in particular states, right? I'm not interested in controlling every single state. I'm only worried that there's one particular state that I want to avoid, perhaps, and I want to just control some of the states, a subset of them. And so you can have essentially what we call global control, local control. You can have instantaneous stationary distributions, or you can have completely arbitrary ones. And the question is: can you then solve this problem in the context of these kind of discrete state Markov models? Markov models? And the answer to this is yes. You can actually, again, I'm going to, in the interest of time, I can't go into the mathematical details, but you basically start with your Markov state description. There's a whole kind of machinery of graph theory that you can apply to these types of networks. And you can actually characterize the perturbed fields that you create in kind of graph theoretical terms, in terms of the fundamental cycles and spanning trees of the underlying graph. And you actually find these fields. And you can actually find these fields that basically perturb your underlying description, which in this case is a master equation, not a Fokker-Planck, and give you a, you know, allow you basically to say that the system is going to actually follow a particular target in probability series. What's interesting about this is generically, if your graph has loops, you'll actually have infinitely many solutions. And the methodology actually allows you to basically enumerate, you know, basically in closed form, all possible such solutions. So you're going to have these widespread. So, you're going to have this widespread degeneracy of possible solutions. Let me just give you a very quick example of this. So, consider, for example, a three-state network. In this particular case, it corresponds to an operator, which you can have a repressor bound to it, or you can have a repressor and co-repressor bound. And that final state is the one that, of course, maximally turns off the gene. This is a case where all the parameters have been characterized experimentally, and each individual edge here depends. And each individual edge here depends on some concentration of ligands in the back, whether they're the repressor or co-repressor or the complex of those. So, for a particular set of concentrations, you can calculate equilibrium probability distributions. You can basically simulate this directly and just solve the master equation. You'll see that, like in the case of the evolution, your actual solution will generally lag behind your instantaneous equilibrium one. Equilibrium one. So in this particular case, we're still keeping kind of the everything is in the same equilibrium. It's not arbitrary. So this is kind of directly analogous to our original evolutionary example. And we can now add a perturbation to these concentrations to basically make the solution directly fit the target. But this is not the only solution, right? This is one perturbation to those three different concentrations. Here's another one that also makes it follow exactly the same target. There's an infinite variety of these solutions. And then you can actually begin to ask questions over this is something that we're exploring: like, what are the thermodynamic properties of all these sorts of set of possible solutions that hit a particular target? You can ask things like, for example, entry production rates, which we heard about earlier this morning. And these different solutions, even though they hit the same target, because they involve different rate constants, will have different rates of entry production. And among the entire space of solutions that hit a target, you can then ask, well, what's the solution that optimizes, you know. That optimizes instantaneous entry production at every single state. So, this would be an example of, for example, in this particular case, having a particular type of objective function that you're trying to optimize. And that, in this particular case, that set of concentrations looks like this solid graph curve. Okay, so you can do this now. Again, this is direct analogy, total global control, but you can also generalize this, right? So, you can ask now questions like, wait, what if I'm only interested in a subset of those things? only interested in a subset of those things to control. So I specify that the states from 1 to nt, I give some functions rho for those states. Those are my targets, but the other ones are totally arbitrary. I'll call them pi. And of course, by definition, now you're not necessarily going to be trying to hit an equilibrium distribution because you're only caring about a subset of states. And let's say maybe you only have a subset of your edges that can be influenced by external rates. And let's call that the number of such edges EC. They're drawn here, the controllable edges as dark. Controllable edges as dark red arrows, the controllable states as solid blue circles. So, in this particular example, let's say you have four states that you want to control, and you only have these, you only influence rates at these particular locations in your network. And here it turns out that you can actually introduce a concept known as a target subgraph. So, for each target state, you look at the connected subgraphs reachable by the controllable states, and those are kind of outlined in the dashed lines here. So, this particular example has three. So, this particular example has three such target subgraphs. And there's actually a very simple graphical criterion to tell you whether you can actually do this control or not. And that's basically saying the idea here is that every target subgraph must include at least one non-target state. So when you have such a target subgraph, you have to at least one state, which is a white circle here. So in this particular case, that criteria is satisfied. So local control is possible. In this particular case, it's not, right? Because this target subgraph does not include. Because this target subgraph does not include any non-target states. And one consequence of this is also it's impossible to have local control if your number of control edges is smaller than the number of target states. All right. So, yeah. So, but since global control is possible, does it mean that local control is not possible in the sense that only global control would be possible? So, this question, I mean, global control basically you would ask, okay, you would just get the whole thing. You would have just get the whole thing. Oh, yeah. So, in these types of things, when you specify the targets, if you want to get to the global control limit, one of the states, which is your, you know, let's say you have n states, you're basically only specifying the targets at n minus one of them, right? Because the probabilities all added up to one. So you have that one last state, which in this, if you want to kind of generalize this local control thing, would be your quote unquote non-target state. And then the target subgraph would, if it includes that, you're totally fine. Yeah. You're totally fine. So, this and everything here in local control, you can show mathematically reduces the global control in the appropriate limits. So, there's no inconsistency there. So, in the last couple of minutes, just I want to show you just one example of kind of implementing this kind of global control. And this is in the context of chaperone-mediated protein folding. So, proteins in general are kind of under constant threat of misfolding and aggregation. Even at normal temperatures, it's going to be a fraction of your proteins that tend to go to misfolded states, which then That tend to go to misfolded states, which then have a propensity to aggregate. And so, you know, cells have developed systems, essentially chaperone proteins, to try to mitigate this. And the idea here is that the chaperone protein will try to preferentially bind your misfolded protein, catalyze unfolding of it to some kind of intermediate state, which then gives you another chance to go into the main state. And this might happen over and over again, but it basically tries to get you out of this misfolded state, which is. This misfolded state, which is potentially dangerous. Now, what's interesting about this is that this loop here generally involves hydrolysis of ATP. So it's actually a non-equilibrium stationary state, which is now tweakable because you can control things like the concentration of chaperones or the concentration of ATP. And the other thing that's important to note about this is that in normal kind of conditions, almost all your chaperons are occupied. So there's not too much spare capacity because it's a bit expensive to. Expensive to maintain these kind of chaperone population levels. So essentially, then if the cell goes into like a high-temperature environment, you have to create more chaperones in order to be able to deal with this temperature rise. So here's two experimental examples, one from yeast and one from E. coli. So I'm showing relative mRNA expression levels, kind of a proxy for concentration of the protein as after heat shock. And you can see that there's this kind of Heat shock, and you can see that there's this kind of spike in almost in some cases by two orders of magnitude and then kind of leveling off. And in E. coli here, in this black curve for DNAK chakron, there's a similar kind of spike. E. coli, interesting enough, also has a spike in ETP during that process. I'll explain maybe why that might occur. Okay, so just this last few slides. So let's imagine you're in a situation where you only have a single You're in a situation where you only have a single control knob, right? Where you only can basically, you can basically change chaperone concentration, increase it according to some protocol. So this would be kind of corresponding to the yeast experimental situation. In this case, if you're interested, for example, if your target is to get rid of, you know, to minimize the probability of being misfolded, because that's the dangerous state, you can essentially have a single target subgraph. You have one controllable edge that looks like this. And in this particular case, the theory. And in this particular case, the theory tells you that you can only basically, you can basically arbitrarily choose a particular target for your probability of being in state one. So here, for example, in the dashed lines is a target where we're very rapidly decreasing probability of being in state one. And the corresponding concentration that does that basically has this characteristic overshoot, which we saw in the experimental case as well. So this kind of qualitatively suggests that essentially nature and doing this kind of upgradation of children. This kind of uprimmation of chapters is in some sense doing something qualitatively similar to local control of the misfolded state. In the E. coli case, you actually have two control blockages, right? Because you can also influence this catalysis rate through the concentration of ATP. And the theory then tells you that actually you can control two things. So you can also control state number two, which is the state of the misfolded protein bound to chaperone. Now, in the previous example, you saw this kind of accumulation of chaperone on the misfolded protein. On the smoldered protein. So kind of this transient peak in stage two. And now, if you have this extra control with ATP concentration, you can get rid of that transient accumulation. So you can actually free up your chaperone to do other things. And that's essentially the way you accomplish that is by spiking your, effectively, your ATP rate transiently during this control. So E. coli may have evolved actually a system to do kind of not only to get rid of, you know, to minimize folic probability, but also perhaps to minimize the probability of being bound to the. Bound to the chapter, which is beneficial. So, this sentence shows that in principle, it's not just an abstract theory, but nature actually has the tools to implement these types of control ideas directly. And we're actually exploring different ways of extensions of this in development biology, in ecology. So, it's a quite general kind of paradigm for doing a particular type of control in these systems. And with that, I'll thank my collaborators at CASE and Themon Clinic. At CASE and Thema Clinic, and also Instagram QEMs and Systems. Can you go back to your last slide and share the last thing? If you know properties of node one and node two, can you get out of your formulas the probability for the local control state that you don't know the local control state? Once you choose a particular control control, is that just a drawing or no, no, this is the actual. A drawing or no, no, this is the actual, this is the actual, this is the mathematical result, right? So these other curves that we basically weren't interested in, you know, once you, once you, there's actually some freedom there as well. There's actually multiple solutions. Even once you specify some of the targets, there often are multiple solutions of what the other problem is. What do you need as input to generate all this problem? In some sense, you need to know, you have to have a description of your system. So you just need to know the individual rates between the states. But that's it. Between the states. But that's it. That's what it is. I've got to talk to you. Okay. Yeah. So if you have a constraint on which rates are kind of externally modifiable, like can you since you have so many possible solutions, does it mean that for certain constrained rates that you are allowed to modify, that you still will find a solution by only modifying a few rates? Or do you have any kind of bounce there of how many? Any kind of bounce there of how many rates? Yeah, so well, you do have to satisfy these criteria, right? So you have to make sure, first of all, that the set of controllable rates that you have kind of is sufficient for your particular target that you're interested in. And then even within there, there are some additional criteria that, for example, you want all your probabilities to not be even zero and one. That actually puts a kind of weaker constraint, which oftentimes is automatically satisfied, but there are, there's sometimes. Satisfied, but there are, there are sometimes you have to do worry about things that are not there. In this particular case, for these cases where you try to decrease the misfolded probability, you run into, there's really no additional strong constraints on your system. It seems like it's a very robust way. You will always be able to arbitrarily rapidly decrease the misfolded probability using these types of protocols. So, but I guess more precisely, does it mean that you only need to usually be able to control rates that are kind of close to the nodes that That are kind of close to the nodes that you want to control, or could there be rates of control? Yeah, well, in some sense, yes. You do have to satisfy this local control criteria, which means that, yes, because every target subgraph must include at least one, the target subgraph are the nodes you want to control. And you basically, it's the subgraph reached by the controllable edges. So in some sense, the control, but edges should be speaking to your targets. If you're trying to control things with edges very Trying to control things with edges very far away, you know, you won't be able to do that. I mean, maybe there'll be special individual solutions that are still possible, but at least you won't be able to arbitrate, you know, to implement an arbitrary protocol if your edges are far away. Thank you for a very stimulating talk. I think we will stop there. So would you be willing to look at the map? Would you be willing to look at this question from a macro point of view? COVID. I was just so curious about whether or not I use the data to predict the area. So, what would be my control in some sense? What would be the way of kind of perturbing the systems? Vaccinations and proximity. It's proximity and time. And I can show you the image. And then it just struck me. I had no idea about this graph theory theorem. Yeah. Once that's a part of the