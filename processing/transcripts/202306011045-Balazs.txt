Okay, thank you very much, everyone. Thanks for the organizer. It's my first time here, and it's amazing. Thank you. 20 years ago, on my first day, I rode in Valac home. I went to see Timo, and he showed me an office, said, This is your office. These are the classes you're going to teach. And I will be fourth store if you ever need me. So I went up quite a number of times. Quite a number of times in the period that came, and it turned out to be my most productive three years. So, thank you very much, Timo, for those three years and also for the years after. And let me also wish you a happy rebirthday on your first day of being monitore. I was told, I mean, you told us we're not allowed to mention your birthday anymore, but I see if you can mention your rebirthday. One more disclaimer, Nicholas Gerby, you told me that Nicholas Gerby, you told me that I inspired him for the animations. I here we'd give up the competition. Way beyond me and not competing anymore. Okay, so I'm going to talk to you about some stuff which I did a couple of years ago with Offware and Timo. This is our latest one with Timo, so that's why I'm doing it here. It's about the coalescence of part 3. So everybody in here knows Lance Passage calculation, the exponent. Last passage calculation, the exponential classical case, the exponential case. So I'm going to go through this very quickly. So I call the geodesics between two points A and Y pi of A Y and my weights on the Z to my I are the exponential ones. And everybody, I believe, here knows the Guzman functions. So I'm just going to look at the Guzman functions across one edge. So I'm going to refer to them as increments. So I look at the Lawrence force each time to x minus the Lawrence force each time to its left negative. Minus delta plus each time to its left neighbor from a common starting point A. And the difference between these two times I'm going to call ix. And the difference when it's a vertical edge, so last position to x minus its south neighbor, I'm going to call that jx. And these increments are actually quite useful in a lot of ways. Here is one way they are useful. Suppose that I want to look at the longest path from A to Y, and I have a smaller kind of rectangle closer to Y. Closer to y, so I have kind of a smaller piece of this last passage model. And I'm interested in the longest part, the geodesic, that falls, the part of geodesic that falls into this smaller rectangle. And my claim is that in order to figure out what this looks like, I don't actually need to know all of these paths, assuming that I know the last brassage increments, these Boozmans. So I can just optimize from this corner, for example, along these Bozmann values and the Values and the bulk weights, and I can forget about whatever my class looked like before that. Okay, that's again a well-known property. Last passage, it came up in some of the talks on the landscape as well, so this is quite trivial. So it's going to be important for me that this smaller boundary, the smaller rectangle boundary, acts as a good boundary for a smaller model. For a smaller model, if I know the values of the Given function. So, what is a stationary aspirational creation? Again, I'm going to go through five minutes because people here, most of them, know. So, if instead of looking at point-to-point LPP, between point A and point Y, I'm going to modify things a little bit. I'm going to replace the exponential one weights on the boundary by exponential rho vertically and exponential one minus rho horizontally, then I get something called the stationary aspects. Model. Called the stationary last percentage model. So these weights are still high, ID, everything is completely independent of everything, but the distribution is modified. So you have this row parameter between 0 and 1, and that's the stationary last precision model. The statement is for, or the statement of the stationary is that if I do that and I look at the increments on a smaller rectangle, in fact I look at the increments on any downright path, they are still independent of each other, they are still independent of whatever reads come from the upper right side, and they still have this structure. And they still have this structure that horizontal increments are exponential rule and vertical increments exponential one minus rho. This is an old result from 2006. What I want to show you, okay, so this implies that this small rectangle in the stationary picture has the exact same structure as the original, and that's why I call this stationary. Now, what I want to show you is actually a proof of this. Why am I coming up with that? Because just a year ago, like 16 years before we did that, after we did that, Before we did that, after we did that, I just found a new proof, a nice intuitive proof, which I want to share with you. The original idea came from Berg's theorem in TASAF and in Qing. But if you don't want to go to particle systems or Qs, here's another proof you can do. So here's the picture. It's going to be the basic ingredient of this proof is kind of a recursion step done on one square. So the square has upper right corner x and it has its exponential one weight omega x. And here I have the horizontal increment and the vertical increment. I'm also going to complete these two edges to make it a square, actually. So I look at this point here, x minus c1 minus c2, and then the corresponding increments are there. So the Lance Passage percolation basic recursion tells you that if you want the Lazfastisch time to X, what you need to do is look at the left neighbour, the uh south neighbour, take the longest uh of the two Lauspass times and add your independent omega x in this corner. Independent omega x in this quarter. That's the very definition of last passage. So just a few lines of elementary calculations here. So if you subtract the last passage time at this point, g of a and x minus c1, then you subtract the same thing here, so this becomes zero. In other words, you start talking about a positive part, because you take the maximum of zero with something, so that's a positive part. You subtract the same quantity from that guy, and you can easily rewrite this in terms of these i and j increments. Terms of this I and J increments. So this is the definition of my I increment. This is just the difference between two last percentage times horizontally. And if I subtract the common last percentage value on this lower left corner, then just a second or so three reals that you start seeing the horizontal increment down here and the vertical increment on the left there. So you rewrite this recursion in terms of these i and j's. And you can also do that by subtracting the other Las Plus. The other Nasras each time there, and then you arrive to this because that's just a way of rewriting the image. It's very classical. So here it is again, but there are too many indices, so let me just simplify notation. So on the right side, I'm just going to do i and j, and on the upper right side and the lower left side, I'm going to do u and v. And so here is the recursion again. You can get this horizontal increment from u and v and omega this way, and that one. Omega, this way, and that one from that way. So it's exactly the same thing, just simple notation. So here is the lemma. Here is the basic lemma of stationary. Suppose that the u and the v are independent, exponential 1 minus rho and rho, as in my stationary boundary. Suppose that the omega up here is exponential 1 and they are all jointly independent. Then if you do this transformation, then the i and j will be independent of each other and they will have the same distribution. Other and they will have the same distribution exponential variable rho. And if you also introduce the minimum between u and v, it's going to be exponential one. And these three will also be jointly independent. So that's the element to 11 which I want to prove to you. Okay, so all this was very well known. We did this back in 2006, so this is very long, very known. But I saw that this is a cute little proof I want to show you, and this is so it's not a big deal, but I think it's worth the months. It's worth seeing once. Okay, so what do I want to do? So I have u exponential 1 minus u b exponential rho, and for some reason I introduce this minimum of the two. And I want to visualize these random variables. What's the first thought that comes to mind? Of course, two Poisson processes, right? So take a Poisson process of intensity one here and color the marks independently with probability rho blue and with probability one minus rho red. So mark the Poisson process with two colors. Then how can you read of U, V and Then, how can you read of u, v, and z? So u is exponential 1 minus rho, and obviously it's going to be the location, or it could be, the location of the first mark on the red colour Poisson process, right? And V is going to be exponential rho, so it could be the first mark on the blue colour Poisson process. One could come before the other, I don't know. It's a probability, right? It's a random event. And then you have omega, which is completely independent. It's not on my picture. But Z is on my picture. But Z is on my picture. So what is Z? Z is the minimum of U and V, but you can, of course, also consider it as my first mark in the uncolored Poisson process, right? Because you got U and V from coloring the original rate 1 Poisson process. So Z is going to be this guy here, exponential 1. Now here's the key insight. U minus V, so the difference between these two guys, which could be positive or negative, is independent of Z. Why is that? Because Z is my first. Why is that? Because that is my first mark in the original Poisson process. And u minus v depends on how I color the marks and how far the subsequent marks come after the first one. Those are independent things. So u minus v is independent of z. That's all I need. So here it is again. And now I'm going to start to look at this triplet here. So I have u minus v, and I have z, which is independent. And I have Z, which is independent of that, and I have omega, which has not yet come into the picture. So, of course, it's independent of the other two. So, omega is independent of these guys, and these two are independent of each other. In other words, this triplet is completely independent. Which means, and they have the right distribution, so omega is exponential one, z is exponential one. If I swap the two, I still have three independent 20 red volts of the same joint distribution. All right, so now. Alright, so now I'm going to do u minus v plus plus omega, v minus u plus plus omega, and z. I'm going to look at this triplet. What is this triplet? Well, before I tell you what this triplet is, first, because of the same distribution property, I can swap omega itself. And I have the same distribution, right? But what is the first one? The first one is by definition i, j, z. I is by definition this guy. J by definition is. J by definition is this guy and Z is that. And what is the second one? Well, take the minimum of U and V, that's Z, add the positive part of the difference, that's U. Take the minimum of V, or U and V, that's Z, add the positive part of the other difference, that's V. Still they have the same as the proof. No more enjoying functions, no verb TRM. I mean, I guess it's Verb TRM in some way, but okay, just for some processing. Okay, just pull a sound processing. Okay, so from here it's very classical. So, how do you complete the proof of stationary? You do the corner flip procedure. So, you have your IID weights, exponential row, exponential row minus row, and they are all independent and independent of these weights here. You apply the lemma on the lower left corner. So, you replace these increments by those increments. And you know that what you get is independent, these two are independent of each other. And of course, it uses the omega here, but it doesn't use any of the omegas there, so it's still independent of the bulk omegas. It uses these two weights, but not the other weights, so it's completely independent of these other weights. So now you have a new kind of path, a downright path, which goes like this. And it still will have, according to the lemma, the right distribution, and everything is completely independent. Keep doing that, you keep flipping corners until you reach your new boundary. So now your new boundary. Boundary. So now your new boundary has the corresponding distributions and it's independent of whatever you see in the power. Okay, so that's the proof of stationary. So inside here you have the same structure. Right, now let me tell you a bit more about first our results back in 2006 with Eric Cutter and Eric and Timo. A result viewed as today is quite weak. The boundary is quite weak because internal chromatic. Quite weak because integral probability could do much better. But back at the time, we were quite happy with this. So the result I'm going to use, and again, integral probability can do much better now, is that if you now fix this parameter rho, which is 0 and 1, then there is something we call the stationary direction. And the geodesic in the stationary model, which I denote by green, so it's not the point-to-point I talked about before, it's using these modified boundary rates. My boundary rates with the station energy on the thing. It wants to go in that direction. So it wants to hit these boundaries more or less in this direction, which is characterized by 1 minus rho square and rho square. It doesn't do that exactly. It's going to fluctuate around it in the order of box size to the to the third, and that was the old result we had in the continuum back in 2006. By playing with row, we can actually aim the stationary past in a way. If we In a way, right? If we change rho, increasing rho will increase the parameter on the vertical side, so that will decrease the weights on the vertical, and it will increase the weights on the horizontal. I'm looking at the long-term pass, so increasing row will, if I'm right, it's gonna just push my likely exit point more to the right, and decreasing it is gonna push up. I hope I was screwed a bit too much. In the wrong place, in the wrong place. It's in the wrong place. So if L is box size to the two-thirds, that's when you have more than one probability. Anyway, you get the point, right? It's around here, up to book size, I think. Right. Okay, so just a side remark that you don't actually need to impose a stationary boundary to see it artificially. If you do point-to-point and you move this A down to negative infinity along this direction, To negative infinity along this direction, so you zoom out and you keep moving this point, automatically you start seeing this exponential arrangement. So that's another kind of manifestation of stage. Okay, so this is all well by most of it. Here is the first result we proved a couple of years back with Rofer and Timo. So take this stationary picture, okay, so green is always my stationary last percent, geodesic, and take the point. And take the point-to-point on the same picture. So the black one is point-to-point. It doesn't feel the modified boundary, it just feels exponential ones that you have. And the first result we have is that these two will coalesce somewhere. So if you go point to point and you do this stationary, if you look at a small box of size n to the two-third times some constant, with probability going to one as this constant goes to zero. So small. Constant goes to zero. So small factor times n to the two-third box, if you look at that, with a high probability, the two paths will have coalesced. You will not be able to tell inside whether the path started with the stationary boundary or it just started with the without boundary from the point A. Okay, the bound we give is again just unpower law because we do not use integrable input. Offer and Patrick Ferrari, quite soon after that, added a bit of integrable input in it and improved this pound much, much more. Can improve this bound much, much more. That's the first result. The second result is that now you look at two point-to-point paths. So one started from A to Y, the other from B to Y, again not feeling the stationary boundary. So black is always point-to-point without stationarity. And you take them n to the two-thirds apart, where n is again the distance between these two and y. And then again, the coalescence will happen somewhere in a macroscopic proportion. Proportion. So the probability that the coalescence happens, so if you look at the coalescence horizontal coordinate D, the probability that the horizontal coordinate is less than a small constant times the full box size goes to zero with that constant. But the probability that n minus d, so the other side of the coalescence point, is smaller than a small constant times n, again goes to zero with alpha. Okay, so coalescence will happen in a macroscopic proportion of the full length. Full length. That's the result we had. And again, so we did this with internal probability. I show you the proof. But around the same time, Basusarka and Sly and Bolswang had a similar result. I think they had stronger results again using internal. Alright, so let me sketch the proof of these. And to do that, I'm going to tell you a bit about the joint boundaries, the one which Offer and other people are talking about in the case of last passage. I'm not going to In the case of last passage, I'm not going to do the station parallel, I'm not going to do more than two boundary parameters, I'm going to only do two. So it's simpler than what we saw before. So now, if I want to do exponential boundaries, so I have the exponentials, what's your first thought? Well, of course, your first thought, if you have a problem, is to look at the Poisson process, right? And the Poisson process has increments or distances of million miles, as the higher the exponentials. That's not what I want to do. I want to complicate things slightly. So, what is Slightly. So, what is also an exponential random boundary? Well, I'm going to look at my Poisson process, but I'm going to add another Poisson process of a slightly bigger parameter, bigger intensity rule. And I'm going to play the ML1Q game. So, I'm going to consider these as arrivals and these as potential service times. And then, here are the customers. So, they come somewhere, they wait for their turn, and they get served. Berkeley or M tells us that what comes out of this game, That's what comes out of this game is a Poisson-Lambda process. That's the classical Berkeley theorem for Q's. So if I measure the increments here, which are the exponential lambda, that can act as my lambda boundary. So that's a slightly more complicated of doing the lambda boundary than just doing a quantum process. Why did I do that? Because now comes this construction of the stationary multi-line boundaries. I can embed the exponential row boundary in this. Exponential row boundary in this picture in the following way. I'm going to look at again these services and I'm going to count the service times of customers. I'm going to look at how long customers stay at the server in the server monthly. So I'm going to show you a couple of examples, but for now, let me just say again. So here's a customer arriving, they spend some time in the queue, and this time is recorded, and that turns out to be a And that turns out to be a exponential low random variables. And here is the work of Louis Fannen and Timo from 2020. But these kind of constructions in particle systems, I believe, came from Pablo and James Martin's work. This kind of construction, so I have now two sets of IA, the exponential. IID exponential weights, the IID across the line, but of course they depend on each other heavily. This set of joint exponential boundaries is going to be stationary for last passenger. Not only I have an exponential boundary which is stationary, this joint boundary for two different parameters is also going to be stationary. So let me show you a couple of examples. What I want to concentrate on is the following fact. As you see in a second, the output is the As you see in a second, the outcome of these two exponentials is going to be very similar in most cases. So let's see what can happen. So here's the customer. The customer arrives at this point, but at this moment, if you think about this as time, at this moment it sees some other customers in the queue, so it has to wait. It's going to wait until this point, and this customer starts service at this moment, and the service length is going to be this one here. Okay, so the service length out. Okay, so the service length output, which is my exponential row, is going to be this length. The original output of the ML1Q is going to be that length, because that's the inter-departure times. And as you can very well see, these two are equal. So I'm going to record the same exponential variables, the same realization of the exponential variables on this boundary included. That's because the customer who arrived saw a non-empty queue, so the service time was the same as the internet. So the service time was the same as the internal departure time. Okay, here's another customer. Again, they see a non-empty queue, so the service time they spent here is the same as the internal departure time of the whole queue. So the recorded exponential rates are the same. Now in this case, here comes a next customer, but the queue is empty. So they start service immediately, and their service time happens to be this small, whereas the inter departure time is much longer. Departure time is much longer. The inter-departure time is this length here, the service time is only that length there. So, this is the service time, this is the inter-departure time. So, now we have a difference between the Poisson, the lambda and the exponential lambda. This is when the two boundaries can differ, if the Q is empty. And then it happens here again, so the Q is empty, service time is short, but inter-departure time is a bit longer. One more example of that, but eventually it might. Example of that, but eventually it might return to a busy queue, in which case the service time is the same as the inter-departure time. So this exponential weight will agree again. This is how this coupling works. You have this Q, you have the service time, you have inter-departure times, and if lambda is close to rho, so the Q is almost critical, then in most of the cases, the two outputs will be equal. And it's going to be very rare that the Q is different, that the exponential rates differ. Exponential rates differ. Okay, so that was the main observation which we use. So let's go back to the results we want to prove. We want to prove coalescence here with the stationary path and the point-to-point path. So how do we do that? We're going to say that we can fix another parameter, lambda, and we can play with lambda and we can play with rho a little bit. So that with high probability, the exit point here in green, with the rho parameter, is With the row parameter is on the right of A, and the exit point in red is above A. Because of this result we had back in 2006, we can play with the parameters like this happens with high probability. In other words, we can squeeze between two stationary paths the point-to-point paths, the black point-to-point paths. And if you work out how how we should do that, it not not it's not hard to see that the difference between lambda and rho should be box size to the minus. In other words, the two parameters are indeed close to each other. Two parameters are indeed close to each other. If the two parameters are close to each other, that means that the Q is almost critical. So the output in this joint stationary construction, the output on the two boundaries, the lambda and the rho boundaries, will almost be the same in most cases. But then you use joint stationarity to say that, okay, in this smaller box, I again have this joint coupled boundary with the same parameters on bandro, which are still close to each other. If this is not too numerous, If this is not too numerous, if this is not like more than n to the two-thirds, which it is, then with high probability, the queues will actually not become empty in this region. So you can do just, it's essentially random walk, right? In the stationary queuing picture, with high probability, you will never see an empty queue in this region, meaning that the two boundaries will just match as realizations of random variables, they will be exactly the same. If the two boundaries Exactly the same. If the two boundary is exactly the same, then the paths inside will have no way to tell whether it's the one boundary or the other, whether it's the lambda boundary or the rho boundary, because they happen to realize the same numbers. So whatever happens inside for the lambda process and for the rho process will be exactly the same, with high probability. Otherwise, the guys coalesced. And because they squeezed in the point-to-point path, and because paths can also form a loop. Coast path can also form the loop. You now have the squeezing property, and now you have that the point-to-point pass was actually coalescing with both the red and the green guy. So that's how coalescence works. Notice that it wasn't actually important what I look inside. Anything I look inside will have the same argument applied to it. So in fact, I can say that we hold geolocoracy actually. Not not only uh pass to Y, but pass to any map. Passed to any map. So that's the coalescence for protein. Now, the other thing is that I can actually do this trick with two point-to-point pass, which was one of the other statements I made. So now let's add another one, which starts from B. If this distance is m to the two-thirds, then I can essentially repeat the previous argument. And not only am I going to squeeze one point-to-point pass between two stationary things, but I can squeeze these two guys at the same time together. The same time together, which implies that these two guys must have coalesced before reaching this small box. Okay, so that's the proof of coalescence of point-to-point. And in fact, a careful look at this reveals that in fact this little box doesn't actually need to be in the corner. I can pull this a little bit forward. It's a small box, it's only size n to third, but I'm free to move it a little bit forward. In fact, I'm free to move it macroscopically to position alpha times m. Alpha times M. And that's how you prove that coalescence must happen in a proportional distance to M. Okay, so you can boost this argument a little bit to get what you want. All right, we've seen talks about the stationary horizons, so I'm not going to comment this too much. When you do this for more than two uh parameters, you get a whole process of parameters that's head to the stationary horizon. But for this proof we only need it for two different uh values. Two different uh values. And then finally, I want to tell you about uh coalescence uh too soon. So, so far what we did was that they have to coalesce before reaching this warm boss, so they cannot coalesce too late. Let me show you that they cannot coalesce too soon either. If you want to do that sorry, again, so what's the statement? You start a point to point from A to Y and from B to Y, they are entering two-thirds apart. They are actually two-thirds apart, and you want to show that coalescence will not happen sooner than small alpha times n. So it's not going to happen very close to where they start from. How do you prove that? Well, again, you're going to realize two different stationary paths. By playing around with parameter lambda and rho, you can make sure that they both start between A and B with high probability. And if they do so, sorry, and they still are different a little bit, so that they start. A little bit, so that the starting points are likely to be actually two-thirds apart, then if you want these guys to coalesce very soon here, they must have coalesced already the stationary paths as well. Again, the squeezing principle. But stationary pulse don't like to coalesce too soon because that would mean at least one of them has to deviate from the natural direction by n to the two thirds, and for that we have bounds. So transversal fluctuation bounds show you that that cannot happen with large problems. Happen with Marshall. So, this is actually a simple argument. It doesn't actually use any of these QAs. And that's it. Thank you very much. Have you thought of that or other models where you can do a similar Where you can do a similar kind of something like a Poisson process construction for this perk type? I believe that all of these tissue polymer models have some kind of a similar interpretation. We have this family of four, right? And this last classage I'm going to be not. I think they all have some kind of problem with interpretation or anyway. I mean when we first checked this we came to the in last message we came to it via vertical from JSAP which was a natural way but then in the paper I think we just check it with more energetic functions and it's a bit less there should be there should be something like this for all models and probably there in some of the cases there are I'm not sorry I'm not very expert in control We have a bit of a break till starting at 11:35.