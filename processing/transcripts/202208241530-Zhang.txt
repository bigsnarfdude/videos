Before I came here, I thought a socket variable is some variable that you can use to describe something you cannot measure or something really complex to describe. But after two days of learning from this workshop, I really learned a lot. I found this probably is off topic. So let me start. Let me start. This is a joint work with two of my students with underline, two of my students and my collaborators. So everybody knows the COVID pandemic make a massive negative impact on us. If you search, you can see a lot of different numbers and facts. So I just like Like, I do not want to repeat those things here. Everybody knows this is really big. So, as a statistician, I was considering what can I contribute. This is one work that we contribute here. So, first, we want to ask us some questions. So, what are the key factors affect the COVID infection? Specifically, we are interested. Specifically, we are interested in the impact of lockdown because in the community, even in the academic community, people don't agree. Some people think lockdown is good, some people think lockdown is bad. So we want to use data, use our own analysis, try to give the public or give the community some opinion from our side. So to answer these questions, To answer these questions, we started searching for data available. So these are the data we use. First, we found Hopkins has the research center. They have a daily count of that is the county level. We have 3,000 counties in US. We have daily count in the infection. Really count in the infection, death, recover. So, all different of things, all different kinds of things. We just want to focus on the infection. So, we want to use this as outcome. So this gives us a trajectory, like a daily trajectory for each county. We want to know what factors can change the shape of the trajectory. So the factors we consider are like a county-wise demographic factor. There is a very good database called American Community Survey. This is a very rich database. You can use there is an R interface. You can use that to access the database. So basically from here, we can find a whole lot of information about each county. Most importantly, because we focus on lock. Importantly, because we focus on lockdown, so we have to know what are the lockdown dates. So I believe lockdown have very different role because we have multiple lockdowns, especially the later lockdown, they probably play different roles. So we want to focus on the first lockdown. So to make our problem simpler, so we can get a reasonable answer. Can get a reasonable answer. So, and the next is the non-pharmaceutical intervention. We found this data from Oxford COVID-19 government response tracker. There is a GitHub for this. So we found data from there. So basically, this information includes something like government policies, different kind of policy. So these are all our data. All our data. So we consider this is the major objective we want to know, and others we are also interested. And we also want to adjust to other factors because we don't want others confounding this. So these are our data set. My students spend a lot of time collecting from this data, put them together. So here are some overview of the method. Uh, overview of the method. Um, so from this talk, you can see I'm a very applied statistician. There is nothing like a fancy method here. We just want to ask important question. We want to find the proper data. We want to use the most simple method to answer our question. So the first thing is the trajectory is something really complex. How can we characterize the trajectory? So we will use the functional PCA. So we will use the functional PCA. I will describe that very soon. We are lucky after functional PCA, we found the first PC explain 93% of the variance, and the first PC have a good interpretation. So we can convert the trajectory into one variable. That was what I thought that was a surrogate variable. But now I think we can just say we use that variable to describe the outcome. The outcome. So once we have this, the problem can be very simple. Very standard problem, we have one variable as outcome and a whole bunch of predictors. We want to find the relationship. So as you can see, we want to find the timing of the first lockdown. So how to model the lockdown is a very important thing. We tried a few things. We found a timing of first lockdown is the most Timing of first lockdown is most informative and without too many noises. If you deal with later lockdown, maybe like the vaccine or other things will get involved. So we found that the signal for the first lockdown may be more pure. And most importantly, the first lockdown play really a big role. So like I mentioned, demographic factors, MPI, all of them have been. Uh, MPI, all of them as predictor. Uh, first, first thing, we just do some scatter plot to see the relationship and build some regression model to see the marginal effect. Um, from the marginal effect, we found the relationship, some relationship is not linear. I will go into that very soon about segmentity regression. And finally, we use the last unite to find the joint effect. Uh, let me go into the detail. Me go into the detail. I'm not an expert. I believe in the audience, a lot of experts of FPCA. So I just want to briefly introduce this thing. I'm just a user. So we want to model the log count, the daily infection count. We model the log value as a function of time and county. So I and G are indexed of, I is index of county, J is index of time points. Is the index of time points or days? So, we want to model this as a function of time. So, there is an average curve or average trajectory for all of the counties and each county, the trajectory will be some function added to the average. And the phi orthogonal basis function. So, these functions are orthogonal, and the coefficient is called like a functional PC score. score. So this will be used for the outcome. So basically from the longitudinal curves or from the trajectories, we want to learn, convert each trajectory into the scores. We can think this way. So it's similar to PCA, but a functional PCA, you can incorporate the time order relationship. And working with function, we can Working with function, we can smooth the curve and the denoise, remove some noise. So we map each trajectory into a functional space. The orthogonal function defines the axis and the coefficient is the coordinate. So there are standard software you can use to fit this model to learn the functional PC score. PC score. So after we see the functional PC score, surprisingly, we found 93% of the variance can be explained by one variable. Maybe some people think it's not a surprise because a lot of people, when they come in, they will think about exponential growth. So exponential growth, that means that you only have one parameter. So let's see. So let's see what happened here. So basically, these are the proportion of variance explained by each PC score. And this is the first eigenfunction. So because we are working in the log scale, so exponential growth means we will have a linear function. So this is clearly not linear. So we add for each county, we multiply this function by a scalar. function by a scalar and add it to the average. So that is what how we reconstruct the curves of the trajectories. So what scalar we multiply by this to this to this function is basically the PC score we want to use to explain the trajectory. As you can see, all of the numbers are positive. That means if you have a positive scalar, that means this that means this county have overall like a higher number of infection. And this part says like the change is not consistent, not consistent along the time. So anyway, we summarize this. We decide just to use one variable to We decide just to use one variable to describe the trajectory. And here are some visualization. We visualize the first PC score on a US map. We found in the east coast, west coast, we have really high PC score. In the middle, we have a lower PC score. That is like, so this information not only describes the Information not only describes the overall infection count, also some speed, like the speed, how fast it grows. If you have a bigger number in the beginning, you will grow much faster than others. If you have a negative number, you will grow slower than the average. So this map tells us two information: overall count and the speed of grow in the beginning. So we have a collaborator, like a causer, is a medical doctor. He explained this in the paper. So that's not my expertise. So basically, he believes this agree with his intuition. So now we can move on. So we decide the outcome variable converts the trajectory into a single number. We can use a very standard method. Something I want to highlight is Something I want to highlight is for the for the lockdown, how can we model the lockdown? We try the like a time to the lockdown time to the number when a county have five or more case, then from there we count how many days do we lock down. So we want to use the time to see. As you can see, if you lock down very early, you could have some benefit, but not really. some benefit but not really uh not very strong uh so but uh if you lock down too late uh after some point some some uh some date um the the pc scar will like grow like crazy uh the the later you uh you the later you lockdown the worse it will be like uh if you see this number bigger that means that county will have a faster growth in the beginning and the overall high Beginning and the overall high count in the whole period. So to find the inflection point, we fit a segmented regression and find the change point, which is about seven or eight days before the lockdown. So this information tell us if we don't adjust to other factors, so basically we should lock down as early as we can. The lockdown as early as we can. If you lock down, when you see five case, it's already late. The first lockdown must be fast, otherwise, it will be bad. I don't think this results hold for other lockdowns. So for the second, third, or even later, I think maybe some lockdowns may be not necessary, or maybe even worse. But the first lockdown, we must do it fast, as fast as possible. possible. And using the cutoff, like before the before before that date, after that date, we can separate the US counties into two groups and we can see these are their average the infection count trajectory with the confidence interval. The red one, I think the red one are the county who has a late lockdown and the blue one who has The blue one who has an early lockdown, you can see in the beginning the growth speed is different, but after some point it will become kind of parallel. On the very top, it shows us the proportion of lockdown, the proportion of county that lockdown. As you can see, about 30 days after five counts, every county locked down. But early lockdown, all of them locked down in the very beginning. Down all of them lockdown in the very beginning before even five counts. So the late lockdown can change quite differently. So again, we found late lockdown will cause problem. So the next thing is we have so many parameters. What should we, we should look at their joint effect just to some variables. Adjust to some variables. So, this is very standard. A lot of methods can do it. We just use Elastinite. So, before we use Elastinate, the ACS, the American Community Survey Data, it's a really big database. We have to discuss with the medical doctor to decide what he thinks is an important factor. So, we manually select some variables and then we use elastinide. And then we use Elastinite to do further selection. The good thing in Elastinite is it helps us automatically select a variable and it's easy to interpret because the model is just a linear model with some phenotype. The bad thing is we do not have confidence interval. In the literature, many people have done that. So we basically generate a huge lot of random subset. In each subset, we repeat the analysis. Then we can get a lot of Then we can get a lot of different results. We construct the 95% confidence interval. So after we do this, we found six predictors still remain. The most important predictor is this, the blue one. The third one, basically, that is the slope after the inflection point. So that means the so So, this is a variable like made we constructed by like x multiplied by x larger than the inflection point. So this is related to lockdown timing. So, again, look at all of the results. We found lockdown timing is the most important. We also found other things, not surprising. We found population is a big thing. If a county have a lot of population that is a busy county, there is higher risk. That is a busy country, there is higher risk, and the age is an active thing. So I think this country from here, we want to give the community some advice, like maybe lockdown, we can do it personalized, not similar to personalized medicine, but this is not to the people, this is to the community. To the community. Maybe for different communities, we can look at their risk factor. And for some community, we can have like a bigger, like a more strict, more strict rule. For some community, like a lower risk, maybe we can do it like easier. Here are the conclusion. We want to let the community know the first lockdown is really important. Uh, the first lockdown is really important. We should do it, and we should do it as early as possible. Um, and the government should lock down even only five cases when there is no vaccine. So, because this is the first lockdown, when there is vaccine, probably the story can be totally different. So, after the critical time, things can get really bad. We also found like a population. We also found like population, family income, genius index, mobility of the county can be important factors. Other MPI, we didn't see they have a significant effect. Only lockdown timing is great. So here are some future work we are interested in. So first is when should we stop lockdown? Because lockdown comes with a lockdown come with uh come with some negative impact as well uh sometimes not lockdown maybe do not even help the covid so at some stage we should stop the lockdown this is a very important question if we can answer uh like what are the important the impact of other lockdowns other lockdowns can be really messy uh if you look at the the data uh so that needs a more complex mathematical model to to to model Model to model what has the impact are others like the second lockdown, third lockdown, even more. How does vaccine affect this impact? Because after the first lockdown, the vaccine can kick in like a negative impact. So another thing very interesting is I see the literature, many people model these counts together, like infection, deaths, recover. We do see that in the Hopkins data. The Hopkins data. So maybe that is another good future direction. So here are the availability of our work. The paper is published in e-clinical medicine. This is a new journal with good impact factor. And the code for reproduce our result can be found from the GitHub. If you want to use the data, you can find the data from can find the data from the COVID count you can find from Hopkins and ACS you can find from this website. There are some R interface you can read directly from R. Here are the MPI data and the NBC news about lockdown. This is a hard lesson we learned. Actually, we work in the very beginning of COVID. We have the idea, we want to do it. Have the idea we want to do it, but we work in a quite relaxed style. After half a year, we found lesson. Lessons, they have a sub-journal called Lesson Global Health. They publish their paper. Some Indian researcher, they use their account and their community survey data. So they did very simple. They just fixed the date. Then I got the count. I do the association publishing. I do the association publishing really high-impact journal. And after a few months, Yama has another paper. So that gives us really big trouble. When we submit these to Lancet Global Health, they reject, but they suggest us to transfer to this journal. We did the transfer and it came out. So if I do it again, I will do it faster because so many people work on this. A lot of people have a similar idea. So thank you everyone. I think this is the off-topic talk. Hope you get relaxed after listening to my talk as a rest. Okay, so thank you very much. It's a very interesting talk. We have five or ten minutes for some questions. So Layla, we'll start. So, Layla, we'll start with you. It's my job to have a question. So, it's more of a comment that, and first I'll say I have not worked on any COVID and might use the wrong terminology here. And second, like I said on the first day, with almost anybody, if you tell me what you do, I can tell you how it's surrogate markers. So, I'm going to tell you how I see this. Tell you how I see this. So, um, to me, you know, at the beginning of COVID, everybody was talking about cases, right? It was all about case count. And again, I am not an expert, but it's very much seemed like over time, people started saying, actually, we don't care about case counts. We care about hospitalizations from COVID. We care about deaths from COVID and deaths from COVID versus deaths. Versus deaths with COVID, very different. And that I do know something about because at RAND, we had to deal a lot with like coding for COVID. And, you know, if someone enters hospice care and they have COVID as the primary diagnosis, does that mean that they are in hospice care? You know, they're dying because they got COVID or they just happen to have COVID when they came into hospice care. So it's a big mess. But it seems to me that really, you know. You know, probably when the lockdown timing happened, since we were all talking about case counts, then we did care about the impact of lockdown timing on case counts. But at least selfishly, what I would want to know is like, how did lockdown timing affect deaths from COVID? And it seems, you know, that's a much harder thing to measure. Case counts were all over the place, right? There were all these websites that had case counts everywhere, and anybody could just download. Counts everywhere, and anybody could just download them. So, to me, you're basically using like a longitudinal surrogate that's these daily case counts over time. Um, so it's a longitudinal measure as a surrogate for like total deaths in the county from COVID. And so, your whole outcome here is this like summary of a longitudinal surrogate measure. So, you're just using a surrogate as your outcome. And I know Dennis will talk also tomorrow, I think, about how you. About how you like evaluate, you know, validate a longitudinal surrogate for an outcome. So that's all. So it's not totally off topic. Yeah. Thank you, Layla. Yeah, the deaths and hospitalization are also in the Hopkins database. If you like, you can find counter there. Yeah, especially for the follow-up lockdowns, maybe the infection probably is not a thing because we do find the signal is really messy. The signal is really messy, but if you focus on deaths or hospitalization, probably you can find some interesting story. Right, yeah, thank you. Hi, this is here. Can I also say a few things? Sure. Yeah, we've been looking into this quite a bit also. And I would actually turn it around to what Leila said. I think in the beginning, and that's actually my concern a little bit. A little bit. Case scams were really, in a way, well, unreliable is not the right word, but there was a strong under-reporting. For example, if I look at Belgium, but it's not any different anywhere else in the world. We reported like we confirmed, test confirmed, like about one in 30, maybe even only one in 50 cases came summer 2020, the Northern Hemisphere summer. This had gone up to one in three, to maybe one in five. In three to maybe one in five. Nevertheless, the evolution in the case count is useful, and I think it remained useful for two years following. There has been a lot of debate from all angles, politicized, yes or no, on the use of case counts, but its evolution has always been informative. And think about it as a surrogate for the total number of cases, which you can only estimate with, for example, Can only estimate with, for example, mathematical models. At the same time, I think it's indeed also useful in retrospect, in particular, to study hospitalizations and mortality. When it happens, while it's ongoing, we're in the heat of the action, so to speak, then of course these are late indicators. And by the time you see the effect of a surge on mortality, it's way too late to take measures. And I think that's a very important message that we can take. Very important message that we can take away from the talk, but from many other similar pieces of research. You need to act early. So that's one of the many advantages of case counts. It's also, and this is basically dovetailing in the next presentation, I think, it's also why we have to look at other variables like, for example, the workload for GPs or wastewater. And that's wastewater surveillance is something. Wastewater surveillance is something that here and now, as we speak in Belgium, is giving a signal, whereas case counts are going down, hospitalizations are going down, but in wastewater we see the reverse signal. So that's why we are on alert right now, even though it's not fully visible yet. A few small other comments are: it's of course also good, and you mentioned that to take mobility into account and that of And that, of course, may spill over into even a spatial analysis. A county, a county has its own signature, and you refer to the Gini index, you can think of the ethnic composition, etc. Maybe not population is one thing, but also population density is something you may want to look at. So there are a number of things that you can take into account as covariates, in addition to the stringency, because when you refer to the Oxford government tracker, essentially you're referring to stringency or the components of stringency. Stringency or the components of stringency. Well, in addition to that, you may also want to take characteristics of a county into account. But there are exceptions, but many counties, think for example, of a city like New York or Los Angeles or New Orleans or etc. Of course, they don't live in isolation. It's very important to realize, to understand, and to take into account in your models what are the The streams of mobility from that county into another county. Think of the early days in New York City when in New Rochelle there was a huge outbreak. The next thing that happened is that the city was overrun with virus. And we know what that led to, of course. Well, these are a few reflections I wanted to offer. I'll rest my case here. Thank you. Okay. Thanks, Georg. One more question from Boris. From Boris? Thank you. Yeah, I just wanted to comment a little bit. We did a similar work, but with French data. And one thing, so just to after what Leila said is one of the difference between what we did and what you did is this trogate marker that you chose, the summary from the functional PCA. Summary from the functional PCA. And the approach we took was to actually do an epidemiology SER type modelization and work on the instantaneous transmission, which we had for every day from the model and work the regression with that. And so that was interesting as well in the sense that we didn't need the We didn't need the Elastic Net component because we had a lot more data, because we had data each day. And also, we could incorporate data from the case, but also from the hospitalization and from the death through the SIR modeling. So I just wanted to comment on that. And yeah, I thought it was related. Sorry. Okay. Okay, so I think we're going to go ahead and move on. We can probably come back if people have more questions at the end.