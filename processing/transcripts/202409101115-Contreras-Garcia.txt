As you can see, I have totally or very much changed the title of my talk, though I have kept a bit of superconductivity because when I said this to Alberto, he complained. So I've kept a couple of slides on that. So I've changed the title because I realized that actually had lots of bits and Actually, I had lots of bits and pieces of work done on kinetic energy. So I thought since this is a workshop, it was the perfect place to actually put all this together, which again, it's bits and pieces, but hopefully I can give some overall story about it. So, why do I have all this information, all these bits? These information, all these bits and pieces about kinetic energy. So, what just as wrong in the previous talk, what we usually do in calculations is we go from structure to energy, and once we have our minimized structure, we can calculate the properties. But if we actually think about the history of chemistry, The history of chemistry, we didn't need all that because we could actually understand different conformers and their properties just from understanding their chemical bond. And this is a lot of information that has been put together through many years that we're actually somehow not using that much, probably because this information was qualitative. So, how can we use all this information? Use all this information and hopefully in a quantitative way is what we care about in my group, which is the chemical interpretation group in the Laboratoire de Chimit√©rique in Paris. This is the view from the university. As you can imagine, this is the wonderful view. So it's from the administrative building. It's not from my office. So again, going back to kinetic energy, if we care about the chemical bond, why do we care so much about kinetic energy? Do we care so much about kinetic energy? Well, actually, we can understand a system made of localized orbitals. And once we have this, imagining a chemical bond somehow, we see that since the kinetic energy density is given by the gradient of the orbitals, if we have each region being nearly monodeterminantal, then this gradient is going to give us a pretty much good. Give us a pretty much good idea of where electrons are localized because they're going to be somehow slower. And this relates to something that actually Rong already introduced. So what I'm going to be talking about today a lot is the electron localization function. So we have here, so what is it? It was interpreted by Andreas as an excess of local kinetic energy density due to polar repulsion. Kinetic energy density due to polar repulsion. And what does this all mean? So basically, we start from the kinetic energy density and we get away the bisaka term. So what we're left with, it's called the polykinetic energy densities, how much, how faster electrons are moving because of the fact that they're fermions. Now, this is a kinetic energy density, and that's probably one of the things that we were actually hearing yesterday. It depends on the electron density. So it actually The electron density. So it actually peaks at the atoms. There is no structure in here, no shells revealed by the polykinetic energy density, even though we could think that it should be already contained in that. So you actually need to divide by the Thomas Fermi gas, so the first order in the expansion, to actually have some shell image. And then the electron localization function. And then the electron localization function is just this quantity mapped so that it goes from 0 to 1, and so that we have maxima where we have localization so that it looks like orbitals, localized orbitals. So let me show you one example. Here we have the nitrogen molecule. So we have nitrogen cores, we have nitrogen, nitrogen bond, and nitrogen lone pairs. And as I was saying, this is the polykinetic energy density. We only see peaks in nitrogen. No shell structure whatsoever. No shell structure whatsoever. It is not until we divide by the Thomas Fermi gas that we do get a shell structure. And that's something very important that needs to be emphasized. And that's also something beautiful. I usually tell my physicist, the students, that they can somehow get away without knowing chemistry if they know how to use these tools. Because here you don't need to be able to draw this Lewis structure if you know how to draw these kinds of pictures. Here you can see that. Pictures. Here you can see that electrons are relatively slower where they're paired. So in the lone pair, in the core, and in the bond. So you do get your Lewis structure, you do get your chemistry from the molecule. Now we do the mapping, and so we have maxima where we have localization. And here, the red line is the electron localization function. If we actually, instead of doing the polykinetic energy. Doing the polykinetic energy density, we do the bite-sackle term over Thomas Fermi, we have the blue line. So you can see that actually this normalized, if you like, or Weizager term is pretty much equal to the polykinetic energy density in the course, but it is not in the balance. So we do get very different behavior in these kinetic energy densities depending on which region we are in. On which region are we in with. So one of the things that we wondered at some point is: since we have very different kinetic energy densities and certainly other energies related to the different chemical regions, how about we try to understand the energetic terms involved in these different regions? And for that, the first thing we can think of is since we need to be able Is since we need to be able to differentiate these different regions, then we do a topological partition. So basically, here we have this island, we look at where the maxima are and where the valleys are found, and this is a topological partition. We do the same, and it has important properties. These regions are non-overlapping and they fill up the whole volume, so they're additive. So, if we do this, for example, So, if we do this, for example, to the electron density of lithium hydride, we can divide this lithium hydride into lithium and hydrogen. We can integrate properties within them. So we can see that it's, for example, we have two and two electrons, so it's a hydride. These values have a chemical meaning inherited from the fact that these maxima do have a chemical meaning. And these properties are additive. So, So, we can also do that to the energies, and that's called interacting quantum atoms. We can actually integrate energies over each of the different basins, let's say, and the total energy will be the sum of the energies of each of these parts, fragments, and the interaction between them. So, each of these energies will have a kinetic energy part. Will have a kinetic energy part, a classical electrostatic interaction, and exchange correlation. Since, remember that what we wanted to understand was the energies in the different chemical parts of the molecule, then the topological partition that we want to induce should be given by this chemical region. So, we use what we need is to use a partition here that is related to this chemical partition. So, the electro-localization function is a good option. The electron localization function is a good option. So, we basically did the interacting quantum atoms, which is usually used with atoms in molecules, with the electron localization function. And with this implementation, we can have a kinetic energy and all these terms for the different parts of the molecule, so the lone pair, the bond, and so on. And their additive. Let's see how it works. So, we started with very simple models. So, we started with ethane introducing functionality. With ethane introducing functionalization, so nitrogen, oxygen, fluorine, because they're simple. And we can actually see how the charge accumulates in the lone pair. So you can see here how it goes from 2.2, for example, for the nitrogen up to 6.8 in fluorine, and how this also is concomitant with depletion in the carbon-carbon bond from one point eight till eight zero point eighty five. 0.85 electrons, and we can calculate the energies related to each of these parts in the molecule. So, I'm going to show you the amine, but basically we get similar results for all the systems. Here you have the electrostatic energy. So, you can see that we can get the intramole, the intra-fragment, so the intra, in this case, carbon-nitrogen bond, and also the intra-fragment. Nitrogen bond are also the interfragment terms. So, in this case, it's the bond with the carbon atom or the sorry, here, or the bond with the nitrogen atom over here. As you can see, we get different trends that we can actually explain with a simple monopole approximation. For the kinetic energies, we have again so. Again, so in this case, sorry, I forgot to say. So, what we were trying to do was stretching each of these molecules to see how these energies behave. So, here we have the kinetic energy in the lone pair and in the carbon-nitrogen bond. So, basically, when we actually fitted these terms, which as you can see in all cases, they behave very easily, it was pretty easy to fit, they behave. To fit, they behaved like what had already been obtained in the Bond trans model. So basically, inside each of these chemical regions, we have a homogeneous electron gas behavior. But obviously, it changes from one fragment to the other. So, in a sense, we have a discontinuity, but in this case, it is 3D and it changes completely from one region. It changes completely from one region to the next. So, yesterday that we also should care about exchange correlation. So, this method also allows us to see how exchange correlation changes from one chemical region to another. So, here we have the different terms like the bond with the carbon, bond with the nitrogen, and the lone pair with the nitrogen. Again, very good correlation. Again, very good correlations that we could fit. And as you can see, the extinct correlation is very small with respect to kinetic and Boulogne. So in a sense, what we have with this is something in between having the kinetic energy of the total system or the local kinetic energy densities. Now we have kinetic energies associated. Kinetic energies associated to each of the chemical regions in the molecule. And as a matter of fact, they behave in a very, as you can see, in a way which is extremely easy to parametrize. So, what we thought was in collaboration with a Mexican colleague with Margarita Bernal was to obviously Bernal was obviously since we have analytical expressions, how about using it for a force field? For a force field, which it's different from what we usually think of a force field. So in this case, we don't have interactions in between atoms, we have interactions between electron pairs. So the interesting thing is that, for example, since it's electron pairs, we don't have the issue of coordination on how to Coordination on how to transform a bond, like how to make a reaction, because these electron pairs can directly transform one into one another. This is ongoing work, but I wanted to show you just, for example, the fit of kinetic energy densities for lone pairs and for hydrogens. Here we found that actually we had a convergence issue. So this is fixed. So, as I was saying, these are bits. As I was saying, these are bits and pieces. Half of it is work ongoing, but it's just to give you an idea of how we can actually use these kinetic energies or hope to use these kinetic energies, regional kinetic energies. So, if you've done topological partitions, then you must be thinking you're kidding me because I'm showing you that we have an I'm showing you that we have analytical expressions, but if we want to use them, then we need to know where the lone pair is and where the bond is. And for that, we would need to do anyway the DFT calculation and the topological partition, right? So another part of work that is also ongoing is how to actually avoid this part so that everything can be coupled together. And for that, we were collaborating with people from high pressure in the metallization. From high pressure in the metallization of hydrogen. So it's data from a collaborator from GENG from Abinitium Molecular Dynamics at 1500K. So here you have the electron localization function for hydrogen going from molecular to metallic, in this case, to atomization. As a matter of fact, this is something that we'll come back later to. Here you can see this. Here you can see these things are very localized and they become faster with metallization. So, this is basically a characteristic of metallization that I'm going to be coming to later on. So, actually, when we do the, we have our wave function calculation and we calculate the electron localization function, that actually means that we end up with a grid of L values for each snapshot. Values for each snapshot, molecule, whatever you want to call it, which is plenty of data. So we said, okay, how about using this with machine learning? So we took randomly 1% of this data, so very little, and the structure, so where the hydrogens are. These were like 500 atom box hydrogen atom boxes. And we have We have a very nice collaboration with people from mathematics, and so they actually worked on a neural network that would try to get the L values from just distances and angles, so just the structure. We used the MD data we had, so the set for molecular and for atomic. Atomic and this is the qualitative result. So here you have the calculated atomic, sorry, molecular and metallized, and here the predicted with ML. As you can see, they look pretty much the same. So we have qualitative agreement. From the quantitative viewpoint, here you have the histogram, it's logarithmic scale. So basically, we should be over here if we got all the good results. It's yellow. The good results. It's yellow over here, so it's a pretty good result, but we still have outlayers in the mid-range, so around there in the electronicalization function. That's something we're trying to fix. So assuming this can be fixed, we could also have, well, as you can see anyway, the position of the maxima are there, so that's something we can get. So then we could actually hope to couple both things. Actually, hope to couple both things. Good thing about this is that at the beginning, the 500 hydrogen box was taking just delve computation, 25 days. So we could only do some snapshots and we had to do the FT. Once it is trained, it took less than three minutes and we could do it for the full trajectory because we only need this structure. So, in a sense, I've shown you two bits and finished of how to predict. Of how to predict the kinetic energy for regions with forces and how to get the potential for each of these regions. Sorry, how to get the topology and how to get the interactions. I said at the beginning that we care about not only the chemical bond and the energy, but also the properties, and that's where I'm going to show some of the applications that we've been doing in superconductivity. That we've been doing in superconductivity. So, here you have the ELF picture of this Lanthanum high-grade system, which is superconducting. And here, what I'm showing you is actually the graph that we can draw from these LISO surfaces. What we did is, remember I showed you that when it is a metallic system, everything is kind of delocalized. So, actually, this can. So, actually, this can be translated into having a complete graph, so delocalized over the full cell. So, electrons are easily localized over the full cell at a high L value. That would mean it is, we basically have a high density of states at the Fermi level typically. When we do this, sorry that it comes. So, when we did this for a data set of like For a data set of like 170 systems, hydride systems that were already known, we actually managed by mixing this feature from the topology I just showed you with the hydrogen fraction and the density of states on hydrogen at the Fermi level. When mixing all this, we actually got this correlation, which we could also obtain from sign-bolling regression, though at that time we did it by hand. And I don't know why, but the But the typography of my slides has changed to a more fancy one. Just so that you know, in case you're using PowerPoint, then you might get some stylish refurbishing. So we got this expression for the critical temperature in terms of this quantity. It was the first time that First time that a sufficient condition was obtained for critical for estimating critical temperature. Why is this important? So, as a matter of fact, like me, so these things influencing critical temperature were already known, but were not sufficient. They were necessary, not sufficient. So, in a sense, you had to introduce somehow this metallicity concept inside. Why is this? Inside. Why is this important? And I forgot to add the numbers here, but typically for the lanthanum hydride I showed before, if you want to do an accurate calculation of Tc, it's like 3000 CPU hours. With this, which is pretty easy to obtain after developing a code that that's what I did visually, it takes nine minutes. So it actually means that you can do a high throughput. And that's And that's what we're doing now. So we've coupled this approximation to a structured prediction code. And please don't take pictures because it's unpublished. My students would kill me. So basically, what was I going to say before they kill me? Yeah, so now with this fast. So, now with these fast estimates that are again related to kinetic energies, which can be related to how electrons behave in our structure, to our chemical bond localization and delocalization, we can actually understand properties like chemists have always done. So, have a grasp of what is going on with the properties of our system and use that. And use that to exactly what chemists were doing. So, get a fast idea of what's going on. So, basically, obviously, we're not doing an exact calculation. We are just getting an idea that can be used in high-throughput screening, because otherwise, if you have a 30,000 CPU hours calculation, you will never be able to do a structure search. Shubin, you will have to tell me when I have to finish because I'm always horrible with timing. So that's the first thing I wanted to show you on kinetic energies. But I also wanted to show you something that is related. So what I've been showing you, especially with the electron pair force field, is that we can actually get insight by using regional energies or taking. Or taking so this intermediate step into the whole system or pointwise, and that's something that we had already done for other energy terms. So a long time ago, just after my postdoc with Weitao, where I met Erin, Erin had been working, well, she was obviously very much aware of how hydrogen and helium floodplain condition. Helium flat plane condition can be met if you actually use Becker's non-dynamical correlation energy, exact exchange, and Becker-Russell correlation model. So, where you actually need to have an idea of the effective occupation of the orbitals in order to introduce the correction here in the non-dynamical part. So, what we did is we used a core valence partition to estimate this number of electrons. Estimate this number of electrons in other S elements. And so we were able to also obtain the flat paint condition in lithium and sodium. So that was another way of using topology to actually go into energy terms. And some other thing that we did later on. So while I was also with Waita, we worked on the NCI index, which is basically related. Which is basically related to the Weitzacher term over Thomas Fermi. And it can also be used, as we just saw in the previous talk, to visualize non-covalent interactions. So just to give you an idea, it can be used to visualize hydrogen bonds. We have here water dimer, formic acid dimer. So we have these regions over here that appear when we have a hydrogen bond. We have flatter surfaces, extended ones, when we have a surface. Surfaces extended ones when we have kind of undervalued interactions, like we have here benzene dimer and methane dimer. And it can even go to repulsive interactions like Branch octane or bicycle octane. So these regions are actually pinpointing to where we have non-covalent interactions. So obviously, the next question is: can we actually use those somehow to get Somehow, to get a grasp of non-covalent interactions, non-covalent interaction energies. So, we did, we started with the S22 benchmark set. Here you have some DFT errors. As you can see, obviously, we need to introduce this person to correct them, but they're still pretty big. Obviously, the first thing to do was a regression. So, what we did actually was to integrate the Integrate the get the volume and the charts related to these interactions and when you do that you see that it correlates pretty well well in I mean not so bad if you take into account that these are the results for for example D3 lib D this is done with promolecular densities which means that we did not do the energetic calculation we just energetic calculation we just used non-self convergent densities. Obviously the point in all that is to think of methods that could give us an idea of non-covalent interactions in big systems where we will not be able to do our DFT calculations. But another thing that we tried was to actually use it as an extra piece of information with machine learning. So with a kernel retreat So, with a kernel regressor, we corrected the bit relib D, which was the best DFD estimate of our group, going from 16% error. We used a bigger data set, S66, with the different stretch positions, and the MCA information I just showed you with promolecular densities. And we got an error down to 6%. We also used the volume from over here. From over here. As a matter of fact, when using this information, the weight for the energy went down as from some other pieces of information we tried to use. So it did correct. It did contain some energy information. Here you have the different results for the different samples. So we have the DFT results. That's the error. So we want a zero. We want a zero for DFD for DSCC corrected, and then with the kernel in red. So, with this, I'm done. Again, I've shown you basically many things that are not finished, but which are all related to how to understand energy in regions, including obviously kinetic energy, and how they actually fit pretty well when we. Actually, it fits pretty well when we consider chemical regions. How we can hope to use it in new potentials which are electron pair based. So, for that, we actually need to know the topology of the system. So, we've machine learning it, or we are machine learning it. So, it's a general thought on all this. So, how to actually use this in Use this intermediate information of energies in regions that we have already used for correlation and dispersion. And here are the people who worked in these projects. So from Sorbonne, from the Basque country, from Poitiers. So this is Yvonne, who is our collaborator in mathematics through the ANERC Synergy Project that I want to thank because he's funded. Because he's funding my trip here. And thank you for your attention.