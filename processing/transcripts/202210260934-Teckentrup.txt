Can I stop? Okay, yeah, she's going to talk about key process, process regulation in e-merge products and the macrowave team from the panel. Okay, thank you very much for the introduction and thanks to the organizers for the invitation. I wish I could be there in person, but I'm teaching at the moment, so it's very difficult. I'm teaching at the moment, so it's very difficult to get away. So, what I want to talk about today is joint work with my colleague Costas Degalakis and our joint PhD student, Tian Ming Bai. Usually, I start by explaining inverse problems and Bayesian inverse problems, but I think I pick in B quite fast on that part for this audience. I'm then going to go through Gaussian process regression, maybe a bit more slowly, because I think not everybody. Slowly, because I think not everybody would be familiar with that. And then essentially, what we do is we use Gaussian process regression to construct a reduced order model or surrogate model for the forward model in the inverse problem. So that then gives us an approximate posterior distribution I'm going to talk about. And in the end, I'm going to talk a little bit on how to incorporate the fact that the forward model is a PDE into this Gaussian process regression, but that will come in the end. But that will come in the end, and in the first sections, everything that I'm going to say does apply to completely general forward models. So I think you all know what an inverse problem is. So this is the inverse problem that we're interested in solving. I have an unknown U and I have indirect and noisy observations. So my capital G here is the observation to parameter map. So I observe Y and I have some additive noise eta. Relative noise eta. This appears in very many different application areas, and we have seen different applications in the workshop so far. I'm particularly interested in problems where the forward model is given by a partial differential equation. So geophysics applications, for example, such as this one. So again, that's an example that we've already seen before. So Riccardo Baptista yesterday talked about this example as well. So we have kind of the formation of the subsurface. Formation of the subsurface where we have different layers of rock and we have the water flowing through the subsurface. What we can measure is the water pressure, so flow rates, how the water flows at some locations xi, and what we want to reconstruct is the permeability or conductivity of the subsurface. Mathematically, that looks like this. So we have this PDE that governs the flow of the water underground. The water underground. So, this just comes from Darcy's law plus an incompressibility condition. So, here we have the conductivity k of the surface. That depends on what type of rock you have. And k is large for types of rock where water flows through very quickly. And then k is small if you have a type of rock where water flows through very slowly. A P is the resulting pressure of the water, the groundwater, and then the G represents some source. And then the G represents some source or sink terms. The observed data that you have in this context are some observations related to the solution P. So you can measure the water pressure P at some points Xi in your domain. And what you want to learn, the parameters U, is essentially the conductivity K. And so that's something that you typically can't measure directly. So you want to reconstruct K. So you have this parametric expansion for K, where the use of the For k, where the u's are then parameters. So you can think of something like a Fourier expansion where you're learning the Fourier coefficients, or you can have a piecewise constant model for k, where you're then learning the values of k in the different subdomains. This is just a motivational example. And if you didn't follow all of the details, that is absolutely fine. But in general, you have some information about the PDE solution and you want to learn the diffusion coefficient. Learn the diffusion coefficient that you have inside of that PDE. And generally, again, mathematically, you can just write it down like this, where the G in the PDE example would involve the solution of the PDE. So again, as everybody knows, this is a problem that's typically ill-posed and or ill-conditioned. And to get around some of those problems, you can solve it in a Bayesian approach where you treat both the unknown U and the observed. The unknown u and the observed data y and your noise as random variables. You then choose a prior distribution on your unknown u. You then get the likelihood of the data, so the PDF of the observed data y given the particular value of the unknown u. You get that just from your observation model, so assuming that the data y comes from g of u plus additive Gaussian noise. Plus additive Gaussian noise, the likelihood has this standard form that I'm sure most of you have seen before. This comes from the density of the Gaussian. And then you can get what's called the posterior measure, which is the distribution of u given y using Bayes' theorem. And it's essentially just the product of the likelihood times the prior multiplied by a normalization constant. So that is. So, that is the Bayesian approach. Typically, what you're then interested in is performing some kind of inference with this posterior, right? So you're interested in learning U from the data Y. And so this posterior distribution, which is the distribution on U given Y, is exactly what you're after. Typically, you then want to either sample from this posterior. So if you're interested in computing something like probabilities or other quantities of interest. Or other quantities of interest from the posterior, you then need to produce samples. You do that, for example, using Markov chain Monte Carlo methods, or you might be interested in just a point estimate of the unknown parameters u. So, for example, computing the so-called maximum A posteriori estimate, which is just the one that is the most likely value of the parameters u under the posterior distribution. That is something that, in practical applications and, in particular, PDE-based applications, can become very computationally expensive. Again, that's something that we've seen in previous talks. So, for example, applying Markov-Chain-Monte Carlo methods in every iteration of the Markov-Chain-Monte Carlo method, you need to evaluate your likelihoods, you need to evaluate your forward model. Quite often, you need to do that tens of thousands or even millions of times in practical applications. Of times in practical application. And so that's just something that you can't really afford to do, right? You just have to solve your PDE or evaluate your forward model, maybe up to a million times, which is just not feasible. So what a lot of people do and what we're going to do is we're going to use a reduced order model or surrogate model or emulator, depending on which community you come from. I'm mostly going to be using surrogate model to approximate the likelihood. So you can either direct Approximate the likelihood. So, you can either directly approximate the negative log likelihood phi. So, that was just this phi is just the norm that you have in the likelihood here. Or you can directly approximate the parametered observation map, so the forward model G, and we approximate that by a surrogate. Okay, so there are then, of course, many different choices for this. Different choices for this surrogate model. You can essentially use whatever surrogate model or reduced order model you like. We are going to be using Gaussian process regression. So there's a couple of reasons why we ended up using this. So this is a well-established methodology going back many years. One of the benefits is that you can really treat it as a completely black box methodology. So all you need in order to be able to use Gaussian process regression. order to be able to use Gaussian process regression is that you can evaluate your forward model. As long as you can run your forward model for different values of the parameter u, you can use it. And so it works also for very complicated models where otherwise constructing a reduced order model might be quite complicated. It does also allow to kind of open the black box a little bit. So if you do, for example, know that your approximate Know that you're approximating a PDE, that is something that you can incorporate to some extent into the methodology, and that's something I'll be talking about later. The really important part for this talk is that Gaussian process regression, in fact, is a Bayesian procedure. You're using a Bayesian procedure to construct your surrogate model, which means that you don't just get your surrogate model, but you also get some uncertainty quantification on your surrogate model. So essentially, what we're computing. Model right, so essentially what we're computing is a probability distribution on the surrogate model, and so that kind of gives you some uncertainty quantification there. And I'll come back to that later on why that is important in this context. So just very quickly, Gaussian process regression. So as I said, it's a Bayesian methodology to emulate or produce a surrogate model for some function f. In our context, we're interested in applying it either to the log likelihood phi or Likelihood phi or the forward model g. The way it works is that you put a Gaussian process prior on your unknown function. So this is just a particular prior in infinite dimensions, a prior on functions. What this means is that under the prior f ui for any collection of points ui is a joint multivariate Gaussian. And the mean is given by this mean function here. I've chosen mean zero here for simplicity. Here, I've chosen mean zero here for simplicity, and this covariance kernel k gives you the covariance between two different points, right? So, visually, you get something like this: you choose a mean function, which in this case is just the zero function, and then at each point in your domain, say at minus two, you then have a Gaussian random variable, and you have a mean and a certain variance for that Gaussian random variable. So, if you look at sample paths or realizations of the prior, that then look something like this, so you get continuous functions that's Get continuous functions that stay close to the mean and then fluctuate around the mean with fluctuations proportional to the size of the standard deviation that you've chosen. You then do the standard prior to posterior update that you do in Bayesian inference. The data in this case are function values. So we evaluate our function f at a finite number of points un. So in this case, I assume I've observed it at these. Observed it at these four points here. And then you just condition your prior on going through those data points. Because everything is Gaussian and linear, this posterior is again a Gaussian process. You again get a Gaussian process with an updated mean now. So our mean now goes through these data points and also an updated variance. And the variance you can see is zero at these points because at these points we have observed the function. These points we have observed the function, we know exactly what it is, and so there's no uncertainty here. And then in between, you have these confidence intervals as before. So what this gives you is that then surrogate models, so we're using this to construct surrogate models. You can either just use the mean, so in this case here, you can use the predictive mean M and F, this black line here, as a surrogate model, right? So as I said, Right, so as I said, this gives you a whole probability distribution on surrogate models, and so you could just use the mean, which in this case is the most likely surrogate model because everything is Gaussian. Or you could really just use the full distribution. So if you look at the full Gaussian process at n, you then get kind of this distribution of surrogate models that you have over here, right? So they all interpolate the data because you're conditioning on going through the data, but then in between, they Data, but then in between, they kind of all do something a bit different because, in between, you don't really know what your function really is doing because you haven't observed it today. So the mean, you can view that as kind of a circuit model or an interpolant of your function, f that you're trying to approximate. And then the Gaussian process emulator that you get, the fn, is kind of a random surrogate model or a random interpolant of the function f that you're approximate. Of the function that you approximate. So these are surrogate models in the sense that they are a lot simpler and a lot cheaper to evaluate than your function f. So if you, for example, look at the predicted mean, that's just a linear combination like this. So you just have the prior covariance kernel k that you've chosen here. And so to evaluate this surrogate model at a point U, you only need to evaluate this. You only need to evaluate this linear combination. You don't need to evaluate your original function f. And so that's a lot faster. So, to give you some ideas here, if you were to evolve in this context, evaluate the function f, which involves a PDE solve, with this implementation in Python and FireDrake, that was 0.3 seconds, and evaluating the surrogate model is a lot faster. Okay. Okay, so we now have our Bayesian posterior distribution. This was the posterior that we were interested in. What we're now going to do is we're going to take our forward model G and then approximate that using Gaussian process regression. You can do the same for approximating directly the local likelihood phi. So, for simplicity, I'm just going to talk about using Gaussian process approximation to approximate the G. G. So, because we have a random surrogate model, right, so the Gaussian process regression gives us a random surrogate model for G based on the n training data, n function evaluations that we were using. You then have to think about how to use that. So you can either just plug in the mean of the random surrogate model. So, this was the MNG that we had, which was the mean that we get of the Gaussian process emulator. The Gaussian process emulator, or you can really plug in the random surrogate model in the likelihood and then take the expected value of the likelihood. So we call this the marginal approximation because essentially you're integrating out the randomness in the surrogate model in the likelihood. So these are two different things that you can do. Both of them make sense. And in particular, if you have enough data, both of them converge to the Both of them converge to the true fosterium. So, if you use enough training points to construct your surrogate models, if your surrogate model becomes essentially close to your true model, then both of those converge to the true posterior. And you can see that here. And we have a lot of theory that supports that. Essentially, you just need to make sure that your surrogate model. You just need to make sure that your surrogate model gets more accurate. So, you want to then compare your surrogate model to the true function that you're approximating. And as long as that error goes to zero, the error in the posterior will also go to zero. So, from that perspective, the two approximations using just the mean or really using the random surrogate model are not that different if you have enough data. And if your surrogate model is good enough, then there's not really much difference. Much difference, and they all both converge to the true posterior. But if you don't have a lot of data, so if you only have a small number n of function evaluations, then there is a big difference. And that is going to be the case for us, because if you go back here and remember what the capital N is, the capital N is the number of times that you need to approximate the F. And in our case, the F is The F is the forward model G, so it's the number of times that you need to evaluate your forward model in order to construct the surrogate model. And so because our G is very expensive, the N is usually going to be very small in practice. So we can only do this a small number of times. And then whether you look at the mean-based approximation or the marginal approximation actually makes a very big difference. So here I'm showing you an example. An example. So these are three different posterior approximations. So none of these are the true posterior. They're all approximate posteriors with some surrogate model. It's a two-dimensional problem. So I have two unknown parameters, U1 and U2. This is the posterior for U1. This is the posterior for U2. And then here we have the joint posterior between U1 and U2. The true values are indicated by these lines here. So the vertical. Indicated by these lines here. So the vertical dashed line here is the true value for U1. The vertical dashed line here is the true value for U2. And then the cross here indicates the true value in the joint space. The blue line in this is a mean-based approximation. So the blue line is a mean-based approximation. The orange and the green are both marginal approximations. And you can see that there really is a big difference between Really is a big difference between the different posteriors and how you construct them. So the n here is 20. We're only evaluating the forward model 20 times to construct the surrogate model. And so that's quite small. What you should take away from this figure is that if you only use the mean-based approximation, so you only use the mean of the surrogate model and plug that in as an approximation to your forward model, that can lead to what's That can lead to what's often called biased predictions with high confidence. What does this mean? Biased predictions means that you're predicting the wrong thing. So if you look at the blue plot here, which was the mean-based approximation, you can see that at the true value, it doesn't actually assign a lot of probability. So it's actually kind of shifted away and does not give you a good coverage of the true value. Likewise, here for the U2, you actually get essentially. U2, you actually get essentially zero probability at the true value. But it does have high confidence, which means that the posterior distributions are actually quite narrow. So the prior that we've chosen here was just a uniform prior on minus one, one. So the possible range for U1 and U2 are both from minus one to one. And so you can see that the support of this posterior is actually quite narrow. So you are quite confident what you think the value is, but it is the wrong value. But it is the wrong value. And so that's the problem that these mean-based approximations can have. You get these bias predictions with high confidence. And you can see that the inflated posteriors or the sorry, the marginal posteriors, so the orange and the green one, which are the ones which really use the random surrogate model, do a lot better in that context. So for the case of Gus. For the case of Gaussian process regression, so if your random surrogate model is Gaussian, you can actually compute analytically what the marginal likelihood is. So this marginal likelihood that we saw in our second approximation, are we taking the random surrogate model as an approximation to the forward model and then integrating out or taking the expected value of the likelihood? Because your g n is Gaussian at every point u, you can just write it. Every point u, you can just write it as its mean plus a zero mean Gaussian random variable. Right, so here we've just taken the mean and then kind of taken it out and then separate the Gaussian into its mean part and the random fluctuations. And then you can just actually compute this integral, as I said, explicitly. So here, this expected value then turns into Expected value then turns into this integral over the random variable Ïˆ. And then you can just complete the square that you get here. So the xi is Gaussian, which is where we have this density here. And then you can just complete the square, and essentially you end up with this expression here. So it's something you can compute analytically. And this is the final expression that you get. And if you compare it to the one that you just get from the The one that you just get from the mean-based posterior, the one where you immediately just plug in the mean of your random surrogate model. You can see that that is essentially a form of variance inflation. So instead of just the noise gamma that we had in the observations, we now have this additional noise that's coming from the randomness in the surrogate model. So it's a form of variant inflation, and that's why we quite often also. We quite often also refer to this marginal approximation as an inflated, or the marginal posterior as the inflated posterior, because it is essentially a form of variance inflation. I see I'm running a bit short of time, so I'll probably have to skip some of the results now. So, variance inflation is something that's not necessarily new, so it's something that a lot of people New. So it's something that a lot of people have used recently to improve on Bayesian inference in complex models. It is, of course, related to including modeling errors. That's something that has been done in the statistics literature for quite some time. Introducing additional errors that's supposed to represent the difference between real data and your mathematical model. So essentially, that's also what we're doing here. Also, what we're doing here is that we from Gaussian process regression do get a variance inflation that depends on u. So that's something that's more general than you usually have. And it's something that you get for free, right? So the sigma of u is something that you get for free when computing the surrogate model. So it does not need any additional work. And it's something that's easily tuned because it just comes from standard parsing process regression. Pressure. So once you have these methods, you then, of course, need to think about how to actually sample from them. So if you now have your approximate posteriors, either the mean base or the marginal ones, you can sample from them using, for example, Markov chain Monte Carlo. And we have some efficient algorithms there. So if you think, for example, about using Metropolis-Hastings algorithms, the main ingredient is then the proposal distribution that you have. And if you want to. And if you want to use things like metropolis-adjusted Langevin samplers, where your proposal distribution looks something like this, and in particular, you need information on the gradient of your target density. Usually with PDE-based inverse problems, that's quite difficult to do because you kind of need the derivative of your PDE problem. But with these surrogate models, you then just need the derivative of the surrogate model, and that's then something that you. And that's then something that you can do quite easily. And I'm happy to give a bit more detail about that if anybody's interested. All right, so far everything that I've said applied to completely general models, right? So whether your G has a PDE inside or not does not really matter. One thing that you have to think about when emulating About when emulating the G is that the G is usually multi-output, right? So the G is the one that takes you to your data, so it maps into the data space. And if you have more than one observation, which you typically do have, the G is vector-valued. And so when you're defining a prior for it, you need to both define the distribution of each entry, but you also need to define the covariance between the different entries. So the easiest thing you can do is just to approximate. Easiest thing you can do is just to approximate each of the entries independently. So you just take each observation point and you approximate that independently. This is what we get in this orange line. So this is the figure that I showed you earlier with the blue mean-based approximations and then the orange and the green, which were the marginal or the inflated approximations. For the orange one, we just approximated each entry independently. Approximated each entry independently, and the green one is one that you get when you actually introduce correlation. Because in our context, the entries of G are, for example, the PDE solution just evaluated at different points. So you have the PDE solution at xi and then xj. And because the p is a continuous function, there will typically be correlation between them. And so it does make sense to include correlations there as well. And that's essentially how we get the green. Well, and that's essentially how we get the green line. So that's how we get something that's even better than the orange line by using that we know that the entries are correlated. So you can do that in different ways. I mean, I really don't have time to talk about that now, unfortunately. But if people are interested, then I'm happy to answer some questions about it. You can essentially introduce spatial correlation with just a standard kernel, like the Gaussian kernel. Standard kernel like the Gaussian kernel or any Matern kernel, but you can also use things like physics-informed kernels. So, in fact, using the fact that you are solving a PDE and that your solution P is a solution to this PDE, that's something that you can then incorporate there as well. All right, so that was really all I wanted to say. Um, here's some references, uh, and I would say this is maybe the main reference if you're interested in. The main reference: if you're interested in this kind of thing, and um, yeah, thank you for listening, and I'm happy to take any questions.