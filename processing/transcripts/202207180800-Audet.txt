So, here's a brief outline of the talk. I'll first talk about the problem, the real engineering problem that motivated this work, which involve monotonic functions, continue on with properties of those functions and show how to exploit them within a direct search method, continue on with numerical experiments and discussion. So, if you look at the broad spectrum of optimization problems, on the one end, there's a situation where everything There's a situation where everything is smooth, you have your gradient, everything is reliable, so you do smooth optimization. On the other hand, there's black box optimization. This is where I do most of my research. S and the constraints are the output of a simulation. In between them, this is what I call gray box optimization, where you have some insight about the function you're looking at. And that information, sometimes there's a way to. Information, sometimes there's a way to exploit it to improve your conversion, to improve your method. So I'll talk today about one specific type of gray box information. Back to the motivation. Rio Tinto operates a dam nearby, a bit west of here in BC. And every day they need to solve a black box optimization problem to plan their operations. So the initial point is always infeasible. And Nomad, because they use Nomad to solve that problem, fails or take a long time to find a feasible solution. Here's an example, a snapshot of 10 consecutive days. So the first line is the number of evaluation it took to find one feasible solution. And the second line is the time that it took. So when they fail after nine hours and They fail after nine hours and 28 minutes. Well, it's too late. It's too bad. They don't have a feasible solution. So it makes their day very difficult. And when they do find a feasible solution, it takes hours, two hours, 22 in case two, and five hours in case nine. So that's a problem for them. They want quicker, feasible solutions. So the engineer, the engineer is Pascal Coute, thought about it and Thought about it and he looked at the problem and was often able to find a feasible solution very quickly. But Nomad wasn't able to do that. So he called us, said, Nomad is no good. Okay. So we politely answered, well, what's your insight? How do you find such a feasible solution? Well, he said, it's easy. Our optimization problem is we want to maximize the energy produced. Want to maximize the energy produced, and we've got some constraints. The flow at Vanderhoof has to be within below a certain threshold. The important constraints, the probability of flooding cities has to be very, very small, etc. So he knew that by looking at which constraint was not satisfied with the initial solution, he knew which variables to play with. So, for example, So, for example, if a city gets flooded and one of the variables is the amount of flow that you process through the turbine, well, reduce that amount will reduce the probability of flooding. So he had this extra information, this monotonic information. Variable I affects constraint J, either always increasing all the time or decreasing all the time. So how can we translate that information and use it within the direct. And use it within a direct search framework, this is what this talk is about. So, before doing so, let's talk about monotonicity. If, so the key point here is a function g is said to be k monotone increasing, if for every x that we take and for every y such that y minus x is a direction in the cone. Is a direction in the cone. Well, when we compare g of x and g of i, we get this inequality. So that's k-monetone increasing. We have the mirror definition for decreasing. First obvious result, if g is k-monotone decreasing for any compact set, g attains its minimum on its boundary, because you only need to decrease one variable and you hit eventually the boundary. The boundary. If second proposition is more important, if a function is k1 and k2 monotone, then it's also k monotone on the cone, on the convex hull, sorry, of these cones. Every talk needs a little proof. Here's a trivial one. So if it's monotone on K1 and on K2, and we take a direction D that's in the convex hull of these cones, well, Cones? Well, that direction D can be decomposed at alpha times D1 plus one minus alpha times D2. It decreases in both directions, so it obviously decreases in direction D. So that proposition will be helpful for us. To look at our optimality conditions, we will need to look at the directional derivative or generalized directional derivatives. So if we look at the largest So, if we look at the largest cone for which G is k-monotone increasing, then we get that d belongs to the cone if and only if the scalar product, the transpose of gradient, is greater than or equal to zero. So that's a smooth case. The case that interests us is the non-smooth one. Well, if g is k monotone and lips, then d and k implies that the Clark derivative is non-negative. So we get these nice properties about. So, we get these nice properties about our monotonic functions. So, how to use them? We again look at the same family of problems I've been working on for years. Want to minimize f subject to a bunch of constraints. Capital X is usually Rn, or it's often a bound constraint domain. And the feasible region is omega. So, X and X. is omega, so x and x, and all the constraints are satisfied. The tool that we'll use is, once again, the constraint violation function. It's zero if and only f is if and only if x is feasible, and it's the sum of the violations. Okay, so recall that the user knows what happens when he plays with a variable with respect to some constraints. How can we model this? So this definition here. So, this definition here is the key. We built a trend matrix, a trend matrix that captures usually the intuition of the engineer that knows what happens when we play with one variable. So, Tij, I is the variable number and J is the constraint number. So, Tij will be equal to one if the Jth constraint is k-manotone increasing on the cone. Monaton increasing on the cone spanned by the ith coordinate direction. So one means you increase xi. Well, the constraint CJ will increase. Minus one means that it will decrease. Zero means there's no effect, that xi does not appear in the constraint CJ. And we also added this flag and A, if the information is unknown or if Or if the function is not monotone with respect to that variable. So we build this matrix. So here is a toy problem. We've got five constraints. Four of them are linear, explicitly known because it's easier. So if you look at C1, if you increase C2, the constraint increases. So the first column that corresponds to the first constraint has a one at that position. The coefficient three-quarter is negative. The coefficient recorder is negative, so there's a minus one here. So that's easy enough. Same thing for C2. X1 does not appear here, so we get a zero in the first position. Okay, C3 and C4, similar result. C5, the constraint is a parabola. Well, if you're here and you increase X2, well, the function will increase. And the opposite happens when you're in the top part. Happens when you're in the top part. So we get an NA in the last position. So this is how we build a trend matrix if we know the analytic expression, which is usually not the case. So once we have a trend matrix, if we I look at the first column, so the function increases when x1 decreases and increases when x2 increases. By the convex hull property that I mentioned earlier, it means that the function. Mentioned earlier, it means that the function increases in the gray zone here. So that's good. If I want to decrease that constraint, I would like to pick a direction within that cone. If I look at the last column with the NA, well, the direction in which I'm sure that there's a descent is only the half horizontal abscess. Okay, so these are cones that I can play with for which I know the effect on the constraint. The effect on the constraint. So, given that matrix, what we do next is we build a strict trend direction. That's a direction that will guarantee descent of H. Recall that with the original problem, we wanted to find a feasible solution. So we want to decrease the value of the violated constraints. So we'll look, we'll define SI corresponding to. We'll define Si corresponding to the ith variable, and the trend direction, strict trend direction, will be the sum of the s i times the coordinate direction. And the s i will either be 1 minus 1 or 0. So it will be 1 when for every constraint that's not strictly satisfied, we will put a 1 when tij, the trend element, is either zero or one. Is either zero or one. One, meaning we're sure it's going to descend. Zero means we're sure it won't change because it's not present there. So having a one here ensures that we have a descendant. So when the strict trend direction is non-zero, we're guaranteed that H will decrease. Here on the bottom right picture, the domain is where my cursor is. I have two constraints. If I look at this blue point, If I look at this blue point, monotonicity tells me that the function will decrease when I move right or I go down or if I go anywhere in that direction. So the trend, strict trend direction, sorry, the strict trend direction, yes, will be the diagonal in that cube, in that square. If I look at the black point, both constraints are violated. Violated, the direction that I'll get, the strict trend direction will be directly south. Okay, so I can build these directions quite easily. Now, that was the strict trend direction that guarantees descent. We also build one trend direction without the word strict that takes a chance with the NA. N A is we don't know what happens with the function. Is we don't know what happens with the function, or sometimes it increases, sometimes it decreases. So we add NA to these definitions to increase the likelihood of having one or minus one in those directions. So we'll compare them in numerical experiments. So how do we use these directions? We will use by MAS, it will be used by MADS to order the trial points. So MAS algorithms, steps 0, 1, and 4 are not important here. One and four are not important here: installation, mesh update, and termination check. The search and the poll they generate a bunch of points in SK and in PK, and they terminate. We terminate with the opportunistic strategy. As soon as we have a success, we stop the iteration and go to the other one. So what we do is we order the trial points that we generate by increasing angle. By increasing angle with the trend direction. So if xk is our center or pulse center, the red points are the trial points, and the trend direction looks like this. Well, the first point we'll look at is T1, then T2, T3, and T4 by increasing angle. So that's it. That's the algorithm. It's simple as that. We have our trend direction, build our trend matrix, build a trend direction, order directions. Order directions with these angles, and that's it. Numerically, what does it look like? Before going into the experiment, I'll propose three ways of building the trend matrix. First one is the analytical way, like I did with the toy problem. You look at the sign of the derivatives and you build your matrix. Second way is through sampling. So, for example, the problem at Ryutinto. At Rio Tinto, they solve it every day, but it's essentially the same problem they solve every week. So we can pay an amount to find the sign the monitany relations at some point and use it on every other day. It's not a problem that solved once. So we can pay some function evaluations to do that. So what we do is we generate a bunch of points with hyper-Latin sampling, and then we add one point for every direction. One point for every direction, and we see if it's increasing or not. So, having done that, if there's always a decrease when we look to the left, then that's a decrease direction. If there's always a decrease when we go north, that's a distant direction. So that's one way to generate a trend matrix. And the third way is to ask the engineer: so, what do you think? What's the trend matrix that you have for your problem? Because he knows his problem. knows this problem. First, I'll test three strategies. The two last ones are the ones I mentioned. So we use the trend or strict trend direction. And the first one is the default in Nomad right now. When the algorithm starts, it makes it takes the smallest angle with the last direction of success. I'll call that the success direction. Direction and I'll also compare with the addition of models. So at some point, we will have sampled enough in the space once the optimization has began so that we can build at least linear models. Well, a linear model is even better than a trend direction because we can quantify things. We have more information. So we switch. When we have enough information, we switch from. Information, we switch from using trend direction or using success direction to the model. So Nomad's default baseline is success plus model. What we'll want to compare it is trick plus model and trend with model. Yep. Ordered to Ordered. I said bye, but with a transition. So we start by using the successful directions. And then when we've sampled enough, after, I don't know, 20 evaluations, something like that, we're able to build a linear model. So that linear model is preferable than using trend. So when we have enough information, we switch. And these are for problems where the number of function evaluations. Where the number of function evaluations are quite low, as you saw with the Kimenu problem. So, analytical way. So, Katrin went and looked at the equations of these problems and built these trend matrix. And let's see how it compares. So, these are profiles where we count the proportion of problems that reach feasibility with respect to the number of evaluations for all of Number of evaluations for all of these problems. The red and green do not use trend directions. So the red only use successful direction, and it's always worse than the others. Not surprising. Switching to model the green helps move the curve upward, but using trend direction never hurts. It's usually a bit better, but not a big. Probably a bit better, but not a big thing. These are analytical problems. So these are not the problems I'm really interested in, but I'm glad to see that using the trended information doesn't hurt and sometimes helps a bit. So here's a more realistic problem, the MDO problem, 10 variable, 10 constraints. We've sampled the space with 200 Latin hypercube points to get that trend matrix. So the last two, we've got. The last two, we've got a lot of information in the last two columns. The others have a lot of NAs that appear. So on the left, we use a strict trend direction and on the right, we use a trend directions. Again, the red and the green do not use the trend information. And what we see in both plots is that they're not better, they're worse than using the trend information. Than using the trend information. There's a gap of at least 10% at some point in which using either trend or strict trend helps. So that seems promising. Back to the Kim and O problem, the problem that motivated this work. So this all started out by the engineer showing us the trend matrix. He said, well, of course, you play with this variable. This is what will happen. So he gave us that matrix. Happen. So he gave us that matrix. We built the entire theory, coded everything up, ran the thing, and got that plot. The red and green are not at the bottom now, they're in the middle. The trend, the one that takes a chance when we have an NA, does much better than the strict trend one. So we were kind of surprised. So we challenged the engineer and sampled the space and found out that engineers are not always right. Engineers are not always right. And we had arguments that this trend matrix was wrong. So we reran the problem with that trend matrix. And this is what we got. So the best of NOMAD was successful model, the green one. It did a bit better than the strict trend, which is very rigid because it guarantees descent. But the trend direction that takes a chance when it's a very trendy trend Direction that takes a chance when it's not sure gave much better result on these problems. So using a correct matrix helps. That's the first lesson we learned. And back to the motivation, where it took forever to take feasible, to generate feasible solution. Now with that information on 95% of the test problems, we find a feasible solution with 50 simulations or less. So less than 30 minutes. Less so less than 30 minutes, therefore, the engineer was happy. So, that's the story. Um, conclusion, often a simulation creator have knowledge of which of monotony with respect to some constraints, some variables. This knowledge can be easily adapted with an algorithm such as VADS. It was implemented in NOMAD 3.9, not yet in NOMAD 4, because our Not yet in Nomad 4 because our to-do pile is this big, but it will be at some point. This was published a while ago in Optimization Letters. Future work, take into account the constraint, the objective function, not only the constraints. Another idea is to assign probabilities of descent rather than certainties. Those are ideas that we could look at in the future. Well, that's it for today. But that's it for today. Thank you for listening.