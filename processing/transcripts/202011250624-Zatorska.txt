Thank you, Kubar, for the introduction, and thank you for allowing me to earn this two minutes extra, I hope, for my presentation. My connection is really poor at the moment. I hope you will hear anything of what I will say. Let me first say that my talk is in 75% relevant for this conference. So, I'm going to talk about multi-scale models for complex. Multi-scale models for complex, but not fluids, for complex systems, rather. So, unfortunately, this is not yet in the fluid setting, but it's a work in progress. So, thanks. First, I would like to acknowledge the contribution of my collaborators, and the list is long. Julianne Beret, Jose Antonio Carrillo, Pierre Gon, Diana Richards, Michela Ottobre, and recently also Paul Dobson. So, I will start the presentation from some heuristic formal derivation of the model that I want to talk about. So, this is a model of interacting particles and assume that you have a fixed number of particles occupying the whole plane, so R2, and they can be just points, but we use them to model many other objects. Objects, so some interacting agents simply. And we would like to understand how the interactions between the particles, how the fact that the interactions can also evolve in time can affect the macroscopic model of such interactions. So normally what you do in the world of mean field limits is you look at the microscopic model, you assume you You assume you try to cross-grain it, and you say that in the macroscopic regime, when the number of particles goes to infinity, you have basically, thanks to something like law of large numbers, particle interacting with everybody around it. So feeling in the limits, almost deterministic force. And that's why you end up in the macroscopic level with something like a non-linear Fokker-Planck equation, right? Fokker-Planck equation, right? And those sorts of limits have been justified rigorously under quite mild assumptions. What we are going to do here is to violate this regime, this assumption that the particle senses all its neighborhood. So we are interested in the situation when the interaction network is rather sparse. So what you can imagine is that we have this ensemble of particles and they have some sensitivity. Can they have some sensitivity region which is described by radius r and when they have a neighbor in this sensitivity region r, they can create the link with the neighbor. Okay, and only if the link is created, the two particles will interact between each other. On the picture here, you have the link depicted by the little spring, and this is one of the possibilities of the potential of interaction that we may choose. That we may choose. Okay, on top of it, we have some positional noise. So there is a Brownian motion, independent Brownian motions for each of the particles, xi. So these are dispositions of particles. Mu is the intensity parameter that describes how much we sense these interactions. But on top of that, we have two mechanisms in this simple system. So first of all, we have two Poisson clones. Poisson clocks ticking in the background. First of them, when it ticks, it tells you it's time to create a link. And there is a frequency denoted by mu Fn, so it depends on N. And with this frequency, the links between particles are created, between particles that were not previously linked between each other. Okay, provided that they are close enough to each other. So the distance between them has to be less than r. Okay, there is another clock ticking, another Poisson process going on, and this Poisson process has intensity nu d, d for distraction n. And when this clock ticks, you have certain probability of removing the existing link between the particles. Okay, so we are. Okay, so we are now interested in the limit, asymptotic limit when n goes to infinity, so number of links goes to infinity, but also number of particles goes to infinity, or I would say rather in the opposite direction. But also we want to have the time separation of these two phenomena. So remodeling of the network, linking and unlinking process, we must. And unlinking process will be much faster than the macroscopic diffusion process of the particles. So, how to derive the macroscopic model heuristically? We look at the empirical densities of the particles, of course. So, this is the sum of some delta centered at points x, i. We also look at the distribution of the links, but also at the distribution of two particles. Also, at the distribution of two particles. So, these are two three functions: fn, gk, k denotes a number of the links, and hn again, distribution of two particles. And assuming that those functions have limits in certain sense when n and k go to infinity, we can derive something that we call mesoscopic description, so kinetic type of system. It was done in our work with. System. It was done in our work with Julien Beret and Pierre Degon from 2016, which was based on their previous work together with Diane and Francois. So what you obtain in the macroscopic limit is two equations. So in order to derive this system, even formally, you need to make some assumption about the propagation of chaos. And you obtain two equations, one for distribution of particles and one for distribution of And one for distribution of links, but this is not a closed system. So it's not a closed system because it also involves the function h, which is a two-particle distribution. But the new parameter that appears here is parameter xi, which is the macroscopic limit of the ratio between k and n. So you already see that if the ski is to be finite, the number of links per particle is Per particle is of order one, right? So it's not that a particle senses all the particles around, it's mostly like having one link per particle. All right, so that's the macroscopic model. And in order to get the this was mesoscopic description, and in order to get the macroscopic description, we perfected To get them macroscopic description, we perform further scaling. So, as I said, we introduce parameter epsilon, which distinguishes the time scales of the two processes of remodeling of the network and the diffusion processes going on in the system. So we rescale the space derivative, space variable x and time variable t, and correspondingly we rescale also the functions f now denoted f epsilon and g epsilon. This is the spring. This is the spring force. It's rescaled with power epsilon to minus one, and the length of the spring and the zone of interaction are rescaled accordingly to the scaling of x. So when we formally again let epsilon go to zero and assume that the limits exist, we can show that in this limit from the equation for g, we actually get some explicit relation. Some explicit relation for H in terms of F. So the H was the two-particle distribution, and this is one particle function, provided that we can assume that we again make an assumption that H is actually equal to a product of F's. So it's another closure assumption that we need to make in the system. And then letting epsilon to zero, we obtain. To zero, we obtain function g in terms of f, and therefore our equation for f becomes decoupled from the system. It is an independent equation, and it has this nice form of non-linear Foucault-Planck equation of some potential V. So I'm going to go very rapidly through this heuristic derivation because my talk is going to be focused on something a bit different in the second part. So let us look at this equation. It is a well, it has this parabolic part, but this potential V can describe something like non-look interactions of the particles, which can be, which should be, according to some of the applications that we have in mind, of repulsive nature close to the when the particles are close to each other, and it should have attractive nature when the Attractive nature when the particles are too far from each other. And of course, this potential is going to be truncated at the level R, where R is this sensitivity region for our particles. So in case you model the interactions by the springs, by the Hukian potential, the potential looks like that. And we can perform easy integration over R2 to find out when the dynamic of such system. Dynamic of such system is stable or unstable. So, ignoring the diffusion effect, if the integral of this potential is positive, we say that potential V is H stable or H unstable if the situation is opposite. H stability and H instability, they only mean that constant configuration of the particles will become constant in long time or not. Okay, and so this is just based. You can actually confirm this result based on simple four-year analysis. And that's what we did together again with Julienne Beret and Pierre Grand. Moreover, in our results, a little bit of non-linear analysis was included in order to confirm what was observed qualitatively by Chayas and Panferov in their. By Chayes and Panferov in their previous work from 2010. What I mean by that. So, we observed that on the onset of instability, when the diffusion and the non-local attraction impulsions take place, we may have two types of the instability. It can be either subcritical or supercritical. Okay, so subcritical means discontinuous. We start from some small perturbation of constant initial data and we end up with something big after passing the Up with something big after passing the threshold for instability. So, this threshold, of course, includes all the parameters in the system like length of the spring, region, the size of interaction region, diffusion coefficient D, but also the size of our domain. This analysis can be done for the whole R2, but for numerical simulations, we restricted ourselves to the two-dimensional torus. So, there are two types of subcretions. So, there are two types of subcritical and supercritical bifurcations taking place on the instability offset. So, analysis that we did in the paper with Julien Beret and Pierre de Conde was still a bit formal, I would say. You take dynamical system and you analyze the equilibria of it. And then, what we did, we teamed up with José Antonio Carrillo and Diane Perichard, and we confirmed that our formal derivation of the macroscopic Formal derivation of the macroscopic model can be confirmed numerically. What does it mean to be confirmed numerically? We performed simulations for the particle system for sufficiently large number of particles and links, and we compared the obtained results with the macroscopic model, simulations for the macroscopic model. So, these were based on the finite volume method proposed previously by Jose Antonio Carrillo, hence his contribution to our work. Hence, his contribution to our work, Anna Chartok and Yang Kwan Hang. Okay, so again, this numerical confirmation gave us a lot of confidence that our formal derivation actually makes sense. Moreover, numerical variation also allowed us to see numerically that even the microscopic model, for which this kind of analysis is impossible to obtain, to perform, Obtain to perform also inhibits this kind of subcritical, supercritical bifurcations. This observation, the character of the bifurcation was later on confirmed by José Antonio Carrillo and Greg Pagliottis and two other collaborators that I can't remember right now. But the issue of rigorous derivation of the model from the microscope. The microscopic model was an open problem. So, sorry, okay, I think I went in the wrong direction. And this is the second part of my talk, rigorous result confirming that actually our macroscopic model is what we should see. So, in order to introduce the main result of the paper, and it will be mentioned in a couple of And it will be mentioned in a couple of slides. Let me reformulate the problem a little bit more. Okay, so we start from a different setting. Instead of having the equation for evolution of particles and equation for evolution of links, we'll introduce something that is called in the literature adjacency matrix. So it's a square matrix n times n whose entries are either 0 or 1. This is this matrix Aij. I'm not going to say all the indexes of all the Indexes of all the unknowns in my system because it's going to take me forever. Okay. So this matrix, each of these entries has entry 0 or 1. It is, of course, a symmetric matrix, right? So if there is a link between particle I and J, there is also the same link between particle J and I. And this matrix has zero on the diagonal, so there is no link between particle I and I itself. Okay, and now the dynamics. And now, the dynamics of the adjacency matrix is again dictated by the two Poisson processes. Okay, so distraction process, the formation process. So distraction process happens with the intensity mu d for distraction times epsilon minus one. So epsilon is going to be this parameter for time scale separation. And the other process takes place with a preparation. process takes place with a frequency to minus one. And now you may already notice that there is something strange. So one of these intensities depends on n and the other one doesn't. Well it is precisely for the purpose to make sure that our initial sparse graph of connections between particles is maintained. So we want to make sure that in the macroscopic limit the number of The number of links per particle remains of order one, really. So that's the first assumption that we make in the system. And of course, the formation process has to be modulated by the sensitivity region. So we take characteristic function of the interval 0.0r. And only in this case we have the formation of the links. Of the links to make it a bit more difficult to follow my talk. Well, not to my talk, but the paper, I just realized it right now: that we switched the notation in the paper. So now the interactions between particles are described by potential K, when in the previous slides they were described by V. And V here stands for external confinement potential in my system. So Bi's are independent Brownian motions, and D is a diffusion coefficient right now. Coefficient right now. So you see that the systems, the equations are coupled. First of all, the slow process of the evolution of the particles enters the process of rearrangement of the network through here, through this function that modulates the formation process. But also this process feeds back the equation, the slow equation, by the form of the matrix, by this coefficient Aij. Okay, so you see that the interaction actually takes place. The interaction actually takes place only if Aij is equal to one. Otherwise, it's equal to zero, and this term is cancelled out in our system. Okay, so this system is a system of stochastic differential equations, of course, and for n and epsilon fixed, there is no absolutely no problem with proving the existence of piecewise solutions to the system. Solutions to the system, and then we glue them together. So, you basically what you do is you start from firing your effuescent processes, construct the solution, feed it back to the equation for the particles, and obtain your solution first for two particles and then by induction for n arbitrarily large. So, I'm not going to discuss the existence of solutions to this system. I want to To that system, I want to again explain you how do we derive the macroscopic limit. I'm not going to do it rigorously, but I'm going to give you more of a complete form of the heuristic argument. Okay? Very, just for your information, you have around three minutes, three, maybe four. Three, four, four, four. Maybe, shouldn't I have 25? Okay, um, so so. So we replace immediately the characteristic function by something smooth. That's why it's written in this form, the equation for A. And we observe that this is just a two-stage Markov process. So with the two-stage Markov process, we can easily read what the invariant measure of the process is. So that's the form. You just read the probability of a steady state being achieved and subtracted from one. So you have two points centered. One, so you have two point-centered measure, multiply it for all entries of the matrix A. And if you have this invariant measure, you can now integrate your first equation, equation for the particles against this measure, and you obtain sort of averaged equation. Okay, so the equation when epsilon is equal to zero with averaged coefficient. And that is going to be our intermediate step, this equation. Okay, once we have this equation, what we would like to do is This equation, what we would like to do is to use some sort of classical techniques to let n go to limit infinity, and in fact, we can do it following the results of Silvi Meléard. Actually, we were following some graduate course of Villanye, Cédric Villany, to do it. So, again, we assume that the new N scales together with N in this way to make sure. This way to make sure that we have the sparsity maintained in the system. And we end up in the macroscopic limit with the equation, the Voker-Planck equation for the density of the process X, which describes the evolution of each of the particles. So that's our macroscopic equation. And now I'm not going to have time to discuss exactly the set of assumptions. Exactly, the set of assumptions for the potential k and v in order to formulate my main result. But what is important is to have in mind that both k and gradient of v are globally Lipschitz. So also the second derivatives of those are bounded. And there is one extra assumption which tells us when the estimates that I'm going to show you in two slides are uniform in time. And this slide is devoted to the Is devoted to the form of the initial condition. So we basically take well-prepared data. Everything is the same, no matter whether we are for epsilon fixed on the microscopic system level or epsilon goes to zero. Everything is independent in our system. The distribution of links is independent of the distribution of initial particles. And also, we assume via this complex conditions. Complex conditions that there are not too many links between particles that are far away from each other. So, not only the number of links is small, but also the graph cannot be too connected far away in the infinity. So, having these conditions, our main result reads as follows. And I will stop here. I have one more slide before I say thank you. But let me explain you what the theorem says. It says that the empirical Says that the empirical measure, so again, sum of delta centered on our point of particles, converges to the macroscopic density that we saw satisfying a PDE in the following sense. So we take a test function which has two bounded derivatives, its continuous function, and we say that it is a little bit similar result to what you saw in TOGO, Panita. So we have some sort of distance between the micro and macro. Between the micro and macro densities, although we don't have the underlying convergence result. But what it says is that this sort of distance is controlled in terms of n and epsilon. And now I will tell you where I lied in the previous couple of arguments. I said that we first do the limit epsilon go to zero and then n go to infinity, but this is not true. So what we are actually doing is let n and epsilon Let n and epsilon go to zero all together. So there is some regime for n and epsilon combined together for which it works. So n has to be large, epsilon has to be small, but also n epsilon has to be sufficiently small. Okay, so this is first remark. Second remark is that this estimate is only local in time. Okay, but under this additional assumptions on the strength of confinement potential, we can make it uniform in time. And that's the second part of the theorem that I'm not. Second part of the theorem that I'm not going to present to you today. Okay, I think with this, I really overuse your patience, and I wanted to quickly skip the slides about the proof and thank you for your attention. Okay. Thank you very, very much.