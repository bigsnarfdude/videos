So I'm happy to introduce the second speaker of this morning's session, Mike Reisden, and he will talk on Roger Shepard and genuine inequalities for general measures. So let me say thank you to the organizers for the invitation. This has been a really nice occasion, many, many nice talks. So, as Alina mentioned, I'll talk about Roger Shepard and Jung type inequalities for general measures. And let me mention that. General measures. And let me mention that it is part of multiple joint works. That with Davido Anto Gutierrez, Maria Hernandez-Sifri, Jesus Gepes, and Ardom Zavavic. And then the second paper was with Dylan Langhurst and Ardem. So let's start kind of with the setting. I'll always consider convex bodies, which are compact convex subsets with non-empty interior, and I'll adopt the notation script k to n to denote the class of convex bodies. To denote the class of convex bodies, this is just for notational convenience. We always consider the Minkowski sum of two convex bodies, which is their standard vectorial sum. So it's the set of all x plus y such that x is in k, y is in l. And there's another way to rewrite this where if you fix k, reflect l, and then move them, move l by x in all such ways that this intersection is non-empty. This is also an equivalent way to understand the Minkowski. An equivalent way to understand the Minkowski sum. And the second one will actually be sort of the crux of the entire presentation. And here's just a graphic. You can take the B infinity ball and the B2 ball and add them. And you get the outer parallel set of the square by the ball. Okay. The key feature of considering this is to join. Of considering this is to join it with analysis, and joining geometry with analysis takes its first form for us in this theory, in the form of the Brun-Minkowski inequality, which asserts that the volume functional on the class of convex bodies is one over n concave. In other words, the volume of the Minkowski sum raised to the power one over n is always bigger than or equal to the volume of the first convex body to the one over n plus the volume of the second body to the one over n. And there's equality only if L is. And there's equality only if L is a homothetic image of K, meaning that you can find a positive scalar and a vector v so that L is exactly lambda K plus V. And another equivalent form is the geometric Brominkowski inequality. So you can apply when you take convex combinations of K and L, you can apply the arithmetic geometric mean inequality and get that the volume of the convex Minkowski combination of K with L. Convex-Minkowski combination of K with L always exceeds the geometric average of the volumes of K and L. And again, you can just use a homogeneity argument to get back to the classical form of the Bruminkowski inequality. One of the key applications of the Brumankovsky inequality is, in fact, it provides a very beautiful solution to the isoparametric problem on the cause of convex bodies. So one can define the surface area of a convex body, K, to be the different. Body k to be the difference quotient of the volume of the outer parallel set of k minus the volume of k, all averaged by epsilon. And you take the limit as epsilon goes to zero. So if we go back to the other picture, we all get these parts and we really send it to the boundary of k. And here, b2n is the Euclidean ball, and s to the n minus one is the boundary. And applying the Brumankovsky inequality here, you You really get Minkowski's first inequality, which asserts that the volume of the surface area, so of the boundary of K, or the surface area of K always exceeds N, volume of K to the N minus 1 over N, volume of the Euclidean ball to the power 1 over N. And then you can just use the relation, the fact that the surface area of the ball is n times the volume of the ball to get the isoparametric inequality. This asserts that the volume ratios of the boundaries of K. Boundaries of k and the boundary of the Euclidean ball to the power one over n always exceeds the volume ratio of k and the Euclidean ball to the one over n. So this exactly tells you that Euclidean ball has minimal surface area. Okay. Another key point is the fact that the concavity condition of the volume is not a unique current. In fact, it exists for a whole class of measures, which we call beta concave. Which we call beta concave. And by this, I mean the following: fix some parameter s from minus one over the dimension to plus infinity and some time t between zero and one. Given any measure mu on Rn defined by d mu of x is phi of x dx, where phi is s concave on its support. By this, I just mean phi to the s power is a concave function. And any pair of Borel sets, then mu is a beta concave measure for the parameter beta is. Parameter beta is s over one plus s times the dimension. But this, if you check, is just from minus infinity to one over n. It exactly means that mu of the convex Minkowski combination of A with B is bigger than the beta convex combination of the measure of A with the measure of B. Okay, and just to have an example in our hands, let's take the standard Gaussian probability density. We take the standard Gaussian. We take the standard Gaussian and then the dimension-free version of the Gaussian-Brum-Minkowski inequality asserts that for any pair of Borel sets A and B, in particular convex bodies, the Gaussian measure of the convex-Minkowski combination of A with B is always greater than the geometric average of the Gaussian measures of A and B themselves. And one way to prove this, one very nice way to prove this, is the use of this celebrated Procopa-Leibner inequality, which is very often seen as the Is very often seen as the functional version of the Brubminkovsky inequality. I won't go into this too much because it's out of the context of the talk, but this is a very nice result. Another way to do it is you can just prove it by hand using induction on the dimension with the Gaussian measure. Okay, so we have Bruminkowski. It's curious to know if you can reverse it. And this was exactly the question posed by Rogers and Shepard in the 1950s. So if you choose a very special So, if you choose a very special convex body k, so if you take k and you add to it its negative, then you really get a reverse form of the Brumankovsky inequality. So for any convex body k, the volume of what we call the difference body, k plus minus k, never exceeds 2n choose n times the volume of k. And there's equality only if k is an n-dimensional simplex. And moreover, let me make a comment. Let me make a comment. If K is an origin symmetric convex body, you can apply Gruminkowski on this side and get that the volume of the difference body of K always exceeds 2 to the n volume of K. And here you really get a bound in the volume ratio of any convex body with an origin symmetric one. This is another very nice key feature of the Roger Shepard inequality. And I'd like to mention just a result of Schneider from the 1970s, which is a very, very general. Which is a very, very general Roger Sherpet inequality. And it asserts the following: for any convex body K and any fixed parameter P, the N P dimensional volume of this generalized difference body, so you take a p-tuple of points in Rn, a convex body K in Rn, and you look where K intersected with K plus X1, intersected with all the rest, intersected with K plus XP is non-empty. And he, in fact, And he, in fact, proved that the NP-dimensional volume of this p-difference body never exceeds np plus n choose n, the volume of the original body to the pth power, any characterized equality. There's equality if and only if k is a simplex. So this is a very, very nice. And for free, if you pick p equals one, you of course get back the Roger Shepard inequality. So there's a question that we posed, and it is, if you have a Borel measure. And it is, if you have a Borel measure on Rn, can one expect, even in the case of, say, log concave measures or beta concave measures, to have a Roger-Shepard inequality? So can you find some constant, not necessarily 2ng's n, but some constant depending on the dimension. So the mu of the difference body never exceeds that dimensional constant times the measure of k. And it turns out that it's hopeless as soon as you hit log concave measures. You can see that if you take measures you can see that if you take the gaussian density even on even in the plane even on the line and you take a convex interval and you just move it very very far away its measure can be made arbitrarily small while simultaneously the measure of the difference body of k is always at the origin it's always some fixed positive constant so in this form the question is not really fair it needs to be adjusted and needs to be adjusted in the sense that you need to pay attention to the placement of k. To the placement of k. And this is exactly what we were able to prove. So we were able to prove that if μ is a measure satisfying relatively minimal conditions, its density is ratively decreasing, meaning whenever you look at it in one-dimensional lines, it's just a decreasing function. Then, for any convex body k, mu of the difference body never exceeds 2n choose n, and then a minimum of averages of the sh. The shifted k with μ or the shifted minus k with μ. And this we were able to prove. And we also classified equality in the sense that if phi is assumed to be continuous at the origin, then there's a quality in this inequality if and only if mu is a constant multiple of the Lebesgue measure on the difference body and k is a simplex. And this again recovers the Roger-Shepard inequality just by picking volume and additionally. Volume, and additionally, you get a reverse form of the Gaussian-Bruminkovsky inequality, which is also quite nice. And I would like to demonstrate the necessity of the radially decreasing assumption. So this picture provides all the information that you need. So starting from dimension two, if you take just the standard Euclidean ball in the plane and you dilate it twice, this will be its difference body. And then you kind of pick. Then you kind of pick, you pack the boundary with the ball, exactly six copies. This can be done. It is true that you can find a little disk inside of here and a little annulus here so that inside the disk and on the annulus you make the density one and everywhere else you make it zero. Then you can just see from the picture that mu of the difference body of the Euclidean ball is strictly bigger than the Is strictly bigger than six times even the largest of these shifts. And this is an immediate contradiction to the Roger Shepard inequality. So the radio decreasing assumption in its present form is a necessity, starting from dimension two. And just to mention a result, I won't comment too much about it, but one can generalize Schneider's result to sections of convex bodies. Of convex bodies and sections of the p-difference body. It just asserts that for reasonable radially decreasing measures, you take the product measure, you take a convex body, you average with respect to a measure whose density is 1 over s concave, has maximum at the origin, and then you pick a bunch of different subspaces. You can obtain that the new measure, which is this product measure, of the section of the p-difference body by this product space. This product space never exceeds some constant multiple, never exceeds some constant depending on the dimension, the subdimension, and the concavity of nu divided by the measure of k, the integral over k, and then the product of the mu i measures of these affine sections of k. And yeah, so I would like to mention that if you pick volume here, you pick p equal to. Volume here, you pick p equal to one. You, in fact, get a result of Rudelson about sections of the difference body, at least one of his constants, but it is hiding in here somewhere. Okay, so moving on from Roger Shepard, this was the first half of the talk. The second half of the talk will be concerned with the Zhang inequality. So, for any convex body K, you can, of course, take its support function, which is just the distance from the origin to the boundary of K in the direction. Boundary of k in the direction. And with this, you can understand the Minkowski sum of two convex bodies, just that be the convex body whose support functions in every direction are the sum of the support functions. And with this, I would like to define the difference body. So given a convex body K, the projection body of K is the convex body by K, whose support function is given as the section, as the M minus one dimensional volume of the project. As the m minus one-dimensional volume of the projection of k onto the orthogonal complement. Basically, you take your convex body k, you project it, you take this volume, you do this in all directions, and this forms some origin symmetric zonite. But it's not immediately clear that this is a support function. It's not immediately clear that this is convex. But what one can do is you can write this as a different quotient. A difference quotient, and you can go through the Cauchy projection formula. And this is how one understands that this is, in fact, a support function. Connected with this is the Cavariogram. So the Cavariogram of a convex body is the convolution of the support function of K, of the characteristic function of K and the characteristic function of minus K. In other words, it's the volume of K intersected with X plus K. It's exactly as the picture describes. You take K, you The picture describes: you take k, you move it a little bit, you take the volume of the intersection. And here's one of the key features of the Kavariogram: it's that if you take a radial derivative of it, you get minus one half integral over the boundary of k, the absolute value of the inner product of the direction with the outer unit normal of k at that point y, dy, but this is actually minus the support function of the projection body. Of the projection body. And this is one way to see that this is indeed a support function. Okay, so projection bodies, I mean, they have a long history, but one of the main points of them is the fact that they're essential to the solution of the shepherd's problem. So I know everyone is familiar with the Boosum-Mempetti problem. The Shepherd's problem is its dual, which just says the following. If you have a pair of origin-symmetric convex bodies, Convex bodies such that the volume of the projection of K in every direction is always smaller than the volume of the projection of L in the same direction. And this holds for all directions. Must one have that the volume of K is smaller than the volume of L? In other words, if the support function of the projection body of K is always smaller than the support function of the projection body of L, must the volume of K be smaller than the volume of L? And it was shown that you And it was shown that yes, in dimension one, in dimension two. In dimension two, it is in fact because all origin symmetric convex bodies are projection bodies. And the answer is negative in dimension three and above. And so we have the shepherd's problem in mind, but really the question is about isoparametry. So one very, very important question of Petty in the 1960s. Important question of Petty in the 1960s asked whether ellipsoids minimize the following affine invariant. The volume of K to 1 minus N times the volume of the projection body of K over all origin symmetric convex bodies K in dimension 3 and above. In dimension 2, again, we go back to this comment about every origin symmetric convex body being a projection body. You just dilate, you rotate by pi over 2, and this is what you get. But in dimension 3, it becomes quite a bit more profound. It becomes quite a bit more profound. And Christophe Sauergul showed that, in fact, this quantity is not preserved under standard symmetrization. So the symmetrization techniques that many use to prove these isoparametric inequalities may not work here. I mean, Steiner symmetrization doesn't work, but maybe Minkowski, I don't know. Maybe there's some other way that one can attempt. But But there are some partial answers. I mean, I can't encapsulate the whole history here, but there's this wonderful book of Rolf Schneider and this wonderful book of Richard Gardner, which contain a deep history on this problem and on projection bodies. But here are some key points. Schneider was able to establish a class reduction. So if one knows the Boosman-Petticentroid inequality with the quality conditions for polar zonoids, Conditions for polar zonoids, then from this one can deduce Pettis conjectured inequality and its associated quality conditions. In the 1980s, Ludwig made many works concerning Petti's conjecture. And in 2017, Sargul and Zavovich showed that, in fact, in a very nice neighborhood of the Euclidean ball, in a Bonachmazer neighborhood of the Euclidean ball, with smoothening. Euclidean ball with smooth enough convex bodies that, in fact, Petty's conjecture does hold, which I believe is the first result of this type. And then, of course, there are many more. I mean, Evalki did many things on curvature images, and Ortega Marino and Fran Schuster recently put a paper on the archive about fixed points of Minkowski valuations, which is also of a related nature. Okay, so Petty's conjecture is very, very open. Conjecture is very, very open, very, very hard problem. But he has another affine isoparametric inequality concerning the polar of the projection body. And so, what he instead considered was the volume of k to the n minus one times the volume of the polar projection body of k. And in this case, he in fact was able to establish a maximum for this. So, it's been known as the petty projection inequality. It says that for any convex body k. Says that for any convex body k, the volume of k to the m minus one power times the volume of its polar projection body never exceeds the volume ratio of the Euclidean ball and the volume of the n minus one dimensional Euclidean ball to the power n. And there's equality if and only if k is an ellipsoid. And in fact, this is a very powerful inequality in the fact that Zhong was able to show that it not only implies, but is in fact equivalent to a strengthening of the so-called inequality. To a strengthening of the sub-law of inequality, to some affine version of the sub-love of inequality. And one can see, you know, if you pick the right functional, that this inequality implies the classical isoparametric inequality for convex bodies. So like with the Roger-Shepard inequality being not only a reverse of the Bruminkowski inequality, but a characterization of the simplex, one can consider what is a What is the reverse form of the petty projection inequality? And this was a question answered by Zhang in 91, which says that for any convex body K, the volume of K to power M minus 1 times the volume of the power projection body of K never exceeds 2n choose n divided by n to the n. And there's equality if and only if K is a simplex. So you have these two inequalities. On the higher end, it characterizes the ellipsoid, and on the lower end, it characterizes. And on the lower end, a characterized the simplex, about as far as origin symmetric as one can be. Okay, and even more is true. In the late 90s, Richard Gardner and Zhang were able to find an entire family of convex bodies, which they call radio-mean bodies, which connects the difference body to Zhang's polar projection body. And in a continuous way, I mean, it comes from the Bertwa inequality, but let me just. But let me just state the result in a not so precise way. So, for any convex body k and any parameters p and q greater than negative one, you can find convex bodies r pk or qk called the radial mean bodies such that the volume of the difference body of k never exceeds some constant depending on n and p. Volume of the p radial body, this is always smaller than some constant depending on n and q. Volume of the q radial mean. Volume of the Q radial mean body, and this is always more than or equal to n to the n, volume of k to the n, volume of the polar projection body. And there's a quality in every single one of these, if and only if k is a simplex. And here these constants are expressed in terms of the beta function. And in fact, they showed that when you choose p equal to q equal to n, then the volume of the radial mean body is in fact the volume of k. And so on the far left, you get the Roger-Shepherd inequality, and on the far right, The Roger Shepard inequality, and on the far right, you get Jung's inequality. So, this is a very, very beautiful result. And, in fact, they even proved something of a containment. So, for any convex body K, they show that the difference body of K is always contained in N volume of K times the polar projection body of K. And one can, with this inclusion, together with an argument in polar coordinates, prove a Jean-type inequality for any. Prove a Jean-type inequality for any measure having a non-negative density. So you can take a measure that is absolutely continuous with respect to the Lebesgue measure with non-negative density function and a convex body k. Then you have the following. The average of the covariogram of k with respect to mu never exceeds mu of n volume of k polar projection body. It's asymptotically sharp in the sense that you can find an example of a measure for which you. Example of a measure for which you have equality. So if I take volume here, unfortunately, you don't immediately get back the Sharp-Jang inequality. And this is what we set out to do with Dylan and Ardham. So we first, taking from Gardner and Jung, they posed the question of what about the covariagram of a measure? And we began from here. And it says, given any measure mu with a density which is not negative in a convex body, the mu covariagram is. In a convex body, the mu covariogram is just mu of k intersect x plus k, which is expressible as this integral. And just as an example, one can take a simplex in the plane and the Gaussian measure, and you get this polar right here. So, this is just an example of what these bodies may look like. And we were able to prove a version of the inclusion by Of the inclusion by Gardner and Zhang. So, what we do is we take a function from the non-negative reals to the non-negative reals as increasing invertible and mu a measure that is f of t concave on Rn and has some non-negative density phi, then for any convex body k with positive mu measure and such that when you integrate the gradient of phi over k at zero, then one has that the different body is contained in f of. body is contained in f of mu of k divided by f prime of mu of k times the the polar of the mu projection body of k and in fact we are also able to show a result similar to the radial derivatives so we were able to show that for any convex body a measure mu with the Lipschitz density on k locally Lipschitz density in some domain containing k then the following holds the radial derivative of the mu covariogram in the direction phase Muka variogram in the direction theta is equal to negative one-half, the integral over the boundary of k, the absolute value of the scalar product of the direction with the outer unit normal at y, phi of y dy, plus some shift, and the shift is exactly one half integral over k of the gradient of phi of y. For example, if one takes volume, this gradient dies off. Gradient dies off. This phi is just one, and you have the result of Mitharian back about the radial derivatives. If you take k to be origin symmetric, you take phi to be any even density. Again, this dies off, and you just have this piece here. So this gives us a justification for a support function of these bodies. And you can, of course, you can apply the Gauss map, you can put this on the sphere and talk about this with respect to the. And talk about this with respect to the surface area measure of k. Okay, so with the above theorem in hand, it makes sense to define the mu projection body in exactly this sense. So you have a zonoid and other zonoid, which is quite nice. And actually, as it turns out, these objects had been considered earlier by Galena Liefschitz in her solution to a generalized version of the Shepherd problem for measures. Of the shepherd problem for measures, one which in fact preserves the solutions. She showed that under reasonable assumptions and under reasonable choice of measure, then the Shepherd problem holds in dimension two and one and fails in dimension three and above. Okay, let me just make a mention of a critical M in the paper that we used. So we took a measure. So we took a measure, which was radially non-decreasing, meaning that when you look in a direction, it's an increasing function rather than decreasing. And you have a concave function compactly supported with zero inside of the interior of its support and maximum at the origin and some increasing function. Then the integral over the support of f of the composition of f with q against the measure nu never exceeds some constant times this polar integral. This polar integral, where z of theta is minus the radial derivative of f at zero in the direction of theta times f of zero, and beta is some constant depending on q, f of zero, and on the dimension. And there's equality if and only if u is a constant. And this lemma, together with the theorem about the radial derivatives, led us to Zhang's inequality for two measures. So for any convex body k. So, for any convex body k, any measures μ and ν on Rn, where the density of μ is locally Lipschitz on some domain containing K, and the density of ν is radially non-decreasing. And F is any increasing invertible and differentiable function so that the composition with the mu covariagram of K is assumed to be concave. Then one has that the average of the new measures of the shifts of K over K with respect to mu. With respect to mu never exceeds n over mu of k times nu of the polar projection body of k shifted and then times this ratio f of mu of k divided by f prime of mu of k, then times this constant depending on f, the measure of k, and the dimension. And here, of course, it didn't write it, but we're assuming that mu of k is positive. Otherwise, you know, it's a nonsensical question. And if you pick And if you pick big F to be very nice, you get Zhang's inequality for S-concave measures. So you can take S greater than zero, nu a measure with radially non-decreasing density, mu s concave. Then for any convex body k, you have that n plus s to the minus one, choose n, where this is interpreted in terms of the beta function divided by mu of k times the integral over k nu of y minus k d mu of y never exceeds nu of s to the minus one mu of k. one mu of k uh the mu projection body of k shifted by eta of mu k polar and if they're both taken to be the lebes measure this is in fact jung's inequality for the volume case and uh let me just make one one more small comment about a functional version of the mukavariogram so you take a convex body k you again take a measure with a non-negative density and you take a locally integrable function on And you take a locally integrable function on Rn, you can define the covariagram, the mu covariagram of the function f with respect to the body k to be the integral over k intersect k plus x f of y minus x phi of y dy. Again, I'm assuming that it's sensible on k, even though I didn't write it here, it's implicit. And we were able to show a similar result concerning the radial derivative. So under the above assumptions with the additional assumption of the differentiability of f. Assumption on the differentiability of f and a Lipschitz condition on the density phi one has that the radial derivative of the coveragram of f with respect to mu is one half integral over k inner product of f times the gradient of phi minus p times the gradient of f with theta dy minus one half integral over the boundary of k the absolute value of the scalar product of the direction theta with the outer unit normal of k at y times f of y d mu of y and I And I think this is everything. Thank you. Thank you very much. Sure. Very, very nice. Can we have some questions?