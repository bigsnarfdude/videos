The problem targets of optical burning market wheel transport. Okay, thank you, Robert, and thank you very much for the organizers and for the audience. So today I'd like to talk about the connection of optimal transport type problem to the free boundary problem in PDE of hedication. So this is joint work with In1Gim and also some of the, I mean, the basic tech The basic techniques and tools we are going to use are also based on the work of Kusub and Adam Paimon and myself in the previous works. Okay. So we consider Blanya motion. So it's like a random motion like this. Okay. And then we consider so-called stopping time. So for example, stopping, one example of stopping time is like this. So we have this like a boundary of the domain. You stop the vertical. The domain, you stop the volume motion when it hits the boundary. So that is like a so-called heating time. So stopping time is a random time depending on each random pass, which satisfies certain probabilistic rule. That is, the decision to stop or to go should depend only on the present and the past, but not in the future. Okay, all right, that's stopping time and then. The stopping time. And then we consider, let's say, the initial distribution, and we run the Brownian motion. And then we stop the Brownian motion particles according to some given stopping time. Then we collect those particles as a distribution. So that is this notation. So the distribution of this Brownian motion stopped at this starting time is this like a measure. And so this rotation. And so this notation can be used for not only probability measures, but also for general non-negative measures, having mass not necessarily equal to one. All right, that's the notation. And then let's consider this free target problem. So, for example, you can consider given positive measure mu, and then you consider And then you consider a certain function, non-narrative function, as like a density constraint, so that you want to find a stopping time so that the distribution start initially mu after the stopping time of the Branian motion becomes that distribution satisfying this constraint. So, for example, heat flow, you start with the sub-initial data, as time goes in. Initial data, as time goes to infinity, the density goes to zero. So it automatically satisfies, like, for example, this upper bound equals one condition if you run the Branium if the starting time is large enough. Okay. And so, of course, this problem in usual cases always have solution. And not only one solution, but many, infinitely many solutions. And then among those Among those, let's say automatic server starting time and this target distribution, one may consider optimization problem. Okay, so we considered this like a condition for this target measure by starting time to be bounded by this density upper bound. And for technical reason, we just assume that a new also has to be compactly supported. Also, it has to be compactly supported. Then, under these conditions, we consider minimization problem over cost that depends on the stopping time. And the cost function in this talk, we consider this type of cost, is we call it Lagrangian-type cost. So, you, for each Vagnian pass, you integrate some function along the path until the starting time. Okay, until the starting time, but you have like infinitely many such Brownian passes, you take average as this expected value. So this is, of course, that expected value. Okay, and further, we assume that our Lagrangian function is either type one or type two. Here, type one means it is strictly increasing in time, and type two means strictly decreasing. So, these are the key conditions. Decreasing. So these are the key conditions we are going to use during the talk. And some other technical condition is this: that the L is bounded from below and above. Okay. And also in our consideration, we only consider those initial measure, which are absolutely continuous and compactly supported. Okay, so these are just assumptions. And then this type one and type one or type two are the key conditions we are going to. Are the key conditions we are going to use? Okay. Okay. Then the most important question is should be existence. So if this constraint is compact, sorry, meaning is compactly supported, then existence of the optimal target new, optimal target measure new, which we call optimal free target. Which we call optimum free target. It's not difficult because, I mean, the support is complex. So, whatever measure this is, it has a fixed total mass. Now it's supported in some bounded region. So, we can consciously just minimizing sequence, that minimizing sequence should converge due to weak star compactness of measures of the measures of fixed total mass. So, you just optimal free target is. So existence of optimal free target is easy, but once you find such optimal free target, you can consider the results from fixed target problem. If you have initial measure and then the finite target measure fixed, then you can consider still optimizing the cost where this new indicator is new is fixed. So that is this problem. Yes, that is this problem. Then, this problem has several good results obtained by previous people. In particular, you can solve the dual problem and you get a so-called variable, some set where the Brownian motion stops when it as soon as it enters the barrier set. And such a time. And such a time when it enters the variable set is called heating time. So, optimized stopping time is given in that case by the heating time to a variable. And such optimized stopping time is given uniquely in this case where mu and nu star are fixed. And that is this, sorry, that is this reject by Bigova, Cox, and Hussman. Also, myself and Aaron Paimon made some contributions there. So you get in the space of time, in the space-time, you get a set, so-called a barrier set, like in this picture, some set like here. So that the Brownian motion moves in the space-time. Okay, so this is time direction. This is space. So Brownian motion moves in the space randomly, but in the direction of time, In the direction of time, it moves monotonically. That's why we have this motion monotonically moving in time, but randomly in the space. So then the optimal starting time is given in such a way that first there is certain barrier set determined by mu and nu, okay, the source and target measure. And then optimal stopping time is nothing but the heating time for the Brownian motion to. For the Brownian motion to hit this variable set. Okay, that is this definition. Okay. And one reject Gusen by 7 Aaron Paimon found was that this variance is given by, is determined by the solution to the dual problem. So we establish the existence of the optimal dual solution in this case and characterize this various. Case and characterize this barrier set using the optimal dual solution. Okay. So that is a case when your source and target measures are fixed and you consider the optimization problem of the starting time. Under the cost of this type, either type one, L is strictly increasing or L is strictly decreasing. Then you can get some results like that. And so that is for the case when, let's say, this density of probabilistic constant is compactly supported. But the most interesting case for us is when this F is just constant, constant one over the whole space. One Rn. Okay, so then the existence of optimal free target cannot be obtained that. Cannot be obtained that easily from like a weak star compactness of like measures of fixed total mass. Then, how do we do that? So, in particular, how do we avoid, let's say, the mass of this optimal field target and spread to the infinity, for example, violating this compact support condition, particular. And then one easy One easy idea for that is just to truncate the constraint, and then you get this truncated constraint which is compactly supported, and you sell for this compactly supported constraint, you get the optimal free target. And then for each truncation, you get optimal free target. And the question is, when we enlarge this truncation, L, bigger and bigger, what happens to this optimal free target? To this optimal free target, subject to this truncation. Can you just say that optimal free target is independent of that truncation when L is large enough? And indeed, that can be done using the so-called monotonicity we established for this free target problem. Okay, so I'm going to talk about monotonicity. So monotonicity, this theorem is an This theorem is a novel feature for the free target problem. The statement itself makes sense because we consider a free target problem. What is it? So you consider mu1 and mu2 like two source measures. And then you consider target measure, let's say mu1 and mu2, even by, let's say, stopping times tau one and tau two. Tau1 and Tau2. And then suppose that Tau1 and Tau2 are optimal stopping times between the source and target when those source and target are fixed. And then assume that also target measures satisfy that same constraint. Okay, the same for those two, okay. Those two. Okay. And then we assume this the type of the course: type one or type two. Okay. The motor says the following: if this mu1 as like a distribution of the density is smaller than or equal to mu two, okay. Then if If this new one was the optimal free target of this free target problem, okay, then so this one is the optimal free target, then whatever target nu2 is for this second pair, this stopping time tau two. The stopping time tau2 connecting mu2 and mu2 has to be bigger than or equal to the stopping time tau1. In the following sense, if you restrict this measure mu2 to mu1, sorry, mu1, and you consider those passes, groundion passes starting from mu1, then you can consider restriction of this tau2 from the distribution of mu2. From this distribution mu2 on this initial distribution mu1. So you can restrict, you can consider these Brownian motions and from mu1 and you can stop them either according to tau1 because this one was just originally for this initial distribution mu1 or the or the restriction of tau2 on this mu1, the smaller measure. So then you can compare those two stopping times and Stopping times, and we have this monotony there. If this is optimal, then you have this order of inequality. Yes, any question? Yeah, sorry. So, when you are mu1 and mu2 already both probability measures, or they're just you don't have to assume that just they have to, I mean, you you cannot in general assume that because they have different mass. Okay, so this is really inequality about masses on as as as an equality between measures. As an equality between measures, it's not the stochastic. Yeah, yeah, these are just non-negative measures. Okay, yeah, but mu1 has to have the same measure mass as mu1, of course, and so on. And somehow you always assume that mu1, I mean, that mu's are such that the problem has a solution, right? Because sorry, maybe, maybe, can you just speak of it louder? Because I can. Do we always assume that this problem has a solution? Because if I fix a new one, I mean, if I fix a new one, then yeah, yeah, so we are so this assumption is you have a solution to this fixed problem, fixed target problem, okay, first, okay. And then further, if this new one was also the free the solution to the free target problem, okay, then you have this. Okay, thank you. Okay. Okay. Okay, moreover, if both new one and new two are the solutions to the optimal free target problem for those the corresponding initial distributions, then you have this order of the optimal free targets. Okay. So this that is what we call a monotonous thing here in this context. It's context. All right. So monotonic has, I mean, very easy, but important consequences, you can use this monotonicity and you combine it with the truncation argument I just briefly mentioned before to get existence of optical. Before to get the existence of optimal free target, so the corresponding optimal stopping time tau, and you can use this monotonic T in the case when mu1 and mu2 are not necessary the what the in this sorry unique so you just apply the monotonic using this this condition so if mu1 n mu2 uh gives mu1n Uh, gives mu1 and gives mu1 and mu2 both are optimal for the free target problem corresponding to mu1 and mu2. So, if but then Omoto says we have this, sorry, we have this inequality. So, if mu1 and mu2 are the same, well you also have this backward inequality so that mu1 and mu2 are the same. That gives us the uniqueness. And you consider the case when mu1 and The case when mu and mu are not necessarily in this, like in this order, but just having the same total mass, okay, then you can derive after a few lines this so-called L1 contraction that the L1 difference of the free target, optimal free target, is bounded by the L1 difference of the initial measure. And if you differentiate this LOOM contraction, This LOM contraction, then you get its infinitesimal version, which is the BB estimate. The BBS BB norm of the optimal free target is bounded by the BB norm of optimal, sorry, the BB norm of the initial measure. So these are like easy consequences of the monotonicity. Those that seemingly simple statement of monotonicity gives even this kind of regular. This kind of regularity regions for the optimal feed tag. Okay. So can you comment on this, the BV estimate? I mean, how likely is it that mu is BV? Mu? Yeah. Oh, if mu, it is like you assume mu is B V, having this finite, just Is finite just any nice measure? I mean, just consider some nice measure, even smooth. So, mu is prescribed and mu is the mu is prescribed. Yeah, mu is initial measure is prescribed. Okay, exactly. Initial data, and new is the solution. All right, okay, now let's uh recall the type on. The type one and type two of the cost. So, type one cost of this Lagrangian type. Remember the integral or expected value of integral from zero to the stopping time of Lagrangian motion and T dt. So that was the cost function. And two cases where we consider when L is strictly increasing or L is strictly decreasing. And those types, when you consider the fixed target problem, gives, remember that the optimal stopping time, the fixed target problem has this kind of structure that is given by the heating time to a certain barrier. Then the nature of this barrier changes kind of in the opposite way depending on the type. Depending on the type, whether it is type 1 or type 2. In the type 1 case, the variance set is time monotone. So once you hit the variance set, all the folding time points belong to the variable set. So this is like the shape of value set in this case. Sorry. So this is the time direction. And this is a space. As you mentioned, this is time. And this is space. And in the type 2 case, the value set is time backward. So in the type 1 case, ground motion stops when it hits the barrier set from below, I mean, from previous time to here. And then in the type 2 case, brown hits the barrier from above. Okay, this is the barrier. This is over here. They are kind of two different types contrasting each other. Okay. And monotonicity, which I mentioned in two slides before, kind of gives us some kind of surprising that is surprising to me. That is this universality that you are. You are given constraint and given initial measure, okay, they are fixed. Then you change the cost function by changing the Lagrangian, okay. And you can you consider all the possible Lagrangian guns, either type one or type two. Okay, then for all these possible Lagrangian giants, type one or type two, the corresponding optimal. The corresponding optimal free target is just unique, the same, the same for all the possible Lagrangians of Taiwan and type 2. Okay, so even in, so the barrier sets for Taiwan and type 2, for example, are very different in this way, but still the optimal free target, optimal free target, I mean, the new solving this problem is uniquely determined. Is uniquely determined. You can easily show it using monotonicity. For example, if let's say new one is optimal free target for the course to C1, then if you consider the stopping time, then the stopping time for tau1 is less than or equal to the stopping time. The stopping time of tau 2 for nu2. So you get this. And then, so that order of stopping implies this order, the sub-bounding order between, there's some kind of order, sub-owning order. I'm not going to explain what this is. Some order between new one and new two. Some kind of stochastic order because the corresponding starting time has this order. But you can use new two to the same thing, then you get this other. This other inequality that gives you this opposite order between new one and new two, then as a result, nu1 and new two are the same. So, this reject, even though it's very simple to prove, it kind of supplies is It was surprising to us, Inon and I and me. Okay. All right, so that's the universality. Okay, so all these results so far are consequences of monotonicity. Okay, I think I spent too much time. Okay, so then another result is saturation. So saturation is this. You have some, so You have some, so given initial data, initial distribution, you move the stuff, the Brownian motion, and then there might be the case where you do not move the Brownian motion, and there are parts where you actually move the mass from the initial distribution. But wherever you move the mass, in the end, that region where you moved the branch. Where you moved the Brownian mass should saturate the constraint. Okay, the constraint, the upper bound, density upper bound should be saturated by your optimal target measure wherever your brown motion actually occurred. That is the saturation result. And then you can consider, let's say, some dynamic picture of this saturation. A picture of this situation, this like this. Let's just focus on this pi one case because this is the case I'm going to discuss. So, initially measure, as time goes on, so this initial distribution becomes like the support becomes smaller and smaller, but then it leaves this target measure at each time. So this is This is time direction, and the target measure. This is a finite target measure. This intermediate target measure grows and goes to this finite target measure. It grows like this. This new T, eta T, so eta T or moving Rhino mass kind of deposit its mass here, but it deposits the mass here in such a way that it set it. Here in such a way that it saturates this upper bound constraint for the density. So this new t grows like increasing this shape. So in the end, it just make this. Okay. So in this picture, this part does not move at all. There is some part where there is no movement at all, but whenever it has movement, that is saturated constraint. So type 1 and type 2, the process look different, but the target finite measure, finite optimal target measure are the same due to universality. And this process of this finite of this free target measure, this target measure growing corresponds to the changing free boundary over the time. Free boundary over the time of either a water freezing into ice or ice melting into water. So in both of these pictures, this eta t corresponds to the watery region and this region where it saturates the constraint corresponds to the ice. The ice, okay, and so the ice region. So, here it is ice, but here the eta is here. So, in this case, the outside type 2 is ice. And then, so the final region here is a region of melted ice, so the water. Okay, so this water region spread over melted. Spread over, melting the ice in the environment to get this. But here, waters get frozen. Okay, and this processes has corresponding PDE. Let me skip this part and this part. And in the end, you get the so-called step-up problem. So, in Taiwan case, you have some. You have some equation with this minus symbol, and type 2 case, you get this plus, and type 1 case corresponds to the freezing problem, type 2 case corresponds to the mating problem, and this mating problem is what has been extensively considered in the literature, even to the question of regularity and all these things. There are a lot of great reasons, especially recently by Figali and I should mention Figali and other people here. Sorry, I forgot. People here, sorry, I forgot. There are very recent direct rules in the regular attic cases of this melting problem. But the freezing problem, the Taiwan case, has not been considered very much and not much result. Even there are some negative results, namely no uniqueness. So, where post-nest does not hold and so on. In the freezing case. And okay, so maybe I should. Okay, so maybe I should stop soon. So basically what I want to say is you can use this free target problem to give the solution to this, in particular, the freezing free boundary problem, so-called supercooled step-up problem. And the point is that this optimal free target, which we found, which we found. Which we found from this free target problem gives a certain initial data, the initial domain. And on that initial domain, if we solve this problem, then our optimal stopping time for the corresponding optimal free target leads to the solution for this, let's say, free boundary equation. At least in these two important cases, where in this case, you start with this measure and then you. You start with this measure and then you get your solution. But in this case, okay, I don't want to say much now, but the whole process stops in finite time. And there's another case where the whole process of, let's say, freezing into ice does not stop in infinite time. Okay. It just continues forever. Okay. These are two. Forever, okay. These are two cases, and there are some further questions. Here is a reference, and I thank you very much for your attention. Yes, so can I ask about, so what conditions do you need on the function f I mean in terms of so I guess in some cases if your f is too restrictive, you won't have a solution. You won't have a solution. Are you able to say anything about when that happens in higher dimensions? Sorry, can you repeat? Somehow the background voice is not really easy to hear. I might have missed it. You might have said this, but in high dimensions, I guess, if your F is too restrictive, too small, then there may be no solutions, right? Are you able to say? Solutions, right? Are you able to say anything about? So I do not have that much familiar with the no-solution case, but at least non-uniqueness, you can find some domains like, I don't know, like even the even inner pool. The even in a ball, even in a ball, just this is a ball in our tool, let's say. And then let's say you have an initial measure, like a uniform measure on some small ball. And then you can find infinitely many solutions to the freezing problem in such a way that, I mean, the solution. I mean, the solution, you can consider the corresponding, let's say, target measure, and then you can generate some target measure looking like this analyst plus this, let's say, ball, and you can adjust the distance R1 and R2. Okay, and then Okay, and then you can just change it infinitely many ways, and for each choice of R1 and R2, you get a solution to the freezing problem. So the solution is infinitely many. So in that uniqueness is validated. And I should know this non-existence case too, but sorry, I do not have much familiar with that. But this example is in the paper, in our paper. Paper. Yeah. I mean, I have possibly a related question again about high dimensions. So, in one dimension, I can understand how this saturation condition, essentially, if you give me mu, I'll be able to draw a mu, I think. But in higher dimensions, it's much less clear how the geometry of this saturation will be. So, if I start with some mu and I have a constant. Mu and I have a constant f, but mu is non-there isn't a radial symmetry mu. Can we understand the target, the optional target measure mu? Is it easy to find? So it should be easy to put the type 2 case. Like let's say you have some distribution, like let's say heat energy of water between the ice. Then for example, if the Then, for example, if the initial decision was like the rotational symmetry, then the mating process should be symmetrical. Yes, yes, yes. I'm more interested in sort of highlighting a symmetrical situation. So, where the initial data is really has no symmetry and many, many different, you know, it's multimodal, etc. Where the initial, if you have perfect symmetry, then of course higher dimensions will be yeah, right. So, you can start with, yeah, yes, from the product point of view, you can. Yeah, yes, from the product point of view, you can start with this shape of, let's say, now to mu, and then it will say this complement is what F is, okay. F is some characteristic function of this complement set, okay. Then this mating region will increase in the type two case and the actual. Two case and the actual picture for time two case is like this. I think I already have the picture. Okay, but that's not, yeah, so okay, so I the picture I draw was for type one. So for type two, it is like I don't know, maybe I'm not answering your question, but it's just you can consider this battery of set in the This barrier set in the space-time, the barrier set here looks like this. You have the support of mu. Okay, so this is the support of mu. And then the variable set can be something like this. So some kind of function on the space, value in time. So, okay, let me erase this. So this can be your value set. So then, in the space-time, this region, which is this region, this initial region, increases in time like in this way. Okay, so that is type type, in this case, type 2. So, that's the kind of vetting process. And then, in type 1, okay, thank you. I understand this. I was really thinking of sort of higher dimensions and. Of you know, higher dimensions, and what happens to the geometry of the optimal free target? How can I understand the geometry of the optimal free target from the geometry of the initial measure? In one dimensional measure, I see, I see, I see. So, for example, I think in general, that is related to I mean, even for me, even more interesting question is, can we relate the shape of initial measure mu with the shape of this barrier? Read the shape of this barrier. Right, there's this kind of in the same spirit, right? So, one thing is that if something we could say, but we didn't include in the paper, was if this one was star-shaped, then the optimal target was star-shaped, something like that. I don't quite remember what we proved something really like that, but besides, it's just not super interesting because of some conditions. Because of some conditions we put there. And yeah, so you can do something, but India, I mean, just yeah, you can do something, I would say, but how yeah, how directly can you connect those two geometries? In other words, I do not think I have good understanding, at least myself, of how this barrier. This barrier, the shape of the barrier is determined from the shape of the distribution, initial distribution here. Thank you. One more question? Sorry, can I just ask one more quick question? So, in the 1D case where you have a where your target distribution is sort of fixed, right, there's a connection to optimal stop. There's a connection to optimal stopping problems, it's known. So you can reformulate the barrier problem in terms of optimal stopping problems. Do you know in these higher dimensions and with this sort of upper bound constraint on your target density whether there's something similar when you state your variation of inequality, whether you get a similar sort of. I think I need to listen to your question again. Sorry, I just kind of missed several points. Can you repeat, please? Sorry. Pit, please. So, in one dimension, for example, when you fix the target measure, so you have a unique formula of finding a boundary problem as an optimal stopping problem.