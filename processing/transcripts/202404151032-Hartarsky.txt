So Rob gave us a very broad overview of what there is in monster calculation. He covered really a vast number of models. I will not try to do that. I will try to do exactly the complementary things. So I will pick one model and I will go in depth on that one model. So the model I will pick is more or less the most classical and best studied model in brocure population. So for the purposes of the So, for the purposes of the workshop, I put on the website you can find listed references. So, there are like 30 to 40 papers exactly on this model, which is the two-neighbor model in two dimensions, what Provoc just started talking about. I will only talk about that, or rather a version of that. And the idea is not necessarily that you really desperately care about this model, but rather, But rather, phenomenology is usually the same or similar in other models. Also, techniques can be important from one another. So, if you have your favorite model, either this week or when you go home, you try and do the same kind of things. Maybe some of them work, maybe some of them don't. So, this will be the idea. And also, we will recap what kind of questions we want to look at for that. So, let me. So let me start. It will be about upper bounds today and lower bounds tomorrow. We don't know bounds on what, so it doesn't mean much. But let me start by defining the model. And tell me if it's too small or something. So the model, I will actually not work with the two-neighbor model, but a slightly simpler version of that, which is due to Froboise. From 89. So, in Rob's notation, this is a four-rule update. So, it's an update family with four rules in two dimensions. And it's these four rules. This is the origin, and I ask for these guys to be infected. So X is infected or X is set? X is the origin, and if I have top right and top right neighbors infected, then it also becomes neighboring basis. So in case you forgot Rob's notation already, let me give you another formulation of the same model. So whenever Three of the four vertices of a one-by-one square are infected. Well, yes, this is a common confusion. I will draw it. I declare this to be a one-by-one query. See, this is one. Okay, I don't know. This square, we have a transfer of this square. Once the module is defined, you will not need to discard this promise. So I will also draw up an example. Anyways, yes, the advantage of this is that if you call this a 2x2, somebody might think it's a 3x3. But if you call it a 1x1, nobody will think that it's a 0x. Not this thing, alright? But this thing are infected, then affect the fourth one. Okay, so let me draw a little example for the favorite one. Of course, it's taken at random. That's why I need to copy it. So if this is my grid. More or less, looking like this. Then what happens on the first step? You get this guy and this guy. These are on the first step. On the second step, First step. On the second step, I get this guy, this guy, one. This thing, this square here seems to be a little bit stuck. Here we also form the square. And we keep going. The third step, this one seems to be growing because of this. And this one is still stuck. Then I get this. Now they start interacting, form a kind of a rectangle which sees this. Which sees this square here and it starts growing. Together form eventually to infect everything. Unless I made something happen. Alright, so is the model clear? Okay, so this is the only model I will be talking about. If you don't like this model, you are particularly attached emotionally to the two-neighbor model, feel free to just think about Feel free to just think about the two-neighbor model. Everything I will say works basically the same. It's just a little more technical, and that's why I don't want to. Alright, so this is the model, and I could actually do this experiment also with you, but I've already done it with other people. It's actually more informative when you try to do it with people that don't know anything about anything. So you give them the model and you ask them what you want to know about. So, okay, let me give you five. Okay, let me give you five seconds to choose your answer. Okay, so everybody thought of a question. Let me try the guess. So question one, which I'll actually leave in the exercise, a very nice one. How many infections are needed? Are needed to infect in an n by n whatever n by n means. So, this actually there's multiple very nice solutions to this. One you probably don't know, so you can actually pick it up if you know one. Exercise two. What's an infection? What's an infection? Like, why are infections? It's like some dots. These are what I call infections. Okay. I started with some dots and then I put more dots in the process. So you're especially in the beginning that I have this. Yes, any initial condition, you get to choose the initial conditions, these initial dots. And you need to choose them in a smart way so that you have very few of them and you still manage. Have very few of them, and you still manage to infect everything better. Okay, pretty clear? Okay, thanks for this. So, this is a very nice thing to start with. Exercise two, and if we have time in the end, we can also discuss solutions, which will probably come up. How many steps Steps can take to become stationary, so we can no longer change anything on n by n. Again, whatever it is. Uh so this is uh usually a little bit harder, but here it's really an exercise. But here it's really an exercise. The next one is, I think, much, much less popular, even though I think it's more interesting than this one. So let me call this question three. We can consider it an open problem. I haven't really thought about it, but I don't think it's obvious. It makes me on the contrary. So, how many question choose the longest it can take? Yes. Yes. Can take? Yes. Yes. So this is about minimal number of dots. This is about the number seven of the picture. And this one, so these two are extremal combinatorics. This one will be enumerative combinatorics. So like in exercise two, you don't care about the how many you put the want to make it as long as not maybe you want to make how many steps? With how many steps? Let's take it. So at most how anyway, so find what it means and that's how many configurations With minimal number of initial impactions on M by N in fact every So, you first solve exercise one, then you look at configurations with exactly that many, and you tell me how many such configurations there are. This one is on the enumerative combinatory side, and I think it's not so much explored. So, in case your question is still not on the list, let me actually say what I will be talking about. That we'll be talking about, which is the maybe we'll leave a little space for more questions. So, the statistical physics perspective that Rob already told you about is about the critical scaling. So, this is also very naturally comes up. So, what about accounting role for exercises 2? Is it the county? What about the counting problem for exercise two? Because the question three is the counting problem for exercise one, right? Yes. Well, you could also ask this. Okay. There is a problem for questions. I think it's not even being asked. Sorry? I'm saying there is more room for questions. Yes, yes. I think you're going to have to. Yes, did I cover everybody's favorite question, but you came up in five seconds? Somebody? Somebody? Oh, ah. I mean, for example, yeah, can ask if you can do it like the combination of one and two also. Yes, but when you solve your exercises, you will use. Okay, so this is the one that I will be talking about. Take initial condition. IID with a distribution that I will call t equals k which is the product Bernoulli with parameter p on the square lattice so just take each vertex initially infected with probability p independently of everyone and what do we want to know And what do we want to know? We want to study, I prefer to study the infection time of the origin, as Rob predicted. But if you are again emotionally attached to studying the critical parameter on a finite torus or grid, feel free to do that. Everything is basically. Feel free to do that. Everything is basically done. I like this one because it's naturally defined in infinite volume, and you don't need to worry about cutting domains and stuff. Okay, so it's clear what this is. I don't know if my origin was this site, and it's six in this initial condition. I have a random initial condition, so this is a random variable. I want to know how big it is. We also mentioned the windows. We also mentioned the Windows, or how large is its variance, or something like that. Alright, so the first rigorous result in the actually on bootstrap propagation was made rigorous at least by an enteragon which is around virtually in 87, but he proved that. But we proved that for every P, almost surely the origin does get detected at some point. And Rob told you a little bit how it's proved. I won't detail more than that. I will directly tell you the next result. And there it will also become clear how you can prove this. But this you can see. But this you can see, for example, just by ergotic theory, you will find somewhere a big completely infected square. And if you also add a little bit of infections outside, it will manage to grow to infect everything. But we will see this in a little bit more detail for the next result. So the next result. The next result is what I actually want to tell you how it's proved. So it's due to Eisenman and Leibowitz. I personally regard this as the founding paper of Bustra Proclamation because it really introduces the phenomenology and several And several very important cases. So it's the following result. So for any epsilon positive, the probability that infection time is less than exponential phi squared over 6P plus epsilon goes to 1. Goes to 1 as p goes to 0. Why do we care about this? We care about this because of this result. So this tells us that the infection time is finite for any p. And okay, if you set p a half, then it's probability a half at zero, with probability something else, it's something of order one. You can study its tails, this makes sense. But the thing that they are studying here is what happens. Thing that they are studying here is what happens when you have very, very sparse inertial infections. And they proved this. So they didn't state it like this, but this is what they proved. So let's see how the proof goes. That is the result. Okay, so let me start with the definition, which is a definition of what I Which is a definition of what I call local so bossic operation. So if you know what this means, what I will define is probably not exactly what you think, but it's basically the same. So these local models were introduced by Ander and Janku at some point or they were introduced by They weren't introduced by me, at least in my view. So it's the following thing: consider a growing nested sequence of rectangles. For me, rectangles are things like this: R, A, B, C, D. So now we will have some disagreement, I guess. So this goes up to C minus 1 times D goes up to D minus 1. This uh is a rectangle. This is a rectangle. And you take a nested sequence of rectangles, let's call it RT, defined by induction by Rt plus 1 for any T. I didn't tell you the initial condition, but we'll specify that later. It's going to be if Rt is this. Going to be if Rt is this with ABCD. Next one will be slightly different. So A minus epsilon 1T, B minus epsilon 2T, C plus epsilon 3T and D plus epsilon 4T. Okay, where I'll draw a picture. I'll draw a picture in it, don't worry. Epsilon IT is the indicator of there exists an infection in the initial condition next to side i of R T. Okay, that's enough formula, so I'll just do a picture. So I'll just go a picture. This is your rectangle RT. And let's say there is a this is its side 1, side 2, its side 3, and side 4. If there is an infection here, then epsilon 1 will be 1. So next rectangle will be slightly bigger in this direction. Maybe there's no infection here, so it will not be bigger downwards. So it will not be bigger downwards. Maybe there's a couple of divisions here and here. So in this case, our t plus one is going to be one column wider to the left, one column wider to the right, and one column taller. So this is my R t. Alright, so this is so far just a definition, but how is it? Does it have anything to do with this? Maybe you already see. So epsilon changes for every step on the way. Yes, it depends on two. And it's a zero or one. Right, so let's see why this is relevant if I have a rectangle that Rectangle that I somehow managed to completely infect in non-local verbose population. And I have these infections here. If I have an infection here, what do I see? This is the first column next to the rectangle. Here I see an infection, and here I see an infection. So if I look at this update rule here, I see Here, I see that the cross over there will get infected by this rule. And similarly, so that I don't go back and forth, I will use this rule to go down. Okay, so it actually infects this one and this one, and then it goes in the same way up to the corner, up and down. And similarly, if I have some infection. And similarly, if I have some infections here, it will indeed fill up the entire RT plus one. So this is why this is somehow related and makes sense to consider. Okay. Maybe I'll keep this just in case. Alright, so this local bootstrap propulsion is very useful for proving upper bounds. This is what I call upper bounds. So, lemma for any like this: the probability that That vocal proposal started at the singleton rectangle. This one, in fact, C2 is at least x. least exponential minus pi square over 3p which holds for any p actually of even asymptote okay so before proving the lemma let me draw a picture for how you deduce this from this this is basically the same reasoning that you use to prove this so the picture is the following you once you have this Once you have this, you truncate, so you don't require to infect everything, you just require to manage, starting from zero, to infect something kind of big of size, let's say, p to the minus three. Think of p small. So this will happen with this probability. Once I have this, This it is going to be extremely likely. So, okay, this happens with this probability, but this size is kind of small. So, if I look at the origins here, I look at an extremely large box with size exponential y squared over 6p, roughly. And I split it into boxes of this size, I have approximately this chance to see this stuff happening in each of them. And I'm in two dimensions, so this is why you see this difference of factor two from here to here. With high probability, it will happen somewhere in some of these boxes. Of these oxides. It's just by independence. And once it does happen, let's say it happens here. It's not hard to convince yourself. Let me actually do it. So I can also ask for there to be an infection on each line, either horizontal or vertical, here, and everywhere. And everywhere in this huge box, the probability of this failing is 1 minus p to the power something like e to the minus 3. And then I want this to not happen anywhere. So I want to compare this with the volume. It's a union bound. So this I'm claiming that it's much less than And it controls whatever constant over this tells you that with super high probability there are infections on each line of this size and with very high probability there is a box where uh you manage to infect everything just looking there. Once both of these things are the case, Once both of these things are the case, you see from this picture that things will propagate. And they will propagate at basically linear speed up to a small factor, something like that. But you don't care because it's in front of the exponential. So it gets absorbed in the exile. Okay, so it grows linearly to until it reaches the origin. Reaches the origin. And it does so basically at the distance, which is a more like this. Is this clear? So this reasoning is basically always like this. You don't need to repeat it. It's always like this. When you look at it, it basically proves you this. And now, to prove this, we just need to work on this lemma. Alright, so let me do that. So this proof lemma I will prove Uh so this proof lemma I will prove uh maybe I won't prove here but um it's uh it's not very hard. So proof of lemma. So just one I mean when you say it grows linearly peak you mean it's sort of at speed pq but that doesn't matter at this CL so it grows at speed that's somewhere between one and pq but that's fine. So, the proof of dilemma, because we're looking for an upper bound, it suffices to just suggest a way to do this and compute the probability and hope for the best. A very natural way to do this: so, the probability of what I was written there is, okay, probability of the thing that Probability of the thing that I will draw to occur. I will require the origin will be here. I will require for there to be an infection here. This is the origin. Also draw a cross so that you know it's the origin. And I will also ask for an infection to be here, just above. And I will ask for at least one of these two sites here to be infected. At least one of these two sites here to be infected. At least one of these three sites here to be infected. Sides here to be detected, at least one of these three, at least one of these four, and so on and so forth, to infinity. Okay, so this guy is three, three, four, and so on. And this is an inventory. Let's compute its probability. It's equal to p squared, I'll actually write it correctly, probability n from 1 to infinity of of 1 minus 1 minus p to the power, sorry, to the power n all of this squared because each size appears twice. Right? Okay, so let's keep going. I take the log, so I put it in exponential form, 2 sum 50. 80 log 1 minus something, 1 minus this thing, and I will also use a little bit of convexity of exponential to write e to the minus n of t. So far I haven't done much. Now this starts looking, I will maybe erase, this starts looking strikingly like a Riemann sum. Like a Riemann sum. So the Riemann sum of what? A picture of a function f. f of x is minus log 1 minus e to the minus x, which you basically see appearing here. And this function looks like this. Function looks like this. It's the nicest function you can do. Okay, so this thing starts looking, and then we're looking at the Riemann sum, so something like this. You probably get flashbacks from your undergrad. We are summing this, and of course, a good way to bound it is by the entire integral under the curve. So let's do that. So let's do that because the function is decreasing before. So the exponential times the integral from 0 to infinity of this function f that I'll actually write 1 1 minus x dx and I minus scale so there's a movement over, right? We need to remind us that. Do we need to remind that? Because that integral is positive. Uh this guy looks uh yes. Well, uh, if you'd like, thanks. Uh okay, so we are there. At this point, we just want to compute this integral, which I will actually do. Uh, let me compute the integrals from 0 to integer f. I change variables. I change the variable in the natural way. This e to the minus 6 becomes y times log 1 minus y. There's a change of maybe of sign like this. Sounds good. Okay, so this I can compute. This I can compute by developing this as a Taylor series. I do insist on this on switching in integrals. From 1 to infinity, integral of 1. Here you get y k minus 1 because y over k y. This is this you can integrate. It gives you 1 over you 1 over k, so you get some, and from 1 to infinity, 1 over k squared, which is zeta of 2, which is pi squared over 6. Okay, so this is actually equal exponential pi squared over 3p as I can. So I instead So I insisted on doing this computation so that you don't think that this number is mysterious. It's not. All that there is to this proof is this picture. See this picture? There's just some convexity here, some agreements, some whatever, but there's no mystery. It's just that. Is this proof clear? Sorry, what was this square divided thing? How did that relate to this proof? Again, am I? Sorry, this one. This proof again? I might have this one? Yeah, like what was this picture related to? So, this was how to deduce the theorem that was here from the Bengali sound? I still think it's mysterious. It's not a comment, it's not a question. Right, right. This is as good as I can do in demystifying this. Okay, so before I move on, let me make a few comments. So this bootstrap population is a cellular automaton, as it's clear. So the first thing that comes to mind that you could do with bootstrap population is to simulate, take a random initial condition and run Initial condition and run the automathon. Maybe do this a bunch of times, take the statistics, and see what happens. So, this random variable you can approximate, sample your distribution of this. Now, I will not go too much into that because I think I would talk more in detail. But there is this phenomenon called the booster population paradox, which basically tells you, I'm sorry. Basically, it tells you, long story short, whenever you do this, you get completely wrong results. And so we'll try to understand why. But this actually is, I guess, the main motivation in doing better than this. Because just from this, you don't see why it does not work. Because people from the other side of the culture would say if you do the simulation, then you understand. But whenever these mathematicians related to these stupid things in. Try to do this stupid thing with animals that I always get the most of. I hope that Augusto will convince you that there is a good way to make people happy and still agree that this is indeed what it is. These are all the true guarantee. Yes, so one word more. So, anyway, so this motivates looking for subsequent terms. Subsequent terms. So, what is the asymptotic behavior of this epsilon might be your so which will be the last one? Second order correction. Right, so I will try to prove for you the following theorem, the baby version of what you can find. baby version of what you can find in our paper with a wistful so it's I will directly state it in the terms of the lemma but going from there to the theorem is as usual so local position Proper equation that is at least null minus pi squared over 3p plus pi over Over root. Uh fine. Uh right. And when what could be we'll prove a bit better. Okay, so let me try to convince you of this. This will be more elements of the proof, not the complete proof. So the Isingman-Lebowski result was this picture. That is the upper bound, lower bound model. So there, what are we doing? We are trying to be as fair as possible. We do right, left, uh, right, top, right, top, right, dot. Uh so here the idea will be a bit different. The idea will be a bit different. We'll try to be as stubborn as possible. So we will go. Let me start by telling you what the double step is. Something like this. So you have managed to produce some rectangle A plus B somehow. I don't care. Then I really like going to the right. So I will go to the right. As long as I can away. As long as I can, when can I go to the right when I have at least one infection on each of these columns? And at some point I can't, because here it is. Okay, so then I am obliged to go up. Exercise. I'm going up until when? So I really like going to the room. Like going to the right. So, as soon as I can, I will go to the right. Let's say I can't go here, and then suddenly I actually manage to go to the right. So, I'll find an inflection. Okay, and then I will be able to restart from the slightly bigger rectangle. So, we call this C and D, which is a job. So, what is the problem? What is the probability of the event that I just drew? Well, it's t times this part, which is 1 minus 1 minus e to the power b all of it to the power c minus a minus 1 a times. A times one, uh, p was for this infection. Uh one minus one minus p to the power size b? Oh no, I will not answer it. Be faithful to yourself. Yes, I will try. Uh so this one is So this one is this one is C minus one and this one is D minus B. Okay, so this is the probability of this. Let me rewrite it slightly. And to rewrite it slightly, I will use another picture, which is very useful. We started with the rectangle A times B. I will use these plots quite a lot. And what did we do? And what did we do? We increased the width here C. Then we increased the height, reached D, and we did a little step that applies exactly. This is what we did. And I will try to make appear something here. So this I will write as So, this I will write as so I will introduce this I will call a path gamma A B C D W of this path is going to be the integral of a differential form along the path that is f of x dy plus f of y. y plus f of y f of y dx so this is because you see here you see you have the height this is a weight difference this is a width and this is a height difference okay so that's why they have f of x dy and f of y dx okay so this just with this rewriting you can it's equal and not It's equal, I'm not doing anything. So f of so this is b times q, q I will define in concomitant here. It's minus log 1 minus p, which is approximately p, so you can completely think it's p everywhere, times c minus p. C minus A minus 1 plus it's still in the exponent. Ah, L will be the minus. F of C minus 1 times Q times D minus B. Okay? This is almost the differential form along this path. The only thing that is slightly off is that I'm missing this bit here, the last. This bit here, the last step, which is which I can add and subtract. This becomes P times e to the, I think it was V something like that. I need to refrain for myself. Hopefully, DQ, yes. F of D Q. So a plus. I added a I added and I subtracted and then e to the minus W of gamma A C D. If I rescale it a little bit, I will rescale things a little bit here by Q. Please be sure. All right. Alright, so this is good. Now, one more thing we need to do is to take such, so this will be our basic step. We're going to build stuff from that. Well, maybe it's okay. I'm going to start building things from that. So, out of this basic step, we will build a bigger thing which is still not that big. I'll go from a certain, maybe x is more natural, to x plus delta, x to x plus delta. And so that you know what to think of, this x is already rescaled by a factor of q. Scaled by a factor q, or a detailed. It'll be order 1. And delta, I will take like e to the 1 third. So it's small. I'm going from a square to a slightly bigger square. And I will do so in many such steps. So I will do many such elementary steps actually stack very well when you append. When you append one to the other, they act nicely. So this is some path gamma. And I will, so let me compute the probability of such a path gamma occurring. So it's just the each of those events happens for each of the pieces of the path. It's the product of those things. It's the product of those things. So let me take, right, so this P times e to the minus, sorry, e to the F of EQ. But D is not going to vary much. So gamma, I should have said ten steps, ten double steps. In double steps. So, this D I can more or less replace my X. Let me replace it by X. This thing is to the power n. And then I have this bit here. But integrals of differential forms along paths. Integrals of differential forms along paths, uh well, they concatenate well. So uh sorry, x is multiplied by q ah put up co to the minus w of yeah, maybe one of these things. All right, happy with this? So, what do we do next? I will skip a lemma for now at least. For any gamma, this is approximately the one of the straight path. Okay, this is getting very messy. So, this is the straight path. And this is an analysis level, right? It's just you quantify small, so I can do it alphabetically. But there's more relevant things to do. So let me replace this here. This I can, I know how much I'm worried about this. Now, the key thing about this. Now, the key thing about this event, and even when you take several, is that they are disjoint. This is because I just said it's basically an exploration. You try to go as far right as you can, and then you get blocked, and then so on. So it's really uniquely defined exactly which path we'll take based on the configuration. So these things are going to be distributed. I can actually take the sum. Actually, take the sum over gamma of the probability of gamma. This will be at least what. So the minus 1 over q, by the way, this, okay, this is what? This is the integral wise f from x to x plus L. Just a piece of my integral from s equal to pi squared over 6. And so x to x of delta of f times something. And this something is times. So one thing is this, I'll copy, and then I will need to worry about the combinatorics. So how many. Well, how many such paths are there? I basically fixed how much by how much I want to increase the width and the height, and I fixed how many steps I do to the one. So it's a simple commentarium. Convince yourself that it's approximately delta over Q, approximately choose N square. You need to choose. Square. We need to choose basically these points here on the partition and the ones on this side. Okay, and there's this many ways to do that, basically. Okay, so let's do this. Maybe I won't fit it here. How do we do this? We compute this guy we approximate in the usual way for binomial coefficients. We expect to filter. Times P. By the way, uh this thing, unless did I mess something up or I did not. Oh, I did. Ah, yes, I did. Final Z I'm sorry. There should have been a minus x all over already here. Ah yes, yes, I forgot. Yes, there was this. Yes. Okay. Thank you for pointing this out. There was another term that I forgot, which was not having any infectious features. At least I just forgot to put it. I'm not. So there was times exponential. was times exponential, sorry, 1 minus p to the power t minus 1, which here gives you times e to the minus q times d minus 1. Okay, and this point I would have approximated by minus x. So minus x here, and this thing is you can check if you remember the function f that it's 1 over e to the x minus 1. Right. It's just equal. Okay, so you also require no further steps upward passing along? No, I as soon as I can go to the right, I do. Can go to the right, I do. But there's this P tells me that I stopped the first. All right, so P over e to the X minus 1 R n times, this guy is basically delta over Q N, there's an E R to N. R2 in. This is the binomial partition approximation. And this starts looking well. So I can even put a 2 here and put a root here. Now optimize N. So to optimize N, you just remember that X to the X is The X is optimized at 1 over E minimum, I guess. Okay, so then you get that this is the minus 2 over Q integral of f from X to X plus delta times Times and here get exponential of two node P plus one and one cover normally it's this yep, which I didn't. Yep, which I didn't. Kind of the Q was uh not this one is rooted, this one is not okay, so this root P and Q were approximately equal, so you get just here approximately 2 over Q root Q one over root E to the X minus 1. Okay, so Okay, so we are very happy we managed to do one little step from x to x plus delta. This little step gave us this first order contribution, which is the integral at f, and the second order contribution, which you see has already this right scaling, one over root q. And there is, well, this new function, I'll call h. And now you put many such steps. And now you put many such steps together, it gives you a new Riemann sum. This one is already like the sum of pieces of an integral, this one is a Riemann sum, approximately. So then, okay, I'm skipping a little bit, you get that the probability that we want is at least exponential minus 2 over q integral of f from 0 to infinity plus Plus 2 over root q, the integral from 0 to infinity of h. Okay, and the last exercise for the day, 3 or whatever, however we count. I prefer this. Integral from 0 to infinity of h equals pi. So when you put all this together, So when you put all this together, you get what I claim to in front of the pi. And then when you translate back, you get just a pi, which is not the right one. But this is a spoiler. Okay, so this is what I wanted to show you. Maybe some concluding words. I think I will not prove this lemma and let's. I think I will not prove this lemma unless you really want me to. So let me rather clue here and leave time for questions also on the exercise discussed. Tomorrow we'll talk about lower. So thanks very much. So again, I'm sure you're going to cover this in great detail, but just to point out that the Isingland Digimets have got Ising the neighborhoods, of course, had a lower amount as well. Yes, yes, this is the one. Even more important total than the development. Sorry, yes. I'm not mentioning gold. But okay, so I think the theorem I stated this Eisenhower-Lebowitz result with the pi square over six. They did I think the only thing that they did not do was compute the integral. Compute the integral. But apart from that, I can't be sure. Perhaps it's not so related to what you said today, but a little bit related to what Andrew said previously. So you start with a P, which is the density, but then you get two sources of randomness, which is both the number of points that you sample and also the distribution. So if you just fix the number of points, how do Of points, how does that have an effect to?