Continue. So, when you're ready, Ivan, thank you. Um, hello, everyone. Um, so yeah, so my name is Ivan Gwill. I'm from Monash University, which is in Melbourne, Australia. Um, today I'm going to talk a little bit about robust hedging. And as we know, robust hedging has a sort of a rich history of connections with optimal transport. So, the talk will be roughly divided into two halves. The first half will be about optimal transport in continuous time, and then the second half is in the In continuous time. And then the second half will be sort of results and concepts more specific to the problem of robust hedging American options. The two halves are a little bit disjoint in the sense that the ideas are pretty separate. They don't really overlap too much, but both components are sort of required to come together at the end to get the main results for American options. Okay, so this work is a joint work with Jan as well as Screbalo Pet. So let's start off with. So let's start off with talking about optimal transport in continuous time. So perhaps one of the more famous works of optimal transport in continuous time was from Ben Moore and Brenier, who looked at optimal transport problems for deterministic settings, but in continuous time. So where the cost function, I think, is a cost function of the drift or the velocity parameter. And then since then, there's been a lot of development in the area of stochastic. Uh, in the area of stochastic optimal transport or the so-called martingale benimal brenier. Um, so there are a bunch of different references, but overall, the general theme is we look at the set of probability measures on the canonical space where the canonical process is a semi-Martingale. So, in particular, we have the usual decomposition. We characterize a semi-Martingale with the alpha and beta. So, alpha is the drift and beta is. So, alpha is the drift and beta is the diffusion characteristic. And then the optimal transport problem is to look for a measure, a semi-Marningal measure, so to speak, where it minimizes some function of these alpha and betas. So in particular, we still require marginal constraints at the initial and final times. So we start at mu zero. We want the final marginal at time one to be mu one. We look for a semi-marginal measure where a minimizer. For a semi-mining L measure where it minimizes h, where h is some sort of cost function. So, typically in this sort of work, we require h to be convex, but it can be random. So it's not just a deterministic function. It could depend on t and x. Okay, so a lot has been done about this. So this is the, I guess, the primal problem. Typically, you'll be able to derive a dual formulation in terms of partial differential equations. Terms of partial differential equations, especially if you're in a Markovian setting. So today I'll start off talking a little bit about the path-dependent case where you're not necessarily in the Markovian setting. So the motivation originally was when we looked at this was for the problem of volatility calibration. In particular, this sort of ideas represents the fact that suppose you have a bunch of option prices known for a particular maturity. Those option prices allows you to reconstruct a marginal. Allows you to reconstruct a marginal distribution mu1. So, in that case, what is the volatility model that will give you precisely those marginal distributions? But then the question went on and we thought about what if you don't have the marginal, the entire marginal, instead you just have a finite number of options or a discrete number of options. So, doing so, we need to relax this marginal constraint to something more general. So, for example, instead of the marginal constraint being fixed, what if we marginal constraint being fixed what if we just fix some moments of of x1 or perhaps some path dependent functionals of x the entire process itself or maybe we want to have some constraints on the quantiles and so on so there's all sorts of different constraints that you can place that's not just the the terminal marginal so to speak so then we try to formulate this in a more general way in particular we want to restrict our optimization problem to the set of Our optimization problem to the set of probability measures within some sort of a convex closed subset of probability measures. So here, curly n represents a set of probability measures that satisfy the constraints we want. So for example, it gives you the correct, the desired moment constraint. So how do you formulate this? So you can write down a Lagrange multiplier for this constraint. So in general, it looks something like this, but the crux of it. Something like this, but the crux of it is that it's a function so that it returns zero when you're inside the constraint, but it gives you infinity if you don't. So that's something you can add to your objective to penalize the incorrect measures that are outside the constraints that you're optimizing over. So some basic examples. If you have some sort of expectation on some functionals, then you can write down the usual Lagrange multiplier, lambda, where you're penalizing anything that. Where you're penalizing anything that's different, that gives you the incorrect expectation. Or if you have some sort of marginal constraints of a functional, then you'll be using a Lagrange multiplier that's in the space of continuous functions. Okay, but so you can remember this F star is simply a function that penalizes measures that do not satisfy the constraint. Okay, so because we're dealing with path-dependent constraints, essentially, we need to extend the partial. Extend the partial differential equations to a more path-dependent setting. And then one way to do this is to make use of the path-dependent PDEs introduced by Bruno de Pierre. So roughly speaking, instead of having the usual derivatives, we replace them with the so-called time and space derivatives. Sometimes people also call it the horizontal and vertical derivatives. So the space we're working under is actually the space of our stopped path, lambda, here. Oops. So the space here. Oops, so the space here is this one, so it comes in pairs of time and omega stopped at time t. And then for a given stopped path, the two different kinds of derivatives look at what happens to your function if you perturb it in two different ways. So if you extend the same path forward in time by dt, so that gives you the time derivative, or if you locally have a jump in the path. So of course, originally, this is defined for Cadillac. This is defined for Cadillac, the space of Cadillac parts to allow for this jump. But later on, there's alternate definitions that focus on the space of continuous parts. But in terms of just intuition, it tracks the behavior of the function as you move the endpoint of this stopped path. Okay, so the big important formula is we have the so-called functional Ito formula that looks very much like the usual Ito formula, except we replace all the derivatives with the newly defined. Derivatives with the newly defined time and space or horizontal and vertical derivatives. But other than that, it looks pretty much similar. So, phi here is a C12 function, but this C12 is in a sense of the path derivatives. And then we say a function is in C12 if function, if Ito's formula holds for every semi-Marningal measure. So, typically, you want the semi-Marningal measure to have somehow bounded characteristics or something like that. Somehow, bounded characteristics or something like that, but essentially, you want Ito formula to hold regardless of the semi-Meininga measure that you choose. But this looks just like the Ito formula. So the double dot here, the colon here, is just simply the trace of the matrix product, if you're wondering what that is. But other than that, this is not too surprising. What is a little bit surprising, and that's something that we had to work for, is sort of the converse of the previous statement. Statement. So previously, I said that we want to solve an optimization problem where we have some constraints on the measures. We define some function that penalizes the incorrect measures. Next, we also want to find some sort of way to penalize measures which are not the right semi-Martingale measures. So how do you identify the semi-Martingale measures from the rest of them? So it turns out that you can use this C12 function in the path derivative sense and have the following formula. So what it says exactly. So, what it says exactly is that suppose you have a measure μ and a measure ν, where μ is on the lambda space, so the space of the stopped paths, then you have something that looks like Ito formula once again for some coefficients alpha and beta. And it turns out that this holds for all C1, 2 function if and only if mu is effectively a semi-Meiningau measure. So, you can read this as sort of the converse. Read this as sort of the converse of the previous statement. The previous statement says for every semi-Marlingau measure, a function is a C12 function if you have Ito formula. This is saying that you can use C12 functions as the space of test functions to test for your semi-Martingale measure. So there's a shorthand here just for this equation, but you can see it essentially as a Lagrange multiplier for the space of semi-Martingale measures. So equipped with these. So, equipped with these different Lagrange multipliers, we can go back and write down our original problem. So, our original problem is to solve an optimal transport problem of some kind. I don't know if it's correct to still call it optimal transport since we don't necessarily have marginal constraints anymore, but some sort of optimal optimization problem where we're minimizing a cost function of the diffusion and drift characteristics with the constraints. So, remember here, n is our abstract constraints. Abstract constraints that's replacing the usual marginal constraints. And then we also require P to be in the space of semi-Marnegal measures. So, of course, F star was the Lagrange multiplier for our N constraint, our abstract constraint. And then this curly L was our lemma from before, which penalizes measures which are outside of the semi-martial measure set that we want. So you can write the entire thing as a saddle point problem. And then, of course, as usual, if you're Um, and then, of course, as usual, if you want looking for the dual formulation, you want to swap the inf and the soup. So, the way you do it do this is the pretty standard in optimal transport theory. So, we use the Fenchel-Rockefeller duality theorem. In this case, we have to choose the right pairings to make this work. So, in particular, we're going to pair up mu, which is the Siemy-Manigal measure, with, I guess, in this case, phi1. You don't quite see phi one here because it's within the L. Remember, L is essentially an each. L. Remember, L is essentially an Ito formula, so it has like phi one minus phi zero. But the more interesting part is we pair up nu. So nu here is a measure on the space of in the lambda space, which is a space of stopped paths. We pair up nu with the derivatives of phi. So as mentioned, the derivatives phi are the space and time path derivatives of phi act as the Lagrange multiplier for semi-Malinga measures. Okay, and then the argument after that is. Okay, and then the argument after that is a little bit tedious, a little bit technical, but overall the strategy is what you expect for these kinds of duality arguments. And of course, this is Spencer-Rockefeller duality theorem, which allows to effectively swap an inf with a soup under some conditions. In other words, it transforms an optimization problem in the primal space to the dual space. So instead of maximizing distances between functions, you're minimizing. Between functions, you're minimizing distances between gradients. Okay, so this is again our problem. We apply the Fenghuild-Rockefeller duality theorem to swap the inf and the soup. And after that swap, you can do some simplification here. In particular, the H and the Psi, they all get absorbed into your Ito formula term here. And everything simplifies down to something that might not look very familiar, but Not look very familiar, but if you've seen the Marninger optimal transport result in continuous time or the Maringer-Benemu-Brenier, you can sort of see this F of psi as the terminal condition. So usually you'll see a phi of one times d rho one, something like that here. But instead, because we have the more general constraint, we get a more arbitrary function f here. But also, you have the partial differential equation that you expect, but instead of that, we have a PPD, a path-dependent path. A PPDE, a path-dependent partial differential equation. So the terminal constraint is an inequality, and as well as the PPDE itself is an inequality, and it's, of course, a fully non-linear PPDE. By the way, H star here is, of course, the convex conjugate of the cost function that we had before. As you can see, we sort of transform the cost function of the diffusion and the drift characteristics to our dual terms, which are the space derivatives of phi. Okay, so again, this is just writing out the same equation again, just so we can look at it for reference. So we have a lot of results that you get for free from the Fencher-Rockefeller theorem in particular. We know that the primal problem is attained as long as both sides are finite. So this duality holds even if both sides are infinite. Not only that, there is some stability result in the sense that if you go to the dual problem, which is by the way, Dual problem, which is by the way, a maximization problem of the space of continuous functions and C1, two functions, if you have a minimizing or sorry, a maximizing sequence of them, then in some sense, this maximizing sequence allows you to approximate the optimizer of the primal problem. So in particular, these inequalities become equalities in the limit, and then you can even calculate under some smoothness conditions the optimal alpha and b. The optimal alpha and beta. So, the optimal characteristics that define the semi-Marlinger measure that we were looking for in the first place. And then the other thing that's sort of curious is that the PBD here is essentially an HJB equation, right? Because you have the dual side here is essentially an optimal control problem, a stochastic control problem of some kind. If you go ahead and prove dynamic programming, you can get some sort of a HJB equation, and that's precisely. HJB equation, and that's precisely what the PPDE here says. Except somehow we got to the PPDE formulation without going through the usual dynamic programming, measurable selection path that you would usually do. So this approach, interestingly, sort of bypasses that step and goes straight to the PBDE. And you can actually use this result sort of in reverse to quickly prove dynamic programming sort of in another way without using measurable selection. Selection. Okay, so this is essentially kind of a summary of the path-dependent optimal transport result. So, like I said, originally, this was motivated by problems in model calibration or volatility calibration. So, here's just a brief picture. So, this is a picture of a volatility model that we calibrate to a large set of European options, barrier options, as well as look back options. So, typically, when you only have European prices, you can use DuPia. Have European prices, you can use DuPier's formula or something to get a local volatility. Whereas, here, because we have European prices and a bunch of exotic option prices, we have a volatility surface that depends on the Markov variables that drives all of these options. So, in particular, this volatility function is a function of the current spot price, as well as the running, I think it's the running minimum, because we're doing the down and out side barriers. But this is the But uh, but this is done using simulated data. Um, but we've also applied similar techniques to other kinds of calibration problems. So, in particular, we've had a sort of a paper on the LSV calibration as well as a joint calibration of VIX and SPX option prices. So, so this technique is quite flexible. You just have to sort of apply it in the right setting, then perhaps, you know, extend the dimensions in the right way. And then you'll be able to sort of, you'll have a method that essentially allows you to calculate to. Essentially, it allows you to calculate to exotic options or very complex options exactly. Okay, so but this is not the topic of the talk today. The topic of the talk today is, of course, robust hedging. As mentioned, robust hedging is very, very closely connected to optimal transport. So very briefly, what is robust hedging? So in financial mathematics, we have some underlying and usually the question is, we would like to price some sort of an option. Of an option or derivative contract based on the underlying, but this depends on the model that we choose. So, robust hedging answers the question of what if your model specification was perhaps incorrect in some way, or perhaps there's uncertainty in your model specification. So, instead of having one model, it's relevant to look at a set of possible models. So, here Q represents essentially the set of possible models. And the question is, what is the worst case hedging? What is the worst case hedging price over this set of possible models? So, the typical setup: we have an underlying, we have a bunch of European contracts G, which we already know the price of. So, these are sort of existing contracts already in the market that we can trade as well to help with our hedging. But typically, we allow G to be just statically traded. There's something that you buy and hold from the beginning. And then the big question is: how do you hedge? Question: Is how do you hedge another contract that's outside the set G? Usually, we normalize G to have initial price of zero just to make the algebra a little bit simpler. So, the set of possible models here represents the set of Martingale measures of your underlying with the right expectations for G. So, given another European claim Z, the worst case model is the most expensive of the prices over the set of possible models. The prices of the set of possible models for Z. So, again, the set of possible models are the Marningale measures with zero expectations for the static European portion. There's also a dual side of this, which is the, what is the super hedging price? So the super hedging is, of course, a portfolio that you run that covers all possible outcomes. But because you also have model uncertainty, you want to cover all possible outcomes over the set of all possible models that you could have. So, super hedging. So, superhedging is a in this case, a pair of I include a dynamic component in the underlying Q. So, Q here is a dynamic trading strategy of the underlying, whereas H is a static trading strategy on the European options G that we have lying around. And the goal is, of course, to have a portfolio that super replicates Z at the end. And the question is, what is the cheapest initial startup cost that you can have that achieves this? That you can have that achieves this, and we need to do this over the set of all possible models. So, this needs to be done quasi-surely over Q. Okay, so it's very well known that we have duality in many settings between these two prices, the worst case model price and the so-called cheapest super hedging price. It's very easy to check inequality between the two, that the super hedging price just by taking expectations, you can check it's greater than the one. Uh, you can check it's greater than the worst-case model price, but it's well known that you do have equality. There's been many, many papers about this in all sorts of different settings: there's discrete time, continuous time, and so on. Okay, so but just very quickly, how does this link to the optimal transport that we just talked about a little bit earlier? Well, I'm bringing back here the duality result of the path-dependent optimal transport, but I've put in a specific constraint, so I've put in a specific function. Uh, constraint. So, I'll put in a specific function f at the start here. So, effectively, you can see this: the primal problem here is your robust hedging problem because Z is the contract that you want to hedge. G are those static European claims that you are allowed to use to help you. Here, the inf of H, so H is the Lagrange multiplier of G. In particular, it penalizes G being penalized measures which give you the incorrect prices for those G. And then you also have. Those g and then you also have a cost function in terms. So, what is this cost function in this case? So, as usual, with these sort of problems, you need some convexity of sorry, some compactness on the set of probability measures. And this is done so by one way to do this is choose an H, which essentially disallows characteristics that are outside of some bounds. So, you can think of them as sort of volatility bounds. If your volatility is above a certain level, H will just be infinity, otherwise, H will just be zero. So, this is. Will just be zero. So, this is a kind of cost function you can use for robust hedging. So, yeah, so the entire primal problem is the same as the worst-case model price. The dual problem, on the other hand, we saw it can be written as a PVDE. So, as it turns out, that this dual problem exactly is the super hedging price. And we will see how that works. It's actually quite straightforward. So, again, at the top here, I've just written out the dual problem once again, except I've actually Once again, except I've actually computed what H star is because H star, remember, H was penalizing volatility. So beta here is the square of volatility. H is the cost function is penalizing volatilities that are too big or too small, whatever it is. So the dual of that is simply something that looks like a sort of type of PD that you'll get in the typical control problem. So to check that you actually get the super hedge that we want, we simply That we want. We simply check this term on the left. As you can see, z minus h times g is less than phi 1 by definition. So this holds for every phi. And then we have phi 1 minus phi 0, which by the functional Ito formula has an Ito formula. And this holds for every Sami-Marlinger measure, remember? And then within this Ito formula, some of the terms are negative due to the PPD, right? So in particular, the DT. d right so in particular the dt and the and the second order term the dxx term um is zero sorry is negative so you can remove that term and you you get an inequality and then all you're left with is essentially the hedging portfolio so in particular the hedging portfolio here is the uh the gradient of phi is dx phi okay and then rearranging that just tells you that in fact uh phi zero was a i guess is is a is a feasible startup cost A feasible startup cost for this super hedge because you start with phi zero, you run your uh also your static post portion in G, you have your dynamic portion in X, and then you have an inequality that always super replicates Z. But this is simply using the conditions of the PPDE as well as functional uto formula. But yeah, it comes straight from the dual problem of the optimal transport. And then, yeah, so this shows that for any five. This shows that for any phi in the C12 space, phi zero is a valid superhedge. And if you take the actual dual problem, which minimizes over the set of all C12 functions, you get the superhedging price, the cheapest superhedging price. And the duality tells you that, in fact, the primal problem, which is the worst case model price, is equal to the cheapest superhedging price. But this is not really new. This is sort of known already in lots of different settings. And sort of this connection to optimal. Of this connection to optimal transport is sort of well studied and sort of very nice. Okay, of course, so what we're here to talk about today is American options or the robust hedging of American options. So to do that, we need to add, of course, the element of stopping times. In particular, now the contract can be exercised as some sort of stopping time. So we're looking at this from the seller perspective, I suppose, because you're selling an American option. So you're not controlling the stopping time. Controlling the stopping time. So, when you solve the robust hedging problem, you need to look at the worst-case model price as well as with the worst-case stopping time. So, here Z is a price, sorry, it's a payoff process. So it's a function of both omega and t. And then your objective is to maximize the expectation of the set of all feasible models or possible models, Q, as well as the set of all stopping times. Set of all stopping times. On the side of super hedging, again, you can tell a similar story, except now you've got to keep in mind that as the seller, your hedge can react to the stopping time. In particular, your hedge has sort of two components in the dynamic portion. So you have the usual part that you hedge, that you dynamically trade the underlying up to the stopping time. And then once the stopping time arrives, you can sort of. Stopping time arrives, you can sort of apply a second set of strategies that depend on the time of stopping time, if you like. Of course, sort of in practice, we've seen that if you have an action-american option where the payoff is determined at tell the moment that it's stopped, there's no need to hedge once the stopping happens because the moment the stopping happens, you already super replicated correctly. You just pay off the payoff and then you just don't do anything after that. There's no need to do anything, but in this case, a Z. But in this case, Z is sort of allowed to be not just FT measurable. So ZT could be sort of anticipative, even. Okay, yeah, so we still have this G part lying around, which is, of course, the static European options that you're allowed to add in addition in your hedging strategy. And this hedge needs to be done once again, quasi-sure over the set of all possible measures and over the set of all stopping time. So there is an ordering issue here. Is an ordering issue here. So, depending on whether you put this for or tau inside or outside of the quasi-sure, you get a slightly different statement. So, this is the, I guess, the weaker statement. If you put the tau inside, then you actually have a much stronger requirement because you need to quasi-surely simultaneously hedge against all stopping times and simultaneously at all measures. Whereas when it's on the outside, I guess the null sets where the hedge fails can be different for different measures. Fails can be different for different measures. Okay, so but in terms of duality, this is the typical version that we look at. Once again, there's a sort of fairly obvious inequality between the two. The hedge is always greater than the worst case model price. But the question is, do we have equality? So as it turns out that no, you don't always have equality. And there is a duality gap in cases where the static option exists. So if this HG part exists, then it's possible that. Exist, then it's possible that you don't have duality. You can eliminate this duality gap by enlarging the underlying space to include the dynamic prices of these European options. So essentially, you look at these European options as additional set of part of your canonical space. And then suddenly you have something that's like a Europe, sorry, an American option without that part, but in the enlarged space. But the point is, there is some duality gap if you're. Is there some duality gap if you allow for a non-empty set of European options to go alongside this? But again, this is sort of fairly well studied, particularly in the discrete time framework. There are a bunch of lots of different results, including by authors from people in the audience. Also, there are some continuous time relevant results, in particular looking at maybe more general spaces with marginal constraints or in Markovian settings, or perhaps in sort of incomplete model setups, but not quite in the full. Setups, but not quite in the full sort of the non-dominated robust setup, which is what we're trying to address today. So, this, what we're going to present here in the following slides, are sort of ongoing work that we're sort of currently working on. Okay, so very quickly, so what is the main idea of solving such a problem? So, in Axemitz and Dun and Obloy and Tan's paper here, they sort of solve the problem in discrete time. And the key idea is to enlarge the underlying. is to enlarge the underlying space with the set of stopping decisions. So you enlarge the space to include information you obtain from the stopping time tau to get a larger space omega hat. And then in that larger space, the American option looks more like just look just like a European option, essentially, because now it's a function of, of course, omega as well as the stopping time tau, which is now sort of measurable within that space. And then, of course, we have European, if you have. If you have European duality, you can apply it to this enlarged space, and then you just have to bring it back to the original space and check that that part works. So, in particular, there is duality in the enlarged space. So, pi bar is equal to the supremum of the set of probability measures or Martingale measures in the enlarged space. So, this is essentially the European duality, except we're adding bars on top of everything because we're in the enlarge space. But there is an additional step where you have to on the Where you have to, on the worst-case model side, bring it back to the original space because it's not entirely obvious that measures under the enlarged space can sort of achieve the same supremum as stopping times in the original space. So in discrete time, this is proven using by essentially giving a construction of what tau is in a sort of using a dynamic programming argument. I won't talk too much about the case where the European portion exists. Where the European portion exists, but you can also do this. But as mentioned, somehow you have to enlarge in another way to include the static, sorry, the dynamic prices of G, but the arguments mostly the same. But the key part we want to focus here is this second inequality. So how do we go from p bar, sort of a measure on the enlarged space, to a member of a stopping time and a measure in the original space? So as mentioned in discrete times, this is actually done using induction. Times this is actually done using induction, backwards induction, constructed step by step. But somehow in continuous time, we don't have access to this induction. So, some new idea is needed. Okay, so as mentioned, we focus on the case where there is no G. And then usually pretty much every other step in continuous time can be argued in very similar ways to the discrete time. But the one big difference is that we no longer have access to the dynamic programming. Dynamic programming, the discrete time induction that we do to get this equality. So, the question is: how do we do this? Okay, so this is sort of the second half of the talk where we sort of talk about some new ideas to tackle this. So, first of all, we need to define what is this enlarged space in continuous time. Of course, omega is the original space, the space of continuous functions. We would like to enlarge it with a second space, theta. So, what is theta? So, perhaps easy ways to look at it. So, perhaps the easy ways to look at it is just to look at this picture somehow. So, this is a plot of theta's, the sample path of theta over time. So, it's very simple. Each sample path of theta just moves along the direction of the 45-degree line where it's equal to t up to a certain point, and then it branches off and stays horizontal. So, theta is going to represent essentially the stopping decision as they arrive. So, you can sort of see the diagonal portion of these paths. Diagonal portion of these paths as the sort of the path you travel along before the stopping time occurs, because you don't know when it's going to occur. You're just waiting for it to happen. But the moment it happens, you sort of switch to the horizontal portion of the path. So that's written now in this way. Curly theta just represents the individual elements of this space, which are each part. So, you know, diagonal plus a horizontal portion. And then you can also parameterize this simply with just a real value, right? Because A real value, right? Because this is just one-dimensional, really, in terms of complexity. You can just, you know, with one number, you can characterize exactly which path you're referring to. Now, the good thing about defining theta in this way is now when you combine it with omega, everything is still compatible with the semi-Martingale measures and all those earlier discussions because sort of this is fairly easy to manage. It's simply, you know, something with a drift of one. It's simply something with a drift of one up to a certain point, and then it just stays constant. So, this enlarged space in particular, we can still define semi-Marnegal measures and use the sort of optimal transport result that we had earlier. So, one of the important class measure that we require in this enlarged space is Q bar, which is the set of Martingale measures for X. So, just X. So, even though the canonical space here now has X as well as theta, we only require. We only require the Martingale measures to be in the sense that X is a Martingale. So, theta, of course, is not a Martingale because it's always increasing for a while before going constant. Okay. All right. So, we have the enlarged space. We also need to enlarge the stopped path space. Now, that becomes a little bit cumbersome to sort of follow, but roughly speaking, before when we introduced capital Lambda, it was the pairing t and omega stopped at time t. Omega stopped at time t. So it's very similar to that for the enlarged space omega bar. This is just a pairing t and omega bar stopped at time t. Of course, omega bar, you've got to keep in mind, has two parts. You have the theta and you have the original omega. So the actual elements of this lambda hat looks like this. It actually has three sort of parts. You have your t, you have your theta stopped at t, and your omega stopped at t. But theta stopped at t is, again, something just looks like one. Again, something just looks like one of these pictures, right? One of these paths in this picture. Okay, so as mentioned, everything is still compatible with the semi-mining optimal transport theory that we developed earlier on. So once again, you still have duality, except now everything you have to write with a third component. You have to sort of extend the C12 function to allow for this extra component. But this extra component is not particularly, yeah, not particularly difficult to handle because it's. Particularly difficult to handle because it looks like this. Again, you have a PVD. We have an extra spare term here that captures that portion of the theta that goes diagonal before going flat. But you can just think of it as the drift of theta, if you like. But everything else is pretty much as expected. So, in particular, just like before, this gives us European duality on the enlarged space. Okay. And the arguments pretty much exactly the same. So I won't go. Pretty much exactly the same, so I won't go through it again. But the crux of it is that we've enlarged the space, and then our European options, which are, by the way, options that depend on both omega as well as this new parameter theta, do have the duality that we saw earlier on. Okay, but what about American options? Because, like I said, the difficulty wasn't so much the European duality, but this connection between probability measures in the enlarged space and stopping times in the original. Space and stopping times in the original space. So, given a stopping time and a probability measure, we can combine it to create a measure in the enlarged space. So, all you do is you sort of look at the graph of this map, right, and sort of you concentrate.        Trash for me as well next door. Hello, yeah, I can hear you. You can hear me now. Yes. Okay, we can hear you. Sorry. Maybe I think it's something with the BAM sense or Wi-Fi, possibly. Why are it all of the Zoom clients? Yeah, I co-hosted a lot of people. Hopefully, one of the organizers should be hosting. But it should be good to like you should be able to finish it up. Finish it, but yeah, like people should be able to join the same meetings when we okay. I think we're back up. So, Ivan, could you go back a few slides? I think we missed around here, perhaps I think so. Maybe we'll have one more back or forward or I think we can probably see your post. No, no, we've definitely got that bit. So maybe forward either this one or the next one, I think. Okay. Yep. Okay. Thank you. Hopefully it's all working better now. So yeah, so in the enlarged space, essentially the key idea here is that the whole semi-martine goal optimal transport theory still works. So we can apply the same. Still works. So we can apply the same duality to get the European duality that we had earlier on. So this is the European robust pricing hedging duality. Of course, as now that's done on the enlarged space, pretty much everything works the same as before. So yeah, so this is the same as the original argument, except we have these extra terms lying about. But the key message is that we do have European duality on the enlarged space. Now, the main difficulty of what we're talking about today here is What we're talking about today here is not so much the European duality, but this equation off the top here. So, can we show that optimizing over the set of measures on the enlarged space is the same as optimizing over the set of measures on the original space stopped at the set of stopping times. So, for a given stopping time in a given P, you can certainly construct an element in the enlarged space or measure in the enlarged space so that it matches up in some sense. So, of course, the Some sense. So, of course, the expectation of Z stopping at tau is the same as taking expectations on the enlarge space. You just do this by looking at the graph of the stopping time and then sort of concentrate your measure on the graph. However, the converse is not even close to being true. In particular, here's an example where an element of the enlarged space, a measure of the enlarged space, does not go back to a stopping time. So here we have a two-state model. We have a two-state model where you have one measure that concentrates on one state that stops at time one, another one on the other state that stops at time zero. If you take the midpoint of the two, you get something that puts mass on both states, except one of them needs to stop at time zero. Whereas the other one's stopping at time one. So this is not a stopping time. This is anticipative. Not only is it not a stopping time, it's not even a randomized stopping time. So this is a sort of a true proper random time. Random time. So, in particular, we see that in this equation, somehow the left-hand side should have more than the right-hand side. The left-hand side should be potentially bigger. So, can we show that they are actually the same? Or are they actually the same? So, a quick follow-up to this picture or this configuration here is that even though in that situation we did get a random time, you can somehow recover a randomized stopping time if you only focus on. If you only focus on the functional at the point of stopping, so if you only think about adapted processes or non-anticipated functionals, you don't really care about what happened on the downward branch because you have already stopped that path earlier on. So you only care about the value of it at that junction, at that point, right? At the initial point. So you can replace it by a different measure where it only concentrates on the upper path. And suddenly, you have, once again, a probability. Suddenly, you have once again a probability measure and a randomized stopping time. So that's not so much a random time anymore. But, however, this only works if your functional that you test against is adapted, right? But there's some sort of hope there. And this is a little bit tricky. Okay, so going forward, I need a few quick new concepts. So given a random time row, there's an object called the SMS supermartingale, which essentially measures the amount. Which essentially measures the amount of mass remaining that has not been stopped. So, in particular, if R is the increasing process that corresponds to the random time, so in particular, you can see it as the distribution function of the stopping time, or sorry, the random time path by path. You take the optional projection of it, you get a super martingale. You can check easily that's a super martingale. This is known as the ESMA supermartingale. In the case where you actually have a stopping time, this Actually, we have a stopping time. This just looks like a process that starts at one and jumps to zero. So, this is sort of not very interesting. In the case of a randomized stopping time, you get something that decreases from one to zero, but again, it's actually decreasing. Whereas in general, if you just have a random time, you don't get something decreasing. Instead, you get a super martingale that starts at one and somehow trickles down to zero. So, given this super martingale, there is Given the supermartingale, there exists a multiplicative decomposition of the supermartingale. So, in particular, you can write it as a product of a local Martingale and a decreasing process. Okay, so we use one minus A here because we want the increasing process, the increasing version. But this is a multiplicative decomposition, and the decomposition is unique up to the point where all your stopping, where your random time finishes, so to speak. So, until that point, the stopping, the decomposition is unique. Afterwards, it's not because essentially y is zero. not because essentially y is zero so you have you know zero times something so the something could be anything and then of course very briefly uh if we do have an adapted increasing process that so you can treat that as a randomized stopping time so in particular a stopping time you can see it as as a process that sort of jumps from zero to one at the point of stopping a randomized stopping time is a process that increases from zero to one capturing sort of the fraction of stopping as you move forward so the Stopping as you move forward. So, the difficulty somehow is that for an arbitrary random time, the azimuth supermartingale is not just a monotonic function, whereas for random mystery time, it is a monotonic function. So, here is the first lemma, or I guess the lemma that sort of captures a little bit of that idea of transforming from random times to stopping times in some way. So, given a measure in the enlarged space, if we test it against an adapted Tested against an adapted functional, so a non-anticipated functional psi, so in particular psi only depends on omega up to theta, so it doesn't have you know future information. You can then rewrite it somehow as an integral of an increasing process dA. Okay, so this, but under a new measure, under a new expectation p, where p is somehow different to the original omega or even the marginal omega, I should say. So how does this work? It sort of combines that the few things that Uh, it sort of combines that the few things that we just mentioned. In particular, what we do is we extract the Azima supermartingale from this measure mu, because this measure mu, you can sort of break it down into a marginal over omega as well as a random time. But, or just more explicitly or more directly, you can just write down the, again, the distribution functions of mu for each omega and just take the optional projection. And then we apply the multiplicative decomposition to this supermartingale. To this supermartingale. So, to prove this, instead of checking against the set of all non-anticipative size, we only want to check against the set of indicator functions because that's sufficient. So, yeah, so very quickly, you can check that, you know, if you substitute in a non-anticipative function or indicator function, you can rewrite it as one minus r, because r is the raw process that captures path by path. Captures you know path by path how much is lost or how much is to go. You take the optional projection and then you replace it with a decomposition to extract the increasing process A. So essentially, we start with something that's a super Martingale or decreasing, so not decreasing, but something that's not monotonic. And we recover something is monotonic, where the caveat is that we have an extra Martingale term lying around, a local Martingale term. And then you can do a And then you can do a measure change to absorb that M into the expectation and to get this new expectation that's only in terms of the monotonic process A. So the good news here is that A, as mentioned, because it's a process that starts at zero and goes to one and it's an increasing process, it corresponds to the randomized stopping time. So in other words, a measure on the enlarged space can be somehow written as an evaluation against. A evaluation against randomized stopping time, but under some sort of a measure change. And then you can push this idea even further because this first half of the lemma, we restrict ourselves to the space of adapted functionals or non-anticipative functionals. If you actually have something that's on the full space that could be anticipative, it turns out that there's a similar thing you can do, but it's a little bit more complicated. So let's just have a quick look at what this statement says. So again, you have a measure on. At what this statement says. So, again, you have a measure on the enlarged space. If you test it against an arbitrary function, a bounded arbitrary function, eta, where in particular, within the integral, you see that is an expectation against some probability measure. So, this is the probability measure on omega. Yeah, so you rewrite this as an expectation here, except the expectation is only evaluated at stopping times. Okay, except you need an entire family. You need an entire family of such expectations. So, another way to interpret this is that any measure on the enlarged space can be somehow written as a convex combinations of expectations on the original space evaluated at stopping times. And this convex combination is done with weights that are Lebesgue. Okay, so R here is an index parametrizing the set of measures that forms that convex combination. So, this is a little bit. So, this is a little bit hard to sort of parse at first, and we'll see some examples that hopefully will explain a little bit better. But, roughly speaking, we get this decomposition by disintegrating mu according to the value of A. Okay, so A, remember, is the increasing process that we somehow extracted by doing a multiplicative decomposition on the SM and Martingale. It's something that goes from zero to one. So, if we disintegrate somehow mu against the value of this A, we get. Value of this A, we get sort of a whole spectrum of marginals against omega, and it turns out that you can set them to be stopping times. Part C is simply some sort of consistent conditions on these probability measures, but I guess the key result is part B here. Okay, so let me just show you some examples to maybe better illustrate what is actually happening. So here's an example of a model. So your path is your four states and you have a random time. So in particular, the black dots represent where the random Dots represent where the random time is concentrated on for each omega. As you can see, this is clearly not a stopping time or a randomized stopping time. So the A, if you calculate what it is, it's an increasing process that starts from zero to one. Of course, this is a discrete analog of it. So what actually happens is A have these little jumps at each node. So it starts at zero. And each time some sort of a black point occurs, A sort of makes a little jump. Occurs, A sort of makes a little jump. So, in particular, at the beginning, roughly speaking, a quarter of the mass is lost at the beginning. So, A jumps from zero to a quarter. But then it gets a little bit tricky because on the top node here, A actually goes from a quarter to five eighths because the mass loss here, you have to calculate as a relative portion of the total mass that's remaining on that branch. But anyway, so this is the A that you get from doing the decomposition for this particular case. And then, in terms of the disintegration, Case. And then, in terms of the disintegration, what actually happens is that once you know the value of A, you can kind of partition all the paths according to their A values. And then you track sort of the value of the stopping time for those A values. So here, in particular, you can sort of roughly speaking divide everything into three parts. You have the red, blue, and green. So red are those paths that the stopping happens at the beginning. Green is sort of happens at the top, sorry, at time one for the top path, but time. At time one for the top path, but time two for the bottom path, and blue always stops at the end. So, in particular, red, blue, and green are three probability measures associated with a true stopping time. And then the convex combination of them creates the measure that we had originally. So this was the original measure, and this is the disintegrated measure, sort of sorted into colors. And then you see that in each color, you have effectively a stopping time. Right. Right, so the question is: why make it so complicated? If we just want to disintegrate into stopping time, surely there are easier ways of doing this, and there are. You can simply perhaps just disintegrate over t, you know, just depending on the value of the random time and disintegrate according to when that happens. Then you always get a constant tau, so that's of course the stopping time, or even just disintegrate per omega. Why not just spread each omega to its own element? And then, of course, the random time. Of course, the random time takes a particular value on each path, and you have once again a stopping time. So, this whole idea of disintegrating or decomposing a measure on the enlarged space into measures and stopping times itself is not very surprising at all.              I think in theory you can, but it does create some difficulties. In particular, a lot of the argument used, like the Azima Supermartingale and the decompositions, they're very sort of one-dimensional, right? So, somehow, when you have several stopping time, you need to extend these concepts to include that extra. Concepts that include that extra stopping. Because suddenly it's not a simple matter of before and after stopping. You have sort of these different cases of option one being stopped, option two being stopped. So all these binary decisions between the stopping amongst the set of all American options. So in order to use this sort of argument, one would have to actually find the analog of the Ezema Supermartingale before a set of stopping times, which I think you can likely do. And then you have to find the analog. And then you have to find the analog of the decomposition theorem, and then to identify what is the disintegration for that. But I think it's likely to be true, but it's technically very challenging because it requires all these extensions of existing concepts. Okay, thank you. Any other comments or questions? Anyone on the road? Yeah, Tony? Yeah, Tony. Hi, Ivan. Thank you for the talk. So, thinking about the first displayed equation and the last, the third equality. So, can you say anything about info problem if infirmum is over models and supremum is over stopping times? Or is the equality reliable because you have double supremum? Right, right. So, so in sup, so there's two different kinds of questions you can ask in that case, depending on the order of in soup and soup inf. So, the easier one. So the easier one is follows directly because if the stopping time, so if it's inf over tau and soup over p, if the inf tau is on the outside, then you get duality without too much fuss because you can essentially choose your stopping time at first. And then all you have then is an European, the European case. So you do the European case, you get duality. You insert back the towel, but sort of on the outside. Now, the swap of the soup and the in. So if you want to put the And the in so if you want to put the tau on the inside, so that actually now has a different interpretation because the interpretation is now not so much you are the buyer and you're hedging, it's more so that you're you're the seller and you're somehow choosing the worst case model with respect to all possible stoppings. So you sort of somehow it's the adversarial aspect of that. So I think something like that is known in the discrete case in papers by In papers by Barakhta and Zhou Zhou. They've done some, like, they've done that duality where the harder one, where the inf tau is inside the soup, and they use some maximum inequality to show that you can actually swap and everything still works. But in the continuous time, I'm not sure. It's not something I've looked into. But it's known, some sort of result like that is known in the discrete time for the harder case. Okay, thank you. Okay, thank you. Perhaps, in the interest of time, we can move on. So, thank you, Ivan. And a couple of minutes while we get set up here.