Someone else and error. Virtually is it still just day one? Okay, we're very happy for the last talk here today. We have Mark Selkin, and he'll tell us about algorithms and script classes. Okay, great. So thanks to everyone for. Thanks to everyone for staying for the whole day. So, I'll tell you about algorithmic spin glass theory, and that'll be based on some John Works with these wonderful collaborators, one of whom is here. Okay, so I'll start by explaining what is a spin less. They may be a little bit exotic to some people, and there are a lot of kind of strange and very interesting behaviors. Interesting behaviors that they're predicted to have, and sometimes proof, sometimes not. So I'll try to focus kind of on these interesting qualitative behaviors that to me make the subject really fascinating. We'll be looking at optimization and sampling, so I'll then show you an optimization algorithm, and I'll say something about algorithmic hardness for optimization, and then we'll talk about sampling. Point. Okay. So I like to start off with a motivating example, and one of my favorite ones is tensor PCA. So in the tensor PCA problem, I'm going to fix a positive integer p. p should be at least 2. Really, p should be more than 2. 4 or something. And what I'm going to do is I'm going to try to recover a signal vector x0 on the sphere in. Zero on the sphere and n dimensions from some noisy observation. But I'm not going to observe kind of a linear observation. I'm going to observe a noisy version of the pth tensor power. So to be clear, in the matrix case, I would see a rank one matrix, which is volume by vector tensor squared, plus entry-wise Gaussian place. So somehow the tensor structure is making this kind of a nonlinear problem. And if you want to solve this problem, okay, what would you do? One of the first things you would try to do is write down the maximum likelihood estimator. And you would immediately get a non-convex random polynomial optimization problem. You try to find the point whose pth tensor power maximizes the kind of tensor inner product with the tensor t that you get to a curve. This is an NP hard problem. This is an NP-hard problem, unless you're in the matrix case when it's just an eigenvalue problem. And so, okay, we're looking at a random problem, so NP-hardness doesn't really tell us what's going on. But what that means is that it's unclear what we should expect to happen. Similarly, if you're thinking of trying to sample from some kind of posterior, you're going to sample from a similar kind of situation, instead of taking a maximum, take some kind of genus distribution. So I'm going to be interested in, at kind of a very broad level, the basic computational limits in random optimization and sampling problems. Okay, so what is the precise model we're going to be looking at? It's going to be very similar to tensor PCA. Essentially, it's going to be the null model for tensor PCA. And it's what's called a mean field spin plus. Fields with less. So these models are going to be defined by random low-degree polynomials and many variables. So these polynomials I'll call NHN, that's my Hamiltonian. And my Hamiltonian is going to have random coefficients. So an example would be a random cubic polynomial. So here sigma is a point in Rn, maybe on the sphere on the cube. So a cubic polynomial in n variables has about n cubed. Variables has about n cubed terms, and I'm going to make all of the coefficients IID Gaussian. And you can see that this is the same as generating a Gaussian 3 tensor, so it's the same as what we saw before, except that there's no C. This 1 over n normalization is not so important. It's just going to make sure that the maximum value is of order n. So roughly every dimension contributes order. Sort of. Okay. I'm going to want a slightly broader sandbox to play in, so I'm going to also sometimes mix different degrees together. So how I'm going to do this is I'm going to have some general sequence of constants, and I'll just add these different types of Hamiltonians together. I'll just take independent random polynomials of different degrees. So this is my class of. So, this is my class of models. It's the mixed p-spin model. And one nice compact description is that it's a Gaussian process on Rn with a rotationally invariant covariance. So the covariance between two values is basically given by some one-dimensional function applied to this overlap, this scaled inner product between the two inputs to HN. This one-dimensional function psi is called the mixture function. Called the mixture function sometimes. It should be thought of as constant as n goes to infinity. It kind of parametrizes the model. It's just a generating polynomial for these coefficients gamma. So a random cubic, it's going to be just cubed. In the case of a pure monomial model, like this random cubic, we'll say it's pure and it'll be a pure physical model. Okay, so this is our model. I hope that was clear, but any questions before I go? Okay, great. Okay, great. So we're going to have a couple of algorithmic goals for this model. The first one is optimization. So I'm going to give you this Hamiltonian. I'll generate all my Gaussians for you. And what I'd like you to do is give me an efficient algorithm to optimize. Let's say to give an output that gets the optimal value of this function on the sphere up to some R. On the sphere, up to some arbitrarily good approximation factor, 0.91. You may be wondering: okay, what is the maximum value? That's a deep question. The answer is predicted by Prezi, proved by Talagron and others. I won't say so much about it in this talk. We'll kind of take an algorithms first only today. But, okay, if we can't reach. But, okay, if we can't reach this threshold, we might also just wonder what's the best we can do. The other natural question is sampling. When can you sample from a Gibbs measure? For what kind of inverse temperatures should you be able to do this? As I mentioned, these are kind of NP-hard problems. There are going to be exponentially many local optima. So you could certainly try standard methods like Langevin dynamics. They're very reasonable, but there's They're very reasonable, but there's no clear reason you should expect them to be optimal. It's not like kind of convex. So the spin loss models I'll be focusing on are of kind of particular form, but there are a lot of related models that are also glassy and have pretty similar behavior. So let me describe a few of these. The first one is random constraint satisfaction. Random constraint satisfaction problems or max constraint satisfaction problems on sparse random graphs. So max cutter, max bisection on a sparse graph, max caseat. So for these kinds of problems, if you think about the kind of large clause density or large edge density limit, but the edge density is kind of growing slowly with that, then you'll get something that behaves like a spin bus. Less. So if you take a Ariad of Schneider random graph with average degree of lambda that grows slowly with n, and you ask for the min-bisection value, it's known that this is, okay, to first order, it's n lambda over 4, that's half the number of edges, that's kind of trivial. The next order term is the ground state of the sharing tank for Patrick Spinglass, a random quadratic function on verge. Okay, so that's one connection. There are various other models that are kind of in the same sandbox. That are kind of in the same sandbox. One is the random perceptron. The positive temperature version, you can just think the Hamiltonian is a sum of one-dimensional functions. Geometrically, this is some intersection of different half-spaces or slabs. It's the null model of tensor PCA, as we've seen, and it's related to some other problems like the Hofffield model and certain kind of Bayesian inference problems. As I mentioned, the Charrington-Kirkpatrick or SK model. Trangton-Kirkpatrick or SK model is a random quadratic on the cube. Here, so this is kind of the first mean field spin loss model. It was really developed to understand real physical materials. So the idea here is that each of your n dimensions is the state or spin of an atom. So you have n atoms. The atoms are interacting in a random way. Really, maybe they're interacting in a complicated way. Maybe they're interacting in a complicated way, but it's treated as random. Random is cleaner to think about. And you end up with this kind of model. These models are all mean field because we've thrown away any of the kind of lattice structure of three-dimensional space. So you can also look at spin glasses on lattices. It's very different. Animal and it's generally a lot harder. Okay. Great. So let me compare this. So let me compare this model to a couple of things that may be more familiar. The first one is the ferromagnetic music model. I think this is a pretty familiar model. So it's the same kind of thing as the SK model, except all my edge couplings are positive. They're just one, let's say. And that means that my Gibbs measure is basically pushing me to have some global order or alignment in my space. So to oversimplify, So to oversimplify, the main fight in this model is between energy and entry. And if you think of kind of the zero temperature model, you basically get some trivial configurations of all plus or all minus. In a spin glass, because the couplings have random signs, you get frustration. Can't satisfy every single edge, kind of, you can't get the sign right on every edge. And so even for p equals. And so even for p equals two, if you look at this low temperature limit that was trivial in the ferromagnetic case, you get some kind of max count problem. Is this clear? There's another class of problems that has kind of a similar flavor that are about signal recovery. So I want to say a little bit about this contrast because there's often kind of a qualitative difference. So one is Qualitative difference. So one is tensor PCA, as I've mentioned. Another canonical one is planted clique. So you see a greater shiny random graph with a hidden clique and you'd like to find it. There's another nice problem that was mentioned in one of the lightning talks on matching correlated random graphs. So in all of these models, there's some hidden signal. There's a hidden direction in tensor PCA, there's a hidden clique, and there's kind of a hidden permutation involved in the last model. The last problem. The problems I'm going to be focusing on today, the models I'll really focus on and the other ones I've kind of mentioned, are generally going to be pure noise models. So you can take them to be null models for the first type of problem. There's kind of analogous null models for the latitude. So these, really you have to approach them a bit differently. There's no notion of sample complexity, there's no way to think of hypothesis testing. Think of hypothesis testing as kind of a simplified version of signal recovery. And there's no way to kind of think of your progress as being aligned with any particular signal you're trying to recover. You could make progress going in all kinds of directions within your skill space. Yeah, maybe I'll just say that at a high level, you can think that there are some relations here. So, first off, if you understand the null model, then that helps you hypothesis testing. Helps you hypothesis test or the signal recovery model. You can also imagine that if you're in a regime where you are not able to solve tensor PCA and you want to understand what your algorithm actually behaves like, might as well just study the null model. But they are kind of genuinely different problems. Okay, so that was some comparisons with other types of situations. Let me now say a bit about. Let me now say a bit about the different possible behaviors in spin glasses and kind of other glassy disordered systems. So, just focusing on the spherical pure P-spin model for now, there are already a lot of different phase transitions that are predicted. So, if I start off at beta equals zero, so infinite temperature, I have uniform distribution on the sphere, this is a very simple probability measure. It's going to have all kinds of nice isothermometry. It's going to have all kinds of nice isothermetry and everything. And that will persist up to some threshold, which I'm calling beta d plus. And what is expected is that afterwards there's a phase where you have fast mixing, but from a random start, not from a worst case start. So there will be some rare bottlenecks that cause the spectral gap to technically be very bad, but still you should be able to basically sample because if you start at a typical point, you wouldn't run into this. At a typical point, you wouldn't run into this issue. Then you hit the dynamical threshold where there's a shattered phase. What should happen in the shattered phase is that the Gibbs measure lives on an exponentially large number of very small clusters. So the cartoon would be here and I see here my Gibbs measure is kind of supported on these little clumps. And this will And this will cause slow mixing in a stronger sense. So you really shouldn't be able to sample it here. Finally, you'll hit the critical temperature. You'll have replica symmetry breaking. This is when you start to see something in the free energy. So these first few, I'm describing them as phase transitions, but if you just define phase transitions in terms of free energies, then they aren't really phase transitions. So maybe for this slide, when I say phase transition, I just mean qualitative. When I say phase transition, I just mean qualitative change. Right, so above the critical beta, you'll start seeing kind of macroscopically large clusters instead of a bunch of small ones. I've taken a picture here from a very famous, prominent paper on this topic that illustrates this in the related context of constraint satisfaction problems that have the same type of prediction for things like random case set. Prediction for things like random case set. So here you just look at the uniform distribution on solutions as your analog of the Gibbs measure. So at the start you have something well connected, then you have one large maybe connected component, a bunch of smaller ones, and so on. Here you have one final transition where you just run out of solutions and so on. Okay, so this is kind of the predicted picture. There's a lot of rigorous work establishing all kinds of parts of this. All kinds of parts of this picture. Some also on just understanding dynamics kind of in its own right. There are a lot of interesting conjectures that are touching on even very different aspects of the model, kind of the model for out-of-equilibrium behavior. So this is just to say that this is kind of the scope of the richness of what we expect to be finding when we think. What we expect to be finding when we think about problems in this part of the world. Any questions about this diagram or other things? For like the SK case, are all the different betas supposed to be different? Right, so in the SK case, there's no shattering for sure. Yeah. So, right, so I said spherical P-spin because this is a precise case where they all appear, but you might not always have all of them. Can I ask what was somehow into all there was the shadowing was called in some other name? I think it's also maybe called clustering sometimes. Yeah. And sometimes condensation is another word here. I do it for a star solution. I mean, there have been some different communities who have worked on this. Yeah, I think maybe that maybe the paper I took the picture from calls it cluster Okay, great. So okay, this is all very nice. What does it have to do with algorithms? So that's what I'll try to say something about for the rest of the talk. For sampling, there's been a lot of recent progress using a variety of techniques. Using a variety of techniques. You've heard about some of it. It seems that this prediction I described is basically correct. The dynamical transition does appear to be the fundamental barrier. It's not known sharply on either side, but everything seems consistent with this. For optimization, the answer is a bit more surprising, I would say. So we have a pretty good understanding. We have a pretty good understanding of it, and I'll describe this first. And basically, if you want to understand kind of an optimal optimization algorithm for this type of problem, what you end up finding is a geometric phase transition in the level sets of your objective function really characterizes what's possible and what's not. And in some sense, this threshold cannot be sharply understood from the Gibbs measures. So it's very related to Gibbs measures and Related to Gibbs measures and properties of them, but you can't really describe it in terms of a simple natural property of the equilibrium statistical physics. Okay. So let's look at some actual results here. So, okay, so I want to explain to you the optimization algorithm that turns out to be very good for That turns out to be very good for a spherical spin loss. But I need to motivate it a little bit. So I'll say a little bit about the geometry of the statics. So this should be taken as kind of surprising facts that motivate an algorithm. So you might recall that there's this notion of an ultrametric space. It's a metric space that satisfies this stronger ultrametric triangle inequality. Ultrametric triangle inequality. And it's more or less equivalent to graph distances on the leaves of a rooted tree. So I have this rooted tree here. For every two leaves, I have a combinatorial graph distance between them. If I put positive weights on my edges, I'll get some other weighted graph distance between them. There's a unique path, you know, shortest path between every two vertices, so it's very simple to define. And it's easy to see. And it's easy to see, it'll satisfy this ultrametric triangle inequality. Okay, so these are really equivalent. I mean, it's a bit of a strange type of class of metric spaces. If you've never seen it, all triangles are isosceles, this kind of thing. It turns out that spin glasses are basically ultrametric. So there's a sense in which the Gibbs measure of kind of any mean field spin glass is going to be approximately ultrametric. Metric. I'm going to cheat a tiny bit here, but basically, what this means is that if I take a constant number of Gibbs samples, let's say I take 10 independent Gibbs samples, and I look at the 10-point metric space they form in Rn, just using Euclidean distance in Rn, then they're going to be ultrametric. So all triples will satisfy this ultrametric triangle. And basically, this means that they're forming the leaves of a big tree. So as you kind of take more and more Gibbs samples, you'll kind of take more and more branches of some big tree like this. How does this interact with the notions I described before? So, replica symmetry, the high temperature behavior, means that these distances or these overlaps are approximately. Or these overlaps are approximately constant. And that means the ultrametric structure is kind of trivial. On the other hand, you may have heard of like one RSP or k-step RSP. That's when your ultrametric structure has k levels of clustering. So one step RSP would mean there are two possible values for the overlap. So you have kind of a depth three tree, depending on how you count it. So I'm just stating this as kind of a fact for now. But kind of what happens with the spin glass model is that the Gibbs measure is supported on the leaves of some ultrametric tree, at least in this sense I'm saying here. And what are these internal nodes? They're kind of cluster centers. So this internal node, if these three points are kind of Gibbs samples in Rn, then maybe this internal node is their average. The central node is their average, so it's a point within the sphere or within the cube. And then I have these three different cluster centers, so I think kind of a second-order cluster center. And you get this kind of tree structure that has to be valid and a lot of general. Okay. Why am I telling you about this? Well, this behavior actually gives a very nice template for a potential algorithm. Template for a potential algorithm. So it's a very different template from something like gradient descent or Langevin dynamics. Instead, the template says, well, I kind of know that the low temperature Gibbs measures are going to basically correspond to near optima of my objective. And I know that they're arranged in some ultrametric tree. So let me just try to find any leaf of this low-temperature Gibbs. This low-temperature Gibbs measure tree. And in order to do this, let me just start at the root of the tree, which is going to be the origin in n-dimensional space, and go down the tree one step at a time. Now, I'm drawing this tree as if you can see it somewhere. You can't see it anywhere. It's kind of defined implicitly by this theorem. So it's not clear that this is an algorithm you can implement in any sense, but it's something you could hope to try to do. To try to do that. Any questions about this? Okay, great. If you got a little bit lost with this, this is a good time to come back in because we'll now look at a very nice and elementary optimization algorithm for spherical sphere glasses, which is something that Subag came up with. I'm motivating after the fact. Motivating after the fact using this story. So here's a way you can try to optimize a spin glass function on the sphere. You're going to start at the origin, and you're repeatedly going to take these small orthogonal steps from the inside to the outside. So at each step, you'll consider the Hessian of the Hamiltonian on the orthogonal subspace to your current position. To your current position. So you'll just, you won't look in the radial direction, but otherwise you'll look at the Hessian and you'll take the top eigenvector. And then you'll just take a step in this top eigenvector direction, maybe with a random sign if you want, and you'll move in direction, you'll move by a distance that's a small constant times square root m. We're thinking of optimizing over a sphere of square root m. So you take a large constant number of steps of this form and you Of steps of this form, and you reach the outside. Okay, you'll note that because you're taking orthogonal steps, your squared radius increases kind of at a constant rate, deterministically. So you definitely can decide to exactly reach the outside of this form. Okay, now how can you analyze this? Well, it turns out that because we're working with a Gaussian process, these Hessians have a pretty simple description. So if you're at a deterministic point on the So, if you're at a deterministic point on the sphere, or at radius square root qn, then the Hessian of my Hamiltonian is going to be some Gaussian process over symmetric matrices. And it turns out to be just a simple Gaussian orthogonal ensemble scaled by some deterministic factor. So, this psi, remember, was the generating polynomial for my model. It describes the covariance. So, for example, psi of q is q to the p for a kind of pure piece of the time. For a kind of pure space. Okay, now we know that the top eigenvalue of a Gaussian module ensemble matrix is 2, basically. So the top eigenvalue of this Hessian should be 2 times the scaling factor. And if you just add up what you get, every step, the top eigenvalue tells you how much your Hamiltonian increases. So you integrate and you get this nice formula for the value achieved by this algorithm. The value achieved by this algorithm. So there's some key detail here. This Hessian is not really Gaussian-orthogonal ensemble because the points along the way depend on the Gaussian randomness. So there's some chicken and egg issue. You have to get some kind of a uniform lower bound on the type eigenvalue. It's not so difficult, but I won't say too much about it. Is this clear, other ways? Great. Great. So, how good is this algorithm? Is it any good? Well, in the pure case, it doesn't look like it's very good. So, it'll get you a value of about 2, whereas the true optimal value is about square root. You can easily see this constant by just some kind of chaining if you want to. However, it turns out that this algorithm is asking. This algorithm is asymptotically perfect in some cases for some mixture functions. So it'll get you all the way to the true maximum value asymptotically, if and only if. So first off, there's a condition on psi, it's a bit opaque. Second derivative to the minus one half is concave. You should think it kind of means you're close to the quadratic cases. Quadratic function on the sphere definitely going to be easy to optimize. Easy to optimize. It turns out it's kind of the statement is robust to small perturbations. But the more interesting equivalent condition is that the Gibbs measures at low temperature are full replicas of which you're breaking. So this basically means that the ultrametric Gibbs tree is continuously branching. So for example, pairs of Gibbs samples have a decent chance to have any possible non-negative correlation. Negative correlation. The intuition here is that if you're full RSP, then you kind of have this densely branching ultrametric tree describing your Gibbs measures, and you should be able to take small steps down some path in the tree and kind of stay within the tree the whole time. And once you're taking small local steps, you might think you can just tailor expand your Hamiltonian in some way to understand locally what's going on. Hamiltonian in some way to understand locally what's going on. On the other hand, if you don't have a full RSV, that means that your ultrametric Gibbs measure tree is going to have large jumps between the cluster centers that it kind of is able to see. And so your algorithm maybe will also need to take corresponding large non-local jumps that you wouldn't be able to understand in a simple way just by doing some kind of Taylor flux machine. Okay, so that's some justification for why this algorithm makes sense and why full replica symmetry breaking is kind of a natural condition that corresponds to this type of the algorithm making sense. Let me now say something about barriers for stable algorithms. So we'll be going in a different direction and we'll try to meet in the middle. So we have an algorithm and achieves some value. I'm calling this value alg. This value L. I'd like to say that it's a fundamental threshold for general algorithms in some sense. And ideally, it should have a qualitative characterization that lets me make predictions for other models without having to kind of work extremely hard and make lots of confusing onslaughts and guesses to solve a different model. So, the first results on this were by Gemardak, Jagannath, and Wayne. And what they showed was And what they showed was that a class of stable algorithms, so with stable dependence on the Gaussian coefficients, is not able to reach the asymptotic optimal value unless Subad's algorithm already succeeds. I won't define stable algorithms. We'll kind of go through a cartoon proof that will illustrate what you want them to behave like. But they encompass a lot of your favorite algorithms, greed inflow, logical dynamics, a box of message. Flow logic dynamics, approximate message passing, some slightly more exotic things. So, the interpretation of this result to me is that full RSP is kind of an algorithmically fundamental condition. So, this intuition I was talking about is kind of valid. If you don't have full RSP, then algorithms really are unable to solve this problem. At least stable algorithms. So, there's, I know of no reason to believe that. I know of no reason to believe that there exist better algorithms that are not stable, that are polynomial time, but I'm going to treat this as kind of an onslaughts that proving stable algorithms fail is kind of a reasonable benchmark. Once you're happy working with stable algorithms, which again encompass a lot of very natural ones, you can start to reason geometrically and topologically. And indeed, this result was proved using the overlap gap property, which has been That property, which has been used and developed by Gemardik and collaborators for about 10 years. Let me show you a cartoon of how you would prove something using the overlap count property. So the idea here is going to be to consider not just a single case of my problem, but a whole infinite family of cases of my problem. So I'm going to generate two independent Hamiltonians, Hn0 and Hn1. These are Gaussian processes. These are Gaussian processes, they're centered Gaussian processes. So I can interpolate between them in this kind of usual Gaussian way and get a whole path of Hamiltonians, and they'll all have the same distribution if I just look at a symbol. And the point of a stable algorithm is essentially that you can plug your algorithm into, or you can plug your path of Hamiltonians into your algorithm, and you'll get a solution path. And the solution path will be somehow continuous in t. So you want So you want this to hold in some dimension-free sense. So your definition of stable needs to allow you to argue the variable. Basically, this is what stable is going to mean for this slide. Okay, so you get this path of solutions out at the other end. You apply your algorithm. And an overlap gap property, or OGP, is going to be kind of a strong statement about the landscape of your Hamiltonian. It's going to say that there exists. It's going to say that there exists some intermediate distance QOGP so that once your solution path reaches distance QOGP from where it started, you get some kind of contradiction. What do you need to get a contradiction? What you want to say is something like, consider any t along this path, from 0 to 1, any pair of points on the sphere, let's say, with distance qOGP. With distance qogp from each other. And I'm allowing sigma t to plug into the tth Hamiltonian and sigma 0 to plug into 0th Hamiltonian. Even then, and with t being kind of arbitrary, one of these points has to be suboptimal. So I can't have a path of optimal points that escapes this radius, and so I must get a contradiction. I must get a contradiction for my stable algorithm to be a good device. Okay, so this is some landscape property that's kind of built to support proof by contradiction using this concept. Okay, so that's the basic idea of the overlap gap property. It's been successfully applied in a lot of cases. So what I just described was kind of a two-point OGP. In general, you can define In general, you can define kind of potentially more complicated forbidden constellation of solutions. What you need to be able to do is show that it doesn't exist in the landscape. But if you had a stable algorithm, you would be able to construct it. So one success story is the max independent set problem on a random sparse regular graph. It's now known that local algorithms are suboptimal by a factor of about 2. Factor of about 2. D grows slowly with n. So here, Gemarnik and Sudan gave a suboptimal bound using a 2-OGP. And then Rockman and Virag used this multi-OGP to get a sharp bound. And then Alex Wine used a ladder OGP. So this slide is slit up a bit strangely. But Alex Wine used a ladder OGP to extend it to a broader class of low-degree polymorphs. And there's a similar story for random KSAT using ladder OGP. KSAT using Ladder OGP Bryce and Guide Wrestler can now show that algorithmic threshold for solving a random case set is this value. So it's off from the satisfiability threshold by about log k over k, and there's a factor of about 5 separating the upper and lower bounds. Okay, so this is just to say that OGP is kind of a broadly applicable tool for this type of. In these cases, because you're on a sparse graph, a good notion of algorithm is a local algorithm where you just kind of do local computations, something like a factor of ID. So the main hardness result I want to present is joint with Rice. And what we showed is that a class of Lipschitz algorithms is unable to do better than Suban's algorithms. Unable to do better than Subank's algorithm. When I say an algorithm is Lipschitz, I'm just thinking of it as a function of these Gaussian coefficients here. And I'm just saying it's a Lipschitz function from n to the p-dimensional Euclidean space to n dimensions. And I want the Lipschitz constant to be independent of n. So this includes most of the algorithms I described before, although it's a bit more restrictive. So this says that Subhag's algorithm is really the best you can do, at least. You can do at least if you believe that kind of algorithms of this flavor are as powerful as you can. So to prove this, we introduced a branching version of the OGP. And we actually showed it was necessary to use this version and not previous versions. So here are some cartoons of the other three OGPs I described. A multi-OGP is like a two-OGP, but you have maybe five solutions at medium distance. Five solutions at medium distance from each other. For a latter, you kind of apply the intermediate value theorem iteratively. For a branching overlap gap property, we ended up using kind of an arbitrarily complex ultrametric configuration. So we're really looking at solution clusters that are the set of leaves of a continuously branching tree. So this is kind of unifying the overlap gap property with the full RS. Property with the full RSP kind of predictions, essentially. Now, I mentioned before that to use an overlap gap argument, you need to be able to build this type of geometric constellation using your algorithm. So the first step of the proof should be that if I had a stable algorithm or a Lipschitz algorithm to optimize my objective, then I would be able to use it to construct a constellation of solutions of this type. Of this type. So, for Subogen's hash and ascent algorithm, which is about literally relations, our result also still basically applies because you can use hash and ascent to build a tree of outputs using the top two eigenvectors that it is. So, just maybe it's clear, but you start from the center. Every time you take two different steps using the top two eigenvalue, Steps, using the top two eigenvectors, you'll get a big branching tree. Every leaf of this tree will be essentially equally good. The proof sketch I outlined will still apply. So this is what I'm calling kind of a full branching tree of solutions. So, okay. So, maybe it makes sense that Suvon's algorithm can construct such a tree. It turns out that. A tree. It turns out that if you have any Lipschitz algorithm, you can construct a tree like this. And the idea is basically to start with a tree of correlated Hamiltonians. So I'll have some constants, p0, p1, and p2, and I'll take a tree of Hamiltonians so that each one of these is individually a Gaussian XP spin model, and the correlation between any pair of them is given by their distance in this tree. Distance in this tree. So if I have anyone on the left half and anyone else on the right half, then the label of their common ancestor is P0. And so the entries will be kind of entry-wise correlated by P0. And the point is that when your algorithm is Lipschitz, just by concentration of measure, the overlap, the normalized inner product between the outputs you get, between, say, this. The outputs you get, between say this sigma 1, 1 and sigma 2, 2, will also be a Lipschitz function of the Gaussian disorder. So it will concentrate around some value that just depends on p0 and the algorithm. So the algorithm will have some function that says, you know, if it takes into p-correlated inputs, how correlated are the outputs, you'll have concentration, so this function will essentially be deterministic. Essentially, be deterministic. I mean, I'm just taking, yeah. So you basically get a kind of deterministic transformation of these correlations from the left to the right using concentration measurement. So here I have kind of sibling pairs. They have some different correlation. So they'll have some different correlation on the output side as well. And what you get when you do this argument is you get kind of a fully general ultrametric tree of Ultrametric tree of algorithmic outputs on the right-hand side. And this lets you use a branching overlap gap property argument. And then what you end up wanting to show, which I won't say much about, is that the average energy value, the average objective value of any continuously branching tree of solutions like this is not going to be any better than algorithmic threshold. Any better than algorithmic threshold works for. That's kind of a separate step, but I hope I've explained at least how the geometric structure kind of arises from a Lipschitz algorithm. Which mixture functions does this apply to? Like, do you have to have a second condition that it's close to Lipschitz? No, this is fully different. So, those equivalent conditions tell you whether or not the algorithmic threshold you get in this way actually agrees. Rhythmic threshold you get in this way actually agrees with the true maximum value. But yeah, like the pre-Z formula type of theory doesn't really enter anywhere in this argument. It's just fully general. Any other questions? Yeah, sure. Is this like questions for the end of the talk or for the slide? Um e either one. Are we at the end of the talk? Oh, we're not we're not at the end. I just thought something was questionation. Sorry, I think maybe I missed something, but can you just explain the tree of normal points? Yeah, sorry. So what's happening here is like, so, okay, so I have my Hamiltonian is described by a p tensor. So they're n to the p entries. Let's just look at one of those n to the p entries. So it's going to take four different values on those four Hamiltonians. To take four different values on these four Hamiltonians, I'm going to generate those four values by doing kind of a Gaussian random walk down the tree. So I'll generate a Gaussian here, then I'll add a Gaussian increment here, a Gaussian increment here, independent Gaussian increments over every edge. I'll do that entry by entry independently, and what I end up with is four Gaussian Hamiltonians so that any pair has some correlation entry by entry. And the point is that by concentration of measure, if I have two Hamiltonians with some given entry-wise correlation, the correlation between the outputs of any Lipschitz algorithm has to concentrate around some kind of deterministic value. Kind of push forward the ultrametric structure. Okay, great. So let me just So let me just do a little epilogue for this part and then describe the state of the art for sampling. So this kind of qualitative picture that you get a sharp threshold for Lipschitz or other classes of stable algorithms using the branching overlap gap property and using algorithms of this same flavor as Subog's algorithm with small orthogonal steps. Steps. It extends to a lot of the related problems I mentioned. So, first off, we were discussing the sphere. That's basically because on the sphere, Subag's algorithm is nice and simple because of the symmetric geometry. You get the same basic behavior on the cube, you just end up with much more complicated formulas, more like stochastic controller or some crazy P. You can do the same kinds of things on Spartan. Kinds of things on sparse CSPs, at least in the high constant degree limit. As I mentioned, there is this connection on the level of free energy or maximum values. You can make that algorithmic as well. There's also a nice paper by three different people, so this is a different one, on online matching of IID Ernest-Randy graphs. So this is the null model for matching correlated random graphs. They were able to give a sharp threshold for online matching. To give a sharp threshold for online matching using the branching with a lab gap property. I'll mention a couple more involved cases that I'm very happy about because they are cases where we can find the algorithmic threshold even though the true statics, like the pre-Z formula for the ground state, are completely open. So that's to say this picture ends up being pretty robust. The first one is multi-species. The first one is multi-species spin masses. It looks like a very benign generalization. I have something like a product of spheres as my state space. So, sigma is on one sphere, rho is on the other sphere. I have kind of full symmetry in distribution of my Hamiltonian within the species. But you can see here, this second type of term is linear in sigma and cubic and yellow in rho. So, for these types of models, a Hessian ascent is again optimal. You just have to kind of decide how. Have to kind of decide how fast to explore in each of the different spheres. So there's some kind of function to tune, but otherwise it's the same type of sort. Another result, which Bryce will talk about on Friday and which is still being wrapped up, is a sharp algorithmic threshold for the random perceptron. This is pretty involved because we basically had to build a stochastic control theory within the branching overlap gap property. Overlap gap property. But basically, it gives a complete description for Lipschitz algorithms for the random perceptron in terms of stochastic control. And we're very happy about it. It confirms a kind of experimental finding by some physicists, which says that in this kind of random perceptron model, most solutions will be isolated, but algorithms can find very dense clusters. Can find very dense clusters. So our result kind of says that you can interpret very dense clusters to mean these continuously branching ultrametric configurations. And this is one reason that algorithmic thresholds are very different from statics. If you're looking at statics, most solutions are isolated for a lot of regimes of this model, so you shouldn't be able to find solutions. You might naively think. Solutions, you might not easily think, but as long as they're rare dense clusters of the appropriate form, you can find them using algorithms. Okay, let me switch gears and say a bit about sampling for the last few minutes. Okay, so maybe the first question you might be wondering about sampling is: well, sometimes you can optimize, you can find the ground state value. So, shouldn't you also be able to sample at low temperature then? Sample at low temperature, then? The answer is no, so that's kind of unfortunate. It turns out that in any situation where you have replica symmetry breaking, so rather low temperature, it's impossible to sample at least with a stable outer limit, probably more generally. I'll just quickly explain how this works. So, we again have this path of Hamiltonians, all that mu t beta v the corresponding Gibbs measure. So, there's a So there's an important theorem of Chatterjee called disorder pios, which says that if I have any spin glass at any temperature, and I perturb the disorder by a positive dimension-free amount, and I take independent samples, one from the original Gibbs measure, one from the slightly perturbed one, then these Gibbs samples will have overlap tending to zero, so they'll be kind of approximately or fine. The whole point essentially of replication. The whole point essentially of replica symmetry breaking is that this does not hold when you take two independent samples from the same Gibbs measure. So, just by combining these, what you see is that the Gibbs measure is kind of not stable in some sense to small perturbations. This lets you show that similar types of stable sampling algorithms cannot possibly succeed, even in a very good sense. What about at high temperature? So, at sufficiently High temperature. So, at sufficiently high temperature, we know a lot. So, June was telling us about this just a little while ago. We have kind of optimal mixing for Langevin and Glabberdynnics. For Langevin dynamics, at very high temperature, there's a, Lakosh observed that the curvature of the sphere is enough to overcome the effect of the Hamiltonian. For Global dynamics, it's pretty hard. All these results are using some very Using some very creative ideas. If you use kind of off-the-shelf, very naive methods, you won't get anything dimension-free for your reverse temperature. As I understand it, one reasonable statement of the state of the art for this line of work is that collaborative dynamics has a constant spectral gap. Whenever the maximum operator norm of the Hessian times. Of the Hessian times beta is smaller than a small constant. This is kind of remarkable, I think. It's basically the same condition you end up with for the sphere. And this is much more robust, so you could have kind of a pseudo-random Hamiltonian, and this stuff would still apply. There are some results that worked harder and made things work on sparse graphs with unbounded degree. On the other hand, these methods are not going to give the sharp. Going to give the sharp conjectural thresholds I mentioned earlier because they are based on spectral gaps and you expect fast mixing from a random start to work beyond the regime where you have a good spectral gap. Okay. Are there any other methods? There is another nice method you can use based on diffusions. So it's not a Markov chain. What you do is you What you do is you think of first trying to generate an n-dimensional path, which is given by a Brownian motion with drift x star, where x star is a Gibbs sample. So if you could generate such a path, then after a long time, you would just basically read off the Gibbs sample approximately. And it turns out you can generate a sample of this law on paths. So you can generate or simulate yt without first. YT without first deciding what X starts. This is called filtering theory. It's related to the image generation AIs. All kinds of different interpretations of this method. But basically, it reduces sampling in some approximate sense to iterative mean estimation. In order to simulate this ladder estimate, you just have to keep getting the posterior mean of the The posterior mean of the Gibbs sample, you don't know. So, for the SK model, we were able to implement this with Ahmed and Andrea. Later, Michael Salatano showed that our method worked in the entire high-temperature regime. So, here there's no shattering for the SK model, which comes up. Very recently, Grace, together with Andrea and Lufm, showed that you have a version of this on the sphere that, with a lot of very hard work, gets. Full out of very hard work gets small total variation error up to some threshold. This is not kind of the full regime where sampling is supposed to work, but this suboptimality is kind of, it seems to be inherent to this diffusion method. So diffusions are maybe better for proving things currently than Langevin or dynamics, but they're expected to not actually be as good. There have been There have been various other uses of this method, sampling. Nima and June and friends had a nice work on parallel sampling of some spanning trees and similar distributions. So this is also a versatile method. Let me just say a little bit about this intermediate phase of shattering that I mentioned and drew this little cartoon for earlier. So when you have a shattered phase, Shattered phase, it should look like the following. So I'm writing beta dynamical here. Not enough is known about the shattered phase for me to really give a mathematical definition to it. So let me just say there's some physics prediction, which gives you a formula for it, and it's predicted that certain phenomena occur. So it's just some number for now. But there's often a phase where you expect shatter, and this should obstruct sampling. Sampling, certainly enjoying dynamics. So, what a shattering decomposition is going to consist of for me is going to be a set of clusters on the sphere or the cube, which have individually small diameter in probability. They're uniformly separated from one another. And together, they cover the entire dimension. Okay, so this is a bit more formal way of justifying this printer agreement. On the sphere, for a pure model, just to give some sense of what the numbers are, when p is large, this threshold should kick in at about square e. The critical temperature for replica symmetry breaking is something like square u log p. And stochastic and diffusion-based sampling succeeds up to e over 2, so some other constant. So last year, these authors and us separately proved some shattering results for pure spin glasses on the cube and on the sphere. So we know that there's some shattered phase. What we were also able to show is that when you have these kinds of shattering decompositions, not only is Langevin dynamics going to mix slowly, that's kind of maybe intuitively. Slowly, that's kind of maybe intuitively clear, but you're also going to not have any stable sampling possible. Basically, the reason is that when you add a bit of noise to your Hamiltonian, this clustering will be preserved in the sense that the support will stay the same from the clustering, but the weights on your different clusters will change very drastically. So, you get some kind of Wasserstein sense of instability in your measure. You can't detect this unless. Measure. You can't detect this on the level of overlaps because this is all for the replica symmetric regime. So that's why we call it transport design case. Okay. That's all I have to say. Let me just flash a couple of nice open problems. So, as I mentioned, sharp thresholds for sampling and related dynamics would be great to understand. There are a lot of other Of other algorithm classes you could try to prove hardness for. I don't know how to prove hardness for things like Langevin dynamics run for a polynomial amount of time. Obviously, really hope to be able to prove something like that. There are, of course, a lot of other related problems. We'll hear about some signal recovery problems in a related spirit by Alex later, and also about aging for the dynamics from Rezzo later. Thanks very much for your attention, and I'll enter. Yeah, okay. I'm trying to understand the intuition you had earlier about why this works for full RSB and not one RSB. So first of all, is your algorithmic structural the shattering structure? No. Most past positive? Uh yeah, it's just it's not this problem. Okay. So suppose I had a problem where it shatters into clusters that look like, say, the KSAC clusters. And then inside each cluster then shatters and then again and again again. So would you consider that full RSP? No, I don't think so. I mean the shuttering just I mean replica symmetry breaking should include Ricky should include, like, should be on the level of free energy, right? And shattering just isn't really a statement about free energies. So, yeah, right. So, you could have kind of repeated shattering in the replica symmetric phase, but it would be a different behavior. Okay, all right, thank you. But what is different from standard free energies, or somehow what do you see on free energies? Um so shattering just doesn't show up as a free energy at all. Energy at all. I showed a bunch of things I called phase transitions. Only the last one has anything to do with free energies. For all the others, the log partition function is the same as the expectation of the log, or the log of the expectation of the partition function. So the free energy is kind of trivial. Basically, it turns out that in spin glasses, the free energy is closely related to the overlap between independent Gibbs samples. So in the shattering phase, you have all these different clusters, but if you take two independent Gibbs samples, they'll probably be from different clusters. That means they'll probably be orthogonal, and that means the free energy can't distinguish this phase from a completely simple phase with no interesting structure. Once you have a Interesting structure. Once you have a small number of macroscopic clusters, macroscopic in terms of Gibbs measure, then independent Gibbs samples have a good chance to be in the same cluster and thus overlap with each other unless you see something infrared. Some idea of why you think stable is the same as all algorithms. It seems like a very old. Yeah, I mean, I think the so one reason. I think the so one reason is that there are a lot of high-dimensional inference statistical problems of this flavor, maybe with signal detection. And in a lot of cases, you kind of expect certain first-order methods like approximate message passing to basically be optimal. I mean, the other is just you can run LAM-driven dynamics for longer on the computer, and I think. I think if it worked well, then the physicists would have noticed this kind of thing, right? But I mean, I agree that there's no platonic reason that you should a priori believe this. If there were a counterexample of it, it would be very interesting. Maybe a follow-up question. What should we hope to prove or disprove? Sorry, maybe I have another thing. Maybe I have another thing I can say about Devler's question, actually. So the hardness result I presented, so I was talking about the stability in Lipschitz. Actually, the only condition that you need to get this sharp hardness result is that if you have two correlated Hamiltonians and you run your algorithm, then you have concentration of the overlap of the equipment. To me, this is the kind of statement that To me, this is the kind of statement that seems like it should probably hold for most reasonable high-dimensional algorithms, even if they're not something you can prove as assumptions. I don't know if that property feels better to you than the ones I described. Then my question is: is there something we could try to prove or counterexamples we could hope to search for to come down on one side of this same question, whether it's stable at all? Question: Whether stable is all. Like, let's say you want to prove something to justify further that stable really matches all. Is there some conjecture that we can actually hope to prove? I mean, you could extend hardness to other algorithm classes, certainly. But are you thinking of something more abstract that's I'm just thinking like, I mean, I work on Material too, but like it's a little bit It's a little bit unfortunate that, like, to prove this statement is harder than proving P be not equal to NP. So, is there some way? Is there like, this is completely speculative, but like, is there something we can prove to more justify this? Because otherwise, we just have to sort of believe it until the end of time. Yeah, that's a. So, you're thinking of some reduction? Yeah, I'm not sure. That's a very good question. That's a very good question. I'm not expecting an answer, but something I think about. Okay, let's take Mark again. Remaining outside, so now's a good time to discuss and a good conversation. I might sell the previous talk. So yes, we've got to go to the bottom of the base.  I think that was it. Just like I know, yeah, but it's also like it's just like, yeah, part of the reason I've never seen that. That makes me like a bunch of sweet versions. We're like the dumbest algorithm. We're like the dumbest elderly in the world, that's fine.