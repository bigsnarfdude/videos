It's a very simple process, the averaging process I'm going to talk about. We have a finite undirected graph with an initial vector which you can think of as 1000 on the nodes. So I mean vector on the nodes that so each node gets a label, a real number, and so And so that's a vector, which is the size of the vertex set of the graph. And so this vector evolves in discrete time steps. Like in step T, we pick a random edge and then we average the two endpoints, the numbers on the two endpoints, and we just replace. Points and we just replace both numbers with this average. Now we can think about it in a different way, like that every edge has a Poisson clock and so it wakes up at a random time, Poisson random time, and then it just does this averaging. So that's the same for finite graphs, but actually with Poisson clock one could potentially One could potentially generalize this for infinite graphs. So there is a slight difference. So on this slide, you see this formula again. It's very simple. So the ij origin is replaced with vi plus vj over 2 at i and j. And so this is the process. And And so, when we do this and the graph is connected, then the vector will converge to the uniform vector, which is, well, with the sum of the coordinates is v bar, which will be actually one in our talk. And all coordinates will be known negative. and all coordinates will be non-negative. Then, so this average is preserved after every, this, yeah, the average is preserved, the sum is preserved, the average is preserved after every step. And so if G is connected, then it will just converge to the uniform. And so the question is like how quickly it converges to the uniform. And so here is the talk plan because And so, here is the talk plan because there is such. So, first, I give you like a loser introduction, which is like the motivation for this process and how it relates to quantum supremacy. And just before the talk, it occurred to me that I can define this LLU processes, which ex which I think it's really explains like why. Really explains why we had the intuition that this process has anything to do with quantum supremacy. But this is going to be a loose introduction and after that I go again super specific, super concrete, and I will look into this averaging process again. Okay, so with the first part. So what are So what are what I LLU processes I call LLU local linear update? So in this case we have like a state space and you can think of as n qubit state although I really mean just the linear space, the complex linear space on 2 to the n dimension. Dimension, or you can think of like a discrete fermionic space with like n particles. But again, so I just go linear, not even stochastic or unitary. So we have a locality structure. And finally, we have an update rule. And so the And so the progress, so there's a process. So the update is that so every edge has a Poisson clock. And so the edge wakes up randomly, and then it performs this linear transformation on the qubits associated with the two end points. And of course, And of course, like one can think of generalizations like hypergraphs, or the rule is different on different edges, or the state is in fact a matrix on this space. And in this case, the update rule would be like a super operator on those two qubits. And again, it's just qubits, I say, sort of. I say sort of it's really like C to the four, these two qubits. So again, it's a linear update. So once I define this, and I actually just defined it yesterday or so, so but I see sort of that that's the that's the overarching theme. That's the overarching theme. Like we can I will now give you like four examples to this, which is the averaging process itself, the Moser-Tardosh resample, random unitary circuits, and the Stankov Movasak uh Gibbs state preparation. And and actually there are many others, so this seems like a hopeful class. Like a hopeful class. Okay, so the averaging process is in LLU, and you are asking, okay, so where is the 2 to the n dimensional space here? Because we see an n-dimensional space here. But that just because that's the one particle case, because here is the update rule that the 0, i equals 0, j equals 0. i equals 0, j equals 1. So we think of like a particle on well on the graph. And so the state particle is at I and so you see that only those two states interact where either I or J has the particle and so Particle, and so the particle number remains. So, if I start originally with a state where which is one particle state, then it just remains in that subspace. And you see that this update matrix actually gives exactly the averaging process. So, that's a very simple stochastic matrix. Simple stochastic matrix, actually, not quite stochastic because so those zeros there, but in the middle is stochastic. So on the one particle subspace, it is stochastic. Okay, so that's the first example. So that will be the focus of this talk. Of this talk, and let's go to the next example: so, the Moser-Tardos resample algorithm. So, it is used to solve sparse satisfaction problems. And actually, sparse satisfaction problems are simply always solvable. And that's a very remarkable thing. Well, there ought to certain inequality should hold for this. Hold for the sparsity versus the probability of the constraints are satisfied, and this is captured in the Lovas-Local lemma. And so namely, the probability should be that a clause is solvable, should be very large, and the sparsity should be very small. And I mean, so this should be very sparse, and then the And then the instance is solvable. And Moser, originally Robin Moser, and then Gabor Tados just made it more beautiful, came up with the following process to actually make the Lovas loka, because the Lovas Loka lemma just said the satisfiability, but it was not efficient. So, but then they gave this fantastic algorithm, which is just that a clause. That a clause just looks at itself, and if it is not satisfied, then it just resembles the variables involved. So if the clause is, let's say, X or Y or Z complement, then the only case when it's so it's like probability 1 over 8 that is not satisfied is when it's 0, 0, 1, in which case it in which case it will just set itself to the equal superposition in quantum language of all the possible coin flips on these three Boolean variables. And otherwise it just does nothing. So a clause wakes up let's say Poisson random looks at itself and if it's not set At itself, and if it's not satisfiable, it just resembles itself. So, this is the second example. Now, the third example is the Google or whichever random quantum circuit. So, whichever random quantum circuit, it just means that, well, there are parameters and there are types of gates, but basically the Gates, but basically the idea is that the gates are random and they are also randomly placed on a part on in this case on the grid graph. So you don't know which gate and which grid edge comes next. Well, you know, with the grain of salt, because it's parallel and it's so, and again, this is this. And again, this is the sort of LLU is just the philosophy. But it's basically random. So an edge of this grid grab just wakes up and wakes up to a random unitary transformation, basically. And if you do that many enough times, then like unlike in the averaging process, which is like a classical statistical process. Statistical process which converges to the uniform. So, what this quantum process, and of course now it's not restricted to a subspace either, but it's on the entire like 2 to the n dimension. And if you observe like a 0, 1 string of lengths n, then this is the probability distribution. probability distribution. It's e to the minus e times 2 to the n. Of course it's continuous, but so A is the amplitude and this is the probability density that the amplitude is amplitude square is so A is the amplitude square. So is the probability density that the amplitude square is going to be A. Square is going to be A. Now, again, so this is continuous, so it's a little, so that's why I drew this approximate sign. And so given this Porter-Tomars distribution, then you can do many things. Now, so here the problem is actually to solve, to show that one, that this is really the port. That this is really the Porter-Tomars distribution. And two, if now the gates are not quite unitary, but let's say they have noise, then you get something, depending on the noise level, you get something more and more, like closer and closer to the classical. And if you do it long enough and it's not If you do it long enough and it's noisy enough, then you, instead of the Porter Thomas, you would just see the classical uniform. And it's still not resolved exactly for what parameters you get this quantum chaos when you reach the Porta Tomas and exactly at what noise. Exactly at what noise level will decay and within what depths will decay to the classical uniform. So there are beautiful open problems. So the Stankho-Movasak Gibbs state preparation algorithm is a quantum algorithm which is based on the random circuit idea. Idea, random quantum circuit idea, and examples from the thermalized state of a local Hamiltonian with inverse temperature beta. And it is the first application of random Of random, well, like first useful application of random quantum circuits I know of. And well, again, you have to take it with a grain of salt because if you look at this picture, it's not completely random because I mean the angles are random and sort of the gates are judiciously put there. But yeah, I think you can. But I think you can put them there randomly too. But tomorrow we will hear this talk, and I am looking very much forward to hearing this very nice result. And so now this is the last sort of loose s um I mean, si slide in this loose topic of so supremacy and LLU. Supremacy and LLU. So I just want to make the case here that it is worthwhile to studying the averaging process. And that's because it is basically the simplest process in LLU. It's like the binary symmetric channel of all channels, you know, that you study just so to study just so to understand channels so you study this toy case of LLU just to understand LLU and so the so the way how it relates to quantum supremacy is that aside from Schor's algorithm which would be wonderful to implement the the practical supremacy algorithms Supremacy algorithms and hope this Gibbs state preparation becomes practical, and then it might prepare Gibbs state that classically we cannot. So these are examples to supremacy, also the random quantum circuits. And so the known examples, the known current examples to quantum supremacy. To quantum supremacy are all LLU, and we are studying the baby example of LLU. So that's how we are relating to quantum supremacy. Okay, so now again, back to the concrete stuff, mathematics. And so just to recap. And so, just to recap to you, so this is how it looks, just so that you see a concrete case on the triangle, and the red means that it wakes up and then it averages, and of course it converges to the one-third, one-third, one-third. So, we introduce the PQ convergence, and we are not gonna use this. To use this for other than 1,1 in this talk. So, but let me just tell you the definition because it's interesting and I don't think that before us anyone introduced this notion. So, you might ask, so what is the starting state in the averaging process, or what is the meaningful starting state? And of course, one, zero, zero. And of course, one, zero, zero, you say, and indeed. But if now the convergence can be, of course, measured in all sorts of norms. Like we can measure it in L1 norm, we can measure it in L2 norm, or even L infinity norm. And so in LQ norm, Well, we take the deviation in the Q norm, the Q power of the L2 norm of the deviation of V. And so this is a random process. So the edges wake up randomly. So we over all these wake-up sequences, so these random wake-up sequences, we take the expectation, so that's where the So that's where the expectation is over, and then we take the q's root. And so we are looking at a time step. So then it's like a concrete time step when this expectation decreases below epsilon. And so this. And so this quantity, this number of steps, we call T epsilon PQ. Now, what is, so the P is, okay, so the starting state. So that's the interesting thing. So although we measure the convergence in the Q norm, the starting state we set in the P norm. In the p-norm. And actually, we maximize over lower starting state, so it's like the worst case time. Because obviously, if we already set everything in 1 over n, 1 over n, 1 over n, then it immediately converges. But so we clearly we don't want to minimize the time, we want to maximise the time to get a meaningful notion. To get a meaningful notion. So if we maximize over all initial vectors where the p-norm is one and then the convergence is measured in the q-norm, that's the p-arrow q, but again we look at one, one, and in the case of one, you see that when q is one, then the q's root disappears. root disappears, the q's power disappears, so basically we are just talking about the expectation of basically it's just the statistical distance from v maybe this factor of 2 I always forget whether is there or not. In our case, you will see. Okay, so So let me just show you the so that you see the convergence, how it in real life looks. And so the computer experiments, we have done it for hundred million if we click and star the star graph with hundred million nodes. Hundred million nodes, and that's what you see that originally and at the bottom of the slide, you see that when the starting vector is one zero zero zero and the target vector where the process should go is one over n, one over n, one over n, then the alpha norm is actually two, right? It's not one. And so actually, it drops beautifully at some point. And okay, so this is how you read this graph. So 10 means 10 times n, so 10 to the 9, and 20 means 20 times 10 to the 8. And you see that at around 30. And you see that at around thirteen times ten to the eight, the true two drops down to ha to one and sixteen times and so that's the t and so the epsilon is one there. So t one one is and I just wrote equivalently one arrow one but I simplify one or arrow one just to one so t one one is ten to Is 10 to the 8 times 13, roughly speaking. It's an average of 20, so you have to average, of course, all the possible runs, or you average 20 runs. And so the T 0.011 is still only 10 to the 8 times 25. So you see this drop off. Drop off for the click. And actually, for the star graph, depending on so the red is when you start at the leaf and the blue is when you start at the center, and you see that when you start at the center, it's even, at least for a while, it's even better than the click. So you would say that, okay, the click mix is the quickest, but not quite because the star graph. Not quite because the star graph, but we will show that in a sense the click mixes the clickers. Okay, so what is this quantity, let's say, when we drop to like we get epsilon close to the uniform. So what is the time and what this And what determines it? Well, what determines it, it turns out that in all or in most norms, actually in all norms, basically what determines it is the second smallest eigenvalue of the Laplacian. And again, because you know the Laplacian is made from the adjacency matrix, it's just that you are reversing the adjacency. That you are reversing the adjacency matrix, and you are also introducing in the diagonal the degree sequence. So when you hear talking about the second largest eigenvalue of the adjacency matrix, since we negate it, somehow it's in the Laplacian, it just beautifully comes out so that the smallest eigenvalue is zero, and then the second smallest is. and the second smallest is what used to be for the adjacency matrix, the gap between the largest and the second largest when the graph was regular, but if it was not regular, then, you know, then so that's why we are looking at the Laplacian. Okay, so there is this lambda 2g, the famous lambda 2g, and so there is a number And so there is a number of edges, and so we have this gamma g, which is the number of edges divided by lambda 2g. And actually, in all norm, basically that's the running time, except with the log factor. And so the goal of this research is, so that's easy to prove, and so the research goes to nail down. Goes to nail down this log factor. So let me go on and you will see what I mean. So but first so that you get like an idea what this gamma is on some graphs. For the clique, the gamma is n and for the bounded degree expander the gamma is also n and actually for every And actually, if on every regular expander graph, the gamma is n. So it's really, when the graph is expanding, it's n. On the other hand, the pass is very non-expanding, and there the gamma is n cubed. And again, the gamma is the number of edges divided by this second smallest of Laplace. Okay, so in L2, In L2 is actually the easiest to treat and the easiest to solve, and it is simply gamma g. That's the convergence time you get down to epsilon equals 0.001 within constant time gamma g and not earlier than that from the worst starting point. Point. L1. So now in L1, there is already an uncertainty depending on the graph. There is a log factor or there is not a log factor or depends. Okay, so that's the question. So is there a log factor or not? So that's So that's the main question. Where is gamma g, I mean, where is t epsilon one? So is it gamma g or gamma g times log n or somewhere in between? So the ancestor that actually the result that in part inspired us inspired us and actually Ramis Movasak taught with Percy and then actually this result came later because Percy remembered that oh that's the Jean-Bourgain has also us so not lesser than Jean-Bourguin and then Percy actually proved Proved that for and of course with Chattery, Sly, and Zhang, they proved that there is a sharp cutoff for the clique at precisely at one over two log two and log n. And so the cutoff width. So the cutoff width is n square root of log n. So n square root of log n is just slightly tinier than n log n. And you saw our actual implementation that the cutoff widths looked quite like as large as the initial horizontal plateau at two. So So it just really kicks in because the square root of log n difference is just so small that and there is also this coefficient. So it's really just kicks in like just at very large n, this sharpness of cutoff. And as a matter of fact, if you do the calculation, then remarkably, like 1 over 2 square root of 2 10 to the 8 log 10 to the 8. 8 log 10 to the 8. So their formula gives 13 times 10 to the 8. And the 13 I just in the previous slide I just put there like the T11, if you remember. So when it reduces to 1, so which is sort of in the middle of the cutoff, so they just right hit the middle with this 1 over 2 log 2 and log n. So that's a very good. n log n. So that's a very good formula. And we were wondering if, you know, so what is the case of the star? We couldn't prove such a cutoff, so that would be one of the open problems to have such a sharp cutoff for the star. However, we can actually prove the main term, and that's going to be our main result. And that's gonna be our main result, not only for the star graph. Okay, I let me not get ahead because in one minute I will be there anyways. So, okay, in one second. One over two log2n log n is actually, it's a lower bound for all graphs in the L1 case. Now, actually, there is, it's a little cheating. So, here the one is really one. One is really one minus order of epsilon. So value in again in the previous result, you don't see that this one minus order of epsilon. You just see one and then you see the cutoff of the residual term. So in our case, the residual term case the residual term, if you will, it's epsilon over epsilon times n log n and not epsilon times n square root of log n. But it's true for all graphs, so we prove it for all graphs. We also prove that the worst case starting vector in the L1 case is the 0, 1, 0, and we'd never put it into any abstract. It into any abstract, but somehow people liked it, so now I am just saying it second because people said, Oh, that's very useful to know that the one, zero, basically that's the worst case starting. We proved n cube for the cycle graph, which was raised in an earlier work, but actually it was also, it turns out it was independent. It turns out it was independently proven roughly at the same time. But in any case, in this talk, I will just focus on the n-log and lower bound. Of course, we have made many other observations and computed for graphs and have conjectures and so forth. But let's focus on the Okay, so let's focus on the n log n. So n log n lower bound. Okay, so actually first I just prove a as a matter of fact even with the correct constant I prove the n log n lower bound for all deregular graphs. And you will see it's a very simple proof. Simple proof. It uses entropy. And basically, the idea is that, okay, so I start, and so it's a lower bound, so I can just pick my favorite starting state if I succeed. So I pick the 00100. And so it's a deregular graph. So that's a restriction. Restriction. So our result, so we have our serious result is for every graph, not just the regular graphs. But it's instructive to see the regular graphs. The proof, how entropy comes in. So this is the starting state, and since the sum remains the same. Sum remains the same, and since we always average, which never will never create negative numbers, then we always have a probability distribution at hand, at every step. After every step, it's a probability distribution. So, we can look at the entropy of this probability distribution, and of course, the entropy. The entropy, what I mean, I have to specify because there is so many randomness. So I sort of start to run the process for t steps and then I get a vector which just happens to be a probability distribution and I just take the entropy of that. Now if the edge If the edges woke up in a different order, then I would get a different vector and a different entropy of that. And so I take for all the wake-up sequences, I will take these entropies and I just average them. So I take the expectation. So it's basically the expected entropy. Entropy of the vector at the t-step. So I look at the progress of this quantity. And so in the very end, okay, so the expected entropy, well, I just wrote it out like it's sum of PR. out like it's sum of p i log 1 over p i obviously and but so now let's see how this entropy changes in one step and actually I can bound the expected change and so expected change means that in one step a new edge will wake up which is going to be a random edge. Is going to be a random edge. And I can fix my current vector, so I fix it to V, and so then over point A, the vector V has value VA. And so if the edge that wakes up is the AB edge, then the two endpoints where the value Points, well, the values associated with the two endpoints are VA and VB. So the new entropy will be twice the VA plus VB over 2. So the 2 cancels. So it's VA plus VB times log of 2 over VA plus VB. And then the old entropy was VA. entropy was VA log 1 over VA minus VB log 1 over VB and then simple calculation will show. So again on the right you see that so the VA VB and then it averages and so now I just and of course since it was a random edge that woke up then if I want to compute the expected end Compute the expected entropy change, then I have to average this quantity for all edges. So 1 over Eg times sum da da da that averages this over all edges. So like a simple calculation just shows that so this quantity is just upper bounded Is just upper bounded nicely with like a linear, just with Vi plus Vj times a constant factor, so E based log 2. Okay, so once I have this formula, then I just sum it up, I mean the estimates, and then I actually use the fact. Actually, I used the fact that, and I just made myself when I did this, just to make sure that I am not wrong, that, you know, this is how you do it. Like, it's a deregular graph. So you see VAD times, but then the, oh, it's it's I apologize, it's not VG, it's EJ in the denominator in front of the sum. So front of the sum. So I messed it up. It's ej, so the ej is n times d over 2. So the 2 comes in the denominator and then it becomes 2 times log 2 and then you beautifully get the 2 times log 2 times 1 over n and that's brought to you by the regularity of g and And now, so that's the expected change of entropy in one step. So what is the final entropy? Well, you might say the final state is 1 over n, 1 over n, 1 over n, but not quite. It's something close to that. And I will have a final slide, if I will have one minute, to show that indeed That indeed, when we are close to 1 over n, 1 over n, 1 over n, a probability distribution is L1 close to this distribution, the uniform distribution, then its entropy ought to be basically log n. I mean, log n times 1 minus epsilon. So, well, I just omitted the 1 minus epsilon factor. 1 minus epsilon factor, but if the final entropy is log n and the progress you do is 1 over n, then you get that you need like n times log n steps. So the ratio of the two, obviously. Okay, so that was for regular graphs. Regular graphs. However, we have seen that the star performs super well, and maybe because it's not regular, but we also have seen that the star, although performed super well, did not perform that much better, or if any better, than the click. I mean, it started good, but then it became worse than the clique. It became worse and the click. But so you might ask yourself: okay, so but so non-regular graphs, so maybe this argument certainly does not apply, and I tell you why. So for the case of star, it does not apply because like you go, I mean, you just follow the line of argument. Follow the line of argument up to the point where you really want to. So, you already made the, you already upper bounded the entropy difference with this log 2 times vi plus vj. And then you plug it into this, your sum. But then, well, every edge. Well, every edge well gives a Vi and it gives the V center in that sum. So the V center is going to get like a coefficient n minus one. And so the previous proof worked because the sum of Vi is one. That was an important thing. An important thing, and so for deregular graphs, each Vi occurs exactly D times, so we get like D times summa Vi, which is exactly D. And so we know what it is. But here, the center, like the V of the center, can be anything because during the process it changes, so because of the non-uniformity. Because of the non-uniformity, we cannot really estimate this sum. So, this sum depends on the V center, and so that's the problem. And in general, like you saw, the deregular case, like in the deregular case, there was no such dependent on the individual VIs. However, as turns out, we can remedy We can remedy this situation if to the entropy we add a linear term, so a term which is linear in the Vi with appropriate coefficients. And here the emphasis is on the appropriate coefficients. And I just tell you what is the appropriate coefficient for the star graph, so you just have to add. So, you just have to add twice the V of the center. And so, that's going to work. So, the catch is not catch, but like the gist of the argument is that if you look at this quantity and now you estimate the change in one step, then just mathematics gives that somehow like in the That somehow, like in the case of uniform, the case of regular graphs, like, and I say mathematics gives it because it's really beautifully gives it. So if value, okay, so I did not tell you the real beauty there. Okay, so I just told you the star graph. But in general, the beta i are actually tricky children. Are actually trickily chosen, and that's what basically going to be my last message: that so the beta i's have to be chosen in a tricky way. And so, first we have a lemma which says, basically, it says that with appropriate beta, if the beta is good, so to speak, So to speak, then the mathematics will cooperate and we get this beautiful cancellation where we don't, if we use that formula, we can do the summing. And so for that, the beta must satisfy a certain linear equation. Namely, so this is a vector equation you see in the middle. So the d is the degree. So, the d is the degree sequence as a vector. So, the degree sequence is less or equal than the Laplacian times beta, which is also a vector, plus a constant times the one the one one one one vector. So, if so if and so depending So, if and so, depending on this constant, will now in the final formula it goes in, but then the running time, I mean the sort of the lower bound on the convergence time is can be can be lower bounded. So, lower bounded, and you see t is less or equal, but it's See, t is less or equal, but it's really lower because it says that if t is less than this bound, then we are far away from the average. So the counterpositive is obviously that we need to, that t needs to be larger to be close to the average. Okay, so but so the previous lemma and so So, the previous lemma, and sort of you can say that's the main lemma, but to go from the main lemma to the proof was yet another round because, okay, so if we have such a beta, and you can see for the star that it is a good beta, what I have just said, but for general graphs, can we find such a beta? And again, it turns out that if you solve this equation. That if you solve this equation, so the Laplacian equals like C D minus C D one, which can be solved for every C then actually whatever solution, beta solution you get is going to be a good beta. And since it's easy to see Since it's easy to see that beta is, so a good beta is going to be shift invariant. So we just shift it so that the minimal element of beta is going to be zero. And that minimal element is where the vertex, the vertex where this minimum is taken, that's where we are putting. That's where we are putting the one. Because for non-regular graphs, it actually matters where you put the one, like in the one zero zero thing. So now there are two asides since I have two minutes. I'm not sure whether it's up to 12, 10, or 12, but maybe I should just. But maybe I should just make it to 12.5. That's fine. So I just said that when a vector and so you can forget about now everything, it's just pure mathematics and you know it's just useful to know if you did not know it before. If you did not know it before, that you are asking, okay, so you have a vector which is close to uniform. So, what is the entropy? And actually, in terms of the L1 distance from uniform, you can bound the entropy. As a matter of fact, so here it's like a general. So here it's like a general theorem which says that if the L1 difference of two distributions is, well, what it is, then the entropy difference is that times log n plus a constant. At least no bigger, the entropy difference is no bigger than that. Bigger than that. And so it implies that if we are epsilon close to the uniform in L1, then the entropy of such a distribution can be at most epsilon times log n away from log n, which is the entropy of the uniform. So it's 1 minus epsilon times log n. So actually in the final state, Actually, in the final state, if basically the entropy is log n. And so that's where this epsilon comes in. And so our error term is going to be, when you calculate, it's going to be n times epsilon times n times log n. So another aside slide, and that's my very last slide other than the Other than the open questions. So for the cycle graph, we don't use the entropy calculation, but we use something completely different. And actually, again, I just show you the easy thing and even just part of it that if a pass, if now I have the pass graph and I just basically say that. I just basically say the trivial, which is if you have the parse graph and you take the initial vector, which is concentrated on one endpoint, then the way how it evolves is always that the mass is going to be pushed towards the other side. So the mass never goes back. And so that's easy. And so that's easy to see, and therefore, in this situation, it's easy to show that the n-cubed bound. However, when the one is already in the middle, then it's already harder, and when it's not a pass but a cycle, it's even harder, strangely enough. Strangely enough, it shouldn't be. Somehow you have the feeling, but it is. Okay, so we have very good reason to conjecture that for the L1 case, okay, so we have the n log n lower bound basically for all graphs and the gamma g Gamma G is always a lower bound. And by the way, for the pass graph, the log n is not there. So in the high n, the log n is not there. And it seems that for the high n, the log n is never there. So when you pass n log n, then the log n is never there. So basically, we conjecture that We conjecture that the mixing time is just the minimum of gamma g and the n log n. And so that's one conjecture. And the second conjecture is about this peculiar 2, 1, like when the initial vector is 2 is known. Is normed one in the two norm. And I actually give it out that basically when you look at the second largest eigenvalue, the associated eigenvector, and if it's uniform enough, then the log n, and then the log n is there for L2. Now, you should think about that. You should think about that. So, L2, when the L2 norm is one, then of course your starting vector could be one over n, one over n, one over, I'm sorry, one over square root of n, one over square root of n, one over square root of n. And of course, then the final vector, so we are looking at when, so what is the distance from the uniform, not from the final distance. form not from the final distance from from 1 over n 1 over n 1 over n and so in this case then let's say the the the coefficients I mean the vi's add up to basically square root of n v and in the final we look at the L van difference still still looking at the L van difference Still looking at the Alvan difference, you might say that's a very unfair measure. However, the mathematics speaks for itself because in this case it just seems that beautifully if you look at this measure, however artificial you might find, then this login is always there. So then we get this nice thing. This nice thing that for L2 the log n is never there, for L1, it's sometimes there, and for the L2 one, it's always there. And so this concludes my talk. And thank you very much. All right, well, thank you, Mario. That was a beautiful. All right, well, thank you, Mario. That was a beautiful talk. Looks like we have some questions. So I unfortunately have to run quickly here. So I'm going to hand things over to Ramas to sort of field the questions. So, but well, first, it looks like Nicole Younger-Halpern has a question. So, and then I will see you all this afternoon, and Ramos will take over with the questions here. Sure. Sure, go ahead, Nicole. Great thoughts. Thanks, Argo. Great thoughts. Thanks, Argo. So you started off with entropy and then introduced an extra term when you looked at a graph that was not deregular. And so when you added onto the entropy, you constructed a function that looked a lot like a free energy or really a Massey function, which is basically just proportional to the free energy, more or less. The entropy is the Masu function that is relevant to a system that's closed and isolated, not exchanging anything with its environment. The other Masu functions, or equivalently, other free energies, are relevant to thermodynamic systems that are exchanging energy and particles and electric charge or whatever else with their environments. So, the function that you were putting together. The function that you were putting together suggested that maybe thermodynamic systems that exchange a whole bunch of stuff with their environments are naturally represented by graphs that are not deregular, but have particular structures. Do you have any comments? Well, that's an absolutely excellent remark. And I was thinking about yesterday exactly about this, that so entropy. So entropy, well when everything is like sort of boring, then there is only the entropy. And so when there is some structure there, as you call free energy, which is some useful structure there, and that's where some energy difference is there, then exactly. Then, exactly, that's where we need the extra term. So, I was thinking on, and I wanted to mention in the talk that maybe somehow we can actually use that extra term to measure exactly, but you have put it into a more precise form, which is free energy. Energy. So I was just thinking to myself that extra term is the characteristic whatever quantity of that structure. But I was also thinking about energy, that somehow the leftover term is the energy. Yeah, so that's an excellent observation, and I was thinking about exactly the same thing, like when Same thing, like when I was preparing for the talk. Great. Any other questions? Well, this was a very clear talk and a great talk. So, if there are no other questions, Mario, thank you so much for this great talk, and thanks for everybody. And thanks for everybody for being here. We'll resume in, I believe, about two hours with the afternoon talks. Thank you. Thank you. Thank you all. See you then.   