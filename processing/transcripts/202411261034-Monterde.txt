My talk today is pretty much the um the opposite of movement and so we'll be talking I just realized it last night. I was like, oops, okay, we'll be talking about sedentary vertices in graphs. And I'll try to see if I could sneak in some symmetry. So bear with me. Okay, so jumping right in. So before we make sense of the idea of sedentarianism, we introduce this idea. We introduced this idea of a quantum walk. But what is a quantum walk? Well, we need to start with a quantum spin network, and that's pretty much just a network of interacting qubits. So the motivation behind the mathematics that we'll discuss in this talk is pretty much physical. But for the purposes of this talk, you could just think of this network of interacting qubits as a weighted undirected graph where the Where the vertices and the edges of your graph represent the qubits and their interactions in the network, respectively. So, qubits, these are just placeholders for subatomic particles. So, usually subatomic particles that allow transfer of quantum states. So, you'd like to think of them as bosons, muons, etc. Okay, so our talk will revolve around the following question. Question. We would like to assign a quantum state on the vertex in your graph, and we label that as, we could think of that as a standard basis vector E sub u, zeros everywhere except a one at the u entry. And then we want to ask, how does that quantum state propagate across the graph? How does that move across the graph? So this is the movement part, okay? All right, so if we denote the quantum. Denote the state of your quantum system at time tau, then that will simply just be, so suppose that's C of t and you'll be able to find C of t by multiplying EU to the left with this matrix U of T. So, what is that matrix U of T? Okay, so for us to make sense of this U of T, we introduce this real We introduce this real symmetric matrix M, and we'd like that matrix to respect the adjacencies on the graph. So, which means that the UV entry is zero if and only if U and V are not adjacent. So, this is very similar to the assumption in the inverse eigenvalue problem for graphs. And then a continuous time quantum walk in X relative to the Hamiltonian M is determined precisely by the Is determined precisely by that matrix u of t, which is just the exponential of i t m. So m, that should be m, sorry. t here is just a real parameter, and i squared is negative 1, and we're exponentiating this project. So you may avoid looking at this at the power series expansion because it's a bit scary. So let's just focus ourselves on the fact that this is the exponential of IT. Fact that this is the exponential of i th. All right. So this matrix, so h is real symmetric, you multiply it by a real parameter t, th is still real symmetric. You multiply it by i, and then it becomes q symmetric. And then if you take the exponential of that, it becomes a unitary matrix. So that explains why this is a unitary matrix. In particular, it's symmetric. So it's a bit weird for, not really weird, but. So, it's a bit weird for, not really weird, but special for a matrix to be both unitary and symmetric. And so, since it's a unitary matrix, if you take the complex inner product with any column with itself, right, you will get the sum over all vertices. And each summand looks like a modulus squared of the uj entry. You sum it all over column or row. Choose your poison. Okay? And that should equal. And that should equal one. And this is an interesting equation here because this says that each of these quantities that are non-negative, right, when you sum them all up, it's one. So that says that this represents a probability distribution. So in particular, we may interpret the mu to the squared of the uv entry of this matrix as the probability that the quantum state you assign. That the quantum state you assign at vertex u is found if vertex v at times. Okay, any questions? Good so far? All right. So typically, so where does algebraic graph theory come into this, come into play here? So we always take it as the adjacency or Del Plausian matrix of our graph. But from our assumption here, and from talking to physicists who does quantum walks, pretty much any permission matrix. Pretty much any permission matrix will do the job. But, yeah, for our purposes, since we want to reveal how the underlying structure of the graph affects the quantum walk, we'd like to focus on ending the adjacency relaxing. Okay, let's do a visualization for Q3. So this is our favorite hyper Q. Okay, no doubt. That's everyone's favorite graph. And then we assign a quantum state at one end. And then that's time t equals 0. That's the time t equals zero as we move. So that's how it looks as we propagate. And at time t equals pi over 4, it's not very obvious because there's so much light hitting the screen. But the quantum state that was assigned here, so before pi over 4, you saw that the quantum state was mirrored throughout the graph, right? But at time pi. Right? But at time pi over 4, the smearing is sort of uniform across the vertices. I will not be talking about that today, but that's local uniform mixing. There's a lot of experts here about that. So Harmony, Ada, and Chris and Jova. And as we move through time again, we see that at time t equals pi over two, the quantum state you assigned at one hand has reached the antipodal vertex. Reach the antipodal vertex. And twice this time, you go back to the original vertex. And that's exactly what we call perfect state transfer. Sorry, not the going back to the original, but being transferred to another vertex. So we say that perfect state transfer occurs in a graph if this absolute value is 1. So PST occurs in this case between u and v. And if u coincides with v, then that's just periodicity. Just periodicity. So, perfect state transfer, I'm just gonna mention what it is, but I'm not really gonna talk about it. But it's been studied extensively for the last 25 years, and the point of that is if you want to transfer information, quantum information in this case, between remote parts of your quantum computer, then you would want to understand how that occurs. And that's exactly what perfect K transfer is. What perfect K transfer is. This quantum phenomenon has been generalized to what we call a pretty good state transfer. So yeah, the naming is perfect and a pretty good. Okay. Yeah. I think it's Christian. Okay. And here in pretty good state transfer, one we don't need one to be attained at the same time. Don't need one to be attained at a specific time. We just need one to be a limit point of these absolute values, which makes you a generalization. And what's our tool for determining whether there's PST of perfect PGST between vertices of your graph? We use the idea of spectral decomposition. So, since M is a real symmetric matrix, if you take the distinct eigenvalues and you take their corresponding orthogonal projection matrices, you could write M. Projection matrices. You could write M as a linear combinations of the EJs for which the coefficients are your eigenvalues. And so the EJs here has some very nice properties. But what matters to us is that this spectral decomposition of your Hamiltonian gives us a spectral decomposition for our transition matrix. I forgot to mention that we call U of T S. Mentioned that we call U of T as a transition matrix. So we know that this is just the exponential of this matrix, but since we know the spectral decomposition of this, I can hit this by I Tm on both sides. And the EJs remain invariant if I take the exponential of that. And so that means that the eigenvalues should just be exponential ITM each. And the EJs, as I've said, just stay the same. All right. Just three definitions. Just three definitions, and then after we won't be introducing so much definitions, I swear to you, this is just the bulk of it. So, the eigens value support, the vertex U is just a set of all eigenvalues of your M, such that the projection towards EU is non-zero. So, you could think of this as the youth colon of Ej. If that's non-zero, then I put lambda j in the set. Put lambda j in the set. If it's zero, then I throw it away. Two vertices are strongly cospectral provided the projections towards u and v are equal or same sign. And two vertices are cospectral if these diagonal entries are either equal or opposite in sign. So you might be wondering what's the relationship between strongly cospectral and co-spectral. Well, strong cospectrality is a strengthening of cospectrality. Of cospectrality, at least for the adjacency matrix. In particular, you could think of cospectral vertices if you want to approach it in a really algebraic way. This just means that the vertex-deleted subgraphs, so x minus u and x minus v have the same characteristic unknown. So here I'm just defining post-spectrality in general. And it cannot be minus because this is a positive signal. Sorry, yes, yes. This is a positive signal. Sorry, yes, yes. Sorry. Sorry, that's a time for. Yes, Crystal's right. The plus, this should be equal, not plus minus. Sorry. Thank you. All right, so we're going to head into Sagittarius now. I hope no one's leaved, okay? But just before we get there, so PAPs were of paramount interest, or are still of paramount interest to physicists. And that's why when perfect state transfer was first studied, everyone was. Studied, everyone was busy working with the HAFS, but unfortunately, P2 and P3 are the only ones that admit PST. That was the motivation for generalizing it to PGST. And it turned out there's actually infinite families for which PGST occurs between antipodal or even internal vertices. So that's for the paths. How about for the complete graphs? So for the complete graphs, it's easy to check that you're, I'm just going to. I'm just gonna do that, skip the calculation. It's easy to check that the transition matrix using the spectral decomposition is the adjacency matrix of the complete graph. You could see that it's easy to calculate because there are only to eigenvalues of the complete graph. And so if you zoom into the UV entry where U is not equal to D, it should just look like this. But if I factor the red 50. They factor out and take this red thing here and take the absolute value, then I get this expression. But it turns out that's just bounded above by 2 over n. So that means that there's barely any chance for your complete graph. And when n is very large, this is like almost 0. But if you take a look at the youth diabetal entry of this, you could just check it's equal to that. Again, factor out the red expression here. Expression here, take the absolute value, you will see that this is always bounded below by 1 minus 2 over n. So what happens is when n is very large, this is close to 1. Right? And if we go back to what this means, the absolute value squared of this, this is the probability, the quantum state you assign at u is found at vertex u is very high, right? And that motivates our definition of sedentary. Of sedentary. So a vertex is C sedentary if there exists a constant C greater than zero, such that the infimum over all T positive of this quantity is C. So you could just think of this as the absolute value of this is greater than or equal to C for all positive T. And in case that this C, this infimum, is attained, then we'd call it 10. Is attained, then we call it tightly C segentry. So for the complete graph, we've seen that it's tightly 1 minus 2 over n sedentary. So what does C sedentary mean? So physically speaking, that means that the quantum state you assign at vertex U tends to stay there. And so there's no transfer. And so just some basic properties of C set of sedentary vertices. If vertex U is C sedentary, If vertex u is c sedentary, then it has to be c prime sedentary for any c prime less than or equal to c. So I'm saying this because what we're interested here then is to find the is to find the C for which this bound is attained. We just don't want so technically what's sedentary means that the probability is bounded away from zero. Probability is bounded away from zero. That's just really what you want. But you want the bound here to be as close as possible. That's like the best bound that you can have. And for cospectral vertices, U is sedentary, if and only if B is. So for walk regular grass, for example, it suffices to just check whether one vertex is sedentary and you get that the rest of the vertices are sedentary. Okay, so sedentariness is Sedentariness is motivated by the following fact. If U is sedentary, then it's not involved in pretty good state transfer. So, which means that studying sedentary vertices rules out PGST, and people are very much interested in PGST, so we could, the high-probability transfer, so we could connect the two types of transfer, and we could easily see this proposition from this. This proposition from this. So, this just follows from the fact that the sum of the modulus squared of all the entries, right, in a row or column is one. And so, if u is sedentary, this one is bounded away from zero. So this cannot be arbitrarily close to one. So, indeed, it cannot admit PGST. And if it does admit PGST, this gets arbitrarily close to one. So, this cannot be, so the infimum of this should be zero for all time t possible. For all type T possibly. Okay. However, let me just this proposition is basically saying sedentariness and PGST are mutually exclusive types of state transfer. So of course the natural question would be, well, are there vertices that are neither sedentary nor involved in critical state transfer? And there are. So in the star, for example, the central vertex, it's not sedentary because you can find a time for which. Because you can find a time for which this is relative to the adjacency. You can find a time for which it's zero. However, it doesn't admit strong cold spectrality, which is a necessary condition for perfect state transparency. So that's an example. Furthermore, the bipartite double of your complete graph, it's not okay, for n not congruent to 0 mod 4, it does not admit PST. not admit PST. So PGST and PST here are equivalent, but it's also not sedentary. So these are infinite families for which there is neither sedentariness nor predicate state transfer. All right, so motivated by the fact that these are mutually exclusive, but there are vertices that are neither sedentary nor involved in PGST. We asked the question, In PGST. We asked the question: Are there vertices for which they are opposites? So, are there vertices for which if it's not sedentary, then it's involved in predicate state transfer? Or if it's not involved in PGSC, then it's sedentary. And yes, the answer are twin vertices. So, two vertices in the graph are twins if they have the same neighborhood. And just a spectral characterization of twins. So, if you have a set of twins, then a vertex is there. If only if there's another vertex, There, if and only if there's another vertex in t minus u, such that EU minus EV is an eigenvector associated with some eigenvalue. So this eigenvalue varies depending on what the m is. That's relative to the adjacency matrix? Sorry? That's for the adjacency matrix? And for Delaplassian as well. Oh, okay. Yeah. And for the sinus Laplacian. So it is applied. Okay. So we had this theorem in a 2023 paper that if you have a twin set Have a twin set in X, and for any two vertices that you pick in that set of twins, then this sum of absolute values should be at least one for all time t. And from that, it's very clear, right? So from this fact, we see that a vertex in your twin set is either sedentary or involved in EGST. And the reason there is So if this one, if this quantity is very close to one, right, this is very close to one, then this should tend to zero, right? And vice versa. So that's what explains this corollary. Okay, let me just do a time check here. Okay. So I'm not going to bore you with this slide, but what this slide does, but what this But what this slide is saying is simply that only three things can happen for a set of twins. So it's either your set of twins has size three or it has size two. And if it has size two, then two things can happen here. Either, these are just spectral conditions. So there is an eigenvector that's not in the span of this set here, such that the youth and That the uth and these entries of w, one of them is at least non-zero. And if that happens, then you know that these vertices here are twins. And similarly here, I'm not going to bother you with this number theoretic conditions, but pretty much it's just saying that if one occurs, then the vertices in your twin set are not strongly cospectral and thus they are set. Strongly cospectral and thus they are sedentary. But for two, what you're saying here is that it is possible that U and V are twins and strongly cospectral, but still are sedentary. And that's exactly what the second part of the theorem is. Okay. Oh my god. Okay, maybe we should just skip this. But anyway, I'll do just the main idea here. Just the main idea. So. Here, this domain idea. So, okay, so we have our vertex in the graph, and we have its eigenvalue support, right? And if we have its eigenvalue support, if I can find a non-empty subset of my eigenvalue support, okay, and I take the sum of the youth diagonal entries of the E j, and I represent that as A, for example, okay, and I want this A, I want this sum to be between one half and one. Between one half and one. So that's how I choose a subset S of my eigenvalues. And if that case, sorry, this also holds for the Laplacian, in fact, any Hamiltonian, you can. So this absolute value will now be bounded by this function of time here. And so this will be useful. If this was large, for all time t, if this is larger than 1 minus a, then we know. Then we know that this will be bounded away from zero. So, sort of, this is just a strategy of determining sedentariness. It's just a necessary condition, not sufficient. If A is one half, this is not very useful, because if A is one half, then this is non-positive, and so we don't really get anything meaningful. And so, for example, if U and V are strongly cospectral, then you Then you there is an S for what if S is the plus or minus part of your support, then yeah, then A is one half and you get that this is non-positive, so it's not really useful. Okay, so this so this lemma is just used to provide bounds for sedentariness for twins. Um I'll just go through the corollary because that's what's interesting. That's what's interesting. So, if your twin set then is size at least three, then each vertex in your twin set is this much sediment. But if your twin set is the size two, and you have again this spectral condition here, then each vertex in t will be this much set entry. And this just follows from this theorem, because if this was two, this is just one, one minus one, zero, so you get twice the diagonal entry of that. diagonal entry of that. And yeah, just um this theorem is used to pretty much characterize sedentariness in complete multiparted graphs relative to the Laplacian. I was able to completely characterize sedentariness, Laplacian sedentariness in threshold graphs. So for threshold graphs For threshold graphs, we know that this could be constructed from an empty graph by throwing in an isolated or a dominating vertex. So, a connected threshold graph will have to look like one of these. So, if my graph looks like one of these, and I have a vertex u sitting in an mj or a k mj, one of these here, right? If my alpha j is the sum of m1, m2 to mj, then I know that this. Then I know that this quantity is bounded below by 1 minus 12. So this is now interesting because this can only be 0 if you are at the very first, if this vertex is at the M1, OM1 or O or KM1, right? And so combining this with the results of Zhao Hong from a paper a few years ago, we see that if these conditions hold, that's the time we get PST. That's the time we get PST. Other than that, we get the vertices, all vertices are sedentary. And yeah, I was also able to determine how sedentariness behave under graph operations such as partition products. So a vertex in a partition product is sedentary if and only if the components are sedentary in each of the graph. And as a consequence, A consequence of that particular we have that the Hamming graph is sedentary at each vertex when p is at least 3. Okay, we also have the same result, a similar result for direct products, which involves that the youth diagonal entry of your orthogonal projection matrix is large enough. So, pretty much the arguments just really revolve and change. Much of the arguments just really revolve on choosing what if you have an orthogonal projection matrix having a youth diagonal entry that's large enough, and sort of that forces that vertex U to be sedentary. And so here, the direct product of a complete graph by itself is sedentary, provided the mn is at least 3. However, if you take the bipartite double of kn, it's not sedentary. And yeah, this is just a result that says, well, the bipartite. And yeah, this is just a result that says, well, the bipartite double of Kn is not sedentary, and so I had to find a graph now whose bipartite double is sedentary. And that's basically just that. And yeah, for joints, we have this theorem that says that if I have a vertex that's sedentary in a graph and the sedentariness is large enough, it's like twice divided, sorry, two over the size of your number of vertices. Then in the joint, Then in the joint, okay, in the joint, U will be C minus this quantity sedentary. The sort of joints will preserve sedentariness if the C is large enough. And yeah, some open questions. We don't, you want to characterize sedentariness in trees, scale the graphs, regular graphs. Characterize vertices that are neither sedentary nor involved in PGS. Does the addition of a weighted loop induce sedentariness? So we're allowed to add loops. So in our adjacency matrix, we just add a weight on the youth diagonal entry. And is a dominating vertex in the graph always sedentary? Except for a star, of course. And yeah, I'd like to thank my supervisors, Steve Kirken and Sarah Foscar, the wonderful organizers for, as Sophia said, organizing. For, as Sophia said, organizing this workshop. My department and FGS, my collaborators, some of whom are here. And if you'd like to subscribe to Grass and Matrices workshop, then feel free to reach out to me and I could add your termination. And that's all. Thank you for your time. Are there any questions for Eric? So for your theorem, or the necessary condition of symmetriness, is it for any Hermitian matrix? I believe so. It should work. Any Hemot. Or at least any real symmetry. Okay. Yeah. I was going to ask about trees. How useful do you think it is to figure out trees? Trees. What was your? Can you go back to your result with the drink? I was asking how feasible is it to figure out sedentary for all trees? What was your result for the joint? So if the C is large enough, C greater than 2 over the size of the. But it's for any graph. Any gram. But it's for any graph. Any graph. Um for we we require for the adjacency we require that the xy regular. For the local sign it shouldn't work. So the question is Troy, do you have a tree which is set free? So like which vertice you'd have two questions. If you have a tree, does there exist a sedentary vertex versus if you when would you have all vertices be sedentary? All vertices be said in the earth? I wouldn't ask that question, but you might go for it. Well, it seems that for trees, I think PGST is more common because of the linear independence design. You definitely get PGST, you get time. Well, I'll try anybody about it. I mean, because you've got a lot of functions of PGST. So I think it will start waiting for the  So you kind of can't stop the