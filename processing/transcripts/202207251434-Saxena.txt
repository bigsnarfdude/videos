Had a lot of amazing ideas in this field, but unfortunately, we will not have time to cover all of them, and I will only describe the bare minimum that is needed to understand this one result. As you shall see, we shall soon actually strip out all the auction design from this paper and look at it as a purely communication problem and as a separation between two models of communication. So, let's start by defining our object of interest, which is automatic option. For the purpose of this thought, automatic Of this thought, a tomato auction is just a communication game between three parties. There is an auctioneer who has a certain set of items for sale, and there are two bidders, Alice and Bob. You can have more bidders, but we shall only look at two bidders. And both these bidders have as their input a valuation function. Alice has V1, Bob has V2. And what this function does is that it takes a set S of items as input and it outputs an Input and it outputs a number which is the value or the utility or the happiness that Alice and Bob get when they're given this set of items. So if the set S of items goes to Alice, then Alice gets utility V1 of S. And if it goes to Bob, then he gets utility V2 of S. And these players come with these inputs and they run a communication protocol with the end goal of outputting a welfare maximizing allocation. What is that? What is that? An allocation of items is just a partition into disjoint sets S1 and S2, where S1 goes to Alice, S2 rose to Bob. And the welfare for this allocation is just the sum of the two evaluations. So the welfare of S1 to Alice and S2 to Bob is just V1 of S1 plus V2 of S2. And we want to run a protocol that finds the allocation with the largest welfare. You can look at maximizing welfare. Can look at maximizing welfare exactly. You can look at approximate maximizers, and they're both interesting. We shall talk about both of them. But before we go there, I want to say a few remarks about the way I define combinatorial auctions. Firstly, I actually define combinatorial auctions without using the term prices, which is actually a sin because auctions are the whole point of the auction is generating revenue and you should have prices. But this is still okay because, like I said, very soon we. Still okay because, like I said, very soon we will just strip out all of auction designs. So, I will not need all those nitty-gritties of an auction about prices and everything. We will just work with these clean definition that does not have prices. Also, another key difference between protocols and auctions other than prices is that when you have a protocol, then all the bidders are cooperative. You have, when you design a protocol for a given function, you design one part of the protocol for Alice. One part of the protocol for Alice, and you design another part from Bob. These parts define how they send messages to each other. And if they're designed right, then the messages are all perfectly synchronized so that eventually they will output the value of the function on the inputs. And this is what happens in a protocol. And I will also use the word non-truthful auction to refer to a protocol. But in the auction setting or a truthful auction setting, the situation is different. In a truthful auction setting, there is In a truthful auction setting, there is money involved. And when there is money involved, Alice and Bob really do not have any incentive to follow the protocol that you specify to them. If you gave them a protocol that at some point, say, asked Alice to do some action eds, that ultimately leads her to get $5, and there's another action Y that she could have done at that point that ultimately means she gets $10, then there's no reason for her to choose X over Y. And instead, in an auction setting, we take And instead, in an auction setting, we take these incentives into account and we assume a situation where the bidders can deviate from the protocol as long as it gets them more utility or more money at the end. Okay. So in an auction or a truthful auction setting, the bidders can deviate from the protocol if it gets them more utility. In the non-truthful auction setting, the bidders always follow the protocol. And therefore, designing a truthful auction is at least as hard as designing a non-truthful auction. A non-truthful auction. Put another way, if you want to compute the same function, then a truthful auction will require at least as much communication as a non-truthful auction. And this question that we want to study in this paper is exactly how much more communication is needed. We want to ignore small polynomial factors and we want to know: are there settings where designing a truthful auction to achieve a certain welfare guarantee requires exponentially more communication than designing a non- Essentially, more communication than designing a non-truthful auction. This is the question. And we will look at this question from. Sorry, is there a question? Yeah, can I ask a question? Yes. Are you going to, I didn't follow exactly what was about truthful versus non. Are you going to give more details? And if not, could you repeat what you said? I did not follow what you're saying. Sorry, you're not allowing me. Could you explain what more we mean by truthful versus? More what you mean by truthful versus non-truthful? Okay. So the exact definition is something like: at the end of the auction, Alice and Bob leave with a certain set of items, right? And they're selfish. They want to get as many items as they want. Now, during the protocol, they may lie. They may lie if it gets them more items, because that's their goal. They want to maximize the amount of money they made. And an auction is truthful if it encourages the Encourages the participants or the bidders to not lie. It is in the bidder's best interest to always follow the auction specified to them truthfully and not deviate. And if you have this guarantee, then which is not an easy guarantee to have, then you have a truthful auction. Otherwise, you just have a protocol where you assume that things are as you specified them to be. Evaluation function on modify? Yes, that's a standard assumption. If you get like the If you get like the definite, I think the formal way to say it is that you have free disposal. So if you get extra items, you can just throw them away. And therefore, your value when you get a larger subset is only higher. And Raghuj, you said you won't mention prices, but I presume that there is going to be some money. Otherwise, there's no method to ensure truthfulness, right? Exactly. Yeah. So, yeah, I know. But you will figure out what I mean when I say I don't mention prices. Don't mention prices. There's no truthfulness needs prices to be well defined, but we will not get into that. Okay. So back to the slide. What we want is we want to study this question. Are there truthful options that require exponentially more communication than non-truthful ones? And we want to study this question from a separation standpoint. And when you look at it from this standpoint, you can basically classify all the work in auction design in three broad categories. The first category, Categories. The first category is the settings that are too easy. And here you can have everything that you want. If you want the truthful auction, you have it. You want polynomial communication, you have it. And you want welfare maximization. I give you an algorithm that maximizes it exactly. So this is everything you can hope for. You have exact welfare maximization with truthful auction and polynomial communication. But this is not useful for a separation because if it is easy, even for a truthful auction, then of course it's also easy. Truthful auction, then, of course, it's also easy for a non-truthful auction. There's no further separation. In fact, this result about VCG auctions is more general, and it says that whenever you can maximize welfare exactly by a non-truthful auction, then with a small overhead, you can also maximize welfare exactly by a truthful auction. So, this also means that if you want a separation, you want to look at approximation guarantees and say that for some approximation it's just bounded away from one, you have a separation. Just bounded away from one, you have a separation. This is the first set of results. The second set is the settings that are too hard, and here you basically don't have anything non-trivial. Something that you can always do, which is the trivial thing, is you can just take all the items you have and give them to a random bidder. You don't need any communication whatsoever. You just pitch a bidder random and give them all the items. And because there are only two bidders, this gets you a two approximation. Approximation. And there are known settings. An example is on the slide where even non-truthful options need exponential communication for anything non-trivial, for anything better than a two approximation. Okay. And because these settings are so hard, again, these are not useful if you want a separation. Because if you want a separation, you want something that is easy for non-truthful auctions and it is hard, exponentially harder for truthful auctions. So both these settings are not. So, both these settings are not good for a separation. What we want is: we want settings that have just the right level of complexity. We want settings where the guarantees achievable by the state-of-the-art truthful auction are strictly lower than the guarantees achievable by a state-of-the-art non-truthful auction, and hope to show a lower bound showing that the guarantees, the high guarantees that non-truthful auctions have are not possible by truthful auctions. Okay, one such setting is the setting where Alice and Bob's. Is the setting where Alice and Bob's valuation functions are what are called XOS. A function is XOS if it is the maximum over a set of additive functions. And for this setting, there are other settings too, but this is the main setting that we shall work with. For this setting, the best guarantee achievable by a non-truthful auction with polynomial communication is three-fourths. It's known to be tight. While the best truthful auction is just a trivial half-approximation that takes all the items. Approximation that takes all the items and gives them to a random builder. This means that if you're able to show that no truthful auction can get a three-fourths approximation with polynomial communication, then you're also able to show the separation you want, that truthful auctions need exponentially more communication than non-truthful auctions. This is exactly what we show. We show that when the valuations for Alice and Bob are XOS, then any truthful Then any truthful option with polynomial communication can only offer 179 over 240, which is less than three-fourths. This is 180 over 240 approximation guarantee. Okay. This is, again, a function is XOS if it is the maximum over a set of additive functions. And I want to emphasize that this is the first separation between truthful and non-truthful options. It doesn't really matter if you take HOS functions. matter if you take XOS functions or any other class. XOS is a very natural class, but you can even take contribute classes. It does not matter if you take two bidders or three bidders or n-bidders. You can take basically any game threatening that has been studied and you will still not find a separation between truthful and non-truthful implementations. This is the first one. Okay, so this is the main result. And what I'll do next is I will go over briefly the steps in the proof of this result. Briefly, the steps in the proof of this result. So we start from here, and we ultimately want to show that the approximation guarantee that is possible by a polynomial communication truthful option is strictly smaller than three-fourths. And because this is a separation result, we need to use this truthfulness in the lower bound. We need to use the fact that our lower bound should not apply to general non-truthful options. And Raghuvich, when you say polynomial, this is polynomial. Say polynomial. This is polynomial in what parameter? You have a set M of items, and I want it to be polynomial in M. Yeah. This M is the parameter. That's a good question. I should have mentioned it. So is the complexity of the valuation function not, does that play a role? Or like, is it any XOS function or is it something or is it some particular very natural? Or is it some particular, very nasty one where you need a lot of bits to specify? So the bit complexity actually would not be the reason the lower bound holds because our lower bound would hold even if our function is what is called binary XOS. An XOS function is the maximum over additive functions. A binary XOS functions is a maximum over additive functions where each coefficient is either zero or one. Perfect. So all the terms very small. Yeah, very small. Okay, thanks. Um, uh, I was here, yeah. Okay, so we want to show that the guarantees achievable by truthful auctions are bounded away from three-fourths. And this lower bound crucially needs to use the fact that the auction is truthful. And this part of the proof is because of an amazing result by Shahar Dobzhinsky that shows that if you have a truthful option with a certain approximation. Auction with a certain approximation guarantee x, then you also have a simultaneous auction, which may or may not be truthful, with the same approximation guarantee. What is a simultaneous auction? A simultaneous auction is the same as a regular auction. You have two bidders with inputs and you want to allocate a set of items, except now there's only one message from Alice and Bob sent simultaneously to the auctioneer. You have one round of communication, Alice sends a message, Bob sends a message, then the auction terminates. Message, then the auction terminates and the auctioneer determines the output. Okay, so if you have a truthful auction, Dobzhinsky's result says that if you have a truthful auction with a guarantee, then you have a simultaneous non-truthful auction with the same guarantee, which when you look at it in the contrapositive, it means that if I show a lower bound that any simultaneous auction cannot have a guarantee better than three-fourths, I also get that any truthful auction cannot have a guaranteed better than three-fourths. Three-points, and this is where auction design is completely out of our picture. Now, now, all we are looking about is non-transferable auction is just a protocol. All we are looking at is you want to show a separation between simultaneous protocols and general protocols for this one problem of welfare maximization in this dominant auction setting. Okay, so now on there's no prices, there's nothing, it's just a communication game, and we want to show that simultaneous protocols have a strictly lower. Protocols have a strictly lower guarantee than general protocols. Again, for this part, also, there's another result. And this result is another great result by Mart Braberman, Ji Ming Mao, and Matt Weinberg. And they show that for the decision problem, indeed, simultaneous auctions cannot get a guarantee better than three-fourths. What is the decision problem? In the decision problem, you have the same inputs, but now the auctioneer does not have to. Now, the auctioneer does not have to output a set S1 for Alice and a set S2 for Bob. All the auctioneer needs to do is to decide whether the maximum, the highest possible welfare is at least one, which is the high case, or is it less than three-fourths, which is the low case. Okay, so he does not have to determine the allocation. He just needs to evaluate it and see if the welfare is low or high. And what BMW show is that the decision problem is hard, it needs exponential communication. It needs exponential communication to decide between, to distinguish between low and high with any non-trivial advantage. Okay? Now, this should prick up your ears a little bit because usually when you have a decision lower bound, it also implies a search lower bound. Searching is harder than decision, so decision lower bounds imply search lower bounds. So, why am I saying what is the whole point of this work anyway? The reason is for simultaneous protocols, it is not the case that decision lower bounds implies. Case that decision lower bounds imply search lower bounds. And this is because the trivial way you will get a decision lower bound is: you will first solve the search problem, then you will need one more round of communication to evaluate it, and then you will find the answer to the decision problem. And this extra round kills the simultaneity of the whole setting, and we cannot have this reduction working as is. So, the main step in our work is to show another way from doing for going from simultaneous lower bounds on the decision problem to simultaneous lower bounds. On the decision problem to simultaneous lower bounds for the search problem. And what we actually do is we show that you can take two copies of the decision problem and massage the whole proof to get ultimately get one copy of the search problem and get some lower bound on that. Like this constant less than three-fourths is actually weaker than this constant less than three-fourths, but they're still both less than three-fourths. Okay, so let's see this idea in action. This idea in action. And this is a very contrived setting that has a weird restriction that I will say meds. But this will give you the gist of the whole idea. What is happening here is I take two copies of the decision problem, and now the auctioneer therefore has two sets of items. Alice and Bob also now have two valuation functions. Alice has U1 and V1. U1 is for the first copy. V1 is for the second copy. Bob has U2 and V2. U2 is for the first copy. V2 is for the second copy. And what I will ensure is that And what I will ensure is that the functions u1 and u2 correspond to a low instance of bmw. They do not have high welfare. While the functions b1 and b2 correspond to a high instance of bmw, they have a high welfare. And my restriction would be that the auctioneer can only allocate items in one of the two topies. It can if he wants. He can decide to give Alice a set S1 and Bob a set S2. They're contained entirely in this topic. He can also give them sets that are contained. He can also give them sets that are contained entirely in the first copy, but what the auctioneer cannot do is give them sets that are partly contained in both of the copies. And with this restriction, the lower bound holds because in order to generate a welfare, a high welfare allocation, the auctioneer at least needs to decide. Oh, I forgot to say that low and high is not fits. One of them is randomly selected to be low, the other one is randomly selected to be high. In order to give them a high welfare allocation, the option. High welfare allocation, the auctioneer at least needs to decide which one is the high welfare set copy. And we know by BMW that this decision problem is hard. So because the auctioneer cannot decide this, he cannot generate a high welfare allocation, and therefore we have the lower bound. Okay. Now, this is the lower bound in a restricted setting. How we go from this setting to a general setting with only one set of items and only one valuation function. Let's do that next. Let's do that next. Let us now have only one set of items. And let us first deal with the two valuation functions. This is where we will use the fact that the valuation functions are XOS. Recall that an XOS function is maximum over a set of additive functions. And if you have two different HOS functions, then the maximum of these two is actually another XOS function because the set is just a larger set. And having two different functions is the same as because you'll always pick the higher one. Because you'll always pick the higher one as having the maximum, and therefore this is also HOS. So, this part of the left part of the picture is still legit, even without the restriction, but the right part is not. Earlier, you had two sets of items, now you had one, and now you need to make the whole argument work with only one set of items. And for this, I would want to examine where did we use the fact that there were two different sets of items, and how can we make it work with only one set of items? Now, the place where we used The place where we used the fact that there were only two sets of items is we wanted the referee to determine one of the two copies. We wanted him to say that if Alice is using U1, which is the low copy, then Bob must be using U2, which is also a low copy, and therefore you have a low welfare. And again, if Alice is using V1, which is the high copy, then Bob must also be using V2, which is also a high copy. And he cannot tell which one is which, which is the lower bound. Okay. Lower bound. Okay. Now that you don't have this restriction, this is no longer the case. Now, what may happen is maybe Alice always uses the low topy U1 and Bob always uses the high topic V2. And because they are taking things from different topies, you have no guarantees and the overall welfare turns out to be high. In fact, this is a very serious problem because I don't even need one of the topies to be low and the other one to be high. What I can have is a situation where you Have is a situation where u1 and u2 are low topies, the welfare is low. V1 and v2 are also low topies, the welfare is low. But all the cross terms, when you take u1 from this topic and v2 from this topic and v1 from this topic and u2 from this topic, are high. They have high welfare. And next, we shall see an example of how this may happen. In this example, there will only be 12 items, and the functions will just be set functions. If Alisteth's set S of items that Gets a set S of items that has three items that are red, then she gets value three. And if Bob gets a set that has four items that are blue, then he gets value four. Okay, so they just count how many items are in this special set. And for this situation, the optimal welfare is the union. So here it is eight because the union is one to eight. And the optimal welfare is therefore eight over 12, which is two over three and is less than three fourths. This is a legit low instance. Similarly, Instance. Similarly, I take another instance here where Alice has the set 7 to 12 and Bob has the set 5 to 10. The union, which is the optimal, is 5 to 12, which again has eight elements. And this is a legit low instance because 8 over 12 is again less than two-thirds. But if you look at the cross terms, then the union of this set and this set is actually 10. You have six here and seven, eight, nine, ten here, which means you have 10 elements. Here, which means you have 10 elements, and the 10 over 12 is more than three-fourths. So, and the same applies here. You took two load copies, but the cross terms were high welfare, and this is the problem. Now, you can complain that I took these two to be disjoint, and therefore this is happening, but it's not about, it's not really about that. If you choose these sets independently, because they're both independent, then two sets of size half will intersect at roughly three-fourths, at roughly one-fourths, and therefore the union will be roughly three-fourths. And you will still have. And you will still have this problem. And the way to solve this is to have these sets be carefully designed to also have low intersections with the cross terms. So what we do in the paper is we change the setting copy, we restrict it to only have a small number of possibilities given the first one. And we design it in a way so that the cross terms are also low. As an example, if you keep the first topic like in the previous example, one to six and three to eight. 1 to 6 and 3 to 8. Then, what I want from the second copy is Alice has this red set, which is 2 and 5 to 9. Bob has this blue set, which is the shaded one. And you can verify that the union of the cross terms. Sorry, firstly, the union of these two sets is eight, which is as before. This is also eight, as before. And moreover, the cross terms also have a union of eight, which is again two-thirds, which is less than three-fourths. And the same goes for the other set of cross terms. For the other set of prostrums. So, all the four prostrums are low, and this choice of correlations is what is implying that these are low. And this is what we need to do to get a lower bound. But this is not all of it, because I started with both the cropies being low and it designed cross-terms to get low trosterms, designed the sorry, designed the croppies to get low trosterms, and both of the individual croppies are low. But in the actual argument, In the actual argument, one copy is low and one copy is high. And I need to make this work even if one of the copies is high, I want both the cross-terms to be low. This requires more work, but you can design sets like this. And the next thing I want to say is because one of the copies is high, what we know is that the decision problem on this set is simple. The auctioneer simply outputs high. He always knows there's a high copy and he can just output high. Knows there's a high copy and it can just output higher. So we had the proof by BMW that was working for decision but not for allocation. We were able to extend it using two copies to get a proof for the allocation that is not working for decision. And this is very interesting because neither of the proofs imply the other one. Okay. There have also been follow-up words on this, which try to get better and better separations. They look at functions instead of Functions instead of getting just an approximation, they want to see exactly how the items are allocated instead of just the welfare and their results to that end. But still, some lines and some questions are open. And one big question that is open is we did show that truthful auctions with polycommunication on XOS valuations do not get three-fourths. But we still don't know how, what is the right answer for this set of functions. And we actually don't even know if there is anything non-trivial that we can do. Is anything non-trivial that we can do? The half approximation that we have is trivial. You just give all the items at random. And this is the state of the art. We don't know how to get half plus epsilon using a truthful way. So I think this is a great question that I hope to see resolved some point. Okay, so that's all I had. Thanks for listening. I do have one question, Rob Wanj. Can you hear me? Yes, I can hear you. All right, perfect. So, in this follow-up works that you are saying, is there any result that holds for multiple number of players now? I think one of them, this DR21 has results for multiple players, but I'm not, I am not like, don't have them in memory right now, so I cannot like tell you what they are. But I think this. Tell you what they are. But I think this DR21 had some results on multiple players. What is, can you say, spell out what is this citation? This is Shahar Dobzhinski and Shivi Ron. And I think the title is the Communication Complexity of Payment Computation. Yeah, exactly. Perfect. Thank you. Yeah. So yeah. So the valuation functions The valuation functions are, you know, XOS, binary XOS, but obviously, in order to get exponential communication, you're going to need basically an exponential number of linear terms in each of the valuations. Otherwise, somebody could just send their valuation function, at least in this communication model. So, in the actual truthful auction model where you have prices. Model where you have prices, you wouldn't want those to be revealed in the communication to because that might give things away for the other player, for example, was broadcast communication as opposed to simultaneous. So if the XOS function has a, as an efficient representation, is there what's known in the general function? What's known in the general truthful auction setting where you actually have prices and you have to worry about other players in the truthful auction? Is anything known in that setting? This is actually, so maybe I was misleading. I did not say that our truthful auctions don't have prices. We have the standard notion of truthful auctions. What I meant to say is that for this proof, we will not need to know exactly how the price works. Will not need to know exactly how the price and the truthfulness work. Sure, sure, yeah. Go ahead. So you can have any truthful option you want, but this result will still hold. You will not get anything. Nothing is known better than one half. Even if the valuation function is given by, so obviously you could do it, like in this communication model, you could have a polynomial communication by sending your valuation function to the auctioneer, right? To the auctioneer, right? In this model. Yeah. But if you had the model where, you know, there's a protocol you're following, and it's polynomial size. Could you not, I mean, what's known in that scenario if the XOS function has a polynomial size representation? Okay, so let me see. I think again, this is off my head, so let maybe it's not true, but I think there is even if you allow like this tomatoic model is at least stronger than demand queries, because by posting prices, you can actually run a demand query. And I think even if you restrict to the weaker model where you have demand queries, We did not have a lower bound before. So, this was the first one in that sense. And other than that, I'm not aware of any options that use the representation of the function. Like, I know you can have a value oratal model or a demand-oriental model. And I know that this was, even if you consider demand periods, there was no known lower bounds. But other than that, I really don't know a lot. Don't know like a lot. Okay. Yeah. I was wondering. Okay. No, I was wondering because obviously you can't ask that question in the in the in the particular lower boundary model you've got. Yeah. So Paul, I sorry Rawange. Let me add this thing here regarding your question. If you can represent it in polynomial time, it means that you have a polynomial communication problem that solve it exactly, maybe in exponential time, but exactly with polynomial communication. Exactly with polynomial communication. If you have something like that, you can apply VCG on top of that, which will make it truthful as well. Ah, okay. I see. So VCG will give you the problem with VCG is that it will not be efficient, let's say, in terms of time, but in terms of communication, it remains efficient. I see. So the auctioneer couldn't run VCG. Is that the issue? Or is it? Yeah. It can. Yeah. It can. Now the auctioneer can run VCG. The players will just send their. Well, you have to run VCG. The players send their representations. VCG tell you how to give them the correct prices so that it remains truthful. Sure. So in the communication model, you could do it, but in reality, you can't. That's that's your because of the computation. Sure. That's true. Okay. Thanks. Great. That's exactly. And actually, in the communication model, because you only have two videos, I think. Model because you only have two videos. I think you only need to run VCG like three times. So it's not constant over even. But yeah. Okay. Maybe one more question. What happens if you're not assuming that your value functions are bullet? Like, for example, some items are not automatic, so you don't want them actually. Some items are rotten tomatoes, rotten tomatoes, so like it's not monotone function, so it's your value. But that only makes it harder, right? If you have a lower bound without monotone valuations, then with monotone valuations, you also have a lower bound with general valuations. Yeah, but in this case, for example, don't have a one-half process. Have a one-half approximation, right? Oh, I see what you're saying. Do you not have one-half approximation? I don't know. Maybe you can say, like, maybe both Alice and Bob can say the set they value the most, and one of them gets the set they want. Like, you look at all the sets you can get. Our self-worth will be identical, right? I would send it to metadata, right? For our partner. No, no, the other one will not get anything. No, you can. I thought you have to split those items. No, no, you don't have to. You cannot sell some items. Like, it is monotone, so I can assume you have to allocate everything, but in general, you don't have to. You can just give a set S to Alice and a disjoint set to Bob. Okay, so it's like. I guess what he's suggesting is that you do have to. Suggesting is that you do have to get rid of all the rotten tomatoes. Yes. So you have to split it. You have to. If you have to split it like that, it does. I don't know. That sounds like a very hard problem, even communication-wise. Yeah, I don't know any results I know assume monotonicity. Assume monotonicity, and they also allow you to keep items if none of the parties want them. Okay, let's thank our once again. So we'll be back in 25 minutes or so. I'm not sure to not care.  We're going to need on a different text moral range where I am access to. I think that is actually a lot of all the stuff.   I was thinking I'm still frustrated with how much I would get all of those exactly all of us. Finally, it's my excuse for being lazy for the like the progression of this policy. I have a part of the group of the I did listen to how it's overcome. It's like this last talk too, this idea of pushes and other stuff. Yeah, but there was a lot of models that can be done. For agnostic learning, you're learning all of the functionalists almost functional. I don't know what this is when you fall in the idea since it's not easy to track so bringing a lie to be clicking. One two-way to explore the cities, how we to explore the space.