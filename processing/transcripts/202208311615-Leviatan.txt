This is kind of an old subject I'm interested in, but up until now I worked with algebraic polynomials on a finite interval. And it turned out that this will bring various interesting questions into discussion. So I am going to concentrate more or less on the new points and not really prove the whole. Really prove the whole thing. Well, I will not have time for that. This is a long, very long proof. So, let me start. We take c tilde to be the space of two pi periodic functions f and down with the maximum norm and denote by omega k the kth modulus of smoothness of f. And then, if we add a super r, then we mean the subspace of continuously differentiable functions. Of continuously differentiable functions in SC tilde, and Tn will be the usual trigonometric polynomials with degree less than or equal to n. And given a set Y sub S of two S points in the interval minus five pi here, and S is greater than or equal to one. This is very important. Okay, here, s is greater than or equal to one, and we put them in this order minus pi is less than or equal to y1, and then up to y2s, and then pi is greater than y sub 2s. And we denote by delta 2 of y sub s the collection of functions which Of functions, we change convexity at the points y sub s, and such that minus 1 to the i minus 1 f is convex in the interval yi minus 1 to y i. This just means that I take one of two collections, namely the one that is convex near pi, and then changes the convexity. Okay, and then since we are talking, oops. since we are talking oops since we are talking about the whole straight line then here i extend the y sub s to the whole minus and infinity infinity by moving the points accordingly okay now just a notation the usual notation of the best approximation best approximation Best approximation of the function by trigonometric polynomials that follow its shape, namely change convexity exactly at the points where the function does. Okay, and then yeah, the best co-convex. We call it co-convex because it follows convexity of the function. The function. All right, and what we will be interested in is a general Jackson-type estimate of this type: namely, if f is in CR and delta 2 of y sub s, I ask whether we can get an estimate of this type. Namely, this is kind of ordinary Jackson estimate, which is always best possible, although. Always best possible, although it's never best possible. In other words, it's always best possible in the sense that you can find a function which gives something the worst here, but nevertheless, since if it has higher derivatives, you can improve, etc. But everybody knows that. I don't have to repeat. And not necessarily from n equal k or k plus 1, as may be the case with non-confusion. Maybe the case with no constraints, but some n, and you will see that this n is not so simple to get. Anyway, so the constant n may depend on the various parameters, maybe also on f in general, but no, I don't want it to depend on f. Okay? Then, of course, not on n. All right. All right, now we emphasize that S is greater than or equal to one. That is, F changes its convexity at least once in minus five pi. Mostly it will change twice. But if the change of convexity is at the end points, then you don't see it in minus five pi, so but at least once. And the reason is very simple. Purely convex. Convex periodic function on minus infinity are the constants, nothing else. So there is nothing to work with, and so on. So we need at least one change or an S greater or equal to one. And the other point, do I say it here or later on? Yeah, no, I will probably it's down here. I want to. I want to explain that the algebraic case, which started with Lorentz and Teller, and the real progress was made by DeVore in the monotone approximation case. And the first result in convex approximation was mine, but this was already in the early 1970s, mid-1970s. And from there, then we move to functions that change monotonicity or convexity or higher order monotonicity. I will mention it at the end of my talk. But this waited because there was nothing to do with the monotone or convex. Now, I will not discuss monotone due to various reasons. I will discuss only co-convex approximation. Only co-convex approximation. Or K. Now, here is what I thought I said up there. Y sub s must have an even number of points, because if it has an odd number of points, let's call it y, not y sub s, then abusing the notation a little that regonad polynomials are constant. Yeah, the change the convexity an odd number of times. Only constants do that. And therefore, we cannot approximate more than just by constants. It's not interesting. Okay. The next thing is in recent years, some Jackson estimates, and I don't underestimate them. Estimate them. Funny. By some Ukrainian mathematicians, Jubenko, Zanisko, a few guys, managed to prove this estimate that one can get an estimate like this for a function merely continuous. A function merely continuous, but n depends big n capital N depends on the points where the convexity changes. Now I say but but this will be our case. We cannot do without the dependence of y sub s on the points of change of convexity, contrary to the algebraic. The algebraic case, where some cases capital N depends only on the number of changes of convexity or monotonicity, and not on the points where the changes occur. Others need the points where they occur. All right. So, what I want. Well, the guy is not here. It's not moving. Let me. Oh, he does. Oh, now it moved too much. Okay. Ah, yeah, yeah, okay. Yeah, all right. Yeah. All right. So what I want is a result of this type. Of this type, any k in n, namely one, two, three, etc., are greater than or equal to three, and s greater than or equal to one, there exists a constant, an absolute constant depending on these three parameters, such that if f is in this class, r continuously differentiable, and delta two. differentiable and delta two of y sub s then we have such an estimate i'm interested in in this in in this theorem in other words i will not prove it but it's correct i what i will do is indicate some points in the proof because it's very very long but this is a proof and this is a theorem by okay and Okay, and note that in this form, if we go back to omega 3 due to properties of the modulus of smoothness, we cover K and R in this line, 3, 0, 2, 0, 2, 1, 1, 0, 1, 1, and 1, 2. However, we don't cover the case 2, 2, namely k equal to 2, r equal to 2 in this theorem. In this theorem, because r is greater than or equal to 3. And so here. So, and we have a second result, again, a theorem. This time, the function is twice continuously differentiable and in our class, and we have this result. This result, an estimate involving omega 3. Remember that before we had any k but here, just omega 3, namely also omega 2, because omega 2 is bigger than omega 3. And this is the 2, 2 case that was missing before. But otherwise, the third modulus of F double prime, fourth modulus. Fourth modulus doesn't work. Okay, and here I mentioned the 2-2 case. Okay, so here are the negative results. We can do better than any of the things that I mentioned in the theorems. Namely, N is not, cannot be made independent of what. made independent of y sub s. And one can show that there exists a positive constant no matter what k greater than or equal to one, r greater than or equal to zero, and s greater than or equal to one, and such that for any n, there is a collection and a function in our class, different function and different collection for Collection for different ends such that this inequality holds. You see, we are missing one power of n in the denominator here. Okay. Okay. Moreover. Moreover, if k is greater than or equal to 4, then the second theorem is invalid for omega k, as I said already. And even if we allow n to depend on f, in other words, not only y sub s, yeah. Yeah. But the upper estimate was with n to the r in the denominator. It was from above. And this is from below, and this is bigger. Yeah, this is bigger. In other words, you cannot. Let me go back. Let me go back here. You see the upper estimate. It has n to the r here. Yeah, so if this is. Yeah, so if this is bigger than something with n minus one, n to the r minus one doesn't work. Yeah, yeah, yeah. Going forward is a problem to me. Okay. So if r if k is greater than equal to four, then we can get something like this. Something like this. For any r between zero and two, we have a function in our class such that this limb soup is infinite. You see, so this is just a single function. Previously, we needed a different function for each y sub s and n. So who? So, who knows? It may depend on F, but no, here this doesn't depend even on F, the N. In other words, you have an F, okay, some N will do it, but no. Okay, the next thing. Okay, so basically, what we are going to do is we are going to approximate this function. This function by first by a continuously differentiable 2Ï€ periodic pieceway algebraic polynomial that follows the function. Algebraic, I repeat. In other words, a normal thing that we call piecewise polynomial. I have two reasons for that. One is that for that, I have already a good approximation. And the second is that I and it. And the second is that I, and it was a lot of work to get the algebraic case. And secondly, I don't really know how to put something like this in the trigonometric setting by itself. So I will have the algebraic polynomial replace it by a trigonometric one. Okay. And then, so the algebraic polynomials will be piecewise. The trigonometric polynomials will be. The trigonometric polynomials will be trigonometric polynomials. Okay. I will skip many details. I will not now, I will not, I have already, yeah, I said that I will not explain why we need the peaceful polynomials to be continuously differentiable. I take back this. I'm going to say something about this. When I read it yesterday evening, I said, Read it yesterday evening. I said, Well, I actually should explain a little, but only a little because I don't have the time. I need half day or a week or who knows for that. Furthermore, the construction polynomial, the trigonometric polynomials will be very, very complicated to really go into the details. I will concentrate on a few points which I believe are Which I believe are of interest by themselves. Certain types of approximation that I will introduce. And okay, so let me go back to the interval minus i pi, and here is the Chebyshev kind of Chebyshev partition. If we take the cosine, but If we take the cosine, but we don't. So xj is j pi divided by n. I sub j is the interval x j x j plus 1. And actually, right now I'm taking all j, so I'm not taking the interval minus pi pi, but I will take it shortly. And we take algebraic polynomials of the following type. They have knots at the x sub j's, and those And those that will be in our class, I want the piecewise polynomials to agree around the changes of convexity. In other words, around the inflection points. This comes into what I say here, that we want if we denote the polynomial P. Polynomial piece by p sub j and y sub i is in this interval, then we want the two, the three polynomials to agree, b sub j and those on both sides to agree. In other words, I don't want something to change there. I want it to go smoothly through the inflection point. And I want, can I? Want? Can I get something out of it? So, and then, all right, I'm going to denote by, to put a tilde on the sigma if I have the subset of two pi-periodic such algebraic piecewise polynomials. Okay, so the first thing, okay, and now I'm going to talk about minus y pi. talk about minus y pi so i add an i here to the restriction okay because on i i have good approximation by piecewise algebraic polynomials following the changes of convexity of a function of a just a continuous function on that interval so here is the Here is the theorem that Shevchuk and I proved already quite a few years ago. If either r is equal to 2 and k is less than or equal to 3, or r is greater than or equal to 3 in any k, remember that these are the two theorems that I had. If a function f is in c F is in C R of the integral minus pi pi. I don't need the tilde and I will not have it. Oh, but I will have something here. Then for each n sufficiently large, and this depends on y sub s, there is a piecewise algebraic polynomial in our class. Notice that I have here the degree of the A degree of the or the order of the p-strice polynomials k plus r but it follows our function our changes such that we have these two important properties one is well i'll first go to the bottom one one is the proper order of approximation that we want Approximation that we want, but notice that it's in this interval. We don't need the whole modulus throughout the minus infinity, infinity. We are working in that interval. And very important is that the derivative coming to pi plus. Plus I'm sorry, coming to minus pi plus is bigger than the derivative of the function at minus pi, and the derivative at pi minus is smaller than the derivative of f prime at pi. Okay, so we have such a function. Obviously, it is such a piecewise polynomial, obviously, it's not even periodic. Not even have the same values at both ends before extending it, right? After all, these algebraic polynomials, and we were not interested in more than that, and we don't have more than that at the time. We didn't have. Okay. However, it's easy to modify it and to make it by a small change, namely the linear. namely the linear connecting minus pi s of minus pi and pi and s of pi and then we get a function a piecewise polynomial which agrees on both ends and due to the what the properties that we have had this exists and now since I want to extend it I will not use i any longer I will not use I any longer, so here it is without the I. And at the same time, and this is very important, we have this inequality at the end points, namely the derivative at pi minus is smaller than the derivative at minus pi plus. So now what happens? We have happens we have we have now the function piecewise polynomial but the function which has to continue upward the derivative has to continue upward beyond pi oh that's fine it's periodic so beyond pi it's s it's s pi plus S1 prime pi plus beyond pi also because minus pi, you add to pi, you are at pi. And so it continues convex there, which is what the function does, right? So this now we can extend it to the whole real line. The whole real line, and most more, more important, it's not written here. No, but so I'll say it, but maybe it's written in the next transparency. We get it to follow the function throughout minus infinity, infinity, the convexity of the function. Convexity of the function. But it's not necessarily continuously differentiable, and I need that. But I'm very limited on time. It's already 20 minutes only. So I will rush through this part. So we need that, and it turns out that this can be done. In other words, we can replace. In other words, we can replace the function by a piecewise polynomial which is differentiable in minus five pi and be close enough. Namely, what we get is this theorem that we can get a function of our type, what we need, but also differentiable. Differentiable and not far from S, but S was very close to our F. So this one will be close to our F. And notice, though, one thing that maybe I should mention is that the differentiable one has two N notes, not N nodes, but this doesn't make a big difference in. A big difference in the parameter that we have here. Okay, so and then, all right, so you see that if I take a function S1 in sigma tilde prime of k plus r 2n, which is therefore close to my s1 was in sigma k plus r. Sigma k plus r. Then I have this inequality due to what I have written previously. Then I replace it by this, and eventually I can replace it by this. And last on this is the fact that S1 tilde is close enough to F due to the fact that S. F due to the fact that S1 was close enough to F. Okay, so now why do I need this S continuously differentiable, S1, continuously differentiable? Basically, I want the second derivative. And obviously, I don't have a problem with the second derivative between the knots, and I will not have a problem. And I will not have a second derivative at the knots, but I need the function to behave well enough. So I need S prime to be continuous. Okay? This is something that I did not write down because I decided only to add a word to it later. Okay, so now what I want to discuss is the the main thing. The main thing. You see, we are allowed to take n to depend on y sub s, and of course on k and r. We take it so big that the y's are separated by at least 5 pi over n for n which is bigger than this n. All right, and the reason for that is that what I want is to kind of is to kind of separate two sets. If y is in the interval x i j a j i x i j i plus one, I want to remove for some reason the discussion in the bigger interval. Remember that we had the polynomial continue on both sides, basically. Sides, basically. And this is the interval where it continues. And I call O the sum of all these intervals. And these are a small set, eventually, because we have two S y's and we take three intervals around each of them. So in each interval minus one pi, it's a small Small set. Most of them are in age where the intervals do not intersect AO or omicron, as we said yesterday. So, O All right. So, and then I define pi of t as a product of the sine functions. Of the sine functions at t minus yi, so they change the sign exactly where the y sub i's appear. They change from one sign to another when t goes through y sub i. Delta is a sine, and the sign changes with the convexity. Convexity. I need these two quantities at the bottom here, especially this one. You see, this one says that we are not near X sub J. This is going to be very small because we have any denominator, and if we have a high power of it, it will be very, very small. And I will need that because I will. And I will need that because I will need my polynomials to go down very fast as I move away from my problematic points. Okay, so now I need for some reason to move a little from my original intervals. Where is? Oh, here it is. Oh, here it is. It changed. And I'm taking x sub j minus pi over 2j, not where I move halfway for each of them. And then here, look at the two polynomials that I have. I call them hybrid polynomials. They have a trigonometric part. But they have a polynomial, an algebraic polynomial part up to degree two, x and x squared. And what I'm going to do is to approximate the step function, the algebraic step function in this interval. By these two polynomials, and at the order, at this order, remember delta J was from the previous transparency, the derivatives of the polynomial, of these hybrid polynomials will behave. You see, this one, remember, we multiplied by some. Remember, we multiplied by some pi of x. Since I'm not going into too many details, it's not important that I go back now to show you what it is. But remember, it was on the previous transparency. And so this one, this derivative is going to be small, and this derivative is going to be kind of large throughout the real line. And last but not least is the following that tau j double prime follows the sine of pi of x. And remember, pi of x, it changes its sign exactly at the y sub i's and multiply by pi sub x. Multiply by pi sub x j, this is not important. This will be positive throughout the real line. This will be negative on the real line outside of the intervals that I mentioned before, the i tilde, namely moving halfway. Okay, so this is a Okay, so this is a theorem that will help me. I'm not going to go into any of its details, but I'm going to show you some things that related to it. And this is the theorem that I have to use. Ah, well, I should have said one more word about the second derivative of the piecewise polynomial. What we do at the end. At the end, we have two parts of the real line, collection of intervals on the real line, those on which the second derivative of the piecewise polynomial is small, and those on which the second derivative is large. And we treat them differently and separately. Differently and separately. And we approximate the second derivative on the first second derivative, second derivative, of the two derivatives. Now, when we integrate, they add up to be the original function that we had, right? But this means that each of them Each of them will have an extra x squared times some constant, one with plus and one with minus, because it has to disappear from this. So we need hybrid polynomials to work with. So here is the result that we have. We are going to approximate a function f F which is a sum of g plus ax squared and this function will be in our delta 2 y sub s not not g, but g plus a x squared. So this means that the inflection points move somehow, yeah, because somehow, yeah, because second derivative of ax squared is 2a, right? And so this will change. a is a constant. If a is zero, then of course we are in the previous case. And we are going to approximate them this function for large enough n again by a hybrid polynomial of this form with the same a. And t sub n of x is a trigonometric polynomial of some degree, not n, but c times n when c is a constant. And at the same time, what we'll have is the second derivative of q sub n follows the signs of the changes of convexity. Remember, delta was the sine of pi. Of pi of x, capital pi of x, and it will be close enough to the function f. We will apply it, as I said, to the integration of the second derivatives of two different piecewise polynomials. I will not go into the details of selecting the intervals and how small and how what is small and what is big and so on. Too much work for a short time. Time. Okay, so I'll give you a sketch of that proof. And you see, if we denote by delta sub j the second difference, then of course it is bounded in absolute value by omega 2 of f, which I will denote by omega. And then I'm And then I'm going to define my collection of tau sub j's. Now, for most j's, j star will be j. This is if j is in age. Remember, these were the intervals far away from O, from the kind of bed part where if the function changes, it's convex. The function changes its convexity. And if j is not in age, then we'll take the closest J in age and call it J sub star. And we will select it. I'm sorry. We'll take J star in age to be such that this inequality holds. And of course, J minus J sub star is equal to 2. In other words, it is. Is equal to two. In other words, it is the closest, but I am not taking just anyone, I am taking the one of the two on both sides that will satisfy this. Because you understand that there, I don't know, the difference doesn't have to follow the sign that I need. And so I want to make sure that what I take is something that follows. What I take is something that follows the sign that I need. Okay, and all right, it turns out that the delta j star is bounded by nine times delta j, so I don't have to worry about this. And then notice that by Whitney inequality, a piecewise linear S that interpolates F at all points. f at all points in the interval minus y pi will give us distance omega, omega 2. This was omega 2 of 1 over n pi over n, I'm sorry. And its presentation on the interval minus five pi is like this. Okay? So I'm going to replace the piecewise. Piecewise, what is it? Well, x minus xj plus. How do you call it? Well, whatever. I'll replace it by tau sub j star. Remember that we, yeah, okay, I have one more page, I think. One more page, I think, and so here is the replacement. Okay, so now since we have these properties, V double prime follows the sine of pi of x, and therefore v is co-convex is what we need. What we need, and also it is of distance constant times omega. So, well, this I can prove because after all, I add and subtract the piecewise polynomial, the s function that I have here. Don't forget it's not the piecewise polynomial I had before. So, it turns out that v of x. That V of X has this form. So we have a linear piece and we have an A X squared piece. Okay? The linear piece is not, it's going to go away. And this is a trigonometric polynomial. So eventually. So eventually we define Q by this part, namely subtracting the linear piece, right, from V. So we end up with this. And yeah, this was the linear piece. And it turned out that this, we can estimate this well enough, and therefore Q and approximate. Qn approximates our function f well enough. All right. Okay, no, I will not talk about the Q monotonicity for Q greater than this. I'll stop here. Wait, so I have to go one step forward. Thank you. Yeah, just how important you can this periodic approximation for periodical functions are also approximation by x bracket according to infrared. In classical settings you said x equals cosine theta, right? Then one can get some approximation result of by algebraic polynomials to use it from corresponding result on the circle. no i i haven't thought of that but but you see the construction of the of the approximation was very difficult already in the algebraic case that's right but and then so first you see chef chuk my collaborator suggested that we do that and get rid of this question and i said no we have the algebraic No, we have the algebraic case, this is similar. What were they turned out that it caused us a lot of trouble also to get this done? Okay. So I am going to answer, Tino, about algebraic case, for instance. You see, you ask if it's constructive. You asked me yesterday. So it's as constructive as knowing to find the best approximation. Knowing to find the best approximation of an algebraic polynomial on a piece, small piece of an interval. So, and you may not need the best approximation, you may be satisfied nearly best and so on, but it's quite, well, it's constructive and not constructive at the same time, I would say. Okay. Thank you, Adam. 