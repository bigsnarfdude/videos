Alberto is speaking about rank metric codes. Alberto, whenever you want. Thank you. Yeah, so thanks a lot, Iran, for introducing me. And thanks also for the opportunity to give a talk here at this nice workshop. So yeah, so I was asked to give a talk on rank metric codes. And my talk is divided into two/slash three parts. And I decided to Three parts, and I decided to start with what made rank metric codes basically a so popular topic in our community around 2008, which is network coding. So the first part of my talk is actually about network coding, and I will try in this part to explain basically why rank metric codes in network coding. So how basically the rank metric naturally shows up in the problem of corrective. In the problem of correcting errors in networks. And I know that there is another talk on network coding, so I will try to keep this part short. But I cannot avoid basically explaining the beauty of this theory in connection with network coding. So I will spend 10 minutes on this. So network coding, as we all know, is about data transmission over networks. And to simplify the problem a little bit, this is the problem I am. Bit. This is the problem I am focusing on in this talk. One source of information: a bunch of terminals connected via a network, possibly very complicated, of intermediate nodes. And the source here wishes to transmit vectors, V1 through Vn, which are of fixed length, M, and entries from a finite field of Q. And we focus on the multicast problem, meaning that all the terminals, each terminal wants to receive... The terminals, each terminal wants to receive all the messages, okay. And yes, as I said, it's the multicast. Okay, and our goal is, of course, to use the network resources at our very best. So in other words, maximize the number of messages that can be transmitted to all terminals per channel use in average or not, depending on the model, okay, which is an informal definition of rate of the communication, if you want. And the traditional And the traditional way of approaching this problem would be, of course, routing, so trying to forward as much information as possible. But the field of network coding originated from a simple yet far-reaching idea by Ashwede, Kai Li and Young around 2000, which is to, instead of just forward the information towards the terminals, is to allow the intermediate nodes to recombine the packets, the vectors in this case, okay, in order to. Okay, in order to, if possible, increase the efficiency and exploiting the network resources better. So they illustrate this idea in an example, which became very famous. It's called the butterfly network. Sorry, one source and two terminals, T1 and T2. The source attempts to transmit two vectors, V1 and V2. So in the first move, for example, we could do V1 over the top edge and V1. The top edge NP2 over the bottom edge, and then the first intermediate nodes, this one and this one, they forward what they got. And now we have a node V, which is in a more interesting position. It's called a bottleneck in network information theory, right? And so the traditional way of approaching this routing would mean to just disregard one of the two vectors and forward the other one. And as I Other one, and as I mentioned, the idea of Ashwede, Kylie, and Young is to not do that, but to in fact recombine packets before forwarding them. And in this case, we could send, for example, the sum of the two vectors and then the other node simply forwards. Okay, so it can be shown, and I'm not going into the details here, that this strategy outperforms routing. So with routing in the butterfly network, you cannot do more than 1.5 max. More than 1.5 messages per channel use on average. But this strategy, of course, delivers two messages in a single channel use, right? So two better than 1.5. Okay. So, and in general, if you have a much more complicated network, this was just a tiny toy example, you ask yourself, how many messages can I send, right? And we have a bound for this quantity. It's called the min-cut bound in the theory. The mean cut bound in the theory, and that's the statement. So, n is my network, s is the source, and then I denote by bold t, I'm very sorry for my voice. I have COVID and I am trying my best not to, yeah, I hope I can be understood by everybody. And if not, please interrupt me and ask questions. So, bold T for me is the set of terminals T1 through Tm, and then. And then Ashwede, Kaieli, and Young in the same paper, they prove that the multicast rate of any communication over the network N satisfies this upper bound. So the rate is no more than a graph theory invariant of the network, which I denote by mu on my slides, and it's the minimum of the mean cuts between source and terminals. So the mean cut between source S and terminal TI is the minimum number of edges. Minimum number of edges you need to remove from the network in order to disconnect S and TI. And then you take the minimum overall determinants, you get a number, and that's an upper bound for the rate. And then, of course, the question comes, can we design node operations, which we're going to call the network code, so that this bound is achieved? And in the case of the butterfly network, the node operations were just forwarding and then summing. Wording and then summing two vectors. And we wonder: can we do this in general for an a priori very complicated network? So the answer is going to be yes, if the finite field FQ over which everything happens is large enough. And in fact, not just that, but linear operations are going to be enough. So in the next few slides, I will try to understand how the statement of this, basically a more precise statement for this. Basically, a more precise statement for this line, because that's crucial to then appreciate how rankmetric codes work in the context of network coding. So I need to explain this a little bit to then show how the rank metric kicks in for fixing the problem of error correction over in networks. So just going back to our butterfly network, just to see how we compute and achieve. See how we compute and achieve the bound in this example. The mean cut between the source and each of the two terminals is two. Therefore, my invariant mu is two. And then the strategy I proposed, well, Ashwede, Kaile and Jam proposed of just summing these two vectors and forwarding everywhere else is bound capacity achieving. And of course, we are just using linear operations. So the statement that general So the statement that generalizes this idea and shows that it works for an arbitrarily large network is called the Max Flow Mean Cut theorem. And careful graph theorists here. So this is not the Max Flow Mean Cut theorem from graph theory that talks about flows in networks. It's the MaxFlow Min Cut theorem from network coding. And there is a little bit of preparation for being able to tell you the statement of this result. Tell you the statement of this result. So n is my network, and I denote by little n the Î¼, this minimum of the mean cuts. Now, if the source s sends messages v1 through vn, as we said, sorry, here's an M, FQ to the M, and then the nodes, the intermediate nodes, perform linear operations, say, on the inputs they receive. So we're going to use linear network coding. Then, um, Then I denote by W1T, W2T, etc., up to Wr of T the vectors that are collected by terminal T. And Rt is simply the number of incoming edges for terminal T. Okay, so these are elements from FQ to the M. Great. So since we are using linear operations inside the network, it only linear... Operations inside the network and only linear operations, then I can write each Wi. So W1, for example, T, is going to be a linear combination of the original vectors V1 through Vn, right? And the same applies to W2 and up to Wr of T. Okay, so each of them is going to be a linear combination of the original vectors. And therefore, I can write this matrix equation. I stuck all the received vectors. Received vectors in a matrix like this, all the originally sent vectors in a matrix like this, and I can write this matrix equation with this matrix G, which depends on the terminal. So that's why I write G of T, and it's called the transfer matrix at terminal T, which takes into account all the operations, all the linear operations that the node performed on the way. Great. So now I can state the theorem proved by Can state the theorem proved by Li, Young, and Kai in 2002 with a linear algebra approach and then with a very elegant machinery using basically a generalization of the Schwarzschild lemma by Kotremedar in 2003. So the first part of the statement says that one, without loss of generality, that's an important part actually of the statement. It's not a for free say without loss of generality. R of D, which is the number R of t, which is the number of incoming edges for terminal t, well, is the same for all terminals and is precisely n, the mu of the network, this little n. And the second part, which is the actual statement, so if the number of terminals is no more than the field size, rather, so field size large enough, basically, then there exists linear node operations. Then there exist linear node operations that make all the G n by n and invertible. Okay, so the fact that they are n by n comes from part one, but what's interesting is that, and that's what part two says, that all these matrices which are n by n can be made invertible simultaneously, which is of course the key here. So it's not difficult to prove that each matrix G can be made invertible individually, but Individually, but the magic is that they can be made invertible at the same time. Great. So, this is a more pictorial description of this result. I have a source with a bunch of vectors I want to send. I collect this object into a matrix of size n by m, and then I have a terminal there, and the terminal is associated with a matrix, a transfer matrix G of T. Matrix G of T and terminal T receives the originally transmitted vectors multiplied by G of T. And by the theorem, G of T is invertible for every T. And then, of course, the decoding is just about inverting G, right? There is nothing more to say. The transformative G is known and it's pre-computed, basically. So when I receive G of T, I know G, I know it's invertible, I multiply by its inverse and I. By its inverse, and I recover the original vectors. So it is as simple as that in the case where no errors, of course, occur, and we're going to talk about that in a second. So in the case of the butterfly network, this is just, you know, rewriting things in the matrix form. The transfer matrix for terminal one is simply 1011, and the transfer matrix for terminal two is 1101. They are both. One. They are both invertible over any field. So, to summarize, this result tells you that the multicast rate of any communication over the network satisfies no more than minimum of the mean cuts between source and terminals. And if Q is sufficiently large, then the rate is achievable actually in one shot and with linear network coding. Sorry. Okay, the question, of course, and that's precisely where the rank metric is gonna kick in. The question is: what if errors occur? Okay, and we have to specify the model we are working with first before, of course, going into the detail. And the model that most people concentrate on is the adversarial model. So, we think that there is one adversary who can change the value of up to T edges. Value of up to T edges. Okay, and we call this the adversarial strength. And we assume also that the adversary is omniscient, so the network code is known to everybody. Okay, so now I would like to illustrate the problem of the issue basically that network coding brings that motivates the use of rank metric code. So, suppose that I have an adversary even with adversarial power, just one, t equal to one, and then this edge, the one. One, and then this edge, the one with the cross, is touched by the adversary. So, now since we're using network coding inside the network, so the intermediate nodes, in particular, this one, they're going to recombine the vectors with each other and then send functions of those. So, in this case, I have both these edges that are potentially corrupted, right? Because this vertex has no way of telling that this vector was corrupted, and then it's just going to apply the function there. You're just going to apply the function, the network code, and then compute these two values of these two edges. Okay, and then the same applies to this intermediate node, right? And as you can see, the issue is that I started with just a single corrupted edge. I said t is equal to one, for example. And I end up with, in this case, five potentially corrupted edges at the end. So there is a problem of error amplification. So there is a problem of error amplification here, meaning that the number of corrupted edges can grow exponentially because of the structure of the network. And if you think about it, this is really intrinsic to network coding. This is intrinsic to the scrambling, right, of the vectors inside the network. And the solution that Silva Kutter and Shishran proposed to solve this problem of error amplification is to use rankometric codes, which is precisely the same thing. Rank metric codes, which is precisely why I described I wanted to start with network coding in the first place. So now I will try to explain how rank metric codes can solve this problem basically. So I need to use what I explained so far, and that's the reason why I explained that. Okay, I need to go back to the model and to what we have kind of learned so far. Have learned so far. Source, terminal, and network of intermediate nodes. I am sending a bunch of vectors which I collect into a matrix X, right? And then my terminal receives G times X, and G is invertible for all terminals. Then we already said that in an error-free context, X is sent, G times X is received by terminal T and there is nothing more to say. But then if error occur, then X is sent. Then X is sent, and in general, something else, Y say, is received by terminal T. So the key observation by Silva Kutter and Shisheng in this context is the following, which is really the key here. So if at most the edges were corrupted by the adversary, initially, of course, I'm not talking about the consequences of the action of the adversary, but if at most the edges were corrupted, then if you take Then, if you take what you received and what you should have received, and you compute the rank of the difference between these two matrices, well, this is no more than t. So, in other words, I don't know if I have it written. Yes, in other words, the adversarial power, the number of edges that can be touched, is an upper bound between the rank metric discrepancy between what was received and what should have been received. What should have been received. So, basically, what Silva Koeter and Shishan do in their paper in 2008 is to kind of propose a different way of looking at the problem. So, when we said in our example, in our picture, sorry, that starting from just a single corrupted edge, I end up with five corrupted edges, and that will seem to be a disaster. But basically, this theorem by Silva Koe Terengition tells you that it's not. Transition tells you that it's not such a disaster if you just measure things in a more appropriate way. So, the number of corrupted edges is a way more catastrophic measure for what's going on than, for example, and that's what they propose, the rank metric. So, here they got the idea of measuring the discrepancy between y of t, so what was received, and what should have been received, which was g t. Been received, which was gt times x, via the rank of the difference between these two matrices. Okay, so when the rank metric, rank distance between two matrices, that's how it's defined the rank. So rank distance between A and B is the rank of A minus B. So wrapping up, so again, we have X was sent, G T X should have. G, t x should have been received, but then errors occurred. I received y of t. And then this theorem says that the adversarial strength t is an upper bound for the rank distance between these two matrices, which is very important for the decoding. This is the same as y of t multiplied by g of t on the left, and then x. So, as you see from this very Identity. So, this idea of introducing the rank metric translates the problem of fixing errors in networks in combination with network coding to the problem of decoding in the rank metric. Right, which is the main idea of their approach. And because, according to this metric, and that's what I tried to explain already in the picture, well, errors they propagate. Well, errors they propagate, of course, but they do not amplify anymore. So, before I move on, any questions about this part? Okay, great. So, moving on, just like in the Hamming metric, you measure the discrepancy between two vectors as the number of components in which they are different, and then you define a Different, and then you define a code to be a collection of vectors of sufficiently large Hamming weight. Well, in the rank metric, you do the rankometric analog of that. So, a rankometric code is a non-zero FQ subspace of matrices all of the same size, FQN by M. So, the definition comes now. And the minimum distance of this object is the minimum rank of a non-zero element in my code. Okay, so this is really the rank metric analog of. rank metric analog of what we're used to in in the in the Hamming metric so communication schemes based on rank metric codes so based on this object that I just defined so just to tell you how the story ends very quickly well they are capacity achieving for queue sufficiently large they are of course compatible with linear network coding because that's precisely the motivation for introducing them of course but they're also separate But they're also separable, meaning that the network code and the ranchometric code can be designed independently from each other. Okay, and then this is actually something that is very, very specific to the model we are considering here. One adversary able to corrupt up to T edges of the network. For more general scenarios, so for example, multiple adversaries acting on the network at the same time, erasure adversaries, or most interestingly, Or most interestingly, sorry, restricted adversaries. Well, already together with Frank in this paper, Adversarial Network Coding, we observed that there are no capacity achieving schemes that are both compatible within the network coding and that are separable. Okay, and more recently, we also have a work together with Alison Beamer and one of my students, Altan Kilich, and submitted to MTNS 2022. To MTNS 2022, where we study precisely adversaries that are restricted to operate on a region of the network. And in those cases, unfortunately, rank metric codes don't work and linear network coding also doesn't work. Of course, they work, but they don't achieve capacity. And then you need to come up with different ideas and solutions to fixing that. Okay, so that's the end of the first part. End of the first part of my talk, which was aimed at explaining how precisely the rank metric shows up naturally in the context of network coding. So now, rank metric codes, of course, as I mentioned, they became very popular in our community from 2008, around 2008, when their relevance for error correction in networks was discovered. But they're not unknown. Known, they're not unknown, they were not unknown objects to mathematicians. Okay, and in particular, they have been around since 1978 in various contexts. So, I believe the first one to talk about that, them in a systematic way was Del Sartre, with a nowadays very well-known paper from 1978, which studies association schemes of bilinear forms and rankometric codes, not with that name, but they show up there. And then, of course, Gabita. There and then, of course, Gabby Dooling, who gave us probably the most known construction of optimal rankometric codes, it will come in a second from 1985. Okay, and then, but also Ronnie Roth considered ranchometric codes for application to crisscross error correction. Cooper's teen, that's a paper that has nothing to do with code in theory, and it's about constructing external flats. Constructing external flats, sorry to varieties. That's a paper from 1998. And then finally, what we discussed already at the paper by Silva Kutter and Shishen from 2008. And certainly the rediscovery of rank metric codes in connection with network coding had also the huge merit of reviving the entire field, right? And it's a matter of fact, since 2008, rankometric codes have. 2008, rank metric codes have been studied in connection with really a lot of topics in pure and applied mathematics. And I listed here only a few of them. Association schemes, subspace designs, but also semi-fields and linear sets, which are topics close to people in geometry, projective geometry, sorry. Posets and lattices, matroids and their Q-analog zeta functions, rook theory and Q-analogs. Code-based cryptography, of course. Code-based cryptography, of course, enumerative combinatorics and combinatorial geometry. So, also, you understand, of course, my difficulty of giving an introductory course, an introductory talk on rankometric codes touching on all these topics. Of course, this is not possible. There is material for courses, I think, on this. So, the plan for the rest of my talk is to The rest of my talk is to tell you a little bit about MRD codes and the construction that Del Sartre himself proposed in his paper from 1978, which is basically the same as Gabby Dooling. And in this talk, I will take the chance to specify the connection between the two. And in the last part of my talk instead, I will talk about a problem connected with rank metric because I have been working on in the past few years together with collaborators. Together with collaborators, which also points back to very classical open problems in combinatorial geometry. So that's a little bit the plan, and I will move on with the singleton type bound, the rankometric singleton bound, and the construction of the SART for optimal rankometric codes. So before I move on, any questions? Yes, question, please. Yeah. Yes, please, concerning the application of rammetric code in net coding, as you explained, is it only FQ linear code or FQM linear code as Gabby Julian defined? Yes, so yeah, yeah, yeah. So thanks for the question. So for the application of network coding, you don't require linearity over the end. Over the FQ to the M. Okay, linearity over FQ is enough, and in fact, not even a linear object would be required strictly. But then, of course, the question is: can you decode this object efficiently? So, if you take Dooling codes, then you are guaranteed that you have an efficient decoding algorithm. Those are linear over the big field. I don't know if this answers the question. Okay, thanks, thanks. Okay. Okay, great. So, throughout the rest of the talk, I'm going to assume m at least n without loss of generality, otherwise, one can transpose the matrices. And then I am going to start with this result by the start. So, if C is a rank metric code of minimum rank distance, at least D, then the dimension of the code is no more than M times N minus D plus one. And coding theorists, of course, we immediately. And coding theorists, of course, we immediately recognized N minus D plus one in connection with the single tombound from MDS codes, of course. And Belsart gives association scheme, a theoretic proof for this, but like a linear algebra way of seeing this fact, this bound, is by observing that the projection pi from the code onto the last, say, n minus d plus one rows must be. D plus one rows must be injective because of the minimum distance of the code, right? And therefore, by a simple dimension argument, we get that the dimension of C cannot exceed the dimension of the code domain, M times N minus D plus one. Okay, and then we're going to call MRD a code for which the dimension is precisely M n minus D plus one. And this, so MRD stands for maximum rank distance, so maximum rank distance codes. maximum distance codes and these are probably the most studied rankometric codes in the entire in the entire business so of course the there is the existence question right which is still open we know modular you know known cases of the mds conjecture um so there is a bound and then you ask yourself is there is there always a code within the bound so for mds codes So, for MDS codes, the question is still open, but for MRD codes, it isn't. Okay, so this is how Del Sartre constructs an MRD code of minimum distance D and dimension M n minus D plus 1 over FQ. So, you start by fixing an order basis, beta 1, beta M over, sorry, of FQ to the M over FQ. Okay, so you see FQ to the M as a linear space, FQ linear space, and then you fix a basic. And then you fix a basis of that, and then you denote by k and minus d plus one. And then to a vector omega of components omega 0 to omega k in fq to dm, of course, k plus 1, we associate a matrix, which I denote by m omega, and it's defined in this way. m omega entry i j is equal to so you take beta j So you take beta j and then the sum from l equals zero to k omega l beta i q to the l and then you take the field trace of this product between the element and the sum okay for i and j okay and then you simply put c to be the collection of all the m of omegas okay as omega ranges over all the vectors okay so this Okay, so the SART gives this very explicit construction of MRD codes. And of course, everybody nowadays is very familiar with the construction of Debidouling, which is obtained by evaluating linearized or Q polynomials, right, over the field extension of Q to the M. And so in this talk, I wanted to take the chance to say that this is basically the same thing because so the So, the linearized polynomials are hidden in this thing. So, this is the evaluation of a linearized polynomial over a basis. And then, to see the connection with the Bidouling construction, it suffices to show, well, it's basically follows from really the definition of dual basis, that if you have alpha in FQ to the M, then the trace of beta J alpha is nothing else than the J component of alpha with respect to the dual basis of the basis. dual basis of the basis beta 1 beta m so when you do trace and then beta j and then an element okay you are simply writing down the element into its coordinates just over the dual basis so this construction by the start is also taking the linearized polynomials up to a certain q degree evaluating them over independent elements and then writing them over a basis So, people worked a lot on constructing MRD codes. This is the original construction proposed by Desart. There are many more, and the difficulty in this business is always to prove that your construction is new, meaning that it gives rise to codes that are inequivalent to codes that are known already, and it's very open. Open field of research, and for a survey on that, I would like to redirect you to this chapter by John Shiki, MRD Codes, Constructions and Connections, where a lot of constructions are surveyed there, together with considerations about equivalence and inequivalence of that. Okay, so any questions about this part? Okay, so as Okay, so as I mentioned, I would like to conclude my talk in the last part with a problem I have been working on in the past few years, which is about MRD codes. And it's one of the simplest question I can imagine about MRD codes, which is, however, very difficult to solve. And so the question is simply how many MRD codes are out there? So equivalently, So equivalently, this is the same as asking to compute the value of this quantity I denoted by delta Q and by M D, which is just the number of MRD codes of distance D and therefore this dimension, right? And divided by, I simply divide by the number of codes having that dimension. So some of you probably already heard talks from me about this problem. So in this talk, I decided to also include some new. Talk: I decided to also include some new results that we got this year, so very fresh things. But what I would like to achieve with this last part of the talk is to show that some extremely simple objects like linear spaces of matrices, like MRD codes are, are actually connected to very deep, very difficult, and still open problems in combinatorial geometry and combinatorics more generally from more than 50. From more than 50 years back. Okay, and at least for me, the theory of rank metric code is making me kind of rediscover these problems as well and to study them in connection with the rank metric. So I would like to tell you a little bit about this line of research that myself and a bunch of collaborators, I will all mention, of course, are working on. So the problem of So the problem of computing MRD codes in a just, you know, in a few words, it's a very difficult problem. And it actually dates back to a question asked by Crip when Rota in 1970. Okay, and it's called the generalized critical problem in combinatorial geometry. And it's also very easy to state. If you have a linear space over FQ, say capital X, and then P is a collection of projective points. Is a collection of projective points of x. So you ask yourself how many k-dimensional subspaces of x avoid every element of p. Okay, so the question is very easy. You have a bunch of vectors up to scalar multiples, and you ask yourself in a space, and then you ask how many k-dimensional spaces miss all these points. That's the generalized critical problem by Crepo and Rota. So Crepo and Rota themselves in Rota themselves, in it's actually a book from 1970, proved that the answer to this question depends heavily on the combinatorics of the elements of P in a precise sense. So this element, this projective point, they generate a geometric lattice. It's a sub-lattice of the lattice of subspaces of X. And then computing, by computing here, I mainly say this for the crypto people. I always mean in this domain. I always mean in this domain, finding a closed formula for okay. So, computing the avoiders, so the spaces that miss all these points is the same as computing the Whitney numbers of such a lattice, which is known to be a very hard problem, unless the lattice is very special. And how is this related to MRD codes? Well, one just have to write down the right space and the right projective points. So, if I take X to be FQ. So if I take x to be fqn by m as a as a space and then p all the non-zero matrices of rank no more than d minus one up to multiples, then the avoiders of the largest possible dimension, which by the singleton bound is mn minus d plus one, so the avoiders of p are precisely the MRD codes of distance d. So computing the number of MRD codes is an instance of this very old problem from problem from 1970 and the plan for the next i think i have like 15 minutes yes for the next 15 minutes is to take you on a very short excursion on this topic its roots and its connection with classical topics from projective geometry and combinatorics in general and the new results that that we got about them and i want to start with the result which is actually which is actually sorry not by myself Which is actually sorry, not by myself, it was proved by Antrobus and Closie Lerson in 2008. Where they are able to compute, so they consider the density, so 2 by M MRD codes of minimum distance 2, therefore dimension M, and they compute the limit for the field size goes to infinity of their density. And they get a very curious expression, okay, and which they got. Okay, and which they got by expanding on the theory of spectrum-free matrices. So you have this alternating sum, right? I from 0 to M minus 1i divided by I factorial. And then this number, of course, as soon as M is large enough, but it's enough that M is like, yeah, very small as well. So this number is very close to 1 over E. And then one asks at least that. One asks, at least that's what I ask myself: well, why does the exponential function show up in this context? And is it like normal that the exponential function shows up? And is this situation about the density of MRT codes of these parameters typical? And by typical, I mean something very precise here, and which is summarized in these two items. So, what do I mean? Items. So, what do I mean by this? Well, there are approximately Q to the M matrices of rank one up to multiples in FQ2 by M. These are the ones we try to avoid, right, by constructing an MRD code of minimum distance two. And then you can ask yourself: well, if P is a uniformly random set of projective points, it F Q2 by M of size asymptotically Q to the M for Q large. Okay, so now. Q large. Okay, so now I take. So I know that we know that MRD cause they need to avoid the matrices of a small rank, but what if I take a uniformly random set that has the same cardinality, in this case, roughly Q to the M? So what is the density of the M-dimensional avoiders of this set, okay, for Q large on average, of course? And then, surprise, the average density, this is a result we. This is a result we got this year together with one of my students, Anina Kruiza and John Sheeke and Ferdinando Zullo, is that the average density is exactly one over E, okay, for Q going to plus infinity. Okay, so in other words, so this result shows that the number of MRD codes or their density equivalently is actually a very typical is actually a very typical number for the number of projective points we try to avoid looking at things through the lens of the critical problem by Krapo and Rota from the 70s. Okay, so yeah. And then you ask yourself, of course, well, is it always the case with MRD codes, right? Is the situation always that typical? And in general, what is their number and what is their Number and what is their density or the asymptotic behavior of their density for Q large? Okay, so the answer is that it's going to be no, meaning that the situation here of the 2 by M MRD code is very special. We will see that. And to do that, of course, we would need some more information to then compare with the average, right, about the asymptotic behavior of the density function of MRD codes. Density function of MRD codes, which is another problem which is very hard. Okay. So one main result in this context is that, well, MRD codes, while they are the rank analogues of MRD, of MDS codes, sorry, which are known to be dense over 4Q large. So if you take a random code of dimension k in the Hamming metric, this is going to be MDS with the. metric this is going to be mds with very large probability well in the rank metric it is exactly the opposite so we proved in 2020 that the density function of mrd codes so n by m of minimum distance d is actually in o of q to d minus d minus 1 n minus d plus 1 plus 1 as q goes to infinity and this number goes to zero of course with q Of course, with Q very quickly, meaning that MRD codes are just a very small proportion of all the codes having the same cardinality. Okay, and this result we got precisely thanks to the interpretation of MRD codes as the avoiders of certain projective points inspired by the work by Crepo and Rota from the 70s. And the tools that we use in our approach is, well, this interpretation as a Is well, this interpretation as avoiders combined with some draft theory. So, note that this result shows that MRD codes are sparse. So, if you pick a code of a certain dimension, M and minus D plus one at random, this is going to be MRD with very, very small probability. So, the fact that MRD codes are not dense, so that you don't get an MRD with the probability approaching one. Probability approaching one. This is known from 2018 and it was established in two papers that came out approximately the same time by Antrobus and Clius Ilnerson, the authors of the alternating summary I showed already, and in a joint paper together with Emer Bern. Okay, but what we get combining this result about the sparsness together with results from Antrobus and Closely Lesson, so from 2018, is So from 2018 is the computation of the limit for the density of MRD codes, which is one, that's the trivial case, the alternating sum we already talked about, and then corollary of this theorem, zero otherwise. But then of course, this is just the limit of the density, and this is just an upper bound. To understand the connection, the real connection with the generalized critical problem by CREPO and Rota and to compare. rota and to compare mrd codes with the typical situation for that problem we would need um an exact estimate right for the for the density function and that's much more hard in general it's a it's a difficult problem or at least considered to be very difficult and the solution is known only in very few cases so we have seen one already the two by m distance two By M, distance 2, MRD codes. And then the other known cases, they all basically use the theory of semi-fields one way or another, which I don't have the time to explain or comment on. But the main result that all these results are based on, and I stated here in this form, like in this kind of vague form, because it was proved by various authors and in various forms, depending on the notion of semi-filty peak. notion of semi-fields you pick depending on the on the notion of equivalence of mrd codes you pick but basically the result says that there is a one-to-one correspondence between equivalent classes of n by n full rank mrd codes and isotopic classes of semi-fields okay so semi-fields are algebraic structures that generalize fields and the connection between mrd codes and semi-fields has been known for a while and Has been known for a while, and probably the paper that first structurally points to this connection is this one from 2016, where they use semi-fields to construct new MRD codes. Well, based on this connection with semi-fields, in 2019, Heitek Lusing-Lerson computed the exact density of 3x3 rank 3 MRD codes. Three MRD codes and the asymptotic behavior is a third q to the minus three. But this year we managed to generalize this result using a quite, it's always using some semi-fields, but using different areas, so to say, of the theory. And we managed to give a lower bound for the number of full rank MRD codes. So, which is this, the number of full rank MRD codes. number of full rank MRD codes in FQN by M is at least this. So there is the size of the general linear group involved and then binomial coefficients and everything. But what's interesting about this result is that it is sharp for n prime and q sufficiently large. And you certainly remember that we are interested in computing asymptotics of things, so q sufficiently large is good enough for us, right? So I see that it on f So I see that I don't have many minutes left. I want it to be done in 50 or so. So I'm going to skip the comments about how we actually get this result and immediately go to the corollary, okay, which is this. So for n prime, the asymptotic behavior of the density function of n by n rank n MRD codes is this. Okay, so you have a coefficient in front, n minus one. have a coefficient in front n minus 1 n minus 2 divided by 2n and then a polynomial decay q to the minus n cubed plus 3n squared minus n and then you can very well ask the same question that we asked before right do i expect this density right in connection with the generalized critical problem by crepo and rota i mentioned already well we set up the problem and the question Problem and the question more precisely, exactly in the same way. So, there are roughly q to be n squared minus two matrices of rank no more than n minus one up to multiples in fqn by n. And then you ask yourself, well, if p is a uniformly random set of projective points in my space of size roughly q to the n squared minus 2, well, what is the density of the n-dimensional avoiders of and dimensional avoiders of p for q large on average so if you remember in the case 2 by m um rank 2 mrd codes we found that so the the actual density was the alternating sum and then the average was so close to one over e and the density was precisely one over e and in this case the situation is very very different okay so for these parameters if you For these parameters, if you plug in, so the average density is like way, way smaller. So one divided by e to the power q to the power n minus two for q going to plus infinity. Okay, so to conclude, so for n prime at least, that's the case we can analyze. So full rank n by n MRD codes, they are sparse, okay, and that's the result I mentioned before. and that's the result I mentioned before the density was in O of Q to the minus, right? Something positive in general, but they're certainly way less sparse than the average, okay, which kind of reconciles maybe our intuition, at least the intuition I had about MRD codes, just like, you know, being the analog of MDS codes being kind of, you know, easy to find. Well, we know that they're not easy to find, but they are way more dense than the average. Way more dense than the average avoider of a set of projective points of the cardinality of the matrices of small rank. So I hope the line of reasoning is clear here and that the connection with this old problem from the 70s is also clear. And we are working a lot on this and nice things are coming up. As I said, it's also very nice to kind of rediscover an old Rediscover an old theory through a modern topic, if you want. So I have decided to, since this was an introductory talk on rank metric codes, and probably there are many students, PhD students in the audience who might want to approach this topic and learn more about it. So I decided to conclude my talk by giving some visibility to some references, which are introductory references on the topic. Introductory references on the topic. And of course, when a topic starts to be in book chapters, book and everything, it means it almost became a classical topic, right? Well, in coding theory for us. So Elisa and I wrote this book chapter in connection with the cost action on network coding that finished a few years back. And Elisa herself has another. And Elisa herself has another book chapter in the concise encyclopedia of coding theory, rank metric codes, where she also studies the notion of the various notions of supports that were proposed in this context. I already mentioned the chapter by John Shiki, MRD codes, construction and connections, various constructions of MRD codes, their inequivalence and connections with projective geometry topics. Projective geometry topics. There's also this brand new monograph. So it's actually very long and very nice: ranchometric codes and their applications. Okay. Edited by Alexander Bark in the now series. Foundations and Trends in Communication and Information Theory. There is also a work actually by Gabi Duling that recently appeared and this was edited and translated by Vladimir Sidore. That translated by Vladimir Sitorenko, and that's fully available, fully available online through TUMA Publisher, TUM Publisher. And then me and my students are also working and finishing, hopefully soon, a chapter on rank metric codes and their parameters. And there are probably many more references that I missed. I hope this is enough for a first approach to the topic. And with this, I would like to thank you. And with this, I would like to thank you all for listening to me. Sorry again for the voice. And if you have any questions, please ask. Thank you very much, Alberto. Let's take Alberto, please. We have a question from the live audience. Yeah, so this is an algebraic question. So, sorry. So, here's an algebraic geometry question. First, about it's really about the set of. First, about it's really about the set of projective points p. So, first, you could imagine an incidence correspondence with a Grassmannian. For this is for any variety, but you know, you've got a set of points P. You set up an incidence variety with the Grassmannian of K planes in Pn, which meet that variety. And then, so this would be not over a finite field, but that incidence variety will have some degree and some interesting geometry. And I'm curious if you guys or if anyone in the network coding community has looked at. Community has looked at the sort of relationship between that incidence variety, maybe its degree or dimension or things like that, and this sort of the avoiders. And then the other question was, I guess in practical applications, I'm assuming that the points are generally what we would call generic, or in algebraic geometry, we would call them generic, but in sort of a uniformly random position. Is there any interest in sort of analyzing the situation when your points? So there's a massive literature in algebraic geometry on studying points. In algebraic geometry, on studying points in special position, for example, right? So, is there any interest in studying the situation when those points are not generic? So, that was a long-winded question. I apologize. But, oh, and thanks for a really nice talk. I appreciate it. I'm not a grad student, but I appreciated the introductory aspect. Thanks a lot for the questions. Yes, in particular, the second one I can comment on. So, for the first one, we didn't explore algebraic geometry approaches and Geometry approaches, and I know there are people in the audience who are way more qualified than me to talk about this. But about the points, the position of the points, we really studied that. And actually, we so here we take the average. In my talk, I only took the average over all the points of a certain cardinality. But like the next refinement that you could take is how about taking the average? Could take is how about taking the average over all the points of a certain cardinality and spanning a set of a certain rank? Okay, so that could be another possibility. And we managed to compute the average also in that case. And the formulas are extremely nasty that you get. So that's why I didn't include them in my talk. But yes, so in our paper, we have also considerations about the specific About the specific positions of the points, of course. So you can think of arcs, for example, or cups. That's another example we investigated. So yes, definitely. There is certainly a study there to do conditioning basically the results that you get on the positions, as you say in project. As you say in projective geometry of the points, there is another question from Sudhir. Yeah. Hi. Hi. First of all, thank you for this wonderful talk. Thank you for attending. Yeah. So I just was trying to understand, maybe I don't completely understand your definition of density, but when you showed the general result, which had the asymptotic Result which had the asymptotic in the general n cross m case. You had on the right-hand side was independent of m uh you just depended on q and n if i remember correctly the bound you mean yeah yeah the bound yes no no no not the square face but uh you had the rectangular one uh which sorry which ones maybe before this uh if you don't mind this uh if you don't mind this one no no uh yeah yeah yeah yeah here you don't see an you don't see an m here right here and yes is that strange or is it this is to be expected and no no so we would correspond to mds scores right yes so the problem is that of course this is just a bound right so this is an o of something okay and without Okay, and with our approach, with our approach, we don't get an M. So, M in the asymptotics as Q goes to, there is, of course, an M in the bound. Okay, the bound is nasty, it's like two lines of formula. But then when you compute the asymptotics of this, the M goes away because it plays a very minor role. Now, whether it is true or not in the actual value of the density and of the limit, of course, whether or not M plays Whether or not m plays a marginal role, nobody knows. Okay, because we know, for example, that this result, at least for the parameters n by n and then d equal to n, is quite far from the truth, so to say, from the actual density value. Okay, so it can very well be that m plays an important role in the theory, and this is just not captured by the tools we are using. So it's a very pertinent and interesting. So it's a very pertinent and interesting question, but nobody knows. So m equal to one would correspond to MDS codes, right? Usual MDS your problem? No. If I mean if this Delsat rank metric code and which are maximum rank distance and if your M is equal to one, is that not the same thing as MDS? I don't think so because M equal to one the rank. One the rank can only be one. Yeah, it's only rank one. Yeah. Okay. Maybe the okay, not the delta circle. And I was just thinking whether this implies anything about the problem about finding the number of MDS codes. Yes, so the problems are related. The problems are, of course, related. Problems are, of course, related, where there are specifications, if you want, of this same problem by Crepo and Rota from the 70s, but we don't get results on MDS codes by applying results on rank metric codes. At least we don't. Okay. Because that problem is also pretty wide open. Yeah, of course. Of course, of course. Of course. And we tried, of course. And we tried, of course, we tried to dig into results about counting MDS codes. But they are very specific. The tools that people use are very, very specific to the Hamming metric. And none of them seem to translate to the rank metric. And that's why people outsource to STEMI fields, which are very different beasts than the object that people use in connection with the Hami metric codes. Thank you. I think Nathan has a question. Thank you. I think Nathan has another question on the slide, so I let him ask that. Alberto, can we take five more minutes from your time, please? Oh, yeah, yeah, yeah, yeah. Nathan, please. Oh, great. Thank you for a very nice talk. Also, I hope you feel better soon. Thanks. I think I'm just going to jump on this last sentence that you just said and say, I've never thought about the problem of counting MRD codes. Of counting MRD codes, but I've thought a lot about counting MDS codes. And okay, the setup there is counting MDS, K-dimensional MDS codes of length N is basically the same thing up to some details as counting K by N matrices with entries in FQ so that none of the K by K minors are zero. And there's this very nice paper of Skora Bogotov about like linear code, strata of Grassmannians, and the problems of Segra, where And the problems of Segra, where he explains how this is basically the same thing as counting FQ points on a certain open stratum of this Grassmannian of K-dimensional subspaces of FQ to the F. And then this is great because that's a variety to find over Z, and you can use tools from like compute the cohomology of this variety to get estimates on the number of F2 points using results of Gorpade and Lasho and people like that. And what I want And what I want to know is: is there a similar setup for MRD codes where you're counting FQ points on something where you can start to use these more algebraic geometric tools? I'm a little nervous about what the answer is going to be because I don't really know anything about semi-fields. So maybe it's more complicated and there isn't a nice interpretation. The answer to the first question: is there a similar setup? Is yes. The answer, whether you can then The answer: whether you can then use tools on that, I don't know. Okay, but the short, I mean, probably what interests you is that, yes, so MRD codes can be described as the non-zeros of a certain polynomial. So they can be described in that way. Okay, so if you fix the matrix space even in the rectangular case, n by n, and then you fix a certain rank that you want. Rank that you want, then you can say, Well, this is a polynomial, there is one polynomial, and you can say, Well, the MRD codes precisely in the same modulo, the same thing you were saying, you know, matrices with non-zero, where all the minors are non-zero, right? Exactly in the same way, yes, MRD codes can be described as the non-zeros of this polynomial. And this was the first approach that. The first approach that people tried to use to prove that MRD codes are actually dense because that's one way of proving that MDS codes are dense. So you describe the MDS codes as the non-zero of a polynomials and then you use the Schwartz zippo lemma that says that over a sufficiently large field that you have very few non-sorry very few zeros. So the non-zeros are dominant. But then you don't you can You cannot apply the same result here because you don't have any control on the degree. Well, you have a control on the degree of this polynomial, but it doesn't go to zero with Q. So I hope this answers at least in part your question. Yeah, thank you. Thanks. Thank you. Thank you very much. Let's thank Alberto again, please. Thank you. Thank you, Alberto. 