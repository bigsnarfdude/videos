Different regimes which are somehow summarized here. And suddenly, so due to the discussion that we just had, this part here might be very irrelevant in the sense that when we are below the controller scale, it could be that in most applicative flows, I mean, we are basically dominated by a molecular diffusion of the gas, so which means that we cannot. gas so which means that we cannot think about this exponential stuff so basically what what i'm i'm willing to to to understand is how uh the fruitful intermittency can can can um affect the exponential regime that we we know uh uh could be true if we are believing in the solution to the levy stocks so basically the so i'm considering pairs which are uh at a distance much smaller than the smallest scale uh the commodore scale of Scale, the Komrolog scale of my flow. And so that basically I'm interested in the tangent dynamics, which is assuming that the time derivative of the separation between the pairs is given by the fluid velocity gradients along a given tracer. So usually, in order to study this pair separation, when he's introducing what is called the stretching rates, also Stretching rates, or also the finite time-you have enough exponents, which are basically the exponential growth rate of this distance between infinity semi-close pairs. And basically, which is so like a one over t times the log of the ratio between these distances, and which can easily be written as a time average of some quantity, which is the gradient of the velocity projected on. Velocity projected on the unit vector which is made by this pair. So, in this study, so basically, as you can see, it's tempting to say that this stretching rate can be seen as a sum of uncorrelated or weakly correlated elements. And basically, so that basically we have all the I mean, all the considerations based on ergodic theory that will tell us how to quantify the fluctuations of the searching rate. So, in particular, if we apply the so-called Low Farge number, we can deduce that for almost all trajectories, I mean, if the system is ergodic, of course, if the dynamics is ergodic, that things that we believe, that's the structure. We believe that the stretching rate will tend to the Lyapunov exponent when time is going to infinity, and the Lyapunov exponent be nothing but the average of this projected velocity gradient. So then, under some assumptions, we can also think that there is a central limit theorem which will tell us that the variance of this finite time Lebanon of exponent of the searching rate will also go like. Also, go like so, we go like one of a time, and so that when it's rescaled by time, it should go to a constant, which is also a way to quantify the fluctuations of this mixing property, I mean, of this mixing by the gradients. And then even so, one can draw in some cases some large deviations form where basically which are amounting to say that the probability distribution. Wanting to say that the probability distribution over a time t of this stretching rate of computed over a time t goes like an exponential of t so maybe the one is used to define it with a minus here times a rate function which depends only on how far we are from the mean okay so so all this stuff has been essentially worked out in model flows so for Model flows. So, for instance, in cases where the gradient is white noise, is uncorrelated in time. And this was introduced by Craichnan in the 70s and studied in details by Belkovsky and Fuxon in the late 90s. And so, the question I want to address is whether or not one can detect the signature of intermittent velocity statistics on these different considerations. So, there is some. So there is something which is well known, is the fact that the Lyapunov exponents has shown some dependence on the Reynolds number coming from intermittency. And basically the reasoning is the following, is to say that typically the thing that we are summing, I mean, the projected gradient has an amplitude which is of the order of the gradient itself. So that's basically the Lyapunov exponent, which is nothing but the Exponent, which is nothing but the mean of these infinitesimal stretching rates, should go like the mean velocity gradients. And we know that this thing, when once rescaled by the viscous time scale, has some power law dependence on the Reynolds number, which is pretty weak. And basically, with a typical multifractal model, one obtains that this exponent is of the order of 210 to the minus 2. So something which is. 10 to the minus 2, so something which is very, very quick. So, here, what I've done is to put together different measurements from the celebrated work by Gélémagi and Pope in the 90s up to what I'll be considering here. And as you see, the Lyapunov exponent, once represented as a function of Doreno's number, is indeed showing a tendency to decrease, but it's very hard to assess the fact that we indeed for That we are indeed following this minus delta power law with delta of the order of 10 to the minus 2. So, one possibility to explain this spread, it could be in the fact that the data are pretty heterogeneous. So basically, they are computed with different means involving different number of trajectories, for instance, or different lengths of the time average over which they are complete. Of the time average over which they are computed. And basically, the other point also is that it's very hard to understand whether or not these measurements are sensitive to given fluctuations that will be observed in the flow. So another dependence on the Reynolds number stemming from intermittency is in the variance, in the variance which is entering the central limit theorem, which basically is Which basically is telling us that if we rescale the variance of the stretching rate with time, basically this thing should go to some finite limit. And basically, it was observed in the work of Chrysanti, Paladin and Vulpiani from the 90s that this variance is, instead of decreasing as the mean, is increasing substantially with the Reynolds number. With the Reynolds number with an exponent which is of the order of 0.3. So, what they did was measurements in some shell models of turbulence for which they were able to get this variance. And they measured this exponent without really explaining how it's coming, I mean, how it relates to the intermittency of the velocity gradients. So, it's a simple observation to consist in writing down this gradient. Consists in writing down this gradient, I mean, I'm sorry, this variance as simply the time integral of the time correlation of the projected velocity gradient. And basically, so that we can typically write this variance as the variance of the infinitesimal thing that we are summing times the integral correlation. times the integral correlation time of this variable. And so clearly the variance of this thing will go like tota to the minus two. So basically here there is no intermittency correction because it's exactly the definition of the, I mean it directly relates to the dissipation rate of kinetic energy. While this thing can clearly be something which is Clearly, be something which is increasing as a function of the Reynolds number. And in particular, it could be that it's of the order of the large scale time of the system, which will make it going like Reynolds to the power one half. So basically, this quantity here is strongly dependent on the large case of the flow, and this is at variance with the Lyapunov exponent. And this was stressed in a recent. And this was stressed in a recent work by Frag Fuchson and collaborators. So, in order to be able to apply the central limit theorem to the stretching rate, one requires that we are looking at times which are much larger than the integral time of this projected gradients. And so that basically, if we make some guess. If we make some guess about what will be the validity of the central limit CRM, it will require that we are looking at separation at time tau, which are less than the Komograph's case, which means that basically we have gone from initial separation up to a separation atom top, typically remaining always below the Komoglos case. So, this I think that Greg will be will be That Greg will be scrambling now. And this implies, in particular, that the initial separation in units of eta has to be much less than an exponential of something which is decreasing with a positive power of the Reynolds number, which means that typically we will never in any application have to rely on the central limit theorem in order to describe per. Limit theorem in order to describe pair separations. So, basically, here, still, I mean, here, what I'm showing is some measurements of this variance, so computed for very, very long times. And basically, what you see is that, again, things are pretty noisy and it's pretty hard to make a difference between the prediction of crescenti and color, which is of the order of 0.3, which is the dashed line here, and something where. Line here, and something where typically it's the large scales of the flow which is determining this integral time scale and which will correspond to the dashed line here. So basically, with the level of dispersion we have in the data, I mean, it's pretty hard to make a choice between the two logs. So what I want to propose is a description of the fluctuations of the finite... Of the finite time stretching rate or the finite time happen of exponents at intermediate times. So, basically, at times which are inside the initial range, for which, as we will see, there is no way to stick to the central limit theorem. So, for that, I'm relying not on experiments, but on numerical simulations. And basically, on typically, simulations where I'm integrating. Where I'm integrating the first Navier-Stokes equation, incompressible Navi-Stokes equation, with tracers which are spread inside this thing. And then I'm looking at the statistics of gradients along these tracers. So I'm using two data sets with two different Reynolds numbers, one which is coming from the ICFD database of Federalikotovsky, and the other one which is coming from the LATU code of From the Latin code of Holger Hohmann. So basically, these two things are, these two data sets are compared in order to assess our results. So they display, I mean, the Reynolds number is sufficient large to display multifractal statistics, including in a Lagrangian frame. So basically, if I'm looking at the kinetic energy dissipation along Lagrangian paths, which is defined this way, so with the The trace of the square of the symmetric part of the gradient tensor evaluated along a trajectory. And then I'm doing what is usual in a multifractal analysis. I'm doing a coarse graining of this quantity in order to define some kinetic energy dissipation over a scale tau. Basically, what I do see is that in the inertial range, when tau is sufficiently inertial range when tau is sufficiently large compared to the to the common growth time scale and smaller than the large scale basically my my my uh coarse-grained uh dissipation is obeying some some multifractal statistics is following some multifractal statistics so basically the the probability that I see some some dissipation cost-grain dissipation scaling like tau to the power beta Like tau to the power beta is behaving as a power law of tau itself with a co-dimension that is estimated here. So basically, these are different data, different times of cross-graining for cross-graining the dissipation. And basically, the data are collapsing pretty well at negative values, which corresponds to large fluctuations of epsilon. Of epsilon and a bit less well at the small fluctuations, places where epsilon is small. And it's pretty well described, at least in this range, by both the log normal and the log Poisson. So the log normal, the usual log normal model and the log Poisson, which is the Scholevec with the Scholevec parameter. So it's pretty, they are pretty well approximating the data up to Approximating the data up to reasonable values of beta, and the log normal is even going further. So, this is true for negative values of beta, so corresponding to a strong fluctuation of epsilon, but at the positive value of beta, where epsilon is weak, basically we don't really observe a collapse between the different curves, nor with the usual multifractal models. So basically, here now I'm willing to say a bit more about the statistics of the projected gradient. So basically, remember I'm evolving a solution to the tangent system, and then I project my gradient on the direction of this tangent system. And basically, so if one is looking at how this signal is behaving as a function of time, it's clear that. As a function of time, it's clear that it's something which is very intermittent, where one is observing some bursts of very strong fluctuations of sigma zero, followed by very smooth periods during which sigma zero is not fluctuating much. And typically, this is a bit surprising, the length of this burst is pretty long. I mean, it's much longer than the typical estimate. Than the typical estimate for the large-scale time of the system. Or minutes of the order. So we have measured also the autocorrelation coefficient. So basically the time correlation normalized by the variance of this sigma zero. And for the two different set data set that we have, so basically we observe qualitatively the same behavior. Same behavior. So there is a very significant decrease of correlations on times of the order of the Konogov scale, which is followed by a very slow decrease of time correlations, which is a signature basically of this very strong intermittency in a sigma zero. And so basically, there is a range somewhere here. So basically, it So basically it's clearer if one is zooming, of course, where the correlation decrease very, very slowly, almost like a logarithm. So basically this is clearer actually if we look instead of looking at the autocorrelation of sigma zero itself, we look at the autocorrelation of the log of sigma zero. Basically, we do, which is this red curve here. What we do observe is that for times inside the For times inside the inertial range, there is a long time lag during which the correlations, the time correlations, are decreasing like a logarithm. And basically, this logarithmic decrease with a rate which is twice one half of the rate that we observed when we do the same measurement. When we do the same measurement, but this time for the energy dissipation. And basically, which is suggesting somehow that one can more or less think that the amplitude of the projected gradient could be in law similar to one half of To one half of the power, one half of the cost grain dissipation. And basically, and then the slope that we measure is something which is close to 0.1. And this is consistent with the log-normal statistics that we were discussing before, because there is a relationship between this logarithmic decrease and the multiplicative models for log-normal statistics. And this was pointed out by And this was pointed out by Arne Odo and collaborators. So now, the fact that we have this very long range and very slowly decreasing correlations has implications on the measurements when we measure the variance of the stretching rates. So, basically, the variance of the stretching rate, remember, they are just proportional to the time integral of this time correlation. And basically, they have. And basically, they hardly saturate to a given value. So here they are represented as a function of the time over which the stretching rate is computed. And basically, what one expects is these things to saturate to a given value at very, very long times. So you see at times which may be of the order of tens of the larger d turnover times. So that then we can get some estimate of the variance entering the central limit theorem. So here, if we are interested in time smaller than the larger determinant of the time, what we do observe is the presence of random time scales over which this variance is growing actually like a parallel. Growing actually like a power law. So it's not constant, but rather growing like a power law. And basically, this is something on which we will try to draw some conclusions on the form of the fluctuations of the finite fun of exponents. So basically, if we look at high-order fluctuations, so by looking at the moments, so not only the values, but also the moments of the stretching rate. The stretching rate, so of the centered stretching rate. What we do observe is that, as a function of time, they do behave as parallels, indicating with an exponent which depends non-trivially on the order of the statistics, indicating that there is a clear link with the multifractal nature of the terminal fluctuations. And so basically, actually, the actually the the so we can measure uh so basically if if if the fluctations were were just Gaussian all this exponent alpha p will be will be equal to zero and if we measure them basically what we do observe so we measure them inside the inertial range what we do observe is that they follow some law which is pretty well approximated again by the log normal statistics assuming this time that we Assuming this time, that we can make a connection between the finite time searching rates and the value of the dissipation cost grain on the time scale at which this stretching rate is computed with a correction which depends on the Reynolds number, of course, because we know that this quantity will fluctuate as a function of the Reynolds number, but the Reynolds number computed at the scale at which we are doing our course graining. scale at which we are doing our cost graining. So basically assuming that we can write this stretching rate in this way, basically what we obtain is a relationship between the moments of the stretching rate and the moments, I'm sorry, it's not a capital T should be tau here, and the moments of the Gauss grain density, which is given by which is followed by this dashed line here. Followed by this dashed line here. So now going now to the next step, which is the distribution itself of the searching rates. So basically, what we found is that there are two behaviors depending whether or not we are looking at strong fluctuations or weak fluctuations. So if we assume that the switching rates are following the usual Following the usual large deviation form, which is based on something like exponential minus t times a rate function. What we do observe is that indeed we have some collapse of the different estimation of the grammar or the rate function corresponding to different time scales. Corresponding to different time scales, but only on the left-hand part of the distribution, which corresponds to values of the searching rate, which are less than the Yapunov exponents. So basically, the collapse is so good that you don't see that there are many curves here, which are collapsing on the top of each other. I mean, for time scales, which are for almost all time scales above maybe 10. Maybe 10 to 8000. But then, for the right-hand side, fluctuations for which corresponds to values of sigma, which are much larger than the average, I mean, we need to wait a very, very long time in order to start to see a collapse to the gamma function. And this time being clearly of the order of the larger determiner time. But in the for time. For times which are inside the inertial range, what we'd observe is that we have absolutely no collapse to a master curve, but rather we have some dependence on the coarse graining time, for which basically which are indicating that the longer we wait, the more important are the fluctuations that we can get. So now, with the previous considerations on the moments, basically, there is another way to look at the same data by just focusing this time on the large fluctuations, which corresponds to assume that the searching rate itself has a fractal distribution, so basically, which is somehow a consequence of the fact that the Consequence of the fact that the moments that we observed here, so the positive moments, are going like parallels of tau. And so now by rescaling differently, this time, instead of just looking at the separation, we look at the exponents somehow of the stretching rate and we rescale the PDF. I'm sorry, we rescale the PDF with the logarithm. With the logarithm of time, what we observe is that the different distributions are collapsing on the top of each other, and they correspond pretty well to the log-normal distribution. So basically, we have two behaviors, one which is the usual large deviation coming from the sum of almost independent variables for small fluctuations, and something which is more like a fractal. like a fractal distribution where basically the typical stretching rates are going like parallels with some singularity exponents, which is distributed with a given codimension. So just to conclude, so basically what we have seen is that turbulent intermittency has strong impacts on the distribution of stretching rates. So in particular, it's decreasing the Lyapunov exponent as a function of Leynz number, but also Exponent as a function of Leynz number, but also increasing fluctuations, that there is a failure of the central limit theorem at intermediate times because of the long-range time correlation of the Lagrangian gradients, and that the measurements at the end might be very sensitive to the length of the time average because of this weird behavior where there is no central limit theorem. So the fluctuations of the finite time searching rate, they seem to follow two different large deviation principles, which is something a bit funny. So, which is something a bit funny because for negative fluctuations, for small fluctuations, it's like an additive large division principle where we are summing a number of elements which is proportional to time. While for the large fluctuations, basically it's more like a multiplicative large deviation principle, where the number is now the logarithm of time. And basically, now we are working on trying to formalize a bit. We are working on trying to formalize a bit this statistical study of this kind of large deviation principle by looking at sums of local rate variables. So basically, we can assume that the switching rate is a sum of random variables with logarithmically decreasing correlations. And basically, what we want is to find what we can say on the statistics of this sum of large numbers. Statistics of the sum of large numbers. And I will stop here. Thanks. I would like to make a short remark, if possible. Of the first point of Jeremy's summary, I think that this long arrange time correlation of the Lagrangian gradient is probably a Lagrangian counterpart to multimode correlation. Counterpart to multi-mode correlations, which I believe must be present in turbulence. So, this is maybe the Lagrangian side of this long correlation between different or maybe a remark. Maybe this is wrong, but the negative fluctuation. The negative fluctuations, it seems quite natural actually that the negative fluctuations should obey the standard large deviations principle for IID random variables with thin tails. These negative fluctuations are... The Lyapunov exponent of an incompressible flow is greater than or equal to zero. And this Lyapunov exponent is some positive number. So when you're estimating these events, you're estimating the event of your conditioning on Conditioning on events where the random variables are constrained to lie in some compact interval somehow. So it seems quite natural to me that for negative fluctuations, it should be kind of controlled somehow. The positive fluctuations are far more interesting. I completely agree. They're way larger than they should be somehow. But this is kind of the art of the problem. Anyway, I don't know. Anyway, I don't know. Yes, but at the same time, so basically there is something which is a bit confusing, which is the fact that if you think about calm regions, so things which will contribute to basically to small fluctuations, what you expect also at the same time is time scales to be very long in that case. Because if you have small velocities or small gradients. Or small gradients will give long time scales. And so basically, I was actually, I was expecting the reverse. I was expecting that the fluctuations will be weird when looking at negative fluctuations. So it's a bit counterintuitive at the same time. I think this is, it depends a lot on the specifics of your model, though, right? This was kind of like a Cretan type of Type a velocity field, right? Something like this. What was the velocity field again? So it's a solution to Navier Stokes? Yes. So, I mean, I think that the cam Torai, even if they are there, they should be extremely tiny. But we can talk about this. Maybe this isn't so surprising to me. Okay, thank you. Could I make just a little bit? Could I make just a quick comment? Very quick. Jeremy, I think I have good news. Actually, I think this is a case where putting in thermal noise is going to help. So in fact, talking, you know, talk more with Alex about this, but I think that they have a lot of tools for studying Lyapunov exponents for both Eulerian and Lagrangian flows with extra stochastic noise. So this actually makes the problem in some ways easier. Problem in some ways easier. Yeah, because you're losing correlations quicker. So they have nice tools to address this. There's something quite scary about this, though, that the majority of our toolkit is geared towards this kind of stationary picture, but this interesting multi-scale behavior is occurring at a kind of intermediate time scale. This is something that happens kind of often in turbulence, right? happens kind of often in turbulence right it takes time it takes a lot of time for the uh the the process to kind of equilibriate uh fully right so these intermediate time scales are very important and um no this is this is kind of a major challenge right to kind of tailor ergotic theory to these intermediate time scales in a meaningful way um anyway i'd be happy to talk more about this uh yeah Coast, can I ask a question? Yeah, sure. So, so I was gonna ask this before. Unfortunately, I was driving home from an appointment when Greg was having his whole discussion about sub-comograph scale. I mean, one question I have, though, is that a lot of these models, you know, like some of the models that Alex has done and things like that, require the forcing to be, you know, really rough at fine scales. So they essentially kind of posit a priority. Kind of posit a priority a fine-scale regularization. And I guess I was wondering if you think that that is the fine-scale regularization to put in fluctuating hydrodynamics, right? Is that clear that it should be so rough? And if that was true, would that not, would that noise not obliterate what Jeremy just talked about? Hi, Jeremy. It's nice to see you. It's been a while. Well, I guess I don't, I mean, it's extremely rough because, of course, the spectrum of the noise is growing with wavelengths. Of the noise is growing with wave number, right? It has to, it has to grow like k squared, and so you have a very rapidly growing noise. But I guess what we see is that the, you know, the part of the traditional dissipation range still exists, and then it becomes just Gaussian. And so there's a pretty quick transition from something that looks a lot like traditional Na'vius-Dokes dissipation range and then around. Range and then around the Komogura scale, you very rapidly go into something that's close to Gaussian. Just you really do want to put it like in an equipartition thermal bath at that point. Absolutely. That's not what I want. That's what nature wants. No, no, I understand. I understand. I take whatever nature gives me, but yeah, I'm just saying I take what it gives me. So I think we should postpone the discussion to the Related to them. Yeah. Sorry for interrupting. So let's continue. The next