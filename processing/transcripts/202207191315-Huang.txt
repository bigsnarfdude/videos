Name is Dominic. So I am a master. I just done my master's study at UBC Okenegin. So my supervisor is Dr. Warren here. So today I'm mainly like presenting my thesis, sorry, my master's thesis, my master's thesis. So okay. So in today's talk, I'm going to introduce the decode method we developed. So this is a Developed. So, this is a hybrid method. So, our goal is to combine the direct search, the model-based search, and line search in the same method. And on top of that, we were able to develop the smart default method, which allows us to choose the proper strategies more intelligently. And then we apply our method onto the solid tank design problem provided by UBCO Joe Group. trial group so uh and um so here is my one-dimensional black box uh black box figure so we are dealing with oh sorry yeah that's one dimensional that's just one line you see we i don't have that box there or i don't have any fancy box here just a question mark so that's why it's one dimensional uh okay so um we are dealing with black box function and then we are using derivative Box function, and then we are using derivative-free method. So, um, the reason why we want to do a hybrid approach is that it's because of the nature of black box problems. Although we have a lot of well-developed durative-free method, we do not know how to choose the appropriate method. So, inspired by the Arculif method proposed by Mano et al. 2020, we combine the They combine the strengths of three search strategies into one method. So we took this idea and we moved one step forward. We combine the strengths of three kinds of search strategies into one method. In addition, we allow the method to choose these search strategies dynamically and adaptively. So let's start from the framework of the qual method. Framework of DEQUAL method. So DQuo stands for direct, quadratic, and linear step. That represents the three major search steps of our framework. So we initialize our step lengths, we begin our search steps, and then we update, stop, or loop to the next iteration. So I'm going to introduce the concept of the three search steps and the And the direct step, what we are trying to do is to search on the directions of rotated positive and negative coordinate direction by step length of delta k, just by one step length. So here what we are dealing with is a rotated coordinate direction, and to properly guide such rotations, we came up with this idea called desired and undesired direction. Direction. So, in the desired direction, what we are trying to do is to, if we have some direction RK, that's our sober belief that it's likely to be a decreasing direction. It's going to mark it as a desired. And then we try to align our search direction with Rk. So if the solver believes Rk is likely to be an increasing direction, that means it's undesired, then we try to. Then we try to rotate our search directions such that they stay away from RK as much as possible. And the first strategies we came up under this framework, or like actually like manner they did it in the Arculav method, we inherited from them is the random rotation. So it simply alternates between the coordinate direction and just a random rotation. And we're going to introduce more. And we are going to introduce more direct step strategy in the next section. So for now, let's just keep with the random rotation. And the next thing is the quadratic step. So the quadratic step is trying to use the model-based strategy. So we are going to extract the quadratic information from some previously evaluated candidates within the trust region. So we use two kinds of models. We try to use the least squares. We try to use the least squares quadratic model, and we try to use the approximate Newton's method. So, the idea is that here the green curve is our objective function. We take some sample point, we try to approximate this function by this black curve over here, and then we try to evaluate at the minimizer of this quadratic model and see if we can gain an improvement. Improvement. And the lastly is the, so the last search step is the linear step. And the idea in the linear step is that we want to search just on one single direction. And there are two pieces of information we want to determine. So firstly, is a fixed search direction L, and secondly, is some linear search steps alpha j. And then here we can see if we got these two pieces of information, we can search. These two pieces of information, we can search on this fixed direction as some, like in this case, as three candidates. So, how do we determine these two these two informations? So, firstly, is the search direction. So, we had two idea. We can use the approximate DPS descent direction, which is just the take the negative of the approximate gradient. And the approximate gradient is approximated from the simplex center gradient. From the simplex center gradient. And the second idea is to just use the last descent. And the idea of the last descent is that if we ever make an improvement from our last X best to our current X best, then how about we keep searching on these directions? And it could be a, and it's, if we are lucky, we are able to find an improvement in the same direction. And the next idea, so the next piece of The next piece of information is the step lengths. So also we have two strategies. So the first one is we simply use the step lengths delta K and we just take one step. So it gives us one candidate. And the second idea is to use the safeguarded bracket search method proposed by Mifflin and Straw Deer in 1989. And the difference is that right now we are able to That right now we are able to obtain multiple search candidates for us to search in one on the same direction. So this alpha is just a parametrized. So it's where we try to parametrize our original objective function into a one parameter function. And so here this gives us four different linear step strategies and by step strategies and by combining by combining two search direction strategies and two search step strategies. And then after the search step, we go to the update step. So this is going to extend, either extend, shrink, or maintain the same step length according to the results, succeed or fails from the direct quadratic and linear step. And so here is just a flow diagram of Dequered. We start from initialization, we got some initial parameters, we go to the direct step search. If we find the improvement, we proceed with the upstate step and go to the next iteration. If we didn't, we go to the quadratic step and we try to search on the minimizer of the quadratic model. If that's an improvement, we go to the next step. That's an improvement, we go to the next step. And if that's not an improvement, we try the linear step. And whatever the result we get from the linear step, we proceed to the next iteration. So here is just a small demo of our default method. And this contour diagram here is our objective function. The yellow one is the high region, the blue one is the low region. And of course, this is invisible to our solver. Our solver. And this red dot is our initial search point. In the first iteration, we take we search on these rotated coordinate directions, and then we find a new improvement right here, the red dot. And then we are able to approximate the simplex, the center simplex gradient, which gives us a steepest descent direction. But we already find the improvement, so we go to the next. Define the improvement. So we go to the next iteration and with the extended step lengths. So here there's no improvement found. So we go to the quadratic step. And this is the prediction from our quadratic model. That's not a very good prediction. So that's not an improvement. So we go to the linear step. We search at just take one step in this DPS descent direction. And that's still not an improvement. So we go to the next step, and then we start shrinking our step size. Shrinking our step size. So, as we can see, like all these candidates is slowly converging to this low region. So, does it actually converge to a local optima? So that's what we try to answer in our convergence analysis. So, in our convergence analysis, we were able to show that if function f has a compact level set L x naught, x naught is our initial point. Not is our initial point. And in addition, if the gradient of f is Lipschitz continuous in an open set containing this compact level set, then these candidates produced by the D4 method will have that the limit of the iteration will give us the length of the iteration will give us these the gradients, sorry, the norm of the gradients of f x k. gradient of f xk will be zero. So what this tells us is that if we run our iteration for infinite number of times, what we have is that the xk have a limit point x naught, x star for which the gradient is zero. And that is, we have a local optima at the limit. And the proof can be found in my thesis. So the next question we will try to answer. So, the next question we will try to answer is the performance. So, we try to do hybrid to boost our to try to make an improvement in performance. So, how well do we actually does it actually work? So, what we have is one option from the rep step. So, just our random rotation. We have our three options from the quadratic step. We can disable it. We can use the other two strategies. We have five options from our linear step. options with our from our linear step. We can disable it. We have other four strategies. Is there a winner among these 15 combinations? So here we cannot disable direct step because it is crucial to the convergence of our server. So there's only one option in the direct step. And we try to answer this from the performance profile. So firstly, we need to define our stopping conditions. So for the sake of time, I'm going to skip this. Time, I'm going to skip this. So, what we are trying to achieve here is that our final solution should have a step length that's between this mean step and max step, and the norm of gradient should be small enough, and we should not exceed our number of function calls, which is max search right here. And so, here is our performance profile. So, in the performance profile, we try to get as higher as sooner as possible. So, we try to get higher as soon as possible. Possible. So we try to get higher as soon as possible. And here, if you just look at this profile, so the strategy one, two, three is our best over in this case. And this one, two, three stands for direct strategy one, quadratic strategy two, and linear strategy three. It's a winner, but it doesn't win by a lot. So let's see what else, what other information can we extract? So just look at this map. So just look at this map, sorry, just look at this profile, we can see that our solar roughly forms into three clusters. So the first cluster here representing the quadratic strategy two, and this second cluster here representing the quadratic strategy one, and this last cluster, the slowest one, representing the quadratic strategy, representing disabled quadratic. Representing disabled quadratic steps. That means our quadratic strategy is very good, and we should use quadratic strategy too as much as possible. And the second thing we will try to answer from this profile is that how which one is the best linear step. So, but here what we can see is all these linear steps are mixed up with each other. So, in this top. With each other. So, in these top clusters, the three is a pretty obvious winner. So, that's good. But in the second cluster, they all mix up together. And in these third clusters, they all mix up with each other again. So, it's very hard to find a good winner for the direct step. So, this idea came to our head. So, does it mean that all our direct step actually has their own their own? Their own distinct advantage. So, our goal from the direct step is to try to find the best scenario for each different distinct strategies. So for distinct direct strategies, such that we are able to such that we might be able to gain a very huge improvement. So before we move on, let's see like what else can we extract? Like, what else can we extract? So, this strategy 100, it's very close to just a normal pattern search method. So, this is ours, it's in our slowest cluster right here. This blue cross dot line right here. And this strategy 111, oh, sorry, yes, strategy 111 is the RQLeaf method, and it locates right here in the second cluster. Case right here in the second cluster. And just by doing some combination, we are able to find a better method, strategy one, two, three. And can we do better? That's what we try to answer in the smart decode method. And so the smart quadratic step is pretty straightforward. As we said, we want to use the approximate Newton's method as much as possible. And this one has a streeter. Has a streeter rule to implement it. So it can only be implemented if we have a well-defined Haysian approximation. So that's why we can only do that if we have Hayesian approximation well-defined. If that's not the case, we check if gradient approximation is well defined. If that answer is yes, we go to the least square quadratic model. If not, we just disable the quadratic step. So quadratic step. So, the quadratic step is straightforward. How about the linear step? So, we did a lot more experiments and then we find these trends for all our linear step strategies. So, what we found is that one step in the last descent direction has the best exploration abilities. That means it's best, it works best when we try to do a global search. It works best when this optima is further away from our. Is further away from our current search candidates. And this bracket search in this deepest descent direction has the backs exploitation ability. That means it works best when we try to do a local search, and then it works best when our optima is super close to our current search candidates. And this one step in the steepest design direction is where we think. The steepest descent direction is very simple and efficient. We found that we can use it in all other general cases because it's just one candidate. So with this in mind, we developed the following rule for our smart direct step. If the last descent is further than the step length, that means that our current progress, our current progress. Our current progress is much much further, sorry, is much larger than our current search region. That means probably our optima is still very far away from us. So we just use this strategy with better exploration ability. So if that's not the case, that means probably like our optima is already within our trust region. So we try to see if the step length meets the stopping condition. meet the stopping condition. If that's the case, that tells us the only thing we need to improve is the gradient. So we try to use the strategy with the best exploitation ability. And so we take bracket search in the steepest descent directions. And if that's not the case, we just use so we just use the most general strategy here. That's one steps in the steepest descent. One steps in the steepest descent direction. And so, what can we do about the direct step? So, we did a lot of experiment for the direct step. So, we didn't find a very good improvement. So, this idea come to our head. If we are able to extract some information from the last iteration to guide our rotation, probably we can get a better result. Probably we can get a better result. So, what information can we extract from the last iteration? So, let's see from the last direct step, it can tell us if our last rotation is good. And from our last quadratic step, it can tell us if our last quadratic model is good. And from our last linear step, it can tell us if our last linear search direction is good. So, with this in mind, we are So, with this in mind, we are able to use this information to guide our rotation in the direct step. If the last direct step succeed, then we want to keep the same search direction. So we keep the same last rotation direction as desired. And if the last quadratic step succeed, that means the quadratic model probably be a pretty good approximation. And we just use the last quadratic model, the Newton's. The Newton's direction from the last quadratic model as desired direction. And if that's not the case, we check the last linear step if that succeed. And if that, that means probably our linear step direction is desired. So we keep the same linear step direction as search direction. And if that's still not the case, so we just mark the search direction as undesired. And for all the other special circumstances, And for all the other special circumstances that we cannot extract these information, we just keep with the coordinate direction. And that's our smart decode step. So how does it actually perform? So we do the experiment with the same test problems. And here, strategy SSS stands for Smart, Direct, Quadratic, and Linear Step. So which is the yellow curve right here. Yellow curve right here. And what we have is that in 45% of problems, our smart equal method is the best solver. And it's able to solve like 15% more problems than our last winner, which is strategy one, two, three. So that's pretty good progress. So let's see, we make one step right here from AccuLeaf to, sorry, from Petro. So, from pattern search to RQLeap, we make one more step to the default method, and then we are able to make one additional step to the smart default method. So that's good. So, it's good by theory. How does it actually work in the experiment? That's what we try to implement in the solid tank design problem. And so, here is the solid tank design problem from maybe. From ABCL job group. So, our goal in the solid tank design problem is to design these what they call solid tanks. So, here, these five parameters defines the geometry of the solid tanks. And then we are trying to find the best, the design with the best image quality. And that's a black box function. Black box function. Sorry, there's a black box problems, or this evaluation is done from the simulator. And here is all, here, this is the constraint for our parameter. So here it tells us this is a box constraint problem. So we need to do some transformation to adapt our method for this box constraint problem. And more details can be found in my thesis. But here is But here is the result we found. So, in this original approach by the UBCO draw group, they used the green search method. And these three columns represents three different profile settings we can give for the solid tank design simulator. And what we can see here, if we compare to our original approach, all this MAR decode method is able to achieve a better design than the GRESearch method. Than the GRI search method. So, yeah, that's more reliable than GRISERCH method. That's good. And then we also try to implement this with Nomad. So this is old version of Nomad. So we know there is a newer version. We would like to try that as well. And what we found out that is that in two of the profiles, our method actually do better. That's water and clear view. But in the FlexDose 3D, our method flexed those 3d our method is actually worse than the nomad so uh so this is uh so this is not so this cannot tell us which method is the better method for these problems but at least it tells us our smart default method is pretty competitive compared to nomad and also just to keep in mind here in the nomad we didn't spend a lot of effort to fine-tuning all the parameters To fine-tuning all the parameters. So, this is not a very fair comparison in the academic sense. So, what do we have for the Deco method? So that is a local DFO method. So, just for unconstrained black box optimization problems. It is able to combine multiple search strategies. It is converging to local. It is converging to local optima for some functions. And the smart decor method is developed under the framework of decomposer. It is built under the same framework, so inherit all the characters of decor method. It's able to choose search strategies dynamically and adaptively. And it's faster and more robust than any simple combination from our Decor method study. And it is more reliable and efficient than our original approach. Than our original approach, which is the grid search method for the solid tank design problem. And so, in the future development, we would like to integrate more search strategies for the decro method. So, that's just a framework. It has an ability to integrate with a lot of more search strategies. And we would like to design a more sophisticated decision tree. And in addition, we would like to specialize the decision. To specialize the decision-making mechanism for specific revolutions. So, thank you so much for listening to my talk. So, the code in the MATLAB is available at this link. And here is the two references that shown up in my talk. And this is a reference to my master thesis. Thank you so much.