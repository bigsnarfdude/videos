Let's begin with our next talk. We've got a talk by Wesley Calbert on computable structure theory. So please, tell us things. Thank you. So I should start by pointing out a procedural matter. I was not intending to give a history of computable structure theory when I categorized ways of thinking. Categorized ways of thinking and different kinds of questions, I realized afterward that it could appear like a history, which it is not. And I should figure out which of these buttons actually does advance the slide. Okay. Leslie, while you're figuring that out, would you like questions during or after? I will be happy to accept questions at any time and respond to them as well as I know how at that time. As well as I know how at that time. Okay, and for those of you who are remote, you're welcome to either just unmute and speak up, or if you want, you can put it in the chat and I will be your voice. All right. Vince has stepped out and I don't know how to operate this thing. Let me embarrass myself by pretending I'm helping. So what I have now is Zoom sharing my slides. What I need actually is my slides so that they'll advance. My slides so that they'll advance. He showed me this working perfectly a moment ago when we just had the slides. I haven't checked whether. Okay, this will work. I can use the keyboard. Yeah. Okay, sorry. I think we had a conversation with that. Okay. Conversation about. Okay, we got it. So this should not be mistaken for history. In particular, in trying to get good coherent exposition where everybody agreed on what terms were used for what things. In many places, this is slanted toward some of the Western work. Oftentimes, there was Oftentimes, there was Russian work, either simultaneously, sometimes earlier, occasionally later. There were reasons that at that time the two communities were not able to talk to one another, reasons that were non-mathematical, and reasons that have given some of us that have worked to amend this gap cause for concern in recent years. But that belongs to history. It will also It will also sound occasionally as if I am talking about particular periods of thought that opened and closed, and that is not true. Everything that I will talk about does have some thread leading down to current work that is actually still interesting. Do not mistake something's position in this talk as relegating it to the past. Now, solidly in the past, we have Van der Berden asking how much field theory can be carried out explicitly. And it's not entirely clear that he knew what he was asking here. He definitely knew some things that he would say counted. If you have, say, the rationals. Say the rationals, and have a particular finite extension of it in mind, actually building that finite extension, that he figured he could do explicitly. And there were some other things he could do as well. Now, since it's 1930, language like computable or recursive or effective or any of the other terms that you would like to use. Other terms that you would like to use, definable in typed lambda calculus, whatever. This is a bit early for that. And so it's also, critically, a bit early for negative answers to this question. You need a definition to get proofs that something can't exist. And so, once some of that other stuff was worked out, that. That could provide a framework for saying what van der Veerden meant. Fralik and Shepardson wrote a paper claiming that this is what van der Verden would have meant if he had had the language for it, going through and actually proving in this framework some of the things that he proved in his, and showing a few newer things as well, sometimes sharpening things, sometimes. Sharpening things, sometimes entirely new things. But one thing that they said was an example of something that he would have meant. Take a ring whose elements are equivalence classes of natural numbers under a computable equivalence relation and whose operations are computable functions. That they called an explicit ring. We have other names for it now, but they called it an explicit ring. Called it an explicit ring. Now, the equivalence classes of natural numbers. A lot of times in modern work, you won't even see the equivalence stuff mentioned. You'll just think of these as elements, and you have this matched up with natural numbers, and you reckon that equality should be computable. It amounts to the same thing, although. The same thing, although, if for instance you're building structures by taking quotients of other structures, this can be helpful. And that sometimes does come up in rings and fields. And indeed, if you have a field of this kind and a finite extension of it, then the finite extension is. The finite extension is explicit for essentially the same reasons that everybody would have reckoned at the beginning. You can build an extension by an indeterminate. You can take a quotient by the appropriate irreducible polynomial. That gives you a computable equivalence relation. Also, if you have an explicit field with a splitting algorithm. Splitting algorithm does not mean factors it entirely. Splitting algorithm says does it factor. And if you take the finite extension of that, then you can carry your splitting algorithm across to the finite extension as well. Extension as well. I think I may have copied the citation wrong on that one. Either that or I had my head in historical remarks in the Freelich and Shepherdson paper that I do not now remember. And I think that may be the case, that they were tracing the Case that they were tracing the reasoning back to him. But if you had a splitting algorithm that covered all fields uniformly, all computable explicit fields uniformly, then you would be able to compute every set of natural numbers. So you can't have one of those. Where was that? Yes, there it is. So I think what it was is that Freylich and Shepardson attributed this insight to Van der Verden, and they said, oh, and by the way, since we now know you can't do that, there is no general splitting algorithm. You can still hope to have splitting algorithms for particular fields. And this doesn't even entirely exclude the possibility that every Possibility that every explicit field could have a splitting algorithm. It doesn't, but that theorem doesn't exclude the possibility. So, if you have an explicit field and a finite extension of it, then the finite extension is explicit and unique up. And unique up to computable isomorphism. Any two copies of this, there's going to be a computable isomorphism, a computable function witnessing that. Computable isomorphism. Fixing F. Fixing K. Fixing the level one, yeah. Also, if you start with an explicit. Also, if you start with an explicit field, you can extend it, and you can extend it to something that has no computable transcendence basis. And in a bunch of indeterminates, presumably you know which ones you've added, that's no problem. But you can extend it in a similar way where you can't find those. You can't find those. And I mean, you could look for them. If you tried to look for them, what would you do? You'd say, okay, I have this thing that doesn't look like it's the zero of any polynomial. I mean, I haven't checked all the polynomials yet, but it looks like it's different. And you could even start checking some of the polynomials. And as long as you don't find any that it satisfies. Find any that it satisfies, you're okay. But you run into the halting set again. So the way you build this extension without a computable transcendent space, I've persuaded you, I hope, that it's at least believable that there could be such a thing. Here's how you would prove it: start with your field. Start with your field, add on a bunch of indeterminants, and take some computable function without a computable range. By 1956, okay, we know those exist. 1930? Wait, how do you know you can do that? Okay, 1956, yeah, you can do that. So then take a bunch of polynomials. Pn are the primes. So You get one of those for each value in the range of lambda. Take the quotient by that stuff. That'll give you an extension. And if you could find a transcendence basis, then you could compute the range of lambda. I also proved that every explicit field has an explicit extension with no splitting algorithm. So, not only are there fields with no splitting algorithm, but they are in some sense dense. Go forward a few years. So far, I haven't, I've occasionally slipped up and said. I've occasionally slipped up and said computable field. Explicit field was the language they were using at the time. But the reason I followed that language is to emphasize that at this stage, people are still thinking very much about algebra. And they're thinking about algebra from a particular perspective, from the perspective of which algebraic things could you actually do, and which algebraic things can you? Things and you prove they exist, but they're out there in the ether somewhere. Rabidin was trying to do a similar thing. He actually did use the term computable. He said that a group is computable if and only if its elements are equivalence classes of natural numbers under a computable equivalence relation, and the group operation is computable. And a ring is computable under similar circumstances. Is computable under similar circumstances. So this is the same thing as an explicit ring. And now we have it for groups too. Having it for structures, I do not see in the literature at this stage, but having it for groups and rings is now there. And also some stuff that if you That if you had asked the question before, is not too surprising. It actually does work out. Take a computable group, take a computable normal subgroup. That quotient should be computable, and the projection onto the quotient should be computable. This is the theorem from that same paper that I guess gets mentioned the most these days, especially if you hear Russell or occasionally me or some other people talk about it. If you have a computable field, then there's a computable algebraic closure and a computable embedding of f into its closure. Now, if you have not heard this joke before, you will Before, you will think that this is a very, very odd article to use here. Because it should be that the algebraic closure of F is computable, and there's a computable embedding of F into the closure. Well, yeah, stay tuned. I actually do mean A. I had forgotten that I was going to move on from that so quickly. Yeah, you can actually produce two different algebraic closures where there's no computable isomorphism between them. So, in this sense, the existence of algebraic closure is true in a computable perspective, the uniqueness is not. The uniqueness is not. Wesley, can I ask a question? Absolutely. Can you, if you have those two algebraic closures, can you at least compute an isomorphism of them from zero jump? Or for every Turing degree, can you find algebraic closures that the Turing degree can't. Let's see. So, algebraic closure, uniqueness of algebraic closure. I know you can prove in ACA not, I think one jump is enough. If I. Is enough. Okay, I see people that know and are not giving a talk right now nodding, so I'm probably right that one is enough. Okay, thank you. Anything else at this point? So there is still work in this effective algebra direction where you think about algebra from the perspective Algebra from the perspective of what could you actually do. Definitely, there's quite a lot done these days on reverse mathematics. This acronym ACA Arithmetic Comprehension Axiom that I just dropped in comes from that line of work. And the original paper thought about quite a lot of questions of this kind, and others have since. Definitely, you can see recent work by Joambaleti and Demir Chatari. By John Beleti and Dmir Chaparov and several others on if you look at a unique factorization degree, how complicated can the set of primes be? There are still people working from this direction. Oh, we have also Brown and McNichol and several others on LP spaces. And LP spaces, I know if you look where they come. I know if you look where they come in the standard graduate curriculum, they are analytic structures. It's a vector space with some extra stuff on it. There's another perspective on thinking about computable structures. Start with a computable Start with a computable language, by which I mean the set of symbols in your signature is computable, and the arity of each function and the arity of each predicate is computable. If you have a finite signature, that's absolutely great. If you like infinite signatures, no problem as long as you can keep careful track of everything. No cheating by encoding stupid things in the signature. Things in the signature. Once you have that, then you can put your numberings on everything. And you can think of a formula as a number. And a set of formulas is a set of numbers. So you can think of things as computable. In this context, you can say that a structure is computable if and only if its atomic diagram is computable. Is computed. So the atomic diagram should have all the quantifier-free formulas with instantiation of elements in the structure. You should be able to say 2 plus 3 equals 5, yes or no? Yes? Yes, yes. Well, in the structure I'm thinking of, yes. But you could interpret. That you could interpret all those symbols in other structures where it has different answers. I just insist that you be able to answer. I don't care what the answer is, only so long as you can give it. But Wesley, can I ask a question about that? Sorry. Absolutely. Just from an implementation perspective, so you're viewing the atomic diagram as a collection of sentences in a language extending the original language by adding new symbols for every element of the structure. Every element of the structure, might as well assume the structure is universes n, right? The naturals, and then just fix some effective numbering of the formulae in that extended structure. Is that in the extended language? Is that right? That's exactly it. So traditional computable structure theory, everything is countable. Yeah, we can work around the edges there a good deal. Is there a good deal? But the stuff I'm telling you about, think of things as countable, which means that they might as well be the natural numbers. And then, if you want to make a computable equivalence relation and make quotients with that, no problem. But yes, you should think of the structures living on the natural numbers. The atomic diagram consists of sentences in a language extended by all those natural numbers. Natural numbers, and you should be able to evaluate all of the functions, all of the predicates equality. You should be able to evaluate all of these things on this structure computably. Great, thank you. One that you don't hear about quite so much anymore, but it has been important and is nice when you can get it, is to say that a structure is decidable if and only if it's full elementary. If and only if its full elementary diagram is computable. So here you have not only the quantifier-free sentences, but all of the first-order sentences. Now, if you start with a complete decidable theory, then having a computable prime model. Having a computable prime model is equivalent to this slightly unwieldy condition. It says that the types are computable with a whole lot of uniformity. So it says that if you have a formula, you can find an index for a computable principal type containing that formula. So not only is every formula contained in a type, and the types, not only is every formula contained in a principal type, not only do all those have to be computable, but the relationship also has to be computable. Yeah, so index here. So, a type is a set of formulas. A set of formulas might or might not be computable. It can be thought of as a set of natural numbers. And a computable set as some Turing machine that computes it, take the natural number corresponding to that, like the encoding in one natural number. Encoding in one natural number of its source code in whatever programming language you like to use. Is there anything more than just carefully carrying out the usual proof of this and showing it can be done effectively? Or are there any serious tricks involved? Definitely the outline is carrying out the usual proof with attention to effectiveness. There may have been some There may have been some tricks needed at some place. It is not a long paper, and it is not, as I remember it, a complicated paper. I think it is making sure that things actually work, and sometimes you have to be careful to make sure they do. Yeah. Could the model, the prime model be computable or decidable? I'm thinking about the reverse direction, showing that if you have a computable prime model, then you can get this function. And I'm worried about being able to decide when you. Have to decide when you know something like the idea in my mind would be look for an element that satisfies phi, but you need to know it satisfies phi, right? I don't know if that's actually been proved about the second or so ago. That's a good question, and that's that's definitely something that I should look back at the paper and find out. Yeah, this may be what's supposed to be, T has a decidable prime module. The example they use there is mostly differential fields and their closures, but there you have quantifier recommendation. So it doesn't effectively say, okay, you know, quantifiers decide that you have to check. Yeah. I don't know. Good thing to ask, though. Good thing to ask, though. So this exemplifies a second direction of thinking about computable structures, where you're thinking about computable structure theory as a certain kind of model theory. And in fact, when I started doing it, you would hear the term computable model theory a good deal more than you heard the term computable structure theory. Structure theory. And I think by that time, by 20 years ago, I think the reality was maybe moving away from this perspective toward being broader. There were still people at art, people still thinking about a particular kind of model theory, just as there are people thinking about a particular kind of algebra. This is the way that people think about it. Ah, I even wrote down what the proof was. Yes, the proof is used the Hankin construction with a little care. About the same time, you see a paper of Millar working through a lot of classical model theory and showing a bunch of things that you can do and a few things that you can't. A type realized in a decidable model. In a decidable model is computable. So you can say what the formulas are. If you have a complete decidable theory and a computable type that's consistent with that theory, then you can realize it in a decidable model. And you can also omit types. Well, you can omit computable. You can omit computable non-principal types. There are also things that you can't get away with. So there is a complete decidable theory where all the types are computable and the And the computable saturated model is not decidable. And I guess the equivalence in the Harrington theorem earlier shows that you could also have the prime model not be decided. You can have all sorts of models not exist. Sorry, here it says the countable saturated model is not decided. says the countable saturated model is not decidable but could it be is it always computable or can you even make that stronger statement that it's not even computable yeah so that was that was james's question a minute ago um where i wasn't sure whether i had correctly copied um no that was a question though for harrington's theorem right so i'm asking it for the countable saturated model oh countable saturated model okay um yeah so what he proved is Yeah, so what he proved is not decidable. I think you could probably get not computable. I don't know for sure. I think these examples tend to have quantifier elimination. I don't know if this one in particularly, but. Yeah. Yeah, that would be a very sensible thing for Millar to have done in the paper that I have not read carefully. That I have not read carefully in a long time. So, yeah, the answer to the question is: I don't know. So, one case where this non-existence is at least interesting enough to make it look like more of a feature than a bug is this theorem of Tenenbaum that among models of PA, Among models of PA, the only computable model is the standard one. If you have any non-standard model, then you can recover non-computable sets by what happens with some of the non-standard elements. What happens, remember right, when you try to factor some of the non-standard elements. You might expect that a model theoretically nice theory. Maybe decidability isn't enough. Maybe you need a really nice decidable theory to have normal model theory work out, to have all the constructions work the way they should. At least from the perspective of existence of computable prime models, omega-stable. Omega stable is not good enough. And here, I do know that this was computable rather than decidable because of which language people were using for things in the Russian literature. In fact, strongly minimal isn't good enough to make everything work. Exactly how much it works or doesn't work. Much it works or doesn't work. Gantrav asked: okay, take a strongly minimal theory. I know what its models have to be. There's the zero-dimensional one and the one-dimensional one and the two-dimensional one. Here they are. Now, which one of these have computable copies? And he showed that some omissions that you wouldn't want are possible. More recently, you have Uri Andrews and Alice Mitfid give. And Alice Medvedev and Julia Knight and Stefan Lympt and some other people. I think they may have completely solved this by now. If not, they're close to it. A lot more is known about the answer to this question than was known then, and some of it fairly recent. Smallar was famously not optimistic about the future of computable model theory. Computable model theory. And yeah, you can kind of see from the previous slide or two where a person could get this idea. But others disagree. I've mentioned this work on the strongly minimal theories. It's also worth mentioning even the existence of prime models, existence of homogeneous models. Homogeneous models people have worked on more recently. And there are some subtle questions that you can ask around: okay, what degrees are there such that there is always a prime model of this degree? And there are some nice results there. Third perspective on computer The third perspective on computable structure theory is that if you insist on everything being computable, you get a different category. And the right analogy here, I think, is with topological groups. If you are a very, very carefully pure group theorist who thinks that a group is a set with an operation satisfying these three principles and group by Principles and group isomorphism is what matters, then you would be slightly puzzled by some of the things that go weird about topological groups. I mean, you can definitely have topological groups that are not isomorphic as topological groups, but as groups, they're isomorphic. And who would think of distinguishing two isomorphic groups? Well, you would think of it if you think about topological groups. You think about topological groups. And I think that perspective informs the broader idea of computable structure theory and this third approach to thinking about it. Okay, so we're adding on some more structure by saying that things are computable. You have this algorithm. Okay, what do you get in this world? So take a structure and take some relation on it. And I do not mean a relation symbol. And I do not mean a relation symbol, I do not mean a relation named in the signature, I mean some subset of A to the n. If you like concreteness, okay, let A be a vector space and let R be the relation on n-tuples saying that they're independent. Suppose that you have an exercise. But you have an existential formula. Oh. I think that should have been a fee here. Yeah, it definitely should have been a fee here. So, what you really want is to know whether R is computably enumerable in every computable isomorphic copy. Computable isomorphic copy. Notice I don't say every isomorphic copy, only the computable ones. So we're going to play by the rules of this game where we're thinking only about the computable stuff. Great, only think about the computable copies. But it might happen, and it does with vector spaces and independence, that yeah, it could be computable in one copy, follow an isomorphism over here that scrambles everything around. Yeah, you might not be able to find that again. Be able to find that again? Yes, yes. Let's see. No, this does not require the isomorphism to be computable. And it turns out that under some slight decidability hypotheses here, R is computably enumerable in every computable isomorphic copy, if and only if. If and only if there's a computably enumerable sequence of existential formulas that define it by their disjunction. If you like thinking about infinitary formulas, please start doing that now. If you don't, I will ease into that shortly. I thought I must have said something very strange. We're still waiting for that. I'm sorry to bother. Can you go back one thing to the previous slide? Sorry. Sure. Why existential and not just quantifier-free? Just quantifier-free. I mean, because couldn't I, if I'm an existential formula and I want to know if there's a witness, couldn't I just look at the matrix of that formula and be enumerating like tuples from the or oh, is this basically somehow um preventing zero jump from coming in? Is that why you require for existential? Because I'm just trying to naively think if I'm existential and I want. If I'm existential and I want to know if phi of CA is true, I would just start enumerating tuples from my structure. And if I could, and I can decide those, right? Because I'm a computable structure. I can decide quantifier-free things. So is this assumption somehow like allowing you to get rid of this use of zero jump? Or I'm just not quite understanding why you have existential formulae here. The existential formula in the big hype. Extential formula in the big hypothesis? Yeah. In the big hypothesis or in the second condition? In the big hypothesis. Yeah, so that I have always thought of that one as a technicality. It's a little bit more, it's requiring that the structure be a little bit more than computable. It does not require it to be decidable. It requires it to be decided. Decidable. It requires it to be just a little bit more decidable than computable is. So I think you probably could sneak in zero jump there in a lot of cases. Okay, no problem. You could make it, well, so you couldn't sneak in zero jump because you have the hypothesis that A is a structure that has this much stuff decidable in it. Has this much stuff decidable in it. So it's saying existential formulas can't do too much. Well, but like if you didn't assume this, right? So what like if you just have a computable structure and you want to decide phi CA for phi existential, you would on the face of it need zero jump, right? Yeah, yeah. So this is the you know yeah, this means this means that you don't Yeah, this means that you don't need that to decide this particular kind of existential uh problem in A. Okay. All right, thank you. It's probably fair to say that in 1981, that condition and the assumption irritated a lot of people. Why do we need it? It still irritates me. Actually, is it known? So, is it known that you need it? Is there an example of? Known that you need it? Is there an example of this theorem? I think it's known that you don't. No, okay. Okay, for this, yeah, for this theorem you do need it. Yeah, I had not actually planned to follow this a whole lot farther in this talk. Yeah, you do need it. Okay, this problem of treating things as different that are isomorphic, or if you like the topological groups metaphor, thinking of a different kind of isomorphism now. You might look to see how an isomorphism type, a classical isomorphism type, how it splits in this new category. Because there are fewer isomorphisms now. Fewer isomorphisms now. And you may have one isomorphism type that, okay, everything in there is computably isomorphic. Or you may have infinitely many different things that are pairwise not computably isomorphic. It's hard to imagine there could be any other options. Yeah, probably there aren't. But yeah, for vector spaces, for instance. Spaces, for instance, if you have vector spaces over, let's say, the rations, a finite-dimensional vector space, okay, once you know a basis, that's finitely much stuff. And so is entirely free from a computability perspective. Okay, name these three elements over here, name these three elements over here. I know how to make an isomorphism. Now, there's not a whole lot of uniformity in that computable isomorphism, and you can. Computable isomorphism, and you can productively follow that track too. Now, if you have an infinite-dimensional vector space, well you can hide those dependence relations in a whole lot of different ways. And so there are infinitely many copies of this same vector space which are not computably isomorphic. And you see here why somebody might think that one and infinity are the only options, because you do see with vector spaces at least, I mean one example is an excuse to start making conjectures. With vector spaces, you have a critical thing that if it's finite, dimension one, if it's infinite, dimension infinity. It's not always that way. You can have two or any other finite number that you wish. And in fact, more recent work has shown that you can have these in all sorts of different classes of structures. You do not have to have something. Okay, you really do have to have something that's specially built for the occasion, but you can get it, for instance. But you can get it, for instance, in an L Potent group. You can get it in integral domains. You can get it in fields. We don't know if you can get it in algebraic fields, but you can get it in fields. But it's not easy to get it in any of these places. And usually, the way you get it in any of these places is you take that one and you come up with a real And you come up with a really good coding strategy. You come up with a way to build whatever it is, a nil potent group. Build one of those that somehow has the structure with one binary relation or whatever it is somehow represented in a way that you could recover by looking at it computably. Now there are. Now, there are lots of examples supporting the one or infinitely many thing. Boolean algebras, count how many atoms. It goes a little bit like the vector spaces. Linear orderings. Look at the successor relation. If there aren't too many successors, computable dimension one. We use the term computably categorical to mean that there is computable dimension one, to mean that that isomorphism type does not split under computable isomorphism. Now, for thinking about these things and for making at least that second condition of the Ashnerode result. The Ashner result prettier, and a lot of other things too. It's sometimes helpful to think in infinitary languages. So a computable sigma zero or pi zero formula is a first order quantifier-free formula. A computable sigma alpha plus one formula is a computable disjunction of formulas of the form there exists. Of the form there exists x such that r where r is pi 0 alpha. Well, r is pi alpha. And similarly with the pi's, take a conjunction and a for all sorry, can you just say what you mean by a computable disjunction or computable conjunction? What I mean. What I mean is that the set of formulas that you're conjoining or disjoining is a computable set of formulas. Okay, great, thanks. And the number of variables and the existential or universal quantifier, they don't have to be the same for each of the formulas? For variables. Let's see, I don't think you need any consistency of how many. How many variables are you using there now? Okay, thank you. Finitely many. Yeah, you can only have finitely many variables. Yeah, this should be a conjunction here for the pi alpha things. The idea is that if you're thinking from a computable perspective, those things that you learned early on about compactness. Early on about compactness, saying that you can't really define a torsion group, for instance. Well, sure, I can define a torsion group. I just go looking forever and see whether I ever double back on myself. Okay, I get why you can't do that, but you can't do that for the same reason you can't say there exists. It is exactly the same reason. And this definition. And this definition takes account of that intuition. Doing a search for one thing that's going to work, whether it's phrased as an existential quantifier or phrased as an infinite disjunction, that costs the same amount, whichever way you phrase it. Looking for the one-counterexample, whether it's phrased as a for-all or whether it's phrased as a conjunction. As a conjunction, either of those costs the same amount. Now, if you don't say computable, then you've got something called L omega 1 omega. You get arbitrary countable conjunctions, arbitrary countable disjunctions, and only finite nesting of quantifiers. And what I just told you about the intuition of costing the same amount for their exists as for a disjunction, there is actually some truth in that. You can prove that satisfaction of computable sigma alpha formulas in a computable structure is sigma z. structure is sigma 0 alpha and pi 0 alpha the same. All conceivable uniformity is the wording that I received and I also pass it down to you. Uniform in the structure, in the formula, in the notations that you use for the ordinals in the formula, everything. Now there is an older theorem in which you will note the complete lack of any word sounding at all like computable, effective, explicit, recursive, any of that. And that difference is critically important. If you take accountable structure, then there is an element of one omega sentence that picks it out precisely. This can be done in first order for a finite structure. Say there exists x1 to xn, and here's how they relate to one another, and there does not exist xn plus 1 that's distinct from all of those, and you have it. For finite structures, you can do this at first order. Countable structures, it is harder, but you can't actually get away with it in infinitary logic. And what you're doing effectively is isolating a bunch of types. And that gives rise to some relations that are useful to have around. So, two tuples are zero equivalent if they satisfy the same quantifier free formulas. What we're trying to do. What we're trying to build here is what it would take to do a back and forth argument, which is how you prove that any two things satisfying this formula, satisfying this sentence, are isomorphic. So zero equivalent means they satisfy the same quantifier-free formulas. Alpha equivalent means that for any beta less than alpha and any extension on one side, you can extend on the other side. One side, you can extend on the other side to match. And it should be not only for each C there exists D, but also for each D there exists a C. And you don't have to match it up to the same level, but you have to be able to match it up to any lower level. The Scott rank of a tuple is how far do you have to go in this process before you know everything about the tuple. Know everything about the tuple means that you have an isomorphism of the structure mapping one to the other. If two tuples stand in this relation to one another, then they really are the same. Scott rank is how far do you have? Scott rank is how far do you have to go before you know that they're really the same. The scot rank of the structure is the least ordinal, greater than all of the scott ranks of tuples. By the way, you will find at least half a dozen inconsistent definitions of scott rank in the literature. And many of them have interesting stories about how they came about. This is the This is the one I'm using. None of them differ by a lot if a lot is understood from the right perspective. But do not be alarmed if you find a different definition. And also do not be alarmed if you see two different things about Scott Rank where you're off by omega or something. Natal did not say computable structure and did not say omega 1ck plus 1. Omega 1ck is the least ordinal which does not have a computable copy as a linear ordering. He actually had all of this in the language in the language of admissible sets. The theorem is actually more general. The theorem is actually more general than this. But when applied to computable structures, here's what it says: there's a bound on the Scott ranks. And you actually can achieve every value up to and including this one. It took us a while to find one that hits omega 1 CK exactly, but it can be done. The computable ordinals are not so hard to get. Are not so hard to get, and omega 1c plus 1 is not so hard to get. But you can achieve omega 1c exactly as well. Another thing you can try to do, and this actually is something that I was asked to drop in by one of the other speakers. So you can calculate index sets of things. Calculate index sets of things. So you'd like to know among those vector spaces, which vector spaces are they that have infinite dimension? And you classify that as a decision problem, as a computability problem. It happens to be incomplete pi zero three. And you can get a Scott sentence for it. Get a Scott sentence for it. That's the easy side. Say that for all n, there exist at least n things that are independent. This inside conjunction is over linear combinations of the X. You should be able to say that all of the linear combinations are not zero. The non-zero linear combinations. Yeah. The way you prove the completeness, though, you start with the CE set and you build a vector space from it. I'm sorry. Why is that a Scott sentence? That just looks like an infinitary axonization of being an infinite dimensional vector space. Why is that a Scott sentence? Because the countable structures satisfying this sentence are exactly the infinite dimensional q vector spaces. Dimensional Q vector spaces. That is the one's isomorphic to this one. Right, sorry, yes, thank you. So, to witness completeness, you start with a bunch of elements that might be a basis. In fact, you might try mapping them to a basis in some infinite dimensional vector space you know. And then you're occasionally going to put some of them back in their place. Occasionally, you will see a new. Occasionally, you will see a new element enter S, and then find some linear combination that you haven't said anything about yet. Because over time, to make this a computable structure, you do have to say, this linear combination is equal to zero. This linear combination is not equal to zero. Find one that you haven't taken a stand on yet, and use it to make this thing dependent on some of the ones that came before it. Before it, what comes out of that is that if S was co-finite, then the vector space you build will be finite dimensional. If S is co-infinite, then the vector space you build will be infinite dimensional. And we knew that the problem of deciding whether Problem of deciding whether a CE set is co-finite or co-infinite, we knew that that was McComplete Pi 03. Much more complicated game, which I will not give in detail, but will at least hint at. Set of indices for well orderings is incomplete pi 11. So there you get one. So, there, you get one set type quantifier, and it's a universal. And that's the easy side. You want to say that every subset or every infinite subset is not a descending sequence. The way you prove completeness is similar in outline to the thing with the vector spaces. You make a sequence of lens. You make a sequence of linear orderings such that if n is in your pi11 set, you get a computable ordinal. And otherwise, you get this thing that really has no business being computable, but it actually is. It looks so much it looks so much like It looks so much like a non-computable thing if you're just looking at any piece of it and looking at any sigma alpha level of precision. So final perspective I wanted to suggest in the last few minutes here is what if there isn't a computable thing? I mean, the previous section about computable structure theory without the parentheses. Structure theory without the parentheses was thinking only about the computable structures and the computable isomorphisms between them. And there's an interesting way to go forward here too. So one way to think about it is for structure existence. Okay, take a countable structure. And, okay, it's countable. Okay, take a countable structure on the natural numbers. On the natural numbers, it has some Turing degree. Maybe not zero, maybe it is zero, I don't know, but it has some degree. Now look at all the isomorphic copies. They have some degrees, maybe one of them is zero, I don't know. But look at all of them. Take the least one. If there is a least one. Maybe there isn't. But if there is a least one, take it. And that somehow is a Turing degree that is an invariant of the isomorphism. That is an invariant of the isomorphism type. And for any Turing degree, you can make a structure like that. You can make a structure where that degree is witnessed as the lowest degree in which that structure can have a copy. And you can also arrange to not have a least degree. For any interesting structure, the set of degrees in which this thing has copies are closed upwards. I say for any interesting structure, the details are here. Assume that there is no finite tuple such that any permutation of the whole structure, if you preserve just that finite tuple, you've got an automorphism. Got an automorphism. Assume that you don't have a tuple like that. Then the degrees in which you have copies are closed upwards. And you can see a lot of this going on as well. You'll see categoricity with an oracle. So maybe not computably categorical, but look in the isomorphism type. How many different types does it split to if you look for? Different types does it split to if you look for isomorphisms computable under zero jump or under zero double jump or zero triple jump. In a lot of structures you'll eventually catch them all. In what degrees does the structure have a copy? You can see a lot of that. What degrees do compute an isomorphism? So that's sort of the other perspective on the categoricity question. Question. Instead of saying, here's how complicated an isomorphism I want to think about, what isomorphisms can I see from there? You would instead say, what sort of degree would I have to have to see that isomorphism? It's a lot of work. And this one question is not entirely new at justice, but work around Scott sentences and scott ranks and Scott ranks, and which structures will have a computable infinitary Scott sentence up. The Scott theorem never guaranteed any effectiveness on the sentence. And even Nadel's bound doesn't guarantee any effectiveness on the sentence, just bounds the ray. And there is a lot done, of course, with sets of indices for structures with this or that property. I think this may be an appropriate time to take any more questions. Let me unplug you first. I guess. I have a question. Go ahead. Actually, I have two. First question is: You started very early on in the talk about if you have an explicit field, then you can get explicit algebraic closures, although maybe. Closures, although maybe you know, multiple different ones that aren't computably isomorphic. How much of that generalizes to existential closeness more generally? Like if I have a computable structure in a computable language, can I find a computable extension of it that is existentially closed? It might depend on decidability of the theory, too. I'm not sure. Does anybody know the answer to that? Save the theory. Say the theory is decidable, complete decidable theory, for example. Well, maybe I don't want it to be complete. Like I have some decidable universal theory, and I have some model of it, computable model. Can I find a computable extension of it, which is an EC model of that universal theory? I don't know. I'd like to. I'd like to know, but I don't. I mean, the standard is amalgamate the heck out of your thing, right? Just keep throwing in witnesses to your existentials and catch your tail at the end. Doesn't seem very effective, right? Yeah, so the proof that I know for this one seems to be really fieldy. Seems to be really fieldy and seems to depend a good deal on we know what the things are going to look like. Here, list off a bunch of polynomials. No, really, list off all the polynomials and do this and that with them. So you might be able to get away with it. I would have to, there is a point at which it says, okay, and now you have a maximal ideal, so there we go. So you might be able to get away with it more generally. I don't know that. With it more generally, I don't know that I've seen it. I'd be interested to know it. I'm wondering in really horrendous situations like groups where you don't even have a model companion, like I have a computable group. Would it really be the case that I could find a computable group extending it that's EC? Like to me, it sounds doubtful, but I'm curious if it's known. It's certainly not known to me. Does anything have anything about this? Yeah, I think that's what she's working on. About this? Yeah, I think that's what she's working on. Okay. Yeah, yeah, so I saw a talk when I was getting ready to leave the conference. Isabella Scott at University of Chicago is the person to ask. Okay, cool. And my other question was, you asked a bunch of questions on your very last slide, or not questions on your last slide, but like different directions. And unless I missed it, what about? And unless I missed the, what about, like, what if instead of your structure not having a computable copy, but it, you know, you have it has a Turing degree? Um, what is known about like the dimension of like the number of computable, the number of decomputable copies where D is that Turing degree of the structure? Like, do you have the same kinds of results as you do for computable dimension? Computable dimension? There are differences. The big one that I know, the big difference that I know, Charlie McCoy in his thesis proved that computable dimension does not relativize. And so, see, or finite computable dimension does not relativize. You can still have the one or infinity, but having finite values seems to really be a thing about computable structures. Wait, so might I understand that if you Wait, so am I to understand that if you have a Turing, if your Turing degree is zero jump or larger, then you must satisfy the dichotomy, either have one or inflame any, is that what you're saying? I'd want to think about what exactly the statement is before I know whether I have a proof of it. Yeah, they have structures and sketches. So if you have if you've got a cubel in the If you have comput if you've got a computable computable structure, then its dimension at zero jump will either be one or two. So you look at zero jump computable copies of the zero jump computable as well. You'll get one. Okay, okay, okay, yeah. You could then have a structure that's not computer presentable, but only zero jump computable presentable. Then you could get back to having the machines to hear that? Did you hear Gecko? Kind of, but it sounds like it's still not 100% addressing what I'm saying. But I'll ask more about it later. Thank you. I have a question. The examples you mentioned where you have this dichotomy where like I put dimensional vector spaces and Boolean algebras without very many atoms, these feel like situations where you have like a lot of automorphisms. There's some general. Is there some general statement to that effect that if there's that you have this dichotomy and you can be metrics? Wait, so I think with Boolean algebras, you can have finitely many atoms and still have a lot of craziness, and you can have infinitely many atoms and still have a lot of craziness. And definitely with linear orderings, you can have finite or infinite successor relations. Successor relations, and you can have a whole lot of craziness either way on that. If you find out many atoms, then there's a complement of the union of the atoms is going to be an atomless, a countable atomless Blue algebra, right? So won't that have a ton of automorphisms? Okay, yeah, yeah, that wouldn't, that wouldn't evolve. And it may go the same for linear orderings. Okay. Okay. Didn't Antonio have a thing something like this a few years ago about something about the make Matthew, maybe it was you, you know, the coffee geometry and it's sort of nice thing to do with VK. Then you can have the winner implement copies. Especially because if you do this thing with the basis, like a computer basis can also copy from a confused basis. Basis in whatever pre-geometry this is. But does the pre-geometry need to somehow control the rest of the structure? Not so much. So if you take like real closed scales, you just take the algebraic closure. Oh, this isn't being whatever it is. But it has to sort of have like sort of a non-fictionality kind of. If it's something independent, you can sort of make it dependent while still satisfying some formula. Anything else, either virtual or in person? I don't know whether any of these things in the chat are I've been keeping an eye, so now. Okay. So in that case, maybe let's thank Wesley again. 