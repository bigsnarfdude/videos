Thoughts in virtual because his work had an impact in my research career that goes beyond what I'm going to talk here. The title of the talk is The Bias and Variance of Thomson Multi-Taper Estimator. But what I really want to communicate is The mathematical formulation and quantification of a property of the Slapian functions that we call the accumulation property. And that is the ingredient that for a mathematician allows for a mathematician point of view creates this magic in the average. In the average estimator of reducing the variance by a factor of k while keeping the bias close to the one created by a perfect bandpass window. So the discovery of this property, actually it was discovered by David Thompson in his 1982 paper and it extends to several fields of Extends to several fields of harmonic analysis, probability. It is a very universal phenomenon. But I just came here by like Alberto Klumbaum said, since we're honoring Evid Slepian Serendi Pitti, it was an accident just to came to Came to Thomson's original paper. So, this is going to be into the foundations of the multi-taper. So, I'm going to be short with the basics. So, the spectral density, I guess everyone here is quite familiar with this. We want to learn the spectral density from one realization of a stochastic process. We assume it ergodic, stationary. Ergodic, stationary, we have limit observations, stochastic fluctuations, and normally a single shot realization. So, the pre-odogram is the classical approach. There is just an approach to the spectral density, and this is the intensity of the finite Fourier transport of the data. This is asymptotically unbiased by this definition. Definition. But it has a terrible variance. The example is the white noise, white Gaussian noise case, where the variance is absolute. The never estimate by the peregrine will give an idea that we are dealing with white noise. And it also creates non-zero values in places where there are no frequencies because of leakage. So the corresponding So, corresponding to the flat function that we are tapering the pre-odogram is the Dirichlet kernel, and this is poorly concentrated in the interval minus ongoing. So there is spectral leakage even with this bias going down with n. So, normally the observations are tapered with a taper window. This is just multiplying, weighting the pre-autogram. Waiting the pre-adogram. We have the special effect of leakage well defined by this convolution. And this is here the Fourier transform. So if we see this on the Fourier side, we have the convolution of the true spectrum with the Fourier transform of the window. So tapering introduces bias from speculative. It depends of the window. It depends on the window and it does not considerably reduce variance. So now this is the punchline. The minimal bias of taper will be achieved, the minimal spectral leakage bias by an ideal bandpass filter, which is something that is really an idealistic thing. And the bias of ideal And the bias of the ideal band bias filter will be bonded by the square of the bandwidth. So we have here a problem. We used to have a problem before 1982. How to reduce variance while keeping bias close to the optimal omega square. Is this possible? This seems to be apparently impossible, but using slapin. Using slaping sequences as stapers and they've discrete Fourier transforms, so just a little bit. The discrete sequences satisfy this equation and the transforms satisfy this continuous integral equation. So these are normally called the Fourier transforms, the slips. So Thompson multi-taper estimator is taper with a prolate sequence K. Taper with a prolite sequence k and then all these estimates are averaged. So this brings down the variance by a factor of k immediately. And what we were able to prove, this was work with Jos√© Luis Comer that he briefly mentioned in his talk, but I'm going to go more focus here. We proved that the bias of the average Bias of the average multi-type estimator is on square. So it's the optimal band pass ongo square plus log n and k. So it decreases with increasing this excess bias introduced by the multi-tapering is a minimal thing if k is big. So normally k is two times n bandwidth. And the bandwidth. So, this can be increased. We can increase the number of windows, keeping the variance low and without bringing bias. So, this is the main result. And this was conjectured by Thomson. And I'm going to revive a little bit of Thomson's heuristics in the 1982 proceedings IEEE paper. Proceedings IEEE paper because it was actually my source. That's where I learned this. So I've tried to follow his reasonings. So the heuristics follow from this spectral window, the average of the intensities of the prolights, being very similar to the ideal band pass. Okay. Okay, so the bias, if this is close to this, then the convolution with this, it's very close to the convolution with this. So this is the main heuristical thing. And our program was to really quantify this mathematically and trying to understand what is going on here. So this approximation here. So this approximation here resembles the Pythagoras identity for the simplest case where such a thing happens. So we call it the accumulation property. The energy profiles of the functions are complementary. So each function is going to take the space of the other function and the average becomes flat. So this is how it works with the Pythagoras identity. The allocation of sine squared. The allocation of sine square is complementary to the allocation of the cosine square, and they are organizing so that the energy spaces left by one feel the energy spaces left by the other one. So it's the square intensity sum up to one. Now, the Fourier transform of the Slapian sequences. It has a pattern that we can see that this second one is designed at the Is designed to be uncorrelated with this in a special way. So this one here is also going to fill in more spaces left by this and this one. This one is going to complement the spaces of this and the spaces of this. And the same will happen. It seems we lost our speaker momentarily. Let's just give him a moment to come back. Yeah, he's frozen. He'll be back.   So, sorry, I'm really having internet problems and this fault again. So, I was talking about the complexion property of the spectrum. The accumulation property of the slapian functions. I think this was the last slide. I showed the picture from Thompson's paper. I think that was still okay. So now I'm going to show an animation of how this property develops. So here are the prolates below. So this is the first prolights, and this is the spectral window of Thompson's estimator. With five prolates, we have this profile of the spectral window. Then it starts getting smooth. Then, after 39, 46 prolates, we see that this becomes flat. What happened is that miraculous, all these functions are going to fill in the space left by the functions before, and they end up forming what is in the limit a perfect band pass filter. So Oh, okay. Just trying to okay, so going back to the So, going back to the No Okay Okay, so Okay, so I'm back to the slides. Is the sound in order? Okay, so I illustrate, I hope that the animation was illustrative. So that's what we call the accumulation property. So what we did was to measure the bias by this approximation. So this accumulates to this. To this. So we measure in the L1 norm how far the accumulated spectral window in Thomson estimator is far from an AD YL bandpass filter. And this gave us this error. And this precisely what is going to be added to the bias of the perfect bandpass filter. So this is precisely how. Is precisely how this little increase shows up in the bias estimate. So, from here, we obtained the full MSA error, which is the square of the bias plus the variance, which gives this. And this is optimal. We can prove that it's not possible for channel signals to obtain a better estimate here. So, the key step of the proof was to The key step of the proof was to show this identity for the eigenvalues. This controls the deviation of the accumulated spectral window from the perfect bandpass filter. So the bond is optimal and there were previous attempts of obtaining this estimate. Now the technical problem here was that people were estimating the eigenvalue. Estimating the eigenvalues and trying to get an estimate of the sum of the eigenvalues out of individual estimates. And doing this, it doesn't seem to be possible to obtain this bound. So we treat the whole sun like a single object. Then to say more than this, it will have to go to the details of the proof, but they are relatively elementary. Are relatively elementary and they are published, I think, in a clear way. So, showing this identity was the key. So, this property holds for eigenfunctions in other geometry. So, in the time frequency domain, so that was our first paper was the accumulation in time frequency analysis, so the accumulated spectrograms. Accumulated spectrograms. It holds in circular symmetric domains, I mean, with the 2D slapians. So we also have this thing. It holds in this settings considered by Frederick Simon in spherical domains. We have on the spectral window, so in those domains, we also have an attempt property. And it depends. Property, and it depends only on the linear space generated by the prolates. And this was the basis for the work that you've seen earlier from Anden and Romero, where what I believe that is a very important thing problem was solved, which is the problem of constructing multi-tapers with this minimal bias, but adapted to But adapted to irregular general domains. So, this is sort of the way of getting free from the approximation of the probates and the computation of all those functions, which do not even exist if the geometry is not regular. Maybe having additional technical difficulties. Let's just skip the speaker a moment. It's quite interesting that you can get this sum over uk squared like that and get this convergence result because it's like a parallel to the sparse basis approximations that Slapian introduced, the two and w theorems he was looking at. So it's quite interesting to see that. It's quite interesting to see that there's an invariance in a way to the squaring of the basis functions to get something similar like that. So this this I think I managed to somehow tune the internet fault. internet fault with my time schedule and this was the this Wait, look at the speaker again. Um Perhaps he could be convinced to share his slides as well after the meeting. That's unfortunate. Slides are posted on the BIRS website, by the way. How do you upload to them? How do you upload to them? Is there a link? Yeah, you go to the BR BIR, the conference webpage, so the workshop webpage. So you go to, I don't know if you can do that, but go to Google and type BIR. Oh, yeah, I know. Okay. I'm assuming they'll be there. Okay. Thanks. And the video has been posted as well, the one that shows the animation, really short. Pretty short with the convergence. Oh, you're muted. So, thank you very much for staying here. And I'm really sorry for the interruptions, but well, I try to communicate in the periods in between the main ideas. Mr. Any question? Okay. Sounded like a nice talk. Sorry, it had technical difficulties, but