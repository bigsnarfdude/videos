From the gradient of the ball versus diagnosis, but yes, you have a half an hour and then plus some questions. Sounds good? Perfect. Oh, okay. Sorry, I guess I didn't turn on my video so that you guys weren't seeing me. Well, thank you. I'm sorry, I don't get to be there. I had some visa issues. I actually got the email that my visa was ready to send my passport last Friday, but yeah, it was too late to get there. To get there. Well, but I'll thank you guys for being able to actually still talk, even in the Zoom setting. And I hope I won't bore you to death. And so please stop me with any questions. Zoom works pretty well for questions. Okay, so what I'll be talking about is a bit of a classical topic, but we're going to be giving it a new perspective. So what we're going to be talking about is the grazing collision limit. Limit, which in a sense is the passage from the Boltzmann equation to the lambda range. Okay, so here I have set up like the Boltzmann equation in which okay, we have the usual collision operator in which In which, I mean, one thing I should be saying is this would be always in the spatially homogeneous case because this is where we can have the gradient flow interpretations that I'll be talking about. So, kind of what's the idea in the grazing collision limit is the idea is that we're going to be considering the collisions in which they're going to be grazing in the sense that the inbound velocity and the outgoing velocity are going to be closed. Are going to be close to each other. So, here, when we're considering the angle theta, we are going to be looking at whenever theta is really concentrated around zero. Okay, so we'll have to introduce a bit of notation to at least get the formal collision limits, and then I'll go into the gradient flow representation. Okay, so just to introduce a bit of notes. So, just to introduce a bit of notation, so here we have the inbound velocities b and b star, and then we have the outgoing velocities which are b prime and b prime star. So here the idea of the angle is that the angle between b and b prime is going to be theta. And this can be represented in represent this can be represented in the in the different variables in this case uh sigma what i was wrote in before or w which is the difference between b and b prime okay so what's the idea of the raising collision limit is that we are considering that the inbound velocity is similar to the outbound velocity. So we are considering that most of the collisions are happening when theta is close to zero. Is close to zero. So, kind of what's the idea here is that we have some particle that is going to be charged and it's coming in with velocity b. And then there is this, there is a collision, a grazing collision with another particle that is coming in with velocity b star. And so, the point of them being grazing is that they actually don't really hit each other, but they like pass fairly close. Like pass fairly close. And because we are considering that these are charged particles that have some Coulomb interactions, this has a tiny bit of a long range. So instead of just actually colliding, this particle will sparely miss this other particle and will end up with velocity B prime. And this particle coming here will end up with a velocity. Here we'll end up with a velocity v star prime. Okay, so yeah, so I didn't say this. The idea is that whenever you heat up a gas enough, the idea is that the electrons will start freely flowing around. So you have a lot of charged particles. And so the interactions have to do with actually the Coulombic interactions, which is just for charged particles. So there is not an actual collision, but basically they actually pass. But basically, they actually pass close to each other and they change velocities just minimally. Okay, so again, just kind of setting the notation is that, okay, so here I'm considering K, which is B minus B star, just the normalized version. And so the angle here is just K times sigma, where sigma is the difference between B prime and B. is the difference between B prime and B prime star, and K is the difference between B and B star. Okay, and so the idea is when we are considering these interactions is that we have to also consider that there is an extra when I'm looking at this picture, I can consider this B prime that is also being integrated around the sphere. So I actually have an extra coordinates that I'm actually Extra coordinates that I'm actually considering these interactions with. So, yeah, so this is just a picture to say, okay, so in fact, I not only I have to think that this same picture of this circle that I have here, I can always rotate in itself. And I have this extra coordinate here, which in this picture here, I'm denoting by. Picture here, I'm denoting by P. Okay. And so then the point is that now I have this extra integration over this rotation axis of P. Okay? Yeah, I hope I didn't lose you. And hopefully, you have seen something like this before. So, here, what we are going to be considering is that To be considering is that most of the interactions are going to be happening when the angle is close to zero. So, to actually do this in a more mathematically rigorous way, what we're going to be considering is kernel, an interaction kernel that puts most of the weight around theta equals to zero. So, here, what we're going to be considering is this beta epsilon, which This beta epsilon, which charges most of the interactions when theta is around epsilon. So we kind of extend this interaction beta, which is zero outside zero and pi, minus pi and pi. And then what we are thinking is that all of the interactions are happening when this angle theta is really, really small. Okay, so we are thinking that this aperture here. That this aperture here is tight. Sorry, Matthias? Yeah. Why is there an epsilon cube? Isn't it an angle? Why is there an epsilon cube? So, well, that comes out of even of the formal computations. So, if you put one over epsilon, you are maintaining the mass. But the idea is that the lambda operator appears at a second order. So, in fact, this is the scaling. This is the scaling that preserves the second moment of beta, which is what is going to be giving you in the formal Taylor expansion, the second order operator here. Okay, hope that answers your question. Yeah, thank you. Sure. Okay, so I mean, formally, what's going on is I can consider the Boltzmann operator applied to a test function. Operator applied to a test function. And so here what I'm getting is: okay, so this is the usual. So here, when I write this gradient bar of phi, I'm considering the usual difference of phi prime, phi of b prime star minus phi of b minus phi of b star. Okay, so this is not a gradient in kind of the strict sense, but the idea is that I'm going to kind of start treating it as a gradient. Of start treating it as a gradient because that's usually how, yeah, I mean, that's what you're going to obtain in the limit. And also, this is how you get the formal structure that I'm trying to like to get at. Okay, so the point here is that once you kind of undo the scaling of this divided by epsilon, and yes, and we have this one over epsilon cubed, we have this one over epsilon squared in front of this gradient. front of this gradient tilde of psi. And the idea is that now what we're considering is that B prime is really similar to B and B star prime is really similar to B star. So the point is that now when I'm taking this average over this DP, which kind of what I'm saying is the average over dp is this integration over This integration over this extra variable that I have here. So, what I'll be having in fact is that this term here is converging to the gradient, but only with respect to the perpendicular directions with respect to B V star. Okay, so I'm integrating this DP, but now dp but now p is perpendicular to what i was writing as k where k was b minus b star okay so if we actually do a taylor expansion and in fact this is just formal so here the only thing that you have to do is do a taylor expansion and integrate out P. Okay, and so the idea: this is what I'm saying is that this pi here is the projection onto B minus B star perpendicular. Okay, so what we have here is that formally. What we have here is that formally, what we have shown, and yeah, I mean, you have to believe all of the hand waving that I've done, is that formally, what you're showing is that the Boltzmann operator at the epsilon level, when we take epsilon to zero, we are converging to the lambda operator of phi. Okay, so I should start kind of citing people here. So, I mean, of course, this wasn't apparently set originally. This wasn't apparently said originally by Landau, but it was later kind of said by physicists that, in general, like when you're considering this, the limit when grazing collisions, you are actually obtaining the Lambda equation. And this was mathematically shown in this formal way in the nineties by I think it's De Villette and also by De Gaunt. By the Gunt and look at the third. And so, yeah, so these papers, my understanding is that this is only formal and in fact proving this rigorously was a bit later by Alexander Milani. A bit later by Alexander and Villani in the 2000s. Okay, so in the limit, what we are obtaining is this the Landau equation, which I mean, using a bit of hand wavy, the idea is that what I'm trying to use is this kind of formal expressions of taking this gradient bar of psi, and here what I obtain in Here, what I obtain in the limit is in essence what I would be calling a gradient tilde of the logarithm of F. Okay, and so the point is that I want to do a bit a formal relationship with the heat equation that we have actually shown more rigorously in a paper with Debile, Jose Carrill. With Debbie Led, Jose Carrillo, and Jeremy Wu. So, the point that I'm trying to make is that we can consider the heat equation in a similar way, in which if we are considering dtf is equal to the Laplacian of F, we can rewrite this as the divergence of f times the gradient. Times the gradient of the log of F. Okay, so the point is that at least formally, the Landau equation follows a similar structure as the heat equation. Okay, and so, and this is what we are trying to use to actually show this rigorous convergence of the Convergence of the grazing collision limits. Okay, yeah, so I should say that the first rigorous proof of this was by Alexandre and Bilani in the 2000s. Okay, and the way they do this is by looking at the By looking at the renormalized solutions of the pernalions. Okay, so yeah, so I want to kind of make an analogy with the heat equation. And so the first point I should make here, let me make this a little smaller. The first point The first point I want to make here is that we're going to be kind of really exploiting the H theorem. Okay, so we're here just this usually notation, H of F is the usual entropy for mathematicians, which is just F log F. And so if I take formally the derivative of the entropy with respect to either the Boltzmann Respect to either the Boltzmann or the Landau equation, I get that the entropy is getting dissipated. And I can formally compute explicitly the dissipation of in the Boltzmann case by this functional here, and in the Landau case, by this functional here. So, what we did with Jose Carrillo, Lauren de Viletz, and Jeremy Wu was to Was to, in particular, show that the Landau equation is a gradient flow of the entropy with respect to a metric that we constructed specifically to actually preserve this structure here. Okay, so in essence, what we're going to be considering for this talk is the definition The definition of what we're going to be calling H gradient flow is that F epsilon F is a solution if and only if it satisfies this entropy, this Entropy, this energy dissipation inequality. Okay, so what's the kind of the conceptual advantage of gradient flows is that instead of looking at the equation itself, we can restrict ourselves to just looking at an inequality. Looking at an inequality. And if everything is regular enough, the point is that being a solution to the equation is actually equivalent to satisfying this inequality for every time. Okay, so I have to introduce a bit of notation, but the point is that here we have the usual dissipation that I had written here for the H theorem. And then I have this new object, which is the metric derivative with respect of. Respect of an epsilon metric, which I will define in a second. And the point is that now I'm giving this as a definition because this is following in some work by Erber, which says that in the Maxwellian case, in the Maxwellian case, In the Maxwellian case, f epsilon is a solution if and only if it satisfies the ADI. Okay, so we did a Okay, so we did a similar characterization for the Lambda equation. So unfortunately, we are actually not able to get the Coulomb case for the inequality for this characterization. But the point is of this convergence of the Graysian collision limit is that we're kind of forgetting if we can actually characterize the solutions if and only if with this inequality, but we're just saying, okay, so if I consider this as my definition. This is my definition of solution, then when I pass the epsilon to zero, I actually retrieve the same inequality for the Lambda equation. Of course, if we knew that the solutions to the Landau equation were regular, then in fact we can actually characterize them through this inequality, but that's not something that is available right now. And what we were focusing on was just in fact passing to the limit in this inequality. Limit in this inequality. So, right? So, just to get an idea, and I won't be able to do this in 10 minutes. So, kind of what I'm looking at is, in a sense, the analogy to the heat equation. Okay, so we're considering this dt. Where we're considering is dtf is equal to the Laplacian of F. So the point is that this is the gradient flow of the entropy in the two Baselstein distance. Okay, so morally I'm always kind of trying to go down the entropy. Trying to go down the entropy, but now I'm following these two Basestein distance. So, how do you kind of define the Basestein distances? So, let's say that I have an initial configuration F naught, and then I have a target configuration F1. The idea is that I want to transport the mass in F0 to F1 following some trajectories while While minimizing the kinetic energy. Okay, so what I would be considering is, let's say, some curve that satisfies a continuity equation, dt mu, divergence of some vector field B is equal to zero, where mu of zero is equal to F naught and mu of one is equal to F one. Okay, and so the point is. Okay, and so the point is: I'm following V, a vector field while minimizing over B that satisfies the above. I want to minimize the kinetic energy, which is just B squared divided by mu. So, if I do this, what I actually obtain is that this is the Baserstein two distance squared between F0 and F1. Okay, and so the point at least for the heat equation is that if I'm looking at this representation, I'm looking at this representation using this as my metric derivative, which is the amount of change that I'm kind of moving in the vast time distance at every specific time. What I have is that the dissipation of the entropy is actually equal to the metric derivative. Okay, so morally, what I need to do to actually obtain a representation like this is to find a metric in such a way that In such a way that the dissipation of the entropy coincides with the metric derivative of the curve at the same point. Okay, so here, of course, what I was writing B here is just going to be the gradient of F if I'm looking at the Laplacian. So this is just the divergence of the gradient of F. And so the point is that if I look at this I look at this kind of specific functional for v squared of μ is that what is that the dissipation of the entropy, which is the fission information, coincides with the metric derivative of the Baselstein 2 distance. Okay, so I have only five minutes, so I won't be able to do too much. So, but the point is that you can actually get similar representations for these Boltzmann. For this Boltzmann metric and for the Landau metric. Okay, so this would be the Boltzmann metric, which was introduced by Erbert. And this is the Lambda metric that we introduced. Okay, and so the difference with the usual Bush-Time 2 distance is that here I'm integrating out. Here I'm integrating out this extra variable. So the idea is that the action here, so here the kinetic, the kinetic energy is only depending on the point that I'm at. But here, the associated kinetic energy is depending on the whole configuration of the gas at the same time. Okay, and this is true both for the Boltzmann metric and the Landau metric. And so then you could think that this is a Basserstein II metric that depends on. That depends on the whole state of the gas at the same time, and it's not just local. Okay, so the metric itself is non-local. All right, so yeah, I only have five minutes, so I'll just kind of give you kind of a broad perspective of why might you want to like do it like this, or what is the conceptual advantage of doing these type of things, is that now my notion of solution is just these inequalities here. Inequalities here. So I need to be able to pass to the limit in the inequality. And so the point is that I don't actually need to pass to the limit in the inequality in a strong way because I only care about preserving the inequality going this way. So I only have to pass to the limit in a lower semi-continuous way for the dissipation and for the metric derivative. Okay? And so this was something that was introduced by Andie. Introduced by Andie and Serfati, in which the point is that, okay, so I need to pass to the limit in the initial condition strongly, but then I only need to get the limin of the dissipation converges with an inequality to the dissipation of the Landau metric. Of the Landau metric, and the limit of the metric derivative converges again with an inequality to the Landau metric. So to the Landau dissipation first and to the Landau metric in the second case. So, okay, so the point is that here in San Diego T, I kind of have three steps. So one is show that f epsilon converges to That f epsilon converges to some limits. So this is just compactness. And then the second part is to show that the limit of the epsilon of f epsilon is bigger or equal than the lambda of f. And the third part is that the limit of f dot epsilon in the epsilon. f dot epsilon in the epsilon metric is bigger than the metric derivative in the lambda squared. So okay, I only have two minutes. So now the point is that now we have reduced this grazing collision limit into just passing into these three steps, which in a sense gives you the consistency of this Boltzmann metric and this Landau metric that we can actually see And this Landau metric that we can actually see that as epsilon is going to zero, you are actually just showing this. So, I guess in the last minute here, so to actually simplify these computations here, the compactness follows by kind of the usual compactness ideas. In fact, you can actually see that these guys will be compact in the dual of Lipschitz functions. And to show these low And to show this lower semi-continuity, the usual trick is just to use affine representations. Okay, so kind of what is the idea of affine representation? So this is the usual trick of writing, if I want to show that something is always continuous, I can just write it as a supremum of continuous functionals. So in fact, if I want to just write, let's say that the L2 norm of f, this This is going to be equal to the supremum over any test function of f times phi minus, so let's say two times f times phi minus phi squared the integral of phi squared. Okay, so this is what I'm calling an affine representation. Okay. Okay, and so the point is to show these inequalities, we can just actually use a fine representation for both of these things and just use the formal convergence that we had earlier to actually pass to the limit here. Okay, so yeah, I won't have time to actually go through this, but the idea is that the Boltzmann dissipation has a specific affine representation, and now we only need to pass to the limit in the easy term, which is the formal computation. Term, which is the formal computation that I showed at the beginning, and similarly for the Boltzmann metric and the Lambda metric. And I think I'll stop here so I'm not over time. So please let me know if you have any questions or comments. Thank you, Matthias. Is there any questions? Yes. Come on here, this is vendor. Quick question. So now that we have this gradient flow structure, have you guys looked at what PDs you get or what flows you get if you look at different functionals? No, actually, we haven't. So you're saying instead of taking the entropy, what happens if we take, like, let's say the L2 norm or something like that? Yeah, right. Used to be, you know, right? Know, right? Because so many flows, right, like come from mass-time when you use in the function for a video, some other kind of kinetic equation. That's a fair question. No, we have not looked at that to see. I mean, yeah, what would happen? I guess my first thing would be to try like something like the L2 norm and see what you will be getting. But yeah, no, actually, I haven't actually tried this computation, so I don't know what you get as an equation. I don't know what you get as an equation. Oh, thank you. What do you think about the Coulomb case? Is it maybe not true or is it a technical thing that doesn't work for the endpoint case? I don't know. I think there are more experts there of what they can tell you more about the Coulomb case. I mean, for us, at the end of the day, it was a bit more. us at the end of the day was a bit more uh this in terms of regularity so let's say that you have really regular so if you restrict to really regular things then you can expect to have this um you can expect to have this characterization that you are a solution if and only if um you're satisfying the inequality uh but yeah to be honest with you kind of everything breaks down exactly Kind of everything breaks down exactly at the Coulomb case, which I mean, I think for the people in the audience is not really surprising. But I would say that at least in the sense of like the result that we are saying here applies for even softer cases than Coulomb case. But of course, we are kind of making up our own definition of what is a solution by saying, okay, a solution is something that satisfies. A solution is something that satisfies this inequality, which should conceptually characterize the equation. Let's take a speaker. Oh, Perfect. So the next talk starts at 11 and 10. I think we should schedule it because of the program. So we have like a seven minute break. But perfect so we can think about