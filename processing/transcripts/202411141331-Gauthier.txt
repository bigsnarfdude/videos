I'm very happy to be here. This is about hedging index options or hedging and stock options. Joint work with Claudos PÃ©rez Mendoza and Federica Day at the in the MAT department at Coca-Cola University and Pascal Francois in the finance department at Ashosimoria. Okay, hedging options. There is thousands of papers on that topic. Thousands of papers on that topic. So, what's new? I would say, first of all, you know, most of the papers in that literature, what they do is they start with a model for the underlying asset. So, you try to have a dynamic for the return of the underlying asset and maybe some risk factors. We can think of stochastic volatilities, jumps, maybe stochastic interest rates. And then you think of the change of measure going risk neutral, having Going risk neutral, having your risk neutral measures, so you're in absence of arbitrage, and then the option prices come as an output of the model. And then you design your hedging policy according to the model option prices. The problem with this is that today on the SP 500, you have about 2,000 options treated. And there is no way that reduced from A reduced form model like the one I've described will exactly match all the option prices today. So it's an absence of arbitrage in terms of the dynamic over time because in fact the option prices coming from these models are coherent together, but doesn't mean that it matches the actual data. So what we do different is we use the real traded option prices as an input of a model. And then And then the hedging policy depends on the real prices. So the next step is to put that in practice and we can do that. We can put that into production. So that is the main, I would say, contribution of this paper. Now, there's a price to pay. And the price to pay is, you know, the hedging problem, usually there's you you solve them with a dynamic optimization problem. Dynamic optimization problem, and then you solve it backward in time, right? And but these suffers from the curse of dimensionalities. And then if you want to embed into your state variable the information coming from the real option market, the dimension of the space is too big to be able to handle this using classical techniques. And that is why we go for reinforcement learning. And so this is a big picture. And so this is a big picture, and if you have to fall asleep right now, the only thing that you should remember from now is that it works. So let's go into the detail. So you have an option payoff, you know, FOPN option. The payoff is psi. It's a function of the underlying asset price. Okay. And then you are allowed to trade two things, the cash and the underlying asset. The underlying asset. So the position in the cache and the underlying asset are predictable processes. So you start at time t minus one, deciding how many cache you have, what is the position in the underlying asset, wait until the end of the period. And then you have, you know, here, the cash account that appreciate at the risk free rate. And then you have the position in the underlying asset on which we include the fact that you may have dividends. The fact that you may have dividends. Now you get new information because you're at the end of the period, and you like to update your position in the underlying asset in the cash so that you benefit from the new information. Okay, so we have now the new position in the stock or in the index, and then we have, we consider the fact that. We consider the fact that you have transaction cost, right? So, this is something we had also. And so, the transaction cost is proportional to the amount you deal, right, when you do the rebalancing. And because we want these investment strategy to be self-financing, saying that you're not allowed to remove cash or put more money, new money, into the strategy, it has to be equal to the actual value of the investment strategy. The investment strategy. And so, for that reason, the only decision variable you have is the amount of shares you have in the underlying asset because then the amount in the cash is fully determined by the self-financing condition. Okay. So, what we want to do, find the best sequence of position in the underlying asset so that we try to minimize some function. Try to minimize some function of the hedging error. So, this is your option cash flow, this is the terminal value of your hedging strategy, and because we're trying to hedge a short position in the option, when this side, the hedging error is positive, it means that you're losing money. And when it's negative, you're making a kind of profit. So, the goal of hedging is not to make profit, it's to reduce risk. Reduce risk. So we are, and this is an editorial point. For me, when we think of hedging, because it's been so long that I'm working with the finance people, you know, the financial product is a bit different because you're allowed to trade the underlying assets. It's not like the insurance. And so, for that reason, for me, hedging means replication. I try to be as close as I can from the option payoff. And so, my goal is to actually. And so, my goal is to actually minimize a mean square error, the mean square hedging error, which is equation 3. Now, in this literature, especially if you go for computer science and AI and everything related to reinforcement learning, they consider a more general problem where they try to minimize some risk measure. Rho could be the Min Scuerra, but it could be also a C-var, it could be also a semi-min scuera. Means whoever, I don't mind, but for me, it's risk management, it's not hedging. But you know, one among the good things that AI does is marketing, right? So calling that deep hedging close to deep learning, I fully agree. And I won't try to change, you know, this whole bunch of literature about this topic. So let's call it deep hedging and we solve this particular problem. But for me, I really focus on this one, but you'll see results for both type of measure. Type of measure. Please feel free to interrupt if you have a question. Coming from me, it's not surprising. So historically, we solved that by dynamic optimization. And now the problem is because of this state space. When we do dynamic optimization, what you have to solve at each time step is that you compute the expected value of the hedging error in the future, knowing the information now. Knowing the information now. So it's all about where is the information now. And you know, hedging option, you really, really have to deal with what the option market tells you about the risk, not only the underlying asset. And so the state space, and I will describe, I will spend some time describing the state space, but it's too large, and then we use we tackle the problem four. The problem four is that one, right, for the general one, using reinforcement learning. Using reinforcement learning. Can I ask a quick clarification? In the slide before, the risk measure is this a one-step risk measure or looking at a dynamic risk measure? Dynamic, okay. Okay. And so now what we have is the number of shares of the underlying assets you should hold at time t and goes up to time t plus one is a function of our state variable. Okay, and it's many dimensional. Many dimensional. Okay, so yes, of course. So, why are you thinking that the control is only a function of the state variable but not a time-dependent? Is it trying to be aligned with the winflows closer? It could be time-dependent because in your state variable, you can put time to maturity, for example, as one of the variables you want to consider. So, it could be time-dependent because you put it in the X vector. Okay. Okay, so many attempts, but the way we solve that, right? The function, you know, the number of shelves, the underlying assets you hold, it is a function of your state variable and you get that through four hidden layers, neural network. What else? The terminal layer is usually a linear function, right? So most of the time we see that. So, most of the time we see that. And people claim that, oh, it's neural net, so it's a black box, so we don't really understand what's going on, but it works, right? But we spend a lot of time analyzing, you know, because once the model is trained, you do have all these parameters of your neural net, and then you can do sensitivity sensitivity uh analysis, and you can also look at what it goes on some specific path. If you put linear transformation, then your reinforcement learning agent learns to gamble. Okay, so and why is that? So I won't go into the detail, but just give you the feeling of what's going on, is because your neural net is trained on a finite set. So imagine that you have an option with a three-month maturity, so 6-3 days. So 63 days, and you don't have infinitely many paths, right? You have to train this model. And so, on that time period, it doesn't see the worst case, right? It's too limited. And so, what it does is, you know, we see some path for which it bets on, you know, when it lose, you put more weight on the underlying asset, doubling, doubling, until you recover all the losses. And so, for that reason, you have to control your. Control your algavitan by putting a budget constraint, limiting how much you can borrow in the cash account so that you prevent the RL agent to learn how to gamble. And so my first warning is when you go into these numerical techniques, it's not because you have a risk matrix and you try to minimize a risk matrix and you call that deep hedging that you do deep hedging. You do hedging, right? Hedging, you do hedging, right? You see strange pattern, speculation, and everything, and you have to be very cautious about that. Okay, so again, now the state space, and this is my second point I'd like to discuss. So we're hedging a short position, right? And what we'll do is we'll include the information from the option market and how to tackle that, it's not that easy. That it's not that easy. So, first of all, I need to explain, you know, short. What is it? Oh, you have a question? Yeah. Yes, of course. So, you use the information from the option market, but then you use the options directly as well. But you'll see. It's exactly what I will explain. Okay, now equation five: flat shoals. Black shoes for multiple colour option. What I mean by implied volatility is here you have a Here you have a true option price today, right? And you ask yourself what is the implied volatility, what is the volatility parameter you should put in the Black Scholars formula so that you exactly match the traded price. Now, it doesn't mean because we're using Black Scholars model that we believe it's the right model. It's only a projection between prices and something else. And why we don't work with prices directly, it's for two main reasons. It's for two main reasons. Out-of-money options at small prices, much smaller than at-the-money options, so there is a discrepancy. And as you move over time, because we'll have 25 years of data, you know, the index grows, and so the option prices grows, and you have those unstability in terms of level, and it's hard to do a good statistical work on getting good parameters and everything. Good parameters and everything if your data is not stable. When you work with implied volatility, no matter if you're deep out, out of the money, or in 1996 or in 2020, it's all about the same order of magnitude, right? Between 15 and 40% or whatever, but you know. So it's easier statistically speaking to work with this. Your data, right? So, top left panel, you have what is the implied volatility surface back in 1996. The bottom right panel, you know, more toward the end of the sample. What we can observe from that is there is much more option right now than there was at the beginning of the sample. If you look at this panel, you have the financial crisis, right? So, the level raise, it's 1.2, this is 0.6, right? So it's raised a lot. So, what we can It raised a lot. So, what we can see from that, if Dashel's formula was right, or if the Dashel's model were right, you know, these flats will be, these surfaces will be flat and constant over time. Clearly, it's not the case. Second thing, you can see that this is the time to maturity of the option, and you see an upward sloping. Same thing there. But during the financial crisis, the slope is inverted. You also see some convexity in the direction of the moneyness of the option. The money of the option. And obviously, the Okystic paddle, right? We're Canadian. So it's the smirk. And so the idea, okay, so I have about 2,000 options in this figure, but clearly it's not a 2,000-dimensional problem, right? It's highly structured. So the first thing we've done is to try to, on a daily basis, one day after the other, can we reduce the dimension and get some The dimension and get something that will explain, you know, all the information I have in all the option prices. And the answer is a picture. So it's a functional regression. And we found those characteristics. So you have the level, you have the time demeritraising slope, and you have the money nest slope, and you have something related to the curator and the hockey stick paddle, right? And then you just do a functional. And then you just do a functional regression, very easy to do, ONS. And in fact, what you back out from the whole data set, it's five coefficients that characterize the whole information about the option market that day. And so these five parameters change over time. So it's a paper by itself. It's not that easy to do that. Once you know the answer, it's fine, right? You know the answer is fine, right? But we have plenty of other constraints to make sure that there is no static arbitrage, you know, once we calibrate that. And so I skipped the details, but you know, this is the first step. So we resume all the information about option market into five parameters: vector 1, 2, 3, 4, and 5. Okay, it's not enough. We have a dynamic. We have a dynamic over time. So we do a bit of eyeball statistics now. Can we look at the first yes? This is a really silly question. Yes, how do you determine the functions f1, through f5? So we first start with a PCA, look at that, and then fit to the data, look where the error was, and tweak the function, look at that again, until we find something maintaining the code. Find something maintaining the constraint not to avoid static arbitrage between the option prices. And it's related to have a nice continuous and twice differentiable function in the direction of the exercise plus. Okay, top panel. The return of, okay, look at the black curve for now. I'll explain the gray curve later on. So the black curve. So, the black curve, what we see from the return of the SP 500? Any clue? Cluster of volatility, right? And then what you see, it spiked, and then you have a slow exponential decay. So, for me, it tells that you have, you need to handle something related to jumbo or at least having something that will capture extreme values sometimes. Now, second panel, you have in black the level of the implied volatility, it's the daily level of the implied volatility surface. So it raised during the financial crisis, again during the COVID. And so you can see that, you know what, that would be a good proxy to capture the volatility of the underlying asset returns, right? Don't you think that the level of the intact That the level of the influx volatility surface increases where you need it for explaining how volatile the returns are. But you have to be careful because we do risk management and risk management is on the P. But implied volatility is on the Q. So it's not exactly the proper level, but at least it's highly correlated. Okay, now third panel, you have the time to make. The time to maturity slope, what you see that it, you know, it increased during the crisis, right? The 2008 crisis, and then the COVID crisis, you have the aging crisis there. And so the slope changes during crisis. And then this is due to the money nest slope. And then you have the thing related to the curvature of the so this is very practical work, right? Very practical work, right? But once you go into the data, look at that eyeball statistics, you say, Well, now it's time to design a model, right? And why we need a model? Well, imagine, because people claim, my co-oper was saying, you know what, reinforcement learning is model-free. It's all data-driven. Well, wrong. If I go for 25 years of daily data in a financial market, I have In a financial market, I have 6,300 points. My neural net has 15k parameters. Sorry, more work. Okay, so most of the papers using reinforcement learning for hedging, in fact, what they learn is a property of the model they're using for simulating to train the network, right? And so it's super important that at least your model reflects what you have in your data. What you have in your data. And that is why we come up with this time dynamic framework. So, what we do, we have a six-dimensional time series, highly correlated. Look at that, they all spike together there, right? So you have to account for the fact that they co-move together. Okay, you have to account for extreme movements. So, what we do, we first fit the extreme values. We first fit the extreme values using non-Gaussian noise term. In fact, what we use is standardized NIG distribution because we have two other parameters for skewness and ketosis. And then all these, right, if you look at these time series, they're in time-varying volatility. Okay, so we need to introduce some conditional variance. Some conditional variance for each of them. We account for the codependence between their movement through a Gaussian catalog. So we start with the NIG, use the cumulative distribution function, go back to the uniform, from the uniform, go back to the Gaussian, apply the capillar there. Yes? By Gaussian copula, another D-coptula? We could have tried a couple of them, but it works, right? So it's not the same. Yeah. So it's notice for drawing it's independent? Uh well that that okay, so my principle is start simple and complexify until you fit the goodness of the text. So it's what we did, right? So if you remove any of these, you found the goodness of fit, and with this, it works. Okay, so let's go back. First set of Go back. First set of equations is the return on the SP 500. And the way we do that, it's RT, right? So we have the risk-free rate, and I skipped the detail about mathematics because we have to account for the fact that the noise term is not Gaussian, but it's the risk-fremium coming from the Radonikadim derivative and the constraint of absence of arbitrage, the martingale property. So at least for this part. So at least for this part, we have a dynamic model which is internally consistent in absence of arbitrage for the SP fragmenting. What you have here is the stochastic volatility, well time-varying volatility, a noise term. And if you look at this, it looks like it's the same noise term here. So it's a kind of garch process, but not exactly because it is mean reverting to. mean reverting toward the implied volatility. So it's not exactly, it's a fraction, right? Because I told you the implied volatility is under the Q measure, but then we're doing risk management, so we're under P, but it's fine, right? It's a good proxy, and we after that allow for a noisy behavior around this implied volatility, and so it works. What is good about that is we have a kind of two levels. It's we have a kind of two layers volatility, but no latent factor. Super easy to estimate. It's simply energy like you do for garge. And why we choose that instead of a stochastic volatility model? Well, it's not because we don't know how to do that. We have committed a couple of papers about how you filtering volatility and everything else from, but it's just we want to put this into production. To put this into production into the industry. So, we want to have a kind of straightforward estimation procedure so that actually we can use it. Okay, and then here it's the five coefficients. So, it's a vector value process for the, you know, the five factors that reflect how the implied volatility surface evolves over time. And again, for the first one, you know, the level of the implied volatility, again, we could see that, you know. Again, we could see that having a mean reverting around the implied volatility produce this time varying. Let's go back to the picture. If you look at this one, it's time varying. You see that it's 5 and it's valid despite exactly when it's 5. And so that is why we come up with this framework. And in fact, what you see with the gray curve there, it's exactly. Gray curve there, it's exactly the estimation of this model, but I'm presenting the grays, the transitional variants that evolve over time. Okay, so once you have parameters for this, we tested the standard goodness of fit, and you know what? Fitting 25 years of daily observation in a Of daily observation in a six-dimensional problem and not failing the goodness of the test, it's an explorer. I don't know much model that is able to handle this. It's not a calibration, the parameter are fixed over time, and it works. Okay, now, once you know that, this is your state variable, right? So you have the value of your portfolio, the position, and the under. Portfolio, the position and the underlying asset, your time-varying variable. So you have the time to maturity, and because you move in time, the time to the maturity of the option shrinks, right? So you have a time dependence here. The level of the underlying asset, your five coefficient that captures the, I would say, the implied volatility that they, the variance of the SP returns, and the variance of your. And the variance of your implied relative D surface. Yes. Maybe if I ask, may you ask about, you know, maybe you can do a Latinx or a lightweight ratio test to see which part of the model actually is capable of replicating which part in the sense that, you know, pair or which component is really necessary to get the good fit. Yes, we did. And it's a paper by itself. In fact, there's a lot of okay. And so I just want you. Okay, and so I just want you to end this. I'd like to show you a couple of results. So the way we train the model is we pick at random, you know, an initial point in the 25 years. From that, we use a model to simulate a path. We try to price, to hedge an option of three months. And so we simulate path 400,000 paths to train the model, and we also have path to for the test set. Okay, I just said that. Now we look at different periods, right? So we classify them in terms of where we start the initial point. So we have the Asian crisis, the bubble crisis, the global financial crisis, and the COVID. And let's see how it looks like. So many, many ways. So the blue bars are related to the practitioners' delta, what the practitioners do. Delta, what the practitioners do. So, delta hedging and different ways to do that. Then, the yellow curve is the result when you have the RL agent trained using minimizing the mean squared error. And the red bars and the orange ones is when you try to minimize the C bar. Okay, so let's focus on hedging, so the mean square error, right? So, anytime when you look at that. So, anytime when you look at that, the error is smaller when you use the agent. So, it works. And this is out-of-sample measure, it's not in sample, it's mu pi. In terms of what it looks like, you know, the green, these are the distribution of the hedging error when you train with the RLH and minimizing the mean square. The yellow one is the delta edging, the classical one, but of course, we have to, you know, it's not the. Of course, we have the, you know, it's not the basic black shoals we have because we know where we are on the intra-relative dissurface. Now, if you want to compare about, you know, this is when you minimize a mean square error, when you minimize a C-bar. And so you see that when you focus on C-var, you minimize a left tail, but you're allowed to make profit, right? So there's a bit of a component of speculation. And in fact, we look at the difference between what is a policy when you do reinforcement. What is the policy when you do reinforcement learning, and what is the policy when you do delta hedging? And we can show that if you're too soft on your risk metric, then there is a statistical arbitrage, right? So you have to be very careful the way you design your objective function. And then maybe this is account for transaction cost. I'm almost there. Let's skip that, and I just want to show you maybe this because. Maybe this because you'll say, well, it's fine, right? But everything is on simulated data. So, how can you prove me that actually it works for real? And so, this is a back test. So, once your RL agent is trained, what we do is every month we pick an option with three months to maturity. And according to the real path of the underlying asset return and the option, we hedge this option up to the end. And then we look at the edging error. And then we look at the edging error, and we do that every month of our sample. So, what you have is the cumulative PL for each of these strategy. And this is without transaction cost. And they all do about the same, but the yellow curve, which is the reinforcement net page and minimizing the mean square error, do better. But look at on the right panel, then your comfort trajectory class and Project class and guess who is winning, right? So, what is the main message of that is that hedging, you know, training your model and your hedging decision using reinforcement learning works, but, and but yes, there is a but, you have to be very careful handling this black box. Look through the path because you have to, in fact, control what it wants. It's not because you have designed a proper objective function that actually it. Proper objective function that actually it does what you think it does. Thank you. SIGAS is a very nice fit of 25 years, but at a given day, is it really accurate enough so that the further consideration using this? Because for some reason both the insist on super accurate calculations. It's why we fit, you know, the aesthetic model is a paper by itself, and we took care that the distance between the surface fitting and the actual traded price fall between the bidouts. So it's good. 