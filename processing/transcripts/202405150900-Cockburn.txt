For welcoming you, Bernardo, thank you so much for joining us. I was saying that very lucky for me, very fortunate because you need no introduction. You're so thank you very much for joining us and please go on when ready. Okay, so should I begin? Should I start? Yes, okay. Well, thank you very much for the invitation to this meeting about contemporary challenges in TREF methods. I have never worked on this particular type of method, but I see that there are many discontinuous lurking Discontinuous lurking traffic methods and things like that, so maybe I'm not out of place. So, what I would like to do today is I want to propose a new challenge in traffic methods. So I'm going to propose that at the very end of the talk. Very end of the talk. And what I'm going to do is, I'm going to introduce a new idea, I think it's new, a new idea that relates continuous and discontinuous methods. And the idea is that you guys apply this to TRES methods. Test methods. So, what I'm going to do then is the following. Okay, so here is the outline of the talk. Well, maybe before going through this thing, let me tell you a little bit of an introduction. So, I mean, you know that you might know that these continuous regularity methods were introduced back. were introduced back in the early early 70s, 73 by Widam Hill, were two guys working in Los Alamos and they published a little pamphlet, a little not pamphlet, but you know, a little report that apparently they never published. So fortunately for us, Lusan Lusa and Ravia were able to identify this report when they were working in the Commission of Atomic Energy in France. And then they wrote a very nice paper about that method in 1974. And then there was a series of applications. A series of applications of these methods to time matching as time matching techniques for elliptic equations. And then we work with Q1, as you might know. And so what happened was that some time ago, I was asked to write I was asked to write a paper for the 65th birthday of Chu Wang Shu. And so I thought it was the right time to reflect a little bit on what we have been doing. And then I came up with a very strange result which I'm going to show to you. So I'm going to show these. I'm going to show this in the frame of a simple ODE. And I'm going to introduce the Galerkin method, the continuous Galerkin method, and the discontinuous Galerkin method. And I'm going to propose a link between them, which I think is going to be very, very fruitful for the near future. So, in order to So, in order to establish the link between these two methods, I'm going to use some Radau polynomials, which I'm going to define here. And then I'm going to identify the stabilization term in the discontinuous Galeric method. And we are going to transform this stabilization term into spaces. Spaces and this transformation is going to give rise to a natural post-processing of the Galactic method, which is going to be continuous and it's going to be more accurate than this continuous Galactic method. So, I'm going to show how to rewrite the original formulation of the DG methods. I'll show some. I'll show some superconvergence. I'm going to say something about what we are doing about this, give some references, and to honor the title of the conference, I'm going to propose a contemporary challenge in theft methods along these lines. Okay. Any question? No question. All right. So. Uh, all right, so uh, please don't feel insulted by the simplicity of this method. Of this model problem is just du dt equal to f of tu, a simple non-linear ODE. And I chose this simple example because I will be able to prove everything in this talk, and the essence of the idea can be captured very nicely here. Very nicely here. All right, so we are going to do this thing, and I'm going to start with Bernie Hong. So in 72, so a long time ago, I guess many of you were not even born, in 72, Hall introduced the continuous Valerian method as a method for solving. Solving this ODE. So on the interval in, we have Tn minus 1, Tn. Tn are the nodal points of our mesh. Then UCG is the element of the space of polymers that will be K plus 1, not K, but K plus 1 that solves the following formulation. So essentially, you can see that. You can see that we multiply this ODE by a test function, the test function, and we require the test function to be in pk, not pk plus one, but pk. And since we need one extra condition to fix the polynomial, then we require continuity. Require continuity across the intervals. Okay? So, this in our modern vocabulary, we will call this a petropical lurking method. It's a petropical lurking method because the trial space is pk plus one, but the test. But the test space is PK, so the spaces are different. All right. Any question? No question. All right. Okay, so that was in 72, very close to 73 and 74. In 73, with an hill and also the Saint and Raviar, as I mentioned before. And Raviar, as I mentioned before, introduced this continuous inner method. And as you might know, it is defined as follows. So in this time, we take dgh in pk, not pk plus one, and we require that it solves a different formulation. So essentially. So essentially, what we do is we integrate by parts, and when we integrate by parts, we put a little hat and we take this at the upwinding method, which is this one. So this is the upwinding numerical trace, right? So you see that the right-hand side, the right-hand side, there are many differences between Between this DG method and the CG method. First of all, we use, this is a Galerkin method, and the previous one was a Petro-Galerkin method. This uses these continuous functions, and the other one uses continuous functions. So, and the root formulation looks very Very very different, very different. So for 50 years, right? 50 years, 70, 80, 90, yeah, for 50 years, these methods were not considered to be relatable. And I am going to show you that that was a huge mistake. A huge mistake. So, fortunately, after 50 years, we can fix the situation. I'm going to fix the situation as follows. All right, so first I'm going to introduce some auxiliary polynomials, which I call radol polynomials. I look for the literature in the literature if there is something called radol. If there is something called Radot polynomials, I didn't find any definition like that. They talk about Radot quadrature rules. Well, you know, the quantity rules are related to zeros of polynomials. So I call, I'll call the corresponding polynomial for a double polynomial. So what the polynomial I want is a polynomial degree k. I want is a polynomial degree k plus 1. It's going to be 0 at the extreme left, right of the interval, and 1 on the other one. And it's going to be orthogonal to PK management. So these polynomials are very easy to find. If you are familiar with Legend polynomials, these are. Polynomials, it's this Rn is one half of the Legend polynomial k plus one minus Legend polynomial of k minus one times a constant plus or minus one. I don't remember, but they are very easy. The point is that they are very easy to find. Okay, so now let's do the what we want to do. So, I'm going to do I'm Going to do, I'm going to do the following thing. So, here I'm going to integrate this term by parts, integrate the term by part, and then I'll get d eu dt v and here I get an additional term. So let me show you that. Okay, so I integrated by parts, and I have something here, and by the this term. This term has two terms, but one of them is zero when I integrate by parts because of the definition of the upwinding method. The term associated at Tn is zero, but the term that survives is the one associated to n minus one. So here we go. Sh is equal to this. SH is equal to this thing, but the TN term disappears. Okay. And we are going to call this the stabilization term. So what I'm going to show you is the following. What I want to do, okay, so first of all, notice that if I move SH to the right-hand side and F to the left-hand side, we see that. left hand side we see that we have here du dt minus f which is the residual inside the element on the other hand minus s gives me this term times v and this is the residual at the interface so we have two residuals right if the two residuals were equal to zero then we have the exact solution uh so what this meant what So what this term does, what this DG method does, is relates the residual inside the element to the residual on the border. And so what I'm going to do is I'm going to change the shape of this residual in the border and I'm going to incorporate what happens in What happens into U. Okay? So I'm going to transform this residual on the border into a part of a residual in the interpre inside the element. Okay. And this is what we could call the transformation of the stability. Transformation of the stabilization into some space. Okay. All right. So I'm going to do this this way. So I'm going to take this S and put it here. And I'm going to have this is the jump and this is V. And all you need to do, what I'm going to do, is to. I'm going to do is to take a first year of calculus. And you know, our job as mathematicians is to make things so simple that they are embarrassing. So I am actually embarrassed to show you this, which means that I did a good job. So look at this guy. So this is a test function v at tn minus one, and I write this. T n minus 1, and I write this as 0 times v at tn minus 1, v at tn minus 1. Then by 2 and 3, by 2 and 3, by these two guys, 2 and 3, I replace 0 by R at that point, at the end, replace 1 by R at the end. And then we see that these things. This thing is a divergence, the integral of a divergence of the citizen derivative, that fundamental term of calculus, I suppose. And then I differentiate and there's a term that has vanished because that term is R times D V D T. DVDT is in PK minus one, and I have requested that R be That R be orthogonal to that by property number four. So here I replace W by D V D T and by four this is zero. So you see that now what I can do is to grab this term and put it together with R, right? And so this term that was the residual. The residual at the interface times something is now an integral of v times something, some time derivative. It looks like this term, v times the time derivative of something. Okay, so you see here v, the time derivative of something. So this something is the jump times r. So here it is. So, here it is: the jump times R. So, I'm going to define this new post-processing of the DG solution. And as you see, I only have to grab the residual at the interface and multiply by my favorite Radau polynomial. Okay, so properties. Okay, so properties of this guy are the following. This is PK, but the whole thing is PK plus one. So this is PK plus one. The other thing is that this is continuous. Now, why is this continuous? You can see that if I evaluate at Tn, this is going to be one, and then this constant with that, and we get U hat. You had. And now, if I evaluate this to Tn from the interior, then this is zero and I have Tn, but Tn is equal to U hat. So this guy is equal to U hat at the nodal point. It's continuous. Not only that, this cost processing is equal to DG at the node. Is equal to dg at all the points at which my Radal polynomial is zero. So I have this kind of equality. This is not Juha. This is just U. Uh is equal to DG. These two guys coincide at the Radao zeros. Okay, so now we are almost there. Now what I'm going to Now, what I'm going to do is, I'm going to use this formulation to this new post-processing to rewrite the original formulation of the DG method. So, this is the original formulation. And now, this term has this form V times DT plus something else. I'm going to use that. To use that, so this is something this is something else we're adding, and then the theorem you obtained by integration by parts is the following. The DG method, the DG star guy is PK plus one and staticize this we formulation. So remember that DG at the nodal point, you see what the U hat. See what you hat, and they are continuous, right? So, remember that we have this. So, this equation becomes in our new notation, it becomes this one. So, the only difference between the oh, the only difference between these. This form of the DG method and the continuous galactic method is this red term. If you recall the definition of the D, the continuous method, we have CG, CG, CG. This CG is PK plus one and the test function is PK. So here, this guy is PK plus one, have the same equation here, and so the And so, the message of this thing is that the only difference between the continuous Glorian method and the discontinuous Glorian method is not the discretization of the time delivered, it is just the right-hand side. That's the only difference. So, essentially, the continuous Geraltian method had always been identical. Had always been identical to the discontinuous relating method in the way the time delivered was descriptized. And I guess we all miss that. We don't miss that. How is it possible? And this gives a very interesting consequence, which is this one. So now assume, I mean, if we, for example, you can use this as For example, you can use this as the basis for a discrete galaxy method, as Bernie Hall defined them. So you can use an interpolation here and then you generate a Hundi-Puta method. So if we interpolate this guy exactly at the Radal points, if we interpolate this guy exactly at the Radal points of this, then points of this then uh pg star is equal to u cg the corresponding uh discrete alerting method and more since this is equal to that and since uh bernie holm proved that this thing converges with order k plus two then uh we can prove that this guy converges with order k plus two converges with order k plus 2, not k plus 1 at the dg method. And moreover, at the zeros of that, remember that the zeros of that guy, at the zero of this guy, dg is equal to this guy. So this converges with order k plus two at those points, and this also converges with order k plus two at those points. So we get superconversion for free. So the method So, the DG method should be converged with the k plus 2 and the k plus 1 zeros of this guy. So, what I have shown is that we can transform the stabilization of the DG method in order to generate a better approximation, an approximation that has one order more. And so, it's kind of interesting to see that that's. Kind of interesting to see that that's possible. I guess that we have been buzzing around that idea for a long time, but it was here is kind of very clear. I mean, you can see that, as I was saying before, this guy is just a residual on the boundary. And it's not clear that these. That this stabilization could be rewritten in such a way that it would add something useful to the DG method. So the point of this talk is to say that, yes, it does improve the accuracy of the VG method by one order. Okay, so this is the idea. So, this is the idea in a nutshell. And what I want to discuss now is what are we doing now? So, the main two questions that are pushing us are the following. The first is that we can do that for any PVE in a systematic manner. And the other question is, And the other question is whether additional order of convergence or accuracy can be gained. And so I have a bunch of collaborators here. So I want to mention them a little bit so that you guys get an idea of what we are doing with Sinvatsa and Antaramo, who is a mechanical engineer. We are applying these things to the continuous glow. These things to the continuous glerking method for second-order elliptic PDEs. So, you know, in that case, the residuals are the residual in the interior of the method, the jump and the jump of the first-order derivative. So, we are applying this technique in order to convert the in order. Well, we are applying this technique there. And then we assume. There and then, with Zugin Lal, who is my last PhD student, we are doing this for CFD. And then with my collaborators of MIT, we are working on wave propagation. We do one superconvergence of functionals. So we can get order with polynomials degree k. With polymers degree k, we can get order 4k if you do these things properly. With uh Shikai Du and Sanchez, we are extending these to shallow water equations and KDD with Alexander Urn to fluid systems and with Oikawa and Saito to HDG and MIT metal for elliptic PDEs. Now, I have to say, I have to say that some of my collaborations. That some of my collaborators still do not know they are working with me on this topic. So, but I'll let them know soon enough. Okay, so all of this to show you that there is a lot of work going on. And I want to discuss a little bit the references. So, if you don't know Bernie Hong, Bernie Hong, I would encourage you guys to read his 72 papers. They are super cool, super cool. So the one, the first paper is about the continuous galaxy method. And the second paper is a follow-up in which he uses interpolation to evaluate the The integrals. And so those are the maybe two papers that everybody should read from now on. And then we also have the good old reference about the DG method to read and heal in 73, the one in Los Alamos, guys, and then Lisa R of DR. Lusan R of DR, who did a magnificent work on this method. And they were the first to show that this is applied to ODEs. It corresponds to the second sub-diagonal in the Padir approximation of the exponentials. Very good, very good. Exponentials. Very good, very good paper. And so, those are the oldies, and the new Vs are the following. So, this idea of transforming the residuals into spaces, I think I introduced that in this paper in 2023 in Japan. And then with an answer. Then, with an answeramu, we also publish a paper in which we show that you can do the reverse of what I have done here. So, here I grab the stabilization term and transform it into a space. And then you can imagine that you can do exactly the same reverse procedure. And that's what we did. So, we grabbed the hybrid. So, we grab the habitat Robiatoman method and we transform a part of the spaces into a stabilization. So, in such a way that there are less degrees of freedom to locally, to globally solve for. And so, we show that, or he shows, he showed that there is again. He showed that there is a gain of about between 10% and 20% when you go from k equal to 1 to k equal to 20. So that's another application of this idea. And then there's another paper which is exactly what I just show you. And this is the paper in the honor of Chi Wan's 65th birthday. 55th birthday, and the advantage of this paper is that we only have five pages. So I can give it to you anytime. So it's currently in revision. And to end my talk, I guess I was too fast, I guess. To end my talk, I would like to propose a contemporary challenge in test method. Temporary challenge in test methods, and the question is: how to extend this procedure to threat method. And I believe that it's not very difficult, I think, and it would allow you guys to solve for your trust method and then do some local processings to enhance the accuracy of the method essentially for free. So, yeah, in particular, Yeah, in particular, in particular, I had to say, let me go back, let me go back. Okay, with Subin. Subin is my last, as I said, my last PhD student, and we have started to apply this thing to Digimettos for the transport equation, Monday. So, and here I have shown that you can. That you can increase the accuracy by one order. With zooming LAN, we have shown that you can repeat this process iteratively k times. So for the DG method with polynomials of degree k, we usually get order k plus one, but with this. One but with this post-processing, we can get up to 2k plus 1. So, um, so and then you have to be a little bit careful about how to define these iterations. But but once you grab the trick, it's fairly fairly easy. It's very, very easy. It's embarrassing. And so my proposal is that it's highly probable, highly, and it is highly possible to do something similar for traffic methods. I don't think this is the fact that it is traffic or not traffic doesn't really matter. And so And so that's the talk. Any questions? So thank you very much, Bernardo, for your outstanding talk. Apparently, we have been saving the questions, so we will start with questions here in the room. Thank you for your talk. I hope that you can hear me. Do you know the method that is called flux or construction that is very close to this, I think, because this has some connection with Raddo polynomials that is constructed exactly in the same way as your flux correction before. And I am asking my I am asking myself if your approach does not give proof to this flu flux reconstruction method, and until which point? But if you don't have an answer. Let's see, can you repeat a little bit? Because I cannot hear you very well. You say that there is a reference I should know. Liz Marie will type in the chat. Okay, okay. The choice. Okay, okay. Please, please do. There is a method called flux reconstruction with connection with the radio polynomial, which has exactly the same continuity correction than you. Okay. And that is equivalent to a DG method. Okay. And I think it is the same. So perhaps it might be the same, yes. Perhaps it can be the same in 1D. In Wendy, and perhaps your approach gives a proof of convergence for FR. That is mostly open. An open question. Okay, and who wrote this paper? The first paper about EFER is WIN. H-U-I-N. H H-U-U-I-N. Win H-U-E-N. H U E N. Oh, H U Y N. Yes, exactly. In 2007. Okay, okay. And it gives the equivalence between DJ and DG and F A. Oh, that's okay. So I think you should have a look. I will. Thank you very much. Because your work can really improve this technique. Your work can really. Your work can uh really extend uh the their work. It can really bring something that you have done. Okay. Thank you. Hi, Ricardo. It is uh Bruno Despre. Yeah, Bruno. Come on, come on. So, okay, so you mentioned the work. Okay, I have a question and then I have a remark. So, you mentioned the work of there are. So you mentioned the work of there are both remarks actually. Uh you mentioned the work of Alexander Ayr and perhaps he is not still aware that you collaborate with him. Are you is he or not? Is he or not? He's not aware. He's not aware. Okay, okay. Yeah, yeah, okay. No, no, no. Okay, because Alexandre also collaborates a lot with a guy, Martin Voralique, perhaps you have met him once. Yes. And I remember some works by Martin. By Martin, different, completely different from what you have explained, of course, but Martin also tried to make a bridge. It was more in multi-D, it was more between, say, finite volume techniques or high-order discontinuous techniques and finite element techniques. The bridge between continuous and discontinuous techniques. Yes. And exactly. So, yeah, so I think now it is a So I think now it is a you're right, it is a natural tendency to explain, if I it is a natural act of research, to explain that many of the methods that have been invented in the past are not that different are not that different. Yes, yes, yes. But I understand more better what you explained, that Martin explained to me. So the last remark is. The last remark is that I have, it is exactly the slide that you have here on the screen. And then suddenly, yeah, because I am currently working on transmethode. This is why I am here. And now I understand I have to think of exactly if there can be a bridge between continuous and discontinuous trans methods. And I agree with you, it is a good question. Yes. Probably I should have a look at. I should have a look at this question for my own work. Thank you. Thank you, Ricardo. Yeah, yeah. You're welcome. Thank you for the remarks. I appreciate them. Any other questions? We are going to have a break for the next call. Thank you so much. Okay. 