If at any point you have questions, please just interrupt, shout at me. There's 90 minutes to work with here, so there should be plenty of time to answer questions. Generally, throughout everything today, X is always going to be a convex metric space. It's just going to be a homeomorphism. Sometimes, often, I'll be talking. Sometimes, often, I'll be talking about flows. So, this will just be a continuous flow. And D is always just going to be some continuous potential. So, given this setup, right, we all do thermodynamic. We can look at this system. We can look at the system XFB, and we can say, one, is there a unique equilibrium state? And the second question is: what mixing properties does this equilibrium say at? This mutton. And so today, we'll mainly be talking about two specific types of mixing properties. The first is the Bernoulli property. This is the strongest qualitative mixing property that you can have. It's just saying that it's going to be, your system is going to be isomorphic to To for newly shifted. And then the mixing property below that, weaker than that, is going to be the K property. What this is, is this is completely positive entropy. So every non-trivial factor has positive entropy. Phrased in terms of mixing conditions, it's that the future is independent from the arbitrarily distant past. Hopefully, one of these two kind of works for you in your brain, but it's going to be a mixing property. It's obviously weaker than Bernoulli, and it's stronger than mixing of all orders. So, it's quite a strong mixing property with some nice kind of immediate consequences. Immediate consequences. So today, as kind of indicated by the title of the talk, we'll be talking about the specification approach to answering these questions. All right, so what's the kind of first setting that we should think about? Given the title of this workshop, we can let M just be a closed negatively curved manifold. And then we just, our space is going to be a tangent bundle, and then our flow is going to be the geodetic flow, which Mark talked about yesterday. So in this setting, if phi is older continuous, then we know that mu phi is. Then we know that mu phi is unique and renewable. We know lots of other things, but by the specification approach, we can actually employ those as well. So the way to kind of go about doing this is to follow work with Bowen, who kind of introduced this whole specification approach. And so this result of Bowen is as follows. So kind of in the general setting of compact metrics, In the general setting of compact metric spaces. So suppose one, your system is expansive. Meaning, if you have two points, then they separate by scale epsilon at some point in time. And if they don't, then they must be the same point. Your system has specification. I'll explain what specification is in just a second. Three, your potential phi has the bone property. And if you have these three conditions, then there exists a unique equilibrium state mu phi. So in proves it's partially mixing, but for Especially mixing, but for today, we'll kind of stop at ergotic because he doesn't make it all the way up to the mixing or mixing of all orders of the k property or anything like this. So what are the definitions kind of involved here? Well, expansive, I said out loud. So what's the specification property? The specification property is this visible blue bulge. What this says is it says that for all epsilon greater than zero, there exists some specification, specification time, tau greater than zero. Starting to run. Okay. So I was like, oh, great. Gotten more ink since yesterday. Okay. So for all epsilon greater than zero, this is going to be a shadowing constant. There exists some. Shadowing constant, there exists some specification time tau such that given any collection of orbit segments, xi, ni, i equals one to k, then we can shadow them. So if these are our orbit segments, x1, f to the n1, x1, x2, f to the n2, x2, and k is going to be three for me today. Going to be three for me today, f to the m3 x3, then we can find some point y and it's going to always shadow at scale epsilon. And it's going to take exactly time tau, where it will do anything at once. We don't know what, but it will take exactly time tau to shadow and kind of go from one segment to the next. So, this is a specification property. You pick some shadowing constant epsilon. Shadowing constant epsilon, then it gives out some traveling time to get from orbit segment to orbit segment. And then, given any kind of number of orbit segments, can be three, four, twenty, you can go and construct the specifying orbit. This is the specification property. And written like this, we say that specific, it has specification at all scales, meaning that you can kind of shrink epsilon down. Meaning that you can kind of shrink epsilon down all the way. Yeah. And you can do this even if you've got an infinite sequence. So all of a sequence in here. If you make it work, yeah. So in the definition, just of the property, it just requires finitely many. And then from there, you kind of take the limiting sequence. Have a wealth of markers. I have a wealth of markers now. But yeah, so this is the specification property. And what's the Bellen property? Feel the need to specify. Bellen didn't, you know, name it. So the Bellen property is just going to be a regularity property. And so what it says. And so, what it says is it says that there exists some constant k greater than zero such that for all x in your space, if you look at the supremum over of the difference between the birkhoffs, well, not quite the birkhoffs, but Our problems, but uh, we sum along the orbits of b of f to the ix minus b of f to the iy from i equals zero to n minus one. And you take the supremum over all y in the Bowen ball of time n and scale epsilon over all n and n. This is going to be bounded by some constant x. So, the Bowen ball, this is just going to be all points that say epsilon close for time n. And so you can think of this as a regularity property, basically saying if you, instead of looking at this sum, the zergatic sum for X, you instead look at something in the Bowen mall, it's going to change by at most a constant. Yes. 20. I see. Thank you. Okay. Yeah. I'll rewrite it and then we'll just leave this as a reminder to myself. Yeah, sorry. So bone property at scale epsilon. So you pick some scale epsilon, it has the bone property at that scale, and then it At that scale, and then it's going to have the bone property of scale epsilon, it will have the bone property at different various different scales as well. At some scale epsilon, yes. So here, fix some scale, then it will have specification at all scales. So just rewriting the Bellin property here. So there exists K. It depends. There exists k, it depends on your scale epsilon greater than zero, such that for all x and x, you look at the supremum over y in the Bowen ball of time n's like scale epsilon and n and n of the difference between the sum Between the sum my equals zero and minus one v of f to the i x minus v of f to the iy. So just rewriting the track. So with these kind of three conditions, Bone is able to show that there's going to be a unique equilibrium state kind of in this for anything satisfying this regime. Oh, oh, thank you. Yeah. No. Very important. Good to have endings to your clauses. So yeah, so the reason kind of for these different properties are because all of these are going to be hallmarks of uniformly hyperbolic systems with older continuous potential. So he's just kind of abstracting out away from this. Away from this. I promised that you could get to the Bernoulli property and clear me left up and make it even to the K property. And so how do we kind of continue up the mixing hierarchy? Well, we use this beautiful result of LaDrappier. So what this result is, is it a It's a way of showing the K property for various systems with unique equilibrium. So, theorem of Libra. I'm rephrasing it slightly from how he wrote it, but from looking at the proof, this is, you can see that this is going to be the case. But what it is, is it's if you look at the Cartesian product of the system with itself. has a unique and if it has a unique equilibrium state so the potential defined by psi of xy is equal to b of x plus b of y so you look at the sum of the potential on each coordinate and if this has a unique equilibrium state for this kind of potential in the product then you have two things are true one uh Two things are true. One, there exists a unique equilibrium state, UV, for the base system. He didn't write this down, but it's not hard to show. So, but the second thing is kind of the meat of the result. And what it says is that mu phi has this hay. And so now, what this result says is it gives us a path towards proving the K property, right? What you need to do is you need to somehow show that there's going to be a unique equilibrium state in the product system. A priori, this is very unclear how you would do that, but he hopefully provided a nice corollary, namely that the mu phi from Bowen's theorem. From Bowen's theorem. Okay. And this is a very short actual proof. So this, by the way, a very nice result. And I highly recommend you look it up. If people want to know, I can tell you about the proof. A couple, one paragraph, really. But it's quite nice. So how do we? So, how do we follow this corollary? Well, what we need to do is we need to look at the Cartesian product and show that it has a unique equilibrium state. And so, what we do is we say, okay, can we lift all of these conditions from Bowen's original theorem and show that they all lift to the product? Well, we're looking at a discrete time system and we care about expansivity. Well, that lists to the product without any issue, right? Because we say, if the If the distance between f to the i x, f to the i y, or x1, y1, and f to the i x2, f to the iy2 is less than or equal to epsilon for all i and z. Well, if this is the case, then both of the coordinates must be epsilon close. So x minus z would be less with no issues. The product of expensive systems is always expensive, provided it's discrete time, yes. Yeah, so and careful. I'm being careful to work with the discrete time thing here. If you are working with flows, things get more annoying. Yeah. So the specification property is also going to lift to products. It's slightly more difficult to see, but not too much. What you have to imagine is that you're ambidextrous, right? You start, you still. Right, you start, you still take your shadowing constant, get some specification time, and then what you're given is you're given orbit segments in the product. So you just draw one with your right hand, one with your left hand, and then you can shadow and line up the orbit segments because you're working with exact times tau in between each orbit segment. So if you're familiar with weak specification, which is where you have tau is just an upper bound for the specification time, that's already going to be a problem because weak specification. A problem because weak specification isn't going to lift to products. So it's strictly the fact that we're using this strong specification property here. So specification lifts to products without any issue. And then the Boeing property, well, what you can see is that because our potential of the product is just going to be the sum, then it splits up nicely and it's an application of the triangle inequality. So everything works out very beautifully. Works out very beautifully. And all of a sudden, we say, okay, now in this work of Bowen, these unique equilibrium states all have the K property. Great. And it was really cheap, too. All we needed to do was just use the work of Bowen and just use it twice. So this is the K property. I promised Bernoulli, how does the argument for Bernoulli work? Bernoulli worked. So the mu phi in setting one are Bernoulli. What this is going to do is this is going to follow because, I guess, due to an argument of Ornstein and Weiss. Which gives a method of jumping from the K property to the Bernoulli property, provided that your system is, in their case, they were working specifically kind of with the setting. But in general, what you need is you need some amount of hyperbolicity. This is plenty. And then you need your measure to look like a product measure on the stable and the unstable. Stable. This argument isn't written down nicely anywhere that I'm aware of, but it's by cobbling together different pieces. You can see that this is pretty difficult. Yes. Yeah. I guess yeah, no, she does use the argument. Arts in the box. Okay, solid. Yeah. Yeah. So, yeah. So using these kind of three different steps, getting uniqueness, showing up. Yes. Did Regna go to Rixley from Bowen to the Norwegian, or did she go to screen showing that it was how you use it La Drafier? She didn't use LaDraffier to my knowledge, but I think she is. To my knowledge, but I think she assumed, I think she already knew that it was fay for other reasons. So you can't get kayed via. I don't. So there's work of Ornstein and Weiss from 94 that gives an argument to get K using local product structure, but it's specific to smooth measures. And yeah, so it's not going to be. It's not going to be there, yeah. Um, but that would have been well after Regner did that, but yeah, so she said it was pay through, I think, I don't remember what she cited, but I don't think it was letter. But yeah, so we have this kind of method for when we can apply. Apply the specification argument to get uniqueness. We can try and show that all of the properties lit to the product using the drop here to get the pay property. And then sometimes when your settings are nice enough, you can get the Bernoulli property as well. This is very heavily setting to kind of this is much longer. So, any questions as of right now? Okay. So now, what I'll do is I'll give kind of a rough sketch of how these different components of the these different assumptions of Bellman actually contribute to the proof of uniqueness of equilibrium states. And then this will lead into kind of this generalization of Felen's work by Kungemage and Paul. So, what are the kind of this is going to be a very rough sketch of Bowen's document. So, what he does is first expansivity. What it does is expansivity lets us. Expansivity lets us kind of work at some specific scale, epsilon, and kind of construct a measure from n epsilon separated sets from maximizing N epsilon separated sets. E m this just means that if you take any two points in your set and flow them forward by time n, or I guess move them, hit it with the transformation n times, then at some point we'll separate by distance epsilon. And maximizing is something that's going to be with respect to the given potential. And then what you can do is you can. And then, what you can do is you can define new m to be supported just on the set EM, weight it properly. Again, I won't get into too many details about how you actually weight it unless people ask, but you just, this is finitely many points. You take a sum of point masses, weight it, and then you look the. And then you define μn is just going to be the sum, the average of these new n's pushed forward by n. And then what you can say is you can say, okay, well, mu and k, you have some convergent sub-sequence which is going to converge to an equilibrium state, followed by the variation principle argument. This is one thing that expansivity does. The next kind of main part of the proof. Yeah, so this produces a mu phi. Mu phi is an equilibrium state just from kind of this assumption that you're building this out of these maximizing equilibrium. Maximizing equilibrium is in the end of Yeah, you so you choose it to maximize the sum uh of E to the sum S and phi of X, or at least at least for God. So doing both expensive as specification to know that is just an equilibrium. All we use here is expensive. So, all you need to know is that the impression it appears to say at epsilon, so even way we couldn't expand it if we were there. Yeah. Yeah, the main thing is here is that everything is living at some scale epsilon. Where specification comes in, I want to leave that up. So, specification comes in because what it tells us is it gives us information about what this is actually going to look like. So items two and three tell us, so specification and the filling property. So two and three. Tell us that is a Gibbs measure, meaning you have some constant v of epsilon such that this is going to be less than or equal to me of vn x epsilon divided by e to the minus n e of b plus some minus zero to n minus one. To n minus one, the of that x. And it's bounded above by c of epsilon as well. And so this is where the specification property, or one of the places of the specification property, kind of comes into play. And the heart of the argument is going to be, okay, you take, we care about the measure of these kind of m epsilon Bowen balls. So you take some x, you look at the orbit segment starting at x and going. Segment starting at x and going for time to n, and then somehow you use the specification property to connect a bunch of a maximizing set of orbit segments kind of that go through that go through here and then kind of join up with each. Join up with each one of their compatriots on either side. And you're not actually shadowing, I guess you're shadowing X, but really you're shadowing some orbit segments that's in your set EN. But this is really where the specification property is being used, and the Bohemian property is being used to let you kind of play around with whether or not you're looking at the sums over X or the sums over something in the n of the long Bowen ball. But this is somehow the picture to kind of keep in mind: you have your specific point X, and then you're estimating the measure of it, of the kind of phone ball around it, and you show that there must be a lot of elements in it. Then, so this is kind of how the specification property and the bone property are used. So, then what we have is we have an equilibrium state with the Gibbs property. Have an equilibrium state with the Gibbs property, and then a similar argument or a similar style of argument shows that mu phi is ergot. And the way that this argument works is you show that you look at the measure of Of bow involved intersected with f to the minus k the m y epsilon. So this is going to be greater than or equal to some constant times the measure of bn x epsilon measure of b m y epsilon. And this is a sort of partial mixing condition, but it implies ergodicity. And it's a similar style of argument. But once you get this, what you can do is you can approximate sets using expansivity with these bone balls. And so really, then use expansivity. Then we have our goodistic. So then we have ergodicity. And then finally, what you do is you show there do not exist mutually singular equilibrium states. So what you do is you say, okay, we have this equilibrium state mu, it's ergodic. And if there's any other equilibrium state, it can't be mutually singular. And so if you have, since you already know that it's ergodic, it must be the only equilibrium state. So this is kind of the very rough sketch of how Bowen's argument works. Of how Bowens' argument works. The question now is: okay, how do we extend Bowens' argument? All of this is supposed to be hallmarks of uniform hyperbolicity. We shouldn't expect to always have this specification property everywhere or even have expansivity. In particular, what we can do, this leads me to setting two, which is just going to be imagine that you have a non-positively curved manifold, rank one. Instantly, we can't. Uh, instantly, we can't use Bowen's argument and its full generality. So how to extend and so this is really where the work of Ball and Dam come in. So how to extend, I guess, to non-uniformly good. Good settings EG rank one non-positively curved. So before I write down the Common Heiger-Thompson result, I want to talk about what the key ideas behind it are. So the key ideas at least At least, what I think of as the key ideas, Dan, should please stop me if you disagree. So it's that everything we've talked about, we've mentioned is in terms of orbit segments. So I've been using this terminology loosely, but I've just Basically, by just mean everything that we talk about, we're not caring about specification kind of as some abstract thing. What we're saying is we're saying we can glue orbit segments together. Here, what we're doing is we're looking at the ergonomic sums along specific orbit segments. Even this argument for the Gibbs property, we're just looking at orbit segments again, because every time that we talk about a Bowen ball, we're just looking at some ball that shadows at scale epsilon. You know, ball that shadows at scale epsilon around a specific orbit segment. So, if we think of everything now in terms of orbit segments, then we can kind of break this up into two classes. One, good orbit segments have specification and the Boeing property. So, if we look at the definition of specification, The definition of specification here, what we said is we said, okay, given any shadowing constant, there exists some time such that given any collection of orbits, but we can just as easily do this in black. Yeah. So we can just as easily say that we want this collection of orbit segments to be taken from some collection of good orbit segments. So what we're doing is we're shadowing specific. So, what we're doing is we're shadowing specifically these good orbit segments. And here, what we can do is we can say for all x and x, and we can change that to instead of looking at x and x, we look specifically at orbit segments xn that are in some collection of good orbit segments. Right? So, now what we're doing is we're saying, okay, we have these good orbit segments that have. We have these good orbit segments that have specification and the bone property. As you recall, those were the main tools that we needed to kind of get the Gibbs property for this thing. So now what you should imagine is you should imagine that if you require that this orbit segment is good, that these ones are maybe good, then you can still get some form of the Gibbs property. Then the final kind of key idea is that we can decompose. Is that we can decompose any orbit segment into something that's good and two things that are bad. So if this is just some arbitrary orbit segment xn, we break it up. This part in the middle, we say this is good. That's where we can kind of glue things together. We've got the Bowen property. This is going to be something that's bad. This is going to be something that's bad, and that's going to also be something that's bad. I did a P here and an S here for prefix and suffic. And so then what we can do is we can say, okay, we have our collection of good orbit segments, and then we have everything else that's either truly bad or we can break it down into its component parts. With these kind of key ideas, I can state Von and Dan's results. So theorem Herman Haga Thompson. This will take a little bit of time, but you should understand most of what we've talked about so far, following kind of the same definition. Following kind of the same definitions as Mellon. So you suppose that you have some decomposition of your space. If I can do a script G, I can't write a G anymore. That's a first. Okay. So suppose you have a decomposition, meaning given any orbit segment, you can chop it up. You can chop it up into three parts, which will follow this. So, given any orbit segment, or you have this decomposition, and first, you have the pressure of obstructions to expansivity. So this is going to be the supremum of the entropy, the time one map, plus the integral of E d mu over all measures. All measures which assign positive measure to this non-expansive set. I won't really go into defining this, but basically it's just points where you have non-expansive behavior, where it's shadowed by something that's not in an orbit site. So suppose that this pressure is less than full pressure, right? We want everything to be expansive. So if we don't have this pressure gap here, then we shouldn't expect to have a unique equilibrium state, because there should be some equilibrium state coming. Equilibrium state coming from here. So, this is kind of condition one. Condition two is going to be that G has weak specification. So that's just this definition here, except instead of having exactly time tau between things, you have an upper bound of tau. So these might get closer together, they might get, but they won't get any. They might get, but they won't get any farther. Condition three is that V has the Bowen property. Yeah, so weak specification is instead of having this be exactly tau, it's less than or equal to that. Let those so. So, P has the bone property on G. That's exactly this definition here. And then there's an additional kind of fourth condition that we didn't see. We can see the analogs of bone's three conditions here, an expansivity condition, a specification condition, a bone property condition. But we also need that the pressure of these collections of orbit segments. Is not full. It turns out that you can define the pressure, some sort of non-stationary version of pressure, which I won't go into on these collections of orbit segments. We need it to not be whole pressure. Yeah, so the significance of the square brackets is basically a way to discretize the Discretize the collections of orbit segments so that way instead of having orbit segments of any time length, you have orbit segments with integer time lengths. We're going to ignore it in about seven minutes, at which point you can forget all about it. So if you want to start forgetting about it now, that's fine. If you have these conditions, when you say expanded in green, do you mean just to start more exactly or? just the starting point actively or yeah the whole the whole orbit segment the whole orbit segment yeah so yeah so you you can't go go further so i guess really what you're going to do is you're going to get rid of the n there because you're looking at if you have something that's good for all time n then that's kind of going to be included the supremum over n g is equal to e c Um, g is a coefficient of economics. Yeah, so I'll write that down. G is a subset of x cross there and that. Yeah, same with prefixes and suffixes. If you have all these conditions, there exists a unique equilibrium state mu thing. Yes, pointing out condition two. Um, addition to what I've written down, I think this is true now, but that needed an improvement to what they're um probably going to say this anyway. Uh, yeah, so I'm going to get that. So, uh, so yeah, so this is going to follow from work of Pacifico Young Young letting you state it like this. Um, so yeah, so I'll state it now. Thank you. State it now. Thank you. And so we can kind of compare this to this result of Bowen. We have three corresponding conditions plus an extra condition to kind of get rid of these bad portions. So what are some of the kind of new difficulties that need to be overcome? Well, what happens is this condition right here, condition one, is still used to construct the equilibrium. One is still used to construct the equilibrium state, or show that you can construct an equilibrium state by the same method. What it does is it lets you show that the pressure at some scale epsilon is the full pressure. What does four do? Yeah, I can. Yeah. So, what does kind of condition four do? Well, condition four provides a kind of key. So, condition four is used to show that mu phi has a lower Gibbs property. Meaning that instead of having meaning that instead of having both a lower bound and an upper bound, all we have is a lower bound. And what condition four does is it shows that there are enough kind of of these orbit segments before and enough of these orbit segments after that are good and that we can that belong to the collection of good orbit segments and that we can kind of connect in using specification. There's one other other things are used in addition to show this. All of the kind of conditions are used to show that. Are used to show that, but this is, I think, one, at least in terms of these steps, that's one of the kind of tools that it's used for. Similarly, you need the same thing to show something kind of like this to get ergodicity. Except you don't quite get quite this nice upper bound. But here I talked about using Uh, here I talked about using expansivity to approximate any arbitrary set. But for Clement Hager-Thompson, uh, what they can do is they can they use one to approximate invariant sets. They can't necessarily approximate any set whatsoever. Uh, it turns out that this is sufficient. It turns out that this is sufficient to run the argument to show that this is going to be your product. You only need to approximate an invariant set. And similarly, it's enough to run the argument, but there's no mutually singular equilibrium states. You again only need to approximate invariant sets. But this is kind of the one of the key steps is that you can't. You can't approximate just any step anymore. So these are kind of some of the key steps. There's a lot more work going into this than kind of what I've outlined, but the bare bones of the Bowen argument, it's going to kind of come together with these key steps, and the general structure is going to be the same. So yeah. Yeah, lots of stuff going into these key steps, but from a kind of broad overview. So there's some very obvious pros to this. Namely, it's very flexible and can be used in any setting you can apply it to. There's also going to be, so it's quite general. One of the difficulties, the difficulty is finding a good decomposition. No guidance is given to what the decomposition should be. On the one hand, this is great. If you find one that works, you're happy. If you find one that works, you're happy. But on the other hand, if you're coming at it and trying to apply this theorem to something, you have to start from scratch. So, what's the solution? The solution is just pick a decomposition in advance or pick a form of decomposition. So, basically, what you're doing is that you can do that. So basically, what you do is you sacrifice a little bit of the flexibility and the generality, and by picking a specific type of form of decomposition, you gain, it turns out you can get a lot more in terms of mixing properties. Okay. So what specific type of decomposition? I'm going to explain exactly what I mean by that. So I'm going to give you a general decomposition and then tell you how you figure it out. And then tell you how you figure it out. I wanted to call it a shape of the decomposition, and then I realized it just sounded good in my head, and I didn't know what that meant. So I changed it out for form. So what you're going to do is given some function lambda from x that's non-negative, which is lower semi-continuous. Is lower semi-continuous and bounded. So you can just think of this as continuous if you want. That's fine. This is mostly an artifact of one specific application. So given some function lambda, define the lambda decomposition at scale eta. At scale eta, as we say v of eta, this is going to be our collection of bad orbit segments. This is going to be everything which you have that the average value from zero to t of lambda of f s x d s is less than eta. So the average value of lambda along your orbit segment is bounded above by eta. Segment is bounded above by eta and your collection of good orbit segments. This is going to be everything which instead of having that it just has average value greater than eta, what you're going to do is you're going to say that every initial subsegment has average value greater than or equal to eta, as does every terminal subsegment. So. So you can write this out, but I think the picture is clearer about what's going on. But given this as a good orbit segment, then you can define your prefixes and your suffixes to be this collection of bad orbit segments. And then what you do for a decomposition is you start with some given x or some given orbit segment. You go and you take the part. You go and you take the farthest point along that's going to be bad. Then you go from the back or from the future, work backwards, and you pick the farthest point that's going to be a bad orbit segment, meaning the average value is at most theta. And then what's left is going to satisfy this kind of good proportion. So, this is the thing to understand, and this is the picture to keep in mind. This might seem a little arbitrary, but it turns out that many applications of Clemenhager-Thompson actually use this form of decomposition. In particular, the work of Burns, Kemenhager, Fisher, and Thompson for rank one non-positively curved manifolds uses lambda decomposition. They have a continuous lambda, but that's fine. Continuous implies lower semi-continuity. But it turns out that But it turns out that with this particular type of decomposition, you get a generalization, not a generalization, you get a different version of this theorem, I'll say. So I'll just put in red the amendments. So if you have instead that this is specifically a lambda decomposition, then condition one stays the same. Condition two, now what you want is you want g is you want g of eta has weak specification for all eta greater than zero you want that phi has the bone property on g of eta for all eta greater than zero and now you can get rid of this discretization as promised maybe slightly longer than seven minutes ago uh and instead what you do is you say okay the pressure of the intersection uh the pressure of the set for which lambda For which lambda is zero for all time, this pressure is less than full pressure. So you look at the set of points for which lambda is always zero. This should in some sense be the worst, right? If something is bad just by having low average value, if you're always zero, you've got to be terrible. So what you do is you say, okay, this set, this invariant set, compact invariant set, does not have full pressure. Then, if you have these kind of new additions, then you have that there exists a unique equilibrium state, mu theta. So, right now I haven't changed the implication at all. So, you're like, okay, Ben, why do you do this? Well, what you can do is you can say, okay, if I had a blue marker. If instead of weak specification, you work with strong specification, so you have specific exact gaps between orbit segments, then this unique equilibrium state in u phi is weak mixing. Further, if your base system Your base system is asymptotically entropy expansive. Am I running into the podium down here? Or can you see? I see no complaints. So if this is asymptotically H expansive and you have that the pressure, I'll write this over there again. So, if you haven't had your system as asymptotically entropy expansive, this is a much stronger condition than what's actually necessary, but since really what's necessary is just that the entropy map is upper semi-continuous in the product system, but that's a mathful right. So further, F X F asymptotically H expansive. And the pressure of this set and the product of the set of points for which lambda is zero in both coordinates for all time does not have full pressure with respect to this potential from LaDropier's proof. From LaDropier's group, I'll say what these things are. Then mu p is k, where psi of xy is just the potential given by phi of x plus phi of y, and lambda tilde of xy is just going to be the product of lambda of x times lambda of y. Yes? Twice the pressure of mean is the pressure of psi. That is that. Is the pressure of psi. That is, that is, yeah. That's bias. Yes. So twice the pressure of phi or the pressure of psi. Thank you. So if you add in this additional condition, then you can get all the way up to the k property by using the drop A. So we see that somehow by working specifically with these lambda decompositions, we can kind of make everything. Of make everything jump much further up the mixing hierarchy. So, kind of a little bit of the idea. Well, the idea of the proof is going to be the same basic thing as how we showed that LaDrapier applied to Bellin. Show that these conditions let. Lift enough to run uniqueness machinery of Clement Hagatons. In particular, this is a non-trivial kind of statement. How do we run this uniqueness machinery? Well, for Well, for starters, the facts that we are working with specifically a lambda decomposition gives us a natural decomposition on the product space given by Lambda tilde. Lambda tilde is going to be lower summing continuous, bounded, and non-negative. So we can define a Lambda tilde decomposition, and it interacts really nicely with our collection of good orbit seismors, namely. Collection of good orbit segments. Namely, if something is good for lambda tilde, then it's got to be contained in the set of good cross-good orbit segments. So if it's good for lambda tilde, then each coordinate is good for lambda. Whereas a general decomposition. Yes. No, that's exactly right. If you have, take some random decomposition you think of, chances are it won't lift naturally to the product in any way. So, this gives us a decomposition, which lets us kind of try and run a lot of the arguments. One of the major problems that you run into is expansivity does not lift. Which Keith asked about much earlier, about expansivity. If I was saying that the product of expansive things was expensive. If expansive things was expansive for discrete time, they are, but for a flow, if you're looking at things with shadow saying that, okay, it's everything except for some little small orbit segment around the point. Then in general, it's possible for the non-expansive set for the flow. For the flow and the Cartesian product at scale epsilon to just be everything. Which, if you have that, then clearly condition one won't hold. So you need to overcome this. Then the other kind of big obstacle that you need to overcome is, as you may recall, for Klenkanga Thompson, I said, well, you can only approximate invariant sets. We're working with the Cartesian product, so now we can only approximate. products so now we can only approximate uh can only approximate uh invariant sets that are invariant uh in both time coordinates working independently you have some set you move you flow one coordinate keep the other the same or change both coordinates at once Both coordinates at once. Oh, that's too low. Thank you, Anne and only approximate invariant sets. Right, this is an extremely strong condition to ask for some random set. For some random set is for it to be invariant in both coordinates at once working independently. If you want to show ergodicity, for instance, it's not enough, right? There are lots of invariant sets that are invariant just along the diagonal, but aren't going to be invariant in both coordinates. So it turns out to be enough to run the mutually singular, no mutually singular argument, but to show ergodicity, what you need to do is you need to actually get this weak mixing result. Because if you may recall, If you may recall, if x at μ is weak mixing, that's equivalent to the Cartesian product being ergonomic, which is a nice result. So, I like mentioning it. So, these are kind of the obstacles that you have to overcome in the proof. Overcome in the proof. I won't really go into it too much. The really big thing is first coming up with the decomposition at all and then figuring out this expansivity, these expansivity issues. All of this is all well and great and very abstract, but this is in theory a workshop about geodesic flows, so I should talk about this a little bit. So, what regimes kind of fall into this framework? Well, trivially, the geodetic flow on negatively curved manifolds is going to fall into this, but we don't need all of this for that. So what does this apply to? Well, first it applies to rank one, the non-positively curved manifolds, with the condition that the pressure of the singular set with respect Pressure of the singular set with respect to the potential is less than pole pressure. So that's going to basically imply condition one and condition four is what this is going to do. And this is due to Bernstein, Hage, Fisher, and Helmson that the lambda decomposition applies. And then myself and Dan upgraded this to the K property, showing specifically that. Property showing specifically that we have this additional condition over here. So, this is kind of one setting where this applies. And why is this kind of seem natural? Well, the singular set, it turns out, is going to be exactly equal to the set of points for which lambda is always zero. What other settings? Well, this is going to. What other settings? Well, this is going to apply to no focal points with the same pressure gap condition. And this is due to Chen, Cao, and Park. So this is weakening the curvature kind of restrictions using a different choice of lambda, but still going to be one which falls into this framework. And again, the singular sign. The singular set is going to be equal to the set of points for which lambda is zero for all time. So you can kind of continue weakening the curvature assumptions. New conjugate points uses some of the kind of Hagger-Thompson machinery, but some other things as well. But you can also, instead of weakening curvature and still working on Ramanian manifolds, you can ask, what about a cat zero? A cat zero space. We can define the due as a flow on cat zero spaces, and we know that there's a unique measure of maximal entropy due to RIT. Rick, there exists unique MME. His techniques follow the work, follow the techniques of Knieper, which is mixing, and Babio. And Babio, and in particular, they don't generalize to non-zero potential. So, what I'll mention is work that my collaborators and I did, not in the general pet zero setting, but in a specific class of examples. So, Mark mentioned yesterday, the translation surface will draw the picture again. So, what this is going to be is you identify opposite sides. And then you have that the metric is flat everywhere except at these kind of cone points, which have angle bigger than 2 pi around them. And so, what this means is you have if you have a geodesic that kind of enters That kind of enters into a cone point, then, well, if we draw this kind of on the universal cover, we have this angle pi, you have this angle pi, and then you have all of these potential exits for the geodesic, all of which still are going to keep this locally length minimizing property. So you say, okay, well, then how can you choose just Say, okay, well, Ben, how can you choose just one? There's infinitely many, and so I say, why do you have to choose? Pick them all. And so, what we're going to do is we define the geodesic flow specifically on the space of geodesics, which is going to be the set of all gamma from your space, sorry, from R to your space, where gamma is a local isometry. This is just going to be a video. This is just going to be a geodesic or the space of geodesics. And in particular, what this means is if you imagine on your surface that this is some geodesic going in to this point, then as long as you don't exit via kind of this region here, via this region, these regions, or this. This region, you can leave through any other exit that you want at any other angle that you want. What you can see if you kind of trace these portions around, these dashed lines are going to correspond to the ones with angle pi. Because you go out through here, and then you come around, and that whole thing will be angle high. But so you can leave here if you want. You can leave here if you want. Leave here if you want, you can leave here if you want. Take your pick. Anything works. So, picking a geodesic means that you're basically going to be picking infinitely many directions at all of the cone points that it's going to hit for the entirety of its life. So how can we kind of hope to apply this lambda decomposition? Well, what this is meant to capture is it's meant to capture the hyperbolicity, right? All of this, what All of this, what it's doing is it's saying, let's imagine that we have non-uniformly hyperbolic things, and the good parts are where it has, you know, behavior that's closer to hyperbolicity. So in this setting, what we can see is everywhere where it's flat, we have no hyperbolic behavior. If you imagine two parallel geodesics that just kind of loop around the cylinder, they're never going to deviate. They'll just trace out a flat cylinder, trace out a flat strip. No good. No good. Instead, all of the negative curvature is concentrated at the cone points. And so, what we need to do is we need to somehow define lambda such that it captures what. Captures what, when geodesics go through the cone points, at what angle they turn at, how far away they are from just continuing on as if they didn't see a cone point at all. Right? If you imagine this is your entering segment of your geodesic, if it leaves going at angle pi, did it really pass through a cone point if it didn't turn? Not really, right? You could imagine that it was just flat here and we wouldn't know any better. So we somehow want lambda to reflect this. And then, right, this is going to hopefully anyway, give us the specification property and the Bowen property, but we also somehow need this pressure gap condition and this expansivity condition. And so the other thing that you want is you want the The set of points for which lambda is zero for all time to be somehow the worst set. Right, so what's the worst set going to be here? Is it going to be a geodesic that takes a long time to hit a cone point, but eventually does and turns? No. The worst set is going to be what happens exactly kind of the picture that I described above. Kind of the picture that I described above or earlier, where you have some point which goes through, just kind of travels along, and it's just a cylinder and never sees a cone point. You should think of it like a flat strip. We want lambda to be zero there. We want lambda to be zero for all time. And if we can get that, then what we can do is we can say, okay, if we impose some pressure gap assumption on the set of points for which lambda is zero. The set of points for which lambda is zero for all time, that's going to imply that where we don't have expansivity, exactly these spot strips will also have this pressure gap condition. And so it turns out that you can define lambda to do this. Let's do that. And the way you do it, basically, all you demand is that lambda is going to increase. Going to increase the greater that the angle that a geodesic turns at the next cone point is, and the closer that the next cone point is to it. What you do is define lambda to be the minimum of two auxiliary functions, lambda s and lambda u. And lambda s should be The S should be should look forward in time to the next cone point it turns at the lambda s of gamma, the next pin point gamma turns at and it goes up. It goes up. If the angle goes up, the angle it turns at increases and it goes up as the cone point gets closer in time. Similarly, lambda u. Is the same, but looking in the past. And so, what we're saying is we're saying, okay, if we have this function lambda, we can kind of naturally define good and bad orbit segments. So then an orbit segment or a good orbit segment. Is going to look like it kind of comes in to some cone point, and then it's going to leave via some cone point, and then will turn with some set amount of angle greater than or equal to eta, greater than or equal to eta. And so we have this natural kind of collection of good orbit segments to look at. Of good orbit segments to look at. Some stuff can happen in the middle. Lots of things, obviously, can pass through many, many cone points. But somehow, these are what the good orbit segments look like. And the bad orbit segments are going to be ones which take a very, very long time to hit another cone point, or ones which never hit a cone point at all. With this kind of definition of lambda, what you can do is you can actually define, or well, you got. Actually, define, or when you get this result, the theorem. This is due to myself, Dave Constantine, Elena Archenko, Noel Sawyer, and Grace Work. What you say is if S is a S is a compact surface genus at least two with that's flat except finitely many cone points of angle greater than Greater than 2π, then if the pressure of the singular set, meaning things which never hit a cone point and turn, is less than full pressure, there exists a unique equilibrium state, mu phi, and mu phi is K. And then work in progress, which hopefully we'll have out by the end of the summer. Out by the end of the summer or by the end of the year, depending on how it goes, is that μ phi is Bernoulli. Following the Ornstein-Weiss argument by establishing local product structure using an argument following this non-uniform Gibbs version of specification or non-uniform Gibbs that you get from the Clement-Hauber-Hansen result. So somehow by choosing Lambda such By choosing lambda such that it measures hypervelicity and such that when it's zero for all time, it captures all of the non-expansive behavior. Then we're able to put it to work and get uniqueness of equilibrium states in the K property for a wide class of potentials, anything where this pressure gap holds. In particular, this is going to hold if P is holder continuous and if it's locally constant on the singular set. Constant on the singular set. So if it's locally constant on the singular set and it's folder, then that's sufficient. And that's great. I should say that P is folder in the assumption. Oh, wide class of potentials, which is folds. So yeah, so that's another nice application that falls into the cat zero setting of these lambda decompositions. I could keep talking for a little bit, but I think I'll just stop here and people don't have questions. And if people don't have questions, then break early. So I think of lambda as measuring the curvature and the angle between the stable and the unstable, how I think of it. Unstable with how I think of it. Um, the formal definition is in terms of Jacobi field, which I don't want to get into now. So it's got something to do with the curvature. Yeah, even though. Yeah, so in the no focal point case, what they do is they kind of, I think, average out over time. Am I describing that, right? Yeah. But yeah, so somehow it's measuring specifically this curvature of the horospheres and the angle is the next consequence, which yeah. Next consequence, which gets you most of what you're looking for. Someone you put this weed specification with the most yeah. So yeah, so for me, I'm assuming that it's that. For me, I'm assuming that it's got exactly 10 path, not that it's at least 10 path. Being able to get it for at least 10 paths depends a little bit more on the stuff in what I've been working on. Week specification, yeah, it's an upper bound. We can still run the argument. So I don't know what the question is. No. Well, there are three different types of specifications, but. Yeah, and many, many more. Yeah, so I yeah, there's many, many types. Yeah, you understand exactly. And they're all called the same thing sometimes. So it's confusing. So the second question, so bone proves that extensivity plus the specification variable or the public specification. So if you wait without So if you with Afile we had an ETP step also continuous flow expensive and show that we can have the periodic orbit tracing property which is almost the same but it allows a time shift that just has orbit pieces which say up to some time shift plus mixing topologically implies the periodical specification so if you do not know how to If you do not know how to use the spacing, but may have this periodic other present colour, there is some reason about the existed most violently made. But it's a massive matter. Because I had some immense problems to show mixing and still needs searching, but I don't know. I don't know. I mean, I wonder, I don't know exactly the conditions of the periodic orbit tracing, but I wonder if you can somehow get weak specification via, I don't know how small the time shift is. So I think that's actually very similar. The argument that you outlined, that that plus topologically mixing, is pretty similar to how we actually got. Is pretty similar to how we actually got specification here because we were able to get least specification. But what that meant is then somehow, because the difference was small enough in the way RD composition worked, we were able to turn that small difference into just a difference in scale to make it work out. But I don't know an answer. Yeah, I don't know an answer if you don't have mixing, if you can get down. Or found that the interesting, yeah. I don't seem possible, but that's me feeling optimistic. Any others? Under the assumptions for the given Haybert-Thompson theorem, the entropy map is axiomicable. They don't assume that the top is semi-continuous. That it's okay semi-continuous, but that's you have examples where it's not every single continuous, then you have to be um, yeah, um, yeah, I mean, then there's a question of the way that we didn't completely explore this, um, but I think the condition of first name one is basically saying that we can be as generous as you can possibly imagine, but only things with motherfucking figures. With my interface, yeah. So, I think opportunity continues to certainly fail there. I think probably our opposite continuous where it matters, but I never prove that. How essential is that should not be? No, in that I will take what you have from your mod is with the call for some classes of just continuous maths. Continuous maths and all the specification property and so on. I think Dulling works with one-sided, that's fine, but I don't... And then was it expanded? Yeah, yeah. Yeah, I think it should be okay, but I've written it down, so I don't want to. But I think it should be. Yeah. I think, how far are you from moving? How far are you from moving journaling property and do you expect any problems with that? We're writing it down. Okay, so that's pretty much done. Modulo writing. But no, I'm not expecting problem. The Ornstein-White argument, the go from K to Bernoulli that this holds works via kind of the fact that this setting is nicely, non-uniformly hyperbolic. A non-uniformly hyperbolic or telemetric version of it. The difficult part of it is getting that the measures have a local product structure, but we figured it out. We're writing it down. Yeah, and I'm not expecting problems. All right. Thank you, Louis.