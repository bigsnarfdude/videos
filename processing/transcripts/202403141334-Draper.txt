And thanks, everyone else, who's here on this nice Sunday, sunny Thursday afternoon. So, today I'm going to talk about some work I did a little while back with Jing Yang, who's at Penn State now, and Rob Mervack, who's at Wisconsin, Madison. And this came actually out of a thesis defense I was in in the systems, CS systems. So, what the student Yvek Srimu Gastava was interested in, he and his advisor Suman Banerjee, were interested in wireless local access. Wireless local access networks that were designed for kind of enterprises where there was some kind of backbone that could see what's going on at all the access points. And they were trying to understand the interference environment, which access points were interfering with each other, which ones, maybe which access points were paired with nodes that were interfered with by other access points. And there had been a bunch of work in the CS literature, the CS systems literature, about how you do probing, kind of active. You do probing, kind of active, looking around for these sorts of things. And they thought that was like a significant amount of overhead. And they were worried that as these networks scaled up, the overhead would start to dominate. So they were looking at passive ways that just kind of monitoring network traffic. They could see collisions, they could see failures, and then kind of see how the interference environment evolves. So when I was hearing this, it seemed to me like, oh, that's interesting. There's like kind of two things that we're familiar with here. One is there's some sparsity in this because there's some graph. Some sparsity in this because there's some graph and things are kind of spread out. There's some sparsity in this graph learning problem they're interested in. And there's also some kind of something that's a bit reminiscent of group testing. And so we were kind of, Rob and Jim and I got involved in this. So it'll be a rather simplified physical layer model, but it will lead us to hopefully some kind of interesting algorithms and results. Wait, I go with the pointer. There we go. Delay. All right, so this is the general model. General model: You have a bunch of access points, or they're just three, the triangles. Each have a bunch of clients, these are kind of showing the radiuses of their transmission, they overlap. And the interest was, you know, you want to have these knowledge of how the transmission is going to interfere with each other so you can do useful things like channel alignment, maybe power control, scheduling, that sort of thing. And this environment will change over time. I'm going to do a static analysis of it, but the general idea was that, you know, if you could do the static analysis, Idea was that if you can do the static analysis quickly, you can monitor how things change over time. And so, this was this Vivek's thesis called Pie in the Sky, so passive interference estimation. And so, again, I already said this earlier work he was building on traffic into the network, active probing type of stuff. And he was looking at: okay, it's a little older now, carrier sense, multiple access, carrier avoidance protocols, and also having some access. And also having some ACNAC information when you can't see the other. And so they'd only look at these small test beds. And like I said, we're curious how things scale to larger networks as the number of nodes gets larger, as the kind of radius of interference gets larger. I'll mention at the end some analogies with you testing problems. Our contributions here is that we're able, for a simplified model, I'll introduce in a second, quantify the observation time, the number of observations you have to collect to understand what the graph is. To understand what the graphs are. And there's two types of interference I'll talk about. And we're able to also have like min-max lower bounds that for a model should be kind of order optical. So there are two types of interference that people were, that we think was interesting in these thesis. One was direct, so this is carrier sense multiple axis, collision avoidance. The idea is, like in this upper left-hand, if you have this green guy, he's in the sort of sensing radius of the red guy and the great. The red guy and the gray guy down there, they'll kind of avoid transmitting at the same time, right? And that's kind of a symmetric because they can hear each other. So, if you want to represent the idea of who can interfere with whom in this carrier sensing, we call that direct. That's an undirected graph. It's a reciprocal of the change. The other possibility, always kind of like down here, we have a bunch of these little clients associated with the access point, and maybe if this guy transmits, And maybe if this guy transmits, he can't hear the blue access point. Maybe there could even be a wall or obstruction between them, so you can't hear it, so a hidden node problem. But so he'll interfere if he transmits, and he might block that guy's reception, so some interference there. In this case, it wouldn't necessarily do it all the time, because maybe if the access point was transmitting to that user down there, that's out of the interference region. So these ones. So these ones you can't or will detect these through having some reporting mechanism of success or failure. Okay, so we were interested in building two graphs. So a graph has the number of nodes, n, that's the axis points, and there are two sets of edges, these kind of reciprocal relationships, the direct graphs, those are undirected, as I said, and these hidden interferes, which are directed ones, which was that second example. There are two kinds of notations I won't be. There are two kinds of notations I won't use too much of, but the thing we're going to kind of track is these activation patterns. Every time every time slots can be a time-slotted setup, every time someone transmits, some of the nodes are on, some are off. So n is the number of access points. Some are transmitting, some aren't each time. And so that will be our kind of activation pattern. We're going to build statistics of those. And then the second thing is this feedback. So success or failure, if you do transmit to someone and it fails or it success. Sorts of things. Our model that we're going to study is idealized at the end. I'll do some experiments with a little more realistic model to show kind of the trends look about what we predict. So again, an access point is a time-slotted system. In each time slot, an access point has some data to send, some probability peak. Okay, so we're going to just say, you know, sometimes it has something to send, sometimes it tells it that something to send. This is going to be in our analysis. This is going to be in our analysis IID across time slots. At the end, when I kind of do some simulations, they'll won't be IID, but for our analysis, it's IID. And for each access points, there's going to be some number n interferes. Those are the guys in the carrier sensing range. And we have a bound on that, D. So D is going to be less than N. So the question is: how does the learning time scale basically D and N? That's what we were interested in. The second half, I'll In the second half, I'll talk about this hidden interference problem. So, again, each access point has some hidden interference. So, if I just go back one slide to kind of recall, like for this access point, because it has this guy here, this is the hidden interfere. And that's going to be the set script S. And then, because, again, as an example before, at access points, you know, receivers, clients are maybe close or far from the interferer, there's going to be some probability that. There's going to be some probability that effectively, if the interfere is transmitting, it's actually going to interfere with what I'm saying. It's going to interfere if my client is close, but it won't interfere if my client is sort of away from the other guy. And again, we're going to look at channel, static channel states. Okay, so let me. So there's two. Sorry, a quick question about the model. So the AP, at every time spot, the XL. Every time spot, the access points has data to send, it's some probability, right? Does it also choose a random receiver in its one receiver at random? One receiver. Yeah, one receiver per time slot. That's right. So it's kind of a time division thing. And I mean, you can, you know, so then some of the applications they had in mind were channel assignments. You can imagine channels might be orthogonal. So if you detect their exposure on this channel, then schedule and you can put them on a different channel next time. So that's kind of how they would use the information, but I'm not going to kind of focus on information. But I'm not going to kind of focus on that. Okay, so the algorithm is kind of simple. So if I have concurrent transmissions in character sensing range from two transmitters, if two things happen, then they don't sense each other. And so therefore, there can't be an edge, right? They can't be direct interference with each other. So our algorithm is kind of a very natural one. We start with a fully connected. Perfectly natural one. You start with a fully connected graph, you gradually remove edges as you see people transmit at the same time, and then you get down to a sparser graph. So, okay, the interesting kind of part, I think, I miss a little bit, is that the activation patterns are coupled. And so I want to kind of show you why that's the case. So here are two different graphs. I have two access points of interest: the blue guy and the red guy. They're not directly. They're not directly interfering because they're far apart. In the left graph, they have a bunch of, these are other access points they interfere with. Here are the access points. This guy interferes with their decoupled language on different continents. All over here, they're shared. So in the left-hand side, the probability of this guy transmitting, if they all have data to transmit, well, because we have this kind of uniform idea of who gets to transmit first, it's a uniform back-off thing. They're one, two, three. Uniform backoff thing. They're one, two, three, four, five, six. So he'll have a probability of one sixth. This guy will also have a probability of one sixth. But over here, the probability is higher because they're coupled, right? So if the red guy transmits, he gets his channel, that will block all these guys from contending for the channel. And so that will allow the blue guy to transmit. So there's some dependence among these activation patterns. So for the red side, so they received the So they received the information from both sides. Oh, no, so sorry, these lines are just trying to indicate these guys can interfere with each other. They're only carrying sensing range of each other. Oh, I see. It's more like a cell phrase one. Okay. Yeah, yeah. So this is sort of like I have two disconnected networks. There's no interaction between them. This one is just to show that who's on and who's off at each time is not an IID process. Even though whether you or I have data transmit is IID, whether or not I hit the channel is not, because there's coupling through. That the channel is not because there's coupling through the network. This is just the simplest sort of example I can think of. But you can imagine if I have, this goes on, there could be coupling through one stage, two stage, and all the way across. The important thing, kind of the basic idea that we show in the paper, is that this is kind of the worst case. The worst case meaning that for any two nodes that you want to figure out if they have an edge, you know, whether they're in cure-sensing range of each other, whether they interfere, it's going to take the longest. It's going to take the longest, the most on average, if they're decoupled, because there's no interaction between them. What will happen here is that if this guy turns on, that is going to prevent some people that might prevent him from transmitting. Even if there's many layers here, this one might prevent the first layer and the second one the third layer. So the probability that they both transmit at the same time only goes up if there's kind of this coupling error. So you'll see that in our, I'm not going to prove it here, but you'll see that. I'm not going to prove it here, but you'll see that whole example for that trigger. So, this is basically that lemma, or that comes out of the lemma. So, here's, we can kind of analyze this in steps here. So, I have the idea here, remember, is I want, I have a fully connected graph, and I want to ask how many times, or with what probability, is an edge eliminated where the two nodes that are on that putative edge are actually not at interfering range of each other. Well, that's kind of this term here. Of this term here. So, first is p squared is they both have something to data to transmit. So, then they may transmit, that's their kind of their duty cycle is the d. And then the d plus one for each of them is they're the one in their kind of neighborhood. The d is, remember, the most number of interferers you have, direct interferes, and d plus one is you plus your neighbors. But they kind of beat everyone else, so they get the channel first. And so then that p squared over d plus one squared is. P squared over d plus 1 squared is the probability that they both transmit, they both have the opportunity to transmit, and then 1 minus is the probability that they don't. So every time you go through, k, this is an independent sort of thing, and it drops exponentially k. This is the lower bound because there's this coupling. This would be the correct if there was no coupling in the first example. And then I have some number of edges. This is just a basic upper bound. There are n minus 2 edges at. Gupper bound, they're n minus two edges at most. They're going to be fewer than that because they're curved. So I have this n minus two follow that sort of thing there. And we can turn this around by putting a probability on it, the probability that in k steps you don't recover the correct graph as this square over here on the right is just manipulating that around. And we see if p over d is small, this is scales roughly as d squared, okay, observed this d squared over p. Observed with this d squared over p. This term gets small and then becomes out of the log. That's our scaling. So it takes roughly k d squared log n observations to recover the graph. It turns out this is also, overall graphs, this is also, this is an upper bound on how many k you need. But it turns out, by lower bounds, no upper bounds, but it turns out if k is lower than that, K is lower than that. There are graphs out there. So we set up direct interference graphs that cause a problem. So I'll give you the example in a second. So how we prove this min-max result. So basically, if k scales slower than d squared log n, then you can have an error in this min-max. So you need that scaling of d squared log n, basically. And the way we prove this is. And the way we prove this is kind of, let me show three steps of the general idea is we pick a simple network within a class of all direct interfering networks, but that's easy to characterize the activation patterns. So that's kind of what I've drawn it down here. So this is the subfamily of all possible interference graphs that we characterize. What we first do is we take all the n-nodes and we split them into D-clusters. Into D clusters, or sorry, not D clusters, N over D clusters. Each has D elements in it. And so it's a clique. So each of these guys is like a set of transmitters are all close to each other. So they all interfere with each other, but they're isolated from everyone else. And then we build a bunch of other networks that are very similar to it. So they're hard to distinguish. They're going to be n of these. They basically are the same network, but they have like one extra edge. But they have like one extra edge that goes between two of those distinct cleats. For these, we can characterize the activation patterns. The activation patterns are very simple for this one because each of these looks independent and then each of them contends equally with each other. So kind of the activation patterns are very easy to characterize here. And you have to do a non-trivial amount of work, actually, but some amount of work to get to figure out what the activation patterns look like for. Activation patterns look like for each of these guys here. So we are able to characterize the probability that you see an activation pattern being a probability that who's on in each time. We're able to characterize that. And what then you can do is you say, actually, the distribution for this guy versus this guy, my KL measure, is the same because of kind of all uniformly different symmetry throughout this whole thing as all the other ones. So the KL measures, KL. So the KL measures the KL distance between the, so this is my P0 here, the activation pattern corresponding to this graph is I'm going to call P0. This would be P1, Pn. Those are all the same. So then we use a result from non-permanent statistics to lower bound. Here's the result. I'll just quote it. So this is how we adapted it here. And there are just two things I wanted to point out. So one is there's a distance measure in this result. So, one is there's a distance measure in this result. So, we use the edit distance, the livestream distance, because our graphs are slightly different from each other. And then, k is the number of observations. So as k gets larger, so basically what the same is if your distance is large enough between each of these distributions, you should graphs rather, then as long as this sum of tail divergences, which are all the same for us because our p0 is the same for each of those graphs in the family, is Is sufficiently small, then basically your probability of errors can be bounded from zero. And so for us, the k happens, of course, as I observe more and more, when I get more and more data, effectively I get IID repetitions of PI, P0. And so eventually you're going to exceed that bound. And for us, in our proof, M is N. This is a four-channel state. That gives us this lower bound that has the matching, says that you have to scale as to square power. Okay, so that's the direct graph, direct interference. And the second part is the indirect interference problem. So this is the one where you don't sense each other. And so if I think about it, so what I want to do is I want to find out, like, okay, I'm at an access point, I get a failure, and then I think about, well, who might be interfering with me? I can't hear them directly, but I, because I Directly, but I, because again, there's some. This is the idea here: that there's a backbone that's kind of monitoring all these access points. They can say they know who's transmitting, and you make a list of every time. So if I have, in the first time slot, access point J's transmission fails, then the kind of supervisor says, oh, well, I know who was transmitting. 1, 2, 7, I1, and 9. So my two true interferes are going to be I1 and I2. The next slot, transmission succeeds. Transmission succeeds, no information. The next slot, I get another failure, then another failure. So I have all these lists. And then you can think about: well, the idea is that if you have a failure here in our model, the failures come from interference. So some interference must be present in each of these lists. So you look in that list to say, who's present? You know, I need people to be present in the lists, and I need at least one person who's an interference to be present in each list. To be present in each list. So I look at the, for the smallest number of elements, the indices here of access points that are in each list, that's called a hidden set. Because it hits each list. There's an element in each list. In this case, one hidden set would be like the 1,3 or the I1, I2. So in this case, you don't know. Could it be 1,3, could be interfering, or I1, I2? So the natural thing is to collect another data sample and see what happens. So in my example here, in the next, in time slot file, And the next, in time slot five, now you see I2 is transmitting again. And now you can say, okay, if I look across this list, the smallest set of elements that intersects with all the lists is I1, I2. That's called the minimal hidden set. Generally, finding the minimum hidden set is a pretty hard problem to NP hard, but we know that for us, it's a little simpler because we know we have a bound, we say there are O slight S hidden interference. So that makes it a little easier than looking at all A is a scale. Okay, so this just to recap here is our algorithm. So I give you a collection of subsets. This is just my definition. A set that intersects all those subsets in one element is called the hidden set. The smallest set, that's called the minimal hidden set. So our algorithm says, okay, I get k observations, and then I first figure out which transmissions failed. Those are the ones that those are the only ones that can give me information. Those are the only ones that can give me information. Then I say for each of those times there's a failure, I say who is transmitting in that time, those are the potential interferers. And then I calculate the minimum pain set. And so then, so I look for the argument, which may not be unique at source, but as I go on longer, eventually hopefully it will settle down to a unique one. So what's the minimal set? S, or the cardinality, so the set is S. The cardinality of S is what you're trying to minimize, such that it's intersected. What you're trying to minimize, such that its intersection with each of those kinds of set of candidate interferes is non-empty for each of those times, you have a failure. So then we analyze how long does it take to get to this minimum set. And so here's, it looks pretty, looks kind of like the other, the earlier result with a couple added terms that I can explain. So the difference is, I guess let me just walk through all the letters here. First, I might All the letters here. First, I might have a minimal paving set that's not the correct one. So when I go through this argmin early on, maybe all the, there's going to be more than one. There's not a unique argmin. So there's many possibilities. And so I pick one. And maybe it's not the case. So there is actually an interferer that doesn't show up in there. Maybe that interfere hasn't even transmitted yet. So the probability that it doesn't show up. Probability that it doesn't show up in that heating set is going to be bounded. And so, what do we have? We have this term, which is familiar from the first part. That's that basically the two transmitters, I and J, are both transmitting, or a lower bound on them, they're both transmitting. And then I have Pi to J, that's the probability that I actually have the interference. It could be that J, that's the guy who had the failure. It could be that, well, I is transmitting, but at this point, this is time. Transmitting, but at this point, this time slot, the person that acts on the script transmitting to is on the far side of the cell. So you don't have that, you don't collect any data. And then what this term comes from is, well, we say, if I have a candidate teaching set that's causing a problem, that I think is not the correct one, just like before, at some point, with some probability, none of those transmitters are going to be on. They have nothing to send. To send. So, in fact, our converse constructs something, a graph that looks just like that. So, they have nothing to send. And so, at some point, with this probability, they're not going to be in play. And so, then I actually get useful information at the bottom of the play. So, this way I can have this probability, and I can work out the same as before, then applying a union bound across all access points and all interferes for each access point interferes. That's why I get the head. That's why I get the NS, which is the upper bound. So then we get a similar sort of bound before as before, so high probability bound. So you're going to recover correctly with high probability as long as k scales this way. So you see again that t squared log n, but there's some more kind of stuff underneath it, which causes problems. We also derived a min-max lower bound for this, which is sort of For this, which is sort of similar, you have if I go back, just to do, I didn't actually draw a picture for this one. But it looks a little bit like this, except each of these cliques has a bunch of hidden interferes who are all by themselves. So they don't interact with all the other guys, and so they all will cause cause that one minus p to the s term. Yeah. Yeah, just want to confirm, we are talking about hidden inter in the interference. You mean the like the potential interference? The potential interference. And there is an interference with some possibility between the transmitter. So they're like out of your carrier sensing range, or they're behind a building. That's why they're hidden. So I don't know that they're interferes until I see a failure of transmission. That's why the terminology comes from me. It's like the exposed terminal and the hidden terminal problem. It's that terminology. All right, and then, so just to, okay, so before, and to this point, all our analysis has been IID and very idealized. So we also kind of did a simulation where I actually had a wireless network, like an 802.11 network, with pass-loft, shadowing, packets arrived in some puss-on fashion, not IID, so they were in queued. So you had some temporal correlation across time. Across time. And this is just to kind of show that the scalings of the algorithms we derived kind of look similar when you do it in practice, well, not exactly in practice in simulation. So on the left here, this is the number of access points. And here there's six direct interferes. This is for the direct interference problem. And these are the different, this is the different arrival rates. And this is heavier traffic and lower traffic. And so the two kind of things to observe are, you know, it looks kind of sublinear, kind of log. You know, it looks kind of sublinear, kind of log n-ish. This is n. And then as lambda plays the role of p, remember it was d over p. So as p gets bigger, things drop. So similarly, as lambda gets bigger, it takes less time. Conversely, on the right-hand side, if I have a fixed network and go to higher degrees, it takes longer. So how much time does it take for you to figure out the network? It takes longer. That's like a squared scaling. And similar for the second part on the hidden transmitters, you have that kind of log n scaling. And then here, this is just, in this example, there's a single hidden interfere. And here's a few more interference. So, with that, let me kind of conclude, and I can take questions. So, we formulated this, you know, kind of this problem I thought was interesting from the CS systems literature, past contributions. Yes, systems literature, passive interference estimation, statistical learning, and these two kinds of contexts. And I thought, so I would say I think this is kind of an interesting type of group testing problem. In a sense, you can think about the hidden interferes as, you know, they're my defects. So for each one, there's a bunch of people who are causing me problems. And actually, each transmitter has a bunch of, has its own group. So we're kind of in parallel doing a bunch of these problems. A difference from standard group testing is we don't continue. From standard group testing, we don't control the test vectors, right? Those are the activation patterns that happen without any control over us. That was what it took our time to kind of figure out. On the downside, I do want to point out, like, the scaling is going to be, you know, scaling is kind of d squared log n, but it's important to have these p's in there, because this one minus p of the s becomes, if you were in a heavy traffic regime, right, this is, this, this kind of can grow a lot. Anyway, okay, so let me quickly pause there. 