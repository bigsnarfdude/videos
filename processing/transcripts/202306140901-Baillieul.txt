This morning session is a session in honour of Roger Rocket, who sadly passed away a couple of months ago. So we have some colleagues and students of Roger who will be talking during the morning. So it consists of three half-hour talks, two talks, a break, and then another talk, and then there will be a half-hour session where we open things up to the floor so for people to say something if they'd like to. So we'd like to begin with John Burdiel from Boston University, who's going to talk about systems of Going to talk about systems control for the logistics. All right. Okay, so I think it's fair to say I'm one of Roger's oldest students, and it's an honor to be here with some of Roger's youngest students. And thanks for the invitation. So I'll put this up. I'll let people read it. I won't read all of the words, but just talk. This talk is going to have just a little bit of math that I was. That I was motivated in many ways by conversations I had with Roger over the years. Roger and I became friends, I guess really, when I was a student. We never did anything jointly. We didn't publish anything jointly when I was a student, but then later on, we had some papers early on on various things, including. Various things, including stability and dynamics of feedback amplifiers, or pulse with modulated amplifiers, actually. And then we just interacted as friends. Turns out that for many years, recently, I lived four miles from where Roger lived, and we were always And we were always together and talking. Roger would call. Regularly, I would call him. And we would go to dinner at each other's houses all the time. So it was very intimate, long-term relationship. He was really a dear friend. And much of what I did throughout my career is things that we talk about on the phone. And he was always, of course, supportive and encouraging. Of course, supportive and encouraging, really wonderful. So the field has changed so much in the recent times, and this is, I'm not trying to promote the encyclopedia, but I think it's interesting that when we did the second edition eight years after the first, there were just all these new topics that had to go in because they were showing up everywhere. Up everywhere. So let me just play a little bit of Roger in his own words. I do remember being there with Krishna, John Farris, David Gawkin. It was a pretty rich experience. So we're coming somewhat toward the end of the hour, and there are other things we need to talk about. I want to talk about more things. All right. All right. All right, so I didn't feed you another question, but I think maybe you can improvise. Well, what I want to address is the fact that around, well, in the early 80s, I decided that I had done what I thought was interesting enough to do in the area of differential geometry. Geometry, and I decided to start a robotics lab. Now, this was an abrupt change, and the opportunity for failure was certainly there if you looked at it from the outside. I didn't entertain that possibility myself. But you could say, why would you do something where other people already have a head start on you? The people of Clanaging Melana and so forth. People of Carnegie Mellon and so forth were well ahead. Why did you do this? And I think there are three reasons. One of them, three important reasons. One of them is that I thought that non-linear control had entered a sort of a baroque stage, and I didn't want to do that anymore. Another one was that I had our two oldest children who were approaching. We were approaching college, and they had been on the leading edge of the personal computer world and had filled our house with such things for some time. And I saw how exciting they found it. And I didn't think they shared that same excitement for a different phrageology. So I said, well, gee, if I'm going to interact with Going to interact with the now generation, maybe it would be better to do something that's more now-like. So, I'm going to go on here. We'll come back to the interview later in the talk. But that was Roger in his own words. Now, one of the things that I find is showing up in at least 50% of the talks that I've gone to in the last six months is ChatPPT. Chat GPT. And I suspect, so Fred and Art, you had this workshop last month, I know, in Monterey. How many of the talks had something quoting something from GPT? Not many, actually. Really? John Barris's talk. What? John Barris's talk? Very few. Well, anyway, so I fed it actually the transcript of the interview and I asked it this question and I asked it this question, and there you go. This is, I think, a pretty good summary, actually. And in conclusion, Brockett encourages others to have confidence in changing fields and not to get stuck in a rut, emphasizing that new opportunities and discoveries are abundant. So, if we have time to play that, we'll hear him say that. So, just a few things that, you know, Roger did try to move around. Try to move around and think about new things. And it was maybe seven or eight years ago there was a workshop that I guess Jershan was involved in. Jershan's not here, but at Washington University, and it was on brain science. And so Roger was invited, I was invited, we gave plenary talks. Plenary talks. Well, I guess every talk was a plenary talk in those days. I mean, at that workshop, like here. And so Roger talked, and here's the pointer to his talk, Shallow Learning for Acquiring Basic Motor Skills. So, you know, this is something that's come up, that came up, I think, when Fred was talking yesterday: that, you know, brain science and neuroscience are one of the things. Science are one of the things that people are interested in and interested in, you know, what can control and systems people say about neuroscience? Are there things to say? And, you know, in many ways, the brain is a very simple thing. In other ways, it's phenomenally complex. And it's probably the complexity is sort of their Sort of there are parallels between things that show up in these large language models that people are interested in and neuroscience. This is just gives an example. Here's a book from Eric Kandel's monumental tome on neuroscience that just gives some diagrams of different types of neurons. Some of the neurons that are involved in motor control are the Are these Purking neurons that have these heads of just incredible numbers of dendrites? So there's just these lots and lots of interconnections of different neurons in different regions of the brain. And so one of the things that I've been thinking about since we've been started to talk to a lot of neuroscience is, you know, are there features that we can Are there features that we can mimic in control systems that are characteristic of the way neurons in the natural world interact. And, you know, you might say, well, what the hell do you think you're doing if you think that the brain is x dot equals ax plus b u and And you know, I'll come back to this again. But here's an idea that might be interesting: is that the way that the neurons work is there are just incredible numbers of them. Here are some order of magnitude things that the number of, there are three types of neurons that are listed here, you know, and 10 to the 9th, 10 to the 9th. 10 to the 9th, 10 to the 11th, maybe 10 to the 15th neuron in children, in human children. You know, children, part of developmental neurobiology is that things are pruned as children get older, and that's the way that the brain wires itself. So, what we were thinking is: well, suppose I take x dot equals ax plus bu, at y equals cx, and instead of doing the usual thing, And instead of doing the usual thing to assume that you have fewer controls than states, suppose you've got a certain number of states that reflect the action you want to study. And the number of inputs, on the other hand, and the number of outputs is huge. And let's also assume, just keep in mind, I'll come back to this, that these are very simple in form. So think about spiking neurons. They're either spiking. Spiking neurons, they're either spiking or they're quiescent. They either act as inhibitory inputs or excitatory inputs. And suppose I just look at linear systems this way, and what are things that you can say about what's possible with that? So, yeah, so here's the setup. This is This is a picture, a hand drawing of a neuron that came from a book that you can buy. It's a picture book, it's beautiful, called The Beautiful Brain by Santiago Cajal, who is the only person that I'm aware of who has ever won a Nobel Prize for artwork. And he was in the early, very, very early part of the 20th century that he was doing his work. That he was doing his work and he got brain specimens and he chopped them up and drew pictures of neurons. So, anyway, this is the setup. The B matrix has got many more columns than rows, and the C matrix has many more rows than columns. So, this is the thing. And one of the things we're going to study is resilience, the brain and neurobiology. Brain and neurobiology are certainly resilient. We know that people recover from strokes, so that if there is damage to a certain part of the neurobiology, things can be relearned, or in the best case, things still continue to work. So resilience is one thing we want to study. So here I'm going to say, let's simple consider simple projection matrices with ones and zeros on the With ones and zeros on the main diagonal. And if there are zeros, that corresponds to you've lost a channel of input, you've lost a channel of output, something like that. So here's the controllability Gramian with channel dropouts. And if this is positive definite, of course, it's just a standard thing. It's a controllable system in the sense of linear. In the sense of linear control. And this is just an example of a simple matrix. So here, when I say the number of columns is significantly greater than the number of rows, in this case, it's just greater by one. So it's not even significantly greater. But the thing is that with channel dropouts, you can get by with this particular A and B pair, it remains controllable. With its, it remains controllable if any of the channels drop out, except in the bottom-center case there. So lots of inputs. Here's a theorem that may be interesting, is that if you add inputs and you want to solve the least squares optimization problem, then this is just a standard point-to-point. This is just a standard point-to-point optimization over a path, and the cost goes down if you add a channel to it. And what does it look like? Well, going back to this example that we started with, I've got three different B matrices, so sort of minimally controlled in the first two cases, and then in the third case, we've got this extra degree of. Extra degree of input. And what you see is that the trajectories, the optimal trajectories, if you consider the problem of steering from the origin to a point on the unit circle, they look like the top three rows there in three different cases. And this is what happens to the cost. So when I add a row and I go from just one input to two, the cost drops precipitately. The cost drops precipitously and it continues to drop, consistent with the previous theorem, but it stops dropping so fast. And this is one of the things that's very interesting about neurobiology, is that how many neurons does it take for different brain functions? Certainly, you know, more is better up to a point, but Point, but neurons use a lot of energy. The brain is a relatively small organ, and yet it uses 20% of the total energy that we use throughout the day. And so there's clearly a tipping point where you really don't want to have more neurons. So this is something that's very much optimized by just biology, and it's one of the interesting things to think about. One of the interesting things to think about. So the other thing we can think about is, you know, what can you achieve in terms of resilience with these extra degrees of freedom? So this is just a little math that I'm not going to dwell on, but the way that we study this is we lift the input systems from just having the B matrix. Having the B matrix operate on the input vectors to generate outputs and steer the system. We lift that up to a matrix world and these liftings, which I will not spend a lot of time talking about, are important if you want to prove some theorems. And the You know, what we're interested in is the lifted matrix A, that's one of the things we lift, plus a design feedback gain will steer the system faithfully to a goal point. And depending on certain invariants, this Variance, this will happen despite channel dropouts. So you've got the system and under certain conditions, and I don't want to dwell on them, but invariance under the projections that involve the dropped out channels, that the thing will work whether the channel is there or not. Of course, it changes. It may take a different path, like in the optimal control problems. Like in the optimal control problems, but it still works. And here's a, this is in honor of the observer. You can create an observer theory, a resilient observer theory, whereby you have observers and inputs that are resilient under these. That are resilient under these projection operators, the channel dropouts. And what's remarkable is that you can develop sort of universal feedback laws that operate despite any number of different channel dropouts up to a point. So, this is the kind of thing that is reflected. And I want to also talk about. To also talk about how this works in the case of quantized inputs. That's really where we wanted to go from the beginning. So what I want to do is instead of thinking about continuous outputs, is I want to think about quantized inputs and outputs. And to be roughly corresponding to these neurobiology things, the Neurobiology things, the inputs can be either minus one, you know, maybe inhibitory input, zero for not being activated, or one for excitatory. And then what are some problems that you might do? Well, one of the things that you try to think about doing in terms of what we learn in terms of the neurobiology of movement is we learn to not only just move about, but maybe energy. But maybe emulate good performance by an athlete or something. And so here's a very stylized version of that problem where you've got these quantized inputs. And what you'd like to do is to emulate the paths of a system, say, that's a Hurwitz matrix, so it's a stable linear control system. And what things look like is the following. So you've got Is the following. So you've got here's a couple of these B-type matrices. Again, not huge numbers of inputs, but for the sake of illustration, it's probably best to keep it small. And in the case of the B matrix on the left, there are quantized linear dependencies. And so although you have three of the M, which would be 81 for these four. 81 for these four column things, 81 activation patterns, you only get effectively the B matrices produce these different vector directions. If you choose something where you don't have these linear dependencies, you have this much richer spray of vector directions. And so these are like alphabets that you can use. And you use the alphabets to the best of your ability to approximate. To approximate with these quantized inputs what the linear system, the continuous linear system, looks like. And this is what you get if you take a standard here's x dot equals, this is like a feedback design of a double integrator that is stable. It has its poles or eigenvalues at minus one, both of them. And the face portrait looks like on the right. Phase portrait looks like on the right. And it turns out that if you solve sort of the optimal quantized approximation, that you only use certain numbers of the inputs that you have. And so it's just the red vectors that show up. And what we've been playing a lot with is sort of learning how do you learn for any given system. And so we have all of these learning algorithms. Some of them are very simple. Some of them are very simple, like this Oya Heb rule here, and we've looked at lots of other things. And what you do is you do the usual training of these things, and you learn what the vector directions are that you want. And this is, again, just a very simple. You're trying to learn the phase portraits from points that originate. Points that originate on the unit circle, and it turns out you just use some of the things in the alphabet, and the portrait looks like what you see on the far right. And this is one of the reasons we think that these learning things are good is that they show you not only what's optimal, but what's close to optimal, and then you can start looking at the results. And then you can start looking at the resilience and what happens to learning if you lose channels. Do you still learn the same thing? Is learning robust and resilient? And so, those are the kinds of questions that we can look at here. Okay, so I'm not going to go into details, but I want to bring Roger back. Second thing is that so far as computer vision is concerned, one of the problems is that it's Concerned. One of the problems is that if two pictures are taken of the same thing, but their cameras all of it one way or another, you might want to put those in alignment. And one thing that you could ask is, if I make a distance-preserving transformation, that is an orthogonal transformation to try to line up the pictures, what is that transformation? What is that transformation that would do it with ending up with the least error between after you register? There's got to be some error because life is like that, but how can you minimize that through a orthogonal transformation? And that simple question led me to think and think and think, and that turned out again, luckily. Again, luckily, no forethought on my part, but luckily, that equation turned out to be related to integral systems, related to algorithms for finding eigenvalues of matrices, etc., etc., etc. And it lives today, well, among other ways, in a textbook written by Uva Helmke and John Moore, and other places as well. Well, so message change fields with confidence and don't get in a row. New stuff is everywhere. So this is something that certainly I picked up on a lot and got very interested in computer vision as a navigation tool, so sensing and so. So, sensing. And so, we got interested in optical flow in particular because we know that optical flow is one of the essential sensoring modalities for especially animals that don't have a good centered field of view, but they have their eyes pointed out like kitchens to the right and left. But even for humans and owls, it's important. And so. And so, this is just a video of outside my office. We had a quad rotor with a GoPro camera on it. And so, the way that this is related to exactly what Roger was talking about, registration, is that this is creating a rendering of the optical flow by matching sequential frames in the video stream. And so you've got a frame. Frame at time k, time k plus 1, and the time interval, of course, is very short. What you try to do is match features, and then you draw a vector, and that gives you the optical flow, and the size of the vector at that particular point tells you something about the velocity of your motion. So, this is something again that I'm not going to go into great detail because time is short. Time is short, but we've come up with this concept of what I call Eulerian optical flow. So, if you know fluid mechanics, you know there are Lagrangian models and Eulerian models. And what we try to do is to translate that from fluid mechanics into optical flow situation. And one of the things we've done is create these stylized models where we have. With where we have just a few pixels on each side of the optical axis, but we get good information there about things like time to contact, which may be on another slide, I guess it's not, but we have this idea of time to transit, which we're balancing the times until the features pass. The features pass from the field of view. And by doing this, you can get actually stable motions. It's very exciting to try to see how to adapt this to different visual environments. So we're talking about Python last night over a glass of wine. So Python plays a huge role in ROS, the robot operating system. ROS, the robot operating system for people who are into robotics. And this is just, we built with just moving boxes, we built these corridor structures and we're doing this navigation. That's our little jackal robot there that's going down the corridor in the lower right-hand panel. And so it works. Certainly, a lot of fine-tuning remains to be done and sort of understanding how you deal with. You know, how you deal with multiple agents that are moving about and interacting, but lots to think about. Okay, so Matt did a great job yesterday putting up in real time references to the things he was talking about. So I didn't do such a good job, but here's some things that people are interested. I'll share the slide. And I just want to go back to my earlier comment about. Comment about why would anybody in their right mind want to model a brain by linear systems. So, just this is a shout-out to Danny Bassett. I don't know how many people know Danny Bassett. So, she's kind of an interesting phenomenon, too. And she does a lot of this, but she's got a much better connection because she's got these amazing brain images that she makes the correspondence with. That she makes the correspondence with. So there are other people who are pursuing this crazy line of work. So, with that, this is a picture just a couple days before Roger fell, sort of a happy time. Roger was, I would say Roger was always throughout his life a happy person. And this is a historical society of Lexington functions. Society of Lexington function that his wife of 62 years, Carol Ann, managed. And this is him dressed up as a carnival person. And this is Roger. So thanks very much. Thanks very much, John. So any questions for John? I had one eval. You had a slide and you were trying to go from point A to point B and you had this project version of controllability and you had a result that said you could decrease the cost by adding inputs. And I was just wondering if it might fall out from your techniques, what's the optimal input that you could add to decrease the cost the most? Well, I think this is not a mathematically precise answer to your question. Mathematically precise answer to your question, but it's. I think the basic result, which was illustrated in the figure, is that you get the biggest bang for the buck with the first column you add. If you add subsequent columns, you get better, but less better. And in the limit, you pretty much don't get anything. So there's definitely an end point that you want to cut it off. So, what methods are you going to do? So yeah, what matters as well there is a normalization of B, right? Because if all the columns we add of B have the same magnitude, just right, we could just even add the same column, split Q by 2, and because we have to do it. Right, so if you have to have some sort of normal in order for it to make sense. I mean, it's still true, but it's not clear that it. Right, to have a fair comparison. Yeah, you want to have a fair comparison. Fair comparison. Yeah, you want to have a fair comparison. Large number of controls also occurs like a version of control, you know, sometimes physiology to just control the hand of larger sequences. Oh, yeah. Yeah, that's complicated enough. Yeah. Okay. All right, thanks very much. Okay. So next up is So next up is another distinguished student, brother, Krishna. So are you there, Krishna? You're still muted, Krishna. See you speak. People see me as a speaker. When you see something over there, we don't see the slide. So can I sh uh show try the uh uh the slide? Can you see the slides? Not yet. Can you see the slides? Not here.