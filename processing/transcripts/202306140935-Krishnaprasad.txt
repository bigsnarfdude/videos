To Roger's early work. And the theme is on collective behavior. And this was work done some years ago, but still has linkages to more recent contributions that my other students and I are making. But this work was done with a former student of many years ago, Eric Just. So I just want to show you some things. Want to show you some things that are of important memory for us. About 50 years ago, there was a meeting in London, which involved a diverse group of engineers and mathematicians talking about the geometrical methods that are foundational in system theory. I know that Arthur and Hector Sussman were at that meeting. Where at that meeting and had papers in the proceedings volumes issued by the NATO Advanced Study Institute. And around the same time, Roger also had a paper in Sciam Journal on Applied Math about lead theory and control systems defined on spheres. And so this paper is one of the earliest papers that Roger. Of the earliest papers that Roger wrote on GMET lead theory related to control, and there was also a companion expository article in the NATO Advanced Study Institute proceedings, which is much more detail. Both these papers were chock full of ideas, dealt with deterministic equations as well as stochastic differential equations. And in the SIAM journal. And in the SIAM journal paper, Roger made a special effort to connect the work he was presenting to the recent past in optimal control in linear quadratic settings. And so to some extent, my talk is about one of the set of equations that he presented there and how it connects to the story on collective behavior that I'm going to talk about. So, here's the So, here's the story. You're seeing on the screen a collective of starlings moving about. They are undergoing rapid turns, but in a very coherent way. This is from data supplied by a collaborator, Andrea Cavania, from Rome. Now, these types of coordinated behaviors are very important and seen widely in biology and behavioral biology. In biology, in behavioral biology, and an influential paper from the 80s along these lines gave a particular name to it, namely alleloomimetic behavior. So alleloomimesis is the terminology. Here's a Wikipedia definition, if you like, which says that if you have a collective in which the performance of a behavior increases the probability of that behavior being performed. That behavior being performed by other animals nearby, then you would say some kind of copying is going on, and this is allelomimesis. And there is examples of this, initiation of movement from stationary state, initiation of vigilance when you're looking out for predators. You all know pictures of meerkats standing up and looking around and then. Around and then initiation of flocking and sustaining of flocking. And the function of these behaviors has to do with migration, roost-seeking, predator avoidance, and so forth. And this copying behavior, certain self-sustaining quality to it, at the same time, put in different environments, the copying behavior can produce overall behaviors that can look dramatically different. And so we asked the question: are there any A question: Are there any optimality principles with which we can discuss this type of copying behavior emerging? And can we formulate some basic models that are accessible to some analysis? And are there any symmetries that are natural to consider? And how would we solve these problems if they are optimal control problems? If they are optimal control problems, how can we simplify them? Are the techniques of simplification in the style of reduction theory? So these are some of the questions we asked. And so this led us to think about modeling agents or individuals in a collective in terms of matrix differential equations. And so these GKs represent matrices, but they are invertible matrices and they stand And they stand for elements of a Lie group. And the concrete example to keep in mind is the rigid motion group in the plane or the rigid motion group in three dimensions when you're thinking about flight behavior. If you're thinking about curves in the plane or curves in three dimensions, these group curves, GK, also correspond to thinking about moving frames. Thinking about moving frames attached to the curves. So, and in that setting, the XK matrices live in the Lie algebra of the Lie group, and you should think about them as what people would call Cartan matrices for the moving frame, for instance. And so, in this context, the originators, Li and also the founder of much of modern Founder of much of modern symmetry theory, Nerder figured prominently in the field and also in this work that I'm going to talk about. So if you have not just one agent, but many agents. So the K is an index that keeps track of an agent, and there are N of them, then you want to know how they are interacting. To produce an interaction, we need to think about some To think about some interaction structure, and we think of that in the present setting in a very simple way: a fixed graph, a static graph of interactions between the members of a collective. This is aimed at trying to see what basic results one can get out of even these very restrictive assumptions. And this graph, we assume, has no self-loops. It's undirected, and it has an incidence matrix. And it has an incidence matrix or adjacency matrix given by the matrix A. And associated to it, we have the graph Laplacian B. And if the graph is connected, then B has a one-dimensional kernel and given by the column vector one, one, one, et cetera. So in this setting, one can formulate optimal control problems. Optimal control problem. So the idea here is that the agents are doing their own thing. However, the so-called Carton matrices CK have inside them controls. And these controls are the things that ensure the agents are driven in some way. And these controls are not determined just by the individuals alone, but by means of an underlying optimization principle. Optimization principle where we think about the controls as being determined by a cost functional where there is cost coupling. And so the idea here is that you solve an optimization problem over a period of time. Think of it as a fixed endpoint optimal control problem. And the cost functional is given by a certain Lagrangian L, which has And L, which has got what are known as self-motion costs, which is given by the first summation term on the right-hand side for the Lagrangian. And then mismatch costs associated with how a motion or a control associated with agent K differs from that of agent J, that is a neighbor to that. KJ pair, okay, K, the K agent K. So it's all weighted by the adjacency matrix A Kj with zeros and ones. And the importance of this mismatch term is measured in terms of a coupling constant, chi. And with this idea of an optimal control problem, which involves individual agent motion costs as well as Well, as costs associated with mismatches, one can write up the cost functional also in terms of the graph Laplacian B that I had written down earlier. So that's the first bit. And then the second bit is, what are the ways in which the control enters into the matrices CK? Well, it could enter in various complicated ways, but we choose. Various complicated ways, but we choose to write it in the form of equation two here. And the controls enter in an affine way, and that there is also a drift term xq. Here, the x1 through xn form a basis for the Lie algebra in question, and xq is a drift term element, and you are under actuation in this setting, and we certainly have to assume some sort of controllability condition. Controllability condition. So the machine, of course, we will depend on is the maximum principal of Pontryagin and Company. And the second machine we will depend on is the fact that the Lagrangian I wrote down has nowhere in it any of the group variables. So, what this means is then that, well, the system of n agents evolves on the Cartesian product of N copies. Of n copies of the same group G, the cost functional itself has no involvement of the group G. So that it means that the cost functional is invariant under the Cartesian product. So the optimal control problem itself has this invariance, big invariance group. So one can hope to do reduction. And there is a machine for doing the reduction as well. For doing the reduction as well. And this machine here is what is known as Lee Poisson reduction. And so we employ these two machines in order to write down relatively manageable equations in order to attack the question about what these controls that emerge from such optimization look like. Okay, so there's a long story, and the story in And the story involves the steps we have to take to define a pre-Hamiltonian in the usual way for an optimal control problem. And then the reduction process involves porting or transporting the cost state or momentum variable p to the identity, which it is possible to do because of the way in which the Legendre transform works. And then you express the pre-Hamiltonian itself in terms of certain variables mu, which we call momenta, but in this case, these are so-called reduced momenta, and they live in the dual of the Lie algebra. And there are for each agent, there is a momentum mu k, and so there is a. K and so there is a big long vector of momenta, k is equal to one through n. And the momenta relates to the control variables by means of equation 10. And now it is rewritten in a nicer way in equation 12. All the momenta are expressed as a big long vector with the matrix in front. With the matrix in front of the control vector. And this matrix is interesting because it involves a big identity matrix plus an extra term, which depends on the coupling constant multiplied by the Laplacian, the Graph Laplacian. Because of the positive semi-definite character of the Graph Laplacian, the whole thing is invertible. And so the inversion allows you to express the controls in terms of the In terms of the momentum vector. So the question is: what are the controls going to be when we apply the maximum condition of maximum principle? And so that leads you to the Hamiltonian as opposed to the pre-Hamiltonian. So I want you to look at the red box here, equation 16. So this is the thing you end up with when you have a Application of the maximum principle together with Liepoissan deduction. So we call this a many-body collective Hamiltonian for the multi-agent system. And we've gotten rid of group variables completely in writing things this way. And now the next question is, what are the Hamilton's equations in this setting? So the Hamilton's equations are going to look not like the usual QP Hamiltonian equation in classical. Hamiltonian equation in classical mechanics of particles, but instead they are going to look more like the rigid body dynamics equation where the body angular momenta are governed by Euler's equation. So the Hamilton's equation are going to be in this setting a big old bunch of vector differential equations. And they involve something called the Le Poisson tensor, which is the direct sum of. Which is the direct sum of the Le Poisson tensors associated with each of the factor agents. And then they involve the gradient of the Hamiltonian that I wrote down in the previous slide. But there, because of the coupling terms, you have introduced very coupled dynamics into the setting. So when you look at a problem like this, you sort of throw your hands up and ask, how can I even remotely solve? Ask how can I even remotely solve any of this? What special cases I might think about? A long time ago, Roger was invited to write a review for the IEEE transactions on automatic control and of the book of Jerry Marston, in particular, the second edition from 1978, Abraham and Marston on foundations of mechanics. And I quote here from that article. He suggested that And he suggested that this, a program for us, would be to have an explicit solvability program, and that is to explore integrable systems, something that John talked about and Roger talked about in his video. And whereas in Whedaker's book on classical mechanics, integrable systems were certainly considered a corresponding story in optimal control setting. At that time, Setting at that time certainly had not gotten to a level of detail that one expected from mechanics. And it's still an ongoing program to which people in your audience, very much Tony Block and collaborators, have contributed hugely. So practical cases emerge when we specialize to groups like the rigid motion group in the plane or rigid motion group in. Plane or rigid motion group in three-dimensional. So, this is what we dealt with, Eric and I. And so, in the rigid motion group in the plane setting, if you had only one agent, equation 18 gives us what the Hamiltonian looks like. It's a quadratic in momentum Hamiltonian with the linear, with an extra linear term. If you had many agents, then the Hamiltonian looks more elaborate with. Looks more elaborate with this psi matrix, which involves the graphyloplastine in it. And the machinery we all know and love is to look for invariants. Hamiltonians themselves are conserved quantities. Are there other invariants? Well, there are these so-called Casimir functions that are associated with the Poisson tensor in the present setting of the rigid motion group in the plane. The Casimir functions take the form as the bottom of the slide, namely they are Bottom of the slide, namely, they are quadratic Casimirs. Casimir, of course, is this very famous Dutch physicist who contributed to quantum mechanics in a profound way and also was deeply influential in industrial research at Phillips Laboratories and elsewhere. So this story involving Casimirs and conserved quantities is not enough. We also have to consider what happens in various limiting cases. In various limiting cases. What limiting cases one might have? What is the parameter to take limits with? So the parameter chi, the coupling constant, is one. If you send the parameter chi to zero, then you have a decoupled system. And every one of these uncoupled systems is in fact an integrable system. And in fact, it can be solved by using Jacobi elliptic functions. On the other hand, On the other hand, when you send chi going to some other limit, for instance, strong coupling limit would be chi sending to infinity, does it make sense to even talk about it? Do we have a system of equations that makes sense to consider and what are their solutions? So I will say that the ultimate system of equations still looks like this, even when we go to chi going to infinity. And why is this? Well, Well, this is because what we are able to show is that in the chi going to infinity case, the so-called strong coupling limit, you end up actually having to solve a single particle problem and you have synchronization. And that's the thing that turned out to be sort of wonderful to see happen. If we made some hypothesis about the problem, and that is that the graph is connected. If the graph is connected, the graph. Graph is connected, the graph Laplacian is positive semi-definite for sure, but also it has only one zero eigenvalue. And so, for as a result, this psi infinity for chi going to infinity limit. So, for any finite chi, psi is certainly invertible, but we don't know if it is going to remain invertible as chi goes to infinity. And that is the case for a connected graph. And with this, we are able to make a calculation that allows. Able to make a calculation that allows us to show that the problem collapses into what is essentially a single particle problem and involving a collective momentum. And the collective momentum satisfies the same equation, which is at the bottom, alpha, one, double dot, et cetera, and identical to the equation that we had in the single particle case. And this is all made possible with the presence of additional symmetry. Symmetry. So it's kind of lovely. And so we asked the following question: Okay, if this is all going to work for a single particle, for a rigid motion group in the plane, what could we do for more general groups? And here's where we make contact with Rogers' 1973 paper and the interesting and clever way in which he approached the optimal conclusion. The optimal control problem that he formulated there, which has very strong connection with what we do, except that he was in some sense dealing with a single agent optimal control problem, which meant that he had no coupling constant or coupling terms or mismatch terms involved. And then the problem was a problem on a Lie group, but he just treated it as if it was a problem in a surrounding space of matrices. Surrounding space of matrices. So he embedded the problem in a or enlarged the problem. So he took an extrinsic view. And this extrinsic view or enlargement point of view has been there in the literature since then in mechanics through the work of Moser, Carston, Carsten, and Sternberg and other people. And Moser's observation was that certain problems may prove to be integrable, not because Proved to be integrable not because you reduce them to some low-dimensional case which is identifiable as an integrable problem, but you actually recognize that the problem that is presented to you is, in fact, a projection or a quotiented version of a problem living in higher dimension, where the higher dimensional problem is easy to solve. So, this is sort of a rough and ready way of saying things that is a much more involved way of thinking. Much more involved way of thinking about this, as appears in this paper by 1978 paper by Cashtan, Kosten, and Sternberg with specific application to a certain Hamiltonian system called the collagero Hamiltonians. So, Tony, do I have another five minutes? Sure, go ahead, Krishna. Five minutes, yeah. Okay, and then more recently, there is also work on the continuum side by Work on the continuum side by Udit Halder, who is actually a former student of mine, but now a postdoc with Prashant Mehta at Illinois, and he works on octopus-inspired robots and associated continuum physics as well. So going back to Rogers' 1973 paper, what kind of problem did he deal with? Well, the problems he dealt with are cast in quite different way from the way I did, but really there is very close connection. Really, that is a very close connection. So, his problem embedded into my problems will look like this. So, the first equation qi dot is exactly what he would write down in his paper. The Lagrangian, however, it will be different. In his case, the Lagrangian L had no chi term, no coupling term. And so there was no graph Laplacian or anything to deal with. It was only a single agent problem. Agent problem. And then he would say, Okay, this problem has no Q dependence in the Lagrangian. Let me write down the cost state equation for applying maximum principle. And that looks like as above in the first line of this slide. And then he did something very surprising. He pulled that Q and the P together and defined a matrix K. And then this came. And then this K matrix satisfies an equation that can be recognized as in the Euler-Ernold Lax form with the substitution of the UIs in terms of the traces of K, B, et cetera, coming from application of maximum principle. So this was something that we saw as translatable to our many particle system. And to cut a long story short, To cut a long story short, this whole process led us to a limit argument for general group settings that parallels what we did in the SE2 case. So the strong coupling limit actually is something that one can deal with using Rogers' machine in some way for an applied general group. So now there's a long story following. So now there's a long story following Roger's original paper. There's John Balliol's PhD thesis, his 1978 paper that connected with the Sabrimania geometry problems. Roger himself worked on some variational aspects of the double bracket equation. And Tony and Roger and Peter Crouch and other collaborators have worked extensively on understanding these kinds of things. So I have no more to say on the technical side. To say on the technical side, I want to make a couple of remarks. So, here is a nice picture of the Speer Cathedral in Germany, not very far from Kaisers Lauden, where we had a 1997 60th birthday event for Paul Furman from Bersheva. And Rudy Kalman attended, Roger attended, various of us attended. At various of us attendant. Here, Rudy and Roger are just leaving the tour. And it's nice to see this picture. Now, later, Roger wrote a paper talking about the early days of nonlinear geometric control. It's very worth reading. But I want to close this with this last slide. Roger had a highly admired colleague, Raul. Highly admired colleague Raul Bott. In fact, they co-supervised a student Nicholas Gunther who wrote a thesis on Hamiltonian aspects of sub-Riemannian geometry in 1982 or so. Tony probably knows this work and others know as well. And so I really quote here a quote from Raul Bott. Raul Bott was an electrical engineer as an undergrad at Miguel. Undergrad at Miguel. And then he went to Carnegie Tech in the 40s and wrote a thesis on network theory with Richard Duffin, who is very famous as an applied mathematician. So here's what he says. I learned a lot of things from Richard Duffin, but first of all, I liked and have tried to emulate his way of being a mathematical samurai. What he meant was that Was that he talks about it a little bit more in an interview at the Notices of the American Math Society organized? So the person, Alan Jackson, who interviewed him, asked him, you wrote in a notices article that you tried to emulate his way of being a mathematical samurai. The original remark was from Bott's Steel Price Acceptance Speech from 1919. So Bott says, yes, that's the point. Says, yes, that's the point. It's the problem you go after rather than the fail. You have to trust your instincts. In my view, Roger Brockett agreed with this. And in fact, he felt very much that it's the problem one goes after. And after all, in Beliol's talk, you heard various problems that Roger went after and very successfully. Thanks a lot. Tony, thank you very much for allowing me a couple of extra minutes. So I'm happy to take questions. I will stop sharing. Any questions, question remarks? I certainly remember Nick Gunther, by the way, who I mentioned, I think, went off to law school after that thesis with the project. You mentioned a thesis, a recent thesis about the wafer question, the non-money and waiver question. Equation, the non-linear wave equation. What spatial dimensions are you working on? So, in that setting, the concrete derivation of the analog of this coupled Lagrangian system model, the spatial setting was we imagined that we have a flock and the flock is organized in a continuum. So we thought of So, we thought of the first way to attack this problem would be to think about a flock organized as a string. So, it's a one-dimensional spatial setting. And so you have also periodic boundary conditions. So, our wave equation corresponds to thinking about maps from a circle into various settings, in particular. Settings, in particular, rigid motion group SE2. And so that's the configuration space. So the reduction process applied to that setting leads us to a PDE, which is a nonlinear PDE, which has values, takes values and the dual of the Lie algebra of the rigid motion group. So every point. So, every point on the circle maps to that. So, that's the infinite-dimensional setting. Thank you. Thank you, Arthur. So, you have this coupling parameter, chi. Yes. If I understand correctly, if chi is zero, you get sort of chaotic action of the order. Chaos is the wrong way. Or chaos is the wrong word, but there's no coherence among the different agents. That's right. No synchronization. So each agent does its own thing depending on initial condition, but in an identical way, in the sense that their equations are the same, the governing equations, because of this setup. However, in the rigid motion group case, it's integrable because we should. Integrable because we showed it in that case. So it acts as if it's a single agent, a bunch of single unconnected agents. So, so would you actually see something that resembled a flock if chi is zero or you would see just things going off in their own direction? That's right. You would see if you considered sort of a, if you think about the rigid motion groups. Think about the rigid motion group setting as in which your control variable is curvature, speed is constant, then that curvature variable satisfies the same equation for every member, but depending on initial conditions, the directions in which they'll be moving will be very different. And so there is no coherence to that. Is it just one follow-up? Is it just one follow-up? Is it interesting to do a parameter suite and look at what the flocks do, look for singularities or something? You mean parameter in the parameter chi? Yeah, parameter chi, exactly. Yeah, so in fact, we did, and we have some, we made some movies out of that. And how, let me see, do I have time to show a movie? Okay, I'll try to pull it up. Give me a second. Okay, uh, source. I hope I have it handy, but if not, I'm sorry, John. I think it's buddied in another folder. So, Prisoner, we talk enough so that you can see it today. Yeah, okay. Okay, thanks a lot. And so it does show, so when the chi, the coupling constant goes up, the synchronization gets, it is getting closer and closer to synchronization. Otherwise, you see some sort of space-filling looking curves. Okay, so in the In the control space. And so that's closer to, I think, your remarks about incoherent behavior. Thank you, John. Anybody else? Yeah, I have a quick question. You restricted yourself to regular extra amount. Have you looked at the singular one and whether they exist in what type of One and whether they exist, and what type of motion would it be for the flow? No, I'm sorry, we haven't looked at that. I mean, it's just that we were making a stab at this through this regular extremals setting and be able to do calculations. But it's very, very interesting to get deeper into these kinds of things, especially in this sort of particular. In this sort of particular cost-functional settings, which I don't love to do that, but at the moment we have not done anything along those lines. I have a question about the coupling term. Yes. I noticed that that's in terms of basically biangular velocity, right? Yeah. So they're penalized for only difference in the velocities. Difference in velocities. So, if there's an let's say an agent, one agent really far from the group initially, it's going to just fly like that. So, this agent is not going to be pulled back to this group later on, I'm guessing. Well, so, I mean, there is a certain level of artificiality the way we set up things in the sense that there is a static graph, and that so the neighborhood structure is predefined, at least for the duration. Defined at least for the duration of the optimal control problem. And so you could imagine that even with the strong coupling limit, it's really the curvatures or the steering rates that are getting synchronized, but not necessarily the actual Actual paths traced out because that there will be phase shifts and so forth. And also, the actual trajectories are not confined to anything, any small region because you're motion in the plane. And so, yeah, I think that there is no reason to expect that the Far away agents would be pulled in if you assumed a realistic graph structure. But here, this is somewhat artificial. Any other questions? Okay, great. Thank you very much, Krista. Thank you, Tony. Appreciate it. Appreciate it. I'm going to stop sharing screen. So I think I already did. Yeah. Yeah. Okay. Thank you. Okay, so have a break now. This is 35, 35. Yeah, 30 minutes. So 10.35 for me back and far. Okay. So Arthur is talking next? Yes, 10:35. 20 minutes. Okay. Don't just read the question here. Mary. Can you speak the question? Yeah, Chris. I'll be back. It's probably a rewrite for instance because there's a configuration space.