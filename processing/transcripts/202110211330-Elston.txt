mean by polarity establishment for this talk. And then what I want to talk about is the different levels that we can model polarity at and how each might be appropriate for asking different questions. And then give you some examples of where we have used this microscopic versus mesoscopic versus macroscopic approach. And I'm going to go through what I mean by each of those as I go through the talk. So here's the introduction to polarity, which you've heard. Polarity, which you've heard before, but this is basically that cells in various different contexts have to arrange proteins and other molecules inside them in an asymmetric fashion. So the classic example is cell migration, where the cell has to put the proteins it needs for protrusion in the front and attraction in the back. And then the other examples are epithelial cells. So, for example, cells that line year long, they have a top and a bottom. They have a top and a bottom, and then some during immune response, T cells will polarize towards their targets, and then some cell division can occur in an asymmetric way. And so we've been interested in how cells are able to generate polarity and in some cases, break symmetry to do that. And so that's what I want to tell you a little bit about today. And as you've already heard, a key regulator of this is the Of this is the GTPA CC42. And when I talk about polarity in this talk, what I really am just going to mean is the asymmetric distribution of CEC42. Okay, so CSC42 is a molecular switch. When it's off, it's held in the cytoplasm and then can transition to the membrane, in which case GDP gets exchanged for GTP and it becomes active and it can then interact with various molecules. And then interact with various molecules and do various things. And then the key thing that I want to point out here is that when it is off in the cytoplasm, it diffuses very rapidly. And when it's in the membrane, it diffuses slowly. And so this difference in diffusion rates is a key to developing polarity, as we'll see. Okay, so now what I want to do is kind of walk through the different levels at which you could model this system. Model this system, starting with the microscopic and then going all the way to the macroscopic, and then talking about this mesoscopic approach, which is somewhere in between. So, when I'm talking about microscopic description here, what I'm really talking about is the models that take into account the molecular nature of matter. So, when we do simulations, we're going to keep track of all the molecules in the system. And for us, as Sam pointed out earlier today, we're going to take the doi interpretation. The doi interpretation so that as our molecules are diffusing around, if they get close enough, they can react with some probability. So these are molecularly detailed models, and they capture the intrinsic stochasticity that these systems have because of thermal diffusion and because of just the random nature of the biochemical reactions. But they're computationally expensive. They take a lot of time to run, and they're not really amenable to any type of analysis. And they're not really amenable to any type of analysis. Okay. So, but just to give you a little bit more detail on these microscopic descriptions. So again, these molecules have to diffuse around, and when they get close enough, they can then react. So this leads to two kind of limiting behaviors. One is a diffusion-limited reaction, where it's the time that these particles have to diffuse to get to each other, which really matters. Diffuse to get to each other, which really matters. And when they do get close enough, they basically react instantaneously. In that sense, the reaction is diffusion limited. And then at the other extreme, there are many encounters between molecules before a reaction happens. And so what matters is this, what I'm referring to as this K micro, this rate at which the reaction occurs when they're close enough, that's the limiting step. And we call that reaction limited. Okay. And also, I just want to point out, so there are these microscopic parameters that we have to. Microscopic parameters that we have to specify when we do these types of simulations. For example, we need to specify the diffusion coefficient, the reaction radius, how close they have to be to interact, and then this rate constant, which I'm going to refer to as the K micro, because that's the microscopic rate constant, that the rate at which they react when they're close enough together. Okay, so then we can kind of go to the other extreme where we're just going to ignore the molecular nature of matter. We're going to talk about concentrations. And here we're going Concentrations, and here we're going to deal with reaction diffusion equations. Where again, we model reactions and diffusion, but we do this with partial differential equations. And these can be computationally efficient, and they're often amenable to analysis. And typically, when we go into the lab and we measure rate constants, that's what we're measuring: are these macroscopic rate constants that we put into mass action reactions? Reactions. So, what we want to be able to do is to do this contraction down from the microscopic description to the macroscopic description. And that's what this reaction rate theory is doing for us. It's telling us how these macroscopic rate constants are related to the microscopic parameters. And so there's been a lot of work, has a long history in reaction rate therapy, going back to luminaries like Smolikowski, Anshager, and Kramer. Answager and Crommer and many others. Okay. So that's the microscopic and the macroscopic. And now in between, we have this intermediate level of description that we refer to as mesoscopic. And what we hope is that it correctly captures the intrinsic fluctuations in the system without having to resolve all the molecular detail that we did with the microscopic description. Microscopic description. And a very typical way to do this is through what people refer to as Spatial Gillespie, where you take space now and you discretize it. So your system lives on a grid. And so your particles can hop from grid point to grid point, but we don't keep track of their positions within the grid. We just keep track of the numbers. And then when these particles are in the same grid, they can react with some probability. And so what Probability. And so, what the challenge here is to pick what I'm going to refer to as these mesoscopic rate constants, that is how these reactions occur once with particles in the grid, so that we get the best approximation to the microscopic dynamics that we can. And so, what we've, but one important thing is that when we now do this mesoscopic description, we've introduced this other parameter, which in a sense is kind of artificial, but it's how we coarse grain. Artificial, but it's how we coarse grain the system. So it's the size of the grid. And so our mesoscopic rate constants not only can depend upon the microscopic parameters, which are sort of the physical things, but also on this grid size that we have selected. Okay, and I will go through that in a little more detail when we get to an example of that. Okay, so now let's go to some of the The examples, and I'm going to start with what has been my favorite system to study polarity in, which is polarity establishment in yeast. I'm going to talk about budding yeast, not fission yeast, and then in two different contexts, budding and mating. So yeast, budding yeast, they will polarize their growth in two different contexts. Once is when they are growing, dividing, the way they grow is that the mother cell will form a bud that eventually becomes the daughter cell. A bud that eventually becomes the daughter cell. And the first thing that happens in that process is CDC42 gets polarized. And so, what you're seeing down in this movie down here is the green is basically a marker of where CDC42 is. And you can see it gets first polarized in the mother cell and then in the daughter, the budding cell. Okay. And then also during mating, yeast will polarize their growth. So yeast typically diploid cells, but they can't exist as haploids. And when they do that, Exist as haploids, and when they do, they come in two mating types, A and alpha. And an alpha cell will emit a mating pheromone, an alpha factor, which the A cell can detect, and then will grow towards the gradient of alpha factors. So this is a chemo tropic growth of the cell. And what you're seeing down here is an A cell, again, the green is CC42, growing, detecting the AC cell or the alpha cell, and then eventually fusing to form. And then eventually fusing to form the diploid. So, another context where these cells have to polarize. So, now let me give you the cartoon of how we think this happens, how this polarity occurs. So, here is CDC42, and it's sitting in the membrane, and it can come off and on and off the membrane at random. One of these CC42 molecules could get activated, say, at chance. Activated, say at chance. But then what happens once it becomes active, it recruits some other proteins. You know, only thing to remember is that one of the things that it recruits is CC24. And don't worry about the name, that's just the GEF that catalyzes this conversion of GDP to GTP. So you activate CC42, it then recruits the molecule that can activate its neighbors, which then you get recruit more of the GAF, and you get that chain reaction going, and eventually you build up. You build up a polarity site. And the reason that it doesn't grow throughout the whole cell is that one of these factors is limiting. And it's most likely BEM1 here that is limiting. And once you run out of that, you stop. The polarity site doesn't grow anymore. Okay. So that's the kind of cartoon. Here's a very simple mathematical description of that based on the original work of Goryeo Chef and Pohilko, who came up with this model for yeast. This model for yeast back in 2008. So, here we just have two. So, this is a macroscopic description that we have two reaction diffusion equations. You can think U here is the active CC42. And so it can diffuse, but it can also, the inactive form can also get converted to the active form. And the rate at which that happens depends on how much active CC42 you have. So, that's the positive feedback that you need. That's the positive feedback that you need to get this thing going. Then it can get converted back to the inactive form. And then, again, what's the key here is that when it is active, it diffuses at a slower rate than when it is inactive. And it's straightforward to show that these two equations can undergo a Turing type instability so that if you start from a homogeneous state and give it a small perturbation, the system will spontaneously. The system will spontaneously polarize. Okay, so this is a deterministic description. There are no fluctuations in here. But if you actually look at the process in cells, and I should say this is work, all the data that I will show comes from Danny Lev's lab, who's a longtime collaborator. So what we're seeing here is that these cells that are budding, and what you observe is that initially there's more than one polarity site. Than one polarity site. But very rapidly, that polarity site, one of them out-competes the other one, and you end up with a unique polarity site. And that can occur in about, that occurs in about two minutes. Okay, so the questions that we then had are, are molecular fluctuations sufficient to initiate two sites? Because you'll never get two sites with this deterministic description. And how do these fluctuations affect the time for these two sites to compete? For these two sites to compete and for one to win, because it's very important that you only have a unique polarity site when you're budding. So, to start to address this question, this is work by former graduate student, Mike Pablo. So, he's going to use particle-based simulations to simulate this process. So, again, the particles can diffuse, and if they get close enough, they will react. Yeast cell is pretty. Yeast cell is pretty spherical, so it's good to think of it as a sphere. However, we're going to make the simplifying assumption, at least initially, that we can flatten out the cell and only think about it's in two dimensions. And we're also going to, the computational domain is going to have periodic boundary conditions. So when you go out one side, you come back the other, which is technically a torus in 2D, not a sphere. And then the only other thing to be aware of is that these molecules. That these molecules that, as they're diffusing around, if they transition into the membrane, they then diffuse more slowly, or if they transition back into the cytoplasm, they will diffuse rapidly. And so, that's what distinguishes particles in the membrane from the cytoplasm is their diffusion coefficient. Okay, so I'm going to show you a simulation of these. And then, of course, we simulate the reactions that I described earlier in the cartoon. So, I'll show you the results of a simulation and what you'll see. Results of a simulation, and what you'll see, these red dots are active CC42. So, and starting with random initial conditions, you see that the system rapidly evolves into two polarity sites. And then the larger one is eventually able to out-compete the smaller one, and it resolves into one polarity site. And if you look at the time it takes. At the time it takes for that to happen, it happens on roughly the right time scale as the experiments, around two minutes. And I should say, we also have fairly decent estimates for a lot of these parameters, which is one of the nice things about working with yeast. So that looks good. But what we want to do now is try to make this kind of fair comparison from the microscopic to the macroscopic. If we want to understand the role. If we want to understand the role of intrinsic fluctuations, we need to be able to compare it to the macroscopic description. And so that means we need to, again, have these rate constants, these macroscopic rate constants. We need to know what they are in terms of these microscopic parameters. And if we've been working in 3D, there is a nice theory worked out by Reddick Urban and his coworkers that would tell us how to do this, that given the capture radius. That given the capture radius, the diffusion rates, and these microscopic rate constants, how we should, what the corresponding macroscopic rate constants would be. However, we're not working in 3D, we're working in 2D, and we have a slightly more complicated system that I just want to describe. So there's some challenges with this. The main one being that reactions in 2D don't have well-defined rate constants. Well-defined rate constants when you're in the diffusion limit. So, when diffusion, when the time for the reaction to occur is dominated by the time for two molecules to diffuse to meet each other. Okay, and I'm just going to show you this by an example. So here's a reaction of A plus P this yellow curve. That's the result of doing many particle-based simulations and averaging. Okay. And then the black curve. And then the black curve is just taking this rate equation and fitting it to the yellow curve. And here we're in the reaction limit where diffusion is fast and we get a very nice fit. But as we start to make diffusion slower and slower, what we see is that there is now no longer a good fit between the rate equation and our simulations. And that's because these And that's because these rate constants don't actually exist, again, in the diffusion limit for 2D reactions. It's a more complicated process that can be described simply by this. However, we also have one other thing that's going on in our model, which actually at the end of the day saves us, is that we don't have just one diffusion rate. We actually have diffusion, slow diffusion in the membrane, where things are diffusion limited, but then we also have fast diffusion in a cytoplasm. Diffusion in a cytoplasm. And basically, what happens is that there's an effective diffusion rate that is a combination of this fast and slow that sort of pushes the system away from this reaction or diffusion limited regime. And so what we are able to do is to simulate all the second order reactions in the model and include these on and off rates and then empirically estimate rate. Estimate rate constants from those simulations of just the second-order reactions. And now we actually do get a nice fit to this rate equation to our simulations. But what's important is that these macroscopic rate constants also depend on this on and off rate. Okay, so they have that rate varied, those rates buried in them as well. But the overall reaction is well described with. Is well described with this mass action rate equation. So we can now take those rates that we've determined empirically, we can put them into the reaction diffusion equation, and then we can run our particle-based simulations for a while, use those as initial conditions in our reaction diffusion, and then run the system forward in time. And basically what you find is that when you have this stochastic fluctuations going on all the time, the time for these two For these two polarity sites to compete is much shorter than when you only have the reaction diffusion equations. Okay, so these fluctuations shorten the time for competition. And that had always been a concern with these Turing type models for polarity establishment that this time scale to resolve into a single peak was too long. But when you include the noise, you get the right time scale. That you get the right time scales. Okay, so just to summarize this first part, it looks like these intrinsic fluctuations are sufficient to generate multiple clusters, and they decrease the time to resolve into a single site. And one thing I don't have time to show today, but what is also true is that they actually, including fluctuations, actually increases the parameter range over which polarity occurs. Over which polarity occurs. So, in a sense, it makes the system more robust to polarize. Okay, however, one thing that you may have noticed is that once this polarity site forms in these simulations, it is always static. It never moved. It just sat there. Okay. And what I'm going to show you is that that's not true when we look at polarity establishment during the mating response. So here again, some data from Danny's lab where you're looking at polarization. Lab where you're looking at polarization, but now you're looking at the cells that are polarizing in response to pheromone. And what you should see in this movie is that initially that polarity site is very mobile. It moves around a lot, but then eventually this cell finds its mating partner, in which case the polarity site stops moving and it grows and fuses with the neighboring cell. So over here, I've just quantifying that data where you have this very This very mobile, active polarity site, and then in time it becomes stable. And so, Danny refers to this as it's kind of like dating or looking for a mate as we do. At first, we're very indecisive, but then we find somebody we like and we commit. So there's this indecisive phase and there's this committed phase. And then if you look at the MAP kinase activity, which is just a downstream signaling molecule, what you see is that the activity What you see is that the activity of that molecule correlates very nicely with the mobility of the patch, just suggesting that MAP kinase activity could be regulating the mobility of the patch in some way, in some unknown way. So this led to these questions that we wanted to think about is that what drives this patch mobility? Is this model not sufficient in that because you always get a static or stable site? Get a static or stable site? Or is it just because we couldn't find the right parameters that we always got this static site? And then, if it does generate a mobile patch, what is a good way to regulate that mobility? Okay, so there was a technical challenge that had to be overcome because these particle-based simulations can take hours and days to perform, even in 2D. And then, so, but the patch movement. But the patch movement that I showed you, and I should have said, occurs over tens of minutes. Okay, so we're not going to be able to study different parameter values very easily by doing these particle-based simulations. So this is where Sam Ramirez, a postdoc working with me, came in. And what he wanted to do was to use this mesoscopic description to study this problem. Okay. And again, so let me just remind you. So at the mesoscopic level, At the mesoscopic level, we're gonna discretize space now so that the system lives on a grid. And then we're going to let the particles jump on the grid. And if they're in this occupy the same grid site, they can react. Okay. And then we have to decide what the reaction rate we should use in here is so that hopefully it best corresponds to the microscopic dynamics. And there is a bit of an issue that Sam. An issue that Sam even alluded to earlier: that if you just think about the problem of two particles trying to find each other in this random walk on the grid, the time that it takes to do that depends on the grid size. Okay, so there was this nice work done by Hillander et al where they said, well, let's do this. Let's take this problem of a particle living on a grid and let's compute the average. Let's compute the average time it would take for two molecules to find each other. And then we can also solve that problem in the continuous case where we have a continuous space problem. We can solve it on an analogous using the same area, basically. We can solve that. And then we can force those times to be the same. And from that, we're going to get a condition that tells us what rate constant we should use here. Okay. And that rate constant is going to depend on our choice of grid size. So that's why it's referred to as a. Grid size. So that's why it's referred to as a scale-dependent rate constant. And this can actually work really well, but it works really well when the number of molecules in your system is relatively low. Okay. And what this is showing here, so these are results from the particle-based simulation, and these are results from using this approach for just this reaction, A plus P goes to C. And so when the particle number is relatively small, everything works fine. But when you get to these high density, Everything works fine, but when you get to these high-density particle numbers, you see that there's a discrepancy between our mesoscopic and our microscopic, which kind of makes sense based on the way this was derived. Essentially, you're assuming here that all pairs of molecules are independent. And clearly, when you get to high levels and there are multiple molecules in the same cell, you're going to run into potentially some issues. So what Sam did is he took a different approach. He said, rather than solving He said, rather than solving the problem for two molecules encounter on a grid, when you have many molecules in your grid cell, you can define the average mean-free area that they would experience if they were in an area of this size. And then you can solve the problem for how long it would take on average for them to react there and to get a time. And let's just use one over the time basically as the microscopic rate constant. Rate constant for this grid. And so, what you see is that these rate constants have a concentration dependence. So, in general, they're going to depend on how many molecules are present in this grid at any given time. So, they're changing in time, but that's still okay. You can still solve that efficiently. And what he showed is that now when you take that same reaction and you do it this way, even at these high numbers, it works very well. And in fact, we've thought that this may not work now for low abundances, but actually, this is just. Abundances, but actually, this is just showing that it works reasonably well, even for when you have low molecular abundances. So he thought this was a good approach. So then he went and applied it to the polarity model. And this is just showing that when you compare again the particle-based simulations, which are these dashed lines, with the mesoscopic description now, and this is the time to polarize, you get a very good. Polarize, you get a very good correspondence. And this is just showing, so this is a measure of polarity as a function of the number of GEFs in the system. And there's a transition from an unpolarized state to a polarized state. And what it's showing is that there are some definitely some discrepancies, but overall, it works pretty well. So now he's got a very fast way of doing these simulations, which allowed him to kind of just go through and test many, many parameter values. And I don't have a lot. Parameter values, and I don't have a lot of time to tell you, but what he was able to show is that there are indeed parameter values that will allow this patch to be very mobile. So here's a case now where the patch is no longer static, it's very mobile. And then what he found is that by changing this rate, the rate at which the GEF and the active CC42 interact on the membrane, he could very nicely regulate the speed at which the patch moves. This is an effective diffusion. At which the patch moves. This is an effective diffusion coefficient. So here is when K4 is low and it moves a lot. And then as K4A gets big, it becomes much more stationary, suggesting that this may be a way of regulating the mobility of the patch if, say, map kinase activity affected this rate. And then everything I've done so far is in two dimensions. And now we were even assuming a mesoscopic description. We were even assuming a mesoscopic description. So, what he then went back and did is these full 3D simulations, particle-based simulations, and compared the full 3D results to the 2D results. And there are definitely differences, but qualitatively and fairly quantitatively, the results look pretty good. So, that gives us confidence in the results that he has are actually will hold when you consider a full 3D cell. So, I have, I think, a little bit more. I think a little bit more time. You're one minute shy of 30 minutes. Okay, let me just take a few extra minutes now to turn to the macroscopic work. So this is in phagocytosis. This is a relatively new project that we have going. It's in collaboration with Klaus Hahn, who's at UNC and the pharmacology department as well. So here's a very brief introduction to phagocytosis. This is basically the way cells. This is basically the way cells internalize large objects, and in particular, things like bacteria and viruses. So, what can happen is that this bacteria gets coated with an antibody that this cell, which is like a macrophage, can recognize by receptors on the cell surface. And once that happens, that triggers the phagocytosis, which basically the cell eats the particle. Okay, so what Klaus is like. Okay, so what Klaus's lab does is to simplify that process, they can micro-pattern the antibody, in this case IgG, down on a substrate. And so you have a lot of these IgG patches. And so when the cell crawls over a patch, it tries to eat it, but because it's stuck down on the substrate, it can't do that. And they call that frustrated phagocytosis. Okay. And so what this movie is showing is showing actin as the cell tries to eat this. Tries to eat this micro-pattern circle. And what the main point is that if you look at the actin structure, you get these high-density actin regions, which are potasome-like structures, which just means there's high-density actin. And so the question is, how do you form this, we call it a rosette of these potasomes around what the cell is trying to eat? And I won't go into this, just to say, this is the motivate that CDC42 clouds. That CDC42 Klaus builds biosensors that show where CC42 is active. And if you look near those sites, you see CC42 is active. And this is just some very polymer data that seem to indicate that myosin, so it could be that contractility is important for forming these structures. But if you block myosin activity, you still form these protosomes. So basically, what we think is happening is it's the same. Is happening is it's the same model that I explained before for polarity with one modification. Because when we did the model that I showed, you always had competition. The sites basically one of them won. And the reason for that is in that model, the positive feedback is basically unlimited. So as one of the polarity sites gets a little bit of an advantage, the positive feedback keeps getting stronger and it can out-compete the smaller one for all the CC42 in the size. For all the CC42 in the cytoplasm, and it wins. So, what you just need to do is have a way of limiting that positive feedback by introducing a negative feedback. And so, what we postulate is that there is a negative feedback in this case that involves activation of a gap. And then it's been known, this is not worked by us, but by other people have shown that if you include that negative feedback, now you get polarity sites that are stable. And this is just showing. And this is just showing that, which I'll and those will last for as long as you care to watch them. Okay, so Cody Heron, who's a graduate student who's doing this work, he realized there are two ways that this could happen. You could first form this ring of some protein that could become activated, and then that ring could then lead to the protasome formation. Okay, this actually turns out to be honestly the easier way to do it. Honestly, the easier way to do it. It's quite easy to form a ring, and once you have a ring, to make this rosette pattern. But he was also curious as to whether this could happen in one step if you could do it without first forming a ring. And that actually turned out to be a little bit challenging to find parameters that would do that. And so what he did, first I'll just say what he did quickly, he just assumes that we have this model, and then the rates can depend on whether you're over the IgG patch or not. Okay, so you can have. Patch or not. Okay, so you can have things rates that are increased and fall off as you move away from this patch, or you can have things that are low and then become high. And then what he did is he took this model with these possibilities and he put it into an evolutionary algorithm and he just let the computer basically run through a bunch of parameters using ideas from evolution, including crossover and mutation. Basically, it's an efficient way to search parameter space and to search what reactions have a spatial dependence or not. And he was able to. Not. And he was able to then evolve these models that would lead to this nice ring pattern. And in all the models, even the ones where it's two-step, it seems the key to doing this is that you have to have the positive feedback loop be regulated over the patch, increased over the patch. And then for this all-in-one model, you also have to have the negative feedback, the activation. Negative feedback, the activation of the gap be increased over the patch. With those two together, you then can generate these stable patterns in a ring. So I'm going to wrap up there. I know I went a few minutes over, but I'll just summarize to say that, you know, now we have at least a sufficient mechanism to explain this. But of course, what we need to do is test that. Just because it works doesn't mean that's actually how it happens. But Klaus's lab developed. Happens, but Klaus's lab develops lots of biosensors and optogenetic approaches where he can go in and turn things on and off with light. And I think the tools are now available to go in and try to test this model experimentally. So I will stop there. I'll just again acknowledge Cody, Sam, and Mike, who are the main people who did this work. And then I've been fortunate to have many collaborations here at UNC and at the Duke. And I'm stopping. And I'm stop, and I'm happy to take any questions. Okay, great. Thanks, Tim, for an awesome talk. Why don't we start with the remote folks? Are there questions? Feel free to just unmute yourself and speak up if you have a question. I see Jay Newby's got his hand up to begin with. Yeah, can you hear me? I can hear you. Yeah, so I thought that was really cool. I thought that was really cool how the spot moves around. You describe it in terms of an effective diffusion that I'm guessing you computed sort of numerically. Can you derive a reduction from any of your any scale of your stochastic models to a diffusion? So you would like to be able to say relate. Would you like to be able to say relate that effective diffusion to say parameters in yeah, that that's a great question, and I cannot answer that we have not done that. Um, and I don't know it would be great if it were possible. I'd be very interested if you had ideas on how to do that. Um, I know they do similar things in neural field theory to like talk about the Talk about the stochastic motion of like a traveling front, and I think they do with bumps and different things. You know, one thing I didn't get to talk about is why that patch moves so much more than the one that was stationary. And I think this may complicate things because it turns out you can have exactly the same number of CC, not exact, but very, very similar numbers of CC42 and the GEF in a patch, and one will move and one will not move. Will move and one will not move. So it's not, it's not, because we just thought of, you know, less numbers, more mobile patch. But what turns out is it's actually not the number fluctuations. These patches that move, they have very large spatial fluctuations. Now, when you look at the distribution, there's all kinds of, and it has to do, you have to make the exchange between the cytoplasm and the membrane kind of fast to generate these spatial fluctuations. But then once you have. Spatial fluctuations, but then once you have them, the patch moves. I think it kind of locally sort of breaks up a little bit, but then reforms fast enough that it doesn't ever just completely go away and it just kind of ends up moving. So I don't, yeah, but it would be great to try to capture that in a in some way. So let's see. Wooder John has his hand up. Next. Yeah, thanks. I have a question about kind of the first part of your talk. The way you presented it, I thought it was a The way you presented it, I thought it was a Turing instability, but a Turing instability has a certain wavelength. And later on, you said that these instabilities were competing and they kept competing and therefore one wins. I wasn't quite clear where that came into your equations. Yeah, so it is a Toring, first of all, it is a Turing instability. And if you kept making this one way to, I guess, to stabilize or have... Stabilize or have the patches last longer would be to make the system bigger. Okay. However, even with this model, it's always going to compete. That has been shown mathematically. And the qualitative reason for that, again, is that you can, the feedback, the positive feedback, there's no way to limit it. Limit it. All right. Now, having said that, you can have patches that will coexist for time scales that are longer than all relevant biological time scales because they compete exponentially slow. All right. So you can get coexisting patches. From a math perspective, that's not stable. One will, unless you have them exactly. Will win, unless you had them exactly equal. When one gets an advantage, it will win. But on a biological time scale, it could last for a very, very long time. Thank you. Great. Will, you're up next. I think we have time for one, maybe two more if we go fast. I really like the spatial Gillespie stuff. And you had said with slow diffusion constants, it sort of falls apart. And you showed a curve that fell rapidly and then had a long tail. Can you just give me an intuitive answer? Can you just give me an intuitive explanation of that? Yeah. Why it fails, why you don't have a rate constant, well-defined rate constant in the diffusion limit. So there's a mathematical way that may not be very satisfying to you. The way you get these rate, you could get these rate constants is by solving the diffusion. By solving the diffusion equation. And in 3D, you would solve it with an absorbing sphere at the origin and look at the flux into that sphere when you hold the concentration fixed at infinity. In 2D, and in 3D, you get that one over R dependence on the con and everything is fine. When you do it in 2D, it turns out that because of the logarithms, that flux actually goes to zero as you make the system bigger and bigger. And so you can't define it. And so you can't define it that way. And it really has to do with these searches in three versus two dimensions. Yeah. There's a fundamental difference. Great. Thank you. Cool. Okay. So, John, I think we have time for one more from you. Sure. Hi. Hi, Jim. Hi. Hi. Just a very quick question about your phagocytosis project. I'm struck by the very regular Struck by the very regular size of the acting patch. So, when Zinu model, what gave raise to this characteristic size? Are you talking about the circle? Right, right. Yeah, that's that's, I didn't make this clear. Sorry, that is put down experimentally. That is micro-patterned onto the substrate. Okay, so what is an interesting question is the spacing between the protosomes, you can change the size. Between the podisomes, you can change the size of that. And the spacing looks like it stays pretty constant. That is, you just keep getting more and more. It's not like, you know, so whatever the mechanism is, has to have that. And some of the models that I showed, I didn't didn't have that behavior. So they're probably not right. Okay, great. Thanks, Tim. Thanks for a great talk. Next up is Demetrios Vavilonas. Vavalonas is going to tell us something interesting. I don't no longer looking at his title, but I'm sure we're going to see it in a minute. Yep, there we go. All right. Take it away, Dimitrios.