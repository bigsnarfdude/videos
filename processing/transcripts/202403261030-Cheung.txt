And so my name is Han and I'm from Light. I'm from the University of Calgary. So today I'm going to present one of my work, which is about astrology solution of a class of second-order HGB equations in the Watson-Science space. So my stuff is not that closely related to optimal transport or the distribution robustness, but as because I Robustness, but as because I'm doing something on the motor science base, so I think I can be vaguely regarded as doing some optimal transport. Yeah, so let's see what it is about. Okay, this is today's close. First of all, I'll go with the problem settings, and then I will talk about what's the field view of restrictive solution. And finally, I have little questions regarding the radium maps. I think we can just skip this slide. So it just introduces the Washington space, and I believe that you are more familiar than IP. Okay, so first of all, because I'm going to talk about some restorative solution stuff, and it is a PDE. So because it is a PDE, so we have to introduce some derivative notions on the Watson-Sein space. But as you know, then the Watson-Sein space is a metric space. Is a metric space, which is hard for us to define what derivatives are. And I know that there's an interesting notion of what's a sign gradient, but we have to have something of second order, so it is not applicable here. So we make use of the notion of L derivative, which is proposed by Pierre Remarks. So basically, it is saying that, well, for a function f, which is adding all Which is acting on the waste-time space, we can treat it as a function on the space of random variables. And once we treat it as on the space of random variables, then we can, because this space is a Huber space, so we can talk about the first shared derivatives on a Huber space, right? And we say that, oh, if it admits contains a first-rate derivative of this form, then we say it is like. Then we say it is like L-differentiable because the L here stands for Lyon's. And yeah, so if the lifting is, I mean, if the derivative, if the first derivative is differentiable for one more time, then we say that it's L-differentiable for a second time. So this is the main idea of the L-deal, which is not that fancy, but just the lifting of the Leaf thing of the Washington space to a space of random variables. So the X-JB equation that I consider today is coming from the following state dynamics. It is written as like Xs equals to plus C plus the, this is the drap plus the volatility part, and plus this red term. So for this, so here, the P W. The P W0 XT, it is denoted as the conditional distribution of Xt different W0. So here, actually, this dynamic, we can regard it as something like infinite dimensional stuff. What I mean by different dimensional is that you may consider this to be like there are n players. And each of them here, following the, you may replace this one by the amputal measures of all the players. And then Players and then this noise is acting on all the players, but this noise here is acting on the player alone. So this is the idiosyncratic noise and this is the common noise. So we consider this kind of stage and then as follows. And finally, we can define the value function to be like read t equals c equals to like here the alpha. It goes to the right. Here, the alpha is in the control set. And then it could be shown that the V T is actually depending on the law zone. So the V here can actually be regarded as a function on the Wolfsonstein space. And therefore, later we will show that this V will satisfy, we'll have the up here just some standard assumption which says that I require those V to be. I require those B to be nucleus and bounded. Thank you. Yep. Why is it important to see this as a function on the Hassan space? Oh, yeah. Because it's hard for us to handle stuff on the space of random variables. Yeah, and this is actually a good question. But actually, we want to go back to the settings. Like, go back to the settings of Watson Science Place. Otherwise, because it seems like here, we can think of it as we lift the things up. Because originally, our input functions are some stuff from the Washington space. And then we lift the things up to the space of random variables. Of course, we have to leave things, we have to prove dance things, right? So that's why we have to like. That's why we have to like trace it back to the most nice box. So, if you are familiar with control theory, then this is quite a standard result which states the dynamic programming principle, which says that if you want to solve this problem, then you may first solve it from the terminal and then you just run time from T to this time. And for this moment, you may just simply ignore this supreme manufacture mode. Ignore this suprema manufacturing, then there's a relation between the VtC and the Vs. And just for this moment, if you just naively put the Vs to your left-hand side, then you expect that this plane will lead you to some PD equations. So my work here is mainly about how to solve these PD equations in a restorative, I mean in a rich sense, which is in the sense of. sense which is in the sense of we saw these solutions. So here this left Polarian principle will lead me to this HTV equations which looks like this. And I have this like red term coming from the common noise. So if there's no common noise then yes done by someone before. So my work here is just to extend the stuff with common noise. Yep. So our role So, our goal here, as I mentioned, our goal is to show that the value function V is actually the unique distortive solution of the above HJP. So, because we talk about our distortive solution, so we have to choose what our test functions are. So, in this time, our set of test functions is all those lines from this function that satisfy this. I mean, they have some regularity, and then here, it's Here, it has a operation about this derivative. So, and here, so there's one point, like here, the bounds are about second moments. But compared to the usual set of test functions, I mean, in the usual temperature, they usually choose those with like the point-wise bar instead of the moment spawn. And because our equation here. And because our equation here is there are some integrals, so in some point you would you would expect that you have to use a dominated convergence theorem. If we have the light polymerized part, then it is much easier to deal with. But in this case, we only draw the movement part, so we have to use some more advanced techniques. And what do we draw? We're solution is a continuous function such that, first of all, we repeat. First of all, we replace all the stuff of equalities to inequalities, and then we require that if this u minus phi where phi lies in the test function set and attains a maximum at some point, then we require the phi will hold the HTML equations at that point, but here we replace it to be an inequality. We replace it to be an inequalities at that point. So there is a problem that it will come later: is that we have to actually attain this maximum or minimum. And it is a problem in Washington space because the Watson-side space, I mean, the structure is not that nice. It is not locally compact. So we cannot guarantee that we can attain this point. Okay, so the existence theorem is easier. The existence theorem is easier. So we say that the theorem is that the value function V is a resulting solution of our H J equations. So the schedule of proof is that we just simply examine this difference quotient and then we can make use of the dimension principle, a relaxed detoller lemma, and the regularity of the phi. Then we can get the show that the V is actually a restorative solution. This solution. So, the difficulty, as I mentioned before, like we have to make use of the dominant convergence theorem and we don't have the cost part. So, the remedy is that we can make use of the second moment, which gives us the uniformity probability. I wonder where does the first we have to talk. We have to talk about the differentiations in this right. So the partial mu is the Lyon stability. Okay, so actually we could choose another set of test functions which is easier for us to establish the existent theorem. But then it will pose a question on how to prove the uninitians because it is It is trying to ask for choose appropriate test functions because for the existent part, we have to show that those five in the test function, they are, they satisfy this property. So if they are less functions in the set of test functions, then it is easier to show the existence. But for uniqueness, we often use an contradiction argument. So if there are more functions in the test function, then If there are more functions in the test function, then we are easier to show the universe. So the reason that we are using this test function set instead of the more usual one is because we could not establish the uninitus in our case if we use the more usual set of test functions. So the theorem is that we can actually have the unimbus, and improving the unimbus. And in proving the uniqueness, what we often do is that we prove by contradictions. We assume that there exists some T0, mu0, such that this thing is greater than 0, and we require the U1 minus U2 to be achieved at some point, the maximum of U1 minus U2. Clarification, when you said you choose a different S functions, is it just a proof trick, or are you changing? Just a proof quick, or are you changing the nature of the results? I think it's just what Riscorati Solution does. We choose, so because usually we may not, I mean, the function itself may not have this kind of regularities. So instead of like we require the function to have this kind of regularity, we just uh just transfer the regularity um condition from the function itself to some test functions. The function itself to some test functions. So you're adding regularity constraints in order to get no. I mean, so the philosophy of restorative solution is that we may not have some classical solutions to these equations, but we have a solution in another sense, which is Which is written here. So we require that if this one, the u minus phi, attains a maximum at some point, then we require the phi would satisfy the HJB, but in an inequality sense. And this, I mean, this actually comes from some full dynamics. Should I continue? Yeah, okay. So because we require I mean and we require the maximum of u1 minus u2 is to be achieved at some point. And as I've said before, the space of Osenstines is not that nice. So we do not have the local chunkers. So it may not be achieved. But the remedy here is that we adopt the same approach as this paper. like this paper, so which makes use of the variational principle. So it says that although your function, oh sorry, so it states that the variational principle says that although your function may not achieve the maximum point, but after a perturbation of the so-called gauge function, then we can actually achieve the maximum point or the minimum point. So you may wonder what is a gauge function? A gauge function is just something that looks like a maximum function. Just something that looks like a metric, but and it dominates the original metric, but without a triangle report. So we choose the gauge function to be, I mean, it's introduced in this paper to be like this one. So it's another kind of Lagos time distance. And the the philosophy here is that we are projecting our n dimensional scale to one dimensional, and then we integrate along the whole ball. Along the whole ball, and this thing acts as an equivalent matching to the Watson-size fix. And then we just like to make it more smoother, we trumble with normal distribution. And I know that I'm running out of time, so I'll be fast. So you may wonder why do I have to project into the one-dimensional? It's because in 1D, there's an explicit formula for the binary map. In this case, I can just simply In this case, I can just simply write my motor size distance as this form, where the t is the premium map here. And this helps to show the regularity of the metric which is needed. So here is just a statement of like, if I perturb my original function by the gauge function, then I can obtain the maximum or the mean. And here is the regularity of the metric. So finally, it goes back to the proof of uninness. Goes back to the proof of units. So basically, I just will choose this one as my test functions. And then, because of my regularity, then I'm able to draw some contradictions because of the regularity proven. And I think this concludes my thoughts. Thank you. Unless there is