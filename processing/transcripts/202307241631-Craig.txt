Well thank you very much for the introduction and thank you very much to the organizers for putting together this workshop. It's always amazing to be here in Bay. So today I'm going to be talking about non-local particle approximations and that is a little bit of a mouthful and for historical reasons and also kind of due to the themes of the workshop instead of calling these non-local particles Instead of calling these non-local particle approximations, for most of my talk, I'm just going to call them Blob methods. And so this dates back to Beale and Maida's work on Blob methods for the Euler and Nager-Stokes equations. And kind of the basic idea was we were interested in looking at these evolutions of Lagrangian coordinates, but the velocity field involved kind of convolution with the vorticity, and the convolution kernel, the BO sub R kernel, had a singularity. And so if you kind of were taking Singularity. And so, if you kind of were taking an approximation of the vorticity as an empirical measure, you could run into problems with that singularity. And so, they kind of got around this by convolving the VS of R kernel with a modifier. And this is going to be the same idea that I used in all of the PEs that I'll introduce to Fix. So, we'll call them Blob methods, and they'll be Blob methods for optimal transport and degenerate fusion. And so these are the kind of, these will motivate kind of the two PDEs that I'll be talking about. Talking about. And I'll explain: you know, these PDEs arise in a variety of contexts, but one application that unifies them both because I think they both could be potentially interesting in the sampling context. So here's my plan for today's talk. I'm going to start off by motivating what I mean by this sampling problem. What are some classical PE approaches to this problem? And why are these kind of new dynamics that I'm going to be talking about today potentially interesting for sampling? About today, potentially interesting for sampling. Both of the dynamics I'll be talking about have a strong interpretation in terms of optimal transport and Falserstein gradient flows. So I'll give a little bit of background on that and also explain how we're using this optimal transport perspective in order to discretize these equations. Because we start off with these continuum PDEs, but at some point we have to kind of develop a numerical method for discretizing it, who we're actually going to be using in practice for sampling. Sampling. And so this leads to these two blog methods: the blog method for degenerate diffusion and then the blob method for optimal transport. I'll tell you a little bit about our convergence results, kind of the pros and cons for each of these methods in a sampling application, and then I'll show a few little gold samples. Okay, so here's the motivating problem for these two dynamics. We assume that we're given a desired target distribution, rho bar. I'm going to assume that rho bar. Rho bar. I'm going to assume that rho bar is a probability measure on some domain omega. I'm thinking of omega as being a convex subset of d-dimensional Euclidean space, but more general domains could be possible. And the problem we want to solve in sampling is we want to figure out how can we choose samples, so these are kind of n vectors contained in omega, to accurately represent this desired target distribution rho bar. And so what we mean. Bar. And so, what we mean by that is we want that if we consider the empirical measure at those samples, as we draw more and more samples, this empirical measure converges to rho bar in some sense. So, you know, at this level of generality, there's a million different ways to solve this problem. But depending on the application you have in mind, there's a variety of considerations that might help you decide which of the many different possible sampling models. Many different possible sampling algorithms to use. What is kind of one consideration is what are the available convergence guarantees? Often this depends on some kind of structural assumption that your desired target distribution provard. Another consideration is do you want a kind of a stochastic sampling method or a deterministic sampling method? I think, you know, classically, people have been very happy with stochastic sampling methods. And in a lot of applications, Application kind of sampling is almost part of a broader numerical scheme, and it makes perfect sense to use a stochastic approach for sampling. But you can also think of applications where you really wouldn't want a stochastic approach. So, for example, let's imagine that we're considering an application where we have some balloons, like weather balloons over a rural area, and they're trying to broadcast cellular signal. And the distribution we're trying to optimize is the distribution of cell signal over this area. The distribution of cell signal over this area. And if one of the balloons goes offline, we want the other balloons to kind of evolve their locations to distribute themselves well according to the desired signal. And so this is a case where you wouldn't necessarily want a stochastic method. You might want a deterministic method where ideally you can have some kind of convergence guarantees. And then lastly, while I'm going to be mostly focusing on the problem of drawing samples from a probability measure, sometimes Sometimes a sampling method will give you even a little bit more information, maybe help you not only draw samples, but maybe help you with density estimation or maybe the problem of drawing extra samples. So if I have a method where it does a great job of drawing, you know, n equals 113 samples, but then I go back and I say, oh shoot, I actually wanted 114, so I have to run the whole method kind of all the third one. And so it's classical that P And so it's classical that PDEs can inspire new ways to construct this empirical measure. And the best known example of this is Langevin dynamics based on the Flock of equation. So here we have the Focker-Planck equation, its initial value problem starting with some initial condition rho naught, and then evolving forward in time according to diffusion. And then here we have a drift term. And there you see the dependence on the desired target distribution of R. Target distribution from R. Why is the Fokker-Plock equation, why does this give us kind of a good source of dynamics for sampling? Under various assumptions on your rho bar, most simply if you assume that rho bar is strongly log concave, then you can show that solutions of the Falker-Flock equation converge to the desired target distribution exponentially. Target distribution exponentially quickly in time. So here I'm measuring the distance between solution at time t and the desired target distribution in terms of their Kolb-Leibler divergence. And so because what this tells us is that under these types of assumptions, on our rho bar, as long as our rho bar is sufficiently nice, then solutions of the Flock or Flock equation are flowing towards it really quickly in time, no matter what initial conditions pick. And so this makes it kind of a suitable choice of dynamics for Kind of a suitable choice of dynamics for sampling. Because the idea being that I can choose any row knot, maybe a really nice row knot that I know a lot about, and flow forward in time, and I'll get close to my desired row bar. And so to discretize this in practice, the most common approach is just to use the fact that this is a nice linear diffusion equation. And so I can discretize it with a stochastic particle method, with the Browning motion term. Motion term and a drift term. And you can show that if you initialize, you choose your rho naught as something you know a lot about, something that it's easy to draw samples from. So it's easy to approximate with an empirical measure. Maybe rho naught is just like a uniform distribution on the square or something like that. And then you evolve the locations of those samples forward in time according to this stochastic particle method. And then you can Particle method. And then you can show that as n goes to infinity, the empirical measure at the locations of the samples at time t will actually converge to a solution of the P D at time t. And then, of course, then by sending time n to infinity and t to infinity, you can expect to converge to your desired robot. Okay, so this is the basic idea underlying the classical approach. And just to kind of hammer two key points, hope. Here are two key points home, because this is going to be the spirit motivating a lot of what I talk about in the rest of the talk. Is this an example of kind of a particle method for sampling? So you start with an initial condition, rho naught, that you know a lot about, from which it's easy to draw samples from the Gaussian distribution. And then you want to evolve these samples forward in time in some way approximating the dynamics of your flow. And if we think about how does Langevin dynamics know how does logic and dynamics kind of stack up in terms of these classical or in terms of these considerations I said by which we should evaluate sampling methods you know we have convergence guarantees at least under you know appropriate assumptions on the desired target distribution for example if it's strongly non-concave it's a stochastic method it doesn't maybe naturally come along with a bunch of information for density estimation but it's great for drawing extra samples for Great for drawing extra samples because the evolution of each particle is independent of all the other particles. So, this is not an interacting particle system approach in contrast to the other two that I'm going to be talking about. Okay, so today's talk is going to be looking at two different types of dynamics, which we'll contrast with the Fokker-Plock case. So, the first dynamics that I'm going to talk about is this type of porous medium equation. This type of porous medium equation at the top. So it's a spatially inhomogeneous porous medium equation. So there's our rho bar that we're trying to approximate. I could expand this all out, but it gets a little messy, so I just expanded it out in the case where the desired target distribution is rho bar equals one, uniform distribution where you see the familiar course of equation. Why on earth would this type of PDE show up in the context of sampling? In the context of sampling. Well, one motivation, I'll give you another one in a second, is that again, under the exact sort of same hypotheses on your desired target distribution, you can again show that solutions of this equation converge exponentially quickly to rho bar. Okay, so you're flowing to rho bar really quickly, so maybe you could do the same thing here. Come up with some way to discretize these dynamics in terms of a quartz method. Now, the downside is this is no longer sort of a friendly. No longer sort of a friendly linear diffusion equation. So you can't just apply kind of off-the-shelf as sort of standard stochastic ODE techniques. So maybe it takes a little bit of thought to think about how to discretize this in practice. And the other dynamics I'm going to talk about is this PDE-constrained minimization problem. So I'll go into a little bit more about the interpretation of this. Little bit more about the interpretation of this. But in this problem, I assume that I'm initializing my density at rho one, or rho naught. This is my nice measure I know a lot about. And I'm assuming that at row one, it actually equals rho bar. So it's not just converging to rho bar as t goes to infinity. It actually equals rho bar at time one. And that I'm looking for a solution of the continuity equation for some choice of velocity field that satisfies this. That satisfies this source constraint, terminal constraint. And it turns out that there's a bunch of them, there's a bunch of rows and v's, which would satisfy this. And I want to find the one which has the smallest kinetic energy. Okay, so again, it's maybe not so obvious how to discretize this. It's a particle method. And I'll go into the details of our approach, but it turns out that for both of these equations, Turns out that for both of these equations, we are able to get some convergence guarantee. So I'll say kind of what we know and what we don't. I'd say the hope for a robust convergence, like, I think we could really hope to get a great convergence theory for the top. The bottom, it seems like we'll be able to know some things and not others. They're both going to end up being deterministic sampling methods, so that's kind of very different from the classical logic of dynamics. In this one, you know, the downside is I don't anticipate we're going to get as nice if the convergence theories. We're going to get as nice if the convergence theory is at the top. But it does seem to have really nice potential for solving some of these related problems in density estimation or kind of drawing extra samples. Yeah. Excuse me, so the second benefits you don't know the X etc. So right now I'm letting rhobar, I don't have any assumptions for the structure of the rhobars. So maybe it's not so surprising that the convergence guarantees will be less if we assume less of the Today, to kind of link these two different projects, I'm focusing a lot on the application and sampling. But at some level, all we're doing is just developing numerical methods for these two PDE problems. And these types of PDE problems show up in a lot of contexts outside of sampling. It turns out that this one is related to models of two-layer neural networks, not the neural networks we were hearing about in the previous slide, that these kind of These kinds of artificial neural networks. And then this problem, I'm talking about in this context, but I'll say how it can be generalized to a variety of problems in kind of meaning-build control theory. Okay, so I've given you a flash of the dynamics that we're interested in. Let me tell you a little bit about the optimal transport interpretation of these dynamics and how we use that. Of these dynamics and how we use that perspective in order to discretize them to develop our numerical objective. So, I think many people in the audience are very familiar with optimal transport, but I will tell you again because I love it so much, I could tell you a million times. So, if we're talking about the goal of optimal transport is how do we, we have one measure over here, a pile of dirt, we want to rearrange it to another pile of dirt optimally. But before we say how we can transport, But before we say how we can transport one thing to another, optimally first, we'll just say how can we transport one thing to another. And so, how we can transport one thing to another is we have these two probability measures. And we'll say that t transports rho naught onto rho one if it satisfies this equation for all bounded functions. And in this case, we'll abbreviate it as t transports rho naught onto rho one. And you know, intuitively, what's going on here is that. On here is that this function t of x tells you where mass starting off at location x in row 0 should get set to in row 1. And there's many different ways to rearrange row 0 to look like row 1. I can maybe push the mass in the middle a little to the out. That would seem like a pretty reasonable way to do it. I could do it in an unreasonable way. I could push the mass in the little out, and then I could switch the right and the left. And then I could switch the right and the left. Okay, but you know, whatever. Lots of different ways to rearrange row naught to look like row one. But we'll say that the Bosser sign distance between row naught and row one is kind of the optimal way to do it in terms of this notion of effort. So I'm taking the infimum over all possible t's that rearrange row naught to look like rho one, and I want to find the t that kind of minimizes this notion of energy or an effort. Energy or an effort. So, how I'm measuring effort is I look at how far I had to move the mass, like how far did it have to go from x to t squaring that and then summing it up over all of the mass in the plot. And so this does give you a true distance on the face of probability measures. It kind of makes sense. It's basically saying how similar or different they are in terms of how difficult or easy it would be to rearrange one to look at. Easy it would be to rearrange one to look like another. But for today's talk, I'm going to be focused on a slightly different formulation of the Gosserstein distance than I had before, which is a dynamic formulation due to Vitamin Rignier. And so, of course, just like I was telling you if I have a row knot, especially if I have a row knot that's absolutely continuous with respect to Lebesgue measure, there's a transport map that'll send that to any other measure. That will synth that to any other measure. And it turns out there's a similar situation if I, instead of thinking about just a fixed measure, I'm thinking about a measure that's evolving in time. So for any smooth curve, so rho from 0, 1 into the space of probability measures, so you can think of this as like a measure evolving in time, it turns out that there exists a velocity field. Okay, I'm not saying much about the regularity of the velocity field. It's L2 with respect to rho and time and kind of L2 and time. So that this continuity equation holds in some unique sense. And in general, there might be bunches of velocity fields. So I could have, well, well, okay, you can modify it in like a stupid way, but I won't say that. At least we know there exists one. And so what Penamoux and Brunier's result was, and it was kind of further refined in this nice textbook due to Ambrosio, Gili, and Sabaret. Textbook due to Ambrosio-Julian Sabaret is that the two Bosser sign distance squared that I told you on the previous slide coincides with this PDE constraint minimization problem. So thinking about transporting one measure to look like another in the most efficient way is the same as thinking about all of the different ways I can flow from one measure to another by satisfying the continuity equation and trying to make the And trying to make the kinetic energy of that contributing equation as small as possible. And so, this is exactly the dynamics that I'm interested in discretizing. Oh, yeah, this is like an amazing numerical simulation. And it really shows you how, kind of, yeah, by rearranging one probability measure to look like another, here the probability measures are. Here, the probability measures are gray-scale images. You're really looking at all the different ways to kind of flow from one to the other and trying to find the one that takes the least amount of effort. Okay, so this is the first dynamics we're interested in that we want to develop a particle discriminatization of. It would be great if we could do it. In fact, this dynamics kind of gives us a lot more information than we need, right? Like, not only, okay, we start at whatever row naught we want, we end up exactly at time one at the Exactly at time one at the row one we're interested in. And you might think, well, as long as I can just find sort of any way of flowing from row naught to row one, I would be pretty happy. Like that would give me a good way of drawing samples. But I'm asking for more. I'm saying we're not just going to flow from row naught to row one. We're going to do it in a way that makes the kinetic energy as small as possible. And so I think at this point it might be kind of fair to be like, well, right, you're trying to like yielding the lily here. Right, you also want the kinetic energy. The lily here, right? You also want the kinetic energy to be as small as possible. But this is an interesting piece because it turns out, I mean, maybe it's not so surprising, that there's a strong connection between the optimal velocity field here and the optimal transport map that I mentioned on the previous slide. You can kind of infer one from the other. And so, and what's nice about that, so if I could find a way of flowing from row naught to row one that's kind of optimal in this. To row one, that's kind of optimal in this sense, then I can infer the optimal transfer map. An optimal transfer map is something that has a lot of structure. It's always going to be, you know, under sufficient kind of regularity assumptions on row naught and row one, it's always going to be the gradient of the convex function. And being able to know not just how to flow from row naught to row one, but a transport map that sends me from row one to row one with all this nice structure, this could help a lot in kind of getting broader, solving other problems in addition to sampling. Solving other problems in addition to the sampling, like these kind of density estimations or problems of drying more samples. So, I'll say a little bit more about that later. So, at first, it seems like we're kind of asking for way too much, but this kind of gives us a nice, of the many, many ways to flow from row naught to row one, this gives us a really nice choice with a lot of good structure. Okay, so this was the second dynamics that I interested in. What about the first? What does that diffusion equation have anything to do with these optimal transport ideas? Yes. And so it turns out, you probably maybe have encountered this, is that this degenerate diffusion equation is a gradient flow with respect to this metric. So we have this two-Walserstein metric on the space of probability measures. And whenever you have a metric, you can at least define some sort of weak notion of gradient flow. We know what gradient flow is in Euclidean space. You just have some energy. Here, this is an energy defined on R2. You have some. R2, you have some initial conditions, and then you just evolve in the direction of steepest descent of that energy, kind of perpendicular to the level sets of the energy. And it turns out you can do the same thing with Bosser-Steinmetric. Bosser-Steinmetric has sort of like a formal inner product, so you can make sense of what it means to be evolving in a direction that's perpendicular to the level sets of an energy. And so, because of that, you can say what it means to be a Valser-Sein gradient flow. So, of course, in Euclidean space, a gradient flow. In Euclidean space, a gradient flow is just a curve in Euclidean space. Here it's just a curve in R2 that's going to where the energy is smaller. And in Wonserstein metric, a Walserstein gradient flow is just a curve in the space of probability metrics, or an evolving probability measure that's evolving to try to make the energy small as quickly as possible with respect to this Walserstein structure. And in fact, we kind of have already seen these gradient flows, and Heng Ji's talked. Already seen these breeding flows in Heng Ji's talk earlier today. There was like a bit of a modified Vosser-Seid metric with a different mobility. So the first equation that we saw in today's talk, the Fokker-Planck equation, turns out to be a Vosser-Seid gradient flow of the full back-Muller divergence. So solutions of this equation are evolving to make this small as quickly as possible. And this is kind of the second reason that one might be interested in this porous medium equation in the context of C pointoint. In the context of C point. This is a Walserstein gradient flow of this energy. I think from a statistical physics background, we think of this as kind of a Remni entropy. But if you come from a sampling background, you might think of this as just differing from the chi-squared divergence by a constant. So this is the chi-squared divergence. This is a way of measuring how similar rho is. A way of measuring how similar rho is to rho bar in a statistics context. But if I expand out the square and use that everything is a probability measure, it turns out that it's exactly equal to this plus a constant. And when you're doing gradient descent, the constant doesn't matter. So we can think of the Fokker-Poch dynamics. This is maybe what you would do for sampling if you wanted to flow towards rho bar as quickly as possible with respect to KL divergence. And then this maybe coarse medium type equation is what you want to do if you want to. Of time equation is what you want to do if you want to flow towards rho bar as quickly as possible with respect to chi-squared divergence. Other PDs that have arisen to the context of this conference already are the Fossette radio flow structure. You saw these types of aggregation or non-local interaction equations in the previous talk. He wrote K where I write grab K, so it only works if the interaction is great and you took a potential for. Interaction is a great neutron potential for it to be a Bostonstein gradient flow. And then I'll just flash at the bottom. There's been several recent works on looking at these mean field models of two-layer neural networks as a Bostonstein gradient flow. I'm not even going to write a PDE because it's so weird, but here's the energy. And what will be relevant in today's talk is that if your activation function in your two-layered neural network depends not necessarily on X and Z independently, but on absolute value of X. But on absolute value of x minus z, then it turns out that you can rearrange this so it's an example of this kind of energy. And this will turn out to connect to this force equation. Okay, so great. We see the connection between this force-median equation and optimal transport, but how is this going to help us at all with our ultimate goal of developing a numerical discretization of this that can be useful in sampling? Useful in the sampling. So, the key observation here is that all of these Alcerstein gradient flows are continuity equations where the velocity is kind of induced by the energy. It's the gradient of the first variation of the energy. And so, in a sense, kind of thinking about it from this way, this porous medium equation has a very similar structure as that P D constrained optimization problem, the dynamic optimal transport problem. In both cases, we have. Problem. In both cases, we have some sort of dynamics that are governed by a continuity equation, and we want to discretize this. So the natural approach for discretizing this, something along these lines, would just be to use a particle method. So let me give you a high-level idea of what this discretization is in a case where everything is really, really nice, which of course is not at all the case for the equations that I'm telling you about. But we'll start from here and then we can kind of, you know, add. Here and then we kind of add on the complexities. So let's assume that I have a continuity equation and it has a uniformly Lipschitz continuous velocity. And you can either think of this as like just a velocity that depends on x and t as in the dynamical optimal transport case. Or you can even kind of think of this as a velocity field that depends on rho. So, for example, in the case of non-local interactions, it would look like that aggregation equation would look like that for some fixed kernel, k. And so, but I'm going to assume that this velocity is really nice. So it's uniformly Lipschitz continuous in time, and also for now I'm going to assume it's uniformly Lipschitz in rho. So, you know, it's always just. It's always just super, super well behaved. And if my velocity field is that great, then I have a following scheme for approximating solutions of this initial value problem. Step number one is I approximate the initial data. So this is again getting back to the idea that we're always going to assume that our initial data is something we know a lot about. It's easy to approximate with my empirical measure. And then I take these locations of the empirical measure. Locations of the empirical measure, and I evolved them forward in time by this ODE. It's a system of ODEs because one of these for each of the i locations. But through this velocity field, we see that the velocity field driving the ith particle can kind of depend on the locations of all of the other particles. And so that's why I wrote this velocity field depends on empirical measure and time. This is saying looking at where all of the particles are. Looking at where all of the particles are at time t. And you can see that the fact that the locations of the particles solve this system of ODTs turns out to be equivalent to the empirical measure being a weak solution of this continuity equation. And then because I've put so many assumptions on my velocity field, you can even get these types of stability estimates saying, well, how different is the empirical particle approximation to the actual stability estimates? Particle approximation to the actual solution of my continuity equation, and we can show that you kind of control it in terms of the Lipschitz constant of the velocity field and the difference between the initial data. So as long as I can make this approximation as good as I want, as n goes to infinity on bounded time intervals, I'll know that this particle approximation converges to a solution of the original equation. Okay, so this is kind of the general idea for General idea for particle methods for a continuity equation. So, how can we apply this in our context? And the key problem is that certainly for both of these equations, there's no guarantees that that velocity field would sign by any sort of uniform sound. But for an aggregation equation, this would be okay as long as your interaction kernel or drift potential were sufficiently nice. So the idea is: can we introduce an appropriate regularization that somehow makes this a little bit more like this, gives us that nice behavior of the velocity field, and then we can do a particle method. So here's the idea. We know that this is the equation that we want to do a particle method for, but its velocity field is not nice enough. So the ostracize gradient flow of that energy. And you know, the idea behind particle method is we're sort of basically replacing We're sort of basically replacing our row with an empirical measure. And we even just see at the level of energy that that doesn't make sense. Like it wouldn't make sense to plug in an empirical measure here. This just makes sense, but you can square an empirical measure. So this inspired the approximation. So we say, well, what if we had kind of a mollifier there? Now, if we put a mollifier in our energy, now even if rho is an empirical Now, even if rho is an empirical measure, this is still a perfectly nice function, weighted set with, for example, Gaussians. We can square it, and that energy makes sense. And if you give me any energy, I can tell you what the Volscreen gradient flow is. So it turns out to be this PDE. And there's at least some hope that, you know, if rho was reasonably well behaved, this energy would converge to that energy. So there's kind of, it's not crazy to hope that somehow these dynamics. To hope that somehow these dynamics would approximate the original force medium dynamics. And now this is a little bit of a crazy, weird PDE because we have all these convolutions and everything, but at least this regularization solved the first problem we were confronting, which is now this velocity field is actually at least locally Lipschitz, though of course the Lipschitz constant deteriorates with epsilon as you Deteriorates with epsilon, as you would expect, if you remove the modifier. But now we at least know that for fixed epsilon positive, we can turn this crate I told you about on the previous slide and say what it means to be a particle solution of this PDE. And so particle solutions are just evolving empirical measures where the locations of the particles satisfy this ODE. You'll notice that there is an integral. There is an integral on the right-hand side in this ODE. That's where we see the appearance of the desired target distribution, rho bar. For the numerical simulations, I'm going to show you all of the rho bars that we pick, it turns out that this integral can just be computed analytically. So it doesn't have to be approximated in our scheme. In practice, you are actually dealing with a more unusual row bar and moving your weather balloons around to distribute. To distribute cell signals, this is an integral that you would want to approximate. But it's somehow saying that what matters is how the ith particle and the j-th particle sense the desired target distribution sort of through these mollifiers centered at those locations. So we know things are fine as long as epsilon is fixed and positive, but of course that's not what we're interested in. We're interested in ritual force meeting with. And so that leaves the question of what happens as n goes to infinity and epsilon goes to zero. There'd actually been a lot of previous work. I guess these things were all previous. Well, this last one, this one came out shortly after our work. But there had been a lot of work in this direction, though all of it had been in the case of rho bar identically equal to one. Identically equal to one. So this was looking at like a spatially homogeneous porous median equation. So this wasn't motivated by the sampling context. This was more motivated by the numerical PDE approach. And so our contribution was that as long as you know that your target distribution is nice, it's long concave, we additionally require it to be bounded above and below on some bounded convex domain omega. Convex domain omega. And then, as long as you are approximating your rho-naught with an empirical measure, pretty quickly, so this, you expect in these types of things, these types of blob methods where you have like a regularization parameter epsilon and number of particles in, that there's got to be some relationship between the n and the epsilon. Like, you can't send n to infinity too fast, those epsilon. Was epsilon, or see, you can't send n to infinity too slow as epsilon goes to zero. And so that's kind of what's encoded here: that n has to grow pretty quickly as epsilon goes to zero. And then the continuum initial data that you're approximating, it doesn't actually have to be that nice. It just has to have bounded entropy, by which I just mean like the integral of rho naught log rho naught has to be finite. So not too restrictive of the deception. Not too restrictive of the definition, then we're able to show that on bounded time intervals, this particle solution indeed converges to a solution of the PDE. So on one hand, we were happy with this. Like this is at least getting us kind of some information about what happens as n goes to infinity and epsilon goes to zero. A limitation of this result was that it was only on bounded time intervals. And of course, for sampling, you want to know what's happening as t goes to infinity. What's happening as t goes to infinity. And so, what's been kind of nice is that to complement this result, there was some recent work by Luz, Lepchev, and Wong that studied the convergence of the steady states as epsilon goes to zero. And so I think there's kind of hope that by combining these two things, one could ultimately attain global convergence in time as n goes to infinity, epsilon goes to zero. So we go back to the considerations we had for evaluating these different sampling methods. These different sampling methods. In terms of sampling using these dynamics, we do have convergence guarantees as long as rho bar is log concave. We can actually do this result without rho bar log concave. It just doesn't make as much sense in the context of sampling because you're not necessarily guaranteed to blow to it as t goes to infinity. But if you have an application that you want to use this with rho bar is not log concave, I can tell you why it's okay. It's a deterministic method. Maybe doesn't help. Maybe doesn't help as much with these extra points of distance of the estimation or drawing extra samples. Here, you know, you start with some fixed number of particles, you go to all this effort of solving this interacting particle system up to time t in order to draw the samples, and you would be really sad if someone said, oh, actually, I needed n plus one samples. You really kind of would. I mean, the good news is you could at least take the n samples that you got as the initialization, as the initial data. So you wouldn't be totally starting from scratch, but it's not like Lash Vivid Dynamics where each sample. Not like Lash of Dynamics where each sample's trajectory is totally independent, it's easy to throw another end. Here's just a few numerical simulations to give you a rough idea of what's going on in our method. So at the bottom, I have the trajectories of the particles. They're all initialized between negative 0.5 and 0.5 uniformly. And at the top, what we have is just a kind of a naive kernel density estimate of the particles, just to give you a rough idea of their. Particles, just to give you a rough idea of their shape and what measure they're approximating. And in purple, this is the desired target distribution. So that was just a uniform target distribution. This was a log-concave target distribution. This was something that was like definitely not log-concave. But in spite of that, if you look at the evolution of the density forward in time, it kind of does seem to agree fairly well, even with a relatively small number of particles. Of particles. Another nice part of our method is that I mentioned one of the reasons you would even be interested in this forest medium equation for sampling was because we had this exponential decay of the KL divergence. It's converging really fast to the desired target distribution. And what's kind of cool is we see that same exponential decay of the KL divergence at the discrete level. Now, of course, for a finite number of particles, it does saturate. Particles, it does saturate at some point, but as you have more and more particles, it kind of tracks that exponential decay long-world. And we see basically first-order convergence in the number of particles to the desired target distribution. Okay, so I told you a little bit about this first approach, this degenerate diffusion equation. Now, let's contrast that with these other dynamics. So, here we have the dynamical optical transport problem. How can we use these? Transfer problem, how can we use these same ideas of a particle method to discretize this? Well, at first, when you start going through it, you're like, oh, wait, this is really easy. I know how to do what to do with the row, row naught. I just approximate that by an empirical measure. That's what we did before. And I know what to do with the continuity equation because I know that solving a system of a continuity equation is the same as kind of solving a system of ODEs. Here I'm using an abbreviation. Using an abbreviation, that VIT is the velocity evaluated at the location of the ith particle. So we're like, okay, well, that part was easy. And then for the energy, like, well, this is actually not so bad either because rho is an empirical measure. And so that integral becomes a sum. We still have a time integral, but time discretization is typically the easy part, so you don't have to worry about that. And so at first glance, About that. And then, so at first glance, it seems like: okay, well, what was the problem? What new idea did you need? And the new idea is just how do you enforce this terminal constraint? Because, of course, if you're just looking at solutions of the continuity equation where the velocity field is sufficiently nice, if you start with an empirical measure, it's just going to always stay an empirical measure. And what if the rho what rho bar you want to practice approximate is not an empirical measure? Approximate is not an empirical measure. Or even if it is an empirical measure, how would you enforce the fact that the right particle in the source got sent to the right particle in the target? So that turned out to be kind of the tricky part. But because we had just finished this project on the force degenerate diffusion equation, the idea was to maybe take a page out of that. So what we do is we kind of soften this. Do is we kind of soften this terminal constraint, in a sense, with the same type of energy that we had in the previous project. So first you can think about this without that mollifier there. Just think about rho 1 minus rho bar squared integral 1 over delta. So this would make sense if rho 1 and rho bar were both square L2 functions. And then we know that as delta gets smaller and smaller, that constraint is getting. That constraint is going to get stronger and stronger. So when the delta goes to zero limit, we'll know that kind of minimizers of this will exactly satisfy that constraint. But just like before, where it didn't make sense to look at these types of integral of rho squared if rho is just an empirical measure, we have the same situation here. We know that this evolving empirical measure at time one is still going to be an empirical measure. Still going to be an empirical multiple so we can bolve the whole thing with a modifier. And now this makes sense. Okay, so we soften the terminal constraint, and then we just go through the same approach I did before. So here, I kind of jumped ahead, I plugged in that everything was an empirical measure, I expanded the square, and then I dropped the constant term. There's one term that just depends on how far, not on actually the trajectories of the particles. So I expanded a bunch of. Particles. So I expanded a bunch of things. But this is just to say that, you know, once you kind of plug in all these assumptions, you end up with this sort of minimization problem, depending on. So we're looking at all the different ways we can evolve particles from time 0 to time 1 that solve this sort of system of ODEs. This is what imposes that they're getting close enough to the desired target distribution at time 1. And then we want to do it in a way that makes the kinetic. And then we want to do it in a way that makes the kinetic energy small. And so now the last thing I'm going to do is I'm going to substitute in this equation for xi and kinetic energy. And then this leads to the optimization problem we wanted to solve. So we're going to fix our epsilon, that's the epsilon of the modifier, to be something small. We're going to fix delta, that's the penalization for the time equals one constraint. We're going to fix that to be really small. And we're going to fix the And we're going to fix the initial locations of our particles. This is the approximation of our row naught that we know a lot about. And then we want to solve, find what paths those particles should follow to make this as small as possible. Here, I wrote it at the continuous time level because I think it's easier to read, but of course, in practice, we actually do a finite difference even kind of just pretty similar. So, what are the good parts about this problem? So, what are the good parts about this problem? The good parts about this problem is: so far we have kind of no assumptions on rho bar. And in ongoing work, we're looking at the problem, but showing consistency with the original formulation of the problem as epsilon goes to zero, delta goes to zero, and n goes to infinity. And that seems to work well in the sense that we can show that minimizers of this problem converge to a minimizer of the original problem. To a minimizer of the original problem, but that's not quite as good as the previous project. Because all we're saying is that if you find a minimizer of this problem, we can guarantee that as n goes to infinity, epsilon goes to zero, delta goes to zero, that's close to the original problem. But how do you find a minimizer of this problem? Like, that's the tricky part. And indeed, we expect this optimization landscape to be non-conducts. And we have examples in the paper whereas. Examples in the paper, but where it's badly non-convex. So that's the downside. It's a non-convex minimization problem to find a minimizer. So thinking about the right ways of solving this non-convex optimization problem are going to strongly impact the performance of the method. We just started off with a pretty naive approach. We thought a little bit about how to initialize the method. Basically, we assumed that we are always able to initial That we were always able to initialize our method so that the particles went to the center of mass of rho bar. So we assumed we knew that piece of information. And then we just did gradient descent. So we did kind of a pretty naive optimization scheme. And even with that, you'll see that we actually get reasonable results. So kind of sort of not the greatest convergence guarantees, but reasonable performance in practice. Again, it's deterministic. Again, it's deterministic. But what I think is the most interesting thing about this method is that once we have the trajectories that are approximate minimizers of this problem, from those trajectories we can infer an approximate optimal transport map from row naught to row one. And once you know that, that's something that can be very powerful in terms of doing density estimation of the target measure and also for kind of drawing additional samples. Like once you know what the approximate optical transport map is. The approximate optimal transport map is, then you just have to draw more samples of rho naught and pass them through the transport map to get more trick samples of rho n. Okay, so now let me show you a few examples in practice. I'm actually going to end with the sampling example and start with a few warm-up examples. So here we wanted to compare the performance of our method, which can be thought of just a method for solving the optimal transport problem, with Problem with a more classical approach, like based on the Khodorovich formulation of the problem. So, here we have a classical approach. This was implemented by the Python optimal transport library EMD function, which is W2. And then this was the results of our method. So, here we have, we were looking at optimal transport between two empirical measures. So, the source is blue and the target is red. If you look carefully, they are slightly different. The paths that we computed are not exactly the same as the paths they computed. Exactly the same as it has been. You can also see that because we softened the terminal constraint, here you have, you'll see in black dots the actual final locations of our particles, and they're an approximation of the source measure. It's not exactly equal to the source measure. However, what I think is really interesting is if you compare our solution of this optimal transport problem with a more classical approach, just in terms of the value of objective. Just in terms of the value of the objective function, it turns out that they're basically indistinguishable. So, this shows how, you know, I said we're computing that approximate minimizer by gradient descent. So, this shows like as we do our gradient descent, how good is our approximate minimizer in terms of the value of the objective function, in terms of the amount of effort it took to rearrange this one to look like that one. And it turns out that both of these matchings are basically indistinguishable in terms of effort. And so, you know, that seems So, you know, that seems like a good thing to me. I mean, especially when you're thinking about optimal transport between empirical measures, there's not always a unique optimal transport matching between them. And so, you know, maybe we didn't compute the exact same one they did, but we computed one that was sort of indistinguishable in terms of the effort of the matching. I mentioned that this method is pretty flexible and can be used to solve other problems in control theory. So it turns out it's really easy to, for example, add an object. Really easy to, for example, add in obstacles. So, here we did optimal transport from a uniform measure on the grid to actually a continuum Gaussian. That's the mean and that's the standard deviation. And we said that the particles couldn't pass through this region. And so if you do optimal transport in the usual way with the Kantorovich formulation, it's a pain to add in obstacles because you have to be able to compute the distance between everything in the source and everything in the target. In the source and everything in the target around the part, the obstacles, the pairwise distances between all of the points. But for our method, we don't have to do that. All we have to do is add in some extra penalties to our objective function that tells the particles to kind of be repelled from those areas. So I think this is something else that's kind of interesting about this particle approach to dynamic optimal transport: it's easy to, for example, add in part obstacles, or you could even add in like a quicksand region. A quicksand region where, like, particles move slowly through that region, or something like that. So, it's very flexible to more complicated geometry because that would be kind of annoying to deal with with the usual control-energy correlation. And then, while I've only talked about this velocity control, trying to make the kinetic energy as small as possible, because that's what we see in classic optimal transport, it's easy to do other types of controls using our method. So, here we actually looked at an acceleration. Here we actually looked at an acceleration control. So here, this was the initialization, and this is the approximate minimizer. So the initialization was saying we're starting off the row naughts as they have, those are their initial positions, those are their initial velocities, and that's their terminal position and velocity. And the desired target distribution, the desired row one, has those terminal conditions. Terminal conditions and terminal positions and velocities. And we can see that after the gradient descent has been read, it really agrees well and kind of reaches those terminal positions and velocities in a way that at least visually minimizes the acceleration. So it can be useful in more general control theory context. And then lastly, I'll close with an example that's actually related to sampling. So here we were looking at optimal transport between uniform measure on a grid. Uniform measure on a grid. In the top, we had continuum Gaussian. So that's the mean one standard deviation to the standard deviation. And just for a visual reference, on the bottom, these X's, those are just IID samples. I tried to check actually what method they were drawn by. It's the numpy rand in function, but I am not actually sure what algorithm that is used for drawing these IIT samples, but it's probably something not going to be dynamics. It's probably something about the electron dynamics. And so you can see that the black dots, when you compare them to the red X's down here, they have much more structure to them. You know, that could be good, especially if you're using this sort of, is a sampling method where you want to be evaluating a lot of integrals. You know, quadratural integrals is maybe better if your samples have a little bit more structure. And then here I kind of we Here, I kind of just for fun, we said, Well, what if instead of doing optimal transport from the uniform measure on the grid to the continuum Gaussian, like we did up here, we did it to the samples of the Gaussian, the red X's. And you can see this is maybe an example that shows some of the flaws of the method. Because we just initialize them all at the middle to begin with, they don't find all of the samples in this pre-orderation. Things about premierization. And you know, maybe if I think in practice, if you wanted to make this approach good, even when you had like large gaps between samples or large regions where your rho bar was very close to zero, you would probably want to look at multiple choices of initializations and make sure that the approximate minimizer you were finding is a good one. Okay, so I'll close there. Thank you very much. Closed air. Thank you very much. So I think for the first method that you described, so you mentioned that the for the discrete particles, the KAL distance is also like exponentially. I'm just curious how is that defined for How is that to be defined for empirical matrix? You also have to regularize it. Exactly. So, what I was actually plotting up here was instead of, I mean, obviously, I'm not plotting the sum of, we're not plotting the sum of direct masses, it was a very kind of the most, the world's most naive kernel density estimate. So we were plotting that, and that was also what we were plugging into the KL divergence. So, yeah. So, yeah, you're absolutely right. So, approximation is required to make the KL divergence make sense when one measure is not absolutely continuous with respect to the other. There's a question between the relationship between epsilon and delta, right? And so for this one, it's epsilon and n, and at the end, the other one we have epsilon n and delta. So for this one, epsilon is the regularization, and n is the number of particles. And again is the number of particles. And then for the second one, we had. Yeah, exactly. For this one, we had delta for the penalization, epsilon for the kind of bandwidth or standard deviation of the modifier, and n is the number of particles. So yeah, so I think... And for your convergence result, do you have to have some? So for this one, we don't. For the consistency result, we don't need, but as I said, it's a bit of a weak result in terms of... It's a bit of a weak result in terms of just saying minimizers converge to minimizers, as opposed to like what would be a really like a result I would love to have would be to say, what if I do gradient descent on this problem defined the minimizer, and then I'm looking at maybe gradient descent of the continuum problem. Are those gradient descent dynamics in some way the same? And so both converge to the same minimizer. I think that would be a much stronger convergence result, but I'm not sure. Result, but I'm not sure how tractable that is. I'm not sure how late that one is. In terms of, for example, how well can you sample from the tails of the distribution because of penalty, I mean, you have this fixed epsilon, and I suppose that in regions where you have less points, this kind of a constraint is not as severe as in regions where you have points. Yeah, kind of the rough way to interpret these things is this is sort of some inner particle repulsion, is what this one is doing. Particles repel each other, and that's sort of forcing some searching, some exploration of the space. And then this is saying that if a particle gets somehow within epsilon of a place where rho bar puts mass, it will be attracted to it. But you're absolutely right that if it's more that it can somehow the particle can only see what's like within distance epsilon. What's like within distance epsilon around it? So, yeah, that's definitely an issue. For example, yeah, there's some bimodal distribution with a really low region in the middle. It's like how will the particle kind of explore that? So is it, I mean, can some of these methods, like say, you know, comboing with a kernel? I mean, is there a way to say do something more based on nearest neighbors? So supposed to just base on. Nearest neighbours, so supposed to just based on distance, you say, like, oh, we're gonna fix. I mean, this is kind of like a a convolution, but say uh density-driven somehow. Like, it depends on where you are, your radius would be expanding or not. And in the implementation, I guess you'll be just checking all the time who are your cases. Yeah, I think adaptive choices of epsilon and delta make a lot of sense. Like, to me, it makes a ton of sense. Like, if I was going. Uh, like, if I was going to, you know, if I'm doing this, I'm finding this approximate minimizer by gradient descent, and we looked a little bit at this, but then we'll let we leave that for the next paper. But, you know, something that seems very reasonable to me would be to start off with epsilon and delta somewhat large to kind of encourage sort of exploration of the space. And then after you feel like the particles are somewhat in roughly the right region for rho bar, crank epsilon and delta down so that they kind of snap into place. Because what we see in some examples. You know what we see in some examples that we go back to this one. The thing is, obviously, like if epsilon is really big, the red x's are going to be too far from the black dots. But they'll be in sort of roughly the right area. And so maybe you get to sort of a rough distribution of points that epsilon larger than dialogue domain. So this concludes our first day. I will rejoin tomorrow at the same time, 9 o'clock. So about the way you approximate your end, right? So you essentially just take your modifier and you modify the device, right? So the energy, you look at all this example, right? It has just the same form. It's the V squared times the next, right? So let's say V is As an opposite case, but you work on yourself. The modification usually shows some programming. The turbulence which is well adapted to particular density. So what that is is the power. So you take your P, then you multiply by density, and then you multiply, then you divide. Mm-hmm. Then you divide by modify eight second. Yes, yeah, yeah, yeah. And then you modify one second. Okay. So let's call this E epsilon. So if you look at it for this particular case, right, then the robot cancels, and then you simply have a rho evolution of V epsilon, rho bar evolution of V epsilon, and another evolution. So, the advantage of this is actually regardless of any features overall, or any smoothness overall. So, there's this theorem that you can prove that E minus R X modified if L V R is going to be bounded by epsilon to, let's say, So this is one interesting property. Another interesting property is that it's actually symmetric with respect to inner product when it Inner product, relative related inner product. So if you take, let's say, two velocity bits relative to one, right? It's gonna switch. So it's kind of very natural. I mean, the original modification, just straight modify with B, that's not gonna be the same. Right, because then you'd have to pull them up the map that everything's gonna be. Yeah, but but the way this algebra works out is that it Works out is that it checks out to semi. Okay. So we've used this a lot. Turbulence and well, and this is a game that we like constantly have to play with. And this does the job. So you'll continue like the case for the quality of the game which is actually simply just for all. Yeah, it's really not, especially if you think that, like, I mean, as long as our robar is something nice, this is going to be pretty close. This is going to be pretty close to Robart. So, yeah, so in that way, it's it actually just say like yeah, yeah. Oh, that's not the right thing. Yeah, sorry, so yeah, so for So yeah, so for us yeah so the diff here's the difference is that let's see so in our velocity is actually it's well I guess what I write is V is the greatest, but just ignore the greatness. And so the difference is I don't have the modifier volume. That's right. Well what you do here is you modify just the row. Exactly. So I can volume row in parentheses all of that divided by row volume. Yeah, so what I'm not doing is modifying the star. How about the same? Yeah, and I agree. Yeah, from like a numerical perspective, that should be a distinguishable that my husband's favorite. Maybe you can get better convergence results or more guarantees. So this particular modification is called Fabric Innovation. Fogrems. It was used for modeling your driven so for non-homogeneous fluids, gaseous stars, and then this modification here we used it with my student Trevor and then I actually explored it quite in detail on my breakout. So because it fits very well. So I try to stick it anywhere. So I try to stick it anywhere I see everywhere I see. Well and it reminds me very much of in this book just out of that factor. I think I've seen this. That's the thing that would really help me. Help me. But they see since it's the same way. So here they're looking at, again, solution. So they're looking at a solution of the continuity equation, and they regularize the mu. Yeah, so this is probably. But you have to boot one more in order to ensure that you have the symmetry. Yeah, yeah. And actually, the symbol symmetry. So what they're doing is the exact possibility. Well, there's the exact possible problem. I'll try that. Yeah, yeah, no, I'll look into that. Biology or maybe some sort of function of it. And it could take different forms, right, for different velocities. Right, well, it's a general velocity. Of course, what we're interested in, what we're working on now is. In what we're working on now is, of course, what we would love to do is heat equations. We were thinking about rho bars identically one, then we were doing course medium, but what about heat equation or even like fast equation equation? Yes, so that it's not a knowing how to do that. So this is something we're working with right now. But yeah, then there's a lot of choice, like exactly where do you put the mollifier with respect to VM and things like that. And things like that. Yeah, the sort of, this is what we call the modifier exchange. This is always like the hardest part to deal with. Yeah, because when you have weighted spaces, the modifier doesn't just switch. Right, right, right, yeah, yeah, yeah, yeah. Yeah. What is it? Legacy. Yeah. Commutativity of the modifiers great when you're integrating its multi. Alright, okay. Of course, we have a specific setting, but say the mixing rate of the markup change somehow from, let's say, at level N, from C or level N, somehow that mixing rate or not in a given one doesn't, uh but but somehow uh the question was The question was: does assembling the generate position kind of make this thing bigger? So that's why I was kind of curious if there was some notion of you're making finer and finer approximations. Yeah, that is what you should do that. And I what what is that I'm curious about my physical path? So it's called It's fewer than the code for cycloproxygen here. So it's something that has the keywords on the scalability of sampling algorithms. Algorithms. Probably that's not the first part of the title, but it has those words. And so this was based on Tom So Andrews or had like this when you're doing something in the function space, then there are some of these some methods that are designed to basically have something similar. So then, I mean, a lot of the point that Andrew's was this is with Andrew's correct? Yeah, so oh no, this is not what Andrew but with this with uh This is not more than this for the hundreds of students. But Andrew had proposed kind of these methods for, you know, like when you have a first problem in a function space, okay, how can we guarantee that this Have a sampling method that at least mathematically, you know, it's sense that he's not going to. Not like his concern is what if you discretize first and then post some something method and what happens is that something method degenerates. What he would push for is this idea of no, do everything and the function space, do the method, and then later you discretize is kind of like different from discrete. Exactly. And so but somehow so the idea was that there was an analog, let's say, method that you could do inspired by what you would do in the functions. Trying to do something similar at the discrete level, and then if you do have some sort of stability tone, then you can say, oh, you know, as I said, Like, oh, you know, as I disproportionate more and more, my sampling scheme is not going to start kind of misbehaving or something like that. So it was along that line. Yeah, I mean, that was also like the whole thing with the big one sufficient. And my my I mean uh if I remember like the things that we were doing there again. Again, different contexts, but somehow the behavior of the sampling algorithm, like the knowledge generating, was very strongly connected to how well you could approximate behaviors and some of the operators that define the for whatever person. So, I mean, now that you have changed kind of the setting, or let's say you send it the setting, knows how those two things work. 