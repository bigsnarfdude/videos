Thank you for having me here. It's a pleasure to present both of you. So my name is Sober and I'm going to talk about my joint research with my colleague at UCSP and Georgia Tech, Akash and Samuel Kugen. I work with them at Georgia Tech and Sasha and Henchesko. I was a postdoc at UCSP. I did some work with them. Some work with them, and the results that are presenting in these slides are based on these networks, and based on the papers that I have mentioned here, you can find them on our website also. Okay, so let me start by the motivation of this whole talk that neural networks are being employed more and more frequently as controllers in dynamical system. And most of these applications are in safety-critical application, where it's important to ensure or verify the safety of the system. Ensure or verify the safety of the system. And this becomes much more critical in the scenario that we have a neural network as a controller because usually neural networks have some features which makes it a little bit more vulnerable to perturbation and disturbances. For example, they have a large number of parameters and they're non-linear. It's known that they have a sensitivity, lower sensitivity to input perturbation. Instances of this is studied as adversarial perturbation. And also, usually they And also, usually they are trained with very limited safety or robustness as an open loop, and of course, in the closed loop, you cannot ensure anything. So, as a result of all these features of neural network controllers, it's important to study to develop algorithms to ensure that they are safe and be able to verify them. And the main challenge that I'm going to address in this talk is to come up with algorithms which are sound, which means that they can ensure that you're They can ensure that your closed-loop system is safe and they're computationally efficient and fast because usually we need to do these in the runtime and we have to ensure that our neural network is safe. So our algorithm should be very fast and computationally efficient. So in this talk, I am going to study the safety of this closed-loop system from a reachability analysis perspective. So what do I mean by this? I consider the closed loop system as a dynamical system with a state in Rn. system with a state in Rn and disturbances in a set W. I don't assume that I don't know the disturbance. And also, but I know that it's in set W. And also I assume that I don't have access to complete measurements of our initial state. So we have some region, like initial state region here, which our system can be here. And we want to see where our system evolved. And a very natural notion to study this is the notion of reachable set, which I defined it here. Ritual set, which I defined it here, and it tells you exactly based on different disturbances, different initial sets, where do you end up? And we can define a ritual set based on that. And the kind of safety problems that we study in this talk is whether this ritual set is inside target set, whether I achieve some target, for example, some goal that I have, or whether I am avoiding an unstable dangerous region. And all of these can be expressed in a set theoretical perspective using these regional sets. perspective using these rich males. The problem is that usually for these non-linear systems, exact computation of richable sets is complicated. So what we what usually in literature people come up with is over approximations of virtual sets and they want to come up with this over approximation in a very composition and efficient way at the same time having enough accuracy that can ensure that we never enter unsafe set or we always get to the target. So I have to mention that the reachability and also So I I have to mention that the reachability analysis of dynamical system is an old problem. It has several approaches exist in the literature. But most of these approaches have this problem that they are either not fast, they are very slow and not scalable to larger scale system, or they're only applicable to linear system or very specific classes of system. And here we want some kind of a general approach which is fast and computational efficient. Okay, so my approach here is based on two frameworks, two mathematical frameworks. Two frameworks, two mathematical frameworks, contraction theory and monotonous system theory. They are both frameworks in control and dynamical system. And I'm going to use them to come up with these kind of algorithms for approximating reachable sets of dynamical systems. So let me briefly review what's contraction theory. Contraction theory is essentially a framework for stability analysis. So a dynamical system is called contracting if the distance between every two trajectory of the dynamical system increase or decrease with a rate with an exponential rate C. With a rate, with an exponential rate C with respect to time. If C is positive, so this distance is increasing, so the trajectories are going away. If C is negative, they are moving toward each other. And in the literature, contraction theory has been studied, for example, for convergence of dynamical system to reference trajectories, for input-output-robosis of dynamical systems, for entering to periodic orbits. But in this talk, what we want to focus is using attraction theory. Focus is using contraction theory for reachability analysis to understand over-approximation of reachable sets using contraction. So, the first, before I go to this reachability analysis, let me tell you exactly how we can characterize the contracting dynamical system. So, the definition that I gave you about contracting dynamical system, it requires finding solutions. And it's impossible to find all the solutions and check if they are converging to each other or directly. But it's interesting to see if we can find conditions on the vector field of the dynamical system. On the vector of the dynamical system to ensure that it is contracted. And the answer is a classical problem. It has been studied very well in contraction theory literature. And the notion of the key here is the notion of matrix measures. So if you are given a matrix and a norm, then you can define the matrix measure of matrix A with respect to the norm that is given using this formula that you can see here. So you can interpret this formula as the directional derivative of this matrix norm. Directional derivative of this matrix known in the direction of matrix A at point I. So, this matrix, this notion of matrix measure, this is a very popular notion in other things also, but it doesn't have the same name. So, for example, in numerical analysis, they use the notion of one-sided which is functional, which is related, which is very closely related to this topic. Also, notion of logarithmic norm is exactly the same thing that defines. The same thing that we define in the L this measure. So, the nice thing about this matrix measure is that for a good number of knowns, L2, L1, L infinity, diagonally related ones, we can find closed form formulas for matrix measure of a given matrix A. And these formulas are very closely connected to the norm, to the associated norm, associated weighted two norm, L1 norm, and L2 norm. But they are a little bit different, as you can see here. This is lambda marks of. can see here this is lambda max of a plus a transpose here for mu1 you don't take the absolute value of the diagonal element and the same for mu2 so they're closely connected but they're they're different um and you can see that these matrix measure unlike norm they can be negative or positive whereas the norm of the matrix is always a positive or a zero okay what is eta uh eta is uh right now it's a weight I consider it as a diagonal weight so all of these are diagonal this is like So all of these are di this is like matrix measure of matrix A with respect to L2 diagonally weighted L2. And this is diagonally weighted L1. So this is the induced norm? This is the induced matrix norm, exactly. Right. So matrix measures are defined for matrix norms. So this norm that I use here is L to eta norm, which is induced matrix norm from L to eta on the vectors. Diag eta is a matrix located down the main diagonal? Exactly. Exactly. Exactly. But does anyone in the literature talk about this as being the derivative of the norm of the identity in the direction A, which I think this is? Well, I... Yes, they talk about this, but it's not that much of a useful discussion. Oh, I see. Okay. I agree. I just wanted to explain this funda in a in a way, so I put it here. But it's, yeah. Oh, I didn't notice those on your slide. I'm sorry. Oh, yeah, I yeah. Oh, yeah, I okay. So, the classical result in contraction theory is that we can use this matrix measure of the Jacobian of the vector field of our dynamical system to completely characterize contracting to our system. In other words, our dynamical system is contracting with respect to a norm with rate c if and only if the matrix measure of the Jacobian is always less than or equal to c for every x and x d. So, this is a very classical result in our contraction theory, and this is. And contraction theory, and this is in the ink in the same model description. So we have derivatives here. There are other forms of it, which is invaluation of it, but I'm not going to. Okay, so I think this is my review of contraction theory. So can you start? When you have a map, and for example, here you have a volution of a differential equation, you say it's contracting with respect to so it can go back. Normally one thinks of it as if you start from two different initial conditions, you get close M and all. You get closer, even normal. That is. That norm is the Euclidean norm for the X's. And there's a little bit of a precision, at least it confuses me. Because you're talking about contraction of the differential with respect to Euclidean nodes, and then we're talking about the matrix node. My apology. Yes, this matrix node is not. So these are these two different nodes. This is the matrix node induced from that. This is the matrix norm induced from that, the norm on the RN. My apology, I should have. Any matrix norm. No. Oh, it's the induced norm. It's the induced norm. Yes. For the underlying thing. For the underlying. Exactly. And that's contracting with respect to the norm down below. Exactly. My apologies. I should have mentioned that. Yeah, this is the induced norm coming from the norm on our AM. I forgot to mention that. Thank you. Any other questions? Okay, so let's see how we can use contraction theory to study reachability of a dynamical system. And I think that this result is a little bit trivial. So what we do is that we take one reference trajectory, one reference initial point, and one reference disturbances, and run the system along that. And we say that because the system is contracting, then we can find bounds over this trajectory where my system is evolving, based on this. Based on this. And that's exactly what this formula is telling you. It says that if we start from a ball with respect to norm that is given here, with radius r1 and x0 star, and if our disturbance set is again another ball, then we can say that our reachable set evolved in this ball, and it's contained in this ball. And you can see that the center of this ball is the solution to this dynamical system, this is the trajectory that we. To this dynamical system, this is the trajectory that we picked. And the radius is given by this number, which, as you can see, is a function of time. And I want to mention that if c is negative, you can see that these terms, these two terms, cancels as time goes to infinity. So we end up with a constant therapy. If c is positive, this spawns goes to infinity and larger and larger. So I'll give a sketch of proof of this because I think this is important for the later slides that I want to. For the later slides that I want to talk, but it's a very obvious, so it's not a very accurate proof. So, how do we prove this? We consider another trajectory of dynamical system associated with some W. And we use the Taylor expansion. We can write this expression using the Taylor expansion as this, just a higher order. And this is kind of an identity that we have. And then what we do is that we compute the upper Dini derivative of the norm of xt minus x star t. This is the definition of the Dini derivative of Gaining derivative of this norm. And as you can see now, I can use this identity that I showed you in the previous slide. And if I replace it and I ignore the higher order term, I will get something like this. Then if I use the triangle inequality, I can separate this A and B part. And you can see that these two red parts, they are actually this mu infinity definition that I have. So I'm sorry, the mu of A that I have. And then I get this distribution. So this is exactly something like a. This is exactly something like. So, and another thing is that if I assume that my the my system is contracting with rate C and the norm of the Lipschitz bound of F with respect to data mu is upper bounded by L, then I can replace this mu and this norm of B with C and L. And what I get essentially is a generalized differential inequality. Inequality and I can use generalized Gronwawl inequality to find the bound that I have in T. So this bound is exactly coming from applying a generalized version of Gronwawl level to this inequality differential inequality. So as you can see here, this C is a contraction rate of my dynamical system and this L is Lipschitz bound with respect to the disturbances. This C is a scalar which kind of captures the effect of the states on each other. The states on each other, and L is a constant which captures the effect of disturbances on your states. So, but these counts are usually very conservative. And there are several reasons for that. One is that C and L are usually a global constant. So you have to maximize this mu and norm on the whole status space. And this becomes very large now. It becomes very conservative. And as you can see, it's also a little bit conservative because it's Because it's reducing a dynamical system to a scalar system. So it's ignoring the effects of the positive and negative effects of different components on each other. But this gives us some intuition, especially the bound that we found here, it's nice in terms of it gives you explicit formula on how these bounds are evolving by time, which is very interesting, especially in the case when C is negative, we can see that it can. So when is C negative out C typically? C is I mean, that is a an aspect of the dynamical system, right? Right. And so C is negative when you have what kind of dynamical system? So it depends on the norm, of course. But the the dynamical system is contracted. So it means that if we keep it uh the the disturbances constant, then all the trajectories are converging to each other. All the trajectories are converging to each other. If C is positive, it means that if we keep the disturbance constant, the trajectories are going away from each other. So if you want to consider a linear dynamical system, for example, x stop equals Ax plus B, then this happens when A plus A transpose is positive. In the L2 norm. In the L infinity norm, when it's diagonally down, diagonally row down. And L1 norm is And L one node is uh diagonal column uh dummy. Okay. So uh yeah. Uh so this is this is a little bit of over conservative uh constant, but it's useful because it gives us some explicit purpose. So so here I want to introduce another form of bounding of dynamical system, and I will see how this interacts with this contraction-based bounding. So let me start with the definition of monoclonal dynamical system. So let me start with the definition of monotone dynamical system. Let me start to say what's a monotone dynamical system. So dynamical system is called monotone if I start from two points where one, two initial points, where one initial point is larger than another initial point with respect to a cone. And also if I start from two disturbances where the first disturbance is less than or equal to another disturbance with respect to another cone. And if this hold for a monotonous dynamical system, the trajectory of the first system is always going to be Of the first system is always going to be less than or equal to the trajectory of the space system. It means that the trajectories during the time they preserve the partial. So, this is a definition of monotone system. It has been studied very extensively in the literature. And there are characterizations of, I think, in this picture I showed how this is, so this x prime is larger than x. And this monotone, always, when we evolve a system, it's always the trajectories are preserving that partial voltage. And there were several conditions for categories. And there are several conditions for characterizing this monotonicity. So for example, here I showed how we can characterize it for polyhedral cone. We have half a space representation and vertex representation. This is of this form and this of course exists in the literature. And then when we have a standard order, where our cones are standard cones, then we can check that this dynamical system is monotone, if and only if the Jacobian with respect to X is Metzler, which means that it's off-diagnosed or positive. It means that it's off-diagnosed or positive, and the covariant with respect to that diagram is positive. So, this is essentially the things that we need from monotonous dynamical system. And one very nice feature of monotony costs is that their reachability can be characterized by just evaluating two trajectories. So, you evaluate the first trajectory starting from the lower initial condition with the lower bound of the disturbance, and another trajectory from upper initial condition. Trajectory from upper initial condition with the upper bounds. And these two, because of the partial order between the trajectories of the system, you can ensure that your reachable set is always between these two bounds. Okay, so for example, I showed it in this example that this always happens, that if you start, if you have a disturbance which is hyper rectangle, and if your initial condition is always hyper rectangle, then you can bound your virtual set very easily using. Your reachable set very easily using just two extreme trajectories. So one thing that that happened that the one question that arises is that now I have one way to bound my trajectories using monotone dynamical system. I introduce something based on contraction based. How do these two interact with each other? Which one is better? So it turns out that the monotone way, if your dynamical system is monotone, it's better to use this monotone way. A monotone-based contraction, monotone-based reachability, because it's better than any diagonal-evated L-N-fultino contraction base. And you can prove it, and the idea is very simple. The reason is that you can see that these two trajectory are always in the reachable set, and as a result, there is no hyper rectangle better than this hyperrectangle that can contain relations. So, if you come up with any other If you come up with any other contraction-based approach, it's not going to give you a better value. So, this monoton-based approach is a tight compared to any other approach. Okay, so how about non-monoton dynamical systems? Monotony systems are not a large class of systems. There are many systems who are not monitored. What can we say about it? Unfortunately, these two extreme trajectories would not provide upper and lower bound for trajectories of non-mounted magnetic systems. And we need to do something. Dynamical system. And we need to do something else. So, what we do here is that we embed our non-monitor dynamical system into a larger dynamical system, and it's such that that dynamical system is modeled. So, the idea is that, let's assume that we have this original dynamical system. We want to embed it into another dynamical system in R2n this time, where this d is called a decomposition function. And the idea is that this t is a That this T is separating the cooperative and competitive effect of F. And on the diagonal, when x underscore and x underscore are equal, and w underscore, w over score are equal, f and d are the same. It means that this is actually contain of the original system. So this means embedding system contain original system. This means that it's separate the cooperative and competitive effect. And it can be shown that embedding system, if you can find such a D, this embedding system is a monotony. This embedding system is a monotonic dynamical system with respect to the southeast order. And southeast order is defined like this: if x, x hat, y hat is southeast order if this one is less than this, and this one is larger than this. And this is exactly associated with the cone of r positive times minus. So now this is this is very nice because now we embedded our original system into an embedding system, which is now it's marked. This embedding system is marked. Now I can Embedding system is not. Now I can use all the techniques for monotonous dynamical system on this embedding system to find reachable sets of my overarching reach. So the idea is simple. If we have a disturbance which is hyperrectangular, if we have initial condition which is hyperrectangular, just you need to simulate one single trajectory of the embedding system starting from x underscore x underscore. And at every time x, at every time t, x underscore and x underscore program. x underscore and x underscore provide a hyper rectangle which contains your reachable set. And the idea is that this is a monotony system. It contains my original system as its embed, as a part of it. And as a result, the original set would be in this dynamic system. You can consider these di's also as the rate of change of the edges of the rectangle that we have. And this is a very scary And this is a very scalable approach because what you need to do to find our approximation is just run a single treatment of it. So let me show you how this embedding system looks like for linear system. So if you have a linear dynamical system, we introduce this Metzler non-metzular decomposition that if you have a matrix, you can decompose it into two parts. The first part, it keeps the diagonal as it is. Keeps the diagonal as it is. And for the off-diagonal elements, it keeps all the off-diagonal elements which are positive. The non-negative ones become zero. And the non-Metzler part, it only keeps the non-negative of them. And using this decomposition, we can show that if our original system is linear, the embedding system has this very nice form, closed form. And one nice thing about this embedding system, specific embedding system that I constructed here is that it also preserves the interconnection structure. The interconnection stress. So, if for example, here you can see one and three are connected and one and two are connected, and the same is with the embedding system. You can see that the two states which are associated, upper and lower bound of x2 and x1, are connected, and x3 and x1. Okay, so this is for linear system. We can find embedding systems for linear system, run this system with single trajectory, find the over approximation of each of the sets. So, how about non-linear systems? So, how about non-linear systems? So, I will show you using an example. So, let's go back to the example that I showed you. It was not monotone, but we can decompose it into the red parts, which is the monotone part, which is a cooperative part, and the blue part, which is a competitive part. So the cooperative part, if you look at this, the the the Jacobian with respect to x is always positive, the Jacobian with respect to L is positive. The non-cooperative part, the Jacobian with respect to X is always negative. X is always named. And as a result of this decomposition, we can find the decomposition functions like this by collecting the red parts together, blue parts together, and then we can find the embedding system as this. One single trajectory of the embedding system and find these two points which are the variable simulation of our regions. So you might say that this is a very special system. You could see by just looking at the system how you decompose this thing. So is there any systematic So, is there any systematic way to find this decomposition function? And the answer is yes, we can find this decomposition function. Actually, we can find the best decomposition function using these formulas. So, essentially, these optimization problems are saying that on a rectangle, I am maximizing the effect of electrophase on the upper edge and minimizing the effect of electrophase on the rectangle. So, if we can find, if we can. So if we can s find, if we can solve this optimization problem, we can find the best decomposition function for our dynamical system, which gives us the best, tightest over-approximation of richness. Unfortunately, these optimization problems are in general not very tractable. So essentially, what we do is that we can solve them for some class elementary systems, elementary vector fields, like exponential, sine, cosine, and then write a general system as a composition of this elementary function. Or we can use some Jacobian. Function, or we can use some Jacobian-based approaches and come back to the linear system phase and find a connection with the linear system. So there are some ways to handle this problem with non-factor data systems. So the final thing is that now how about the tightness of the mixed market bounds that we found? How how does it compare with the contraction based approach that I mentioned to you? Based approach that I mentioned to you. And indeed, there is a theorem here which we say that if we have a dynamical system, if you have a dynamical system, and if we can find the embedded system using the tightest decomposition function, and if this is this, then they have the same contraction. So this means that the mix molecular reachability is at least as good as contraction reachability with respect to beta L infinity. So we are not losing. Um so we are not we are not losing anything by doing this amount. Okay, so uh I think with this I will I will uh I don't have too much uh time, but I will stop the I will I will uh end this discussion about the general framework of reachability analysis and come back to the reachability analysis of neural network closed loop systems. So, what we have is that we have a dynamical system, an open loop system here, which has been which we are using the feedback of the form of the Of the form of a neural network. I assume that this neural network has been trained offline, so all of its parameters is known, there is no learning of it. And what we want to do is that we want to study the reachable set of the closed-free system, which is the reachable set of this one. So finding the reachable set of this one based on the framework that I mentioned to you require finding the composition function of the closed-loop system and running single trajectory. However, this is a little bit complicated because neural networks are identified. Complicated because neural networks are high-dimensional, they have a lot of parameters. So, what we do here is we take a compositional approach. We find the composition function for the open-up system, we find some bounds for the neural networks n underscore n underscore using the existing neural network verification algorithm, and we kind of combine these two to get the composition function for the closed normal system. So, let me tell you a little bit about how Let me tell you a little bit about how this bound for neural networks works. So, what we need from a neural network is that if we have an interval, z underscore zero underscore, we want to find bounds like that where our neural network is upper bounded and lower bounded by the groups. And indeed, many neural network verification algorithms, they give us these kind of bounds. For example, Crown is one of these popular neural network verification algorithms, which gives you a bound of linear form. This is based on linearization. This is based on linearization of activation functions. And indeed, one can modify this to get bounds of the form that I mentioned. So using this bound and open-width dynamical system, we can compose them together as this to get a decomposition function for the closed-wood system and run that dynamical embedding system to get upper bound and lower bound unreachable set. So let me tell you exactly how this This composition works. So, if we have our original system, this is my open loop system, this is my neural network. So, in the embedding world, I have an open loop embedding system for my open loop system. I can find it using the techniques that I mentioned before. And I have this bound from neural network, which is coming from some of these neural network verification algorithms. So, the way I compose these two is that I will find the lower bound and upper bound of the neural network on these intervals, and then I On these intervals, and then I evaluate them on the corresponding axis, and then decompose them together, and we get the decomposition function. So, I think with that, I will stop here and I will go to the conclusion. So, what we did is that we studied missed monotonicity-based and contraction-based reachability in this talk. I studied the connection between these two concepts. And finally, I proposed a compositional-based approach to study reachability sets. Approach the study which both sets of a neural network controller with a diagnosis. So, if you have any questions. Yes. So, just conceptually, I mean, I think of neural nets as things you train and you have data that you train them on. I mean, but once it's trained, you think of it as just being a function. That's what it looks like. A function, but that's what it looks like. It's just a function. It's just a function right now. But it has a lot of parameters. And it makes things much more complicated if you want to do reachability analysis in a closed-loop system. So you have a closed-loop system with a lot of parameters, a lot of non-linearities, and you want to do it very fast. Most of the algorithms which exist in the literature, they cannot come. When the number of parameters goes very high, they cannot comp. Parameters go very high, they cannot compute each other sets very fast. Thank you very much. I have lots of connections with things. In connection to the question that John said, again, at the end of the day, somehow the analysis relies on the bounds that you're given from training the use function. That is true, yes. Which are linear. Here, yes, I am. Or at least a file. Yes, I assume. Or at least a fine. I assume that I have a fine bounce. Can you get tighter than a fine bounce? Yes, I think Crown itself, in the paper, they mentioned that they can get quadratic bounces. Quadratic bounce. They are more accurate, I agree. Another thing that's more like a comment, and I'm not sure, but it looks to me that for more consistence, more consistency. The modern system should be very closely related to the geometry of the Hilbert metric, the one I talked before. Like, for example, at least it should be possible to show relatively easily that monoton maps are bounded in this Hilbert metric, you cannot contract it. And there are some theorems for non-linear evolutions. They are, okay. Unfortunately, I'm not. Hilbert metrics. I think. So again, I don't know if it will give. Again, I don't know if it would give additional things, but things need a different angle to get. Yeah, thank you. I think that was very interesting. I remember Rodolphe's a popper, he talked about this. Monotone. Right. Yeah, he mentioned he worked on Hilbert metric. He mentioned Hilbert metric, but I'm not sure if he has studied. Oh, yeah, right, right. He had a work. He gave a talk at UCSB. He already talked about this, but I don't know the connection. But I thank you for that. Yes, for mentioning that. Thank you for that. Yes, for mentioning that. It might be atrophone? Yes. So, this is what was the question exactly? I mean, if you have a system, right? It doesn't matter how non-linear, how unbounded, or whatever, it's always monolithic. Say that again, a goddamn? Okay, if I give you a one-dimensional differential equation, that's always monolithic. That's always monopolal. Correct. That's always one of the things. Correct. It doesn't matter how unstable, unbounded. Right, right. So you can't really expect any monotonicity of the system to give you anything about components, per se. Yes. You have, yeah, I mean, preserves the partial order. Well, I mean, so definitely you can say something about boundedness in the Hilbert metric. But again, if that gives you a little bit of a problem, you have to be a little bit careful, but definitely, of course, we use, you know, yes, we use the Hilbert metric when you have, say, stochastic matrices, which, you know, basically give you some sort of monotonicity, right? Yes. Because they're netsular matrices, right? So yes, people have used it. We have used things like Ubermetric for things. Like in neural networks, actually, we did. Keep your networks actually with it. But I don't see them on automatic parts of continuity on the technique. Yeah. It's just a comment that I think this has to be looked at a little bit more. But there are a lot of relationships. Sure. Dissipation, a number of other things. Yes, yes, yes, absolutely. Yes. No, I agree. Okay, thank you. Have a second, yeah. So I need Rodolph. So Rudolph's papers they actually explore this connection. And so you go and check his papers. Okay. So he has a notion that goes beyond contractivity, defined using Riemannian metrics and so on, and he established this connection with contractivity using the Uber general metric. Yeah, I remember you talked about it. But my question was similar, that you reduce the neural network to these bounds, but these bombs are. These parts. But these parts are would it be variables? So have you tried to actually practice picking a neural network, a differential equation, and doing reachability analysis to square? Right, I think that the problem is that now you need some kind of bound on this neural network, right? Because oh, you mean not using this kind of. I was expecting that you were going to do some analysis of the neural network to show that it's also monotone. Oh, most of the neural networks. Oh, most of the neural networks are not monotone. Aha, that's a very good question. If you do the embedding, you can do the embedding of neural network. You can consider that input-output map, do the embedding. What you get is much looser bound than this. What you get is exactly IBP, interval bound propagation, in the literature, which is known to be a very loose bound, but it's a very good bound for training around that. It's a very loose bound for verifying. Very loose bound for verifying about that. But that's actually a great point. That reduces completely to IBP. But yeah, I think Crown is kind of doing something a little bit smarter because it's kind of relaxing the IBP is going to be very... Uh how how loose they can be loose at some points. Yes, that is right. It depends on this this uh interval. It depends on this interval. If the interval is small, they are very good. But if the interval becomes large, they lose accuracy. The difference between these two can be very large. So the hope is that what we do in our simulations is that we partition our initial set and our disturbances so that these bounds are small. And using those partitions, so we need to run more number of trajectories, but at least we can ensure that these bounds. Can we can ensure that it's bound? I think that's a yeah, that's a key button inaccuracy. You're right, exactly. Yeah, it's just when the interval is small, basically the bound is the one type of basically linear approximation of your control. When this interval z, z bar, z bar, is it's small. These two bounds are basically the basically you are saying if the minimization controller works. Oh, then okay, when this w Oh, then, okay, when this b when these two are very close to each other, x and x half are also very close to each other. So you are like at the point. So it becomes exactly your neural network at that point. When you do the embedding, so the system becomes monitoring, can you say anything else about the properties of the embedded system as it compared to the embedding? Oh, that's a very good question. Yes, I think you can say a lot. Here I'm using, but Sam Cook and he is. But Sam Hook and he studied environments of dynamical systems, monotone embeddings. He studied convergence to periodical using embedding system. I think a large number of things can be done using the embedding system. Here I just use it as a reachability tool, but that's a very strong tool, I guess. In math literature, people study global study. Could I make a comment on that? Sure. So we added. So we had introduced these embedding systems way back when, maybe about, I don't know, 15 years ago, with Al Smith. And the idea is that, I mean, they're not exactly the same. This goes much further, right? There are algorithms and so on. But the reason we introduced it was because we were very interested in understanding we have a large non-linear system. How could you decompose it into feedbacks, negative feedbacks around a monotone system? Feedbacks around a monotone system. And the reason for doing that is because then you can apply small game type of ideas, for example. And this became extremely powerful, but what's interesting is that the computational complexity of getting those decompositions is an MD hard product. So you get into all kinds of interesting graph theoretic issues of how to get decompositions now. But this work is a little different because it goes much further and actually looking for algorithms for doing this. Algorithms for doing this in even more generality than just a specific way we're doing it. But definitely, it's a very useful composition for understanding dynamics of general systems. And it was, for instance, you know, theorems about the extended, if you do it in a certain way, the extended system has a need that would be real if and only if the original system has global convergence or things of that sort. So there's some very nice, and actually this goes back even longer to some French different. Back even longer to some French literature from the 1990s, where this has been observed without giving it a name. So I think it's a pretty powerful technique for understanding non-linear systems, but it is hard to get positive positions. Anyway, so I like to talk. I mean, I think it's very interesting. Just one question, one quick question. So when the nonlinearities are rent