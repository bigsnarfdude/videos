Which is certainly a topic I'm interested in. It's one of the ways I got into off-model transport. So, looking forward for the talk. Go ahead. Okay. Thank you very much, Aaron, for the kind introduction. And also, I would like to thank the speakers both for inviting me and for helping me in switching the time of my talk around since I had some scheduling issues for the speakers had anything to do with. The speakers had anything to do with this, Jovan. No, I'm joking. Yeah, you said I thank the speakers, but oh, sorry, so I thank the organizer. Yeah. Yeah, not the speakers. Sorry. Well, anyways, I thank everybody. I mean, it's very nice to be here. So let's make it this way. Sorry. Okay. So I'm going to talk about a class of Hamilton-Jacobi equations that arise in connection with the Schrodinger problem. In connection with the Schrodinger problem. And in particular, I'm going to discuss uniqueness of solutions, so the so-called comparison principle. But before doing this, let me give some motivation. So why did we come to this? First of all, let me recall something that has been discussed extensively through the conference, which is duality. So we have the So, we have the probably the most famous one, the Mosh-Kantorovich duality, which asserts that the squared Vassersten distance is in duality with Emil-Jacobi. So essentially, the Vassersten distance between mu and mu is the supremum over nice enough test functions phi of the expectation of phi zero against mu minus the expectation of phi against mu, where phi zero. Against nu, where phi zero is just the propagation, the backward propagation of phi along the Hamilton-Jacobi-Bellman equation. Then we come to the classical Schrodinger problem, so independent particles, Brownian motion. And you, well, one of the various ways in which you can rewrite the duality result is the following. So you take exactly the same statement that you had before. That you had before. But now, in order to get the entropic cost instead of Wasserstein, you have to propagate along Hamilton-Jacobi-Belvand. So you will pick up another Laplacian here. Okay, so of course, duality is a very rich concept. It has plenty of nice applications. So you would like to get similar results also for the more general class of Schrodinger problems that you get. Of Schrödinger problems that you get if you go back to the original thought experiment by Schrodinger, and instead of taking the cloud of independent particles, you take a cloud of interacting particles. In this case, there is not really an explicit way to obtain a static formulation of the problem. Let me remark that the static formulation of both Moshkantorovich and Schrodinger. Morskantorovich and Schrodinger are kind of essential in order to write down this duality results. And I guess the intuition to see this is that both in optimal transport and in the classical transport, once a particle knows where she starts and where she has to end, she will either follow a straight line or a Brownian bridge, but she doesn't have to coordinate with the other particles. And somehow, if you turn on the And somehow, if you turn on the interaction in the particle system, then she will have to do so. So the reduction to the static problem is not really clear. But still, you would like to get some kind of duality result. So you can resort to an optimal control approach. So the idea, which I'm going to explain in the next slides, is that you can obtain a duality result if you interpret the fluid dynamic formulation. Interpret the fluid dynamic formulation of the Schrödinger problem that you're looking at as a control gradient flow problem, and then you leverage the machinery of control in order to get a duality result. Let me to fix ideas. Let me give one example of these Schrodinger problems with interacting particles, which is the mean field Schrodinger problem. And you see that it's in its Benam-Muconier formulation, you can interpret it as the problem of steering. Has the problem of steering the gradient flow of the energy that you get summing up the entropy plus the interaction. You steer it through a control psi, you pay for the size of the control effort, and you have to join new. And this is the picture that is quite recurrent in the talks we have seen so far. So the Schrödinger problem is in general terms a problem where you steer known dynamics to Steer non-dynamics towards a target law, trying to make minimum effort. So, what's the W? What's the W is a potential is an interaction potential. Okay, so if you leverage this viewpoint, as I will show you now in a second, you can get a duality result, but you will have to pay a heavy price. Heavy price because the Hamilton-Jacobi equation, instead of setting it on Rd, you will have to set it on the space of probability measures over Rd. So somehow it's a bit by chance that in the superclassical problems you can work on the base space Rd. In all the other instances, you will have to go to the larger space. So let me just give the idea on how the procedure works. On how the procedure works. So, let me build an abstract framework that relies on the following observation or kind of general belief that whatever Schrodinger problem you can formulate by means of large deviations will look like a control gradient flow problem. So, if you believe in this, then okay, the best thing to fix ideas is to work with the most simple Schrodinger problem you can think of, which is this. Cost which you can think of, which is this toy model. So, this is a problem on our RD. And essentially, all what we have to do, we have to steer a gradient flow on Rd to a target point with minimum quadratic effort. In the instances of the Schrödinger problems that we consider, actually, all the differential objects that appear here and the energy as well. And all and the energy as well, they are associated with a formal Riemannian metric, which is maybe autocalculus, but maybe something else. And both the energy and the metric, they are dictated by the microscopic interaction mechanism between the particles. So, in the mean-field-Schrodinger problem, where the n-particle system is just a system of weakly coupled diffusion processes, the underlying remote. Processes. The underlying Riemannian metric is the autometric or the Riemannian metric of optimal transport. And the energy is exactly the sum of these two terms. You have the interaction, the per potential, plus the entropic term. Okay, now let's work on the toy model to develop the result that we will eventually try to prove in the general setting. So, the first thing that you can do is you take the toy model. So, before recall, we had this constraint that we must end up at y at terminal time. So, you just kill it. And instead, you add a terminal payoff, which you may interpret as a Lagrange multiplier, in the objective function. So, this is arguably a bit simpler problem because you don't have such a hard constraint. Because you don't have such a hard constraint, and for this problem, you can apply the usual dynamic programming Hamilton-Jacobi approach, and you get this Hamilton-Jacobi equation for the value function. So it's this one. Let me comment a little bit. So essentially, we have the quadratic part that comes from the fact that we penalize quadratically here. And then you have this extra term. So it's the inner product between the The inner product between the gradient of the energy and the gradient of the value function. And plus, you have your terminal condition. So if you're able to solve this Hamilton-Jacobi equation, then you have your formal duality results. So the cost, which is actually the optimal value in this problem. No, sorry, it's the optimal value in the toy problem that I showed in the former slide. Shown in the former slide, the cost is just the soup over all multipliers of phi zero of x minus phi of y. So this is the result you payment. Now, if you want to run this procedure for, for instance, the mean filtering problem, well, you run into the issue that the state space move from Rd to the set of probability measures over Rd and RT and consequently, the Hamilton-Jacobi equation you're looking at, well, it does the same transition. And so, the issue is that there is not really a well-posed theory for the Amiton-Jacobi equation that you would be considering. And this is what we set out to do. Maybe this is a good point to stop. Are there questions or remarks? Marks. Okay. So I can move on. Sorry. So when you say this is a formal duality result, are you saying that the cost, I mean, sorry, what's the relation between the cost at the bottom and the infimum at the top, if any? Do they agree? Yes. So the cost is actually this infimum here is what I call the cost, right? Okay, thanks. And so it's not related directly to this one, but. Directly to this one, but so this is formal in the sense that it's true for the toy model, but whenever you go to the Schrödinger problems that I've discussed before, you cannot make sense of the Hamilton-Jacobi equation yet. But sorry, but on the previous slide, the thing you called a cost doesn't have this soft penalization in it, and this thing seems to have. Oh, you take a supremum over all possible soft penalizations. I see. Okay. Yeah. Okay. Okay, so let's move on to the Emilton-Jacobi equation that we actually did consider. And now I'll try to be a bit more rigorous. And I will not consider... So the idea is that you should consider the abstract version of this in, for instance, the Wasserstein space. But I will slightly modify the equation for a reason that I'm going to explain. So I will consider this equation: F minus some Hamiltonian applied to F equals to little. Hiltonian applied to f equals to little h. So the Hamiltonian is exactly the thing that I had here with a sign change. But this is harmless. It just means that I made a sign change on the solution. Now I consider an abstract energy function on E, and I set my equation on a general space, X D. And instead of the time derivative here, I Instead of the time derivative, here I pick just f. So I will not essentially before I had this term, now I'm gonna kill it. Um, and the other thing is that before here, I had zero, and now I have my h. So why did I do so? Well, the first thing is that this equation is studied in the literature, is much more studied than the one that I have shown before, which as far as I know has never been studied before. And actually, this equation, I would say, is the object of a book. I would say the object of a book. It's this nice book about Lar deviations by Feng and Kurtz. So that's why we turn our attention to this equation. And moreover, the difficulties that you have in solving this one are exactly the ones that you have in solving the equation that I've shown before. So we believe that there is not really a big change when you introduce the time variable. And okay, the last remark is that. And okay, the last remark is that the equation doesn't change very much in the sense that the Hamiltonian age is exactly the same. To conclude, this equation can also be interpreted as the equation that stems from a control gradient flow problem, which is not that different from the Teutronian problem that I've just introduced. Okay, so now let me outline a little bit what we wanted to do. So, what we wanted to do is to get So, what we wanted to do is to get the uniqueness of these causative solutions. And of course, we wanted to do so with a geometric approach based on optimal transport. I'm stressing a bit this point because there are really many ways of dealing with infinite dimensional equations, and one approach could be extrinsic, meaning that you lift the space of probability measures onto some Hilbert space, and then you try to use the technology available for Hilbert spaces. Hilbert spaces. So here we really try to stay in the space we started with. So what are the technical issues? I mean, there is a big literature about Hamilton-Jacobi equations in infinite dimensional spaces. So let me point out a little bit what are the problems with this one. But there is a huge problem is that typically the energy functional, think about the one of the mean field Schrodinger problem, is not differentiable. You cannot really compute its gradient. You can sometimes compute its sub-differential. You can sometimes compute it sub-differential, but the gradient doesn't really exist. But it's rather displacement k-convex. So somehow we have to find a remedy for the fact that there is no gradient and we have to exploit k-convexity. Moreover, the Hamiltonian is not really locally Lipschitz with respect to the measure input, which is a typical assumption for these kinds of equations. So the standard So, the standard proofs would not really apply. And then you also have this annoying fact that metric balls are not compact. And this will cause additional problems if you try to run the usual argument when you duplicate variables. Sorry. I will come back to this issue at the end of my talk. And then, okay, plus there is all the bad stuff that comes with infinite-dimensional Hamilton-Jacobi equations. Okay, so let me sketch a bit the idea that we used, which is borrowed from by Feng. So instead of trying to define the action of the Hamiltonian on a function, which is not possible because simply the gradient doesn't exist, the gradient of your energy doesn't exist, you will define formal upper and lower bound. So these are two different Hamiltonians, H dagger and H double dagger, that formal dagger and H double dagger that formally are one smaller and one larger than the true Hamiltonian. And instead of showing uniqueness for the object that you can't define, you show that there is at most one continuous function that is at the same time, a viscosity subsolution for the upper bound and a viscosity super solution for the lower bound. Okay, so you get in some sense, this is an even stronger result because you get it from Result because you get it from upper and lower grounds. And then the hope is that you don't really have to define the action of the Hamiltonian on any function, but you just need to work with functions, with test functions that are of this form. So they are the distance squared from a given point that I call rho plus a constant. And why do you have this hope? Because if you think about the usual proof of the comparison principle, Usual proof of the comparison principle, these are exactly the test functions that you need for the doubling variable method to work. So those are essentially the only test functions that matter. Well, of course, what is the game that you have to play a bit well is that you have to define your lower bound in such a way that there are an upper bound in a rigorous fashion. So in somehow, you have to get rid of the gradients. But that the bounds have to be tight enough for the comparison principle to be proven. To be proved. Sorry, you need all A or just A between 0 and 1? All positive A or just A between 0 and 1? I think we know I think we need all A's. Okay. Then I guess by some scaling you can. Well, I don't want to say stupid, but I think you need all A's. So actually, what I want to tell you a little bit is what is the idea to construct these upper and lower bounds that That we found because it's really related to gradient flows and, in particular, to EVI gradient flows. So, let me first recall what is an EVI gradient flow. So, we have our energy functional E, and we give ourselves some K in R, and we say that. That there exists an EVIK gradient flow for the energy functional. If for any initial point pi, you can find a curve, S pi, that satisfies this differential inequality. So which states the following: take any point with finite energy and look at the difference, sorry, look at the derivative of the distance squared from the point. Distance squared from the point along the gradient flow and the point rho, then you can find an upper bound for this quantity, which is given by the difference of the entropies between the base point and the gradient flow minus, once again, the d square function weighted by the parameter k. So EVI gradient flows are quite powerful because once you can Powerful because once you can find such a curve, it comes along with many, many nice properties. And at first sight, this definition may look a bit complicated, but somehow this is just mimicking the fact that the entropy or the energy is displacement k-convex. So if you go back to the RD setting and you assume that your energy is k-convex, this calculation is pretty straightforward. And what is somehow... Straightforward, and what is somehow very good is that this calculation indeed uniquely identifies the gradient flow in a rather general setting. So the full definition of EVI comes with other items. You also want to impose the semi-group property on SPY, but I will skip that for the rest of my talk. So the only message is that EVI gives us an upper bound for the An upper bound for the derivative of the square distance along the gradient flow. And why this should relate to the Hamilton-Jacobi equation that we're looking at? The reason is the following. If you take the second term in my Hamiltonian, then you can formally rewrite it as the derivative in time of f along the gradient flow. This is the, once again, if you go to the usual RD setting, this is a one-line calculation using the chain rule. line calculation using the chain rule because the gradient flow is nothing but the equation x dot equals minus the gradient of the energy so if you differentiate f along the gradient flow well you pick up gradient of f times minus the gradient of the energy which is exactly the the term that um that pops out in my equation okay so let's Okay, so let's do this on the test function that we believe is the only one we need, as I said before. So I take f, which is the following. It's a constant time distance squared from a given point plus, well, another harmless constant c. And let's find an upper bound for the Hamiltonian that doesn't require two defined gradients. So here I just write the formal Hamiltonian applied to The formal Hamiltonian applied to the test function f, where I already used the fact that the energy part can be dealt with using EVI. So we have a quadratic part first that we have to deal with. And this you once again do a geometric argument. So if we were on Rd and you define the function f of x is equal f of x is equal to what norm of x squared, then of course the gradient of f computed at x is nothing but x itself, meaning that the gradient of f the modulus of the gradient of f squared at x is nothing but, sorry, there is a 2 is nothing but 4 times modulus of x squared, which is 4 times your initial function. Initial function. So if you leverage this analogy in here, well, what you believe is that the first term is equal to a square over two times d square pi over. Then we need to find an upper bound for the second term. And here is where EVI And here is where EVI comes into play, of course, because EVI is just giving us this for free. Okay, so just giving us the bound that we need. So then here you would put plus k entropy of rho minus entropy of pi minus k over two d square. Square pi rho. Okay, so now the good thing is that this object here, let me call the right-hand side g of pi. So this object here is completely free of gradients. There are no gradients appearing here. So this function here, it might be minus infinity somewhere, but it's you can define it. I mean, it's defined. Can define it. I mean, it's defined everywhere. So then the temptation is the following: you say, okay, my upper bound is the following: is the following is the operator given by all pairs, F and G, A and C are constants, and the entropy of rho is finite. So this is somehow is what we would like to do. But there is an issue that I'm going to explain in a while. But before doing so, let me But before doing so, let me just say that with the same argument, you can produce a lower bound. So you've written there, the graph of H plus, right? Yeah, for me, the Hamiltonian is just pairs. Yeah. But G is H plus of F in some sense. Yeah, yeah, G morally stands for H of course. Yes. Okay. Okay, so we would like to go with this, but now we have another problem that if you try to run the usual doubling variable procedure, then you run into the issue that when you penalize, you have to produce optimizers. And typically, you rely on the fact that balls are compact, but in this setting, there is no hope that this is true. So you have to come up with a remedy. Come up with a remedy. And the classical remedy is to invoke the so-called perturbed optimization or Echelon principle to produce semi-optimal points, which have nice properties. And typically, the application of Echelon's principle relies on the choice of a divergence function or a pseudo-distance function. So the most natural thing to do would be: okay, I just pick the distance. The distance is the function. The distance. The distance is the function that I use in the application of the equalence principle. But you have an issue that the distance is not Lepsch along the gradient flow. And this fact actually makes the usual arguments break down. So you need to be a bit more to work a bit more to choose better divergence. Actually, the problem that I've described. Described is known. And to get around this issue, Tataru came up with a modification of the initial distance, which is called, of course, Tataru distance. So the Tataru distance between pi and rho is the following thing. So suppose you have pi here and you have rho here. So So, what you can do essentially, you let the gradient flow start from rho, and you can choose the closest point. So you can choose any point along the gradient flow. But if you do so, so if you choose the point that is at time t, you will pay a price t. Okay, so you can forget if you maybe this term, forget it. forget if you maybe this term forget it for for the moment just look at this definition so essentially you can take you take the the closest point you so you can go along the gradient flow take the distance but you then you pay a price t and this distance has two fundamental properties it is lipschitz with respect to the base metric so with respect to d and it is leap shit along the gradient flow so this is the key thing this is this is what the usual distance uh fails to satisfy fails to satisfy. So the distance, the tatar distance between pi and s pi of t is less or equal than t uniformly in pi. So now I think I'm running out of time, so I will not give more details than that. The thing that we have to do is to use the tatar distance in the perturbed optimization principle in order to get In order to get the proof of the comparison principle. But to do so, you need to define your upper and lower bounds for test functions that include the Tataro distance. So let me just show the objects that you have to deal with. So before I just had this term and the constant, and now you have to include the total distance. Now, by doing similar calculations as the one that I've shown. Calculations as the one that I've shown a couple of slides before, that I will not reproduce in the interest of time, you can arrive to a meaningful upper bound. This is the part that comes from the quadratic term, and this is the part that comes from EVI. And you can then define a new candidate upper bound. Upper bound. And finally, the result that you can show is that you have uniqueness of these costly solutions, assuming essentially, of course, there are some other technical assumptions that your energy functional admits an EVI gradient flow and the variations of the energy functional can be controlled with its metric slope, not along any direction and not uniformly, but at least along a set of nice directions. I don't want to. Direction. So, I don't want to be more precise about this. Well, one example where these hypotheses are fulfilled is if you pick the Vaserton space and you equip it with an energy functional that satisfies the Meccan condition. So, here I just put one representative of this class of functionals, which is the one that corresponds to the Schrödinger problem. Okay, I guess. Okay, I guess this is all I wanted to say, and I would like to thank you all for paying attention to the talk. All right, let's thank Giovanni for the very interesting talk. And we do have time for some questions and discussion. Does anyone have? Does anyone have something to start? Actually, I want to ask specifically: when you've changed at the end a little bit the viscosity solution, it seems, but do you still have the value functions you would get by representation as a control problem as viscosity solutions? Yeah, this we still don't, so we haven't carried out this in detail yet. But of course, the candidate solution is that way, yeah. Solution is that way, yeah. The thing is that, in some sense, this definition that we gave is very good because it has very few test functions, so you don't need to verify many conditions, but the tata distance is not so smooth. So, of course, so somehow the belief is that showing that this is the viscosity, that the value function in the viscar system solution is simpler than the comparison principle. Than the comparison principle, but we need to do it carefully. Sorry, in the previous slide, when you gave this example, and you said it needs to satisfy my condition, but what you really mean is that the pair potential here, the W, has to be kappa convex or something like that, right? Okay. Okay. So, I mean, I don't know what pair of potentials you were considering, but of course, the first pair of potential where I saw this kind of thing worked out was in Gregoire Lauper's thesis, and he was looking at the Coulomb potential, which, of course, is not, you know, it has singularities in it, so it's not kappa-convex for any kappa. kappa convex for any kappa and yeah for that one i think we are still a bit a bit far so i think maybe one one example of application which is outside the the the optimal transport area is the um is hilbert spaces of course this whole methodology would work for gradient flows of heat on hilbert spaces and there you have some cute some cute examples Some cute examples. Do you know what are the sort of limitations of taking this approach to sort of other more general like Hamiltonians? In particular, I'd be interested in sort of like something that's like second order, I guess. So the simplest example from games would be like with common noise. Okay, no, okay. Common noise, to be honest, I don't. I to be honest, I don't know how far I don't I don't know how far this goes. There is usually there is always a tricky part in this thing that many equations that you would write as second order for if you if you use this lift notion, they're actually first order if you use the geometrical inside of optimal transport. So, for instance, even for the classical Schrodinger problem, you know. Even for the classical Schrodinger problem, you know, I told, I said it's Hamilton-Jacobi-Bellman. So second order, but when you look at the level of measures, it becomes first order because you just have degree of the tree. So I don't know which second order you actually meant, but if it's the one coming from the common noise, we haven't thought about it. I don't know. Probably another limitation is that if you want, so if you want to apply this to a general If you want to apply this to a general mean field control problem, you need to find the underlying gradient flow. This is not always the case. Sometimes there are many mean field control problems that people look at in probability. They don't really admit this nice cream flow interpretation. But it's quite powerful in the choice of the energy. You can take some rather wild. Yeah, like very naive question, but if you replace the Brassage time distance with those introduced by Dolbo, NASA, Esteva, yeah, it should work. Um, it should work because you have AVI gradient flows, yeah, exactly. If you consider still this energy functional, yeah, that should work for simple. Yeah, it should work for simple exclusion in zero range. But then so I don't want to advertise this too much because we have to verify this. But this is should be an should I think it works, but one has to be careful. Thank you. All right, if there are any other questions, let's thank Giovanni again. And I want to give And I wanted to give a little information again about the rest of the schedule. So this afternoon, we want to have some social get-together on Gathertone. And I'm going to post the link again in the chat so you can join at 2:30 Mountain Time for this sort of informal. Sort of informal meeting place to discuss some of the things relating to the workshop. And I also wanted to mention that tomorrow afternoon, we're planning to have a sort of open problem discussion for problems related to entropy optimal transport. And we still have some room in the schedule if anyone wants to volunteer to sort of propose some of these problems and get some time. Get some time to start the conversation tomorrow. And I think it will also be held in this main Zoom room, although the schedule says Gather Town, but I think we'll do it here. I'll add in, there's lots of room in the schedule. So don't be shy. Yeah, just send us an email. Okay, so I. Okay, so I just want to update that we are supposed to have this presentation by MITAX, but the representative is running late. He will be here in 12.15, so in eight minutes. So we have a little bit time. Robert, we can't hear you. You're muted. Is this Gather Town link? Were we emailed that as well, or we have to get it out of the chat? Oh, we can email them too. We can email it too. That's a good idea. I want to send an email to everybody. Yep. Thanks. And yeah, alcohol is allowed. As long as we bring some to share with everyone, right? Yes. All right. I know it's very, very late for the Europeans already. So whoever is still there, I thank you guys for still staying there. 