It's a pleasure for me. Thank you all for being here. It's a pleasure for me to introduce Imer. Imer is speaking about Q matrix, Q polymatrix and run making codes. Thank you. Whenever you want to start. Thanks very much, Hiram, and thanks to you and the rest of the organizers for inviting me to give this talk. So I'm going to. I'm going to, I wouldn't exactly say this tutorial, but on the other hand, I'm not assuming that anyone knows any more about Matroids than I did at the end of 2019. So I'm going to start with some simple examples. In the first part of the talk, I'll try and relate a lot of it to codes and then later on, just for arbitrary QPoly matroids. And these results are really around applications of some of the invariants associated with the matroid. Associated with the Matroid. Okay, so this first slide, reminiscent of the spirit of a simply read song for this community, that is, if you don't know me by now, you will never, ever, ever know me. So I'm just going to remind us some things that we all know. We're going to use notation like FQ is the finite field. I'm going to use this square brackets here to denote the set from integers of one to n. From integers of one to n. We know about the Hamming distance between two code words, it's just a number of coordinates where they differ. And then the support of a word is the set of coordinates that are non-zero for that particular word. So this notion of support is kind of important, and I'm sure we all have come across it before, but it's going to be a sort of a thread throughout the talk. The talk. So, some other things we already know, we know about the weight enumerator, which is a list, if you like, that counts the number of words in a code C of a given weight. So WIC is just the number of words of having weight I. And of course, this is just another way of writing this is to say that we're counting the number of words in the code whose support size is equal to some set S, where we look at all of the. Equal to some set S, where we look at all of the sets of a fixed set I. So that looks probably a rather complicated way of saying what we already know here, but it does have a purpose in terms of the invariance of the code. And then the support of a code is going to be the union of the supports of the code words in it. So unless if you've got a linear code and its generator matrix doesn't have a column of zeros, then it has full support. A column of zeros, then it has full support equal to n. And this quantity here is a subcode, so C sub S. It's a set of words that have zero in the positions indexed by the set S. So often when we shorten a code, we look at a bunch of code words that have zeros in a given set of coordinates, and then we choose those and then we puncture them. Here we're not puncturing, we're just using it to select these code words. We're just using it to select these code words. Okay, so another way of saying that is that it's the set of code words whose support is contained in the complement of the set S. Okay, so let's go straight into what a matroid is. And I'm going to just define this with respect to a rank function. So it's a pair basically where you have a It's a pair basically where you have a ground set S, a finite set, and some function. The function is from the Boolean lattice, so the set of subsets of S to the set of non-negative integers that satisfies these three conditions. So the rank of zero is equal to zero, and more generally, the rank of a subset is no more than its cardinality. Than its cardinality, it's an increasing function, and it obeys this semi-modularity property. So we can derive a matroid from a code as follows. So this is probably one of the most amenable ways to get a matroid for a coding theorist. And that is we take a code of length n and dimension k and take some generator matrix for the code. Matrix for the code. And what we're going to do is look at a not a subcode, but a code that you obtain by projecting onto the coordinates indexed by this set S. So this generator matrix has as its columns all of the columns of G that are indexed by S. So this only has length cardinality of S. And this rank. And this rank function we're going to define says we're going to take any subset S and we're going to give it the value the dimension of the columns that the dimension of the columns indexed by the set S. So I take the columns indexed by S, I look at the span of those things. That's a vector space in FQ to the K, and the dimension of that is going to be my rank function. Of that is going to be my rank function. So, this is an extremely well-known and old construction. And if your matroid has this property, in other words, it can be identified with the linear code in this way, then we say that it's representable. So, this is a kind of an important class of matroids. So, I'm going to denote this by saying that the matroid M is equal to M with these two. M is equal to m with these square brackets c to indicate that it's coming from this particular code. Okay, so if I look at a quick example here, I've got a 844 code with this generator matrix. And if I check any set of three columns, I'll see that they're linearly independent. So that means that the rank of any three set, any S of size three or cardinality three, is equal. Is equal to three, and any pair of columns are going to give me a space of dimension two. So any two set, any set of cardinality two is rank two, etc. And on the other hand, I can find some collections of four vectors that have rank equal to three that are linearly dependent. So they have rank three. And in fact, that occurs for. Rank three. And in fact, that occurs for every subset of this set of numbers from one to eight. Any three set of columns there, or four set of columns rather, they'll all have rank three except for the one corresponding to the if I take all of the columns. So the rank of the whole set is equal to eight, and eight is the support of this code word. This code worked. Okay, so in a sense, what you're saying when you're representing a matrix by code is that you're identifying your list from one to eight with the columns or some set of vectors in, in this case, F2 to the four. And then you assign the function depending on the linear independence of the sets of columns that you pick from this set, this set of eight columns. Instead of eight columns. So I'm just going to, these next few slides are almost all identical. I just want us to understand different interpretations of that. So what we said was that this thing CS, when I introduced it before the example, I said that was basically the obtained by taking the generator matrix and projecting onto the coordinates indexed by S. To the coordinates indexed by s. So, in other words, this is giving you a code. The code has length and cardinality of s, and the rank function is just a dimension of that. So, I've just written that in a slightly different way, and you can see that we've thrown away the generator matrix. So, this definition is completely independent of your choice of generator matrix for the code. So, this is basically the punctured code, this thing CUS. Code, this thing CUS. And furthermore, I can think about another code. So this shortened subcode that I mentioned before, this is all of the code words that have a zero in the coordinates indexed by S. So this is actually, if I think about taking my code C and then projecting onto these S. Projecting onto these S coordinates, then the elements, the code words in this set are in the kernel of that projection map. So these two things are isomorphic to each other as vector spaces. So equivalently, I can say then that the dimension of Cs is just equal to the dimension of the code, which is K, minus the dimension of this space, and therefore the rank function can. And therefore, the rank function can equivalently be written in this way. So the rank of s is equal to k minus the dimension of this code. And I'm just pointing this out because this is when we go to the q analog, typically how we actually define the rank function associated with a rank metric code. Okay, so that's you can prove that. This construction gives you this function r that satisfies these three properties and is therefore a matroid. Okay, and then finally, we'll just rewrite this set CS in a slightly different way. So these are all the words that have CS equal to zero when S is contained in that set S. And that's another way of saying that that is that the support of your code word in this, if it's in this set, is In this, if it's in this set, it is contained in the complement of S. Okay, so the support of C is contained in the complement of S. Okay, so Matroid theory essentially is inspired by graph theory and linear algebra. And many of the concepts that you see in there arose first in these things, so notions of independence and such like from. Of independence and such like from linear algebra and graph theory, things like circuits and that sort of thing, the Tud polynomial and all that. You all arose in these two fields. So a lot of the constructions and examples and families come from graphs and codes. But on the other hand, most matroids themselves are not representable, meaning they can't really be. Meaning, they can't really be represented by a linear code or graph in the same way that I showed you before. And in fact, if you look at the proportion of matroids versus the proportion of representable matroids, then you see that the proportion of representable matroids goes to zero as n goes to infinity. So that was shown by Nelson, at least a paper on the archive in 2016, building on other results. 16, building on other results like Cnut's got a lower bound, for example, on the number of matroids as n goes to infinity. So, most matroids in this sense are not representable. On the other hand, I think representable matroids are really core to the theory because it gives us ways of constructing matroids. There's lots of axiomatic descriptions of matroids. I'm not going to go into those in this talk. Into those in this talk, but they're very convenient. So, the ones I've given you are the axioms based on the rank function, but you can do this for independent sets and cycles and bases and circuits and all kinds of things. And finally, natroids do arise a lot in different applications. So, I can't say I know the details of any of this stuff, but I know that it's true. So, Amina already hinted at that in relation to batch codes. They come up in network coding and in. Network coding and in secret sharing schemes. Okay, so essentially, what I want to do here is move from the classical theory into the Q analog. And to do that, we just observe that underlying a classical matroid is a Boolean lattice. And when we go to the Q analog, we're just going to change the lattice. And that's really what's happening. What's happening? So, this is just the lattice of subsets of the set E, say. So, say E is the integers from 1 to N, for example, or it could be a collection of n vectors or whatever. And we're viewing that as a lattice with respect to union and intersection. And associated with that lattice might be this function called the Mobius function. We'll just say what it is. We're not going to study this. We're just going to maybe remark on it later on. On it later on, and in the subspace lattice, we just lattice of subspaces of a given vector space E of dimension n. The join is the vector space sum and the meet is the intersection. And we also have these Mobius coefficients and we can explicitly write what they are in terms of the dimension of a subspace. So, for example, this. So, for example, this is an example of a subset lattice. So, it's got two elements. I'm just writing them as two vectors, 1, 0, and 0, 1. And in the Q analog, we're looking at a subspace lattice. I've got a subspace, for example, generated by these two vectors, like F2 to the 2. And it has these different one-dimensional spaces. And so, this is the minimal element, this is the maximal element, and these things are, this is the meat of these two, for example. The meat of these two, for example. Okay, so now let's say a little bit about rank metric codes. So thankfully, this has been introduced already before by Alberto at least and Umberto. We have these matrix codes. They're just subspaces, linear spaces of n times n matrices. Of n times n matrices, and we measure them with respect to the rank metric. So the distance between two matrices is just the rank of their difference. So for example, here I've got a matrix or a linear code of matrices, four by four matrices. It's got dimension four, one, two, three, four. Each one of these has rank four, right? So it's a Right, so it's a, and it's if I check any of the ranks of all the things that are spanned by those, that's also equal to four as well. So this is a four times four code. And in analogy with what I said on the first slide, I want to think about the supports associated with these code words. So the support of a matrix is just going to be its column space, and we could equivalent It's column space, and we could equivalently say, Well, the support is equal to the row space, and indeed, there's other ways you could define a support. I'm going to mostly be restricting to just the column space. And then the support of this linear code is going to be the vector space sum of the supports of its elements. Okay, so most of the time, say if your code is non-degenerate, then this is just going to be equal to the whole space. And if I'm looking at n times m matrices, it'll be, you know, FQ. Matrices, it'll be, you know, FQ to the N. And I think about these supports sort of for the lattice of subspaces, in this case, FQ to the N, sort of a coordinate system for our codes, for our rank nature codes. And also, in analogy, what we said before, I can define the C sub U. The C sub U, and this is like the shortened subcode for the Hamming metric. It's all of the code words whose support is contained in UPERP. And that may seem a bit irritating the way I've written it there with the UPERP, but another way of saying that is that it's the set of all code words such that u times X is equal to zero. So when you think of it that way, maybe it's a little more familiar for all U contained in. For all u contained in this vector space u. And then I can also say what the weight enumerator is. So this counts the number of code words of rank equal to i. And an awkward looking way of writing that down is to say we're going to collect together all of the code words whose support is equal to some subspace W, whose column space is equal to some subspace W, where that W has. Where that w has dimension equal to i. Okay, so this is my q analog of a linear code. And a subclass of those are the FQ to the M linear codes. So here I'm really thinking about collections of linear spaces that are linear over FQ to the M. So just vectors, ordinary vectors as we usually think of them. Ordinary vectors as we usually think of them, and I declare the rank distance of that to be the dimension of the coefficients as a space over Fq. So I can rewrite this code here as a matrix code by just expanding each coordinate C1, C2 up to Cn as a vector of length m with respect to some fixed basis. So these codes, although they're a special subclass that they can. They're a special subclass that they can be interpreted in the same way that we described the codes before. Okay, so a matroid is just basically a set with a function that has these properties, increasing, semi-modular, and bounded by the cardinality, etc. And the Q analog of that is to The q analog of that is to take the same behavior of the function but now change the lattice to the lattice of subspaces. So that's all we're doing. And that means then that we switch cardinality with dimension and containment is still going to be containment, except these are subspaces. And we exchange the join in the Boolean lattice, which is union with vector space sum in this. Vector space sum in this subspace lattice. So this is what a Q matroid is. And we can go a little bit further and just weaken this first axiom R1 and we get a polymatroid or a Q-polymatroid, which has the same two properties of being increasing and semi-modular, but we don't have the same restriction on the Restriction on the upper, we don't have the same upper bound on the rank of the elements in the lattice. Okay, so here I'm following the definition by Shiramoto. This has also appeared in paper with half of the organizers, Elise, Yaram, Rolinda, and Alberto. And the difference here in this other one is just that the Other one is just that the rank function wasn't integer valued. Here I'm choosing the integer valued because it's sort of nice when I want to describe the characteristic polynomial later on. So anyway, an easy way to think about a polymatroid is just that we say that the atoms of the lattice, so the singletons in this case, don't they can have ranks bigger than one. Can have ranks bigger than one, and simply for the one-dimensional space. We don't really need this extra parameter L, but we can put it in there and say, well, okay, it's upper bounded by L times dimension of A. And all of these objects, this is finite dimensional, and this is a finite set, so there's obviously always an upper bound of some kind anyway. Okay, so how do we get the representable matrix? A representable matroid from a code. So, how do we get a matroid, a q matroid, or a q polymatroid from a matrix code? We do it exactly in analogy with the definition that I showed you before. So we take these shortened subcodes and we say that the rank function takes a subspace, an element of this lattice, and it assigns it the value k. So, k is the dimension of the matrix code, the dimension of the matrix. Of the matrix code, the dimension over Fq, minus the dimension of this shortened subcode. Okay, so this is why I went to the trouble of converting the previous definition, which is more familiarly, so more commonly seen to this one. And you can also rewrite this one in the original type of one as well. Okay, so this gives you a polymatroid. You give a polymatroid, and it doesn't necessarily give you a Q matroid. Here's an example of how we go about getting it. So I've got a code here, and it's got these matrices in it. And so it's over F2, and I've just left out the zero matrix. So that's the whole code written down there. And underneath here, I've written down the support, like the column. Down the support, like the column space of each of the corresponding matrices. So, this matrix here, for example, has got rank 3. So, its column space is equal to F2 to the 3. And this matrix is generated by these two column vectors, and I can rewrite it like that. Okay, so we know what all the supports are in this case, what they exactly are. So, remember, this shortened subcode is the collection of code words whose columns are. Of code words whose column spaces are contained within some subspace, like writing it as a CU perp. So suppose I write down just these U perps and now I want to look at code words that have whose supports whose column spaces are contained in any of these. So if I go through and I scan through these column spaces, then what I can see is that none of them are contained. Can see is that none of them are contained in any of these subspaces. So, the only code except for the zero code word, right? So, for all of these supports U, I only have the zero code word whose column space is contained in these spaces. So the rank in that case is K, the dimension of the code, minus the dimension, which is zero. So, they all have rank three. If I look at this collection, so these U perps. And I check and see: well, how many, what's the dimension of the subcodes that have column space contained in it? Well, for example, this say u curb is equal to 111. I've got this code word whose column space is contained in that, and I've got the zero word. So, and that's it, right? So, for C sub U, in that case, the dimension is equal to one, so that. To one, so that subcode is going to have rank two, and you can check through if you want to to see that the same is true for the remaining subspaces. Okay, and then if I take any pair of code words, the column space is going to be equal to the whole space. So I don't have any two-dimensional ones that are contained in U. So it has no subspaces around. U. So it has no subspaces of rank one. Okay, so there's so there's an example of a Q polymatroid coming from a code and you can check and see the proof is very similar to the classical case that it obeys the axioms R1 into R3. Okay. Okay, so what I want to mention now is just the Mobius function. I don't want to go into any details about it. I just want to make a remark. So what is it? So everyone is happy what it means. Well, not what it means like necessarily, but you know, it's not totally random. So we start with some partially ordered set, a pose set. And this is all you need to define a Mobius function, you can define it recursively. Define it recursively as follows. So, mu xx, for example, is equal to one. And if x is not comparable with y, it's equal to zero. And I compute xy, mu of xy, by just going upwards through every chain between x and y and iteratively, you know, starting with mu x. So, like, if there's nothing in between x and y, then this value is going to be equal to minus one, et cetera. Equal to minus one, etc. Okay. And the exact value of it isn't that important. I mean, you can say what they are, you know, mu zero of u, whatever it is for both lattices. They're computed. You need a lattice to be able to do this nicely. But the important thing is just that we have an inversion formula. So this is very handy. You don't really need to know explicitly what these are a lot of the time. I just have, it gives me a way of counting. Have it gives me a way of counting that's a generalization of the inclusion-exclusion principle. So, if I have a function that can be expressed as a, so a function defined on the poset, and that can be expressed as a sum of other functions g y, say where x is contained in y. Then I can retrieve what gx is by this inversion process, right? And I can do this in two directions. So, um So, the point about this is that it's quite handy for computing formulas and allowing us to say certain things. And it's important in the invariants that are computed in these results I'm kind of going to talk about. So, the kind of principle invariant, I guess, underlying a lot of this is this. A lot of this is this characteristic polynomial. So you have some kind of a lattice with the join and a meet, and you can think of that as vector space sum and intersection or union and intersection. You know, we're only interested in those two lattices that I've mentioned. Minimal element theorem, writing down the maximal element is E. And supposing then that you've got a function for the lattice that basically behaves in a polymatroid way. Behaves in a polymatroid way. Then I can define the characteristic polynomial of this matroid, which I'm not specifying as being or polymatroid. It's either a Q polymatroid or a polymatroid. It's just on one of these lattices. And this is how we define it. Okay, so it's Z is indeterminate. It captures the ranks of each of the Of each of the elements in the lattice between zero and e, and it's got a coefficient there as the associated Mobius function. So I can do an operation essentially on this matroid, which I'm going to write like this. So this is like a minor of the matroid, not defining it properly, so I'm just saying, well, this is what. Well, this is what the characteristic polynomial would be for this polymatroid. And the point here I'm just making is that I can apply Moby's inversion now to this sum and rewrite the Z to the whatever some function of the rank in this way, right? So I can invert this and obtain an expression for. Obtain an expression for these powers of z. So if in particular, this holds anyway for any matroid or polymatroid or whatever, and if your matroid comes from a code, then this dimension of the C of U is exactly equal to the difference between these two rank functions. So the rank of the matroid, so K, the dimension of the code, minus the rank of U. That's how we. Minus the rank of u. That's how we defined the rank. And in that case, then what you see is this Z to the row E minus row of U. Well, if I put a Q in there, that's just giving me the cardinality of this shortened subcode. And then I can express the cardinality of this shortened subcode by evaluating this characteristic. Evaluating this characteristic, this sum of characteristic polynomials when z is equal to q. So, long story short, I'm just saying that this characteristic polynomial can count things. So, if your code, I mean, if your matroid is representable, then this characteristic function allows you to count, for example, the size of the shortened subcodes. Short and sober codes. So, this was basically what was observed by Craibo and Rota and others. So, in the critical theorem, so first published by Craibo and Rota in 1970 and with lots of different variations on it. So, Green gave a very nice description of it. Nice description of it in terms of codes, which is the one I'm kind of extracting from here, also done by Brits in 2005. It was done for polymatroids by Whittle and Kuhn did different generalizations of it. And there are like tons and tons and tons of papers written on this critical theorem and more generally on critical problems. And so here's just a coding theory friend. Uh, coding theory-friendly representation of it. So, this is just now for writing it for a matroid. So, I've got some matroid m and I've got a linear code, and I'm supposing that this m can be represented, that should be square bracket C, you know, with respect to that linear code. That means basically you take your set S and you identify it with the columns of the generator matrix. Choose some subset X of Some subset X of the support set, so from 1 to N, and I can count the number of T tuples such that the union of the supports of those T tuples of codewords is equal to that set S, X exactly. And this number is given by the evaluation of the characteristic polynomial. Of the characteristic polynomial for the matroid or a contracted matroid evaluated at q to the t. And arriving at that result is actually not that difficult at all. You just use Mobius inversion, and that's what Craybo and Rota did, and that's what I think Green didn't even bother doing it, and Whittle did it, etc. So, what's counting is the number of subcodes of C of dimension at most t, right? I'm taking no more than t of them, whose support is equal to x. Okay, so here's the q matroid version of that thing. So, again, I'm writing down this characteristic polynomial for this minor of the matroid. So, however, we get. Of the matroid, so however we get that, and it's just a polynomial with these Mobius coefficients. And if I sometimes find it convenient to change the slash here for a dot, this is the relation between these two characteristic polynomials. And very easily, I've written the proof down below, you can derive the critical theorem for Q polymatroids. For Q polymatroids. So I have some Q polymatroid, I've got a matrix code, so your matrix has to be representable. And I choose some subspace U. Then the number of T tuples of code words such that the sum of their supports is equal to that U can be counted by evaluating this characteristic. By evaluating this characteristic polynomial at q to the t. And the proof is literally two lines. It probably looks disgusting, but it's really not. Or at least it's very easy. So the point is this. When I count these t-tuples, I'm looking at all of the number of t-tuples of codewords in C, such that the vector space sum of their column spaces is. Of their column spaces is contained in some subspace, right? Which is just the same as saying the number of t-tuples where each individual column space is contained in this subspace. That's just equal to the CW to the power of t, right? Because when I count one of these being contained in here, I get this value, and then I just take t products of those. So that's easy to count. And if I want to count where it's easy, And if I want to count where it's equal, then I just imply apply Mobius inversion using the fact that this sum here of the less than or equal to is just found by counting all of the tuples where the sums of the supports is equal to whatever different subspace is contained in W per. So now I just have this thing here. I have this thing here. I write down what this is evaluated at q to the t. Right, so it's just take the expression I have here for my characteristic polynomial, and I input in q to the t wherever I see a z. So I've got that guy there. I look at that and I go, oh yeah, that thing, k minus rho of v, that's actually the dimension of c of v. Of C of V. So I've got Q to the T times the dimension. Well, that's just equal to C V to the T. So that tells me then exactly what this number is equal to. So that's just the critical theorem for Q polymatroids. And it follows through with exactly the same argument as you have in the classical case. It's something that only depends on the underlying. Depends on the underlying lattice, and all that changes is the specific values of the Mobius function and a little bit else, not much else. Right, so for that reason, you can just write it like this, just have an arbitrary, not an arbitrary, but complemented lattice. So, here I'm just thinking as my lattice as either being the Boolean lattice or the lattice of subspaces, and I'm just writing down the I'm just writing down the join here. It could be vector space sum, it could be union of subsets, and I have the critical theorem that holds there. Okay, so that's said there, as it's sort of a well-studied topic in matroid theory. It follows through in the Q matroid case, and you can start to ask questions. You can start to ask questions now about: well, first of all, it's an application of the characteristic polynomial, just saying, yes, that this really is a coding theory invariant. And also that we can now start thinking about how it's used, like what can I say about critical exponents and things like that. So here is where things get a little bit. I should add, actually, I should have said this here, that this theorem is. That this theorem is also shown for the QMADroid case by Ben Janey recently published a preprint on the archive using projectivization. So identifying the Q matroid with the classical matroid. Okay, so in Crabland wrote his original paper, they talk about Original paper, they talk about distinguishing a set. And you have a representable matroid. So you take a matroid, you know, some S and you index it with vectors coming from FQ to the K. And you've got a list of linear forms. And then you say that this list of linear forms distinguishes the set S if no member of this set G, so no G of S. This set G, so no G of S is contained in the kernel of these FI's. And Green sort of goes to the trouble of explaining why this is exactly the same condition as saying that the intersection of the kernels is or the rather the union of the supports. Of the supports of the corresponding code words associated with these FIs contains each GS. So I wanted to look about what the Q analog of this might be, this statement might be. So what's happening here, which I haven't explained very well. Here, which I haven't explained very well with my explanation, is that basically we're talking about these lists of linear forms. These linear forms are vectors in Fq to the K. They're like the message vectors, and you multiply them by your generator matrix, and you get a code word. And what you don't want is that you get so you're saying that F distinguishes it at S if you don't have. If you don't have zeros going all through all of those coordinates when s is that coordinate. It just happens that it sort of describes nicely that you can distinguish the set, the set of vectors, also by those set of linear functionals in this kind of natural way. So, in the queue analog, what I was suggesting is that one Q analog of this is to take a list of bilinear forms. So these bilinear forms are nothing more than a bunch of code words in a matrix code. They're all bilinear forms. And then we can say that this list distinguishes the space U if the intersections of the left kernels of the Sections of the left kernels of those bilinear forms is contained in U perp. And this is just the same as saying that U is contained in the supports of those corresponding code words. So that, I'm suggesting that because that then nicely gives the Q analog of the following corollary, which tells us that if you've got a rank metric code, then the number of t-topes. Then, the number of t-tuples of bilinear forms induced by C, that just means the number of codewords in C that distinguish the set X is equal to this number. So it's just a simple rewriting of the previous critical theorem. So in particular, if C is non-degenerate, then this number is equal to this. So what this is counting is, again, just the number of subcodes of dimension at most t. Of dimension at most t, whose support is equal to the support of your code. And then we can say, at least, well, we can define what we mean by this critical number. So this is the least number T of bilinear forms of C, of code words of C that distinguish FQ to the N. So it's the least number of bilinear forms or the least number of code words that give you a space whose support is equal to Support is equal to the whole possible column space FQ to the n. And so because of this theorem, what you're saying is that this is just a minimum number r such that this number is positive. So I'm mentioning it now because that means then that we can sort of now make sense to, if you like, look at rank metric codes and And try and compute this number for different families of codes. So, this is something that's sort of an ongoing work with myself and Jeanira Alfarano. Okay, so that's, I already feel like, I don't know how about you, I feel exhausted. I feel like I must have exhausted everybody else already. So, that was one application of the characteristic polynomial. I want to mention another one, which is Another one, which is just that we can derive a McWilliams identity for matroids. So, at this part of the talk, we're now kind of leaving the representable matroids. So, Berlowski wrote down this theorem. So, basically gave Emmig Williams theorem for matroids, not requiring the matroids to be representable. So, this thing was derived, for example, Thing was derived, for example, in Green's paper in 1976, but this is saying something different. We're not requiring Matroy to be representable. And this has been generalized in different directions by Brits and Shiramotu and others to give McWilliams identities and different formulations of them and explorations in respect of the Tut polynomial, etc., for matroids. So, one object that they So, one object that they define is this, what they call a co-boundary polynomial, which is just the analog of a weight enumerator. And it's a polynomial of polynomials, so its coefficients are these polynomials in Z, where if you remember, these things are, you know, this thing is like the ith weight enumerator. We sum up these characteristic polynomials when x is. When x, the second, these are indexed by some set x, and each x has to have the same size or cardinality i. So the same machinery that allows McWilliams duality theorem to work for codes also holds just for matroids without any associated code. So, if you do have a representable matroid and then you substitute in Q, what you get is the McWillian's theorem for. McGuillian's theorem for linear codes. So basically, if you're already feeling rather tired, what I'm going to say next is that, well, we have a similar result for Q-volume atroids. Also, they don't have to be representable ones. Okay, so one thing about the different, so there's many different ways of expressing Williams' theorem, not just Williams' theorem, not just for codes, but also for matroids. So, for example, in this 2009 paper, Brits Royal and Shiromojo gave another version of McWilliams generalizing the plus power moments. And that allows them to write down this result. So this is sort of an application of the McWilliams identity. And it tells you that if you've partial information on the weight enumerator of the dual of a matroid and the matroid, and I haven't defined these things yet. And I haven't defined these things yet. Then you can determine basically the weight enumerators for both matroids. And one application of this is to get an extended version of the Asses-Matson theorem for matroids. So what was nice about this work that they did was that they've taken a very sort of celebrated result that tells you how to find a design among the supports of a code. Among the supports of a code, and they've extended that to these very general objects, matroids. And there are many, many more matroids than there are codes. So there is a lot more potential there. And in the paper that they published, they give some examples of non-representable matroids that satisfy the theorem and therefore give you subspace designs. So I think from a theoretical point of view, I think from a theoretical point of view, this result is very interesting. Of course, the problem with this and in the Q matroid case is that these sort of constructions of matroids that satisfy the kind of criteria that you want in order to apply the theorem that they get, how do you actually go about constructing these things? That's a big problem. So I'm not going to talk about this. This. I'm just going to mention here that we have an ocean of a dual matroid which is defined as follows. You just have a, you start off and say we've got a cube polymatroid. E is our FQ to the N basically, or some n-dimensional vector space. And then we can define a dual rank function as follows. We just do like this. It's something that you write in terms of the rank function. That you write in terms of the rank function of the original matroid. And you can show that this gives you another matroid. And this perp here is sort of, I mean, we can just interpret that as being the orthogonal complement respect to a bilinear form, but you could replace it actually with any anti-isomorphism on the lattice that's an involution, so it just obeys this property. Obeys this property. So in Eliza and Hiram Plus's paper, this result was shown that the dual of a representable matroid is isomorphic or is equivalent to the matroid that you get, the representable matroid you get by using the dual code. And so that's nice. Nice, and we can also derive in a matroid way a kind of a standard duality result between punctured and shortened codes translated to contracted and restricted matroids. So, I don't have time to do that properly. So, I'm just going to skip over here and just say that the The weight enumerator, we would, you know, an analogy that we would define for a matroid. So you can also write down a co-boundary polynomial using exactly the same principles as in the classical case, but swapping that the cardinality of x now with the dimension of x, as you might expect. And so this isn't counting anything, right? It's just an invariant. And you put in different values of z, and maybe you can count different things. Maybe you can count different things if your matroid is representable, or if your q polymatroid is representable, and you put in a q here, you're going to get a weight enumerator for your code. And using the same or using rather Mobius inversion and looking around with things and following arguments that aren't that different to what happens already in the rank metric case, you can derive then a McWilliams theorem for. Williams' theorem for these weight enumerators of arbitrary Q polymatroids. So these are not representable, but they still exhibit the same behavior that you see in a weight distribution for a rank metric code. And this particular formulation of this McGuilliams identity that allows you to go from the weight enumerator of one matroid to the weight enumerator. One matroid to the weight enumerator of its dual is nice because it's going to, you have this expression basically says, imagine this is a vector here. I have this upper triangular vector, I've got this lower triangular matrix rather, and it's extremely well behaved. These are Q Pascal matrices, and we know a lot about their minors and stuff like that. So that allows us to get a Q analog of the result I showed you before. Result I showed you before in Brits Royal and Shiramota's paper. So you can get this thing here. And then similarly, you can use that to in the same way to get an analog of the Asmus-Matson theorem, but generalized in some different directions. So I'll just say what a weight. I'll just say what a weighted design is over GFQ. It's a combinatorial object that generalizes the notion of a subspace design. And it's just defined as follows. You've got a collection of k-dimensional subspaces. We call them blocks. And you've got a function from the blocks to some abelian group, right? Most of the time, probably. Most of the time, probably, well, probably the integers in fairness, but you know, could be anything. And then there exists a lambda such that for all T subspaces, these sums are constant and they're equal to this number lambda. So if you were to have that this function just sent everything to one, every member of the blocks to one, this definition would be something called a subspace. Would be something called a subspace design. And then what this property would be saying is that every t-dimensional subspace is contained in Lambda blocks. So this is a lot more of a general object than a subspace design. You would hope that it was therefore more common. And so, using that version of the McWilliamsite duality theorem, you can. Duality theorem, you can write down some criterion for identifying when a weighted subspace design can be constructed from a given Q polymatroid. And that Q polymatroid has to have a weight enumerator that's fairly well behaved. And one of the motivations for this would be similar to what was observed in the classical case, which is that you're taking Which is that you're taking an asleep, you're taking McWilliams' duality theorem, you're applying it to a much larger class of objects than rank metric codes, for example. Most of these polymatroids are probably not representable. And you also have a weaker object. So one would hope that maybe there's an easier way to find examples of such objects using the Of subject objects using the theorem. I'm just going to, that's what the theorem looks like. I don't think we want to look at it anymore, so I'm going to go back here. But it's basically saying that the weight enumerator associated with your matroids, there shouldn't be so many non-zero entries in that, in the dual, and then the smallest coefficient, non-zero coefficient should be reasonably large. And if everything Reasonably large, and if everything works out, then you're guaranteed to be able to find one of these objects. So, I will thank you for your, we've all been so quiet, it's very nice. And I'll just say thanks and finish at that point. Thank you. Thank you very much. Thank you. So, let's thank you. Let's tell you a speaker, please. Questions? Any questions or emails? So, the work that I've done with matrix has typically been with hyperplane arrangements. So, this is sort of coming from an algebraic geometry standpoint and someone who's kind of a peripheral to coding theory. So, a lot of these, the invariants that you touched on, so the characteristic polynomial in the context of hyperplane arrangements, they're sort of Of hyperplane arrangements, they're sort of coarse invariants of a deeper structure. So, for example, an hyperplane arrangement gives you a very nice geometric lattice. So that's a combinatorial structure, but there's a deeper algebraic and topological structure underlying it. So I wonder if it would be possible for, say, for these rank metric codes to connect them, this sort of discrete data. This sort of discrete data to some sort of a topological or algebraic object. So, what I mean by that, again, this is a long-winded and rambling off rambling question. So, for example, for hyperplane arrangements, the characteristic polynomial of the coefficients are simply counting the dimensions of the cohomology of the complement of the space that's the complement of the hyperplane. So, you could imagine, again, doing something similar with these, with the rank metric codes, where you create some sort of a topological. Create some sort of a topological or algebraic object. And then maybe some finer invariance of those objects would give you interesting information about the coding theory. So this is like totally speculative. And it's sort of coming from a very different perspective. But so has anybody looked at these sorts of things or not? No, no, it's so you can just say no, it's an idiotic question. No, it's an idiotic question. No, no, it's not idiotic, it's just it's I'm an idiot. I'm sorry, you're wasting your comment on an idiot. Um, so it's, I don't know, is the short answer to that question. Yeah, but uh, thanks for your comment. Imer, can you read the chat? There are a couple of questions. Oh, sorry, the chat. Okay. Do you have access? Oh, yeah, I can see it. Okay. How do you calculate these things? How do you calculate these things in practice? Well, with a lot of hard work, is how you calculate them. So, basically, that's kind of part of the issue. So, these invariants, it's not like that they're necessarily easy to compute. It's what you want is to be able to give the construction of a code when you can kind of predict those things, is what I would say. So, the point about the invariance is that, well, they give. Invariants is that well, they give you these, you can mess around with them, they behave in a particular way. Um, and in the end, um, they allow us to do something like we get a McWilliams theorem or something like that, or we can describe, we can predict, derive equations that have unique solutions because of certain constraints that are imposed on linear systems. So the elephant in the room is what should be asked. The room is what should be asking me is: well, can you give us some examples of these objects? And what I would say is that I find that to be a very difficult question because I've spent a lot of time thinking about how to construct both rank metric codes and a little bit of time on Qbody matroids that have these sort of restrictive constraints and their coefficients or whatever these invariants. Coefficients or whatever these invariants are. But none of the ideas that might come from the classical case seem to work. So it's not that these things are going to necessarily be easy to compute. We can do it for small examples. But what you really want is a clever construction of codes where these invariants are something you can predict. So you don't really need to compute them. I mean, you can compute them, but not because otherwise you're just bashing through. You're taking every subspace, you know. Taking every subspace, you know, of these p, u, q to the t, what are you doing? You're looking at all of the shortened subcodes. You've got to go through every, you know, it's as difficult as computing the weight enumerator, basically. And can we use matroids in the Lie metric? Um, I doubt it. I doubt it because I don't think the Lie metric behaves. don't think the metric behaves um behaves nicely in this way but i well i shouldn't i i can't say yes or no but i would be so i don't think so we wouldn't if we if she put a gun to my head and said emir can we do this i would say no please take the gun away thank you thank you for regarding this so um so with alberto we we looked at this not really exactly at the Not really exactly a deli metric, but like different support functions and different like induced weight functions. And there is certain properties that you need to require to get a Metroid out on the support side. So when you have a certain support function on a code, and when it has certain properties, then it creates a metroid, like the supports are the circuits of a matroid. And the limit metric doesn't have this property. And the limit metric doesn't have this property. So I would say if you do it in the way that you'd expect it to do, no, you don't get a metroid. And maybe there's something else to be done that we haven't thought, but I would say the obvious thing does not give you a matrix. Great, great. Thank you. Thank you for your comment. So let's thank Emil again, please. 