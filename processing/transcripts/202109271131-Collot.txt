It's a real pleasure to meet with the community online, as has been the usual stuff for like one year and a half. So, this talk is going to be about a joint work with Joachim Ampatzoglou and Pierre Germain. Both of them are in the current institute in New York. And I'm going to talk about a I'm going to talk about a subject which is not directly linked with singularity formation. In fact, it's what happens in a completely different regime where you have weak nonlinearities, but you still want to understand what's happening with these weak nonlinearities. So the first part of my talk is going to be about introducing you to this issue. This issue because I don't expect that everyone in the audience is familiar with the concept of weak wave turbulence and with kinetic wave equations. So I'm going to be, I mean, starting from scratch, say. So I'm going to study nonlinear Schrodinger equations of the following form. So I always have something like I dtu plus U plus La plus U. And then I'm going to study different right-hand sides. So this one is the standard cubic NLS, but I'm going to focus on other type of nonlinearities today, which are quadratic nonlinearities. And I put them of this form. So here, the first and second line are basically the same if you just change variables. If you just change variables, what I want to say is that u plus u bar it gives a Hamiltonian equation. And here I'm going to introduce several parameters. So first of all, there is little omega, which is my dispersion relation. And it might be the Laplacian, but sometimes it might also not be the Laplacian. And I have And I have some other parameter, which is the strength of nonlinear effects, which are with these lambdas here. And they will ensure that my equation is what we call weakly nonlinear. So nonlinear effects are here, but they're not too strong. And finally, we are going to see that there will be some issues with quadratic nonlinearities at log frequencies. And so some results are going to be valid with a Are going to be valid with a specific Fourier multiplier. So I'm going to play a little bit with the nonlinearity at low frequencies, depending on the properties of my dispersion relation. So this is a time model. And as I'm saying, like the idea is under which conditions on these parameters that we have can we say something in the kinetic regime. So my data are going to My data are going to be taken randomly. So I have some randomness, and I don't have a random forcing, but I have random initial data. And there are two types of regime in which you can study the equation. The first one is one in which most of the current literature has been dealing with. It's the homogeneous setting. So basically, in the homogeneous setting, you assume that You assume that your equation is periodic and you have a torus, and you assume that the situation in the whole space is just like homogeneous, everywhere is the same. However, in the inhomogeneous case, you rather take things which are different depending on the different locations at which you are. And so since I'm dealing with a randomness, the randomness will be somewhat different at different locations. Different at different locations. Okay, so what is weak wave? Why did you have lambda and lambda square? It's just because in my scaling, I assume that I have this type of normalization, that u0 is granted of one. So I just put a lambda to say that lambda is really the strength of my non-linearity here somehow. It's like a It's like a okay, it's just a normalization. It's like, yeah, I mean, you could put lambda as a parameter. It's just, it's the usual scaling. So if I want to refer to the retrieval, right? But I could have replaced the lambda square by lambda in the first equation, of course. Okay. So in weak wave turbulence, the nonlinearity is weak. So here I'm just going. Nonlinearity is weak. So, here I'm just going to recall what happens in strongly nonlinear regimes and weakly nonlinear regimes. So, I assume that I have two time scales: one is the linear time scale, and the other one is the non-linear time scale. So, if on a time interval, my nonlinear time scale is not seen, then I'm in the linear regime and nothing is interesting. And if my nonlinear time scale is Time scale is happening, say, before my linear time scale, then I see coherent structures. For example, stationary states, the linear effects are compensating the nonlinear effects. I can see solitons, self-similar solutions, and this is where I can have a singularity formation. However, if I'm in the weakly nonlinear regime, this means that my linear effects, they act Linear effects, they act at a time scale which is much shorter than the nonlinear time scale. And so I still have nonlinear effects, but they accumulate in a way that is filtered through linear effects. And so you don't see the same non-linear effects. And in particular, you see some kind of linear dynamics which is perturbed by non-linear effects. And in And in weak wave turbulence, you also have another important assumption: is that you are dealing with a random system. And so, here we will have many degrees of freedom and you want to have a statistical description of what is happening in this weekly nonlinear regime. Okay, and so for this NLS equation, this is what happens. We want What happens? We want to study this quantity, which is called the point spectrum of energy. So you go in Fourier. So here I'm in the homogeneous setting. So I'm working on the torus, right? So I see my non-inertial English equation as some lattice dynamics. And I want to study how my energy in Fourier will move. Like recall that if my dynamics is purely linear, my phase is the oscillator. My phases oscillate in Fourier, and so nothing happens. So, in weak wave turbulence, we want to study how the Fourier spectrum will start to move to study either cascades from low to high frequencies or from high to low frequencies. And so you assume various hypotheses on your system. So, there is this RPA assumption, which is RPA assumption, which is the fact that when you deal with Fourier variables, each Fourier coefficient is taken randomly, independently of the others. You have random phases and the modulus of your Fourier coefficient, they are also random. And then I repeat, we are in a weakly nonlinear regime. And so in this regime, it's conjectured that in many situations, and for example, for this nonlinear exchange equation, you have Inertial equation, you have a deterministic effective equation. So at first you have randomness, but when you go to the limit, there is some statistical point of view where you can understand what is going on through a deterministic equation. And so this is stated as follows. If you renormalize correctly my point energy spectrum, it converges to some function that I call rho, and rho will solve a determinant. Will solve a deterministic equation which is of the form dtœÅ equal to some non-linear term, and this non-linear term is seen as a collision operator as if linear waves they were you know making collisions one with another in energy with Boltzmann and it's a nonlinear convolution which depends on the specific nonlinearity I'm dealing with. So since in this talk I'm speaking about different nonlinearity I'm speaking about different nonlinearities. I don't put an explicit expression here. And what I want to mention is that this type of nonlinear Schninger equations, they are the toy models that are typically studied in physics textbooks. So here I put some references. There is a famous book by Zakharov, Elvas, and Falkovich. There is another famous book by Nazarenko. And there And there was no rigorous derivation of the kinetic equation until very recently, which is what I'm going to talk about today. So this was in the homogeneous setting. And now if you're in the inhomogeneous setting, then sorry, what is the kinetic time here? So the kinetic time, it's dependent on the... How do you compare it with T linear and T linear? With the T linear and T nonlinear? So I did not put an exact expression because again I deal with different equations. So when I'm going to be specific is when I'm going to talk about my main subject, which is this quadratic nonlinearities here. And here I can give you the kinetic time. It's here. So when I'm dealing with this specific equation, and in particular, you can check that this kinetic time is. Kinetic time is much after both the linear time and the nonlinear time. So, this brings a difficulty to reach this time because basically your nonlinear effects really started to change the solution. And thank you for this remark, Sim. So, in the inhomogeneous setting, what you have to imagine is that you have the same situation as before, but now you As before, but now you are on a domain, and so your little waves are going to travel now. And this transport effect appears here in my kinetic equation. If I'm in the inhomogeneous setting, then I have some transport which happens. And so here I see a kinetic equation, which is really comparable to Boltzmann equation. So rho solves the. So rho solves the dt rho equals transport plus collision and rho what it is now before it was the Fourier spectrum of my solution and I was in the homogeneous setting so on the torus I just take my Fourier coefficients but now I have to imagine what can be the analog on the whole space and so The whole space. And so the analog is going to be the following: it's that I have a Gaussian field which is oscillating with some envelope. And the envelope is at special scale one, while my oscillations are very rapid at scale epsilon. And the randomness actually depends on my position. So here I see. Position. So here I see some local oscillations, and here I see different local oscillations. So this is the typical quantity you want to look at. It's the Wigner transform, which is really, you have to think about it as a local point-energy spectrum. It's like as if you were doing local Fourier analysis, like what is the energy at frequency one over epsilon at position x? At position x. Okay? And so here I put for you the exact form of the collision operator. You see this nonlinear convolution here. It's of quadratic type and you have some specific elements which are showing up. So here you have some kind of Kirchhoff law so that the So that the frequencies have some specific linear properties. And then you have this other measure showing in your collision operator. And this is due to the resonances that I'm going to talk about right now. Okay, so this is the kinetic wave equation I want to show that it's happening in the quadratic case. So in the difference to Quadratic case. So, in the difference to the previous cases, now I have transport and I cannot do a Fourier analysis on the torus. So, it's no more some kind of lattice dynamics. Okay, so why is this equation showing up? Again, since I assume that most of the audience is not familiar with the concept of weak wave turbulence, I'm gonna just introduce you to the basic concepts. So, the initial datum is what we call Atom, it's what we call a Gaussian field. So, this is a function if you look at it at some point, it has a Gaussian behavior and it has correlation at spatial scale epsilon. So, as soon as two points are away at a distance greater than epsilon, basically the Gaussian field decorrelates. And we assume that the local Fourier spectrum of this Gaussian field This Gaussian field has this form so that as epsilon goes to zero, so here I forgot to put that, as epsilon goes to zero, you see that my Wigner transform is just this function A here. So the reason why we take initial data of this form is because in the homogeneous case, you have what is called the spectral representation theorem that tells you that most of the smooth and local, I mean. Any smooth and localized Gaussian field has to be of this form. Then, again, in the weak nonlinear regime, I repeat that, but the nonlinear effects, they accumulate, but filter by linear effects. So, this is what will create the resonances I was talking about. And finally, the last thing to have in mind is that when you deal with In mind, is that when you deal with Gaussian field, then you have some specific rule to understand non-linear effects, which are explained via Vick's rule. It's like if you want to study how this product of four Gaussian fields, how it works, like for example, statistically, you take the expectation. In fact, you just have to compute all the The pairwise expectations when you can put your Gaussian fields in any configuration two by two. So this is the graphical representation that I have here. If I have four Gaussian variables, then to compute the expectation of the product of the four, there is some specific rule. And so this will allow to understand the correlation. To understand the correlations in my function. Okay, so these were the first basic concepts. And now, as I was talking about, there is this idea that weak nonlinearity means that to leading order, the dynamics is linear and perturbed by some non-linear effects. So, if you want to understand that, it seems a good idea to just do Duhamel representation, right? Two leading order mechanics. Right? Two leading order, my function is evolving according to a linear dynamics. This is my first piece. And then I have my non-linear correction, which is computed on my linear dynamics. So somehow a GML formula is as if I was filtering my dynamics by my linear semiconductor. And here, when I do that, I see that this second term that I have here, so I have this quantity, sorry, to the Have this quantity, sorry, to the square here. And when I develop this quantity, I see, for example, that I have terms of this form. It's an integral where I have some Kirchhoff law that I was already talking about in my convolution operator. And very importantly, I have my resonances showing up. So when you make linear waves interact to form Interact to form an outgoing wave after they have some nonlinear interaction, you have this key integral which shows up. This number here is called the resonance modulus. And if your resonance modulus is very small in the first case, then you really have some nonlinear contribution, like this term gives some growth. However, if Some growth. However, if my resonance modulus is very large, then I have some oscillation in time and I don't see any growth. So the nonlinear effects, they will mostly restrict to the set where you have zero resonance moduli. Okay. And so now what are the results? Well, most of the results have appeared. Results have appeared in the homogeneous case. And here I'm going to just sum up the results in a graphical way. So you have several time scales. I already talked about the linear time scale. Then after that, you have the deterministic non-linear time scale. Then you have some specific time on the torus, which is the time of fully resonance. I'm not going to talk a lot about that. And then you have finally the kinetic time. And so here. And so, here, in this way of representing the time that you want your solution to live up to end this y quantity here, the question is, if I give you any x here, how far can you go up to control your solution? So, the further you can go up, it means that you can control your solution to times which are arbitrarily close to the kinetic time. Kinetic type. And so there were first works by the Suzonians Webgoff Fau on related issues, but not really on the derivation of the kinetic equation in this setting. And the very first work that appeared on this issue was the work by Buckmaster, Germain, Hani, and Chata back in 2019. Then there are also very recent works by Dimov Cooksin and Stephen Anitran, but for different equations, so I cannot enter. Equations, so I cannot enter into details. So, the first result that we had with Pierre Germain was to control the solution up to this time. And so you see that here at this particular location, we were not able to reach the kinetic time scale, but we were arbitrarily close to this. Then the solution was similarly to this problem, was similarly. To this program was similarly studied by Deng and Hani. And back around the same time, they could control the solution up to this time that I display here. So it's a bit further both for both in several directions, but here you can see that there is some specific time, which is a specific regime where the kinetic time is equal to one, where they could also One where they could also approach it almost, like up to some little polynomial loss. Then the year after with Pierre, we said, okay, maybe with this standard Laplacian, it's not the correct way to see this problem because for large times, if you are working on the torus, then you have really some number theoretical issues which show up. Theoretical issues which show up. And so, if you deal with the Laplacian, your resonances, they have really specific features because resonance moduli, they have to be integer. So either they are zero and then you are fully resonant, or they are not zero, in which case you are just non-resonant at all. So if you replace your Laplacian with some generic non-diagonal quadratic dispersion relation, maybe something better happens. Maybe something better happens. And we showed that this was the case. So, if you start to play with your dispersion relation, then you can go to much larger times. And we were able to almost reach the kinetic time for a wider range of regimes. And here I put it as a remark that we were also able to show that, I mean, this is going to be technical and I'm going to talk about this later on. And I'm going to talk about this later on, but when we represent a solution as a Dyson series, we were able to show that there was something that wasn't converging when we were dealing with kinetic times smaller than one. And so we really thought that there was an issue there. And we were surprised because, in fact, Deng and Honey this year, they could solve the full problem, at least for certain regimes and for some diagonal dispersion relations. Some diagonal dispersion relations, but they were able to reach the kinetic time and for some kinetic times strictly smaller than one, and for the kinetic time equal to one. And so they were the very first ones to fully derive the kinetic wave equation, which I believe is a very impressive result. So this was about the homogeneous case. So as you can see, like there was some rapid progress on this. Like there was some rapid progress on this. And there are still many issues. Like, what about the reaching this kinetic time for kinetic times which are greater than one for different dispersion durations, etc. And so this is the result that we had with Joachim and Patsoglu and with Pierre-Termain about the non-homogeneous case. Homogeneous case, so inhomogeneous case, and with quadratic nonlinearity. It's that we can show the control of the solution up to a time that is arbitrarily close to the kinetic time. So we must allow for some polynomial loss here. So we almost reach it. And we see the validity of the kinetic wave equation. So we see that. So, we see that this transport effect indeed shows up. And so, the result is twofold. So, first, there exists a solution which lives on this interval 0t, 4t of this form. And then, on this interval, it's true that if I look at my Fourier spectrum, then it's well approximated by the solution of the kinetic wave equation in this sense. So, we are not fully justifying the kinetic wave. Not fully justifying the kinetic wave equation, but we are rather justifying the onset of the kinetic wave equation. So we are rather justifying some Taylor expansion, that the Taylor expansion of the two equations, they agree asymptotically. Okay, and to be able to show that, we needed to, in fact, impose certain relations on either the dispersion relation or The dispersion relation or the nonlinearity. So, if you want the u plus u bar nonlinearity to square, then you must take that your dispersion relation is not zero at the origin. And if you want to allow your dispersion relation not to be to be zero at the origin, then in fact you face some inflation at least. Face some inflation at low frequencies, like we have also certain partial examples of growth that maybe the kinetic wave equation is not valid in this case. And so, if you want to avoid this issue when your dispersion relation is zero at zero, then you must impose some cancellation in your nonlinearity. So, basically, you put a Fourier multiplier in front of your nonlinear effects and you make them vanish at zero. Vanish at zero. Okay, so and I have to say that before that there were some formal results by Spohn, but there was no rigorous result on the inhomogeneous case, which is the physically relevant one because you see this transport phenomenon. So I'm really interested in knowing if the Degenhane result can be adapted in this case, showing the full validity of the kinetic wave equation when you have this. Equation when you have this transport effects. Okay, so I have what I have five minutes more, Junchen, maybe? You actually have seven minutes, eight minutes. Okay, so that's perfect. So it's not 30 minutes, it's 35. Perfect. So I can go and give certain brief ideas in the proof. Proof. So there is one part which is of a PD type, and people here are very familiar with that. It's similar to a singularity formation. It's that you want to stabilize some approximate solution. So as I was saying, the good idea to understand how non-linear effects are behaving under Behaving under the linear effects, which happen at a much smaller time scale, is to do some GML form representation. So basically, your first approximation is just the linear evolution, and then you will add more profiles to your solution, each one taking into account the NS iteration of your DML formula. So if you do so, then you get what we call in this field the Dyson series expansion. The Dyson series expansion. So, this type of expansion was done by people before us. So, here I put several references by H. Bohem, but mostly by Erdos and Leo in some linear setting. And you take your full solution with this form, you approximate it with your Dyson series that you cut at some large integer capital N. Integer capital N. And then you take some reminder which is an error, which is not explicit, this reminder. And what you want to show is that this reminder is small in certain norms. So you will use some fixed point argument in suitable spaces. And regarding these spaces, there was some first non-linear analysis done in this work by Beckmaster, German, and Ian Chata. And it was improved along several works. So with a Several works. So, with Pierre and myself, we were using better adapted Borgian spaces. Deng Hani came up at the same time with some similar analysis to close the nonlinear analysis. And then finally, this year, Deng and Hani, they could really show an exact control up to the kinetic time of the error term. So the error term, it will solve an equation of. It will solve an equation of this form. Here, there is some linear interaction, then some bilinear self-interaction with the R term, and there is the error that is generated by my approximate solution. So, to control the linear term, we use some tools from random matrices theory. So, basically, we have an operator which is random. An operator which is random, and we can try to estimate the trace of L L star, the expectation of this trace when we put it to some large order. This is like some classical trick in random matrices. Then the billinear term, the idea is just to put the error term in some suitable Borgian spaces and then it closes almost automatically. So this is better. I mean, here we are going. By here, we are going back to the analysis of Borgia basically. And then, how can we say that the error term here is small? So, I will now just focus on this error term. So, this error term is generated by my Dyson series. And so, to control this error term, I need to show that my Dyson series has some specific bound. And here is an example of such a computation. A computation. So you represent your objects via graphs. So here I have one term. So this is, for example, U2 here. I mean, one piece of U2 on the left. And in order to control the L2 norm, so there is a U2 against U2 bar. So here this is U2 bar somehow. And And I said that there was this Vic rule in order to understand products of Gaussians. So, when you compute the expectation, it will make certain pairings appear here. This is when you do the expectation. And so, a specificity of the inhomogeneous setting is that now we have new slow variables that appear, which change the analysis that was previously done. Previously done. And you have many, many different diagrams of this form. And to compute the L2 norm of your nth iterates in your Dyson series, it is equivalent to compute the sum of all quantities indexed by these paired diagrams. So this is diagrammatic computation. This was due I mean this was already used in the works of Spohn. Already used in the works of Spohn, Erdos, Yao, and works after that. And so here I'm just going to say one novelty that appears in this work. So because I'm going a bit out of time, so we'll focus here on the main novelties. So you have we have come up with some kind of new algorithm to estimate these diagrammatic quantities. Quantities. And basically, I was saying that there was this issue with the dispersion relation at low frequencies. So we really have some low frequency issue which wasn't appearing exactly the same way for the cubic nonlinearity that we studied before with Pierre. And so the idea is to decompose a diagram into several parts. Into several parts. You have good parts and bad parts. And here we had what to introduce what we call clusters in our analysis. And so you have clusters which you cannot treat the way you would like to. And so you have to do a case-by-case study. And so when you have a specific cluster, you can show that each cluster, in fact, admits a good estimate. And in order to close And in order to close your estimate, you show a decomposition lemma. So, when you have a big graph, you decompose it into parts where you have good vertices and bad clusters, and you show that these parts are disjoints and that the clusters are mutually disjoints. So, basically, to sum up, this is more of a combinatorial type somehow. So, the main input here was of graph analysis, I would say. Analysis, I would say. And I'm done. So, thank you for your attention. Okay, thank you, Charles, for the very nice and very interesting talk. Are there any questions? Yeah, can I ask a question? Yes. So, Charles, thank you very much for the talk. Can you quickly again compare your result with Deng Hani and how their diagrammatic proof Diagrammatic proof is different from your diagrammatic proof. Okay, so maybe I can start with what I was going to say here. It's that what we used before in the diagrammatic expansion was an algorithm which was studying vertices. Vertices one by one. So, say this one, first one, second one, this one, third one, this one is the fourth one. So, you study them one by one. And one problem that you face is that what happens at one vertex is not completely uncorrelated with what happens at another vertex. So, at each vertex, So, at each vertex, you have resonances. So, here, say I have a first resonance here. Here, I have a second resonance. And here, I have a third resonance, etc. And the problem is that these resonances, they depend on variables, which are the Fourier variables involved at each vertices. So, here, for example, I have one Fourier variable. I have one Fourier variable that I call, say, xi involved here. So this is xi2, say this is xi1. And here this is my, I would put xi. So here this depend on xi, psi1, xi2. So somehow all these resonances, they are coupled. I mean, they are coupled because there are some Kirscher flows which are coupling every. Which are coupling everything in your graph. And so the first result that we had with Pierre was a result in which we could study what happens at each vertex separately from what happens at other vertices. So basically, said differently, it's a result in which you say that adding a vertex A vertex adds one oscillation. And so adding a vertex adds one factor of the form one over t over the kinetic time to the power one half. And so if you have four vertices here, then you will get t over the kinetic time to the power four over two in your final. 4 over 2 in your final estimate. And you just basically study things with some good order. But once you found the good order in which to study vertices one after another, then you don't care really about what happens between different vertices. And the thing is that if you want to reach exactly the kinetic time scale, you need to go deeper there because Because if you just sum all the ways that you need to put your graphs to obtain this identity here, what we proved with Pierre was that f of g was less than t over the kinetic time to the power n. To the power n. I don't know that I'm writing very well, but say this was of size n. Then, if you just go to some fixed order capital N, you are dealing with a finite sum. However, if you want to reach the kinetic time, you have to let capital N go to infinity, depending on epsilon. Depending on epsilon. And so you have really to go in the details because your sum contains way too much terms. And so you have to say which term are actually contributing more than others. And this is really a very deep analysis that Deng and Hani did. It's that they identify leading and sub-leading terms and they And they can show that the leading terms, the one actually having this estimate here, there are not too much of them. And the vast majority of the other terms are actually having better estimates. And so you can sum. Is that a good explanation of what happened? Okay, yeah, thank you for the explanation. You for the explanation. Thank you for the nice talk. And since our time is very tight, so let's go to the let's go to the next talk. Fabio.