Generally, I argue that for any tree, you can identify to a single vertex with always red degree at most two. Is it clear? So the Bonnet and Kim Thomas participant in 2002. Patrickant in 2012, they defined the twin experiment. So, here the trigraph is a graph whose edges are colored black or red. So, black edges, you can consider as normal edges, and red edges are some special edges. And for a graph, we say that a sequence of graphs, sequence of trigraphs is a reduction sequence if it starts from the given graph, and the last graph is a singletone graph. So, tunis of a graph is just the minimum k such that there is a reduction sequence for which the maximum radio degree of each GI is at most k. So you can see that the cographs have a basic class of twin is zero, exactly twin the class of twin is zero, because the cographs on these two vertices always have twins. Then you identify twins, then you don't create any red edges. Create any red edges so you can recursively identify two vertices without creating any red edges. So we generalize this concept for the two reduced f of graph. We simply take any natural graph parameter f, like f can be a maximum degree, tree with bandwidth, compound size, and so on. So just definition is that the replace the Definition is that replace the maximum degree in the twin definition with F. So reduce F of graph is the minimum k. So there is a reduction sequence for each maximum F value of each GI is M most K. So maximum among F value of GI is MK. So by definition, reduced maximum degree is just the twinnish. But also this kind of variation has been considered by these twinnish guys. By the twin skies, the reduced compound size is turns out to be equivalent to rank with, and reduced number of edges, the total number of red edges in the red graph is equivalent to linear ranks. Some are interesting. It's equivalent to some previous known parameters. So, one observation is that if F is bounded on all stars, then we just. Stars, then we just should be bounded for all graphs because you can just give a linear ordering of the vertices, and then from the left to right, you can just identify and recursively. Then the red graph always just tell whose center is the leftmost vertex, and then some others. So yeah. So if for instance, if we take F as a tree with simply tree with, then it doesn't really make It doesn't really make an interesting parameter, but then we may consider actually maximum of f and delta as a function. So we basically want to, so at least the bound delta and then also bound further. So we might consider this kind of classes like bounded, reduced delta and reduced maximum of tree within delta and passwords and delta and bandwidth component size. A tree depths and delta give a bounded component size. Size. So it's the same. So in this, so the but the reduced component size is equivalent to the rank with. So it's already well known. But the other parameters are somehow we don't know. So basic question might be that there are differences between those classes. Yes, because so the right picture gives us some idea. So for instance, in So, for instance, in the claw, so if you identify a huge each vertex is replaced with a huge complete bipartite graph, and then the original edge becomes a perfect matching between the two complete bipartite graphs. Then you can argue that if in the reduction sequence is delta is bounded, then you always contain the original graph as a red graph during the sequence. Sequence. So it's already used some construction in the Twinist paper. So for instance, if you distinguish the tree with the label and pass with label, you just take a huge binary tree and replace each vertex with a huge complete bipartite graph. But if the class is KTT-free, then there might be some remaining questions that we are working on. In this paper, On that. In this paper, we more focus on the classes of bounded reduced bandwidth. So there are some classes of known bounded tree, known classes of bounded trees, bounded reduced bandwidth. So our main result is that, sorry, so I just remind of what is bandwidth. So bandwidth of graph is the minimum k such that there is a permutation of the vertex set such that the Such that for every edge u b the position of u and b the indexes are different by m most k you can easily see that the if bandwidth is m most k then maximum degree is m most 2k because for a fixed vertex you may have a k neighbors on the light right side and then k neighbors on the left hand side. So, our main result is that we showed that proper minor closed classes have bounded reduced boundaries, and also their R powers also have bounded reduced boundaries. This strengthened the result of this Twinist first paper that proper minor closed classes have bounded twins. So, for this, we use the product CRM for minor closed classes. And also, the And also the maybe more interesting part would be the plano graphs. So we improved the previous bound for the planographs for the twinnies. So we proved the planographs have a reduced band with MOS 466 and Twins MOS 583. And also by the result for memory, so we can produce the sequence in polynomial time because we can compute the product structure in the polynomial time. Structure in the polynomial time, and then what we are doing is just some algorithm. So, note that the previous bounds for plane graphs was quite huge because they use some grid structure theorem. So, in general, the tunis is not close undertaking subgraph. So, that's some difficulty to argue. And then they argue that if the class is KTT-free, then when you take a subgraph. then when you take a subgraph then you have a steer do not contain some huge grid and then you bound you can bound the twins of the the subgraph but then the using the the grid like structure theorem would give us some blow up but here we just directly give us some sequence use only using the product theorem so this this avoids that blow and we also argue some And we also argue something more: that, for instance, graphs of all the genus G have reached spend this at most 164 G plus 468, and planar map graphs or any map graphs drawing on the some surface of all the genus G have some reduced bounded reduced boundaries, which is not to be so. Here, I would like to focus on the planar graphs and then the later. Graphs and then later I will explain the other theorems so what we can do. Yeah, so we basically use these two results seriously. So the product theory, the recent product theorem by UK and Wood and Ye, that every planet graph is subgraph of product of graphs of bounded graphs of tree with MO6 and some SP. M of 6 and some S P. And also, we proved that for every vertex z S in a planar graph, the number of possible neighborhoods on S from the outside vertices are bounded by 6 times S minus 9. We proved that this is tight. And I think this should have been known before, but we couldn't find any literature. So if you know some literature, maybe you can give us, then we can cite it. Can give us, then we can cite it. But we also generalize to the Euler genus case, which is tight bound. Yeah, so I want to first explain some difficulty. So when you identify two vertices, the planarity may be destroyed. So this is maybe some big problem. And it's hard to find some natural sequence preserving the planarity. So it's somehow difficult to It is somehow difficult to describe so design some induction arguments the idea is that we will not use the plenarity when constructing a reduction sequence we at the beginning we just find some global some structure using the product theorem and then we just forget about planarity then give some concept so if you if i give us some picture then it will be clear and i would like to note that we can slightly improve this Note that we can slightly improve this bounds by looking at the neighborhood complexity in the product structure carefully. Because to obtain a product theorem, you find this BFS tree and then find the path and so on. So this gives us more structures than just the product theorem. But so we can slightly improve their balance, like on 400 or something like that. But we do not know whether we can improve. But we do not know whether we can improve the MOS 100. So, this is still an interesting question. So, here is a picture. So, here I give some idea. So, here is H, and then suppose that pass P is W1, W2, W3, and so on. So, each of them give a slice. So, in the H, I consider this 3D composition as a rooted decomposition. So, R is a root. Routed decomposition. So R is a root back, and I choose some back B, which only have lip backs as a children. For instance, look at the vertex play in the Q1D lip B, which is on the W2 slice, which is on the here. Yeah. So the easy argument is that its neighbors should be contained in the Q1 union B. Contained in the Q1 union B part plus, which is on the slides W1 and W2 and W3 slides. It cannot have neighbors to both slice. Sorry, there is some comment. Sorry, Tony has a some questions. No, so for the tonnies case, yeah, okay. There is an answer. Yeah, so it basically the all the possible. So it basically the older possible subsets can be realized and then someone can face. And yes. And the idea is that, so yeah, we want to identify the so basically, so I will recursively see the W1 slice and W2 slice and so on. Then look at the backs. Then look at the backs corresponding to Q1 and Q2. And the union of Q1 and Q2 is small. Then I just take a union of them to make one back. And otherwise, I want to find some twins in the union of Q1 and Q2, which have the same neighborhood on the B part. So that is just a basic idea. And then at the end, I just make one back for every slice. One back for every slice, and then I modify the H where that remove a Q1 and Q2 and then make one back, and we provide the number of backs in it. So before going to describe the induction argument in more details, I need to introduce some important concepts. The first is this graph SXQ. So there are two parameters. It's basically obtained from Is basically obtained from clue by subdividing each edge into x times. And then for every vertex of degree two or one, we replaced with the click of size q and then the degree three guys, so we replaced with the click of size two q minus one and between the two clicks we make a joint so completely adjacent. join so completely adjacent to each other so the observation is that the delta of the maximum degree of this class this graph is just 5q minus 2 because the maximum is realized by some vertex in the 2q minus 1 click so it has a q minus 2q minus 2 neighbors in the click and then q neighbors in the three neighbor clicks and also bandwidth is uh And also bandwidth is bounded by Q minus two. So bandwidth can be, you can give an ordering from the starting from one branch and then arrive and the middle click. And then so you alternatively use the one branch and the other branch and recursive. Then this gives a 4Q minus 2 or so today. This bounce does not depend. This bounce does not depend on the size of x. So, this is important. And also, in the rooted decomposition, we need to use these two concepts. So, KQ routed decomposition is that the rooted decomposition where internal vectors have size and most k plus one and leaf backs have size and most q. So, we usually take a q as a n is k plus one so that if the Plus one, so that if the tree is just k, then it is k q routed composition. But we need to specify some larger leap back size. And another concept is the rooted separation. So this is simply some separation C D as in the picture, where you take some back B and then you take a sum of the children, for instance B1 and B2, and then the union of all the below bags. All the below bands that would be a c and then d is the rest together with so the the separation separator would be a exactly b and we also need to say that the parameter f subgrab parameter like a tree with or the maximum degree is good if it is close under taking subgraph and disjoint union So, the first statement is the following. So, f is some good parameter, and g is some function where f x s x q is the most g of q. So, you can imagine the g is, so f, yeah, f is something like a delta or the bandwidth and g of q, as I said, that if delta, if f is delta, then g q is like 4q minus 2. And T B be a KQ rooted 3D composition of H and F would be a trigraph which is on the H product P. In some graph, we satisfy these three conditions. The red edge condition is that for every red edge in the F, there is some leap back B with a parent V prime, where the B and W lie on the display B prime parts. Prime part and the second condition is that for every rooted separation C D of H and then look at the some G part G slice then from the C D L D on the this G slice the number of possible neighborhoods on the this D product V P part will be bounded by this described number Bounded by this described number Q. And also for every vertex, so its neighbors are contained in the corresponding closed neighborhood on the so if G was in the slice containing V, then the neighborhoods should be contained in the slice corresponding to the neighborhoods of G. Then we show that we use f is almost the g of q. Yeah. So for planar graphs, so we can start with the tree, the h being a tree with almost 6. So we can take a k is a 6. And q would be this 6 times 7, 7 times 3 minus 9. So 7 times 3. 7 times 3 is just the size of the union of 3 vectors. As I said, that we will find some twins here that have the same neighborhoods on this part. So this is the size of 7 times 3. And then this 6s minus 9 is just the neighborhood complexity. And then we adapt the bandwidth and delta as a f, then we prove that the reduced bandwidth is. Prove that the reduced band receives from the 66 and 20s also bound. Yeah, so now with this statement, it's the easy to argue. So first note that we can apply this to any class with product structure, the H, product P. So we didn't really use the planarity in this argument. So, this is a starting point. And then, as I said, that if Q1, so the statement is the same statement, so you don't need to read. And so, I just look at the Q1 and Q2. And then from the slice W1 and W2, if the Q1 union and Q2 is small, then just take a union. And if Q1 and Q2 is a large size, their union has a size larger than Q, then. Then we so we know that because of the separation condition, so the neighborhood types to here is bounded by a Q. So if the size is more than Q here, then there should be some two twins that have the same neighborhoods on these three backs. So we just shrink them. So this might create some red edges to the here or here. So we don't really care. Don't really care, so we just allow them, but we don't make red edges to the oval. This is important because otherwise, we might so we contract here and there, then we can create some red vertex, vertex of a large red degree on top. But also, note that because this is a KQ routine decomposition, originally it's Originally, each leap backs have a size and most q. The union of two backs become a size and most 2q. So this is also an important thing. And then we just do this recursively. And then after contracting all the bags into the one bag, then I replace the q1 and q2 in H with some one bag of just a click of size Q and then attach it to B and then we To B and then we apply the induction. So when you have a so when you have some bag where it has only one children, then we just union this B with this children. So and then same argument. But for this, we need to look at the rooted separation in above X. So this is a reason why we need a separation condition for every rooted separation. At some point, some routine separation. So, some rootie separation can be used. Yeah, so basically, the same argument to shrink. And then at the end, we only have one back. And then in that case, we just shrink arbitrarily from the left-hand back to the right-hand back. Yeah, so this is maybe an important point. So, when you identify these things, Identify these things. So maybe here is the first three backs are identified apart. Then they are the some backs of size Q, right? And then there might be some red edges arbitrarily between them. And then current procedure is working on here. Then this back has a size and most 2Q minus 1 because originally 2Q, but we contracted at least one pair. So there are One pair, so there is a M most to K minus one, and then the rest is the we did not contract identify yet, but there is a Q1 part and Q2 part, which are independent. So this corresponds to the SXQ graph. Yeah, so since so each of the components actually looks like this, and actually. Looks like this. And if it's closed on the subgraph and it's showing union, so each red component has a value at most G of Q. And then all of the union also have value at most G of Q. So this gave a show that the reaches F of large F is M of Q. Is this clear? And for the so we also considered R powers. R powers. So for the two units, we know that any pulse of the transduction would give would preserve the twins. But bandwidth, we do not know that property yet. But for our powers, if you have a product structure, then when you take R powers, then you have also the same property. So simply, we consider the R power of Sxq instead of Sxq. instead of xxq so because that is a possible graph and so we also in the neighborhood condition we replace just mpg with the the r closed neighborhood and for the separation condition so when you look at the this c delete d part and then d part down here so we need to so so we need to consider the what is neighborhood complex to the This neighborhood complex to the above part, but this is the CDLD on this side to the above part to be blocked by the at most 2R plus 1 backs or something like that, because you cannot traverse arbitrarily left. And then if we know the distance r propies to this 2r plus 1 backs, then we can give a bound. Then we can give a bound. So actually, we can just simply use the r plus one to the size of s, which is the trivial distance r proper paris bounds. But we can also use a linear bounds by Arkmeier and F. So they proved that almost linear bounds for the no-air zero classes. And we try to look at the map graphs a bit more carefully, and then we also have some quite good. Also, we have some quite good bounds for the MacGraphs because the MacGraphs can be obtained from the second power of sine graphs. The lastly, so we can consider the X minus 3 graphs. So, we can use the theorem by this two small big idea. So, there is the global tree-like structure where the every tool. structure where that the every total of the bag is a subgraph of this product structure plus the sum ka right so k so now so first we need to look at the each back and then we have to deal with this additional apex vertices but it's not difficult because uh when you consider the neighborhood complexity we also consider the this neighborhood complexity with the a vertices so this just gives a slight blow Is just to give a slight blow. So we just identify all the vertices on the H product P part and then the remaining, identify the remaining guys. And the difficulty is that when we know that the below backs, how to identify the below backs. So now when we identify this part, we have to consider this and this part. So we have to impose this to the So we have to impose this to the H product P plus Ka. But we know that these two backs are closely linked by the click sum, right? So there is some, it's not arbitrarily positioned in this product structure. So we need some argument there. So anyway, this is, and even we can consider the R powers of the algorithms. So the conclusion is that we proved that the conclusion is that we proved that the problem is closed classes and there are power self-bounded reuse bandwidth and some cash so is so is it true that the planar graphs have reduced bandwidth of tears at most 10. I don't know so the the low bound was like four I'm I think so I think it's difficult to give a low bound because we can arbitrarily identify the vertices. The vertices. So it's somehow difficult, but it's an interesting question. And the second question is also interesting. So we write for two functions, we compare these two functions and say that f1 is less than f2. There is some function pi such that for every graph g, so f1 g is bounded by pi of f2. So which means that f1 is strict better than f2. Is there some parameter f which is the better than bandwidth? Which is the better than bandwidth, but strictly better than bandwidth, and also planographs are bounded with so using this proof. I think the bandwidth is the best bound because SXQ is really correspond to the bandwidth parameter. But maybe the other probe, other kind of proof can give maybe better functionality. And is there some natural parameter tied to Natural parameter tied to reduced bandwidth equivalent to reduced bandwidth because, like, reduced compound size was equivalent to rank width, right? So, it's quite interesting. Probably there is some node or natural parameter tied to reduced bandwidth. And also, so we are asking some application of reduced bandwidth. So, we were thinking about this, but we couldn't really find quite an interesting application. Tracing application. So, if you maybe you can try to think about this. Okay, this is all. Thanks.