We are happy to have with us this week Andrea Montanari, who will give a series of five lectures, one each day. There will also be a couple of exercise sessions on Tuesday, Wednesday, later on, and a lecture by Leom Yolan on Thursday. So that's the schedule for this week. A reminder that these lectures are being recorded and live-streamed. So if you do not reach Live streamed. So, if you do not wish to appear in the videos or on the internet, please keep your camera off and your microphone muted. So, we will have a one-hour lecture. There will be a short break at some point in the middle for people to have a chance to ask questions. There will also be more time afterwards to ask questions. The questions after the lecture will not be recorded, so people are more free to take part. To take part. So, we do welcome discussion, and if you have any questions during the talk, please ask them in the chat. So, some of us will be monitoring the chat, and we also have Michael Celentano, is that right, I hope, who is also here to answer questions during the talk. So, we have a Zulip forum where you can also ask questions after. Questions after the lecture if you have some things here that are unclear, and it will be answered as well. So, Andrea, if you could share your screen at this point. Okay, so c can you see? Yes. Thank you. Okay, so thanks, Omer. Thanks, Leia and Alex for organizing this and Luigi also, I guess. So this will be a series of lectures about. So the title is Minfield Methods in high-dimensional statistics and non-convex optimization. And okay, I want to. And okay, I want to describe some progress that was made over the last several years about algorithms and methods in statistics with ideas that come mostly from probability theory or physics. And this is a plan of the lecture. I want to start with some motivations, so kind of describe why people, even not probabilists, might be interested in this kind of questions and the conversation. Of questions and the connection with statistics, then describe a way to get exact asymptotics for this problem via a Gaussian comparison inequalities, then pass to algorithms and in particular first-order methods and a special first-order method that is called approximate message passing, and how to get optimal first-order method. Get the optimal first-order method for regression problems using this technology. So, these first things will take the first four points, will probably take about three lectures, and then the last two lectures instead will be devoted to spin glasses and how the same type of algorithms can be used to optimize spin glass Hamiltonians. So, I will first cover some bigger. Will first cover some background, then, a special MP algorithm for optimization in spin glasses and connection to concepts in spin glass theory, in particular Parisi formula, and how to get ground state of Sharington-Kirkpatrick and related models using these techniques. Okay, so okay, so let me start and okay, as a premise. Start and okay, as a premise, I decided that since I'll try to write, I'll use this tablet for writing, writing references will heat up part of my time. So I'll decided not to cite any references, any authors, except for theorems that have a name. And I'll post actually, I sent already a sheet with the references and you can use that to look who proved what. To look who proved what. I think that's more efficient. Okay, so my motivation, or part of my motivation, comes from statistics. So, in statistics, you have what do you have? You have a set of probability distribution p theta that is indexed by a vector theta that is in some set capital theta. Capital theta is a set in Rd. And so, these are what are our probability distribution. Distribution on, say, some set, some measurable space chi, and then or x. And then what you have, you have data that are your samples Z1, Zn that are IID from one of this distribution on this class. And let me write underline Z for the collection of all the samples. Samples and what you want to do. Well, ideally, you want to come up with an estimator. So, an estimator is something that gives me an estimate of the parameter theta that was used to generate the data. So, this is a map from xn to reals to the d that takes underline z and spit out. Z and spit out theta hat of underlying C. So this is what is an estimator. And how do I measure the quality of an estimator? What is my goal? Well, I measure it typically by computing a risk function. So this depends on theta hat, in the sense it depends on the function theta hat and on the true value of the parameter. Let me call it theta zero. Estimate 12. zero to estimate to emphasize that this is true value and this is defined as the expectation of some distance between theta hat of z and theta zero okay and this expectation is taken when theta zero is the true true value of the parameters okay so this is the general setting of statistical estimation Setting of statistical estimation. You have samples, and you want to estimate a parameter or a function of the distributions that these samples have been generated from. Now, there exists one, let's say, canonical approach to this, and the most popular approach is the following. You come up with a function, let's call it L. This is sometimes called a loss function. This is from the sample space times r. From the sample space times Rd or times theta to let's say the non-negative variables. Okay, and you want this function to construct it such that if you define the following object, L of theta, this is so this is sometimes called the loss function. You define the expected loss E under theta zero of L of zero of L of Z and theta. So if you define then this quantity, then what you want to happens is that theta zero is the argument of L of theta. Theta zero with respect to theta. zero with respect to theta okay so you want you want the function you know to want to construct a function script l that is an expectation and such that if you minimize the script function this returns the desired parameter well if you have constructed such a function then you know you can try to do estimation by okay what is called in statistics is called m estimation in machine called M-estimation in machine learning is called empirical risk minimization, but is you basically in the definition of L, you replace the population mean by the empirical mean. And then this is ZI okay so the expectation of this So the expectation of this quantity, so this is you can write it also the expectation of an empirical sample of L of Z theta. Okay, so if you have such a function now, if you construct this empirical mean, now what you do is that you define your estimator theta hat as argument of Ln. Of ln of theta, and this perhaps is constrained to theta subset. Okay, so okay, so this is the summary of what statistics is about, or you know, a big chunk of statistics and machine learning is about. Yeah, it's just a five-minute summary, so obviously I left out some ingredients, but let me give you one standard example of this loss functional. function L if your probability is a density you can take minus log of the density and and the rational for this is that then if you compute you know if you compute L of theta theta zero the population risk this is minus the X minus the expectation over theta zero of log p theta of z and this you must realize that is the same as the kl divergence between p theta and p theta zero i think it's like this plus a constant so this is uniquely minimized at as Uniquely minimized as the desired parameters. So, why this whole approach should work? Well, the idea is that if you are you have this space theta and your population risk looks like this. This is theta zero and instead And instead, your empirical risk ln is something that in expectation in expectation should be very close to this. I mean, expectation is equal to that. So this is ln. An expectation is equal to L and therefore you might hope that for large, so you minimize it, so perhaps. So you minimize it, so perhaps you get this point. For large n, will be very close to it uniformly, and therefore theta hat will be close to theta zero. Okay, so this was my summary of what statistics is about. Andrea. Yeah. What is omega n? Why does it depend upon n? We have a question. Ah, okay. So good question. So here I'm hiding a bunch of You know, a bunch of important things. So, if you look at this figure, so this is a whole area of statistics that I don't want to enter in, but if you look at this figure here, as I said, the justification for minimizing the empirical risk is that you hope that the empirical risk is everywhere close to the population risk, right? So, you hope that these two are everywhere close. Okay, but you might imagine. But you might imagine that this is a little bit of a trade-off between two things, right? On one hand, you have n, you know, for n large, they will be, you know, close everywhere. But on the other hand, if your set of parameter capital theta, on which this lowercase theta lives, is very large, this will hurt you. Okay, the larger is capital theta, the less likely is that they are everywhere close, right? So you want the two to be close, uniform. So, you want the two to be closed uniformly over the set capital theta, right? So, because of that, sometimes instead of minimizing over capital theta, you minimize over a smaller set, and you can make this set larger and larger as the sample size gets larger and larger. This is not always necessary, and of course, will not be a main topic of this lecture, but just for you know, be careful, I wrote a constraint. I wrote a constraint there. Okay, yeah, please interrupt me if there is any question. Okay, so this is the picture. Now, these recipes mainly come from classical statistical problems in which, let's say, this is classically, you think of D, the dimension in which. The dimension in which theta lives as fixed and the sample size going to infinity. So this is what started at the beginning of last century. Over the last 10 to 20 years, people looked and were very interested in high-dimensional statistics. This is a set of Well, this is a set of problems in which instead, okay, both n and d go to infinity, but often in fact n is much smaller than the dimension. So this is kind of surprising that you can infer or estimate a parameter vector with d entrace with the sample size that is smaller than d. Here, the trick or the catch is that you can That you kind of work in problems in which theta has an effective dimension, let me call it the dimension of theta, that is much smaller than the sample size. So even if the parameter vector is very long, its effective dimension in a sense is much smaller. And the canonical or the most important example of this is the cases in which theta, the parameter space, is the space. The parameter space is the space of S0 sparse vectors in RD. That is the set of vectors that have only S0, you know, non-zero component, and you take S0 much smaller than D and And it's zero, much smaller than that. All right, so this is the whole area of compressed sensing and sparse regression, high-dimensional regression, etc. So what I'd be concerned here in the next couple of lectures will be a case in which, let's call it noisy, high-dimensional statistics, in which the d over n is of order one, and also the dimension of theta, if theta is simple over n is of order one. All of these quantities are all diverge and they are all of order one. This is to say asymptotic. Okay, so let me give you a couple of examples. Of problems that one might look at. So let me start, for instance, one example number one. I will not treat it this example, but is an example that can be treated in this vein. You have your distribution ZI, the sample ZI, are IID with the mixture distribution. With the mixture distribution. So, these are our samples that are IID samples, and with probability half they are generated from a Gaussian. Generated from a Gaussian with mean theta zero and covariance identity, and with probability one-half are generated with mean minus theta zero and covariance identity. In one dimension, this will look like this. So you have n samples of these types, and you want to reconstruct theta zero. Okay, so Leo is going to give a seminar, I think, and you know, is Think and his kind of problems that he looks at in that seminar are kind of a generalization of this problem. Example number two, sparse regression. So the example that I gave before is a mixture of Gaussian. Gave before is a mixture of Gaussians, a sparse regression. So, this is a case in which my zi are yi xi where let's say xi is normal zero identity and say yi is Theta zero times xi plus noise, let me call the noise epsilon i, epsilon i normal zero sigma square. Okay, and and you know, a popular and you know, sparse regression because I, you know, perhaps I can assume that theta zero is sparse. That is, as a constant fraction of, you know, a certain fraction of non-zero. A popular method to estimate theta zero in this case is to minimize the following cost function. Okay, here y is the vector of zero. Okay, here y is the vector whose height entry is yi and x is the matrix whose ith rho is the vector xi. Okay, so what is the rational for this cost function is that okay if you want this is minus log p theta of z. So this is the maximum like So, this is the maximum likelihood component, and this is a regularization terms that promote theta sparse. Okay, um, oh, well, I'm out of time. Okay, so these are two examples you can make. Examples, you can make up many other examples by changing, for instance, the details here. For instance, you can change the distribution of the noise epsilon and then look at what's called sometimes robust regression in which instead of minimizing the sum of squares. Of minimizing the sum of squares, I'm minimizing another penalty. Okay, where rho is a function. Okay, perhaps you, for instance, you can take rho to be the absolute value. Okay, so these are three examples and. And again, we are interested in studying asymptotic behavior of these methods in these problems. And I will describe in this lecture two methods, in the next two lectures, two methods. One is Gaussian comparison. Okay, so these are kind of classical techniques, but they've been revived in this context fairly recently. And the nice thing is that they are really simple to apply. And they are pretty elegant. And another set of techniques that I'll talk about is related to this approximate message passing algorithm. Message passing algorithm, and the advantage of this kind of method is that it is their algorithmic in the sense that they don't only give you an analysis of the problem, but also give you really an algorithm that solves it efficiently. Okay, so perhaps I'll take a little break as recommended by Lucia. As recommended by Luigi, and I'll check whether there are questions. Thank you. There are a couple of questions in the chat. Okay, one question. Do you want me to read them to you, Ambrea? Yeah, I don't know if I can read the questions. I didn't like. Okay, one question which was. Okay, one question which was asked, which okay, someone answered, but it's why is this example called robust? Ah, yeah, okay. So, this example that I mentioned here, why it in general is really called M-estimation in statistics. And but a special case of it, this was popular and robust statistics. Was popular and robust statistics, and the idea. Now, okay, the basic idea is the following: you know, in what I described before, in the square loss, you see, the square loss, the point is that the square loss is very sensitive when you have a data point that is an outlier. Okay, so the simplest example of this thing is, of course, the one-dimensional example, right? In which you are given data points, you know, let's say Z1. say Z1, Zn that are IID with some, you know, theta, they are equal to theta plus epsilon i, where epsilon i is some noise, right? And you want to compute the mean, some zero mean noise, and you want to compute the mean theta, okay? And so what people do since the Gauss is you compute one over n sum over r, or before gauss probably. Before Gauss, probably z i, okay, which implicitly is minimizing sum over i of z i minus theta square. Okay, so where this comes from is from minimizing this cost function. But something that you know very well is that the mean is very sensitive to an outlier. If you have a single outlier, this will hurt you a lot. And so, something that is sometimes better to do is compute. Sometimes better to do is compute the median, for instance, and so this corresponds to changing the cost function, right? Instead of minimizing the sum of square, I minimize the sum of absolute values. So by changing rho, I can obtain more robust estimators. So this gives the median. I hope this answers the question. So here's one. We are not going to cover the Bayesian interpretation of the penalties? That's the question. Well, no, I'm not going to cover any Bayesian interpretation. Of course, you can think of, if you add, if you look, for instance, a cost function like the last so, you can give a Bayesian interpretation in the sense that this is. In the sense that this is the mode of the posterior when the noise is Gaussian and when the prior is Laplace. But I don't think, for instance, the Bayesian interpretation is very illuminating in this case. And actually, I think it's misleading in this specific case. But we'll discuss something that is Bayesian in nature in the lower bound. Nature in the lower bound, what follows probably tomorrow. Okay, I'm not sure exactly what this question is referring to, but it says, or absolute values equal to row, perhaps? I'm not sure. I think that was referring to the robust regression answers. Okay. Yeah. So here in this case, this is, I'm thinking of this summarization. I'm thinking of the sum over i rho of zi minus theta. Yeah. So in this case, yeah, I'm taking rho to be the absolute value function. All right. So so today I'll try to describe this approach based on Gaussian comparison. And the basic theorem is the following inequality. Is the following inequality inequality and says the following: you have two Gaussian processes, finite Gaussian processes. So these are indexed by some finite set, and so they are centered, and T and S are finite and you assume the following. That okay, the variances are equal point one, point two, you assume that if you keep this first thing, the first index Unchanged. Oh, this is minus X, sorry. So this goes in this direction. For all T one. For all T1 different from T2, different or equal, doesn't matter. And the third condition is that the colours are going to be a very important thing. And this is for all this one and all T1 through two. Then, if you assume these three conditions was, then I'm gonna look at the mean. The mean over s, the max over t of x s t and then gonna allow me some shift xi and the claim that this is you know dominates stochastically the mean over s the max over t of R of YST okay. And by dominate, so this is for any set of xi. xi are real number. And you know, dominate stochastically, what I mean by this is that, okay. Okay, let's say that Adams. Okay, so this is going. Okay, so this is Gordon inequality. I will not prove it. It's not a difficult proof. It's something quite simple. It's not that often taught. Something that is more commonly taught is often taught perhaps because maximum problems perhaps are not so popular, but something that is more popularly taught is. Popularly thought is Fernik inequality, and you can see that this generalizes Fernik inequality that you recover if you, for instance, set one of the inner optimization problem to be trivial. So, if you take the set T to be of size one, so the maximization problem becomes trivial, and therefore, this is inequality. And therefore, this is an inequality between minima or maxima that is the same. And you have the usual thing that if one of the two Gaussian distances dominates the other, then the minimum dominates stochastically the other minimum. So this is the inequality. Perhaps I should show it again. So the true condition to check are these ones. And okay, so what I want to describe is how. So, what I want to describe is how it's applied to one of these statistical problems. Okay, it's not complicated, it's just a matter of choosing things in the right way. And the convenient corolla is the following. Take two sets, U. Okay, I'll take you to be in R D. To be in Rd, say, and B in Rn. And just to be careful, let's say that they are compact. And let's take a function Q that is continuous. Probably. Okay, and then I'll define two quantities. Okay, first of all, let me take a matter. Okay, first of all, let me take a matrix G that has element gij that are iid normal zero one and two vectors g normal zero one I id and uh h Okay, so I'm given two matrix. The matrix will be n by d and two vectors g and h. Okay, and then I'll define two quantities, two max mean problem, and star. This depends on the matrix G and this is the mean over U. Over u in capital U of the max over B in capital B of B G U. This is color product plus Q U D okay, and the other one will be C star or okay, let me call. Okay, let me call it B star just of G and H. This will be the mean of the max of, and now I'll do something much simpler. Okay, so I have these two problems. Then the claim is that okay, let me write it here the The probability that L star okay, let me omit the argument for any U okay so in other words B is a stochastic lower bound tool. A stochastic lower bound to L. So this gives you one side. Further, if the problem min max is concave, combats concave. So, what I mean by this, I mean that this. So, what I mean by this, I mean that this optimization problem is. So, you see, each of these optimization problems, there is a part that is linear in U and linear in V, the first part. Okay, at least if you look at the first optimization problem, there is a part that is linear in U and linear in V. And then there is another part that is a function Q U V. So, you want this overall objective to be concave in V and convex in U. And convex in U, and the two set U and B to be convex. Okay, so if that happens, then you have the reverse inequality. So, the nice thing is that this basically, you know, I'm That this basically, you know, in the case of convex concave problem, if B star concentrates, this gives you upper and lower bound, and the upper and lower bound will basically concentrate around the same value. So the typical picture here is that the probability that B star is bigger or equal than U as a sharp term. As a sharp threshold around the typical value, and therefore, if you use these two inequalities, so this is let's say the typical B. This is let's say U. And this is the typical B. So it has a sharp threshold around a certain B, in which it goes from zero to one, this probability, and there. One, this probability, and therefore, if you use these two, this bound and the previous bound, and this other bound, then you get that the probability also that L star must also concentrate around this lowercase b. Okay, now what is the interest of this is that if you look at these two optimization problems, the first optimization problem has this part that is, okay, is this Q U B that is general, but depends on. That is general, but depends on U and V. Also, the first, even if QUV is simple, this bilinear part in V and U depends in a tricky way on U and V. Instead, the second thing, the second optimization problem is much simpler because basically if you treat norm of V and norm of U as constants, it becomes separable in U and V. So it amounts to optimizing each coordinate of U. Optimizing each coordinate of u and each coordinate of v separately. So if you forget, or another way to think about it is that if you forget the norm of v and the norm of u here, this problem is basically linear, module of the function q u b. So the second problem is much simpler to analyze than the second. So I claim that this corollary is really, as I said, a kind of immediate consequence of Gordon theorem. Gordon theorem. Once you come up with this comparison, it's just a matter, you know, these are two Gaussian processes. You're optimizing two Gaussian processes that are indexed by vectors v and u. So there is a trivial technical difficulty is that okay, v and u range over sets that are not countable, not finite and not countable. But okay, I chose my assumptions here. Okay, I chose my assumptions here in such a way to make this easy, right? I can discretize the sets capital U and capital B because they are compact, and since Q is continuous, I'm in good shape. So going from finite set to infinite set is not a big deal here. The only thing that we have to check to apply Gordon is to check that the covariances are in the right order, the covariances of the two problems. Covariances of the two processes are in the, you know, this q plays the role of the constant xi. The only thing that I have to check is that the covariances are on the right order. And okay, I'll do this quickly, this exercise. Okay, so I have these two processes again, what I call X in Gordon's theorem. This is B times G U. G U plus U times H V and what I called Y is V times G U plus and okay, here is a trick I'll add you know Z times norm of U times norm of V where Z is another scalar random variable. Variable. This Z might make my life easy. Notice that this Z doesn't appear in my optimization problem here because I wanted to keep things clean, and I'm pinged for the sloppiness of putting the Z here by this factor 2. So this factor 2 is basically the effect of conditioning of Z being positive or negative. But you understand that this Z is not play a big role, it's just a single scalar. So now I'll check that these two. So now I'll check that these two processes are in the right order as required by Gordo's theorem. And okay, so the way the calculation that you have to do is computing x u1 d1 y u2 d2 minus expectation of x u one d one x u two y d two. And okay, you see, when you compute the covariance of u, you get a piece that comes from you get a piece that comes from this guy and a piece that comes from this guy. Okay. And so those two pieces are one is the piece that comes from the matrix term as the form of U1 B. U1 V1 times, no, that doesn't make sense. U1 U2 times V1 V2 and the piece that comes from the Z guy is trivial, it's simple. U1 U2 B1 B two and then. And then there is the you subtract the dx contribution. And again, there is a piece that comes from this term and a piece that comes from this term. And of course, they are symmetric, so they are simple to compute. And you get is one is u1, the first one is u1, u2 times v1. times V1 V2 and the second one is V1 V2 from H times C times U1 jumped around U2 okay so if you put everything together this difference is now magically let's see what I should write. Let's see what I should write. It's magically U1 U2 minus V1 minus U1 U2 times V1 V two minus U one V two Okay, and and uh And because of Coshwars, these two are positive, so this is always positive. And then you check that this implies all the conditions that you wanted. Okay. So this proves this corollary, the first part. Okay, how do you prove the convex thing? This is just a duality argument. If the problem is concave, convex, then this L star is a mean over U. Over u max over V of V G U plus blah blah blah and this is equal to max over max over the mean over u and here I'm using the the concave convexity. Concave convexity. Okay, and this is okay, this is of course minus of the mean over v, the max over u of v minus g u plus blah blah blah. And now this minus g matrix is really you know distributed. Is really distributed as the G matrix. And therefore, I can get a bound on the other side by this argument, by the same argument as before. Okay, so this describes a general corollary. Now I want to describe how to apply it. And instead of taking the most general setting, I'll take the last. So, how to apply it. And okay, the basic idea is: okay, I want to study, if you remember, so in the lasso, I wanted to do a sparse regression, and my cost function looked like 1 over 2n, and then there is y minus x theta squared. x theta square plus lambda theta one norm. Okay. Okay. And what I'm interested in is I'm interested in the minimum over theta of ln of theta. So that this is not a min-max problem, but I can write it. mean max problem but I can write it as a mean max problem simply as the mean over okay first of all let me let me do something this has a first difficulty is that here y and x are correlated so it doesn't take the simple form as as we were describing before but I can use the fact that y is equal to x times That y is equal to x times theta zero plus a Gaussian vector. And I can define theta minus theta zero equal u and so I get that this is the mean over u in R d of one over two and then sigma w w is Sigma w is a Gaussian vector with IID, you know, Gaussian coordinates minus xu. Okay, now this is very nice because now all the randomness, all the Gaussian randomness is in this matrix X, that is exactly, you know, up to where a scaling is just the same. Whereas scaling is just the same as our matrix G in the in the little lemma. Okay, and now I want to write this as a min-max problem. And this is just simple. You write this as oh, sorry, forgot the max max will better be, and then there is. And then there is one over and then and then minus sigma w times v plus lambda times okay. Okay, so this takes now exactly the form that I described before. This piece is V G U and all the rest is the function. Q. Okay, and at this point, I can characterize. So, by using Gordon theorem, I can prove that the minimum concentrate around a certain value. Now, this is not what I'm really interested in. What I'm really interested in is computing questions properties of theta hat of the minimizer. And the way I go about it is simply saying, okay, I'll define the minimum of this over a set S. And I use Gordon theorem to compute the limit of this value. And if the limit of L star of S is bigger. L star of S is bigger. Okay, I just use the fact that if strictly where this is the global minimum, this implies that theta hat is in S complement. So, by choosing in the right way the set S, I can show that. Way the set S, I can show that theta hat is in a certain other set. So for instance, I can take a typical thing that I want to prove is that theta hat minus theta zero, two norm square concentrate around some value, so converges, for instance, in probability to some limit A. So I'll take S the set of theta such that theta minus theta zero. minus theta zero square minus a is bigger than epsilon all right so by proving that the minimizer in this set is is bigger i i i can prove that uh you know this convergence this kind of convergence theorem okay so this is Okay, so this is the basic idea of how this is done. Now, let me describe in five minutes. I want to try to describe the result, the typical result that you get here for the LASSO. And I'll describe one precise theorem, I'll just state it. And so the setting is you take n and d goes to infinity, and then n over. And then n over d goes to some ratio delta say. And I'll assume what I'm assuming about theta zero is that if I look at the empirical distribution of theta zero, this converges, say, W two distance to some limit law, P theta. And so now the limit is described by a set of you know solution of a set of equations. So I call theta star beta star the solution of the solution is unique of these two equations theta squared equals sigma squared plus one over delta. plus one over delta expectation of eta theta plus two z minus theta square okay this is the first equation and the second equation is beta equals two times one minus one over delta probability okay Ah, okay, let me write it this way. Theta plus dot z absolute value. Okay, so these are here, these equations are with respect to capital theta that has the distribution P theta and A naught z that has normal zero one and the two have to be independent. And the two have to be independent. Okay, so you know, okay, I will not describe at the moment where these two equations come from, but you solve these two equations. This come basically, one way to derive it is to analyze this Gordon problem. Here, okay, there is one thing I didn't define. Okay, I was a bit quick here. So, here there is another parameter here that I call tau lambda ver beta. Lambda ver beta. Here I didn't define this function eta. Eta of x and u is a special function is x minus u positive part times sine of x. So it's a function that looks like this. It's zero between minus Is zero between minus u and u and then is linear outside the interval minus u. Okay, so but you know, I solve these two equations in tau and beta, okay, and then and then you know this will give me the limit value of the limit distribution of the last. So, in the following sense, okay, one minute, let me just state this thing. Uh, I look This thing, I look at muhet lambda. This is one over d sum over i one to d delta theta zero i theta i. So this is the joint empirical distribution of the true vector and the Lasso estimate. And then on the other hand, let me call mu d lambda. Lambda is the law the law of theta and theta eta tau lambda over beta star of theta plus two z okay and the theorem is that the probability The theorem is that the probability that the distance between μ hat and μ hat d is bigger than epsilon is smaller than some constant of epsilon e to the minus n, some other constant of epsilon. Okay, so basically, this is you know what is telling this theorem is give you the complete joint empirical. Complete joint empirical distribution of the true parameter vector and of the Lasso estimates, and in terms of the solution of these two equations. So you solve these two equations. This is very easy. This gives you two parameters, to embed. And then you compute these two random variables. One is theta, of course, and the other is eta applied to theta plus Gaussian noise. Noise, you compute these two. And I'm sorry here, I messed up my formula. Okay, and then you know, these two are closed in the sense that their distribution are close, for instance, in Buser-Sein distance. Okay, so I'm sorry I went over time, but I guess that's all for. But I guess that's all for today. That's okay, thank you. So we will now stop the recordings. We will unmute all the participants to thank Andrea. And now I stop. We will now stop the recordings and the live stream and have a question period. After that, we will also have breakout rooms so people can also chat informally for a while longer if they like. So feel free to unmute yourself to ask questions at this point or ask on the chat if you prefer. Yeah, now we can see the chat there are a few questions in the chat. Do you want to look at them, Andrea? Yeah, I was looking. How do we get the PDF?