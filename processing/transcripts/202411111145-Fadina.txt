How to work on a framework of measures of risk under uncertainty. And this is a joint work with Yang Liu and Rudo Wang. So the motivation comes from the fact that when a risk analyst wants to assess the potential loss in a portfolio, it's probably going to consider different sources of information. Information. So, in most cases, the assessment is not only based on the specification of X, which is a random versus, but also on the different sources of scenario. But then in the literature, when you look at risk measures, risk measure is often defined on a set of random losses with the assumption that the scenario model is fixed, which is kind of unjustifiable. So, in this paper, So, in this paper, we design a unifying framework whereby we define risk measure jointly on the set of random losses and then on the set of probability measures, which we can see or define as set of possible scenarios. And we call this type of risk measures generalized risk measure. So, in this talk, Measure. So, in this talk, I'll introduce this generalized risk measure and then I'll introduce the properties and then try to characterize it. And then again, we look into the literature and we look at the mostly well-used risk measure, the coherence risk measure, and then we try to characterize this risk measure in our framework. And then, also, another crucial property when you talk about this measure is you look at the lawyer. This measure is you look at the law invariance, and then it turns out that in our framework we have different forms of law invariance. So, we introduce this type of forms of law invariance to you and then kind of connect it to what we already know in the literature. Okay, so risk measure, if you all know that risk measure basically just map risk via a model to a number and is used for regulating capital calculation, insurance pricing, decision making. Insurance pricing, decision making, and then the list goes on like that. Okay, and then again, Haskell, in the literature, listening measures are defined, the set of randomness, which I said earlier. And then there are two important aspects to it. You look at the specification, which basically, you know, you try to define the risk in the sense could be maybe financial loss or gain for holding assets or derivative or investment. Well, other investments. Other investments in the portfolio, or you look at the modeling, which basically is the statistical assessment which tells the likelihood or the severity of the loss. But then there is a gap. So again, this is the gap. In practice, neither the losses or P is generally fixed. So this kind of evolve. So a change in health means you adjust your. Health means you adjust your positions by trading financial securities, and a change in PIN basically means you try to update your modeling techniques. Which again tells that when one wants to look at risk measure, then it's important that you consider not only the set of random losses, but also you imbibe your modeling, which is the set of possible scenarios in your definition. So, again, Definition. So again, you finance both X and P, you involve on a daily basis. So this is a typical example. So suppose that a regulator specifies, let's say, risk measure, expenditure shortfall at 7.5%, and then this regulator kind of gives two different frames, same portfolio, and asks them to compute the experience for at 27.5. At 27.5. Due to the different underlying models or their modularity techniques, they are likely going to report different values for this particular risk in this portfolio, even though they have the same portfolio. Again, the risk measure should not be only determined by the specification of eggs, which is a portfolio risk, but also considering this set of possible scenarios. Of possible scenarios. And then that is one of the reasons why we introduced this new risk measure, which I said we called the generalized risk measure. So we define this risk measure jointly. So we consider the lost random variable and also we consider this set of probability measures. And then another motivating example is how the Vasil Committee on Banking Supervision works. So when you look at the structure of the Look at the structure of their framework, you have two main players. So, you have the external player and then you have the internal player. So, the external player can be the regulator, but then the internal could be the financial institution. So, for the financial institution, then you have the risk analyst, portfolio manager, and then you have the model risk manager. So, let's start from the regulator. So, their roles is to specify. One of their rules is to specify the rules for choosing this scenario and then specify the generalized risk measure. And then they give this information to the risk analyst. And then the risk analyst, you know, go does a scenario queue and then work with the portfolio manager who chooses the portfolio position and give this to the risk analyst. So using the information from the regulator and the portfolio from the portfolio manager. Portfolio for the portfolio manager, the risk analysis is going to evaluate the risk value here. And then this information will then be given back to the portfolio manager who will optimize to choose the best portfolio of risk care for the internal need. And this will be given to the model risk manager who will backtest the model and then they will report it back to the portfolio manager who will then report the risk value as a capital. Report the risk value has a capital requirement. So, when you look at what happens there, you hold actions there. The role of the regulator or the actions of the regulator is kind of fixed. However, everything that happens within a financial institution evolves daily. Okay, and that brings us to the generalized risk measure. So, here we define the generalized risk measure. We define a generalized face measure, which is just a mapping. And like I said, now this measure is defined jointly on the set of random buses, and then we have this set of probability measures. And then this generalized risk measure is called standard if you want to assess the risk of heads given this set of scenarios. But if that is a customer, there is no risk around it. So that is going to just. Going to just report X. And then we have what we call the scenario or single scenario risk measure, which is kind of, you know, more like the generalized risk measure. But then we look at the central seven argument here. And instead of having this power set, so here you have this P, and that P is just more like a set of singleton of scenario. And then we call this. And then we call this single scenario risk measure the curl. So when I mention core going on, I'm basically referring to a less risk measure whereby the second argument is basically just this set of possible scenarios. Okay, so these are the properties that pin down the generalized risk measure. So we have the So we have the uncertainty aversion, we have the scenario monotonicity, and we have the scenario upper bound. So the first one, the uncertainty intervention basically tells us that the risk assessment of, well, I say, if modern uncertainty increases, then the risk value will also increase. And then the second one basically tells. And then the second one basically tells us that if I want to assess the risk of X, considering if I want to assess this assessment of X given a single scenario P, if this is less risky than the assessment of Y under the single scenario, then the overall risk evaluation of heads giving Q Of heads given Q would definitely be less than the overall risk evaluation of Y given Q. And then we have this third property, which is a scenario hopper bound. And what this tells us is that the evaluation of risk on hex, giving Q cannot be extreme than when you consider the worst case scenario. And then this is what more like examples of generalized. Of generalized risk measures, clearly when we look at the value at risk and then the experience shortfall. So, this is the classical definition: value at risk and experience shortfall. And in our case, when we consider generalized risk measure, then it's basically more like looking at the worst case value at risk for the value at risk and then the worst case expectations for. But then, keep in mind that you have this in the sense that your In the sense that your random losses and then also the set of gravity measures, they are hydrally considered endogenously in the sense that here, modern uncertainty is considered in the modeling. So, for example, I mean, a natural question would be, how is this different from what we have already in the literature for those that are familiar with the worst case value at risk or the worst case expiration for? Case expected shortfall. For here, one model uncertainty in a classical setting is introduced as exogenous subjects, which is not the case in our framework. Also, in our framework, Q, which is a set of scenarios, can actually vary. So you can work with different sets of scenarios at every instances. Okay, so these are related literature. Are related literature. So, for risk measure, again, if you are familiar with the robust converse risk measure or the scenario-based risk measure by Wanda and Zieger, again, in their framework, they introduce modern uncertainty as well. So, they define this measure, consider modern uncertainty. But their framework is different from ours in the sense that, again, in their framework, the set of probability measures is kind of fixed, which in our case is the Fixed, which in our case it is not fixed. Again, in their framework, model uncertainty is introduced as an exogenous object, which in our case, again, it is imbibed in the modeling. And when you look at decision theory, I mean, we have a long list of literature that consider the study decision theory under uncertainty. So we have the work by Gebob and Maya, the one by Macaroni and Arena, and then Are Nassi, and then we have this one is on variational preference under modern uncertainty. We have the one by Dila and Dachos, and this paper by Piglo Ansett, Macroni, and Mirianasi, which is very close to our setting, but again, their framework is based on decision theory, where I have is based on risk assessment, and then again, in our own case, model uncertainty. His model uncertainty is kind of introduced in our model endogenously. And then we have literature on robust portfolio optimization. This one by Hei Caro is based on worst case value at race. The one by Zua Shima is based on worst case expected shortfall. And when you compare this literature to what we did, GAS is more like an example. Yes, it's more like an example of our set. Okay, so now let's just try to characterize the generalized risk measure. So for generalized risk measure, psi here, we suppose that the psi is standard and it satisfies the uncertainty of ration and scenario monotonicity if and only if it admits all things for excitation, which is. things representation which is more like the worst case representation there and then again if size satisfies uncertainty aversion and scenario upper bound um size satisfies uncertainty aversion and scenario upper bound if and only if again it admits this representation. So it's quite straightforward to establish that this representation satisfies uncertainty agrees and scenario monotonicity. And for the other direction, And for the other direction, it basically follows from us trying to establish equality of two inequality in the sense that when you consider the uncertainty aggression, you are going to have this representation where you have the less than or equals to and then it's never going to still give you the other direction, which gives us that result. And then the same approach for the second result here when you consider the answer. Result here when you consider the uncertainty of version and then this narrow upper bound to establish that this representation actually holds. Okay, so I think the takeaway from this slide is just to tell us that the core, which is when you define the generalized risk measure, when the second argument is just this p, which is set. Um, P, which is a set of single scenarios, basically correspond to the standard generalized risk measure that satisfies the uncertainty operation and then the scenario monotonicity. And if this theorem holds, then we can say that the curve on the when we define the risk measure jointly, the set of random losses, and then the set of our singleton of scenario. Singleton of scenario induces the generalized risk measure. So, going forward, my prioritization will be based on the core of the generalized risk measure. But just keep in mind that this actually induces generalized risk measure. Okay, so there's a special type core. Again, this is it, and then this induces generalized risk measure, and this, if we reduce If we reduce, if we fix Q, and if we fix Q, then this can be seen as the robust coherent risk measure. And just the same thing for the case of the penalized extension type 4. So this induces the generalized, let's say, convex risk measure. And then if you fix Q and you produce an exogenous subject, this is going to correspond to the traditional, the robust traditional. Robust traditional converse risk measure in informal and shade book. Okay, like I said earlier, one of the important properties of mist measure is when we look at the law invariance. So what law evariance basically tells us is that if I have two mistake positions with the same distribution with respect to the initial probability, then I should have assigned the same risk value to these two. Same risk to these two risky positions. But the question here is: when we have this generalized framework where we are trying to define risk measure jointly on the set of random losses and also on the set of probability measure, then what would be the correct form or expectation of the law or law invariance in this setting? And this brings up this natural. And this brings up this natural question, which is: if I want to evaluate the risk in a portfolio, what should it depend on? Will it depend only on the distribution or both the distribution and the scenario model or both the distribution and the lost variable? And to answer this, then we are going to go through the forms of law invariance that we have in this setting. So, the first one is the strong. So the first one is the strong law invariance, which tells us that if I have a MISTIP position hex given P and this has the same distribution as another MISTI position Y given Q, then I should the risk assessment of S given P should be the same thing as that of Y given Q. So this can be reduced to the classical law invariance. And then we have this loss law invariance, which tells that if I Which tells that if I have considered H given P, and this has the same distribution as Y given P, then the risk assessment of H given P should be the same thing as that of Y given on P. And then we have the third one, which is this neural law covariance, which tells that if I have HMAP and this has the same distribution as HESDMAQ, then this assessment on HESDMAP to be Assessment on hex giving P to be the same thing as that of hex given Q. So, one way to put this into perspective is to think of P as, let's say, an economic scenario. So, you can think of P as a good economy and then think of Q as maybe not so good economy or think about the economy during COVID. And what this is saying is that if I have a position head during a good economy, and this had the same distribution as a position. Distribution as a position why during a bad economy, then I should still assign the same risk value to these two. And what this is saying is that so p is my good economy scenario, then if I have a position hex in a good economy, and this has the same distribution as y in a good economy, then I should be able to assign the same risk value to these two. And what this thought is saying, I mean, this general law invariance is saying. Law invariance is saying is that if I have this position in a good economy and it has the same distribution and I have the same position again, let's say in a bad economy, they have the same distribution, but keep in mind that we are considering two different economy here, then the risk assessment should be the same thing. So these are the three forms of law invariance that we have in this new framework. New framework when we define risk measures jointly on the set of random losses and set of probability measures whereby the measures can actually vary. Okay, so the cause, they are strongly, these cause are strongly low-invariant. So basically, I just try to go back to the examples that I gave earlier when I'm trying to introduce the cause that induced a generalized risk measure, and then I'm trying to. This measure, and then I'm trying to classify them here into whether they are strong blood invariants or they are lost blood invariants or scenario blood invariants. And then it turns out that expectation, value at risk, they have strong law invariants. And then when you look at this type of risk measure, when this is a matter of the converse risk measure, this is more of a, this is loss law invariance. And when you look at this type of risk measure, this belongs to the class of. This belongs to the class of narrow loss law invariants. And then also, we show this equivalence between the strong law invariance and then the lost law invariance and the scenario law invariance, which we classify as the weak law invariance. So, basically, we showed that for a curl of generalized risk scenario, then the strong law invariance basically implies both the lost law invariance and the strong variable. Both the loss-glaw invariance and the scenario lost law invariance. And then we try to establish the other direction, which you can only prove if you have your state is a standard rule here. Otherwise, you cannot kind of establish that. Lost law invariance plus general law invariance is going to give you strong law invariance. So, further, we kind of represent the generalized risk measure, but now. The generalized risk measure, but now in the context in the context of loss and the context of law invariance. So, just a quick definition here. So, here is just a set of compact supported distribution of R, and then this is more like the distribution of X on the B. And then this, my sigma, is just the set of all law invariants. And then hit mapping, which is like this distribution, this set of my distribution here represents the. And my distribution here represents the traditional loss law invariant. So, basically, here we just want to introduce risk measure, but then we want to define risk measure on the set of distributions. Okay, so by law invariance, we just characterize the worst case on generalized free measure here, basically defining it on the distribution set. So, similar to what we did before, so if far here is generalized free, Here is analyzed risk measure, then we say that size satisfies the first property, which is uncertainty of version, and then the uncertainty of background, and then this one is the strong blow invariance. If an holy heap, there exists this blow invariance such that there are lights-wisk measures, and then Eureka has this worst-case law invariance. Again, instead of straightforward to prove this, in the sense that This in the sense that if size satisfies the uncertainty of ratio and the scenario upper bound, then immediately I have the representation for generalized risk measure. But here I'm going to have the size of x given p. But since I'm considering strong blood invariance, a strong blue invariance from the properties that we saw here, we can see that it's indifferent to this economic scenario and also. Economic scenario and also is indifference to the risky position. So, in that case, then I can easily just write my size of hex of p as the law invariance function there. And that is how we established that. And they just the same procedure to show the representation for the last law invariance and also for the scenario law invariance. So, the next thing that we want to do is basically just to characterize the coherent risk measure in our setting. That will be the coherent generalized risk measure. So, these are the properties of, I mean, the traditional risk measure, you have monotonicity, the cache activity, post-homogeneity, subactivity, hypnotonic activity, which basically tells that if X and Y are monotonic, that means that if X and Y are moving in the same direction, Why are moving in the same direction? Then the risk assessment of heads versus why should be the same thing as when you assess the risk on heads and the risk of why separately. And if one and two are satisfied, then you have the monetary property, and if still monotonicity, cash activity, post-homogeneity, and sub-activity is satisfied, you're going to have the coherence property. And then to characterize the coherence generalized risk measure. Coherence generalized risk measure, we need this additional property which we call that it of curve. And so, for the results, we basically just say that if somebody generalized risk measure satisfies uncertainty aversion, uncertainty monotonicity, strong blood invariance, and then monotonicity together with activity, they are going to have this representation. Again, to establish this follows from representation, I'm Representation, there is an assumption that if A1 and A2O, that you're going to have representation for the generalized risk measure. And if you have that, you know in the literature that the risk measure is monotone, standard, additive, and it's low invariance, then that risk measure is likely going to be of expectation time. And then we basically just use that to pin down this representation that we have there. And the good thing is. There. And the good thing is, this kind of risk measure is already being used in practice, just that has not been characterized in the literature. That is basically what we try to do here. Then I think my time is almost up, so I will skip this part and I will just move to the connection to decision theory. So again, in our framework, we try to understand what will be the result or the extension of the result that we already have. Extension of the result that we already have in decision theory on the uncertainty. And the idea here is: decision is to compare risk and a set of scenarios with another risk on another set of scenarios. So, popular literature on decision theory, other uncertainty is this work by Gibo and Schwedler, where they consider multiple preference. And this is the representation again. Representation again, we just extend what they did to our framework. Basically, considering the fact that you introduce model uncertainty endogenously in your framework, and then we have this work by Edmacaroli, Marasi, and Shine on variational preference. And then again, we kind of extend their results at FRIMO. And this is kind of very straightforward to do. Looking at this presentation, you can see that this is very. Representation: You can see that this is very close to robust convergence-wise measure, just that instead of having the expectation, then you have the expected utility here, and then you have the minimum instead of the supremum. So, we use the same idea that we use to represent the convert risk measure on our setting to basically just establish their extend their results. And then, this recent result on model in specification preference, what they did in this paper is very. What they did in this paper is very similar to our framework as well. And they basically just extend their results to our framework. So I characterize one of, so this particular result by Grobler and Schidler, we have the, we characterize it in our paper, but because of time, I will just go through the properties that we need to do that. So basically, we transfer the result that we have or the one that. The result that we have, or the one that we use in the risk measure to decision theory. So, this is one like the strong variance that we have in risk assessment, and then this is uncertainty version, the uncertainty bond. And then we use independence and the continuity property in decision theory. And those are the properties that we used, and we're able to establish that the preference on this page satisfies those properties that I listed earlier. Properties that I listed earlier: if and only if it is a multi-prong expected utility, that is, if there is a utility function which is increasing, then we can actually establish that if this is less preferred to this, if this is less preferred to this, then the expected utility on X should be less than that of the one on Y. And then again, the proof is just followed directly from our representation for the generalized risk method. For generalized risk measure and the classical results in decision theory by one Neymar Hannon Walkerstein. So, my contribution in this paper will develop a framework for generalized risk measure and then we characterize this risk measure. We introduce the concept of strong law invariance and then it turns out that we have three forms of law invariance and we try to understand the relationships between these law invariants and then we extend our results to decision. We extend our results to decision theoretic outlook. And that is all I want to say. Thank you. Can you show me an example of a generalized risk measure which is not a standard risk measure? Okay. I don't see the difference on this. So, yeah, so I don't have an example of a risk manager. Yeah, so I do have an example of a risk measure that's not the standard. Generalized risk measure that's not the standard risk measure. However, what I can tell is that not all risk measure can actually be characterized as generalized risk measure. For example, if you look at the first property there, which is the uncertainty aversion that we have. This property basically tells that if you are considering. Tell us that if you are considering average risk measure, then this is not going to work. I agree with that, but my feeling is you cannot choose your Psi function and your Q set independently. Because you had Psi, and Psi already controls a set of probability measures. Now you put another set of probability measures on top of this. So this has to be consistent. Now I see this works when you have a reference measure. Reference measure, then you put this Q set on top. Measure, then you put this q set on top, and you end up with this robust representation, which gives you a standard risk. But what I'm missing is a consistency requirement between the psi and the q. It's already a set of probability measures encoded between psi. Yes, because psi is defined jointly on the set of random losses and the set of probability measures. Hard, YL into choice. Same? Yes, set a probability measures half, yer into choice. This set has to be somehow consistent with the Q? Yeah, because Q has to be a subset or it has to be taken from this set of probability measures. The set of probability measures that we have is more like a power set, which contains different set of probability measures. So it can actually vary. I just have a question or let's say more comment about how you bound or let's say make the amount of uncertainty plausible because I think you're also about the robust control literature where you have the detection error probability where you make an arrow out of bound of how much uncertainty is impossible. How do you specify that in in your framework? Because otherwise I think that it's uh yeah it's very broad, it's very uh hard to apply it, no? Yeah, yeah, I think you're right on that because our soupy here, our power setting is very, very large. And we do not have any restriction on it except the fact that it cannot be empty because it is empty and cannot do anything. But in terms of how large that be, then there is no restriction on how large that can be. Yeah, just maybe the food for cloud would be useful to specify how large otherwise everything goes in a scroll. Sometime that's the memory workers to go. How much do you do in the morning session? Do we have announcements from our late afternoon addresses? We have lunch break until 13.30. We have to start with March.