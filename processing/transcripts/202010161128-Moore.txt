All right, audio still okay? No, we lost it a bit, so maybe we have to be very close to the laptop. Okay. Trying this again. Yeah. Is it when I shared the slides there's an issue? I can hand over the slides. I can't hear anyone. It's okay. Yeah, maybe just continue. Yeah. My apologies. Well, yeah, so at least let me. Yeah, so at least let me get to some of the topics that I want to talk over with you. So I am going to give some motivation. And I think that's one of the important things I want to get to, motivation at the beginning of this session for some of the different work that you're going to get to see from the other speakers. And I'll show one example of our own work, and then I'm going to look at some open problems. Problems. So, really, in drug development, there is this funnel effect. When we start in discovery, there are so many programs that we might consider targets, particular compounds to bind to those targets. And there's a lot of optimization that goes on here in the lab. And then a small number of those, smaller number, come out to be testing in mice, typically first. Typically, first, we do different species testing, and here in the phase one, two, and three is where we go into human subjects and test the compounds. And all along here, there's a lot of money, there's a lot of time, and there's a lot of attrition. So these factors lead up to long timelines. It can be 13 years to develop a successful drug from target validation. From target validation through the approval. It can be one to two billion dollars, and your chances of success for any one that you try are low. So in just focusing on the phase one, two, three, the clinical phases, that's where we hit these large expenses. And as I mentioned earlier, we in the U.S. have led drug development to the private sector. So private sector. So, private sector puts a lot of capital in, and there's risk. Maybe they win, maybe they lose, but all of that cost is needed. All of that money is needed to get a successful drug. And what if we could reduce those costs and the time and increase the probability of success? That would be great. Even a small improvement would be very helpful. And when we looked at the reasons for failures in the clinic, after In a clinic, efficacy is a very common cause of failure. That's the purple region. And then the toxicity, unanticipated toxicity, can be a cause for failure as well. That's another significant area. And so we use modeling to look at questions like what would be a dose that is predicted to be high enough to achieve efficacy? And what would be a dose that is low enough still to avoid? To avoid toxicity. If I talk about high enough and low enough, when we increase the dose, we could hit that tox level. So we come back down from the tox. But we want to be high enough that we're getting efficacy. And we want that window to be as large as possible. So we try to optimize the drug properties to increase those windows. Look for drugs that have large windows. Almost any drug that we might try is going to be toxic if we get enough of it. Toxic if we get enough of it, and that includes drugs we consider safe, like aspirin. But if we get enough of it, it is toxic. So, modeling is often used to address these questions, and these mechanistic systems models that I'll talk about are very commonly used in this part of the drug development process. We would start knowing a target from the biology work. We would use some in-vitro data to calibrate the mechanistic model. The mechanistic model and update that within VIVO, update again when we get clinical data, and make predictions along the way. Once we get the predictions, we validate and we revise and come back again. So this process of modeling and incorporating data, making predictions and revising the model has been shown to be very fruitful in drug development. So there's some really good success stories. Some really good success stories. And one of the keys to the types of modeling that I'm going to talk about is including mechanisms. Having a mechanistic model, not just capturing the data, just getting a curve through the data accurately. That can help us address a lot of the blog questions. What if we had a patient whose kidneys didn't work as well? What if we had a patient whose disease status was worse than the one? Was worse than the ones we had originally tested. All of these different ways of questions can be interrogated in a mechanistic model. And this term here is quantitative systems pharmacology. And we call this PLSP. These really are just systems biology models that you put in a drug, at least one drug, if you don't have more than one. So there's systems pharmacology. Pharmacology refers to the drug. Quantity is used for historical reasons. Is used for historical reasons. It's really existence pharmacology models. And so, commonly, these are models made with ordinary differential equations, and we can study them just like we do in math biology, in academia. Lots of good work going on studying those types of systems. In the drug development arena, we would look at all kinds of questions. And we might look at properties of the drugs and see if we can find properties to keep the doses low enough. To keep the doses low enough, efficacious doses could still be low enough. We could come up with a drug that's going to have a chance of working, so that kind of a toxicity level. And we might look at drugs that could have higher dosing intervals, how long in between the doses. We would make predictions before we go into a clinic. And all of this work to support these decisions along the way from early development through the clinic help us trim those timelines, cut those timelines. Trim those timelines, cut those costs, use those resources to go to other potential better drugs if the ones that we're looking at are not going to be feasible. So I've got a case study I want to share and a few abbreviations here that I'm going to use, the ones that I'm making sure you know about, are pharmacocometics. We abbreviate that by PK and this is really the drug concentration over time. Drug concentration over time for that curve of drug concentration. And I also will refer to intravenous dosing as IV. Subcutaneous dosing as SC. Intravenous is injected into the patient's bloodstream. And subcutaneous, we would do that into some area in between the skin and the muscle below it. So this case study was a situation where a company had collected some data in the clinic and the In the clinic, and the data turned out to be different than they expected. So, when you look at the low dose of this data set, the pattern, the speed at which it's being cleared is different than the pattern or the speed at which this drug is being cleared at a higher dose. Usually, if we see what we call linear pharmacokinetics, then the blue and the green and the red would all have the same shape. They would just be shifted. It would just be shifted three times higher for the green, and then up to the red would be two additional times higher. But that's not what we see. We see something that we would call non-linear concentration behavior, non-linear PK. So that was one of the mysteries that occurred when the client saw the data in the clinic. Another issue that they encountered was they saw high variability in the subcutaneous dosing. And these can be problems when you're trying to develop a drug. Problems when you're trying to develop a drug. If you want to make a prediction of a dose in the next clinical trial so that you can achieve efficacy, that can be very problematic. So they came to us and said, can we help? Can we build a model that could explain the nonlinear PK and the variability in the subcutaneous? With the goal of, you know, they needed to get a prediction that they could hit a certain target by 90%. And if they couldn't do that, but they couldn't confidently predict that they will. They predict that they will succeed here, they might just stop the program now. So that was the problem we had. And here's the model that we created to help. This is a mechanistic model that has several different types of cells. The light blue, the red, and the purple are all different cell types, but they all have the same target receptor. There's this little open target receptor, and there's a natural ligand in the system, in the patient, that. In the patient, that okay. So, their goal was to have a trug that's represented by the Y shape. It's an antibody, so it's a large molecule, and that drug, this antibody, could bind to that receptor. And when that happens, then the ligand, this little L, cannot come in there and bind also. So, it's competing. So, trying to block the ligand from ligand. And this mechanistic model is. Mechanistic model is fit for purpose. It has as few players as possible to answer the question about inhibition. Could we inhibit that lighting body and kind of bump the lighting off and get the drug on? And there are equations that come from looking at each of the cell types. So cell type one in the blood compartment would have one differential equation, cell type two in the blood compartment would have another differential equation, and the drug in the blood compartment would have And the drug in the blood compartment would have an equation, and then the drug in the peripheral compartment would have an equation, and all of there's seven more. So, all of these equations have parameters, and those parameters have to be fit, have to be estimated somehow. So, using literature data, and then using animal data, this is cinnamologous monkey data, the model was fit. Now, you notice it's not ideal, but that's because it's a mechanistic. But that's because it's a mechanistic model. It's not empirical. We're not just trying to get a curve through all of the points. We have a mechanism behind it. And we have certain parameter ranges that we would consider for those mechanisms, those parameters. And so with those constraints, the model can do a pretty good job of fitting both the IV data, the higher and lower doses, and the subcutaneous. And so with that fitting, then we make predictions for the human data. Predictions are the camera data. And here are the predictions. Note, there's some misses here, so we can predict perfectly, but I will emphasize these are predictions before the data and before we saw any of the human data here. So all of the dots are data with the bars to fix indicating one standard deviation of both sides. And so the predictions are also overlaid on the data, and you can see on a lot of these we do pretty well. There's an over prediction at the lower. There's an over-prediction at the lower doses and an under-prediction at the higher doses, but we're within the bands where the higher doses. So that's the really important piece. The other important piece was the target occupancy, or TO. And here's a threshold. We wanted to hit the 90% inhibition. So if we do that, if we give the doses as planned above, do we predict that we would hit that threshold and keep the target below that? Keep the target below that threshold going up. So, in this case, the curve is pretty much matching the data. It's certainly matching about the time we're going to come above the threshold. So, we can see that we may not go below that threshold with these low doses or the subcutaneous, even with a moderate dose for subcutaneous. So, that was intent. Now, in some other examinations, with the variability. With the variability, this was, we created these blue curves by using the variability in the patient, sorry, in the volunteer data, and then predicting what the concentrations should be, and then overlaying with the actual curves for the concentrations. And we have a pretty good match there of the variability in the drug concentrations, just based on the original input parameters. And then the target occupancy was not fit at all. It was not fit at all, but we did predict fairly well how long patients are going to stay below the threshold that we want. So, pretty good prediction. Now, this was used to also show that 120 would not be quite enough, especially in one of the areas that we were testing, in one of these disease areas, indication two. That the patients would be coming up above that threshold a little too soon, and that was. Little too soon, and that was used to justify a higher dose. So the clinical trial was changed, and ARM was added with a higher dose for the subcutaneous administration. And so that amendment happened. And then the predictions of those doses gave these concentrations, and the predictions were fairly good. So pretty good agreement there. And then, as a result, that because That the client's molecule was positioned to be the first in class because they got the jokes right, they were able to continue. Whereas, if they hadn't added that arm, they would not have hit the efficacy. They wouldn't have seen efficacy, and there's the possibility they would have discontinued the program. So, big take a big impact on their program, on their decisions. And they also got this nice period of front payment from... A large upfront payment from a bigger company that had a lot of experience in drug development to help them take that drug and continue it farther. So, those are things that we would consider good outcomes. Okay, now I'm going to, so that's my case study that I wanted to show. Based on the mechanistic model, we were able to help inform decisions along the way. I showed one decision where they made a change in a clinical trial that allowed them to continue the program. Really could. Program. Really pivotal information that was provided for that decision. And then I'm going to just go over a few of the open problems that I find of interest. I'm personally interested in some of these open problems. When we have these large systems models, it could be a dozen equations. It could be many dozens of equations. It could be hundreds of equations. And we have at least as many. And we have at least as many parameters. So there's a question: what sensitivity analysis should we be using for these large models? They're so large and they have nonlinearities that they're very challenging computationally to do global sensitivity analysis. So sometimes you'll see one at a time or local sensitivity analysis. And the question is: are there others that we could use that would be better? Would be better, and one proposal is to use a Morris method, which is global but also not too computationally expensive. There's a partial rate correlation coefficient, which can handle more of the non-linearities, as long as the output is monotonic in the input as a function of the inputs. There's an extended Fourier input sensitivity test, so all these are very. Test, so all these are variant-safe sampling methods. So, there are a variety of things that we should be considering, and there's not a real agreement. A certain size of the model, certain properties of the model, here's what's recommended. I've listed a couple of references that I found very useful. So Ralph's book on uncertainty quantification is one that I've read a lot of and I've been learning from. There's a really nice primer by Andrade Zaltelli and his colleagues. Altelli and his colleagues on global census data analysis. You can find that one online. And so, those are some good references. There's also a question of identifiability. You have these huge models, lots of equations, lots of parameters, very little data. So, you might wonder, is it even possible to estimate some of those parameters? And maybe the sensitivity analysis has shown that those parameters are Parameters are very influential in the outcome. So they're important. So then the question is: what can we identify those most important ones? And here are a few software packages. These are all using differential average rate techniques. And there's one reference here that I like, Cal and Eisenberg, that shows an example of even a simple model, not so large and original, where one parametrization shows the drug to be efficacious, another parametrization shows. Another parameterization shows it's not efficacious. So, very important. Even in a simple model, the parametrization can be misleading and more so for the larger models. I'm just going to mention that I've organized a session at a conference coming up, and Rob Smith and Marissa Eisenberg are two speakers in that session. They're going to talk about sensitivity analysis and identifiability on the next slide I'll show the conference. So, it's a question I think that we really need to. But it's a question I think that we really need. These are questions I think we need to be working on. Model reduction could also be used. Whether we have these computationally challenging systems to do the sensitivity identifiability, we could just reduce the models first. That's another area that I think is important to work on. So to summarize what I've set some time talking about, why use math and data format? It's really about the resources. You see those enormous price tariffs. Price tariffs for just the cost of development, cost, time, probability of success. So, mathematics can be used to reduce those. And if we could save 5%, if you think about the scale, that's very significant. And suppose we could do this more often. We can really pay for that work very easily in the savings. So, an example I showed would use systems normality models as the QSP models. As the QSP models, I talked about a few open problems that I think are very important. I think mathematical and computational researchers could really help us in these areas. And then I also wanted to mention, what if you wanted a job? What if you're a student, you're getting a PhD in applied math or math, and you'd like to do some of this work, you're very motivated to help people who are sick, then why don't I help you get a job? Why don't I help you get a job? Because I want that help. We need your help. And so, one good way to do that is to attend conferences that are mostly industry driven. So, there's a really good one that's coming up, the American Conference on Pharmacometrics. And this conference is mid-November and it's virtual, so you'll be able to attend from any location. And if you're a student, you can register for $50. Register for $50 as long as you do it by Monday. And here's the link. There are lots of great presentations, and I recommend that you go to the posters, find posters that you're interested in. These will be senior people presenting posters. And then go to their poster session and ask them questions about their poster. And that's a great way to meet people in industry and let them know you're interested. So that's where the tutorial is that I have and I organize, and we'll have the tutorial session. organize and we'll have a tutorial session on the 13th Friday and then that will be on sensitivity analysis and identifiability. I also recommend some other conferences where you have industry speakers. So some of the other speakers and I have gone to these conferences, we organize sessions, we will sponsor events of the sessions. So Society for Mathematical Biology and the Society for Industrial and Applied Mathematics. Society for Industrial and Applied Mathematics, SIAAM. Those are great ones. Those have a good industry presence. I also say you can find jobs by looking at LinkedIn and by looking at individual company websites. If you find a list of the largest biopharmas in the Boston area, then you'll get a list and you can go to each of their websites and they will list their jobs there. And you can search for QSP or math or modeling. You can try different things and see how that works. You can try different things and see how that works. And one easy one is the fact that my company has openings right now. So you can go to our website and we have openings there. And I will stop here and see if there are any quick questions before we need the next speaker to start. Yeah, Helen, thanks a lot. So I'm having an eye on the chat. There's nothing. So if you want to ask a little question, you can unmute yourself. Question: You can unmute yourself or put it in the chat and then I will read it. Maybe, Helen, why people think about this? You mentioned sensitivity, identifiability, and reduction. These are not standard expressions in the math curriculum. Would you mind saying a little bit about the three? Sure. Sensitivity analysis says you've got a set of differential equations and they have parameters in them. Parameters in them. And what we'd really like to understand is: how is the output, for example, tumor volume after half a year of treatment, how does that level depend on those parameters if you're going to make a prediction? And so you can think about taking the derivative of the tour volume with respect to that parameter. And if you do it at a point as local, if you do it, sample those values as global to be an average somehow. Be an average somehow. So that's a sensitivity metric that we find to be very useful for determining which parameters drive the outcomes. And for these very complex, often highly nonlinear systems, you could have non-intuitive parameters being the drivers. Some of them are often intuitive, but some of them are non-intuitive. And you actually could use the drods to come up with different drods that have different parameter values. Identifiability is Identifiability is like a matrix, a rank matrix condition. If you look at the matrix of the coefficients of the fishery of equation matrix, so there are certain matrix, and if you have enough independent equations, it's like a system of linear algebraic equations. If you have two equations and two unknowns, then you can solve for the unknowns if the equations are independent. So if they're not linearly independent, then you have enough information. And then you have enough information. So, the question is: do we have enough information in the types of things we can measure? Do we get enough equations with enough information that we can actually estimate each of the parameters in there? And then the model reduction is just you can draw an equation as if you have five equations, you like to reduce it to four or three. And there are these systematic ways to do that. Great, okay. Thank you, Helen. So, that there didn't show up any questions here. So, then thank you very much for your presentation. I thank you very much for your presentation. And then I would just move on to Richard. So, Richard Allen is from Pfizer. And, Richard, I'm sure you will tell us about Pfizer a little bit as well, right? Yes, I'll try to.