Yeah, so excited to share with folks some of the recent areas we've been exploring thinking about machine learning for spatial biologies, for spatial omics. And also happy, really excited to discuss with you some of the open problems and challenges that I see are really interesting for method developers in this space. So let's see, okay. Yeah, so there's been a ton of, I think, really exciting recent. A ton of really exciting recent developments in terms of new technologies for generating high-throughput spatially resolved omics measurements. So, here I'm showing you a couple of examples of this. On the left is basically like spatial proteomics. This is measured with codex, a particular technology which I'll say a bit more about later. And what we're looking at here is basically the different colors corresponds to different antibody stains, right? So, all together here, we'll be able to measure. So, all together here, we'll be able to measure something like 40 to 100 different antibody stains simultaneously on the same tissue section. Here, I'm just showing you only four different stains because that's how many colors that we can, as humans, we can visualize. But there's just a really rich amount of information here, and you can make out the nuclei, individual nuclei, individual cells, as well as the morphology at the subcellular resolution. On the right here is examples of sort of spatial. Here is examples of sort of spatial transcratomic measurements. This is from Visium from 10X, where here we can also measure on the orders of several hundreds to thousands of genes. For each gene, we have measurements also around the spatially resolved. It's not quite that single cell resolution, but it's getting on the waters of maybe a neighborhood of tens of cells. Right, so the colors on each of this on this heat map corresponds to the expression of a particular gene facet. Of a particular gene fastened, and for other genes, for hundreds of other genes, you get similar maps. This is also measured simultaneously on the same tissue slots. So these kinds of technologies, I think, are super exciting because they are capturing things, often, for example, for proteins at single cell resolution. And in addition, it's capturing these molecular measurements in the native context of the cells of the tissues. So you didn't have to dissolve and to To dissolve and to isolate the cells, which in the process can really introduce a lot of perturbations. So, here we're actually being able to measure what the cells' native microenvironment actually looks like, and what is their molecular state in terms of their transcriptome and proteome. And this is especially, I mean, people are especially excited about using this kind of information to study, for example, tumor microenvironments, cell-cell interactions. And we'll come back to this in a bit. So, there are many different types of technologies people have. Different types of technologies people have developed for measuring these kinds of spatially resolved biology. So, I think at the sort of broad scope, they sort of fall under two main categories. One is based on imaging-based measurements, other is based on sequencing. So, I'll just give a quick overview of how people actually do these experiments because it's also quite clever and quite interesting. So, an example of the imaging-based technique for these spatial measurements is, I think a good example of this is by I think a good example of this is by Codex, which is called Code Detection by Indexing. And the idea here is that we have a bunch of different antibodies that we're interested in to measure simultaneously, then we can tag each of the antibodies with sort of DNA barcodes. And then the idea is actually quite intuitive, right? So we'll basically take this tissue section, which we can get from biopsy of a tumor, and then actually apply in different iterations. In different iterations, different combinations of antibodies. So, maybe in each iteration, we'll apply three antibodies, right? And then with different barcodes, so we can actually measure the so they correspond to different colors. And then just with microscopy, we can image them, then wash out those antibodies, and then apply the next set of three and do this iteratively. So, this is how people are able to currently measure on the order of self-management up to about 100 antibodies in parallel on the same. In parallel on the same tissue sections. So, the sequencing-based techniques is exemplified by sort of this VCM or spatial transotomic measurements. This is invented by one of my close collaborators, Joachim Blundberg. And the idea here is that you actually develop these chips. So, this is a chip here, and each thought on this chip corresponds to basically one probe or one set of probes. Here's the vertical cross. Of probes. Here's the vertical cross-section of this. And when you have a tissue section, you can just basically overlay the tissue section on top of the chip, right? And these probes will basically penetrate into the cells. And the probes have barcodes, which indicates the XY location of the probe. And when the barcode interacts or comes into contact with a transcript, we'll attach the XY location to the transcript. After this, you can do standard kind of sequencing, and then you have And then you have the XY locations of each of the individual transcripts. Okay, and then there's been a ton of excitements around this. This was also named the sort of nature methods, the method of year about a year ago. So I think especially for the students and for the researchers in this audience, I think these kinds of measurements and data really opens. And data really opens the door to a whole host of really interesting new computational questions. It's really revolved around how do we really analyze and model these kinds of spatial biology. So in my view, there are sort of two broad set of questions I think are really exciting. The first one is really around how do we take these kinds of really rich spatial information and try to identify spatially resolved motifs that are really disease relevant. And the second set of questions really around how do we really leverage the spatial information and to link the morphologies of the cells and the microenvironments with the molecular states, right? So that we can learn more information about these cellular interactions. So what I want to do for the presentation today is to sort of go through a bit of how we're thinking about the challenges and the methods in both of these questions. And I would really love to hear what people, any questions that people have and other thoughts that people have on this topic. People have, and other thoughts that people have on this topic. So, please feel free to interrupt me at any point. Okay, so for the first part, right, so now that we have these extremely rich images, right, so how do we really identify meaningful spatial microenvironments? And how do we really link these microenvironments to the disease outcome of the patients? Outcome of the patients. So, the approach that we've been developing is based on the idea of really trying to develop what we're calling these spatial cellular graphs. So, the idea is as follows. So, we take this very rich raw image. So, here is shown again an image, example of the raw codex image. Here, we're just visualizing about seven different antibodies, but you can imagine there's like another 40 plus antibodies that we don't have the. That we don't have the bandwidth to visualize here. The first thing that we do is to basically segment out from this raw codex image the individual cells. So this is visualized in the middle here with these Volnoid diagrams. And then we can turn this into this spatial cellular graph, where each node of the graph corresponds to one of the cells that we've segmented. And the edges indicate sort of the adjacencies of the cells. So there's an edge. Of the cells, right? So there's an edge if the two cells are neighbors in the actual tissue. So once we have this graphical representation, so the nice thing about this is it's actually quite flexible and it's able to capture both the topology and at different resolutions out of the tissue. And then what we do is to really look at these subgraphs, which corresponds to the local micro environments. Microborn environments. And we can look at subgraphs of different sizes. And computationally, we identified usually in many cases, a subgraph of sort of about three hops, right? Usually around 20 to 50 cells tends to capture most of the relevant biology. So we look at these three hop subgraphs. So here's one example of one of the subgraphs. If I just look at this dot here and then look at its neighbor, this is the subgraph here. Again, each node here corresponds. Again, each node here corresponds to one of the cells, and the node is also annotated with a rich set of features corresponding to that cell. So for each node, we have, for example, the 40 plus protein expression levels. We can also embed information about the morphology or the geometry of the cell and its nuclei. So, to model the interactions between the cells, right? So, we use actually a graph neural network. And the idea here is let's And the idea here is that it's basically modeling cell-cell interactions through message passing. So you look at the cell and you look at all of its neighbors. And with the neural network, it's basically that every iteration, there will actually be messages that are passed between each cell and its neighbor explicitly. So the message will basically contain information about what is the expression status of the neighbor and also the expression status and the morphology of the neighbor's neighbors. So this information, these messages will be passed. So, this information, these messages, will be passed around between all pairs of neighbors and will propagate throughout the different layers of the neural network. So, then all of that information is finally grouped together into one set of embeddings for each node, for each node of the graph, which is what we're calling sort of the embedding of the microenvironments at that node. And that's the information that we use to make these phenotype predictions. Right, so just to summarize this, we start with the individual graph, we'll look at extracts the local neighborhood. To look at extracts the local neighborhoods, local subgraph, and using this information we're able to predict for that local microenvironment, what is the corresponding disease status? Is that a healthy microenvironment or is that indicative of sort of tumor, certain kinds of tumor outcomes? So this is actually quite different from how people are currently analyzing these spatial data. So the current state-of-the-art approach is actually quite simple. It's basically just taking these local neighborhoods. It's basically just taking these local neighborhoods, people typically define a fixed neighborhood size, and then just represent the neighborhood actually by the cell type composition, right? So, how many T cells, how many granular sites, how many tumor cells. So, that actually basically loses all of the local geometries, which we want to capture more flexibly with the sub-graph approach. So, with this flexible graphical representation of these codex data, right, so we can do a variety of interesting. Data, right? So we can do a variety of interesting applications. So, one application I'm showing you here is actually using this to predict how a patient is going to respond to immunotherapies. So, as a part of the study, we've actually generated the largest set of codec samples to date, about 600 plus codec samples. These are all coming from patients with headed neck cancers. And we collect the samples before they started immunotherapy treatment. And basically, what we want to do is to predict just from these samples. Right, just from these samples, how well do they respond to the immunotherapy treatment? And we look at several different outcomes of interest. So, the primary outcome is basically how long do the patients survive, right? That's survival, but we can also look at secondary outcomes, like does the cancer come back, recurrence, etc. So we trained with these graph neural networks, we trained them on one set of patients, which all together corresponds to about 1.4 million cells. So, each sample would have on the orders of like Would have on the orders of like tens of thousands of cells. And then we tested on a different set of patients and samples from different cover slips. So here is basically the performance of the different models that we tried. So the SpaceGM is the one that we actually use this graph neural network approach that has this more flexible graphical representation. And a space lines, basically, what we can do is to train neural networks or train different models on top of just using low. Train different models atop of just using local cellular compositions, which is what people currently are doing. And we can really see that by more flexibly capturing the graphical structures, right, the topology of how the cells are arranged at this higher resolution, the model actually learns a lot more information that's predictive of patient response to immunotherapy compared to if we just simply use the local cellular compositions. And to show that the method is actually generalizable, we actually Generalizable, we actually took new patients from an entirely different site from Dina-Farber. And on these new patients, just taking the same model without any fine-tuning, it's actually still able to predict, to have make reasonably good predictions, and especially able to still show that the graphical structure is able to capture more information than just looking at a composition. So then it's really interesting to ask: okay, so what are the kinds of spatial? So, what are the kinds of spatial motifs that the model is actually able to pick up? And can we learn interesting biology by looking at these spatial motifs? So, I just want to show you one concrete example to illustrate the kinds of insights that we can learn. So, we'll be basically looking at these subgraphs. We can cluster the subgraphs and identify a whole list of maybe about 20 different spatial motifs. And I'm just focusing on like two of them. So, each row here corresponds to one of the spatial motifs we identified. So, the first spatial motif is essentially represented by one of the motif. Essentially, here's represented by one of these exemplar subgraphs. So, it basically corresponds to microenvironments where you have dispersed granular sites. So, the cells that are colored in brown basically are the granular sites and they're more dispersed. The second motif we found basically corresponds to microenvironments where you have more coherent granular sites. So, these brown cells are clustered together. So, everything else between these two microenvironments actually. Everything else between these two microenvironments is actually very similar. They have the similar number of tumor cells, lymphocytes, et cetera. So the only difference is basically the spatial coherence of these grandular sites, whether they're dispersed or whether they're clustered together. And it actually seems that the patient outcome is very different, depends on the presence of these more dispersed microenvironment or the more coherent microenvironment. So here's basically the outcome of the patients. Each dot corresponds to one patient. And then the red dots are Right, um, and then the red dots are basically um indicate no evidence of disease. These are the patients that actually have good outcomes. So, what we see here is that just empirically, that it seems like if the patients actually have more coherent granular site microenvironments, then they actually have tend to have better outcomes, better survival outcomes compared to patients that have more dispersed microenvironment granular sites. And the nice thing about this or a graphical About this or a graphical model is that we can actually verify many of these empirical findings computationally. So, one thing that we can do is to take this graph, this micro local subgraph, we can computationally permute the cells to make the granular sites more coherent. I just swap the granular sites with some neighbors until the granular sites actually cluster together. So, this is what I do in the top here. And we can see that computationally, when I cluster the granular sites to make them closer together, right, so that also. them closer together, right? So that also increases the model's prediction for good outcomes for the patient. So the x-axis here corresponds to how likely the patient is likely to survive as predicted by the model. And we make this coherent permutations, the patients have better survival likelihoods. In parallel, in contrast, if we take microenvironments where the grander sites are coherent and computationally in silico permute them to make them more dispersed, To make them more dispersed, that actually corresponds to the model predicts that that actually corresponds to worse patient outcomes, which is consistent with the experimental observations. So this demonstrates how we can actually use this graph neural network model. And because it's able to actually predict patient response to immunotherapies, then we can go back and interrogate the model to identify spatial motifs that are driving some of these. Describing some of these patient outcome predictions. In this case, one of the special motif corresponds to the coherence or dispersion of granular sites. And this is also consistent with what people are finding empirically in other studies. So let me pause here to see if people have any questions before I move on to the next part. Hi, so I understand the beauty of using this graph framework for the application that you're interested in, but because we are dealing with this spatial relationships of neighbors, did you use CNN at all as a baseline just to see what the performance looked like and if some of these could come from regular convolution? Yeah, it's a good question. So we have also trained. It's a good question. So, we have also trained in parallel CNN models, and we found pretty consistently that the graphical representation is more flexible, so it's more powerful than a CNN approach. And it's also easier to explain, easier to interrogate, right? Because with the graph representation, we can actually very easily do these kind of permutation experiments by extracting graph nodes, cells with their neighbors. And those kinds of permutations are harder to do with the CNN, because the CNN. To do was the CNN because the CNN typically is just dealing with image patches. So I can't really easily permute cells within an image patch. Yeah, I thought that was the case. So, when you say powerful, it's more about this downstream interesting analysis, but prediction accuracy-wise, it's... Yeah, so in terms of prediction accuracy, the graph model is also makes better predictions, has higher accuracy, and also more generalized growth in the CNN. I see. I see. We've also found that the CNN is more likely to be more prone to some of the bash effects in the images. Interesting. Great. Thank you. Okay, great. Now I'll keep going then. So, yeah, so I think there's certainly a lot of really, no, I think we're. Of really, um, no, I think we're just really scratching the surface of how to flexibly model these sort of spatial interactions, and I think there's a lot more open questions and room to do for developing new methods. So the second big area where I think there's definitely a lot of room for a new and interesting computational approach is to really understand how these cellular morphologies link to the molecular states or the expression or the protein state of the individual cells. Because that's really one of the powers. Because that's really one of the towers of the spatial data that's not really not so easily available with standard single-star RNA sequencing. And why do we want to do this? I think there are many reasons. I'll just highlight two of them here. First is that I think the morphology of the cells, of the tissue microenvironments, is actually very common, relatively easy to collect. So oftentimes you just go standard imaging where HNE histology. H and E histology can actually collect a lot of these morphology data. So, if we can actually make this linkage, then this basically becomes a way to integrate a lot more of the already available imaging data. A second reason is that by really linking the morphology and function with the cellular states, this helps us to identify some of the molecular basis how cells interact and how their functions depend on these interactions. So, as an illustration. So, it's an illustration of both of these. So, the first thing that we want to do is to actually see: can we actually use the morphology data to help us to just computationally impute the codex in silico? And the reason why we want to do this is because actually still collecting this kind of codex data is very expensive. And there are only a few groups in the world who can really do this at a high throughput and consistent fashion. And whereas these kind of morphology data. Whereas this kind of morphology data is actually very widely and commonly available. So, we've been working on this approach called encyclo multiplexing or encilical codex, where the idea is to basically take the cellular morphologies that we can get from these images, as well as a small number of commonly measured biomarkers. So, this you can measure them with the standard IHC kind of stains. And see, can we actually use this information to just impute? Use this information to just impute these multiplex codex images. So, here's an example of sort of a new biomarker at CD163 that's experimentally measured with codex. And these are ones that we're able to impute computationally just using the morphology of the cells along with some of these other biomarkers that are commonly measured, right? From different tissue sections of different patients. And how this in silico cortex workflow works? In silico codex workflow works is that basically we're taking the codecs measuring potentially up to 100 different markers. So we try to first select seven markers that are relatively common, is easy to collect. And we chose seven because that's where you can actually have, you know, there are cheaper and existing methods to do sort of sevenplex IHC measurements. And then we basically extract out the morphology informations at different resolutions around each of the cells. Resolutions around each of the cells. We extract the morphology information together with the information from these seven biomarkers, and we use this to basically impute the remaining biomarkers computationally. And this actually is what we call in silico codex, right? And it actually works relatively well. So here, the top here is basically corresponds to actual experimental codex measurements that we made. So the different colors indicated different cell types that we can identify by doing a 40plex. Identify by doing a 40plex codex of measuring 40 antibodies. And the bottom corresponds to the same information, the same cell types we can identify just by using the silica codex, where we started with only seven antibodies, right, and it computationally imputed the other 33. And then here I'm showing you basically how well the model performs at 25th, 50th, and 75th percentile. So 25th one, basically that's around the lower end of how well the model performs. End of how well the model performs. But even here, you can still see that it's able to capture mostly the right cell type composition in the microenvironments. And we've shown that this kind of similar strategies can also be used to impute spatial transphotomics in addition to spatial proteomics. So the idea is quite similar. We take this input here, just very standard HE images, which are very widely available, in this case from breast. Very widely available in this case from breast cancer patients. And the method, in this case, called STNETs, just take this, it's basically doing like an image-to-image translation, right? So it takes its inputs, the standard HIE histology image, and then computationally translate that into hundreds of new images. Each of the new computationally generated image corresponds to the spatially resolved expression profile of a different gene of interest. So in this case, let's say if you're interested in this fastin, which is a breast cancer biomarker, right, one of the mutely genetic One of the newly generated images would indicate what is the spatial resolved expression profile for FASAN. So the yellow regions are where it's highly expressed, and the blue regions are where it's predicted to be lowly expressed, just based on the morphology. If you're interested in a different gene, well, of the collagen markers, then you get a different set of expression profiles. And you can do this for, and we can do this pretty accurately for about 200 genes. And when we measured, you know, compared this with the actual experimental measurements, in this case, taken from the In this case, taking from the 10x Visium platform, we can actually validate that computationally generated spatial transcriptomics for these 200 genes actually match up quite well with experimental measurements. And we have more quantitative metrics to show this. And this also works well across different patients. And the approach is actually quite similar to what we do with the Codex case, right? So here, again, the idea is to look at Again, the idea is to look at the individual morphologies around local neighborhoods of individual cells. In this case, here I'm showing you the zoomed-in version of these local microenvironments around one of these H and E images. We extract out using convolutional CNN to extract out the morphologies features around each of these local patches. And this is what we use to impute the expressions of that local patch. It is done in sort of a multitask learning framework. Sort of a multitask learning framework. So there's about 200 genes where we're able to relatively accurately impute the expression directly just from the morphology itself. So these genes tend to be genes that we already have relatively highly expressed. So that's where we have more data from the spatial transitomic measurements. And also these genes are, in some sense, tend to be more visible from the morphologist. More visible from the morphology itself. By more visible, I mean these genes tend to be involved in cell growth, so more of the cellular architectures, mobility patterns, as well as immune activities. And interestingly, this actually captures a lot of the tumor markers as well as the immune markers. In addition to imputing the expression of these local neighborhoods, we could actually also use We could actually also use the morphology information to do basically spatial super resolution. So, what I mean by super resolution is that if you recall from how I described the initial technologies for spatial cryptotomics, it's actually not at single cell resolution, right? Because it's measured at these individual dots. So each dot corresponds to one probe, and each probe is basically capturing about 10 to 20 different cells. So when we are doing this measurement with Visium, Measurement with Viscm, we're actually really measuring the pseudo-bulk average expression of each of these local neighborhoods, about 20 or 10 cells. So the actual experimental data we get is for each gene of interest, we can get sort of one expression value for each of the probe, but each probe then is actually capturing the average expression not of an individual cell, but of a local neighborhood of cells. So it's a fairly pixelated measurement. Measurements. So, by combining the DISCM experimental measurements with the cellular morphology, we're able to super-resolve this computationally to get much higher spatial resolution at single-cell and sub-cellar resolution. So the second row corresponds to when we combine the morphology information, right, with the experimental measurements and the coarser measurements, we're able to computationally impute the expressions of each of these genes at much higher. Each of these genes at much higher spatial resolution. And this is also validated by looking at comparing it against experimental results when we do individual in situ hybridization for each of these genes of interest. So the actual algorithms end up being quite similar to the algorithms I described before. So I think the really nice thing about these kinds of by linking the morphology with the expressions that in the Morphology with expressions that, in addition to being to computationally impute this information or doing super resolution, we're able to really study some quite interesting biology. So now we actually have a single cell and sub-celler resolution, the spatially resolved expression patterns of individual genes of interest. And we also have their morphologies of the individual cells in the native states of the tissue. Then we can actually measure things like: okay, how does the morphology of the cells? Morphology of the cells associates with the expression levels of different genes. It's a sort of like a morphology-wide association study, where now the phenotype of interest is really the morphology of the individual cells as well as the morphology of the cells with their neighbors, which capture information like cell-cell interactions. So as an initial step of this, we did a sort of a simple analysis experiment here, where we just took a list of pretty relatively straightforward morphology. Straightforward morphological features of individual nuclei. So these are things like the size of the nuclei, the axis ratio, which is basically how elongated the nucleus are, and how dense the nuclei is, which sort of capture some information about the chromatin condensation. And each row of this basically corresponds to one of the genes, which where we can actually have single-cell resolution measurements, which result measurements for the expression of that gene. And then we can basically do this association to see, okay, so how does the expression of the E-Rep? To see, okay, so how does the expression of each of these genes correlate with the size of the nuclei, right, or with the elongation of the nuclei? And here are some of the, you know, a few examples of the kind of associations we can find. There are similar kinds of associations for hundreds of other genes that we can identify. Right, so the nice thing about this is that this is all done in the native context of the micro-environment of cells. So we didn't have to disturb the cells. And this enables us to potentially gain more information about sort of. Eventually, to gain more information about sort of the morphology and the function of these cells and how that relates to the transcriptome states. So, just to summarize and to wrap up here, right? So, I think, I mean, overall, I think there's really a lot of really exciting data that's being generated and new technologies being created, especially around spatial biology, both spatial proteomics and also spatial transcriptomics, and they capture complementary information. Complementary information. And the nice thing about these kinds of data is that many of them are at sort of single cell or sub-cellar resolution. And you can measure just from one sample on the orders of tens of thousands and soon to be 100,000 cells just from each of the individual samples. So one big challenge then from a computational perspective is how do we really model flexibly, right, mathematically, these kinds of very rich spatial data? And we propose that actually these kinds of. Now, we propose that actually these kind of cellular graph-based models is sort of a nice framework to flexibly capture many of these spatial motifs and cell-cell interactions. And in the case of patent cancer, we're able to identify spatial motifs that really predict how well patients are going to respond to immunotherapies, which is really one of the big questions in the cancer space. And in particular, we identified interpretable patterns such as the coherence or dispersions of granular sizes being really want to. Of granular size as being really one of the strongest spatial predictors of patient response. The other thing was quite exciting is to basically really link the morphology itself, right? So this kind of morphoas or morphology-wide association study, I guess, showed in the last couple of slides, I think this could be a really exciting direction going forward. So I'll just stop here. So some of these papers are very recent, they're just on the bio archive. I also want to thank my students who really led these works. Students who really led these works: Michael and Eric for these codex analysis, Brian working in collaboration with YoCam's group for the spatial transitomic analysis. So, I'll stop here and happy to take any further questions.