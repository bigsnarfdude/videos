So let's go over, I have some preliminaries. So throughout my entire talk, T is going to be a complete theory. U will be a monster model of T. And when I write X and Y, these will always denote tuples of variables. And then I have the definition of a Keyser measure, if you haven't seen it before. Okay, every time I give, I give this definition. So, okay, I didn't want to do it. It takes me away. So I just did it beforehand. So let A be a subset of U. A is a keys are measured in variable X over A, okay. X over A, okay. Uh-oh, did I mess this up? Oh, so excuse me, a Keyser measure in variable X over A is a finitely additive probability measure. Finally additive probability measure on Lx of A. So IE, right, mu is a Hieser measure that maps from Lx of A to 0, 1 with the following properties. So mu of x equals x is equal to 1. Mu of the negation of a 4 milliphy of xy is equal to 1 minus mu of 1. is equal to 1 minus mu of phi of x. And then we have this double counting rule. So the measure of phi of x union psi of x is the measure of phi of x plus the measure of psi of x minus through intersection. Okay? Okay, so we denote the space of ks or measures. So I'm just going to write km in variable x. In variable x over a and it's funny m. It's got three humps, x, a. What? The four? There's three. One, two, three, four. Four. The humps. What? Okay. Just a matter. So this question, or excuse me, this talk is about nice extensions. So what do I mean by nice? I need a definition. So, okay. Definition. So, okay, we have. I'm going to give you a definition of niceness. So, I'm going to let, say, M be a small sub-model of my monster model. And I'm going to let, say, mu. It meant to be substituted, excuse me, and it might be subscribed. It doesn't matter. Yeah, it really doesn't matter. But okay, if we want, we can do elementary substrate. It doesn't matter. You know, you are so the same. I know, I'm sorry. Okay, there we go. Okay, so I let mu be a global measure. Okay, one, we say, say we do nu, nu is definable over, say, m, right? F, okay, the following map, f mu phi, and I'll have to find what it is in a second. And I'll define what it is in a second. From the parameter space, excuse me, let me say, for any, it's definable over n, if for any, say, phi of xy without any variables, we have this map, f mu, phi, which maps from the parameter space to 0, 1, is well defined plus continuous. And what does this map do? Well, this map takes n a. Well, this map takes NA type and spits out the measure of a realization of that type, or B model s B. So you can check that this is a generalization of what it means for a type to be definable. No, Q is N over F, We say that a measure mu in a global measure, it is finally satisfiable in M if for any, say phi of x, then L of u, we have that if the measure of phi of x is greater than 0, this implies that the requirement. zero, because this implies that there exists some A and M such that, okay, u says that A satisfies. And then finally, okay, if I put these two properties together, this is the notion of niceness that I care about for this talk. So we say, mu is D of S. is D of S over, say, M, right, if, say, mu is both definable and finally satisfiable over F. So this is what I mean, of course, my talk, what I mean to be nice. So let me give kind of the classic example of these three types of measures. So I'm going to let, say, m So I'm going to let say m be the reals, just order. I take a monster model, I'd say m is elementary inside u. So if I draw my picture, like something like this, here's the reals, this is my whole model, then, okay, I have my co-air over the reals, I'm going to call this P. I have my error above the whole model, which I'm going to call Q. The whole model, which I'm going to call q. Okay? And then I'll give examples of each of the three. So the measure delta p is finally satisfiable at s over the reals. You can check if you're bored with this in my talk. The measure given by delta q is definable. Is definable. So you're called the type definitely type of definable. Because the type is definable, the measure is going to be definable. Yes. And then finally, if I define, say, lambda, my final measure, it's going to be the Lebesgue measure of the collection of real points. So R and R, such that U says that of R is true. This set intersects, say, 0 to 1. This measure is going to be both. This measure is going to be both defined one by any sets, by the way. It is both. What am I saying? It's DFS. Okay, so we have an example, but global type, or excuse me, global measures can be finally satisfiable. It's not definable. So not definable. This one is not finally satisfiable. Many sub-model. And this one is going to be the events. It's actually something stronger, it's more smooth, but okay. Stronger, quote, smooth, but okay, cool there is it. Okay, so I want to give some motivation. These are our definitions, but kind of in general, why do I care about extensions of measures? So in general, maybe low vision. I miss Logan. How do you prove things about measures? Well, in practice, it really helps if you know something about extensions. It really helps if you know something about extensions. So, looking at extensions, say, of measures, lets you prove things about measures. Okay, about the original measuring, yes. The original measure. And okay, so what do I mean if I can give you some What do I mean if I can give you some examples? So this first theorem is usually attributed to Kiesler. So Kiesler, it says essentially if you're in the NIP context, then nice extensions always exist. So, and this is going to be used to do a lot of things. So if, say, T is NIP, Is an IP, and say mu is a measure over a small set of parameters, then the theorem says that, okay, mu admits a nice extension. And okay, the theorem really says that it emits a smooth extension, which okay, we didn't define this, but it's a stronger version of DFS. But it's a stronger version of DFS. So thank it, strong, stronger than DFS. In practice, we think about smooth extensions as realizations of measures, in some sense. And this theorem is used to do, okay, kind of some important things. Sorry? Over a decreen hole. Yeah, so it makes an extension, right? So it's smooth over a peak of all. It pressed on only over a peak of a small set of parameters. Most of parameters. Yes. Yes. I mean, what does it mean to omit an extension? There's some global measure, right? Such that when I restrict the set of parameters, it equals mu, and over some larger model, it is smooth. So that's what I mean when somebody emits a nice explanation. UA is not even a model. Sorry? UA is not even a model. I need to be able to go. I don't need to be a bump, though. Okay, so what does this theorem let me prove? Well, from this theorem, you can prove the following. So, for instance, we need kind of this extension theorem to prove that, okay, the Morley product for measures is associative. Okay, this is only true in the NIP context, T is NIP. And we also need this to prove, okay, we don't need this to prove, but it can also show that if, say, mu is a global measure for u, nu is another global measure, maybe in variable y, and I look at the Borley product, mu times nu, this commutes. So nu mu times nu is the same as mu mu o times mu. So I have a version of Fubi. And this is really what's going on. Oh yeah, yeah, yeah, sorry. Mu is definable. Mu is finally satisfied. And again, I need that my whole theory is an IP. Does it need both or one of them? Sorry? I need both of these ones? Or both of these? Mu is defined, whole new is finally satisfied where I get the commuting and then my whole thing is a whole can be both. Sorry? Whole new can be both. Oh, if it's DFS? Oh, if it's DFS? Yeah, but then it's assumed by the statement. Right? By the statement. Okay, both of these can be proved via looking at smooth extensions. This one, you actually need... Sorry? Is there a question? I was thinking that it's enough for one of them to be DFS to have both. It's enough for one of them to be... Oh, it's BDFS, yes, that is true. In DNA path, that's most of them. But okay, I'm writing it like this because both of these theorems follow from Kiesler's original theorem. So there's the proofs of both of these. So proofs of both theorems which follow from Kiesler's original theorem. So from Kiesler's. I mean, I should also say that. I mean, I should also say that there's a proof, the original proof of this fact, right, is done by Russovsky-Play and Sloan, and it does not use, okay, smooth extensions. You don't need that to prove this, but you can. I mean, this is, it can follow from this. Okay. So, what do I want to say? I want to say the following. So, I have the following question. So, when, say, in general, So when, say in general, do measures, say emit, okay, nice extensions, right? I can even just say DFS extensions. Outside of an idea. So what is this true? And in general, okay, this is a hard question. But even if you knew it, it wouldn't apply the theorem part. So it does if you can get a thin extension, but I'm not going to. A FIM extension, but I'm not going to get into this right now. Yeah, so if you get a DFS extension, it's not enough, but if you get a generative stable extension, okay, a FIM extension, then you can actually get some things. But I'm just asking the question about, okay, in general, when do I get a dice extension? When do I get a DFS extension? In general, this is a hard question. I don't know what the answer is. Even kind of a more concrete question, I can just ask: suppose, or you know what, But you know, for example, though you can't. Can't what? Can't be able to describe it. Yes. So suppose. I mean, it's in this T one half infinity. I mean, it's hard to describe it. So suppose that mu is fem. So okay, if you don't know what this is, we can talk about it later. So if mu is fem, we can ask, does mu admit a smooth extension? Base moved extension. So these types of questions, I don't know the answers. But big theory is operative or global like that. Big theory. Yeah, so okay. You can ask whether or not it's, okay, the global measure admits a smooth eccentric to the larger monster model, right? This is what I'm saying. This is okay? No? Yeah. Okay. Sorry, but to be completely clear, you allow more parameters. So you want the extension to be DFS over a larger set of parameters. Yes, it's always over a larger. That's what I mean when I say an extension, right? I'm always going up to a larger. When I say an extension, right? I'm always going up to a larger set of parameters. Oh, no, I'm saying to measurly over a bigger set of parameters. But also, this is going to be DFS over a bigger set of parameters. Yes, yeah, yeah, yeah. DFS can be over a larger set of parameters. Yes, there's perfect. But okay, so these questions are hard, and you get a lot from them if you answer them correctly. But these are the questions that, okay, I'm not going to answer today. I'm going to answer the following. So, say, when does Then, does a measure say emit no. Nice extensions. So one cannot be as far away from, okay, being nice as possible, right? So, what's the difference between this question and the question? First of all, okay, I'm going to give a sufficient condition, so it doesn't give us fault. Sufficient condition, so it doesn't. It's not a. I can give you a sufficient condition for the last question. Okay, so for the purposes of this talk, we'll give a sufficient and we'll need to talk about, okay, packing numbers of measures. Okay, so here's my definition. So let, say, mu be a measure over a set of parameters. I'm going to let, say, phi is a formula. Okay, I can add parameters just from A. Then I would define the packing number with phi and epsilon of the phase. With phi and epsilon of my measure phi is going to be defined to be the largest, say, n, such that we have, okay, there exists some b, a subset of my parameters, such that, okay, the size of b is equal to n. And for any b and b prime, and b, which are distinct, so And B, which are distinct, so B is not equal to B prime, I have then the measure of this metric difference, when I plug these in, is greater than x. So we have the measure of phi of xb, to make the difference, phi of xb prime is triple greater than s. So this is my packing. So it's hard to get a lot of things. But standard technologies, these are the quite ones they actually all of these joint. Okay, so this is my definition for no code stuff. This is, you can call it whatever you want, but just number phi sub f1. It depends on capital A. It does depend on, yes, but my measure is just over capital A. And said B is a subset of A too. B is a subset of A, yes, and that's correct. The measure is associated to A. Come in on the measure. Associated to A. So I'm going to know the measure. Yeah, if you write it. Yeah. So, fun. Yes? Okay. So I can compute this. Okay. So what can this number be? Well, okay, so this number, say, what do you want to say? V sub epsilon of mu, right? It's lives inside the natural numbers, or it can be infinity, right? Plus infinity, if there's no number. No number. So, as a theorem, kind of the answer to this last question, giving a sufficient condition, so C V G H, we have that if, okay, if I let mu be inside Mx of A, and I suppose that there exists, say, some epsilon greater than zero, some formula the of x, y, and L x of A. And LXA such that my packing number, so fee, excuse me, dollars, what is this called? Hashtags? What is this called? Hashtags. Sean, okay. If my pegging number of mu is equal to infinity, then mu does not emit any DFS extensions. So it doesn't have any smooth extensions. So, doesn't it have any smooth extensions? It has not. So, if I have an infinite packing number, then mu does not admit a smooth extension. Excuse me, DFS extension. Can you move the path at the end? So, let mu be inside mx of n, right? So it's a measure over. So it's a measure over Lx of A. And suppose that I have one of these packing numbers is infinity. A lot of them. For one formula. Then mu does not emit a d of this subject. What's an example of one du solvent? I'll do that if you want. What? Related to all the first question would be solved, which was. No, I don't know. I don't know because, yeah, I don't, because if it was true, then Finn measurement wouldn't. Yeah, yeah. No, no, no. So. Yes. Okay, so let's discuss the proof. I mean, okay, so i.e., for every global measure, say mx of u, such that I'm looking restriction nu to A, which is equal to mu, we have that nu is not d of s. This is the true. This is for sure. That's what I precisely mean when I say does not admit to DFS extension. Over any model? Nowhere. It can't be anywhere. Over any. Over anywhere, yeah. Okay, so the proof of this is we need the following facts. You can make it a model if you want. We can make it a model. So not TFS over TFS over ASML. So let, okay, new be a global measure. A global measure. If new is D of S, say over M, then nu is phi optifuin. So this is an ingredient that we need in the proof. What do I mean? Okay. Precisely I mean that our math. What you find is what? Sorry? What do you find? Um for every feed, I should say, as included. For every V, I should say, an inclusive. So then, right? Then for any V, that's why we have that new is Viakinea. These are definable. What do I mean? You cannot just speak is a physical definite. Phi stands for something assumption. No, this is just a fact. It's a different fact. It is. Okay? You don't think you just. Yes, I'm about to state it. Okay. Okay. So, what do I mean? I.e., I mean that for every epsilon greater than zero, right? And, okay, there exists say formulas. So theta i, y, i less than n, such that, okay, these partition, say u, y. And we also have that, okay, if I look at the supremum, the difference between my function, f mu of phi, this function can be approximated by a finite sum of characteristic functions. So sum of i is equal to ones, and r i characteristic functions y of p2i of p stop number? Gender eyes or phi star formulas? They are phi star formulas, thank you. Yes. These are, no, this is in general. These live inside phi star of M. C form. What are the combinations? What? What are the combinations? Boolean combinations, yes. Mosets? Yes. No, just Boolean combinations. R i's are not 01, they are 0s. Sorry? The R i's, excuse me, yes, so the R i's are greater than 0 and they sum to 1. So this is what I mean by Q at the final. I can approximate this function by, okay, this function. Now we can prove the theory. Very cute. It's not very easy. We really need this if for whatever reason your measure always took the value zero for all these instances? Well, it can. Sorry. Sorry, I was being silly. What did you say? So if your function f mu phi always took the value zero for all the instances of phi, I mean it could happen. Why? I mean, you're actually going through this. We're actually going through this. So I can this could be inconsistent or something, right? It can still sometimes partition the whole thing, right? I mean, I'm happy if you allow the errors to be natural or bad, natural or zero. I mean, that's okay. But if you're assuming that they must be positive, I'm not happy. No, no, it's less than epsilon epsilon. Yes, less than epsilon. It's the sum equals one, epsilon. Why don't you look at zero? Because if you look at the perturbation, it's just. Yes, but are i greater or equals zero? Oh, yes, sir. Oh yeah, sorry, it's not a market. So all issues. Yes, yes. Yeah. You're not slicing, you're just okay, it's fine. Yeah, it's fine. Okay. Okay, so we can prove this. So let's prove the theorem. So I'm going to let mu be inside mx of k. I'm assuming that the packing number on some formula, phi of x epsilon. formula, excuse me, phi epsilon of mu is going to be equal to infinity. And I can assume, without loss of generality, that phi has no parameters. So phi is an L, say x, y of the empty set. It's okay, if it has parameters, then I just take them. I take them out, and I just have more, longer to so suppose. That I have some mu in m x of u, right, such that a mu's restriction to A, excuse me, mu's restriction to A is equal to mu, and mu, say, is dFs over some m, which contains a. Now, the formula that I want to consider, here's the trick, is the following. It's the following. So I'm going to let, say, psi of x, y1, y2 be equal to v of x, y1, symmetric difference, v of x, y2. So this is my formula. So since we have that v is d of s, We have that V is DFS over my model M. I have that, okay, F sub nu phi triangle phi is equal to F sub nu, say, of psi. I'm just rewriting it, it's the same thing. This is approximately, okay, I can choose an approximation, say epsilon over 3, to some function like this. Some function like this. So sum of i is equal to 1 to n r i is 1 theta i y 1 y 2. Since we know that hashtag, sorry, packing number feed epsilon of mu is equal to infinity, right? I have, say there exists a Say there exists a i by i and omega such that, okay, we have that mu of phi of x a i, symmetric difference phi of x aj is greater than epsilon. For i not equal to j, this is a combined because the backing number is only. Because the plug-in number is only getting five, sorry? A lot large enough. When we defined, okay, I mean, this was well defined when we defined it. We said if it's infinite, if I can find an infinite set, this is what we're going to... No, you can find. Okay, yes, it's the same, but for right now, I mean literally infinite. Okay, it's the same, but this is how I have the proof of it. This is how I had the proof of it. Is it actually possible that it actually is? Like in tags, you can notice that. And the computer. But it would be because we want to say tags. That's quite right. Oh, that's not right. And this AI, maybe you don't mean the master model, right? They're nothing in master. No, they're in A. I mean, okay. I mean, the way that I defined it with R. Just let me finish. Okay? So I'm going to let B. So I'm going to let B. Let's see the name of the closet. I'm going to let A be the parameters that occur inside, say, my set theta i, y1, y2, right, i less than n. And the whole point is that. And the whole point is that, okay, there exists a claim Ai and Aj, such that if I look at the type V star of AI over B, this is equal to the type of V star of AJ over B. Just by pigeonhole. Can I get like two minutes? Is that okay? Two minutes. Okay. So, okay. So, okay, so I get two types that are the same, and I claim that this implies that actually, if I look at the type of phi of, since then we're P star, of Ai Aj over B, this is the same as the type of Ai Ai over B. C is my triangle. So finally, So finally, if we just compute, we get yeah so AI AJ AI AI. So if I compute, so C i just C star C star. C star. Thank you. So finally I just need to compute, so we'll be done. So the measure of the symmetric difference between AI and AI And AI is equal to 0, which is equal to, okay, this function f new phi of the type of AI, AI over m, which I claim is approximately the epsilon over 3, by your assumption, the sum of i equals 1 to n of r i, say, these. Say these thetas by one by two of this type, Ai Aj over M, right? But here I only AIAI, thank you, right? But since they have the same type over B, and this only cares about what's going on with these parameters, this is the same as the sum of i is equal to 1 to n of, say, ri, theta i, y. Theta i, y, 1, y, 2, of the type of Ai Aj over m. So this follows from this right here, right? It's having the same type here. And so, okay, I mean, then we're done, right? Because this is f nu of phi, of the type of ai, a j over m, which we know needs to be greater than epsilon. To be greater than epsilon, right? And so we have a contradiction. Okay, thank you so much. I'm sorry I went up. So yeah, those really nice. I think we're running a little on time with some questions during the uh during the lecture. So maybe we'll uh just in the question time now and uh Question time now, and we'll have to talk to you about the extraction.