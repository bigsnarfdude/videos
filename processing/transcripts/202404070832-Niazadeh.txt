So, today I'm going to talk about my recent working paper, Robust Dynamic Establishment with Prediction, which is a joint work with my co-author, Gidding Feng, my great friend and colleague Baida Manchetti at Gale, and our co-author at Amazon, Sabon Habu. So two disclaimers. So the first one that this is pretty much a working paper, and literally this is the first time I'm giving a talk on this, and I haven't prepared much, so maybe I should not say that. For a camera, any feedback is extremely about. Feedback is extremely welcome. And then the second disclaimer: this is based on a joint collaboration with Amazon last month, but mostly I'm going to cover the theory part of the working talk. I'm happy to talk about the collaboration a little bit more if you're interested online. All right, so I was thinking about how to open this talk, and the title yesterday, David, had the perfect introduction for my talk. I wish I could have recorded him and replayed what he said. Let me repeat the. Let me repeat the version I have, which is probably not as good as David's version. So, this talk is basically about Tale of Two Cities. So, as the person who has been thinking about online algorithms for a while, on one hand, think about online algorithms and maybe the economical application, online resource allocation. When you are designing an algorithm that is making sequential decisions subject to some operational constraints, maybe software and demand, and then you are trying to optimize some economically justified objectives. And then, when it comes to the same thing, And then, when it comes to data, you have what I say limited use of data. Either you design fire free worst case type algorithms that they work against any input instance without any assumption, or we might actually encode the data in the form of distributions and then think of a Bayesian and try to design algorithm in the Bayesian work. On the other hand, you look at what's happening in machine learning, there is this also machine learning method. There is this awesome machine learning methods and tools that they provided with estimations and forecasts. And I would say they are way more effectively and adaptively using the huge amount of data that exists in many applications to train models. But their focus on machine learning tasks, like classification, regression. Still, with the use of that also, they provide the real-time decision maker with what I call sequential information. So this talk is really about how you can use sequential information. About how we can use sequential information in order to make sequential decisions in a robust fashion. So, I'm gonna make it more complex. So, let's talk about the specific motivating application, maybe even the main application of this work, which came out of our collaboration with Amazon last month. It's a problem, I'm gonna call it Amazon last month, the starting problem. So, am I liking this sense? Yeah, but in this case. So, think of the following problem. We look at the planning horizon, the point on the left is a sub. Horizon, the point on the left is a surface planning. The point on the right is what I call the operating day. So, this is imagine a station, last time the station on Amazon is operating. Two, three weeks before the operating day, they think about time. There are certain, what they call, under-the-roof tasks that they need to be done here. Imagine the workers, they are loading, unloading trucks, they are sorting out packages, and eventually the packages need to be delivered to houses. And then there is a target demand. And then there is a target demand. Think of it as the number of packages that need to be delivered on this thing. Okay? So now, the team I was working with were tasked with doing what they call sequential staffing, meaning that from the start of planning until the operating day, there are a certain number of days. And every day they have to decide how many workers they should hire, actually, how to schedule them to different jobs across different worker pools, the supply pools that they have access to. And in particular, And in particular, so there are Amazon fixed workers, that's the terminology they were using, which are the full-time workers. Working for Amazon, they're expensive but reliable. They need to be scheduled for a job far in advance because these people are workers, they care about their workers they more than anybody else, I hope. I don't count actually. And there's a limited number of them. But because you have to kind of fix their schedule early on, That are scheduled early on, they do the initial stuffing from this pool, and then there is a little bit of adjustment down the load. Then there is a second pool, the gig economy ready workers, which you should think of them as people that use some sort of jobboard or online platform to help the last one deliver packages. They have short response time through this job board. If you send announcement that here is a task, they're going to pick it up pretty quickly. They are cheaper, but less reliable when they can cancel. Reliable public and cancel. And most importantly, these are people that they become less and less available as closer to the operator. Like, for example, if I asked you to help me deliver packages tomorrow, it's less likely that you are available for that job versus if I asked you two weeks before. But you can't plan out. Alright? So the goal is trying to make these sequential stuffing decisions so that to minimize what I call the imbalance cost. This is a simplified objective. Cost. This is a simplified objective, but a thinking about this objective for the purpose of this talk, which is somehow the summation of the overstaffing and understaffing cost. Overstaffing happens when you hire multiple and the number of packages that need to be delivered. Imagine each person can just deliver one package or vote on one package, and understaffing is the other case. Good. That's a good question. Is there a pricing issue also? If I offer them more, then they'll be more responsive. Yes, definitely that transaction. The exact idea that, and that's actually the second part of the paper. I'm not going to talk about exactly, so that's really like one instance that you can provide, so it makes them more detailable. But I'm just going to talk about the band in a model needs. So the main challenge, similar to newsletter model, is that you don't have demand, this uncertain parameter. So in applications that the lead time is long, meaning that binding mentor is stopping, doesn't happen immediately, then usually one-time predictions is enough. So you just One-time predictions is enough. So you just predict the demand, maybe a distribution knowledge about the demand, and you call it a bit. But in an application like this, when you have short lead time, it's actually an opportunity that you use an entire arsenal of machine learning to do sequential demand forecasting. And when I was talking to them, it's like, hey, what do you do? They were like, well, we have 10 teams. Some of them are using recurrent neural network combined with time series. Some of them are using convolution neural network, combined with time series. And at the end of the day, these machine learning teams, quote-unquote machine learning teams, are. Machine learning teams, quote-unquote machine learning teams, are providing the algorithm team that I was working with, algorithmic team I was working with, with some sort of sequential demand prediction. And now, here is how I would like to think about that. There are many ways that you can model sequential demand forecasting. This is how I would like to think about it. So imagine there is this wicky-wacky curve. Think of it kind of like a Brownian motion, which is the demand forecast trajectory. So you don't see that as a So, you don't see that as a decision maker. You get to see some sort of estimation of that. So, as new inputs arrived, your estimation of this demand through the forecast becomes more and more accurate. So, at time zero, you basically get some information about the demand in the form of maybe a conformal prediction interval, maybe a just confidence interval. As you get closer and closer to the operating date, new data arrive with machine learning algorithms. So, their prediction about the demand becomes more and more accurate. Prediction about the demand comes more and more accurate. And when it gets very close to the operating data, it's actually part of the demand that is realist, nothing is certain prediction. You see some packages there, and then your estimation becomes extremely accurate very closely at operating day, and you know exactly demand on the day of operation. So now, when you put this sequential demand forecast technology together with the sequential assessment form of adventure link, you That's something from about mentioning, you see a trade-off. So, on one hand, as it gets closer to the operating day, your information about the demand is increasing. On the other hand, the supplies are becoming more and more scarce because workers become more and more unavailable as it gets closer to the operating day. And the info research question I'm going to ask in this talk, I'm going to try to answer that is how to design an online algorithm for sequential stopping that does this trade-off in some mathematical sense. Does this trade-off in some mathematical forms follow? Optimal? I'm going to formalize this question soon. And let me actually get to the model. So, this is the model I'm going to talk about today. And this is just a special case of the model that we investigate in the paper. So, imagine I have capital T number of days. It's the finite horizon. There are n heterogeneous supply pools of workers. Each one has an initial size. Let's call that SI. Let's call that SI. Imagine all the workers are available on the first day of planning. And then each worker becomes available with some probability at the beginning of every day. For example, worker I, worker in full I become or stays available with probability alpha I on each day T. Just a simplified part. And now I'm going to make a large market assumption that I'm going to work with fluid approximations. And when you think about the fluid relaxation of this probabilistic model, Of this probabilistic model, essentially, you start with a supply pool Si, and then the size of the pool in a fractional way is going to shrink at some rates. Let's call that rho it, which probably is equal to the product of all these 1 minus alpha it's. But this is kind of like the abstraction I would like to think about, that there is a shrinkage rate, rho it, rho i1 is greater than rho i t greater than rho i capital T for every pool I, these shrinkage curves are different for different pools. Are different for different posts, and they are given to you. And you start from SI, and then the supply issues are. Now, the online algorithm is making what I call the sequential stuffing decisions subject to supply constraints. And there is actually an easy way to write the supply constraints here. You can write the supply constraints basically by n equations. For each supply pool, the kind of the projected amount of hiring on day one should be no more than the initial. On day one should be no more than the initial supply value. For people that are familiar with net present value, this is pretty much like the net present value of your stuffing. And it should be no more than the amount of initial supply that you have. So such a staffing decision is called feasible. Quick question about the rules. Why are they decreasing? It's a product of 1 minus alpha it's. So it's going to be decreasing, in that sense. Okay, I say it's decreasing. Yes? Uh so this is a deterministic model. So you start from SI and then you have this curve. I'm just looking at the fluid application. So it's the probability model, the workers are independent, accurate themselves in one pool and accurate other workers in other pools. Uh do you have a sense of like a gap between the fluid and you can do concentration down and get some sort of like one minus one by a square root. Get some sort of like one minus one over a square root L if L is in the same system. Probably. So, depending on your distribution, you get a concentration bound, and that's the job. Like any other problem. 8P, do you know how many remain from the past? You get to see that. So, yeah, so let me talk about the online algorithm. The online problem that you're solving. X is greater than fluid too, right? What's that X's are fluid? X is a fluid. Everything is fluid. Except for the fruit. Everything is fruit. The very simple one. So the rows are assumed to be like interesting uncertainty in growing in the demand. Is it fair to say that the uncertainty grows a lot smaller than practice? That's true. So you know rows very well, and that's exactly what they told me, that hey, you can have a very good control of what the supply is available, but we don't really do it. That's why I assume that the demand is unknown. And if you consider some sort of demand D, There is some sort of demand, D, then this is the cost object that we try to produce. Somehow, the summation of the understaffing cost and overstaffing cost. Very standard. And now this is back to Warren's question. This is the online problem that we try to solve. On each day T, at the beginning of the day, imagine that there will be a prediction interval that is revealed to the online algorithms. So interval RT to LT or LT to RT. And I'm not coming. And I'm not going to make any assumption of this prediction interval. Imagine there is an adversary, an almighty adversary that is shooting you this prediction interval at time t. And then the online algorithm is making a feasible staffing decision XIT based on the history of the time t and the prediction that he received at that time, together with everything else that Daniel knows. I'm going to make that clear soon. So, how do I tell? So, how do I think about this sequential forecast? There are two properties I want the sequential forecast to satisfy. This can be adversarial, but I'm tying the hands of the adversary so that the predictions are consistent, which means the unknown demand at the end is going to be in all these intervals. And when you think about this for a second, without subjects, you can assume that we get to see nested intervals with the consistency error. And then the second one is the bounded error. So imagine that every time t, the length of the consistency. Time t, the length of the continuous interval or the length of the prediction interval is going to be no more than delta t, and this error term is known given to the online algorithm of time t. So now here is the sequential game play between an online algorithm and an adversary. And knowing the supply availability curve rho it and the error curve delta t, now consider an algorithm that is trying to minimize the costs by deciding the sequential. By deciding the sequential feasible decisions, adversary who is deciding on the sequential prediction intervals together with the final demand. And that defines the sequential min maximum. Where you can now define, for example, for a given algorithm, what is the cost current? What is the maximum cost that the algorithm will include against the worst-case sequence of prediction intervals and target demands? Right? Right? Now, here's the formal research question. Can we find the minimax optimal algorithm? Can we design or let's say compute or characterize a polynomial type online algorithm, ideally polynomial time, that achieves the best cost quality? In other words, it is mean-max optimal in this sequential. So the moment that you start thinking about this, you face some computational and also information political challenge, mostly because of the Political challenge, mostly because of the fact that the two players in this game, they have either exponential size or even have it exponential size strategy and spaces. So the minimizer with the algorithm should basically pitch as online algorithm in the space of all the online algorithms, which is already very complex. And then the adversary can be adaptive, history-dependent, and kind of based on each history at time t should decide on a prediction interval. So that's another. So that's another exponential size, or maybe even direct exponential size, depending on how you encode the strategies. So now this is the main result. It turns out that there exists a simple polynomial time deterministic min-max optimal learning algorithm. I'm going to call it LP emulator. It has two steps. The first step, I call it LP step. So given the known parameters of the problem, this algorithm is going to solve an offline optimization problem which turns out. Solve an offline optimization problem, which turns out to be a linear program. And use it, so that linear program gives you, quote-unquote, the value of this game, together with some canonical solution to start with. And then in the second step, the only third step of designing an online algorithm that tries to follow this empty solution as much as possible. And it turns out that when you combine the two steps, you get the minimum exotic output. There are a lot of practical extensions for this problem. Let me go over them very quickly in the interest of time. For example, if you have a budget for hiring, different pools might have different wages, some might be more expensive, some might be cheaper, pools might have different initial sizes, availability can be different. You might have different stations that you're jointly deciding for them. They are sharing the same supply pool, and then your goal is to minimize maybe the magic. And then your goal is to minimize maybe the maximum imbalance cost accuracy of stations, or maybe the sum of the imbalance costs accuracy the stations. You can think of the setting where you have multiple operating days and you're deciding on how to start for them jointly. You can also think about the case that these workers can cancel or you can cancel the assignments. So you hire someone later, you decide to kick them out because that's going to help you with bringing down the overstaffing costs. Staffing costs. So, all of those extensions can be captured in the model. So, the LP frame emulator framework that we have in the paper, which I'm not going to talk about in this talk, captures all of these extensions. I feel like knowing the deltas errors is a little bit stronger. Well, so many times, you know, so given the amount of data that you have, so there is a guarantee, the convergence rate of that machine learning algorithm, for example, or the error round of the machine learning algorithm. The error bound of the machine learning algorithm. This is basically what we get out of that image. Whether those error bounds are tight or not, that's a question for the ML team. Hopefully, they are. If they are tight bounds, then this is going to help us to destroy better. But that's the third one. But this is an objective. Are the costs? Right, it's the linear function. It doesn't need to be linear. The linear is for the simplification in this talk. The overstaffing cost or understaffing, you pay either, right? Or under something, you pay either, right? So you are either under something. And you are something times some chapter C, under something times particular C, and you sum them. Is it a function of the type of worker? Type of worker, no. But didn't you say one is cheaper? Right, so in the version of the paper, we have budget for the staffing, and then that will play a role. In the version, I'm presenting this talk. I'm not talking about imagine all sorts of equal elections. But like canceling on someone who is not on the Canceling on someone who is not on demand is worse than canceling on someone. That's true. So they can be captured in the extension. Okay. So in this talk, I just wanted to give you the crux of the idea, which is this trade-off between the information and stop-light shrinkage. But you're after this. That's what you need to think about in all of these extensions. The first one is the one that's relevant. If if if the interval given is confidence interval, can the framework incorporate that? Let's say every day I give you fifty ninety five percent as a confidence interval, or they minimize it. Right. So is there a way to extend that? You don't know the interval, you just have a point estimation together. There's a small probability that an interval will be reached, let's say. And let's say it will be. Right, yeah, so good. So if you have inconsistencies. Right. So we can capture inconsistencies. That's another extension we have in the paper. So how does the cost change in that sense, right? Because it's not worth it. So we can additive error in the cost. That is linear in the amount of inconsistencies. Linear in the amount of inconsistency, depending on how we define the inconsistency. So if epsilon fraction of the time somehow you're inconsistent, then that's going to appear as a linear extra term in the cost. But it doesn't scale up with T. I think that's important. Because we have a multiplicative way of defining some systems. Let's take a lot of time. So the objective doesn't reward for early scheduling. Early scheduling. So, why can't I wait? Why can't you delay? Why can't I delay because the supply is shrinking? You might actually lose your chance. I thought there were two types. So, the full time doesn't disappear. Well, so you need to schedule them in advance, so they disappear. Because you don't want to tell your worker to do something like tomorrow, like these types of workers, they need to be a scheduled employee. Otherwise, somebody is going to swap out. That was my understanding. That was my understanding. All right, so there is a vast literature that we connect to. Robot mechanism design, David mentioned, only decision making with advice. It's definitely a related literature to us. Many people in this audience have papers. It's related to inventory control, inventory management. There's really like a huge literature. In the interest of time, let me just skip over that. And how much time do you have? 10. Okay. So, in the next 10 minutes, let me try to give you some of the high-level ideas of how you can get these results. Let me just start with a recap. And the recap is that adversary is picking the final demand together with the predictions about LTRT. And the hard part is that this is the adversary's problem, how to find the worst case strategy against the algorithm, is the high-dimensional problem. So, here's a question that anyone should ask. So here's a question that anyone should ask when you think about the min-max problem with high-dimensional space. Can you actually identify a class of strategies, in this case for adversary, that in some sense, if you restrict the adversary, it's going to be without loss. Meaning that if I tie the hands of the adversary, at least it doesn't change the value of the j. Right? And it's a hard question to answer, typically, and even a hard question to come up with, because you need to identify that path. It turns out that in our problem, such a structure exists. A structure against. So there is a class, which I'm going to call them, single switch strategies, that basically, intuitively speaking, they try to push the allied album to think that, hey, it needs to hire a lot, because otherwise it's going to pay a lot of Android staffing costs. And then later switches to a different mode that fools down an algorithm to think that it's going to eventually pay a lot of now overstaffing costs. So, this is the adversary. Imagine there is a delta t, which is the length of the interval that's kind of going to fix, even though it was an upper bound. The Volski's adversary is just going to use all the power. So, the length of the prediction intervals is going to fix, but they can move around. And you also have the consistency, so they should be messed up. So, this is a switching adversary. It's always going to keep this top part the same until some switching point. And then after that, it's going to switch to prediction intervals at the lower parts of it. Or that the lower parts are. It turns out that if you restrict yourself to this, then this is going to be kind of without autogenicity. Not against any algorithm, but for the mean-max up to algorithm, this is the class in which it identifies the worst decides. Usually the minmax algorithm is the toner. Yes, let's actually talk about that. Let's just start from a simple example to see what does the mean-max alternative algorithm do. Single pool, this is the simplest version of the problem. You have just one pool, one demand, you get these. One demand, you get these sequence of predictions, and the supply is shrinking at some certain rate that is new. And you want to design the algorithm. All right, so let's say I want to force my algorithm to have over a staffing cost bounded by some number gamma. Then I say that any algorithm you think of should satisfy this invariant at every single time. The amount that you stop up to that point, minus L, at that time, should be no more than gamma over c. Than gamma over C. Why? Because just imagine a switching adversary that at some time switches to lowest interval. So the moment that it switches, it allows the adversary to pick L T at that time as the target demand. So if you want to ensure that overstaffing cost is no more than gamma, you better have this imbalance in every single round. And this is actually necessary and sufficient. Okay. All right, so that's observation number one. Observation number two. Observation number two: if I give you any demand, and then you have some staffing profile at access time, if you kind of like shift it to earlier time, then this is going to be a original staffing was feasible. The second one also is going to be feasible because supply is only shrinking over time. But not only that, in terms of understaffing cost, you are going to be weakly better. So you pay just weakly better understaffing cost, weekly. Understaffing cost, we can get a smaller understaffing cost. So now I put these observations together. That suggests that you want to do greediest stuffing while having the invariant in observation one. So that gives a very simple algorithm for this special case. Greedier stuffing with target overstaffing costs. So this algorithm has a parameter delta, omega, gamma. Parameter gamma, I need to work on my library teak. So you have to. Labor, you think. So you have gamma. At every time t, what it does is essentially tries to do greediest stuffing subject to that inequality in observation number one. And this is essentially what it does. So you plot some gamma in the algorithm, let's say some gamma star. I'm going to tell you what gamma star is. Then it's going to ensure that at every time the starting level is going to be L T plus some this gamma star divided by C. Some this gamma star divided by c, unless it runs out of subway, so there will be some realm that it runs off out of subway. After that, it's not going to do any stuffing. And back to your question, this is the mean max optimal. And the proof that this is min max optimal is almost at the level of a triviality given the two observations I had. Why? Because plug a gamma to be gamma star and run this algorithm. So because of observation number one, your understaffing cost is going to be at most gamma star. cost is going to be at most gamma star. Second, the optimal min-max, the min-max optimal algorithm has an overstaffing cost that is at most gamma star. So it should be in that class. At the same time, in terms of understaffing cost, the greediest staffing among everything in that class is the best. So therefore, the mean-max often algorithm is going to be basically this algorithm when you set gamma to be gamma staff. By just using observation models. And I implicitly use the fact that. And I implicitly use the fact that the adversary is going to be single switch, but it's going to play a more important role when I ask you this question how to find gamma star. Because if I know gamma star, I know how to run this algorithm. It turns out that all I need to do is think about these strategies, the single strings, and try to find an optimal algorithm against this. And that can be captured using a simple linear program. For this special case, actually, very simple fixed-point argument. So let's think about it. Let's say I have some gamma and then I start running my algorithm. After some time, I reach to this point. So I'm just running the algorithm against the adversary that switches. And the adversary is going to switch exactly at the time that the algorithm runs out of stuffing. So when I run the algorithm, then you have this picture. And this is going to be essentially the over stuffing under a stuffing cost that you calculate, the maximum possible under stuffing cost of the something. You understand something possible to something. And back to the monotony question, maybe this is what you were kind of referring to. It turns out that this maximum under something you pay is going to be monotone as a function, monotone decreasing as a function of gamma. Now I can hope to find a fixed point. So increasing gamma until this function of gamma becomes equal to gamma. And that, if you can find such a point, easily can show this is going to be the gamma star. You can show this is going to be the gamma star. And if you cannot find that point, basically you need to stop at time zero. And that again gives you another expression for gamma star. So this kind of like fixed-point argument gives you a way to calculate gamma spa. And when I got this result, I was like, there should be a cleaner way to describe this. And it turns out that linear programming is the solution. So for the general version of the problem, the multiple version, you can actually now think of restriction. Actually, now think of restricting yourself as the adversary to this cost. And then think of a linear program that characterizes, it seems to be a relaxation, someone characterizes the worst case cost against the adversary that can switch at any possible single time k. So this is the software constraint. This is the imbalance cost in the objective fundamental. This is the max of the two really by adding auxiliary vibrations which can make this a linear program. And this one is guaranteeing that your understaffing cost is no more than 10. Understaffing cost is no more than theta, and this is guaranteed that every time t, your overrestuffing cost is no more than lambda. And I'm just like restricting myself to the class of addresses that can switch at some point k from 1 to capital T. But this L P definitely is a realization to the problem. So whatever objective I get is going to be a lower bound on gamma star. Now, if I can give you an online algorithm that can satisfy this, that can get this objective value against This objective value against an arbitrary algorithm is the max optimum, and that's the emulator algorithm which I'm going to kind of tell you more about it. All right, cool. I'm almost done. So the TTV message, this is a new model for robot sequential staffing. It uses sequential information, kind of captures this trade-off between information and software scarcity. And there is a lot that I see needs to be done. Any feedback is welcome. You can download the paper. Welcome, you can download the paper from the QR code. And with that, I'm done. Thank you so much.